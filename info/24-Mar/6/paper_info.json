[
  {
    "id": "arXiv:2403.02354",
    "title": "Spatio-Temporal Field Neural Networks for Air Quality Inference",
    "abstract": "The air quality inference problem aims to utilize historical data from a limited number of observation sites to infer the air quality index at an unknown location. Considering the sparsity of data due to the high maintenance cost of the stations, good inference algorithms can effectively save the cost and refine the data granularity. While spatio-temporal graph neural networks have made excellent progress on this problem, their non-Euclidean and discrete data structure modeling of reality limits its potential. In this work, we make the first attempt to combine two different spatio-temporal perspectives, fields and graphs, by proposing a new model, Spatio-Temporal Field Neural Network, and its corresponding new framework, Pyramidal Inference. Extensive experiments validate that our model achieves state-of-the-art performance in nationwide air quality inference in the Chinese Mainland, demonstrating the superiority of our proposed model and framework. ",
    "url": "https://arxiv.org/abs/2403.02354",
    "authors": [
      "Yutong Feng",
      "Qiongyan Wang",
      "Yutong Xia",
      "Junlin Huang",
      "Siru Zhong",
      "Kun Wang",
      "Shifen Cheng",
      "Yuxuan Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.02355",
    "title": "Temporal Knowledge Graph Completion with Time-sensitive Relations in  Hypercomplex Space",
    "abstract": "Temporal knowledge graph completion (TKGC) aims to fill in missing facts within a given temporal knowledge graph at a specific time. Existing methods, operating in real or complex spaces, have demonstrated promising performance in this task. This paper advances beyond conventional approaches by introducing more expressive quaternion representations for TKGC within hypercomplex space. Unlike existing quaternion-based methods, our study focuses on capturing time-sensitive relations rather than time-aware entities. Specifically, we model time-sensitive relations through time-aware rotation and periodic time translation, effectively capturing complex temporal variability. Furthermore, we theoretically demonstrate our method's capability to model symmetric, asymmetric, inverse, compositional, and evolutionary relation patterns. Comprehensive experiments on public datasets validate that our proposed approach achieves state-of-the-art performance in the field of TKGC. ",
    "url": "https://arxiv.org/abs/2403.02355",
    "authors": [
      "Li Cai",
      "Xin Mao",
      "Zhihong Wang",
      "Shangqing Zhao",
      "Yuhao Zhou",
      "Changxu Wu",
      "Man Lan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.02360",
    "title": "Towards Optimal Customized Architecture for Heterogeneous Federated  Learning with Contrastive Cloud-Edge Model Decoupling",
    "abstract": "Federated learning, as a promising distributed learning paradigm, enables collaborative training of a global model across multiple network edge clients without the need for central data collecting. However, the heterogeneity of edge data distribution drags the model towards the local minima, which can be distant from the global optimum. Such heterogeneity often leads to slow convergence and substantial communication overhead. To address these issues, we propose a novel federated learning framework called FedCMD, a model decoupling tailored to the Cloud-edge supported federated learning that separates deep neural networks into a body for capturing shared representations in Cloud and a personalized head for migrating data heterogeneity. Our motivation is that, by the deep investigation of the performance of selecting different neural network layers as the personalized head, we found rigidly assigning the last layer as the personalized head in current studies is not always optimal. Instead, it is necessary to dynamically select the personalized layer that maximizes the training performance by taking the representation difference between neighbor layers into account. To find the optimal personalized layer, we utilize the low-dimensional representation of each layer to contrast feature distribution transfer and introduce a Wasserstein-based layer selection method, aimed at identifying the best-match layer for personalization. Additionally, a weighted global aggregation algorithm is proposed based on the selected personalized layer for the practical application of FedCMD. Extensive experiments on ten benchmarks demonstrate the efficiency and superior performance of our solution compared with nine state-of-the-art solutions. All code and results are available at https://github.com/elegy112138/FedCMD. ",
    "url": "https://arxiv.org/abs/2403.02360",
    "authors": [
      "Xingyan Chen",
      "Tian Du",
      "Mu Wang",
      "Tiancheng Gu",
      "Yu Zhao",
      "Gang Kou",
      "Changqiao Xu",
      "Dapeng Oliver Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.02367",
    "title": "adaptNMT: an open-source, language-agnostic development environment for  Neural Machine Translation",
    "abstract": "adaptNMT streamlines all processes involved in the development and deployment of RNN and Transformer neural translation models. As an open-source application, it is designed for both technical and non-technical users who work in the field of machine translation. Built upon the widely-adopted OpenNMT ecosystem, the application is particularly useful for new entrants to the field since the setup of the development environment and creation of train, validation and test splits is greatly simplified. Graphing, embedded within the application, illustrates the progress of model training, and SentencePiece is used for creating subword segmentation models. Hyperparameter customization is facilitated through an intuitive user interface, and a single-click model development approach has been implemented. Models developed by adaptNMT can be evaluated using a range of metrics, and deployed as a translation service within the application. To support eco-friendly research in the NLP space, a green report also flags the power consumption and kgCO$_{2}$ emissions generated during model development. The application is freely available. ",
    "url": "https://arxiv.org/abs/2403.02367",
    "authors": [
      "S\u00e9amus Lankford",
      "Haithem Afli",
      "Andy Way"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.02368",
    "title": "A Novel Hybrid Feature Importance and Feature Interaction Detection  Framework for Predictive Optimization in Industry 4.0 Applications",
    "abstract": "Advanced machine learning algorithms are increasingly utilized to provide data-based prediction and decision-making support in Industry 4.0. However, the prediction accuracy achieved by the existing models is insufficient to warrant practical implementation in real-world applications. This is because not all features present in real-world datasets possess a direct relevance to the predictive analysis being conducted. Consequently, the careful incorporation of select features has the potential to yield a substantial positive impact on the outcome. To address the research gap, this paper proposes a novel hybrid framework that combines the feature importance detector - local interpretable model-agnostic explanations (LIME) and the feature interaction detector - neural interaction detection (NID), to improve prediction accuracy. By applying the proposed framework, unnecessary features can be eliminated, and interactions are encoded to generate a more conducive dataset for predictive purposes. Subsequently, the proposed model is deployed to refine the prediction of electricity consumption in foundry processing. The experimental outcomes reveal an augmentation of up to 9.56% in the R2 score, and a diminution of up to 24.05% in the root mean square error. ",
    "url": "https://arxiv.org/abs/2403.02368",
    "authors": [
      "Zhipeng Ma",
      "Bo N\u00f8rregaard J\u00f8rgensen",
      "Zheng Grace Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.02411",
    "title": "NiNformer: A Network in Network Transformer with Token Mixing Generated  Gating Function",
    "abstract": "The Attention mechanism is the main component of the Transformer architecture, and since its introduction, it has led to significant advancements in Deep Learning that span many domains and multiple tasks. The Attention Mechanism was utilized in Computer Vision as the Vision Transformer ViT, and its usage has expanded into many tasks in the vision domain, such as classification, segmentation, object detection, and image generation. While this mechanism is very expressive and capable, it comes with the drawback of being computationally expensive and requiring datasets of considerable size for effective optimization. To address these shortcomings, many designs have been proposed in the literature to reduce the computational burden and alleviate the data size requirements. Examples of such attempts in the vision domain are the MLP-Mixer, the Conv-Mixer, the Perciver-IO, and many more. This paper introduces a new computational block as an alternative to the standard ViT block that reduces the compute burdens by replacing the normal Attention layers with a Network in Network structure that enhances the static approach of the MLP Mixer with a dynamic system of learning an element-wise gating function by a token mixing process. Extensive experimentation shows that the proposed design provides better performance than the baseline architectures on multiple datasets applied in the image classification task of the vision domain. ",
    "url": "https://arxiv.org/abs/2403.02411",
    "authors": [
      "Abdullah Nazhat Abdullah",
      "Tarkan Aydin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.02429",
    "title": "Towards efficient deep autoencoders for multivariate time series anomaly  detection",
    "abstract": "Multivariate time series anomaly detection is a crucial problem in many industrial and research applications. Timely detection of anomalies allows, for instance, to prevent defects in manufacturing processes and failures in cyberphysical systems. Deep learning methods are preferred among others for their accuracy and robustness for the analysis of complex multivariate data. However, a key aspect is being able to extract predictions in a timely manner, to accommodate real-time requirements in different applications. In the case of deep learning models, model reduction is extremely important to achieve optimal results in real-time systems with limited time and memory constraints. In this paper, we address this issue by proposing a novel compression method for deep autoencoders that involves three key factors. First, pruning reduces the number of weights, while preventing catastrophic drops in accuracy by means of a fast search process that identifies high sparsity levels. Second, linear and non-linear quantization reduces model complexity by reducing the number of bits for every single weight. The combined contribution of these three aspects allow the model size to be reduced, by removing a subset of the weights (pruning), and decreasing their bit-width (quantization). As a result, the compressed model is faster and easier to adopt in highly constrained hardware environments. Experiments performed on popular multivariate anomaly detection benchmarks, show that our method is capable of achieving significant model compression ratio (between 80% and 95%) without a significant reduction in the anomaly detection performance. ",
    "url": "https://arxiv.org/abs/2403.02429",
    "authors": [
      "Marcin Pietro\u0144",
      "Dominik \u017burek",
      "Kamil Faber",
      "Roberto Corizzo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.02439",
    "title": "Root Causing Prediction Anomalies Using Explainable AI",
    "abstract": "This paper presents a novel application of explainable AI (XAI) for root-causing performance degradation in machine learning models that learn continuously from user engagement data. In such systems a single feature corruption can cause cascading feature, label and concept drifts. We have successfully applied this technique to improve the reliability of models used in personalized advertising. Performance degradation in such systems manifest as prediction anomalies in the models. These models are typically trained continuously using features that are produced by hundreds of real time data processing pipelines or derived from other upstream models. A failure in any of these pipelines or an instability in any of the upstream models can cause feature corruption, causing the model's predicted output to deviate from the actual output and the training data to become corrupted. The causal relationship between the features and the predicted output is complex, and root-causing is challenging due to the scale and dynamism of the system. We demonstrate how temporal shifts in the global feature importance distribution can effectively isolate the cause of a prediction anomaly, with better recall than model-to-feature correlation methods. The technique appears to be effective even when approximating the local feature importance using a simple perturbation-based method, and aggregating over a few thousand examples. We have found this technique to be a model-agnostic, cheap and effective way to monitor complex data pipelines in production and have deployed a system for continuously analyzing the global feature importance distribution of continuously trained models. ",
    "url": "https://arxiv.org/abs/2403.02439",
    "authors": [
      "Ramanathan Vishnampet",
      "Rajesh Shenoy",
      "Jianhui Chen",
      "Anuj Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.02445",
    "title": "Free Proxies Unmasked: A Vulnerability and Longitudinal Analysis of Free  Proxy Services",
    "abstract": "Free-proxies have been widespread since the early days of the Web, helping users bypass geo-blocked content and conceal their IP addresses. Various proxy providers promise faster Internet or increased privacy while advertising their lists comprised of hundreds of readily available free proxies. However, while paid proxy services advertise the support of encrypted connections and high stability, free proxies often lack such guarantees, making them prone to malicious activities such as eavesdropping or modifying content. Furthermore, there is a market that encourages exploiting devices to install proxies. In this paper, we present a 30-month longitudinal study analyzing the stability, security, and potential manipulation of free web proxies that we collected from 11 providers. Our collection resulted in over 640,600 proxies, that we cumulatively tested daily. We find that only 34.5% of proxies were active at least once during our tests, showcasing the general instability of free proxies. Geographically, a majority of proxies originate from the US and China. Leveraging the Shodan search engine, we identified 4,452 distinct vulnerabilities on the proxies' IP addresses, including 1,755 vulnerabilities that allow unauthorized remote code execution and 2,036 that enable privilege escalation on the host device. Through the software analysis on the proxies' IP addresses, we find that 42,206 of them appear to run on MikroTik routers. Worryingly, we also discovered 16,923 proxies that manipulate content, indicating potential malicious intent by proxy owners. Ultimately, our research reveals that the use of free web proxies poses significant risks to users' privacy and security. The instability, vulnerabilities, and potential for malicious actions uncovered in our analysis lead us to strongly caution users against relying on free proxies. ",
    "url": "https://arxiv.org/abs/2403.02445",
    "authors": [
      "Naif Mehanna",
      "Walter Rudametkin",
      "Pierre Laperdrix",
      "Antoine Vastel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.02446",
    "title": "On Latency Predictors for Neural Architecture Search",
    "abstract": "Efficient deployment of neural networks (NN) requires the co-optimization of accuracy and latency. For example, hardware-aware neural architecture search has been used to automatically find NN architectures that satisfy a latency constraint on a specific hardware device. Central to these search algorithms is a prediction model that is designed to provide a hardware latency estimate for a candidate NN architecture. Recent research has shown that the sample efficiency of these predictive models can be greatly improved through pre-training on some \\textit{training} devices with many samples, and then transferring the predictor on the \\textit{test} (target) device. Transfer learning and meta-learning methods have been used for this, but often exhibit significant performance variability. Additionally, the evaluation of existing latency predictors has been largely done on hand-crafted training/test device sets, making it difficult to ascertain design features that compose a robust and general latency predictor. To address these issues, we introduce a comprehensive suite of latency prediction tasks obtained in a principled way through automated partitioning of hardware device sets. We then design a general latency predictor to comprehensively study (1) the predictor architecture, (2) NN sample selection methods, (3) hardware device representations, and (4) NN operation encoding schemes. Building on conclusions from our study, we present an end-to-end latency predictor training strategy that outperforms existing methods on 11 out of 12 difficult latency prediction tasks, improving latency prediction by 22.5\\% on average, and up to to 87.6\\% on the hardest tasks. Focusing on latency prediction, our HW-Aware NAS reports a $5.8\\times$ speedup in wall-clock time. Our code is available on \\href{https://github.com/abdelfattah-lab/nasflat_latency}{https://github.com/abdelfattah-lab/nasflat\\_latency}. ",
    "url": "https://arxiv.org/abs/2403.02446",
    "authors": [
      "Yash Akhauri",
      "Mohamed S. Abdelfattah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2403.02460",
    "title": "MagicClay: Sculpting Meshes With Generative Neural Fields",
    "abstract": "The recent developments in neural fields have brought phenomenal capabilities to the field of shape generation, but they lack crucial properties, such as incremental control - a fundamental requirement for artistic work. Triangular meshes, on the other hand, are the representation of choice for most geometry related tasks, offering efficiency and intuitive control, but do not lend themselves to neural optimization. To support downstream tasks, previous art typically proposes a two-step approach, where first a shape is generated using neural fields, and then a mesh is extracted for further processing. Instead, in this paper we introduce a hybrid approach that maintains both a mesh and a Signed Distance Field (SDF) representations consistently. Using this representation, we introduce MagicClay - an artist friendly tool for sculpting regions of a mesh according to textual prompts while keeping other regions untouched. Our framework carefully and efficiently balances consistency between the representations and regularizations in every step of the shape optimization; Relying on the mesh representation, we show how to render the SDF at higher resolutions and faster. In addition, we employ recent work in differentiable mesh reconstruction to adaptively allocate triangles in the mesh where required, as indicated by the SDF. Using an implemented prototype, we demonstrate superior generated geometry compared to the state-of-the-art, and novel consistent control, allowing sequential prompt-based edits to the same mesh for the first time. ",
    "url": "https://arxiv.org/abs/2403.02460",
    "authors": [
      "Amir Barda",
      "Vladimir G. Kim",
      "Noam Aigerman",
      "Amit H. Bermano",
      "Thibault Groueix"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2403.02472",
    "title": "OffLanDat: A Community Based Implicit Offensive Language Dataset  Generated by Large Language Model Through Prompt Engineering",
    "abstract": "The widespread presence of offensive languages on social media has resulted in adverse effects on societal well-being. As a result, it has become very important to address this issue with high priority. Offensive languages exist in both explicit and implicit forms, with the latter being more challenging to detect. Current research in this domain encounters several challenges. Firstly, the existing datasets primarily rely on the collection of texts containing explicit offensive keywords, making it challenging to capture implicitly offensive contents that are devoid of these keywords. Secondly, usual methodologies tend to focus solely on textual analysis, neglecting the valuable insights that community information can provide. In this research paper, we introduce a novel dataset OffLanDat, a community based implicit offensive language dataset generated by ChatGPT containing data for 38 different target groups. Despite limitations in generating offensive texts using ChatGPT due to ethical constraints, we present a prompt-based approach that effectively generates implicit offensive languages. To ensure data quality, we evaluate our data with human. Additionally, we employ a prompt-based Zero-Shot method with ChatGPT and compare the detection results between human annotation and ChatGPT annotation. We utilize existing state-of-the-art models to see how effective they are in detecting such languages. We will make our code and dataset public for other researchers. ",
    "url": "https://arxiv.org/abs/2403.02472",
    "authors": [
      "Amit Das",
      "Mostafa Rahgouy",
      "Dongji Feng",
      "Zheng Zhang",
      "Tathagata Bhattacharya",
      "Nilanjana Raychawdhary",
      "Mary Sandage",
      "Lauramarie Pope",
      "Gerry Dozier",
      "Cheryl Seals"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.02473",
    "title": "When do Convolutional Neural Networks Stop Learning?",
    "abstract": "Convolutional Neural Networks (CNNs) have demonstrated outstanding performance in computer vision tasks such as image classification, detection, segmentation, and medical image analysis. In general, an arbitrary number of epochs is used to train such neural networks. In a single epoch, the entire training data -- divided by batch size -- are fed to the network. In practice, validation error with training loss is used to estimate the neural network's generalization, which indicates the optimal learning capacity of the network. Current practice is to stop training when the training loss decreases and the gap between training and validation error increases (i.e., the generalization gap) to avoid overfitting. However, this is a trial-and-error-based approach which raises a critical question: Is it possible to estimate when neural networks stop learning based on training data? This research work introduces a hypothesis that analyzes the data variation across all the layers of a CNN variant to anticipate its near-optimal learning capacity. In the training phase, we use our hypothesis to anticipate the near-optimal learning capacity of a CNN variant without using any validation data. Our hypothesis can be deployed as a plug-and-play to any existing CNN variant without introducing additional trainable parameters to the network. We test our hypothesis on six different CNN variants and three different general image datasets (CIFAR10, CIFAR100, and SVHN). The result based on these CNN variants and datasets shows that our hypothesis saves 58.49\\% of computational time (on average) in training. We further conduct our hypothesis on ten medical image datasets and compared with the MedMNIST-V2 benchmark. Based on our experimental result, we save $\\approx$ 44.1\\% of computational time without losing accuracy against the MedMNIST-V2 benchmark. ",
    "url": "https://arxiv.org/abs/2403.02473",
    "authors": [
      "Sahan Ahmad",
      "Gabriel Trahan",
      "Aminul Islam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.02484",
    "title": "Encodings for Prediction-based Neural Architecture Search",
    "abstract": "Predictor-based methods have substantially enhanced Neural Architecture Search (NAS) optimization. The efficacy of these predictors is largely influenced by the method of encoding neural network architectures. While traditional encodings used an adjacency matrix describing the graph structure of a neural network, novel encodings embrace a variety of approaches from unsupervised pretraining of latent representations to vectors of zero-cost proxies. In this paper, we categorize and investigate neural encodings from three main types: structural, learned, and score-based. Furthermore, we extend these encodings and introduce \\textit{unified encodings}, that extend NAS predictors to multiple search spaces. Our analysis draws from experiments conducted on over 1.5 million neural network architectures on NAS spaces such as NASBench-101 (NB101), NB201, NB301, Network Design Spaces (NDS), and TransNASBench-101. Building on our study, we present our predictor \\textbf{FLAN}: \\textbf{Fl}ow \\textbf{A}ttention for \\textbf{N}AS. FLAN integrates critical insights on predictor design, transfer learning, and \\textit{unified encodings} to enable more than an order of magnitude cost reduction for training NAS accuracy predictors. Our implementation and encodings for all neural networks are open-sourced at \\href{https://github.com/abdelfattah-lab/flan_nas}{https://github.com/abdelfattah-lab/flan\\_nas}. ",
    "url": "https://arxiv.org/abs/2403.02484",
    "authors": [
      "Yash Akhauri",
      "Mohamed S. Abdelfattah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2403.02486",
    "title": "Demonstrating a Robust Walking Algorithm for Underactuated Bipedal  Robots in Non-flat, Non-stationary Environments",
    "abstract": "This work explores an innovative algorithm designed to enhance the mobility of underactuated bipedal robots across challenging terrains, especially when navigating through spaces with constrained opportunities for foot support, like steps or stairs. By combining ankle torque with a refined angular momentum-based linear inverted pendulum model (ALIP), our method allows variability in the robot's center of mass height. We employ a dual-strategy controller that merges virtual constraints for precise motion regulation across essential degrees of freedom with an ALIP-centric model predictive control (MPC) framework, aimed at enforcing gait stability. The effectiveness of our feedback design is demonstrated through its application on the Cassie bipedal robot, which features 20 degrees of freedom. Key to our implementation is the development of tailored nominal trajectories and an optimized MPC that reduces the execution time to under 500 microseconds--and, hence, is compatible with Cassie's controller update frequency. This paper not only showcases the successful hardware deployment but also demonstrates a new capability, a bipedal robot using a moving walkway. ",
    "url": "https://arxiv.org/abs/2403.02486",
    "authors": [
      "Oluwami Dosunmu-Ogunbi",
      "Aayushi Shrivastava",
      "Jessy W Grizzle"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.02491",
    "title": "Ivie: Lightweight Anchored Explanations of Just-Generated Code",
    "abstract": "Programming assistants have reshaped the experience of programming into one where programmers spend less time writing and more time critically examining code. In this paper, we explore how programming assistants can be extended to accelerate the inspection of generated code. We introduce an extension to the programming assistant called Ivie, or instantly visible in-situ explanations. When using Ivie, a programmer's generated code is instantly accompanied by explanations positioned just adjacent to the code. Our design was optimized for extremely low-cost invocation and dismissal. Explanations are compact and informative. They describe meaningful expressions, from individual variables to entire blocks of code. We present an implementation of Ivie that forks VS Code, applying a modern LLM for timely segmentation and explanation of generated code. In a lab study, we compared Ivie to a contemporary baseline tool for code understanding. Ivie improved understanding of generated code, and was received by programmers as a highly useful, low distraction, desirable complement to the programming assistant. ",
    "url": "https://arxiv.org/abs/2403.02491",
    "authors": [
      "Litao Yan",
      "Alyssa Hwang",
      "Zhiyuan Wu",
      "Andrew Head"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2403.02506",
    "title": "Differentially Private Representation Learning via Image Captioning",
    "abstract": "Differentially private (DP) machine learning is considered the gold-standard solution for training a model from sensitive data while still preserving privacy. However, a major barrier to achieving this ideal is its sub-optimal privacy-accuracy trade-off, which is particularly visible in DP representation learning. Specifically, it has been shown that under modest privacy budgets, most models learn representations that are not significantly better than hand-crafted features. In this work, we show that effective DP representation learning can be done via image captioning and scaling up to internet-scale multimodal datasets. Through a series of engineering tricks, we successfully train a DP image captioner (DP-Cap) on a 233M subset of LAION-2B from scratch using a reasonable amount of computation, and obtaining unprecedented high-quality image features that can be used in a variety of downstream vision and vision-language tasks. For example, under a privacy budget of $\\varepsilon=8$, a linear classifier trained on top of learned DP-Cap features attains 65.8% accuracy on ImageNet-1K, considerably improving the previous SOTA of 56.5%. Our work challenges the prevailing sentiment that high-utility DP representation learning cannot be achieved by training from scratch. ",
    "url": "https://arxiv.org/abs/2403.02506",
    "authors": [
      "Tom Sander",
      "Yaodong Yu",
      "Maziar Sanjabi",
      "Alain Durmus",
      "Yi Ma",
      "Kamalika Chaudhuri",
      "Chuan Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.02518",
    "title": "MPI Errors Detection using GNN Embedding and Vector Embedding over LLVM  IR",
    "abstract": "Identifying errors in parallel MPI programs is a challenging task. Despite the growing number of verification tools, debugging parallel programs remains a significant challenge. This paper is the first to utilize embedding and deep learning graph neural networks (GNNs) to tackle the issue of identifying bugs in MPI programs. Specifically, we have designed and developed two models that can determine, from a code's LLVM Intermediate Representation (IR), whether the code is correct or contains a known MPI error. We tested our models using two dedicated MPI benchmark suites for verification: MBI and MPI-CorrBench. By training and validating our models on the same benchmark suite, we achieved a prediction accuracy of 92% in detecting error types. Additionally, we trained and evaluated our models on distinct benchmark suites (e.g., transitioning from MBI to MPI-CorrBench) and achieved a promising accuracy of over 80%. Finally, we investigated the interaction between different MPI errors and quantified our models' generalization capabilities over new unseen errors. This involved removing error types during training and assessing whether our models could still predict them. The detection accuracy of removed errors varies significantly between 20% to 80%, indicating connected error patterns. ",
    "url": "https://arxiv.org/abs/2403.02518",
    "authors": [
      "Jad El Karchi",
      "Hanze Chen",
      "Ali TehraniJamsaz",
      "Ali Jannesari",
      "Mihail Popov",
      "Emmanuelle Saillard"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2403.02528",
    "title": "DACO: Towards Application-Driven and Comprehensive Data Analysis via  Code Generation",
    "abstract": "Data analysis is a crucial analytical process to generate in-depth studies and conclusive insights to comprehensively answer a given user query for tabular data. In this work, we aim to propose new resources and benchmarks to inspire future research on this crucial yet challenging and under-explored task. However, collecting data analysis annotations curated by experts can be prohibitively expensive. We propose to automatically generate high-quality answer annotations leveraging the code-generation capabilities of LLMs with a multi-turn prompting technique. We construct the DACO dataset, containing (1) 440 databases (of tabular data) collected from real-world scenarios, (2) ~2k query-answer pairs that can serve as weak supervision for model training, and (3) a concentrated but high-quality test set with human refined annotations that serves as our main evaluation benchmark. We train a 6B supervised fine-tuning (SFT) model on DACO dataset, and find that the SFT model learns reasonable data analysis capabilities. To further align the models with human preference, we use reinforcement learning to encourage generating analysis perceived by human as helpful, and design a set of dense rewards to propagate the sparse human preference reward to intermediate code generation steps. Our DACO-RL algorithm is evaluated by human annotators to produce more helpful answers than SFT model in 57.72% cases, validating the effectiveness of our proposed algorithm. Data and code are released at https://github.com/shirley-wu/daco ",
    "url": "https://arxiv.org/abs/2403.02528",
    "authors": [
      "Xueqing Wu",
      "Rui Zheng",
      "Jingzhen Sha",
      "Te-Lin Wu",
      "Hanyu Zhou",
      "Mohan Tang",
      "Kai-Wei Chang",
      "Nanyun Peng",
      "Haoran Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.02547",
    "title": "Projection Mapping under Environmental Lighting by Replacing Room Lights  with Heterogeneous Projectors",
    "abstract": "Projection mapping (PM) is a technique that enhances the appearance of real-world surfaces using projected images, enabling multiple people to view augmentations simultaneously, thereby facilitating communication and collaboration. However, PM typically requires a dark environment to achieve high-quality projections, limiting its practicality. In this paper, we overcome this limitation by replacing conventional room lighting with heterogeneous projectors. These projectors replicate environmental lighting by selectively illuminating the scene, excluding the projection target. Our contributions include a distributed projector optimization framework designed to effectively replicate environmental lighting and the incorporation of a large-aperture projector, in addition to standard projectors, to reduce high-luminance emitted rays and hard shadows -- undesirable factors for collaborative tasks in PM. We conducted a series of quantitative and qualitative experiments, including user studies, to validate our approach. Our findings demonstrate that our projector-based lighting system significantly enhances the contrast and realism of PM results even under environmental lighting compared to typical lights. Furthermore, our method facilitates a substantial shift in the perceived color mode from the undesirable aperture-color mode, where observers perceive the projected object as self-luminous, to the surface-color mode in PM. ",
    "url": "https://arxiv.org/abs/2403.02547",
    "authors": [
      "Masaki Takeuchi",
      "Hiroki Kusuyama",
      "Daisuke Iwai",
      "Kosuke Sato"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2403.02567",
    "title": "Eliciting Better Multilingual Structured Reasoning from LLMs through  Code",
    "abstract": "Development of large language models (LLM) have shown progress on reasoning, though studies have been limited to English or simple reasoning tasks. We thus introduce a multilingual structured reasoning and explanation dataset, termed xSTREET, that covers four tasks across six languages. xSTREET exposes a gap in base LLM performance between English and non-English reasoning tasks. We then propose two methods to remedy this gap, building on the insight that LLMs trained on code are better reasoners. First, at training time, we augment a code dataset with multi-lingual comments using machine translation while keeping program code as-is. Second, at inference time, we bridge the gap between training and inference by employing a prompt structure that incorporates step-by-step code primitives to derive new facts and find a solution. Our methods show improved multilingual performance on xSTREET, most notably on the scientific commonsense reasoning subtask. Furthermore, the models show no regression on non-reasoning tasks, thus showing our techniques maintain general-purpose abilities. ",
    "url": "https://arxiv.org/abs/2403.02567",
    "authors": [
      "Bryan Li",
      "Tamer Alkhouli",
      "Daniele Bonadiman",
      "Nikolaos Pappas",
      "Saab Mansour"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.02576",
    "title": "AceMap: Knowledge Discovery through Academic Graph",
    "abstract": "The exponential growth of scientific literature requires effective management and extraction of valuable insights. While existing scientific search engines excel at delivering search results based on relational databases, they often neglect the analysis of collaborations between scientific entities and the evolution of ideas, as well as the in-depth analysis of content within scientific publications. The representation of heterogeneous graphs and the effective measurement, analysis, and mining of such graphs pose significant challenges. To address these challenges, we present AceMap, an academic system designed for knowledge discovery through academic graph. We present advanced database construction techniques to build the comprehensive AceMap database with large-scale academic publications that contain rich visual, textual, and numerical information. AceMap also employs innovative visualization, quantification, and analysis methods to explore associations and logical relationships among academic entities. AceMap introduces large-scale academic network visualization techniques centered on nebular graphs, providing a comprehensive view of academic networks from multiple perspectives. In addition, AceMap proposes a unified metric based on structural entropy to quantitatively measure the knowledge content of different academic entities. Moreover, AceMap provides advanced analysis capabilities, including tracing the evolution of academic ideas through citation relationships and concept co-occurrence, and generating concise summaries informed by this evolutionary process. In addition, AceMap uses machine reading methods to generate potential new ideas at the intersection of different fields. Exploring the integration of large language models and knowledge graphs is a promising direction for future research in idea evolution. Please visit \\url{https://www.acemap.info} for further exploration. ",
    "url": "https://arxiv.org/abs/2403.02576",
    "authors": [
      "Xinbing Wang",
      "Luoyi Fu",
      "Xiaoying Gan",
      "Ying Wen",
      "Guanjie Zheng",
      "Jiaxin Ding",
      "Liyao Xiang",
      "Nanyang Ye",
      "Meng Jin",
      "Shiyu Liang",
      "Bin Lu",
      "Haiwen Wang",
      "Yi Xu",
      "Cheng Deng",
      "Shao Zhang",
      "Huquan Kang",
      "Xingli Wang",
      "Qi Li",
      "Zhixin Guo",
      "Jiexing Qi",
      "Pan Liu",
      "Yuyang Ren",
      "Lyuwen Wu",
      "Jungang Yang",
      "Jianping Zhou",
      "Chenghu Zhou"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.02586",
    "title": "Improving Event Definition Following For Zero-Shot Event Detection",
    "abstract": "Existing approaches on zero-shot event detection usually train models on datasets annotated with known event types, and prompt them with unseen event definitions. These approaches yield sporadic successes, yet generally fall short of expectations. In this work, we aim to improve zero-shot event detection by training models to better follow event definitions. We hypothesize that a diverse set of event types and definitions are the key for models to learn to follow event definitions while existing event extraction datasets focus on annotating many high-quality examples for a few event types. To verify our hypothesis, we construct an automatically generated Diverse Event Definition (DivED) dataset and conduct comparative studies. Our experiments reveal that a large number of event types (200) and diverse event definitions can significantly boost event extraction performance; on the other hand, the performance does not scale with over ten examples per event type. Beyond scaling, we incorporate event ontology information and hard-negative samples during training, further boosting the performance. Based on these findings, we fine-tuned a LLaMA-2-7B model on our DivED dataset, yielding performance that surpasses SOTA large language models like GPT-3.5 across three open benchmarks on zero-shot event detection. ",
    "url": "https://arxiv.org/abs/2403.02586",
    "authors": [
      "Zefan Cai",
      "Po-Nien Kung",
      "Ashima Suvarna",
      "Mingyu Derek Ma",
      "Hritik Bansal",
      "Baobao Chang",
      "P. Jeffrey Brantingham",
      "Wei Wang",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.02608",
    "title": "DNNLasso: Scalable Graph Learning for Matrix-Variate Data",
    "abstract": "We consider the problem of jointly learning row-wise and column-wise dependencies of matrix-variate observations, which are modelled separately by two precision matrices. Due to the complicated structure of Kronecker-product precision matrices in the commonly used matrix-variate Gaussian graphical models, a sparser Kronecker-sum structure was proposed recently based on the Cartesian product of graphs. However, existing methods for estimating Kronecker-sum structured precision matrices do not scale well to large scale datasets. In this paper, we introduce DNNLasso, a diagonally non-negative graphical lasso model for estimating the Kronecker-sum structured precision matrix, which outperforms the state-of-the-art methods by a large margin in both accuracy and computational time. Our code is available at https://github.com/YangjingZhang/DNNLasso. ",
    "url": "https://arxiv.org/abs/2403.02608",
    "authors": [
      "Meixia Lin",
      "Yangjing Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2403.02609",
    "title": "Search Intenion Network for Personalized Query Auto-Completion in  E-Commerce",
    "abstract": "Query Auto-Completion(QAC), as an important part of the modern search engine, plays a key role in complementing user queries and helping them refine their search intentions.Today's QAC systems in real-world scenarios face two major challenges:1)intention equivocality(IE): during the user's typing process,the prefix often contains a combination of characters and subwords, which makes the current intention ambiguous and difficult to model.2)intention transfer (IT):previous works make personalized recommendations based on users' historical sequences, but ignore the search intention transfer.However, the current intention extracted from prefix may be contrary to the historical preferences. ",
    "url": "https://arxiv.org/abs/2403.02609",
    "authors": [
      "Wei Bao",
      "Mi Zhang",
      "Tao Zhang",
      "Chengfu Huo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.02618",
    "title": "TinyGC-Net: An Extremely Tiny Network for Calibrating MEMS Gyroscopes",
    "abstract": "As the errors of microelectromechanical system (MEMS) gyroscopes are complex and nonlinear, the current calibration methods, which rely on linear models or networks with numerous parameters, are inadequate for low-cost embedded computing platforms to achieve both precision and real-time performance. In this paper, we introduce a extremely tiny network (TGC-Net) that characterizes the measurement model of MEMS gyroscopes. The network has a small number of parameters and can be trained on a central processing unit (CPU) before being deployed on a microcontroller unit (MCU). The TGC-Net leverage the robust data processing capabilities of deep learning to derive a nonlinear measurement model from fragmented gyroscope data. Subsequently, this model is used to regress errors on the gyroscope data. Moreover, we analyze the relationship between the compact network and the traditional linear model for MEMS gyroscopes, and emphasize the significance of the adequate angular motion stimulation for train the network. The experimental results, based on public datasets and real-world scenarios, demonstrate the practicality and effectiveness of the proposed method. These findings suggest that this technique is a viable candidate for applications that require MEMS gyroscopes. ",
    "url": "https://arxiv.org/abs/2403.02618",
    "authors": [
      "Cui Chao",
      "Zhao Jiankang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.02631",
    "title": "Privacy in Multi-agent Systems",
    "abstract": "With the increasing awareness of privacy and the deployment of legislations in various multi-agent system application domains such as power systems and intelligent transportation, the privacy protection problem for multi-agent systems is gaining increased traction in recent years. This article discusses some of the representative advancements in the filed. ",
    "url": "https://arxiv.org/abs/2403.02631",
    "authors": [
      "Yongqiang Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2403.02637",
    "title": "BSDP: Brain-inspired Streaming Dual-level Perturbations for Online Open  World Object Detection",
    "abstract": "Humans can easily distinguish the known and unknown categories and can recognize the unknown object by learning it once instead of repeating it many times without forgetting the learned object. Hence, we aim to make deep learning models simulate the way people learn. We refer to such a learning manner as OnLine Open World Object Detection(OLOWOD). Existing OWOD approaches pay more attention to the identification of unknown categories, while the incremental learning part is also very important. Besides, some neuroscience research shows that specific noises allow the brain to form new connections and neural pathways which may improve learning speed and efficiency. In this paper, we take the dual-level information of old samples as perturbations on new samples to make the model good at learning new knowledge without forgetting the old knowledge. Therefore, we propose a simple plug-and-play method, called Brain-inspired Streaming Dual-level Perturbations(BSDP), to solve the OLOWOD problem. Specifically, (1) we first calculate the prototypes of previous categories and use the distance between samples and the prototypes as the sample selecting strategy to choose old samples for replay; (2) then take the prototypes as the streaming feature-level perturbations of new samples, so as to improve the plasticity of the model through revisiting the old knowledge; (3) and also use the distribution of the features of the old category samples to generate adversarial data in the form of streams as the data-level perturbations to enhance the robustness of the model to new categories. We empirically evaluate BSDP on PASCAL VOC and MS-COCO, and the excellent results demonstrate the promising performance of our proposed method and learning manner. ",
    "url": "https://arxiv.org/abs/2403.02637",
    "authors": [
      "Yu Chen",
      "Liyan Ma",
      "Liping Jing",
      "Jian Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.02639",
    "title": "False Positive Sampling-based Data Augmentation for Enhanced 3D Object  Detection Accuracy",
    "abstract": "Recent studies have focused on enhancing the performance of 3D object detection models. Among various approaches, ground-truth sampling has been proposed as an augmentation technique to address the challenges posed by limited ground-truth data. However, an inherent issue with ground-truth sampling is its tendency to increase false positives. Therefore, this study aims to overcome the limitations of ground-truth sampling and improve the performance of 3D object detection models by developing a new augmentation technique called false-positive sampling. False-positive sampling involves retraining the model using point clouds that are identified as false positives in the model's predictions. We propose an algorithm that utilizes both ground-truth and false-positive sampling and an algorithm for building the false-positive sample database. Additionally, we analyze the principles behind the performance enhancement due to false-positive sampling and propose a technique that applies the concept of curriculum learning to the sampling strategy that encompasses both false-positive and ground-truth sampling techniques. Our experiments demonstrate that models utilizing false-positive sampling show a reduction in false positives and exhibit improved object detection performance. On the KITTI and Waymo Open datasets, models with false-positive sampling surpass the baseline models by a large margin. ",
    "url": "https://arxiv.org/abs/2403.02639",
    "authors": [
      "Jiyong Oh",
      "Junhaeng Lee",
      "Woongchan Byun",
      "Minsang Kong",
      "Sang Hun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.02652",
    "title": "AlloyInEcore: Embedding of First-Order Relational Logic into Meta-Object  Facility for Automated Model Reasoning",
    "abstract": "We present AlloyInEcore, a tool for specifying metamodels with their static semantics to facilitate automated, formal reasoning on models. Software development projects require that software systems be specified in various models (e.g., requirements models, architecture models, test models, and source code). It is crucial to reason about those models to ensure the correct and complete system specifications. AlloyInEcore allows the user to specify metamodels with their static semantics, while, using the semantics, it automatically detects inconsistent models, and completes partial models. It has been evaluated on three industrial case studies in the automotive domain (https://modelwriter.github.io/AlloyInEcore/). ",
    "url": "https://arxiv.org/abs/2403.02652",
    "authors": [
      "Ferhat Erata",
      "Arda Goknil",
      "Ivan Kurtev",
      "Bedir Tekinerdogan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2403.02665",
    "title": "DGAP: Efficient Dynamic Graph Analysis on Persistent Memory",
    "abstract": "Dynamic graphs, featuring continuously updated vertices and edges, have grown in importance for numerous real-world applications. To accommodate this, graph frameworks, particularly their internal data structures, must support both persistent graph updates and rapid graph analysis simultaneously, leading to complex designs to orchestrate `fast but volatile' and `persistent but slow' storage devices. Emerging persistent memory technologies, such as Optane DCPMM, offer a promising alternative to simplify the designs by providing data persistence, low latency, and high IOPS together. In light of this, we propose DGAP, a framework for efficient dynamic graph analysis on persistent memory. Unlike traditional dynamic graph frameworks, which combine multiple graph data structures (e.g., edge list or adjacency list) to achieve the required performance, DGAP utilizes a single mutable Compressed Sparse Row (CSR) graph structure with new designs for persistent memory to construct the framework. Specifically, DGAP introduces a \\textit{per-section edge log} to reduce write amplification on persistent memory; a \\textit{per-thread undo log} to enable high-performance, crash-consistent rebalancing operations; and a data placement schema to minimize in-place updates on persistent memory. Our extensive evaluation results demonstrate that DGAP can achieve up to $3.2\\times$ better graph update performance and up to $3.77\\times$ better graph analysis performance compared to state-of-the-art dynamic graph frameworks for persistent memory, such as XPGraph, LLAMA, and GraphOne. ",
    "url": "https://arxiv.org/abs/2403.02665",
    "authors": [
      "Abdullah Al Raqibul Islam",
      "Dong Dai"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2403.02667",
    "title": "G-EvoNAS: Evolutionary Neural Architecture Search Based on Network  Growth",
    "abstract": "The evolutionary paradigm has been successfully applied to neural network search(NAS) in recent years. Due to the vast search complexity of the global space, current research mainly seeks to repeatedly stack partial architectures to build the entire model or to seek the entire model based on manually designed benchmark modules. The above two methods are attempts to reduce the search difficulty by narrowing the search space. To efficiently search network architecture in the global space, this paper proposes another solution, namely a computationally efficient neural architecture evolutionary search framework based on network growth (G-EvoNAS). The complete network is obtained by gradually deepening different Blocks. The process begins from a shallow network, grows and evolves, and gradually deepens into a complete network, reducing the search complexity in the global space. Then, to improve the ranking accuracy of the network, we reduce the weight coupling of each network in the SuperNet by pruning the SuperNet according to elite groups at different growth stages. The G-EvoNAS is tested on three commonly used image classification datasets, CIFAR10, CIFAR100, and ImageNet, and compared with various state-of-the-art algorithms, including hand-designed networks and NAS networks. Experimental results demonstrate that G-EvoNAS can find a neural network architecture comparable to state-of-the-art designs in 0.2 GPU days. ",
    "url": "https://arxiv.org/abs/2403.02667",
    "authors": [
      "Juan Zou",
      "Weiwei Jiang",
      "Yizhang Xia",
      "Yuan Liu",
      "Zhanglu Hou"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2403.02681",
    "title": "SGD with Partial Hessian for Deep Neural Networks Optimization",
    "abstract": "Due to the effectiveness of second-order algorithms in solving classical optimization problems, designing second-order optimizers to train deep neural networks (DNNs) has attracted much research interest in recent years. However, because of the very high dimension of intermediate features in DNNs, it is difficult to directly compute and store the Hessian matrix for network optimization. Most of the previous second-order methods approximate the Hessian information imprecisely, resulting in unstable performance. In this work, we propose a compound optimizer, which is a combination of a second-order optimizer with a precise partial Hessian matrix for updating channel-wise parameters and the first-order stochastic gradient descent (SGD) optimizer for updating the other parameters. We show that the associated Hessian matrices of channel-wise parameters are diagonal and can be extracted directly and precisely from Hessian-free methods. The proposed method, namely SGD with Partial Hessian (SGD-PH), inherits the advantages of both first-order and second-order optimizers. Compared with first-order optimizers, it adopts a certain amount of information from the Hessian matrix to assist optimization, while compared with the existing second-order optimizers, it keeps the good generalization performance of first-order optimizers. Experiments on image classification tasks demonstrate the effectiveness of our proposed optimizer SGD-PH. The code is publicly available at \\url{https://github.com/myingysun/SGDPH}. ",
    "url": "https://arxiv.org/abs/2403.02681",
    "authors": [
      "Ying Sun",
      "Hongwei Yong",
      "Lei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2403.02689",
    "title": "Deep Common Feature Mining for Efficient Video Semantic Segmentation",
    "abstract": "Recent advancements in video semantic segmentation have made substantial progress by exploiting temporal correlations. Nevertheless, persistent challenges, including redundant computation and the reliability of the feature propagation process, underscore the need for further innovation. In response, we present Deep Common Feature Mining (DCFM), a novel approach strategically designed to address these challenges by leveraging the concept of feature sharing. DCFM explicitly decomposes features into two complementary components. The common representation extracted from a key-frame furnishes essential high-level information to neighboring non-key frames, allowing for direct re-utilization without feature propagation. Simultaneously, the independent feature, derived from each video frame, captures rapidly changing information, providing frame-specific clues crucial for segmentation. To achieve such decomposition, we employ a symmetric training strategy tailored for sparsely annotated data, empowering the backbone to learn a robust high-level representation enriched with common information. Additionally, we incorporate a self-supervised loss function to reinforce intra-class feature similarity and enhance temporal consistency. Experimental evaluations on the VSPW and Cityscapes datasets demonstrate the effectiveness of our method, showing a superior balance between accuracy and efficiency. ",
    "url": "https://arxiv.org/abs/2403.02689",
    "authors": [
      "Yaoyan Zheng",
      "Hongyu Yang",
      "Di Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.02692",
    "title": "Uplift Modeling for Target User Attacks on Recommender Systems",
    "abstract": "Recommender systems are vulnerable to injective attacks, which inject limited fake users into the platforms to manipulate the exposure of target items to all users. In this work, we identify that conventional injective attackers overlook the fact that each item has its unique potential audience, and meanwhile, the attack difficulty across different users varies. Blindly attacking all users will result in a waste of fake user budgets and inferior attack performance. To address these issues, we focus on an under-explored attack task called target user attacks, aiming at promoting target items to a particular user group. In addition, we formulate the varying attack difficulty as heterogeneous treatment effects through a causal lens and propose an Uplift-guided Budget Allocation (UBA) framework. UBA estimates the treatment effect on each target user and optimizes the allocation of fake user budgets to maximize the attack performance. Theoretical and empirical analysis demonstrates the rationality of treatment effect estimation methods of UBA. By instantiating UBA on multiple attackers, we conduct extensive experiments on three datasets under various settings with different target items, target users, fake user budgets, victim models, and defense models, validating the effectiveness and robustness of UBA. ",
    "url": "https://arxiv.org/abs/2403.02692",
    "authors": [
      "Wenjie Wang",
      "Changsheng Wang",
      "Fuli Feng",
      "Wentao Shi",
      "Daizong Ding",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2403.02693",
    "title": "Optimizing Mobile-Friendly Viewport Prediction for Live 360-Degree Video  Streaming",
    "abstract": "Viewport prediction is the crucial task for adaptive 360-degree video streaming, as the bitrate control algorithms usually require the knowledge of the user's viewing portions of the frames. Various methods are studied and adopted for viewport prediction from less accurate statistic tools to highly calibrated deep neural networks. Conventionally, it is difficult to implement sophisticated deep learning methods on mobile devices, which have limited computation capability. In this work, we propose an advanced learning-based viewport prediction approach and carefully design it to introduce minimal transmission and computation overhead for mobile terminals. We also propose a model-agnostic meta-learning (MAML) based saliency prediction network trainer, which provides a few-sample fast training solution to obtain the prediction model by utilizing the information from the past models. We further discuss how to integrate this mobile-friendly viewport prediction (MFVP) approach into a typical 360-degree video live streaming system by formulating and solving the bitrate adaptation problem. Extensive experiment results show that our prediction approach can work in real-time for live video streaming and can achieve higher accuracies compared to other existing prediction methods on mobile end, which, together with our bitrate adaptation algorithm, significantly improves the streaming QoE from various aspects. We observe the accuracy of MFVP is 8.1$\\%$ to 28.7$\\%$ higher than other algorithms and achieves 3.73$\\%$ to 14.96$\\%$ higher average quality level and 49.6$\\%$ to 74.97$\\%$ less quality level change than other algorithms. ",
    "url": "https://arxiv.org/abs/2403.02693",
    "authors": [
      "Lei Zhang",
      "Tao Long",
      "Weizhen Xu",
      "Laizhong Cui",
      "Jiangchuan Liu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2403.02695",
    "title": "Controllable Prompt Tuning For Balancing Group Distributional Robustness",
    "abstract": "Models trained on data composed of different groups or domains can suffer from severe performance degradation under distribution shifts. While recent methods have largely focused on optimizing the worst-group objective, this often comes at the expense of good performance on other groups. To address this problem, we introduce an optimization scheme to achieve good performance across groups and find a good solution for all without severely sacrificing performance on any of them. However, directly applying such optimization involves updating the parameters of the entire network, making it both computationally expensive and challenging. Thus, we introduce Controllable Prompt Tuning (CPT), which couples our approach with prompt-tuning techniques. On spurious correlation benchmarks, our procedures achieve state-of-the-art results across both transformer and non-transformer architectures, as well as unimodal and multimodal data, while requiring only 0.4% tunable parameters. ",
    "url": "https://arxiv.org/abs/2403.02695",
    "authors": [
      "Hoang Phan",
      "Andrew Gordon Wilson",
      "Qi Lei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.02698",
    "title": "Causal Walk: Debiasing Multi-Hop Fact Verification with Front-Door  Adjustment",
    "abstract": "Conventional multi-hop fact verification models are prone to rely on spurious correlations from the annotation artifacts, leading to an obvious performance decline on unbiased datasets. Among the various debiasing works, the causal inference-based methods become popular by performing theoretically guaranteed debiasing such as casual intervention or counterfactual reasoning. However, existing causal inference-based debiasing methods, which mainly formulate fact verification as a single-hop reasoning task to tackle shallow bias patterns, cannot deal with the complicated bias patterns hidden in multiple hops of evidence. To address the challenge, we propose Causal Walk, a novel method for debiasing multi-hop fact verification from a causal perspective with front-door adjustment. Specifically, in the structural causal model, the reasoning path between the treatment (the input claim-evidence graph) and the outcome (the veracity label) is introduced as the mediator to block the confounder. With the front-door adjustment, the causal effect between the treatment and the outcome is decomposed into the causal effect between the treatment and the mediator, which is estimated by applying the idea of random walk, and the causal effect between the mediator and the outcome, which is estimated with normalized weighted geometric mean approximation. To investigate the effectiveness of the proposed method, an adversarial multi-hop fact verification dataset and a symmetric multi-hop fact verification dataset are proposed with the help of the large language model. Experimental results show that Causal Walk outperforms some previous debiasing methods on both existing datasets and the newly constructed datasets. Code and data will be released at https://github.com/zcccccz/CausalWalk. ",
    "url": "https://arxiv.org/abs/2403.02698",
    "authors": [
      "Congzhi Zhang",
      "Linhai Zhang",
      "Deyu Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.02710",
    "title": "FastOcc: Accelerating 3D Occupancy Prediction by Fusing the 2D  Bird's-Eye View and Perspective View",
    "abstract": "In autonomous driving, 3D occupancy prediction outputs voxel-wise status and semantic labels for more comprehensive understandings of 3D scenes compared with traditional perception tasks, such as 3D object detection and bird's-eye view (BEV) semantic segmentation. Recent researchers have extensively explored various aspects of this task, including view transformation techniques, ground-truth label generation, and elaborate network design, aiming to achieve superior performance. However, the inference speed, crucial for running on an autonomous vehicle, is neglected. To this end, a new method, dubbed FastOcc, is proposed. By carefully analyzing the network effect and latency from four parts, including the input image resolution, image backbone, view transformation, and occupancy prediction head, it is found that the occupancy prediction head holds considerable potential for accelerating the model while keeping its accuracy. Targeted at improving this component, the time-consuming 3D convolution network is replaced with a novel residual-like architecture, where features are mainly digested by a lightweight 2D BEV convolution network and compensated by integrating the 3D voxel features interpolated from the original image features. Experiments on the Occ3D-nuScenes benchmark demonstrate that our FastOcc achieves state-of-the-art results with a fast inference speed. ",
    "url": "https://arxiv.org/abs/2403.02710",
    "authors": [
      "Jiawei Hou",
      "Xiaoyan Li",
      "Wenhao Guan",
      "Gang Zhang",
      "Di Feng",
      "Yuheng Du",
      "Xiangyang Xue",
      "Jian Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.02723",
    "title": "Minimum Topology Attacks for Graph Neural Networks",
    "abstract": "With the great popularity of Graph Neural Networks (GNNs), their robustness to adversarial topology attacks has received significant attention. Although many attack methods have been proposed, they mainly focus on fixed-budget attacks, aiming at finding the most adversarial perturbations within a fixed budget for target node. However, considering the varied robustness of each node, there is an inevitable dilemma caused by the fixed budget, i.e., no successful perturbation is found when the budget is relatively small, while if it is too large, the yielding redundant perturbations will hurt the invisibility. To break this dilemma, we propose a new type of topology attack, named minimum-budget topology attack, aiming to adaptively find the minimum perturbation sufficient for a successful attack on each node. To this end, we propose an attack model, named MiBTack, based on a dynamic projected gradient descent algorithm, which can effectively solve the involving non-convex constraint optimization on discrete topology. Extensive results on three GNNs and four real-world datasets show that MiBTack can successfully lead all target nodes misclassified with the minimum perturbation edges. Moreover, the obtained minimum budget can be used to measure node robustness, so we can explore the relationships of robustness, topology, and uncertainty for nodes, which is beyond what the current fixed-budget topology attacks can offer. ",
    "url": "https://arxiv.org/abs/2403.02723",
    "authors": [
      "Mengmei Zhang",
      "Xiao Wang",
      "Chuan Shi",
      "Lingjuan Lyu",
      "Tianchi Yang",
      "Junping Du"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.02730",
    "title": "A Two-Stage Training Method for Modeling Constrained Systems With Neural  Networks",
    "abstract": "Real-world systems are often formulated as constrained optimization problems. Techniques to incorporate constraints into Neural Networks (NN), such as Neural Ordinary Differential Equations (Neural ODEs), have been used. However, these introduce hyperparameters that require manual tuning through trial and error, raising doubts about the successful incorporation of constraints into the generated model. This paper describes in detail the two-stage training method for Neural ODEs, a simple, effective, and penalty parameter-free approach to model constrained systems. In this approach the constrained optimization problem is rewritten as two unconstrained sub-problems that are solved in two stages. The first stage aims at finding feasible NN parameters by minimizing a measure of constraints violation. The second stage aims to find the optimal NN parameters by minimizing the loss function while keeping inside the feasible region. We experimentally demonstrate that our method produces models that satisfy the constraints and also improves their predictive performance. Thus, ensuring compliance with critical system properties and also contributing to reducing data quantity requirements. Furthermore, we show that the proposed method improves the convergence to an optimal solution and improves the explainability of Neural ODE models. Our proposed two-stage training method can be used with any NN architectures. ",
    "url": "https://arxiv.org/abs/2403.02730",
    "authors": [
      "C. Coelho",
      "M. Fernanda P. Costa",
      "L.L. Ferr\u00e1s"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2403.02736",
    "title": "Bootstrapping Rare Object Detection in High-Resolution Satellite Imagery",
    "abstract": "Rare object detection is a fundamental task in applied geospatial machine learning, however is often challenging due to large amounts of high-resolution satellite or aerial imagery and few or no labeled positive samples to start with. This paper addresses the problem of bootstrapping such a rare object detection task assuming there is no labeled data and no spatial prior over the area of interest. We propose novel offline and online cluster-based approaches for sampling patches that are significantly more efficient, in terms of exposing positive samples to a human annotator, than random sampling. We apply our methods for identifying bomas, or small enclosures for herd animals, in the Serengeti Mara region of Kenya and Tanzania. We demonstrate a significant enhancement in detection efficiency, achieving a positive sampling rate increase from 2% (random) to 30%. This advancement enables effective machine learning mapping even with minimal labeling budgets, exemplified by an F1 score on the boma detection task of 0.51 with a budget of 300 total patches. ",
    "url": "https://arxiv.org/abs/2403.02736",
    "authors": [
      "Akram Zaytar",
      "Caleb Robinson",
      "Gilles Q. Hacheme",
      "Girmaw A. Tadesse",
      "Rahul Dodhia",
      "Juan M. Lavista Ferres",
      "Lacey F. Hughey",
      "Jared A. Stabach",
      "Irene Amoke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.02737",
    "title": "Neural Fractional Differential Equations",
    "abstract": "Fractional Differential Equations (FDEs) are essential tools for modelling complex systems in science and engineering. They extend the traditional concepts of differentiation and integration to non-integer orders, enabling a more precise representation of processes characterised by non-local and memory-dependent behaviours. This property is useful in systems where variables do not respond to changes instantaneously, but instead exhibit a strong memory of past interactions. Having this in mind, and drawing inspiration from Neural Ordinary Differential Equations (Neural ODEs), we propose the Neural FDE, a novel deep neural network architecture that adjusts a FDE to the dynamics of data. This work provides a comprehensive overview of the numerical method employed in Neural FDEs and the Neural FDE architecture. The numerical outcomes suggest that, despite being more computationally demanding, the Neural FDE may outperform the Neural ODE in modelling systems with memory or dependencies on past states, and it can effectively be applied to learn more intricate dynamical systems. ",
    "url": "https://arxiv.org/abs/2403.02737",
    "authors": [
      "C. Coelho",
      "M. Fernanda P. Costa",
      "L.L. Ferr\u00e1s"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2403.02738",
    "title": "Causal Prompting: Debiasing Large Language Model Prompting based on  Front-Door Adjustment",
    "abstract": "Despite the significant achievements of existing prompting methods such as in-context learning and chain-of-thought for large language models (LLMs), they still face challenges of various biases. Traditional debiasing methods primarily focus on the model training stage, including data augmentation-based and reweight-based approaches, with the limitations of addressing the complex biases of LLMs. To address such limitations, the causal relationship behind the prompting methods is uncovered using a structural causal model, and a novel causal prompting method based on front-door adjustment is proposed to effectively mitigate the bias of LLMs. In specific, causal intervention is implemented by designing the prompts without accessing the parameters and logits of LLMs.The chain-of-thoughts generated by LLMs are employed as the mediator variable and the causal effect between the input prompt and the output answers is calculated through front-door adjustment to mitigate model biases. Moreover, to obtain the representation of the samples precisely and estimate the causal effect more accurately, contrastive learning is used to fine-tune the encoder of the samples by aligning the space of the encoder with the LLM. Experimental results show that the proposed causal prompting approach achieves excellent performance on 3 natural language processing datasets on both open-source and closed-source LLMs. ",
    "url": "https://arxiv.org/abs/2403.02738",
    "authors": [
      "Congzhi Zhang",
      "Linhai Zhang",
      "Deyu Zhou",
      "Guoqiang Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.02744",
    "title": "Self-adaptive Traffic Anomaly Detection System for IoT Smart Home  Environments",
    "abstract": "With the growth of internet of things (IoT) devices, cyberattacks, such as distributed denial of service, that exploit vulnerable devices infected with malware have increased. Therefore, vendors and users must keep their device firmware updated to eliminate vulnerabilities and quickly handle unknown cyberattacks. However, it is difficult for both vendors and users to continually keep the devices safe because vendors must provide updates quickly and the users must continuously manage the conditions of all deployed devices. Therefore, to ensure security, it is necessary for a system to adapt autonomously to changes in cyberattacks. In addition, it is important to consider network-side security that detects and filters anomalous traffic at the gateway to comprehensively protect those devices. This paper proposes a self-adaptive anomaly detection system for IoT traffic, including unknown attacks. The proposed system comprises a honeypot server and a gateway. The honeypot server continuously captures traffic and adaptively generates an anomaly detection model using real-time captured traffic. Thereafter, the gateway uses the generated model to detect anomalous traffic. Thus, the proposed system can adapt to unknown attacks to reflect pattern changes in anomalous traffic based on real-time captured traffic. Three experiments were conducted to evaluate the proposed system: a virtual experiment using pre-captured traffic from various regions across the world, a demonstration experiment using real-time captured traffic, and a virtual experiment using a public dataset containing the traffic generated by malware. The experimental results indicate that a system adaptable in real time to evolving cyberattacks is a novel approach for ensuring the comprehensive security of IoT devices against both known and unknown attacks. ",
    "url": "https://arxiv.org/abs/2403.02744",
    "authors": [
      "Naoto Watanabe",
      "Taku Yamazaki",
      "Takumi Miyoshi",
      "Ryo Yamamoto",
      "Masataka Nakahara",
      "Norihiro Okui",
      "Ayumu Kubota"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.02745",
    "title": "CURATRON: Complete Robust Preference Data for Robust Alignment of Large  Language Models",
    "abstract": "This paper addresses the challenges of aligning large language models (LLMs) with human values via preference learning (PL), with a focus on the issues of incomplete and corrupted data in preference datasets. We propose a novel method for robustly and completely recalibrating values within these datasets to enhance LLMs resilience against the issues. In particular, we devise a guaranteed polynomial time ranking algorithm that robustifies several existing models, such as the classic Bradley--Terry--Luce (BTL) (Bradley and Terry, 1952) model and certain generalizations of it. To the best of our knowledge, our present work is the first to propose an algorithm that provably recovers an {\\epsilon}-optimal ranking with high probability while allowing as large as O(n) perturbed pairwise comparison results per model response. Furthermore, we show robust recovery results in the partially observed setting. Our experiments confirm that our algorithms handle adversarial noise and unobserved comparisons well in both general and LLM preference dataset settings. This work contributes to the development and scaling of more reliable and ethically aligned AI models by equipping the dataset curation pipeline with the ability to handle missing and maliciously manipulated inputs. ",
    "url": "https://arxiv.org/abs/2403.02745",
    "authors": [
      "Son The Nguyen",
      "Niranjan Uma Naresh",
      "Theja Tulabandhula"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.02753",
    "title": "Learning Group Activity Features Through Person Attribute Prediction",
    "abstract": "This paper proposes Group Activity Feature (GAF) learning in which features of multi-person activity are learned as a compact latent vector. Unlike prior work in which the manual annotation of group activities is required for supervised learning, our method learns the GAF through person attribute prediction without group activity annotations. By learning the whole network in an end-to-end manner so that the GAF is required for predicting the person attributes of people in a group, the GAF is trained as the features of multi-person activity. As a person attribute, we propose to use a person's action class and appearance features because the former is easy to annotate due to its simpleness, and the latter requires no manual annotation. In addition, we introduce a location-guided attribute prediction to disentangle the complex GAF for extracting the features of each target person properly. Various experimental results validate that our method outperforms SOTA methods quantitatively and qualitatively on two public datasets. Visualization of our GAF also demonstrates that our method learns the GAF representing fined-grained group activity classes. Code: https://github.com/chihina/GAFL-CVPR2024. ",
    "url": "https://arxiv.org/abs/2403.02753",
    "authors": [
      "Chihiro Nakatani",
      "Hiroaki Kawashima",
      "Norimichi Ukita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.02769",
    "title": "HUNTER: Unsupervised Human-centric 3D Detection via Transferring  Knowledge from Synthetic Instances to Real Scenes",
    "abstract": "Human-centric 3D scene understanding has recently drawn increasing attention, driven by its critical impact on robotics. However, human-centric real-life scenarios are extremely diverse and complicated, and humans have intricate motions and interactions. With limited labeled data, supervised methods are difficult to generalize to general scenarios, hindering real-life applications. Mimicking human intelligence, we propose an unsupervised 3D detection method for human-centric scenarios by transferring the knowledge from synthetic human instances to real scenes. To bridge the gap between the distinct data representations and feature distributions of synthetic models and real point clouds, we introduce novel modules for effective instance-to-scene representation transfer and synthetic-to-real feature alignment. Remarkably, our method exhibits superior performance compared to current state-of-the-art techniques, achieving a substantial 87.8\\% improvement in mAP and closely approaching the performance of fully supervised methods (62.15 mAP vs. 69.02 mAP) on HuCenLife. ",
    "url": "https://arxiv.org/abs/2403.02769",
    "authors": [
      "Yichen Yao",
      "Zimo Jiang",
      "Yujing Sun",
      "Zhencai Zhu",
      "Xinge Zhu",
      "Runnan Chen",
      "Yuexin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.02786",
    "title": "Semi-Supervised Graph Representation Learning with Human-centric  Explanation for Predicting Fatty Liver Disease",
    "abstract": "Addressing the challenge of limited labeled data in clinical settings, particularly in the prediction of fatty liver disease, this study explores the potential of graph representation learning within a semi-supervised learning framework. Leveraging graph neural networks (GNNs), our approach constructs a subject similarity graph to identify risk patterns from health checkup data. The effectiveness of various GNN approaches in this context is demonstrated, even with minimal labeled samples. Central to our methodology is the inclusion of human-centric explanations through explainable GNNs, providing personalized feature importance scores for enhanced interpretability and clinical relevance, thereby underscoring the potential of our approach in advancing healthcare practices with a keen focus on graph representation learning and human-centric explanation. ",
    "url": "https://arxiv.org/abs/2403.02786",
    "authors": [
      "So Yeon Kim",
      "Sehee Wang",
      "Eun Kyung Choe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.02803",
    "title": "Towards Robust Federated Learning via Logits Calibration on Non-IID Data",
    "abstract": "Federated learning (FL) is a privacy-preserving distributed management framework based on collaborative model training of distributed devices in edge networks. However, recent studies have shown that FL is vulnerable to adversarial examples (AEs), leading to a significant drop in its performance. Meanwhile, the non-independent and identically distributed (non-IID) challenge of data distribution between edge devices can further degrade the performance of models. Consequently, both AEs and non-IID pose challenges to deploying robust learning models at the edge. In this work, we adopt the adversarial training (AT) framework to improve the robustness of FL models against adversarial example (AE) attacks, which can be termed as federated adversarial training (FAT). Moreover, we address the non-IID challenge by implementing a simple yet effective logits calibration strategy under the FAT framework, which can enhance the robustness of models when subjected to adversarial attacks. Specifically, we employ a direct strategy to adjust the logits output by assigning higher weights to classes with small samples during training. This approach effectively tackles the class imbalance in the training data, with the goal of mitigating biases between local and global models. Experimental results on three dataset benchmarks, MNIST, Fashion-MNIST, and CIFAR-10 show that our strategy achieves competitive results in natural and robust accuracy compared to several baselines. ",
    "url": "https://arxiv.org/abs/2403.02803",
    "authors": [
      "Yu Qiao",
      "Apurba Adhikary",
      "Chaoning Zhang",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.02810",
    "title": "Dynamic Gaussian Graph Operator: Learning parametric partial  differential equations in arbitrary discrete mechanics problems",
    "abstract": "Deep learning methods have access to be employed for solving physical systems governed by parametric partial differential equations (PDEs) due to massive scientific data. It has been refined to operator learning that focuses on learning non-linear mapping between infinite-dimensional function spaces, offering interface from observations to solutions. However, state-of-the-art neural operators are limited to constant and uniform discretization, thereby leading to deficiency in generalization on arbitrary discretization schemes for computational domain. In this work, we propose a novel operator learning algorithm, referred to as Dynamic Gaussian Graph Operator (DGGO) that expands neural operators to learning parametric PDEs in arbitrary discrete mechanics problems. The Dynamic Gaussian Graph (DGG) kernel learns to map the observation vectors defined in general Euclidean space to metric vectors defined in high-dimensional uniform metric space. The DGG integral kernel is parameterized by Gaussian kernel weighted Riemann sum approximating and using dynamic message passing graph to depict the interrelation within the integral term. Fourier Neural Operator is selected to localize the metric vectors on spatial and frequency domains. Metric vectors are regarded as located on latent uniform domain, wherein spatial and spectral transformation offer highly regular constraints on solution space. The efficiency and robustness of DGGO are validated by applying it to solve numerical arbitrary discrete mechanics problems in comparison with mainstream neural operators. Ablation experiments are implemented to demonstrate the effectiveness of spatial transformation in the DGG kernel. The proposed method is utilized to forecast stress field of hyper-elastic material with geometrically variable void as engineering application. ",
    "url": "https://arxiv.org/abs/2403.02810",
    "authors": [
      "Chu Wang",
      "Jinhong Wu",
      "Yanzhi Wang",
      "Zhijian Zha",
      "Qi Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.02816",
    "title": "Efficient simulation of complex Ginzburg--Landau equations using  high-order exponential-type methods",
    "abstract": "In this paper, we consider the task of efficiently computing the numerical solution of evolutionary complex Ginzburg--Landau equations. To this aim, we employ high-order exponential methods of splitting and Lawson type for the time integration. These schemes enjoy favorable stability properties and, in particular, do not show restrictions on the time step size due to the underlying stiffness of the models. The needed actions of matrix exponentials are efficiently realized with pointwise operations in Fourier space (when the model is considered with periodic boundary conditions) or by using a tensor-oriented approach that suitably employs the so-called $\\mu$-mode products (when the semidiscretization in space is performed with finite differences). The overall effectiveness of the approach is demonstrated by running simulations on a variety of two- and three-dimensional (systems of) complex Ginzburg--Landau equations with cubic and cubic-quintic nonlinearities, which are widely considered in literature to model relevant physical phenomena. In fact, in all instances high-order exponential-type schemes can outperform standard techniques to integrate in time the models under consideration, i.e., the well-known split-step method and the explicit fourth-order Runge--Kutta integrator. ",
    "url": "https://arxiv.org/abs/2403.02816",
    "authors": [
      "Marco Caliari",
      "Fabio Cassini"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2403.02818",
    "title": "Are Dense Labels Always Necessary for 3D Object Detection from Point  Cloud?",
    "abstract": "Current state-of-the-art (SOTA) 3D object detection methods often require a large amount of 3D bounding box annotations for training. However, collecting such large-scale densely-supervised datasets is notoriously costly. To reduce the cumbersome data annotation process, we propose a novel sparsely-annotated framework, in which we just annotate one 3D object per scene. Such a sparse annotation strategy could significantly reduce the heavy annotation burden, while inexact and incomplete sparse supervision may severely deteriorate the detection performance. To address this issue, we develop the SS3D++ method that alternatively improves 3D detector training and confident fully-annotated scene generation in a unified learning scheme. Using sparse annotations as seeds, we progressively generate confident fully-annotated scenes based on designing a missing-annotated instance mining module and reliable background mining module. Our proposed method produces competitive results when compared with SOTA weakly-supervised methods using the same or even more annotation costs. Besides, compared with SOTA fully-supervised methods, we achieve on-par or even better performance on the KITTI dataset with about 5x less annotation cost, and 90% of their performance on the Waymo dataset with about 15x less annotation cost. The additional unlabeled training scenes could further boost the performance. The code will be available at https://github.com/gaocq/SS3D2. ",
    "url": "https://arxiv.org/abs/2403.02818",
    "authors": [
      "Chenqiang Gao",
      "Chuandong Liu",
      "Jun Shu",
      "Fangcen Liu",
      "Jiang Liu",
      "Luyu Yang",
      "Xinbo Gao",
      "Deyu Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.02834",
    "title": "Second-order robust parallel integrators for dynamical low-rank  approximation",
    "abstract": "Due to its reduced memory and computational demands, dynamical low-rank approximation (DLRA) has sparked significant interest in multiple research communities. A central challenge in DLRA is the development of time integrators that are robust to the curvature of the manifold of low-rank matrices. Recently, a parallel robust time integrator that permits dynamic rank adaptation and enables a fully parallel update of all low-rank factors was introduced. Despite its favorable computational efficiency, the construction as a first-order approximation to the augmented basis-update & Galerkin integrator restricts the parallel integrator's accuracy to order one. In this work, an extension to higher order is proposed by a careful basis augmentation before solving the matrix differential equations of the factorized solution. A robust error bound with an improved dependence on normal components of the vector field together with a norm preservation property up to small terms is derived. These analytic results are complemented and demonstrated through a series of numerical experiments. ",
    "url": "https://arxiv.org/abs/2403.02834",
    "authors": [
      "Jonas Kusch"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2403.02850",
    "title": "Scalable Syndrome-based Neural Decoders for Bit-Interleaved Coded  Modulations",
    "abstract": "In this work, we introduce a framework that enables the use of Syndrome-Based Neural Decoders (SBND) for high-order Bit-Interleaved Coded Modulations (BICM). To this end, we extend the previous results on SBND, for which the validity is limited to Binary Phase-Shift Keying (BPSK), by means of a theoretical channel modeling of the bit Log-Likelihood Ratio (bit-LLR) induced outputs. We implement the proposed SBND system for two polar codes $(64,32)$ and $(128,64)$, using a Recurrent Neural Network (RNN) and a Transformer-based architecture. Both implementations are compared in Bit Error Rate (BER) performance and computational complexity. ",
    "url": "https://arxiv.org/abs/2403.02850",
    "authors": [
      "Gast\u00f3n De Boni Rovella",
      "Meryem Benammar",
      "Tarik Benaddi",
      "Hugo Meric"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2403.02867",
    "title": "Scalable Continuous-time Diffusion Framework for Network Inference and  Influence Estimation",
    "abstract": "The study of continuous-time information diffusion has been an important area of research for many applications in recent years. When only the diffusion traces (cascades) are accessible, cascade-based network inference and influence estimation are two essential problems to explore. Alas, existing methods exhibit limited capability to infer and process networks with more than a few thousand nodes, suffering from scalability issues. In this paper, we view the diffusion process as a continuous-time dynamical system, based on which we establish a continuous-time diffusion model. Subsequently, we instantiate the model to a scalable and effective framework (FIM) to approximate the diffusion propagation from available cascades, thereby inferring the underlying network structure. Furthermore, we undertake an analysis of the approximation error of FIM for network inference. To achieve the desired scalability for influence estimation, we devise an advanced sampling technique and significantly boost the efficiency. We also quantify the effect of the approximation error on influence estimation theoretically. Experimental results showcase the effectiveness and superior scalability of FIM on network inference and influence estimation. ",
    "url": "https://arxiv.org/abs/2403.02867",
    "authors": [
      "Keke Huang",
      "Ruize Gao",
      "Bogdan Cautis",
      "Xiaokui Xiao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.02870",
    "title": "Precise Extraction of Deep Learning Models via Side-Channel Attacks on  Edge/Endpoint Devices",
    "abstract": "With growing popularity, deep learning (DL) models are becoming larger-scale, and only the companies with vast training datasets and immense computing power can manage their business serving such large models. Most of those DL models are proprietary to the companies who thus strive to keep their private models safe from the model extraction attack (MEA), whose aim is to steal the model by training surrogate models. Nowadays, companies are inclined to offload the models from central servers to edge/endpoint devices. As revealed in the latest studies, adversaries exploit this opportunity as new attack vectors to launch side-channel attack (SCA) on the device running victim model and obtain various pieces of the model information, such as the model architecture (MA) and image dimension (ID). Our work provides a comprehensive understanding of such a relationship for the first time and would benefit future MEA studies in both offensive and defensive sides in that they may learn which pieces of information exposed by SCA are more important than the others. Our analysis additionally reveals that by grasping the victim model information from SCA, MEA can get highly effective and successful even without any prior knowledge of the model. Finally, to evince the practicality of our analysis results, we empirically apply SCA, and subsequently, carry out MEA under realistic threat assumptions. The results show up to 5.8 times better performance than when the adversary has no model information about the victim model. ",
    "url": "https://arxiv.org/abs/2403.02870",
    "authors": [
      "Younghan Lee",
      "Sohee Jun",
      "Yungi Cho",
      "Woorim Han",
      "Hyungon Moon",
      "Yunheung Paek"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.02886",
    "title": "Revisiting Confidence Estimation: Towards Reliable Failure Prediction",
    "abstract": "Reliable confidence estimation is a challenging yet fundamental requirement in many risk-sensitive applications. However, modern deep neural networks are often overconfident for their incorrect predictions, i.e., misclassified samples from known classes, and out-of-distribution (OOD) samples from unknown classes. In recent years, many confidence calibration and OOD detection methods have been developed. In this paper, we find a general, widely existing but actually-neglected phenomenon that most confidence estimation methods are harmful for detecting misclassification errors. We investigate this problem and reveal that popular calibration and OOD detection methods often lead to worse confidence separation between correctly classified and misclassified examples, making it difficult to decide whether to trust a prediction or not. Finally, we propose to enlarge the confidence gap by finding flat minima, which yields state-of-the-art failure prediction performance under various settings including balanced, long-tailed, and covariate-shift classification scenarios. Our study not only provides a strong baseline for reliable confidence estimation but also acts as a bridge between understanding calibration, OOD detection, and failure prediction. The code is available at \\url{https://github.com/Impression2805/FMFP}. ",
    "url": "https://arxiv.org/abs/2403.02886",
    "authors": [
      "Fei Zhu",
      "Xu-Yao Zhang",
      "Zhen Cheng",
      "Cheng-Lin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.02889",
    "title": "In Search of Truth: An Interrogation Approach to Hallucination Detection",
    "abstract": "Despite the many advances of Large Language Models (LLMs) and their unprecedented rapid evolution, their impact and integration into every facet of our daily lives is limited due to various reasons. One critical factor hindering their widespread adoption is the occurrence of hallucinations, where LLMs invent answers that sound realistic, yet drift away from factual truth. In this paper, we present a novel method for detecting hallucinations in large language models, which tackles a critical issue in the adoption of these models in various real-world scenarios. Through extensive evaluations across multiple datasets and LLMs, including Llama-2, we study the hallucination levels of various recent LLMs and demonstrate the effectiveness of our method to automatically detect them. Notably, we observe up to 62% hallucinations for Llama-2 in a specific experiment, where our method achieves a Balanced Accuracy (B-ACC) of 87%, all without relying on external knowledge. ",
    "url": "https://arxiv.org/abs/2403.02889",
    "authors": [
      "Yakir Yehuda",
      "Itzik Malkiel",
      "Oren Barkan",
      "Jonathan Weill",
      "Royi Ronen",
      "Noam Koenigstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.02893",
    "title": "Zero-Shot Cross-Lingual Document-Level Event Causality Identification  with Heterogeneous Graph Contrastive Transfer Learning",
    "abstract": "Event Causality Identification (ECI) refers to detect causal relations between events in texts. However, most existing studies focus on sentence-level ECI with high-resource language, leaving more challenging document-level ECI (DECI) with low-resource languages under-explored. In this paper, we propose a Heterogeneous Graph Interaction Model with Multi-granularity Contrastive Transfer Learning (GIMC) for zero-shot cross-lingual document-level ECI. Specifically, we introduce a heterogeneous graph interaction network to model the long-distance dependencies between events that are scattered over document. Then, to improve cross-lingual transferability of causal knowledge learned from source language, we propose a multi-granularity contrastive transfer learning module to align the causal representations across languages. Extensive experiments show our framework outperforms previous state-of-the-art model by 9.4% and 8.2% of average F1 score on monolingual and multilingual scenarios respectively. Notably, in multilingual scenario, our zero-shot framework even exceeds GPT-3.5 with few-shot learning by 24.3% in overall performance. ",
    "url": "https://arxiv.org/abs/2403.02893",
    "authors": [
      "Zhitao He",
      "Pengfei Cao",
      "Yubo Chen",
      "Kang Liu",
      "Zhiqiang Zhang",
      "Mengshu Sun",
      "Jun Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.02909",
    "title": "Gaze-Vector Estimation in the Dark with Temporally Encoded Event-driven  Neural Networks",
    "abstract": "In this paper, we address the intricate challenge of gaze vector prediction, a pivotal task with applications ranging from human-computer interaction to driver monitoring systems. Our innovative approach is designed for the demanding setting of extremely low-light conditions, leveraging a novel temporal event encoding scheme, and a dedicated neural network architecture. The temporal encoding method seamlessly integrates Dynamic Vision Sensor (DVS) events with grayscale guide frames, generating consecutively encoded images for input into our neural network. This unique solution not only captures diverse gaze responses from participants within the active age group but also introduces a curated dataset tailored for low-light conditions. The encoded temporal frames paired with our network showcase impressive spatial localization and reliable gaze direction in their predictions. Achieving a remarkable 100-pixel accuracy of 100%, our research underscores the potency of our neural network to work with temporally consecutive encoded images for precise gaze vector predictions in challenging low-light videos, contributing to the advancement of gaze prediction technologies. ",
    "url": "https://arxiv.org/abs/2403.02909",
    "authors": [
      "Abeer Banerjee",
      "Naval K. Mehta",
      "Shyam S. Prasad",
      "Himanshu",
      "Sumeet Saurav",
      "Sanjay Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2403.02930",
    "title": "A Second Look on BASS -- Boosting Abstractive Summarization with Unified  Semantic Graphs -- A Replication Study",
    "abstract": "We present a detailed replication study of the BASS framework, an abstractive summarization system based on the notion of Unified Semantic Graphs. Our investigation includes challenges in replicating key components and an ablation study to systematically isolate error sources rooted in replicating novel components. Our findings reveal discrepancies in performance compared to the original work. We highlight the significance of paying careful attention even to reasonably omitted details for replicating advanced frameworks like BASS, and emphasize key practices for writing replicable papers. ",
    "url": "https://arxiv.org/abs/2403.02930",
    "authors": [
      "Osman Alperen Kora\u015f",
      "J\u00f6rg Schl\u00f6tterer",
      "Christin Seifert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.02934",
    "title": "iSummary: Workload-based, Personalized Summaries for Knowledge Graphs",
    "abstract": "The explosion in the size and the complexity of the available Knowledge Graphs on the web has led to the need for efficient and effective methods for their understanding and exploration. Semantic summaries have recently emerged as methods to quickly explore and understand the contents of various sources. However in most cases they are static not incorporating user needs and preferences and cannot scale. In this paper we present iSummary a novel scalable approach for constructing personalized summaries. As the size and the complexity of the Knowledge Graphs for constructing personalized summaries prohibit efficient summary construction, in our approach we exploit query logs. The main idea behind our approach is to exploit knowledge captured in existing user queries for identifying the most interesting resources and linking them constructing as such highquality personalized summaries. We present an algorithm with theoretical guarantees on the summarys quality linear in the number of queries available in the query log. We evaluate our approach using three realworld datasets and several baselines showing that our approach dominates other methods in terms of both quality and efficiency. ",
    "url": "https://arxiv.org/abs/2403.02934",
    "authors": [
      "Giannis Vassiliou",
      "Fanouris Alevizakis",
      "Nikolaos Papadakis",
      "Haridimos Kondylakis"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2403.02944",
    "title": "Neural Image Compression with Text-guided Encoding for both Pixel-level  and Perceptual Fidelity",
    "abstract": "Recent advances in text-guided image compression have shown great potential to enhance the perceptual quality of reconstructed images. These methods, however, tend to have significantly degraded pixel-wise fidelity, limiting their practicality. To fill this gap, we develop a new text-guided image compression algorithm that achieves both high perceptual and pixel-wise fidelity. In particular, we propose a compression framework that leverages text information mainly by text-adaptive encoding and training with joint image-text loss. By doing so, we avoid decoding based on text-guided generative models -- known for high generative diversity -- and effectively utilize the semantic information of text at a global level. Experimental results on various datasets show that our method can achieve high pixel-level and perceptual quality, with either human- or machine-generated captions. In particular, our method outperforms all baselines in terms of LPIPS, with some room for even more improvements when we use more carefully generated captions. ",
    "url": "https://arxiv.org/abs/2403.02944",
    "authors": [
      "Hagyeong Lee",
      "Minkyu Kim",
      "Jun-Hyuk Kim",
      "Seungeon Kim",
      "Dokwan Oh",
      "Jaeho Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.02950",
    "title": "A general approach to enhance the survivability of backdoor attacks by  decision path coupling",
    "abstract": "Backdoor attacks have been one of the emerging security threats to deep neural networks (DNNs), leading to serious consequences. One of the mainstream backdoor defenses is model reconstruction-based. Such defenses adopt model unlearning or pruning to eliminate backdoors. However, little attention has been paid to survive from such defenses. To bridge the gap, we propose Venom, the first generic backdoor attack enhancer to improve the survivability of existing backdoor attacks against model reconstruction-based defenses. We formalize Venom as a binary-task optimization problem. The first is the original backdoor attack task to preserve the original attack capability, while the second is the attack enhancement task to improve the attack survivability. To realize the second task, we propose attention imitation loss to force the decision path of poisoned samples in backdoored models to couple with the crucial decision path of benign samples, which makes backdoors difficult to eliminate. Our extensive evaluation on two DNNs and three datasets has demonstrated that Venom significantly improves the survivability of eight state-of-the-art attacks against eight state-of-the-art defenses without impacting the capability of the original attacks. ",
    "url": "https://arxiv.org/abs/2403.02950",
    "authors": [
      "Yufei Zhao",
      "Dingji Wang",
      "Bihuan Chen",
      "Ziqian Chen",
      "Xin Peng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.02953",
    "title": "Single-level Robust Bidding of Renewable-only Virtual Power Plant in  Energy and Ancillary Service Markets for Worst-case Profit",
    "abstract": "This paper proposes a novel single-level robust mathematical approach to model the RES-only Virtual Power Plant (RVPP) bidding problem in the simultaneous Day Ahead Market (DAM) and Secondary Reserve Market (SRM). The worst-case profit of RVPP due to uncertainties related to electricity prices, Non-dispatchable Renewable Energy Sources (ND-RES) production, and flexible demand is captured. In order to find the worst-case profit in a single-level model, the relationship between price and energy uncertainties leads to some non-linear constraints, which are appropriately linearized. The simulation results show the superiority of the proposed robust model compared to those in the literature, as well as its computational efficiency. ",
    "url": "https://arxiv.org/abs/2403.02953",
    "authors": [
      "Hadi Nemati",
      "Pedro S\u00e1nchez-Mart\u00edn",
      "Ana Baringo",
      "\u00c1lvaro Ortega"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.02955",
    "title": "XAI-Based Detection of Adversarial Attacks on Deepfake Detectors",
    "abstract": "We introduce a novel methodology for identifying adversarial attacks on deepfake detectors using eXplainable Artificial Intelligence (XAI). In an era characterized by digital advancement, deepfakes have emerged as a potent tool, creating a demand for efficient detection systems. However, these systems are frequently targeted by adversarial attacks that inhibit their performance. We address this gap, developing a defensible deepfake detector by leveraging the power of XAI. The proposed methodology uses XAI to generate interpretability maps for a given method, providing explicit visualizations of decision-making factors within the AI models. We subsequently employ a pretrained feature extractor that processes both the input image and its corresponding XAI image. The feature embeddings extracted from this process are then used for training a simple yet effective classifier. Our approach contributes not only to the detection of deepfakes but also enhances the understanding of possible adversarial attacks, pinpointing potential vulnerabilities. Furthermore, this approach does not change the performance of the deepfake detector. The paper demonstrates promising results suggesting a potential pathway for future deepfake detection mechanisms. We believe this study will serve as a valuable contribution to the community, sparking much-needed discourse on safeguarding deepfake detectors. ",
    "url": "https://arxiv.org/abs/2403.02955",
    "authors": [
      "Ben Pinhasov",
      "Raz Lapid",
      "Rony Ohayon",
      "Moshe Sipper",
      "Yehudit Aperstein"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.02983",
    "title": "Federated Learning Under Attack: Exposing Vulnerabilities through Data  Poisoning Attacks in Computer Networks",
    "abstract": "Federated Learning (FL) is a machine learning (ML) approach that enables multiple decentralized devices or edge servers to collaboratively train a shared model without exchanging raw data. During the training and sharing of model updates between clients and servers, data and models are susceptible to different data-poisoning attacks. In this study, our motivation is to explore the severity of data poisoning attacks in the computer network domain because they are easy to implement but difficult to detect. We considered two types of data-poisoning attacks, label flipping (LF) and feature poisoning (FP), and applied them with a novel approach. In LF, we randomly flipped the labels of benign data and trained the model on the manipulated data. For FP, we randomly manipulated the highly contributing features determined using the Random Forest algorithm. The datasets used in this experiment were CIC and UNSW related to computer networks. We generated adversarial samples using the two attacks mentioned above, which were applied to a small percentage of datasets. Subsequently, we trained and tested the accuracy of the model on adversarial datasets. We recorded the results for both benign and manipulated datasets and observed significant differences between the accuracy of the models on different datasets. From the experimental results, it is evident that the LF attack failed, whereas the FP attack showed effective results, which proved its significance in fooling a server. With a 1% LF attack on the CIC, the accuracy was approximately 0.0428 and the ASR was 0.9564; hence, the attack is easily detectable, while with a 1% FP attack, the accuracy and ASR were both approximately 0.9600, hence, FP attacks are difficult to detect. We repeated the experiment with different poisoning percentages. ",
    "url": "https://arxiv.org/abs/2403.02983",
    "authors": [
      "Ehsan Nowroozi",
      "Imran Haider",
      "Rahim Taheri",
      "Mauro Conti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2403.02985",
    "title": "Evolution Transformer: In-Context Evolutionary Optimization",
    "abstract": "Evolutionary optimization algorithms are often derived from loose biological analogies and struggle to leverage information obtained during the sequential course of optimization. An alternative promising approach is to leverage data and directly discover powerful optimization principles via meta-optimization. In this work, we follow such a paradigm and introduce Evolution Transformer, a causal Transformer architecture, which can flexibly characterize a family of Evolution Strategies. Given a trajectory of evaluations and search distribution statistics, Evolution Transformer outputs a performance-improving update to the search distribution. The architecture imposes a set of suitable inductive biases, i.e. the invariance of the distribution update to the order of population members within a generation and equivariance to the order of the search dimensions. We train the model weights using Evolutionary Algorithm Distillation, a technique for supervised optimization of sequence models using teacher algorithm trajectories. The resulting model exhibits strong in-context optimization performance and shows strong generalization capabilities to otherwise challenging neuroevolution tasks. We analyze the resulting properties of the Evolution Transformer and propose a technique to fully self-referentially train the Evolution Transformer, starting from a random initialization and bootstrapping its own learning progress. We provide an open source implementation under https://github.com/RobertTLange/evosax. ",
    "url": "https://arxiv.org/abs/2403.02985",
    "authors": [
      "Robert Tjarko Lange",
      "Yingtao Tian",
      "Yujin Tang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2403.02990",
    "title": "Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and  Challenges",
    "abstract": "In the rapidly evolving field of machine learning (ML), data augmentation (DA) has emerged as a pivotal technique for enhancing model performance by diversifying training examples without the need for additional data collection. This survey explores the transformative impact of Large Language Models (LLMs) on DA, particularly addressing the unique challenges and opportunities they present in the context of natural language processing (NLP) and beyond. From a data perspective and a learning perspective, we examine various strategies that utilize Large Language Models for data augmentation, including a novel exploration of learning paradigms where LLM-generated data is used for further training. Additionally, this paper delineates the primary challenges faced in this domain, ranging from controllable data augmentation to multi modal data augmentation. This survey highlights the paradigm shift introduced by LLMs in DA, aims to serve as a foundational guide for researchers and practitioners in this field. ",
    "url": "https://arxiv.org/abs/2403.02990",
    "authors": [
      "Bosheng Ding",
      "Chengwei Qin",
      "Ruochen Zhao",
      "Tianze Luo",
      "Xinze Li",
      "Guizhen Chen",
      "Wenhan Xia",
      "Junjie Hu",
      "Anh Tuan Luu",
      "Shafiq Joty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.02995",
    "title": "Mitigating Label Flipping Attacks in Malicious URL Detectors Using  Ensemble Trees",
    "abstract": "Malicious URLs provide adversarial opportunities across various industries, including transportation, healthcare, energy, and banking which could be detrimental to business operations. Consequently, the detection of these URLs is of crucial importance; however, current Machine Learning (ML) models are susceptible to backdoor attacks. These attacks involve manipulating a small percentage of training data labels, such as Label Flipping (LF), which changes benign labels to malicious ones and vice versa. This manipulation results in misclassification and leads to incorrect model behavior. Therefore, integrating defense mechanisms into the architecture of ML models becomes an imperative consideration to fortify against potential attacks. The focus of this study is on backdoor attacks in the context of URL detection using ensemble trees. By illuminating the motivations behind such attacks, highlighting the roles of attackers, and emphasizing the critical importance of effective defense strategies, this paper contributes to the ongoing efforts to fortify ML models against adversarial threats within the ML domain in network security. We propose an innovative alarm system that detects the presence of poisoned labels and a defense mechanism designed to uncover the original class labels with the aim of mitigating backdoor attacks on ensemble tree classifiers. We conducted a case study using the Alexa and Phishing Site URL datasets and showed that LF attacks can be addressed using our proposed defense mechanism. Our experimental results prove that the LF attack achieved an Attack Success Rate (ASR) between 50-65% within 2-5%, and the innovative defense method successfully detected poisoned labels with an accuracy of up to 100%. ",
    "url": "https://arxiv.org/abs/2403.02995",
    "authors": [
      "Ehsan Nowroozi",
      "Nada Jadalla",
      "Samaneh Ghelichkhani",
      "Alireza Jolfaei"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2403.02996",
    "title": "A Convex Optimization Framework for Computing Robustness Margins of  Kalman Filters",
    "abstract": "This paper proposes a novel convex optimization framework for designing robust Kalman filters that guarantee a user-specified steady-state error while maximizing process and sensor noise. The proposed framework simultaneously determines the Kalman gain and the robustness margin in terms of the process and sensor noise. This is the first paper to present such a joint formulation for Kalman filtering. The proposed methodology is validated through two distinct examples: the Clohessy-Wiltshire-Hill equations for a chaser spacecraft in an elliptical orbit and the longitudinal motion model of an F-16 aircraft. ",
    "url": "https://arxiv.org/abs/2403.02996",
    "authors": [
      "Himanshu Prabhat",
      "Raktim Bhattacharya"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2403.02998",
    "title": "Towards Calibrated Deep Clustering Network",
    "abstract": "Deep clustering has exhibited remarkable performance; however, the overconfidence problem, i.e., the estimated confidence for a sample belonging to a particular cluster greatly exceeds its actual prediction accuracy, has been overlooked in prior research. To tackle this critical issue, we pioneer the development of a calibrated deep clustering framework. Specifically, we propose a novel dual-head deep clustering pipeline that can effectively calibrate the estimated confidence and the actual accuracy. The calibration head adjusts the overconfident predictions of the clustering head using regularization methods, generating prediction confidence and pseudo-labels that match the model learning status. This calibration process also guides the clustering head in dynamically selecting reliable high-confidence samples for training. Additionally, we introduce an effective network initialization strategy that enhances both training speed and network robustness. Extensive experiments demonstrate the proposed calibrated deep clustering framework not only surpasses state-of-the-art deep clustering methods by approximately 10 times in terms of expected calibration error but also significantly outperforms them in terms of clustering accuracy. ",
    "url": "https://arxiv.org/abs/2403.02998",
    "authors": [
      "Yuheng Jia",
      "Jianhong Cheng",
      "Hui Liu",
      "Junhui Hou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.03002",
    "title": "Mem-elements based Neuromorphic Hardware for Neural Network Application",
    "abstract": "The thesis investigates the utilization of memristive and memcapacitive crossbar arrays in low-power machine learning accelerators, offering a comprehensive co-design framework for deep neural networks (DNN). The model, implemented through a hybrid Python and PyTorch approach, accounts for various non-idealities, achieving exceptional training accuracies of 90.02% and 91.03% for the CIFAR-10 dataset with memristive and memcapacitive crossbar arrays on an 8-layer VGG network. Additionally, the thesis introduces a novel approach to emulate meminductor devices using Operational Transconductance Amplifiers (OTA) and capacitors, showcasing adjustable behavior. Transistor-level simulations in 180 nm CMOS technology, operating at 60 MHz, demonstrate the proposed meminductor emulator's viability with a power consumption of 0.337 mW. The design is further validated in neuromorphic circuits and CNN accelerators, achieving training and testing accuracies of 91.04% and 88.82%, respectively. Notably, the exclusive use of MOS transistors ensures the feasibility of monolithic IC fabrication. This research significantly contributes to the exploration of advanced hardware solutions for efficient and high-performance machine-learning applications. ",
    "url": "https://arxiv.org/abs/2403.03002",
    "authors": [
      "Ankur Singh"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2403.03008",
    "title": "Knowledge Graphs as Context Sources for LLM-Based Explanations of  Learning Recommendations",
    "abstract": "In the era of personalized education, the provision of comprehensible explanations for learning recommendations is of a great value to enhance the learner's understanding and engagement with the recommended learning content. Large language models (LLMs) and generative AI in general have recently opened new doors for generating human-like explanations, for and along learning recommendations. However, their precision is still far away from acceptable in a sensitive field like education. To harness the abilities of LLMs, while still ensuring a high level of precision towards the intent of the learners, this paper proposes an approach to utilize knowledge graphs (KG) as a source of factual context, for LLM prompts, reducing the risk of model hallucinations, and safeguarding against wrong or imprecise information, while maintaining an application-intended learning context. We utilize the semantic relations in the knowledge graph to offer curated knowledge about learning recommendations. With domain-experts in the loop, we design the explanation as a textual template, which is filled and completed by the LLM. Domain experts were integrated in the prompt engineering phase as part of a study, to ensure that explanations include information that is relevant to the learner. We evaluate our approach quantitatively using Rouge-N and Rouge-L measures, as well as qualitatively with experts and learners. Our results show an enhanced recall and precision of the generated explanations compared to those generated solely by the GPT model, with a greatly reduced risk of generating imprecise information in the final learning explanation. ",
    "url": "https://arxiv.org/abs/2403.03008",
    "authors": [
      "Hasan Abu-Rasheed",
      "Christian Weber",
      "Madjid Fathi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.03021",
    "title": "Accelerating the convergence of Newton's method for nonlinear elliptic  PDEs using Fourier neural operators",
    "abstract": "It is well known that Newton's method, especially when applied to large problems such as the discretization of nonlinear partial differential equations (PDEs), can have trouble converging if the initial guess is too far from the solution. This work focuses on accelerating this convergence, in the context of the discretization of nonlinear elliptic PDEs. We first provide a quick review of existing methods, and justify our choice of learning an initial guess with a Fourier neural operator (FNO). This choice was motivated by the mesh-independence of such operators, whose training and evaluation can be performed on grids with different resolutions. The FNO is trained using a loss minimization over generated data, loss functions based on the PDE discretization. Numerical results, in one and two dimensions, show that the proposed initial guess accelerates the convergence of Newton's method by a large margin compared to a naive initial guess, especially for highly nonlinear or anisotropic problems. ",
    "url": "https://arxiv.org/abs/2403.03021",
    "authors": [
      "Joubine Aghili",
      "Emmanuel Franck",
      "Romain Hild",
      "Victor Michel-Dansac",
      "Vincent Vigon"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2403.03024",
    "title": "Toward Improved Deep Learning-based Vulnerability Detection",
    "abstract": "Deep learning (DL) has been a common thread across several recent techniques for vulnerability detection. The rise of large, publicly available datasets of vulnerabilities has fueled the learning process underpinning these techniques. While these datasets help the DL-based vulnerability detectors, they also constrain these detectors' predictive abilities. Vulnerabilities in these datasets have to be represented in a certain way, e.g., code lines, functions, or program slices within which the vulnerabilities exist. We refer to this representation as a base unit. The detectors learn how base units can be vulnerable and then predict whether other base units are vulnerable. We have hypothesized that this focus on individual base units harms the ability of the detectors to properly detect those vulnerabilities that span multiple base units (or MBU vulnerabilities). For vulnerabilities such as these, a correct detection occurs when all comprising base units are detected as vulnerable. Verifying how existing techniques perform in detecting all parts of a vulnerability is important to establish their effectiveness for other downstream tasks. To evaluate our hypothesis, we conducted a study focusing on three prominent DL-based detectors: ReVeal, DeepWukong, and LineVul. Our study shows that all three detectors contain MBU vulnerabilities in their respective datasets. Further, we observed significant accuracy drops when detecting these types of vulnerabilities. We present our study and a framework that can be used to help DL-based detectors toward the proper inclusion of MBU vulnerabilities. ",
    "url": "https://arxiv.org/abs/2403.03024",
    "authors": [
      "Adriana Sejfia",
      "Satyaki Das",
      "Saad Shafiq",
      "Nenad Medvidovi\u0107"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2403.03035",
    "title": "Mars 2.0: A Toolchain for Modeling, Analysis, Verification and Code  Generation of Cyber-Physical Systems",
    "abstract": "We introduce Mars 2.0 for modeling, analysis, verification and code generation of Cyber-Physical Systems. Mars 2.0 integrates Mars 1.0 with several important extensions and improvements, allowing the design of cyber-physical systems using the combination of AADL and Simulink/Stateflow, which provide a unified graphical framework for modeling the functionality, physicality and architecture of the system to be developed. For a safety-critical system, formal analysis and verification of its combined AADL and Simulink/Stateflow model can be conducted via the following steps. First, the toolchain automatically translates AADL and Simulink/Stateflow models into Hybrid CSP (HCSP), an extension of CSP for formally modeling hybrid systems. Second, the HCSP processes can be simulated using the HCSP simulator, and to complement incomplete simulation, they can be verified using the Hybrid Hoare Logic prover in Isabelle/HOL, as well as the more automated HHLPy prover. Finally, implementations in SystemC or C can be automatically generated from the verified HCSP processes. The transformation from AADL and Simulink/Stateflow to HCSP, and the one from HCSP to SystemC or C, are both guaranteed to be correct with formal proofs. This approach allows model-driven design of safety-critical cyber-physical systems based on graphical and formal models and proven-correct translation procedures. We demonstrate the use of the toolchain on several benchmarks of varying complexity, including several industrial-sized examples. ",
    "url": "https://arxiv.org/abs/2403.03035",
    "authors": [
      "Bohua Zhan",
      "Xiong Xu",
      "Qiang Gao",
      "Zekun Ji",
      "Xiangyu Jin",
      "Shuling Wang",
      "Naijun Zhan"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2403.03048",
    "title": "Design of Stochastic Quantizers for Privacy Preservation",
    "abstract": "In this paper, we examine the role of stochastic quantizers for privacy preservation. We first employ a static stochastic quantizer and investigate its corresponding privacy-preserving properties. Specifically, we demonstrate that a sufficiently large quantization step guarantees $(0, \\delta)$ differential privacy. Additionally, the degradation of control performance caused by quantization is evaluated as the tracking error of output regulation. These two analyses characterize the trade-off between privacy and control performance, determined by the quantization step. This insight enables us to use quantization intentionally as a means to achieve the seemingly conflicting two goals of maintaining control performance and preserving privacy at the same time; towards this end, we further investigate a dynamic stochastic quantizer. Under a stability assumption, the dynamic stochastic quantizer can enhance privacy, more than the static one, while achieving the same control performance. We further handle the unstable case by additionally applying input Gaussian noise. ",
    "url": "https://arxiv.org/abs/2403.03048",
    "authors": [
      "Le Liu",
      "Yu Kawano",
      "Ming Cao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.03076",
    "title": "Fast and robust method for screened Poisson lattice Green's function  using asymptotic expansion and Fast Fourier Transform",
    "abstract": "We study the lattice Green's function (LGF) of the screened Poisson equation on a two-dimensional rectangular lattice. This LGF arises in numerical analysis, random walks, solid-state physics, and other fields. Its defining characteristic is the screening term, which defines different regimes. When its coefficient is large, we can accurately approximate the LGF with an exponentially converging asymptotic expansion, and its convergence rate monotonically increases with the coefficient of the screening term. To tabulate the LGF when the coefficient is not large, we derive a one-dimensional integral representation of the LGF. We show that the trapezoidal rule can approximate this integral with exponential convergence, and we propose an efficient algorithm for its evaluation via the Fast Fourier Transform. We discuss applications including computing the LGF of the three-dimensional Poisson equation with one periodic direction and the return probability of a two-dimensional random walk with killing. ",
    "url": "https://arxiv.org/abs/2403.03076",
    "authors": [
      "Wei Hou",
      "Tim Colonius"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2403.03082",
    "title": "Recall-Oriented Continual Learning with Generative Adversarial  Meta-Model",
    "abstract": "The stability-plasticity dilemma is a major challenge in continual learning, as it involves balancing the conflicting objectives of maintaining performance on previous tasks while learning new tasks. In this paper, we propose the recall-oriented continual learning framework to address this challenge. Inspired by the human brain's ability to separate the mechanisms responsible for stability and plasticity, our framework consists of a two-level architecture where an inference network effectively acquires new knowledge and a generative network recalls past knowledge when necessary. In particular, to maximize the stability of past knowledge, we investigate the complexity of knowledge depending on different representations, and thereby introducing generative adversarial meta-model (GAMM) that incrementally learns task-specific parameters instead of input data samples of the task. Through our experiments, we show that our framework not only effectively learns new knowledge without any disruption but also achieves high stability of previous knowledge in both task-aware and task-agnostic learning scenarios. Our code is available at: https://github.com/bigdata-inha/recall-oriented-cl-framework. ",
    "url": "https://arxiv.org/abs/2403.03082",
    "authors": [
      "Haneol Kang",
      "Dong-Wan Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.03111",
    "title": "Improved LiDAR Odometry and Mapping using Deep Semantic Segmentation and  Novel Outliers Detection",
    "abstract": "Perception is a key element for enabling intelligent autonomous navigation. Understanding the semantics of the surrounding environment and accurate vehicle pose estimation are essential capabilities for autonomous vehicles, including self-driving cars and mobile robots that perform complex tasks. Fast moving platforms like self-driving cars impose a hard challenge for localization and mapping algorithms. In this work, we propose a novel framework for real-time LiDAR odometry and mapping based on LOAM architecture for fast moving platforms. Our framework utilizes semantic information produced by a deep learning model to improve point-to-line and point-to-plane matching between LiDAR scans and build a semantic map of the environment, leading to more accurate motion estimation using LiDAR data. We observe that including semantic information in the matching process introduces a new type of outlier matches to the process, where matching occur between different objects of the same semantic class. To this end, we propose a novel algorithm that explicitly identifies and discards potential outliers in the matching process. In our experiments, we study the effect of improving the matching process on the robustness of LiDAR odometry against high speed motion. Our experimental evaluations on KITTI dataset demonstrate that utilizing semantic information and rejecting outliers significantly enhance the robustness of LiDAR odometry and mapping when there are large gaps between scan acquisition poses, which is typical for fast moving platforms. ",
    "url": "https://arxiv.org/abs/2403.03111",
    "authors": [
      "Mohamed Afifi",
      "Mohamed ElHelw"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.03122",
    "title": "NRDF: Neural Riemannian Distance Fields for Learning Articulated Pose  Priors",
    "abstract": "Faithfully modeling the space of articulations is a crucial task that allows recovery and generation of realistic poses, and remains a notorious challenge. To this end, we introduce Neural Riemannian Distance Fields (NRDFs), data-driven priors modeling the space of plausible articulations, represented as the zero-level-set of a neural field in a high-dimensional product-quaternion space. To train NRDFs only on positive examples, we introduce a new sampling algorithm, ensuring that the geodesic distances follow a desired distribution, yielding a principled distance field learning paradigm. We then devise a projection algorithm to map any random pose onto the level-set by an adaptive-step Riemannian optimizer, adhering to the product manifold of joint rotations at all times. NRDFs can compute the Riemannian gradient via backpropagation and by mathematical analogy, are related to Riemannian flow matching, a recent generative model. We conduct a comprehensive evaluation of NRDF against other pose priors in various downstream tasks, i.e., pose generation, image-based pose estimation, and solving inverse kinematics, highlighting NRDF's superior performance. Besides humans, NRDF's versatility extends to hand and animal poses, as it can effectively represent any articulation. ",
    "url": "https://arxiv.org/abs/2403.03122",
    "authors": [
      "Yannan He",
      "Garvita Tiwari",
      "Tolga Birdal",
      "Jan Eric Lenssen",
      "Gerard Pons-Moll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.03149",
    "title": "Robust Federated Learning Mitigates Client-side Training Data  Distribution Inference Attacks",
    "abstract": "Recent studies have revealed that federated learning (FL), once considered secure due to clients not sharing their private data with the server, is vulnerable to attacks such as client-side training data distribution inference, where a malicious client can recreate the victim's data. While various countermeasures exist, they are not practical, often assuming server access to some training data or knowledge of label distribution before the attack. In this work, we bridge the gap by proposing InferGuard, a novel Byzantine-robust aggregation rule aimed at defending against client-side training data distribution inference attacks. In our proposed InferGuard, the server first calculates the coordinate-wise median of all the model updates it receives. A client's model update is considered malicious if it significantly deviates from the computed median update. We conduct a thorough evaluation of our proposed InferGuard on five benchmark datasets and perform a comparison with ten baseline methods. The results of our experiments indicate that our defense mechanism is highly effective in protecting against client-side training data distribution inference attacks, even against strong adaptive attacks. Furthermore, our method substantially outperforms the baseline methods in various practical FL scenarios. ",
    "url": "https://arxiv.org/abs/2403.03149",
    "authors": [
      "Yichang Xu",
      "Ming Yin",
      "Minghong Fang",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.03157",
    "title": "Rethinking Clustered Federated Learning in NOMA Enhanced Wireless  Networks",
    "abstract": "This study explores the benefits of integrating the novel clustered federated learning (CFL) approach with non-orthogonal multiple access (NOMA) under non-independent and identically distributed (non-IID) datasets, where multiple devices participate in the aggregation with time limitations and a finite number of sub-channels. A detailed theoretical analysis of the generalization gap that measures the degree of non-IID in the data distribution is presented. Following that, solutions to address the challenges posed by non-IID conditions are proposed with the analysis of the properties. Specifically, users' data distributions are parameterized as concentration parameters and grouped using spectral clustering, with Dirichlet distribution serving as the prior. The investigation into the generalization gap and convergence rate guides the design of sub-channel assignments through the matching-based algorithm, and the power allocation is achieved by Karush-Kuhn-Tucker (KKT) conditions with the derived closed-form solution. The extensive simulation results show that the proposed cluster-based FL framework can outperform FL baselines in terms of both test accuracy and convergence rate. Moreover, jointly optimizing sub-channel and power allocation in NOMA-enhanced networks can lead to a significant improvement. ",
    "url": "https://arxiv.org/abs/2403.03157",
    "authors": [
      "Yushen Lin",
      "Kaidi Wang",
      "Zhiguo Ding"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.03165",
    "title": "Leveraging Federated Learning and Edge Computing for Recommendation  Systems within Cloud Computing Networks",
    "abstract": "To enable large-scale and efficient deployment of artificial intelligence (AI), the combination of AI and edge computing has spawned Edge Intelligence, which leverages the computing and communication capabilities of end devices and edge servers to process data closer to where it is generated. A key technology for edge intelligence is the privacy-protecting machine learning paradigm known as Federated Learning (FL), which enables data owners to train models without having to transfer raw data to third-party servers. However, FL networks are expected to involve thousands of heterogeneous distributed devices. As a result, communication efficiency remains a key bottleneck. To reduce node failures and device exits, a Hierarchical Federated Learning (HFL) framework is proposed, where a designated cluster leader supports the data owner through intermediate model aggregation. Therefore, based on the improvement of edge server resource utilization, this paper can effectively make up for the limitation of cache capacity. In order to mitigate the impact of soft clicks on the quality of user experience (QoE), the authors model the user QoE as a comprehensive system cost. To solve the formulaic problem, the authors propose a decentralized caching algorithm with federated deep reinforcement learning (DRL) and federated learning (FL), where multiple agents learn and make decisions independently ",
    "url": "https://arxiv.org/abs/2403.03165",
    "authors": [
      "Yaqian Qi",
      "Yaqian Qi",
      "Xiangxiang Wang",
      "Hanzhe Li",
      "Jingxiao Tian"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.03170",
    "title": "SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context  Misinformation Detection",
    "abstract": "Misinformation is a prevalent societal issue due to its potential high risks. Out-of-context (OOC) misinformation, where authentic images are repurposed with false text, is one of the easiest and most effective ways to mislead audiences. Current methods focus on assessing image-text consistency but lack convincing explanations for their judgments, which is essential for debunking misinformation. While Multimodal Large Language Models (MLLMs) have rich knowledge and innate capability for visual reasoning and explanation generation, they still lack sophistication in understanding and discovering the subtle crossmodal differences. In this paper, we introduce SNIFFER, a novel multimodal large language model specifically engineered for OOC misinformation detection and explanation. SNIFFER employs two-stage instruction tuning on InstructBLIP. The first stage refines the model's concept alignment of generic objects with news-domain entities and the second stage leverages language-only GPT-4 generated OOC-specific instruction data to fine-tune the model's discriminatory powers. Enhanced by external tools and retrieval, SNIFFER not only detects inconsistencies between text and image but also utilizes external knowledge for contextual verification. Our experiments show that SNIFFER surpasses the original MLLM by over 40% and outperforms state-of-the-art methods in detection accuracy. SNIFFER also provides accurate and persuasive explanations as validated by quantitative and human evaluations. ",
    "url": "https://arxiv.org/abs/2403.03170",
    "authors": [
      "Peng Qi",
      "Zehong Yan",
      "Wynne Hsu",
      "Mong Li Lee"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2403.03193",
    "title": "VeriEQL: Bounded Equivalence Verification for Complex SQL Queries with  Integrity Constraints",
    "abstract": "The task of SQL query equivalence checking is important in various real-world applications (including query rewriting and automated grading) that involve complex queries with integrity constraints; yet, state-of-the-art techniques are very limited in their capability of reasoning about complex features (e.g., those that involve sorting, case statement, rich integrity constraints, etc.) in real-life queries. To the best of our knowledge, we propose the first SMT-based approach and its implementation, VeriEQL, capable of proving and disproving bounded equivalence of complex SQL queries. VeriEQL is based on a new logical encoding that models query semantics over symbolic tuples using the theory of integers with uninterpreted functions. It is simple yet highly practical -- our comprehensive evaluation on over 20,000 benchmarks shows that VeriEQL outperforms all state-of-the-art techniques by more than one order of magnitude in terms of the number of benchmarks that can be proved or disproved. VeriEQL can also generate counterexamples that facilitate many downstream tasks (such as finding serious bugs in systems like MySQL and Apache Calcite). ",
    "url": "https://arxiv.org/abs/2403.03193",
    "authors": [
      "Yang He",
      "Pinhan Zhao",
      "Xinyu Wang",
      "Yuepeng Wang"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2403.03215",
    "title": "A Safety-Critical Framework for UGVs in Complex Environments: A  Data-Driven Discrepancy-Aware Approach",
    "abstract": "This work presents a novel data-driven multi-layered planning and control framework for the safe navigation of a class of unmanned ground vehicles (UGVs) in the presence of unknown stationary obstacles and additive modeling uncertainties. The foundation of this framework is a novel robust model predictive planner, designed to generate optimal collision-free trajectories given an occupancy grid map, and a paired ancillary controller, augmented to provide robustness against model uncertainties extracted from learning data. To tackle modeling discrepancies, we identify both matched (input discrepancies) and unmatched model residuals between the true and the nominal reduced-order models using closed-loop tracking errors as training data. Utilizing conformal prediction, we extract probabilistic upper bounds for the unknown model residuals, which serve to construct a robustifying ancillary controller. Further, we also determine maximum tracking discrepancies, also known as the robust control invariance tube, under the augmented policy, formulating them as collision buffers. Employing a LiDAR-based occupancy map to characterize the environment, we construct a discrepancy-aware cost map that incorporates these collision buffers. This map is then integrated into a sampling-based model predictive path planner that generates optimal and safe trajectories that can be robustly tracked by the augmented ancillary controller in the presence of model mismatches. The effectiveness of the framework is experimentally validated for autonomous high-speed trajectory tracking in a cluttered environment with four different vehicle-terrain configurations. We also showcase the framework's versatility by reformulating it as a driver-assist program, providing collision avoidance corrections based on user joystick commands. ",
    "url": "https://arxiv.org/abs/2403.03215",
    "authors": [
      "Skylar X. Wei",
      "Lu Gan",
      "Joel W. Burdick"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.03217",
    "title": "Self-supervised 3D Patient Modeling with Multi-modal Attentive Fusion",
    "abstract": "3D patient body modeling is critical to the success of automated patient positioning for smart medical scanning and operating rooms. Existing CNN-based end-to-end patient modeling solutions typically require a) customized network designs demanding large amount of relevant training data, covering extensive realistic clinical scenarios (e.g., patient covered by sheets), which leads to suboptimal generalizability in practical deployment, b) expensive 3D human model annotations, i.e., requiring huge amount of manual effort, resulting in systems that scale poorly. To address these issues, we propose a generic modularized 3D patient modeling method consists of (a) a multi-modal keypoint detection module with attentive fusion for 2D patient joint localization, to learn complementary cross-modality patient body information, leading to improved keypoint localization robustness and generalizability in a wide variety of imaging (e.g., CT, MRI etc.) and clinical scenarios (e.g., heavy occlusions); and (b) a self-supervised 3D mesh regression module which does not require expensive 3D mesh parameter annotations to train, bringing immediate cost benefits for clinical deployment. We demonstrate the efficacy of the proposed method by extensive patient positioning experiments on both public and clinical data. Our evaluation results achieve superior patient positioning performance across various imaging modalities in real clinical scenarios. ",
    "url": "https://arxiv.org/abs/2403.03217",
    "authors": [
      "Meng Zheng",
      "Benjamin Planche",
      "Xuan Gong",
      "Fan Yang",
      "Terrence Chen",
      "Ziyan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.03221",
    "title": "FAR: Flexible, Accurate and Robust 6DoF Relative Camera Pose Estimation",
    "abstract": "Estimating relative camera poses between images has been a central problem in computer vision. Methods that find correspondences and solve for the fundamental matrix offer high precision in most cases. Conversely, methods predicting pose directly using neural networks are more robust to limited overlap and can infer absolute translation scale, but at the expense of reduced precision. We show how to combine the best of both methods; our approach yields results that are both precise and robust, while also accurately inferring translation scales. At the heart of our model lies a Transformer that (1) learns to balance between solved and learned pose estimations, and (2) provides a prior to guide a solver. A comprehensive analysis supports our design choices and demonstrates that our method adapts flexibly to various feature extractors and correspondence estimators, showing state-of-the-art performance in 6DoF pose estimation on Matterport3D, InteriorNet, StreetLearn, and Map-free Relocalization. ",
    "url": "https://arxiv.org/abs/2403.03221",
    "authors": [
      "Chris Rockwell",
      "Nilesh Kulkarni",
      "Linyi Jin",
      "Jeong Joon Park",
      "Justin Johnson",
      "David F. Fouhey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.02467",
    "title": "Applied Causal Inference Powered by ML and AI",
    "abstract": "An introduction to the emerging fusion of machine learning and causal inference. The book presents ideas from classical structural equation models (SEMs) and their modern AI equivalent, directed acyclical graphs (DAGs) and structural causal models (SCMs), and covers Double/Debiased Machine Learning methods to do inference in such models using modern predictive tools. ",
    "url": "https://arxiv.org/abs/2403.02467",
    "authors": [
      "Victor Chernozhukov",
      "Christian Hansen",
      "Nathan Kallus",
      "Martin Spindler",
      "Vasilis Syrgkanis"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.02500",
    "title": "RVRAE: A Dynamic Factor Model Based on Variational Recurrent Autoencoder  for Stock Returns Prediction",
    "abstract": "In recent years, the dynamic factor model has emerged as a dominant tool in economics and finance, particularly for investment strategies. This model offers improved handling of complex, nonlinear, and noisy market conditions compared to traditional static factor models. The advancement of machine learning, especially in dealing with nonlinear data, has further enhanced asset pricing methodologies. This paper introduces a groundbreaking dynamic factor model named RVRAE. This model is a probabilistic approach that addresses the temporal dependencies and noise in market data. RVRAE ingeniously combines the principles of dynamic factor modeling with the variational recurrent autoencoder (VRAE) from deep learning. A key feature of RVRAE is its use of a prior-posterior learning method. This method fine-tunes the model's learning process by seeking an optimal posterior factor model informed by future data. Notably, RVRAE is adept at risk modeling in volatile stock markets, estimating variances from latent space distributions while also predicting returns. Our empirical tests with real stock market data underscore RVRAE's superior performance compared to various established baseline methods. ",
    "url": "https://arxiv.org/abs/2403.02500",
    "authors": [
      "Yilun Wang",
      "Shengjie Guo"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Machine Learning (cs.LG)",
      "Pricing of Securities (q-fin.PR)"
    ]
  },
  {
    "id": "arXiv:2403.02532",
    "title": "Superposition detection and QMA with non-collapsing measurements",
    "abstract": "We prove that QMA where the verifier may also make a single non-collapsing measurement is equal to NEXP, resolving an open question of Aaronson. We show this is a corollary to a modified proof of QMA+ = NEXP [arXiv:2306.13247]. At the core of many results inspired by Blier and Tapp [arXiv:0709.0738] is an unphysical property testing problem deciding whether a quantum state is close to an element of a fixed basis. ",
    "url": "https://arxiv.org/abs/2403.02532",
    "authors": [
      "Roozbeh Bassirian",
      "Kunal Marwaha"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2403.02601",
    "title": "Low-Res Leads the Way: Improving Generalization for Super-Resolution by  Self-Supervised Learning",
    "abstract": "For image super-resolution (SR), bridging the gap between the performance on synthetic datasets and real-world degradation scenarios remains a challenge. This work introduces a novel \"Low-Res Leads the Way\" (LWay) training framework, merging Supervised Pre-training with Self-supervised Learning to enhance the adaptability of SR models to real-world images. Our approach utilizes a low-resolution (LR) reconstruction network to extract degradation embeddings from LR images, merging them with super-resolved outputs for LR reconstruction. Leveraging unseen LR images for self-supervised learning guides the model to adapt its modeling space to the target domain, facilitating fine-tuning of SR models without requiring paired high-resolution (HR) images. The integration of Discrete Wavelet Transform (DWT) further refines the focus on high-frequency details. Extensive evaluations show that our method significantly improves the generalization and detail restoration capabilities of SR models on unseen real-world datasets, outperforming existing methods. Our training regime is universally compatible, requiring no network architecture modifications, making it a practical solution for real-world SR applications. ",
    "url": "https://arxiv.org/abs/2403.02601",
    "authors": [
      "Haoyu Chen",
      "Wenbo Li",
      "Jinjin Gu",
      "Jingjing Ren",
      "Haoze Sun",
      "Xueyi Zou",
      "Zhensong Zhang",
      "Youliang Yan",
      "Lei Zhu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.02645",
    "title": "Over-The-Air Double-Threshold Deep Learner for Jamming Detection in 5G  RF domain",
    "abstract": "With the evolution of 5G wireless communications, the Synchronization Signal Block (SSB) plays a critical role in the synchronization of devices and accessibility of services. However, due to the predictable nature of SSB transmission, including the Primary and Secondary Synchronization Signals (PSS and SSS), jamming attacks are critical threats. By leveraging RF domain knowledge, this work presents a novel deep learning-based technique for detecting jammers in 5G networks. Unlike the existing jamming detection algorithms that mostly rely on network parameters, we introduce a double threshold deep learning jamming detector by focusing on the SSB. The detection method is focused on RF domain features and improves the robustness of the network without requiring integration with the pre-existing network infrastructure. By integrating a preprocessing block that extracts PSS correlation and energy per null resource elements (EPNRE) characteristics, our method distinguishes between normal and jammed received signals with high precision. Additionally, by incorporation of Discrete Wavelet Transform (DWT), the efficacy of training and detection are optimized. A double threshold double Deep Neural Network (DT-DDNN) is also introduced to the architecture complemented by a deep cascade learning model to increase the sensitivity of the model to variations of signal to jamming noise ratio (SJNR). Results show that the proposed method achieves 96.4% detection rate in extra low jamming power, i.e., SJNR between 15 to 30 dB which outperforms the single threshold DNN design with 86.0% detection rate and unprocessed IQ sample DNN design with 83.2% detection rate. Ultimately, performance of DT-DDNN is validated through the analysis of real 5G signals obtained from a practical testbed, demonstrating a strong alignment with the simulation results. ",
    "url": "https://arxiv.org/abs/2403.02645",
    "authors": [
      "Ghazal Asemian",
      "Mohammadreza Amini",
      "Burak Kantarci",
      "Melike Erol-Kantarci"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2403.02808",
    "title": "Face-hitting Dominating Sets in Planar Graphs",
    "abstract": "A dominating set of a graph $G$ is a subset $S$ of its vertices such that each vertex of $G$ not in $S$ has a neighbor in $S$. A face-hitting set of a plane graph $G$ is a set $T$ of vertices in $G$ such that every face of $G$ contains at least one vertex of $T$. We show that the vertex-set of every plane (multi-)graph without isolated vertices, self-loops or $2$-faces can be partitioned into two disjoint sets so that both the sets are dominating and face-hitting. We also show that all the three assumptions above are necessary for the conclusion. As a corollary, we show that every $n$-vertex simple plane triangulation has a dominating set of size at most $(1 - \\alpha)n/2$, where $\\alpha n$ is the maximum size of an independent set in the triangulation. Matheson and Tarjan [European J. Combin., 1996] conjectured that every plane triangulation with a sufficiently large number of vertices $n$ has a dominating set of size at most $n / 4$. Currently, the best known general bound for this is by Christiansen, Rotenberg and Rutschmann [SODA, 2024] who showed that every plane triangulation on $n > 10$ vertices has a dominating set of size at most $2n/7$. Our corollary improves their bound for $n$-vertex plane triangulations which contain a maximal independent set of size either less than $2n/7$ or more than $3n/7$. ",
    "url": "https://arxiv.org/abs/2403.02808",
    "authors": [
      "P. Francis",
      "Abraham M. Illickan",
      "Lijo M. Jose",
      "Deepak Rajendraprasad"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2403.02871",
    "title": "Quantum Mixed-State Self-Attention Network",
    "abstract": "The rapid advancement of quantum computing has increasingly highlighted its potential in the realm of machine learning, particularly in the context of natural language processing (NLP) tasks. Quantum machine learning (QML) leverages the unique capabilities of quantum computing to offer novel perspectives and methodologies for complex data processing and pattern recognition challenges. This paper introduces a novel Quantum Mixed-State Attention Network (QMSAN), which integrates the principles of quantum computing with classical machine learning algorithms, especially self-attention networks, to enhance the efficiency and effectiveness in handling NLP tasks. QMSAN model employs a quantum attention mechanism based on mixed states, enabling efficient direct estimation of similarity between queries and keys within the quantum domain, leading to more effective attention weight acquisition. Additionally, we propose an innovative quantum positional encoding scheme, implemented through fixed quantum gates within the quantum circuit, to enhance the model's accuracy. Experimental validation on various datasets demonstrates that QMSAN model outperforms existing quantum and classical models in text classification, achieving significant performance improvements. QMSAN model not only significantly reduces the number of parameters but also exceeds classical self-attention networks in performance, showcasing its strong capability in data representation and information extraction. Furthermore, our study investigates the model's robustness in different quantum noise environments, showing that QMSAN possesses commendable robustness to low noise. ",
    "url": "https://arxiv.org/abs/2403.02871",
    "authors": [
      "Fu Chen",
      "Qinglin Zhao",
      "Li Feng",
      "Chuangtao Chen",
      "Yangbin Lin",
      "Jianhong Lin"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.03013",
    "title": "The clique chromatic number of sparse random graphs",
    "abstract": "The clique chromatic number of a graph is the smallest number of colors in a vertex coloring so that no maximal clique is monochromatic. In this paper, we determine the order of magnitude of the clique chromatic number of the random graph G_{n,p} for most edge-probabilities p in the range n^{-2/5} \\ll p \\ll 1. This resolves open problems and questions of Lichev, Mitsche and Warnke as well as Alon and Krievelevich. One major proof difficulty stems from high-degree vertices, which prevent maximal cliques in their neighborhoods: we deal with these vertices by an intricate union bound argument, that combines the probabilistic method with new degree counting arguments in order to enable Janson's inequality. This way we determine the asymptotics of the clique chromatic number of G_{n,p} in some ranges, and discover a surprising new phenomenon that contradicts earlier predictions for edge-probabilities p close to n^{-2/5}. ",
    "url": "https://arxiv.org/abs/2403.03013",
    "authors": [
      "Manuel Fernandez V",
      "Lutz Warnke"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2403.03053",
    "title": "Neural Codebook Design for Network Beam Management",
    "abstract": "Obtaining accurate and timely channel state information (CSI) is a fundamental challenge for large antenna systems. Mobile systems like 5G use a beam management framework that joins the initial access, beamforming, CSI acquisition, and data transmission. The design of codebooks for these stages, however, is challenging due to their interrelationships, varying array sizes, and site-specific channel and user distributions. Furthermore, beam management is often focused on single-sector operations while ignoring the overarching network- and system-level optimization. In this paper, we proposed an end-to-end learned codebook design algorithm, network beamspace learning (NBL), that captures and optimizes codebooks to mitigate interference while maximizing the achievable performance with extremely large hybrid arrays. The proposed algorithm requires limited shared information yet designs codebooks that outperform traditional codebooks by over 10dB in beam alignment and achieve more than 25% improvements in network spectral efficiency. ",
    "url": "https://arxiv.org/abs/2403.03053",
    "authors": [
      "Ryan M. Dreifuerst",
      "Robert W. Heath Jr"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.03071",
    "title": "On a Neural Implementation of Brenier's Polar Factorization",
    "abstract": "In 1991, Brenier proved a theorem that generalizes the $QR$ decomposition for square matrices -- factored as PSD $\\times$ unitary -- to any vector field $F:\\mathbb{R}^d\\rightarrow \\mathbb{R}^d$. The theorem, known as the polar factorization theorem, states that any field $F$ can be recovered as the composition of the gradient of a convex function $u$ with a measure-preserving map $M$, namely $F=\\nabla u \\circ M$. We propose a practical implementation of this far-reaching theoretical result, and explore possible uses within machine learning. The theorem is closely related to optimal transport (OT) theory, and we borrow from recent advances in the field of neural optimal transport to parameterize the potential $u$ as an input convex neural network. The map $M$ can be either evaluated pointwise using $u^*$, the convex conjugate of $u$, through the identity $M=\\nabla u^* \\circ F$, or learned as an auxiliary network. Because $M$ is, in general, not injective, we consider the additional task of estimating the ill-posed inverse map that can approximate the pre-image measure $M^{-1}$ using a stochastic generator. We illustrate possible applications of \\citeauthor{Brenier1991PolarFA}'s polar factorization to non-convex optimization problems, as well as sampling of densities that are not log-concave. ",
    "url": "https://arxiv.org/abs/2403.03071",
    "authors": [
      "Nina Vesseron",
      "Marco Cuturi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.03089",
    "title": "VQSynery: Robust Drug Synergy Prediction With Vector Quantization  Mechanism",
    "abstract": "The pursuit of optimizing cancer therapies is significantly advanced by the accurate prediction of drug synergy. Traditional methods, such as clinical trials, are reliable yet encumbered by extensive time and financial demands. The emergence of high-throughput screening and computational innovations has heralded a shift towards more efficient methodologies for exploring drug interactions. In this study, we present VQSynergy, a novel framework that employs the Vector Quantization (VQ) mechanism, integrated with gated residuals and a tailored attention mechanism, to enhance the precision and generalizability of drug synergy predictions. Our findings demonstrate that VQSynergy surpasses existing models in terms of robustness, particularly under Gaussian noise conditions, highlighting its superior performance and utility in the complex and often noisy domain of drug synergy research. This study underscores the potential of VQSynergy in revolutionizing the field through its advanced predictive capabilities, thereby contributing to the optimization of cancer treatment strategies. ",
    "url": "https://arxiv.org/abs/2403.03089",
    "authors": [
      "Jiawei Wu",
      "Mingyuan Yan",
      "Dianbo Liu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.03205",
    "title": "Finding Super-spreaders in Network Cascades",
    "abstract": "Suppose that a cascade (e.g., an epidemic) spreads on an unknown graph, and only the infection times of vertices are observed. What can be learned about the graph from the infection times caused by multiple distinct cascades? Most of the literature on this topic focuses on the task of recovering the entire graph, which requires $\\Omega ( \\log n)$ cascades for an $n$-vertex bounded degree graph. Here we ask a different question: can the important parts of the graph be estimated from just a few (i.e., constant number) of cascades, even as $n$ grows large? In this work, we focus on identifying super-spreaders (i.e., high-degree vertices) from infection times caused by a Susceptible-Infected process on a graph. Our first main result shows that vertices of degree greater than $n^{3/4}$ can indeed be estimated from a constant number of cascades. Our algorithm for doing so leverages a novel connection between vertex degrees and the second derivative of the cumulative infection curve. Conversely, we show that estimating vertices of degree smaller than $n^{1/2}$ requires at least $\\log(n) / \\log \\log (n)$ cascades. Surprisingly, this matches (up to $\\log \\log n$ factors) the number of cascades needed to learn the \\emph{entire} graph if it is a tree. ",
    "url": "https://arxiv.org/abs/2403.03205",
    "authors": [
      "Elchanan Mossel",
      "Anirudh Sridhar"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:1905.07342",
    "title": "Pair-Matching: Links Prediction with Adaptive Queries",
    "abstract": " Comments: 78 pages ",
    "url": "https://arxiv.org/abs/1905.07342",
    "authors": [
      "Christophe Giraud",
      "Yann Issartel",
      "Luc Leh\u00e9ricy",
      "Matthieu Lerasle"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2001.05371",
    "title": "Making deep neural networks right for the right scientific reasons by  interacting with their explanations",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:1805.08578 ",
    "url": "https://arxiv.org/abs/2001.05371",
    "authors": [
      "Patrick Schramowski",
      "Wolfgang Stammer",
      "Stefano Teso",
      "Anna Brugger",
      "Xiaoting Shao",
      "Hans-Georg Luigs",
      "Anne-Katrin Mahlein",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2104.04987",
    "title": "AutoGL: A Library for Automated Graph Learning",
    "abstract": " Comments: Extended version; initial version published at ICLR 2021 Workshop on Geometrical and Topological Representation Learning ",
    "url": "https://arxiv.org/abs/2104.04987",
    "authors": [
      "Ziwei Zhang",
      "Yijian Qin",
      "Zeyang Zhang",
      "Chaoyu Guan",
      "Jie Cai",
      "Heng Chang",
      "Jiyan Jiang",
      "Haoyang Li",
      "Zixin Sun",
      "Beini Xie",
      "Yang Yao",
      "Yipeng Zhang",
      "Xin Wang",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.04274",
    "title": "3D Human Pose Estimation Based on 2D-3D Consistency with Synchronized  Adversarial Training",
    "abstract": " Title: 3D Human Pose Estimation Based on 2D-3D Consistency with Synchronized  Adversarial Training ",
    "url": "https://arxiv.org/abs/2106.04274",
    "authors": [
      "Yicheng Deng",
      "Cheng Sun",
      "Yongqi Sun",
      "Jiahui Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.01633",
    "title": "Reducing Linear Hadwiger's Conjecture to Coloring Small Graphs",
    "abstract": " Comments: 25 pages. In this version, some minor typos fixed. Previously updated in response to referee comments. This and the three previous versions add the necessary results from arXiv:2006.11798 in order to create a self-contained standalone paper. arXiv admin note: text overlap with arXiv:2006.11798, arXiv:2010.05999 ",
    "url": "https://arxiv.org/abs/2108.01633",
    "authors": [
      "Michelle Delcourt",
      "Luke Postle"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2109.10795",
    "title": "Neural network relief: a pruning algorithm based on neural activity",
    "abstract": " Title: Neural network relief: a pruning algorithm based on neural activity ",
    "url": "https://arxiv.org/abs/2109.10795",
    "authors": [
      "Aleksandr Dekhovich",
      "David M.J. Tax",
      "Marcel H.F. Sluiter",
      "Miguel A. Bessa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.10657",
    "title": "Generalizing Graph Neural Networks on Out-Of-Distribution Graphs",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2111.10657",
    "authors": [
      "Shaohua Fan",
      "Xiao Wang",
      "Chuan Shi",
      "Peng Cui",
      "Bai Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10089",
    "title": "Kernel Normalized Convolutional Networks",
    "abstract": " Title: Kernel Normalized Convolutional Networks ",
    "url": "https://arxiv.org/abs/2205.10089",
    "authors": [
      "Reza Nasirigerdeh",
      "Reihaneh Torkzadehmahani",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10209",
    "title": "On the Alignment of Group Fairness with Attribute Privacy",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2202.02242 ",
    "url": "https://arxiv.org/abs/2211.10209",
    "authors": [
      "Jan Aalmoes",
      "Vasisht Duddu",
      "Antoine Boutet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.13715",
    "title": "Trust Your $\\nabla$: Gradient-based Intervention Targeting for Causal  Discovery",
    "abstract": " Comments: Accepted to 37th Conference on Neural Information Processing Systems (NeurIPS 2023) ",
    "url": "https://arxiv.org/abs/2211.13715",
    "authors": [
      "Mateusz Olko",
      "Micha\u0142 Zaj\u0105c",
      "Aleksandra Nowak",
      "Nino Scherrer",
      "Yashas Annadani",
      "Stefan Bauer",
      "\u0141ukasz Kuci\u0144ski",
      "Piotr Mi\u0142o\u015b"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2211.15188",
    "title": "Incremental Spatial and Spectral Learning of Neural Operators for  Solving Large-Scale PDEs",
    "abstract": " Title: Incremental Spatial and Spectral Learning of Neural Operators for  Solving Large-Scale PDEs ",
    "url": "https://arxiv.org/abs/2211.15188",
    "authors": [
      "Robert Joseph George",
      "Jiawei Zhao",
      "Jean Kossaifi",
      "Zongyi Li",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.17029",
    "title": "Directed Acyclic Graph Structure Learning from Dynamic Graphs",
    "abstract": " Comments: Accepted by AAAI23 ",
    "url": "https://arxiv.org/abs/2211.17029",
    "authors": [
      "Shaohua Fan",
      "Shuyang Zhang",
      "Xiao Wang",
      "Chuan Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.09522",
    "title": "Optimising Event-Driven Spiking Neural Network with Regularisation and  Cutoff",
    "abstract": " Title: Optimising Event-Driven Spiking Neural Network with Regularisation and  Cutoff ",
    "url": "https://arxiv.org/abs/2301.09522",
    "authors": [
      "Dengyu Wu",
      "Gaojie Jin",
      "Han Yu",
      "Xinping Yi",
      "Xiaowei Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12515",
    "title": "LiDAR-CS Dataset: LiDAR Point Cloud Dataset with Cross-Sensors for 3D  Object Detection",
    "abstract": " Comments: 8 pages ",
    "url": "https://arxiv.org/abs/2301.12515",
    "authors": [
      "Jin Fang",
      "Dingfu Zhou",
      "Jingjing Zhao",
      "Chenming Wu",
      "Chulin Tang",
      "Cheng-Zhong Xu",
      "Liangjun Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.13056",
    "title": "SATBA: An Invisible Backdoor Attack Based On Spatial Attention",
    "abstract": " Comments: 9 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2302.13056",
    "authors": [
      "Huasong Zhou",
      "Xiaowei Xu",
      "Xiaodong Wang",
      "Leon Bevan Bullock"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04497",
    "title": "A Unified Framework for Exploratory Learning-Aided Community Detection  Under Topological Uncertainty",
    "abstract": " Comments: 17 pages, 9 figures, 6 tables; its conference version was presented at the ACM International Conference on Information and Knowledge Management (CIKM 2022) ",
    "url": "https://arxiv.org/abs/2304.04497",
    "authors": [
      "Yu Hou",
      "Cong Tran",
      "Ming Li",
      "Won-Yong Shin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2304.12228",
    "title": "Hierarchical Contrastive Learning Enhanced Heterogeneous Graph Neural  Network",
    "abstract": " Comments: This paper has been accepted by TKDE as a regular paper. arXiv admin note: substantial text overlap with arXiv:2105.09111 ",
    "url": "https://arxiv.org/abs/2304.12228",
    "authors": [
      "Nian Liu",
      "Xiao Wang",
      "Hui Han",
      "Chuan Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.06176",
    "title": "Fine-tuning Language Models with Generative Adversarial Reward Modelling",
    "abstract": " Comments: 22 pages, 9 figures, 12 tables ",
    "url": "https://arxiv.org/abs/2305.06176",
    "authors": [
      "Zhang Ze Yu",
      "Lau Jia Jaw",
      "Zhang Hui",
      "Bryan Kian Hsiang Low"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.18149",
    "title": "Multiscale Positive-Unlabeled Detection of AI-Generated Texts",
    "abstract": " Comments: ICLR2024 (Spotlight) ",
    "url": "https://arxiv.org/abs/2305.18149",
    "authors": [
      "Yuchuan Tian",
      "Hanting Chen",
      "Xutao Wang",
      "Zheyuan Bai",
      "Qinghua Zhang",
      "Ruifeng Li",
      "Chao Xu",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02775",
    "title": "Input-gradient space particle inference for neural network ensembles",
    "abstract": " Comments: Published at ICLR 2024 (spotlight presentation). Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2306.02775",
    "authors": [
      "Trung Trinh",
      "Markus Heinonen",
      "Luigi Acerbi",
      "Samuel Kaski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14940",
    "title": "A Self-Adaptive Penalty Method for Integrating Prior Knowledge  Constraints into Neural ODEs",
    "abstract": " Title: A Self-Adaptive Penalty Method for Integrating Prior Knowledge  Constraints into Neural ODEs ",
    "url": "https://arxiv.org/abs/2307.14940",
    "authors": [
      "C. Coelho",
      "M. Fernanda P. Costa",
      "L. L. Ferr\u00e1s"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2307.16807",
    "title": "On the use of associative memory in Hopfield networks designed to solve  propositional satisfiability problems",
    "abstract": " Comments: 7 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2307.16807",
    "authors": [
      "Natalya Weber",
      "Werner Koch",
      "Ozan Erdem",
      "Tom Froese"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2308.06354",
    "title": "Large Language Models to Identify Social Determinants of Health in  Electronic Health Records",
    "abstract": " Comments: Peer-reviewed version published at NPJ Digital Medicine: this https URL ",
    "url": "https://arxiv.org/abs/2308.06354",
    "authors": [
      "Marco Guevara",
      "Shan Chen",
      "Spencer Thomas",
      "Tafadzwa L. Chaunzwa",
      "Idalid Franco",
      "Benjamin Kann",
      "Shalini Moningi",
      "Jack Qian",
      "Madeleine Goldstein",
      "Susan Harper",
      "Hugo JWL Aerts",
      "Guergana K. Savova",
      "Raymond H. Mak",
      "Danielle S. Bitterman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.10664",
    "title": "A Safe Deep Reinforcement Learning Approach for Energy Efficient  Federated Learning in Wireless Communication Networks",
    "abstract": " Comments: 12 Pages Double Column, 6 Figures, Accepted for publication in the IEEE Transactions on Green Communications and Networking (TGCN). arXiv admin note: text overlap with arXiv:2306.14237 ",
    "url": "https://arxiv.org/abs/2308.10664",
    "authors": [
      "Nikolaos Koursioumpas",
      "Lina Magoula",
      "Nikolaos Petropouleas",
      "Alexandros-Ioannis Thanopoulos",
      "Theodora Panagea",
      "Nancy Alonistioti",
      "M. A. Gutierrez-Estevez",
      "Ramin Khalili"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.16910",
    "title": "Robust Variational Physics-Informed Neural Networks",
    "abstract": " Title: Robust Variational Physics-Informed Neural Networks ",
    "url": "https://arxiv.org/abs/2308.16910",
    "authors": [
      "Sergio Rojas",
      "Pawe\u0142 Maczuga",
      "Judit Mu\u00f1oz-Matute",
      "David Pardo",
      "Maciej Paszynski"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2309.04386",
    "title": "ARRTOC: Adversarially Robust Real-Time Optimization and Control",
    "abstract": " Title: ARRTOC: Adversarially Robust Real-Time Optimization and Control ",
    "url": "https://arxiv.org/abs/2309.04386",
    "authors": [
      "Akhil Ahmed",
      "Ehecatl Antonio del Rio-Chanona",
      "Mehmet Mercangoz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.05035",
    "title": "Duplicate Question Retrieval and Confirmation Time Prediction in  Software Communities",
    "abstract": " Comments: Full paper accepted at ASONAM 2023: The 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining ",
    "url": "https://arxiv.org/abs/2309.05035",
    "authors": [
      "Rima Hazra",
      "Debanjan Saha",
      "Amruit Sahoo",
      "Somnath Banerjee",
      "Animesh Mukherjee"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Software Engineering (cs.SE)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.08849",
    "title": "Learning a Stable Dynamic System with a Lyapunov Energy Function for  Demonstratives Using Neural Networks",
    "abstract": " Title: Learning a Stable Dynamic System with a Lyapunov Energy Function for  Demonstratives Using Neural Networks ",
    "url": "https://arxiv.org/abs/2309.08849",
    "authors": [
      "Yu Zhang",
      "Yongxiang Zou",
      "Haoyu Zhang",
      "Xiuze Xia",
      "Long Cheng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.10331",
    "title": "Hardness results for decoding the surface code with Pauli noise",
    "abstract": " Comments: 44 pages, 21 figures. 29 pages, 13 figures in main text. This version includes minor improvements to explanations, more standardized terminology, and minor extensions of the results in Appendices C and D ",
    "url": "https://arxiv.org/abs/2309.10331",
    "authors": [
      "Alex Fischer",
      "Akimasa Miyake"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2309.10402",
    "title": "Minimum width for universal approximation using ReLU networks on compact  domain",
    "abstract": " Title: Minimum width for universal approximation using ReLU networks on compact  domain ",
    "url": "https://arxiv.org/abs/2309.10402",
    "authors": [
      "Namjun Kim",
      "Chanho Min",
      "Sejun Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.13944",
    "title": "Provable Training for Graph Contrastive Learning",
    "abstract": " Comments: NeurIPS 2023 spotlight. Camera-ready version ",
    "url": "https://arxiv.org/abs/2309.13944",
    "authors": [
      "Yue Yu",
      "Xiao Wang",
      "Mengmei Zhang",
      "Nian Liu",
      "Chuan Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.14225",
    "title": "HumanMimic: Learning Natural Locomotion and Transitions for Humanoid  Robot via Wasserstein Adversarial Imitation",
    "abstract": " Title: HumanMimic: Learning Natural Locomotion and Transitions for Humanoid  Robot via Wasserstein Adversarial Imitation ",
    "url": "https://arxiv.org/abs/2309.14225",
    "authors": [
      "Annan Tang",
      "Takuma Hiraoka",
      "Naoki Hiraoka",
      "Fan Shi",
      "Kento Kawaharazuka",
      "Kunio Kojima",
      "Kei Okada",
      "Masayuki Inaba"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.16487",
    "title": "Towards Poisoning Fair Representations",
    "abstract": " Title: Towards Poisoning Fair Representations ",
    "url": "https://arxiv.org/abs/2309.16487",
    "authors": [
      "Tianci Liu",
      "Haoyu Wang",
      "Feijie Wu",
      "Hengtong Zhang",
      "Pan Li",
      "Lu Su",
      "Jing Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00648",
    "title": "PETA: Parameter-Efficient Trojan Attacks",
    "abstract": " Title: PETA: Parameter-Efficient Trojan Attacks ",
    "url": "https://arxiv.org/abs/2310.00648",
    "authors": [
      "Lauren Hong",
      "Ting Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.09527",
    "title": "A discontinuous plane wave neural network method for Helmholtz equation  and time-harmonic Maxwell's equations",
    "abstract": " Title: A discontinuous plane wave neural network method for Helmholtz equation  and time-harmonic Maxwell's equations ",
    "url": "https://arxiv.org/abs/2310.09527",
    "authors": [
      "Long Yuan",
      "Qiya Hu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.09793",
    "title": "Automated Detection of Cat Facial Landmarks",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2305.04232 ",
    "url": "https://arxiv.org/abs/2310.09793",
    "authors": [
      "George Martvel",
      "Ilan Shimshoni",
      "Anna Zamansky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.09847",
    "title": "XRMDN: An Extended Recurrent Mixture Density Network for Short-Term  Probabilistic Rider Demand Forecasting with High Volatility",
    "abstract": " Comments: 11 pages, 14 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2310.09847",
    "authors": [
      "Xiaoming Li",
      "Hubert Normandin-Taillon",
      "Chun Wang",
      "Xiao Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.17748",
    "title": "Making the End-User a Priority in Benchmarking: OrionBench for  Unsupervised Time Series Anomaly Detection",
    "abstract": " Title: Making the End-User a Priority in Benchmarking: OrionBench for  Unsupervised Time Series Anomaly Detection ",
    "url": "https://arxiv.org/abs/2310.17748",
    "authors": [
      "Sarah Alnegheimish",
      "Laure Berti-Equille",
      "Kalyan Veeramachaneni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19794",
    "title": "Robust Causal Bandits for Linear Models",
    "abstract": " Title: Robust Causal Bandits for Linear Models ",
    "url": "https://arxiv.org/abs/2310.19794",
    "authors": [
      "Zirui Yan",
      "Arpan Mukherjee",
      "Burak Var\u0131c\u0131",
      "Ali Tajer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.14058",
    "title": "Identification for Tree-shaped Structural Causal Models in Polynomial  Time",
    "abstract": " Title: Identification for Tree-shaped Structural Causal Models in Polynomial  Time ",
    "url": "https://arxiv.org/abs/2311.14058",
    "authors": [
      "Aaryan Gupta",
      "Markus Bl\u00e4ser"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2311.15453",
    "title": "DISYRE: Diffusion-Inspired SYnthetic REstoration for Unsupervised  Anomaly Detection",
    "abstract": " Comments: 5 pages, 3 figures. Accepted for publication in ISBI 2024 ",
    "url": "https://arxiv.org/abs/2311.15453",
    "authors": [
      "Sergio Naval Marimont",
      "Matthew Baugh",
      "Vasilis Siomos",
      "Christos Tzelepis",
      "Bernhard Kainz",
      "Giacomo Tarroni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2311.16417",
    "title": "Challenges and Opportunities to Enable Large-Scale Computing via  Heterogeneous Chiplets",
    "abstract": " Title: Challenges and Opportunities to Enable Large-Scale Computing via  Heterogeneous Chiplets ",
    "url": "https://arxiv.org/abs/2311.16417",
    "authors": [
      "Zhuoping Yang",
      "Shixin Ji",
      "Xingzhen Chen",
      "Jinming Zhuang",
      "Weifeng Zhang",
      "Dharmesh Jani",
      "Peipei Zhou"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2311.18061",
    "title": "TransNAS-TSAD: Harnessing Transformers for Multi-Objective Neural  Architecture Search in Time Series Anomaly Detection",
    "abstract": " Comments: 32 pages , 4 figures, It will submitted to a journal ",
    "url": "https://arxiv.org/abs/2311.18061",
    "authors": [
      "Ijaz Ul Haq",
      "Byung Suk Lee",
      "Donna M. Rizzo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.18177",
    "title": "An Effective Universal Polynomial Basis for Spectral Graph Neural  Networks",
    "abstract": " Title: An Effective Universal Polynomial Basis for Spectral Graph Neural  Networks ",
    "url": "https://arxiv.org/abs/2311.18177",
    "authors": [
      "Keke Huang",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.03085",
    "title": "ScAR: Scaling Adversarial Robustness for LiDAR Object Detection",
    "abstract": " Title: ScAR: Scaling Adversarial Robustness for LiDAR Object Detection ",
    "url": "https://arxiv.org/abs/2312.03085",
    "authors": [
      "Xiaohu Lu",
      "Hayder Radha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.05772",
    "title": "A^3-CodGen: A Repository-Level Code Generation Framework for Code Reuse  with Local-Aware, Global-Aware, and Third-Party-Library-Aware",
    "abstract": " Title: A^3-CodGen: A Repository-Level Code Generation Framework for Code Reuse  with Local-Aware, Global-Aware, and Third-Party-Library-Aware ",
    "url": "https://arxiv.org/abs/2312.05772",
    "authors": [
      "Dianshu Liao",
      "Shidong Pan",
      "Xiaoyu Sun",
      "Xiaoxue Ren",
      "Qing Huang",
      "Zhenchang Xing",
      "Huan Jin",
      "Qinying Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2312.08616",
    "title": "A Generalized Neural Diffusion Framework on Graphs",
    "abstract": " Comments: Accepted by AAAI 2024 ",
    "url": "https://arxiv.org/abs/2312.08616",
    "authors": [
      "Yibo Li",
      "Xiao Wang",
      "Hongrui Liu",
      "Chuan Shi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.12450",
    "title": "Can It Edit? Evaluating the Ability of Large Language Models to Follow  Code Editing Instructions",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2312.06024 ",
    "url": "https://arxiv.org/abs/2312.12450",
    "authors": [
      "Federico Cassano",
      "Luisa Li",
      "Akul Sethi",
      "Noah Shinn",
      "Abby Brennan-Jones",
      "Anton Lozhkov",
      "Carolyn Jane Anderson",
      "Arjun Guha"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2312.15504",
    "title": "Power Allocation and Beamforming Design for IRS-aided Secure Directional  Modulation Network",
    "abstract": " Title: Power Allocation and Beamforming Design for IRS-aided Secure Directional  Modulation Network ",
    "url": "https://arxiv.org/abs/2312.15504",
    "authors": [
      "Rongen Dong",
      "Feng Shu",
      "Fuhui Zhou",
      "Yongpeng Wu",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2401.06401",
    "title": "DevEval: Evaluating Code Generation in Practical Software Projects",
    "abstract": " Comments: There are mistakes in the dataset. We need to re-check the dataset and repeat our experiments ",
    "url": "https://arxiv.org/abs/2401.06401",
    "authors": [
      "Jia Li",
      "Ge Li",
      "Yunfei Zhao",
      "Yongmin Li",
      "Zhi Jin",
      "Hao Zhu",
      "Huanyu Liu",
      "Kaibo Liu",
      "Lecheng Wang",
      "Zheng Fang",
      "Lanshen Wang",
      "Jiazheng Ding",
      "Xuanming Zhang",
      "Yihong Dong",
      "Yuqi Zhu",
      "Bin Gu",
      "Mengfei Yang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.06509",
    "title": "AntEval: Evaluation of Social Interaction Competencies in LLM-Driven  Agents",
    "abstract": " Comments: Preliminary version of an ongoing work ",
    "url": "https://arxiv.org/abs/2401.06509",
    "authors": [
      "Yuanzhi Liang",
      "Linchao Zhu",
      "Yi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.15906",
    "title": "Mean Estimation with User-Level Privacy for Spatio-Temporal IoT Datasets",
    "abstract": " Comments: 14 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2401.15906",
    "authors": [
      "V. Arvind Rameshwar",
      "Anshoo Tandon",
      "Prajjwal Gupta",
      "Aditya Vikram Singh",
      "Novoneel Chakraborty",
      "Abhay Sharma"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2402.02649",
    "title": "Densely Decoded Networks with Adaptive Deep Supervision for Medical  Image Segmentation",
    "abstract": " Title: Densely Decoded Networks with Adaptive Deep Supervision for Medical  Image Segmentation ",
    "url": "https://arxiv.org/abs/2402.02649",
    "authors": [
      "Suraj Mishra",
      "Danny Z. Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.12426",
    "title": "Attacks on Node Attributes in Graph Neural Networks",
    "abstract": " Comments: Accepted to AAAI 2024 AICS workshop ",
    "url": "https://arxiv.org/abs/2402.12426",
    "authors": [
      "Ying Xu",
      "Michael Lanier",
      "Anindya Sarkar",
      "Yevgeniy Vorobeychik"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12721",
    "title": "PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for  Recognizing Low-Quality Images",
    "abstract": " Comments: Accepted at ICLR 2024 ",
    "url": "https://arxiv.org/abs/2402.12721",
    "authors": [
      "Jinsung Jeon",
      "Hyundong Jin",
      "Jonghyun Choi",
      "Sanghyun Hong",
      "Dongeun Lee",
      "Kookjin Lee",
      "Noseong Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.12936",
    "title": "Measuring Impacts of Poisoning on Model Parameters and Neuron  Activations: A Case Study of Poisoning CodeBERT",
    "abstract": " Title: Measuring Impacts of Poisoning on Model Parameters and Neuron  Activations: A Case Study of Poisoning CodeBERT ",
    "url": "https://arxiv.org/abs/2402.12936",
    "authors": [
      "Aftab Hussain",
      "Md Rafiqul Islam Rabin",
      "Navid Ayoobi",
      "Mohammad Amin Alipour"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.13613",
    "title": "Overview of the VLSP 2023 -- ComOM Shared Task: A Data Challenge for  Comparative Opinion Mining from Vietnamese Product Reviews",
    "abstract": " Comments: In Proceedings of VLSP 2023 ",
    "url": "https://arxiv.org/abs/2402.13613",
    "authors": [
      "Hoang-Quynh Le",
      "Duy-Cat Can",
      "Khanh-Vinh Nguyen",
      "Mai-Vu Tran"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13852",
    "title": "Neural Control System for Continuous Glucose Monitoring and Maintenance",
    "abstract": " Comments: 9 Pages, 4 figures, ICLR 2024 Tiny Papers Track this https URL ",
    "url": "https://arxiv.org/abs/2402.13852",
    "authors": [
      "Azmine Toushik Wasi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.13948",
    "title": "Improved Syndrome-based Neural Decoder for Linear Block Codes",
    "abstract": " Comments: 6 pages, 7 figures. Published in Proc. IEEE Global Communications Conference (GLOBECOM 2023), Kuala Lumpur, Malaysia, December 4-8, 2023. \\c{opyright} 2023 IEEE ",
    "url": "https://arxiv.org/abs/2402.13948",
    "authors": [
      "Gast\u00f3n De Boni Rovella",
      "Meryem Benammar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2402.15183",
    "title": "GraphEdit: Large Language Models for Graph Structure Learning",
    "abstract": " Title: GraphEdit: Large Language Models for Graph Structure Learning ",
    "url": "https://arxiv.org/abs/2402.15183",
    "authors": [
      "Zirui Guo",
      "Lianghao Xia",
      "Yanhua Yu",
      "Yuling Wang",
      "Zixuan Yang",
      "Wei Wei",
      "Liang Pang",
      "Tat-Seng Chua",
      "Chao Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.18372",
    "title": "FedUV: Uniformity and Variance for Heterogeneous Federated Learning",
    "abstract": " Comments: 11 pages, 4 figures, 5 tables, to appear at CVPR 2024 ",
    "url": "https://arxiv.org/abs/2402.18372",
    "authors": [
      "Ha Min Son",
      "Moon-Hyun Kim",
      "Tai-Myoung Chung",
      "Chao Huang",
      "Xin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2402.19001",
    "title": "Analysis of the Two-Step Heterogeneous Transfer Learning for Laryngeal  Blood Vessel Classification: Issue and Improvement",
    "abstract": " Title: Analysis of the Two-Step Heterogeneous Transfer Learning for Laryngeal  Blood Vessel Classification: Issue and Improvement ",
    "url": "https://arxiv.org/abs/2402.19001",
    "authors": [
      "Xinyi Fang",
      "Chak Fong Chong",
      "Kei Long Wong",
      "Yapeng Wang",
      "Wei Ke",
      "Tiankui Zhang",
      "Sio-Kei Im"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.19170",
    "title": "Improving Legal Judgement Prediction in Romanian with Long Text Encoders",
    "abstract": " Comments: Rejected at LREC-COLING with 4/4/3 ",
    "url": "https://arxiv.org/abs/2402.19170",
    "authors": [
      "Mihai Masala",
      "Traian Rebedea",
      "Horia Velicu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.19280",
    "title": "Mobile Health Text Misinformation Identification Using Mobile Data  Mining",
    "abstract": " Title: Mobile Health Text Misinformation Identification Using Mobile Data  Mining ",
    "url": "https://arxiv.org/abs/2402.19280",
    "authors": [
      "Wen-Chen Hu",
      "Sanjaikanth E Vadakkethil Somanathan Pillai",
      "Abdelrahman Ahmed ElSaid"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2403.00030",
    "title": "GraphPub: Generation of Differential Privacy Graph with High  Availability",
    "abstract": " Title: GraphPub: Generation of Differential Privacy Graph with High  Availability ",
    "url": "https://arxiv.org/abs/2403.00030",
    "authors": [
      "Wanghan Xu",
      "Bin Shi",
      "Ao Liu",
      "Jiqiang Zhang",
      "Bo Dong"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.00225",
    "title": "Robust Policy Learning via Offline Skill Diffusion",
    "abstract": " Comments: Accepted for AAAI 2024 ",
    "url": "https://arxiv.org/abs/2403.00225",
    "authors": [
      "Woo Kyung Kim",
      "Minjong Yoo",
      "Honguk Woo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.00579",
    "title": "NeuPIMs: NPU-PIM Heterogeneous Acceleration for Batched LLM Inferencing",
    "abstract": " Comments: 13 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2403.00579",
    "authors": [
      "Guseul Heo",
      "Sangyeop Lee",
      "Jaehong Cho",
      "Hyunmin Choi",
      "Sanghyeon Lee",
      "Hyungkyu Ham",
      "Gwangsun Kim",
      "Divya Mahajan",
      "Jongse Park"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2403.00685",
    "title": "Know your exceptions: Towards an Ontology of Exceptions in Knowledge  Representation",
    "abstract": " Comments: 18 pages, 4 pages are appendix. (v2 updates: minor revisions on discussions, terminology and text editing) ",
    "url": "https://arxiv.org/abs/2403.00685",
    "authors": [
      "Gabriele Sacco",
      "Loris Bozzato",
      "Oliver Kutz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.00867",
    "title": "Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by  Exploring Refusal Loss Landscapes",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2403.00867",
    "authors": [
      "Xiaomeng Hu",
      "Pin-Yu Chen",
      "Tsung-Yi Ho"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.00890",
    "title": "Improving Android Malware Detection Through Data Augmentation Using  Wasserstein Generative Adversarial Networks",
    "abstract": " Comments: 20 pages ",
    "url": "https://arxiv.org/abs/2403.00890",
    "authors": [
      "Kawana Stalin",
      "Mikias Berhanu Mekoya"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.01085",
    "title": "A Strongly Subcubic Combinatorial Algorithm for Triangle Detection with  Applications",
    "abstract": " Comments: The triangle detection algorithm may fail. The analysis of Case 2.1 (in Subsection 2.1) is invalid. Thanks to Zach Hunter for pointing this out ",
    "url": "https://arxiv.org/abs/2403.01085",
    "authors": [
      "Adrian Dumitrescu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2403.01131",
    "title": "LLaMoCo: Instruction Tuning of Large Language Models for Optimization  Code Generation",
    "abstract": " Title: LLaMoCo: Instruction Tuning of Large Language Models for Optimization  Code Generation ",
    "url": "https://arxiv.org/abs/2403.01131",
    "authors": [
      "Zeyuan Ma",
      "Hongshu Guo",
      "Jiacheng Chen",
      "Guojun Peng",
      "Zhiguang Cao",
      "Yining Ma",
      "Yue-Jiao Gong"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2403.01548",
    "title": "In-Context Sharpness as Alerts: An Inner Representation Perspective for  Hallucination Mitigation",
    "abstract": " Comments: code repo is available at: this https URL ",
    "url": "https://arxiv.org/abs/2403.01548",
    "authors": [
      "Shiqi Chen",
      "Miao Xiong",
      "Junteng Liu",
      "Zhengxuan Wu",
      "Teng Xiao",
      "Siyang Gao",
      "Junxian He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.01802",
    "title": "TNF: Tri-branch Neural Fusion for Multimodal Medical Data Classification",
    "abstract": " Title: TNF: Tri-branch Neural Fusion for Multimodal Medical Data Classification ",
    "url": "https://arxiv.org/abs/2403.01802",
    "authors": [
      "Tong Zheng",
      "Shusaku Sone",
      "Yoshitaka Ushiku",
      "Yuki Oba",
      "Jiaxin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.01897",
    "title": "Fostering the Ecosystem of Open Neural Encoders for Portuguese with  Albertina PT* Family",
    "abstract": " Title: Fostering the Ecosystem of Open Neural Encoders for Portuguese with  Albertina PT* Family ",
    "url": "https://arxiv.org/abs/2403.01897",
    "authors": [
      "Rodrigo Santos",
      "Jo\u00e3o Rodrigues",
      "Lu\u00eds Gomes",
      "Jo\u00e3o Silva",
      "Ant\u00f3nio Branco",
      "Henrique Lopes Cardoso",
      "Tom\u00e1s Freitas Os\u00f3rio",
      "Bernardo Leite"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.01944",
    "title": "Fourier-basis Functions to Bridge Augmentation Gap: Rethinking Frequency  Augmentation in Image Classification",
    "abstract": " Comments: Accepted at CVPR 2024 ",
    "url": "https://arxiv.org/abs/2403.01944",
    "authors": [
      "Puru Vaish",
      "Shunxin Wang",
      "Nicola Strisciuglio"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.02175",
    "title": "LiSTA: Geometric Object-Based Change Detection in Cluttered Environments",
    "abstract": " Comments: 6+n page limit for (accepted) ICRA 2024 submission ",
    "url": "https://arxiv.org/abs/2403.02175",
    "authors": [
      "Joseph Rowell",
      "Lintong Zhang",
      "Maurice Fallon"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.02241",
    "title": "Neural Redshift: Random Networks are not Random Functions",
    "abstract": " Title: Neural Redshift: Random Networks are not Random Functions ",
    "url": "https://arxiv.org/abs/2403.02241",
    "authors": [
      "Damien Teney",
      "Armand Nicolicioiu",
      "Valentin Hartmann",
      "Ehsan Abbasnejad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]