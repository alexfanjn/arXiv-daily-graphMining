[
  {
    "id": "arXiv:2403.17969",
    "title": "Antimagic Labeling of Graphs Using Prime Numbers",
    "abstract": "Graph labeling is a technique that assigns unique labels or weights to the vertices or edges of a graph, often used to analyze and solve various graph-related problems. There are few methods with certain limitations conducted by researchers previously on this topic. This research paper focuses on antimagic labeling of different types of graphs and trees. It entails the assignment of distinct prime values to edges in a manner that ensures the cumulative sum of edge labels at each vertex remains unique. This research proposes a conjecture on antimagic labeling of any graphs and proves two theories. Firstly, we tried to give weights to the edges randomly, as some exceptions are faced in particular phases in this way, we followed a whole new way to mitigate this problem. This research paper demonstrates computational and mathematical verification to prove that antimagic labeling of any perfect binary tree and complete graph is possible. ",
    "url": "https://arxiv.org/abs/2403.17969",
    "authors": [
      "Arafat Islam",
      "Md. Imtiaz Habib"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2403.17978",
    "title": "Holographic Global Convolutional Networks for Long-Range Prediction  Tasks in Malware Detection",
    "abstract": "Malware detection is an interesting and valuable domain to work in because it has significant real-world impact and unique machine-learning challenges. We investigate existing long-range techniques and benchmarks and find that they're not very suitable in this problem area. In this paper, we introduce Holographic Global Convolutional Networks (HGConv) that utilize the properties of Holographic Reduced Representations (HRR) to encode and decode features from sequence elements. Unlike other global convolutional methods, our method does not require any intricate kernel computation or crafted kernel design. HGConv kernels are defined as simple parameters learned through backpropagation. The proposed method has achieved new SOTA results on Microsoft Malware Classification Challenge, Drebin, and EMBER malware benchmarks. With log-linear complexity in sequence length, the empirical results demonstrate substantially faster run-time by HGConv compared to other methods achieving far more efficient scaling even with sequence length $\\geq 100,000$. ",
    "url": "https://arxiv.org/abs/2403.17978",
    "authors": [
      "Mohammad Mahmudul Alam",
      "Edward Raff",
      "Stella Biderman",
      "Tim Oates",
      "James Holt"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.17980",
    "title": "EG-ConMix: An Intrusion Detection Method based on Graph Contrastive  Learning",
    "abstract": "As the number of IoT devices increases, security concerns become more prominent. The impact of threats can be minimized by deploying Network Intrusion Detection System (NIDS) by monitoring network traffic, detecting and discovering intrusions, and issuing security alerts promptly. Most intrusion detection research in recent years has been directed towards the pair of traffic itself without considering the interrelationships among them, thus limiting the monitoring of complex IoT network attack events. Besides, anomalous traffic in real networks accounts for only a small fraction, which leads to a severe imbalance problem in the dataset that makes algorithmic learning and prediction extremely difficult. In this paper, we propose an EG-ConMix method based on E-GraphSAGE, incorporating a data augmentation module to fix the problem of data imbalance. In addition, we incorporate contrastive learning to discern the difference between normal and malicious traffic samples, facilitating the extraction of key features. Extensive experiments on two publicly available datasets demonstrate the superior intrusion detection performance of EG-ConMix compared to state-of-the-art methods. Remarkably, it exhibits significant advantages in terms of training speed and accuracy for large-scale graphs. ",
    "url": "https://arxiv.org/abs/2403.17980",
    "authors": [
      "Lijin Wu",
      "Shanshan Lei",
      "Feilong Liao",
      "Yuanjun Zheng",
      "Yuxin Liu",
      "Wentao Fu",
      "Hao Song",
      "Jiajun Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.17983",
    "title": "Is Watermarking LLM-Generated Code Robust?",
    "abstract": "We present the first study of the robustness of existing watermarking techniques on Python code generated by large language models. Although existing works showed that watermarking can be robust for natural language, we show that it is easy to remove these watermarks on code by semantic-preserving transformations. ",
    "url": "https://arxiv.org/abs/2403.17983",
    "authors": [
      "Tarun Suresh",
      "Shubham Ugare",
      "Gagandeep Singh",
      "Sasa Misailovic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.17995",
    "title": "Semi-Supervised Image Captioning Considering Wasserstein Graph Matching",
    "abstract": "Image captioning can automatically generate captions for the given images, and the key challenge is to learn a mapping function from visual features to natural language features. Existing approaches are mostly supervised ones, i.e., each image has a corresponding sentence in the training set. However, considering that describing images always requires a huge of manpower, we usually have limited amount of described images (i.e., image-text pairs) and a large number of undescribed images in real-world applications. Thereby, a dilemma is the \"Semi-Supervised Image Captioning\". To solve this problem, we propose a novel Semi-Supervised Image Captioning method considering Wasserstein Graph Matching (SSIC-WGM), which turns to adopt the raw image inputs to supervise the generated sentences. Different from traditional single modal semi-supervised methods, the difficulty of semi-supervised cross-modal learning lies in constructing intermediately comparable information among heterogeneous modalities. In this paper, SSIC-WGM adopts the successful scene graphs as intermediate information, and constrains the generated sentences from two aspects: 1) inter-modal consistency. SSIC-WGM constructs the scene graphs of the raw image and generated sentence respectively, then employs the wasserstein distance to better measure the similarity between region embeddings of different graphs. 2) intra-modal consistency. SSIC-WGM takes the data augmentation techniques for the raw images, then constrains the consistency among augmented images and generated sentences. Consequently, SSIC-WGM combines the cross-modal pseudo supervision and structure invariant measure for efficiently using the undescribed images, and learns more reasonable mapping function. ",
    "url": "https://arxiv.org/abs/2403.17995",
    "authors": [
      "Yang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.17998",
    "title": "Text Is MASS: Modeling as Stochastic Embedding for Text-Video Retrieval",
    "abstract": "The increasing prevalence of video clips has sparked growing interest in text-video retrieval. Recent advances focus on establishing a joint embedding space for text and video, relying on consistent embedding representations to compute similarity. However, the text content in existing datasets is generally short and concise, making it hard to fully describe the redundant semantics of a video. Correspondingly, a single text embedding may be less expressive to capture the video embedding and empower the retrieval. In this study, we propose a new stochastic text modeling method T-MASS, i.e., text is modeled as a stochastic embedding, to enrich text embedding with a flexible and resilient semantic range, yielding a text mass. To be specific, we introduce a similarity-aware radius module to adapt the scale of the text mass upon the given text-video pairs. Plus, we design and develop a support text regularization to further control the text mass during the training. The inference pipeline is also tailored to fully exploit the text mass for accurate retrieval. Empirical evidence suggests that T-MASS not only effectively attracts relevant text-video pairs while distancing irrelevant ones, but also enables the determination of precise text embeddings for relevant pairs. Our experimental results show a substantial improvement of T-MASS over baseline (3% to 6.3% by R@1). Also, T-MASS achieves state-of-the-art performance on five benchmark datasets, including MSRVTT, LSMDC, DiDeMo, VATEX, and Charades. ",
    "url": "https://arxiv.org/abs/2403.17998",
    "authors": [
      "Jiamian Wang",
      "Guohao Sun",
      "Pichao Wang",
      "Dongfang Liu",
      "Sohail Dianat",
      "Majid Rabbani",
      "Raghuveer Rao",
      "Zhiqiang Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18024",
    "title": "Enriching Word Usage Graphs with Cluster Definitions",
    "abstract": "We present a dataset of word usage graphs (WUGs), where the existing WUGs for multiple languages are enriched with cluster labels functioning as sense definitions. They are generated from scratch by fine-tuned encoder-decoder language models. The conducted human evaluation has shown that these definitions match the existing clusters in WUGs better than the definitions chosen from WordNet by two baseline systems. At the same time, the method is straightforward to use and easy to extend to new languages. The resulting enriched datasets can be extremely helpful for moving on to explainable semantic change modeling. ",
    "url": "https://arxiv.org/abs/2403.18024",
    "authors": [
      "Mariia Fedorova",
      "Andrey Kutuzov",
      "Nikolay Arefyev",
      "Dominik Schlechtweg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.18038",
    "title": "TGGLinesPlus: A robust topological graph-guided computer vision  algorithm for line detection from images",
    "abstract": "Line detection is a classic and essential problem in image processing, computer vision and machine intelligence. Line detection has many important applications, including image vectorization (e.g., document recognition and art design), indoor mapping, and important societal challenges (e.g., sea ice fracture line extraction from satellite imagery). Many line detection algorithms and methods have been developed, but robust and intuitive methods are still lacking. In this paper, we proposed and implemented a topological graph-guided algorithm, named TGGLinesPlus, for line detection. Our experiments on images from a wide range of domains have demonstrated the flexibility of our TGGLinesPlus algorithm. We also benchmarked our algorithm with five classic and state-of-the-art line detection methods and the results demonstrate the robustness of TGGLinesPlus. We hope our open-source implementation of TGGLinesPlus will inspire and pave the way for many applications where spatial science matters. ",
    "url": "https://arxiv.org/abs/2403.18038",
    "authors": [
      "Liping Yang",
      "Joshua Driscol",
      "Ming Gong",
      "Shujie Wang",
      "Catherine G. Potts"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18040",
    "title": "Global Point Cloud Registration Network for Large Transformations",
    "abstract": "Three-dimensional data registration is an established yet challenging problem that is key in many different applications, such as mapping the environment for autonomous vehicles, and modeling objects and people for avatar creation, among many others. Registration refers to the process of mapping multiple data into the same coordinate system by means of matching correspondences and transformation estimation. Novel proposals exploit the benefits of deep learning architectures for this purpose, as they learn the best features for the data, providing better matches and hence results. However, the state of the art is usually focused on cases of relatively small transformations, although in certain applications and in a real and practical environment, large transformations are very common. In this paper, we present ReLaTo (Registration for Large Transformations), an architecture that faces the cases where large transformations happen while maintaining good performance for local transformations. This proposal uses a novel Softmax pooling layer to find correspondences in a bilateral consensus manner between two point sets, sampling the most confident matches. These matches are used to estimate a coarse and global registration using weighted Singular Value Decomposition (SVD). A target-guided denoising step is then applied to both the obtained matches and latent features, estimating the final fine registration considering the local geometry. All these steps are carried out following an end-to-end approach, which has been shown to improve 10 state-of-the-art registration methods in two datasets commonly used for this task (ModelNet40 and KITTI), especially in the case of large transformations. ",
    "url": "https://arxiv.org/abs/2403.18040",
    "authors": [
      "Hanz Cuevas-Velasquez",
      "Alejandro Gal\u00e1n-Cuenca",
      "Antonio Javier Gallego",
      "Marcelo Saval-Calvo",
      "Robert B. Fisher"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18042",
    "title": "Extending Network Calculus To Deal With Partially Negative And  Decreasing Service Curves",
    "abstract": "Network Calculus (NC) is a versatile analytical methodology to efficiently compute performance bounds in networked systems. The arrival and service curve abstractions allow to model diverse and heterogeneous distributed systems. The operations to compute residual service curves and to concatenate sequences of systems enable an efficient and accurate calculation of per-flow timing guarantees. Yet, in some scenarios involving multiple concurrent flows at a system, the central notion of so-called min-plus service curves is too weak to still be able to compute a meaningful residual service curve. In these cases, one usually resorts to so-called strict service curves that enable the computation of per-flow bounds. However, strict service curves are restrictive: (1) there are service elements for which only min-plus service curves can be provided but not strict ones and (2) strict service curves generally have no concatenation property, i.e., a sequence of two strict systems does not yield a strict service curve. In this report, we extend NC to deal with systems only offering aggregate min-plus service curves to multiple flows. The key to this extension is the exploitation of minimal arrival curves, i.e., lower bounds on the arrival process. Technically speaking, we provide basic performance bounds (backlog and delay) for the case of negative service curves. We also discuss their accuracy and show them to be tight. In order to illustrate their usefulness we also present patterns of application of these new results for: (1) heterogeneous systems involving computation and communication resources and (2) finite buffers that are shared between multiple flows. ",
    "url": "https://arxiv.org/abs/2403.18042",
    "authors": [
      "Anja Hamscher",
      "Vlad-Cristian Constantin",
      "Jens B. Schmitt"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2403.18056",
    "title": "Self-Clustering Hierarchical Multi-Agent Reinforcement Learning with  Extensible Cooperation Graph",
    "abstract": "Multi-Agent Reinforcement Learning (MARL) has been successful in solving many cooperative challenges. However, classic non-hierarchical MARL algorithms still cannot address various complex multi-agent problems that require hierarchical cooperative behaviors. The cooperative knowledge and policies learned in non-hierarchical algorithms are implicit and not interpretable, thereby restricting the integration of existing knowledge. This paper proposes a novel hierarchical MARL model called Hierarchical Cooperation Graph Learning (HCGL) for solving general multi-agent problems. HCGL has three components: a dynamic Extensible Cooperation Graph (ECG) for achieving self-clustering cooperation; a group of graph operators for adjusting the topology of ECG; and an MARL optimizer for training these graph operators. HCGL's key distinction from other MARL models is that the behaviors of agents are guided by the topology of ECG instead of policy neural networks. ECG is a three-layer graph consisting of an agent node layer, a cluster node layer, and a target node layer. To manipulate the ECG topology in response to changing environmental conditions, four graph operators are trained to adjust the edge connections of ECG dynamically. The hierarchical feature of ECG provides a unique approach to merge primitive actions (actions executed by the agents) and cooperative actions (actions executed by the clusters) into a unified action space, allowing us to integrate fundamental cooperative knowledge into an extensible interface. In our experiments, the HCGL model has shown outstanding performance in multi-agent benchmarks with sparse rewards. We also verify that HCGL can easily be transferred to large-scale scenarios with high zero-shot transfer success rates. ",
    "url": "https://arxiv.org/abs/2403.18056",
    "authors": [
      "Qingxu Fu",
      "Tenghai Qiu",
      "Jianqiang Yi",
      "Zhiqiang Pu",
      "Xiaolin Ai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.18057",
    "title": "Prioritized League Reinforcement Learning for Large-Scale Heterogeneous  Multiagent Systems",
    "abstract": "Large-scale heterogeneous multiagent systems feature various realistic factors in the real world, such as agents with diverse abilities and overall system cost. In comparison to homogeneous systems, heterogeneous systems offer significant practical advantages. Nonetheless, they also present challenges for multiagent reinforcement learning, including addressing the non-stationary problem and managing an imbalanced number of agents with different types. We propose a Prioritized Heterogeneous League Reinforcement Learning (PHLRL) method to address large-scale heterogeneous cooperation problems. PHLRL maintains a record of various policies that agents have explored during their training and establishes a heterogeneous league consisting of diverse policies to aid in future policy optimization. Furthermore, we design a prioritized policy gradient approach to compensate for the gap caused by differences in the number of different types of agents. Next, we use Unreal Engine to design a large-scale heterogeneous cooperation benchmark named Large-Scale Multiagent Operation (LSMO), which is a complex two-team competition scenario that requires collaboration from both ground and airborne agents. We use experiments to show that PHLRL outperforms state-of-the-art methods, including QTRAN and QPLEX in LSMO. ",
    "url": "https://arxiv.org/abs/2403.18057",
    "authors": [
      "Qingxu Fu",
      "Zhiqiang Pu",
      "Min Chen",
      "Tenghai Qiu",
      "Jianqiang Yi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.18063",
    "title": "Spectral Convolutional Transformer: Harmonizing Real vs. Complex  Multi-View Spectral Operators for Vision Transformer",
    "abstract": "Transformers used in vision have been investigated through diverse architectures - ViT, PVT, and Swin. These have worked to improve the attention mechanism and make it more efficient. Differently, the need for including local information was felt, leading to incorporating convolutions in transformers such as CPVT and CvT. Global information is captured using a complex Fourier basis to achieve global token mixing through various methods, such as AFNO, GFNet, and Spectformer. We advocate combining three diverse views of data - local, global, and long-range dependence. We also investigate the simplest global representation using only the real domain spectral representation - obtained through the Hartley transform. We use a convolutional operator in the initial layers to capture local information. Through these two contributions, we are able to optimize and obtain a spectral convolution transformer (SCT) that provides improved performance over the state-of-the-art methods while reducing the number of parameters. Through extensive experiments, we show that SCT-C-small gives state-of-the-art performance on the ImageNet dataset and reaches 84.5\\% top-1 accuracy, while SCT-C-Large reaches 85.9\\% and SCT-C-Huge reaches 86.4\\%. We evaluate SCT on transfer learning on datasets such as CIFAR-10, CIFAR-100, Oxford Flower, and Stanford Car. We also evaluate SCT on downstream tasks i.e. instance segmentation on the MSCOCO dataset. The project page is available on this webpage.\\url{https://github.com/badripatro/sct} ",
    "url": "https://arxiv.org/abs/2403.18063",
    "authors": [
      "Badri N. Patro",
      "Vinay P. Namboodiri",
      "Vijay S. Agneeswaran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2403.18128",
    "title": "HealthGAT: Node Classifications in Electronic Health Records using Graph  Attention Networks",
    "abstract": "While electronic health records (EHRs) are widely used across various applications in healthcare, most applications use the EHRs in their raw (tabular) format. Relying on raw or simple data pre-processing can greatly limit the performance or even applicability of downstream tasks using EHRs. To address this challenge, we present HealthGAT, a novel graph attention network framework that utilizes a hierarchical approach to generate embeddings from EHR, surpassing traditional graph-based methods. Our model iteratively refines the embeddings for medical codes, resulting in improved EHR data analysis. We also introduce customized EHR-centric auxiliary pre-training tasks to leverage the rich medical knowledge embedded within the data. This approach provides a comprehensive analysis of complex medical relationships and offers significant advancement over standard data representation techniques. HealthGAT has demonstrated its effectiveness in various healthcare scenarios through comprehensive evaluations against established methodologies. Specifically, our model shows outstanding performance in node classification and downstream tasks such as predicting readmissions and diagnosis classifications. Our code is available at https://github.com/healthylaife/HealthGAT ",
    "url": "https://arxiv.org/abs/2403.18128",
    "authors": [
      "Fahmida Liza Piya",
      "Mehak Gupta",
      "Rahmatollah Beheshti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2403.18136",
    "title": "Securing GNNs: Explanation-Based Identification of Backdoored Training  Graphs",
    "abstract": "Graph Neural Networks (GNNs) have gained popularity in numerous domains, yet they are vulnerable to backdoor attacks that can compromise their performance and ethical application. The detection of these attacks is crucial for maintaining the reliability and security of GNN classification tasks, but effective detection techniques are lacking. Following an initial investigation, we observed that while graph-level explanations can offer limited insights, their effectiveness in detecting backdoor triggers is inconsistent and incomplete. To bridge this gap, we extract and transform secondary outputs of GNN explanation mechanisms, designing seven novel metrics that more effectively detect backdoor attacks. Additionally, we develop an adaptive attack to rigorously evaluate our approach. We test our method on multiple benchmark datasets and examine its efficacy against various attack models. Our results show that our method can achieve high detection performance, marking a significant advancement in safeguarding GNNs against backdoor attacks. ",
    "url": "https://arxiv.org/abs/2403.18136",
    "authors": [
      "Jane Downer",
      "Ren Wang",
      "Binghui Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.18142",
    "title": "HERTA: A High-Efficiency and Rigorous Training Algorithm for Unfolded  Graph Neural Networks",
    "abstract": "As a variant of Graph Neural Networks (GNNs), Unfolded GNNs offer enhanced interpretability and flexibility over traditional designs. Nevertheless, they still suffer from scalability challenges when it comes to the training cost. Although many methods have been proposed to address the scalability issues, they mostly focus on per-iteration efficiency, without worst-case convergence guarantees. Moreover, those methods typically add components to or modify the original model, thus possibly breaking the interpretability of Unfolded GNNs. In this paper, we propose HERTA: a High-Efficiency and Rigorous Training Algorithm for Unfolded GNNs that accelerates the whole training process, achieving a nearly-linear time worst-case training guarantee. Crucially, HERTA converges to the optimum of the original model, thus preserving the interpretability of Unfolded GNNs. Additionally, as a byproduct of HERTA, we propose a new spectral sparsification method applicable to normalized and regularized graph Laplacians that ensures tighter bounds for our algorithm than existing spectral sparsifiers do. Experiments on real-world datasets verify the superiority of HERTA as well as its adaptability to various loss functions and optimizers. ",
    "url": "https://arxiv.org/abs/2403.18142",
    "authors": [
      "Yongyi Yang",
      "Jiaming Yang",
      "Wei Hu",
      "Micha\u0142 Derezi\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18149",
    "title": "Code Generation for Conic Model-Predictive Control on Microcontrollers  with TinyMPC",
    "abstract": "Conic constraints appear in many important control applications like legged locomotion, robotic manipulation, and autonomous rocket landing. However, current solvers for conic optimization problems have relatively heavy computational demands in terms of both floating-point operations and memory footprint, making them impractical for use on small embedded devices. We extend TinyMPC, an open-source, high-speed solver targeting low-power embedded control applications, to handle second-order cone constraints. We also present code-generation software to enable deployment of TinyMPC on a variety of microcontrollers. We benchmark our generated code against state-of-the-art embedded QP and SOCP solvers, demonstrating a two-order-of-magnitude speed increase over ECOS while consuming less memory. Finally, we demonstrate TinyMPC's efficacy on the Crazyflie, a lightweight, resource-constrained quadrotor with fast dynamics. TinyMPC and its code-generation tools are publicly available at https://tinympc.org. ",
    "url": "https://arxiv.org/abs/2403.18149",
    "authors": [
      "Sam Schoedel",
      "Khai Nguyen",
      "Elakhya Nedumaran",
      "Brian Plancher",
      "Zachary Manchester"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2403.18158",
    "title": "The Effects of Short Video-Sharing Services on Video Copy Detection",
    "abstract": "The short video-sharing services that allow users to post 10-30 second videos (e.g., YouTube Shorts and TikTok) have attracted a lot of attention in recent years. However, conventional video copy detection (VCD) methods mainly focus on general video-sharing services (e.g., YouTube and Bilibili), and the effects of short video-sharing services on video copy detection are still unclear. Considering that illegally copied videos in short video-sharing services have service-distinctive characteristics, especially in those time lengths, the pros and cons of VCD in those services are required to be analyzed. In this paper, we examine the effects of short video-sharing services on VCD by constructing a dataset that has short video-sharing service characteristics. Our novel dataset is automatically constructed from the publicly available dataset to have reference videos and fixed short-time-length query videos, and such automation procedures assure the reproducibility and data privacy preservation of this paper. From the experimental results focusing on segment-level and video-level situations, we can see that three effects: \"Segment-level VCD in short video-sharing services is more difficult than those in general video-sharing services\", \"Video-level VCD in short video-sharing services is easier than those in general video-sharing services\", \"The video alignment component mainly suppress the detection performance in short video-sharing services\". ",
    "url": "https://arxiv.org/abs/2403.18158",
    "authors": [
      "Rintaro Yanagi",
      "Yamato Okamoto",
      "Shuhei Yokoo",
      "Shin'ichi Satoh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18162",
    "title": "Optimizing Cyber Response Time on Temporal Active Directory Networks  Using Decoys",
    "abstract": "Microsoft Active Directory (AD) is the default security management system for Window domain network. We study the problem of placing decoys in AD network to detect potential attacks. We model the problem as a Stackelberg game between an attacker and a defender on AD attack graphs where the defender employs a set of decoys to detect the attacker on their way to Domain Admin (DA). Contrary to previous works, we consider time-varying (temporal) attack graphs. We proposed a novel metric called response time, to measure the effectiveness of our decoy placement in temporal attack graphs. Response time is defined as the duration from the moment attackers trigger the first decoy to when they compromise the DA. Our goal is to maximize the defender's response time to the worst-case attack paths. We establish the NP-hard nature of the defender's optimization problem, leading us to develop Evolutionary Diversity Optimization (EDO) algorithms. EDO algorithms identify diverse sets of high-quality solutions for the optimization problem. Despite the polynomial nature of the fitness function, it proves experimentally slow for larger graphs. To enhance scalability, we proposed an algorithm that exploits the static nature of AD infrastructure in the temporal setting. Then, we introduce tailored repair operations, ensuring the convergence to better results while maintaining scalability for larger graphs. ",
    "url": "https://arxiv.org/abs/2403.18162",
    "authors": [
      "Huy Q. Ngo",
      "Mingyu Guo",
      "Hung Nguyen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2403.18163",
    "title": "A Study of Three Influencer Archetypes for the Control of Opinion Spread  in Time-Varying Social Networks",
    "abstract": "In this work we consider the impact of information spread in time-varying social networks, where agents request to follow other agents with aligned opinions while dropping ties to neighbors whose posts are too dissimilar to their own views. Opinion control and rhetorical influence has a very long history, employing various methods including education, persuasion, propaganda, marketing, and manipulation through mis-, dis-, and mal-information. The automation of opinion controllers, however, has only recently become easily deployable at a wide scale, with the advent of large language models (LLMs) and generative AI that can translate the quantified commands from opinion controllers into actual content with the appropriate nuance. Automated agents in social networks can be deployed for various purposes, such as breaking up echo chambers, bridging valuable new connections between agents, or shaping the opinions of a target population -- and all of these raise important ethical concerns that deserve serious attention and thoughtful discussion and debate. This paper attempts to contribute to this discussion by considering three archetypal influencing styles observed by human drivers in these settings, comparing and contrasting the impact of these different control methods on the opinions of agents in the network. We will demonstrate the efficacy of current generative AI for generating nuanced content consistent with the command signal from automatic opinion controllers like these, and we will report on frameworks for approaching the relevant ethical considerations. ",
    "url": "https://arxiv.org/abs/2403.18163",
    "authors": [
      "Michael DeBuse",
      "Sean Warnick"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2403.18172",
    "title": "Vision-Based Force Estimation for Minimally Invasive Telesurgery Through  Contact Detection and Local Stiffness Models",
    "abstract": "In minimally invasive telesurgery, obtaining accurate force information is difficult due to the complexities of in-vivo end effector force sensing. This constrains development and implementation of haptic feedback and force-based automated performance metrics, respectively. Vision-based force sensing approaches using deep learning are a promising alternative to intrinsic end effector force sensing. However, they have limited ability to generalize to novel scenarios, and require learning on high-quality force sensor training data that can be difficult to obtain. To address these challenges, this paper presents a novel vision-based contact-conditional approach for force estimation in telesurgical environments. Our method leverages supervised learning with human labels and end effector position data to train deep neural networks. Predictions from these trained models are optionally combined with robot joint torque information to estimate forces indirectly from visual data. We benchmark our method against ground truth force sensor data and demonstrate generality by fine-tuning to novel surgical scenarios in a data-efficient manner. Our methods demonstrated greater than 90% accuracy on contact detection and less than 10% force prediction error. These results suggest potential usefulness of contact-conditional force estimation for sensory substitution haptic feedback and tissue handling skill evaluation in clinical settings. ",
    "url": "https://arxiv.org/abs/2403.18172",
    "authors": [
      "Shuyuan Yang",
      "My H. Le",
      "Kyle R. Golobish",
      "Juan C. Beaver",
      "Zonghe Chua"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.18178",
    "title": "Online Embedding Multi-Scale CLIP Features into 3D Maps",
    "abstract": "This study introduces a novel approach to online embedding of multi-scale CLIP (Contrastive Language-Image Pre-Training) features into 3D maps. By harnessing CLIP, this methodology surpasses the constraints of conventional vocabulary-limited methods and enables the incorporation of semantic information into the resultant maps. While recent approaches have explored the embedding of multi-modal features in maps, they often impose significant computational costs, lacking practicality for exploring unfamiliar environments in real time. Our approach tackles these challenges by efficiently computing and embedding multi-scale CLIP features, thereby facilitating the exploration of unfamiliar environments through real-time map generation. Moreover, the embedding CLIP features into the resultant maps makes offline retrieval via linguistic queries feasible. In essence, our approach simultaneously achieves real-time object search and mapping of unfamiliar environments. Additionally, we propose a zero-shot object-goal navigation system based on our mapping approach, and we validate its efficacy through object-goal navigation, offline object retrieval, and multi-object-goal navigation in both simulated environments and real robot experiments. The findings demonstrate that our method not only exhibits swifter performance than state-of-the-art mapping methods but also surpasses them in terms of the success rate of object-goal navigation tasks. ",
    "url": "https://arxiv.org/abs/2403.18178",
    "authors": [
      "Shun Taguchi",
      "Hideki Deguchi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18183",
    "title": "Can AI Models Appreciate Document Aesthetics? An Exploration of  Legibility and Layout Quality in Relation to Prediction Confidence",
    "abstract": "A well-designed document communicates not only through its words but also through its visual eloquence. Authors utilize aesthetic elements such as colors, fonts, graphics, and layouts to shape the perception of information. Thoughtful document design, informed by psychological insights, enhances both the visual appeal and the comprehension of the content. While state-of-the-art document AI models demonstrate the benefits of incorporating layout and image data, it remains unclear whether the nuances of document aesthetics are effectively captured. To bridge the gap between human cognition and AI interpretation of aesthetic elements, we formulated hypotheses concerning AI behavior in document understanding tasks, specifically anchored in document design principles. With a focus on legibility and layout quality, we tested four aspects of aesthetic effects: noise, font-size contrast, alignment, and complexity, on model confidence using correlational analysis. The results and observations highlight the value of model analysis rooted in document design theories. Our work serves as a trailhead for further studies and we advocate for continued research in this topic to deepen our understanding of how AI interprets document aesthetics. ",
    "url": "https://arxiv.org/abs/2403.18183",
    "authors": [
      "Hsiu-Wei Yang",
      "Abhinav Agrawal",
      "Pavlos Fragkogiannis",
      "Shubham Nitin Mulay"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2403.18191",
    "title": "The process of polarisation as a loss of dimensionality: measuring  changes in polarisation using Singular Value Decomposition of network graphs",
    "abstract": "The increasing polarisation in our societies is a major international concern. Current approaches to defining and detecting polarisation largely rely on finding evidence of bimodality in social networks or voter opinion surveys. It is difficult to detect temporal trends in polarisation, as the results usually fall into a binary of polarised or non-polarised, which cannot robustly show that subsequent increases in bimodality are statistically significant. Our work is aligned with Baldassari and Gelman's theory that polarisation should be defined as increasing correlation between positions in the ideological field. We also draw from post-structuralist work which argues that polarisation is the process of both the ideological and material layers of society being segregated into two poles, as in cases of apartheid. Thus, in order to measure the polarisation in a society, it would be beneficial to be able to assess social networks directly. In this paper we use Random Dot Product Graphs to embed social networks in metric spaces. In the case of a social network, the embedded dimensionality corresponds to the number of reasons any two people may form a social connection. A decrease in the optimal dimensionality for the embedding of the network graph, as measured using truncated Singular Value Decomposition of the graph adjacency matrix, indicates increasing polarisation in the network. We apply this method to two different Twitter networks based on discussions of climate change, and show that our methods agree with other researchers' detection of polarisation in this space. We also use networks generated by stochastic block models to explore how an increase of the isolation between distinct communities in a network, or the increase in the predominance of one community over the other, are identifiable as polarisation processes. ",
    "url": "https://arxiv.org/abs/2403.18191",
    "authors": [
      "Sage Anastasi",
      "Giulio Dalla Riva"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2403.18193",
    "title": "Middle Fusion and Multi-Stage, Multi-Form Prompts for Robust RGB-T  Tracking",
    "abstract": "RGB-T tracking, a vital downstream task of object tracking, has made remarkable progress in recent years. Yet, it remains hindered by two major challenges: 1) the trade-off between performance and efficiency; 2) the scarcity of training data. To address the latter challenge, some recent methods employ prompts to fine-tune pre-trained RGB tracking models and leverage upstream knowledge in a parameter-efficient manner. However, these methods inadequately explore modality-independent patterns and disregard the dynamic reliability of different modalities in open scenarios. We propose M3PT, a novel RGB-T prompt tracking method that leverages middle fusion and multi-modal and multi-stage visual prompts to overcome these challenges. We pioneer the use of the middle fusion framework for RGB-T tracking, which achieves a balance between performance and efficiency. Furthermore, we incorporate the pre-trained RGB tracking model into the framework and utilize multiple flexible prompt strategies to adapt the pre-trained model to the comprehensive exploration of uni-modal patterns and the improved modeling of fusion-modal features, harnessing the potential of prompt learning in RGB-T tracking. Our method outperforms the state-of-the-art methods on four challenging benchmarks, while attaining 46.1 fps inference speed. ",
    "url": "https://arxiv.org/abs/2403.18193",
    "authors": [
      "Qiming Wang",
      "Yongqiang Bai",
      "Hongxing Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18195",
    "title": "SCANet: Correcting LEGO Assembly Errors with Self-Correct Assembly  Network",
    "abstract": "Autonomous assembly in robotics and 3D vision presents significant challenges, particularly in ensuring assembly correctness. Presently, predominant methods such as MEPNet focus on assembling components based on manually provided images. However, these approaches often fall short in achieving satisfactory results for tasks requiring long-term planning. Concurrently, we observe that integrating a self-correction module can partially alleviate such issues. Motivated by this concern, we introduce the single-step assembly error correction task, which involves identifying and rectifying misassembled components. To support research in this area, we present the LEGO Error Correction Assembly Dataset (LEGO-ECA), comprising manual images for assembly steps and instances of assembly failures. Additionally, we propose the Self-Correct Assembly Network (SCANet), a novel method to address this task. SCANet treats assembled components as queries, determining their correctness in manual images and providing corrections when necessary. Finally, we utilize SCANet to correct the assembly results of MEPNet. Experimental results demonstrate that SCANet can identify and correct MEPNet's misassembled results, significantly improving the correctness of assembly. Our code and dataset are available at https://github.com/Yaser-wyx/SCANet. ",
    "url": "https://arxiv.org/abs/2403.18195",
    "authors": [
      "Yuxuan Wan",
      "Kaichen Zhou",
      "jinhong Chen",
      "Hao Dong"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.18196",
    "title": "Looking Beyond What You See: An Empirical Analysis on Subgroup  Intersectional Fairness for Multi-label Chest X-ray Classification Using  Social Determinants of Racial Health Inequities",
    "abstract": "There has been significant progress in implementing deep learning models in disease diagnosis using chest X- rays. Despite these advancements, inherent biases in these models can lead to disparities in prediction accuracy across protected groups. In this study, we propose a framework to achieve accurate diagnostic outcomes and ensure fairness across intersectional groups in high-dimensional chest X- ray multi-label classification. Transcending traditional protected attributes, we consider complex interactions within social determinants, enabling a more granular benchmark and evaluation of fairness. We present a simple and robust method that involves retraining the last classification layer of pre-trained models using a balanced dataset across groups. Additionally, we account for fairness constraints and integrate class-balanced fine-tuning for multi-label settings. The evaluation of our method on the MIMIC-CXR dataset demonstrates that our framework achieves an optimal tradeoff between accuracy and fairness compared to baseline methods. ",
    "url": "https://arxiv.org/abs/2403.18196",
    "authors": [
      "Dana Moukheiber",
      "Saurabh Mahindre",
      "Lama Moukheiber",
      "Mira Moukheiber",
      "Mingchen Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2403.18201",
    "title": "Few-shot Online Anomaly Detection and Segmentation",
    "abstract": "Detecting anomaly patterns from images is a crucial artificial intelligence technique in industrial applications. Recent research in this domain has emphasized the necessity of a large volume of training data, overlooking the practical scenario where, post-deployment of the model, unlabeled data containing both normal and abnormal samples can be utilized to enhance the model's performance. Consequently, this paper focuses on addressing the challenging yet practical few-shot online anomaly detection and segmentation (FOADS) task. Under the FOADS framework, models are trained on a few-shot normal dataset, followed by inspection and improvement of their capabilities by leveraging unlabeled streaming data containing both normal and abnormal samples simultaneously. To tackle this issue, we propose modeling the feature distribution of normal images using a Neural Gas network, which offers the flexibility to adapt the topology structure to identify outliers in the data flow. In order to achieve improved performance with limited training samples, we employ multi-scale feature embedding extracted from a CNN pre-trained on ImageNet to obtain a robust representation. Furthermore, we introduce an algorithm that can incrementally update parameters without the need to store previous samples. Comprehensive experimental results demonstrate that our method can achieve substantial performance under the FOADS setting, while ensuring that the time complexity remains within an acceptable range on MVTec AD and BTAD datasets. ",
    "url": "https://arxiv.org/abs/2403.18201",
    "authors": [
      "Shenxing Wei",
      "Xing Wei",
      "Zhiheng Ma",
      "Songlin Dong",
      "Shaochen Zhang",
      "Yihong Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18202",
    "title": "TGMM: Combining Parse Tree with GPU for Scalable Multilingual and  Multi-Granularity Code Clone Detection",
    "abstract": "The rapid evolution of programming languages and software systems has necessitated the implementation of multilingual and scalable clone detection tools. However, it is difficult to achieve the above requirements at the same time. Most existing tools only focus on one challenge. In this work, we propose TGMM, a tree and GPU-based tool for multilingual and multi-granularity code clone detection. By generating parse trees based on user-provided grammar files, TGMM can extract code blocks at a specified granularity and detect Type-3 clones efficiently. In order to show the performance of TGMM, we compare it with seven state-of-the-art tools in terms of recall, precision, and execution time. TGMM ranks first in execution time and precision, while its recall is comparable to the others. Moreover, we analyzed the language extensibility of TGMM across 30 mainstream programming languages. Out of these, a total of 25 languages were supported, while the remaining five currently lack the necessary grammar files. Finally, we analyzed the clone characteristics of nine popular languages at five common granularities, hoping to inspire future researchers. The source code of TGMM is available at: https://github.com/TGMM24/TGMM.git. ",
    "url": "https://arxiv.org/abs/2403.18202",
    "authors": [
      "Yuhang Ye",
      "Yuekun Wang",
      "Yinxing Xue",
      "Yueming Wu",
      "Yang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2403.18205",
    "title": "Exploring the Privacy Protection Capabilities of Chinese Large Language  Models",
    "abstract": "Large language models (LLMs), renowned for their impressive capabilities in various tasks, have significantly advanced artificial intelligence. Yet, these advancements have raised growing concerns about privacy and security implications. To address these issues and explain the risks inherent in these models, we have devised a three-tiered progressive framework tailored for evaluating privacy in language systems. This framework consists of progressively complex and in-depth privacy test tasks at each tier. Our primary objective is to comprehensively evaluate the sensitivity of large language models to private information, examining how effectively they discern, manage, and safeguard sensitive data in diverse scenarios. This systematic evaluation helps us understand the degree to which these models comply with privacy protection guidelines and the effectiveness of their inherent safeguards against privacy breaches. Our observations indicate that existing Chinese large language models universally show privacy protection shortcomings. It seems that at the moment this widespread issue is unavoidable and may pose corresponding privacy risks in applications based on these models. ",
    "url": "https://arxiv.org/abs/2403.18205",
    "authors": [
      "Yuqi Yang",
      "Xiaowen Huang",
      "Jitao Sang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.18207",
    "title": "Road Obstacle Detection based on Unknown Objectness Scores",
    "abstract": "The detection of unknown traffic obstacles is vital to ensure safe autonomous driving. The standard object-detection methods cannot identify unknown objects that are not included under predefined categories. This is because object-detection methods are trained to assign a background label to pixels corresponding to the presence of unknown objects. To address this problem, the pixel-wise anomaly-detection approach has attracted increased research attention. Anomaly-detection techniques, such as uncertainty estimation and perceptual difference from reconstructed images, make it possible to identify pixels of unknown objects as out-of-distribution (OoD) samples. However, when applied to images with many unknowns and complex components, such as driving scenes, these methods often exhibit unstable performance. The purpose of this study is to achieve stable performance for detecting unknown objects by incorporating the object-detection fashions into the pixel-wise anomaly detection methods. To achieve this goal, we adopt a semantic-segmentation network with a sigmoid head that simultaneously provides pixel-wise anomaly scores and objectness scores. Our experimental results show that the objectness scores play an important role in improving the detection performance. Based on these results, we propose a novel anomaly score by integrating these two scores, which we term as unknown objectness score. Quantitative evaluations show that the proposed method outperforms state-of-the-art methods when applied to the publicly available datasets. ",
    "url": "https://arxiv.org/abs/2403.18207",
    "authors": [
      "Chihiro Noguchi",
      "Toshiaki Ohgushi",
      "Masao Yamanaka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.18208",
    "title": "An Evolutionary Network Architecture Search Framework with Adaptive  Multimodal Fusion for Hand Gesture Recognition",
    "abstract": "Hand gesture recognition (HGR) based on multimodal data has attracted considerable attention owing to its great potential in applications. Various manually designed multimodal deep networks have performed well in multimodal HGR (MHGR), but most of existing algorithms require a lot of expert experience and time-consuming manual trials. To address these issues, we propose an evolutionary network architecture search framework with the adaptive multimodel fusion (AMF-ENAS). Specifically, we design an encoding space that simultaneously considers fusion positions and ratios of the multimodal data, allowing for the automatic construction of multimodal networks with different architectures through decoding. Additionally, we consider three input streams corresponding to intra-modal surface electromyography (sEMG), intra-modal accelerometer (ACC), and inter-modal sEMG-ACC. To automatically adapt to various datasets, the ENAS framework is designed to automatically search a MHGR network with appropriate fusion positions and ratios. To the best of our knowledge, this is the first time that ENAS has been utilized in MHGR to tackle issues related to the fusion position and ratio of multimodal data. Experimental results demonstrate that AMF-ENAS achieves state-of-the-art performance on the Ninapro DB2, DB3, and DB7 datasets. ",
    "url": "https://arxiv.org/abs/2403.18208",
    "authors": [
      "Yizhang Xia",
      "Shihao Song",
      "Zhanglu Hou",
      "Junwen Xu",
      "Juan Zou",
      "Yuan Liu",
      "Shengxiang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2403.18223",
    "title": "A Transformer-Based Framework for Payload Malware Detection and  Classification",
    "abstract": "As malicious cyber threats become more sophisticated in breaching computer networks, the need for effective intrusion detection systems (IDSs) becomes crucial. Techniques such as Deep Packet Inspection (DPI) have been introduced to allow IDSs analyze the content of network packets, providing more context for identifying potential threats. IDSs traditionally rely on using anomaly-based and signature-based detection techniques to detect unrecognized and suspicious activity. Deep learning techniques have shown great potential in DPI for IDSs due to their efficiency in learning intricate patterns from the packet content being transmitted through the network. In this paper, we propose a revolutionary DPI algorithm based on transformers adapted for the purpose of detecting malicious traffic with a classifier head. Transformers learn the complex content of sequence data and generalize them well to similar scenarios thanks to their self-attention mechanism. Our proposed method uses the raw payload bytes that represent the packet contents and is deployed as man-in-the-middle. The payload bytes are used to detect malicious packets and classify their types. Experimental results on the UNSW-NB15 and CIC-IOT23 datasets demonstrate that our transformer-based model is effective in distinguishing malicious from benign traffic in the test dataset, attaining an average accuracy of 79\\% using binary classification and 72\\% on the multi-classification experiment, both using solely payload bytes. ",
    "url": "https://arxiv.org/abs/2403.18223",
    "authors": [
      "Kyle Stein",
      "Arash Mahyari",
      "Guillermo Francia III",
      "Eman El-Sheikh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18230",
    "title": "Large Language Models Need Consultants for Reasoning: Becoming an Expert  in a Complex Human System Through Behavior Simulation",
    "abstract": "Large language models (LLMs), in conjunction with various reasoning reinforcement methodologies, have demonstrated remarkable capabilities comparable to humans in fields such as mathematics, law, coding, common sense, and world knowledge. In this paper, we delve into the reasoning abilities of LLMs within complex human systems. We propose a novel reasoning framework, termed ``Mosaic Expert Observation Wall'' (MEOW) exploiting generative-agents-based simulation technique. In the MEOW framework, simulated data are utilized to train an expert model concentrating ``experience'' about a specific task in each independent time of simulation. It is the accumulated ``experience'' through the simulation that makes for an expert on a task in a complex human system. We conduct the experiments within a communication game that mirrors real-world security scenarios. The results indicate that our proposed methodology can cooperate with existing methodologies to enhance the reasoning abilities of LLMs in complex human systems. ",
    "url": "https://arxiv.org/abs/2403.18230",
    "authors": [
      "Chuwen Wang",
      "Shirong Zeng",
      "Cheng Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.18238",
    "title": "TAFormer: A Unified Target-Aware Transformer for Video and Motion Joint  Prediction in Aerial Scenes",
    "abstract": "As drone technology advances, using unmanned aerial vehicles for aerial surveys has become the dominant trend in modern low-altitude remote sensing. The surge in aerial video data necessitates accurate prediction for future scenarios and motion states of the interested target, particularly in applications like traffic management and disaster response. Existing video prediction methods focus solely on predicting future scenes (video frames), suffering from the neglect of explicitly modeling target's motion states, which is crucial for aerial video interpretation. To address this issue, we introduce a novel task called Target-Aware Aerial Video Prediction, aiming to simultaneously predict future scenes and motion states of the target. Further, we design a model specifically for this task, named TAFormer, which provides a unified modeling approach for both video and target motion states. Specifically, we introduce Spatiotemporal Attention (STA), which decouples the learning of video dynamics into spatial static attention and temporal dynamic attention, effectively modeling the scene appearance and motion. Additionally, we design an Information Sharing Mechanism (ISM), which elegantly unifies the modeling of video and target motion by facilitating information interaction through two sets of messenger tokens. Moreover, to alleviate the difficulty of distinguishing targets in blurry predictions, we introduce Target-Sensitive Gaussian Loss (TSGL), enhancing the model's sensitivity to both target's position and content. Extensive experiments on UAV123VP and VisDroneVP (derived from single-object tracking datasets) demonstrate the exceptional performance of TAFormer in target-aware video prediction, showcasing its adaptability to the additional requirements of aerial video interpretation for target awareness. ",
    "url": "https://arxiv.org/abs/2403.18238",
    "authors": [
      "Liangyu Xu",
      "Wanxuan Lu",
      "Hongfeng Yu",
      "Yongqiang Mao",
      "Hanbo Bi",
      "Chenglong Liu",
      "Xian Sun",
      "Kun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18249",
    "title": "Exploring the Deceptive Power of LLM-Generated Fake News: A Study of  Real-World Detection Challenges",
    "abstract": "Recent advancements in Large Language Models (LLMs) have enabled the creation of fake news, particularly in complex fields like healthcare. Studies highlight the gap in the deceptive power of LLM-generated fake news with and without human assistance, yet the potential of prompting techniques has not been fully explored. Thus, this work aims to determine whether prompting strategies can effectively narrow this gap. Current LLM-based fake news attacks require human intervention for information gathering and often miss details and fail to maintain context consistency. Therefore, to better understand threat tactics, we propose a strong fake news attack method called conditional Variational-autoencoder-Like Prompt (VLPrompt). Unlike current methods, VLPrompt eliminates the need for additional data collection while maintaining contextual coherence and preserving the intricacies of the original text. To propel future research on detecting VLPrompt attacks, we created a new dataset named VLPrompt fake news (VLPFN) containing real and fake texts. Our experiments, including various detection methods and novel human study metrics, were conducted to assess their performance on our dataset, yielding numerous findings. ",
    "url": "https://arxiv.org/abs/2403.18249",
    "authors": [
      "Yanshen Sun",
      "Jianfeng He",
      "Limeng Cui",
      "Shuo Lei",
      "Chang-Tien Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.18253",
    "title": "MD-PK: Metaphor Detection via Prompt Learning and Knowledge Distillation",
    "abstract": "Metaphors are ubiquitous in daily life, yet detecting them poses a significant challenge. Previous approaches often struggled with improper application of language rules and overlooked the issue of data sparsity. To address these challenges, we introduce knowledge distillation and prompt learning into metaphor detection. Specifically, we devise a prompt learning template tailored for the metaphor detection task. By masking target words and providing relevant prompt information, we guide the model to accurately infer the contextual meaning of these words. This approach not only mitigates the interference from the literal meaning of target words but also ensures the proper utilization of MIP language rules for metaphor detection. Moreover, we employ a teacher model equipped with prior knowledge to generate meaningful soft labels, guiding the optimization process of the student model. The inclusion of soft labels, akin to label smoothing, helps alleviate the model's tendency towards over-confidence and effectively addresses the challenge of data sparsity. Experimental results demonstrate that our proposed model achieves state-of-the-art performance across multiple datasets. ",
    "url": "https://arxiv.org/abs/2403.18253",
    "authors": [
      "Kaidi Jia",
      "Rongsheng Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.18256",
    "title": "Manipulating Neural Path Planners via Slight Perturbations",
    "abstract": "Data-driven neural path planners are attracting increasing interest in the robotics community. However, their neural network components typically come as black boxes, obscuring their underlying decision-making processes. Their black-box nature exposes them to the risk of being compromised via the insertion of hidden malicious behaviors. For example, an attacker may hide behaviors that, when triggered, hijack a delivery robot by guiding it to a specific (albeit wrong) destination, trapping it in a predefined region, or inducing unnecessary energy expenditure by causing the robot to repeatedly circle a region. In this paper, we propose a novel approach to specify and inject a range of hidden malicious behaviors, known as backdoors, into neural path planners. Our approach provides a concise but flexible way to define these behaviors, and we show that hidden behaviors can be triggered by slight perturbations (e.g., inserting a tiny unnoticeable object), that can nonetheless significantly compromise their integrity. We also discuss potential techniques to identify these backdoors aimed at alleviating such risks. We demonstrate our approach on both sampling-based and search-based neural path planners. ",
    "url": "https://arxiv.org/abs/2403.18256",
    "authors": [
      "Zikang Xiong",
      "Suresh Jagannathan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.18266",
    "title": "Branch-Tuning: Balancing Stability and Plasticity for Continual  Self-Supervised Learning",
    "abstract": "Self-supervised learning (SSL) has emerged as an effective paradigm for deriving general representations from vast amounts of unlabeled data. However, as real-world applications continually integrate new content, the high computational and resource demands of SSL necessitate continual learning rather than complete retraining. This poses a challenge in striking a balance between stability and plasticity when adapting to new information. In this paper, we employ Centered Kernel Alignment for quantitatively analyzing model stability and plasticity, revealing the critical roles of batch normalization layers for stability and convolutional layers for plasticity. Motivated by this, we propose Branch-tuning, an efficient and straightforward method that achieves a balance between stability and plasticity in continual SSL. Branch-tuning consists of branch expansion and compression, and can be easily applied to various SSL methods without the need of modifying the original methods, retaining old data or models. We validate our method through incremental experiments on various benchmark datasets, demonstrating its effectiveness and practical value in real-world scenarios. We hope our work offers new insights for future continual self-supervised learning research. The code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2403.18266",
    "authors": [
      "Wenzhuo Liu",
      "Fei Zhu",
      "Cheng-Lin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18267",
    "title": "DSF-GAN: DownStream Feedback Generative Adversarial Network",
    "abstract": "Utility and privacy are two crucial measurements of the quality of synthetic tabular data. While significant advancements have been made in privacy measures, generating synthetic samples with high utility remains challenging. To enhance the utility of synthetic samples, we propose a novel architecture called the DownStream Feedback Generative Adversarial Network (DSF-GAN). This approach incorporates feedback from a downstream prediction model during training to augment the generator's loss function with valuable information. Thus, DSF-GAN utilizes a downstream prediction task to enhance the utility of synthetic samples. To evaluate our method, we tested it using two popular datasets. Our experiments demonstrate improved model performance when training on synthetic samples generated by DSF-GAN, compared to those generated by the same GAN architecture without feedback. The evaluation was conducted on the same validation set comprising real samples. All code and datasets used in this research will be made openly available for ease of reproduction. ",
    "url": "https://arxiv.org/abs/2403.18267",
    "authors": [
      "Oriel Perets",
      "Nadav Rappoport"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.18270",
    "title": "Image Deraining via Self-supervised Reinforcement Learning",
    "abstract": "The quality of images captured outdoors is often affected by the weather. One factor that interferes with sight is rain, which can obstruct the view of observers and computer vision applications that rely on those images. The work aims to recover rain images by removing rain streaks via Self-supervised Reinforcement Learning (RL) for image deraining (SRL-Derain). We locate rain streak pixels from the input rain image via dictionary learning and use pixel-wise RL agents to take multiple inpainting actions to remove rain progressively. To our knowledge, this work is the first attempt where self-supervised RL is applied to image deraining. Experimental results on several benchmark image-deraining datasets show that the proposed SRL-Derain performs favorably against state-of-the-art few-shot and self-supervised deraining and denoising methods. ",
    "url": "https://arxiv.org/abs/2403.18270",
    "authors": [
      "He-Hao Liao",
      "Yan-Tsung Peng",
      "Wen-Tao Chu",
      "Ping-Chun Hsieh",
      "Chung-Chi Tsai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2403.18277",
    "title": "BlendX: Complex Multi-Intent Detection with Blended Patterns",
    "abstract": "Task-oriented dialogue (TOD) systems are commonly designed with the presumption that each utterance represents a single intent. However, this assumption may not accurately reflect real-world situations, where users frequently express multiple intents within a single utterance. While there is an emerging interest in multi-intent detection (MID), existing in-domain datasets such as MixATIS and MixSNIPS have limitations in their formulation. To address these issues, we present BlendX, a suite of refined datasets featuring more diverse patterns than their predecessors, elevating both its complexity and diversity. For dataset construction, we utilize both rule-based heuristics as well as a generative tool -- OpenAI's ChatGPT -- which is augmented with a similarity-driven strategy for utterance selection. To ensure the quality of the proposed datasets, we also introduce three novel metrics that assess the statistical properties of an utterance related to word count, conjunction use, and pronoun usage. Extensive experiments on BlendX reveal that state-of-the-art MID models struggle with the challenges posed by the new datasets, highlighting the need to reexamine the current state of the MID field. The dataset is available at https://github.com/HYU-NLP/BlendX. ",
    "url": "https://arxiv.org/abs/2403.18277",
    "authors": [
      "Yejin Yoon",
      "Jungyeon Lee",
      "Kangsan Kim",
      "Chanhee Park",
      "Taeuk Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.18278",
    "title": "Identification and Uses of Deep Learning Backbones via Pattern Mining",
    "abstract": "Deep learning is extensively used in many areas of data mining as a black-box method with impressive results. However, understanding the core mechanism of how deep learning makes predictions is a relatively understudied problem. Here we explore the notion of identifying a backbone of deep learning for a given group of instances. A group here can be instances of the same class or even misclassified instances of the same class. We view each instance for a given group as activating a subset of neurons and attempt to find a subgraph of neurons associated with a given concept/group. We formulate this problem as a set cover style problem and show it is intractable and presents a highly constrained integer linear programming (ILP) formulation. As an alternative, we explore a coverage-based heuristic approach related to pattern mining, and show it converges to a Pareto equilibrium point of the ILP formulation. Experimentally we explore these backbones to identify mistakes and improve performance, explanation, and visualization. We demonstrate application-based results using several challenging data sets, including Bird Audio Detection (BAD) Challenge and Labeled Faces in the Wild (LFW), as well as the classic MNIST data. ",
    "url": "https://arxiv.org/abs/2403.18278",
    "authors": [
      "Michael Livanos",
      "Ian Davidson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.18294",
    "title": "Multi-scale Unified Network for Image Classification",
    "abstract": "Convolutional Neural Networks (CNNs) have advanced significantly in visual representation learning and recognition. However, they face notable challenges in performance and computational efficiency when dealing with real-world, multi-scale image inputs. Conventional methods rescale all input images into a fixed size, wherein a larger fixed size favors performance but rescaling small size images to a larger size incurs digitization noise and increased computation cost. In this work, we carry out a comprehensive, layer-wise investigation of CNN models in response to scale variation, based on Centered Kernel Alignment (CKA) analysis. The observations reveal lower layers are more sensitive to input image scale variations than high-level layers. Inspired by this insight, we propose Multi-scale Unified Network (MUSN) consisting of multi-scale subnets, a unified network, and scale-invariant constraint. Our method divides the shallow layers into multi-scale subnets to enable feature extraction from multi-scale inputs, and the low-level features are unified in deep layers for extracting high-level semantic features. A scale-invariant constraint is posed to maintain feature consistency across different scales. Extensive experiments on ImageNet and other scale-diverse datasets, demonstrate that MSUN achieves significant improvements in both model performance and computational efficiency. Particularly, MSUN yields an accuracy increase up to 44.53% and diminishes FLOPs by 7.01-16.13% in multi-scale scenarios. ",
    "url": "https://arxiv.org/abs/2403.18294",
    "authors": [
      "Wenzhuo Liu",
      "Fei Zhu",
      "Cheng-Lin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18296",
    "title": "GeNet: A Graph Neural Network-based Anti-noise Task-Oriented Semantic  Communication Paradigm",
    "abstract": "Traditional approaches to semantic communication tasks rely on the knowledge of the signal-to-noise ratio (SNR) to mitigate channel noise. However, these methods necessitate training under specific SNR conditions, entailing considerable time and computational resources. In this paper, we propose GeNet, a Graph Neural Network (GNN)-based paradigm for semantic communication aimed at combating noise, thereby facilitating Task-Oriented Communication (TOC). We propose a novel approach where we first transform the input data image into graph structures. Then we leverage a GNN-based encoder to extract semantic information from the source data. This extracted semantic information is then transmitted through the channel. At the receiver's end, a GNN-based decoder is utilized to reconstruct the relevant semantic information from the source data for TOC. Through experimental evaluation, we show GeNet's effectiveness in anti-noise TOC while decoupling the SNR dependency. We further evaluate GeNet's performance by varying the number of nodes, revealing its versatility as a new paradigm for semantic communication. Additionally, we show GeNet's robustness to geometric transformations by testing it with different rotation angles, without resorting to data augmentation. ",
    "url": "https://arxiv.org/abs/2403.18296",
    "authors": [
      "Chunhang Zheng",
      "Kechao Cai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.18309",
    "title": "Bayesian Learned Models Can Detect Adversarial Malware For Free",
    "abstract": "The vulnerability of machine learning-based malware detectors to adversarial attacks has prompted the need for robust solutions. Adversarial training is an effective method but is computationally expensive to scale up to large datasets and comes at the cost of sacrificing model performance for robustness. We hypothesize that adversarial malware exploits the low-confidence regions of models and can be identified using epistemic uncertainty of ML approaches -- epistemic uncertainty in a machine learning-based malware detector is a result of a lack of similar training samples in regions of the problem space. In particular, a Bayesian formulation can capture the model parameters' distribution and quantify epistemic uncertainty without sacrificing model performance. To verify our hypothesis, we consider Bayesian learning approaches with a mutual information-based formulation to quantify uncertainty and detect adversarial malware in Android, Windows domains and PDF malware. We found, quantifying uncertainty through Bayesian learning methods can defend against adversarial malware. In particular, Bayesian models: (1) are generally capable of identifying adversarial malware in both feature and problem space, (2) can detect concept drift by measuring uncertainty, and (3) with a diversity-promoting approach (or better posterior approximations) lead to parameter instances from the posterior to significantly enhance a detectors' ability. ",
    "url": "https://arxiv.org/abs/2403.18309",
    "authors": [
      "Bao Gia Doan",
      "Dang Quang Nguyen",
      "Paul Montague",
      "Tamas Abraham",
      "Olivier De Vel",
      "Seyit Camtepe",
      "Salil S. Kanhere",
      "Ehsan Abbasnejad",
      "Damith C. Ranasinghe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.18318",
    "title": "Uncertainty-Aware SAR ATR: Defending Against Adversarial Attacks via  Bayesian Neural Networks",
    "abstract": "Adversarial attacks have demonstrated the vulnerability of Machine Learning (ML) image classifiers in Synthetic Aperture Radar (SAR) Automatic Target Recognition (ATR) systems. An adversarial attack can deceive the classifier into making incorrect predictions by perturbing the input SAR images, for example, with a few scatterers attached to the on-ground objects. Therefore, it is critical to develop robust SAR ATR systems that can detect potential adversarial attacks by leveraging the inherent uncertainty in ML classifiers, thereby effectively alerting human decision-makers. In this paper, we propose a novel uncertainty-aware SAR ATR for detecting adversarial attacks. Specifically, we leverage the capability of Bayesian Neural Networks (BNNs) in performing image classification with quantified epistemic uncertainty to measure the confidence for each input SAR image. By evaluating the uncertainty, our method alerts when the input SAR image is likely to be adversarially generated. Simultaneously, we also generate visual explanations that reveal the specific regions in the SAR image where the adversarial scatterers are likely to to be present, thus aiding human decision-making with hints of evidence of adversarial attacks. Experiments on the MSTAR dataset demonstrate that our approach can identify over 80% adversarial SAR images with fewer than 20% false alarms, and our visual explanations can identify up to over 90% of scatterers in an adversarial SAR image. ",
    "url": "https://arxiv.org/abs/2403.18318",
    "authors": [
      "Tian Ye",
      "Rajgopal Kannan",
      "Viktor Prasanna",
      "Carl Busart"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18328",
    "title": "PIPNet3D: Interpretable Detection of Alzheimer in MRI Scans",
    "abstract": "Information from neuroimaging examinations (CT, MRI) is increasingly used to support diagnoses of dementia, e.g., Alzheimer's disease. While current clinical practice is mainly based on visual inspection and feature engineering, Deep Learning approaches can be used to automate the analysis and to discover new image-biomarkers. Part-prototype neural networks (PP-NN) are an alternative to standard blackbox models, and have shown promising results in general computer vision. PP-NN's base their reasoning on prototypical image regions that are learned fully unsupervised, and combined with a simple-to-understand decision layer. We present PIPNet3D, a PP-NN for volumetric images. We apply PIPNet3D to the clinical case study of Alzheimer's Disease diagnosis from structural Magnetic Resonance Imaging (sMRI). We assess the quality of prototypes under a systematic evaluation framework, propose new metrics to evaluate brain prototypes and perform an evaluation with domain experts. Our results show that PIPNet3D is an interpretable, compact model for Alzheimer's diagnosis with its reasoning well aligned to medical domain knowledge. Notably, PIPNet3D achieves the same accuracy as its blackbox counterpart; and removing the remaining clinically irrelevant prototypes from its decision process does not decrease predictive performance. ",
    "url": "https://arxiv.org/abs/2403.18328",
    "authors": [
      "Lisa Anita De Santi",
      "J\u00f6rg Schl\u00f6tterer",
      "Michael Scheschenja",
      "Joel Wessendorf",
      "Meike Nauta",
      "Vincenzo Positano",
      "Christin Seifert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18330",
    "title": "Tracking-Assisted Object Detection with Event Cameras",
    "abstract": "Event-based object detection has recently garnered attention in the computer vision community due to the exceptional properties of event cameras, such as high dynamic range and no motion blur. However, feature asynchronism and sparsity cause invisible objects due to no relative motion to the camera, posing a significant challenge in the task. Prior works have studied various memory mechanisms to preserve as many features as possible at the current time, guided by temporal clues. While these implicit-learned memories retain some short-term information, they still struggle to preserve long-term features effectively. In this paper, we consider those invisible objects as pseudo-occluded objects and aim to reveal their features. Firstly, we introduce visibility attribute of objects and contribute an auto-labeling algorithm to append additional visibility labels on an existing event camera dataset. Secondly, we exploit tracking strategies for pseudo-occluded objects to maintain their permanence and retain their bounding boxes, even when features have not been available for a very long time. These strategies can be treated as an explicit-learned memory guided by the tracking objective to record the displacements of objects across frames. Lastly, we propose a spatio-temporal feature aggregation module to enrich the latent features and a consistency loss to increase the robustness of the overall pipeline. We conduct comprehensive experiments to verify our method's effectiveness where still objects are retained but real occluded objects are discarded. The results demonstrate that (1) the additional visibility labels can assist in supervised training, and (2) our method outperforms state-of-the-art approaches with a significant improvement of 7.9% absolute mAP. ",
    "url": "https://arxiv.org/abs/2403.18330",
    "authors": [
      "Ting-Kang Yen",
      "Igor Morawski",
      "Shusil Dangi",
      "Kai He",
      "Chung-Yi Lin",
      "Jia-Fong Yeh",
      "Hung-Ting Su",
      "Winston Hsu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18340",
    "title": "The Metric Distortion of Randomized Social Choice Functions: C1 Maximal  Lottery Rules and Simulations",
    "abstract": "The metric distortion of a randomized social choice function (RSCF) quantifies its worst-case approximation ratio of the optimal social cost when the voters' costs for alternatives are given by distances in a metric space. This notion has recently attracted significant attention as numerous RSCFs that aim to minimize the metric distortion have been suggested. However, such tailored voting rules usually have little appeal other than their low metric distortion. In this paper, we will thus study the metric distortion of well-established RSCFs. In more detail, we first show that C1 maximal lottery rules, a well-known class of RSCFs, have a metric distortion of $4$ and furthermore prove that this is optimal within the class of majoritarian RSCFs (which only depend on the majority relation). As our second contribution, we perform extensive computer experiments on the metric distortion of established RSCFs to obtain insights into their average-case performance. These computer experiments are based on a new linear program for computing the metric distortion of a lottery on a given profile and reveal that some classical RSCFs perform almost as well as the currently best known RSCF with respect to the metric distortion on randomly sampled profiles. ",
    "url": "https://arxiv.org/abs/2403.18340",
    "authors": [
      "Fabian Frank",
      "Patrick Lederer"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2403.18343",
    "title": "The Artificial Neural Twin -- Process Optimization and Continual  Learning in Distributed Process Chains",
    "abstract": "Industrial process optimization and control is crucial to increase economic and ecologic efficiency. However, data sovereignty, differing goals, or the required expert knowledge for implementation impede holistic implementation. Further, the increasing use of data-driven AI-methods in process models and industrial sensory often requires regular fine-tuning to accommodate distribution drifts. We propose the Artificial Neural Twin, which combines concepts from model predictive control, deep learning, and sensor networks to address these issues. Our approach introduces differentiable data fusion to estimate the state of distributed process steps and their dependence on input data. By treating the interconnected process steps as a quasi neural-network, we can backpropagate loss gradients for process optimization or model fine-tuning to process parameters or AI models respectively. The concept is demonstrated on a virtual machine park simulated in Unity, consisting of bulk material processes in plastic recycling. ",
    "url": "https://arxiv.org/abs/2403.18343",
    "authors": [
      "Johannes Emmert",
      "Ronald Mendez",
      "Houman Mirzaalian Dastjerdi",
      "Christopher Syben",
      "Andreas Maier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18346",
    "title": "Quantifying and Mitigating Unimodal Biases in Multimodal Large Language  Models: A Causal Perspective",
    "abstract": "Recent advancements in Large Language Models (LLMs) have facilitated the development of Multimodal LLMs (MLLMs). Despite their impressive capabilities, MLLMs often suffer from an over-reliance on unimodal biases (e.g., language bias and vision bias), leading to incorrect answers in complex multimodal tasks. To investigate this issue, we propose a causal framework to interpret the biases in Visual Question Answering (VQA) problems. Within our framework, we devise a causal graph to elucidate the predictions of MLLMs on VQA problems, and assess the causal effect of biases through an in-depth causal analysis. Motivated by the causal graph, we introduce a novel MORE dataset, consisting of 12,000 VQA instances. This dataset is designed to challenge MLLMs' abilities, necessitating multi-hop reasoning and the surmounting of unimodal biases. Furthermore, we propose two strategies to mitigate unimodal biases and enhance MLLMs' reasoning capabilities, including a Decompose-Verify-Answer (DeVA) framework for limited-access MLLMs and the refinement of open-source MLLMs through fine-tuning. Extensive quantitative and qualitative experiments offer valuable insights for future research. ",
    "url": "https://arxiv.org/abs/2403.18346",
    "authors": [
      "Meiqi Chen",
      "Yixin Cao",
      "Yan Zhang",
      "Chaochao Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18373",
    "title": "BAM: Box Abstraction Monitors for Real-time OoD Detection in Object  Detection",
    "abstract": "Out-of-distribution (OoD) detection techniques for deep neural networks (DNNs) become crucial thanks to their filtering of abnormal inputs, especially when DNNs are used in safety-critical applications and interact with an open and dynamic environment. Nevertheless, integrating OoD detection into state-of-the-art (SOTA) object detection DNNs poses significant challenges, partly due to the complexity introduced by the SOTA OoD construction methods, which require the modification of DNN architecture and the introduction of complex loss functions. This paper proposes a simple, yet surprisingly effective, method that requires neither retraining nor architectural change in object detection DNN, called Box Abstraction-based Monitors (BAM). The novelty of BAM stems from using a finite union of convex box abstractions to capture the learned features of objects for in-distribution (ID) data, and an important observation that features from OoD data are more likely to fall outside of these boxes. The union of convex regions within the feature space allows the formation of non-convex and interpretable decision boundaries, overcoming the limitations of VOS-like detectors without sacrificing real-time performance. Experiments integrating BAM into Faster R-CNN-based object detection DNNs demonstrate a considerably improved performance against SOTA OoD detection techniques. ",
    "url": "https://arxiv.org/abs/2403.18373",
    "authors": [
      "Changshun Wu",
      "Weicheng He",
      "Chih-Hong Cheng",
      "Xiaowei Huang",
      "Saddek Bensalem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18379",
    "title": "IIP-Mixer:Intra-Inter Patch Mixing Architecture for Battery Remaining  Useful Life Prediction",
    "abstract": "Accurately estimating the Remaining Useful Life (RUL) of lithium-ion batteries is crucial for maintaining the safe and stable operation of rechargeable battery management systems. However, this task is often challenging due to the complex temporal dynamics involved. Recently, attention-based networks, such as Transformers and Informer, have been the popular architecture in time series forecasting. Despite their effectiveness, these models with abundant parameters necessitate substantial training time to unravel temporal patterns. To tackle these challenges, we propose a simple MLP-Mixer-based architecture named 'Intra-Inter Patch Mixer' (IIP-Mixer), which is an architecture based exclusively on multi-layer perceptrons (MLPs), extracting information by mixing operations along both intra-patch and inter-patch dimensions for battery RUL prediction. The proposed IIP-Mixer comprises parallel dual-head mixer layers: the intra-patch mixing MLP, capturing local temporal patterns in the short-term period, and the inter-patch mixing MLP, capturing global temporal patterns in the long-term period. Notably, to address the varying importance of features in RUL prediction, we introduce a weighted loss function in the MLP-Mixer-based architecture, marking the first time such an approach has been employed. Our experiments demonstrate that IIP-Mixer achieves competitive performance in battery RUL prediction, outperforming other popular time-series frameworks ",
    "url": "https://arxiv.org/abs/2403.18379",
    "authors": [
      "Guangzai Ye",
      "Li Feng",
      "Jianlan Guo",
      "Yuqiang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.18393",
    "title": "Tensor-based Graph Learning with Consistency and Specificity for  Multi-view Clustering",
    "abstract": "Graph learning is widely recognized as a crucial technique in multi-view clustering. Existing graph learning methods typically involve constructing an adaptive neighbor graph based on probabilistic neighbors and then learning a consensus graph to for clustering, however, they are confronted with two limitations. Firstly, they often rely on Euclidean distance to measure similarity when constructing the adaptive neighbor graph, which proves inadequate in capturing the intrinsic structure among data points in many real-world scenarios. Secondly, most of these methods focus solely on consensus graph, ignoring view-specific graph information. In response to the aforementioned drawbacks, we in this paper propose a novel tensor-based graph learning framework that simultaneously considers consistency and specificity for multi-view clustering. Specifically, we calculate the similarity distance on the Stiefel manifold to preserve the intrinsic structure among data points. By making an assumption that the learned neighbor graph of each view comprises both a consistent graph and a view-specific graph, we formulate a new tensor-based target graph learning paradigm. Owing to the benefits of tensor singular value decomposition (t-SVD) in uncovering high-order correlations, this model is capable of achieving a complete understanding of the target graph. Furthermore, we develop an iterative algorithm to solve the proposed objective optimization problem. Experiments conducted on real-world datasets have demonstrated the superior performance of the proposed method over some state-of-the-art multi-view clustering methods. The source code has been released on https://github.com/lshi91/CSTGL-Code. ",
    "url": "https://arxiv.org/abs/2403.18393",
    "authors": [
      "Long Shi",
      "Lei Cao",
      "Yunshan Ye",
      "Yu Zhao",
      "Badong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18397",
    "title": "Colour and Brush Stroke Pattern Recognition in Abstract Art using  Modified Deep Convolutional Generative Adversarial Networks",
    "abstract": "Abstract Art is an immensely popular, discussed form of art that often has the ability to depict the emotions of an artist. Many researchers have made attempts to study abstract art in the form of edge detection, brush stroke and emotion recognition algorithms using machine and deep learning. This papers describes the study of a wide distribution of abstract paintings using Generative Adversarial Neural Networks(GAN). GANs have the ability to learn and reproduce a distribution enabling researchers and scientists to effectively explore and study the generated image space. However, the challenge lies in developing an efficient GAN architecture that overcomes common training pitfalls. This paper addresses this challenge by introducing a modified-DCGAN (mDCGAN) specifically designed for high-quality artwork generation. The approach involves a thorough exploration of the modifications made, delving into the intricate workings of DCGANs, optimisation techniques, and regularisation methods aimed at improving stability and realism in art generation enabling effective study of generated patterns. The proposed mDCGAN incorporates meticulous adjustments in layer configurations and architectural choices, offering tailored solutions to the unique demands of art generation while effectively combating issues like mode collapse and gradient vanishing. Further this paper explores the generated latent space by performing random walks to understand vector relationships between brush strokes and colours in the abstract art space and a statistical analysis of unstable outputs after a certain period of GAN training and compare its significant difference. These findings validate the effectiveness of the proposed approach, emphasising its potential to revolutionise the field of digital art generation and digital art ecosystem. ",
    "url": "https://arxiv.org/abs/2403.18397",
    "authors": [
      "Srinitish Srinivasan",
      "Varenya Pathak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18402",
    "title": "On Spectrogram Analysis in a Multiple Classifier Fusion Framework for  Power Grid Classification Using Electric Network Frequency",
    "abstract": "The Electric Network Frequency (ENF) serves as a unique signature inherent to power distribution systems. Here, a novel approach for power grid classification is developed, leveraging ENF. Spectrograms are generated from audio and power recordings across different grids, revealing distinctive ENF patterns that aid in grid classification through a fusion of classifiers. Four traditional machine learning classifiers plus a Convolutional Neural Network (CNN), optimized using Neural Architecture Search, are developed for One-vs-All classification. This process generates numerous predictions per sample, which are then compiled and used to train a shallow multi-label neural network specifically designed to model the fusion process, ultimately leading to the conclusive class prediction for each sample. Experimental findings reveal that both validation and testing accuracy outperform those of current state-of-the-art classifiers, underlining the effectiveness and robustness of the proposed methodology. ",
    "url": "https://arxiv.org/abs/2403.18402",
    "authors": [
      "Georgios Tzolopoulos",
      "Christos Korgialas",
      "Constantine Kotropoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18415",
    "title": "The Topos of Transformer Networks",
    "abstract": "The transformer neural network has significantly out-shined all other neural network architectures as the engine behind large language models. We provide a theoretical analysis of the expressivity of the transformer architecture through the lens of topos theory. From this viewpoint, we show that many common neural network architectures, such as the convolutional, recurrent and graph convolutional networks, can be embedded in a pretopos of piecewise-linear functions, but that the transformer necessarily lives in its topos completion. In particular, this suggests that the two network families instantiate different fragments of logic: the former are first order, whereas transformers are higher-order reasoners. Furthermore, we draw parallels with architecture search and gradient descent, integrating our analysis in the framework of cybernetic agents. ",
    "url": "https://arxiv.org/abs/2403.18415",
    "authors": [
      "Mattia Jacopo Villani",
      "Peter McBurney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Category Theory (math.CT)"
    ]
  },
  {
    "id": "arXiv:2403.18423",
    "title": "SemRoDe: Macro Adversarial Training to Learn Representations That are  Robust to Word-Level Attacks",
    "abstract": "Language models (LMs) are indispensable tools for natural language processing tasks, but their vulnerability to adversarial attacks remains a concern. While current research has explored adversarial training techniques, their improvements to defend against word-level attacks have been limited. In this work, we propose a novel approach called Semantic Robust Defence (SemRoDe), a Macro Adversarial Training strategy to enhance the robustness of LMs. Drawing inspiration from recent studies in the image domain, we investigate and later confirm that in a discrete data setting such as language, adversarial samples generated via word substitutions do indeed belong to an adversarial domain exhibiting a high Wasserstein distance from the base domain. Our method learns a robust representation that bridges these two domains. We hypothesize that if samples were not projected into an adversarial domain, but instead to a domain with minimal shift, it would improve attack robustness. We align the domains by incorporating a new distance-based objective. With this, our model is able to learn more generalized representations by aligning the model's high-level output features and therefore better handling unseen adversarial samples. This method can be generalized across word embeddings, even when they share minimal overlap at both vocabulary and word-substitution levels. To evaluate the effectiveness of our approach, we conduct experiments on BERT and RoBERTa models on three datasets. The results demonstrate promising state-of-the-art robustness. ",
    "url": "https://arxiv.org/abs/2403.18423",
    "authors": [
      "Brian Formento",
      "Wenjie Feng",
      "Chuan Sheng Foo",
      "Luu Anh Tuan",
      "See-Kiong Ng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18442",
    "title": "Backpropagation-free Network for 3D Test-time Adaptation",
    "abstract": "Real-world systems often encounter new data over time, which leads to experiencing target domain shifts. Existing Test-Time Adaptation (TTA) methods tend to apply computationally heavy and memory-intensive backpropagation-based approaches to handle this. Here, we propose a novel method that uses a backpropagation-free approach for TTA for the specific case of 3D data. Our model uses a two-stream architecture to maintain knowledge about the source domain as well as complementary target-domain-specific information. The backpropagation-free property of our model helps address the well-known forgetting problem and mitigates the error accumulation issue. The proposed method also eliminates the need for the usually noisy process of pseudo-labeling and reliance on costly self-supervised training. Moreover, our method leverages subspace learning, effectively reducing the distribution variance between the two domains. Furthermore, the source-domain-specific and the target-domain-specific streams are aligned using a novel entropy-based adaptive fusion strategy. Extensive experiments on popular benchmarks demonstrate the effectiveness of our method. The code will be available at https://github.com/abie-e/BFTT3D. ",
    "url": "https://arxiv.org/abs/2403.18442",
    "authors": [
      "Yanshuo Wang",
      "Ali Cheraghian",
      "Zeeshan Hayder",
      "Jie Hong",
      "Sameera Ramasinghe",
      "Shafin Rahman",
      "David Ahmedt-Aristizabal",
      "Xuesong Li",
      "Lars Petersson",
      "Mehrtash Harandi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18443",
    "title": "$\\mathrm{F^2Depth}$: Self-supervised Indoor Monocular Depth Estimation  via Optical Flow Consistency and Feature Map Synthesis",
    "abstract": "Self-supervised monocular depth estimation methods have been increasingly given much attention due to the benefit of not requiring large, labelled datasets. Such self-supervised methods require high-quality salient features and consequently suffer from severe performance drop for indoor scenes, where low-textured regions dominant in the scenes are almost indiscriminative. To address the issue, we propose a self-supervised indoor monocular depth estimation framework called $\\mathrm{F^2Depth}$. A self-supervised optical flow estimation network is introduced to supervise depth learning. To improve optical flow estimation performance in low-textured areas, only some patches of points with more discriminative features are adopted for finetuning based on our well-designed patch-based photometric loss. The finetuned optical flow estimation network generates high-accuracy optical flow as a supervisory signal for depth estimation. Correspondingly, an optical flow consistency loss is designed. Multi-scale feature maps produced by finetuned optical flow estimation network perform warping to compute feature map synthesis loss as another supervisory signal for depth learning. Experimental results on the NYU Depth V2 dataset demonstrate the effectiveness of the framework and our proposed losses. To evaluate the generalization ability of our $\\mathrm{F^2Depth}$, we collect a Campus Indoor depth dataset composed of approximately 1500 points selected from 99 images in 18 scenes. Zero-shot generalization experiments on 7-Scenes dataset and Campus Indoor achieve $\\delta_1$ accuracy of 75.8% and 76.0% respectively. The accuracy results show that our model can generalize well to monocular images captured in unknown indoor scenes. ",
    "url": "https://arxiv.org/abs/2403.18443",
    "authors": [
      "Xiaotong Guo",
      "Huijie Zhao",
      "Shuwei Shao",
      "Xudong Li",
      "Baochang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18447",
    "title": "Can Language Beat Numerical Regression? Language-Based Multimodal  Trajectory Prediction",
    "abstract": "Language models have demonstrated impressive ability in context understanding and generative performance. Inspired by the recent success of language foundation models, in this paper, we propose LMTraj (Language-based Multimodal Trajectory predictor), which recasts the trajectory prediction task into a sort of question-answering problem. Departing from traditional numerical regression models, which treat the trajectory coordinate sequence as continuous signals, we consider them as discrete signals like text prompts. Specially, we first transform an input space for the trajectory coordinate into the natural language space. Here, the entire time-series trajectories of pedestrians are converted into a text prompt, and scene images are described as text information through image captioning. The transformed numerical and image data are then wrapped into the question-answering template for use in a language model. Next, to guide the language model in understanding and reasoning high-level knowledge, such as scene context and social relationships between pedestrians, we introduce an auxiliary multi-task question and answering. We then train a numerical tokenizer with the prompt data. We encourage the tokenizer to separate the integer and decimal parts well, and leverage it to capture correlations between the consecutive numbers in the language model. Lastly, we train the language model using the numerical tokenizer and all of the question-answer prompts. Here, we propose a beam-search-based most-likely prediction and a temperature-based multimodal prediction to implement both deterministic and stochastic inferences. Applying our LMTraj, we show that the language-based model can be a powerful pedestrian trajectory predictor, and outperforms existing numerical-based predictor methods. Code is publicly available at https://github.com/inhwanbae/LMTrajectory . ",
    "url": "https://arxiv.org/abs/2403.18447",
    "authors": [
      "Inhwan Bae",
      "Junoh Lee",
      "Hae-Gon Jeon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.18462",
    "title": "Decoy Effect In Search Interaction: Understanding User Behavior and  Measuring System Vulnerability",
    "abstract": "This study examines the decoy effect's underexplored influence on user search interactions and methods for measuring information retrieval (IR) systems' vulnerability to this effect. It explores how decoy results alter users' interactions on search engine result pages, focusing on metrics like click-through likelihood, browsing time, and perceived document usefulness. By analyzing user interaction logs from multiple datasets, the study demonstrates that decoy results significantly affect users' behavior and perceptions. Furthermore, it investigates how different levels of task difficulty and user knowledge modify the decoy effect's impact, finding that easier tasks and lower knowledge levels lead to higher engagement with target documents. In terms of IR system evaluation, the study introduces the DEJA-VU metric to assess systems' susceptibility to the decoy effect, testing it on specific retrieval tasks. The results show differences in systems' effectiveness and vulnerability, contributing to our understanding of cognitive biases in search behavior and suggesting pathways for creating more balanced and bias-aware IR evaluations. ",
    "url": "https://arxiv.org/abs/2403.18462",
    "authors": [
      "Nuo Chen",
      "Jiqun Liu",
      "Hanpei Fang",
      "Yuankai Luo",
      "Tetsuya Sakai",
      "Xiao-Ming Wu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2403.18479",
    "title": "Lightweight Embeddings for Graph Collaborative Filtering",
    "abstract": "Graph neural networks (GNNs) are currently one of the most performant collaborative filtering methods. Meanwhile, owing to the use of an embedding table to represent each user/item as a distinct vector, GNN-based recommenders have inherited the long-standing defect of parameter inefficiency. As a common practice for scalable embeddings, parameter sharing enables the use of fewer embedding vectors (i.e., meta-embeddings). When assigning meta-embeddings, most existing methods are a heuristically designed, predefined mapping from each user's/item's ID to the corresponding meta-embedding indexes, thus simplifying the optimization problem into learning only the meta-embeddings. However, in the context of GNN-based collaborative filtering, such a fixed mapping omits the semantic correlations between entities that are evident in the user-item interaction graph, leading to suboptimal recommendation performance. To this end, we propose Lightweight Embeddings for Graph Collaborative Filtering (LEGCF), a parameter-efficient embedding framework dedicated to GNN-based recommenders. LEGCF innovatively introduces an assignment matrix as an extra learnable component on top of meta-embeddings. To jointly optimize these two heavily entangled components, aside from learning the meta-embeddings by minimizing the recommendation loss, LEGCF further performs efficient assignment update by enforcing a novel semantic similarity constraint and finding its closed-form solution based on matrix pseudo-inverse. The meta-embeddings and assignment matrix are alternately updated, where the latter is sparsified on the fly to ensure negligible storage overhead. Extensive experiments on three benchmark datasets have verified LEGCF's smallest trade-off between size and performance, with consistent accuracy gain over state-of-the-art baselines. The codebase of LEGCF is available in https://github.com/xurong-liang/LEGCF. ",
    "url": "https://arxiv.org/abs/2403.18479",
    "authors": [
      "Xurong Liang",
      "Tong Chen",
      "Lizhen Cui",
      "Yang Wang",
      "Meng Wang",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2403.18489",
    "title": "Impact of Employing Weather Forecast Data as Input to the Estimation of  Evapotranspiration by Deep Neural Network Models",
    "abstract": "Reference Evapotranspiration (ET0) is a key parameter for designing smart irrigation scheduling, since it is related by a coefficient to the water needs of a crop. The United Nations Food and Agriculture Organization, proposed a standard method for ET0 computation (FAO56PM), based on the parameterization of the Penman-Monteith equation, that is widely adopted in the literature. To compute ET0 using the FAO56-PM method, four main weather parameters are needed: temperature, humidity, wind, and solar radiation (SR). One way to make daily ET0 estimations for future days is to use freely available weather forecast services (WFSs), where many meteorological parameters are estimated up to the next 15 days. A problem with this method is that currently, SR is not provided as a free forecast parameter on most of those online services or, normally, such forecasts present a financial cost penalty. For this reason, several ET0 estimation models using machine and deep learning were developed and presented in the literature, that use as input features a reduced set of carefully selected weather parameters, that are compatible with common freely available WFSs. However, most studies on this topic have only evaluated model performance using data from weather stations (WSs), without considering the effect of using weather forecast data. In this study, the performance of authors' previous models is evaluated when using weather forecast data from two online WFSs, in the following scenarios: (i) direct ET0 estimation by an ANN model, and (ii) estimate SR by ANN model, and then use that estimation for ET0 computation, using the FAO56-PM method. Employing data collected from two WFSs and a WS located in Vale do Lobo, Portugal, the latter approach achieved the best result, with a coefficient of determination (R2) ranging between 0.893 and 0.667, when considering forecasts up to 15 days. ",
    "url": "https://arxiv.org/abs/2403.18489",
    "authors": [
      "Pedro J. Vaz",
      "Gabriela Sch\u00fctz",
      "Carlos Guerrero",
      "Pedro J. S. Cardoso"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18495",
    "title": "Direct mineral content prediction from drill core images via transfer  learning",
    "abstract": "Deep subsurface exploration is important for mining, oil and gas industries, as well as in the assessment of geological units for the disposal of chemical or nuclear waste, or the viability of geothermal energy systems. Typically, detailed examinations of subsurface formations or units are performed on cuttings or core materials extracted during drilling campaigns, as well as on geophysical borehole data, which provide detailed information about the petrophysical properties of the rocks. Depending on the volume of rock samples and the analytical program, the laboratory analysis and diagnostics can be very time-consuming. This study investigates the potential of utilizing machine learning, specifically convolutional neural networks (CNN), to assess the lithology and mineral content solely from analysis of drill core images, aiming to support and expedite the subsurface geological exploration. The paper outlines a comprehensive methodology, encompassing data preprocessing, machine learning methods, and transfer learning techniques. The outcome reveals a remarkable 96.7% accuracy in the classification of drill core segments into distinct formation classes. Furthermore, a CNN model was trained for the evaluation of mineral content using a learning data set from multidimensional log analysis data (silicate, total clay, carbonate). When benchmarked against laboratory XRD measurements on samples from the cores, both the advanced multidimensional log analysis model and the neural network approach developed here provide equally good performance. This work demonstrates that deep learning and particularly transfer learning can support extracting petrophysical properties, including mineral content and formation classification, from drill core images, thus offering a road map for enhancing model performance and data set quality in image-based analysis of drill cores. ",
    "url": "https://arxiv.org/abs/2403.18495",
    "authors": [
      "Romana Boiger",
      "Sergey V. Churakov",
      "Ignacio Ballester Llagaria",
      "Georg Kosakowski",
      "Raphael W\u00fcst",
      "Nikolaos I. Prasianakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2403.18519",
    "title": "Improving Line Search Methods for Large Scale Neural Network Training",
    "abstract": "In recent studies, line search methods have shown significant improvements in the performance of traditional stochastic gradient descent techniques, eliminating the need for a specific learning rate schedule. In this paper, we identify existing issues in state-of-the-art line search methods, propose enhancements, and rigorously evaluate their effectiveness. We test these methods on larger datasets and more complex data domains than before. Specifically, we improve the Armijo line search by integrating the momentum term from ADAM in its search direction, enabling efficient large-scale training, a task that was previously prone to failure using Armijo line search methods. Our optimization approach outperforms both the previous Armijo implementation and tuned learning rate schedules for Adam. Our evaluation focuses on Transformers and CNNs in the domains of NLP and image data. Our work is publicly available as a Python package, which provides a hyperparameter free Pytorch optimizer. ",
    "url": "https://arxiv.org/abs/2403.18519",
    "authors": [
      "Philip Kenneweg",
      "Tristan Kenneweg",
      "Barbara Hammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.18537",
    "title": "A Path Towards Legal Autonomy: An interoperable and explainable approach  to extracting, transforming, loading and computing legal information using  large language models, expert systems and Bayesian networks",
    "abstract": "Legal autonomy - the lawful activity of artificial intelligence agents - can be achieved in one of two ways. It can be achieved either by imposing constraints on AI actors such as developers, deployers and users, and on AI resources such as data, or by imposing constraints on the range and scope of the impact that AI agents can have on the environment. The latter approach involves encoding extant rules concerning AI driven devices into the software of AI agents controlling those devices (e.g., encoding rules about limitations on zones of operations into the agent software of an autonomous drone device). This is a challenge since the effectivity of such an approach requires a method of extracting, loading, transforming and computing legal information that would be both explainable and legally interoperable, and that would enable AI agents to reason about the law. In this paper, we sketch a proof of principle for such a method using large language models (LLMs), expert legal systems known as legal decision paths, and Bayesian networks. We then show how the proposed method could be applied to extant regulation in matters of autonomous cars, such as the California Vehicle Code. ",
    "url": "https://arxiv.org/abs/2403.18537",
    "authors": [
      "Axel Constant",
      "Hannes Westermann",
      "Bryan Wilson",
      "Alex Kiefer",
      "Ines Hipolito",
      "Sylvain Pronovost",
      "Steven Swanson",
      "Mahault Albarracin",
      "Maxwell J.D. Ramstead"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2403.18539",
    "title": "Safe and Robust Reinforcement-Learning: Principles and Practice",
    "abstract": "Reinforcement Learning (RL) has shown remarkable success in solving relatively complex tasks, yet the deployment of RL systems in real-world scenarios poses significant challenges related to safety and robustness. This paper aims to identify and further understand those challenges thorough the exploration of the main dimensions of the safe and robust RL landscape, encompassing algorithmic, ethical, and practical considerations. We conduct a comprehensive review of methodologies and open problems that summarizes the efforts in recent years to address the inherent risks associated with RL applications. After discussing and proposing definitions for both safe and robust RL, the paper categorizes existing research works into different algorithmic approaches that enhance the safety and robustness of RL agents. We examine techniques such as uncertainty estimation, optimisation methodologies, exploration-exploitation trade-offs, and adversarial training. Environmental factors, including sim-to-real transfer and domain adaptation, are also scrutinized to understand how RL systems can adapt to diverse and dynamic surroundings. Moreover, human involvement is an integral ingredient of the analysis, acknowledging the broad set of roles that humans can take in this context. Importantly, to aid practitioners in navigating the complexities of safe and robust RL implementation, this paper introduces a practical checklist derived from the synthesized literature. The checklist encompasses critical aspects of algorithm design, training environment considerations, and ethical guidelines. It will serve as a resource for developers and policymakers alike to ensure the responsible deployment of RL systems in many application domains. ",
    "url": "https://arxiv.org/abs/2403.18539",
    "authors": [
      "Taku Yamagata",
      "Raul Santos-Rodriguez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.18545",
    "title": "Optimal Resource Efficiency with Fairness in Heterogeneous GPU Clusters",
    "abstract": "Ensuring the highest training throughput to maximize resource efficiency, while maintaining fairness among users, is critical for deep learning (DL) training in heterogeneous GPU clusters. However, current DL schedulers provide only limited fairness properties and suboptimal training throughput, impeding tenants from effectively leveraging heterogeneous resources. The underlying design challenge stems from inherent conflicts between efficiency and fairness properties. In this paper, we introduce OEF, a new resource allocation framework specifically developed for achieving optimal resource efficiency and ensuring diverse fairness properties in heterogeneous GPU clusters. By integrating resource efficiency and fairness within a global optimization framework, OEF is capable of providing users with maximized overall efficiency, as well as various guarantees of fairness, in both cooperative and non-cooperative environments. We have implemented OEF in a cluster resource manager and conducted large-scale experiments, showing that OEF can improve the overall training throughput by up to 32% while improving fairness compared to state-of-the-art heterogeneity-aware schedulers. ",
    "url": "https://arxiv.org/abs/2403.18545",
    "authors": [
      "Zizhao Mo",
      "Huanle Xu",
      "Wing Cheong Lau"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2403.18546",
    "title": "Efficient Heatmap-Guided 6-Dof Grasp Detection in Cluttered Scenes",
    "abstract": "Fast and robust object grasping in clutter is a crucial component of robotics. Most current works resort to the whole observed point cloud for 6-Dof grasp generation, ignoring the guidance information excavated from global semantics, thus limiting high-quality grasp generation and real-time performance. In this work, we show that the widely used heatmaps are underestimated in the efficiency of 6-Dof grasp generation. Therefore, we propose an effective local grasp generator combined with grasp heatmaps as guidance, which infers in a global-to-local semantic-to-point way. Specifically, Gaussian encoding and the grid-based strategy are applied to predict grasp heatmaps as guidance to aggregate local points into graspable regions and provide global semantic information. Further, a novel non-uniform anchor sampling mechanism is designed to improve grasp accuracy and diversity. Benefiting from the high-efficiency encoding in the image space and focusing on points in local graspable regions, our framework can perform high-quality grasp detection in real-time and achieve state-of-the-art results. In addition, real robot experiments demonstrate the effectiveness of our method with a success rate of 94% and a clutter completion rate of 100%. Our code is available at https://github.com/THU-VCLab/HGGD. ",
    "url": "https://arxiv.org/abs/2403.18546",
    "authors": [
      "Siang Chen",
      "Wei Tang",
      "Pengwei Xie",
      "Wenming Yang",
      "Guijin Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18547",
    "title": "Neural Architecture Search for Sentence Classification with BERT",
    "abstract": "Pre training of language models on large text corpora is common practice in Natural Language Processing. Following, fine tuning of these models is performed to achieve the best results on a variety of tasks. In this paper we question the common practice of only adding a single output layer as a classification head on top of the network. We perform an AutoML search to find architectures that outperform the current single layer at only a small compute cost. We validate our classification architecture on a variety of NLP benchmarks from the GLUE dataset. ",
    "url": "https://arxiv.org/abs/2403.18547",
    "authors": [
      "Philip Kenneweg",
      "Sarah Schr\u00f6der",
      "Barbara Hammer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.18554",
    "title": "CosalPure: Learning Concept from Group Images for Robust Co-Saliency  Detection",
    "abstract": "Co-salient object detection (CoSOD) aims to identify the common and salient (usually in the foreground) regions across a given group of images. Although achieving significant progress, state-of-the-art CoSODs could be easily affected by some adversarial perturbations, leading to substantial accuracy reduction. The adversarial perturbations can mislead CoSODs but do not change the high-level semantic information (e.g., concept) of the co-salient objects. In this paper, we propose a novel robustness enhancement framework by first learning the concept of the co-salient objects based on the input group images and then leveraging this concept to purify adversarial perturbations, which are subsequently fed to CoSODs for robustness enhancement. Specifically, we propose CosalPure containing two modules, i.e., group-image concept learning and concept-guided diffusion purification. For the first module, we adopt a pre-trained text-to-image diffusion model to learn the concept of co-salient objects within group images where the learned concept is robust to adversarial examples. For the second module, we map the adversarial image to the latent space and then perform diffusion generation by embedding the learned concept into the noise prediction function as an extra condition. Our method can effectively alleviate the influence of the SOTA adversarial attack containing different adversarial patterns, including exposure and noise. The extensive results demonstrate that our method could enhance the robustness of CoSODs significantly. ",
    "url": "https://arxiv.org/abs/2403.18554",
    "authors": [
      "Jiayi Zhu",
      "Qing Guo",
      "Felix Juefei-Xu",
      "Yihao Huang",
      "Yang Liu",
      "Geguang Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18569",
    "title": "PDNNet: PDN-Aware GNN-CNN Heterogeneous Network for Dynamic IR Drop  Prediction",
    "abstract": "IR drop on the power delivery network (PDN) is closely related to PDN's configuration and cell current consumption. As the integrated circuit (IC) design is growing larger, dynamic IR drop simulation becomes computationally unaffordable and machine learning based IR drop prediction has been explored as a promising solution. Although CNN-based methods have been adapted to IR drop prediction task in several works, the shortcomings of overlooking PDN configuration is non-negligible. In this paper, we consider not only how to properly represent cell-PDN relation, but also how to model IR drop following its physical nature in the feature aggregation procedure. Thus, we propose a novel graph structure, PDNGraph, to unify the representations of the PDN structure and the fine-grained cell-PDN relation. We further propose a dual-branch heterogeneous network, PDNNet, incorporating two parallel GNN-CNN branches to favorably capture the above features during the learning process. Several key designs are presented to make the dynamic IR drop prediction highly effective and interpretable. We are the first work to apply graph structure to deep-learning based dynamic IR drop prediction method. Experiments show that PDNNet outperforms the state-of-the-art CNN-based methods by up to 39.3% reduction in prediction error and achieves 545x speedup compared to the commercial tool, which demonstrates the superiority of our method. ",
    "url": "https://arxiv.org/abs/2403.18569",
    "authors": [
      "Yuxiang Zhao",
      "Zhuomin Chai",
      "Xun Jiang",
      "Yibo Lin",
      "Runsheng Wang",
      "Ru Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.18570",
    "title": "Physics-Informed Graph Neural Networks for Water Distribution Systems",
    "abstract": "Water distribution systems (WDS) are an integral part of critical infrastructure which is pivotal to urban development. As 70% of the world's population will likely live in urban environments in 2050, efficient simulation and planning tools for WDS play a crucial role in reaching UN's sustainable developmental goal (SDG) 6 - \"Clean water and sanitation for all\". In this realm, we propose a novel and efficient machine learning emulator, more precisely, a physics-informed deep learning (DL) model, for hydraulic state estimation in WDS. Using a recursive approach, our model only needs a few graph convolutional neural network (GCN) layers and employs an innovative algorithm based on message passing. Unlike conventional machine learning tasks, the model uses hydraulic principles to infer two additional hydraulic state features in the process of reconstructing the available ground truth feature in an unsupervised manner. To the best of our knowledge, this is the first DL approach to emulate the popular hydraulic simulator EPANET, utilizing no additional information. Like most DL models and unlike the hydraulic simulator, our model demonstrates vastly faster emulation times that do not increase drastically with the size of the WDS. Moreover, we achieve high accuracy on the ground truth and very similar results compared to the hydraulic simulator as demonstrated through experiments on five real-world WDS datasets. ",
    "url": "https://arxiv.org/abs/2403.18570",
    "authors": [
      "Inaam Ashraf",
      "Janine Strotherm",
      "Luca Hermes",
      "Barbara Hammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.18579",
    "title": "On Optimizing Hyperparameters for Quantum Neural Networks",
    "abstract": "The increasing capabilities of Machine Learning (ML) models go hand in hand with an immense amount of data and computational power required for training. Therefore, training is usually outsourced into HPC facilities, where we have started to experience limits in scaling conventional HPC hardware, as theorized by Moore's law. Despite heavy parallelization and optimization efforts, current state-of-the-art ML models require weeks for training, which is associated with an enormous $CO_2$ footprint. Quantum Computing, and specifically Quantum Machine Learning (QML), can offer significant theoretical speed-ups and enhanced expressive power. However, training QML models requires tuning various hyperparameters, which is a nontrivial task and suboptimal choices can highly affect the trainability and performance of the models. In this study, we identify the most impactful hyperparameters and collect data about the performance of QML models. We compare different configurations and provide researchers with performance data and concrete suggestions for hyperparameter selection. ",
    "url": "https://arxiv.org/abs/2403.18579",
    "authors": [
      "Sabrina Herbst",
      "Vincenzo De Maio",
      "Ivona Brandic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2403.18580",
    "title": "MisGUIDE : Defense Against Data-Free Deep Learning Model Extraction",
    "abstract": "The rise of Machine Learning as a Service (MLaaS) has led to the widespread deployment of machine learning models trained on diverse datasets. These models are employed for predictive services through APIs, raising concerns about the security and confidentiality of the models due to emerging vulnerabilities in prediction APIs. Of particular concern are model cloning attacks, where individuals with limited data and no knowledge of the training dataset manage to replicate a victim model's functionality through black-box query access. This commonly entails generating adversarial queries to query the victim model, thereby creating a labeled dataset. This paper proposes \"MisGUIDE\", a two-step defense framework for Deep Learning models that disrupts the adversarial sample generation process by providing a probabilistic response when the query is deemed OOD. The first step employs a Vision Transformer-based framework to identify OOD queries, while the second step perturbs the response for such queries, introducing a probabilistic loss function to MisGUIDE the attackers. The aim of the proposed defense method is to reduce the accuracy of the cloned model while maintaining accuracy on authentic queries. Extensive experiments conducted on two benchmark datasets demonstrate that the proposed framework significantly enhances the resistance against state-of-the-art data-free model extraction in black-box settings. ",
    "url": "https://arxiv.org/abs/2403.18580",
    "authors": [
      "Mahendra Gurve",
      "Sankar Behera",
      "Satyadev Ahlawat",
      "Yamuna Prasad"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.18587",
    "title": "The Impact of Uniform Inputs on Activation Sparsity and Energy-Latency  Attacks in Computer Vision",
    "abstract": "Resource efficiency plays an important role for machine learning nowadays. The energy and decision latency are two critical aspects to ensure a sustainable and practical application. Unfortunately, the energy consumption and decision latency are not robust against adversaries. Researchers have recently demonstrated that attackers can compute and submit so-called sponge examples at inference time to increase the energy consumption and decision latency of neural networks. In computer vision, the proposed strategy crafts inputs with less activation sparsity which could otherwise be used to accelerate the computation. In this paper, we analyze the mechanism how these energy-latency attacks reduce activation sparsity. In particular, we find that input uniformity is a key enabler. A uniform image, that is, an image with mostly flat, uniformly colored surfaces, triggers more activations due to a specific interplay of convolution, batch normalization, and ReLU activation. Based on these insights, we propose two new simple, yet effective strategies for crafting sponge examples: sampling images from a probability distribution and identifying dense, yet inconspicuous inputs in natural datasets. We empirically examine our findings in a comprehensive evaluation with multiple image classification models and show that our attack achieves the same sparsity effect as prior sponge-example methods, but at a fraction of computation effort. We also show that our sponge examples transfer between different neural networks. Finally, we discuss applications of our findings for the good by improving efficiency by increasing sparsity. ",
    "url": "https://arxiv.org/abs/2403.18587",
    "authors": [
      "Andreas M\u00fcller",
      "Erwin Quiring"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18607",
    "title": "Spikewhisper: Temporal Spike Backdoor Attacks on Federated Neuromorphic  Learning over Low-power Devices",
    "abstract": "Federated neuromorphic learning (FedNL) leverages event-driven spiking neural networks and federated learning frameworks to effectively execute intelligent analysis tasks over amounts of distributed low-power devices but also perform vulnerability to poisoning attacks. The threat of backdoor attacks on traditional deep neural networks typically comes from time-invariant data. However, in FedNL, unknown threats may be hidden in time-varying spike signals. In this paper, we start to explore a novel vulnerability of FedNL-based systems with the concept of time division multiplexing, termed Spikewhisper, which allows attackers to evade detection as much as possible, as multiple malicious clients can imperceptibly poison with different triggers at different timeslices. In particular, the stealthiness of Spikewhisper is derived from the time-domain divisibility of global triggers, in which each malicious client pastes only one local trigger to a certain timeslice in the neuromorphic sample, and also the polarity and motion of each local trigger can be configured by attackers. Extensive experiments based on two different neuromorphic datasets demonstrate that the attack success rate of Spikewispher is higher than the temporally centralized attacks. Besides, it is validated that the effect of Spikewispher is sensitive to the trigger duration. ",
    "url": "https://arxiv.org/abs/2403.18607",
    "authors": [
      "Hanqing Fu",
      "Gaolei Li",
      "Jun Wu",
      "Jianhua Li",
      "Xi Lin",
      "Kai Zhou",
      "Yuchen Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.18609",
    "title": "A survey on learning models of spiking neural membrane systems and  spiking neural networks",
    "abstract": "Spiking neural networks (SNN) are a biologically inspired model of neural networks with certain brain-like properties. In the past few decades, this model has received increasing attention in computer science community, owing also to the successful phenomenon of deep learning. In SNN, communication between neurons takes place through the spikes and spike trains. This differentiates these models from the ``standard'' artificial neural networks (ANN) where the frequency of spikes is replaced by real-valued signals. Spiking neural P systems (SNPS) can be considered a branch of SNN based more on the principles of formal automata, with many variants developed within the framework of the membrane computing theory. In this paper, we first briefly compare structure and function, advantages and drawbacks of SNN and SNPS. A key part of the article is a survey of recent results and applications of machine learning and deep learning models of both SNN and SNPS formalisms. ",
    "url": "https://arxiv.org/abs/2403.18609",
    "authors": [
      "Prithwineel Paul",
      "Petr Sosik",
      "Lucie Ciencialova"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.18621",
    "title": "Performance Analysis of Integrated Sensing and Communication Networks  with Blockage Effects",
    "abstract": "Communication-sensing integration represents an up-and-coming area of research, enabling wireless networks to simultaneously perform communication and sensing tasks. However, in urban cellular networks, the blockage of buildings results in a complex signal propagation environment, affecting the performance analysis of integrated sensing and communication (ISAC) networks. To overcome this obstacle, this paper constructs a comprehensive framework considering building blockage and employs a distance-correlated blockage model to analyze interference from line of sight (LoS), non-line of sight (NLoS), and target reflection cascading (TRC) links. Using stochastic geometric theory, expressions for signal-to-interference-plus-noise ratio (SINR) and coverage probability for communication and sensing in the presence of blockage are derived, allowing for a comprehensive comparison under the same parameters. The research findings indicate that blockage can positively impact coverage, especially in enhancing communication performance. The analysis also suggests that there exists an optimal base station (BS) density when blockage is of the same order of magnitude as the BS density, maximizing communication or sensing coverage probability. ",
    "url": "https://arxiv.org/abs/2403.18621",
    "authors": [
      "Zezhong Sun",
      "Shi Yan",
      "Ning Jiang",
      "Jiaen Zhou",
      "Mugen Peng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.18624",
    "title": "Vulnerability Detection with Code Language Models: How Far Are We?",
    "abstract": "In the context of the rising interest in code language models (code LMs) and vulnerability detection, we study the effectiveness of code LMs for detecting vulnerabilities. Our analysis reveals significant shortcomings in existing vulnerability datasets, including poor data quality, low label accuracy, and high duplication rates, leading to unreliable model performance in realistic vulnerability detection scenarios. Additionally, the evaluation methods used with these datasets are not representative of real-world vulnerability detection. To address these challenges, we introduce PrimeVul, a new dataset for training and evaluating code LMs for vulnerability detection. PrimeVul incorporates a novel set of data labeling techniques that achieve comparable label accuracy to human-verified benchmarks while significantly expanding the dataset. It also implements a rigorous data de-duplication and chronological data splitting strategy to mitigate data leakage issues, alongside introducing more realistic evaluation metrics and settings. This comprehensive approach aims to provide a more accurate assessment of code LMs' performance in real-world conditions. Evaluating code LMs on PrimeVul reveals that existing benchmarks significantly overestimate the performance of these models. For instance, a state-of-the-art 7B model scored 68.26% F1 on BigVul but only 3.09% F1 on PrimeVul. Attempts to improve performance through advanced training techniques and larger models like GPT-3.5 and GPT-4 were unsuccessful, with results akin to random guessing in the most stringent settings. These findings underscore the considerable gap between current capabilities and the practical requirements for deploying code LMs in security roles, highlighting the need for more innovative research in this domain. ",
    "url": "https://arxiv.org/abs/2403.18624",
    "authors": [
      "Yangruibo Ding",
      "Yanjun Fu",
      "Omniyyah Ibrahim",
      "Chawin Sitawarin",
      "Xinyun Chen",
      "Basel Alomair",
      "David Wagner",
      "Baishakhi Ray",
      "Yizheng Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.18650",
    "title": "MPC-CBF with Adaptive Safety Margins for Safety-critical Teleoperation  over Imperfect Network Connections",
    "abstract": "The paper focuses on the design of a control strategy for safety-critical remote teleoperation. The main goal is to make the controlled system track the desired velocity specified by an operator while avoiding obstacles despite communication delays. Control Barrier Functions (CBFs) are used to define the safety constraints that the system has to respect to avoid obstacles, while Model Predictive Control (MPC) provides the framework for adjusting the desired input, taking the constraints into account. The resulting input is sent to the remote system, where appropriate low-level velocity controllers translate it into system-specific commands. The main novelty of the paper is a method to make the CBFs robust against the uncertainties caused by the network delays affecting the system's state and do so in a less conservative manner. The results show how the proposed method successfully solves the safety-critical teleoperation problem, making the controlled systems avoid obstacles with different types of network delay. The controller has also been tested in simulation and on a real manipulator, demonstrating its general applicability when reliable low-level velocity controllers are available. ",
    "url": "https://arxiv.org/abs/2403.18650",
    "authors": [
      "Riccardo Periotto",
      "Mina Ferizbegovic",
      "Fernando S. Barbosa",
      "Roberto C. Sundin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.18659",
    "title": "INEXA: Interactive and Explainable Process Model Abstraction Through  Object-Centric Process Mining",
    "abstract": "Process events are recorded by multiple information systems at different granularity levels. Based on the resulting event logs, process models are discovered at different granularity levels, as well. Events stored at a fine-grained granularity level, for example, may hinder the discovered process model to be displayed due the high number of resulting model elements. The discovered process model of a real-world manufacturing process, for example, consists of 1,489 model elements and over 2,000 arcs. Existing process model abstraction techniques could help reducing the size of the model, but would disconnect it from the underlying event log. Existing event abstraction techniques do neither support the analysis of mixed granularity levels, nor interactive exploration of a suitable granularity level. To enable the exploration of discovered process models at different granularity levels, we propose INEXA, an interactive, explainable process model abstraction method that keeps the link to the event log. As a starting point, INEXA aggregates large process models to a \"displayable\" size, e.g., for the manufacturing use case to a process model with 58 model elements. Then, the process analyst can explore granularity levels interactively, while applied abstractions are automatically traced in the event log for explainability. ",
    "url": "https://arxiv.org/abs/2403.18659",
    "authors": [
      "Janik-Vasily Benzin",
      "Gyunam Park",
      "Juergen Mangler",
      "Stefanie Rinderle-Ma"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.18674",
    "title": "Deep Learning for Robust and Explainable Models in Computer Vision",
    "abstract": "Recent breakthroughs in machine and deep learning (ML and DL) research have provided excellent tools for leveraging enormous amounts of data and optimizing huge models with millions of parameters to obtain accurate networks for image processing. These developments open up tremendous opportunities for using artificial intelligence (AI) in the automation and human assisted AI industry. However, as more and more models are deployed and used in practice, many challenges have emerged. This thesis presents various approaches that address robustness and explainability challenges for using ML and DL in practice. Robustness and reliability are the critical components of any model before certification and deployment in practice. Deep convolutional neural networks (CNNs) exhibit vulnerability to transformations of their inputs, such as rotation and scaling, or intentional manipulations as described in the adversarial attack literature. In addition, building trust in AI-based models requires a better understanding of current models and developing methods that are more explainable and interpretable a priori. This thesis presents developments in computer vision models' robustness and explainability. Furthermore, this thesis offers an example of using vision models' feature response visualization (models' interpretations) to improve robustness despite interpretability and robustness being seemingly unrelated in the related research. Besides methodological developments for robust and explainable vision models, a key message of this thesis is introducing model interpretation techniques as a tool for understanding vision models and improving their design and robustness. In addition to the theoretical developments, this thesis demonstrates several applications of ML and DL in different contexts, such as medical imaging and affective computing. ",
    "url": "https://arxiv.org/abs/2403.18674",
    "authors": [
      "Mohammadreza Amirian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18695",
    "title": "An Efficient Risk-aware Branch MPC for Automated Driving that is Robust  to Uncertain Vehicle Behaviors",
    "abstract": "One of the critical challenges in automated driving is ensuring safety of automated vehicles despite the unknown behavior of the other vehicles. Although motion prediction modules are able to generate a probability distribution associated with various behavior modes, their probabilistic estimates are often inaccurate, thus leading to a possibly unsafe trajectory. To overcome this challenge, we propose a risk-aware motion planning framework that appropriately accounts for the ambiguity in the estimated probability distribution. We formulate the risk-aware motion planning problem as a min-max optimization problem and develop an efficient iterative method by incorporating a regularization term in the probability update step. Via extensive numerical studies, we validate the convergence of our method and demonstrate its advantages compared to the state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2403.18695",
    "authors": [
      "Luyao Zhang",
      "George Pantazis",
      "Shaohang Han",
      "Sergio Grammatico"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.18703",
    "title": "Fpga-Based Neural Thrust Controller for UAVs",
    "abstract": "The advent of unmanned aerial vehicles (UAVs) has improved a variety of fields by providing a versatile, cost-effective and accessible platform for implementing state-of-the-art algorithms. To accomplish a broader range of tasks, there is a growing need for enhanced on-board computing to cope with increasing complexity and dynamic environmental conditions. Recent advances have seen the application of Deep Neural Networks (DNNs), particularly in combination with Reinforcement Learning (RL), to improve the adaptability and performance of UAVs, especially in unknown environments. However, the computational requirements of DNNs pose a challenge to the limited computing resources available on many UAVs. This work explores the use of Field Programmable Gate Arrays (FPGAs) as a viable solution to this challenge, offering flexibility, high performance, energy and time efficiency. We propose a novel hardware board equipped with an Artix-7 FPGA for a popular open-source micro-UAV platform. We successfully validate its functionality by implementing an RL-based low-level controller using real-world experiments. ",
    "url": "https://arxiv.org/abs/2403.18703",
    "authors": [
      "Sharif Azem",
      "David Scheunert",
      "Mengguang Li",
      "Jonas Gehrunger",
      "Kai Cui",
      "Christian Hochberger",
      "Heinz Koepp"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18710",
    "title": "Deep Learning for Traffic Flow Prediction using Cellular Automata-based  Model and CNN-LSTM architecture",
    "abstract": "Recent works have attempted to use deep learning to predict future states of traffic flow, but have met with mixed results. These approaches face two key challenges. First, training deep learning neural networks requires large amounts of training data which are not yet easily available for traffic flow systems. Second, even when data is available, the neural networks require access to historical data that covers most possible traffic flow dynamics to successfully predict future traffic states. Specifically, these deep learning approaches do not fully leverage domain-knowledge about traffic flow dynamics, despite a significant existing knowledge-base. In this work, we propose to solve both issues using a Convolutional Neural Network (CNNs) with Long Short Term Memory (LSTM) deep learning architecture to successfully predict traffic flow, while leveraging a cellular automata-based statistical mechanics model of traffic flow to generate training and test data. Another major contribution of this paper is the insight that training data for a large traffic system can actually be sampled from the simulations of a much smaller traffic system. This is achieved through observing that the normalized energy distribution of the statistical mechanics model is scale invariant, which significantly eases the burden of data generation for large scale traffic systems. The resulting simulations indicate good agreement between the predicted and the true traffic flow dynamics. ",
    "url": "https://arxiv.org/abs/2403.18710",
    "authors": [
      "Zhaohui Yang",
      "Kshitij Jerath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18711",
    "title": "SAT-NGP : Unleashing Neural Graphics Primitives for Fast Relightable  Transient-Free 3D reconstruction from Satellite Imagery",
    "abstract": "Current stereo-vision pipelines produce high accuracy 3D reconstruction when using multiple pairs or triplets of satellite images. However, these pipelines are sensitive to the changes between images that can occur as a result of multi-date acquisitions. Such variations are mainly due to variable shadows, reflexions and transient objects (cars, vegetation). To take such changes into account, Neural Radiance Fields (NeRF) have recently been applied to multi-date satellite imagery. However, Neural methods are very compute-intensive, taking dozens of hours to learn, compared with minutes for standard stereo-vision pipelines. Following the ideas of Instant Neural Graphics Primitives we propose to use an efficient sampling strategy and multi-resolution hash encoding to accelerate the learning. Our model, Satellite Neural Graphics Primitives (SAT-NGP) decreases the learning time to 15 minutes while maintaining the quality of the 3D reconstruction. ",
    "url": "https://arxiv.org/abs/2403.18711",
    "authors": [
      "Camille Billouard",
      "Dawa Derksen",
      "Emmanuelle Sarrazin",
      "Bruno Vallet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.18717",
    "title": "Semi-Supervised Learning for Deep Causal Generative Models",
    "abstract": "Developing models that can answer questions of the form \"How would $x$ change if $y$ had been $z$?\" is fundamental for advancing medical image analysis. Training causal generative models that address such counterfactual questions, though, currently requires that all relevant variables have been observed and that corresponding labels are available in training data. However, clinical data may not have complete records for all patients and state of the art causal generative models are unable to take full advantage of this. We thus develop, for the first time, a semi-supervised deep causal generative model that exploits the causal relationships between variables to maximise the use of all available data. We explore this in the setting where each sample is either fully labelled or fully unlabelled, as well as the more clinically realistic case of having different labels missing for each sample. We leverage techniques from causal inference to infer missing values and subsequently generate realistic counterfactuals, even for samples with incomplete labels. ",
    "url": "https://arxiv.org/abs/2403.18717",
    "authors": [
      "Yasin Ibrahim",
      "Hermione Warr",
      "Konstantinos Kamnitsas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.18723",
    "title": "Four Formal Models of IEEE 1394 Link Layer",
    "abstract": "We revisit the IEEE 1394 high-performance serial bus (\"FireWire\"), which became a success story in formal methods after three PhD students, by using process algebra and model checking, detected a deadlock error in this IEEE standard. We present four formal models for the asynchronous mode of the Link Layer of IEEE 1394: the original model in muCRL, a simplified model in mCRL2, a revised model in LOTOS, and a novel model in LNT. ",
    "url": "https://arxiv.org/abs/2403.18723",
    "authors": [
      "Hubert Garavel",
      "Bas Luttik"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Hardware Architecture (cs.AR)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2403.18729",
    "title": "ConstraintFlow: A DSL for Specification and Verification of Neural  Network Analyses",
    "abstract": "The uninterpretability of DNNs hinders their deployment to safety-critical applications. Recent works have shown that Abstract-Interpretation-based formal certification techniques provide promising avenues for building trust in DNNs to some extent. The intricate mathematical background of Abstract Interpretation poses two challenges: (i) easily designing the algorithms that capture the intricate DNN behavior by balancing cost vs. precision tradeoff, and (ii) maintaining the over-approximation-based soundness of these certifiers. General-purpose programming languages like C++ provide extensive functionality, however, verifying the soundness of the algorithms written in them can be impractical. The most commonly used DNN certification libraries like auto_LiRPA and ERAN prove the correctness of their analyses. However, they consist of only a few hard-coded abstract domains and abstract transformers (or transfer functions) and do not allow the user to define new analyses. Further, these libraries can handle only specific DNN architectures. To address these issues, we develop a declarative DSL -- ConstraintFlow -- that can be used to specify Abstract Interpretation-based DNN certifiers. In ConstraintFlow, programmers can easily define various existing and new abstract domains and transformers, all within just a few 10s of Lines of Code as opposed to 1000s of LOCs of existing libraries. We also provide lightweight automatic verification, which can be used to ensure the over-approximation-based soundness of the certifier code written in ConstraintFlow for arbitrary (but bounded) DNN architectures. Using this automated verification procedure, for the first time, we can verify the soundness of state-of-the-art DNN certifiers for arbitrary DNN architectures, all within a few minutes. We prove the soundness of our verification procedure and the completeness of a subset of ConstraintFlow. ",
    "url": "https://arxiv.org/abs/2403.18729",
    "authors": [
      "Avaljot Singh",
      "Yasmin Sarita",
      "Charith Mendis",
      "Gagandeep Singh"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2403.18731",
    "title": "Enhancing Manufacturing Quality Prediction Models through the  Integration of Explainability Methods",
    "abstract": "This research presents a method that utilizes explainability techniques to amplify the performance of machine learning (ML) models in forecasting the quality of milling processes, as demonstrated in this paper through a manufacturing use case. The methodology entails the initial training of ML models, followed by a fine-tuning phase where irrelevant features identified through explainability methods are eliminated. This procedural refinement results in performance enhancements, paving the way for potential reductions in manufacturing costs and a better understanding of the trained ML models. This study highlights the usefulness of explainability techniques in both explaining and optimizing predictive models in the manufacturing realm. ",
    "url": "https://arxiv.org/abs/2403.18731",
    "authors": [
      "Dennis Gross",
      "Helge Spieker",
      "Arnaud Gotlieb",
      "Ricardo Knoblauch"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18739",
    "title": "Usage-Specific Survival Modeling Based on Operational Data and Neural  Networks",
    "abstract": "Accurate predictions of when a component will fail are crucial when planning maintenance, and by modeling the distribution of these failure times, survival models have shown to be particularly useful in this context. The presented methodology is based on conventional neural network-based survival models that are trained using data that is continuously gathered and stored at specific times, called snapshots. An important property of this type of training data is that it can contain more than one snapshot from a specific individual which results in that standard maximum likelihood training can not be directly applied since the data is not independent. However, the papers show that if the data is in a specific format where all snapshot times are the same for all individuals, called homogeneously sampled, maximum likelihood training can be applied and produce desirable results. In many cases, the data is not homogeneously sampled and in this case, it is proposed to resample the data to make it homogeneously sampled. How densely the dataset is sampled turns out to be an important parameter; it should be chosen large enough to produce good results, but this also increases the size of the dataset which makes training slow. To reduce the number of samples needed during training, the paper also proposes a technique to, instead of resampling the dataset once before the training starts, randomly resample the dataset at the start of each epoch during the training. The proposed methodology is evaluated on both a simulated dataset and an experimental dataset of starter battery failures. The results show that if the data is homogeneously sampled the methodology works as intended and produces accurate survival models. The results also show that randomly resampling the dataset on each epoch is an effective way to reduce the size of the training data. ",
    "url": "https://arxiv.org/abs/2403.18739",
    "authors": [
      "Olov Holmer",
      "Mattias Krysander",
      "Erik Frisk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.18745",
    "title": "Fast Decision Algorithms for Efficient Access Point Assignment in  SDN-Controlled Wireless Access Networks",
    "abstract": "Global optimization of access point (AP) assignment to user terminals requires efficient monitoring of user behavior, fast decision algorithms, efficient control signaling, and fast AP reassignment mechanisms. In this scenario, software defined networking (SDN) technology may be suitable for network monitoring, signaling, and control. We recently proposed embedding virtual switches in user terminals for direct management by an SDN controller, further contributing to SDN-oriented access network optimization. However, since users may restrict terminal-side traffic monitoring for privacy reasons (a common assumption by previous authors), we infer user traffic classes at the APs. On the other hand, since handovers will be more frequent in dense small-cell networks (e.g., mmWave-based 5G deployments will require dense network topologies with inter-site distances of ~150-200 m), the delay to take assignment decisions should be minimal. To this end, we propose taking fast decisions based exclusively on extremely simple network-side application flow-type predictions based on past user behavior. Using real data we show that a centralized allocation algorithm based on those predictions achieves network utilization levels that approximate those of optimal allocations. We also test a distributed version of this algorithm. Finally, we quantify the elapsed time since a user traffic event takes place until its terminal is assigned an AP, when needed. ",
    "url": "https://arxiv.org/abs/2403.18745",
    "authors": [
      "Pablo Fondo-Ferreiro",
      "Saber Mhiri",
      "Cristina L\u00f3pez-Bravo",
      "Francisco Javier Gonz\u00e1lez-Casta\u00f1o",
      "Felipe Gil-Casti\u00f1eira"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2403.18746",
    "title": "CYCLE: Learning to Self-Refine the Code Generation",
    "abstract": "Pre-trained code language models have achieved promising performance in code generation and improved the programming efficiency of human developers. However, their self-refinement capability is typically overlooked by the existing evaluations of code LMs, which focus only on the accuracy of the one-time prediction. For the cases when code LMs fail to implement the correct program, developers actually find it hard to debug and fix the faulty prediction since it is not written by the developers themselves. Unfortunately, our study reveals that code LMs cannot efficiently self-refine their faulty generations as well. In this paper, we propose CYCLE framework, learning to self-refine the faulty generation according to the available feedback, such as the execution results reported by the test suites. We evaluate CYCLE on three popular code generation benchmarks, HumanEval, MBPP, and APPS. The results reveal that CYCLE successfully maintains, sometimes improves, the quality of one-time code generation, while significantly improving the self-refinement capability of code LMs. We implement four variants of CYCLE with varied numbers of parameters across 350M, 1B, 2B, and 3B, and the experiments show that CYCLE consistently boosts the code generation performance, by up to 63.5%, across benchmarks and varied model sizes. We also notice that CYCLE outperforms code LMs that have 3$\\times$ more parameters in self-refinement. ",
    "url": "https://arxiv.org/abs/2403.18746",
    "authors": [
      "Yangruibo Ding",
      "Marcus J. Min",
      "Gail Kaiser",
      "Baishakhi Ray"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.18749",
    "title": "Robust Numerical Algebraic Geometry",
    "abstract": "The field of numerical algebraic geometry consists of algorithms for numerically solving systems of polynomial equations. When the system is exact, such as having rational coefficients, the solution set is well-defined. However, for a member of a parameterized family of polynomial systems where the parameter values may be measured with imprecision or arise from prior numerical computations, uncertainty may arise in the structure of the solution set, including the number of isolated solutions, the existence of higher dimensional solution components, and the number of irreducible components along with their multiplicities. The loci where these structures change form a stratification of exceptional algebraic sets in the space of parameters. We describe methodologies for making the interpretation of numerical results more robust by searching for nearby parameter values on an exceptional set. We demonstrate these techniques on several illustrative examples and then treat several more substantial problems arising from the kinematics of mechanisms and robots. ",
    "url": "https://arxiv.org/abs/2403.18749",
    "authors": [
      "Emma R. Cobian",
      "Jonathan D. Hauenstein",
      "Charles W. Wampler"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2403.18755",
    "title": "Many-Objective Evolutionary Influence Maximization: Balancing Spread,  Budget, Fairness, and Time",
    "abstract": "The Influence Maximization (IM) problem seeks to discover the set of nodes in a graph that can spread the information propagation at most. This problem is known to be NP-hard, and it is usually studied by maximizing the influence (spread) and, optionally, optimizing a second objective, such as minimizing the seed set size or maximizing the influence fairness. However, in many practical scenarios multiple aspects of the IM problem must be optimized at the same time. In this work, we propose a first case study where several IM-specific objective functions, namely budget, fairness, communities, and time, are optimized on top of the maximization of influence and minimization of the seed set size. To this aim, we introduce MOEIM (Many-Objective Evolutionary Algorithm for Influence Maximization) a Multi-Objective Evolutionary Algorithm (MOEA) based on NSGA-II incorporating graph-aware operators and a smart initialization. We compare MOEIM in two experimental settings, including a total of nine graph datasets, two heuristic methods, a related MOEA, and a state-of-the-art Deep Learning approach. The experiments show that MOEIM overall outperforms the competitors in most of the tested many-objective settings. To conclude, we also investigate the correlation between the objectives, leading to novel insights into the topic. The codebase is available at https://github.com/eliacunegatti/MOEIM. ",
    "url": "https://arxiv.org/abs/2403.18755",
    "authors": [
      "Elia Cunegatti",
      "Leonardo Lucio Custode",
      "Giovanni Iacca"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.18756",
    "title": "Detection of subclinical atherosclerosis by image-based deep learning on  chest x-ray",
    "abstract": "Aims. To develop a deep-learning based system for recognition of subclinical atherosclerosis on a plain frontal chest x-ray. Methods and Results. A deep-learning algorithm to predict coronary artery calcium (CAC) score (the AI-CAC model) was developed on 460 chest x-ray (80% training cohort, 20% internal validation cohort) of primary prevention patients (58.4% male, median age 63 [51-74] years) with available paired chest x-ray and chest computed tomography (CT) indicated for any clinical reason and performed within 3 months. The CAC score calculated on chest CT was used as ground truth. The model was validated on an temporally-independent cohort of 90 patients from the same institution (external validation). The diagnostic accuracy of the AI-CAC model assessed by the area under the curve (AUC) was the primary outcome. Overall, median AI-CAC score was 35 (0-388) and 28.9% patients had no AI-CAC. AUC of the AI-CAC model to identify a CAC>0 was 0.90 in the internal validation cohort and 0.77 in the external validation cohort. Sensitivity was consistently above 92% in both cohorts. In the overall cohort (n=540), among patients with AI-CAC=0, a single ASCVD event occurred, after 4.3 years. Patients with AI-CAC>0 had significantly higher Kaplan Meier estimates for ASCVD events (13.5% vs. 3.4%, log-rank=0.013). Conclusion. The AI-CAC model seems to accurately detect subclinical atherosclerosis on chest x-ray with elevated sensitivity, and to predict ASCVD events with elevated negative predictive value. Adoption of the AI-CAC model to refine CV risk stratification or as an opportunistic screening tool requires prospective evaluation. ",
    "url": "https://arxiv.org/abs/2403.18756",
    "authors": [
      "Guglielmo Gallone",
      "Francesco Iodice",
      "Alberto Presta",
      "Davide Tore",
      "Ovidio de Filippo",
      "Michele Visciano",
      "Carlo Alberto Barbano",
      "Alessandro Serafini",
      "Paola Gorrini",
      "Alessandro Bruno",
      "Walter Grosso Marra",
      "James Hughes",
      "Mario Iannaccone",
      "Paolo Fonio",
      "Attilio Fiandrotti",
      "Alessandro Depaoli",
      "Marco Grangetto",
      "Gaetano Maria de Ferrari",
      "Fabrizio D'Ascenzo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18760",
    "title": "MLDT: Multi-Level Decomposition for Complex Long-Horizon Robotic Task  Planning with Open-Source Large Language Model",
    "abstract": "In the realm of data-driven AI technology, the application of open-source large language models (LLMs) in robotic task planning represents a significant milestone. Recent robotic task planning methods based on open-source LLMs typically leverage vast task planning datasets to enhance models' planning abilities. While these methods show promise, they struggle with complex long-horizon tasks, which require comprehending more context and generating longer action sequences. This paper addresses this limitation by proposing MLDT, theMulti-Level Decomposition Task planning method. This method innovatively decomposes tasks at the goal-level, task-level, and action-level to mitigate the challenge of complex long-horizon tasks. In order to enhance open-source LLMs' planning abilities, we introduce a goal-sensitive corpus generation method to create high-quality training data and conduct instruction tuning on the generated corpus. Since the complexity of the existing datasets is not high enough, we construct a more challenging dataset, LongTasks, to specifically evaluate planning ability on complex long-horizon tasks. We evaluate our method using various LLMs on four datasets in VirtualHome. Our results demonstrate a significant performance enhancement in robotic task planning, showcasing MLDT's effectiveness in overcoming the limitations of existing methods based on open-source LLMs as well as its practicality in complex, real-world scenarios. ",
    "url": "https://arxiv.org/abs/2403.18760",
    "authors": [
      "Yike Wu",
      "Jiatao Zhang",
      "Nan Hu",
      "LanLing Tang",
      "Guilin Qi",
      "Jun Shao",
      "Jie Ren",
      "Wei Song"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.18769",
    "title": "Improved Neural Protoform Reconstruction via Reflex Prediction",
    "abstract": "Protolanguage reconstruction is central to historical linguistics. The comparative method, one of the most influential theoretical and methodological frameworks in the history of the language sciences, allows linguists to infer protoforms (reconstructed ancestral words) from their reflexes (related modern words) based on the assumption of regular sound change. Not surprisingly, numerous computational linguists have attempted to operationalize comparative reconstruction through various computational models, the most successful of which have been supervised encoder-decoder models, which treat the problem of predicting protoforms given sets of reflexes as a sequence-to-sequence problem. We argue that this framework ignores one of the most important aspects of the comparative method: not only should protoforms be inferable from cognate sets (sets of related reflexes) but the reflexes should also be inferable from the protoforms. Leveraging another line of research -- reflex prediction -- we propose a system in which candidate protoforms from a reconstruction model are reranked by a reflex prediction model. We show that this more complete implementation of the comparative method allows us to surpass state-of-the-art protoform reconstruction methods on three of four Chinese and Romance datasets. ",
    "url": "https://arxiv.org/abs/2403.18769",
    "authors": [
      "Liang Lu",
      "Jingzhi Wang",
      "David R. Mortensen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.18771",
    "title": "CheckEval: Robust Evaluation Framework using Large Language Model via  Checklist",
    "abstract": "We introduce CheckEval, a novel evaluation framework using Large Language Models, addressing the challenges of ambiguity and inconsistency in current evaluation methods. CheckEval addresses these challenges by dividing evaluation criteria into detailed sub-aspects and constructing a checklist of Boolean questions for each, simplifying the evaluation. This approach not only renders the process more interpretable but also significantly enhances the robustness and reliability of results by focusing on specific evaluation dimensions. Validated through a focused case study using the SummEval benchmark, CheckEval indicates a strong correlation with human judgments. Furthermore, it demonstrates a highly consistent Inter-Annotator Agreement. These findings highlight the effectiveness of CheckEval for objective, flexible, and precise evaluations. By offering a customizable and interactive framework, CheckEval sets a new standard for the use of LLMs in evaluation, responding to the evolving needs of the field and establishing a clear method for future LLM-based evaluation. ",
    "url": "https://arxiv.org/abs/2403.18771",
    "authors": [
      "Yukyung Lee",
      "Joonghoon Kim",
      "Jaehee Kim",
      "Hyowon Cho",
      "Pilsung Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.18774",
    "title": "RAW: A Robust and Agile Plug-and-Play Watermark Framework for  AI-Generated Images with Provable Guarantees",
    "abstract": "Safeguarding intellectual property and preventing potential misuse of AI-generated images are of paramount importance. This paper introduces a robust and agile plug-and-play watermark detection framework, dubbed as RAW. As a departure from traditional encoder-decoder methods, which incorporate fixed binary codes as watermarks within latent representations, our approach introduces learnable watermarks directly into the original image data. Subsequently, we employ a classifier that is jointly trained with the watermark to detect the presence of the watermark. The proposed framework is compatible with various generative architectures and supports on-the-fly watermark injection after training. By incorporating state-of-the-art smoothing techniques, we show that the framework provides provable guarantees regarding the false positive rate for misclassifying a watermarked image, even in the presence of certain adversarial attacks targeting watermark removal. Experiments on a diverse range of images generated by state-of-the-art diffusion models reveal substantial performance enhancements compared to existing approaches. For instance, our method demonstrates a notable increase in AUROC, from 0.48 to 0.82, when compared to state-of-the-art approaches in detecting watermarked images under adversarial attacks, while maintaining image quality, as indicated by closely aligned FID and CLIP scores. ",
    "url": "https://arxiv.org/abs/2403.18774",
    "authors": [
      "Xun Xian",
      "Ganghua Wang",
      "Xuan Bi",
      "Jayanth Srinivasa",
      "Ashish Kundu",
      "Mingyi Hong",
      "Jie Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18775",
    "title": "ImageNet-D: Benchmarking Neural Network Robustness on Diffusion  Synthetic Object",
    "abstract": "We establish rigorous benchmarks for visual perception robustness. Synthetic images such as ImageNet-C, ImageNet-9, and Stylized ImageNet provide specific type of evaluation over synthetic corruptions, backgrounds, and textures, yet those robustness benchmarks are restricted in specified variations and have low synthetic quality. In this work, we introduce generative model as a data source for synthesizing hard images that benchmark deep models' robustness. Leveraging diffusion models, we are able to generate images with more diversified backgrounds, textures, and materials than any prior work, where we term this benchmark as ImageNet-D. Experimental results show that ImageNet-D results in a significant accuracy drop to a range of vision models, from the standard ResNet visual classifier to the latest foundation models like CLIP and MiniGPT-4, significantly reducing their accuracy by up to 60\\%. Our work suggests that diffusion models can be an effective source to test vision models. The code and dataset are available at https://github.com/chenshuang-zhang/imagenet_d. ",
    "url": "https://arxiv.org/abs/2403.18775",
    "authors": [
      "Chenshuang Zhang",
      "Fei Pan",
      "Junmo Kim",
      "In So Kweon",
      "Chengzhi Mao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18777",
    "title": "New Graph and Hypergraph Container Lemmas with Applications in Property  Testing",
    "abstract": "The graph and hypergraph container methods are powerful tools with a wide range of applications across combinatorics. Recently, Blais and Seth (FOCS 2023) showed that the graph container method is particularly well-suited for the analysis of the natural canonical tester for two fundamental graph properties: having a large independent set and $k$-colorability. In this work, we show that the connection between the container method and property testing extends further along two different directions. First, we show that the container method can be used to analyze the canonical tester for many other properties of graphs and hypergraphs. We introduce a new hypergraph container lemma and use it to give an upper bound of $\\widetilde{O}(kq^3/\\epsilon)$ on the sample complexity of $\\epsilon$-testing satisfiability, where $q$ is the number of variables per constraint and $k$ is the size of the alphabet. This is the first upper bound for the problem that is polynomial in all of $k$, $q$ and $1/\\epsilon$. As a corollary, we get new upper bounds on the sample complexity of the canonical testers for hypergraph colorability and for every semi-homogeneous graph partition property. Second, we show that the container method can also be used to study the query complexity of (non-canonical) graph property testers. This result is obtained by introducing a new container lemma for the class of all independent set stars, a strict superset of the class of all independent sets. We use this container lemma to give a new upper bound of $\\widetilde{O}(\\rho^5/\\epsilon^{7/2})$ on the query complexity of $\\epsilon$-testing the $\\rho$-independent set property. This establishes for the first time the non-optimality of the canonical tester for a non-homogeneous graph partition property. ",
    "url": "https://arxiv.org/abs/2403.18777",
    "authors": [
      "Eric Blais",
      "Cameron Seth"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2403.18788",
    "title": "Peregrine: ML-based Malicious Traffic Detection for Terabit Networks",
    "abstract": "Malicious traffic detectors leveraging machine learning (ML), namely those incorporating deep learning techniques, exhibit impressive detection capabilities across multiple attacks. However, their effectiveness becomes compromised when deployed in networks handling Terabit-speed traffic. In practice, these systems require substantial traffic sampling to reconcile the high data plane packet rates with the comparatively slower processing speeds of ML detection. As sampling significantly reduces traffic observability, it fundamentally undermines their detection capability. We present Peregrine, an ML-based malicious traffic detector for Terabit networks. The key idea is to run the detection process partially in the network data plane. Specifically, we offload the detector's ML feature computation to a commodity switch. The Peregrine switch processes a diversity of features per-packet, at Tbps line rates - three orders of magnitude higher than the fastest detector - to feed the ML-based component in the control plane. Our offloading approach presents a distinct advantage. While, in practice, current systems sample raw traffic, in Peregrine sampling occurs after feature computation. This essential trait enables computing features over all traffic, significantly enhancing detection performance. The Peregrine detector is not only effective for Terabit networks, but it is also energy- and cost-efficient. Further, by shifting a compute-heavy component to the switch, it saves precious CPU cycles and improves detection throughput. ",
    "url": "https://arxiv.org/abs/2403.18788",
    "authors": [
      "Jo\u00e3o Romeiras Amado",
      "Francisco Pereira",
      "David Pissarra",
      "Salvatore Signorello",
      "Miguel Correia",
      "Fernando M. V. Ramos"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2403.18810",
    "title": "LightningNet: Distributed Graph-based Cellular Network Performance  Forecasting for the Edge",
    "abstract": "The cellular network plays a pivotal role in providing Internet access, since it is the only global-scale infrastructure with ubiquitous mobility support. To manage and maintain large-scale networks, mobile network operators require timely information, or even accurate performance forecasts. In this paper, we propose LightningNet, a lightweight and distributed graph-based framework for forecasting cellular network performance, which can capture spatio-temporal dependencies that arise in the network traffic. LightningNet achieves a steady performance increase over state-of-the-art forecasting techniques, while maintaining a similar resource usage profile. Our architecture ideology also excels in the respect that it is specifically designed to support IoT and edge devices, giving us an even greater step ahead of the current state-of-the-art, as indicated by our performance experiments with NVIDIA Jetson. ",
    "url": "https://arxiv.org/abs/2403.18810",
    "authors": [
      "Konstantinos Zacharopoulos",
      "Georgios Koutroumpas",
      "Ioannis Arapakis",
      "Konstantinos Georgopoulos",
      "Javad Khangosstar",
      "Sotiris Ioannidis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18814",
    "title": "Mini-Gemini: Mining the Potential of Multi-modality Vision Language  Models",
    "abstract": "In this work, we introduce Mini-Gemini, a simple and effective framework enhancing multi-modality Vision Language Models (VLMs). Despite the advancements in VLMs facilitating basic visual dialog and reasoning, a performance gap persists compared to advanced models like GPT-4 and Gemini. We try to narrow the gap by mining the potential of VLMs for better performance and any-to-any workflow from three aspects, i.e., high-resolution visual tokens, high-quality data, and VLM-guided generation. To enhance visual tokens, we propose to utilize an additional visual encoder for high-resolution refinement without increasing the visual token count. We further construct a high-quality dataset that promotes precise image comprehension and reasoning-based generation, expanding the operational scope of current VLMs. In general, Mini-Gemini further mines the potential of VLMs and empowers current frameworks with image understanding, reasoning, and generation simultaneously. Mini-Gemini supports a series of dense and MoE Large Language Models (LLMs) from 2B to 34B. It is demonstrated to achieve leading performance in several zero-shot benchmarks and even surpasses the developed private models. Code and models are available at https://github.com/dvlab-research/MiniGemini. ",
    "url": "https://arxiv.org/abs/2403.18814",
    "authors": [
      "Yanwei Li",
      "Yuechen Zhang",
      "Chengyao Wang",
      "Zhisheng Zhong",
      "Yixin Chen",
      "Ruihang Chu",
      "Shaoteng Liu",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.17992",
    "title": "Interpretable cancer cell detection with phonon microscopy using  multi-task conditional neural networks for inter-batch calibration",
    "abstract": "Advances in artificial intelligence (AI) show great potential in revealing underlying information from phonon microscopy (high-frequency ultrasound) data to identify cancerous cells. However, this technology suffers from the 'batch effect' that comes from unavoidable technical variations between each experiment, creating confounding variables that the AI model may inadvertently learn. We therefore present a multi-task conditional neural network framework to simultaneously achieve inter-batch calibration, by removing confounding variables, and accurate cell classification of time-resolved phonon-derived signals. We validate our approach by training and validating on different experimental batches, achieving a balanced precision of 89.22% and an average cross-validated precision of 89.07% for classifying background, healthy and cancerous regions. Classification can be performed in 0.5 seconds with only simple prior batch information required for multiple batch corrections. Further, we extend our model to reconstruct denoised signals, enabling physical interpretation of salient features indicating disease state including sound velocity, sound attenuation and cell-adhesion to substrate. ",
    "url": "https://arxiv.org/abs/2403.17992",
    "authors": [
      "Yijie Zheng",
      "Rafael Fuentes-Dominguez",
      "Matt Clark",
      "George S.D. Gordon",
      "Fernando Perez-Cota"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.18026",
    "title": "Cross-system biological image quality enhancement based on the  generative adversarial network as a foundation for establishing a  multi-institute microscopy cooperative network",
    "abstract": "High-quality fluorescence imaging of biological systems is limited by processes like photobleaching and phototoxicity, and also in many cases, by limited access to the latest generations of microscopes. Moreover, low temporal resolution can lead to a motion blur effect in living systems. Our work presents a deep learning (DL) generative-adversarial approach to the problem of obtaining high-quality (HQ) images based on their low-quality (LQ) equivalents. We propose a generative-adversarial network (GAN) for contrast transfer between two different separate microscopy systems: a confocal microscope (producing HQ images) and a wide-field fluorescence microscope (producing LQ images). Our model proves that such transfer is possible, allowing us to receive HQ-generated images characterized by low mean squared error (MSE) values, high structural similarity index (SSIM), and high peak signal-to-noise ratio (PSNR) values. For our best model in the case of comparing HQ-generated images and HQ-ground truth images, the median values of the metrics are 6x10-4, 0.9413, and 31.87, for MSE, SSIM, and PSNR, respectively. In contrast, in the case of comparison between LQ and HQ ground truth median values of the metrics are equal to 0.0071, 0.8304, and 21.48 for MSE, SSIM, and PSNR respectively. Therefore, we observe a significant increase ranging from 14% to 49% for SSIM and PSNR respectively. These results, together with other single-system cross-modality studies, provide proof of concept for further implementation of a cross-system biological image quality enhancement. ",
    "url": "https://arxiv.org/abs/2403.18026",
    "authors": [
      "Dominik Panek",
      "Carina Rz\u0105ca",
      "Maksymilian Szczypior",
      "Joanna Sorysz",
      "Krzysztof Misztal",
      "Zbigniew Baster",
      "Zenon Rajfur"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2403.18030",
    "title": "EinExprs: Contraction Paths of Tensor Networks as Symbolic Expressions",
    "abstract": "Tensor Networks are graph representations of summation expressions in which vertices represent tensors and edges represent tensor indices or vector spaces. In this work, we present EinExprs.jl, a Julia package for contraction path optimization that offers state-of-art optimizers. We propose a representation of the contraction path of a Tensor Network based on symbolic expressions. Using this package the user may choose among a collection of different methods such as Greedy algorithms, or an approach based on the hypergraph partitioning problem. We benchmark this library with examples obtained from the simulation of Random Quantum Circuits (RQC), a well known example where Tensor Networks provide state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2403.18030",
    "authors": [
      "Sergio Sanchez-Ramirez",
      "Jofre Vall\u00e8s-Muns",
      "Artur Garcia-Saez"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Mathematical Software (cs.MS)"
    ]
  },
  {
    "id": "arXiv:2403.18134",
    "title": "Integrative Graph-Transformer Framework for Histopathology Whole Slide  Image Representation and Classification",
    "abstract": "In digital pathology, the multiple instance learning (MIL) strategy is widely used in the weakly supervised histopathology whole slide image (WSI) classification task where giga-pixel WSIs are only labeled at the slide level. However, existing attention-based MIL approaches often overlook contextual information and intrinsic spatial relationships between neighboring tissue tiles, while graph-based MIL frameworks have limited power to recognize the long-range dependencies. In this paper, we introduce the integrative graph-transformer framework that simultaneously captures the context-aware relational features and global WSI representations through a novel Graph Transformer Integration (GTI) block. Specifically, each GTI block consists of a Graph Convolutional Network (GCN) layer modeling neighboring relations at the local instance level and an efficient global attention model capturing comprehensive global information from extensive feature embeddings. Extensive experiments on three publicly available WSI datasets: TCGA-NSCLC, TCGA-RCC and BRIGHT, demonstrate the superiority of our approach over current state-of-the-art MIL methods, achieving an improvement of 1.0% to 2.6% in accuracy and 0.7%-1.6% in AUROC. ",
    "url": "https://arxiv.org/abs/2403.18134",
    "authors": [
      "Zhan Shi",
      "Jingwei Zhang",
      "Jun Kong",
      "Fusheng Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18233",
    "title": "Benchmarking Image Transformers for Prostate Cancer Detection from  Ultrasound Data",
    "abstract": "PURPOSE: Deep learning methods for classifying prostate cancer (PCa) in ultrasound images typically employ convolutional networks (CNNs) to detect cancer in small regions of interest (ROI) along a needle trace region. However, this approach suffers from weak labelling, since the ground-truth histopathology labels do not describe the properties of individual ROIs. Recently, multi-scale approaches have sought to mitigate this issue by combining the context awareness of transformers with a CNN feature extractor to detect cancer from multiple ROIs using multiple-instance learning (MIL). In this work, we present a detailed study of several image transformer architectures for both ROI-scale and multi-scale classification, and a comparison of the performance of CNNs and transformers for ultrasound-based prostate cancer classification. We also design a novel multi-objective learning strategy that combines both ROI and core predictions to further mitigate label noise. METHODS: We evaluate 3 image transformers on ROI-scale cancer classification, then use the strongest model to tune a multi-scale classifier with MIL. We train our MIL models using our novel multi-objective learning strategy and compare our results to existing baselines. RESULTS: We find that for both ROI-scale and multi-scale PCa detection, image transformer backbones lag behind their CNN counterparts. This deficit in performance is even more noticeable for larger models. When using multi-objective learning, we can improve performance of MIL, with a 77.9% AUROC, a sensitivity of 75.9%, and a specificity of 66.3%. CONCLUSION: Convolutional networks are better suited for modelling sparse datasets of prostate ultrasounds, producing more robust features than transformers in PCa detection. Multi-scale methods remain the best architecture for this task, with multi-objective learning presenting an effective way to improve performance. ",
    "url": "https://arxiv.org/abs/2403.18233",
    "authors": [
      "Mohamed Harmanani",
      "Paul F. R. Wilson",
      "Fahimeh Fooladgar",
      "Amoon Jamzad",
      "Mahdi Gilany",
      "Minh Nguyen Nhat To",
      "Brian Wodlinger",
      "Purang Abolmaesumi",
      "Parvin Mousavi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Tissues and Organs (q-bio.TO)"
    ]
  },
  {
    "id": "arXiv:2403.18269",
    "title": "Clustering Change Sign Detection by Fusing Mixture Complexity",
    "abstract": "This paper proposes an early detection method for cluster structural changes. Cluster structure refers to discrete structural characteristics, such as the number of clusters, when data are represented using finite mixture models, such as Gaussian mixture models. We focused on scenarios in which the cluster structure gradually changed over time. For finite mixture models, the concept of mixture complexity (MC) measures the continuous cluster size by considering the cluster proportion bias and overlap between clusters. In this paper, we propose MC fusion as an extension of MC to handle situations in which multiple mixture numbers are possible in a finite mixture model. By incorporating the fusion of multiple models, our approach accurately captured the cluster structure during transitional periods of gradual change. Moreover, we introduce a method for detecting changes in the cluster structure by examining the transition of MC fusion. We demonstrate the effectiveness of our method through empirical analysis using both artificial and real-world datasets. ",
    "url": "https://arxiv.org/abs/2403.18269",
    "authors": [
      "Kento Urano",
      "Ryo Yuki",
      "Kenji Yamanishi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18302",
    "title": "Super-Resolution of SOHO/MDI Magnetograms of Solar Active Regions Using  SDO/HMI Data and an Attention-Aided Convolutional Neural Network",
    "abstract": "Image super-resolution has been an important subject in image processing and recognition. Here, we present an attention-aided convolutional neural network (CNN) for solar image super-resolution. Our method, named SolarCNN, aims to enhance the quality of line-of-sight (LOS) magnetograms of solar active regions (ARs) collected by the Michelson Doppler Imager (MDI) on board the Solar and Heliospheric Observatory (SOHO). The ground-truth labels used for training SolarCNN are the LOS magnetograms collected by the Helioseismic and Magnetic Imager (HMI) on board the Solar Dynamics Observatory (SDO). Solar ARs consist of strong magnetic fields in which magnetic energy can suddenly be released to produce extreme space weather events, such as solar flares, coronal mass ejections, and solar energetic particles. SOHO/MDI covers Solar Cycle 23, which is stronger with more eruptive events than Cycle 24. Enhanced SOHO/MDI magnetograms allow for better understanding and forecasting of violent events of space weather. Experimental results show that SolarCNN improves the quality of SOHO/MDI magnetograms in terms of the structural similarity index measure (SSIM), Pearson's correlation coefficient (PCC), and the peak signal-to-noise ratio (PSNR). ",
    "url": "https://arxiv.org/abs/2403.18302",
    "authors": [
      "Chunhui Xu",
      "Jason T. L. Wang",
      "Haimin Wang",
      "Haodi Jiang",
      "Qin Li",
      "Yasser Abduallah",
      "Yan Xu"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18339",
    "title": "H2ASeg: Hierarchical Adaptive Interaction and Weighting Network for  Tumor Segmentation in PET/CT Images",
    "abstract": "Positron emission tomography (PET) combined with computed tomography (CT) imaging is routinely used in cancer diagnosis and prognosis by providing complementary information. Automatically segmenting tumors in PET/CT images can significantly improve examination efficiency. Traditional multi-modal segmentation solutions mainly rely on concatenation operations for modality fusion, which fail to effectively model the non-linear dependencies between PET and CT modalities. Recent studies have investigated various approaches to optimize the fusion of modality-specific features for enhancing joint representations. However, modality-specific encoders used in these methods operate independently, inadequately leveraging the synergistic relationships inherent in PET and CT modalities, for example, the complementarity between semantics and structure. To address these issues, we propose a Hierarchical Adaptive Interaction and Weighting Network termed H2ASeg to explore the intrinsic cross-modal correlations and transfer potential complementary information. Specifically, we design a Modality-Cooperative Spatial Attention (MCSA) module that performs intra- and inter-modal interactions globally and locally. Additionally, a Target-Aware Modality Weighting (TAMW) module is developed to highlight tumor-related features within multi-modal features, thereby refining tumor segmentation. By embedding these modules across different layers, H2ASeg can hierarchically model cross-modal correlations, enabling a nuanced understanding of both semantic and structural tumor features. Extensive experiments demonstrate the superiority of H2ASeg, outperforming state-of-the-art methods on AutoPet-II and Hecktor2022 benchmarks. The code is released at https://github.com/G14nTDo4/H2ASeg. ",
    "url": "https://arxiv.org/abs/2403.18339",
    "authors": [
      "Jinpeng Lu",
      "Jingyun Chen",
      "Linghan Cai",
      "Songhan Jiang",
      "Yongbing Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.18347",
    "title": "A Quantum Fuzzy-based Approach for Real-Time Detection of Solar Coronal  Holes",
    "abstract": "The detection and analysis of the solar coronal holes (CHs) is an important field of study in the domain of solar physics. Mainly, it is required for the proper prediction of the geomagnetic storms which directly or indirectly affect various space and ground-based systems. For the detection of CHs till date, the solar scientist depends on manual hand-drawn approaches. However, with the advancement of image processing technologies, some automated image segmentation methods have been used for the detection of CHs. In-spite of this, fast and accurate detection of CHs are till a major issues. Here in this work, a novel quantum computing-based fast fuzzy c-mean technique has been developed for fast detection of the CHs region. The task has been carried out in two stages, in first stage the solar image has been segmented using a quantum computing based fast fuzzy c-mean (QCFFCM) and in the later stage the CHs has been extracted out from the segmented image based on image morphological operation. In the work, quantum computing has been used to optimize the cost function of the fast fuzzy c-mean (FFCM) algorithm, where quantum approximate optimization algorithm (QAOA) has been used to optimize the quadratic part of the cost function. The proposed method has been tested for 193 \\AA{} SDO/AIA full-disk solar image datasets and has been compared with the existing techniques. The outcome shows the comparable performance of the proposed method with the existing one within a very lesser time. ",
    "url": "https://arxiv.org/abs/2403.18347",
    "authors": [
      "Sanmoy Bandyopadhyay",
      "Suman Kundu"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18514",
    "title": "CT-3DFlow : Leveraging 3D Normalizing Flows for Unsupervised Detection  of Pathological Pulmonary CT scans",
    "abstract": "Unsupervised pathology detection can be implemented by training a model on healthy data only and measuring the deviation from the training set upon inference, for example with CNN-based feature extraction and one-class classifiers, or reconstruction-score-based methods such as AEs, GANs and Diffusion models. Normalizing Flows (NF) have the ability to directly learn the probability distribution of training examples through an invertible architecture. We leverage this property in a novel 3D NF-based model named CT-3DFlow, specifically tailored for patient-level pulmonary pathology detection in chest CT data. Our model is trained unsupervised on healthy 3D pulmonary CT patches, and detects deviations from its log-likelihood distribution as anomalies. We aggregate patches-level likelihood values from a patient's CT scan to provide a patient-level 'normal'/'abnormal' prediction. Out-of-distribution detection performance is evaluated using expert annotations on a separate chest CT test dataset, outperforming other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2403.18514",
    "authors": [
      "Aissam Djahnine",
      "Alexandre Popoff",
      "Emilien Jupin-Delevaux",
      "Vincent Cottin",
      "Olivier Nempont",
      "Loic Boussel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18535",
    "title": "Theoretical Bound-Guided Hierarchical VAE for Neural Image Codecs",
    "abstract": "Recent studies reveal a significant theoretical link between variational autoencoders (VAEs) and rate-distortion theory, notably in utilizing VAEs to estimate the theoretical upper bound of the information rate-distortion function of images. Such estimated theoretical bounds substantially exceed the performance of existing neural image codecs (NICs). To narrow this gap, we propose a theoretical bound-guided hierarchical VAE (BG-VAE) for NIC. The proposed BG-VAE leverages the theoretical bound to guide the NIC model towards enhanced performance. We implement the BG-VAE using Hierarchical VAEs and demonstrate its effectiveness through extensive experiments. Along with advanced neural network blocks, we provide a versatile, variable-rate NIC that outperforms existing methods when considering both rate-distortion performance and computational complexity. The code is available at BG-VAE. ",
    "url": "https://arxiv.org/abs/2403.18535",
    "authors": [
      "Yichi Zhang",
      "Zhihao Duan",
      "Yuning Huang",
      "Fengqing Zhu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18560",
    "title": "Noise-Robust Keyword Spotting through Self-supervised Pretraining",
    "abstract": "Voice assistants are now widely available, and to activate them a keyword spotting (KWS) algorithm is used. Modern KWS systems are mainly trained using supervised learning methods and require a large amount of labelled data to achieve a good performance. Leveraging unlabelled data through self-supervised learning (SSL) has been shown to increase the accuracy in clean conditions. This paper explores how SSL pretraining such as Data2Vec can be used to enhance the robustness of KWS models in noisy conditions, which is under-explored. Models of three different sizes are pretrained using different pretraining approaches and then fine-tuned for KWS. These models are then tested and compared to models trained using two baseline supervised learning methods, one being standard training using clean data and the other one being multi-style training (MTR). The results show that pretraining and fine-tuning on clean data is superior to supervised learning on clean data across all testing conditions, and superior to supervised MTR for testing conditions of SNR above 5 dB. This indicates that pretraining alone can increase the model's robustness. Finally, it is found that using noisy data for pretraining models, especially with the Data2Vec-denoising approach, significantly enhances the robustness of KWS models in noisy conditions. ",
    "url": "https://arxiv.org/abs/2403.18560",
    "authors": [
      "Jacob M\u00f8rk",
      "Holger Severin Bovbjerg",
      "Gergely Kiss",
      "Zheng-Hua Tan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2403.18578",
    "title": "SteinGen: Generating Fidelitous and Diverse Graph Samples",
    "abstract": "Generating graphs that preserve characteristic structures while promoting sample diversity can be challenging, especially when the number of graph observations is small. Here, we tackle the problem of graph generation from only one observed graph. The classical approach of graph generation from parametric models relies on the estimation of parameters, which can be inconsistent or expensive to compute due to intractable normalisation constants. Generative modelling based on machine learning techniques to generate high-quality graph samples avoids parameter estimation but usually requires abundant training samples. Our proposed generating procedure, SteinGen, which is phrased in the setting of graphs as realisations of exponential random graph models, combines ideas from Stein's method and MCMC by employing Markovian dynamics which are based on a Stein operator for the target model. SteinGen uses the Glauber dynamics associated with an estimated Stein operator to generate a sample, and re-estimates the Stein operator from the sample after every sampling step. We show that on a class of exponential random graph models this novel \"estimation and re-estimation\" generation strategy yields high distributional similarity (high fidelity) to the original data, combined with high sample diversity. ",
    "url": "https://arxiv.org/abs/2403.18578",
    "authors": [
      "Gesine Reinert",
      "Wenkai Xu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18597",
    "title": "Heterogeneous Peridynamic Neural Operators: Discover Biotissue  Constitutive Law and Microstructure From Digital Image Correlation  Measurements",
    "abstract": "Human tissues are highly organized structures with specific collagen fiber arrangements varying from point to point. The effects of such heterogeneity play an important role for tissue function, and hence it is of critical to discover and understand the distribution of such fiber orientations from experimental measurements, such as the digital image correlation data. To this end, we introduce the heterogeneous peridynamic neural operator (HeteroPNO) approach, for data-driven constitutive modeling of heterogeneous anisotropic materials. The goal is to learn both a nonlocal constitutive law together with the material microstructure, in the form of a heterogeneous fiber orientation field, from loading field-displacement field measurements. To this end, we propose a two-phase learning approach. Firstly, we learn a homogeneous constitutive law in the form of a neural network-based kernel function and a nonlocal bond force, to capture complex homogeneous material responses from data. Then, in the second phase we reinitialize the learnt bond force and the kernel function, and training them together with a fiber orientation field for each material point. Owing to the state-based peridynamic skeleton, our HeteroPNO-learned material models are objective and have the balance of linear and angular momentum guaranteed. Moreover, the effects from heterogeneity and nonlinear constitutive relationship are captured by the kernel function and the bond force respectively, enabling physical interpretability. As a result, our HeteroPNO architecture can learn a constitutive model for a biological tissue with anisotropic heterogeneous response undergoing large deformation regime. Moreover, the framework is capable to provide displacement and stress field predictions for new and unseen loading instances. ",
    "url": "https://arxiv.org/abs/2403.18597",
    "authors": [
      "Siavash Jafarzadeh",
      "Stewart Silling",
      "Lu Zhang",
      "Colton Ross",
      "Chung-Hao Lee",
      "S. M. Rakibur Rahman",
      "Shuodao Wang",
      "Yue Yu"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18664",
    "title": "Neural Network-Based Piecewise Survival Models",
    "abstract": "In this paper, a family of neural network-based survival models is presented. The models are specified based on piecewise definitions of the hazard function and the density function on a partitioning of the time; both constant and linear piecewise definitions are presented, resulting in a family of four models. The models can be seen as an extension of the commonly used discrete-time and piecewise exponential models and thereby add flexibility to this set of standard models. Using a simulated dataset the models are shown to perform well compared to the highly expressive, state-of-the-art energy-based model, while only requiring a fraction of the computation time. ",
    "url": "https://arxiv.org/abs/2403.18664",
    "authors": [
      "Olov Holmer",
      "Erik Frisk",
      "Mattias Krysander"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.18734",
    "title": "A vascular synthetic model for improved aneurysm segmentation and  detection via Deep Neural Networks",
    "abstract": "We hereby present a full synthetic model, able to mimic the various constituents of the cerebral vascular tree: the cerebral arteries, the bifurcations and the intracranial aneurysms. By building this model, our goal was to provide a substantial dataset of brain arteries which could be used by a 3D Convolutional Neural Network (CNN) to either segment or detect/recognize various vascular diseases (such as artery dissection/thrombosis) or even some portions of the cerebral vasculature, such as the bifurcations or aneurysms. In this study, we will particularly focus on Intra-Cranial Aneurysm (ICA) detection and segmentation. The cerebral aneurysms most often occur on a particular structure of the vascular tree named the Circle of Willis. Various studies have been conducted to detect and monitor the ICAs and those based on Deep Learning (DL) achieve the best performances. Specifically, in this work, we propose a full synthetic 3D model able to mimic the brain vasculature as acquired by Magnetic Resonance Angiography (MRA), and more particularly the Time Of Flight (TOF) principle. Among the various MRI modalities, the MRA-TOF allows to have a relatively good rendering of the blood vessels and is non-invasive (no contrast liquid injection). Our model has been designed to simultaneously mimic the arteries geometry, the ICA shape and the background noise. The geometry of the vascular tree is modeled thanks to an interpolation with 3D Spline functions, and the statistical properties of the background MRI noise is collected from MRA acquisitions and reproduced within the model. In this work, we thoroughly describe the synthetic vasculature model, we build up a neural network designed for ICA segmentation and detection, and finally, we carry out an in-depth evaluation of the performance gap gained thanks to the synthetic model data augmentation. ",
    "url": "https://arxiv.org/abs/2403.18734",
    "authors": [
      "Rafic Nader",
      "Florent Autrusseau",
      "Vincent L'Allinec",
      "Romain Bourcier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1904.07184",
    "title": "A monotone scheme for G-equations with application to the explicit  convergence rate of robust central limit theorem",
    "abstract": " Comments: 33 pages ",
    "url": "https://arxiv.org/abs/1904.07184",
    "authors": [
      "Shuo Huang",
      "Gechun Liang"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2109.00970",
    "title": "A Construction of 2-D Z-Complementary Array Code Sets with Flexible Even  Row Lengths and Applications in Massive MIMO",
    "abstract": " Title: A Construction of 2-D Z-Complementary Array Code Sets with Flexible Even  Row Lengths and Applications in Massive MIMO ",
    "url": "https://arxiv.org/abs/2109.00970",
    "authors": [
      "Abhishek Roy",
      "Sudhan Majhi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2204.11041",
    "title": "Learning by Erasing: Conditional Entropy based Transferable  Out-Of-Distribution Detection",
    "abstract": " Comments: update new experimental results ",
    "url": "https://arxiv.org/abs/2204.11041",
    "authors": [
      "Meng Xing",
      "Zhiyong Feng",
      "Yong Su",
      "Changjae Oh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.02200",
    "title": "Task-wise Sampling Convolutions for Arbitrary-Oriented Object Detection  in Aerial Images",
    "abstract": " Comments: 15 pages, 13 figures, 11 tables ",
    "url": "https://arxiv.org/abs/2209.02200",
    "authors": [
      "Zhanchao Huang",
      "Wei Li",
      "Xiang-Gen Xia",
      "Hao Wang",
      "Ran Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.17126",
    "title": "BEVUDA: Multi-geometric Space Alignments for Domain Adaptive BEV 3D  Object Detection",
    "abstract": " Comments: Accepted by ICRA2024 ",
    "url": "https://arxiv.org/abs/2211.17126",
    "authors": [
      "Jiaming Liu",
      "Rongyu Zhang",
      "Xiaoqi Li",
      "Xiaowei Chi",
      "Zehui Chen",
      "Ming Lu",
      "Yandong Guo",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.02505",
    "title": "Nested Dirichlet models for unsupervised attack pattern detection in  honeypot data",
    "abstract": " Title: Nested Dirichlet models for unsupervised attack pattern detection in  honeypot data ",
    "url": "https://arxiv.org/abs/2301.02505",
    "authors": [
      "Francesco Sanna Passino",
      "Anastasia Mantziou",
      "Daniyar Ghani",
      "Philip Thiede",
      "Ross Bevington",
      "Nicholas A. Heard"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2302.06912",
    "title": "Regret-Based Defense in Adversarial Reinforcement Learning",
    "abstract": " Comments: Accepted at AAMAS 2024 ",
    "url": "https://arxiv.org/abs/2302.06912",
    "authors": [
      "Roman Belaire",
      "Pradeep Varakantham",
      "Thanh Nguyen",
      "David Lo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.09817",
    "title": "Interpretable machine learning for time-to-event prediction in medicine  and healthcare",
    "abstract": " Comments: An extended version of an AIME 2023 paper submitted to Artificial Intelligence in Medicine ",
    "url": "https://arxiv.org/abs/2303.09817",
    "authors": [
      "Hubert Baniecki",
      "Bartlomiej Sobieski",
      "Patryk Szatkowski",
      "Przemyslaw Bombinski",
      "Przemyslaw Biecek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2303.17251",
    "title": "Demystifying Misconceptions in Social Bots Research",
    "abstract": " Title: Demystifying Misconceptions in Social Bots Research ",
    "url": "https://arxiv.org/abs/2303.17251",
    "authors": [
      "Stefano Cresci",
      "Kai-Cheng Yang",
      "Angelo Spognardi",
      "Roberto Di Pietro",
      "Filippo Menczer",
      "Marinella Petrocchi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.06427",
    "title": "In-Distribution and Out-of-Distribution Self-supervised ECG  Representation Learning for Arrhythmia Detection",
    "abstract": " Comments: This paper has been published in the IEEE Journal of Biomedical and Health Informatics (JBHI). Copyright IEEE. Please cite as: S. Soltanieh, J. Hashemi and A. Etemad, \"In-Distribution and Out-of-Distribution Self-Supervised ECG Representation Learning for Arrhythmia Detection,\" in IEEE Journal of Biomedical and Health Informatics, vol. 28, no. 2, pp. 789-800, Feb. 2024 ",
    "url": "https://arxiv.org/abs/2304.06427",
    "authors": [
      "Sahar Soltanieh",
      "Javad Hashemi",
      "Ali Etemad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.02151",
    "title": "Identifying the Correlation Between Language Distance and Cross-Lingual  Transfer in a Multilingual Representation Space",
    "abstract": " Comments: SIGTYP Workshop 2023 (co-located with EACL 2023) ",
    "url": "https://arxiv.org/abs/2305.02151",
    "authors": [
      "Fred Philippy",
      "Siwen Guo",
      "Shohreh Haddadan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12523",
    "title": "Multi-Static Target Detection and Power Allocation for Integrated  Sensing and Communication in Cell-Free Massive MIMO",
    "abstract": " Comments: 16 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2305.12523",
    "authors": [
      "Zinat Behdad",
      "\u00d6zlem Tu\u011ffe Demir",
      "Ki Won Sung",
      "Emil Bj\u00f6rnson",
      "Cicek Cavdar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.02928",
    "title": "Weakly-Supervised Conditional Embedding for Referred Visual Search",
    "abstract": " Comments: 28 pages, 13 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2306.02928",
    "authors": [
      "Simon Lepage",
      "J\u00e9r\u00e9mie Mary",
      "David Picard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.08304",
    "title": "Chart2Vec: A Universal Embedding of Context-Aware Visualizations",
    "abstract": " Title: Chart2Vec: A Universal Embedding of Context-Aware Visualizations ",
    "url": "https://arxiv.org/abs/2306.08304",
    "authors": [
      "Qing Chen",
      "Ying Chen",
      "Ruishi Zou",
      "Wei Shuai",
      "Yi Guo",
      "Jiazhe Wang",
      "Nan Cao"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2307.02203",
    "title": "Neural Fields for Interactive Visualization of Statistical Dependencies  in 3D Simulation Ensembles",
    "abstract": " Title: Neural Fields for Interactive Visualization of Statistical Dependencies  in 3D Simulation Ensembles ",
    "url": "https://arxiv.org/abs/2307.02203",
    "authors": [
      "Fatemeh Farokhmanesh",
      "Kevin H\u00f6hlein",
      "Christoph Neuhauser",
      "Tobias Necker",
      "Martin Weissmann",
      "Takemasa Miyoshi",
      "R\u00fcdiger Westermann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07572",
    "title": "High-Rate Phase Association with Travel Time Neural Fields",
    "abstract": " Title: High-Rate Phase Association with Travel Time Neural Fields ",
    "url": "https://arxiv.org/abs/2307.07572",
    "authors": [
      "Cheng Shi",
      "Maarten V. de Hoop",
      "Ivan Dokmani\u0107"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.09136",
    "title": "The Effects of Mixed Sample Data Augmentation are Class Dependent",
    "abstract": " Comments: 21 pages, 18 figures, Overall Revision ",
    "url": "https://arxiv.org/abs/2307.09136",
    "authors": [
      "Haeil Lee",
      "Hansang Lee",
      "Junmo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.16075",
    "title": "Redesigning Large-Scale Multimodal Transit Networks with Shared  Autonomous Mobility Services",
    "abstract": " Comments: 48 pages, 18 figures, accepted for publication in Transportation Research Part C: Emerging Technologies, and presentation in the 25th International Symposium on Transportation and Traffic Theory (ISTTT25) ",
    "url": "https://arxiv.org/abs/2307.16075",
    "authors": [
      "Max T.M. Ng",
      "Hani S. Mahmassani",
      "\u00d6mer Verbas",
      "Taner Cokyasar",
      "Roman Engelhardt"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2308.02396",
    "title": "HOOD: Real-Time Human Presence and Out-of-Distribution Detection Using  FMCW Radar",
    "abstract": " Comments: 10 pages, 2 figures, project page: this https URL ",
    "url": "https://arxiv.org/abs/2308.02396",
    "authors": [
      "Sabri Mustafa Kahya",
      "Muhammet Sami Yavuz",
      "Eckehard Steinbach"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06822",
    "title": "Approximate and Weighted Data Reconstruction Attack in Federated  Learning",
    "abstract": " Title: Approximate and Weighted Data Reconstruction Attack in Federated  Learning ",
    "url": "https://arxiv.org/abs/2308.06822",
    "authors": [
      "Yongcun Song",
      "Ziqi Wang",
      "Enrique Zuazua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2308.10483",
    "title": "Aggregate Model of District Heating Network for Integrated Energy  Dispatch: A Physically Informed Data-Driven Approach",
    "abstract": " Title: Aggregate Model of District Heating Network for Integrated Energy  Dispatch: A Physically Informed Data-Driven Approach ",
    "url": "https://arxiv.org/abs/2308.10483",
    "authors": [
      "Shuai Lu",
      "Zihang Gao",
      "Yong Sun",
      "Suhan Zhang",
      "Baoju Li",
      "Chengliang Hao",
      "Yijun Xu",
      "Wei Gu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.11138",
    "title": "NLP-based detection of systematic anomalies among the narratives of  consumer complaints",
    "abstract": " Title: NLP-based detection of systematic anomalies among the narratives of  consumer complaints ",
    "url": "https://arxiv.org/abs/2308.11138",
    "authors": [
      "Peiheng Gao",
      "Ning Sun",
      "Xuefeng Wang",
      "Chen Yang",
      "Ri\u010dardas Zitikis"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Computation and Language (cs.CL)",
      "Risk Management (q-fin.RM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.12531",
    "title": "CARE: Co-Attention Network for Joint Entity and Relation Extraction",
    "abstract": " Comments: Accepted by LREC-COLING 2024 ",
    "url": "https://arxiv.org/abs/2308.12531",
    "authors": [
      "Wenjun Kong",
      "Yamei Xia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.12882",
    "title": "LCANets++: Robust Audio Classification using Multi-layer Neural Networks  with Lateral Competition",
    "abstract": " Comments: Accepted at 2024 IEEE International Conference on Acoustics, Speech and Signal Processing Workshops (ICASSPW) ",
    "url": "https://arxiv.org/abs/2308.12882",
    "authors": [
      "Sayanton V. Dibbo",
      "Juston S. Moore",
      "Garrett T. Kenyon",
      "Michael A. Teti"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.13356",
    "title": "CEIMVEN: An Approach of Cutting Edge Implementation of Modified Versions  of EfficientNet (V1-V2) Architecture for Breast Cancer Detection and  Classification from Ultrasound Images",
    "abstract": " Title: CEIMVEN: An Approach of Cutting Edge Implementation of Modified Versions  of EfficientNet (V1-V2) Architecture for Breast Cancer Detection and  Classification from Ultrasound Images ",
    "url": "https://arxiv.org/abs/2308.13356",
    "authors": [
      "Sheekar Banerjee",
      "Md. Kamrul Hasan Monir"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11427",
    "title": "Generative Pre-Training of Time-Series Data for Unsupervised Fault  Detection in Semiconductor Manufacturing",
    "abstract": " Title: Generative Pre-Training of Time-Series Data for Unsupervised Fault  Detection in Semiconductor Manufacturing ",
    "url": "https://arxiv.org/abs/2309.11427",
    "authors": [
      "Sewoong Lee",
      "JinKyou Choi",
      "Min Su Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11798",
    "title": "A Comprehensive Review of Community Detection in Graphs",
    "abstract": " Title: A Comprehensive Review of Community Detection in Graphs ",
    "url": "https://arxiv.org/abs/2309.11798",
    "authors": [
      "Jiakang Li",
      "Songning Lai",
      "Zhihao Shuai",
      "Yuan Tan",
      "Yifan Jia",
      "Mianyang Yu",
      "Zichen Song",
      "Xiaokang Peng",
      "Ziyang Xu",
      "Yongxin Ni",
      "Haifeng Qiu",
      "Jiayu Yang",
      "Yutong Liu",
      "Yonggang Lu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.03325",
    "title": "Learning Concept-Based Causal Transition and Symbolic Reasoning for  Visual Planning",
    "abstract": " Title: Learning Concept-Based Causal Transition and Symbolic Reasoning for  Visual Planning ",
    "url": "https://arxiv.org/abs/2310.03325",
    "authors": [
      "Yilue Qian",
      "Peiyu Yu",
      "Ying Nian Wu",
      "Yao Su",
      "Wei Wang",
      "Lifeng Fan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01191",
    "title": "VIGraph: Generative Self-supervised Learning for Class-Imbalanced Node  Classification",
    "abstract": " Title: VIGraph: Generative Self-supervised Learning for Class-Imbalanced Node  Classification ",
    "url": "https://arxiv.org/abs/2311.01191",
    "authors": [
      "Yulan Hu",
      "Sheng Ouyang",
      "Zhirui Yang",
      "Yong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01483",
    "title": "FedSN: A Novel Federated Learning Framework over LEO Satellite Networks",
    "abstract": " Comments: 14 pages, 17 figures ",
    "url": "https://arxiv.org/abs/2311.01483",
    "authors": [
      "Zheng Lin",
      "Zhe Chen",
      "Zihan Fang",
      "Xianhao Chen",
      "Xiong Wang",
      "Yue Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.03683",
    "title": "Preventing Arbitrarily High Confidence on Far-Away Data in  Point-Estimated Discriminative Neural Networks",
    "abstract": " Comments: Accepted at AISTATS 2024 ",
    "url": "https://arxiv.org/abs/2311.03683",
    "authors": [
      "Ahmad Rashid",
      "Serena Hacker",
      "Guojun Zhang",
      "Agustinus Kristiadi",
      "Pascal Poupart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.07335",
    "title": "Throughput Maximization in Multi-Band Optical Networks with Column  Generation",
    "abstract": " Comments: 6 pages, 4 figures, accepted by IEEE International Conference on Communications 2024 (ICC2024) ",
    "url": "https://arxiv.org/abs/2311.07335",
    "authors": [
      "Cao Chen",
      "Shilin Xiao",
      "Fen Zhou",
      "Massimo Tornatore"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2311.08100",
    "title": "PPAD: Iterative Interactions of Prediction and Planning for End-to-end  Autonomous Driving",
    "abstract": " Title: PPAD: Iterative Interactions of Prediction and Planning for End-to-end  Autonomous Driving ",
    "url": "https://arxiv.org/abs/2311.08100",
    "authors": [
      "Zhili Chen",
      "Maosheng Ye",
      "Shuangjie Xu",
      "Tongyi Cao",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.10319",
    "title": "Shifting to Machine Supervision: Annotation-Efficient Semi and  Self-Supervised Learning for Automatic Medical Image Segmentation and  Classification",
    "abstract": " Comments: Seventeen pages (incl. references), five figures, and one table. (Under Review) ",
    "url": "https://arxiv.org/abs/2311.10319",
    "authors": [
      "Pranav Singh",
      "Raviteja Chukkapalli",
      "Shravan Chaudhari",
      "Luoyao Chen",
      "Mei Chen",
      "Jinqian Pan",
      "Craig Smuda",
      "Jacopo Cirrone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.13888",
    "title": "On the robustness of high-order upwind summation-by-parts methods for  nonlinear conservation laws",
    "abstract": " Title: On the robustness of high-order upwind summation-by-parts methods for  nonlinear conservation laws ",
    "url": "https://arxiv.org/abs/2311.13888",
    "authors": [
      "Hendrik Ranocha",
      "Andrew R. Winters",
      "Michael Schlottke-Lakemper",
      "Philipp \u00d6ffner",
      "Jan Glaubitz",
      "Gregor J. Gassner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2311.15803",
    "title": "SOAC: Spatio-Temporal Overlap-Aware Multi-Sensor Calibration using  Neural Radiance Fields",
    "abstract": " Comments: Accepted at CVPR 2024. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2311.15803",
    "authors": [
      "Quentin Herau",
      "Nathan Piasco",
      "Moussab Bennehar",
      "Luis Rold\u00e3o",
      "Dzmitry Tsishkou",
      "Cyrille Migniot",
      "Pascal Vasseur",
      "C\u00e9dric Demonceaux"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.17456",
    "title": "DifFlow3D: Toward Robust Uncertainty-Aware Scene Flow Estimation with  Iterative Diffusion-Based Refinement",
    "abstract": " Comments: Camera-ready version of CVPR 2024. Codes are released at this https URL ",
    "url": "https://arxiv.org/abs/2311.17456",
    "authors": [
      "Jiuming Liu",
      "Guangming Wang",
      "Weicai Ye",
      "Chaokang Jiang",
      "Jinru Han",
      "Zhe Liu",
      "Guofeng Zhang",
      "Dalong Du",
      "Hesheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.18113",
    "title": "Back to 3D: Few-Shot 3D Keypoint Detection with Back-Projected 2D  Features",
    "abstract": " Comments: Accepted to CVPR 2024, Project page: this https URL ",
    "url": "https://arxiv.org/abs/2311.18113",
    "authors": [
      "Thomas Wimmer",
      "Peter Wonka",
      "Maks Ovsjanikov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2312.01220",
    "title": "Boosting Object Detection with Zero-Shot Day-Night Domain Adaptation",
    "abstract": " Comments: Accepted to CVPR 2024 ",
    "url": "https://arxiv.org/abs/2312.01220",
    "authors": [
      "Zhipeng Du",
      "Miaojing Shi",
      "Jiankang Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.03256",
    "title": "CAFE: Towards Compact, Adaptive, and Fast Embedding for Large-scale  Recommendation Models",
    "abstract": " Title: CAFE: Towards Compact, Adaptive, and Fast Embedding for Large-scale  Recommendation Models ",
    "url": "https://arxiv.org/abs/2312.03256",
    "authors": [
      "Hailin Zhang",
      "Zirui Liu",
      "Boxuan Chen",
      "Yikai Zhao",
      "Tong Zhao",
      "Tong Yang",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.10842",
    "title": "Compositional Inductive Invariant Based Verification of Neural Network  Controlled Systems",
    "abstract": " Title: Compositional Inductive Invariant Based Verification of Neural Network  Controlled Systems ",
    "url": "https://arxiv.org/abs/2312.10842",
    "authors": [
      "Yuhao Zhou",
      "Stavros Tripakis"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.13094",
    "title": "Automated MPI code generation for scalable finite-difference solvers",
    "abstract": " Comments: 10 pages, 12 figures (18 pages with References and Appendix) ",
    "url": "https://arxiv.org/abs/2312.13094",
    "authors": [
      "George Bisbas",
      "Rhodri Nelson",
      "Mathias Louboutin",
      "Paul H.J. Kelly",
      "Fabio Luporini",
      "Gerard Gorman"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Mathematical Software (cs.MS)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2312.16943",
    "title": "SAR-Net: Multi-scale Direction-aware SAR Network via Global Information  Fusion",
    "abstract": " Title: SAR-Net: Multi-scale Direction-aware SAR Network via Global Information  Fusion ",
    "url": "https://arxiv.org/abs/2312.16943",
    "authors": [
      "Mingxiang Cao",
      "Jie Lei",
      "Weiying Xie",
      "Jiaqing Zhang",
      "Daixun Li",
      "Yunsong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01647",
    "title": "SIGNeRF: Scene Integrated Generation for Neural Radiance Fields",
    "abstract": " Comments: Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2401.01647",
    "authors": [
      "Jan-Niklas Dihlmann",
      "Andreas Engelhardt",
      "Hendrik Lensch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2401.02379",
    "title": "Detection and Discovery of Misinformation Sources using Attributed  Webgraphs",
    "abstract": " Title: Detection and Discovery of Misinformation Sources using Attributed  Webgraphs ",
    "url": "https://arxiv.org/abs/2401.02379",
    "authors": [
      "Peter Carragher",
      "Evan M. Williams",
      "Kathleen M. Carley"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2401.06712",
    "title": "Few-Shot Detection of Machine-Generated Text using Style Representations",
    "abstract": " Title: Few-Shot Detection of Machine-Generated Text using Style Representations ",
    "url": "https://arxiv.org/abs/2401.06712",
    "authors": [
      "Rafael Rivera Soto",
      "Kailin Koch",
      "Aleem Khan",
      "Barry Chen",
      "Marcus Bishop",
      "Nicholas Andrews"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.07494",
    "title": "Input Convex Lipschitz RNN: A Fast and Robust Approach for Engineering  Tasks",
    "abstract": " Title: Input Convex Lipschitz RNN: A Fast and Robust Approach for Engineering  Tasks ",
    "url": "https://arxiv.org/abs/2401.07494",
    "authors": [
      "Zihao Wang",
      "P S Pravin",
      "Zhe Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2401.11542",
    "title": "Nigel -- Mechatronic Design and Robust Sim2Real Control of an  Over-Actuated Autonomous Vehicle",
    "abstract": " Title: Nigel -- Mechatronic Design and Robust Sim2Real Control of an  Over-Actuated Autonomous Vehicle ",
    "url": "https://arxiv.org/abs/2401.11542",
    "authors": [
      "Chinmay Vilas Samak",
      "Tanmay Vilas Samak",
      "Javad Mohammadpour Velni",
      "Venkat Narayan Krovi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2401.17879",
    "title": "AEROBLADE: Training-Free Detection of Latent Diffusion Images Using  Autoencoder Reconstruction Error",
    "abstract": " Comments: Accepted to CVPR 2024 ",
    "url": "https://arxiv.org/abs/2401.17879",
    "authors": [
      "Jonas Ricker",
      "Denis Lukovnikov",
      "Asja Fischer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.01216",
    "title": "Robust Commutation Design: Applied to Switched Reluctance Motors",
    "abstract": " Comments: 6 pages, 7 figures. Final version ",
    "url": "https://arxiv.org/abs/2402.01216",
    "authors": [
      "Max van Meer",
      "Gert Witvoet",
      "Tom Oomen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.13729",
    "title": "Hybrid Video Diffusion Models with 2D Triplane and 3D Wavelet  Representation",
    "abstract": " Comments: 17 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2402.13729",
    "authors": [
      "Kihong Kim",
      "Haneol Lee",
      "Jihye Park",
      "Seyeon Kim",
      "Kwanghee Lee",
      "Seungryong Kim",
      "Jaejun Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.00211",
    "title": "Trustworthy Self-Attention: Enabling the Network to Focus Only on the  Most Relevant References",
    "abstract": " Comments: Correct Figure 1 ",
    "url": "https://arxiv.org/abs/2403.00211",
    "authors": [
      "Yu Jing",
      "Tan Yujuan",
      "Ren Ao",
      "Liu Duo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.03271",
    "title": "Low-Complexity Linear Decoupling of Users for Uplink Massive MU-MIMO  Detection",
    "abstract": " Title: Low-Complexity Linear Decoupling of Users for Uplink Massive MU-MIMO  Detection ",
    "url": "https://arxiv.org/abs/2403.03271",
    "authors": [
      "S. Sowmya",
      "Gokularam Muthukrishnan",
      "K. Giridhar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2403.04125",
    "title": "Scalable and Robust Transformer Decoders for Interpretable Image  Classification with Foundation Models",
    "abstract": " Title: Scalable and Robust Transformer Decoders for Interpretable Image  Classification with Foundation Models ",
    "url": "https://arxiv.org/abs/2403.04125",
    "authors": [
      "Evelyn Mannix",
      "Howard Bondell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.05218",
    "title": "3D Face Reconstruction Using A Spectral-Based Graph Convolution Encoder",
    "abstract": " Comments: 4 pages, 3 figures. Accepted to WWW 2024 ",
    "url": "https://arxiv.org/abs/2403.05218",
    "authors": [
      "Haoxin Xu",
      "Zezheng Zhao",
      "Yuxin Cao",
      "Chunyu Chen",
      "Hao Ge",
      "Ziyao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.06747",
    "title": "MetaSplit: Meta-Split Network for Limited-Stock Product Recommendation",
    "abstract": " Comments: Accepted at WWW 2024. This work has already been deployed on the Xianyu platform in Alibaba. The first two authors contributed equally ",
    "url": "https://arxiv.org/abs/2403.06747",
    "authors": [
      "Wenhao Wu",
      "Jialiang Zhou",
      "Ailong He",
      "Shuguang Han",
      "Jufeng Chen",
      "Bo Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2403.07392",
    "title": "ViT-CoMer: Vision Transformer with Convolutional Multi-scale Feature  Interaction for Dense Predictions",
    "abstract": " Comments: CVPR2024 ",
    "url": "https://arxiv.org/abs/2403.07392",
    "authors": [
      "Chunlong Xia",
      "Xinliang Wang",
      "Feng Lv",
      "Xin Hao",
      "Yifeng Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.09069",
    "title": "Dyadic Interaction Modeling for Social Behavior Generation",
    "abstract": " Title: Dyadic Interaction Modeling for Social Behavior Generation ",
    "url": "https://arxiv.org/abs/2403.09069",
    "authors": [
      "Minh Tran",
      "Di Chang",
      "Maksim Siniukov",
      "Mohammad Soleymani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10158",
    "title": "Functional Graph Convolutional Networks: A unified multi-task and  multi-modal learning framework to facilitate health and social-care insights",
    "abstract": " Title: Functional Graph Convolutional Networks: A unified multi-task and  multi-modal learning framework to facilitate health and social-care insights ",
    "url": "https://arxiv.org/abs/2403.10158",
    "authors": [
      "Tobia Boschi",
      "Francesca Bonin",
      "Rodrigo Ordonez-Hurtado",
      "C\u00e9cile Rousseau",
      "Alessandra Pascale",
      "John Dinsmore"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.11107",
    "title": "Self-supervised co-salient object detection via feature correspondence  at multiple scales",
    "abstract": " Title: Self-supervised co-salient object detection via feature correspondence  at multiple scales ",
    "url": "https://arxiv.org/abs/2403.11107",
    "authors": [
      "Souradeep Chakraborty",
      "Dimitris Samaras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11656",
    "title": "LocalStyleFool: Regional Video Style Transfer Attack Using Segment  Anything Model",
    "abstract": " Comments: Accepted to 2024 IEEE Security and Privacy Workshops (SPW) ",
    "url": "https://arxiv.org/abs/2403.11656",
    "authors": [
      "Yuxin Cao",
      "Jinghao Li",
      "Xi Xiao",
      "Derui Wang",
      "Minhui Xue",
      "Hao Ge",
      "Wei Liu",
      "Guangwu Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.15098",
    "title": "UniTraj: A Unified Framework for Scalable Vehicle Trajectory Prediction",
    "abstract": " Title: UniTraj: A Unified Framework for Scalable Vehicle Trajectory Prediction ",
    "url": "https://arxiv.org/abs/2403.15098",
    "authors": [
      "Lan Feng",
      "Mohammadhossein Bahari",
      "Kaouther Messaoud Ben Amor",
      "\u00c9loi Zablocki",
      "Matthieu Cord",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.15201",
    "title": "Flip-Breakability: A Combinatorial Dichotomy for Monadically Dependent  Graph Classes",
    "abstract": " Comments: v2: added section \"Conclusions and Future Work\" ",
    "url": "https://arxiv.org/abs/2403.15201",
    "authors": [
      "Jan Dreier",
      "Nikolas M\u00e4hlmann",
      "Szymon Toru\u0144czyk"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ]
  },
  {
    "id": "arXiv:2403.15721",
    "title": "Design and Implementation of an Analysis Pipeline for Heterogeneous Data",
    "abstract": " Comments: 14 pages, 16 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2403.15721",
    "authors": [
      "Arup Kumar Sarker",
      "Aymen Alsaadi",
      "Niranda Perera",
      "Mills Staylor",
      "Gregor von Laszewski",
      "Matteo Turilli",
      "Ozgur Ozan Kilic",
      "Mikhail Titov",
      "Andre Merzky",
      "Shantenu Jha",
      "Geoffrey Fox"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2403.16335",
    "title": "MEDDAP: Medical Dataset Enhancement via Diversified Augmentation  Pipeline",
    "abstract": " Comments: submitted to miccai 2024 submitted to miccai 2024 Submitted to MICCAI-2024 ",
    "url": "https://arxiv.org/abs/2403.16335",
    "authors": [
      "Yasamin Medghalchi",
      "Niloufar Zakariaei",
      "Arman Rahmim",
      "Ilker Hacihaliloglu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16432",
    "title": "$\\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on  Prompt-based Language Models",
    "abstract": " Comments: Accepted to the main conference of NAACL2024 ",
    "url": "https://arxiv.org/abs/2403.16432",
    "authors": [
      "Yue Xu",
      "Wenjie Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16451",
    "title": "DeepMachining: Online Prediction of Machining Errors of Lathe Machines",
    "abstract": " Title: DeepMachining: Online Prediction of Machining Errors of Lathe Machines ",
    "url": "https://arxiv.org/abs/2403.16451",
    "authors": [
      "Xiang-Li Lu",
      "Hwai-Jung Hsu",
      "Che-Wei Chou",
      "H. T. Kung",
      "Chen-Hsin Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.17165",
    "title": "Building an Open-Source Community to Enhance Autonomic Nervous System  Signal Analysis: DBDP-Autonomic",
    "abstract": " Title: Building an Open-Source Community to Enhance Autonomic Nervous System  Signal Analysis: DBDP-Autonomic ",
    "url": "https://arxiv.org/abs/2403.17165",
    "authors": [
      "Jessilyn Dunn",
      "Varun Mishra",
      "Md Mobashir Hasan Shandhi",
      "Hayoung Jeong",
      "Natasha Yamane",
      "Yuna Watanabe",
      "Matthew S. Goodwin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2403.17301",
    "title": "Physical 3D Adversarial Attacks against Monocular Depth Estimation in  Autonomous Driving",
    "abstract": " Comments: Accepted by CVPR 2024 ",
    "url": "https://arxiv.org/abs/2403.17301",
    "authors": [
      "Junhao Zheng",
      "Chenhao Lin",
      "Jiahao Sun",
      "Zhengyu Zhao",
      "Qian Li",
      "Chao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.17458",
    "title": "Expectations Versus Reality: Evaluating Intrusion Detection Systems in  Practice",
    "abstract": " Comments: 10 pages ",
    "url": "https://arxiv.org/abs/2403.17458",
    "authors": [
      "Jake Hesford",
      "Daniel Cheng",
      "Alan Wan",
      "Larry Huynh",
      "Seungho Kim",
      "Hyoungshick Kim",
      "Jin B. Hong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.17647",
    "title": "Intrinsic Subgraph Generation for Interpretable Graph based Visual  Question Answering",
    "abstract": " Comments: Accepted at LREC-COLING 2024 ",
    "url": "https://arxiv.org/abs/2403.17647",
    "authors": [
      "Pascal Tilli",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  }
]