[
  {
    "id": "arXiv:2403.15393",
    "title": "Detection of Opioid Users from Reddit Posts via an Attention-based  Bidirectional Recurrent Neural Network",
    "abstract": "The opioid epidemic, referring to the growing hospitalizations and deaths because of overdose of opioid usage and addiction, has become a severe health problem in the United States. Many strategies have been developed by the federal and local governments and health communities to combat this crisis. Among them, improving our understanding of the epidemic through better health surveillance is one of the top priorities. In addition to direct testing, machine learning approaches may also allow us to detect opioid users by analyzing data from social media because many opioid users may choose not to do the tests but may share their experiences on social media anonymously. In this paper, we take advantage of recent advances in machine learning, collect and analyze user posts from a popular social network Reddit with the goal to identify opioid users. Posts from more than 1,000 users who have posted on three sub-reddits over a period of one month have been collected. In addition to the ones that contain keywords such as opioid, opiate, or heroin, we have also collected posts that contain slang words of opioid such as black or chocolate. We apply an attention-based bidirectional long short memory model to identify opioid users. Experimental results show that the approaches significantly outperform competitive algorithms in terms of F1-score. Furthermore, the model allows us to extract most informative words, such as opiate, opioid, and black, from posts via the attention layer, which provides more insights on how the machine learning algorithm works in distinguishing drug users from non-drug users. ",
    "url": "https://arxiv.org/abs/2403.15393",
    "authors": [
      "Yuchen Wang",
      "Zhengyu Fang",
      "Wei Du",
      "Shuai Xu",
      "Rong Xu",
      "Jing Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.15419",
    "title": "Attention is all you need for boosting graph convolutional neural  network",
    "abstract": "Graph Convolutional Neural Networks (GCNs) possess strong capabilities for processing graph data in non-grid domains. They can capture the topological logical structure and node features in graphs and integrate them into nodes' final representations. GCNs have been extensively studied in various fields, such as recommendation systems, social networks, and protein molecular structures. With the increasing application of graph neural networks, research has focused on improving their performance while compressing their size. In this work, a plug-in module named Graph Knowledge Enhancement and Distillation Module (GKEDM) is proposed. GKEDM can enhance node representations and improve the performance of GCNs by extracting and aggregating graph information via multi-head attention mechanism. Furthermore, GKEDM can serve as an auxiliary transferor for knowledge distillation. With a specially designed attention distillation method, GKEDM can distill the knowledge of large teacher models into high-performance and compact student models. Experiments on multiple datasets demonstrate that GKEDM can significantly improve the performance of various GCNs with minimal overhead. Furthermore, it can efficiently transfer distilled knowledge from large teacher networks to small student networks via attention distillation. ",
    "url": "https://arxiv.org/abs/2403.15419",
    "authors": [
      "Yinwei Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Graphics (cs.GR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.15445",
    "title": "Decoding Multilingual Topic Dynamics and Trend Identification through  ARIMA Time Series Analysis on Social Networks: A Novel Data Translation  Framework Enhanced by LDA/HDP Models",
    "abstract": "In this study, the authors present a novel methodology adept at decoding multilingual topic dynamics and identifying communication trends during crises. We focus on dialogues within Tunisian social networks during the Coronavirus Pandemic and other notable themes like sports and politics. We start by aggregating a varied multilingual corpus of comments relevant to these subjects. This dataset undergoes rigorous refinement during data preprocessing. We then introduce our No-English-to-English Machine Translation approach to handle linguistic differences. Empirical tests of this method showed high accuracy and F1 scores, highlighting its suitability for linguistically coherent tasks. Delving deeper, advanced modeling techniques, specifically LDA and HDP models are employed to extract pertinent topics from the translated content. This leads to applying ARIMA time series analysis to decode evolving topic trends. Applying our method to a multilingual Tunisian dataset, we effectively identified key topics mirroring public sentiment. Such insights prove vital for organizations and governments striving to understand public perspectives during crises. Compared to standard approaches, our model outperforms, as confirmed by metrics like Coherence Score, U-mass, and Topic Coherence. Additionally, an in-depth assessment of the identified topics revealed notable thematic shifts in discussions, with our trends identification indicating impressive accuracy, backed by RMSE-based analysis. ",
    "url": "https://arxiv.org/abs/2403.15445",
    "authors": [
      "Samawel Jaballi",
      "Azer Mahjoubi",
      "Manar Joundy Hazar",
      "Salah Zrigui",
      "Henri Nicolas",
      "Mounir Zrigui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.15454",
    "title": "Emotion Detection with Transformers: A Comparative Study",
    "abstract": "In this study, we explore the application of transformer-based models for emotion classification on text data. We train and evaluate several pre-trained transformer models, on the Emotion dataset using different variants of transformers. The paper also analyzes some factors that in-fluence the performance of the model, such as the fine-tuning of the transformer layer, the trainability of the layer, and the preprocessing of the text data. Our analysis reveals that commonly applied techniques like removing punctuation and stop words can hinder model performance. This might be because transformers strength lies in understanding contextual relationships within text. Elements like punctuation and stop words can still convey sentiment or emphasis and removing them might disrupt this context. ",
    "url": "https://arxiv.org/abs/2403.15454",
    "authors": [
      "Mahdi Rezapour"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2403.15463",
    "title": "Unveiling the Anomalies in an Ever-Changing World: A Benchmark for  Pixel-Level Anomaly Detection in Continual Learning",
    "abstract": "Anomaly Detection is a relevant problem in numerous real-world applications, especially when dealing with images. However, little attention has been paid to the issue of changes over time in the input data distribution, which may cause a significant decrease in performance. In this study, we investigate the problem of Pixel-Level Anomaly Detection in the Continual Learning setting, where new data arrives over time and the goal is to perform well on new and old data. We implement several state-of-the-art techniques to solve the Anomaly Detection problem in the classic setting and adapt them to work in the Continual Learning setting. To validate the approaches, we use a real-world dataset of images with pixel-based anomalies to provide a reliable benchmark and serve as a foundation for further advancements in the field. We provide a comprehensive analysis, discussing which Anomaly Detection methods and which families of approaches seem more suitable for the Continual Learning setting. ",
    "url": "https://arxiv.org/abs/2403.15463",
    "authors": [
      "Nikola Bugarin",
      "Jovana Bugaric",
      "Manuel Barusco",
      "Davide Dalle Pezze",
      "Gian Antonio Susto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.15467",
    "title": "Don't be a Fool: Pooling Strategies in Offensive Language Detection from  User-Intended Adversarial Attacks",
    "abstract": "Offensive language detection is an important task for filtering out abusive expressions and improving online user experiences. However, malicious users often attempt to avoid filtering systems through the involvement of textual noises. In this paper, we propose these evasions as user-intended adversarial attacks that insert special symbols or leverage the distinctive features of the Korean language. Furthermore, we introduce simple yet effective pooling strategies in a layer-wise manner to defend against the proposed attacks, focusing on the preceding layers not just the last layer to capture both offensiveness and token embeddings. We demonstrate that these pooling strategies are more robust to performance degradation even when the attack rate is increased, without directly training of such patterns. Notably, we found that models pre-trained on clean texts could achieve a comparable performance in detecting attacked offensive language, to models pre-trained on noisy texts by employing these pooling strategies. ",
    "url": "https://arxiv.org/abs/2403.15467",
    "authors": [
      "Seunguk Yu",
      "Juhwan Choi",
      "Youngbin Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.15469",
    "title": "Isometric Neural Machine Translation using Phoneme Count Ratio  Reward-based Reinforcement Learning",
    "abstract": "Traditional Automatic Video Dubbing (AVD) pipeline consists of three key modules, namely, Automatic Speech Recognition (ASR), Neural Machine Translation (NMT), and Text-to-Speech (TTS). Within AVD pipelines, isometric-NMT algorithms are employed to regulate the length of the synthesized output text. This is done to guarantee synchronization with respect to the alignment of video and audio subsequent to the dubbing process. Previous approaches have focused on aligning the number of characters and words in the source and target language texts of Machine Translation models. However, our approach aims to align the number of phonemes instead, as they are closely associated with speech duration. In this paper, we present the development of an isometric NMT system using Reinforcement Learning (RL), with a focus on optimizing the alignment of phoneme counts in the source and target language sentence pairs. To evaluate our models, we propose the Phoneme Count Compliance (PCC) score, which is a measure of length compliance. Our approach demonstrates a substantial improvement of approximately 36% in the PCC score compared to the state-of-the-art models when applied to English-Hindi language pairs. Moreover, we propose a student-teacher architecture within the framework of our RL approach to maintain a trade-off between the phoneme count and translation quality. ",
    "url": "https://arxiv.org/abs/2403.15469",
    "authors": [
      "Shivam Ratnakant Mhaskar",
      "Nirmesh J. Shah",
      "Mohammadi Zaki",
      "Ashishkumar P. Gudmalwar",
      "Pankaj Wasnik",
      "Rajiv Ratn Shah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2403.15480",
    "title": "SpikeGraphormer: A High-Performance Graph Transformer with Spiking Graph  Attention",
    "abstract": "Recently, Graph Transformers have emerged as a promising solution to alleviate the inherent limitations of Graph Neural Networks (GNNs) and enhance graph representation performance. Unfortunately, Graph Transformers are computationally expensive due to the quadratic complexity inherent in self-attention when applied over large-scale graphs, especially for node tasks. In contrast, spiking neural networks (SNNs), with event-driven and binary spikes properties, can perform energy-efficient computation. In this work, we propose a novel insight into integrating SNNs with Graph Transformers and design a Spiking Graph Attention (SGA) module. The matrix multiplication is replaced by sparse addition and mask operations. The linear complexity enables all-pair node interactions on large-scale graphs with limited GPU memory. To our knowledge, our work is the first attempt to introduce SNNs into Graph Transformers. Furthermore, we design SpikeGraphormer, a Dual-branch architecture, combining a sparse GNN branch with our SGA-driven Graph Transformer branch, which can simultaneously perform all-pair node interactions and capture local neighborhoods. SpikeGraphormer consistently outperforms existing state-of-the-art approaches across various datasets and makes substantial improvements in training time, inference time, and GPU memory cost (10 ~ 20x lower than vanilla self-attention). It also performs well in cross-domain applications (image and text classification). We release our code at https://github.com/PHD-lanyu/SpikeGraphormer. ",
    "url": "https://arxiv.org/abs/2403.15480",
    "authors": [
      "Yundong Sun",
      "Dongjie Zhu",
      "Yansong Wang",
      "Zhaoshuo Tian",
      "Ning Cao",
      "Gregory O'Hared"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.15485",
    "title": "MOGAM: A Multimodal Object-oriented Graph Attention Model for Depression  Detection",
    "abstract": "Early detection plays a crucial role in the treatment of depression. Therefore, numerous studies have focused on social media platforms, where individuals express their emotions, aiming to achieve early detection of depression. However, the majority of existing approaches often rely on specific features, leading to limited scalability across different types of social media datasets, such as text, images, or videos. To overcome this limitation, we introduce a Multimodal Object-Oriented Graph Attention Model (MOGAM), which can be applied to diverse types of data, offering a more scalable and versatile solution. Furthermore, to ensure that our model can capture authentic symptoms of depression, we only include vlogs from users with a clinical diagnosis. To leverage the diverse features of vlogs, we adopt a multimodal approach and collect additional metadata such as the title, description, and duration of the vlogs. To effectively aggregate these multimodal features, we employed a cross-attention mechanism. MOGAM achieved an accuracy of 0.871 and an F1-score of 0.888. Moreover, to validate the scalability of MOGAM, we evaluated its performance with a benchmark dataset and achieved comparable results with prior studies (0.61 F1-score). In conclusion, we believe that the proposed model, MOGAM, is an effective solution for detecting depression in social media, offering potential benefits in the early detection and treatment of this mental health condition. ",
    "url": "https://arxiv.org/abs/2403.15485",
    "authors": [
      "Junyeop Cha",
      "Seoyun Kim",
      "Dongjae Kim",
      "Eunil Park"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.15486",
    "title": "Sequence-to-Sequence Language Models for Character and Emotion Detection  in Dream Narratives",
    "abstract": "The study of dreams has been central to understanding human (un)consciousness, cognition, and culture for centuries. Analyzing dreams quantitatively depends on labor-intensive, manual annotation of dream narratives. We automate this process through a natural language sequence-to-sequence generation framework. This paper presents the first study on character and emotion detection in the English portion of the open DreamBank corpus of dream narratives. Our results show that language models can effectively address this complex task. To get insight into prediction performance, we evaluate the impact of model size, prediction order of characters, and the consideration of proper names and character traits. We compare our approach with a large language model using in-context learning. Our supervised models perform better while having 28 times fewer parameters. Our model and its generated annotations are made publicly available. ",
    "url": "https://arxiv.org/abs/2403.15486",
    "authors": [
      "Gustave Cortal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.15490",
    "title": "Enhancing retrofit device adoption in social housing: evidence from two  field experiments in Belgium",
    "abstract": "Energy efficient technologies are particularly important for social housing settings: they offer the potential to improve tenants' wellbeing through monetary savings and comfort, while reducing emissions of entire communities. Slow uptake of innovative energy technology in social housing has been associated with a lack of trust and the perceived risks of adoption. To counteract both, we designed a communication campaign for a retrofit technology for heating including social norms for technology adoption and concretely experienced benefits. We report two randomized controlled trials (RCT) in two different social housing communities in Belgium. In the first study, randomization was on housing block level: the communication led to significant higher uptake rates compared to the control group. In the second study randomization occurred on apartment level, again yielding a significant increase, when an interaction with housing blocks was considered. We discuss challenges of conducting randomized controlled trials in social housing communities. ",
    "url": "https://arxiv.org/abs/2403.15490",
    "authors": [
      "Mona Bielig",
      "Celina Kacperski",
      "Florian Kutzner"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2403.15497",
    "title": "On the Detection of Anomalous or Out-Of-Distribution Data in Vision  Models Using Statistical Techniques",
    "abstract": "Out-of-distribution data and anomalous inputs are vulnerabilities of machine learning systems today, often causing systems to make incorrect predictions. The diverse range of data on which these models are used makes detecting atypical inputs a difficult and important task. We assess a tool, Benford's law, as a method used to quantify the difference between real and corrupted inputs. We believe that in many settings, it could function as a filter for anomalous data points and for signalling out-of-distribution data. We hope to open a discussion on these applications and further areas where this technique is underexplored. ",
    "url": "https://arxiv.org/abs/2403.15497",
    "authors": [
      "Laura O'Mahony",
      "David JP O'Sullivan",
      "Nikola S. Nikolov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.15499",
    "title": "A Causal Analysis of CO2 Reduction Strategies in Electricity Markets  Through Machine Learning-Driven Metalearners",
    "abstract": "This study employs the Causal Machine Learning (CausalML) statistical method to analyze the influence of electricity pricing policies on carbon dioxide (CO2) levels in the household sector. Investigating the causality between potential outcomes and treatment effects, where changes in pricing policies are the treatment, our analysis challenges the conventional wisdom surrounding incentive-based electricity pricing. The study's findings suggest that adopting such policies may inadvertently increase CO2 intensity. Additionally, we integrate a machine learning-based meta-algorithm, reflecting a contemporary statistical approach, to enhance the depth of our causal analysis. The study conducts a comparative analysis of learners X, T, S, and R to ascertain the optimal methods based on the defined question's specified goals and contextual nuances. This research contributes valuable insights to the ongoing dialogue on sustainable development practices, emphasizing the importance of considering unintended consequences in policy formulation. ",
    "url": "https://arxiv.org/abs/2403.15499",
    "authors": [
      "Iman Emtiazi Naeini",
      "Zahra Saberi",
      "Khadijeh Hassanzadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2403.15509",
    "title": "Twin Auto-Encoder Model for Learning Separable Representation in  Cyberattack Detection",
    "abstract": "Representation Learning (RL) plays a pivotal role in the success of many problems including cyberattack detection. Most of the RL methods for cyberattack detection are based on the latent vector of Auto-Encoder (AE) models. An AE transforms raw data into a new latent representation that better exposes the underlying characteristics of the input data. Thus, it is very useful for identifying cyberattacks. However, due to the heterogeneity and sophistication of cyberattacks, the representation of AEs is often entangled/mixed resulting in the difficulty for downstream attack detection models. To tackle this problem, we propose a novel mod called Twin Auto-Encoder (TAE). TAE deterministically transforms the latent representation into a more distinguishable representation namely the \\textit{separable representation} and the reconstructsuct the separable representation at the output. The output of TAE called the \\textit{reconstruction representation} is input to downstream models to detect cyberattacks. We extensively evaluate the effectiveness of TAE using a wide range of bench-marking datasets. Experiment results show the superior accuracy of TAE over state-of-the-art RL models and well-known machine learning algorithms. Moreover, TAE also outperforms state-of-the-art models on some sophisticated and challenging attacks. We then investigate various characteristics of TAE to further demonstrate its superiority. ",
    "url": "https://arxiv.org/abs/2403.15509",
    "authors": [
      "Phai Vu Dinh",
      "Quang Uy Nguyen",
      "Thai Hoang Dinh",
      "Diep N. Nguyen",
      "Bao Son Pham",
      "Eryk Dutkiewicz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.15511",
    "title": "Multiple-Input Auto-Encoder Guided Feature Selection for IoT Intrusion  Detection Systems",
    "abstract": "While intrusion detection systems (IDSs) benefit from the diversity and generalization of IoT data features, the data diversity (e.g., the heterogeneity and high dimensions of data) also makes it difficult to train effective machine learning models in IoT IDSs. This also leads to potentially redundant/noisy features that may decrease the accuracy of the detection engine in IDSs. This paper first introduces a novel neural network architecture called Multiple-Input Auto-Encoder (MIAE). MIAE consists of multiple sub-encoders that can process inputs from different sources with different characteristics. The MIAE model is trained in an unsupervised learning mode to transform the heterogeneous inputs into lower-dimensional representation, which helps classifiers distinguish between normal behaviour and different types of attacks. To distil and retain more relevant features but remove less important/redundant ones during the training process, we further design and embed a feature selection layer right after the representation layer of MIAE resulting in a new model called MIAEFS. This layer learns the importance of features in the representation vector, facilitating the selection of informative features from the representation vector. The results on three IDS datasets, i.e., NSLKDD, UNSW-NB15, and IDS2017, show the superior performance of MIAE and MIAEFS compared to other methods, e.g., conventional classifiers, dimensionality reduction models, unsupervised representation learning methods with different input dimensions, and unsupervised feature selection models. Moreover, MIAE and MIAEFS combined with the Random Forest (RF) classifier achieve accuracy of 96.5% in detecting sophisticated attacks, e.g., Slowloris. The average running time for detecting an attack sample using RF with the representation of MIAE and MIAEFS is approximate 1.7E-6 seconds, whilst the model size is lower than 1 MB. ",
    "url": "https://arxiv.org/abs/2403.15511",
    "authors": [
      "Phai Vu Dinh",
      "Diep N. Nguyen",
      "Dinh Thai Hoang",
      "Quang Uy Nguyen",
      "Eryk Dutkiewicz",
      "Son Pham Bao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.15512",
    "title": "Enhancing Effectiveness and Robustness in a Low-Resource Regime via  Decision-Boundary-aware Data Augmentation",
    "abstract": "Efforts to leverage deep learning models in low-resource regimes have led to numerous augmentation studies. However, the direct application of methods such as mixup and cutout to text data, is limited due to their discrete characteristics. While methods using pretrained language models have exhibited efficiency, they require additional considerations for robustness. Inspired by recent studies on decision boundaries, this paper proposes a decision-boundary-aware data augmentation strategy to enhance robustness using pretrained language models. The proposed technique first focuses on shifting the latent features closer to the decision boundary, followed by reconstruction to generate an ambiguous version with a soft label. Additionally, mid-K sampling is suggested to enhance the diversity of the generated sentences. This paper demonstrates the performance of the proposed augmentation strategy compared to other methods through extensive experiments. Furthermore, the ablation study reveals the effect of soft labels and mid-K sampling and the extensibility of the method with curriculum data augmentation. ",
    "url": "https://arxiv.org/abs/2403.15512",
    "authors": [
      "Kyohoon Jin",
      "Junho Lee",
      "Juhwan Choi",
      "Sangmin Song",
      "Youngbin Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.15517",
    "title": "Improving Forward Compatibility in Class Incremental Learning by  Increasing Representation Rank and Feature Richness",
    "abstract": "Class Incremental Learning (CIL) constitutes a pivotal subfield within continual learning, aimed at enabling models to progressively learn new classification tasks while retaining knowledge obtained from prior tasks. Although previous studies have predominantly focused on backward compatible approaches to mitigate catastrophic forgetting, recent investigations have introduced forward compatible methods to enhance performance on novel tasks and complement existing backward compatible methods. In this study, we introduce an effective-Rank based Feature Richness enhancement (RFR) method, designed for improving forward compatibility. Specifically, this method increases the effective rank of representations during the base session, thereby facilitating the incorporation of more informative features pertinent to unseen novel tasks. Consequently, RFR achieves dual objectives in backward and forward compatibility: minimizing feature extractor modifications and enhancing novel task performance, respectively. To validate the efficacy of our approach, we establish a theoretical connection between effective rank and the Shannon entropy of representations. Subsequently, we conduct comprehensive experiments by integrating RFR into eleven well-known CIL methods. Our results demonstrate the effectiveness of our approach in enhancing novel-task performance while mitigating catastrophic forgetting. Furthermore, our method notably improves the average incremental accuracy across all eleven cases examined. ",
    "url": "https://arxiv.org/abs/2403.15517",
    "authors": [
      "Jaeill Kim",
      "Wonseok Lee",
      "Moonjung Eo",
      "Wonjong Rhee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.15520",
    "title": "GTC: GNN-Transformer Co-contrastive Learning for Self-supervised  Heterogeneous Graph Representation",
    "abstract": "Graph Neural Networks (GNNs) have emerged as the most powerful weapon for various graph tasks due to the message-passing mechanism's great local information aggregation ability. However, over-smoothing has always hindered GNNs from going deeper and capturing multi-hop neighbors. Unlike GNNs, Transformers can model global information and multi-hop interactions via multi-head self-attention and a proper Transformer structure can show more immunity to the over-smoothing problem. So, can we propose a novel framework to combine GNN and Transformer, integrating both GNN's local information aggregation and Transformer's global information modeling ability to eliminate the over-smoothing problem? To realize this, this paper proposes a collaborative learning scheme for GNN-Transformer and constructs GTC architecture. GTC leverages the GNN and Transformer branch to encode node information from different views respectively, and establishes contrastive learning tasks based on the encoded cross-view information to realize self-supervised heterogeneous graph representation. For the Transformer branch, we propose Metapath-aware Hop2Token and CG-Hetphormer, which can cooperate with GNN to attentively encode neighborhood information from different levels. As far as we know, this is the first attempt in the field of graph representation learning to utilize both GNN and Transformer to collaboratively capture different view information and conduct cross-view contrastive learning. The experiments on real datasets show that GTC exhibits superior performance compared with state-of-the-art methods. Codes can be available at https://github.com/PHD-lanyu/GTC. ",
    "url": "https://arxiv.org/abs/2403.15520",
    "authors": [
      "Yundong Sun",
      "Dongjie Zhu",
      "Yansong Wang",
      "Zhaoshuo Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2403.15547",
    "title": "Approximation Algorithms for Network Design in Non-Uniform Fault Models",
    "abstract": "The Survivable Network Design problem (SNDP) is a well-studied problem, motivated by the design of networks that are robust to faults under the assumption that any subset of edges up to a specific number can fail. We consider non-uniform fault models where the subset of edges that fail can be specified in different ways. Our primary interest is in the flexible graph connectivity model, in which the edge set is partitioned into safe and unsafe edges. The goal is to design a network that has desired connectivity properties under the assumption that only unsafe edges up to a specific number can fail. We also discuss the bulk-robust model and the relative survivable network design model. While SNDP admits a 2-approximation, the approximability of problems in these more complex models is much less understood even in special cases. We make two contributions. Our first set of results are in the flexible graph connectivity model. Motivated by a conjecture that a constant factor approximation is feasible when the robustness parameters are fixed constants, we consider two important special cases, namely the single pair case, and the global connectivity case. For both these, we obtain constant factor approximations in several parameter ranges of interest. These are based on an augmentation framework and via decomposing the families of cuts that need to be covered into a small number of uncrossable families. Our second set of results are poly-logarithmic approximations for the bulk-robust model when the \"width\" of the given instance (the maximum number of edges that can fail in any particular scenario) is fixed. Via this, we derive corresponding approximations for the flexible graph connectivity model and the relative survivable network design model. The results are obtained via two algorithmic approaches and they have different tradeoffs in terms of the approximation ratio and generality. ",
    "url": "https://arxiv.org/abs/2403.15547",
    "authors": [
      "Chandra Chekuri",
      "Rhea Jain"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2403.15576",
    "title": "Data-centric Prediction Explanation via Kernelized Stein Discrepancy",
    "abstract": "Existing example-based prediction explanation methods often bridge test and training data points through the model's parameters or latent representations. While these methods offer clues to the causes of model predictions, they often exhibit innate shortcomings, such as incurring significant computational overhead or producing coarse-grained explanations. This paper presents a Highly-precise and Data-centric Explanation (HD-Explain), a straightforward prediction explanation method exploiting properties of Kernelized Stein Discrepancy (KSD). Specifically, the KSD uniquely defines a parameterized kernel function for a trained model that encodes model-dependent data correlation. By leveraging the kernel function, one can identify training samples that provide the best predictive support to a test point efficiently. We conducted thorough analyses and experiments across multiple classification domains, where we show that HD-Explain outperforms existing methods from various aspects, including 1) preciseness (fine-grained explanation), 2) consistency, and 3) computation efficiency, leading to a surprisingly simple, effective, and robust prediction explanation solution. ",
    "url": "https://arxiv.org/abs/2403.15576",
    "authors": [
      "Mahtab Sarvmaili",
      "Hassan Sajjad",
      "Ga Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.15600",
    "title": "Just another copy and paste? Comparing the security vulnerabilities of  ChatGPT generated code and StackOverflow answers",
    "abstract": "Sonatype's 2023 report found that 97% of developers and security leads integrate generative Artificial Intelligence (AI), particularly Large Language Models (LLMs), into their development process. Concerns about the security implications of this trend have been raised. Developers are now weighing the benefits and risks of LLMs against other relied-upon information sources, such as StackOverflow (SO), requiring empirical data to inform their choice. In this work, our goal is to raise software developers awareness of the security implications when selecting code snippets by empirically comparing the vulnerabilities of ChatGPT and StackOverflow. To achieve this, we used an existing Java dataset from SO with security-related questions and answers. Then, we asked ChatGPT the same SO questions, gathering the generated code for comparison. After curating the dataset, we analyzed the number and types of Common Weakness Enumeration (CWE) vulnerabilities of 108 snippets from each platform using CodeQL. ChatGPT-generated code contained 248 vulnerabilities compared to the 302 vulnerabilities found in SO snippets, producing 20% fewer vulnerabilities with a statistically significant difference. Additionally, ChatGPT generated 19 types of CWE, fewer than the 22 found in SO. Our findings suggest developers are under-educated on insecure code propagation from both platforms, as we found 274 unique vulnerabilities and 25 types of CWE. Any code copied and pasted, created by AI or humans, cannot be trusted blindly, requiring good software engineering practices to reduce risk. Future work can help minimize insecure code propagation from any platform. ",
    "url": "https://arxiv.org/abs/2403.15600",
    "authors": [
      "Sivana Hamer",
      "Marcelo d'Amorim",
      "Laurie Williams"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.15635",
    "title": "Nonparametric inference of higher order interaction patterns in networks",
    "abstract": "We propose a method for obtaining parsimonious decompositions of networks into higher order interactions which can take the form of arbitrary motifs.The method is based on a class of analytically solvable generative models, where vertices are connected via explicit copies of motifs, which in combination with non-parametric priors allow us to infer higher order interactions from dyadic graph data without any prior knowledge on the types or frequencies of such interactions. Crucially, we also consider 'degree--corrected' models that correctly reflect the degree distribution of the network and consequently prove to be a better fit for many real world--networks compared to non-degree corrected models. We test the presented approach on simulated data for which we recover the set of underlying higher order interactions to a high degree of accuracy. For empirical networks the method identifies concise sets of atomic subgraphs from within thousands of candidates that cover a large fraction of edges and include higher order interactions of known structural and functional significance. The method not only produces an explicit higher order representation of the network but also a fit of the network to analytically tractable models opening new avenues for the systematic study of higher order network structures. ",
    "url": "https://arxiv.org/abs/2403.15635",
    "authors": [
      "Anatol E. Wegner",
      "Sofia C. Olhede"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)",
      "Physics and Society (physics.soc-ph)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2403.15638",
    "title": "Differentially Private Next-Token Prediction of Large Language Models",
    "abstract": "Ensuring the privacy of Large Language Models (LLMs) is becoming increasingly important. The most widely adopted technique to accomplish this is DP-SGD, which trains a model in such a way that guarantees Differential Privacy (DP). However, DP-SGD requires longer training times and larger memory requirements than SGD, while overestimating an adversary's capabilities in having white box access to the model. A more realistic scenario assumes only black-box access to a privacy-sensitive LLM. Motivated by these observations, we present Private Mixing of Ensemble Distributions (PMixED): a private prediction protocol that achieves practical next-token prediction by projecting each of the model's output distribution from an ensemble of fine-tuned LLMs onto a set around a public LLM's output distribution, then averaging the projected distributions and sampling from it. Our approach is more lightweight than DP-SGD in that it is model agnostic, instead providing differential privacy at prediction rather than during training. Our results show that PMixED achieves a stronger privacy guarantee than sample-level privacy and outperforms DP-SGD for privacy $\\epsilon = 8$ on large-scale datasets. ",
    "url": "https://arxiv.org/abs/2403.15638",
    "authors": [
      "James Flemings",
      "Meisam Razaviyayn",
      "Murali Annavaram"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.15648",
    "title": "SRLM: Human-in-Loop Interactive Social Robot Navigation with Large  Language Model and Deep Reinforcement Learning",
    "abstract": "An interactive social robotic assistant must provide services in complex and crowded spaces while adapting its behavior based on real-time human language commands or feedback. In this paper, we propose a novel hybrid approach called Social Robot Planner (SRLM), which integrates Large Language Models (LLM) and Deep Reinforcement Learning (DRL) to navigate through human-filled public spaces and provide multiple social services. SRLM infers global planning from human-in-loop commands in real-time, and encodes social information into a LLM-based large navigation model (LNM) for low-level motion execution. Moreover, a DRL-based planner is designed to maintain benchmarking performance, which is blended with LNM by a large feedback model (LFM) to address the instability of current text and LLM-driven LNM. Finally, SRLM demonstrates outstanding performance in extensive experiments. More details about this work are available at: https://sites.google.com/view/navi-srlm ",
    "url": "https://arxiv.org/abs/2403.15648",
    "authors": [
      "Weizheng Wang",
      "Le Mao",
      "Ruiqi Wang",
      "Byung-Cheol Min"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.15651",
    "title": "GaNI: Global and Near Field Illumination Aware Neural Inverse Rendering",
    "abstract": "In this paper, we present GaNI, a Global and Near-field Illumination-aware neural inverse rendering technique that can reconstruct geometry, albedo, and roughness parameters from images of a scene captured with co-located light and camera. Existing inverse rendering techniques with co-located light-camera focus on single objects only, without modeling global illumination and near-field lighting more prominent in scenes with multiple objects. We introduce a system that solves this problem in two stages; we first reconstruct the geometry powered by neural volumetric rendering NeuS, followed by inverse neural radiosity that uses the previously predicted geometry to estimate albedo and roughness. However, such a naive combination fails and we propose multiple technical contributions that enable this two-stage approach. We observe that NeuS fails to handle near-field illumination and strong specular reflections from the flashlight in a scene. We propose to implicitly model the effects of near-field illumination and introduce a surface angle loss function to handle specular reflections. Similarly, we observe that invNeRad assumes constant illumination throughout the capture and cannot handle moving flashlights during capture. We propose a light position-aware radiance cache network and additional smoothness priors on roughness to reconstruct reflectance. Experimental evaluation on synthetic and real data shows that our method outperforms the existing co-located light-camera-based inverse rendering techniques. Our approach produces significantly better reflectance and slightly better geometry than capture strategies that do not require a dark room. ",
    "url": "https://arxiv.org/abs/2403.15651",
    "authors": [
      "Jiaye Wu",
      "Saeed Hadadan",
      "Geng Lin",
      "Matthias Zwicker",
      "David Jacobs",
      "Roni Sengupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.15652",
    "title": "Parametric Encoding with Attention and Convolution Mitigate Spectral  Bias of Neural Partial Differential Equation Solvers",
    "abstract": "Deep neural networks (DNNs) are increasingly used to solve partial differential equations (PDEs) that naturally arise while modeling a wide range of systems and physical phenomena. However, the accuracy of such DNNs decreases as the PDE complexity increases and they also suffer from spectral bias as they tend to learn the low-frequency solution characteristics. To address these issues, we introduce Parametric Grid Convolutional Attention Networks (PGCANs) that can solve PDE systems without leveraging any labeled data in the domain. The main idea of PGCAN is to parameterize the input space with a grid-based encoder whose parameters are connected to the output via a DNN decoder that leverages attention to prioritize feature training. Our encoder provides a localized learning ability and uses convolution layers to avoid overfitting and improve information propagation rate from the boundaries to the interior of the domain. We test the performance of PGCAN on a wide range of PDE systems and show that it effectively addresses spectral bias and provides more accurate solutions compared to competing methods. ",
    "url": "https://arxiv.org/abs/2403.15652",
    "authors": [
      "Mehdi Shishehbor",
      "Shirin Hosseinmardi",
      "Ramin Bostanabad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.15658",
    "title": "Data-Driven Predictive Control for Robust Exoskeleton Locomotion",
    "abstract": "Exoskeleton locomotion must be robust while being adaptive to different users with and without payloads. To address these challenges, this work introduces a data-driven predictive control (DDPC) framework to synthesize walking gaits for lower-body exoskeletons, employing Hankel matrices and a state transition matrix for its data-driven model. The proposed approach leverages DDPC through a multi-layer architecture. At the top layer, DDPC serves as a planner employing Hankel matrices and a state transition matrix to generate a data-driven model that can learn and adapt to varying users and payloads. At the lower layer, our method incorporates inverse kinematics and passivity-based control to map the planned trajectory from DDPC into the full-order states of the lower-body exoskeleton. We validate the effectiveness of this approach through numerical simulations and hardware experiments conducted on the Atalante lower-body exoskeleton with different payloads. Moreover, we conducted a comparative analysis against the model predictive control (MPC) framework based on the reduced-order linear inverted pendulum (LIP) model. Through this comparison, the paper demonstrates that DDPC enables robust bipedal walking at various velocities while accounting for model uncertainties and unknown perturbations. ",
    "url": "https://arxiv.org/abs/2403.15658",
    "authors": [
      "Kejun Li",
      "Jeeseop Kim",
      "Xiaobin Xiong",
      "Kaveh Akbari Hamed",
      "Yisong Yue",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.15659",
    "title": "A Novel Non-Terrestrial Networks Architecture: All Optical LEO  Constellations with High-Altitude Ground Stations",
    "abstract": "The emergence of low Earth orbit (LEO) satellite mega-constellations is dynamically transforming the space sector. While free-space optical (FSO) links efficiently facilitate intersatellite data forwarding, they suffer from atmospheric/weather conditions in the space-to-ground link. This study delves into utilizing high-altitude platform stations (HAPS) as elevated relay stations strategically positioned above terrestrial ground stations. We introduce the concept of high-altitude ground stations (HAGS), an innovative approach to enabling the development of all optical LEO satellite constellations. The first contribution is an analysis of the HAGS-based network architecture where the LEO spacecraft only hosts FSO transceivers. Secondly, we execute an extensive simulation campaign to determine the gain of HAGS, including a new equivalency model with the traditional ground station approach. Finally, we examine the research challenges of implementing HAGS-based, all optical LEO mega-constellations. ",
    "url": "https://arxiv.org/abs/2403.15659",
    "authors": [
      "Pablo G. Madoery",
      "Juan A. Fraire",
      "Jorge M. Finochietto",
      "Halim Yanikomeroglu",
      "Gunes Karabulut Kurt"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2403.15671",
    "title": "Real-Time Reconfiguration and Connectivity Maintenance for AUVs Network  Under External Disturbances using Distributed Nonlinear Model Predictive  Control",
    "abstract": "Advancements in underwater vehicle technology have significantly expanded the potential scope for deploying autonomous or remotely operated underwater vehicles in novel practical applications. However, the efficiency and maneuverability of these vehicles remain critical challenges, particularly in the dynamic aquatic environment. In this work, we propose a novel control scheme for creating multi-agent distributed formation control with limited communication between individual agents. In addition, the formation of the multi-agent can be reconfigured in real-time and the network connectivity can be maintained. The proposed use case for this scheme includes creating underwater mobile communication networks that can adapt to environmental or network conditions to maintain the quality of communication links for long-range exploration, seabed monitoring, or underwater infrastructure inspection. This work introduces a novel Distributed Nonlinear Model Predictive Control (DNMPC) strategy, integrating Control Lyapunov Functions (CLF) and Control Barrier Functions (CBF) with a relaxed decay rate, specifically tailored for 6-DOF underwater robotics. The effectiveness of our proposed DNMPC scheme was demonstrated through rigorous MATLAB simulations for trajectory tracking and formation reconfiguration in a dynamic environment. Our findings, supported by tests conducted using Software In The Loop (SITL) simulation, confirm the approach's applicability in real-time scenarios. ",
    "url": "https://arxiv.org/abs/2403.15671",
    "authors": [
      "Nhat Minh Nguyen",
      "Stephen McIlvanna",
      "Jack Close",
      "Mien Van"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.15679",
    "title": "DS-NeRV: Implicit Neural Video Representation with Decomposed Static and  Dynamic Codes",
    "abstract": "Implicit neural representations for video (NeRV) have recently become a novel way for high-quality video representation. However, existing works employ a single network to represent the entire video, which implicitly confuse static and dynamic information. This leads to an inability to effectively compress the redundant static information and lack the explicitly modeling of global temporal-coherent dynamic details. To solve above problems, we propose DS-NeRV, which decomposes videos into sparse learnable static codes and dynamic codes without the need for explicit optical flow or residual supervision. By setting different sampling rates for two codes and applying weighted sum and interpolation sampling methods, DS-NeRV efficiently utilizes redundant static information while maintaining high-frequency details. Additionally, we design a cross-channel attention-based (CCA) fusion module to efficiently fuse these two codes for frame decoding. Our approach achieves a high quality reconstruction of 31.2 PSNR with only 0.35M parameters thanks to separate static and dynamic codes representation and outperforms existing NeRV methods in many downstream tasks. Our project website is at https://haoyan14.github.io/DS-NeRV. ",
    "url": "https://arxiv.org/abs/2403.15679",
    "authors": [
      "Hao Yan",
      "Zhihui Ke",
      "Xiaobo Zhou",
      "Tie Qiu",
      "Xidong Shi",
      "Dadong Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2403.15690",
    "title": "EAGLE: A Domain Generalization Framework for AI-generated Text Detection",
    "abstract": "With the advancement in capabilities of Large Language Models (LLMs), one major step in the responsible and safe use of such LLMs is to be able to detect text generated by these models. While supervised AI-generated text detectors perform well on text generated by older LLMs, with the frequent release of new LLMs, building supervised detectors for identifying text from such new models would require new labeled training data, which is infeasible in practice. In this work, we tackle this problem and propose a domain generalization framework for the detection of AI-generated text from unseen target generators. Our proposed framework, EAGLE, leverages the labeled data that is available so far from older language models and learns features invariant across these generators, in order to detect text generated by an unknown target generator. EAGLE learns such domain-invariant features by combining the representational power of self-supervised contrastive learning with domain adversarial training. Through our experiments we demonstrate how EAGLE effectively achieves impressive performance in detecting text generated by unseen target generators, including recent state-of-the-art ones such as GPT-4 and Claude, reaching detection scores of within 4.7% of a fully supervised detector. ",
    "url": "https://arxiv.org/abs/2403.15690",
    "authors": [
      "Amrita Bhattacharjee",
      "Raha Moraffah",
      "Joshua Garland",
      "Huan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.15697",
    "title": "Passivity-based Attack Identification and Mitigation with  Event-triggered Observer Feedback and Switching Controller",
    "abstract": "This paper addresses the problem of output consensus in linear passive multi-agent systems under a False Data Injection (FDI) attack, considering the unavailability of complete state information. Our formulation relies on an event-based cryptographic authentication scheme for sensor integrity and considers FDI attacks at the actuator end, inspired by their practical nature and usages. For secure consensus, we propose (i) a passivity-based approach for detecting FDI attacks on the system and (ii) a Zeno-free event-triggered observer-based switching controller, which switches between the normal and the defense modes following an attack detection. We show that the closed-loop system achieves practical consensus under the controller's action in the defense mode. Simulation examples are provided to support the theoretical findings. ",
    "url": "https://arxiv.org/abs/2403.15697",
    "authors": [
      "Pushkal Purohit",
      "Anoop Jain"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.15700",
    "title": "Improved Soft-k-Means Clustering Algorithm for Balancing Energy  Consumption in Wireless Sensor Networks",
    "abstract": "Energy load balancing is an essential issue in designing wireless sensor networks (WSNs). Clustering techniques are utilized as energy-efficient methods to balance the network energy and prolong its lifetime. In this paper, we propose an improved soft-k-means (IS-k-means) clustering algorithm to balance the energy consumption of nodes in WSNs. First, we use the idea of ``clustering by fast search and find of density peaks'' (CFSFDP) and kernel density estimation (KDE) to improve the selection of the initial cluster centers of the soft k-means clustering algorithm. Then, we utilize the flexibility of the soft-k-means and reassign member nodes considering their membership probabilities at the boundary of clusters to balance the number of nodes per cluster. Furthermore, the concept of multi-cluster heads is employed to balance the energy consumption within clusters. {Extensive simulation results under different network scenarios demonstrate that for small-scale WSNs with single-hop transmission}, the proposed algorithm can postpone the first node death, the half of nodes death, and the last node death on average when compared to various clustering algorithms from the literature. ",
    "url": "https://arxiv.org/abs/2403.15700",
    "authors": [
      "Botao Zhu",
      "Ebrahim Bedeer",
      "Ha H. Nguyen",
      "Robert Barton",
      "Jerome Henry"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.15702",
    "title": "Causal Tracking of Distributions in Wasserstein Space: A Model  Predictive Control Scheme",
    "abstract": "We consider the problem of optimal swarm tracking which can be formulated as a tracking problem for distributions in the Wasserstein metric. Optimal control solutions to this problem are non-causal and require knowing the time-trajectory of the distribution to be tracked in advance. We propose a scheme where these non-causal solutions can be used together with a predictive model for the reference to achieve causal tracking control of a priori-unknown references. We develop the resulting model-predictive control scheme in the simple case where the reference is predicted to be constant-in-time. A computational algorithm based on particle methods and discrete optimal mass transport is presented, and numerical simulations are provided for various classes of reference signals. The results demonstrate that the proposed control algorithm achieves reasonable performance even when using simple predictive models. ",
    "url": "https://arxiv.org/abs/2403.15702",
    "authors": [
      "Max Emerick",
      "Jared Jonas",
      "Bassam Bamieh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2403.15711",
    "title": "Identifiable Latent Neural Causal Models",
    "abstract": "Causal representation learning seeks to uncover latent, high-level causal representations from low-level observed data. It is particularly good at predictions under unseen distribution shifts, because these shifts can generally be interpreted as consequences of interventions. Hence leveraging {seen} distribution shifts becomes a natural strategy to help identifying causal representations, which in turn benefits predictions where distributions are previously {unseen}. Determining the types (or conditions) of such distribution shifts that do contribute to the identifiability of causal representations is critical. This work establishes a {sufficient} and {necessary} condition characterizing the types of distribution shifts for identifiability in the context of latent additive noise models. Furthermore, we present partial identifiability results when only a portion of distribution shifts meets the condition. In addition, we extend our findings to latent post-nonlinear causal models. We translate our findings into a practical algorithm, allowing for the acquisition of reliable latent causal representations. Our algorithm, guided by our underlying theory, has demonstrated outstanding performance across a diverse range of synthetic and real-world datasets. The empirical observations align closely with the theoretical findings, affirming the robustness and effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2403.15711",
    "authors": [
      "Yuhang Liu",
      "Zhen Zhang",
      "Dong Gong",
      "Mingming Gong",
      "Biwei Huang",
      "Anton van den Hengel",
      "Kun Zhang",
      "Javen Qinfeng Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.15712",
    "title": "PNAS-MOT: Multi-Modal Object Tracking with Pareto Neural Architecture  Search",
    "abstract": "Multiple object tracking is a critical task in autonomous driving. Existing works primarily focus on the heuristic design of neural networks to obtain high accuracy. As tracking accuracy improves, however, neural networks become increasingly complex, posing challenges for their practical application in real driving scenarios due to the high level of latency. In this paper, we explore the use of the neural architecture search (NAS) methods to search for efficient architectures for tracking, aiming for low real-time latency while maintaining relatively high accuracy. Another challenge for object tracking is the unreliability of a single sensor, therefore, we propose a multi-modal framework to improve the robustness. Experiments demonstrate that our algorithm can run on edge devices within lower latency constraints, thus greatly reducing the computational requirements for multi-modal object tracking while keeping lower latency. ",
    "url": "https://arxiv.org/abs/2403.15712",
    "authors": [
      "Chensheng Peng",
      "Zhaoyu Zeng",
      "Jinling Gao",
      "Jundong Zhou",
      "Masayoshi Tomizuka",
      "Xinbing Wang",
      "Chenghu Zhou",
      "Nanyang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.15715",
    "title": "EDDA: A Encoder-Decoder Data Augmentation Framework for Zero-Shot Stance  Detection",
    "abstract": "Stance detection aims to determine the attitude expressed in text towards a given target. Zero-shot stance detection (ZSSD) has emerged to classify stances towards unseen targets during inference. Recent data augmentation techniques for ZSSD increase transferable knowledge between targets through text or target augmentation. However, these methods exhibit limitations. Target augmentation lacks logical connections between generated targets and source text, while text augmentation relies solely on training data, resulting in insufficient generalization. To address these issues, we propose an encoder-decoder data augmentation (EDDA) framework. The encoder leverages large language models and chain-of-thought prompting to summarize texts into target-specific if-then rationales, establishing logical relationships. The decoder generates new samples based on these expressions using a semantic correlation word replacement strategy to increase syntactic diversity. We also analyze the generated expressions to develop a rationale-enhanced network that fully utilizes the augmented data. Experiments on benchmark datasets demonstrate our approach substantially improves over state-of-the-art ZSSD techniques. The proposed EDDA framework increases semantic relevance and syntactic variety in augmented texts while enabling interpretable rationale-based learning. ",
    "url": "https://arxiv.org/abs/2403.15715",
    "authors": [
      "Daijun Ding",
      "Li Dong",
      "Zhichao Huang",
      "Guangning Xu",
      "Xu Huang",
      "Bo Liu",
      "Liwen Jing",
      "Bowen Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.15716",
    "title": "Distributed Robust Learning based Formation Control of Mobile Robots  based on Bioinspired Neural Dynamics",
    "abstract": "This paper addresses the challenges of distributed formation control in multiple mobile robots, introducing a novel approach that enhances real-world practicability. We first introduce a distributed estimator using a variable structure and cascaded design technique, eliminating the need for derivative information to improve the real time performance. Then, a kinematic tracking control method is developed utilizing a bioinspired neural dynamic-based approach aimed at providing smooth control inputs and effectively resolving the speed jump issue. Furthermore, to address the challenges for robots operating with completely unknown dynamics and disturbances, a learning-based robust dynamic controller is developed. This controller provides real time parameter estimates while maintaining its robustness against disturbances. The overall stability of the proposed method is proved with rigorous mathematical analysis. At last, multiple comprehensive simulation studies have shown the advantages and effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2403.15716",
    "authors": [
      "Zhe Xu",
      "Tao Yan",
      "Simon X. Yang",
      "S. Andrew Gadsden",
      "Mohammad Biglarbegian"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.15721",
    "title": "Radical-Cylon: A Heterogeneous Data Pipeline for Scientific Computing",
    "abstract": "Managing and preparing complex data for deep learning, a prevalent approach in large-scale data science can be challenging. Data transfer for model training also presents difficulties, impacting scientific fields like genomics, climate modeling, and astronomy. A large-scale solution like Google Pathways with a distributed execution environment for deep learning models exists but is proprietary. Integrating existing open-source, scalable runtime tools and data frameworks on high-performance computing (HPC) platforms are crucial to address these challenges. Our objective is to establish a smooth and unified method of combining data engineering and deep learning frameworks with diverse execution capabilities that can be deployed on various high-performance computing platforms, including cloud and supercomputers. We aim to support heterogeneous systems with accelerators, where Cylon and other data engineering and deep learning frameworks can utilize heterogeneous execution. To achieve this, we propose Radical-Cylon, a heterogeneous runtime system with a parallel and distributed data framework to execute Cylon as a task of Radical Pilot. We thoroughly explain Radical-Cylon's design and development and the execution process of Cylon tasks using Radical Pilot. This approach enables the use of heterogeneous MPI-communicators across multiple nodes. Radical-Cylon achieves better performance than Bare-Metal Cylon with minimal and constant overhead. Radical-Cylon achieves (4~15)% faster execution time than batch execution while performing similar join and sort operations with 35 million and 3.5 billion rows with the same resources. The approach aims to excel in both scientific and engineering research HPC systems while demonstrating robust performance on cloud infrastructures. This dual capability fosters collaboration and innovation within the open-source scientific research community. ",
    "url": "https://arxiv.org/abs/2403.15721",
    "authors": [
      "Arup Kumar Sarker",
      "Aymen Alsaadi",
      "Niranda Perera",
      "Mills Staylor",
      "Gregor von Laszewski",
      "Matteo Turilli",
      "Ozgur Ozan Kilic",
      "Mikhail Titov",
      "Andre Merzky",
      "Shantenu Jha",
      "Geoffrey Fox"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2403.15726",
    "title": "Convection-Diffusion Equation: A Theoretically Certified Framework for  Neural Networks",
    "abstract": "In this paper, we study the partial differential equation models of neural networks. Neural network can be viewed as a map from a simple base model to a complicate function. Based on solid analysis, we show that this map can be formulated by a convection-diffusion equation. This theoretically certified framework gives mathematical foundation and more understanding of neural networks. Moreover, based on the convection-diffusion equation model, we design a novel network structure, which incorporates diffusion mechanism into network architecture. Extensive experiments on both benchmark datasets and real-world applications validate the performance of the proposed model. ",
    "url": "https://arxiv.org/abs/2403.15726",
    "authors": [
      "Tangjun Wang",
      "Chenglong Bao",
      "Zuoqiang Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.15733",
    "title": "Spatio-Temporal Graph Convolutional Network Combined Large Language  Model: A Deep Learning Framework for Bike Demand Forecasting",
    "abstract": "This study presents a new deep learning framework, combining Spatio-Temporal Graph Convolutional Network (STGCN) with a Large Language Model (LLM), for bike demand forecasting. Addressing challenges in transforming discrete datasets and integrating unstructured language data, the framework leverages LLMs to extract insights from Points of Interest (POI) text data. The proposed STGCN-L model demonstrates competitive performance compared to existing models, showcasing its potential in predicting bike demand. Experiments using Philadelphia datasets highlight the effectiveness of the hybrid model, emphasizing the need for further exploration and enhancements, such as incorporating additional features like weather data for improved accuracy. ",
    "url": "https://arxiv.org/abs/2403.15733",
    "authors": [
      "Peisen Li",
      "Yizhe Pang",
      "Junyu Ren"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2403.15760",
    "title": "An Upload-Efficient Scheme for Transferring Knowledge From a Server-Side  Pre-trained Generator to Clients in Heterogeneous Federated Learning",
    "abstract": "Heterogeneous Federated Learning (HtFL) enables collaborative learning on multiple clients with different model architectures while preserving privacy. Despite recent research progress, knowledge sharing in HtFL is still difficult due to data and model heterogeneity. To tackle this issue, we leverage the knowledge stored in pre-trained generators and propose a new upload-efficient knowledge transfer scheme called Federated Knowledge-Transfer Loop (FedKTL). Our FedKTL can produce client-task-related prototypical image-vector pairs via the generator's inference on the server. With these pairs, each client can transfer pre-existing knowledge from the generator to its local model through an additional supervised local task. We conduct extensive experiments on four datasets under two types of data heterogeneity with 14 kinds of models including CNNs and ViTs. Results show that our upload-efficient FedKTL surpasses seven state-of-the-art methods by up to 7.31% in accuracy. Moreover, our knowledge transfer scheme is applicable in scenarios with only one edge client. Code: https://github.com/TsingZ0/FedKTL ",
    "url": "https://arxiv.org/abs/2403.15760",
    "authors": [
      "Jianqing Zhang",
      "Yang Liu",
      "Yang Hua",
      "Jian Cao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2403.15766",
    "title": "BEND: Bagging Deep Learning Training Based on Efficient Neural Network  Diffusion",
    "abstract": "Bagging has achieved great success in the field of machine learning by integrating multiple base classifiers to build a single strong classifier to reduce model variance. The performance improvement of bagging mainly relies on the number and diversity of base classifiers. However, traditional deep learning model training methods are expensive to train individually and difficult to train multiple models with low similarity in a restricted dataset. Recently, diffusion models, which have been tremendously successful in the fields of imaging and vision, have been found to be effective in generating neural network model weights and biases with diversity. We creatively propose a Bagging deep learning training algorithm based on Efficient Neural network Diffusion (BEND). The originality of BEND comes from the first use of a neural network diffusion model to efficiently build base classifiers for bagging. Our approach is simple but effective, first using multiple trained model weights and biases as inputs to train autoencoder and latent diffusion model to realize a diffusion model from noise to valid neural network parameters. Subsequently, we generate several base classifiers using the trained diffusion model. Finally, we integrate these ba se classifiers for various inference tasks using the Bagging method. Resulting experiments on multiple models and datasets show that our proposed BEND algorithm can consistently outperform the mean and median accuracies of both the original trained model and the diffused model. At the same time, new models diffused using the diffusion model have higher diversity and lower cost than multiple models trained using traditional methods. The BEND approach successfully introduces diffusion models into the new deep learning training domain and provides a new paradigm for future deep learning training and inference. ",
    "url": "https://arxiv.org/abs/2403.15766",
    "authors": [
      "Jia Wei",
      "Xingjun Zhang",
      "Witold Pedrycz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.15786",
    "title": "Adversarial Defense Teacher for Cross-Domain Object Detection under Poor  Visibility Conditions",
    "abstract": "Existing object detectors encounter challenges in handling domain shifts between training and real-world data, particularly under poor visibility conditions like fog and night. Cutting-edge cross-domain object detection methods use teacher-student frameworks and compel teacher and student models to produce consistent predictions under weak and strong augmentations, respectively. In this paper, we reveal that manually crafted augmentations are insufficient for optimal teaching and present a simple yet effective framework named Adversarial Defense Teacher (ADT), leveraging adversarial defense to enhance teaching quality. Specifically, we employ adversarial attacks, encouraging the model to generalize on subtly perturbed inputs that effectively deceive the model. To address small objects under poor visibility conditions, we propose a Zoom-in Zoom-out strategy, which zooms-in images for better pseudo-labels and zooms-out images and pseudo-labels to learn refined features. Our results demonstrate that ADT achieves superior performance, reaching 54.5% mAP on Foggy Cityscapes, surpassing the previous state-of-the-art by 2.6% mAP. ",
    "url": "https://arxiv.org/abs/2403.15786",
    "authors": [
      "Kaiwen Wang",
      "Yinzhe Shen",
      "Martin Lauer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.15811",
    "title": "Distance Adjustment of a Graph Drawing Stress Model",
    "abstract": "Stress models are a promising approach for graph drawing. They minimize the weighted sum of the squared errors of the Euclidean and desired distances for each node pair. The desired distance typically uses the graph-theoretic distances obtained from the all-node pair shortest path problem. In a minimized stress function, the obtained coordinates are affected by the non-Euclidean property and the high-dimensionality of the graph-theoretic distance matrix. Therefore, the graph-theoretic distances used in stress models may not necessarily be the best metric for determining the node coordinates. In this study, we propose two different methods of adjusting the graph-theoretical distance matrix to a distance matrix suitable for graph drawing while preserving its structure. The first method is the application of eigenvalue decomposition to the inner product matrix obtained from the distance matrix and the obtainment of a new distance matrix by setting some eigenvalues with small absolute values to zero. The second approach is the usage of a stress model modified by adding a term that minimizes the Frobenius norm between the adjusted and original distance matrices. We perform computational experiments using several benchmark graphs to demonstrate that the proposed method improves some quality metrics, including the node resolution and the Gabriel graph property, when compared to conventional stress models. ",
    "url": "https://arxiv.org/abs/2403.15811",
    "authors": [
      "Yosuke Onoue"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2403.15812",
    "title": "The Impact of Evolutionary Computation on Robotic Design: A Case Study  with an Underactuated Hand Exoskeleton",
    "abstract": "Robotic exoskeletons can enhance human strength and aid people with physical disabilities. However, designing them to ensure safety and optimal performance presents significant challenges. Developing exoskeletons should incorporate specific optimization algorithms to find the best design. This study investigates the potential of Evolutionary Computation (EC) methods in robotic design optimization, with an underactuated hand exoskeleton (U-HEx) used as a case study. We propose improving the performance and usability of the U-HEx design, which was initially optimized using a naive brute-force approach, by integrating EC techniques such as Genetic Algorithm and Big Bang-Big Crunch Algorithm. Comparative analysis revealed that EC methods consistently yield more precise and optimal solutions than brute force in a significantly shorter time. This allowed us to improve the optimization by increasing the number of variables in the design, which was impossible with naive methods. The results show significant improvements in terms of the torque magnitude the device transfers to the user, enhancing its efficiency. These findings underline the importance of performing proper optimization while designing exoskeletons, as well as providing a significant improvement to this specific robotic design. ",
    "url": "https://arxiv.org/abs/2403.15812",
    "authors": [
      "Baris Akbas",
      "Huseyin Taner Yuksel",
      "Aleyna Soylemez",
      "Mazhar Eid Zyada",
      "Mine Sarac",
      "Fabio Stroppa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2403.15813",
    "title": "Learning Early Social Maneuvers for Enhanced Social Navigation",
    "abstract": "Socially compliant navigation is an integral part of safety features in Human-Robot Interaction. Traditional approaches to mobile navigation prioritize physical aspects, such as efficiency, but social behaviors gain traction as robots appear more in daily life. Recent techniques to improve the social compliance of navigation often rely on predefined features or reward functions, introducing assumptions about social human behavior. To address this limitation, we propose a novel Learning from Demonstration (LfD) framework for social navigation that exclusively utilizes raw sensory data. Additionally, the proposed system contains mechanisms to consider the future paths of the surrounding pedestrians, acknowledging the temporal aspect of the problem. The final product is expected to reduce the anxiety of people sharing their environment with a mobile robot, helping them trust that the robot is aware of their presence and will not harm them. As the framework is currently being developed, we outline its components, present experimental results, and discuss future work towards realizing this framework. ",
    "url": "https://arxiv.org/abs/2403.15813",
    "authors": [
      "Yigit Y\u0131ld\u0131rim",
      "Mehmet Suzer",
      "Emre Ugur"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.15815",
    "title": "Resource-efficient Parallel Split Learning in Heterogeneous Edge  Computing",
    "abstract": "Edge AI has been recently proposed to facilitate the training and deployment of Deep Neural Network (DNN) models in proximity to the sources of data. To enable the training of large models on resource-constraint edge devices and protect data privacy, parallel split learning is becoming a practical and popular approach. However, current parallel split learning neglects the resource heterogeneity of edge devices, which may lead to the straggler issue. In this paper, we propose EdgeSplit, a novel parallel split learning framework to better accelerate distributed model training on heterogeneous and resource-constraint edge devices. EdgeSplit enhances the efficiency of model training on less powerful edge devices by adaptively segmenting the model into varying depths. Our approach focuses on reducing total training time by formulating and solving a task scheduling problem, which determines the most efficient model partition points and bandwidth allocation for each device. We employ a straightforward yet effective alternating algorithm for this purpose. Comprehensive tests conducted with a range of DNN models and datasets demonstrate that EdgeSplit not only facilitates the training of large models on resource-restricted edge devices but also surpasses existing baselines in performance. ",
    "url": "https://arxiv.org/abs/2403.15815",
    "authors": [
      "Mingjin Zhang",
      "Jiannong Cao",
      "Yuvraj Sahni",
      "Xiangchun Chen",
      "Shan Jiang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2403.15832",
    "title": "Time-series Initialization and Conditioning for Video-agnostic  Stabilization of Video Super-Resolution using Recurrent Networks",
    "abstract": "A Recurrent Neural Network (RNN) for Video Super Resolution (VSR) is generally trained with randomly clipped and cropped short videos extracted from original training videos due to various challenges in learning RNNs. However, since this RNN is optimized to super-resolve short videos, VSR of long videos is degraded due to the domain gap. Our preliminary experiments reveal that such degradation changes depending on the video properties, such as the video length and dynamics. To avoid this degradation, this paper proposes the training strategy of RNN for VSR that can work efficiently and stably independently of the video length and dynamics. The proposed training strategy stabilizes VSR by training a VSR network with various RNN hidden states changed depending on the video properties. Since computing such a variety of hidden states is time-consuming, this computational cost is reduced by reusing the hidden states for efficient training. In addition, training stability is further improved with frame-number conditioning. Our experimental results demonstrate that the proposed method performed better than base methods in videos with various lengths and dynamics. ",
    "url": "https://arxiv.org/abs/2403.15832",
    "authors": [
      "Hiroshi Mori",
      "Norimichi Ukita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.15848",
    "title": "On the Stability of Learning in Network Games with Many Players",
    "abstract": "Multi-agent learning algorithms have been shown to display complex, unstable behaviours in a wide array of games. In fact, previous works indicate that convergent behaviours are less likely to occur as the total number of agents increases. This seemingly prohibits convergence to stable strategies, such as Nash Equilibria, in games with many players. To make progress towards addressing this challenge we study the Q-Learning Dynamics, a classical model for exploration and exploitation in multi-agent learning. In particular, we study the behaviour of Q-Learning on games where interactions between agents are constrained by a network. We determine a number of sufficient conditions, depending on the game and network structure, which guarantee that agent strategies converge to a unique stable strategy, called the Quantal Response Equilibrium (QRE). Crucially, these sufficient conditions are independent of the total number of agents, allowing for provable convergence in arbitrarily large games. Next, we compare the learned QRE to the underlying NE of the game, by showing that any QRE is an $\\epsilon$-approximate Nash Equilibrium. We first provide tight bounds on $\\epsilon$ and show how these bounds lead naturally to a centralised scheme for choosing exploration rates, which enables independent learners to learn stable approximate Nash Equilibrium strategies. We validate the method through experiments and demonstrate its effectiveness even in the presence of numerous agents and actions. Through these results, we show that independent learning dynamics may converge to approximate Nash Equilibria, even in the presence of many agents. ",
    "url": "https://arxiv.org/abs/2403.15848",
    "authors": [
      "Aamal Hussain",
      "Dan Leonte",
      "Francesco Belardinelli",
      "Georgios Piliouras"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2403.15852",
    "title": "When LLM-based Code Generation Meets the Software Development Process",
    "abstract": "Software process models play a pivotal role in fostering collaboration and communication within software teams, enabling them to tackle intricate development tasks effectively. This paper introduces LCG, a code generation framework inspired by established software engineering practices. LCG leverages multiple Large Language Model (LLM) agents to emulate various software process models, namely LCGWaterfall, LCGTDD, and LCGScrum. Each model assigns LLM agents specific roles such as requirement engineer, architect, developer, tester, and scrum master, mirroring typical development activities and communication patterns. Through collaborative efforts utilizing chain-of-thought and prompt composition techniques, the agents continuously refine themselves to enhance code quality. Utilizing GPT3.5 as the underlying LLM and baseline (GPT), we evaluate LCG across four code generation benchmarks: HumanEval, HumanEval-ET, MBPP, and MBPP-ET. Results indicate LCGScrum outperforms other models, achieving Pass@1 scores of 75.2, 65.5, 82.5, and 56.7 in HumanEval, HumanEval-ET, MBPP, and MBPP-ET, respectively - an average 15% improvement over GPT. Analysis reveals distinct impacts of development activities on generated code, with design and code reviews contributing to enhanced exception handling, while design, testing, and code reviews mitigate code smells. Furthermore, temperature values exhibit negligible influence on Pass@1 across all models. However, variations in Pass@1 are notable for different GPT3.5 model versions, ranging from 5 to over 60 in HumanEval, highlighting the stability of LCG across model versions. This stability underscores the importance of adopting software process models to bolster the quality and consistency of LLM-generated code. ",
    "url": "https://arxiv.org/abs/2403.15852",
    "authors": [
      "Feng Lin",
      "Dong Jae Kim",
      "Tse-Husn",
      "Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.15856",
    "title": "#TeamFollowBack: Detection & Analysis of Follow Back Accounts on Social  Media",
    "abstract": "Follow back accounts inflate their follower counts by engaging in reciprocal followings. Such accounts manipulate the public and the algorithms by appearing more popular than they really are. Despite their potential harm, no studies have analyzed such accounts at scale. In this study, we present the first large-scale analysis of follow back accounts. We formally define follow back accounts and employ a honeypot approach to collect a dataset of such accounts on X (formerly Twitter). We discover and describe 12 communities of follow back accounts from 12 different countries, some of which exhibit clear political agenda. We analyze the characteristics of follow back accounts and report that they are newer, more engaging, and have more followings and followers. Finally, we propose a classifier for such accounts and report that models employing profile metadata and the ego network demonstrate promising results, although achieving high recall is challenging. Our study enhances understanding of the follow back accounts and discovering such accounts in the wild. ",
    "url": "https://arxiv.org/abs/2403.15856",
    "authors": [
      "Tu\u011frulcan Elmas",
      "Mathis Randl",
      "Youssef Attia"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.15878",
    "title": "Diffusion-based Aesthetic QR Code Generation via Scanning-Robust  Perceptual Guidance",
    "abstract": "QR codes, prevalent in daily applications, lack visual appeal due to their conventional black-and-white design. Integrating aesthetics while maintaining scannability poses a challenge. In this paper, we introduce a novel diffusion-model-based aesthetic QR code generation pipeline, utilizing pre-trained ControlNet and guided iterative refinement via a novel classifier guidance (SRG) based on the proposed Scanning-Robust Loss (SRL) tailored with QR code mechanisms, which ensures both aesthetics and scannability. To further improve the scannability while preserving aesthetics, we propose a two-stage pipeline with Scanning-Robust Perceptual Guidance (SRPG). Moreover, we can further enhance the scannability of the generated QR code by post-processing it through the proposed Scanning-Robust Projected Gradient Descent (SRPGD) post-processing technique based on SRL with proven convergence. With extensive quantitative, qualitative, and subjective experiments, the results demonstrate that the proposed approach can generate diverse aesthetic QR codes with flexibility in detail. In addition, our pipelines outperforming existing models in terms of Scanning Success Rate (SSR) 86.67% (+40%) with comparable aesthetic scores. The pipeline combined with SRPGD further achieves 96.67% (+50%). Our code will be available https://github.com/jwliao1209/DiffQRCode. ",
    "url": "https://arxiv.org/abs/2403.15878",
    "authors": [
      "Jia-Wei Liao",
      "Winston Wang",
      "Tzu-Sian Wang",
      "Li-Xuan Peng",
      "Cheng-Fu Chou",
      "Jun-Cheng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.15885",
    "title": "STEntConv: Predicting Disagreement with Stance Detection and a Signed  Graph Convolutional Network",
    "abstract": "The rise of social media platforms has led to an increase in polarised online discussions, especially on political and socio-cultural topics such as elections and climate change. We propose a simple and novel unsupervised method to predict whether the authors of two posts agree or disagree, leveraging user stances about named entities obtained from their posts. We present STEntConv, a model which builds a graph of users and named entities weighted by stance and trains a Signed Graph Convolutional Network (SGCN) to detect disagreement between comment and reply posts. We run experiments and ablation studies and show that including this information improves disagreement detection performance on a dataset of Reddit posts for a range of controversial subreddit topics, without the need for platform-specific features or user history. ",
    "url": "https://arxiv.org/abs/2403.15885",
    "authors": [
      "Isabelle Lorge",
      "Li Zhang",
      "Xiaowen Dong",
      "Janet B. Pierrehumbert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.15891",
    "title": "Human Motion Prediction under Unexpected Perturbation",
    "abstract": "We investigate a new task in human motion prediction, which is predicting motions under unexpected physical perturbation potentially involving multiple people. Compared with existing research, this task involves predicting less controlled, unpremeditated and pure reactive motions in response to external impact and how such motions can propagate through people. It brings new challenges such as data scarcity and predicting complex interactions. To this end, we propose a new method capitalizing differential physics and deep neural networks, leading to an explicit Latent Differential Physics (LDP) model. Through experiments, we demonstrate that LDP has high data efficiency, outstanding prediction accuracy, strong generalizability and good explainability. Since there is no similar research, a comprehensive comparison with 11 adapted baselines from several relevant domains is conducted, showing LDP outperforming existing research both quantitatively and qualitatively, improving prediction accuracy by as much as 70%, and demonstrating significantly stronger generalization. ",
    "url": "https://arxiv.org/abs/2403.15891",
    "authors": [
      "Jiangbei Yue",
      "Baiyi Li",
      "Julien Pettr\u00e9",
      "Armin Seyfried",
      "He Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.15908",
    "title": "Deep Gaussian Covariance Network with Trajectory Sampling for  Data-Efficient Policy Search",
    "abstract": "Probabilistic world models increase data efficiency of model-based reinforcement learning (MBRL) by guiding the policy with their epistemic uncertainty to improve exploration and acquire new samples. Moreover, the uncertainty-aware learning procedures in probabilistic approaches lead to robust policies that are less sensitive to noisy observations compared to uncertainty unaware solutions. We propose to combine trajectory sampling and deep Gaussian covariance network (DGCN) for a data-efficient solution to MBRL problems in an optimal control setting. We compare trajectory sampling with density-based approximation for uncertainty propagation using three different probabilistic world models; Gaussian processes, Bayesian neural networks, and DGCNs. We provide empirical evidence using four different well-known test environments, that our method improves the sample-efficiency over other combinations of uncertainty propagation methods and probabilistic models. During our tests, we place particular emphasis on the robustness of the learned policies with respect to noisy initial states. ",
    "url": "https://arxiv.org/abs/2403.15908",
    "authors": [
      "Can Bogoclu",
      "Robert Vosshall",
      "Kevin Cremanns",
      "Dirk Roos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.15918",
    "title": "An Embarrassingly Simple Defense Against Backdoor Attacks On SSL",
    "abstract": "Self Supervised Learning (SSL) has emerged as a powerful paradigm to tackle data landscapes with absence of human supervision. The ability to learn meaningful tasks without the use of labeled data makes SSL a popular method to manage large chunks of data in the absence of labels. However, recent work indicates SSL to be vulnerable to backdoor attacks, wherein models can be controlled, possibly maliciously, to suit an adversary's motives. Li et.al (2022) introduce a novel frequency-based backdoor attack: CTRL. They show that CTRL can be used to efficiently and stealthily gain control over a victim's model trained using SSL. In this work, we devise two defense strategies against frequency-based attacks in SSL: One applicable before model training and the second to be applied during model inference. Our first contribution utilizes the invariance property of the downstream task to defend against backdoor attacks in a generalizable fashion. We observe the ASR (Attack Success Rate) to reduce by over 60% across experiments. Our Inference-time defense relies on evasiveness of the attack and uses the luminance channel to defend against attacks. Using object classification as the downstream task for SSL, we demonstrate successful defense strategies that do not require re-training of the model. Code is available at https://github.com/Aryan-Satpathy/Backdoor. ",
    "url": "https://arxiv.org/abs/2403.15918",
    "authors": [
      "Aryan Satpathy",
      "Nilaksh",
      "Dhruva Rajwade"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.15927",
    "title": "LOAM: Low-latency Communication, Caching, and Computation Placement in  Data-Intensive Computing Networks",
    "abstract": "Deploying data- and computation-intensive applications such as large-scale AI into heterogeneous dispersed computing networks can significantly enhance application performance by mitigating bottlenecks caused by limited network resources, including bandwidth, storage, and computing power. However, current resource allocation methods in dispersed computing do not provide a comprehensive solution that considers arbitrary topology, elastic resource amount, reuse of computation results, and nonlinear congestion-dependent optimization objectives. In this paper, we propose LOAM, a low-latency joint communication, caching, and computation placement framework with a rigorous analytical foundation that incorporates the above aspects. We tackle the NP-hard aggregated cost minimization problem with two methods: an offline method with a 1/2 approximation and an online adaptive method with a bounded gap from the optimum. Through extensive simulation, the proposed framework outperforms multiple baselines in both synthesis and real-world network scenarios. ",
    "url": "https://arxiv.org/abs/2403.15927",
    "authors": [
      "Jinkun Zhang",
      "Edmund Yeh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2403.15933",
    "title": "Understanding Domain-Size Generalization in Markov Logic Networks",
    "abstract": "We study the generalization behavior of Markov Logic Networks (MLNs) across relational structures of different sizes. Multiple works have noticed that MLNs learned on a given domain generalize poorly across domains of different sizes. This behavior emerges from a lack of internal consistency within an MLN when used across different domain sizes. In this paper, we quantify this inconsistency and bound it in terms of the variance of the MLN parameters. The parameter variance also bounds the KL divergence between an MLN's marginal distributions taken from different domain sizes. We use these bounds to show that maximizing the data log-likelihood while simultaneously minimizing the parameter variance corresponds to two natural notions of generalization across domain sizes. Our theoretical results apply to Exponential Random Graphs and other Markov network based relational models. Finally, we observe that solutions known to decrease the variance of the MLN parameters, like regularization and Domain-Size Aware MLNs, increase the internal consistency of the MLNs. We empirically verify our results on four different datasets, with different methods to control parameter variance, showing that controlling parameter variance leads to better generalization. ",
    "url": "https://arxiv.org/abs/2403.15933",
    "authors": [
      "Florian Chen",
      "Felix Weitk\u00e4mper",
      "Sagar Malhotra"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.15937",
    "title": "Model, Analyze, and Comprehend User Interactions and Various Attributes  within a Social Media Platform",
    "abstract": "How can we effectively model, analyze, and comprehend user interactions and various attributes within a social media platform based on post-comment relationship? In this study, we propose a novel graph-based approach to model and analyze user interactions within a social media platform based on post-comment relationship. We construct a user interaction graph from social media data and analyze it to gain insights into community dynamics, user behavior, and content preferences. Our investigation reveals that while 56.05% of the active users are strongly connected within the community, only 0.8% of them significantly contribute to its dynamics. Moreover, we observe temporal variations in community activity, with certain periods experiencing heightened engagement. Additionally, our findings highlight a correlation between user activity and popularity showing that more active users are generally more popular. Alongside these, a preference for positive and informative content is also observed where 82.41% users preferred positive and informative content. Overall, our study provides a comprehensive framework for understanding and managing online communities, leveraging graph-based techniques to gain valuable insights into user behavior and community dynamics. ",
    "url": "https://arxiv.org/abs/2403.15937",
    "authors": [
      "Md Kaykobad Reza",
      "S M Maksudul Alam",
      "Yiran Luo",
      "Youzhe Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2403.15943",
    "title": "Feature Manipulation for DDPM based Change Detection",
    "abstract": "Change Detection is a classic task of computer vision that receives a bi-temporal image pair as input and separates the semantically changed and unchanged regions of it. The diffusion model is used in image synthesis and as a feature extractor and has been applied to various downstream tasks. Using this, a feature map is extracted from the pre-trained diffusion model from the large-scale data set, and changes are detected through the additional network. On the one hand, the current diffusion-based change detection approach focuses only on extracting a good feature map using the diffusion model. It obtains and uses differences without further adjustment to the created feature map. Our method focuses on manipulating the feature map extracted from the Diffusion Model to be more semantically useful, and for this, we propose two methods: Feature Attention and FDAF. Our model with Feature Attention achieved a state-of-the-art F1 score (90.18) and IoU (83.86) on the LEVIR-CD dataset. ",
    "url": "https://arxiv.org/abs/2403.15943",
    "authors": [
      "Zhenglin Li",
      "Yangchen Huang",
      "Mengran Zhu",
      "Jingyu Zhang",
      "JingHao Chang",
      "Houze Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.15947",
    "title": "Deep Domain Adaptation: A Sim2Real Neural Approach for Improving  Eye-Tracking Systems",
    "abstract": "Eye image segmentation is a critical step in eye tracking that has great influence over the final gaze estimate. Segmentation models trained using supervised machine learning can excel at this task, their effectiveness is determined by the degree of overlap between the narrow distributions of image properties defined by the target dataset and highly specific training datasets, of which there are few. Attempts to broaden the distribution of existing eye image datasets through the inclusion of synthetic eye images have found that a model trained on synthetic images will often fail to generalize back to real-world eye images. In remedy, we use dimensionality-reduction techniques to measure the overlap between the target eye images and synthetic training data, and to prune the training dataset in a manner that maximizes distribution overlap. We demonstrate that our methods result in robust, improved performance when tackling the discrepancy between simulation and real-world data samples. ",
    "url": "https://arxiv.org/abs/2403.15947",
    "authors": [
      "Viet Dung Nguyen",
      "Reynold Bailey",
      "Gabriel J. Diaz",
      "Chengyi Ma",
      "Alexander Fix",
      "Alexander Ororbia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.15955",
    "title": "Finding needles in a haystack: A Black-Box Approach to Invisible  Watermark Detection",
    "abstract": "In this paper, we propose WaterMark Detection (WMD), the first invisible watermark detection method under a black-box and annotation-free setting. WMD is capable of detecting arbitrary watermarks within a given reference dataset using a clean non-watermarked dataset as a reference, without relying on specific decoding methods or prior knowledge of the watermarking techniques. We develop WMD using foundations of offset learning, where a clean non-watermarked dataset enables us to isolate the influence of only watermarked samples in the reference dataset. Our comprehensive evaluations demonstrate the effectiveness of WMD, significantly outperforming naive detection methods, which only yield AUC scores around 0.5. In contrast, WMD consistently achieves impressive detection AUC scores, surpassing 0.9 in most single-watermark datasets and exceeding 0.7 in more challenging multi-watermark scenarios across diverse datasets and watermarking methods. As invisible watermarks become increasingly prevalent, while specific decoding techniques remain undisclosed, our approach provides a versatile solution and establishes a path toward increasing accountability, transparency, and trust in our digital visual content. ",
    "url": "https://arxiv.org/abs/2403.15955",
    "authors": [
      "Minzhou Pan",
      "Zhengting Wang",
      "Xin Dong",
      "Vikash Sehwag",
      "Lingjuan Lyu",
      "Xue Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.15959",
    "title": "Risk-Calibrated Human-Robot Interaction via Set-Valued Intent Prediction",
    "abstract": "Tasks where robots must cooperate with humans, such as navigating around a cluttered home or sorting everyday items, are challenging because they exhibit a wide range of valid actions that lead to similar outcomes. Moreover, zero-shot cooperation between human-robot partners is an especially challenging problem because it requires the robot to infer and adapt on the fly to a latent human intent, which could vary significantly from human to human. Recently, deep learned motion prediction models have shown promising results in predicting human intent but are prone to being confidently incorrect. In this work, we present Risk-Calibrated Interactive Planning (RCIP), which is a framework for measuring and calibrating risk associated with uncertain action selection in human-robot cooperation, with the fundamental idea that the robot should ask for human clarification when the risk associated with the uncertainty in the human's intent cannot be controlled. RCIP builds on the theory of set-valued risk calibration to provide a finite-sample statistical guarantee on the cumulative loss incurred by the robot while minimizing the cost of human clarification in complex multi-step settings. Our main insight is to frame the risk control problem as a sequence-level multi-hypothesis testing problem, allowing efficient calibration using a low-dimensional parameter that controls a pre-trained risk-aware policy. Experiments across a variety of simulated and real-world environments demonstrate RCIP's ability to predict and adapt to a diverse set of dynamic human intents. ",
    "url": "https://arxiv.org/abs/2403.15959",
    "authors": [
      "Justin Lidard",
      "Hang Pham",
      "Ariel Bachman",
      "Bryan Boateng",
      "Anirudha Majumdar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2403.15961",
    "title": "SAT Encoding of Partial Ordering Models for Graph Coloring Problems",
    "abstract": "In this paper, we suggest new SAT encodings of the partial-ordering based ILP model for the graph coloring problem (GCP) and the bandwidth coloring problem (BCP). The GCP asks for the minimum number of colors that can be assigned to the vertices of a given graph such that each two adjacent vertices get different colors. The BCP is a generalization, where each edge has a weight that enforces a minimal \"distance\" between the assigned colors, and the goal is to minimize the \"largest\" color used. For the widely studied GCP, we experimentally compare our new SAT encoding to the state-of-the-art approaches on the DIMACS benchmark set. Our evaluation confirms that this SAT encoding is effective for sparse graphs and even outperforms the state-of-the-art on some DIMACS instances. For the BCP, our theoretical analysis shows that the partial-ordering based SAT and ILP formulations have an asymptotically smaller size than that of the classical assignment-based model. Our practical evaluation confirms not only a dominance compared to the assignment-based encodings but also to the state-of-the-art approaches on a set of benchmark instances. Up to our knowledge, we have solved several open instances of the BCP from the literature for the first time. ",
    "url": "https://arxiv.org/abs/2403.15961",
    "authors": [
      "Daniel Faber",
      "Adalat Jabrayilov",
      "Petra Mutzel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2403.15962",
    "title": "Detection of Problem Gambling with Less Features Using Machine Learning  Methods",
    "abstract": "Analytic features in gambling study are performed based on the amount of data monitoring on user daily actions. While performing the detection of problem gambling, existing datasets provide relatively rich analytic features for building machine learning based model. However, considering the complexity and cost of collecting the analytic features in real applications, conducting precise detection with less features will tremendously reduce the cost of data collection. In this study, we propose a deep neural networks PGN4 that performs well when using limited analytic features. Through the experiment on two datasets, we discover that PGN4 only experiences a mere performance drop when cutting 102 features to 5 features. Besides, we find the commonality within the top 5 features from two datasets. ",
    "url": "https://arxiv.org/abs/2403.15962",
    "authors": [
      "Yang Jiao",
      "Gloria Wong-Padoongpatt",
      "Mei Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2403.15974",
    "title": "CBGT-Net: A Neuromimetic Architecture for Robust Classification of  Streaming Data",
    "abstract": "This paper describes CBGT-Net, a neural network model inspired by the cortico-basal ganglia-thalamic (CBGT) circuits found in mammalian brains. Unlike traditional neural network models, which either generate an output for each provided input, or an output after a fixed sequence of inputs, the CBGT-Net learns to produce an output after a sufficient criteria for evidence is achieved from a stream of observed data. For each observation, the CBGT-Net generates a vector that explicitly represents the amount of evidence the observation provides for each potential decision, accumulates the evidence over time, and generates a decision when the accumulated evidence exceeds a pre-defined threshold. We evaluate the proposed model on two image classification tasks, where models need to predict image categories based on a stream of small patches extracted from the image. We show that the CBGT-Net provides improved accuracy and robustness compared to models trained to classify from a single patch, and models leveraging an LSTM layer to classify from a fixed sequence length of patches. ",
    "url": "https://arxiv.org/abs/2403.15974",
    "authors": [
      "Shreya Sharma",
      "Dana Hughes",
      "Katia Sycara"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.15975",
    "title": "Prioritized Multi-Tenant Traffic Engineering for Dynamic QoS  Provisioning in Autonomous SDN-OpenFlow Edge Networks",
    "abstract": "This letter indicates the critical need for prioritized multi-tenant quality-of-service (QoS) management by emerging mobile edge systems, particularly for high-throughput beyond fifth-generation networks. Existing traffic engineering tools utilize complex functions baked into closed, proprietary infrastructures, largely limiting design flexibility, scalability, and adaptiveness. Hence, this study introduces a software-defined networking (SDN)-based dynamic QoS provisioning scheme that prioritizes multi-tenant network traffic while focusing on the base station-edge cloud scenario. The designed scheme first separates control and data planes and enables traffic management automation using SDN programmability. It then implements dynamic QoS management via the SDN-OpenFlow protocol, which ensures ample bandwidth for multiple priority flows and efficiently manages the remaining bandwidth for non-priority traffic. Empirical experiments are conducted with a Mininet network emulator and an OpenDayLight controller. Performance evaluation validates the proposed scheme's effectiveness in meeting multi-tenant QoS criteria, offering a robust solution for traffic prioritization in SDN-based edge networks. ",
    "url": "https://arxiv.org/abs/2403.15975",
    "authors": [
      "Mohammad Sajid Shahriar",
      "Faisal Ahmed",
      "Genshe Chen",
      "Khanh D. Pham",
      "Suresh Subramaniam",
      "Motoharu Matsuura",
      "Hiroshi Hasegawa",
      "Shih-Chun Lin"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2403.15981",
    "title": "Exploring Accurate 3D Phenotyping in Greenhouse through Neural Radiance  Fields",
    "abstract": "Accurate collection of plant phenotyping is critical to optimising sustainable farming practices in precision agriculture. Traditional phenotyping in controlled laboratory environments, while valuable, falls short in understanding plant growth under real-world conditions. Emerging sensor and digital technologies offer a promising approach for direct phenotyping of plants in farm environments. This study investigates a learning-based phenotyping method using the Neural Radiance Field to achieve accurate in-situ phenotyping of pepper plants in greenhouse environments. To quantitatively evaluate the performance of this method, traditional point cloud registration on 3D scanning data is implemented for comparison. Experimental result shows that NeRF(Neural Radiance Fields) achieves competitive accuracy compared to the 3D scanning methods. The mean distance error between the scanner-based method and the NeRF-based method is 0.865mm. This study shows that the learning-based NeRF method achieves similar accuracy to 3D scanning-based methods but with improved scalability and robustness. ",
    "url": "https://arxiv.org/abs/2403.15981",
    "authors": [
      "unhong Zhao",
      "Wei Ying",
      "Yaoqiang Pan",
      "Zhenfeng Yi",
      "Chao Chen",
      "Kewei Hu",
      "Hanwen Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.15994",
    "title": "Multi-Scale Spatio-Temporal Graph Convolutional Network for Facial  Expression Spotting",
    "abstract": "Facial expression spotting is a significant but challenging task in facial expression analysis. The accuracy of expression spotting is affected not only by irrelevant facial movements but also by the difficulty of perceiving subtle motions in micro-expressions. In this paper, we propose a Multi-Scale Spatio-Temporal Graph Convolutional Network (SpoT-GCN) for facial expression spotting. To extract more robust motion features, we track both short- and long-term motion of facial muscles in compact sliding windows whose window length adapts to the temporal receptive field of the network. This strategy, termed the receptive field adaptive sliding window strategy, effectively magnifies the motion features while alleviating the problem of severe head movement. The subtle motion features are then converted to a facial graph representation, whose spatio-temporal graph patterns are learned by a graph convolutional network. This network learns both local and global features from multiple scales of facial graph structures using our proposed facial local graph pooling (FLGP). Furthermore, we introduce supervised contrastive learning to enhance the discriminative capability of our model for difficult-to-classify frames. The experimental results on the SAMM-LV and CAS(ME)^2 datasets demonstrate that our method achieves state-of-the-art performance, particularly in micro-expression spotting. Ablation studies further verify the effectiveness of our proposed modules. ",
    "url": "https://arxiv.org/abs/2403.15994",
    "authors": [
      "Yicheng Deng",
      "Hideaki Hayashi",
      "Hajime Nagahara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16003",
    "title": "Diverse Representation Embedding for Lifelong Person Re-Identification",
    "abstract": "Lifelong Person Re-Identification (LReID) aims to continuously learn from successive data streams, matching individuals across multiple cameras. The key challenge for LReID is how to effectively preserve old knowledge while learning new information incrementally. Task-level domain gaps and limited old task datasets are key factors leading to catastrophic forgetting in ReLD, which are overlooked in existing methods. To alleviate this problem, we propose a novel Diverse Representation Embedding (DRE) framework for LReID. The proposed DRE preserves old knowledge while adapting to new information based on instance-level and task-level layout. Concretely, an Adaptive Constraint Module (ACM) is proposed to implement integration and push away operations between multiple representations, obtaining dense embedding subspace for each instance to improve matching ability on limited old task datasets. Based on the processed diverse representation, we interact knowledge between the adjustment model and the learner model through Knowledge Update (KU) and Knowledge Preservation (KP) strategies at the task-level layout, which reduce the task-wise domain gap on both old and new tasks, and exploit diverse representation of each instance in limited datasets from old tasks, improving model performance for extended periods. Extensive experiments were conducted on eleven Re-ID datasets, including five seen datasets for training in order-1 and order-2 orders and six unseen datasets for inference. Compared to state-of-the-art methods, our method achieves significantly improved performance in holistic, large-scale, and occluded datasets. ",
    "url": "https://arxiv.org/abs/2403.16003",
    "authors": [
      "Shiben Liu",
      "Huijie Fan",
      "Qiang Wang",
      "Xiai Chen",
      "Zhi Han",
      "Yandong Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16004",
    "title": "A Federated Parameter Aggregation Method for Node Classification Tasks  with Different Graph Network Structures",
    "abstract": "Over the past few years, federated learning has become widely used in various classical machine learning fields because of its collaborative ability to train data from multiple sources without compromising privacy. However, in the area of graph neural networks, the nodes and network structures of graphs held by clients are different in many practical applications, and the aggregation method that directly shares model gradients cannot be directly applied to this scenario. Therefore, this work proposes a federated aggregation method FLGNN applied to various graph federation scenarios and investigates the aggregation effect of parameter sharing at each layer of the graph neural network model. The effectiveness of the federated aggregation method FLGNN is verified by experiments on real datasets. Additionally, for the privacy security of FLGNN, this paper designs membership inference attack experiments and differential privacy defense experiments. The results show that FLGNN performs good robustness, and the success rate of privacy theft is further reduced by adding differential privacy defense methods. ",
    "url": "https://arxiv.org/abs/2403.16004",
    "authors": [
      "Hao Song",
      "Jiacheng Yao",
      "Zhengxi Li",
      "Shaocong Xu",
      "Shibo Jin",
      "Jiajun Zhou",
      "Chenbo Fu",
      "Qi Xuan",
      "Shanqing Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16013",
    "title": "Performance evaluation of accelerated complex multiple-precision LU  decomposition",
    "abstract": "The direct method is one of the most important algorithms for solving linear systems of equations, with LU decomposition comprising a significant portion of its computation time. This study explores strategies to accelerate complex LU decomposition using multiple-precision floating-point arithmetic of the multiple-component type. Specifically, we explore the potential efficiency gains using a combination of SIMDization and the 3M method for complex matrix multiplication. Our benchmark tests compare this approach with the direct method implementation in MPLAPACK, focusing on computation time and numerical errors. ",
    "url": "https://arxiv.org/abs/2403.16013",
    "authors": [
      "Tomonori Kouya"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2403.16021",
    "title": "Digital Twin Assisted Intelligent Network Management for Vehicular  Applications",
    "abstract": "The emerging data-driven methods based on artificial intelligence (AI) have paved the way for intelligent, flexible, and adaptive network management in vehicular applications. To enhance network management towards network automation, this article presents a digital twin (DT) assisted two-tier learning framework, which facilitates the automated life-cycle management of machine learning based intelligent network management functions (INMFs). Specifically, at a high tier, meta learning is employed to capture different levels of general features for the INMFs under nonstationary network conditions. At a low tier, individual learning models are customized for local networks based on fast model adaptation. Hierarchical DTs are deployed at the edge and cloud servers to assist the two-tier learning process, through closed-loop interactions with the physical network domain. Finally, a case study demonstrates the fast and accurate model adaptation ability of meta learning in comparison with benchmark schemes. ",
    "url": "https://arxiv.org/abs/2403.16021",
    "authors": [
      "Kaige Qu",
      "Weihua Zhuang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2403.16023",
    "title": "RPMArt: Towards Robust Perception and Manipulation for Articulated  Objects",
    "abstract": "Articulated objects are commonly found in daily life. It is essential that robots can exhibit robust perception and manipulation skills for articulated objects in real-world robotic applications. However, existing methods for articulated objects insufficiently address noise in point clouds and struggle to bridge the gap between simulation and reality, thus limiting the practical deployment in real-world scenarios. To tackle these challenges, we propose a framework towards Robust Perception and Manipulation for Articulated Objects (RPMArt), which learns to estimate the articulation parameters and manipulate the articulation part from the noisy point cloud. Our primary contribution is a Robust Articulation Network (RoArtNet) that is able to predict both joint parameters and affordable points robustly by local feature learning and point tuple voting. Moreover, we introduce an articulation-aware classification scheme to enhance its ability for sim-to-real transfer. Finally, with the estimated affordable point and articulation joint constraint, the robot can generate robust actions to manipulate articulated objects. After learning only from synthetic data, RPMArt is able to transfer zero-shot to real-world articulated objects. Experimental results confirm our approach's effectiveness, with our framework achieving state-of-the-art performance in both noise-added simulation and real-world environments. The code and data will be open-sourced for reproduction. More results are published on the project website at https://r-pmart.github.io . ",
    "url": "https://arxiv.org/abs/2403.16023",
    "authors": [
      "Junbo Wang",
      "Wenhai Liu",
      "Qiaojun Yu",
      "Yang You",
      "Liu Liu",
      "Weiming Wang",
      "Cewu Lu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16030",
    "title": "VCR-Graphormer: A Mini-batch Graph Transformer via Virtual Connections",
    "abstract": "Graph transformer has been proven as an effective graph learning method for its adoption of attention mechanism that is capable of capturing expressive representations from complex topological and feature information of graphs. Graph transformer conventionally performs dense attention (or global attention) for every pair of nodes to learn node representation vectors, resulting in quadratic computational costs that are unaffordable for large-scale graph data. Therefore, mini-batch training for graph transformers is a promising direction, but limited samples in each mini-batch can not support effective dense attention to encode informative representations. Facing this bottleneck, (1) we start by assigning each node a token list that is sampled by personalized PageRank (PPR) and then apply standard multi-head self-attention only on this list to compute its node representations. This PPR tokenization method decouples model training from complex graph topological information and makes heavy feature engineering offline and independent, such that mini-batch training of graph transformers is possible by loading each node's token list in batches. We further prove this PPR tokenization is viable as a graph convolution network with a fixed polynomial filter and jumping knowledge. However, only using personalized PageRank may limit information carried by a token list, which could not support different graph inductive biases for model training. To this end, (2) we rewire graphs by introducing multiple types of virtual connections through structure- and content-based super nodes that enable PPR tokenization to encode local and global contexts, long-range interaction, and heterophilous information into each node's token list, and then formalize our Virtual Connection Ranking based Graph Transformer (VCR-Graphormer). ",
    "url": "https://arxiv.org/abs/2403.16030",
    "authors": [
      "Dongqi Fu",
      "Zhigang Hua",
      "Yan Xie",
      "Jin Fang",
      "Si Zhang",
      "Kaan Sancak",
      "Hao Wu",
      "Andrey Malevich",
      "Jingrui He",
      "Bo Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16033",
    "title": "Node Classification via Semantic-Structural Attention-Enhanced Graph  Convolutional Networks",
    "abstract": "Graph data, also known as complex network data, is omnipresent across various domains and applications. Prior graph neural network models primarily focused on extracting task-specific structural features through supervised learning objectives, but they fell short in capturing the inherent semantic and structural features of the entire graph. In this paper, we introduce the semantic-structural attention-enhanced graph convolutional network (SSA-GCN), which not only models the graph structure but also extracts generalized unsupervised features to enhance vertex classification performance. The SSA-GCN's key contributions lie in three aspects: firstly, it derives semantic information through unsupervised feature extraction from a knowledge graph perspective; secondly, it obtains structural information through unsupervised feature extraction from a complex network perspective; and finally, it integrates these features through a cross-attention mechanism. By leveraging these features, we augment the graph convolutional network, thereby enhancing the model's generalization capabilities. Our experiments on the Cora and CiteSeer datasets demonstrate the performance improvements achieved by our proposed method. Furthermore, our approach also exhibits excellent accuracy under privacy settings, making it a robust and effective solution for graph data analysis. ",
    "url": "https://arxiv.org/abs/2403.16033",
    "authors": [
      "Hongyin Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.16048",
    "title": "Edit3K: Universal Representation Learning for Video Editing Components",
    "abstract": "This paper focuses on understanding the predominant video creation pipeline, i.e., compositional video editing with six main types of editing components, including video effects, animation, transition, filter, sticker, and text. In contrast to existing visual representation learning of visual materials (i.e., images/videos), we aim to learn visual representations of editing actions/components that are generally applied on raw materials. We start by proposing the first large-scale dataset for editing components of video creation, which covers about $3,094$ editing components with $618,800$ videos. Each video in our dataset is rendered by various image/video materials with a single editing component, which supports atomic visual understanding of different editing components. It can also benefit several downstream tasks, e.g., editing component recommendation, editing component recognition/retrieval, etc. Existing visual representation methods perform poorly because it is difficult to disentangle the visual appearance of editing components from raw materials. To that end, we benchmark popular alternative solutions and propose a novel method that learns to attend to the appearance of editing components regardless of raw materials. Our method achieves favorable results on editing component retrieval/recognition compared to the alternative solutions. A user study is also conducted to show that our representations cluster visually similar editing components better than other alternatives. Furthermore, our learned representations used to transition recommendation tasks achieve state-of-the-art results on the AutoTransition dataset. The code and dataset will be released for academic use. ",
    "url": "https://arxiv.org/abs/2403.16048",
    "authors": [
      "Xin Gu",
      "Libo Zhang",
      "Fan Chen",
      "Longyin Wen",
      "Yufei Wang",
      "Tiejian Luo",
      "Sijie Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16049",
    "title": "Enhancing Demand Prediction in Open Systems by Cartogram-aided Deep  Learning",
    "abstract": "Predicting temporal patterns across various domains poses significant challenges due to their nuanced and often nonlinear trajectories. To address this challenge, prediction frameworks have been continuously refined, employing data-driven statistical methods, mathematical models, and machine learning. Recently, as one of the challenging systems, shared transport systems such as public bicycles have gained prominence due to urban constraints and environmental concerns. Predicting rental and return patterns at bicycle stations remains a formidable task due to the system's openness and imbalanced usage patterns across stations. In this study, we propose a deep learning framework to predict rental and return patterns by leveraging cartogram approaches. The cartogram approach facilitates the prediction of demand for newly installed stations with no training data as well as long-period prediction, which has not been achieved before. We apply this method to public bicycle rental-and-return data in Seoul, South Korea, employing a spatial-temporal convolutional graph attention network. Our improved architecture incorporates batch attention and modified node feature updates for better prediction accuracy across different time scales. We demonstrate the effectiveness of our framework in predicting temporal patterns and its potential applications. ",
    "url": "https://arxiv.org/abs/2403.16049",
    "authors": [
      "Sangjoon Park",
      "Yongsung Kwon",
      "Hyungjoon Soh",
      "Mi Jin Lee",
      "Seung-Woo Son"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2403.16050",
    "title": "A General and Efficient Federated Split Learning with Pre-trained Image  Transformers for Heterogeneous Data",
    "abstract": "Federated Split Learning (FSL) is a promising distributed learning paradigm in practice, which gathers the strengths of both Federated Learning (FL) and Split Learning (SL) paradigms, to ensure model privacy while diminishing the resource overhead of each client, especially on large transformer models in a resource-constrained environment, e.g., Internet of Things (IoT). However, almost all works merely investigate the performance with simple neural network models in FSL. Despite the minor efforts focusing on incorporating Vision Transformers (ViT) as model architectures, they train ViT from scratch, thereby leading to enormous training overhead in each device with limited resources. Therefore, in this paper, we harness Pre-trained Image Transformers (PITs) as the initial model, coined FES-PIT, to accelerate the training process and improve model robustness. Furthermore, we propose FES-PTZO to hinder the gradient inversion attack, especially having the capability compatible with black-box scenarios, where the gradient information is unavailable. Concretely, FES-PTZO approximates the server gradient by utilizing a zeroth-order (ZO) optimization, which replaces the backward propagation with just one forward process. Empirically, we are the first to provide a systematic evaluation of FSL methods with PITs in real-world datasets, different partial device participations, and heterogeneous data splits. Our experiments verify the effectiveness of our algorithms. ",
    "url": "https://arxiv.org/abs/2403.16050",
    "authors": [
      "Yifan Shi",
      "Yuhui Zhang",
      "Ziyue Huang",
      "Xiaofeng Yang",
      "Li Shen",
      "Wei Chen",
      "Xueqian Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16051",
    "title": "Segment Anything Model for Road Network Graph Extraction",
    "abstract": "We propose SAM-Road, an adaptation of the Segment Anything Model (SAM) for extracting large-scale, vectorized road network graphs from satellite imagery. To predict graph geometry, we formulate it as a dense semantic segmentation task, leveraging the inherent strengths of SAM. The image encoder of SAM is fine-tuned to produce probability masks for roads and intersections, from which the graph vertices are extracted via simple non-maximum suppression. To predict graph topology, we designed a lightweight transformer-based graph neural network, which leverages the SAM image embeddings to estimate the edge existence probabilities between vertices. Our approach directly predicts the graph vertices and edges for large regions without expensive and complex post-processing heuristics, and is capable of building complete road network graphs spanning multiple square kilometers in a matter of seconds. With its simple, straightforward, and minimalist design, SAM-Road achieves comparable accuracy with the state-of-the-art method RNGDet++, while being 40 times faster on the City-scale dataset. We thus demonstrate the power of a foundational vision model when applied to a graph learning task. The code is available at https://github.com/htcr/sam_road. ",
    "url": "https://arxiv.org/abs/2403.16051",
    "authors": [
      "Congrui Hetang",
      "Haoru Xue",
      "Cindy Le",
      "Tianwei Yue",
      "Wenping Wang",
      "Yihui He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16055",
    "title": "Modal-adaptive Knowledge-enhanced Graph-based Financial Prediction from  Monetary Policy Conference Calls with LLM",
    "abstract": "Financial prediction from Monetary Policy Conference (MPC) calls is a new yet challenging task, which targets at predicting the price movement and volatility for specific financial assets by analyzing multimodal information including text, video, and audio. Although the existing work has achieved great success using cross-modal transformer blocks, it overlooks the potential external financial knowledge, the varying contributions of different modalities to financial prediction, as well as the innate relations among different financial assets. To tackle these limitations, we propose a novel Modal-Adaptive kNowledge-enhAnced Graph-basEd financial pRediction scheme, named MANAGER. Specifically, MANAGER resorts to FinDKG to obtain the external related knowledge for the input text. Meanwhile, MANAGER adopts BEiT-3 and Hidden-unit BERT (HuBERT) to extract the video and audio features, respectively. Thereafter, MANAGER introduces a novel knowledge-enhanced cross-modal graph that fully characterizes the semantic relations among text, external knowledge, video and audio, to adaptively utilize the information in different modalities, with ChatGLM2 as the backbone. Extensive experiments on a publicly available dataset Monopoly verify the superiority of our model over cutting-edge methods. ",
    "url": "https://arxiv.org/abs/2403.16055",
    "authors": [
      "Kun Ouyang",
      "Yi Liu",
      "Shicheng Li",
      "Ruihan Bao",
      "Keiko Harimoto",
      "Xu Sun"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2403.16066",
    "title": "A Temporal Graph Network Framework for Dynamic Recommendation",
    "abstract": "Recommender systems, crucial for user engagement on platforms like e-commerce and streaming services, often lag behind users' evolving preferences due to static data reliance. After Temporal Graph Networks (TGNs) were proposed, various studies have shown that TGN can significantly improve situations where the features of nodes and edges dynamically change over time. However, despite its promising capabilities, it has not been directly applied in recommender systems to date. Our study bridges this gap by directly implementing Temporal Graph Networks (TGN) in recommender systems, a first in this field. Using real-world datasets and a range of graph and history embedding methods, we show TGN's adaptability, confirming its effectiveness in dynamic recommendation scenarios. ",
    "url": "https://arxiv.org/abs/2403.16066",
    "authors": [
      "Yejin Kim",
      "Youngbin Lee",
      "Vincent Yuan",
      "Annika Lee",
      "Yongjae Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16067",
    "title": "Robust Diffusion Models for Adversarial Purification",
    "abstract": "Diffusion models (DMs) based adversarial purification (AP) has shown to be the most powerful alternative to adversarial training (AT). However, these methods neglect the fact that pre-trained diffusion models themselves are not robust to adversarial attacks as well. Additionally, the diffusion process can easily destroy semantic information and generate a high quality image but totally different from the original input image after the reverse process, leading to degraded standard accuracy. To overcome these issues, a natural idea is to harness adversarial training strategy to retrain or fine-tune the pre-trained diffusion model, which is computationally prohibitive. We propose a novel robust reverse process with adversarial guidance, which is independent of given pre-trained DMs and avoids retraining or fine-tuning the DMs. This robust guidance can not only ensure to generate purified examples retaining more semantic content but also mitigate the accuracy-robustness trade-off of DMs for the first time, which also provides DM-based AP an efficient adaptive ability to new attacks. Extensive experiments are conducted to demonstrate that our method achieves the state-of-the-art results and exhibits generalization against different attacks. ",
    "url": "https://arxiv.org/abs/2403.16067",
    "authors": [
      "Guang Lin",
      "Zerui Tao",
      "Jianhai Zhang",
      "Toshihisa Tanaka",
      "Qibin Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16072",
    "title": "On the Secrecy Enhancement of an Integrated Ground-Aerial Network with a  Hybrid FSO/THz Feeder Link",
    "abstract": "High altitude platforms (HAPs)-aided terrestrial-aerial communication technology based on free-space optical (FSO) and Terahertz (THz) feeder links has been attracting notable interest recently due to its great potential in reaching a higher data rate and connectivity. Nonetheless, the presence of harsh vertical propagation environments and potential aerial eavesdroppers are two of the main challenges limiting the reliability and security of such a technology. In this work, a secrecy-enhancing scheme for HAP-aided ground-aerial communication is proposed. The considered network consists of HAP-assisted communication between a ground station and a legitimate user under the threat of an aerial and ground eavesdropper. Thus, the proposed scheme leverages (i) HAP diversity by exploiting the presence of multiple flying HAPs and (ii) the use of a hybrid FSO/THz transmission scheme to offer better resilience against eavesdropping attacks. An analytical secrecy outage probability (SOP) expression is derived for the scheme in consideration. Results manifest the notable gain in security of the proposed scheme with respect to both (i) the single-HAP and (ii) THz feeder-based benchmark ones, where the proposed scheme's SOP is decreased by four orders of magnitude using $4$ HAPs with respect to the first benchmark scheme, while a $5$-dB secrecy gain is manifested with respect to the second benchmark one. ",
    "url": "https://arxiv.org/abs/2403.16072",
    "authors": [
      "Elmehdi Illi",
      "Marwa Qaraqe"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.16082",
    "title": "SoK: Comprehensive Analysis of Rug Pull Causes, Datasets, and Detection  Tools in DeFi",
    "abstract": "Rug pulls pose a grave threat to the cryptocurrency ecosystem, leading to substantial financial loss and undermining trust in decentralized finance (DeFi) projects. With the emergence of new rug pull patterns, research on rug pull is out of state. To fill this gap, we first conducted an extensive analysis of the literature review, encompassing both scholarly and industry sources. By examining existing academic articles and industrial discussions on rug pull projects, we present a taxonomy inclusive of 34 root causes, introducing six new categories inspired by industry sources: burn, hidden owner, ownership transfer, unverified contract, external call, and fake LP lock. Based on the developed taxonomy, we evaluated current rug pull datasets and explored the effectiveness and limitations of existing detection mechanisms. Our evaluation indicates that the existing datasets, which document 2,448 instances, address only 7 of the 34 root causes, amounting to a mere 20% coverage. It indicates that existing open-source datasets need to be improved to study rug pulls. In response, we have constructed a more comprehensive dataset containing 2,360 instances, expanding the coverage to 54% with the best effort. In addition, the examination of 14 detection tools showed that they can identify 25 of the 34 root causes, achieving a coverage of 73.5%. There are nine root causes (Fake LP Lock, Hidden Fee, and Destroy Token, Fake Money Transfer, Ownership Transfer, Liquidity Pool Block, Freeze Account, Wash-Trading, Hedge) that the existing tools cannot cover. Our work indicates that there is a significant gap between current research and detection tools, and the actual situation of rug pulls. ",
    "url": "https://arxiv.org/abs/2403.16082",
    "authors": [
      "Dianxiang Sun",
      "Wei Ma",
      "Liming Nie",
      "Yang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2403.16097",
    "title": "Can Language Models Pretend Solvers? Logic Code Simulation with LLMs",
    "abstract": "Transformer-based large language models (LLMs) have demonstrated significant potential in addressing logic problems. capitalizing on the great capabilities of LLMs for code-related activities, several frameworks leveraging logical solvers for logic reasoning have been proposed recently. While existing research predominantly focuses on viewing LLMs as natural language logic solvers or translators, their roles as logic code interpreters and executors have received limited attention. This study delves into a novel aspect, namely logic code simulation, which forces LLMs to emulate logical solvers in predicting the results of logical programs. To further investigate this novel task, we formulate our three research questions: Can LLMs efficiently simulate the outputs of logic codes? What strength arises along with logic code simulation? And what pitfalls? To address these inquiries, we curate three novel datasets tailored for the logic code simulation task and undertake thorough experiments to establish the baseline performance of LLMs in code simulation. Subsequently, we introduce a pioneering LLM-based code simulation technique, Dual Chains of Logic (DCoL). This technique advocates a dual-path thinking approach for LLMs, which has demonstrated state-of-the-art performance compared to other LLM prompt strategies, achieving a notable improvement in accuracy by 7.06% with GPT-4-Turbo. ",
    "url": "https://arxiv.org/abs/2403.16097",
    "authors": [
      "Minyu Chen",
      "Guoqiang Li",
      "Ling-I Wu",
      "Ruibang Liu",
      "Yuxin Su",
      "Xi Chang",
      "Jianxin Xue"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2403.16116",
    "title": "Self-Supervised Multi-Frame Neural Scene Flow",
    "abstract": "Neural Scene Flow Prior (NSFP) and Fast Neural Scene Flow (FNSF) have shown remarkable adaptability in the context of large out-of-distribution autonomous driving. Despite their success, the underlying reasons for their astonishing generalization capabilities remain unclear. Our research addresses this gap by examining the generalization capabilities of NSFP through the lens of uniform stability, revealing that its performance is inversely proportional to the number of input point clouds. This finding sheds light on NSFP's effectiveness in handling large-scale point cloud scene flow estimation tasks. Motivated by such theoretical insights, we further explore the improvement of scene flow estimation by leveraging historical point clouds across multiple frames, which inherently increases the number of point clouds. Consequently, we propose a simple and effective method for multi-frame point cloud scene flow estimation, along with a theoretical evaluation of its generalization abilities. Our analysis confirms that the proposed method maintains a limited generalization error, suggesting that adding multiple frames to the scene flow optimization process does not detract from its generalizability. Extensive experimental results on large-scale autonomous driving Waymo Open and Argoverse lidar datasets demonstrate that the proposed method achieves state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2403.16116",
    "authors": [
      "Dongrui Liu",
      "Daqi Liu",
      "Xueqian Li",
      "Sihao Lin",
      "Hongwei xie",
      "Bing Wang",
      "Xiaojun Chang",
      "Lei Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16125",
    "title": "A Codesign of Scheduling and Parallelization for Large Model Training in  Heterogeneous Clusters",
    "abstract": "Joint consideration of scheduling and adaptive parallelism offers great opportunities for improving the training efficiency of large models on heterogeneous GPU clusters. However, integrating adaptive parallelism into a cluster scheduler expands the cluster scheduling space. The new space is the product of the original scheduling space and the parallelism exploration space of adaptive parallelism (also a product of pipeline, data, and tensor parallelism). The exponentially enlarged scheduling space and ever-changing optimal parallelism plan from adaptive parallelism together result in the contradiction between low-overhead and accurate performance data acquisition for efficient cluster scheduling. This paper presents Crius, a training system for efficiently scheduling multiple large models with adaptive parallelism in a heterogeneous cluster. Crius proposes a novel scheduling granularity called Cell. It represents a job with deterministic resources and pipeline stages. The exploration space of Cell is shrunk to the product of only data and tensor parallelism, thus exposing the potential for accurate and low-overhead performance estimation. Crius then accurately estimates Cells and efficiently schedules training jobs. When a Cell is selected as a scheduling choice, its represented job runs with the optimal parallelism plan explored. Experimental results show that Crius reduces job completion time by up to 48.9% and schedules large models with up to 1.49x cluster throughput improvement. ",
    "url": "https://arxiv.org/abs/2403.16125",
    "authors": [
      "Chunyu Xue",
      "Weihao Cui",
      "Han Zhao",
      "Quan Chen",
      "Shulai Zhang",
      "Pengyu Yang",
      "Jing Yang",
      "Shaobo Li",
      "Minyi Guo"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16129",
    "title": "A Survey on Lexical Ambiguity Detection and Word Sense Disambiguation",
    "abstract": "This paper explores techniques that focus on understanding and resolving ambiguity in language within the field of natural language processing (NLP), highlighting the complexity of linguistic phenomena such as polysemy and homonymy and their implications for computational models. Focusing extensively on Word Sense Disambiguation (WSD), it outlines diverse approaches ranging from deep learning techniques to leveraging lexical resources and knowledge graphs like WordNet. The paper introduces cutting-edge methodologies like word sense extension (WSE) and neuromyotonic approaches, enhancing disambiguation accuracy by predicting new word senses. It examines specific applications in biomedical disambiguation and language specific optimisation and discusses the significance of cognitive metaphors in discourse analysis. The research identifies persistent challenges in the field, such as the scarcity of sense annotated corpora and the complexity of informal clinical texts. It concludes by suggesting future directions, including using large language models, visual WSD, and multilingual WSD systems, emphasising the ongoing evolution in addressing lexical complexities in NLP. This thinking perspective highlights the advancement in this field to enable computers to understand language more accurately. ",
    "url": "https://arxiv.org/abs/2403.16129",
    "authors": [
      "Miuru Abeysiriwardana",
      "Deshan Sumanathilaka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.16130",
    "title": "AKBR: Learning Adaptive Kernel-based Representations for Graph  Classification",
    "abstract": "In this paper, we propose a new model to learn Adaptive Kernel-based Representations (AKBR) for graph classification. Unlike state-of-the-art R-convolution graph kernels that are defined by merely counting any pair of isomorphic substructures between graphs and cannot provide an end-to-end learning mechanism for the classifier, the proposed AKBR approach aims to define an end-to-end representation learning model to construct an adaptive kernel matrix for graphs. To this end, we commence by leveraging a novel feature-channel attention mechanism to capture the interdependencies between different substructure invariants of original graphs. The proposed AKBR model can thus effectively identify the structural importance of different substructures, and compute the R-convolution kernel between pairwise graphs associated with the more significant substructures specified by their structural attentions. Since each row of the resulting kernel matrix can be theoretically seen as the embedding vector of a sample graph, the proposed AKBR model is able to directly employ the resulting kernel matrix as the graph feature matrix and input it into the classifier for classification (i.e., the SoftMax layer), naturally providing an end-to-end learning architecture between the kernel computation as well as the classifier. Experimental results show that the proposed AKBR model outperforms existing state-of-the-art graph kernels and deep learning methods on standard graph benchmarks. ",
    "url": "https://arxiv.org/abs/2403.16130",
    "authors": [
      "Feifei Qian",
      "Lixin Cui",
      "Yue Wang",
      "Hangyuan Du",
      "Lu Bai",
      "Edwin R. Hancock"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16131",
    "title": "Salience DETR: Enhancing Detection Transformer with Hierarchical  Salience Filtering Refinement",
    "abstract": "DETR-like methods have significantly increased detection performance in an end-to-end manner. The mainstream two-stage frameworks of them perform dense self-attention and select a fraction of queries for sparse cross-attention, which is proven effective for improving performance but also introduces a heavy computational burden and high dependence on stable query selection. This paper demonstrates that suboptimal two-stage selection strategies result in scale bias and redundancy due to the mismatch between selected queries and objects in two-stage initialization. To address these issues, we propose hierarchical salience filtering refinement, which performs transformer encoding only on filtered discriminative queries, for a better trade-off between computational efficiency and precision. The filtering process overcomes scale bias through a novel scale-independent salience supervision. To compensate for the semantic misalignment among queries, we introduce elaborate query refinement modules for stable two-stage initialization. Based on above improvements, the proposed Salience DETR achieves significant improvements of +4.0% AP, +0.2% AP, +4.4% AP on three challenging task-specific detection datasets, as well as 49.2% AP on COCO 2017 with less FLOPs. The code is available at https://github.com/xiuqhou/Salience-DETR. ",
    "url": "https://arxiv.org/abs/2403.16131",
    "authors": [
      "Xiuquan Hou",
      "Meiqin Liu",
      "Senlin Zhang",
      "Ping Wei",
      "Badong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16132",
    "title": "Runtime Monitoring and Fault Detection for Neural Network-Controlled  Systems",
    "abstract": "There is an emerging trend in applying deep learning methods to control complex nonlinear systems. This paper considers enhancing the runtime safety of nonlinear systems controlled by neural networks in the presence of disturbance and measurement noise. A robustly stable interval observer is designed to generate sound and precise lower and upper bounds for the neural network, nonlinear function, and system state. The obtained interval is utilised to monitor the real-time system safety and detect faults in the system outputs or actuators. An adaptive cruise control vehicular system is simulated to demonstrate effectiveness of the proposed design. ",
    "url": "https://arxiv.org/abs/2403.16132",
    "authors": [
      "Jianglin Lan",
      "Siyuan Zhan",
      "Ron Patton",
      "Xianxian Zhao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16137",
    "title": "A Survey on Self-Supervised Pre-Training of Graph Foundation Models: A  Knowledge-Based Perspective",
    "abstract": "Graph self-supervised learning is now a go-to method for pre-training graph foundation models, including graph neural networks, graph transformers, and more recent large language model (LLM)-based graph models. There is a wide variety of knowledge patterns embedded in the structure and properties of graphs which may be used for pre-training, but we lack a systematic overview of self-supervised pre-training tasks from the perspective of graph knowledge. In this paper, we comprehensively survey and analyze the pre-training tasks of graph foundation models from a knowledge-based perspective, consisting of microscopic (nodes, links, etc) and macroscopic knowledge (clusters, global structure, etc). It covers a total of 9 knowledge categories and 25 pre-training tasks, as well as various downstream task adaptation strategies. Furthermore, an extensive list of the related papers with detailed metadata is provided at https://github.com/Newiz430/Pretext. ",
    "url": "https://arxiv.org/abs/2403.16137",
    "authors": [
      "Ziwen Zhao",
      "Yuhua Li",
      "Yixiong Zou",
      "Ruixuan Li",
      "Rui Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.16146",
    "title": "Realtime Robust Shape Estimation of Deformable Linear Object",
    "abstract": "Realtime shape estimation of continuum objects and manipulators is essential for developing accurate planning and control paradigms. The existing methods that create dense point clouds from camera images, and/or use distinguishable markers on a deformable body have limitations in realtime tracking of large continuum objects/manipulators. The physical occlusion of markers can often compromise accurate shape estimation. We propose a robust method to estimate the shape of linear deformable objects in realtime using scattered and unordered key points. By utilizing a robust probability-based labeling algorithm, our approach identifies the true order of the detected key points and then reconstructs the shape using piecewise spline interpolation. The approach only relies on knowing the number of the key points and the interval between two neighboring points. We demonstrate the robustness of the method when key points are partially occluded. The proposed method is also integrated into a simulation in Unity for tracking the shape of a cable with a length of 1m and a radius of 5mm. The simulation results show that our proposed approach achieves an average length error of 1.07% over the continuum's centerline and an average cross-section error of 2.11mm. The real-world experiments of tracking and estimating a heavy-load cable prove that the proposed approach is robust under occlusion and complex entanglement scenarios. ",
    "url": "https://arxiv.org/abs/2403.16146",
    "authors": [
      "Jiaming Zhang",
      "Zhaomeng Zhang",
      "Yihao Liu",
      "Yaqian Chen",
      "Amir Kheradmand",
      "Mehran Armand"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16149",
    "title": "A Survey on Consumer IoT Traffic: Security and Privacy",
    "abstract": "For the past few years, the Consumer Internet of Things (CIoT) has entered public lives. While CIoT has improved the convenience of people's daily lives, it has also brought new security and privacy concerns. In this survey, we try to figure out what researchers can learn about the security and privacy of CIoT by traffic analysis, a popular method in the security community. From the security and privacy perspective, this survey seeks out the new characteristics in CIoT traffic analysis, the state-of-the-art progress in CIoT traffic analysis, and the challenges yet to be solved. We collected 310 papers from January 2018 to December 2023 related to CIoT traffic analysis from the security and privacy perspective and summarized the process of CIoT traffic analysis in which the new characteristics of CIoT are identified. Then, we detail existing works based on five application goals: device fingerprinting, user activity inference, malicious traffic analysis, security analysis, and measurement. At last, we discuss the new challenges and future research directions. ",
    "url": "https://arxiv.org/abs/2403.16149",
    "authors": [
      "Yan Jia",
      "Yuxin Song",
      "Zihou Liu",
      "Qingyin Tan",
      "Fangming Wang",
      "Yu Zhang",
      "Zheli Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16151",
    "title": "Ultra Low-Cost Two-Stage Multimodal System for Non-Normative Behavior  Detection",
    "abstract": "The online community has increasingly been inundated by a toxic wave of harmful comments. In response to this growing challenge, we introduce a two-stage ultra-low-cost multimodal harmful behavior detection method designed to identify harmful comments and images with high precision and recall rates. We first utilize the CLIP-ViT model to transform tweets and images into embeddings, effectively capturing the intricate interplay of semantic meaning and subtle contextual clues within texts and images. Then in the second stage, the system feeds these embeddings into a conventional machine learning classifier like SVM or logistic regression, enabling the system to be trained rapidly and to perform inference at an ultra-low cost. By converting tweets into rich multimodal embeddings through the CLIP-ViT model and utilizing them to train conventional machine learning classifiers, our system is not only capable of detecting harmful textual information with near-perfect performance, achieving precision and recall rates above 99\\% but also demonstrates the ability to zero-shot harmful images without additional training, thanks to its multimodal embedding input. This capability empowers our system to identify unseen harmful images without requiring extensive and costly image datasets. Additionally, our system quickly adapts to new harmful content; if a new harmful content pattern is identified, we can fine-tune the classifier with the corresponding tweets' embeddings to promptly update the system. This makes it well suited to addressing the ever-evolving nature of online harmfulness, providing online communities with a robust, generalizable, and cost-effective tool to safeguard their communities. ",
    "url": "https://arxiv.org/abs/2403.16151",
    "authors": [
      "Albert Lu",
      "Stephen Cranefield"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2403.16163",
    "title": "An Analytic Solution to Covariance Propagation in Neural Networks",
    "abstract": "Uncertainty quantification of neural networks is critical to measuring the reliability and robustness of deep learning systems. However, this often involves costly or inaccurate sampling methods and approximations. This paper presents a sample-free moment propagation technique that propagates mean vectors and covariance matrices across a network to accurately characterize the input-output distributions of neural networks. A key enabler of our technique is an analytic solution for the covariance of random variables passed through nonlinear activation functions, such as Heaviside, ReLU, and GELU. The wide applicability and merits of the proposed technique are shown in experiments analyzing the input-output distributions of trained neural networks and training Bayesian neural networks. ",
    "url": "https://arxiv.org/abs/2403.16163",
    "authors": [
      "Oren Wright",
      "Yorie Nakahira",
      "Jos\u00e9 M. F. Moura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.16176",
    "title": "Subspace Defense: Discarding Adversarial Perturbations by Learning a  Subspace for Clean Signals",
    "abstract": "Deep neural networks (DNNs) are notoriously vulnerable to adversarial attacks that place carefully crafted perturbations on normal examples to fool DNNs. To better understand such attacks, a characterization of the features carried by adversarial examples is needed. In this paper, we tackle this challenge by inspecting the subspaces of sample features through spectral analysis. We first empirically show that the features of either clean signals or adversarial perturbations are redundant and span in low-dimensional linear subspaces respectively with minimal overlap, and the classical low-dimensional subspace projection can suppress perturbation features out of the subspace of clean signals. This makes it possible for DNNs to learn a subspace where only features of clean signals exist while those of perturbations are discarded, which can facilitate the distinction of adversarial examples. To prevent the residual perturbations that is inevitable in subspace learning, we propose an independence criterion to disentangle clean signals from perturbations. Experimental results show that the proposed strategy enables the model to inherently suppress adversaries, which not only boosts model robustness but also motivates new directions of effective adversarial defense. ",
    "url": "https://arxiv.org/abs/2403.16176",
    "authors": [
      "Rui Zheng",
      "Yuhao Zhou",
      "Zhiheng Xi",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.16184",
    "title": "Improving Scene Graph Generation with Relation Words' Debiasing in  Vision-Language Models",
    "abstract": "Scene Graph Generation (SGG) provides basic language representation of visual scenes, requiring models to grasp complex and diverse semantics between various objects. However, this complexity and diversity in SGG also leads to underrepresentation, where part of test triplets are rare or even unseen during training, resulting in imprecise predictions. To tackle this, we propose using the SGG models with pretrained vision-language models (VLMs) to enhance representation. However, due to the gap between the pretraining and SGG, directly ensembling the pretrained VLMs leads to severe biases across relation words. Thus, we introduce LM Estimation to approximate the words' distribution underlies in the pretraining language sets, and then use the distribution for debiasing. After that, we ensemble VLMs with SGG models to enhance representation. Considering that each model may represent better at different samples, we use a certainty-aware indicator to score each sample and dynamically adjust the ensemble weights. Our method effectively addresses the words biases, enhances SGG's representation, and achieve markable performance enhancements. It is training-free and integrates well with existing SGG models. ",
    "url": "https://arxiv.org/abs/2403.16184",
    "authors": [
      "Yuxuan Wang",
      "Xiaoyuan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16188",
    "title": "Cross-domain Multi-modal Few-shot Object Detection via Rich Text",
    "abstract": "Cross-modal feature extraction and integration have led to steady performance improvements in few-shot learning tasks due to generating richer features. However, existing multi-modal object detection (MM-OD) methods degrade when facing significant domain-shift and are sample insufficient. We hypothesize that rich text information could more effectively help the model to build a knowledge relationship between the vision instance and its language description and can help mitigate domain shift. Specifically, we study the Cross-Domain few-shot generalization of MM-OD (CDMM-FSOD) and propose a meta-learning based multi-modal few-shot object detection method that utilizes rich text semantic information as an auxiliary modality to achieve domain adaptation in the context of FSOD. Our proposed network contains (i) a multi-modal feature aggregation module that aligns the vision and language support feature embeddings and (ii) a rich text semantic rectify module that utilizes bidirectional text feature generation to reinforce multi-modal feature alignment and thus to enhance the model's language understanding capability. We evaluate our model on common standard cross-domain object detection datasets and demonstrate that our approach considerably outperforms existing FSOD methods. ",
    "url": "https://arxiv.org/abs/2403.16188",
    "authors": [
      "Zeyu Shangguan",
      "Daniel Seita",
      "Mohammad Rostami"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16202",
    "title": "FH-SSTNet: Forehead Creases based User Verification using Spatio-Spatial  Temporal Network",
    "abstract": "Biometric authentication, which utilizes contactless features, such as forehead patterns, has become increasingly important for identity verification and access management. The proposed method is based on learning a 3D spatio-spatial temporal convolution to create detailed pictures of forehead patterns. We introduce a new CNN model called the Forehead Spatio-Spatial Temporal Network (FH-SSTNet), which utilizes a 3D CNN architecture with triplet loss to capture distinguishing features. We enhance the model's discrimination capability using Arcloss in the network's head. Experimentation on the Forehead Creases version 1 (FH-V1) dataset, containing 247 unique subjects, demonstrates the superior performance of FH-SSTNet compared to existing methods and pre-trained CNNs like ResNet50, especially for forehead-based user verification. The results demonstrate the superior performance of FH-SSTNet for forehead-based user verification, confirming its effectiveness in identity authentication. ",
    "url": "https://arxiv.org/abs/2403.16202",
    "authors": [
      "Geetanjali Sharma",
      "Gaurav Jaswal",
      "Aditya Nigam",
      "Raghavendra Ramachandra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16206",
    "title": "Rumor Detection with a novel graph neural network approach",
    "abstract": "The wide spread of rumors on social media has caused a negative impact on people's daily life, leading to potential panic, fear, and mental health problems for the public. How to debunk rumors as early as possible remains a challenging problem. Existing studies mainly leverage information propagation structure to detect rumors, while very few works focus on correlation among users that they may coordinate to spread rumors in order to gain large popularity. In this paper, we propose a new detection model, that jointly learns both the representations of user correlation and information propagation to detect rumors on social media. Specifically, we leverage graph neural networks to learn the representations of user correlation from a bipartite graph that describes the correlations between users and source tweets, and the representations of information propagation with a tree structure. Then we combine the learned representations from these two modules to classify the rumors. Since malicious users intend to subvert our model after deployment, we further develop a greedy attack scheme to analyze the cost of three adversarial attacks: graph attack, comment attack, and joint attack. Evaluation results on two public datasets illustrate that the proposed MODEL outperforms the state-of-the-art rumor detection models. We also demonstrate our method performs well for early rumor detection. Moreover, the proposed detection method is more robust to adversarial attacks compared to the best existing method. Importantly, we show that it requires a high cost for attackers to subvert user correlation pattern, demonstrating the importance of considering user correlation for rumor detection. ",
    "url": "https://arxiv.org/abs/2403.16206",
    "authors": [
      "Tianrui Liu",
      "Qi Cai",
      "Changxin Xu",
      "Bo Hong",
      "Fanghao Ni",
      "Yuxin Qiao",
      "Tsungwei Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16215",
    "title": "Systematic construction of continuous-time neural networks for linear  dynamical systems",
    "abstract": "Discovering a suitable neural network architecture for modeling complex dynamical systems poses a formidable challenge, often involving extensive trial and error and navigation through a high-dimensional hyper-parameter space. In this paper, we discuss a systematic approach to constructing neural architectures for modeling a subclass of dynamical systems, namely, Linear Time-Invariant (LTI) systems. We use a variant of continuous-time neural networks in which the output of each neuron evolves continuously as a solution of a first-order or second-order Ordinary Differential Equation (ODE). Instead of deriving the network architecture and parameters from data, we propose a gradient-free algorithm to compute sparse architecture and network parameters directly from the given LTI system, leveraging its properties. We bring forth a novel neural architecture paradigm featuring horizontal hidden layers and provide insights into why employing conventional neural architectures with vertical hidden layers may not be favorable. We also provide an upper bound on the numerical errors of our neural networks. Finally, we demonstrate the high accuracy of our constructed networks on three numerical examples. ",
    "url": "https://arxiv.org/abs/2403.16215",
    "authors": [
      "Chinmay Datar",
      "Adwait Datar",
      "Felix Dietrich",
      "Wil Schilders"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2403.16221",
    "title": "Exemplar-Free Class Incremental Learning via Incremental Representation",
    "abstract": "Exemplar-Free Class Incremental Learning (efCIL) aims to continuously incorporate the knowledge from new classes while retaining previously learned information, without storing any old-class exemplars (i.e., samples). For this purpose, various efCIL methods have been proposed over the past few years, generally with elaborately constructed old pseudo-features, increasing the difficulty of model development and interpretation. In contrast, we propose a \\textbf{simple Incremental Representation (IR) framework} for efCIL without constructing old pseudo-features. IR utilizes dataset augmentation to cover a suitable feature space and prevents the model from forgetting by using a single L2 space maintenance loss. We discard the transient classifier trained on each one of the sequence tasks and instead replace it with a 1-near-neighbor classifier for inference, ensuring the representation is incrementally updated during CIL. Extensive experiments demonstrate that our proposed IR achieves comparable performance while significantly preventing the model from forgetting on CIFAR100, TinyImageNet, and ImageNetSubset datasets. ",
    "url": "https://arxiv.org/abs/2403.16221",
    "authors": [
      "Libo Huang",
      "Zhulin An",
      "Yan Zeng",
      "Chuanguang Yang",
      "Xinqiang Yu",
      "Yongjun Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16222",
    "title": "Cyber-Security Knowledge Graph Generation by Hierarchical Nonnegative  Matrix Factorization",
    "abstract": "Much of human knowledge in cybersecurity is encapsulated within the ever-growing volume of scientific papers. As this textual data continues to expand, the importance of document organization methods becomes increasingly crucial for extracting actionable insights hidden within large text datasets. Knowledge Graphs (KGs) serve as a means to store factual information in a structured manner, providing explicit, interpretable knowledge that includes domain-specific information from the cybersecurity scientific literature. One of the challenges in constructing a KG from scientific literature is the extraction of ontology from unstructured text. In this paper, we address this topic and introduce a method for building a multi-modal KG by extracting structured ontology from scientific papers. We demonstrate this concept in the cybersecurity domain. One modality of the KG represents observable information from the papers, such as the categories in which they were published or the authors. The second modality uncovers latent (hidden) patterns of text extracted through hierarchical and semantic non-negative matrix factorization (NMF), such as named entities, topics or clusters, and keywords. We illustrate this concept by consolidating more than two million scientific papers uploaded to arXiv into the cyber-domain, using hierarchical and semantic NMF, and by building a cyber-domain-specific KG. ",
    "url": "https://arxiv.org/abs/2403.16222",
    "authors": [
      "Ryan Barron",
      "Maksim E. Eren",
      "Manish Bhattarai",
      "Nicholas Solovyev",
      "Kim Rasmussen",
      "Boian S. Alexandrov",
      "Charles Nicholas",
      "Cynthia Matuszek"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16224",
    "title": "Inverse Rendering of Glossy Objects via the Neural Plenoptic Function  and Radiance Fields",
    "abstract": "Inverse rendering aims at recovering both geometry and materials of objects. It provides a more compatible reconstruction for conventional rendering engines, compared with the neural radiance fields (NeRFs). On the other hand, existing NeRF-based inverse rendering methods cannot handle glossy objects with local light interactions well, as they typically oversimplify the illumination as a 2D environmental map, which assumes infinite lights only. Observing the superiority of NeRFs in recovering radiance fields, we propose a novel 5D Neural Plenoptic Function (NeP) based on NeRFs and ray tracing, such that more accurate lighting-object interactions can be formulated via the rendering equation. We also design a material-aware cone sampling strategy to efficiently integrate lights inside the BRDF lobes with the help of pre-filtered radiance fields. Our method has two stages: the geometry of the target object and the pre-filtered environmental radiance fields are reconstructed in the first stage, and materials of the target object are estimated in the second stage with the proposed NeP and material-aware cone sampling strategy. Extensive experiments on the proposed real-world and synthetic datasets demonstrate that our method can reconstruct high-fidelity geometry/materials of challenging glossy objects with complex lighting interactions from nearby objects. Project webpage: https://whyy.site/paper/nep ",
    "url": "https://arxiv.org/abs/2403.16224",
    "authors": [
      "Haoyuan Wang",
      "Wenbo Hu",
      "Lei Zhu",
      "Rynson W. H. Lau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16246",
    "title": "Partially Blinded Unlearning: Class Unlearning for Deep Networks a  Bayesian Perspective",
    "abstract": "In order to adhere to regulatory standards governing individual data privacy and safety, machine learning models must systematically eliminate information derived from specific subsets of a user's training data that can no longer be utilized. The emerging discipline of Machine Unlearning has arisen as a pivotal area of research, facilitating the process of selectively discarding information designated to specific sets or classes of data from a pre-trained model, thereby eliminating the necessity for extensive retraining from scratch. The principal aim of this study is to formulate a methodology tailored for the purposeful elimination of information linked to a specific class of data from a pre-trained classification network. This intentional removal is crafted to degrade the model's performance specifically concerning the unlearned data class while concurrently minimizing any detrimental impacts on the model's performance in other classes. To achieve this goal, we frame the class unlearning problem from a Bayesian perspective, which yields a loss function that minimizes the log-likelihood associated with the unlearned data with a stability regularization in parameter space. This stability regularization incorporates Mohalanobis distance with respect to the Fisher Information matrix and $l_2$ distance from the pre-trained model parameters. Our novel approach, termed \\textbf{Partially-Blinded Unlearning (PBU)}, surpasses existing state-of-the-art class unlearning methods, demonstrating superior effectiveness. Notably, PBU achieves this efficacy without requiring awareness of the entire training dataset but only to the unlearned data points, marking a distinctive feature of its performance. ",
    "url": "https://arxiv.org/abs/2403.16246",
    "authors": [
      "Subhodip Panda",
      "Shashwat Sourav",
      "Prathosh A.P"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16257",
    "title": "Unlearning Backdoor Threats: Enhancing Backdoor Defense in Multimodal  Contrastive Learning via Local Token Unlearning",
    "abstract": "Multimodal contrastive learning has emerged as a powerful paradigm for building high-quality features using the complementary strengths of various data modalities. However, the open nature of such systems inadvertently increases the possibility of backdoor attacks. These attacks subtly embed malicious behaviors within the model during training, which can be activated by specific triggers in the inference phase, posing significant security risks. Despite existing countermeasures through fine-tuning that reduce the adverse impacts of such attacks, these defenses often degrade the clean accuracy and necessitate the construction of extensive clean training pairs. In this paper, we explore the possibility of a less-cost defense from the perspective of model unlearning, that is, whether the model can be made to quickly \\textbf{u}nlearn \\textbf{b}ackdoor \\textbf{t}hreats (UBT) by constructing a small set of poisoned samples. Specifically, we strengthen the backdoor shortcuts to discover suspicious samples through overfitting training prioritized by weak similarity samples. Building on the initial identification of suspicious samples, we introduce an innovative token-based localized forgetting training regime. This technique specifically targets the poisoned aspects of the model, applying a focused effort to unlearn the backdoor associations and trying not to damage the integrity of the overall model. Experimental results show that our method not only ensures a minimal success rate for attacks, but also preserves the model's high clean accuracy. ",
    "url": "https://arxiv.org/abs/2403.16257",
    "authors": [
      "Siyuan Liang",
      "Kuanrong Liu",
      "Jiajun Gong",
      "Jiawei Liang",
      "Yuan Xun",
      "Ee-Chien Chang",
      "Xiaochun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16260",
    "title": "Out-of-Distribution Detection via Deep Multi-Comprehension Ensemble",
    "abstract": "Recent research underscores the pivotal role of the Out-of-Distribution (OOD) feature representation field scale in determining the efficacy of models in OOD detection. Consequently, the adoption of model ensembles has emerged as a prominent strategy to augment this feature representation field, capitalizing on anticipated model diversity. However, our introduction of novel qualitative and quantitative model ensemble evaluation methods, specifically Loss Basin/Barrier Visualization and the Self-Coupling Index, reveals a critical drawback in existing ensemble methods. We find that these methods incorporate weights that are affine-transformable, exhibiting limited variability and thus failing to achieve the desired diversity in feature representation. To address this limitation, we elevate the dimensions of traditional model ensembles, incorporating various factors such as different weight initializations, data holdout, etc., into distinct supervision tasks. This innovative approach, termed Multi-Comprehension (MC) Ensemble, leverages diverse training tasks to generate distinct comprehensions of the data and labels, thereby extending the feature representation field. Our experimental results demonstrate the superior performance of the MC Ensemble strategy in OOD detection compared to both the naive Deep Ensemble method and a standalone model of comparable size. This underscores the effectiveness of our proposed approach in enhancing the model's capability to detect instances outside its training distribution. ",
    "url": "https://arxiv.org/abs/2403.16260",
    "authors": [
      "Chenhui Xu",
      "Fuxun Yu",
      "Zirui Xu",
      "Nathan Inkawhich",
      "Xiang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.16262",
    "title": "HT-LIP Model based Robust Control of Quadrupedal Robot Locomotion under  Unknown Vertical Ground Motion",
    "abstract": "This paper presents a hierarchical control framework that enables robust quadrupedal locomotion on a dynamic rigid surface (DRS) with general and unknown vertical motions. The key novelty of the framework lies in its higher layer, which is a discrete-time, provably stabilizing footstep controller. The basis of the footstep controller is a new hybrid, time-varying, linear inverted pendulum (HT-LIP) model that is low-dimensional and accurately captures the essential robot dynamics during DRS locomotion. A new set of sufficient stability conditions are then derived to directly guide the controller design for ensuring the asymptotic stability of the HT-LIP model under general, unknown, vertical DRS motions. Further, the footstep controller is cast as a computationally efficient quadratic program that incorporates the proposed HT-LIP model and stability conditions. The middle layer takes the desired footstep locations generated by the higher layer as input to produce kinematically feasible full-body reference trajectories, which are then accurately tracked by a lower-layer torque controller. Hardware experiments on a Unitree Go1 quadrupedal robot confirm the robustness of the proposed framework under various unknown, aperiodic, vertical DRS motions and uncertainties (e.g., slippery and uneven surfaces, solid and liquid loads, and sudden pushes). ",
    "url": "https://arxiv.org/abs/2403.16262",
    "authors": [
      "Amir Iqbal",
      "Sushant Veer",
      "Christopher Niezrecki",
      "Yan Gu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.16265",
    "title": "Connecting the Dots: Inferring Patent Phrase Similarity with Retrieved  Phrase Graphs",
    "abstract": "We study the patent phrase similarity inference task, which measures the semantic similarity between two patent phrases. As patent documents employ legal and highly technical language, existing semantic textual similarity methods that use localized contextual information do not perform satisfactorily in inferring patent phrase similarity. To address this, we introduce a graph-augmented approach to amplify the global contextual information of the patent phrases. For each patent phrase, we construct a phrase graph that links to its focal patents and a list of patents that are either cited by or cite these focal patents. The augmented phrase embedding is then derived from combining its localized contextual embedding with its global embedding within the phrase graph. We further propose a self-supervised learning objective that capitalizes on the retrieved topology to refine both the contextualized embedding and the graph parameters in an end-to-end manner. Experimental results from a unique patent phrase similarity dataset demonstrate that our approach significantly enhances the representation of patent phrases, resulting in marked improvements in similarity inference in a self-supervised fashion. Substantial improvements are also observed in the supervised setting, underscoring the potential benefits of leveraging retrieved phrase graph augmentation. ",
    "url": "https://arxiv.org/abs/2403.16265",
    "authors": [
      "Zhuoyi Peng",
      "Yi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.16270",
    "title": "Constricting Normal Latent Space for Anomaly Detection with Normal-only  Training Data",
    "abstract": "In order to devise an anomaly detection model using only normal training data, an autoencoder (AE) is typically trained to reconstruct the data. As a result, the AE can extract normal representations in its latent space. During test time, since AE is not trained using real anomalies, it is expected to poorly reconstruct the anomalous data. However, several researchers have observed that it is not the case. In this work, we propose to limit the reconstruction capability of AE by introducing a novel latent constriction loss, which is added to the existing reconstruction loss. By using our method, no extra computational cost is added to the AE during test time. Evaluations using three video anomaly detection benchmark datasets, i.e., Ped2, Avenue, and ShanghaiTech, demonstrate the effectiveness of our method in limiting the reconstruction capability of AE, which leads to a better anomaly detection model. ",
    "url": "https://arxiv.org/abs/2403.16270",
    "authors": [
      "Marcella Astrid",
      "Muhammad Zaigham Zaheer",
      "Seung-Ik Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16272",
    "title": "L-MAE: Longitudinal masked auto-encoder with time and severity-aware  encoding for diabetic retinopathy progression prediction",
    "abstract": "Pre-training strategies based on self-supervised learning (SSL) have proven to be effective pretext tasks for many downstream tasks in computer vision. Due to the significant disparity between medical and natural images, the application of typical SSL is not straightforward in medical imaging. Additionally, those pretext tasks often lack context, which is critical for computer-aided clinical decision support. In this paper, we developed a longitudinal masked auto-encoder (MAE) based on the well-known Transformer-based MAE. In particular, we explored the importance of time-aware position embedding as well as disease progression-aware masking. Taking into account the time between examinations instead of just scheduling them offers the benefit of capturing temporal changes and trends. The masking strategy, for its part, evolves during follow-up to better capture pathological changes, ensuring a more accurate assessment of disease progression. Using OPHDIAT, a large follow-up screening dataset targeting diabetic retinopathy (DR), we evaluated the pre-trained weights on a longitudinal task, which is to predict the severity label of the next visit within 3 years based on the past time series examinations. Our results demonstrated the relevancy of both time-aware position embedding and masking strategies based on disease progression knowledge. Compared to popular baseline models and standard longitudinal Transformers, these simple yet effective extensions significantly enhance the predictive ability of deep classification models. ",
    "url": "https://arxiv.org/abs/2403.16272",
    "authors": [
      "Rachid Zeghlache",
      "Pierre-Henri Conze",
      "Mostafa El Habib Daho",
      "Yihao Li",
      "Alireza Rezaei",
      "Hugo Le Boit\u00e9",
      "Ramin Tadayoni",
      "Pascal Massin",
      "B\u00e9atrice Cochener",
      "Ikram Brahim",
      "Gwenol\u00e9 Quellec",
      "Mathieu Lamard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16301",
    "title": "Q-adaptive: A Multi-Agent Reinforcement Learning Based Routing on  Dragonfly Network",
    "abstract": "on adaptive routing to balance network traffic for optimum performance. Ideally, adaptive routing attempts to forward packets between minimal and non-minimal paths with the least congestion. In practice, current adaptive routing algorithms estimate routing path congestion based on local information such as output queue occupancy. Using local information to estimate global path congestion is inevitably inaccurate because a router has no precise knowledge of link states a few hops away. This inaccuracy could lead to interconnect congestion. In this study, we present Q-adaptive routing, a multi-agent reinforcement learning routing scheme for Dragonfly systems. Q-adaptive routing enables routers to learn to route autonomously by leveraging advanced reinforcement learning technology. The proposed Q-adaptive routing is highly scalable thanks to its fully distributed nature without using any shared information between routers. Furthermore, a new two-level Q-table is designed for Q-adaptive to make it computational lightly and saves 50% of router memory usage compared with the previous Q-routing. We implement the proposed Q-adaptive routing in SST/Merlin simulator. Our evaluation results show that Q-adaptive routing achieves up to 10.5% system throughput improvement and 5.2x average packet latency reduction compared with adaptive routing algorithms. Remarkably, Q-adaptive can even outperform the optimal VALn non-minimal routing under the ADV+1 adversarial traffic pattern with up to 3% system throughput improvement and 75% average packet latency reduction. ",
    "url": "https://arxiv.org/abs/2403.16301",
    "authors": [
      "Yao Kang",
      "Xin Wang",
      "Zhiling Lan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2403.16312",
    "title": "On Reporting Durable Patterns in Temporal Proximity Graphs",
    "abstract": "Finding patterns in graphs is a fundamental problem in databases and data mining. In many applications, graphs are temporal and evolve over time, so we are interested in finding durable patterns, such as triangles and paths, which persist over a long time. While there has been work on finding durable simple patterns, existing algorithms do not have provable guarantees and run in strictly super-linear time. The paper leverages the observation that many graphs arising in practice are naturally proximity graphs or can be approximated as such, where nodes are embedded as points in some high-dimensional space, and two nodes are connected by an edge if they are close to each other. We work with an implicit representation of the proximity graph, where nodes are additionally annotated by time intervals, and design near-linear-time algorithms for finding (approximately) durable patterns above a given durability threshold. We also consider an interactive setting where a client experiments with different durability thresholds in a sequence of queries; we show how to compute incremental changes to result patterns efficiently in time near-linear to the size of the changes. ",
    "url": "https://arxiv.org/abs/2403.16312",
    "authors": [
      "Pankaj K. Agarwal",
      "Xiao Hu",
      "Stavros Sintos",
      "Jun Yang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2403.16327",
    "title": "Artificial Neural Microcircuits as Building Blocks: Concept and  Challenges",
    "abstract": "Artificial Neural Networks (ANNs) are one of the most widely employed forms of bio-inspired computation. However the current trend is for ANNs to be structurally homogeneous. Furthermore, this structural homogeneity requires the application of complex training and learning tools that produce application specific ANNs, susceptible to pitfalls such as overfitting. In this paper, an new approach is explored, inspired by the role played in biology by Neural Microcircuits, the so called ``fundamental processing elements'' of organic nervous systems. How large neural networks, particularly Spiking Neural Networks (SNNs) can be assembled using Artificial Neural Microcircuits (ANMs), intended as off-the-shelf components, is articulated; the results of initial work to produce a catalogue of such Microcircuits though the use of Novelty Search is shown; followed by efforts to expand upon this initial work, including a discussion of challenges uncovered during these efforts and explorations of methods by which they might be overcome. ",
    "url": "https://arxiv.org/abs/2403.16327",
    "authors": [
      "Andrew Walter",
      "Shimeng Wu",
      "Andy M. Tyrrell",
      "Liam McDaid",
      "Malachy McElholm",
      "Nidhin Thandassery Sumithran",
      "Jim Harkin",
      "Martin A. Trefzer"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16329",
    "title": "Social Deliberation vs. Social Contracts in Self-Governing Voluntary  Organisations",
    "abstract": "Self-organising multi-agent systems regulate their components' behaviour voluntarily, according to a set of socially-constructed, mutually-agreed, and mutable social arrangements. In some systems, these arrangements may be applied with a frequency, at a scale and within implicit cost constraints such that performance becomes a pressing issue. This paper introduces the \\textit{Megabike Scenario}, which consists of a negotiated agreement on a relatively 'large' set of conventional rules, 'frequent' 'democratic' decision-making according to those rules, and a resource-bounded imperative to reach 'correct' decisions. A formalism is defined for effective rule representation and processing in the scenario, and is evaluated against five interleaved socio-functional requirements. System performance is also evaluated empirically through simulation. We conclude that to self-organise their social arrangements, agents need some awareness of their own limitations and the value of compromise. ",
    "url": "https://arxiv.org/abs/2403.16329",
    "authors": [
      "Matthew Scott",
      "Asimina Mertzani",
      "Ciske Smit",
      "Stefan Sarkadi",
      "Jeremy Pitt"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2403.16334",
    "title": "Graphs Generalization under Distribution Shifts",
    "abstract": "Traditional machine learning methods heavily rely on the independent and identically distribution assumption, which imposes limitations when the test distribution deviates from the training distribution. To address this crucial issue, out-of-distribution (OOD) generalization, which aims to achieve satisfactory generalization performance when faced with unknown distribution shifts, has made a significant process. However, the OOD method for graph-structured data currently lacks clarity and remains relatively unexplored due to two primary challenges. Firstly, distribution shifts on graphs often occur simultaneously on node attributes and graph topology. Secondly, capturing invariant information amidst diverse distribution shifts proves to be a formidable challenge. To overcome these obstacles, in this paper, we introduce a novel framework, namely Graph Learning Invariant Domain genERation (GLIDER). The goal is to (1) diversify variations across domains by modeling the potential seen or unseen variations of attribute distribution and topological structure and (2) minimize the discrepancy of the variation in a representation space where the target is to predict semantic labels. Extensive experiment results indicate that our model outperforms baseline methods on node-level OOD generalization across domains in distribution shift on node features and topological structures simultaneously. ",
    "url": "https://arxiv.org/abs/2403.16334",
    "authors": [
      "Qin Tian",
      "Wenjun Wang",
      "Chen Zhao",
      "Minglai Shao",
      "Wang Zhang",
      "Dong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16341",
    "title": "NonlinearSolve.jl: High-Performance and Robust Solvers for Systems of  Nonlinear Equations in Julia",
    "abstract": "Efficiently solving nonlinear equations underpins numerous scientific and engineering disciplines, yet scaling these solutions for complex system models remains a challenge. This paper presents NonlinearSolve.jl - a suite of high-performance open-source nonlinear equation solvers implemented natively in the Julia programming language. NonlinearSolve.jl distinguishes itself by offering a unified API that accommodates a diverse range of solver specifications alongside features such as automatic algorithm selection based on runtime analysis, support for GPU-accelerated computation through static array kernels, and the utilization of sparse automatic differentiation and Jacobian-free Krylov methods for large-scale problem-solving. Through rigorous comparison with established tools such as Sundials and MINPACK, NonlinearSolve.jl demonstrates unparalleled robustness and efficiency, achieving significant advancements in solving benchmark problems and challenging real-world applications. The capabilities of NonlinearSolve.jl unlock new potentials in modeling and simulation across various domains, making it a valuable addition to the computational toolkit of researchers and practitioners alike. ",
    "url": "https://arxiv.org/abs/2403.16341",
    "authors": [
      "Avik Pal",
      "Flemming Holtorf",
      "Axel Larsson",
      "Torkel Loman",
      "Utkarsh",
      "Frank Schaefer",
      "Qingyu Qu",
      "Alan Edelman",
      "Chris Rackauckas"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2403.16347",
    "title": "ChatGPT Incorrectness Detection in Software Reviews",
    "abstract": "We conducted a survey of 135 software engineering (SE) practitioners to understand how they use Generative AI-based chatbots like ChatGPT for SE tasks. We find that they want to use ChatGPT for SE tasks like software library selection but often worry about the truthfulness of ChatGPT responses. We developed a suite of techniques and a tool called CID (ChatGPT Incorrectness Detector) to automatically test and detect the incorrectness in ChatGPT responses. CID is based on the iterative prompting to ChatGPT by asking it contextually similar but textually divergent questions (using an approach that utilizes metamorphic relationships in texts). The underlying principle in CID is that for a given question, a response that is different from other responses (across multiple incarnations of the question) is likely an incorrect response. In a benchmark study of library selection, we show that CID can detect incorrect responses from ChatGPT with an F1-score of 0.74 - 0.75. ",
    "url": "https://arxiv.org/abs/2403.16347",
    "authors": [
      "Minaoar Hossain Tanzil",
      "Junaed Younus Khan",
      "Gias Uddin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16358",
    "title": "ChebMixer: Efficient Graph Representation Learning with MLP Mixer",
    "abstract": "Graph neural networks have achieved remarkable success in learning graph representations, especially graph Transformer, which has recently shown superior performance on various graph mining tasks. However, graph Transformer generally treats nodes as tokens, which results in quadratic complexity regarding the number of nodes during self-attention computation. The graph MLP Mixer addresses this challenge by using the efficient MLP Mixer technique from computer vision. However, the time-consuming process of extracting graph tokens limits its performance. In this paper, we present a novel architecture named ChebMixer, a newly graph MLP Mixer that uses fast Chebyshev polynomials-based spectral filtering to extract a sequence of tokens. Firstly, we produce multiscale representations of graph nodes via fast Chebyshev polynomial-based spectral filtering. Next, we consider each node's multiscale representations as a sequence of tokens and refine the node representation with an effective MLP Mixer. Finally, we aggregate the multiscale representations of nodes through Chebyshev interpolation. Owing to the powerful representation capabilities and fast computational properties of MLP Mixer, we can quickly extract more informative node representations to improve the performance of downstream tasks. The experimental results prove our significant improvements in a variety of scenarios ranging from graph node classification to medical image segmentation. ",
    "url": "https://arxiv.org/abs/2403.16358",
    "authors": [
      "Xiaoyan Kui",
      "Haonan Yan",
      "Qinsong Li",
      "Liming Chen",
      "Beiji Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16377",
    "title": "Real-time Adaptation for Condition Monitoring Signal Prediction using  Label-aware Neural Processes",
    "abstract": "Building a predictive model that rapidly adapts to real-time condition monitoring (CM) signals is critical for engineering systems/units. Unfortunately, many current methods suffer from a trade-off between representation power and agility in online settings. For instance, parametric methods that assume an underlying functional form for CM signals facilitate efficient online prediction updates. However, this simplification leads to vulnerability to model specifications and an inability to capture complex signals. On the other hand, approaches based on over-parameterized or non-parametric models can excel at explaining complex nonlinear signals, but real-time updates for such models pose a challenging task. In this paper, we propose a neural process-based approach that addresses this trade-off. It encodes available observations within a CM signal into a representation space and then reconstructs the signal's history and evolution for prediction. Once trained, the model can encode an arbitrary number of observations without requiring retraining, enabling on-the-spot real-time predictions along with quantified uncertainty and can be readily updated as more online data is gathered. Furthermore, our model is designed to incorporate qualitative information (i.e., labels) from individual units. This integration not only enhances individualized predictions for each unit but also enables joint inference for both signals and their associated labels. Numerical studies on both synthetic and real-world data in reliability engineering highlight the advantageous features of our model in real-time adaptation, enhanced signal prediction with uncertainty quantification, and joint prediction for labels and signals. ",
    "url": "https://arxiv.org/abs/2403.16377",
    "authors": [
      "Seokhyun Chung",
      "Raed Al Kontar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.16380",
    "title": "Tensor Neural Network Based Machine Learning Method for Elliptic  Multiscale Problems",
    "abstract": "In this paper, we introduce a type of tensor neural network based machine learning method to solve elliptic multiscale problems. Based on the special structure, we can do the direct and highly accurate high dimensional integrations for the tensor neural network functions without Monte Carlo process. Here, with the help of homogenization techniques, the multiscale problem is first transformed to the high dimensional limit problem with reasonable accuracy. Then, based on the tensor neural network, we design a type of machine learning method to solve the derived high dimensional limit problem. The proposed method in this paper brings a new way to design numerical methods for computing more general multiscale problems with high accuracy. Several numerical examples are also provided to validate the accuracy of the proposed numerical methods. ",
    "url": "https://arxiv.org/abs/2403.16380",
    "authors": [
      "Zhongshuo Lin",
      "Haochen Liu",
      "Hehu Xie"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2403.16393",
    "title": "Concurrent Linguistic Error Detection (CLED) for Large Language Models",
    "abstract": "The wide adoption of Large language models (LLMs) makes their dependability a pressing concern. Detection of errors is the first step to mitigating their impact on a system and thus, efficient error detection for LLMs is an important issue. In many settings, the LLM is considered as a black box with no access to the internal nodes; this prevents the use of many error detection schemes that need access to the model's internal nodes. An interesting observation is that the output of LLMs in error-free operation should be valid and normal text. Therefore, when the text is not valid or differs significantly from normal text, it is likely that there is an error. Based on this observation we propose to perform Concurrent Linguistic Error Detection (CLED); this scheme extracts some linguistic features of the text generated by the LLM and feeds them to a concurrent classifier that detects errors. Since the proposed error detection mechanism only relies on the outputs of the model, then it can be used on LLMs in which there is no access to the internal nodes. The proposed CLED scheme has been evaluated on the T5 model when used for news summarization and on the OPUS-MT model when used for translation. In both cases, the same set of linguistic features has been used for error detection to illustrate the applicability of the proposed scheme beyond a specific case. The results show that CLED can detect most of the errors at a low overhead penalty. The use of the concurrent classifier also enables a trade-off between error detection effectiveness and its associated overhead, so providing flexibility to a designer. ",
    "url": "https://arxiv.org/abs/2403.16393",
    "authors": [
      "Jinhua Zhu",
      "Javier Conde",
      "Zhen Gao",
      "Pedro Reviriego",
      "Shanshan Liu",
      "Fabrizio Lombardi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16395",
    "title": "Multi-attention Associate Prediction Network for Visual Tracking",
    "abstract": "Classification-regression prediction networks have realized impressive success in several modern deep trackers. However, there is an inherent difference between classification and regression tasks, so they have diverse even opposite demands for feature matching. Existed models always ignore the key issue and only employ a unified matching block in two task branches, decaying the decision quality. Besides, these models also struggle with decision misalignment situation. In this paper, we propose a multi-attention associate prediction network (MAPNet) to tackle the above problems. Concretely, two novel matchers, i.e., category-aware matcher and spatial-aware matcher, are first designed for feature comparison by integrating self, cross, channel or spatial attentions organically. They are capable of fully capturing the category-related semantics for classification and the local spatial contexts for regression, respectively. Then, we present a dual alignment module to enhance the correspondences between two branches, which is useful to find the optimal tracking solution. Finally, we describe a Siamese tracker built upon the proposed prediction network, which achieves the leading performance on five tracking benchmarks, consisting of LaSOT, TrackingNet, GOT-10k, TNL2k and UAV123, and surpasses other state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2403.16395",
    "authors": [
      "Xinglong Sun",
      "Haijiang Sun",
      "Shan Jiang",
      "Jiacheng Wang",
      "Xilai Wei",
      "Zhonghe Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16398",
    "title": "Rethinking the Representation in Federated Unsupervised Learning with  Non-IID Data",
    "abstract": "Federated learning achieves effective performance in modeling decentralized data. In practice, client data are not well-labeled, which makes it potential for federated unsupervised learning (FUSL) with non-IID data. However, the performance of existing FUSL methods suffers from insufficient representations, i.e., (1) representation collapse entanglement among local and global models, and (2) inconsistent representation spaces among local models. The former indicates that representation collapse in local model will subsequently impact the global model and other local models. The latter means that clients model data representation with inconsistent parameters due to the deficiency of supervision signals. In this work, we propose FedU2 which enhances generating uniform and unified representation in FUSL with non-IID data. Specifically, FedU2 consists of flexible uniform regularizer (FUR) and efficient unified aggregator (EUA). FUR in each client avoids representation collapse via dispersing samples uniformly, and EUA in server promotes unified representation by constraining consistent client model updating. To extensively validate the performance of FedU2, we conduct both cross-device and cross-silo evaluation experiments on two benchmark datasets, i.e., CIFAR10 and CIFAR100. ",
    "url": "https://arxiv.org/abs/2403.16398",
    "authors": [
      "Xinting Liao",
      "Weiming Liu",
      "Chaochao Chen",
      "Pengyang Zhou",
      "Fengyuan Yu",
      "Huabin Zhu",
      "Binhui Yao",
      "Tao Wang",
      "Xiaolin Zheng",
      "Yanchao Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16400",
    "title": "ASDF: Assembly State Detection Utilizing Late Fusion by Integrating 6D  Pose Estimation",
    "abstract": "In medical and industrial domains, providing guidance for assembly processes is critical to ensure efficiency and safety. Errors in assembly can lead to significant consequences such as extended surgery times, and prolonged manufacturing or maintenance times in industry. Assembly scenarios can benefit from in-situ AR visualization to provide guidance, reduce assembly times and minimize errors. To enable in-situ visualization 6D pose estimation can be leveraged. Existing 6D pose estimation techniques primarily focus on individual objects and static captures. However, assembly scenarios have various dynamics including occlusion during assembly and dynamics in the assembly objects appearance. Existing work, combining object detection/6D pose estimation and assembly state detection focuses either on pure deep learning-based approaches, or limit the assembly state detection to building blocks. To address the challenges of 6D pose estimation in combination with assembly state detection, our approach ASDF builds upon the strengths of YOLOv8, a real-time capable object detection framework. We extend this framework, refine the object pose and fuse pose knowledge with network-detected pose information. Utilizing our late fusion in our Pose2State module results in refined 6D pose estimation and assembly state detection. By combining both pose and state information, our Pose2State module predicts the final assembly state with precision. Our evaluation on our ASDF dataset shows that our Pose2State module leads to an improved assembly state detection and that the improvement of the assembly state further leads to a more robust 6D pose estimation. Moreover, on the GBOT dataset, we outperform the pure deep learning-based network, and even outperform the hybrid and pure tracking-based approaches. ",
    "url": "https://arxiv.org/abs/2403.16400",
    "authors": [
      "Hannah Schieber",
      "Shiyu Li",
      "Niklas Corell",
      "Philipp Beckerle",
      "Julian Kreimeier",
      "Daniel Roth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.16402",
    "title": "A Distributionally Robust Model Predictive Control for Static and  Dynamic Uncertainties in Smart Grids",
    "abstract": "The integration of various power sources, including renewables and electric vehicles, into smart grids is expanding, introducing uncertainties that can result in issues like voltage imbalances, load fluctuations, and power losses. These challenges negatively impact the reliability and stability of online scheduling in smart grids. Existing research often addresses uncertainties affecting current states but overlooks those that impact future states, such as the unpredictable charging patterns of electric vehicles. To distinguish between these, we term them static uncertainties and dynamic uncertainties, respectively. This paper introduces WDR-MPC, a novel approach that stands for two-stage Wasserstein-based Distributionally Robust (WDR) optimization within a Model Predictive Control (MPC) framework, aimed at effectively managing both types of uncertainties in smart grids. The dynamic uncertainties are first reformulated into ambiguity tubes and then the distributionally robust bounds of both dynamic and static uncertainties can be established using WDR optimization. By employing ambiguity tubes and WDR optimization, the stochastic MPC system is converted into a nominal one. Moreover, we develop a convex reformulation method to speed up WDR computation during the two-stage optimization. The distinctive contribution of this paper lies in its holistic approach to both static and dynamic uncertainties in smart grids. Comprehensive experiment results on IEEE 38-bus and 94-bus systems reveal the method's superior performance and the potential to enhance grid stability and reliability. ",
    "url": "https://arxiv.org/abs/2403.16402",
    "authors": [
      "Qi Li",
      "Ye Shi",
      "Yuning Jiang",
      "Yuanming Shi",
      "Haoyu Wang",
      "H.Vincent Poor"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.16405",
    "title": "Ensemble Adversarial Defense via Integration of Multiple Dispersed Low  Curvature Models",
    "abstract": "The integration of an ensemble of deep learning models has been extensively explored to enhance defense against adversarial attacks. The diversity among sub-models increases the attack cost required to deceive the majority of the ensemble, thereby improving the adversarial robustness. While existing approaches mainly center on increasing diversity in feature representations or dispersion of first-order gradients with respect to input, the limited correlation between these diversity metrics and adversarial robustness constrains the performance of ensemble adversarial defense. In this work, we aim to enhance ensemble diversity by reducing attack transferability. We identify second-order gradients, which depict the loss curvature, as a key factor in adversarial robustness. Computing the Hessian matrix involved in second-order gradients is computationally expensive. To address this, we approximate the Hessian-vector product using differential approximation. Given that low curvature provides better robustness, our ensemble model was designed to consider the influence of curvature among different sub-models. We introduce a novel regularizer to train multiple more-diverse low-curvature network models. Extensive experiments across various datasets demonstrate that our ensemble model exhibits superior robustness against a range of attacks, underscoring the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2403.16405",
    "authors": [
      "Kaikang Zhao",
      "Xi Chen",
      "Wei Huang",
      "Liuxin Ding",
      "Xianglong Kong",
      "Fan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16410",
    "title": "Spike-NeRF: Neural Radiance Field Based On Spike Camera",
    "abstract": "As a neuromorphic sensor with high temporal resolution, spike cameras offer notable advantages over traditional cameras in high-speed vision applications such as high-speed optical estimation, depth estimation, and object tracking. Inspired by the success of the spike camera, we proposed Spike-NeRF, the first Neural Radiance Field derived from spike data, to achieve 3D reconstruction and novel viewpoint synthesis of high-speed scenes. Instead of the multi-view images at the same time of NeRF, the inputs of Spike-NeRF are continuous spike streams captured by a moving spike camera in a very short time. To reconstruct a correct and stable 3D scene from high-frequency but unstable spike data, we devised spike masks along with a distinctive loss function. We evaluate our method qualitatively and numerically on several challenging synthetic scenes generated by blender with the spike camera simulator. Our results demonstrate that Spike-NeRF produces more visually appealing results than the existing methods and the baseline we proposed in high-speed scenes. Our code and data will be released soon. ",
    "url": "https://arxiv.org/abs/2403.16410",
    "authors": [
      "Yijia Guo",
      "Yuanxi Bai",
      "Liwen Hu",
      "Mianzhi Liu",
      "Ziyi Guo",
      "Lei Ma",
      "Tiejun Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16412",
    "title": "Unsupervised Template-assisted Point Cloud Shape Correspondence Network",
    "abstract": "Unsupervised point cloud shape correspondence aims to establish point-wise correspondences between source and target point clouds. Existing methods obtain correspondences directly by computing point-wise feature similarity between point clouds. However, non-rigid objects possess strong deformability and unusual shapes, making it a longstanding challenge to directly establish correspondences between point clouds with unconventional shapes. To address this challenge, we propose an unsupervised Template-Assisted point cloud shape correspondence Network, termed TANet, including a template generation module and a template assistance module. The proposed TANet enjoys several merits. Firstly, the template generation module establishes a set of learnable templates with explicit structures. Secondly, we introduce a template assistance module that extensively leverages the generated templates to establish more accurate shape correspondences from multiple perspectives. Extensive experiments on four human and animal datasets demonstrate that TANet achieves favorable performance against state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2403.16412",
    "authors": [
      "Jiacheng Deng",
      "Jiahao Lu",
      "Tianzhu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16432",
    "title": "$\\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on  Prompt-based Language Models",
    "abstract": "Prompt-based learning is a new language model training paradigm that adapts the Pre-trained Language Models (PLMs) to downstream tasks, which revitalizes the performance benchmarks across various natural language processing (NLP) tasks. Instead of using a fixed prompt template to fine-tune the model, some research demonstrates the effectiveness of searching for the prompt via optimization. Such prompt optimization process of prompt-based learning on PLMs also gives insight into generating adversarial prompts to mislead the model, raising concerns about the adversarial vulnerability of this paradigm. Recent studies have shown that universal adversarial triggers (UATs) can be generated to alter not only the predictions of the target PLMs but also the prediction of corresponding Prompt-based Fine-tuning Models (PFMs) under the prompt-based learning paradigm. However, UATs found in previous works are often unreadable tokens or characters and can be easily distinguished from natural texts with adaptive defenses. In this work, we consider the naturalness of the UATs and develop $\\textit{LinkPrompt}$, an adversarial attack algorithm to generate UATs by a gradient-based beam search algorithm that not only effectively attacks the target PLMs and PFMs but also maintains the naturalness among the trigger tokens. Extensive results demonstrate the effectiveness of $\\textit{LinkPrompt}$, as well as the transferability of UATs generated by \\textit{LinkPrompt} to open-sourced Large Language Model (LLM) Llama2 and API-accessed LLM GPT-3.5-turbo. ",
    "url": "https://arxiv.org/abs/2403.16432",
    "authors": [
      "Yue Xu",
      "Wenjie Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16439",
    "title": "Producing and Leveraging Online Map Uncertainty in Trajectory Prediction",
    "abstract": "High-definition (HD) maps have played an integral role in the development of modern autonomous vehicle (AV) stacks, albeit with high associated labeling and maintenance costs. As a result, many recent works have proposed methods for estimating HD maps online from sensor data, enabling AVs to operate outside of previously-mapped regions. However, current online map estimation approaches are developed in isolation of their downstream tasks, complicating their integration in AV stacks. In particular, they do not produce uncertainty or confidence estimates. In this work, we extend multiple state-of-the-art online map estimation methods to additionally estimate uncertainty and show how this enables more tightly integrating online mapping with trajectory forecasting. In doing so, we find that incorporating uncertainty yields up to 50% faster training convergence and up to 15% better prediction performance on the real-world nuScenes driving dataset. ",
    "url": "https://arxiv.org/abs/2403.16439",
    "authors": [
      "Xunjiang Gu",
      "Guanyu Song",
      "Igor Gilitschenski",
      "Marco Pavone",
      "Boris Ivanovic"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16440",
    "title": "RCBEVDet: Radar-camera Fusion in Bird's Eye View for 3D Object Detection",
    "abstract": "Three-dimensional object detection is one of the key tasks in autonomous driving. To reduce costs in practice, low-cost multi-view cameras for 3D object detection are proposed to replace the expansive LiDAR sensors. However, relying solely on cameras is difficult to achieve highly accurate and robust 3D object detection. An effective solution to this issue is combining multi-view cameras with the economical millimeter-wave radar sensor to achieve more reliable multi-modal 3D object detection. In this paper, we introduce RCBEVDet, a radar-camera fusion 3D object detection method in the bird's eye view (BEV). Specifically, we first design RadarBEVNet for radar BEV feature extraction. RadarBEVNet consists of a dual-stream radar backbone and a Radar Cross-Section (RCS) aware BEV encoder. In the dual-stream radar backbone, a point-based encoder and a transformer-based encoder are proposed to extract radar features, with an injection and extraction module to facilitate communication between the two encoders. The RCS-aware BEV encoder takes RCS as the object size prior to scattering the point feature in BEV. Besides, we present the Cross-Attention Multi-layer Fusion module to automatically align the multi-modal BEV feature from radar and camera with the deformable attention mechanism, and then fuse the feature with channel and spatial fusion layers. Experimental results show that RCBEVDet achieves new state-of-the-art radar-camera fusion results on nuScenes and view-of-delft (VoD) 3D object detection benchmarks. Furthermore, RCBEVDet achieves better 3D detection results than all real-time camera-only and radar-camera 3D object detectors with a faster inference speed at 21~28 FPS. The source code will be released at https://github.com/VDIGPKU/RCBEVDet. ",
    "url": "https://arxiv.org/abs/2403.16440",
    "authors": [
      "Zhiwei Lin",
      "Zhe Liu",
      "Zhongyu Xia",
      "Xinhao Wang",
      "Yongtao Wang",
      "Shengxiang Qi",
      "Yang Dong",
      "Nan Dong",
      "Le Zhang",
      "Ce Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16443",
    "title": "CodeS: Natural Language to Code Repository via Multi-Layer Sketch",
    "abstract": "The impressive performance of large language models (LLMs) on code-related tasks has shown the potential of fully automated software development. In light of this, we introduce a new software engineering task, namely Natural Language to code Repository (NL2Repo). This task aims to generate an entire code repository from its natural language requirements. To address this task, we propose a simple yet effective framework CodeS, which decomposes NL2Repo into multiple sub-tasks by a multi-layer sketch. Specifically, CodeS includes three modules: RepoSketcher, FileSketcher, and SketchFiller. RepoSketcher first generates a repository's directory structure for given requirements; FileSketcher then generates a file sketch for each file in the generated structure; SketchFiller finally fills in the details for each function in the generated file sketch. To rigorously assess CodeS on the NL2Repo task, we carry out evaluations through both automated benchmarking and manual feedback analysis. For benchmark-based evaluation, we craft a repository-oriented benchmark, SketchEval, and design an evaluation metric, SketchBLEU. For feedback-based evaluation, we develop a VSCode plugin for CodeS and engage 30 participants in conducting empirical studies. Extensive experiments prove the effectiveness and practicality of CodeS on the NL2Repo task. ",
    "url": "https://arxiv.org/abs/2403.16443",
    "authors": [
      "Daoguang Zan",
      "Ailun Yu",
      "Wei Liu",
      "Dong Chen",
      "Bo Shen",
      "Wei Li",
      "Yafen Yao",
      "Yongshun Gong",
      "Xiaolin Chen",
      "Bei Guan",
      "Zhiguang Yang",
      "Yongji Wang",
      "Qianxiang Wang",
      "Lizhen Cui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2403.16451",
    "title": "DeepMachining: Online Prediction of Machining Errors of Lathe Machines",
    "abstract": "We describe DeepMachining, a deep learning-based AI system for online prediction of machining errors of lathe machine operations. We have built and evaluated DeepMachining based on manufacturing data from factories. Specifically, we first pretrain a deep learning model for a given lathe machine's operations to learn the salient features of machining states. Then, we fine-tune the pretrained model to adapt to specific machining tasks. We demonstrate that DeepMachining achieves high prediction accuracy for multiple tasks that involve different workpieces and cutting tools. To the best of our knowledge, this work is one of the first factory experiments using pre-trained deep-learning models to predict machining errors of lathe machines. ",
    "url": "https://arxiv.org/abs/2403.16451",
    "authors": [
      "Xiang-Li Lu",
      "Hwai-Jung Hsu",
      "Che-Wei Chou",
      "H. T. Kung",
      "Chen-Hsin Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16459",
    "title": "On the rates of convergence for learning with convolutional neural  networks",
    "abstract": "We study the approximation and learning capacities of convolutional neural networks (CNNs). Our first result proves a new approximation bound for CNNs with certain constraint on the weights. Our second result gives a new analysis on the covering number of feed-forward neural networks, which include CNNs as special cases. The analysis carefully takes into account the size of the weights and hence gives better bounds than existing literature in some situations. Using these two results, we are able to derive rates of convergence for estimators based on CNNs in many learning problems. In particular, we establish minimax optimal convergence rates of the least squares based on CNNs for learning smooth functions in the nonparametric regression setting. For binary classification, we derive convergence rates for CNN classifiers with hinge loss and logistic loss. It is also shown that the obtained rates are minimax optimal in several settings. ",
    "url": "https://arxiv.org/abs/2403.16459",
    "authors": [
      "Yunfei Yang",
      "Han Feng",
      "Ding-Xuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.16460",
    "title": "FedAC: A Adaptive Clustered Federated Learning Framework for  Heterogeneous Data",
    "abstract": "Clustered federated learning (CFL) is proposed to mitigate the performance deterioration stemming from data heterogeneity in federated learning (FL) by grouping similar clients for cluster-wise model training. However, current CFL methods struggle due to inadequate integration of global and intra-cluster knowledge and the absence of an efficient online model similarity metric, while treating the cluster count as a fixed hyperparameter limits flexibility and robustness. In this paper, we propose an adaptive CFL framework, named FedAC, which (1) efficiently integrates global knowledge into intra-cluster learning by decoupling neural networks and utilizing distinct aggregation methods for each submodule, significantly enhancing performance; (2) includes a costeffective online model similarity metric based on dimensionality reduction; (3) incorporates a cluster number fine-tuning module for improved adaptability and scalability in complex, heterogeneous environments. Extensive experiments show that FedAC achieves superior empirical performance, increasing the test accuracy by around 1.82% and 12.67% on CIFAR-10 and CIFAR-100 datasets, respectively, under different non-IID settings compared to SOTA methods. ",
    "url": "https://arxiv.org/abs/2403.16460",
    "authors": [
      "Yuxin Zhang",
      "Haoyu Chen",
      "Zheng Lin",
      "Zhe Chen",
      "Jin Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2403.16464",
    "title": "Training Generative Adversarial Network-Based Vocoder with Limited Data  Using Augmentation-Conditional Discriminator",
    "abstract": "A generative adversarial network (GAN)-based vocoder trained with an adversarial discriminator is commonly used for speech synthesis because of its fast, lightweight, and high-quality characteristics. However, this data-driven model requires a large amount of training data incurring high data-collection costs. This fact motivates us to train a GAN-based vocoder on limited data. A promising solution is to augment the training data to avoid overfitting. However, a standard discriminator is unconditional and insensitive to distributional changes caused by data augmentation. Thus, augmented speech (which can be extraordinary) may be considered real speech. To address this issue, we propose an augmentation-conditional discriminator (AugCondD) that receives the augmentation state as input in addition to speech, thereby assessing the input speech according to the augmentation state, without inhibiting the learning of the original non-augmented distribution. Experimental results indicate that AugCondD improves speech quality under limited data conditions while achieving comparable speech quality under sufficient data conditions. Audio samples are available at https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/augcondd/. ",
    "url": "https://arxiv.org/abs/2403.16464",
    "authors": [
      "Takuhiro Kaneko",
      "Hirokazu Kameoka",
      "Kou Tanaka"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2403.16473",
    "title": "Plaintext-Free Deep Learning for Privacy-Preserving Medical Image  Analysis via Frequency Information Embedding",
    "abstract": "In the fast-evolving field of medical image analysis, Deep Learning (DL)-based methods have achieved tremendous success. However, these methods require plaintext data for training and inference stages, raising privacy concerns, especially in the sensitive area of medical data. To tackle these concerns, this paper proposes a novel framework that uses surrogate images for analysis, eliminating the need for plaintext images. This approach is called Frequency-domain Exchange Style Fusion (FESF). The framework includes two main components: Image Hidden Module (IHM) and Image Quality Enhancement Module~(IQEM). The~IHM performs in the frequency domain, blending the features of plaintext medical images into host medical images, and then combines this with IQEM to improve and create surrogate images effectively. During the diagnostic model training process, only surrogate images are used, enabling anonymous analysis without any plaintext data during both training and inference stages. Extensive evaluations demonstrate that our framework effectively preserves the privacy of medical images and maintains diagnostic accuracy of DL models at a relatively high level, proving its effectiveness across various datasets and DL-based models. ",
    "url": "https://arxiv.org/abs/2403.16473",
    "authors": [
      "Mengyu Sun",
      "Ziyuan Yang",
      "Maosong Ran",
      "Zhiwen Wang",
      "Hui Yu",
      "Yi Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2403.16479",
    "title": "Model-less Is the Best Model: Generating Pure Code Implementations to  Replace On-Device DL Models",
    "abstract": "Recent studies show that deployed deep learning (DL) models such as those of Tensor Flow Lite (TFLite) can be easily extracted from real-world applications and devices by attackers to generate many kinds of attacks like adversarial attacks. Although securing deployed on-device DL models has gained increasing attention, no existing methods can fully prevent the aforementioned threats. Traditional software protection techniques have been widely explored, if on-device models can be implemented using pure code, such as C++, it will open the possibility of reusing existing software protection techniques. However, due to the complexity of DL models, there is no automatic method that can translate the DL models to pure code. To fill this gap, we propose a novel method, CustomDLCoder, to automatically extract the on-device model information and synthesize a customized executable program for a wide range of DL models. CustomDLCoder first parses the DL model, extracts its backend computing units, configures the computing units to a graph, and then generates customized code to implement and deploy the ML solution without explicit model representation. The synthesized program hides model information for DL deployment environments since it does not need to retain explicit model representation, preventing many attacks on the DL model. In addition, it improves ML performance because the customized code removes model parsing and preprocessing steps and only retains the data computing process. Our experimental results show that CustomDLCoder improves model security by disabling on-device model sniffing. Compared with the original on-device platform (i.e., TFLite), our method can accelerate model inference by 21.0% and 24.3% on x86-64 and ARM64 platforms, respectively. Most importantly, it can significantly reduce memory consumption by 68.8% and 36.0% on x86-64 and ARM64 platforms, respectively. ",
    "url": "https://arxiv.org/abs/2403.16479",
    "authors": [
      "Mingyi Zhou",
      "Xiang Gao",
      "Pei Liu",
      "John Grundy",
      "Chunyang Chen",
      "Xiao Chen",
      "Li Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2403.16485",
    "title": "Real-time Model Predictive Control with Zonotope-Based Neural Networks  for Bipedal Social Navigation",
    "abstract": "This study addresses the challenge of bipedal navigation in a dynamic human-crowded environment, a research area that remains largely underexplored in the field of legged navigation. We propose two cascaded zonotope-based neural networks: a Pedestrian Prediction Network (PPN) for pedestrians' future trajectory prediction and an Ego-agent Social Network (ESN) for ego-agent social path planning. Representing future paths as zonotopes allows for efficient reachability-based planning and collision checking. The ESN is then integrated with a Model Predictive Controller (ESN-MPC) for footstep planning for our bipedal robot Digit designed by Agility Robotics. ESN-MPC solves for a collision-free optimal trajectory by optimizing through the gradients of ESN. ESN-MPC optimal trajectory is sent to the low-level controller for full-order simulation of Digit. The overall proposed framework is validated with extensive simulations on randomly generated initial settings with varying human crowd densities. ",
    "url": "https://arxiv.org/abs/2403.16485",
    "authors": [
      "Abdulaziz Shamsah",
      "Krishanu Agarwal",
      "Shreyas Kousik",
      "Ye Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.16486",
    "title": "ColonyOS -- A Meta-Operating System for Distributed Computing Across  Heterogeneous Platform",
    "abstract": "This paper presents ColonyOS, an open-source meta-operating system designed to improve integration and utilization of diverse computing platforms, including IoT, edge, cloud, and HPC. Operating as an overlay, ColonyOS can interface with a wide range of computing environments, fostering creation of so-called compute continuums. This makes it possible to develop AI workflows and applications that can operate across platforms. At its core, ColonyOS consists of distributed executors that integrate with various underlying platforms based on a distributed microservice architecture. These executors collectively form a colony, serving as a unified computing unit. To enable secure integration of various platforms, each colony is provisioned with precisely the resources needed, and all communication is confined within the colony governed by a strict zero-trust security protocol. Interaction with ColonyOS is done by submitting functional meta-descriptions of computational tasks, called function specifications. These are sent to a Colonies server, which acts as intermediary between applications and the executors. Upon assignment, an executor interprets the meta-description and translates it into an executable format, e.g. a Kubernetes deployment description, a Slurm script, or a direct function call within the executor. Furthermore, a built-in meta-file system enables data synchronization directives to be included in meta-descriptions, enabling seamless data management across platforms. Ultimately, ColonyOS paves the way for development of hyper-distributed applications and workflows, which can seamlessly operate in a computing continuum. The paper describes design principles and implementation details of ColonyOS. ",
    "url": "https://arxiv.org/abs/2403.16486",
    "authors": [
      "Johan Kristiansson"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2403.16494",
    "title": "CT-Bound: Fast Boundary Estimation From Noisy Images Via Hybrid  Convolution and Transformer Neural Networks",
    "abstract": "We present CT-Bound, a fast boundary estimation method for noisy images using a hybrid Convolution and Transformer neural network. The proposed architecture decomposes boundary estimation into two tasks: local detection and global regularization of image boundaries. It first estimates a parametric representation of boundary structures only using the input image within a small receptive field and then refines the boundary structure in the parameter domain without accessing the input image. Because of this, a part of the network can be easily trained using naive, synthetic images and still generalized to real images, and the entire architecture is computationally efficient as the boundary refinement is non-iterative and not in the image domain. Compared with the previous highest accuracy methods, our experiment shows that CT-Bound is 100 times faster, producing comparably accurate, high-quality boundary and color maps. We also demonstrate that CT-Bound can produce boundary and color maps on real captured images without extra fine-tuning and real-time boundary map and color map videos at ten frames per second. ",
    "url": "https://arxiv.org/abs/2403.16494",
    "authors": [
      "Wei Xu",
      "Junjie Luo",
      "Qi Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16495",
    "title": "LSTTN: A Long-Short Term Transformer-based Spatio-temporal Neural  Network for Traffic Flow Forecasting",
    "abstract": "Accurate traffic forecasting is a fundamental problem in intelligent transportation systems and learning long-range traffic representations with key information through spatiotemporal graph neural networks (STGNNs) is a basic assumption of current traffic flow prediction models. However, due to structural limitations, existing STGNNs can only utilize short-range traffic flow data; therefore, the models cannot adequately learn the complex trends and periodic features in traffic flow. Besides, it is challenging to extract the key temporal information from the long historical traffic series and obtain a compact representation. To solve the above problems, we propose a novel LSTTN (Long-Short Term Transformer-based Network) framework comprehensively considering the long- and short-term features in historical traffic flow. First, we employ a masked subseries Transformer to infer the content of masked subseries from a small portion of unmasked subseries and their temporal context in a pretraining manner, forcing the model to efficiently learn compressed and contextual subseries temporal representations from long historical series. Then, based on the learned representations, long-term trend is extracted by using stacked 1D dilated convolution layers, and periodic features are extracted by dynamic graph convolution layers. For the difficulties in making time-step level prediction, LSTTN adopts a short-term trend extractor to learn fine-grained short-term temporal features. Finally, LSTTN fuses the long-term trend, periodic features and short-term features to obtain the prediction results. Experiments on four real-world datasets show that in 60-minute-ahead long-term forecasting, the LSTTN model achieves a minimum improvement of 5.63\\% and a maximum improvement of 16.78\\% over baseline models. The source code is available at https://github.com/GeoX-Lab/LSTTN. ",
    "url": "https://arxiv.org/abs/2403.16495",
    "authors": [
      "Qinyao Luo",
      "Silu He",
      "Xing Han",
      "Yuhan Wang",
      "Haifeng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.16499",
    "title": "Self-Supervised Learning for Medical Image Data with Anatomy-Oriented  Imaging Planes",
    "abstract": "Self-supervised learning has emerged as a powerful tool for pretraining deep networks on unlabeled data, prior to transfer learning of target tasks with limited annotation. The relevance between the pretraining pretext and target tasks is crucial to the success of transfer learning. Various pretext tasks have been proposed to utilize properties of medical image data (e.g., three dimensionality), which are more relevant to medical image analysis than generic ones for natural images. However, previous work rarely paid attention to data with anatomy-oriented imaging planes, e.g., standard cardiac magnetic resonance imaging views. As these imaging planes are defined according to the anatomy of the imaged organ, pretext tasks effectively exploiting this information can pretrain the networks to gain knowledge on the organ of interest. In this work, we propose two complementary pretext tasks for this group of medical image data based on the spatial relationship of the imaging planes. The first is to learn the relative orientation between the imaging planes and implemented as regressing their intersecting lines. The second exploits parallel imaging planes to regress their relative slice locations within a stack. Both pretext tasks are conceptually straightforward and easy to implement, and can be combined in multitask learning for better representation learning. Thorough experiments on two anatomical structures (heart and knee) and representative target tasks (semantic segmentation and classification) demonstrate that the proposed pretext tasks are effective in pretraining deep networks for remarkably boosted performance on the target tasks, and superior to other recent approaches. ",
    "url": "https://arxiv.org/abs/2403.16499",
    "authors": [
      "Tianwei Zhang",
      "Dong Wei",
      "Mengmeng Zhua",
      "Shi Gu",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16514",
    "title": "Linguistically Differentiating Acts and Recalls of Racial  Microaggressions on Social Media",
    "abstract": "In this work, we examine the linguistic signature of online racial microaggressions (acts) and how it differs from that of personal narratives recalling experiences of such aggressions (recalls) by Black social media users. We manually curate and annotate a corpus of acts and recalls from in-the-wild social media discussions, and verify labels with Black workshop participants. We leverage Natural Language Processing (NLP) and qualitative analysis on this data to classify (RQ1), interpret (RQ2), and characterize (RQ3) the language underlying acts and recalls of racial microaggressions in the context of racism in the U.S. Our findings show that neural language models (LMs) can classify acts and recalls with high accuracy (RQ1) with contextual words revealing themes that associate Blacks with objects that reify negative stereotypes (RQ2). Furthermore, overlapping linguistic signatures between acts and recalls serve functionally different purposes (RQ3), providing broader implications to the current challenges in content moderation systems on social media. ",
    "url": "https://arxiv.org/abs/2403.16514",
    "authors": [
      "Uma Sushmitha Gunturi",
      "Anisha Kumar",
      "Xiaohan Ding",
      "Eugenia H. Rho"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.16517",
    "title": "Norm Violation Detection in Multi-Agent Systems using Large Language  Models: A Pilot Study",
    "abstract": "Norms are an important component of the social fabric of society by prescribing expected behaviour. In Multi-Agent Systems (MAS), agents interacting within a society are equipped to possess social capabilities such as reasoning about norms and trust. Norms have long been of interest within the Normative Multi-Agent Systems community with researchers studying topics such as norm emergence, norm violation detection and sanctioning. However, these studies have some limitations: they are often limited to simple domains, norms have been represented using a variety of representations with no standard approach emerging, and the symbolic reasoning mechanisms generally used may suffer from a lack of extensibility and robustness. In contrast, Large Language Models (LLMs) offer opportunities to discover and reason about norms across a large range of social situations. This paper evaluates the capability of LLMs to detecting norm violations. Based on simulated data from 80 stories in a household context, with varying complexities, we investigated whether 10 norms are violated. For our evaluations we first obtained the ground truth from three human evaluators for each story. Then, the majority result was compared against the results from three well-known LLM models (Llama 2 7B, Mixtral 7B and ChatGPT-4). Our results show the promise of ChatGPT-4 for detecting norm violations, with Mixtral some distance behind. Also, we identify areas where these models perform poorly and discuss implications for future work. ",
    "url": "https://arxiv.org/abs/2403.16517",
    "authors": [
      "Shawn He",
      "Surangika Ranathunga",
      "Stephen Cranefield",
      "Bastin Tony Roy Savarimuthu"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2403.16520",
    "title": "CMViM: Contrastive Masked Vim Autoencoder for 3D Multi-modal  Representation Learning for AD classification",
    "abstract": "Alzheimer's disease (AD) is an incurable neurodegenerative condition leading to cognitive and functional deterioration. Given the lack of a cure, prompt and precise AD diagnosis is vital, a complex process dependent on multiple factors and multi-modal data. While successful efforts have been made to integrate multi-modal representation learning into medical datasets, scant attention has been given to 3D medical images. In this paper, we propose Contrastive Masked Vim Autoencoder (CMViM), the first efficient representation learning method tailored for 3D multi-modal data. Our proposed framework is built on a masked Vim autoencoder to learn a unified multi-modal representation and long-dependencies contained in 3D medical images. We also introduce an intra-modal contrastive learning module to enhance the capability of the multi-modal Vim encoder for modeling the discriminative features in the same modality, and an inter-modal contrastive learning module to alleviate misaligned representation among modalities. Our framework consists of two main steps: 1) incorporate the Vision Mamba (Vim) into the mask autoencoder to reconstruct 3D masked multi-modal data efficiently. 2) align the multi-modal representations with contrastive learning mechanisms from both intra-modal and inter-modal aspects. Our framework is pre-trained and validated ADNI2 dataset and validated on the downstream task for AD classification. The proposed CMViM yields 2.7\\% AUC performance improvement compared with other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2403.16520",
    "authors": [
      "Guangqian Yang",
      "Kangrui Du",
      "Zhihan Yang",
      "Ye Du",
      "Yongping Zheng",
      "Shujun Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16527",
    "title": "Hallucination Detection in Foundation Models for Decision-Making: A  Flexible Definition and Review of the State of the Art",
    "abstract": "Autonomous systems are soon to be ubiquitous, from manufacturing autonomy to agricultural field robots, and from health care assistants to the entertainment industry. The majority of these systems are developed with modular sub-components for decision-making, planning, and control that may be hand-engineered or learning-based. While these existing approaches have been shown to perform well under the situations they were specifically designed for, they can perform especially poorly in rare, out-of-distribution scenarios that will undoubtedly arise at test-time. The rise of foundation models trained on multiple tasks with impressively large datasets from a variety of fields has led researchers to believe that these models may provide common sense reasoning that existing planners are missing. Researchers posit that this common sense reasoning will bridge the gap between algorithm development and deployment to out-of-distribution tasks, like how humans adapt to unexpected scenarios. Large language models have already penetrated the robotics and autonomous systems domains as researchers are scrambling to showcase their potential use cases in deployment. While this application direction is very promising empirically, foundation models are known to hallucinate and generate decisions that may sound reasonable, but are in fact poor. We argue there is a need to step back and simultaneously design systems that can quantify the certainty of a model's decision, and detect when it may be hallucinating. In this work, we discuss the current use cases of foundation models for decision-making tasks, provide a general definition for hallucinations with examples, discuss existing approaches to hallucination detection and mitigation with a focus on decision problems, and explore areas for further research in this exciting field. ",
    "url": "https://arxiv.org/abs/2403.16527",
    "authors": [
      "Neeloy Chakraborty",
      "Melkior Ornik",
      "Katherine Driggs-Campbell"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.16540",
    "title": "Enhancing Cross-Dataset EEG Emotion Recognition: A Novel Approach with  Emotional EEG Style Transfer Network",
    "abstract": "Recognizing the pivotal role of EEG emotion recognition in the development of affective Brain-Computer Interfaces (aBCIs), considerable research efforts have been dedicated to this field. While prior methods have demonstrated success in intra-subject EEG emotion recognition, a critical challenge persists in addressing the style mismatch between EEG signals from the source domain (training data) and the target domain (test data). To tackle the significant inter-domain differences in cross-dataset EEG emotion recognition, this paper introduces an innovative solution known as the Emotional EEG Style Transfer Network (E$^2$STN). The primary objective of this network is to effectively capture content information from the source domain and the style characteristics from the target domain, enabling the reconstruction of stylized EEG emotion representations. These representations prove highly beneficial in enhancing cross-dataset discriminative prediction. Concretely, E$^2$STN consists of three key modules\\textemdash transfer module, transfer evaluation module, and discriminative prediction module\\textemdash which address the domain style transfer, transfer quality evaluation, and discriminative prediction, respectively. Extensive experiments demonstrate that E$^2$STN achieves state-of-the-art performance in cross-dataset EEG emotion recognition tasks. ",
    "url": "https://arxiv.org/abs/2403.16540",
    "authors": [
      "Yijin Zhou",
      "Fu Li",
      "Yang Li",
      "Youshuo Ji",
      "Lijian Zhang",
      "Yuanfang Chen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2403.16543",
    "title": "Efficient Information Extraction in Few-Shot Relation Classification  through Contrastive Representation Learning",
    "abstract": "Differentiating relationships between entity pairs with limited labeled instances poses a significant challenge in few-shot relation classification. Representations of textual data extract rich information spanning the domain, entities, and relations. In this paper, we introduce a novel approach to enhance information extraction combining multiple sentence representations and contrastive learning. While representations in relation classification are commonly extracted using entity marker tokens, we argue that substantial information within the internal model representations remains untapped. To address this, we propose aligning multiple sentence representations, such as the [CLS] token, the [MASK] token used in prompting, and entity marker tokens. Our method employs contrastive learning to extract complementary discriminative information from these individual representations. This is particularly relevant in low-resource settings where information is scarce. Leveraging multiple sentence representations is especially effective in distilling discriminative information for relation classification when additional information, like relation descriptions, are not available. We validate the adaptability of our approach, maintaining robust performance in scenarios that include relation descriptions, and showcasing its flexibility to adapt to different resource constraints. ",
    "url": "https://arxiv.org/abs/2403.16543",
    "authors": [
      "Philipp Borchert",
      "Jochen De Weerdt",
      "Marie-Francine Moens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16561",
    "title": "FedFixer: Mitigating Heterogeneous Label Noise in Federated Learning",
    "abstract": "Federated Learning (FL) heavily depends on label quality for its performance. However, the label distribution among individual clients is always both noisy and heterogeneous. The high loss incurred by client-specific samples in heterogeneous label noise poses challenges for distinguishing between client-specific and noisy label samples, impacting the effectiveness of existing label noise learning approaches. To tackle this issue, we propose FedFixer, where the personalized model is introduced to cooperate with the global model to effectively select clean client-specific samples. In the dual models, updating the personalized model solely at a local level can lead to overfitting on noisy data due to limited samples, consequently affecting both the local and global models' performance. To mitigate overfitting, we address this concern from two perspectives. Firstly, we employ a confidence regularizer to alleviate the impact of unconfident predictions caused by label noise. Secondly, a distance regularizer is implemented to constrain the disparity between the personalized and global models. We validate the effectiveness of FedFixer through extensive experiments on benchmark datasets. The results demonstrate that FedFixer can perform well in filtering noisy label samples on different clients, especially in highly heterogeneous label noise scenarios. ",
    "url": "https://arxiv.org/abs/2403.16561",
    "authors": [
      "Xinyuan Ji",
      "Zhaowei Zhu",
      "Wei Xi",
      "Olga Gadyatskaya",
      "Zilong Song",
      "Yong Cai",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16569",
    "title": "Revealing Vulnerabilities of Neural Networks in Parameter Learning and  Defense Against Explanation-Aware Backdoors",
    "abstract": "Explainable Artificial Intelligence (XAI) strategies play a crucial part in increasing the understanding and trustworthiness of neural networks. Nonetheless, these techniques could potentially generate misleading explanations. Blinding attacks can drastically alter a machine learning algorithm's prediction and explanation, providing misleading information by adding visually unnoticeable artifacts into the input, while maintaining the model's accuracy. It poses a serious challenge in ensuring the reliability of XAI methods. To ensure the reliability of XAI methods poses a real challenge, we leverage statistical analysis to highlight the changes in CNN weights within a CNN following blinding attacks. We introduce a method specifically designed to limit the effectiveness of such attacks during the evaluation phase, avoiding the need for extra training. The method we suggest defences against most modern explanation-aware adversarial attacks, achieving an approximate decrease of ~99\\% in the Attack Success Rate (ASR) and a ~91\\% reduction in the Mean Square Error (MSE) between the original explanation and the defended (post-attack) explanation across three unique types of attacks. ",
    "url": "https://arxiv.org/abs/2403.16569",
    "authors": [
      "Md Abdul Kadir",
      "GowthamKrishna Addluri",
      "Daniel Sonntag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16591",
    "title": "Deciphering the Interplay between Local Differential Privacy, Average  Bayesian Privacy, and Maximum Bayesian Privacy",
    "abstract": "The swift evolution of machine learning has led to emergence of various definitions of privacy due to the threats it poses to privacy, including the concept of local differential privacy (LDP). Although widely embraced and utilized across numerous domains, this conventional approach to measure privacy still exhibits certain limitations, spanning from failure to prevent inferential disclosure to lack of consideration for the adversary's background knowledge. In this comprehensive study, we introduce Bayesian privacy and delve into the intricate relationship between local differential privacy and its Bayesian counterparts, unveiling novel insights into utility-privacy trade-offs. We introduce a framework that encapsulates both attack and defense strategies, highlighting their interplay and effectiveness. Our theoretical contributions are anchored in the rigorous definitions and relationships between Average Bayesian Privacy (ABP) and Maximum Bayesian Privacy (MBP), encapsulated by equations $\\epsilon_{p,a} \\leq \\frac{1}{\\sqrt{2}}\\sqrt{(\\epsilon_{p,m} + \\epsilon)\\cdot(e^{\\epsilon_{p,m} + \\epsilon} - 1)}$ and the equivalence between $\\xi$-MBP and $2\\xi$-LDP established under uniform prior distribution. These relationships fortify our understanding of the privacy guarantees provided by various mechanisms, leading to the realization that a mechanism satisfying $\\xi$-LDP also confers $\\xi$-MBP, and vice versa. Our work not only lays the groundwork for future empirical exploration but also promises to enhance the design of privacy-preserving algorithms that do not compromise on utility, thereby fostering the development of trustworthy machine learning solutions. ",
    "url": "https://arxiv.org/abs/2403.16591",
    "authors": [
      "Xiaojin Zhang",
      "Yulin Fei",
      "Wei Chen",
      "Hai Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.16592",
    "title": "TrustAI at SemEval-2024 Task 8: A Comprehensive Analysis of Multi-domain  Machine Generated Text Detection Techniques",
    "abstract": "The Large Language Models (LLMs) exhibit remarkable ability to generate fluent content across a wide spectrum of user queries. However, this capability has raised concerns regarding misinformation and personal information leakage. In this paper, we present our methods for the SemEval2024 Task8, aiming to detect machine-generated text across various domains in both mono-lingual and multi-lingual contexts. Our study comprehensively analyzes various methods to detect machine-generated text, including statistical, neural, and pre-trained model approaches. We also detail our experimental setup and perform a in-depth error analysis to evaluate the effectiveness of these methods. Our methods obtain an accuracy of 86.9\\% on the test set of subtask-A mono and 83.7\\% for subtask-B. Furthermore, we also highlight the challenges and essential factors for consideration in future studies. ",
    "url": "https://arxiv.org/abs/2403.16592",
    "authors": [
      "Ashok Urlana",
      "Aditya Saibewar",
      "Bala Mallikarjunarao Garlapati",
      "Charaka Vinayak Kumar",
      "Ajeet Kumar Singh",
      "Srinivasa Rao Chalamala"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.16614",
    "title": "Semantically Enriched Cross-Lingual Sentence Embeddings for  Crisis-related Social Media Texts",
    "abstract": "Tasks such as semantic search and clustering on crisis-related social media texts enhance our comprehension of crisis discourse, aiding decision-making and targeted interventions. Pre-trained language models have advanced performance in crisis informatics, but their contextual embeddings lack semantic meaningfulness. Although the CrisisTransformers family includes a sentence encoder to address the semanticity issue, it remains monolingual, processing only English texts. Furthermore, employing separate models for different languages leads to embeddings in distinct vector spaces, introducing challenges when comparing semantic similarities between multi-lingual texts. Therefore, we propose multi-lingual sentence encoders (CT-XLMR-SE and CT-mBERT-SE) that embed crisis-related social media texts for over 50 languages, such that texts with similar meanings are in close proximity within the same vector space, irrespective of language diversity. Results in sentence encoding and sentence matching tasks are promising, suggesting these models could serve as robust baselines when embedding multi-lingual crisis-related social media texts. The models are publicly available at: https://huggingface.co/crisistransformers. ",
    "url": "https://arxiv.org/abs/2403.16614",
    "authors": [
      "Rabindra Lamsal",
      "Maria Rodriguez Read",
      "Shanika Karunasekera"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.16630",
    "title": "A comparative analysis of embedding models for patent similarity",
    "abstract": "This paper makes two contributions to the field of text-based patent similarity. First, it compares the performance of different kinds of patent-specific pretrained embedding models, namely static word embeddings (such as word2vec and doc2vec models) and contextual word embeddings (such as transformers based models), on the task of patent similarity calculation. Second, it compares specifically the performance of Sentence Transformers (SBERT) architectures with different training phases on the patent similarity task. To assess the models' performance, we use information about patent interferences, a phenomenon in which two or more patent claims belonging to different patent applications are proven to be overlapping by patent examiners. Therefore, we use these interferences cases as a proxy for maximum similarity between two patents, treating them as ground-truth to evaluate the performance of the different embedding models. Our results point out that, first, Patent SBERT-adapt-ub, the domain adaptation of the pretrained Sentence Transformer architecture proposed in this research, outperforms the current state-of-the-art in patent similarity. Second, they show that, in some cases, large static models performances are still comparable to contextual ones when trained on extensive data; thus, we believe that the superiority in the performance of contextual embeddings may not be related to the actual architecture but rather to the way the training phase is performed. ",
    "url": "https://arxiv.org/abs/2403.16630",
    "authors": [
      "Grazia Sveva Ascione",
      "Valerio Sterzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16638",
    "title": "AI-Generated Video Detection via Spatio-Temporal Anomaly Learning",
    "abstract": "The advancement of generation models has led to the emergence of highly realistic artificial intelligence (AI)-generated videos. Malicious users can easily create non-existent videos to spread false information. This letter proposes an effective AI-generated video detection (AIGVDet) scheme by capturing the forensic traces with a two-branch spatio-temporal convolutional neural network (CNN). Specifically, two ResNet sub-detectors are learned separately for identifying the anomalies in spatical and optical flow domains, respectively. Results of such sub-detectors are fused to further enhance the discrimination ability. A large-scale generated video dataset (GVD) is constructed as a benchmark for model training and evaluation. Extensive experimental results verify the high generalization and robustness of our AIGVDet scheme. Code and dataset will be available at https://github.com/multimediaFor/AIGVDet. ",
    "url": "https://arxiv.org/abs/2403.16638",
    "authors": [
      "Jianfa Bai",
      "Man Lin",
      "Gang Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.16656",
    "title": "Graph Augmentation for Recommendation",
    "abstract": "Graph augmentation with contrastive learning has gained significant attention in the field of recommendation systems due to its ability to learn expressive user representations, even when labeled data is limited. However, directly applying existing GCL models to real-world recommendation environments poses challenges. There are two primary issues to address. Firstly, the lack of consideration for data noise in contrastive learning can result in noisy self-supervised signals, leading to degraded performance. Secondly, many existing GCL approaches rely on graph neural network (GNN) architectures, which can suffer from over-smoothing problems due to non-adaptive message passing. To address these challenges, we propose a principled framework called GraphAug. This framework introduces a robust data augmentor that generates denoised self-supervised signals, enhancing recommender systems. The GraphAug framework incorporates a graph information bottleneck (GIB)-regularized augmentation paradigm, which automatically distills informative self-supervision information and adaptively adjusts contrastive view generation. Through rigorous experimentation on real-world datasets, we thoroughly assessed the performance of our novel GraphAug model. The outcomes consistently unveil its superiority over existing baseline methods. The source code for our model is publicly available at: https://github.com/HKUDS/GraphAug. ",
    "url": "https://arxiv.org/abs/2403.16656",
    "authors": [
      "Qianru Zhang",
      "Lianghao Xia",
      "Xuheng Cai",
      "Siuming Yiu",
      "Chao Huang",
      "Christian S. Jensen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2403.16668",
    "title": "Who is bragging more online? A large scale analysis of bragging in  social media",
    "abstract": "Bragging is the act of uttering statements that are likely to be positively viewed by others and it is extensively employed in human communication with the aim to build a positive self-image of oneself. Social media is a natural platform for users to employ bragging in order to gain admiration, respect, attention and followers from their audiences. Yet, little is known about the scale of bragging online and its characteristics. This paper employs computational sociolinguistics methods to conduct the first large scale study of bragging behavior on Twitter (U.S.) by focusing on its overall prevalence, temporal dynamics and impact of demographic factors. Our study shows that the prevalence of bragging decreases over time within the same population of users. In addition, younger, more educated and popular users in the U.S. are more likely to brag. Finally, we conduct an extensive linguistics analysis to unveil specific bragging themes associated with different user traits. ",
    "url": "https://arxiv.org/abs/2403.16668",
    "authors": [
      "Mali Jin",
      "Daniel Preo\u0163iuc-Pietro",
      "A. Seza Do\u011fru\u00f6z",
      "Nikolaos Aletras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.16669",
    "title": "Domain Adaptive Detection of MAVs: A Benchmark and Noise Suppression  Network",
    "abstract": "Visual detection of Micro Air Vehicles (MAVs) has attracted increasing attention in recent years due to its important application in various tasks. The existing methods for MAV detection assume that the training set and testing set have the same distribution. As a result, when deployed in new domains, the detectors would have a significant performance degradation due to domain discrepancy. In this paper, we study the problem of cross-domain MAV detection. The contributions of this paper are threefold. 1) We propose a Multi-MAV-Multi-Domain (M3D) dataset consisting of both simulation and realistic images. Compared to other existing datasets, the proposed one is more comprehensive in the sense that it covers rich scenes, diverse MAV types, and various viewing angles. A new benchmark for cross-domain MAV detection is proposed based on the proposed dataset. 2) We propose a Noise Suppression Network (NSN) based on the framework of pseudo-labeling and a large-to-small training procedure. To reduce the challenging pseudo-label noises, two novel modules are designed in this network. The first is a prior-based curriculum learning module for allocating adaptive thresholds for pseudo labels with different difficulties. The second is a masked copy-paste augmentation module for pasting truly-labeled MAVs on unlabeled target images and thus decreasing pseudo-label noises. 3) Extensive experimental results verify the superior performance of the proposed method compared to the state-of-the-art ones. In particular, it achieves mAP of 46.9%(+5.8%), 50.5%(+3.7%), and 61.5%(+11.3%) on the tasks of simulation-to-real adaptation, cross-scene adaptation, and cross-camera adaptation, respectively. ",
    "url": "https://arxiv.org/abs/2403.16669",
    "authors": [
      "Yin Zhang",
      "Jinhong Deng",
      "Peidong Liu",
      "Wen Li",
      "Shiyu Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16674",
    "title": "Understanding the Functional Roles of Modelling Components in Spiking  Neural Networks",
    "abstract": "Spiking neural networks (SNNs), inspired by the neural circuits of the brain, are promising in achieving high computational efficiency with biological fidelity. Nevertheless, it is quite difficult to optimize SNNs because the functional roles of their modelling components remain unclear. By designing and evaluating several variants of the classic model, we systematically investigate the functional roles of key modelling components, leakage, reset, and recurrence, in leaky integrate-and-fire (LIF) based SNNs. Through extensive experiments, we demonstrate how these components influence the accuracy, generalization, and robustness of SNNs. Specifically, we find that the leakage plays a crucial role in balancing memory retention and robustness, the reset mechanism is essential for uninterrupted temporal processing and computational efficiency, and the recurrence enriches the capability to model complex dynamics at a cost of robustness degradation. With these interesting observations, we provide optimization suggestions for enhancing the performance of SNNs in different scenarios. This work deepens the understanding of how SNNs work, which offers valuable guidance for the development of more effective and robust neuromorphic models. ",
    "url": "https://arxiv.org/abs/2403.16674",
    "authors": [
      "Huifeng Yin",
      "Hanle Zheng",
      "Jiayi Mao",
      "Siyuan Ding",
      "Xing Liu",
      "Mingkun Xu",
      "Yifan Hu",
      "Jing Pei",
      "Lei Deng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16677",
    "title": "FOOL: Addressing the Downlink Bottleneck in Satellite Computing with  Neural Feature Compression",
    "abstract": "Nanosatellite constellations equipped with sensors capturing large geographic regions provide unprecedented opportunities for Earth observation. As constellation sizes increase, network contention poses a downlink bottleneck. Orbital Edge Computing (OEC) leverages limited onboard compute resources to reduce transfer costs by processing the raw captures at the source. However, current solutions have limited practicability due to reliance on crude filtering methods or over-prioritizing particular downstream tasks. This work presents FOOL, an OEC-native and task-agnostic feature compression method that preserves prediction performance. FOOL partitions high-resolution satellite imagery to maximize throughput. Further, it embeds context and leverages inter-tile dependencies to lower transfer costs with negligible overhead. While FOOL is a feature compressor, it can recover images with competitive scores on perceptual quality measures at lower bitrates. We extensively evaluate transfer cost reduction by including the peculiarity of intermittently available network connections in low earth orbit. Lastly, we test the feasibility of our system for standardized nanosatellite form factors. We demonstrate that FOOL permits downlinking over 100x the data volume without relying on prior information on the downstream tasks. ",
    "url": "https://arxiv.org/abs/2403.16677",
    "authors": [
      "Alireza Furutanpey",
      "Qiyang Zhang",
      "Philipp Raith",
      "Tobias Pfandzelter",
      "Shangguang Wang",
      "Schahram Dustdar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2403.16685",
    "title": "ToXCL: A Unified Framework for Toxic Speech Detection and Explanation",
    "abstract": "The proliferation of online toxic speech is a pertinent problem posing threats to demographic groups. While explicit toxic speech contains offensive lexical signals, implicit one consists of coded or indirect language. Therefore, it is crucial for models not only to detect implicit toxic speech but also to explain its toxicity. This draws a unique need for unified frameworks that can effectively detect and explain implicit toxic speech. Prior works mainly formulated the task of toxic speech detection and explanation as a text generation problem. Nonetheless, models trained using this strategy can be prone to suffer from the consequent error propagation problem. Moreover, our experiments reveal that the detection results of such models are much lower than those that focus only on the detection task. To bridge these gaps, we introduce ToXCL, a unified framework for the detection and explanation of implicit toxic speech. Our model consists of three modules: a (i) Target Group Generator to generate the targeted demographic group(s) of a given post; an (ii) Encoder-Decoder Model in which the encoder focuses on detecting implicit toxic speech and is boosted by a (iii) Teacher Classifier via knowledge distillation, and the decoder generates the necessary explanation. ToXCL achieves new state-of-the-art effectiveness, and outperforms baselines significantly. ",
    "url": "https://arxiv.org/abs/2403.16685",
    "authors": [
      "Nhat M. Hoang",
      "Xuan Long Do",
      "Duc Anh Do",
      "Duc Anh Vu",
      "Luu Anh Tuan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2403.16702",
    "title": "ProCQA: A Large-scale Community-based Programming Question Answering  Dataset for Code Search",
    "abstract": "Retrieval-based code question answering seeks to match user queries in natural language to relevant code snippets. Previous approaches typically rely on pretraining models using crafted bi-modal and uni-modal datasets to align text and code representations. In this paper, we introduce ProCQA, a large-scale programming question answering dataset extracted from the StackOverflow community, offering naturally structured mixed-modal QA pairs. To validate its effectiveness, we propose a modality-agnostic contrastive pre-training approach to improve the alignment of text and code representations of current code language models. Compared to previous models that primarily employ bimodal and unimodal pairs extracted from CodeSearchNet for pre-training, our model exhibits significant performance improvements across a wide range of code retrieval benchmarks. ",
    "url": "https://arxiv.org/abs/2403.16702",
    "authors": [
      "Zehan Li",
      "Jianfei Zhang",
      "Chuantao Yin",
      "Yuanxin Ouyang",
      "Wenge Rong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2403.16732",
    "title": "Enabling Uncertainty Estimation in Iterative Neural Networks",
    "abstract": "Turning pass-through network architectures into iterative ones, which use their own output as input, is a well-known approach for boosting performance. In this paper, we argue that such architectures offer an additional benefit: The convergence rate of their successive outputs is highly correlated with the accuracy of the value to which they converge. Thus, we can use the convergence rate as a useful proxy for uncertainty. This results in an approach to uncertainty estimation that provides state-of-the-art estimates at a much lower computational cost than techniques like Ensembles, and without requiring any modifications to the original iterative model. We demonstrate its practical value by embedding it in two application domains: road detection in aerial images and the estimation of aerodynamic properties of 2D and 3D shapes. ",
    "url": "https://arxiv.org/abs/2403.16732",
    "authors": [
      "Nikita Durasov",
      "Doruk Oner",
      "Jonathan Donier",
      "Hieu Le",
      "Pascal Fua"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16757",
    "title": "Bi-objective Optimization in Role Mining",
    "abstract": "Role mining is a technique used to derive a role-based authorization policy from an existing policy. Given a set of users $U$, a set of permissions $P$ and a user-permission authorization relation $\\mahtit{UPA}\\subseteq U\\times P$, a role mining algorithm seeks to compute a set of roles $R$, a user-role authorization relation $\\mathit{UA}\\subseteq U\\times R$ and a permission-role authorization relation $\\mathit{PA}\\subseteq R\\times P$, such that the composition of $\\mathit{UA}$ and $\\mathit{PA}$ is close (in some appropriate sense) to $\\mathit{UPA}$. In this paper, we first introduce the Generalized Noise Role Mining problem (GNRM) -- a generalization of the MinNoise Role Mining problem -- which we believe has considerable practical relevance. Extending work of Fomin et al., we show that GNRM is fixed parameter tractable, with parameter $r + k$, where $r$ is the number of roles in the solution and $k$ is the number of discrepancies between $\\mathit{UPA}$ and the relation defined by the composition of $\\mathit{UA}$ and $\\mathit{PA}$. We further introduce a bi-objective optimization variant of GNRM, where we wish to minimize both $r$ and $k$ subject to upper bounds $r\\le \\bar{r}$ and $k\\le \\bar{k}$, where $\\bar{r}$ and $\\bar{k}$ are constants. We show that the Pareto front of this bi-objective optimization problem (BO-GNRM) can be computed in fixed-parameter tractable time with parameter $\\bar{r}+\\bar{k}$. We then report the results of our experimental work using the integer programming solver Gurobi to solve instances of BO-GNRM. Our key findings are that (a) we obtained strong support that Gurobi's performance is fixed-parameter tractable, (b) our results suggest that our techniques may be useful for role mining in practice, based on our experiments in the context of three well-known real-world authorization policies. ",
    "url": "https://arxiv.org/abs/2403.16757",
    "authors": [
      "Jason Crampton",
      "Eduard Eiben",
      "Gregory Gutin",
      "Daniel Karapetyan",
      "Diptapriyo Majumdar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2403.16760",
    "title": "As Good As A Coin Toss Human detection of AI-generated images, videos,  audio, and audiovisual stimuli",
    "abstract": "As synthetic media becomes progressively more realistic and barriers to using it continue to lower, the technology has been increasingly utilized for malicious purposes, from financial fraud to nonconsensual pornography. Today, the principal defense against being misled by synthetic media relies on the ability of the human observer to visually and auditorily discern between real and fake. However, it remains unclear just how vulnerable people actually are to deceptive synthetic media in the course of their day to day lives. We conducted a perceptual study with 1276 participants to assess how accurate people were at distinguishing synthetic images, audio only, video only, and audiovisual stimuli from authentic. To reflect the circumstances under which people would likely encounter synthetic media in the wild, testing conditions and stimuli emulated a typical online platform, while all synthetic media used in the survey was sourced from publicly accessible generative AI technology. We find that overall, participants struggled to meaningfully discern between synthetic and authentic content. We also find that detection performance worsens when the stimuli contains synthetic content as compared to authentic content, images featuring human faces as compared to non face objects, a single modality as compared to multimodal stimuli, mixed authenticity as compared to being fully synthetic for audiovisual stimuli, and features foreign languages as compared to languages the observer is fluent in. Finally, we also find that prior knowledge of synthetic media does not meaningfully impact their detection performance. Collectively, these results indicate that people are highly susceptible to being tricked by synthetic media in their daily lives and that human perceptual detection capabilities can no longer be relied upon as an effective counterdefense. ",
    "url": "https://arxiv.org/abs/2403.16760",
    "authors": [
      "Di Cooke",
      "Abigail Edwards",
      "Sophia Barkoff",
      "Kathryn Kelly"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2403.16771",
    "title": "Synthetic Data Generation and Joint Learning for Robust Code-Mixed  Translation",
    "abstract": "The widespread online communication in a modern multilingual world has provided opportunities to blend more than one language (aka code-mixed language) in a single utterance. This has resulted a formidable challenge for the computational models due to the scarcity of annotated data and presence of noise. A potential solution to mitigate the data scarcity problem in low-resource setup is to leverage existing data in resource-rich language through translation. In this paper, we tackle the problem of code-mixed (Hinglish and Bengalish) to English machine translation. First, we synthetically develop HINMIX, a parallel corpus of Hinglish to English, with ~4.2M sentence pairs. Subsequently, we propose RCMT, a robust perturbation based joint-training model that learns to handle noise in the real-world code-mixed text by parameter sharing across clean and noisy words. Further, we show the adaptability of RCMT in a zero-shot setup for Bengalish to English translation. Our evaluation and comprehensive analyses qualitatively and quantitatively demonstrate the superiority of RCMT over state-of-the-art code-mixed and robust translation methods. ",
    "url": "https://arxiv.org/abs/2403.16771",
    "authors": [
      "Kartik",
      "Sanjana Soni",
      "Anoop Kunchukuttan",
      "Tanmoy Chakraborty",
      "Md Shad Akhtar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16781",
    "title": "Visual Action Planning with Multiple Heterogeneous Agents",
    "abstract": "Visual planning methods are promising to handle complex settings where extracting the system state is challenging. However, none of the existing works tackles the case of multiple heterogeneous agents which are characterized by different capabilities and/or embodiment. In this work, we propose a method to realize visual action planning in multi-agent settings by exploiting a roadmap built in a low-dimensional structured latent space and used for planning. To enable multi-agent settings, we infer possible parallel actions from a dataset composed of tuples associated with individual actions. Next, we evaluate feasibility and cost of them based on the capabilities of the multi-agent system and endow the roadmap with this information, building a capability latent space roadmap (C-LSR). Additionally, a capability suggestion strategy is designed to inform the human operator about possible missing capabilities when no paths are found. The approach is validated in a simulated burger cooking task and a real-world box packing task. ",
    "url": "https://arxiv.org/abs/2403.16781",
    "authors": [
      "Martina Lippi",
      "Michael C. Welle",
      "Marco Moletta",
      "Alessandro Marino",
      "Andrea Gasparri",
      "Danica Kragic"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.16782",
    "title": "The Anatomy of Adversarial Attacks: Concept-based XAI Dissection",
    "abstract": "Adversarial attacks (AAs) pose a significant threat to the reliability and robustness of deep neural networks. While the impact of these attacks on model predictions has been extensively studied, their effect on the learned representations and concepts within these models remains largely unexplored. In this work, we perform an in-depth analysis of the influence of AAs on the concepts learned by convolutional neural networks (CNNs) using eXplainable artificial intelligence (XAI) techniques. Through an extensive set of experiments across various network architectures and targeted AA techniques, we unveil several key findings. First, AAs induce substantial alterations in the concept composition within the feature space, introducing new concepts or modifying existing ones. Second, the adversarial perturbation itself can be linearly decomposed into a set of latent vector components, with a subset of these being responsible for the attack's success. Notably, we discover that these components are target-specific, i.e., are similar for a given target class throughout different AA techniques and starting classes. Our findings provide valuable insights into the nature of AAs and their impact on learned representations, paving the way for the development of more robust and interpretable deep learning models, as well as effective defenses against adversarial threats. ",
    "url": "https://arxiv.org/abs/2403.16782",
    "authors": [
      "Georgii Mikriukov",
      "Gesina Schwalbe",
      "Franz Motzkus",
      "Korinna Bade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16786",
    "title": "DBPF: A Framework for Efficient and Robust Dynamic Bin-Picking",
    "abstract": "Efficiency and reliability are critical in robotic bin-picking as they directly impact the productivity of automated industrial processes. However, traditional approaches, demanding static objects and fixed collisions, lead to deployment limitations, operational inefficiencies, and process unreliability. This paper introduces a Dynamic Bin-Picking Framework (DBPF) that challenges traditional static assumptions. The DBPF endows the robot with the reactivity to pick multiple moving arbitrary objects while avoiding dynamic obstacles, such as the moving bin. Combined with scene-level pose generation, the proposed pose selection metric leverages the Tendency-Aware Manipulability Network optimizing suction pose determination. Heuristic task-specific designs like velocity-matching, dynamic obstacle avoidance, and the resight policy, enhance the picking success rate and reliability. Empirical experiments demonstrate the importance of these components. Our method achieves an average 84% success rate, surpassing the 60% of the most comparable baseline, crucially, with zero collisions. Further evaluations under diverse dynamic scenarios showcase DBPF's robust performance in dynamic bin-picking. Results suggest that our framework offers a promising solution for efficient and reliable robotic bin-picking under dynamics. ",
    "url": "https://arxiv.org/abs/2403.16786",
    "authors": [
      "Yichuan Li",
      "Junkai Zhao",
      "Yixiao Li",
      "Zheng Wu",
      "Rui Cao",
      "Masayoshi Tomizuka",
      "Yunhui Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.16792",
    "title": "Iterative Refinement of Project-Level Code Context for Precise Code  Generation with Compiler Feedback",
    "abstract": "Large language models (LLMs) have shown remarkable progress in automated code generation. Yet, incorporating LLM-based code generation into real-life software projects poses challenges, as the generated code may contain errors in API usage, class, data structure, or missing project-specific information. As much of this project-specific context cannot fit into the prompts of LLMs, we must find ways to allow the model to explore the project-level code context. To this end, this paper puts forward a novel approach, termed ProCoder, which iteratively refines the project-level code context for precise code generation, guided by the compiler feedback. In particular, ProCoder first leverages compiler techniques to identify a mismatch between the generated code and the project's context. It then iteratively aligns and fixes the identified errors using information extracted from the code repository. We integrate ProCoder with two representative LLMs, i.e., GPT-3.5-Turbo and Code Llama (13B), and apply it to Python code generation. Experimental results show that ProCoder significantly improves the vanilla LLMs by over 80% in generating code dependent on project context, and consistently outperforms the existing retrieval-based code generation baselines. ",
    "url": "https://arxiv.org/abs/2403.16792",
    "authors": [
      "Zhangqian Bi",
      "Yao Wan",
      "Zheng Wang",
      "Hongyu Zhang",
      "Batu Guan",
      "Fangxin Lu",
      "Zili Zhang",
      "Yulei Sui",
      "Xuanhua Shi",
      "Hai Jin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2403.16794",
    "title": "CurbNet: Curb Detection Framework Based on LiDAR Point Cloud  Segmentation",
    "abstract": "Curb detection is an important function in intelligent driving and can be used to determine drivable areas of the road. However, curbs are difficult to detect due to the complex road environment. This paper introduces CurbNet, a novel framework for curb detection, leveraging point cloud segmentation. Addressing the dearth of comprehensive curb datasets and the absence of 3D annotations, we have developed the 3D-Curb dataset, encompassing 7,100 frames, which represents the largest and most categorically diverse collection of curb point clouds currently available. Recognizing that curbs are primarily characterized by height variations, our approach harnesses spatially-rich 3D point clouds for training. To tackle the challenges presented by the uneven distribution of curb features on the xy-plane and their reliance on z-axis high-frequency features, we introduce the multi-scale and channel attention (MSCA) module, a bespoke solution designed to optimize detection performance. Moreover, we propose an adaptive weighted loss function group, specifically formulated to counteract the imbalance in the distribution of curb point clouds relative to other categories. Our extensive experimentation on 2 major datasets has yielded results that surpass existing benchmarks set by leading curb detection and point cloud segmentation models. By integrating multi-clustering and curve fitting techniques in our post-processing stage, we have substantially reduced noise in curb detection, thereby enhancing precision to 0.8744. Notably, CurbNet has achieved an exceptional average metrics of over 0.95 at a tolerance of just 0.15m, thereby establishing a new benchmark. Furthermore, corroborative real-world experiments and dataset analyzes mutually validate each other, solidifying CurbNet's superior detection proficiency and its robust generalizability. ",
    "url": "https://arxiv.org/abs/2403.16794",
    "authors": [
      "Guoyang Zhao",
      "Fulong Ma",
      "Yuxuan Liu",
      "Weiqing Qi",
      "Ming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.16797",
    "title": "Privacy Preservation by Intermittent Transmission in Cooperative LQG  Control Systems",
    "abstract": "In this paper, we study a cooperative linear quadratic Gaussian (LQG) control system with a single user and a server. In this system, the user runs a process and employs the server to meet the needs of computation. However, the user regards its state trajectories as privacy. Therefore, we propose a privacy scheme, in which the user sends data to the server intermittently. By this scheme, the server's received information of the user is reduced, and consequently the user's privacy is preserved. In this paper, we consider a periodic transmission scheme. We analyze the performance of privacy preservation and LQG control of different transmission periods. Under the given threshold of the control performance loss, a trade-off optimization problem is proposed. Finally, we give the solution to the optimization problem. ",
    "url": "https://arxiv.org/abs/2403.16797",
    "authors": [
      "Wenhao Lin",
      "Yuqing Ni",
      "Wen Yang",
      "Chao Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.16798",
    "title": "Cluster-Based Normalization Layer for Neural Networks",
    "abstract": "Deep learning faces significant challenges during the training of neural networks, including internal covariate shift, label shift, vanishing/exploding gradients, overfitting, and computational complexity. While conventional normalization methods, such as Batch Normalization, aim to tackle some of these issues, they often depend on assumptions that constrain their adaptability. Mixture Normalization faces computational hurdles in its pursuit of handling multiple Gaussian distributions. This paper introduces Cluster-Based Normalization (CB-Norm) in two variants - Supervised Cluster-Based Normalization (SCB-Norm) and Unsupervised Cluster-Based Normalization (UCB-Norm) - proposing a groundbreaking one-step normalization approach. CB-Norm leverages a Gaussian mixture model to specifically address challenges related to gradient stability and learning acceleration. For SCB-Norm, a supervised variant, the novel mechanism involves introducing predefined data partitioning, termed clusters, to normalize activations based on the assigned cluster. This cluster-driven approach creates a space that conforms to a Gaussian mixture model. On the other hand, UCB-Norm, an unsupervised counterpart, dynamically clusters neuron activations during training, adapting to task-specific challenges without relying on predefined data partitions (clusters). This dual approach ensures flexibility in addressing diverse learning scenarios. CB-Norm innovatively uses a one-step normalization approach, where parameters of each mixture component (cluster in activation space) serve as weights for deep neural networks. This adaptive clustering process tackles both clustering and resolution of deep neural network tasks concurrently during training, signifying a notable advancement in the field. ",
    "url": "https://arxiv.org/abs/2403.16798",
    "authors": [
      "Bilal Faye",
      "Hanane Azzag",
      "Mustapha Lebbah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2403.16818",
    "title": "Multiple-Source Localization from a Single-Snapshot Observation Using  Graph Bayesian Optimization",
    "abstract": "Due to the significance of its various applications, source localization has garnered considerable attention as one of the most important means to confront diffusion hazards. Multi-source localization from a single-snapshot observation is especially relevant due to its prevalence. However, the inherent complexities of this problem, such as limited information, interactions among sources, and dependence on diffusion models, pose challenges to resolution. Current methods typically utilize heuristics and greedy selection, and they are usually bonded with one diffusion model. Consequently, their effectiveness is constrained. To address these limitations, we propose a simulation-based method termed BOSouL. Bayesian optimization (BO) is adopted to approximate the results for its sample efficiency. A surrogate function models uncertainty from the limited information. It takes sets of nodes as the input instead of individual nodes. BOSouL can incorporate any diffusion model in the data acquisition process through simulations. Empirical studies demonstrate that its performance is robust across graph structures and diffusion models. The code is available at https://github.com/XGraph-Team/BOSouL. ",
    "url": "https://arxiv.org/abs/2403.16818",
    "authors": [
      "Zonghan Zhang",
      "Zijian Zhang",
      "Zhiqian Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16825",
    "title": "Weak Convergence Analysis of Online Neural Actor-Critic Algorithms",
    "abstract": "We prove that a single-layer neural network trained with the online actor critic algorithm converges in distribution to a random ordinary differential equation (ODE) as the number of hidden units and the number of training steps $\\rightarrow \\infty$. In the online actor-critic algorithm, the distribution of the data samples dynamically changes as the model is updated, which is a key challenge for any convergence analysis. We establish the geometric ergodicity of the data samples under a fixed actor policy. Then, using a Poisson equation, we prove that the fluctuations of the model updates around the limit distribution due to the randomly-arriving data samples vanish as the number of parameter updates $\\rightarrow \\infty$. Using the Poisson equation and weak convergence techniques, we prove that the actor neural network and critic neural network converge to the solutions of a system of ODEs with random initial conditions. Analysis of the limit ODE shows that the limit critic network will converge to the true value function, which will provide the actor an asymptotically unbiased estimate of the policy gradient. We then prove that the limit actor network will converge to a stationary point. ",
    "url": "https://arxiv.org/abs/2403.16825",
    "authors": [
      "Samuel Chun-Hei Lam",
      "Justin Sirignano",
      "Ziheng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.16826",
    "title": "A Progressive Codebook Optimization Scheme for Sparse Code Multiple  Access in Downlink Channels",
    "abstract": "Sparse code multiple access (SCMA) is a promising technique for enabling massive connectivity and high spectrum efficiency in future machine-type communication networks. However, its performance crucially depends on well-designed multi-dimensional codebooks. In this paper, we propose a novel progressive codebook optimization scheme that can achieve near-optimal performance over downlink fading channels. By examining the pair-wise error probability (PEP), we first derive the symbol error rate (SER) performance of the sparse codebook in downlink channels, which is considered as the design criterion for codebook optimization. Then, the benchmark constellation group at a single resource element is optimized with a sequential quadratic programming approach. Next, we propose a constellation group reconstruction process to assign the sub-constellations in each resource element (RE) progressively. For the current RE, the assignment of the sub-constellations is designed by minimizing the error performance of the product distance of the superimposed codewords in previous REs. The design process involves both permutation and labeling of the sub-constellations in the benchmark constellation group. Simulation results show that the proposed codebooks exhibit significant performance gains over state-of-the-art codebooks in the low signal-to-noise ratio (SNR) region over various downlink fading channels. ",
    "url": "https://arxiv.org/abs/2403.16826",
    "authors": [
      "Tuofeng Lei",
      "Qu Luo",
      "Shimiao Chen",
      "Xin Song",
      "Pei Xiao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2403.16831",
    "title": "UrbanVLP: A Multi-Granularity Vision-Language Pre-Trained Foundation  Model for Urban Indicator Prediction",
    "abstract": "Urban indicator prediction aims to infer socio-economic metrics in diverse urban landscapes using data-driven methods. However, prevalent pre-trained models, particularly those reliant on satellite imagery, face dual challenges. Firstly, concentrating solely on macro-level patterns from satellite data may introduce bias, lacking nuanced details at micro levels, such as architectural details at a place. Secondly, the lack of interpretability in pre-trained models limits their utility in providing transparent evidence for urban planning. In response to these issues, we devise a novel Vision-Language Pre-Trained Model (UrbanVLP) in this paper. Our UrbanVLP seamlessly integrates multi-granularity information from both macro (satellite) and micro (street-view) levels, overcoming the limitations of prior pre-trained models. Moreover, it introduces automatic text generation and calibration, elevating interpretability in downstream applications by producing high-quality text descriptions of urban imagery. Rigorous experiments conducted across six socio-economic tasks underscore UrbanVLP's superior performance. We also deploy a web platform to verify its practicality. ",
    "url": "https://arxiv.org/abs/2403.16831",
    "authors": [
      "Xixuan Hao",
      "Wei Chen",
      "Yibo Yan",
      "Siru Zhong",
      "Kun Wang",
      "Qingsong Wen",
      "Yuxuan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16836",
    "title": "Energy Efficiency Optimization Method of WDM Visible Light Communication  System for Indoor Broadcasting Networks",
    "abstract": "This paper introduces a novel approach to optimize energy efficiency in wavelength division multiplexing (WDM) Visible Light Communication (VLC) systems designed for indoor broadcasting networks. A physics-based LED model is integrated into system energy efficiency optimization, enabling quantitative analysis of the critical issue of VLC energy efficiency: the nonlinear interplay between illumination and communication performance. The optimization jointly incorporates constraints on communication quality of each channel, and illumination performance, standardized by the International Commission on Illumination (CIE). The formulated nonlinear optimization problem is solved by the Sequential Quadratic Programming (SQP) algorithm in an experiment-based simulation. An integrated Red-Green-Blue-Yellow Light Emitting Diode (RGBY-LED) is measured for model calibration and three different scenarios are simulated to evaluate the generality of the proposed method. Results demonstrate a double enhancement in performance and a high versatility in accommodating various scenarios. Furthermore, it highlights the importance of balancing communication and illumination imperatives in VLC systems, challenging conventional perceptions focused solely on minimizing power consumption. ",
    "url": "https://arxiv.org/abs/2403.16836",
    "authors": [
      "Dayu Shi",
      "Xun Zhang",
      "Ziqi Liu",
      "Xuanbang Chen",
      "Jianghao Li",
      "Xiaodong Liu",
      "William Shieh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2403.16846",
    "title": "GreeDy and CoDy: Counterfactual Explainers for Dynamic Graphs",
    "abstract": "Temporal Graph Neural Networks (TGNNs), crucial for modeling dynamic graphs with time-varying interactions, face a significant challenge in explainability due to their complex model structure. Counterfactual explanations, crucial for understanding model decisions, examine how input graph changes affect outcomes. This paper introduces two novel counterfactual explanation methods for TGNNs: GreeDy (Greedy Explainer for Dynamic Graphs) and CoDy (Counterfactual Explainer for Dynamic Graphs). They treat explanations as a search problem, seeking input graph alterations that alter model predictions. GreeDy uses a simple, greedy approach, while CoDy employs a sophisticated Monte Carlo Tree Search algorithm. Experiments show both methods effectively generate clear explanations. Notably, CoDy outperforms GreeDy and existing factual methods, with up to 59\\% higher success rate in finding significant counterfactual inputs. This highlights CoDy's potential in clarifying TGNN decision-making, increasing their transparency and trustworthiness in practice. ",
    "url": "https://arxiv.org/abs/2403.16846",
    "authors": [
      "Zhan Qu",
      "Daniel Gomm",
      "Michael F\u00e4rber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16848",
    "title": "Multiple Object Tracking as ID Prediction",
    "abstract": "In Multiple Object Tracking (MOT), tracking-by-detection methods have stood the test for a long time, which split the process into two parts according to the definition: object detection and association. They leverage robust single-frame detectors and treat object association as a post-processing step through hand-crafted heuristic algorithms and surrogate tasks. However, the nature of heuristic techniques prevents end-to-end exploitation of training data, leading to increasingly cumbersome and challenging manual modification while facing complicated or novel scenarios. In this paper, we regard this object association task as an End-to-End in-context ID prediction problem and propose a streamlined baseline called MOTIP. Specifically, we form the target embeddings into historical trajectory information while considering the corresponding IDs as in-context prompts, then directly predict the ID labels for the objects in the current frame. Thanks to this end-to-end process, MOTIP can learn tracking capabilities straight from training data, freeing itself from burdensome hand-crafted algorithms. Without bells and whistles, our method achieves impressive state-of-the-art performance in complex scenarios like DanceTrack and SportsMOT, and it performs competitively with other transformer-based methods on MOT17. We believe that MOTIP demonstrates remarkable potential and can serve as a starting point for future research. The code is available at https://github.com/MCG-NJU/MOTIP. ",
    "url": "https://arxiv.org/abs/2403.16848",
    "authors": [
      "Ruopeng Gao",
      "Yijun Zhang",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16852",
    "title": "Towards Explainability in Legal Outcome Prediction Models",
    "abstract": "Current legal outcome prediction models - a staple of legal NLP - do not explain their reasoning. However, to employ these models in the real world, human legal actors need to be able to understand their decisions. In the case of common law, legal practitioners reason towards the outcome of a case by referring to past case law, known as precedent. We contend that precedent is, therefore, a natural way of facilitating explainability for legal NLP models. In this paper, we contribute a novel method for identifying the precedent employed by legal outcome prediction models. Furthermore, by developing a taxonomy of legal precedent, we are able to compare human judges and our models with respect to the different types of precedent they rely on. We find that while the models learn to predict outcomes reasonably well, their use of precedent is unlike that of human judges. ",
    "url": "https://arxiv.org/abs/2403.16852",
    "authors": [
      "Josef Valvoda",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16862",
    "title": "INPC: Implicit Neural Point Clouds for Radiance Field Rendering",
    "abstract": "We introduce a new approach for reconstruction and novel-view synthesis of unbounded real-world scenes. In contrast to previous methods using either volumetric fields, grid-based models, or discrete point cloud proxies, we propose a hybrid scene representation, which implicitly encodes a point cloud in a continuous octree-based probability field and a multi-resolution hash grid. In doing so, we combine the benefits of both worlds by retaining favorable behavior during optimization: Our novel implicit point cloud representation and differentiable bilinear rasterizer enable fast rendering while preserving fine geometric detail without depending on initial priors like structure-from-motion point clouds. Our method achieves state-of-the-art image quality on several common benchmark datasets. Furthermore, we achieve fast inference at interactive frame rates, and can extract explicit point clouds to further enhance performance. ",
    "url": "https://arxiv.org/abs/2403.16862",
    "authors": [
      "Florian Hahlbohm",
      "Linus Franke",
      "Moritz Kappel",
      "Susana Castillo",
      "Marc Stamminger",
      "Marcus Magnor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16865",
    "title": "Encoding of lexical tone in self-supervised models of spoken language",
    "abstract": "Interpretability research has shown that self-supervised Spoken Language Models (SLMs) encode a wide variety of features in human speech from the acoustic, phonetic, phonological, syntactic and semantic levels, to speaker characteristics. The bulk of prior research on representations of phonology has focused on segmental features such as phonemes; the encoding of suprasegmental phonology (such as tone and stress patterns) in SLMs is not yet well understood. Tone is a suprasegmental feature that is present in more than half of the world's languages. This paper aims to analyze the tone encoding capabilities of SLMs, using Mandarin and Vietnamese as case studies. We show that SLMs encode lexical tone to a significant degree even when they are trained on data from non-tonal languages. We further find that SLMs behave similarly to native and non-native human participants in tone and consonant perception studies, but they do not follow the same developmental trajectory. ",
    "url": "https://arxiv.org/abs/2403.16865",
    "authors": [
      "Gaofei Shen",
      "Michaela Watkins",
      "Afra Alishahi",
      "Arianna Bisazza",
      "Grzegorz Chrupa\u0142a"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2403.16871",
    "title": "Conformal Off-Policy Prediction for Multi-Agent Systems",
    "abstract": "Off-Policy Prediction (OPP), i.e., predicting the outcomes of a target policy using only data collected under a nominal (behavioural) policy, is a paramount problem in data-driven analysis of safety-critical systems where the deployment of a new policy may be unsafe. To achieve dependable off-policy predictions, recent work on Conformal Off-Policy Prediction (COPP) leverage the conformal prediction framework to derive prediction regions with probabilistic guarantees under the target process. Existing COPP methods can account for the distribution shifts induced by policy switching, but are limited to single-agent systems and scalar outcomes (e.g., rewards). In this work, we introduce MA-COPP, the first conformal prediction method to solve OPP problems involving multi-agent systems, deriving joint prediction regions for all agents' trajectories when one or more \"ego\" agents change their policies. Unlike the single-agent scenario, this setting introduces higher complexity as the distribution shifts affect predictions for all agents, not just the ego agents, and the prediction task involves full multi-dimensional trajectories, not just reward values. A key contribution of MA-COPP is to avoid enumeration or exhaustive search of the output space of agent trajectories, which is instead required by existing COPP methods to construct the prediction region. We achieve this by showing that an over-approximation of the true JPR can be constructed, without enumeration, from the maximum density ratio of the JPR trajectories. We evaluate the effectiveness of MA-COPP in multi-agent systems from the PettingZoo library and the F1TENTH autonomous racing environment, achieving nominal coverage in higher dimensions and various shift settings. ",
    "url": "https://arxiv.org/abs/2403.16871",
    "authors": [
      "Tom Kuipers",
      "Renukanandan Tumu",
      "Shuo Yang",
      "Milad Kazemi",
      "Rahul Mangharam",
      "Nicola Paoletti"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.16880",
    "title": "DHP-Mapping: A Dense Panoptic Mapping System with Hierarchical World  Representation and Label Optimization Techniques",
    "abstract": "Maps provide robots with crucial environmental knowledge, thereby enabling them to perform interactive tasks effectively. Easily accessing accurate abstract-to-detailed geometric and semantic concepts from maps is crucial for robots to make informed and efficient decisions. To comprehensively model the environment and effectively manage the map data structure, we propose DHP-Mapping, a dense mapping system that utilizes multiple Truncated Signed Distance Field (TSDF) submaps and panoptic labels to hierarchically model the environment. The output map is able to maintain both voxel- and submap-level metric and semantic information. Two modules are presented to enhance the mapping efficiency and label consistency: (1) an inter-submaps label fusion strategy to eliminate duplicate points across submaps and (2) a conditional random field (CRF) based approach to enhance panoptic labels through object label comprehension and contextual information. We conducted experiments with two public datasets including indoor and outdoor scenarios. Our system performs comparably to state-of-the-art (SOTA) methods across geometry and label accuracy evaluation metrics. The experiment results highlight the effectiveness and scalability of our system, as it is capable of constructing precise geometry and maintaining consistent panoptic labels. Our code is publicly available at https://github.com/hutslib/DHP-Mapping. ",
    "url": "https://arxiv.org/abs/2403.16880",
    "authors": [
      "Tianshuai Hu",
      "Jianhao Jiao",
      "Yucheng Xu",
      "Hongji Liu",
      "Sheng Wang",
      "Ming Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.16883",
    "title": "Discrete Latent Graph Generative Modeling with Diffusion Bridges",
    "abstract": "Learning graph generative models over latent spaces has received less attention compared to models that operate on the original data space and has so far demonstrated lacklustre performance. We present GLAD a latent space graph generative model. Unlike most previous latent space graph generative models, GLAD operates on a discrete latent space that preserves to a significant extent the discrete nature of the graph structures making no unnatural assumptions such as latent space continuity. We learn the prior of our discrete latent space by adapting diffusion bridges to its structure. By operating over an appropriately constructed latent space we avoid relying on decompositions that are often used in models that operate in the original data space. We present experiments on a series of graph benchmark datasets which clearly show the superiority of the discrete latent space and obtain state of the art graph generative performance, making GLAD the first latent space graph generative model with competitive performance. Our source code is published at: \\url{https://github.com/v18nguye/GLAD}. ",
    "url": "https://arxiv.org/abs/2403.16883",
    "authors": [
      "Van Khoa Nguyen",
      "Yoann Boget",
      "Frantzeska Lavda",
      "Alexandros Kalousis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.16898",
    "title": "Concerned with Data Contamination? Assessing Countermeasures in Code  Language Model",
    "abstract": "Various techniques have been proposed to leverage the capabilities of code language models (CLMs) for SE tasks. While these techniques typically evaluate their effectiveness using publicly available datasets, the evaluation can be subject to data contamination threats where the evaluation datasets have already been used to train the concerned CLMs. This can significantly affect the reliability of the evaluation. Different countermeasures have been suggested to mitigate the data contamination threat. Countermeasures include using more recent data, curating new data, and refactoring existing data are introduced, yet it is unclear whether these countermeasures could really mitigate data contamination threats to model evaluation. To fill the gap, we systematically study to quantify the impacts of these countermeasures on CLMs' performance. To facilitate the study, we collected over 2 million Python functions with timestamps ranging from January 1st, 2018, to December 31st, 2023. The data created before the models' cut-off date are considered \"contaminated data\", while the data where the countermeasures are taken are regarded as \"cleansed data\". We study the impact of these countermeasures by investigating the difference in CLMs' performance on contaminated and cleansed data derived from different countermeasures. Our experiments yield several interesting observations. For instance, CLMs do not necessarily perform worse on data after the models' cut-off date; on the contrary, they sometimes perform better. In addition, refactoring did not always result in decreased performance; it could lead to improvements instead. Furthermore, existing metrics such as perplexity cannot distinguish contaminated/cleansed data. We hope that the results and observations could help deepen the understanding of CLMs' capabilities and inform the community about data contamination. ",
    "url": "https://arxiv.org/abs/2403.16898",
    "authors": [
      "Jialun Cao",
      "Wuqi Zhang",
      "Shing-Chi Cheung"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2403.16909",
    "title": "Towards Algorithmic Fidelity: Mental Health Representation across  Demographics in Synthetic vs. Human-generated Data",
    "abstract": "Synthetic data generation has the potential to impact applications and domains with scarce data. However, before such data is used for sensitive tasks such as mental health, we need an understanding of how different demographics are represented in it. In our paper, we analyze the potential of producing synthetic data using GPT-3 by exploring the various stressors it attributes to different race and gender combinations, to provide insight for future researchers looking into using LLMs for data generation. Using GPT-3, we develop HEADROOM, a synthetic dataset of 3,120 posts about depression-triggering stressors, by controlling for race, gender, and time frame (before and after COVID-19). Using this dataset, we conduct semantic and lexical analyses to (1) identify the predominant stressors for each demographic group; and (2) compare our synthetic data to a human-generated dataset. We present the procedures to generate queries to develop depression data using GPT-3, and conduct analyzes to uncover the types of stressors it assigns to demographic groups, which could be used to test the limitations of LLMs for synthetic data generation for depression data. Our findings show that synthetic data mimics some of the human-generated data distribution for the predominant depression stressors across diverse demographics. ",
    "url": "https://arxiv.org/abs/2403.16909",
    "authors": [
      "Shinka Mori",
      "Oana Ignat",
      "Andrew Lee",
      "Rada Mihalcea"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2403.16941",
    "title": "SPACE-IDEAS: A Dataset for Salient Information Detection in Space  Innovation",
    "abstract": "Detecting salient parts in text using natural language processing has been widely used to mitigate the effects of information overflow. Nevertheless, most of the datasets available for this task are derived mainly from academic publications. We introduce SPACE-IDEAS, a dataset for salient information detection from innovation ideas related to the Space domain. The text in SPACE-IDEAS varies greatly and includes informal, technical, academic and business-oriented writing styles. In addition to a manually annotated dataset we release an extended version that is annotated using a large generative language model. We train different sentence and sequential sentence classifiers, and show that the automatically annotated dataset can be leveraged using multitask learning to train better classifiers. ",
    "url": "https://arxiv.org/abs/2403.16941",
    "authors": [
      "Andr\u00e9s Garc\u00eda-Silva",
      "Cristian Berr\u00edo",
      "Jos\u00e9 Manuel G\u00f3mez-P\u00e9rez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2403.16983",
    "title": "Robust Filter Design for Graph Signals",
    "abstract": "Our goal in this paper is the robust design of filters acting on signals observed over graphs subject to small perturbations of their edges. The focus is on developing a method to identify spectral and polynomial graph filters that can adapt to the perturbations in the underlying graph structure while ensuring the filters adhere to the desired spectral mask. To address this, we propose a novel approach that leverages approximate closed-form expressions for the perturbed eigendecomposition of the Laplacian matrix associated with the nominal topology. Furthermore, when dealing with noisy input signals for graph filters, we propose a strategy for designing FIR filters that jointly minimize the approximation error with respect to the ideal filter and the estimation error of the output, ensuring robustness against both graph perturbations and noise. Numerical results validate the effectiveness of our proposed strategies, highlighting their capability to efficiently manage perturbations and noise. ",
    "url": "https://arxiv.org/abs/2403.16983",
    "authors": [
      "Lucia Testa",
      "Stefania Sardellitti",
      "Sergio Barbarossa"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2403.17004",
    "title": "SD-DiT: Unleashing the Power of Self-supervised Discrimination in  Diffusion Transformer",
    "abstract": "Diffusion Transformer (DiT) has emerged as the new trend of generative diffusion models on image generation. In view of extremely slow convergence in typical DiT, recent breakthroughs have been driven by mask strategy that significantly improves the training efficiency of DiT with additional intra-image contextual learning. Despite this progress, mask strategy still suffers from two inherent limitations: (a) training-inference discrepancy and (b) fuzzy relations between mask reconstruction & generative diffusion process, resulting in sub-optimal training of DiT. In this work, we address these limitations by novelly unleashing the self-supervised discrimination knowledge to boost DiT training. Technically, we frame our DiT in a teacher-student manner. The teacher-student discriminative pairs are built on the diffusion noises along the same Probability Flow Ordinary Differential Equation (PF-ODE). Instead of applying mask reconstruction loss over both DiT encoder and decoder, we decouple DiT encoder and decoder to separately tackle discriminative and generative objectives. In particular, by encoding discriminative pairs with student and teacher DiT encoders, a new discriminative loss is designed to encourage the inter-image alignment in the self-supervised embedding space. After that, student samples are fed into student DiT decoder to perform the typical generative diffusion task. Extensive experiments are conducted on ImageNet dataset, and our method achieves a competitive balance between training cost and generative capacity. ",
    "url": "https://arxiv.org/abs/2403.17004",
    "authors": [
      "Rui Zhu",
      "Yingwei Pan",
      "Yehao Li",
      "Ting Yao",
      "Zhenglong Sun",
      "Tao Mei",
      "Chang Wen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2403.17009",
    "title": "Optimizing LiDAR Placements for Robust Driving Perception in Adverse  Conditions",
    "abstract": "The robustness of driving perception systems under unprecedented conditions is crucial for safety-critical usages. Latest advancements have prompted increasing interests towards multi-LiDAR perception. However, prevailing driving datasets predominantly utilize single-LiDAR systems and collect data devoid of adverse conditions, failing to capture the complexities of real-world environments accurately. Addressing these gaps, we proposed Place3D, a full-cycle pipeline that encompasses LiDAR placement optimization, data generation, and downstream evaluations. Our framework makes three appealing contributions. 1) To identify the most effective configurations for multi-LiDAR systems, we introduce a Surrogate Metric of the Semantic Occupancy Grids (M-SOG) to evaluate LiDAR placement quality. 2) Leveraging the M-SOG metric, we propose a novel optimization strategy to refine multi-LiDAR placements. 3) Centered around the theme of multi-condition multi-LiDAR perception, we collect a 364,000-frame dataset from both clean and adverse conditions. Extensive experiments demonstrate that LiDAR placements optimized using our approach outperform various baselines. We showcase exceptional robustness in both 3D object detection and LiDAR semantic segmentation tasks, under diverse adverse weather and sensor failure conditions. Code and benchmark toolkit are publicly available. ",
    "url": "https://arxiv.org/abs/2403.17009",
    "authors": [
      "Ye Li",
      "Lingdong Kong",
      "Hanjiang Hu",
      "Xiaohao Xu",
      "Xiaonan Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.15415",
    "title": "Physics-informed and Unsupervised Riemannian Domain Adaptation for  Machine Learning on Heterogeneous EEG Datasets",
    "abstract": "Combining electroencephalogram (EEG) datasets for supervised machine learning (ML) is challenging due to session, subject, and device variability. ML algorithms typically require identical features at train and test time, complicating analysis due to varying sensor numbers and positions across datasets. Simple channel selection discards valuable data, leading to poorer performance, especially with datasets sharing few channels. To address this, we propose an unsupervised approach leveraging EEG signal physics. We map EEG channels to fixed positions using field interpolation, facilitating source-free domain adaptation. Leveraging Riemannian geometry classification pipelines and transfer learning steps, our method demonstrates robust performance in brain-computer interface (BCI) tasks and potential biomarker applications. Comparative analysis against a statistical-based approach known as Dimensionality Transcending, a signal-based imputation called ComImp, source-dependent methods, as well as common channel selection and spherical spline interpolation, was conducted with leave-one-dataset-out validation on six public BCI datasets for a right-hand/left-hand classification task. Numerical experiments show that in the presence of few shared channels in train and test, the field interpolation consistently outperforms other methods, demonstrating enhanced classification performance across all datasets. When more channels are shared, field interpolation was found to be competitive with other methods and faster to compute than source-dependent methods. ",
    "url": "https://arxiv.org/abs/2403.15415",
    "authors": [
      "Apolline Mellot",
      "Antoine Collas",
      "Sylvain Chevallier",
      "Denis Engemann",
      "Alexandre Gramfort"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.15441",
    "title": "Unified Generative Modeling of 3D Molecules via Bayesian Flow Networks",
    "abstract": "Advanced generative model (e.g., diffusion model) derived from simplified continuity assumptions of data distribution, though showing promising progress, has been difficult to apply directly to geometry generation applications due to the multi-modality and noise-sensitive nature of molecule geometry. This work introduces Geometric Bayesian Flow Networks (GeoBFN), which naturally fits molecule geometry by modeling diverse modalities in the differentiable parameter space of distributions. GeoBFN maintains the SE-(3) invariant density modeling property by incorporating equivariant inter-dependency modeling on parameters of distributions and unifying the probabilistic modeling of different modalities. Through optimized training and sampling techniques, we demonstrate that GeoBFN achieves state-of-the-art performance on multiple 3D molecule generation benchmarks in terms of generation quality (90.87% molecule stability in QM9 and 85.6% atom stability in GEOM-DRUG. GeoBFN can also conduct sampling with any number of steps to reach an optimal trade-off between efficiency and quality (e.g., 20-times speedup without sacrificing performance). ",
    "url": "https://arxiv.org/abs/2403.15441",
    "authors": [
      "Yuxuan Song",
      "Jingjing Gong",
      "Yanru Qu",
      "Hao Zhou",
      "Mingyue Zheng",
      "Jingjing Liu",
      "Wei-Ying Ma"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2403.15443",
    "title": "Introducing an ensemble method for the early detection of Alzheimer's  disease through the analysis of PET scan images",
    "abstract": "Alzheimer's disease is a progressive neurodegenerative disorder that primarily affects cognitive functions such as memory, thinking, and behavior. In this disease, there is a critical phase, mild cognitive impairment, that is really important to be diagnosed early since some patients with progressive MCI will develop the disease. This study delves into the challenging task of classifying Alzheimer's disease into four distinct groups: control normal (CN), progressive mild cognitive impairment (pMCI), stable mild cognitive impairment (sMCI), and Alzheimer's disease (AD). This classification is based on a thorough examination of PET scan images obtained from the ADNI dataset, which provides a thorough understanding of the disease's progression. Several deep-learning and traditional machine-learning models have been used to detect Alzheimer's disease. In this paper, three deep-learning models, namely VGG16 and AlexNet, and a custom Convolutional neural network (CNN) with 8-fold cross-validation have been used for classification. Finally, an ensemble technique is used to improve the overall result of these models. The results show that using deep-learning models to tell the difference between MCI patients gives an overall average accuracy of 93.13% and an AUC of 94.4%. ",
    "url": "https://arxiv.org/abs/2403.15443",
    "authors": [
      "Arezoo Borji",
      "Taha-Hossein Hejazi",
      "Abbas Seifi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2403.15483",
    "title": "Rolling bearing fault diagnosis method based on generative adversarial  enhanced multi-scale convolutional neural network model",
    "abstract": "In order to solve the problem that current convolutional neural networks can not capture the correlation features between the time domain signals of rolling bearings effectively, and the model accuracy is limited by the number and quality of samples, a rolling bearing fault diagnosis method based on generative adversarial enhanced multi-scale convolutional neural network model is proposed. Firstly, Gram angular field coding technique is used to encode the time domain signal of the rolling bearing and generate the feature map to retain the complete information of the vibration signal. Then, the re-sulting data is divided into a training set, a validation set, and a test set. Among them, the training set is input into the gradient penalty Wasserstein distance generation adversarial network to complete the training, and a new sample with similar features to the training sample is obtained, and then the original training set is expanded. Next, multi-scale convolution is used to extract the fault features of the extended training set, and the feature graph is normalized by example to overcome the influence of the difference in feature distribution. Finally, the attention mechanism is applied to the adaptive weighting of normalized features and the extraction of deep features, and the fault diagnosis is completed by the softmax classifier. Compared with ResNet method, the experimental results show that the proposed method has better generalization performance and anti-noise performance. ",
    "url": "https://arxiv.org/abs/2403.15483",
    "authors": [
      "Maoxuan Zhou",
      "Wei Kang",
      "Kun He"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.15500",
    "title": "Gene Regulatory Network Inference in the Presence of Dropouts: a Causal  View",
    "abstract": "Gene regulatory network inference (GRNI) is a challenging problem, particularly owing to the presence of zeros in single-cell RNA sequencing data: some are biological zeros representing no gene expression, while some others are technical zeros arising from the sequencing procedure (aka dropouts), which may bias GRNI by distorting the joint distribution of the measured gene expressions. Existing approaches typically handle dropout error via imputation, which may introduce spurious relations as the true joint distribution is generally unidentifiable. To tackle this issue, we introduce a causal graphical model to characterize the dropout mechanism, namely, Causal Dropout Model. We provide a simple yet effective theoretical result: interestingly, the conditional independence (CI) relations in the data with dropouts, after deleting the samples with zero values (regardless if technical or not) for the conditioned variables, are asymptotically identical to the CI relations in the original data without dropouts. This particular test-wise deletion procedure, in which we perform CI tests on the samples without zeros for the conditioned variables, can be seamlessly integrated with existing structure learning approaches including constraint-based and greedy score-based methods, thus giving rise to a principled framework for GRNI in the presence of dropouts. We further show that the causal dropout model can be validated from data, and many existing statistical models to handle dropouts fit into our model as specific parametric instances. Empirical evaluation on synthetic, curated, and real-world experimental transcriptomic data comprehensively demonstrate the efficacy of our method. ",
    "url": "https://arxiv.org/abs/2403.15500",
    "authors": [
      "Haoyue Dai",
      "Ignavier Ng",
      "Gongxu Luo",
      "Peter Spirtes",
      "Petar Stojanov",
      "Kun Zhang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2403.15525",
    "title": "Latent Neural Cellular Automata for Resource-Efficient Image Restoration",
    "abstract": "Neural cellular automata represent an evolution of the traditional cellular automata model, enhanced by the integration of a deep learning-based transition function. This shift from a manual to a data-driven approach significantly increases the adaptability of these models, enabling their application in diverse domains, including content generation and artificial life. However, their widespread application has been hampered by significant computational requirements. In this work, we introduce the Latent Neural Cellular Automata (LNCA) model, a novel architecture designed to address the resource limitations of neural cellular automata. Our approach shifts the computation from the conventional input space to a specially designed latent space, relying on a pre-trained autoencoder. We apply our model in the context of image restoration, which aims to reconstruct high-quality images from their degraded versions. This modification not only reduces the model's resource consumption but also maintains a flexible framework suitable for various applications. Our model achieves a significant reduction in computational requirements while maintaining high reconstruction fidelity. This increase in efficiency allows for inputs up to 16 times larger than current state-of-the-art neural cellular automata models, using the same resources. ",
    "url": "https://arxiv.org/abs/2403.15525",
    "authors": [
      "Andrea Menta",
      "Alberto Archetti",
      "Matteo Matteucci"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2403.15528",
    "title": "Evaluating GPT-4 with Vision on Detection of Radiological Findings on  Chest Radiographs",
    "abstract": "The study examines the application of GPT-4V, a multi-modal large language model equipped with visual recognition, in detecting radiological findings from a set of 100 chest radiographs and suggests that GPT-4V is currently not ready for real-world diagnostic usage in interpreting chest radiographs. ",
    "url": "https://arxiv.org/abs/2403.15528",
    "authors": [
      "Yiliang Zhou",
      "Hanley Ong",
      "Patrick Kennedy",
      "Carol Wu",
      "Jacob Kazam",
      "Keith Hentel",
      "Adam Flanders",
      "George Shih",
      "Yifan Peng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.15560",
    "title": "A2DMN: Anatomy-Aware Dilated Multiscale Network for Breast Ultrasound  Semantic Segmentation",
    "abstract": "In recent years, convolutional neural networks for semantic segmentation of breast ultrasound (BUS) images have shown great success; however, two major challenges still exist. 1) Most current approaches inherently lack the ability to utilize tissue anatomy, resulting in misclassified image regions. 2) They struggle to produce accurate boundaries due to the repeated down-sampling operations. To address these issues, we propose a novel breast anatomy-aware network for capturing fine image details and a new smoothness term that encodes breast anatomy. It incorporates context information across multiple spatial scales to generate more accurate semantic boundaries. Extensive experiments are conducted to compare the proposed method and eight state-of-the-art approaches using a BUS dataset with 325 images. The results demonstrate the proposed method significantly improves the segmentation of the muscle, mammary, and tumor classes and produces more accurate fine details of tissue boundaries. ",
    "url": "https://arxiv.org/abs/2403.15560",
    "authors": [
      "Kyle Lucke",
      "Aleksandar Vakanski",
      "Min Xian"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.15598",
    "title": "An ensemble of data-driven weather prediction models for operational  sub-seasonal forecasting",
    "abstract": "We present an operations-ready multi-model ensemble weather forecasting system which uses hybrid data-driven weather prediction models coupled with the European Centre for Medium-range Weather Forecasts (ECMWF) ocean model to predict global weather at 1-degree resolution for 4 weeks of lead time. For predictions of 2-meter temperature, our ensemble on average outperforms the raw ECMWF extended-range ensemble by 4-17%, depending on the lead time. However, after applying statistical bias corrections, the ECMWF ensemble is about 3% better at 4 weeks. For other surface parameters, our ensemble is also within a few percentage points of ECMWF's ensemble. We demonstrate that it is possible to achieve near-state-of-the-art subseasonal-to-seasonal forecasts using a multi-model ensembling approach with data-driven weather prediction models. ",
    "url": "https://arxiv.org/abs/2403.15598",
    "authors": [
      "Jonathan A. Weyn",
      "Divya Kumar",
      "Jeremy Berman",
      "Najeeb Kazmi",
      "Sylwester Klocek",
      "Pete Luferenko",
      "Kit Thambiratnam"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.15683",
    "title": "On the role of network structure in learning to coordinate with bounded  rationality",
    "abstract": "Many socioeconomic phenomena, such as technology adoption, collaborative problem-solving, and content engagement, involve a collection of agents coordinating to take a common action, aligning their decisions to maximize their individual goals. We consider a model for networked interactions where agents learn to coordinate their binary actions under a strict bound on their rationality. We first prove that our model is a potential game and that the optimal action profile is always to achieve perfect alignment at one of the two possible actions, regardless of the network structure. Using a stochastic learning algorithm known as Log Linear Learning, where agents have the same finite rationality parameter, we show that the probability of agents successfully agreeing on the correct decision is monotonically increasing in the number of network links. Therefore, more connectivity improves the accuracy of collective decision-making, as predicted by the phenomenon known as Wisdom of Crowds. Finally, we show that for a fixed number of links, a regular network maximizes the probability of success. We conclude that when using a network of irrational agents, promoting more homogeneous connectivity improves the accuracy of collective decision-making. ",
    "url": "https://arxiv.org/abs/2403.15683",
    "authors": [
      "Yifei Zhang",
      "Marcos M. Vasconcelos"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.15727",
    "title": "Sub-Micrometer Particles Remote Detection in Enceladus Plume Based on  Cassinis UV Spectrograph Data",
    "abstract": "Enceladus is the Saturnian satellite known to have water vapor erupting from its south pole region called Tiger Stripes. Data collected by Cassini Ultraviolet Imaging Spectrograph during Enceladus transiting Saturn allow us to estimate water plume absorption from 1115.35 - 1912.50 Angstrom and compare it to the Mie solutions of Maxwell equations for particles with a diameter in the range from 10 nm up to 2 um. The best fit performed using Gradient Descent method indicates a presence of submicrometer particles of diameters: 120-180 nm and 240-320 nm consistent with Thermofilum sp., Thermoproteus sp., and Pyrobaculum sp. cell sizes present in hydrothermal vents on Earth. ",
    "url": "https://arxiv.org/abs/2403.15727",
    "authors": [
      "Jan Kotlarz",
      "Katarzyna Kubiak",
      "Natalia Zalewska"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2403.15770",
    "title": "Graph Image Prior for Unsupervised Dynamic MRI Reconstruction",
    "abstract": "The inductive bias of the convolutional neural network (CNN) can act as a strong prior for image restoration, which is known as the Deep Image Prior (DIP). In recent years, DIP has been utilized in unsupervised dynamic MRI reconstruction, which adopts a generative model from the latent space to the image space. However, existing methods usually utilize a single pyramid-shaped CNN architecture to parameterize the generator, which cannot effectively exploit the spatio-temporal correlations within the dynamic data. In this work, we propose a novel scheme to exploit the DIP prior for dynamic MRI reconstruction, named ``Graph Image Prior'' (GIP). The generative model is decomposed into two stages: image recovery and manifold discovery, which is bridged by a graph convolutional network to exploit the spatio-temporal correlations. In addition, we devise an ADMM algorithm to alternately optimize the images and the network parameters to further improve the reconstruction performance. Experimental results demonstrate that GIP outperforms compressed sensing methods and unsupervised methods over different sampling trajectories, and significantly reduces the performance gap with the state-of-art supervised deep-learning methods. Moreover, GIP displays superior generalization ability when transferred to a different reconstruction setting, without the need for any additional data. ",
    "url": "https://arxiv.org/abs/2403.15770",
    "authors": [
      "Zhongsen Li",
      "Wenxuan Chen",
      "Shuai Wang",
      "Chuyu Liu",
      "Rui Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16031",
    "title": "Learning Directed Acyclic Graphs from Partial Orderings",
    "abstract": "Directed acyclic graphs (DAGs) are commonly used to model causal relationships among random variables. In general, learning the DAG structure is both computationally and statistically challenging. Moreover, without additional information, the direction of edges may not be estimable from observational data. In contrast, given a complete causal ordering of the variables, the problem can be solved efficiently, even in high dimensions. In this paper, we consider the intermediate problem of learning DAGs when a partial causal ordering of variables is available. We propose a general estimation framework for leveraging the partial ordering and present efficient estimation algorithms for low- and high-dimensional problems. The advantages of the proposed framework are illustrated via numerical studies. ",
    "url": "https://arxiv.org/abs/2403.16031",
    "authors": [
      "Ali Shojaie",
      "Wenyu Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2403.16144",
    "title": "Predicting Energy Budgets in Droplet Dynamics: A Recurrent Neural  Network Approach",
    "abstract": "Neural networks in fluid mechanics offer an efficient approach for exploring complex flows, including multiphase and free surface flows. The recurrent neural network, particularly the Long Short-Term Memory (LSTM) model, proves attractive for learning mappings from transient inputs to dynamic outputs. This study applies LSTM to predict transient and static outputs for fluid flows under surface tension effects. Specifically, we explore two distinct droplet dynamic scenarios: droplets with diverse initial shapes impacting with solid surfaces, as well as the coalescence of two droplets following collision. Using only dimensionless numbers and geometric time series data from numerical simulations, LSTM predicts the energy budget. The marker-and-cell front-tracking methodology combined with a marker-and-cell finite-difference strategy is adopted for simulating the droplet dynamics. Using a recurrent neural network (RNN) architecture fed with time series data derived from geometrical parameters, as for example droplet diameter variation, our study shows the accuracy of our approach in predicting energy budgets, as for instance the kinetic, dissipation, and surface energy trends, across a range of Reynolds and Weber numbers in droplet dynamic problems. Finally, a two-phase sequential neural network using only geometric data, which is readily available in experimental settings, is employed to predict the energies and then use them to estimate static parameters, such as the Reynolds and Weber numbers. While our methodology has been primarily validated with simulation data, its adaptability to experimental datasets is a promising avenue for future exploration. We hope that our strategy can be useful for diverse applications, spanning from inkjet printing to combustion engines, where the prediction of energy budgets or dissipation energies is crucial. ",
    "url": "https://arxiv.org/abs/2403.16144",
    "authors": [
      "Diego A. de Aguiar",
      "Hugo L. Fran\u00e7a",
      "Cassio M. Oishi"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16175",
    "title": "Enhancing MRI-Based Classification of Alzheimer's Disease with  Explainable 3D Hybrid Compact Convolutional Transformers",
    "abstract": "Alzheimer's disease (AD), characterized by progressive cognitive decline and memory loss, presents a formidable global health challenge, underscoring the critical importance of early and precise diagnosis for timely interventions and enhanced patient outcomes. While MRI scans provide valuable insights into brain structures, traditional analysis methods often struggle to discern intricate 3D patterns crucial for AD identification. Addressing this challenge, we introduce an alternative end-to-end deep learning model, the 3D Hybrid Compact Convolutional Transformers 3D (HCCT). By synergistically combining convolutional neural networks (CNNs) and vision transformers (ViTs), the 3D HCCT adeptly captures both local features and long-range relationships within 3D MRI scans. Extensive evaluations on prominent AD benchmark dataset, ADNI, demonstrate the 3D HCCT's superior performance, surpassing state of the art CNN and transformer-based methods in classification accuracy. Its robust generalization capability and interpretability marks a significant stride in AD classification from 3D MRI scans, promising more accurate and reliable diagnoses for improved patient care and superior clinical outcomes. ",
    "url": "https://arxiv.org/abs/2403.16175",
    "authors": [
      "Arindam Majee",
      "Avisek Gupta",
      "Sourav Raha",
      "Swagatam Das"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16258",
    "title": "Laplacian-guided Entropy Model in Neural Codec with Blur-dissipated  Synthesis",
    "abstract": "While replacing Gaussian decoders with a conditional diffusion model enhances the perceptual quality of reconstructions in neural image compression, their lack of inductive bias for image data restricts their ability to achieve state-of-the-art perceptual levels. To address this limitation, we adopt a non-isotropic diffusion model at the decoder side. This model imposes an inductive bias aimed at distinguishing between frequency contents, thereby facilitating the generation of high-quality images. Moreover, our framework is equipped with a novel entropy model that accurately models the probability distribution of latent representation by exploiting spatio-channel correlations in latent space, while accelerating the entropy decoding step. This channel-wise entropy model leverages both local and global spatial contexts within each channel chunk. The global spatial context is built upon the Transformer, which is specifically designed for image compression tasks. The designed Transformer employs a Laplacian-shaped positional encoding, the learnable parameters of which are adaptively adjusted for each channel cluster. Our experiments demonstrate that our proposed framework yields better perceptual quality compared to cutting-edge generative-based codecs, and the proposed entropy model contributes to notable bitrate savings. ",
    "url": "https://arxiv.org/abs/2403.16258",
    "authors": [
      "Atefeh Khoshkhahtinat",
      "Ali Zafari",
      "Piyush M. Mehta",
      "Nasser M. Nasrabadi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16335",
    "title": "MEDDAP: Medical Dataset Enhancement via Diversified Augmentation  Pipeline",
    "abstract": "The effectiveness of Deep Neural Networks (DNNs) heavily relies on the abundance and accuracy of available training data. However, collecting and annotating data on a large scale is often both costly and time-intensive, particularly in medical cases where practitioners are already occupied with their duties. Moreover, ensuring that the model remains robust across various scenarios of image capture is crucial in medical domains, especially when dealing with ultrasound images that vary based on the settings of different devices and the manual operation of the transducer. To address this challenge, we introduce a novel pipeline called MEDDAP, which leverages Stable Diffusion (SD) models to augment existing small datasets by automatically generating new informative labeled samples. Pretrained checkpoints for SD are typically based on natural images, and training them for medical images requires significant GPU resources due to their heavy parameters. To overcome this challenge, we introduce USLoRA (Ultrasound Low-Rank Adaptation), a novel fine-tuning method tailored specifically for ultrasound applications. USLoRA allows for selective fine-tuning of weights within SD, requiring fewer than 0.1\\% of parameters compared to fully fine-tuning only the UNet portion of SD. To enhance dataset diversity, we incorporate different adjectives into the generation process prompts, thereby desensitizing the classifiers to intensity changes across different images. This approach is inspired by clinicians' decision-making processes regarding breast tumors, where tumor shape often plays a more crucial role than intensity. In conclusion, our pipeline not only outperforms classifiers trained on the original dataset but also demonstrates superior performance when encountering unseen datasets. The source code is available at https://github.com/yasamin-med/MEDDAP. ",
    "url": "https://arxiv.org/abs/2403.16335",
    "authors": [
      "Yasamin Medghalchi",
      "Niloufar Zakariaei",
      "Arman Rahmim",
      "Ilker Hacihaliloglu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16373",
    "title": "A new social welfare function with a number of desirable properties",
    "abstract": "By relaxing the dominating set in three ways (e.g., from \"each member beats every non-member\" to \"each member beats or ties every non-member, with an additional requirement that at least one member beat every non-member\"), we propose a new social welfare function, which satisfies a number of desirable properties including Condorcet winner principle, Condorcet loser principle, strong Gehrlein-stability (hence Smith set principle), anonymity, neutrality, weak Pareto, strong Pareto, non-dictatorship, and [independence of irrelevant alternatives (IIA) when the pairwise majority relation is an ordering on the alternative set]. If the pairwise majority relation is complete and transitive, the proposed method yields a collective preference relation that coincides with the input majority relation. It thus shares the same collective preference function on the dichotomous domain with the approval voting and the majority voting. It runs in polynomial time and thus possesses a competitive advantage over a number of computationally intractable voting rules such as the Dodgson's rule, the Kemeny's rule, the Slater's rule, the Banks rule, and the Schwartz's tournament equilibrium set (TEQ) rule. When it is used in tournaments, its winner belongs to the uncovered set, the top cycle set, the Smith set, and the Schwartz set. In addition, in a tournament where the number of alternatives is not more than 4, its winner set is a subset, sometimes proper, of the Copeland winner set. Whether this attractive argument is still valid in four-more-alternative tournaments remains an open question. ",
    "url": "https://arxiv.org/abs/2403.16373",
    "authors": [
      "Fujun Hou"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2403.16397",
    "title": "RadioGAT: A Joint Model-based and Data-driven Framework for Multi-band  Radiomap Reconstruction via Graph Attention Networks",
    "abstract": "Multi-band radiomap reconstruction (MB-RMR) is a key component in wireless communications for tasks such as spectrum management and network planning. However, traditional machine-learning-based MB-RMR methods, which rely heavily on simulated data or complete structured ground truth, face significant deployment challenges. These challenges stem from the differences between simulated and actual data, as well as the scarcity of real-world measurements. To address these challenges, our study presents RadioGAT, a novel framework based on Graph Attention Network (GAT) tailored for MB-RMR within a single area, eliminating the need for multi-region datasets. RadioGAT innovatively merges model-based spatial-spectral correlation encoding with data-driven radiomap generalization, thus minimizing the reliance on extensive data sources. The framework begins by transforming sparse multi-band data into a graph structure through an innovative encoding strategy that leverages radio propagation models to capture the spatial-spectral correlation inherent in the data. This graph-based representation not only simplifies data handling but also enables tailored label sampling during training, significantly enhancing the framework's adaptability for deployment. Subsequently, The GAT is employed to generalize the radiomap information across various frequency bands. Extensive experiments using raytracing datasets based on real-world environments have demonstrated RadioGAT's enhanced accuracy in supervised learning settings and its robustness in semi-supervised scenarios. These results underscore RadioGAT's effectiveness and practicality for MB-RMR in environments with limited data availability. ",
    "url": "https://arxiv.org/abs/2403.16397",
    "authors": [
      "Xiaojie Li",
      "Songyang Zhang",
      "Hang Li",
      "Xiaoyang Li",
      "Lexi Xu",
      "Haigao Xu",
      "Hui Mei",
      "Guangxu Zhu",
      "Nan Qi",
      "Ming Xiao"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16523",
    "title": "Causal Discovery from Poisson Branching Structural Causal Model Using  High-Order Cumulant with Path Analysis",
    "abstract": "Count data naturally arise in many fields, such as finance, neuroscience, and epidemiology, and discovering causal structure among count data is a crucial task in various scientific and industrial scenarios. One of the most common characteristics of count data is the inherent branching structure described by a binomial thinning operator and an independent Poisson distribution that captures both branching and noise. For instance, in a population count scenario, mortality and immigration contribute to the count, where survival follows a Bernoulli distribution, and immigration follows a Poisson distribution. However, causal discovery from such data is challenging due to the non-identifiability issue: a single causal pair is Markov equivalent, i.e., $X\\rightarrow Y$ and $Y\\rightarrow X$ are distributed equivalent. Fortunately, in this work, we found that the causal order from $X$ to its child $Y$ is identifiable if $X$ is a root vertex and has at least two directed paths to $Y$, or the ancestor of $X$ with the most directed path to $X$ has a directed path to $Y$ without passing $X$. Specifically, we propose a Poisson Branching Structure Causal Model (PB-SCM) and perform a path analysis on PB-SCM using high-order cumulants. Theoretical results establish the connection between the path and cumulant and demonstrate that the path information can be obtained from the cumulant. With the path information, causal order is identifiable under some graphical conditions. A practical algorithm for learning causal structure under PB-SCM is proposed and the experiments demonstrate and verify the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2403.16523",
    "authors": [
      "Jie Qiao",
      "Yu Xiang",
      "Zhengming Chen",
      "Ruichu Cai",
      "Zhifeng Hao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16610",
    "title": "Distributed collaborative anomalous sound detection by embedding sharing",
    "abstract": "To develop a machine sound monitoring system, a method for detecting anomalous sound is proposed. In this paper, we explore a method for multiple clients to collaboratively learn an anomalous sound detection model while keeping their raw data private from each other. In the context of industrial machine anomalous sound detection, each client possesses data from different machines or different operational states, making it challenging to learn through federated learning or split learning. In our proposed method, each client calculates embeddings using a common pre-trained model developed for sound data classification, and these calculated embeddings are aggregated on the server to perform anomalous sound detection through outlier exposure. Experiments showed that our proposed method improves the AUC of anomalous sound detection by an average of 6.8%. ",
    "url": "https://arxiv.org/abs/2403.16610",
    "authors": [
      "Kota Dohi",
      "Yohei Kawaguchi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2403.16678",
    "title": "DeepGleason: a System for Automated Gleason Grading of Prostate Cancer  using Deep Neural Networks",
    "abstract": "Advances in digital pathology and artificial intelligence (AI) offer promising opportunities for clinical decision support and enhancing diagnostic workflows. Previous studies already demonstrated AI's potential for automated Gleason grading, but lack state-of-the-art methodology and model reusability. To address this issue, we propose DeepGleason: an open-source deep neural network based image classification system for automated Gleason grading using whole-slide histopathology images from prostate tissue sections. Implemented with the standardized AUCMEDI framework, our tool employs a tile-wise classification approach utilizing fine-tuned image preprocessing techniques in combination with a ConvNeXt architecture which was compared to various state-of-the-art architectures. The neural network model was trained and validated on an in-house dataset of 34,264 annotated tiles from 369 prostate carcinoma slides. We demonstrated that DeepGleason is capable of highly accurate and reliable Gleason grading with a macro-averaged F1-score of 0.806, AUC of 0.991, and Accuracy of 0.974. The internal architecture comparison revealed that the ConvNeXt model was superior performance-wise on our dataset to established and other modern architectures like transformers. Furthermore, we were able to outperform the current state-of-the-art in tile-wise fine-classification with a sensitivity and specificity of 0.94 and 0.98 for benign vs malignant detection as well as of 0.91 and 0.75 for Gleason 3 vs Gleason 4 & 5 classification, respectively. Our tool contributes to the wider adoption of AI-based Gleason grading within the research community and paves the way for broader clinical application of deep learning models in digital pathology. DeepGleason is open-source and publicly available for research application in the following Git repository: https://github.com/frankkramer-lab/DeepGleason. ",
    "url": "https://arxiv.org/abs/2403.16678",
    "authors": [
      "Dominik M\u00fcller",
      "Philip Meyer",
      "Lukas Rentschler",
      "Robin Manz",
      "Jonas B\u00e4cker",
      "Samantha Cramer",
      "Christoph Wengenmayr",
      "Bruno M\u00e4rkl",
      "Ralf Huss",
      "I\u00f1aki Soto-Rey",
      "Johannes Raffler"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Tissues and Organs (q-bio.TO)"
    ]
  },
  {
    "id": "arXiv:2403.16970",
    "title": "Joint chest X-ray diagnosis and clinical visual attention prediction  with multi-stage cooperative learning: enhancing interpretability",
    "abstract": "As deep learning has become the state-of-the-art for computer-assisted diagnosis, interpretability of the automatic decisions is crucial for clinical deployment. While various methods were proposed in this domain, visual attention maps of clinicians during radiological screening offer a unique asset to provide important insights and can potentially enhance the quality of computer-assisted diagnosis. With this paper, we introduce a novel deep-learning framework for joint disease diagnosis and prediction of corresponding visual saliency maps for chest X-ray scans. Specifically, we designed a novel dual-encoder multi-task UNet, which leverages both a DenseNet201 backbone and a Residual and Squeeze-and-Excitation block-based encoder to extract diverse features for saliency map prediction, and a multi-scale feature-fusion classifier to perform disease classification. To tackle the issue of asynchronous training schedules of individual tasks in multi-task learning, we proposed a multi-stage cooperative learning strategy, with contrastive learning for feature encoder pretraining to boost performance. Experiments show that our proposed method outperformed existing techniques for chest X-ray diagnosis and the quality of visual saliency map prediction. ",
    "url": "https://arxiv.org/abs/2403.16970",
    "authors": [
      "Zirui Qiu",
      "Hassan Rivaz",
      "Yiming Xiao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.16974",
    "title": "Self-STORM: Deep Unrolled Self-Supervised Learning for Super-Resolution  Microscopy",
    "abstract": "The use of fluorescent molecules to create long sequences of low-density, diffraction-limited images enables highly-precise molecule localization. However, this methodology requires lengthy imaging times, which limits the ability to view dynamic interactions of live cells on short time scales. Many techniques have been developed to reduce the number of frames needed for localization, from classic iterative optimization to deep neural networks. Particularly, deep algorithm unrolling utilizes both the structure of iterative sparse recovery algorithms and the performance gains of supervised deep learning. However, the robustness of this approach is highly dependant on having sufficient training data. In this paper we introduce deep unrolled self-supervised learning, which alleviates the need for such data by training a sequence-specific, model-based autoencoder that learns only from given measurements. Our proposed method exceeds the performance of its supervised counterparts, thus allowing for robust, dynamic imaging well below the diffraction limit without any labeled training samples. Furthermore, the suggested model-based autoencoder scheme can be utilized to enhance generalization in any sparse recovery framework, without the need for external training data. ",
    "url": "https://arxiv.org/abs/2403.16974",
    "authors": [
      "Yair Ben Sahel",
      "Yonina C. Eldar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1908.01978",
    "title": "Multi-view Deep Subspace Clustering Networks",
    "abstract": " Comments: Accepted by T-CYB ",
    "url": "https://arxiv.org/abs/1908.01978",
    "authors": [
      "Pengfei Zhu",
      "Xinjie Yao",
      "Yu Wang",
      "Binyuan Hui",
      "Dawei Du",
      "Qinghua Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.05453",
    "title": "Improving White-box Robustness of Pre-processing Defenses via Joint  Adversarial Training",
    "abstract": " Title: Improving White-box Robustness of Pre-processing Defenses via Joint  Adversarial Training ",
    "url": "https://arxiv.org/abs/2106.05453",
    "authors": [
      "Dawei Zhou",
      "Nannan Wang",
      "Xinbo Gao",
      "Bo Han",
      "Jun Yu",
      "Xiaoyu Wang",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.14003",
    "title": "Connected greedy colourings of perfect graphs and other classes: the  good, the bad and the ugly",
    "abstract": " Comments: 14 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2110.14003",
    "authors": [
      "Laurent Beaudou",
      "Caroline Brosse",
      "Oscar Defrain",
      "Florent Foucaud",
      "Aur\u00e9lie Lagoutte",
      "Vincent Limouzy",
      "Lucas Pastor"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2111.10933",
    "title": "Decentralized Multi-Armed Bandit Can Outperform Classic Upper Confidence  Bound: A Homogeneous Case over Strongly Connected Graphs",
    "abstract": " Comments: Submitted to the 63rd IEEE Conference on Decision and Control ",
    "url": "https://arxiv.org/abs/2111.10933",
    "authors": [
      "Jingxuan Zhu",
      "Ji Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.04476",
    "title": "Counting Kernels in Directed Graphs with Arbitrary Orientations",
    "abstract": " Comments: 19 pages, 3 figures, redactional changes, to be published in Discrete Appl. Math ",
    "url": "https://arxiv.org/abs/2202.04476",
    "authors": [
      "Bruno Jartoux"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2202.12074",
    "title": "On The Effectiveness of One-Class Support Vector Machine in Different  Defect Prediction Scenarios",
    "abstract": " Comments: Published at SANER'24 (Winner of the Best RENE paper award) see this https URL ",
    "url": "https://arxiv.org/abs/2202.12074",
    "authors": [
      "Rebecca Moussa",
      "Danielle Azar",
      "Federica Sarro"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.13254",
    "title": "Sample compression schemes for balls in graphs",
    "abstract": " Comments: 27 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2206.13254",
    "authors": [
      "J\u00e9r\u00e9mie Chalopin",
      "Victor Chepoi",
      "Fionn Mc Inerney",
      "S\u00e9bastien Ratel",
      "Yann Vax\u00e8s"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04913",
    "title": "Generalizing to Unseen Domains with Wasserstein Distributional  Robustness under Limited Source Knowledge",
    "abstract": " Title: Generalizing to Unseen Domains with Wasserstein Distributional  Robustness under Limited Source Knowledge ",
    "url": "https://arxiv.org/abs/2207.04913",
    "authors": [
      "Jingge Wang",
      "Liyan Xie",
      "Yao Xie",
      "Shao-Lun Huang",
      "Yang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.06900",
    "title": "Convolutional Spiking Neural Networks for Detecting Anticipatory Brain  Potentials Using Electroencephalogram",
    "abstract": " Comments: 16 pages, 6 figures, Scientific Reports submission ",
    "url": "https://arxiv.org/abs/2208.06900",
    "authors": [
      "Nathan Lutes",
      "Venkata Sriram Siddhardh Nadendla",
      "K. Krishnamurthy"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2208.08233",
    "title": "Dynamical softassign and adaptive parameter tuning for graph matching",
    "abstract": " Title: Dynamical softassign and adaptive parameter tuning for graph matching ",
    "url": "https://arxiv.org/abs/2208.08233",
    "authors": [
      "Binrui Shen",
      "Qiang Niu",
      "Shengxin Zhu"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.08270",
    "title": "On the Privacy Effect of Data Enhancement via the Lens of Memorization",
    "abstract": " Comments: Accepted by IEEE TIFS, 17 pages ",
    "url": "https://arxiv.org/abs/2208.08270",
    "authors": [
      "Xiao Li",
      "Qiongxiu Li",
      "Zhanhao Hu",
      "Xiaolin Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.00915",
    "title": "Detection of diabetic retinopathy using longitudinal self-supervised  learning",
    "abstract": " Comments: Accepted preprint for presentation at MICCAI-OMIA ",
    "url": "https://arxiv.org/abs/2209.00915",
    "authors": [
      "Rachid Zeghlache",
      "Pierre-Henri Conze",
      "Mostafa El Habib Daho",
      "Ramin Tadayoni",
      "Pascal Massin",
      "B\u00e9atrice Cochener",
      "Gwenol\u00e9 Quellec",
      "Mathieu Lamard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.07556",
    "title": "Utilizing Synthetic Data in Supervised Learning for Robust 5-DoF  Magnetic Marker Localization",
    "abstract": " Title: Utilizing Synthetic Data in Supervised Learning for Robust 5-DoF  Magnetic Marker Localization ",
    "url": "https://arxiv.org/abs/2211.07556",
    "authors": [
      "Mengfan Wu",
      "Thomas Langerak",
      "Otmar Hilliges",
      "Juan Zarate"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.06370",
    "title": "Dual Accuracy-Quality-Driven Neural Network for Prediction Interval  Generation",
    "abstract": " Comments: Accepted at the IEEE Transactions on Neural Networks and Learning Systems ",
    "url": "https://arxiv.org/abs/2212.06370",
    "authors": [
      "Giorgio Morales",
      "John W. Sheppard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.09962",
    "title": "Distributional Robustness Bounds Generalization Errors",
    "abstract": " Comments: Updated Version ",
    "url": "https://arxiv.org/abs/2212.09962",
    "authors": [
      "Shixiong Wang",
      "Haowei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.07482",
    "title": "FreshGNN: Reducing Memory Access via Stable Historical Embeddings for  Graph Neural Network Training",
    "abstract": " Comments: Accepted by VLDB 2024 ",
    "url": "https://arxiv.org/abs/2301.07482",
    "authors": [
      "Kezhao Huang",
      "Haitian Jiang",
      "Minjie Wang",
      "Guangxuan Xiao",
      "David Wipf",
      "Xiang Song",
      "Quan Gan",
      "Zengfeng Huang",
      "Jidong Zhai",
      "Zheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.10451",
    "title": "Knowledge-augmented Graph Neural Networks with Concept-aware Attention  for Adverse Drug Event Detection",
    "abstract": " Comments: LREC-COLING 2024 ",
    "url": "https://arxiv.org/abs/2301.10451",
    "authors": [
      "Shaoxiong Ji",
      "Ya Gao",
      "Pekka Marttinen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.10956",
    "title": "Graph Neural Networks can Recover the Hidden Features Solely from the  Graph Structure",
    "abstract": " Comments: ICML 2023 ",
    "url": "https://arxiv.org/abs/2301.10956",
    "authors": [
      "Ryoma Sato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.00325",
    "title": "Privacy Dashboards for Citizens and corresponding GDPR Services for  Small Data Holders: A Literature Review",
    "abstract": " Comments: 29 pages ",
    "url": "https://arxiv.org/abs/2302.00325",
    "authors": [
      "Nico Puhlmann",
      "Alex Wiesmaier",
      "Patrick Weber",
      "Andreas Heinemann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.00352",
    "title": "Flip-width: Cops and Robber on dense graphs",
    "abstract": " Comments: 80 pages ",
    "url": "https://arxiv.org/abs/2302.00352",
    "authors": [
      "Szymon Toru\u0144czyk"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2302.06746",
    "title": "Workload-Balanced Pruning for Sparse Spiking Neural Networks",
    "abstract": " Comments: 11 pages. Accepted to IEEE Transactions on Emerging Topics in Computational Intelligence (2024) ",
    "url": "https://arxiv.org/abs/2302.06746",
    "authors": [
      "Ruokai Yin",
      "Youngeun Kim",
      "Yuhang Li",
      "Abhishek Moitra",
      "Nitin Satpute",
      "Anna Hambitzer",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2302.08347",
    "title": "The autoregressive neural network architecture of the Boltzmann  distribution of pairwise interacting spins systems",
    "abstract": " Comments: 20 pages, 10 figure plus the Supplementary Information ",
    "url": "https://arxiv.org/abs/2302.08347",
    "authors": [
      "Indaco Biazzo"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.10681",
    "title": "FrankenSplit: Efficient Neural Feature Compression with Shallow  Variational Bottleneck Injection for Mobile Edge Computing",
    "abstract": " Comments: Submission to IEEE Transactions on Mobile Computing ",
    "url": "https://arxiv.org/abs/2302.10681",
    "authors": [
      "Alireza Furutanpey",
      "Philipp Raith",
      "Schahram Dustdar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12054",
    "title": "Influencer Backdoor Attack on Semantic Segmentation",
    "abstract": " Title: Influencer Backdoor Attack on Semantic Segmentation ",
    "url": "https://arxiv.org/abs/2303.12054",
    "authors": [
      "Haoheng Lan",
      "Jindong Gu",
      "Philip Torr",
      "Hengshuang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17245",
    "title": "Investigating and Mitigating the Side Effects of Noisy Views for  Self-Supervised Clustering Algorithms in Practical Multi-View Scenarios",
    "abstract": " Title: Investigating and Mitigating the Side Effects of Noisy Views for  Self-Supervised Clustering Algorithms in Practical Multi-View Scenarios ",
    "url": "https://arxiv.org/abs/2303.17245",
    "authors": [
      "Jie Xu",
      "Yazhou Ren",
      "Xiaolong Wang",
      "Lei Feng",
      "Zheng Zhang",
      "Gang Niu",
      "Xiaofeng Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04806",
    "title": "Examining Temporalities on Stance Detection towards COVID-19 Vaccination",
    "abstract": " Comments: Accepted at LREC-COLING 2024 ",
    "url": "https://arxiv.org/abs/2304.04806",
    "authors": [
      "Yida Mu",
      "Mali Jin",
      "Kalina Bontcheva",
      "Xingyi Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.04615",
    "title": "Performance Analysis of In-Band-Full-Duplex Multi-Cell Wideband IAB  Networks",
    "abstract": " Title: Performance Analysis of In-Band-Full-Duplex Multi-Cell Wideband IAB  Networks ",
    "url": "https://arxiv.org/abs/2305.04615",
    "authors": [
      "Junkai Zhang",
      "Tharmalingam Ratnarajah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.05949",
    "title": "Scalable and Precise Application-Centered Call Graph Construction for  Python",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2305.05949",
    "authors": [
      "Kaifeng Huang",
      "Yixuan Yan",
      "Bihuan Chen",
      "Zixin Tao",
      "Yulei Sui",
      "Xin Peng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.12519",
    "title": "LLM Paternity Test: Generated Text Detection with LLM Genetic  Inheritance",
    "abstract": " Title: LLM Paternity Test: Generated Text Detection with LLM Genetic  Inheritance ",
    "url": "https://arxiv.org/abs/2305.12519",
    "authors": [
      "Xiao Yu",
      "Yuang Qi",
      "Kejiang Chen",
      "Guoqiang Chen",
      "Xi Yang",
      "Pengyuan Zhu",
      "Weiming Zhang",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14310",
    "title": "Navigating Prompt Complexity for Zero-Shot Classification: A Study of  Large Language Models in Computational Social Science",
    "abstract": " Comments: Accepted at LREC-COLING 2024 ",
    "url": "https://arxiv.org/abs/2305.14310",
    "authors": [
      "Yida Mu",
      "Ben P. Wu",
      "William Thorne",
      "Ambrose Robinson",
      "Nikolaos Aletras",
      "Carolina Scarton",
      "Kalina Bontcheva",
      "Xingyi Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.16943",
    "title": "DiffusionNAG: Predictor-guided Neural Architecture Generation with  Diffusion Models",
    "abstract": " Comments: Accepted to ICLR 2024 ",
    "url": "https://arxiv.org/abs/2305.16943",
    "authors": [
      "Sohyun An",
      "Hayeon Lee",
      "Jaehyeong Jo",
      "Seanie Lee",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.04337",
    "title": "A study on the impact of Self-Supervised Learning on automatic  dysarthric speech assessment",
    "abstract": " Comments: Accepted as a workshop paper at ICASSP SASB 2024 ",
    "url": "https://arxiv.org/abs/2306.04337",
    "authors": [
      "Xavier F. Cadet",
      "Ranya Aloufi",
      "Sara Ahmadi-Abhari",
      "Hamed Haddadi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.07632",
    "title": "NeuS-PIR: Learning Relightable Neural Surface using Pre-Integrated  Rendering",
    "abstract": " Title: NeuS-PIR: Learning Relightable Neural Surface using Pre-Integrated  Rendering ",
    "url": "https://arxiv.org/abs/2306.07632",
    "authors": [
      "Shi Mao",
      "Chenming Wu",
      "Zhelun Shen",
      "Yifan Wang",
      "Dayan Wu",
      "Liangjun Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2306.08929",
    "title": "On the resilience of Collaborative Learning-based Recommender Systems  Against Community Detection Attack",
    "abstract": " Title: On the resilience of Collaborative Learning-based Recommender Systems  Against Community Detection Attack ",
    "url": "https://arxiv.org/abs/2306.08929",
    "authors": [
      "Yacine Belal",
      "Sonia Ben Mokhtar",
      "Mohamed Maouche",
      "Anthony Simonet-Boulogne"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2307.02591",
    "title": "ODD: A Benchmark Dataset for the Natural Language Processing based  Opioid Related Aberrant Behavior Detection",
    "abstract": " Comments: To be appeared at NAACL 2024 ",
    "url": "https://arxiv.org/abs/2307.02591",
    "authors": [
      "Sunjae Kwon",
      "Xun Wang",
      "Weisong Liu",
      "Emily Druhl",
      "Minhee L. Sung",
      "Joel I. Reisman",
      "Wenjun Li",
      "Robert D. Kerns",
      "William Becker",
      "Hong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.10583",
    "title": "Deep fused flow and topology features for botnet detection basing on  pretrained GCN",
    "abstract": " Title: Deep fused flow and topology features for botnet detection basing on  pretrained GCN ",
    "url": "https://arxiv.org/abs/2307.10583",
    "authors": [
      "Meng Xiaoyuan",
      "Lang bo",
      "Yanxi Liu",
      "Yuhao Yan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.12851",
    "title": "Early Neuron Alignment in Two-layer ReLU Networks with Small  Initialization",
    "abstract": " Comments: iclr 2024 camera-ready ",
    "url": "https://arxiv.org/abs/2307.12851",
    "authors": [
      "Hancheng Min",
      "Enrique Mallada",
      "Ren\u00e9 Vidal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.00186",
    "title": "Learning Complex Motion Plans using Neural ODEs with Safety and  Stability Guarantees",
    "abstract": " Comments: accepted to ICRA 2024 ",
    "url": "https://arxiv.org/abs/2308.00186",
    "authors": [
      "Farhad Nawaz",
      "Tianyu Li",
      "Nikolai Matni",
      "Nadia Figueroa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.00247",
    "title": "Unleashing the Power of Self-Supervised Image Denoising: A Comprehensive  Review",
    "abstract": " Comments: 24 pages ",
    "url": "https://arxiv.org/abs/2308.00247",
    "authors": [
      "Dan Zhang",
      "Fangfang Zhou",
      "Felix Albu",
      "Yuanzhou Wei",
      "Xiao Yang",
      "Yuan Gu",
      "Qiang Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07942",
    "title": "Inductive Knowledge Graph Completion with GNNs and Rules: An Analysis",
    "abstract": " Title: Inductive Knowledge Graph Completion with GNNs and Rules: An Analysis ",
    "url": "https://arxiv.org/abs/2308.07942",
    "authors": [
      "Akash Anil",
      "V\u00edctor Guti\u00e9rrez-Basulto",
      "Yazm\u00edn Iba\u00f1\u00e9z-Garc\u00eda",
      "Steven Schockaert"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.10299",
    "title": "Boosting Adversarial Transferability by Block Shuffle and Rotation",
    "abstract": " Comments: Accepted by CVPR 2024 ",
    "url": "https://arxiv.org/abs/2308.10299",
    "authors": [
      "Kunyu Wang",
      "Xuanran He",
      "Wenxuan Wang",
      "Xiaosen Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2308.11585",
    "title": "Causal Intersectionality and Dual Form of Gradient Descent for  Multimodal Analysis: a Case Study on Hateful Memes",
    "abstract": " Comments: Accepted to LREC-COLING 2024 ",
    "url": "https://arxiv.org/abs/2308.11585",
    "authors": [
      "Yosuke Miyanishi",
      "Minh Le Nguyen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.12581",
    "title": "A Huber Loss Minimization Approach to Byzantine Robust Federated  Learning",
    "abstract": " Title: A Huber Loss Minimization Approach to Byzantine Robust Federated  Learning ",
    "url": "https://arxiv.org/abs/2308.12581",
    "authors": [
      "Puning Zhao",
      "Fei Yu",
      "Zhiguo Wan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.13356",
    "title": "CEIMVEN: An Approach of Cutting Edge Implementation of Modified Versions  of EfficientNet (V1-V2) Architecture for Breast Cancer Detection and  Classification from Ultrasound Images",
    "abstract": " Title: CEIMVEN: An Approach of Cutting Edge Implementation of Modified Versions  of EfficientNet (V1-V2) Architecture for Breast Cancer Detection and  Classification from Ultrasound Images ",
    "url": "https://arxiv.org/abs/2308.13356",
    "authors": [
      "Sheekar Banerjee",
      "Md. Kamrul Hasan Monir"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.01069",
    "title": "Separable Hamiltonian Neural Networks",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2309.01069",
    "authors": [
      "Zi-Yu Khoo",
      "Dawen Wu",
      "Jonathan Sze Choong Low",
      "St\u00e9phane Bressan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.02836",
    "title": "BigVSAN: Enhancing GAN-based Neural Vocoders with Slicing Adversarial  Network",
    "abstract": " Comments: Accepted at ICASSP 2024. Equation (5) in the previous version is wrong. We modified it ",
    "url": "https://arxiv.org/abs/2309.02836",
    "authors": [
      "Takashi Shibuya",
      "Yuhta Takida",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.03103",
    "title": "ContrastWSD: Enhancing Metaphor Detection with Word Sense Disambiguation  Following the Metaphor Identification Procedure",
    "abstract": " Comments: 9 pages, 2 figures, accepted for the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024) ",
    "url": "https://arxiv.org/abs/2309.03103",
    "authors": [
      "Mohamad Elzohbi",
      "Richard Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.04937",
    "title": "LONER: LiDAR Only Neural Representations for Real-Time SLAM",
    "abstract": " Comments: First two authors equally contributed. Webpage: this https URL ",
    "url": "https://arxiv.org/abs/2309.04937",
    "authors": [
      "Seth Isaacson",
      "Pou-Chun Kung",
      "Mani Ramanagopal",
      "Ram Vasudevan",
      "Katherine A. Skinner"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.06617",
    "title": "Accelerating model evaluations in uncertainty propagation on tensor  grids using computational graph transformations",
    "abstract": " Title: Accelerating model evaluations in uncertainty propagation on tensor  grids using computational graph transformations ",
    "url": "https://arxiv.org/abs/2309.06617",
    "authors": [
      "Bingran Wang",
      "Mark Sperry",
      "Victor E. Gandarillas",
      "John T. Hwang"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2309.07289",
    "title": "User Training with Error Augmentation for Electromyogram-based Gesture  Classification",
    "abstract": " Comments: 10 pages, 10 figures. V2: Fix latex characters in author name. V3: Add published DOI and Copyright notice ",
    "url": "https://arxiv.org/abs/2309.07289",
    "authors": [
      "Yunus Bicer",
      "Niklas Smedemark-Margulies",
      "Basak Celik",
      "Elifnur Sunger",
      "Ryan Orendorff",
      "Stephanie Naufel",
      "Tales Imbiriba",
      "Deniz Erdo\u011fmu\u015f",
      "Eugene Tunik",
      "Mathew Yarossi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.09317",
    "title": "Kinematics-aware Trajectory Generation and Prediction with Latent  Stochastic Differential Modeling",
    "abstract": " Comments: 8 pages, conference paper in motion generation ",
    "url": "https://arxiv.org/abs/2309.09317",
    "authors": [
      "Ruochen Jiao",
      "Yixuan Wang",
      "Xiangguo Liu",
      "Chao Huang",
      "Qi Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.09469",
    "title": "Spiking-LEAF: A Learnable Auditory front-end for Spiking Neural Networks",
    "abstract": " Comments: Accepted by ICASSP2024 ",
    "url": "https://arxiv.org/abs/2309.09469",
    "authors": [
      "Zeyang Song",
      "Jibin Wu",
      "Malu Zhang",
      "Mike Zheng Shou",
      "Haizhou Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.09574",
    "title": "Latent assimilation with implicit neural representations for unknown  dynamics",
    "abstract": " Comments: 40 pages ",
    "url": "https://arxiv.org/abs/2309.09574",
    "authors": [
      "Zhuoyuan Li",
      "Bin Dong",
      "Pingwen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Optimization and Control (math.OC)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2309.11528",
    "title": "Learning Complete Topology-Aware Correlations Between Relations for  Inductive Link Prediction",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2103.03642 ",
    "url": "https://arxiv.org/abs/2309.11528",
    "authors": [
      "Jie Wang",
      "Hanzhu Chen",
      "Qitan Lv",
      "Zhihao Shi",
      "Jiajun Chen",
      "Huarui He",
      "Hongtao Xie",
      "Yongdong Zhang",
      "Feng Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11576",
    "title": "Examining the Limitations of Computational Rumor Detection Models  Trained on Static Datasets",
    "abstract": " Comments: Accepted at LREC-COLING 2024 ",
    "url": "https://arxiv.org/abs/2309.11576",
    "authors": [
      "Yida Mu",
      "Xingyi Song",
      "Kalina Bontcheva",
      "Nikolaos Aletras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.11639",
    "title": "The latent cognitive structures of social networks",
    "abstract": " Title: The latent cognitive structures of social networks ",
    "url": "https://arxiv.org/abs/2309.11639",
    "authors": [
      "Izabel Aguiar",
      "Johan Ugander"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.11840",
    "title": "Four universal growth regimes in degree-dependent first passage  percolation on spatial random graphs I",
    "abstract": " Comments: 82 pages. Companion paper: arXiv:2309.11880 ",
    "url": "https://arxiv.org/abs/2309.11840",
    "authors": [
      "J\u00falia Komj\u00e1thy",
      "John Lapinskas",
      "Johannes Lengler",
      "Ulysse Schaller"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2309.12188",
    "title": "SG-Bot: Object Rearrangement via Coarse-to-Fine Robotic Imagination on  Scene Graphs",
    "abstract": " Comments: ICRA 2024 accepted. Project website: this https URL ",
    "url": "https://arxiv.org/abs/2309.12188",
    "authors": [
      "Guangyao Zhai",
      "Xiaoni Cai",
      "Dianye Huang",
      "Yan Di",
      "Fabian Manhardt",
      "Federico Tombari",
      "Nassir Navab",
      "Benjamin Busam"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.12263",
    "title": "On the Relationship between Skill Neurons and Robustness in Prompt  Tuning",
    "abstract": " Title: On the Relationship between Skill Neurons and Robustness in Prompt  Tuning ",
    "url": "https://arxiv.org/abs/2309.12263",
    "authors": [
      "Leon Ackermann",
      "Xenia Ohmer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.00262",
    "title": "Robust Integral Consensus Control of Multi-Agent Networks Perturbed by  Matched and Unmatched Disturbances: The Case of Directed Graphs",
    "abstract": " Title: Robust Integral Consensus Control of Multi-Agent Networks Perturbed by  Matched and Unmatched Disturbances: The Case of Directed Graphs ",
    "url": "https://arxiv.org/abs/2310.00262",
    "authors": [
      "Jose Guadalupe Romero",
      "David Navarro-Alarcon"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.00724",
    "title": "Subtractive Mixture Models via Squaring: Representation and Learning",
    "abstract": " Title: Subtractive Mixture Models via Squaring: Representation and Learning ",
    "url": "https://arxiv.org/abs/2310.00724",
    "authors": [
      "Lorenzo Loconte",
      "Aleksanteri M. Sladek",
      "Stefan Mengel",
      "Martin Trapp",
      "Arno Solin",
      "Nicolas Gillis",
      "Antonio Vergari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01968",
    "title": "PyHexTop: a compact Python code for topology optimization using  hexagonal elements",
    "abstract": " Comments: Accepted in NCMDAO 2023 conference ",
    "url": "https://arxiv.org/abs/2310.01968",
    "authors": [
      "Aditi Agarwal",
      "Anupam Saxena",
      "Prabhat Kumar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2310.04662",
    "title": "HalluciDet: Hallucinating RGB Modality for Person Detection Through  Privileged Information",
    "abstract": " Comments: IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024 ",
    "url": "https://arxiv.org/abs/2310.04662",
    "authors": [
      "Heitor Rapela Medeiros",
      "Fidel A. Guerrero Pena",
      "Masih Aminbeidokhti",
      "Thomas Dubail",
      "Eric Granger",
      "Marco Pedersoli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05022",
    "title": "Fully Spiking Neural Network for Legged Robots",
    "abstract": " Title: Fully Spiking Neural Network for Legged Robots ",
    "url": "https://arxiv.org/abs/2310.05022",
    "authors": [
      "Xiaoyang Jiang",
      "Qiang Zhang",
      "Jingkai Sun",
      "Jiahang Cao",
      "Jingtong Ma",
      "Renjing Xu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05884",
    "title": "A Meta-Learning Perspective on Transformers for Causal Language Modeling",
    "abstract": " Title: A Meta-Learning Perspective on Transformers for Causal Language Modeling ",
    "url": "https://arxiv.org/abs/2310.05884",
    "authors": [
      "Xinbo Wu",
      "Lav R. Varshney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.08446",
    "title": "Towards Robust Multi-Modal Reasoning via Model Selection",
    "abstract": " Comments: Accepted by ICLR 2024 ",
    "url": "https://arxiv.org/abs/2310.08446",
    "authors": [
      "Xiangyan Liu",
      "Rongxue Li",
      "Wei Ji",
      "Tao Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.08774",
    "title": "PhyloGFN: Phylogenetic inference with generative flow networks",
    "abstract": " Title: PhyloGFN: Phylogenetic inference with generative flow networks ",
    "url": "https://arxiv.org/abs/2310.08774",
    "authors": [
      "Mingyang Zhou",
      "Zichao Yan",
      "Elliot Layne",
      "Nikolay Malkin",
      "Dinghuai Zhang",
      "Moksh Jain",
      "Mathieu Blanchette",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.11667",
    "title": "SOTOPIA: Interactive Evaluation for Social Intelligence in Language  Agents",
    "abstract": " Comments: Preprint, 43 pages. The first two authors contribute equally ",
    "url": "https://arxiv.org/abs/2310.11667",
    "authors": [
      "Xuhui Zhou",
      "Hao Zhu",
      "Leena Mathur",
      "Ruohong Zhang",
      "Haofei Yu",
      "Zhengyang Qi",
      "Louis-Philippe Morency",
      "Yonatan Bisk",
      "Daniel Fried",
      "Graham Neubig",
      "Maarten Sap"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15168",
    "title": "Ghost on the Shell: An Expressive Representation of General 3D Shapes",
    "abstract": " Comments: ICLR 2024 Oral (v3: 30 pages, 19 figures, Project Page: this https URL) ",
    "url": "https://arxiv.org/abs/2310.15168",
    "authors": [
      "Zhen Liu",
      "Yao Feng",
      "Yuliang Xiu",
      "Weiyang Liu",
      "Liam Paull",
      "Michael J. Black",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19258",
    "title": "Improving Online Source-free Domain Adaptation for Object Detection by  Unsupervised Data Acquisition",
    "abstract": " Title: Improving Online Source-free Domain Adaptation for Object Detection by  Unsupervised Data Acquisition ",
    "url": "https://arxiv.org/abs/2310.19258",
    "authors": [
      "Xiangyu Shi",
      "Yanyuan Qiao",
      "Qi Wu",
      "Lingqiao Liu",
      "Feras Dayoub"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.02695",
    "title": "Identifying Linearly-Mixed Causal Representations from Multi-Node  Interventions",
    "abstract": " Comments: Accepted for publication at CLeaR 2024 ",
    "url": "https://arxiv.org/abs/2311.02695",
    "authors": [
      "Simon Bing",
      "Urmi Ninad",
      "Jonas Wahl",
      "Jakob Runge"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2311.02760",
    "title": "Causal Question Answering with Reinforcement Learning",
    "abstract": " Comments: Accepted at WWW 2024 ",
    "url": "https://arxiv.org/abs/2311.02760",
    "authors": [
      "Lukas Bl\u00fcbaum",
      "Stefan Heindorf"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.03326",
    "title": "Non-convex potential games for finding global solutions to sensor  network localization",
    "abstract": " Title: Non-convex potential games for finding global solutions to sensor  network localization ",
    "url": "https://arxiv.org/abs/2311.03326",
    "authors": [
      "Gehui Xu",
      "Guanpu Chen",
      "Yiguang Hong",
      "Baris Fidan",
      "Thomas Parisini",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2311.06623",
    "title": "VT-Former: An Exploratory Study on Vehicle Trajectory Prediction for  Highway Surveillance through Graph Isomorphism and Transformer",
    "abstract": " Comments: Completely updated based on the reviews received for the paper ",
    "url": "https://arxiv.org/abs/2311.06623",
    "authors": [
      "Armin Danesh Pazho",
      "Ghazal Alinezhad Noghre",
      "Vinit Katariya",
      "Hamed Tabkhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.08118",
    "title": "Evaluating Neighbor Explainability for Graph Neural Networks",
    "abstract": " Title: Evaluating Neighbor Explainability for Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2311.08118",
    "authors": [
      "Oscar Llorente Gonzalez",
      "Rana Fawzy",
      "Jared Keown",
      "Michal Horemuz",
      "P\u00e9ter Vaderna",
      "S\u00e1ndor Laki",
      "Roland Kotrocz\u00f3",
      "Rita Csoma",
      "J\u00e1nos M\u00e1rk Szalai-Gindl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.08863",
    "title": "Toulouse Hyperspectral Data Set: a benchmark data set to assess  semi-supervised spectral representation learning and pixel-wise  classification techniques",
    "abstract": " Comments: 17 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2311.08863",
    "authors": [
      "Romain Thoreau",
      "Laurent Risser",
      "V\u00e9ronique Achard",
      "B\u00e9atrice Berthelot",
      "Xavier Briottet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.10610",
    "title": "A Poincar\u00e9 Inequality and Consistency Results for Signal Sampling on  Large Graphs",
    "abstract": " Comments: 23 pages ",
    "url": "https://arxiv.org/abs/2311.10610",
    "authors": [
      "Thien Le",
      "Luana Ruiz",
      "Stefanie Jegelka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.12838",
    "title": "Toward parallel intelligence: an interdisciplinary solution for complex  systems",
    "abstract": " Comments: 41 pages, 6 figures. The Innovation (2023) ",
    "url": "https://arxiv.org/abs/2311.12838",
    "authors": [
      "Yong Zhao",
      "Zhengqiu Zhu",
      "Bin Chen",
      "Sihang Qiu",
      "Jincai Huang",
      "Xin Lu",
      "Weiyi Yang",
      "Chuan Ai",
      "Kuihua Huang",
      "Cheng He",
      "Yucheng Jin",
      "Zhong Liu",
      "Fei-Yue Wang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.17516",
    "title": "MMA-Diffusion: MultiModal Attack on Diffusion Models",
    "abstract": " Comments: CVPR 2024. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2311.17516",
    "authors": [
      "Yijun Yang",
      "Ruiyuan Gao",
      "Xiaosen Wang",
      "Tsung-Yi Ho",
      "Nan Xu",
      "Qiang Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01696",
    "title": "BEVNeXt: Reviving Dense BEV Frameworks for 3D Object Detection",
    "abstract": " Title: BEVNeXt: Reviving Dense BEV Frameworks for 3D Object Detection ",
    "url": "https://arxiv.org/abs/2312.01696",
    "authors": [
      "Zhenxin Li",
      "Shiyi Lan",
      "Jose M. Alvarez",
      "Zuxuan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.05541",
    "title": "DPoser: Diffusion Model as Robust 3D Human Pose Prior",
    "abstract": " Comments: Project Page: this https URL; Code Released: this https URL ",
    "url": "https://arxiv.org/abs/2312.05541",
    "authors": [
      "Junzhe Lu",
      "Jing Lin",
      "Hongkun Dou",
      "Ailing Zeng",
      "Yue Deng",
      "Yulun Zhang",
      "Haoqian Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.05654",
    "title": "Spectral methods for Neural Integral Equations",
    "abstract": " Comments: 15 pages, 3 figures and 2 tables. v3: Missing hypotheses for the framework have been now added ",
    "url": "https://arxiv.org/abs/2312.05654",
    "authors": [
      "Emanuele Zappala"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2312.06203",
    "title": "Offloading and Quality Control for AI Generated Content Services in 6G  Mobile Edge Computing Networks",
    "abstract": " Comments: This paper appears in the 2024 IEEE 99th Vehicular Technology Conference (VTC) ",
    "url": "https://arxiv.org/abs/2312.06203",
    "authors": [
      "Yitong Wang",
      "Chang Liu",
      "Jun Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2312.09913",
    "title": "LAENeRF: Local Appearance Editing for Neural Radiance Fields",
    "abstract": " Comments: Accepted to CVPR 2024! Project website: this https URL ",
    "url": "https://arxiv.org/abs/2312.09913",
    "authors": [
      "Lukas Radl",
      "Michael Steiner",
      "Andreas Kurz",
      "Markus Steinberger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.11834",
    "title": "Multi-agent reinforcement learning using echo-state network and its  application to pedestrian dynamics",
    "abstract": " Comments: 26 pages, 17 figures ",
    "url": "https://arxiv.org/abs/2312.11834",
    "authors": [
      "Hisato Komatsu"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2401.02306",
    "title": "Secure Control of Connected and Automated Vehicles Using Trust-Aware  Robust Event-Triggered Control Barrier Functions",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2305.16818 ",
    "url": "https://arxiv.org/abs/2401.02306",
    "authors": [
      "H M Sabbir Ahmad",
      "Ehsan Sabouni",
      "Akua Dickson",
      "Wei Xiao",
      "Christos G. Cassandras",
      "Wenchao Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2401.15770",
    "title": "PILOT: Legal Case Outcome Prediction with Case Law",
    "abstract": " Title: PILOT: Legal Case Outcome Prediction with Case Law ",
    "url": "https://arxiv.org/abs/2401.15770",
    "authors": [
      "Lang Cao",
      "Zifeng Wang",
      "Cao Xiao",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.15911",
    "title": "Distribution-consistency Structural Causal Models",
    "abstract": " Title: Distribution-consistency Structural Causal Models ",
    "url": "https://arxiv.org/abs/2401.15911",
    "authors": [
      "Heyang Gong",
      "Chaochao Lu",
      "Yu Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2402.01295",
    "title": "ExtremeCast: Boosting Extreme Value Prediction for Global Weather  Forecast",
    "abstract": " Title: ExtremeCast: Boosting Extreme Value Prediction for Global Weather  Forecast ",
    "url": "https://arxiv.org/abs/2402.01295",
    "authors": [
      "Wanghan Xu",
      "Kang Chen",
      "Tao Han",
      "Hao Chen",
      "Wanli Ouyang",
      "Lei Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.02023",
    "title": "Self-Supervised Contrastive Learning for Long-term Forecasting",
    "abstract": " Comments: Accepted at International Conference on Learning Representations (ICLR) 2024 ",
    "url": "https://arxiv.org/abs/2402.02023",
    "authors": [
      "Junwoo Park",
      "Daehoon Gwak",
      "Jaegul Choo",
      "Edward Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.05305",
    "title": "Knowledge Distillation for Road Detection based on cross-model  Semi-Supervised Learning",
    "abstract": " Title: Knowledge Distillation for Road Detection based on cross-model  Semi-Supervised Learning ",
    "url": "https://arxiv.org/abs/2402.05305",
    "authors": [
      "Wanli Ma",
      "Oktay Karakus",
      "Paul L. Rosin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.05388",
    "title": "Form-From: A Design Space of Social Media Systems",
    "abstract": " Title: Form-From: A Design Space of Social Media Systems ",
    "url": "https://arxiv.org/abs/2402.05388",
    "authors": [
      "Amy X. Zhang",
      "Michael S. Bernstein",
      "David R. Karger",
      "Mark S. Ackerman"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.07310",
    "title": "BioNeRF: Biologically Plausible Neural Radiance Fields for View  Synthesis",
    "abstract": " Title: BioNeRF: Biologically Plausible Neural Radiance Fields for View  Synthesis ",
    "url": "https://arxiv.org/abs/2402.07310",
    "authors": [
      "Leandro A. Passos",
      "Douglas Rodrigues",
      "Danilo Jodas",
      "Kelton A. P. Costa",
      "Ahsan Adeel",
      "Jo\u00e3o Paulo Papa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.09132",
    "title": "Exploring the Adversarial Capabilities of Large Language Models",
    "abstract": " Title: Exploring the Adversarial Capabilities of Large Language Models ",
    "url": "https://arxiv.org/abs/2402.09132",
    "authors": [
      "Lukas Struppek",
      "Minh Hieu Le",
      "Dominik Hintersdorf",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.11922",
    "title": "Spatio-Temporal Few-Shot Learning via Diffusive Neural Network  Generation",
    "abstract": " Title: Spatio-Temporal Few-Shot Learning via Diffusive Neural Network  Generation ",
    "url": "https://arxiv.org/abs/2402.11922",
    "authors": [
      "Yuan Yuan",
      "Chenyang Shao",
      "Jingtao Ding",
      "Depeng Jin",
      "Yong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13845",
    "title": "Multi-Agent Online Graph Exploration on Cycles and Tadpole Graphs",
    "abstract": " Comments: v2: Update Related Work, more detailed description of models in Motivation ",
    "url": "https://arxiv.org/abs/2402.13845",
    "authors": [
      "Erik van den Akker",
      "Kevin Buchin",
      "Klaus-Tycho Foerster"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2402.16694",
    "title": "HumanEval-XL: A Multilingual Code Generation Benchmark for Cross-lingual  Natural Language Generalization",
    "abstract": " Comments: LREC-COLING 2024 ",
    "url": "https://arxiv.org/abs/2402.16694",
    "authors": [
      "Qiwei Peng",
      "Yekun Chai",
      "Xuhong Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.18107",
    "title": "Multimodal Interaction Modeling via Self-Supervised Multi-Task Learning  for Review Helpfulness Prediction",
    "abstract": " Comments: 10 pages,4 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2402.18107",
    "authors": [
      "HongLin Gong",
      "Mengzhao Jia",
      "Liqiang Jing"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2403.00046",
    "title": "SEED: Customize Large Language Models with Sample-Efficient Adaptation  for Code Generation",
    "abstract": " Title: SEED: Customize Large Language Models with Sample-Efficient Adaptation  for Code Generation ",
    "url": "https://arxiv.org/abs/2403.00046",
    "authors": [
      "Xue Jiang",
      "Yihong Dong",
      "Zhi Jin",
      "Ge Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.01479",
    "title": "Align-to-Distill: Trainable Attention Alignment for Knowledge  Distillation in Neural Machine Translation",
    "abstract": " Comments: Accepted to LREC-COLING 2024 ",
    "url": "https://arxiv.org/abs/2403.01479",
    "authors": [
      "Heegon Jin",
      "Seonil Son",
      "Jemin Park",
      "Youngseok Kim",
      "Hyungjong Noh",
      "Yeonsoo Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.02930",
    "title": "A Second Look on BASS -- Boosting Abstractive Summarization with Unified  Semantic Graphs -- A Replication Study",
    "abstract": " Comments: This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this contribution is published in Advances in Information Retrieval, 46th European Conference on Information Retrieval, ECIR 2024. 16 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2403.02930",
    "authors": [
      "Osman Alperen Kora\u015f",
      "J\u00f6rg Schl\u00f6tterer",
      "Christin Seifert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.03967",
    "title": "Effect of Ambient-Intrinsic Dimension Gap on Adversarial Vulnerability",
    "abstract": " Comments: AISTATS 2024 ",
    "url": "https://arxiv.org/abs/2403.03967",
    "authors": [
      "Rajdeep Haldar",
      "Yue Xing",
      "Qifan Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.04369",
    "title": "From Graph to Word Bag: Introducing Domain Knowledge to Confusing Charge  Prediction",
    "abstract": " Title: From Graph to Word Bag: Introducing Domain Knowledge to Confusing Charge  Prediction ",
    "url": "https://arxiv.org/abs/2403.04369",
    "authors": [
      "Ang Li",
      "Qiangchao Chen",
      "Yiquan Wu",
      "Ming Cai",
      "Xiang Zhou",
      "Fei Wu",
      "Kun Kuang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.04786",
    "title": "Breaking Down the Defenses: A Comparative Survey of Attacks on Large  Language Models",
    "abstract": " Title: Breaking Down the Defenses: A Comparative Survey of Attacks on Large  Language Models ",
    "url": "https://arxiv.org/abs/2403.04786",
    "authors": [
      "Arijit Ghosh Chowdhury",
      "Md Mofijul Islam",
      "Vaibhav Kumar",
      "Faysal Hossain Shezan",
      "Vaibhav Kumar",
      "Vinija Jain",
      "Aman Chadha"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.04810",
    "title": "Restricted Bayesian Neural Network",
    "abstract": " Title: Restricted Bayesian Neural Network ",
    "url": "https://arxiv.org/abs/2403.04810",
    "authors": [
      "Sourav Ganguly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2403.05030",
    "title": "Defending Against Unforeseen Failure Modes with Latent Adversarial  Training",
    "abstract": " Title: Defending Against Unforeseen Failure Modes with Latent Adversarial  Training ",
    "url": "https://arxiv.org/abs/2403.05030",
    "authors": [
      "Stephen Casper",
      "Lennart Schulze",
      "Oam Patel",
      "Dylan Hadfield-Menell"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.06606",
    "title": "Distributionally Generative Augmentation for Fair Facial Attribute  Classification",
    "abstract": " Comments: CVPR 2024 ",
    "url": "https://arxiv.org/abs/2403.06606",
    "authors": [
      "Fengda Zhang",
      "Qianpei He",
      "Kun Kuang",
      "Jiashuo Liu",
      "Long Chen",
      "Chao Wu",
      "Jun Xiao",
      "Hanwang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.07311",
    "title": "Knowledge Graph Large Language Model (KG-LLM) for Link Prediction",
    "abstract": " Comments: 23 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2403.07311",
    "authors": [
      "Dong Shu",
      "Tianle Chen",
      "Mingyu Jin",
      "Yiting Zhang",
      "Chong Zhang",
      "Mengnan Du",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.09506",
    "title": "Don't Judge by the Look: Towards Motion Coherent Video Representation",
    "abstract": " Comments: Accepted by ICLR2024 ",
    "url": "https://arxiv.org/abs/2403.09506",
    "authors": [
      "Yitian Zhang",
      "Yue Bai",
      "Huan Wang",
      "Yizhou Wang",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10119",
    "title": "URS-NeRF: Unordered Rolling Shutter Bundle Adjustment for Neural  Radiance Fields",
    "abstract": " Title: URS-NeRF: Unordered Rolling Shutter Bundle Adjustment for Neural  Radiance Fields ",
    "url": "https://arxiv.org/abs/2403.10119",
    "authors": [
      "Bo Xu",
      "Ziao Liu",
      "Mengqi Guo",
      "Jiancheng Li",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10855",
    "title": "Reinforcement Learning with Options and State Representation",
    "abstract": " Comments: Master Thesis 2018, MVA ENS Paris-Saclay, Tokyo RIKEN AIP ",
    "url": "https://arxiv.org/abs/2403.10855",
    "authors": [
      "Ayoub Ghriss",
      "Masashi Sugiyama",
      "Alessandro Lazaric"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.10963",
    "title": "Pointer-Generator Networks for Low-Resource Machine Translation: Don't  Copy That!",
    "abstract": " Comments: 4 pages ",
    "url": "https://arxiv.org/abs/2403.10963",
    "authors": [
      "Niyati Bafna",
      "Philipp Koehn",
      "David Yarowsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.11542",
    "title": "Topology Data Analysis-based Error Detection for Semantic Image  Transmission with Incremental Knowledge-based HARQ",
    "abstract": " Title: Topology Data Analysis-based Error Detection for Semantic Image  Transmission with Incremental Knowledge-based HARQ ",
    "url": "https://arxiv.org/abs/2403.11542",
    "authors": [
      "Fei Ni",
      "Rongpeng Li",
      "Zhifeng Zhao",
      "Honggang Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.11722",
    "title": "Time Series Compression using Quaternion Valued Neural Networks and  Quaternion Backpropagation",
    "abstract": " Title: Time Series Compression using Quaternion Valued Neural Networks and  Quaternion Backpropagation ",
    "url": "https://arxiv.org/abs/2403.11722",
    "authors": [
      "Johannes P\u00f6ppelbaum",
      "Andreas Schwung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.14253",
    "title": "K-Act2Emo: Korean Commonsense Knowledge Graph for Indirect Emotional  Expression",
    "abstract": " Comments: 10 pages ",
    "url": "https://arxiv.org/abs/2403.14253",
    "authors": [
      "Kyuhee Kim",
      "Surin Lee",
      "Sangah Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.15082",
    "title": "Cell Variational Information Bottleneck Network",
    "abstract": " Title: Cell Variational Information Bottleneck Network ",
    "url": "https://arxiv.org/abs/2403.15082",
    "authors": [
      "Zhonghua Zhai",
      "Chen Ju",
      "Jinsong Lan",
      "Shuai Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.15317",
    "title": "Point-DETR3D: Leveraging Imagery Data with Spatial Point Prior for  Weakly Semi-supervised 3D Object Detection",
    "abstract": " Comments: Accepted by AAAI2024 ",
    "url": "https://arxiv.org/abs/2403.15317",
    "authors": [
      "Hongzhi Gao",
      "Zheng Chen",
      "Zehui Chen",
      "Lin Chen",
      "Jiaming Liu",
      "Shanghang Zhang",
      "Feng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.15365",
    "title": "A Transfer Attack to Image Watermarks",
    "abstract": " Title: A Transfer Attack to Image Watermarks ",
    "url": "https://arxiv.org/abs/2403.15365",
    "authors": [
      "Yuepeng Hu",
      "Zhengyuan Jiang",
      "Moyang Guo",
      "Neil Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  }
]