[
  {
    "id": "arXiv:2504.01023",
    "title": "Omnidirectional Depth-Aided Occupancy Prediction based on Cylindrical Voxel for Autonomous Driving",
    "abstract": "           Accurate 3D perception is essential for autonomous driving. Traditional methods often struggle with geometric ambiguity due to a lack of geometric prior. To address these challenges, we use omnidirectional depth estimation to introduce geometric prior. Based on the depth information, we propose a Sketch-Coloring framework OmniDepth-Occ. Additionally, our approach introduces a cylindrical voxel representation based on polar coordinate to better align with the radial nature of panoramic camera views. To address the lack of fisheye camera dataset in autonomous driving tasks, we also build a virtual scene dataset with six fisheye cameras, and the data volume has reached twice that of SemanticKITTI. Experimental results demonstrate that our Sketch-Coloring network significantly enhances 3D perception performance.         ",
    "url": "https://arxiv.org/abs/2504.01023",
    "authors": [
      "Chaofan Wu",
      "Jiaheng Li",
      "Jinghao Cao",
      "Ming Li",
      "Yongkang Feng",
      "Jiayu Wu Shuwen Xu",
      "Zihang Gao",
      "Sidan Du",
      "Yang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2504.01024",
    "title": "Gaze-Guided 3D Hand Motion Prediction for Detecting Intent in Egocentric Grasping Tasks",
    "abstract": "           Human intention detection with hand motion prediction is critical to drive the upper-extremity assistive robots in neurorehabilitation applications. However, the traditional methods relying on physiological signal measurement are restrictive and often lack environmental context. We propose a novel approach that predicts future sequences of both hand poses and joint positions. This method integrates gaze information, historical hand motion sequences, and environmental object data, adapting dynamically to the assistive needs of the patient without prior knowledge of the intended object for grasping. Specifically, we use a vector-quantized variational autoencoder for robust hand pose encoding with an autoregressive generative transformer for effective hand motion sequence prediction. We demonstrate the usability of these novel techniques in a pilot study with healthy subjects. To train and evaluate the proposed method, we collect a dataset consisting of various types of grasp actions on different objects from multiple subjects. Through extensive experiments, we demonstrate that the proposed method can successfully predict sequential hand movement. Especially, the gaze information shows significant enhancements in prediction capabilities, particularly with fewer input frames, highlighting the potential of the proposed method for real-world applications.         ",
    "url": "https://arxiv.org/abs/2504.01024",
    "authors": [
      "Yufei He",
      "Xucong Zhang",
      "Arno H. A. Stienen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2504.01027",
    "title": "Mesh Compression with Quantized Neural Displacement Fields",
    "abstract": "           Implicit neural representations (INRs) have been successfully used to compress a variety of 3D surface representations such as Signed Distance Functions (SDFs), voxel grids, and also other forms of structured data such as images, videos, and audio. However, these methods have been limited in their application to unstructured data such as 3D meshes and point clouds. This work presents a simple yet effective method that extends the usage of INRs to compress 3D triangle meshes. Our method encodes a displacement field that refines the coarse version of the 3D mesh surface to be compressed using a small neural network. Once trained, the neural network weights occupy much lower memory than the displacement field or the original surface. We show that our method is capable of preserving intricate geometric textures and demonstrates state-of-the-art performance for compression ratios ranging from 4x to 380x.         ",
    "url": "https://arxiv.org/abs/2504.01027",
    "authors": [
      "Sai Karthikey Pentapati",
      "Gregoire Phillips",
      "Alan C. Bovik"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2504.01029",
    "title": "Who is Responsible When AI Fails? Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents",
    "abstract": "           The rapid growth of artificial intelligence (AI) technologies has changed decision-making in many fields. But, it has also raised major privacy and ethical concerns. However, many AI incidents taxonomies and guidelines for academia, industry, and government lack grounding in real-world incidents. We analyzed 202 real-world AI privacy and ethical incidents. This produced a taxonomy that classifies incident types across AI lifecycle stages. It accounts for contextual factors such as causes, responsible entities, disclosure sources, and impacts. Our findings show insufficient incident reporting from AI developers and users. Many incidents are caused by poor organizational decisions and legal non-compliance. Only a few legal actions and corrective measures exist, while risk-mitigation efforts are limited. Our taxonomy contributes a structured approach in reporting of future AI incidents. Our findings demonstrate that current AI governance frameworks are inadequate. We urgently need child-specific protections and AI policies on social media. They must moderate and reduce the spread of harmful AI-generated content. Our research provides insights for policymakers and practitioners, which lets them design ethical AI. It also support AI incident detection and risk management. Finally, it guides AI policy development. Improved policies will protect people from harmful AI applications and support innovation in AI systems.         ",
    "url": "https://arxiv.org/abs/2504.01029",
    "authors": [
      "Hilda Hadan",
      "Reza Hadi Mogavi",
      "Leah Zhang-Kennedy",
      "Lennart E. Nacke"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2504.01036",
    "title": "Carbon Footprint Evaluation of Code Generation through LLM as a Service",
    "abstract": "           Due to increased computing use, data centers consume and emit a lot of energy and carbon. These contributions are expected to rise as big data analytics, digitization, and large AI models grow and become major components of daily working routines. To reduce the environmental impact of software development, green (sustainable) coding and claims that AI models can improve energy efficiency have grown in popularity. Furthermore, in the automotive industry, where software increasingly governs vehicle performance, safety, and user experience, the principles of green coding and AI-driven efficiency could significantly contribute to reducing the sector's environmental footprint. We present an overview of green coding and metrics to measure AI model sustainability awareness. This study introduces LLM as a service and uses a generative commercial AI language model, GitHub Copilot, to auto-generate code. Using sustainability metrics to quantify these AI models' sustainability awareness, we define the code's embodied and operational carbon.         ",
    "url": "https://arxiv.org/abs/2504.01036",
    "authors": [
      "Tina Vartziotis",
      "Maximilian Schmidt",
      "George Dasoulas",
      "Ippolyti Dellatolas",
      "Stefano Attademo",
      "Viet Dung Le",
      "Anke Wiechmann",
      "Tim Hoffmann",
      "Michael Keckeisen",
      "Sotirios Kotsopoulos"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2504.01040",
    "title": "Cal or No Cal? -- Real-Time Miscalibration Detection of LiDAR and Camera Sensors",
    "abstract": "           The goal of extrinsic calibration is the alignment of sensor data to ensure an accurate representation of the surroundings and enable sensor fusion applications. From a safety perspective, sensor calibration is a key enabler of autonomous driving. In the current state of the art, a trend from target-based offline calibration towards targetless online calibration can be observed. However, online calibration is subject to strict real-time and resource constraints which are not met by state-of-the-art methods. This is mainly due to the high number of parameters to estimate, the reliance on geometric features, or the dependence on specific vehicle maneuvers. To meet these requirements and ensure the vehicle's safety at any time, we propose a miscalibration detection framework that shifts the focus from the direct regression of calibration parameters to a binary classification of the calibration state, i.e., calibrated or miscalibrated. Therefore, we propose a contrastive learning approach that compares embedded features in a latent space to classify the calibration state of two different sensor modalities. Moreover, we provide a comprehensive analysis of the feature embeddings and challenging calibration errors that highlight the performance of our approach. As a result, our method outperforms the current state-of-the-art in terms of detection performance, inference time, and resource demand. The code is open source and available on this https URL.         ",
    "url": "https://arxiv.org/abs/2504.01040",
    "authors": [
      "Ilir Tahiraj",
      "Jeremialie Swadiryus",
      "Felix Fent",
      "Markus Lienkamp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2504.01045",
    "title": "Machine Learning for Identifying Potential Participants in Uruguayan Social Programs",
    "abstract": "           This research project explores the optimization of the family selection process for participation in Uruguay's Crece Contigo Family Support Program (PAF) through machine learning. An anonymized database of 15,436 previous referral cases was analyzed, focusing on pregnant women and children under four years of age. The main objective was to develop a predictive algorithm capable of determining whether a family meets the conditions for acceptance into the program. The implementation of this model seeks to streamline the evaluation process and allow for more efficient resource allocation, allocating more team time to direct support. The study included an exhaustive data analysis and the implementation of various machine learning models, including Neural Networks (NN), XGBoost (XGB), LSTM, and ensemble models. Techniques to address class imbalance, such as SMOTE and RUS, were applied, as well as decision threshold optimization to improve prediction accuracy and balance. The results demonstrate the potential of these techniques for efficient classification of families requiring assistance.         ",
    "url": "https://arxiv.org/abs/2504.01045",
    "authors": [
      "Christian Beron Curti",
      "Rodrigo Vargas Sainz",
      "Yitong Tseo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01052",
    "title": "Analyzing homogenous and heterogeneous multi-server queues via neural networks",
    "abstract": "           In this paper, we use a machine learning approach to predict the stationary distributions of the number of customers in a single-staiton multi server system. We consider two systems, the first is $c$ homogeneous servers, namely the $GI/GI/c$ queue. The second is a two-heterogeneous server system, namely the $GI/GI_i/2$ queue. We train a neural network for these queueing models, using the first four inter-arrival and service time moments. We demonstrate empirically that using the fifth moment and beyond does not increase accuracy. Compared to existing methods, we show that in terms of the stationary distribution and the mean value of the number of customers in a $GI/GI/c$ queue, we are state-of-the-art. Further, we are the only ones to predict the stationary distribution of the number of customers in the system in a $GI/GI_i/2$ queue. We conduct a thorough performance evaluation to assert that our model is accurate. In most cases, we demonstrate that our error is less than 5\\%. Finally, we show that making inferences is very fast, where 5000 inferences can be made in parallel within a fraction of a second.         ",
    "url": "https://arxiv.org/abs/2504.01052",
    "authors": [
      "Eliran Sherzer"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2504.01081",
    "title": "ShieldGemma 2: Robust and Tractable Image Content Moderation",
    "abstract": "           We introduce ShieldGemma 2, a 4B parameter image content moderation model built on Gemma 3. This model provides robust safety risk predictions across the following key harm categories: Sexually Explicit, Violence \\& Gore, and Dangerous Content for synthetic images (e.g. output of any image generation model) and natural images (e.g. any image input to a Vision-Language Model). We evaluated on both internal and external benchmarks to demonstrate state-of-the-art performance compared to LlavaGuard \\citep{helff2024llavaguard}, GPT-4o mini \\citep{hurst2024gpt}, and the base Gemma 3 model \\citep{gemma_2025} based on our policies. Additionally, we present a novel adversarial data generation pipeline which enables a controlled, diverse, and robust image generation. ShieldGemma 2 provides an open image moderation tool to advance multimodal safety and responsible AI development.         ",
    "url": "https://arxiv.org/abs/2504.01081",
    "authors": [
      "Wenjun Zeng",
      "Dana Kurniawan",
      "Ryan Mullins",
      "Yuchi Liu",
      "Tamoghna Saha",
      "Dirichi Ike-Njoku",
      "Jindong Gu",
      "Yiwen Song",
      "Cai Xu",
      "Jingjing Zhou",
      "Aparna Joshi",
      "Shravan Dheep",
      "Mani Malek",
      "Hamid Palangi",
      "Joon Baek",
      "Rick Pereira",
      "Karthik Narasimhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2504.01091",
    "title": "Local Constant Approximation for Dominating Set on Graphs Excluding Large Minors",
    "abstract": "           We show that graphs excluding $K_{2,t}$ as a minor admit a $f(t)$-round $50$-approximation deterministic distributed algorithm for \\minDS. The result extends to \\minVC. Though fast and approximate distributed algorithms for such problems were already known for $H$-minor-free graphs, all of them have an approximation ratio depending on the size of $H$. To the best of our knowledge, this is the first example of a large non-trivial excluded minor leading to fast and constant-approximation distributed algorithms, where the ratio is independent of the size of $H$. A new key ingredient in the analysis of these distributed algorithms is the use of \\textit{asymptotic dimension}.         ",
    "url": "https://arxiv.org/abs/2504.01091",
    "authors": [
      "Marthe Bonamy",
      "Cyril Gavoille",
      "Timoth\u00e9 Picavet",
      "Alexandra Wesolek"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2504.01093",
    "title": "Hard-constraining Neumann boundary conditions in physics-informed neural networks via Fourier feature embeddings",
    "abstract": "           We present a novel approach to hard-constrain Neumann boundary conditions in physics-informed neural networks (PINNs) using Fourier feature embeddings. Neumann boundary conditions are used to described critical processes in various application, yet they are more challenging to hard-constrain in PINNs than Dirichlet conditions. Our method employs specific Fourier feature embeddings to directly incorporate Neumann boundary conditions into the neural network's architecture instead of learning them. The embedding can be naturally extended by high frequency modes to better capture high frequency phenomena. We demonstrate the efficacy of our approach through experiments on a diffusion problem, for which our method outperforms existing hard-constraining methods and classical PINNs, particularly in multiscale and high frequency scenarios.         ",
    "url": "https://arxiv.org/abs/2504.01093",
    "authors": [
      "Christopher Straub",
      "Philipp Brendel",
      "Vlad Medvedev",
      "Andreas Rosskopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2504.01097",
    "title": "Combining Extended Convolutional Autoencoders and Reservoir Computing for Accurate Reduced-Order Predictions of Atmospheric Flows",
    "abstract": "           Forecasting atmospheric flows with traditional discretization methods, also called full order methods (e.g., finite element methods or finite volume methods), is computationally expensive. We propose to reduce the computational cost with a Reduced Order Model (ROM) that combines Extended Convolutional Autoencoders (E-CAE) and Reservoir Computing (RC). Thanks to an extended network depth, the E-CAE encodes the high-resolution data coming from the full order method into a compact latent representation and can decode it back into high-resolution with 75% lower reconstruction error than standard CAEs. The compressed data are fed to an RC network, which predicts their evolution. The advantage of RC networks is a reduced computational cost in the training phase compared to conventional predictive models. We assess our data-driven ROM through well-known 2D and 3D benchmarks for atmospheric flows. We show that our ROM accurately reconstructs and predicts the future system dynamics with errors below 6% in 2D and 8% in 3D, while significantly reducing the computational cost of a full-order simulation. Compared to other ROMs available in the literature, such as Dynamic Mode Decomposition and Proper Orthogonal Decomposition with Interpolation, our ROM is as efficient but more accurate. Thus, it is a promising alternative to high-dimensional atmospheric simulations.         ",
    "url": "https://arxiv.org/abs/2504.01097",
    "authors": [
      "Arash Hajisharifi",
      "Michele Girfoglio",
      "Annalisa Quaini",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2504.01135",
    "title": "Performative Drift Resistant Classification Using Generative Domain Adversarial Networks",
    "abstract": "           Performative Drift is a special type of Concept Drift that occurs when a model's predictions influence the future instances the model will encounter. In these settings, retraining is not always feasible. In this work, we instead focus on drift understanding as a method for creating drift-resistant classifiers. To achieve this, we introduce the Generative Domain Adversarial Network (GDAN) which combines both Domain and Generative Adversarial Networks. Using GDAN, domain-invariant representations of incoming data are created and a generative network is used to reverse the effects of performative drift. Using semi-real and synthetic data generators, we empirically evaluate GDAN's ability to provide drift-resistant classification. Initial results are promising with GDAN limiting performance degradation over several timesteps. Additionally, GDAN's generative network can be used in tandem with other models to limit their performance degradation in the presence of performative drift. Lastly, we highlight the relationship between model retraining and the unpredictability of performative drift, providing deeper insights into the challenges faced when using traditional Concept Drift mitigation strategies in the performative setting.         ",
    "url": "https://arxiv.org/abs/2504.01135",
    "authors": [
      "Maciej Makowski",
      "Brandon Gower-Winter",
      "Georg Krempl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01153",
    "title": "Catch Me if You Search: When Contextual Web Search Results Affect the Detection of Hallucinations",
    "abstract": "           While we increasingly rely on large language models (LLMs) for various tasks, these models are known to produce inaccurate content or 'hallucinations' with potentially disastrous consequences. The recent integration of web search results into LLMs prompts the question of whether people utilize them to verify the generated content, thereby avoiding falling victim to hallucinations. This study (N = 560) investigated how the provision of search results, either static (fixed search results) or dynamic (participant-driven searches), affect participants' perceived accuracy and confidence in evaluating LLM-generated content (i.e., genuine, minor hallucination, major hallucination), compared to the control condition (no search results). Findings indicate that participants in both static and dynamic conditions (vs. control) rated hallucinated content to be less accurate. However, those in the dynamic condition rated genuine content as more accurate and demonstrated greater overall confidence in their assessments than those in the static or control conditions. In addition, those higher in need for cognition (NFC) rated major hallucinations to be less accurate than low NFC participants, with no corresponding difference for genuine content or minor hallucinations. These results underscore the potential benefits of integrating web search results into LLMs for the detection of hallucinations, as well as the need for a more nuanced approach when developing human-centered systems, taking user characteristics into account.         ",
    "url": "https://arxiv.org/abs/2504.01153",
    "authors": [
      "Mahjabin Nahar",
      "Eun-Ju Lee",
      "Jin Won Park",
      "Dongwon Lee"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01169",
    "title": "Efficient n-body simulations using physics informed graph neural networks",
    "abstract": "           This paper presents a novel approach for accelerating n-body simulations by integrating a physics-informed graph neural networks (GNN) with traditional numerical methods. Our method implements a leapfrog-based simulation engine to generate datasets from diverse astrophysical scenarios which are then transformed into graph representations. A custom-designed GNN is trained to predict particle accelerations with high precision. Experiments, conducted on 60 training and 6 testing simulations spanning from 3 to 500 bodies over 1000 time steps, demonstrate that the proposed model achieves extremely low prediction errors-loss values while maintaining robust long-term stability, with accumulated errors in position, velocity, and acceleration remaining insignificant. Furthermore, our method yields a modest speedup of approximately 17% over conventional simulation techniques. These results indicate that the integration of deep learning with traditional physical simulation methods offers a promising pathway to significantly enhance computational efficiency without compromising accuracy.         ",
    "url": "https://arxiv.org/abs/2504.01169",
    "authors": [
      "V\u00edctor Ramos-Osuna",
      "Alberto D\u00edaz-\u00c1lvarez",
      "Ra\u00fal Lara-Cabrera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2504.01173",
    "title": "Neural Approaches to SAT Solving: Design Choices and Interpretability",
    "abstract": "           In this contribution, we provide a comprehensive evaluation of graph neural networks applied to Boolean satisfiability problems, accompanied by an intuitive explanation of the mechanisms enabling the model to generalize to different instances. We introduce several training improvements, particularly a novel closest assignment supervision method that dynamically adapts to the model's current state, significantly enhancing performance on problems with larger solution spaces. Our experiments demonstrate the suitability of variable-clause graph representations with recurrent neural network updates, which achieve good accuracy on SAT assignment prediction while reducing computational demands. We extend the base graph neural network into a diffusion model that facilitates incremental sampling and can be effectively combined with classical techniques like unit propagation. Through analysis of embedding space patterns and optimization trajectories, we show how these networks implicitly perform a process very similar to continuous relaxations of MaxSAT, offering an interpretable view of their reasoning process. This understanding guides our design choices and explains the ability of recurrent architectures to scale effectively at inference time beyond their training distribution, which we demonstrate with test-time scaling experiments.         ",
    "url": "https://arxiv.org/abs/2504.01173",
    "authors": [
      "David Moj\u017e\u00ed\u0161ek",
      "Jan H\u016fla",
      "Ziwei Li",
      "Ziyu Zhou",
      "Mikol\u00e1\u0161 Janota"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2504.01213",
    "title": "GRU-AUNet: A Domain Adaptation Framework for Contactless Fingerprint Presentation Attack Detection",
    "abstract": "           Although contactless fingerprints offer user comfort, they are more vulnerable to spoofing. The current solution for anti-spoofing in the area of contactless fingerprints relies on domain adaptation learning, limiting their generalization and scalability. To address these limitations, we introduce GRU-AUNet, a domain adaptation approach that integrates a Swin Transformer-based UNet architecture with GRU-enhanced attention mechanisms, a Dynamic Filter Network in the bottleneck, and a combined Focal and Contrastive Loss function. Trained in both genuine and spoof fingerprint images, GRU-AUNet demonstrates robust resilience against presentation attacks, achieving an average BPCER of 0.09\\% and APCER of 1.2\\% in the CLARKSON, COLFISPOOF, and IIITD datasets, outperforming state-of-the-art domain adaptation methods.         ",
    "url": "https://arxiv.org/abs/2504.01213",
    "authors": [
      "Banafsheh Adami",
      "Nima Karimian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2504.01214",
    "title": "PolygoNet: Leveraging Simplified Polygonal Representation for Effective Image Classification",
    "abstract": "           Deep learning models have achieved significant success in various image related tasks. However, they often encounter challenges related to computational complexity and overfitting. In this paper, we propose an efficient approach that leverages polygonal representations of images using dominant points or contour coordinates. By transforming input images into these compact forms, our method significantly reduces computational requirements, accelerates training, and conserves resources making it suitable for real time and resource constrained applications. These representations inherently capture essential image features while filtering noise, providing a natural regularization effect that mitigates overfitting. The resulting lightweight models achieve performance comparable to state of the art methods using full resolution images while enabling deployment on edge devices. Extensive experiments on benchmark datasets validate the effectiveness of our approach in reducing complexity, improving generalization, and facilitating edge computing applications. This work demonstrates the potential of polygonal representations in advancing efficient and scalable deep learning solutions for real world scenarios. The code for the experiments of the paper is provided in this https URL.         ",
    "url": "https://arxiv.org/abs/2504.01214",
    "authors": [
      "Salim Khazem",
      "Jeremy Fix",
      "C\u00e9dric Pradalier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01220",
    "title": "rPPG-SysDiaGAN: Systolic-Diastolic Feature Localization in rPPG Using Generative Adversarial Network with Multi-Domain Discriminator",
    "abstract": "           Remote photoplethysmography (rPPG) offers a novel approach to noninvasive monitoring of vital signs, such as respiratory rate, utilizing a camera. Although several supervised and self-supervised methods have been proposed, they often fail to accurately reconstruct the PPG signal, particularly in distinguishing between systolic and diastolic components. Their primary focus tends to be solely on extracting heart rate, which may not accurately represent the complete PPG signal. To address this limitation, this paper proposes a novel deep learning architecture using Generative Adversarial Networks by introducing multi-discriminators to extract rPPG signals from facial videos. These discriminators focus on the time domain, the frequency domain, and the second derivative of the original time domain signal. The discriminator integrates four loss functions: variance loss to mitigate local minima caused by noise; dynamic time warping loss to address local minima induced by alignment and sequences of variable lengths; Sparsity Loss for heart rate adjustment, and Variance Loss to ensure a uniform distribution across the desired frequency domain and time interval between systolic and diastolic phases of the PPG signal.         ",
    "url": "https://arxiv.org/abs/2504.01220",
    "authors": [
      "Banafsheh Adami",
      "Nima Karimian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2504.01228",
    "title": "TenAd: A Tensor-based Low-rank Black Box Adversarial Attack for Video Classification",
    "abstract": "           Deep learning models have achieved remarkable success in computer vision but remain vulnerable to adversarial attacks, particularly in black-box settings where model details are unknown. Existing adversarial attack methods(even those works with key frames) often treat video data as simple vectors, ignoring their inherent multi-dimensional structure, and require a large number of queries, making them inefficient and detectable. In this paper, we propose \\textbf{TenAd}, a novel tensor-based low-rank adversarial attack that leverages the multi-dimensional properties of video data by representing videos as fourth-order tensors. By exploiting low-rank attack, our method significantly reduces the search space and the number of queries needed to generate adversarial examples in black-box settings. Experimental results on standard video classification datasets demonstrate that \\textbf{TenAd} effectively generates imperceptible adversarial perturbations while achieving higher attack success rates and query efficiency compared to state-of-the-art methods. Our approach outperforms existing black-box adversarial attacks in terms of success rate, query efficiency, and perturbation imperceptibility, highlighting the potential of tensor-based methods for adversarial attacks on video models.         ",
    "url": "https://arxiv.org/abs/2504.01228",
    "authors": [
      "Kimia haghjooei",
      "Mansoor Rezghi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2504.01230",
    "title": "Highway to Hull: An Algorithm for Solving the General Matrix Code Equivalence Problem",
    "abstract": "           The matrix code equivalence problem consists, given two matrix spaces $\\mathcal{C},\\mathcal{D}\\subset \\mathbb{F}_q^{m\\times n}$ of dimension $k$, in finding invertible matrices $P\\in\\mathrm{GL}_m(\\mathbb{F}_q)$ and $Q\\in\\mathrm{GL}_n(\\mathbb{F}_q)$ such that $\\mathcal{D}=P\\mathcal{C} Q^{-1}$. Recent signature schemes such as MEDS and ALTEQ relate their security to the hardness of this problem. Naranayan et. al. recently published an algorithm solving this problem in the case $k = n =m$ in $\\widetilde{O}(q^{\\frac k 2})$ operations. We present a different algorithm which solves the problem in the general case. Our approach consists in reducing the problem to the matrix code conjugacy problem, i.e. the case $P=Q$. For the latter problem, similarly to the permutation code equivalence problem in Hamming metric, a natural invariant based on the Hull of the code can be used. Next, the equivalence of codes can be deduced using a usual list collision argument. For $k=m=n$, our algorithm achieves the same complexity as in the aforementioned reference. However, it extends to a much broader range of parameters.         ",
    "url": "https://arxiv.org/abs/2504.01230",
    "authors": [
      "Alain Couvreur",
      "Christophe Levrat"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2504.01234",
    "title": "First Field-Trial Demonstration of L4 Autonomous Optical Network for Distributed AI Training Communication: An LLM-Powered Multi-AI-Agent Solution",
    "abstract": "           We demonstrate the first cross-domain cross-layer level-4 autonomous optical network via a multi-AI-agent system. Field trials show 98 percent task completion rate across the distributed AI training lifecycle-3.2x higher than single agents using state-of-the-art LLMs.         ",
    "url": "https://arxiv.org/abs/2504.01234",
    "authors": [
      "Yihao Zhang",
      "Qizhi Qiu",
      "Xiaomin Liu",
      "Dianxuan Fu",
      "Xingyu Liu",
      "Leyan Fei",
      "Yuming Cheng",
      "Lilin Yi",
      "Weisheng Hu",
      "Qunbi Zhuge"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2504.01242",
    "title": "An Agent-based Model Simulation Approach to Demonstrate Effects of Aging Population and Social Service Policies on Pensions Fund and Its Long-term Socio-economic Consequences",
    "abstract": "           Agent-based modeling (ABM) has emerged as a powerful tool in social policy-making and socio-economics, offering a flexible and dynamic approach to understanding and simulating complex systems. While traditional analytic methods may be less effective in unpredictable situations, ABM can provide valuable support for policy-making by generating large ensembles of scenarios and evaluating adaptive policies. This approach has been applied in various fields, including economics, management, sociology, and politics, and has the potential to deepen our understanding of economic policy in the cooperative sector.         ",
    "url": "https://arxiv.org/abs/2504.01242",
    "authors": [
      "Shayan Firouzian Haji"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2504.01246",
    "title": "Dynamic Graph Structure Estimation for Learning Multivariate Point Process using Spiking Neural Networks",
    "abstract": "           Modeling and predicting temporal point processes (TPPs) is critical in domains such as neuroscience, epidemiology, finance, and social sciences. We introduce the Spiking Dynamic Graph Network (SDGN), a novel framework that leverages the temporal processing capabilities of spiking neural networks (SNNs) and spike-timing-dependent plasticity (STDP) to dynamically estimate underlying spatio-temporal functional graphs. Unlike existing methods that rely on predefined or static graph structures, SDGN adapts to any dataset by learning dynamic spatio-temporal dependencies directly from the event data, enhancing generalizability and robustness. While SDGN offers significant improvements over prior methods, we acknowledge its limitations in handling dense graphs and certain non-Gaussian dependencies, providing opportunities for future refinement. Our evaluations, conducted on both synthetic and real-world datasets including NYC Taxi, 911, Reddit, and Stack Overflow, demonstrate that SDGN achieves superior predictive accuracy while maintaining computational efficiency. Furthermore, we include ablation studies to highlight the contributions of its core components.         ",
    "url": "https://arxiv.org/abs/2504.01246",
    "authors": [
      "Biswadeep Chakraborty",
      "Hemant Kumawat",
      "Beomseok Kang",
      "Saibal Mukhopadhyay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2504.01250",
    "title": "R2DN: Scalable Parameterization of Contracting and Lipschitz Recurrent Deep Networks",
    "abstract": "           This paper presents the Robust Recurrent Deep Network (R2DN), a scalable parameterization of robust recurrent neural networks for machine learning and data-driven control. We construct R2DNs as a feedback interconnection of a linear time-invariant system and a 1-Lipschitz deep feedforward network, and directly parameterize the weights so that our models are stable (contracting) and robust to small input perturbations (Lipschitz) by design. Our parameterization uses a structure similar to the previously-proposed recurrent equilibrium networks (RENs), but without the requirement to iteratively solve an equilibrium layer at each time-step. This speeds up model evaluation and backpropagation on GPUs, and makes it computationally feasible to scale up the network size, batch size, and input sequence length in comparison to RENs. We compare R2DNs to RENs on three representative problems in nonlinear system identification, observer design, and learning-based feedback control and find that training and inference are both up to an order of magnitude faster with similar test set performance, and that training/inference times scale more favorably with respect to model expressivity.         ",
    "url": "https://arxiv.org/abs/2504.01250",
    "authors": [
      "Nicholas H. Barbara",
      "Ruigang Wang",
      "Ian R. Manchester"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2504.01260",
    "title": "The Social Life of Industrial Arms: How Arousal and Attention Shape Human-Robot Interaction",
    "abstract": "           This study explores how human perceptions of a non-anthropomorphic robotic manipulator are shaped by two key dimensions of behaviour: arousal, defined as the robot's movement energy and expressiveness, and attention, defined as the robot's capacity to selectively orient toward and engage with a user. We introduce a novel control architecture that integrates a gaze-like attention engine with an arousal-modulated motion system to generate socially meaningful behaviours. In a user study, we find that robots exhibiting high attention -- actively directing their focus toward users -- are perceived as warmer and more competent, intentional, and lifelike. In contrast, high arousal -- characterized by fast, expansive, and energetic motions -- increases perceptions of discomfort and disturbance. Importantly, a combination of focused attention and moderate arousal yields the highest ratings of trust and sociability, while excessive arousal diminishes social engagement. These findings offer design insights for endowing non-humanoid robots with expressive, intuitive behaviours that support more natural human-robot interaction.         ",
    "url": "https://arxiv.org/abs/2504.01260",
    "authors": [
      "Roy El-Helou",
      "Matthew K.X.J Pan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2504.01298",
    "title": "Direction-Aware Hybrid Representation Learning for 3D Hand Pose and Shape Estimation",
    "abstract": "           Most model-based 3D hand pose and shape estimation methods directly regress the parametric model parameters from an image to obtain 3D joints under weak supervision. However, these methods involve solving a complex optimization problem with many local minima, making training difficult. To address this challenge, we propose learning direction-aware hybrid features (DaHyF) that fuse implicit image features and explicit 2D joint coordinate features. This fusion is enhanced by the pixel direction information in the camera coordinate system to estimate pose, shape, and camera viewpoint. Our method directly predicts 3D hand poses with DaHyF representation and reduces jittering during motion capture using prediction confidence based on contrastive learning. We evaluate our method on the FreiHAND dataset and show that it outperforms existing state-of-the-art methods by more than 33% in accuracy. DaHyF also achieves the top ranking on both the HO3Dv2 and HO3Dv3 leaderboards for the metric of Mean Joint Error (after scale and translation alignment). Compared to the second-best results, the largest improvement observed is 10%. We also demonstrate its effectiveness in real-time motion capture scenarios with hand position variability, occlusion, and motion blur.         ",
    "url": "https://arxiv.org/abs/2504.01298",
    "authors": [
      "Shiyong Liu",
      "Zhihao Li",
      "Xiao Tang",
      "Jianzhuang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2504.01308",
    "title": "Safeguarding Vision-Language Models: Mitigating Vulnerabilities to Gaussian Noise in Perturbation-based Attacks",
    "abstract": "           Vision-Language Models (VLMs) extend the capabilities of Large Language Models (LLMs) by incorporating visual information, yet they remain vulnerable to jailbreak attacks, especially when processing noisy or corrupted images. Although existing VLMs adopt security measures during training to mitigate such attacks, vulnerabilities associated with noise-augmented visual inputs are overlooked. In this work, we identify that missing noise-augmented training causes critical security gaps: many VLMs are susceptible to even simple perturbations such as Gaussian noise. To address this challenge, we propose Robust-VLGuard, a multimodal safety dataset with aligned / misaligned image-text pairs, combined with noise-augmented fine-tuning that reduces attack success rates while preserving functionality of VLM. For stronger optimization-based visual perturbation attacks, we propose DiffPure-VLM, leveraging diffusion models to convert adversarial perturbations into Gaussian-like noise, which can be defended by VLMs with noise-augmented safety fine-tuning. Experimental results demonstrate that the distribution-shifting property of diffusion model aligns well with our fine-tuned VLMs, significantly mitigating adversarial perturbations across varying intensities. The dataset and code are available at this https URL.         ",
    "url": "https://arxiv.org/abs/2504.01308",
    "authors": [
      "Jiawei Wang",
      "Yushen Zuo",
      "Yuanjun Chai",
      "Zhendong Liu",
      "Yichen Fu",
      "Yichun Feng",
      "Kin-man Lam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2504.01309",
    "title": "Biomedical Question Answering via Multi-Level Summarization on a Local Knowledge Graph",
    "abstract": "           In Question Answering (QA), Retrieval Augmented Generation (RAG) has revolutionized performance in various domains. However, how to effectively capture multi-document relationships, particularly critical for biomedical tasks, remains an open question. In this work, we propose a novel method that utilizes propositional claims to construct a local knowledge graph from retrieved documents. Summaries are then derived via layerwise summarization from the knowledge graph to contextualize a small language model to perform QA. We achieved comparable or superior performance with our method over RAG baselines on several biomedical QA benchmarks. We also evaluated each individual step of our methodology over a targeted set of metrics, demonstrating its effectiveness.         ",
    "url": "https://arxiv.org/abs/2504.01309",
    "authors": [
      "Lingxiao Guan",
      "Yuanhao Huang",
      "Jie Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2504.01326",
    "title": "CFMD: Dynamic Cross-layer Feature Fusion for Salient Object Detection",
    "abstract": "           Cross-layer feature pyramid networks (CFPNs) have achieved notable progress in multi-scale feature fusion and boundary detail preservation for salient object detection. However, traditional CFPNs still suffer from two core limitations: (1) a computational bottleneck caused by complex feature weighting operations, and (2) degraded boundary accuracy due to feature blurring in the upsampling process. To address these challenges, we propose CFMD, a novel cross-layer feature pyramid network that introduces two key innovations. First, we design a context-aware feature aggregation module (CFLMA), which incorporates the state-of-the-art Mamba architecture to construct a dynamic weight distribution mechanism. This module adaptively adjusts feature importance based on image context, significantly improving both representation efficiency and generalization. Second, we introduce an adaptive dynamic upsampling unit (CFLMD) that preserves spatial details during resolution recovery. By adjusting the upsampling range dynamically and initializing with a bilinear strategy, the module effectively reduces feature overlap and maintains fine-grained boundary structures. Extensive experiments on three standard benchmarks using three mainstream backbone networks demonstrate that CFMD achieves substantial improvements in pixel-level accuracy and boundary segmentation quality, especially in complex scenes. The results validate the effectiveness of CFMD in jointly enhancing computational efficiency and segmentation performance, highlighting its strong potential in salient object detection tasks.         ",
    "url": "https://arxiv.org/abs/2504.01326",
    "authors": [
      "Jin Lian",
      "Zhongyu Wan",
      "Ming Gao",
      "JunFeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2504.01329",
    "title": "Flexible and Explainable Graph Analysis for EEG-based Alzheimer's Disease Classification",
    "abstract": "           Alzheimer's Disease is a progressive neurological disorder that is one of the most common forms of dementia. It leads to a decline in memory, reasoning ability, and behavior, especially in older people. The cause of Alzheimer's Disease is still under exploration and there is no all-inclusive theory that can explain the pathologies in each individual patient. Nevertheless, early intervention has been found to be effective in managing symptoms and slowing down the disease's progression. Recent research has utilized electroencephalography (EEG) data to identify biomarkers that distinguish Alzheimer's Disease patients from healthy individuals. Prior studies have used various machine learning methods, including deep learning and graph neural networks, to examine electroencephalography-based signals for identifying Alzheimer's Disease patients. In our research, we proposed a Flexible and Explainable Gated Graph Convolutional Network (GGCN) with Multi-Objective Tree-Structured Parzen Estimator (MOTPE) hyperparameter tuning. This provides a flexible solution that efficiently identifies the optimal number of GGCN blocks to achieve the optimized precision, specificity, and recall outcomes, as well as the optimized area under the Receiver Operating Characteristic (AUC). Our findings demonstrated a high efficacy with an over 0.9 Receiver Operating Characteristic score, alongside precision, specificity, and recall scores in distinguishing health control with Alzheimer's Disease patients in Moderate to Severe Dementia using the power spectrum density (PSD) of electroencephalography signals across various frequency bands. Moreover, our research enhanced the interpretability of the embedded adjacency matrices, revealing connectivity differences in frontal and parietal brain regions between Alzheimer's patients and healthy individuals.         ",
    "url": "https://arxiv.org/abs/2504.01329",
    "authors": [
      "Jing Wang",
      "Jun-En Ding",
      "Feng Liu",
      "Elisa Kallioniemi",
      "Shuqiang Wang",
      "Wen-Xiang Tsai",
      "Albert C. Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2504.01339",
    "title": "Computing Time-varying Network Reliability using Binary Decision Diagrams",
    "abstract": "           Computing the reliability of a time-varying network, taking into account its dynamic nature, is crucial for networks that change over time, such as space networks, vehicular ad-hoc networks, and drone networks. These networks are modeled using temporal graphs, in which each edge is labeled with a time indicating its existence at a specific point in time. The time-varying network reliability is defined as the probability that a data packet from the source vertex can reach the terminal vertex, following links with increasing time labels (i.e., a journey), while taking into account the possibility of network link failures. Currently, the existing method for calculating this reliability involves explicitly enumerating all possible journeys between the source and terminal vertices and then calculating the reliability using the sum of disjoint products method. However, this method has high computational complexity. In contrast, there is an efficient algorithm that uses binary decision diagrams (BDDs) to evaluate the reliability of a network whose topology does not change over time. This paper presents an efficient exact algorithm that utilizes BDDs for computing the time-varying network reliability. Experimental results show that the proposed method runs faster than the existing method up to four orders of magnitude.         ",
    "url": "https://arxiv.org/abs/2504.01339",
    "authors": [
      "Yu Nakahata",
      "Shun Arizono",
      "Shoji Kasahara"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2504.01345",
    "title": "Breaking BERT: Gradient Attack on Twitter Sentiment Analysis for Targeted Misclassification",
    "abstract": "           Social media platforms like Twitter have increasingly relied on Natural Language Processing NLP techniques to analyze and understand the sentiments expressed in the user generated content. One such state of the art NLP model is Bidirectional Encoder Representations from Transformers BERT which has been widely adapted in sentiment analysis. BERT is susceptible to adversarial attacks. This paper aims to scrutinize the inherent vulnerabilities of such models in Twitter sentiment analysis. It aims to formulate a framework for constructing targeted adversarial texts capable of deceiving these models, while maintaining stealth. In contrast to conventional methodologies, such as Importance Reweighting, this framework core idea resides in its reliance on gradients to prioritize the importance of individual words within the text. It uses a whitebox approach to attain fine grained sensitivity, pinpointing words that exert maximal influence on the classification outcome. This paper is organized into three interdependent phases. It starts with fine-tuning a pre-trained BERT model on Twitter data. It then analyzes gradients of the model to rank words on their importance, and iteratively replaces those with feasible candidates until an acceptable solution is found. Finally, it evaluates the effectiveness of the adversarial text against the custom trained sentiment classification model. This assessment would help in gauging the capacity of the adversarial text to successfully subvert classification without raising any alarm.         ",
    "url": "https://arxiv.org/abs/2504.01345",
    "authors": [
      "Akil Raj Subedi",
      "Taniya Shah",
      "Aswani Kumar Cherukuri",
      "Thanos Vasilakos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01347",
    "title": "MEEK: Re-thinking Heterogeneous Parallel Error Detection Architecture for Real-World OoO Superscalar Processors",
    "abstract": "           Heterogeneous parallel error detection is an approach to achieving fault-tolerant processors, leveraging multiple power-efficient cores to re-execute software originally run on a high-performance core. Yet, its complex components, gathering data cross-chip from many parts of the core, raise questions of how to build it into commodity cores without heavy design invasion and extensive re-engineering. We build the first full-RTL design, MEEK, into an open-source SoC, from microarchitecture and ISA to the OS and programming model. We identify and solve bottlenecks and bugs overlooked in previous work, and demonstrate that MEEK offers microsecond-level detection capacity with affordable overheads. By trading off architectural functionalities across codesigned hardware-software layers, MEEK features only light changes to a mature out-of-order superscalar core, simple coordinating software layers, and a few lines of operating-system code. The Repo. of MEEK's source code: this https URL.         ",
    "url": "https://arxiv.org/abs/2504.01347",
    "authors": [
      "Zhe Jiang",
      "Minli Liao",
      "Sam Ainsworth",
      "Dean You",
      "Timothy Jones"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2504.01354",
    "title": "Dichotomies for \\#CSP on graphs that forbid a clique as a minor",
    "abstract": "           We prove complexity dichotomies for \\#CSP problems (not necessarily symmetric) with Boolean domain and complex range on several typical minor-closed graph classes. These dichotomies give a complete characterization of the complexity of \\#CSP on graph classes that forbid a complete graph as a minor. In particular, we also demonstrate that, whether the maximum degree of vertices is bounded may influence the complexity on specific minor-closed graph classes, and this phenomenon has never been observed in the previous related studies. Furthermore, our proofs integrate the properties of each graph class with the techniques from counting complexity, and develop a systematic approach for analyzing the complexity of \\#CSP on these graph classes.         ",
    "url": "https://arxiv.org/abs/2504.01354",
    "authors": [
      "Boning Meng",
      "Yicheng Pan"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2504.01396",
    "title": "All Patches Matter, More Patches Better: Enhance AI-Generated Image Detection via Panoptic Patch Learning",
    "abstract": "           The exponential growth of AI-generated images (AIGIs) underscores the urgent need for robust and generalizable detection methods. In this paper, we establish two key principles for AIGI detection through systematic analysis: \\textbf{(1) All Patches Matter:} Unlike conventional image classification where discriminative features concentrate on object-centric regions, each patch in AIGIs inherently contains synthetic artifacts due to the uniform generation process, suggesting that every patch serves as an important artifact source for detection. \\textbf{(2) More Patches Better}: Leveraging distributed artifacts across more patches improves detection robustness by capturing complementary forensic evidence and reducing over-reliance on specific patches, thereby enhancing robustness and generalization. However, our counterfactual analysis reveals an undesirable phenomenon: naively trained detectors often exhibit a \\textbf{Few-Patch Bias}, discriminating between real and synthetic images based on minority patches. We identify \\textbf{Lazy Learner} as the root cause: detectors preferentially learn conspicuous artifacts in limited patches while neglecting broader artifact distributions. To address this bias, we propose the \\textbf{P}anoptic \\textbf{P}atch \\textbf{L}earning (PPL) framework, involving: (1) Random Patch Replacement that randomly substitutes synthetic patches with real counterparts to compel models to identify artifacts in underutilized regions, encouraging the broader use of more patches; (2) Patch-wise Contrastive Learning that enforces consistent discriminative capability across all patches, ensuring uniform utilization of all patches. Extensive experiments across two different settings on several benchmarks verify the effectiveness of our approach.         ",
    "url": "https://arxiv.org/abs/2504.01396",
    "authors": [
      "Zheng Yang",
      "Ruoxin Chen",
      "Zhiyuan Yan",
      "Ke-Yue Zhang",
      "Xinghe Fu",
      "Shuang Wu",
      "Xiujun Shu",
      "Taiping Yao",
      "Junchi Yan",
      "Shouhong Ding",
      "Xi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2504.01398",
    "title": "Cause or Trigger? From Philosophy to Causal Modeling",
    "abstract": "           Not much has been written about the role of triggers in the literature on causal reasoning, causal modeling, or philosophy. In this paper, we focus on describing triggers and causes in the metaphysical sense and on characterizations that differentiate them from each other. We carry out a philosophical analysis of these differences. From this, we formulate a definition that clearly differentiates triggers from causes and can be used for causal reasoning in natural sciences. We propose a mathematical model and the Cause-Trigger algorithm, which, based on given data to observable processes, is able to determine whether a process is a cause or a trigger of an effect. The possibility to distinguish triggers from causes directly from data makes the algorithm a useful tool in natural sciences using observational data, but also for real-world scenarios. For example, knowing the processes that trigger causes of a tropical storm could give politicians time to develop actions such as evacuation the population. Similarly, knowing the triggers of processes that cause global warming could help politicians focus on effective actions. We demonstrate our algorithm on the climatological data of two recent cyclones, Freddy and Zazu. The Cause-Trigger algorithm detects processes that trigger high wind speed in both storms during their cyclogenesis. The findings obtained agree with expert knowledge.         ",
    "url": "https://arxiv.org/abs/2504.01398",
    "authors": [
      "Kate\u0159ina Hlav\u00e1\u010dkov\u00e1-Schindler",
      "Rainer W\u00f6\u00df",
      "Vera Pecorino",
      "Philip Schindler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2504.01399",
    "title": "Leveraging Generalizability of Image-to-Image Translation for Enhanced Adversarial Defense",
    "abstract": "           In the rapidly evolving field of artificial intelligence, machine learning emerges as a key technology characterized by its vast potential and inherent risks. The stability and reliability of these models are important, as they are frequent targets of security threats. Adversarial attacks, first rigorously defined by Ian Goodfellow et al. in 2013, highlight a critical vulnerability: they can trick machine learning models into making incorrect predictions by applying nearly invisible perturbations to images. Although many studies have focused on constructing sophisticated defensive mechanisms to mitigate such attacks, they often overlook the substantial time and computational costs of training and maintaining these models. Ideally, a defense method should be able to generalize across various, even unseen, adversarial attacks with minimal overhead. Building on our previous work on image-to-image translation-based defenses, this study introduces an improved model that incorporates residual blocks to enhance generalizability. The proposed method requires training only a single model, effectively defends against diverse attack types, and is well-transferable between different target models. Experiments show that our model can restore the classification accuracy from near zero to an average of 72\\% while maintaining competitive performance compared to state-of-the-art methods.         ",
    "url": "https://arxiv.org/abs/2504.01399",
    "authors": [
      "Haibo Zhang",
      "Zhihua Yao",
      "Kouichi Sakurai",
      "Takeshi Saitoh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01409",
    "title": "Pedestrian-Aware Motion Planning for Autonomous Driving in Complex Urban Scenarios",
    "abstract": "           Motion planning in uncertain environments like complex urban areas is a key challenge for autonomous vehicles (AVs). The aim of our research is to investigate how AVs can navigate crowded, unpredictable scenarios with multiple pedestrians while maintaining a safe and efficient vehicle behavior. So far, most research has concentrated on static or deterministic traffic participant behavior. This paper introduces a novel algorithm for motion planning in crowded spaces by combining social force principles for simulating realistic pedestrian behavior with a risk-aware motion planner. We evaluate this new algorithm in a 2D simulation environment to rigorously assess AV-pedestrian interactions, demonstrating that our algorithm enables safe, efficient, and adaptive motion planning, particularly in highly crowded urban environments - a first in achieving this level of performance. This study has not taken into consideration real-time constraints and has been shown only in simulation so far. Further studies are needed to investigate the novel algorithm in a complete software stack for AVs on real cars to investigate the entire perception, planning and control pipeline in crowded scenarios. We release the code developed in this research as an open-source resource for further studies and development. It can be accessed at the following link: this https URL ",
    "url": "https://arxiv.org/abs/2504.01409",
    "authors": [
      "Korbinian Moller",
      "Truls Nyberg",
      "Jana Tumova",
      "Johannes Betz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2504.01414",
    "title": "Balancing Subjectivity and Objectivity in Network Selection: A Decision-Making Framework Towards Digital Twins",
    "abstract": "           Selecting the optimal radio access technology (RAT) during vertical handovers (VHO) in heterogeneous wireless networks (HWNs) is critical. Multi-attribute decision-making (MADM) is the most common approach used for network selection (NS) in HWNs. However, existing MADM-NS methods face two major challenges: the rank reversal problem (RRP), where the relative ranking of alternatives changes unexpectedly, and inefficient handling of user and/or service requirements. These limitations result in suboptimal RAT selection and diminished quality of service, which becomes particularly critical for time-sensitive applications. To address these issues, we introduce in this work a novel weighting assignment technique called BWM-GWO, which integrates the Best-Worst Method (BWM) with the Grey Wolf Optimization (GWO) algorithm through a convex linear combination. The proposed framework achieves a balanced decision-making process by using BWM to compute subjective weights that capture user/service preferences, while employing GWO to derive objective weights aimed at minimizing RRP. The development and validation of this framework establish a digital model for NS in HWNs, marking the initial step toward realizing a digital twin (DT). Experimental results show that integrating the proposed BWM-GWO technique with MADM-NS reduces RRP occurrence by up to 71.3% while significantly improving user and service satisfaction compared to benchmark approaches.         ",
    "url": "https://arxiv.org/abs/2504.01414",
    "authors": [
      "Brahim Mefgouda",
      "Hanen Idoudi",
      "Mohammad Al-Quraan",
      "Ismail Lotfi",
      "Omar Alhussein",
      "Lina Mohjazi",
      "Sami Muhaidat"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2504.01415",
    "title": "Systematic Literature Review of Automation and Artificial Intelligence in Usability Issue Detection",
    "abstract": "           Usability issues can hinder the effective use of software. Therefore, various techniques are deployed to diagnose and mitigate them. However, these techniques are costly and time-consuming, particularly in iterative design and development. A substantial body of research indicates that automation and artificial intelligence can enhance the process of obtaining usability insights. In our systematic review of 155 publications, we offer a comprehensive overview of the current state of the art for automated usability issue detection. We analyze trends, paradigms, and the technical context in which they are applied. Finally, we discuss the implications and potential directions for future research.         ",
    "url": "https://arxiv.org/abs/2504.01415",
    "authors": [
      "Eduard Kuric",
      "Peter Demcak",
      "Matus Krajcovic",
      "Jan Lang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2504.01422",
    "title": "Optimization of BLE Broadcast Mode in Offline Finding Network",
    "abstract": "           In the Offline Finding Network(OFN), offline Bluetooth tags broadcast to the surrounding area, the finder devices receiving the broadcast signal and upload location information to the IoT(Internet of Things) cloud servers, thereby achieving offline finding of lost items. This process is essentially a Bluetooth low energy (BLE) neighbor discovery process(NDP). In the process, the variety of Bluetooth scan modes caused by the scan interval and scan window settings affects the discovery latency of finder devices finding the tag broadcast packets. To optimize the experience of searching for lost devices, we propose the CPBIS-mechanism, a certain proportion broadcast-intervals screening mechanism that calculates the most suitable two broadcast intervals and their proportion for offline tags. This reduces discovery latency in the BLE NDP, improves the discovery success rate, further enhances the user experience. To our knowledge, we are the first to propose a comprehensive solution for configuring the broadcast interval parameters of advertisers in BLE NDP, particularly for configurations involving two or more broadcast intervals. We evaluated the results obtained by CPBIS on the nRF52832 chip. The data shows that the CPBIS-mechanism achieves relatively low discovery latencies for multiple scan modes.         ",
    "url": "https://arxiv.org/abs/2504.01422",
    "authors": [
      "Li Zhang",
      "Cheng Feng",
      "Tian Xia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2504.01424",
    "title": "On the Role of Priors in Bayesian Causal Learning",
    "abstract": "           In this work, we investigate causal learning of independent causal mechanisms from a Bayesian perspective. Confirming previous claims from the literature, we show in a didactically accessible manner that unlabeled data (i.e., cause realizations) do not improve the estimation of the parameters defining the mechanism. Furthermore, we observe the importance of choosing an appropriate prior for the cause and mechanism parameters, respectively. Specifically, we show that a factorized prior results in a factorized posterior, which resonates with Janzing and Sch\u00f6lkopf's definition of independent causal mechanisms via the Kolmogorov complexity of the involved distributions and with the concept of parameter independence of Heckerman et al.         ",
    "url": "https://arxiv.org/abs/2504.01424",
    "authors": [
      "Bernhard C. Geiger",
      "Roman Kern"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01429",
    "title": "Refining Interactions: Enhancing Anisotropy in Graph Neural Networks with Language Semantics",
    "abstract": "           The integration of Large Language Models (LLMs) with Graph Neural Networks (GNNs) has recently been explored to enhance the capabilities of Text Attribute Graphs (TAGs). Most existing methods feed textual descriptions of the graph structure or neighbouring nodes' text directly into LLMs. However, these approaches often cause LLMs to treat structural information simply as general contextual text, thus limiting their effectiveness in graph-related tasks. In this paper, we introduce LanSAGNN (Language Semantic Anisotropic Graph Neural Network), a framework that extends the concept of anisotropic GNNs to the natural language level. This model leverages LLMs to extract tailor-made semantic information for node pairs, effectively capturing the unique interactions within node relationships. In addition, we propose an efficient dual-layer LLMs finetuning architecture to better align LLMs' outputs with graph tasks. Experimental results demonstrate that LanSAGNN significantly enhances existing LLM-based methods without increasing complexity while also exhibiting strong robustness against interference.         ",
    "url": "https://arxiv.org/abs/2504.01429",
    "authors": [
      "Zhaoxing Li",
      "Xiaoming Zhang",
      "Haifeng Zhang",
      "Chengxiang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2504.01440",
    "title": "Solving Time-Fractional Partial Integro-Differential Equations Using Tensor Neural Networks",
    "abstract": "           In this paper, we propose a novel machine learning method based on adaptive tensor neural network subspace to solve linear time-fractional diffusion-wave equations and nonlinear time-fractional partial integro-differential equations. In this framework, the tensor neural network and Gauss-Jacobi quadrature are effectively combined to construct a universal numerical scheme for the temporal Caputo derivative with orders spanning $ (0,1)$ and $(1,2)$. Specifically, in order to effectively utilize Gauss-Jacobi quadrature to discretize Caputo derivatives, we design the tensor neural network function multiplied by the function $t^{\\mu}$ where the power $\\mu$ is selected according to the parameters of the equations at hand. Finally, some numerical examples are provided to validate the efficiency and accuracy of the proposed tensor neural network-based machine learning method.         ",
    "url": "https://arxiv.org/abs/2504.01440",
    "authors": [
      "Zhongshuo Lin",
      "Qingkui Ma",
      "Hehu Xie",
      "Xiaobo Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01466",
    "title": "Mesh Mamba: A Unified State Space Model for Saliency Prediction in Non-Textured and Textured Meshes",
    "abstract": "           Mesh saliency enhances the adaptability of 3D vision by identifying and emphasizing regions that naturally attract visual attention. To investigate the interaction between geometric structure and texture in shaping visual attention, we establish a comprehensive mesh saliency dataset, which is the first to systematically capture the differences in saliency distribution under both textured and non-textured visual conditions. Furthermore, we introduce mesh Mamba, a unified saliency prediction model based on a state space model (SSM), designed to adapt across various mesh types. Mesh Mamba effectively analyzes the geometric structure of the mesh while seamlessly incorporating texture features into the topological framework, ensuring coherence throughout appearance-enhanced modeling. More importantly, by subgraph embedding and a bidirectional SSM, the model enables global context modeling for both local geometry and texture, preserving the topological structure and improving the understanding of visual details and structural complexity. Through extensive theoretical and empirical validation, our model not only improves performance across various mesh types but also demonstrates high scalability and versatility, particularly through cross validations of various visual features.         ",
    "url": "https://arxiv.org/abs/2504.01466",
    "authors": [
      "Kaiwei Zhang",
      "Dandan Zhu",
      "Xiongkuo Min",
      "Guangtao Zhai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2504.01481",
    "title": "Identifying Obfuscated Code through Graph-Based Semantic Analysis of Binary Code",
    "abstract": "           Protecting sensitive program content is a critical issue in various situations, ranging from legitimate use cases to unethical contexts. Obfuscation is one of the most used techniques to ensure such protection. Consequently, attackers must first detect and characterize obfuscation before launching any attack against it. This paper investigates the problem of function-level obfuscation detection using graph-based approaches, comparing algorithms, from elementary baselines to promising techniques like GNN (Graph Neural Networks), on different feature choices. We consider various obfuscation types and obfuscators, resulting in two complex datasets. Our findings demonstrate that GNNs need meaningful features that capture aspects of function semantics to outperform baselines. Our approach shows satisfactory results, especially in a challenging 11-class classification task and in a practical malware analysis example.         ",
    "url": "https://arxiv.org/abs/2504.01481",
    "authors": [
      "Roxane Cohen",
      "Robin David",
      "Florian Yger",
      "Fabrice Rossi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2504.01482",
    "title": "A Robust Model-Based Approach for Continuous-Time Policy Evaluation with Unknown L\u00e9vy Process Dynamics",
    "abstract": "           This paper develops a model-based framework for continuous-time policy evaluation (CTPE) in reinforcement learning, incorporating both Brownian and L\u00e9vy noise to model stochastic dynamics influenced by rare and extreme events. Our approach formulates the policy evaluation problem as solving a partial integro-differential equation (PIDE) for the value function with unknown coefficients. A key challenge in this setting is accurately recovering the unknown coefficients in the stochastic dynamics, particularly when driven by L\u00e9vy processes with heavy tail effects. To address this, we propose a robust numerical approach that effectively handles both unbiased and censored trajectory datasets. This method combines maximum likelihood estimation with an iterative tail correction mechanism, improving the stability and accuracy of coefficient recovery. Additionally, we establish a theoretical bound for the policy evaluation error based on coefficient recovery error. Through numerical experiments, we demonstrate the effectiveness and robustness of our method in recovering heavy-tailed L\u00e9vy dynamics and verify the theoretical error analysis in policy evaluation.         ",
    "url": "https://arxiv.org/abs/2504.01482",
    "authors": [
      "Qihao Ye",
      "Xiaochuan Tian",
      "Yuhua Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2504.01483",
    "title": "GarmageNet: A Dataset and Scalable Representation for Generic Garment Modeling",
    "abstract": "           High-fidelity garment modeling remains challenging due to the lack of large-scale, high-quality datasets and efficient representations capable of handling non-watertight, multi-layer geometries. In this work, we introduce Garmage, a neural-network-and-CG-friendly garment representation that seamlessly encodes the accurate geometry and sewing pattern of complex multi-layered garments as a structured set of per-panel geometry images. As a dual-2D-3D representation, Garmage achieves an unprecedented integration of 2D image-based algorithms with 3D modeling workflows, enabling high fidelity, non-watertight, multi-layered garment geometries with direct compatibility for industrial-grade this http URL upon this representation, we present GarmageNet, a novel generation framework capable of producing detailed multi-layered garments with body-conforming initial geometries and intricate sewing patterns, based on user prompts or existing in-the-wild sewing patterns. Furthermore, we introduce a robust stitching algorithm that recovers per-vertex stitches, ensuring seamless integration into flexible simulation pipelines for downstream editing of sewing patterns, material properties, and dynamic simulations. Finally, we release an industrial-standard, large-scale, high-fidelity garment dataset featuring detailed annotations, vertex-wise correspondences, and a robust pipeline for converting unstructured production sewing patterns into GarmageNet standard structural assets, paving the way for large-scale, industrial-grade garment generation systems.         ",
    "url": "https://arxiv.org/abs/2504.01483",
    "authors": [
      "Siran Li",
      "Ruiyang Liu",
      "Chen Liu",
      "Zhendong Wang",
      "Gaofeng He",
      "Yong-Lu Li",
      "Xiaogang Jin",
      "Huamin Wang"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2504.01485",
    "title": "Diameter Shortcut Sets on Temporal Graphs",
    "abstract": "           Shortcut sets are a vital instrument for reducing the diameter of a static graph and, consequently, its shortest path complexity, which is relevant in numerous subfields of graph theory. We explore the notion of shortcut sets in temporal graphs, which incorporate a discrete time model into the graph, rendering each edge accessible exclusively at specific points in time. This not only alters the underlying assumptions of regular graphs but also substantially increases the complexity of path problems and reachability. In turn, a temporal graph is often a much more realistic and accurate representation of a real-world network. In this thesis we provide a definition for a shortcut set in a temporal graph and explore differences to classic shortcut sets. Utilizing this definition, we show that temporal and regular shortcut sets yield the same results on temporal paths, enabling the application of existing construction algorithms for static shortcut sets on paths. The primary contribution of this thesis is a translation approach for general temporal graphs that utilizes the static expansion of a temporal graph, allowing the conversion of static shortcut sets into temporal shortcut sets, yielding similar results.         ",
    "url": "https://arxiv.org/abs/2504.01485",
    "authors": [
      "Gerome Quantmeyer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2504.01506",
    "title": "MLKV: Efficiently Scaling up Large Embedding Model Training with Disk-based Key-Value Storage",
    "abstract": "           Many modern machine learning (ML) methods rely on embedding models to learn vector representations (embeddings) for a set of entities (embedding tables). As increasingly diverse ML applications utilize embedding models and embedding tables continue to grow in size and number, there has been a surge in the ad-hoc development of specialized frameworks targeted to train large embedding models for specific tasks. Although the scalability issues that arise in different embedding model training tasks are similar, each of these frameworks independently reinvents and customizes storage components for specific tasks, leading to substantial duplicated engineering efforts in both development and deployment. This paper presents MLKV, an efficient, extensible, and reusable data storage framework designed to address the scalability challenges in embedding model training, specifically data stall and staleness. MLKV augments disk-based key-value storage by democratizing optimizations that were previously exclusive to individual specialized frameworks and provides easy-to-use interfaces for embedding model training tasks. Extensive experiments on open-source workloads, as well as applications in eBay's payment transaction risk detection and seller payment risk detection, show that MLKV outperforms offloading strategies built on top of industrial-strength key-value stores by 1.6-12.6x. MLKV is open-source at this https URL.         ",
    "url": "https://arxiv.org/abs/2504.01506",
    "authors": [
      "Yongjun He",
      "Roger Waleffe",
      "Zhichao Han",
      "Johnu George",
      "Binhang Yuan",
      "Zitao Zhang",
      "Yinan Shan",
      "Yang Zhao",
      "Debojyoti Dutta",
      "Theodoros Rekatsinas",
      "Ce Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01509",
    "title": "PROPHET: An Inferable Future Forecasting Benchmark with Causal Intervened Likelihood Estimation",
    "abstract": "           Predicting future events stands as one of the ultimate aspirations of artificial intelligence. Recent advances in large language model (LLM)-based systems have shown remarkable potential in forecasting future events, thereby garnering significant interest in the research community. Currently, several benchmarks have been established to evaluate the forecasting capabilities by formalizing the event prediction as a retrieval-augmented generation (RAG) and reasoning task. In these benchmarks, each prediction question is answered with relevant retrieved news articles. However, because there is no consideration on whether the questions can be supported by valid or sufficient supporting rationales, some of the questions in these benchmarks may be inherently noninferable. To address this issue, we introduce a new benchmark, PROPHET, which comprises inferable forecasting questions paired with relevant news for retrieval. To ensure the inferability of the benchmark, we propose Causal Intervened Likelihood (CIL), a statistical measure that assesses inferability through causal inference. In constructing this benchmark, we first collected recent trend forecasting questions and then filtered the data using CIL, resulting in an inferable benchmark for event prediction. Through extensive experiments, we first demonstrate the validity of CIL and in-depth investigations into event prediction with the aid of CIL. Subsequently, we evaluate several representative prediction systems on PROPHET, drawing valuable insights for future directions.         ",
    "url": "https://arxiv.org/abs/2504.01509",
    "authors": [
      "Zhengwei Tao",
      "Zhi Jin",
      "Bincheng Li",
      "Xiaoying Bai",
      "Haiyan Zhao",
      "Chengfeng Dou",
      "Xiancai Chen",
      "Jia Li",
      "Linyu Li",
      "Chongyang Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2504.01527",
    "title": "Beyond Nearest Neighbor Interpolation in Data Augmentation",
    "abstract": "           Avoiding the risk of undefined categorical labels using nearest neighbor interpolation overlooks the risk of exacerbating pixel level annotation errors in data augmentation. To simultaneously avoid these risks, the author modified convolutional neural networks data transformation functions by incorporating a modified geometric transformation function to improve the quality of augmented data by removing the reliance on nearest neighbor interpolation and integrating a mean based class filtering mechanism to handle undefined categorical labels with alternative interpolation algorithms. Experiments on semantic segmentation tasks using three medical image datasets demonstrated both qualitative and quantitative improvements with alternative interpolation algorithms.         ",
    "url": "https://arxiv.org/abs/2504.01527",
    "authors": [
      "Olivier Rukundo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2504.01531",
    "title": "DRAN: A Distribution and Relation Adaptive Network for Spatio-temporal Forecasting",
    "abstract": "           Accurate predictions of spatio-temporal systems' states are crucial for tasks such as system management, control, and crisis prevention. However, the inherent time variance of spatio-temporal systems poses challenges to achieving accurate predictions whenever stationarity is not granted. To address non-stationarity frameworks, we propose a Distribution and Relation Adaptive Network (DRAN) capable of dynamically adapting to relation and distribution changes over time. While temporal normalization and de-normalization are frequently used techniques to adapt to distribution shifts, this operation is not suitable for the spatio-temporal context as temporal normalization scales the time series of nodes and possibly disrupts the spatial relations among nodes. In order to address this problem, we develop a Spatial Factor Learner (SFL) module that enables the normalization and de-normalization process in spatio-temporal systems. To adapt to dynamic changes in spatial relationships among sensors, we propose a Dynamic-Static Fusion Learner (DSFL) module that effectively integrates features learned from both dynamic and static relations through an adaptive fusion ratio mechanism. Furthermore, we introduce a Stochastic Learner to capture the noisy components of spatio-temporal representations. Our approach outperforms state of the art methods in weather prediction and traffic flows forecasting tasks. Experimental results show that our SFL efficiently preserves spatial relationships across various temporal normalization operations. Visualizations of the learned dynamic and static relations demonstrate that DSFL can capture both local and distant relationships between nodes. Moreover, ablation studies confirm the effectiveness of each component.         ",
    "url": "https://arxiv.org/abs/2504.01531",
    "authors": [
      "Xiaobei Zou",
      "Luolin Xiong",
      "Kexuan Zhang",
      "Cesare Alippi",
      "Yang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01533",
    "title": "LightDefense: A Lightweight Uncertainty-Driven Defense against Jailbreaks via Shifted Token Distribution",
    "abstract": "           Large Language Models (LLMs) face threats from jailbreak prompts. Existing methods for defending against jailbreak attacks are primarily based on auxiliary models. These strategies, however, often require extensive data collection or training. We propose LightDefense, a lightweight defense mechanism targeted at white-box models, which utilizes a safety-oriented direction to adjust the probabilities of tokens in the vocabulary, making safety disclaimers appear among the top tokens after sorting tokens by probability in descending order. We further innovatively leverage LLM's uncertainty about prompts to measure their harmfulness and adaptively adjust defense strength, effectively balancing safety and helpfulness. The effectiveness of LightDefense in defending against 5 attack methods across 2 target LLMs, without compromising helpfulness to benign user queries, highlights its potential as a novel and lightweight defense mechanism, enhancing security of LLMs.         ",
    "url": "https://arxiv.org/abs/2504.01533",
    "authors": [
      "Zhuoran Yang",
      "Jie Peng",
      "Zhen Tan",
      "Tianlong Chen",
      "Yanyong Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2504.01534",
    "title": "Context-Aware Toxicity Detection in Multiplayer Games: Integrating Domain-Adaptive Pretraining and Match Metadata",
    "abstract": "           The detrimental effects of toxicity in competitive online video games are widely acknowledged, prompting publishers to monitor player chat conversations. This is challenging due to the context-dependent nature of toxicity, often spread across multiple messages or informed by non-textual interactions. Traditional toxicity detectors focus on isolated messages, missing the broader context needed for accurate moderation. This is especially problematic in video games, where interactions involve specialized slang, abbreviations, and typos, making it difficult for standard models to detect toxicity, especially given its rarity. We adapted RoBERTa LLM to support moderation tailored to video games, integrating both textual and non-textual context. By enhancing pretrained embeddings with metadata and addressing the unique slang and language quirks through domain adaptive pretraining, our method better captures the nuances of player interactions. Using two gaming datasets - from Defense of the Ancients 2 (DOTA 2) and Call of Duty$^\\circledR$: Modern Warfare$^\\circledR$III (MWIII) we demonstrate which sources of context (metadata, prior interactions...) are most useful, how to best leverage them to boost performance, and the conditions conducive to doing so. This work underscores the importance of context-aware and domain-specific approaches for proactive moderation.         ",
    "url": "https://arxiv.org/abs/2504.01534",
    "authors": [
      "Adrien Schurger-Foy",
      "Rafal Dariusz Kocielnik",
      "Caglar Gulcehre",
      "R. Michael Alvarez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2504.01550",
    "title": "Representation Bending for Large Language Model Safety",
    "abstract": "           Large Language Models (LLMs) have emerged as powerful tools, but their inherent safety risks - ranging from harmful content generation to broader societal harms - pose significant challenges. These risks can be amplified by the recent adversarial attacks, fine-tuning vulnerabilities, and the increasing deployment of LLMs in high-stakes environments. Existing safety-enhancing techniques, such as fine-tuning with human feedback or adversarial training, are still vulnerable as they address specific threats and often fail to generalize across unseen attacks, or require manual system-level defenses. This paper introduces RepBend, a novel approach that fundamentally disrupts the representations underlying harmful behaviors in LLMs, offering a scalable solution to enhance (potentially inherent) safety. RepBend brings the idea of activation steering - simple vector arithmetic for steering model's behavior during inference - to loss-based fine-tuning. Through extensive evaluation, RepBend achieves state-of-the-art performance, outperforming prior methods such as Circuit Breaker, RMU, and NPO, with up to 95% reduction in attack success rates across diverse jailbreak benchmarks, all with negligible reduction in model usability and general capabilities.         ",
    "url": "https://arxiv.org/abs/2504.01550",
    "authors": [
      "Ashkan Yousefpour",
      "Taeheon Kim",
      "Ryan S. Kwon",
      "Seungbeen Lee",
      "Wonje Jeung",
      "Seungju Han",
      "Alvin Wan",
      "Harrison Ngan",
      "Youngjae Yu",
      "Jonghyun Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2504.01551",
    "title": "Identifying Macro Causal Effects in C-DMGs",
    "abstract": "           Causal effect identification using causal graphs is a fundamental challenge in causal inference. While extensive research has been conducted in this area, most existing methods assume the availability of fully specified causal graphs. However, in complex domains such as medicine and epidemiology, complete causal knowledge is often unavailable, and only partial information about the system is accessible. This paper focuses on causal effect identification within partially specified causal graphs, with particular emphasis on cluster-directed mixed graphs (C-DMGs). These graphs provide a higher-level representation of causal relationships by grouping variables into clusters, offering a more practical approach for handling complex systems. Unlike fully specified causal graphs, C-DMGs can contain cycles, which complicate their analysis and interpretation. Furthermore, their cluster-based nature introduces new challenges, as it gives rise to two distinct types of causal effects, macro causal effects and micro causal effects, with different properties. In this work, we focus on macro causal effects, which describe the effects of entire clusters on other clusters. We establish that the do-calculus is both sound and complete for identifying these effects in C-DMGs. Additionally, we provide a graphical characterization of non-identifiability for macro causal effects in these graphs.         ",
    "url": "https://arxiv.org/abs/2504.01551",
    "authors": [
      "Simon Ferreira",
      "Charles K. Assaad"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2504.01557",
    "title": "FastER: Fast On-Demand Entity Resolution in Property Graphs",
    "abstract": "           Entity resolution (ER) is the problem of identifying and linking database records that refer to the same real-world entity. Traditional ER methods use batch processing, which becomes impractical with growing data volumes due to high computational costs and lack of real-time capabilities. In many applications, users need to resolve entities for only a small portion of their data, making full data processing unnecessary -- a scenario known as \"ER-on-demand\". This paper proposes FastER, an efficient ER-on-demand framework for property graphs. Our approach uses graph differential dependencies (GDDs) as a knowledge encoding language to design effective filtering mechanisms that leverage both structural and attribute semantics of graphs. We construct a blocking graph from filtered subgraphs to reduce the number of candidate entity pairs requiring comparison. Additionally, FastER incorporates Progressive Profile Scheduling (PPS), allowing the system to incrementally produce results throughout the resolution process. Extensive evaluations on multiple benchmark datasets demonstrate that FastER significantly outperforms state-of-the-art ER methods in computational efficiency and real-time processing for on-demand tasks while ensuring reliability. We make FastER publicly available at: this https URL ",
    "url": "https://arxiv.org/abs/2504.01557",
    "authors": [
      "Shujing Wang",
      "Selasi Kwashie",
      "Michael Bewong",
      "Junwei Hu",
      "Vincent M. Nofong",
      "Shiqi Miao",
      "Zaiwen Feng"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2504.01585",
    "title": "Nonlinear Bandwidth and Bode Diagrams based on Scaled Relative Graphs",
    "abstract": "           Scaled Relative Graphs (SRGs) provide a novel graphical frequency domain method for the analysis of nonlinear systems. In this paper, we use the restriction of the SRG to particular input spaces to compute frequency-dependent gain bounds for incrementally stable nonlinear systems. This leads to a nonlinear (NL) generalization of the Bode diagram, where the sinusoidal, harmonic, and subharmonic inputs are considered separately. When applied to the analysis of the NL loop transfer and sensitivity, we define a notion of bandwidth for both the open-loop and closed-loop, compatible with the LTI definitions. We illustrate the power of our method on the analysis of a DC motor with a parasitic nonlinearity, verifying our results in simulations.         ",
    "url": "https://arxiv.org/abs/2504.01585",
    "authors": [
      "Julius P.J. Krebbekx",
      "Roland T\u00f3th",
      "Amritam Das"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2504.01588",
    "title": "Building Knowledge from Interactions: An LLM-Based Architecture for Adaptive Tutoring and Social Reasoning",
    "abstract": "           Integrating robotics into everyday scenarios like tutoring or physical training requires robots capable of adaptive, socially engaging, and goal-oriented interactions. While Large Language Models show promise in human-like communication, their standalone use is hindered by memory constraints and contextual incoherence. This work presents a multimodal, cognitively inspired framework that enhances LLM-based autonomous decision-making in social and task-oriented Human-Robot Interaction. Specifically, we develop an LLM-based agent for a robot trainer, balancing social conversation with task guidance and goal-driven motivation. To further enhance autonomy and personalization, we introduce a memory system for selecting, storing and retrieving experiences, facilitating generalized reasoning based on knowledge built across different interactions. A preliminary HRI user study and offline experiments with a synthetic dataset validate our approach, demonstrating the system's ability to manage complex interactions, autonomously drive training tasks, and build and retrieve contextual memories, advancing socially intelligent robotics.         ",
    "url": "https://arxiv.org/abs/2504.01588",
    "authors": [
      "Luca Garello",
      "Giulia Belgiovine",
      "Gabriele Russo",
      "Francesco Rea",
      "Alessandra Sciutti"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2504.01602",
    "title": "Comment Staytime Prediction with LLM-enhanced Comment Understanding",
    "abstract": "           In modern online streaming platforms, the comments section plays a critical role in enhancing the overall user experience. Understanding user behavior within the comments section is essential for comprehensive user interest modeling. A key factor of user engagement is staytime, which refers to the amount of time that users browse and post comments. Existing watchtime prediction methods struggle to adapt to staytime prediction, overlooking interactions with individual comments and their interrelation. In this paper, we present a micro-video recommendation dataset with video comments (named as KuaiComt) which is collected from Kuaishou platform. correspondingly, we propose a practical framework for comment staytime prediction with LLM-enhanced Comment Understanding (LCU). Our framework leverages the strong text comprehension capabilities of large language models (LLMs) to understand textual information of comments, while also incorporating fine-grained comment ranking signals as auxiliary tasks. The framework is two-staged: first, the LLM is fine-tuned using domain-specific tasks to bridge the video and the comments; second, we incorporate the LLM outputs into the prediction model and design two comment ranking auxiliary tasks to better understand user preference. Extensive offline experiments demonstrate the effectiveness of our framework, showing significant improvements on the task of comment staytime prediction. Additionally, online A/B testing further validates the practical benefits on industrial scenario. Our dataset KuaiComt (this https URL) and code for LCU (this https URL) are fully released.         ",
    "url": "https://arxiv.org/abs/2504.01602",
    "authors": [
      "Changshuo Zhang",
      "Zihan Lin",
      "Shukai Liu",
      "Yongqi Liu",
      "Han Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2504.01605",
    "title": "Multi-Relation Graph-Kernel Strengthen Network for Graph-Level Clustering",
    "abstract": "           Graph-level clustering is a fundamental task of data mining, aiming at dividing unlabeled graphs into distinct groups. However, existing deep methods that are limited by pooling have difficulty extracting diverse and complex graph structure features, while traditional graph kernel methods rely on exhaustive substructure search, unable to adaptive handle multi-relational data. This limitation hampers producing robust and representative graph-level embeddings. To address this issue, we propose a novel Multi-Relation Graph-Kernel Strengthen Network for Graph-Level Clustering (MGSN), which integrates multi-relation modeling with graph kernel techniques to fully leverage their respective advantages. Specifically, MGSN constructs multi-relation graphs to capture diverse semantic relationships between nodes and graphs, which employ graph kernel methods to extract graph similarity features, enriching the representation space. Moreover, a relation-aware representation refinement strategy is designed, which adaptively aligns multi-relation information across views while enhancing graph-level features through a progressive fusion process. Extensive experiments on multiple benchmark datasets demonstrate the superiority of MGSN over state-of-the-art methods. The results highlight its ability to leverage multi-relation structures and graph kernel features, establishing a new paradigm for robust graph-level clustering.         ",
    "url": "https://arxiv.org/abs/2504.01605",
    "authors": [
      "Renda Han",
      "Guangzhen Yao",
      "Wenxin Zhang",
      "Yu Li",
      "Wen Xin",
      "Huajie Lei",
      "Mengfei Li",
      "Zeyu Zhang",
      "Chengze Du",
      "Yahe Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01632",
    "title": "Benchmarking the Spatial Robustness of DNNs via Natural and Adversarial Localized Corruptions",
    "abstract": "           The robustness of DNNs is a crucial factor in safety-critical applications, particularly in complex and dynamic environments where localized corruptions can arise. While previous studies have evaluated the robustness of semantic segmentation (SS) models under whole-image natural or adversarial corruptions, a comprehensive investigation into the spatial robustness of dense vision models under localized corruptions remained underexplored. This paper fills this gap by introducing specialized metrics for benchmarking the spatial robustness of segmentation models, alongside with an evaluation framework to assess the impact of localized corruptions. Furthermore, we uncover the inherent complexity of characterizing worst-case robustness using a single localized adversarial perturbation. To address this, we propose region-aware multi-attack adversarial analysis, a method that enables a deeper understanding of model robustness against adversarial perturbations applied to specific regions. The proposed metrics and analysis were evaluated on 15 segmentation models in driving scenarios, uncovering key insights into the effects of localized corruption in both natural and adversarial forms. The results reveal that models respond to these two types of threats differently; for instance, transformer-based segmentation models demonstrate notable robustness to localized natural corruptions but are highly vulnerable to adversarial ones and vice-versa for CNN-based models. Consequently, we also address the challenge of balancing robustness to both natural and adversarial localized corruptions by means of ensemble models, thereby achieving a broader threat coverage and improved reliability for dense vision tasks.         ",
    "url": "https://arxiv.org/abs/2504.01632",
    "authors": [
      "Giulia Marchiori Pietrosanti",
      "Giulio Rossolini",
      "Alessandro Biondi",
      "Giorgio Buttazzo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2504.01641",
    "title": "Bridge 2D-3D: Uncertainty-aware Hierarchical Registration Network with Domain Alignment",
    "abstract": "           The method for image-to-point cloud registration typically determines the rigid transformation using a coarse-to-fine pipeline. However, directly and uniformly matching image patches with point cloud patches may lead to focusing on incorrect noise patches during matching while ignoring key ones. Moreover, due to the significant differences between image and point cloud modalities, it may be challenging to bridge the domain gap without specific improvements in design. To address the above issues, we innovatively propose the Uncertainty-aware Hierarchical Matching Module (UHMM) and the Adversarial Modal Alignment Module (AMAM). Within the UHMM, we model the uncertainty of critical information in image patches and facilitate multi-level fusion interactions between image and point cloud features. In the AMAM, we design an adversarial approach to reduce the domain gap between image and point cloud. Extensive experiments and ablation studies on RGB-D Scene V2 and 7-Scenes benchmarks demonstrate the superiority of our method, making it a state-of-the-art approach for image-to-point cloud registration tasks.         ",
    "url": "https://arxiv.org/abs/2504.01641",
    "authors": [
      "Zhixin Cheng",
      "Jiacheng Deng",
      "Xinjun Li",
      "Baoqun Yin",
      "Tianzhu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2504.01644",
    "title": "Proposition of Affordance-Driven Environment Recognition Framework Using Symbol Networks in Large Language Models",
    "abstract": "           In the quest to enable robots to coexist with humans, understanding dynamic situations and selecting appropriate actions based on common sense and affordances are essential. Conventional AI systems face challenges in applying affordance, as it represents implicit knowledge derived from common sense. However, large language models (LLMs) offer new opportunities due to their ability to process extensive human knowledge. This study proposes a method for automatic affordance acquisition by leveraging LLM outputs. The process involves generating text using LLMs, reconstructing the output into a symbol network using morphological and dependency analysis, and calculating affordances based on network distances. Experiments using ``apple'' as an example demonstrated the method's ability to extract context-dependent affordances with high explainability. The results suggest that the proposed symbol network, reconstructed from LLM outputs, enables robots to interpret affordances effectively, bridging the gap between symbolized data and human-like situational understanding.         ",
    "url": "https://arxiv.org/abs/2504.01644",
    "authors": [
      "Kazuma Arii",
      "Satoshi Kurihara"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2504.01659",
    "title": "Robust Unsupervised Domain Adaptation for 3D Point Cloud Segmentation Under Source Adversarial Attacks",
    "abstract": "           Unsupervised domain adaptation (UDA) frameworks have shown good generalization capabilities for 3D point cloud semantic segmentation models on clean data. However, existing works overlook adversarial robustness when the source domain itself is compromised. To comprehensively explore the robustness of the UDA frameworks, we first design a stealthy adversarial point cloud generation attack that can significantly contaminate datasets with only minor perturbations to the point cloud surface. Based on that, we propose a novel dataset, AdvSynLiDAR, comprising synthesized contaminated LiDAR point clouds. With the generated corrupted data, we further develop the Adversarial Adaptation Framework (AAF) as the countermeasure. Specifically, by extending the key point sensitive (KPS) loss towards the Robust Long-Tail loss (RLT loss) and utilizing a decoder branch, our approach enables the model to focus on long-tail classes during the pre-training phase and leverages high-confidence decoded point cloud information to restore point cloud structures during the adaptation phase. We evaluated our AAF method on the AdvSynLiDAR dataset, where the results demonstrate that our AAF method can mitigate performance degradation under source adversarial perturbations for UDA in the 3D point cloud segmentation application.         ",
    "url": "https://arxiv.org/abs/2504.01659",
    "authors": [
      "Haosheng Li",
      "Yuecong Xu",
      "Junjie Chen",
      "Kemi Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2504.01668",
    "title": "Overlap-Aware Feature Learning for Robust Unsupervised Domain Adaptation for 3D Semantic Segmentation",
    "abstract": "           3D point cloud semantic segmentation (PCSS) is a cornerstone for environmental perception in robotic systems and autonomous driving, enabling precise scene understanding through point-wise classification. While unsupervised domain adaptation (UDA) mitigates label scarcity in PCSS, existing methods critically overlook the inherent vulnerability to real-world perturbations (e.g., snow, fog, rain) and adversarial distortions. This work first identifies two intrinsic limitations that undermine current PCSS-UDA robustness: (a) unsupervised features overlap from unaligned boundaries in shared-class regions and (b) feature structure erosion caused by domain-invariant learning that suppresses target-specific patterns. To address the proposed problems, we propose a tripartite framework consisting of: 1) a robustness evaluation model quantifying resilience against adversarial attack/corruption types through robustness metrics; 2) an invertible attention alignment module (IAAM) enabling bidirectional domain mapping while preserving discriminative structure via attention-guided overlap suppression; and 3) a contrastive memory bank with quality-aware contrastive learning that progressively refines pseudo-labels with feature quality for more discriminative representations. Extensive experiments on SynLiDAR-to-SemanticPOSS adaptation demonstrate a maximum mIoU improvement of 14.3\\% under adversarial attack.         ",
    "url": "https://arxiv.org/abs/2504.01668",
    "authors": [
      "Junjie Chen",
      "Yuecong Xu",
      "Haosheng Li",
      "Kemi Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2504.01671",
    "title": "Anomaly Detection for Hybrid Butterfly Subspecies via Probability Filtering",
    "abstract": "           Detecting butterfly hybrids requires knowledge of the parent subspecies, and the process can be tedious when encountering a new subspecies. This study focuses on a specific scenario where a model trained to recognize hybrid species A can generalize to species B when B biologically mimics A. Since species A and B share similar patterns, we leverage BioCLIP as our feature extractor to capture features based on their taxonomy. Consequently, the algorithm designed for species A can be transferred to B, as their hybrid and non-hybrid patterns exhibit similar relationships. To determine whether a butterfly is a hybrid, we adopt proposed probability filtering and color jittering to augment and simulate the mimicry. With these approaches, we achieve second place in the official development phase. Our code is publicly available at this https URL.         ",
    "url": "https://arxiv.org/abs/2504.01671",
    "authors": [
      "Bo-Kai Ruan",
      "Yi-Zeng Fang",
      "Hong-Han Shuai",
      "Juinn-Dar Huang"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2504.01705",
    "title": "Sky of Unlearning (SoUL): Rewiring Federated Machine Unlearning via Selective Pruning",
    "abstract": "           The Internet of Drones (IoD), where drones collaborate in data collection and analysis, has become essential for applications such as surveillance and environmental monitoring. Federated learning (FL) enables drones to train machine learning models in a decentralized manner while preserving data privacy. However, FL in IoD networks is susceptible to attacks like data poisoning and model inversion. Federated unlearning (FU) mitigates these risks by eliminating adversarial data contributions, preventing their influence on the model. This paper proposes sky of unlearning (SoUL), a federated unlearning framework that efficiently removes the influence of unlearned data while maintaining model performance. A selective pruning algorithm is designed to identify and remove neurons influential in unlearning but minimally impact the overall performance of the model. Simulations demonstrate that SoUL outperforms existing unlearning methods, achieves accuracy comparable to full retraining, and reduces computation and communication overhead, making it a scalable and efficient solution for resource-constrained IoD networks.         ",
    "url": "https://arxiv.org/abs/2504.01705",
    "authors": [
      "Md Mahabub Uz Zaman",
      "Xiang Sun",
      "Jingjing Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2504.01708",
    "title": "TransforMerger: Transformer-based Voice-Gesture Fusion for Robust Human-Robot Communication",
    "abstract": "           As human-robot collaboration advances, natural and flexible communication methods are essential for effective robot control. Traditional methods relying on a single modality or rigid rules struggle with noisy or misaligned data as well as with object descriptions that do not perfectly fit the predefined object names (e.g. 'Pick that red object'). We introduce TransforMerger, a transformer-based reasoning model that infers a structured action command for robotic manipulation based on fused voice and gesture inputs. Our approach merges multimodal data into a single unified sentence, which is then processed by the language model. We employ probabilistic embeddings to handle uncertainty and we integrate contextual scene understanding to resolve ambiguous references (e.g., gestures pointing to multiple objects or vague verbal cues like \"this\"). We evaluate TransforMerger in simulated and real-world experiments, demonstrating its robustness to noise, misalignment, and missing information. Our results show that TransforMerger outperforms deterministic baselines, especially in scenarios requiring more contextual knowledge, enabling more robust and flexible human-robot communication. Code and datasets are available at: this http URL.         ",
    "url": "https://arxiv.org/abs/2504.01708",
    "authors": [
      "Petr Vanc",
      "Karla Stepanova"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01718",
    "title": "A Novel Dynamic Epidemic Model for Successive Opinion Diffusion in Social Networks",
    "abstract": "           This paper proposes a dynamic epidemic model for successive opinion diffusion in social networks, extending the SHIMR model. It incorporates dynamic decision-making influenced by social distances and captures accumulative opinion diffusion caused by interrelated rumors. The model reflects the impact of rumor spread on social network structures. Simulations validate its effectiveness in explaining phenomena like the echo chamber effect and provide insights into opinion diffusion dynamics, with implications for understanding social polarization and network evolution.         ",
    "url": "https://arxiv.org/abs/2504.01718",
    "authors": [
      "Bin Han",
      "Fabienne Renckens",
      "C. Clark Cao",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2504.01724",
    "title": "DreamActor-M1: Holistic, Expressive and Robust Human Image Animation with Hybrid Guidance",
    "abstract": "           While recent image-based human animation methods achieve realistic body and facial motion synthesis, critical gaps remain in fine-grained holistic controllability, multi-scale adaptability, and long-term temporal coherence, which leads to their lower expressiveness and robustness. We propose a diffusion transformer (DiT) based framework, DreamActor-M1, with hybrid guidance to overcome these limitations. For motion guidance, our hybrid control signals that integrate implicit facial representations, 3D head spheres, and 3D body skeletons achieve robust control of facial expressions and body movements, while producing expressive and identity-preserving animations. For scale adaptation, to handle various body poses and image scales ranging from portraits to full-body views, we employ a progressive training strategy using data with varying resolutions and scales. For appearance guidance, we integrate motion patterns from sequential frames with complementary visual references, ensuring long-term temporal coherence for unseen regions during complex movements. Experiments demonstrate that our method outperforms the state-of-the-art works, delivering expressive results for portraits, upper-body, and full-body generation with robust long-term consistency. Project Page: this https URL.         ",
    "url": "https://arxiv.org/abs/2504.01724",
    "authors": [
      "Yuxuan Luo",
      "Zhengkun Rong",
      "Lizhen Wang",
      "Longhao Zhang",
      "Tianshu Hu",
      "Yongming Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2504.01735",
    "title": "AdPO: Enhancing the Adversarial Robustness of Large Vision-Language Models with Preference Optimization",
    "abstract": "           Large Vision-Language Models (LVLMs), such as GPT-4o and LLaVA, have recently witnessed remarkable advancements and are increasingly being deployed in real-world applications. However, inheriting the sensitivity of visual neural networks, LVLMs remain vulnerable to adversarial attacks, which can result in erroneous or malicious outputs. While existing efforts utilize adversarial fine-tuning to enhance robustness, they often suffer from performance degradation on clean inputs. In this paper, we proposes AdPO, a novel adversarial defense strategy for LVLMs based on preference optimization. For the first time, we reframe adversarial training as a preference optimization problem, aiming to enhance the model's preference for generating normal outputs on clean inputs while rejecting the potential misleading outputs for adversarial examples. Notably, AdPO achieves this by solely modifying the image encoder, e.g., CLIP ViT, resulting in superior clean and adversarial performance in a variety of downsream tasks. Considering that training involves large language models (LLMs), the computational cost increases significantly. We validate that training on smaller LVLMs and subsequently transferring to larger models can achieve competitive performance while maintaining efficiency comparable to baseline methods. Our comprehensive experiments confirm the effectiveness of the proposed AdPO, which provides a novel perspective for future adversarial defense research.         ",
    "url": "https://arxiv.org/abs/2504.01735",
    "authors": [
      "Chaohu Liu",
      "Tianyi Gui",
      "Yu Liu",
      "Linli Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2504.01766",
    "title": "Learning with Imperfect Models: When Multi-step Prediction Mitigates Compounding Error",
    "abstract": "           Compounding error, where small prediction mistakes accumulate over time, presents a major challenge in learning-based control. For example, this issue often limits the performance of model-based reinforcement learning and imitation learning. One common approach to mitigate compounding error is to train multi-step predictors directly, rather than relying on autoregressive rollout of a single-step model. However, it is not well understood when the benefits of multi-step prediction outweigh the added complexity of learning a more complicated model. In this work, we provide a rigorous analysis of this trade-off in the context of linear dynamical systems. We show that when the model class is well-specified and accurately captures the system dynamics, single-step models achieve lower asymptotic prediction error. On the other hand, when the model class is misspecified due to partial observability, direct multi-step predictors can significantly reduce bias and thus outperform single-step approaches. These theoretical results are supported by numerical experiments, wherein we also (a) empirically evaluate an intermediate strategy which trains a single-step model using a multi-step loss and (b) evaluate performance of single step and multi-step predictors in a closed loop control setting.         ",
    "url": "https://arxiv.org/abs/2504.01766",
    "authors": [
      "Anne Somalwar",
      "Bruce D. Lee",
      "George J. Pappas",
      "Nikolai Matni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01783",
    "title": "CLaP -- State Detection from Time Series",
    "abstract": "           The ever-growing amount of sensor data from machines, smart devices, and the environment leads to an abundance of high-resolution, unannotated time series (TS). These recordings encode the recognizable properties of latent states and transitions from physical phenomena that can be modelled as abstract processes. The unsupervised localization and identification of these states and their transitions is the task of time series state detection (TSSD). We introduce CLaP, a new, highly accurate and efficient algorithm for TSSD. It leverages the predictive power of time series classification for TSSD in an unsupervised setting by applying novel self-supervision techniques to detect whether data segments emerge from the same state or not. To this end, CLaP cross-validates a classifier with segment-labelled subsequences to quantify confusion between segments. It merges labels from segments with high confusion, representing the same latent state, if this leads to an increase in overall classification quality. We conducted an experimental evaluation using 391 TS from four benchmarks and found CLaP to be significantly more precise in detecting states than five state-of-the-art competitors. It achieves the best accuracy-runtime tradeoff and is scalable to large TS. We provide a Python implementation of CLaP, which can be deployed in TS analysis workflows.         ",
    "url": "https://arxiv.org/abs/2504.01783",
    "authors": [
      "Arik Ermshaus",
      "Patrick Sch\u00e4fer",
      "Ulf Leser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2504.01802",
    "title": "Distributed Triangle Detection is Hard in Few Rounds",
    "abstract": "           In the distributed triangle detection problem, we have an $n$-vertex network $G=(V,E)$ with one player for each vertex of the graph who sees the edges incident on the vertex. The players communicate in synchronous rounds using the edges of this network and have a limited bandwidth of $O(\\log{n})$ bits over each edge. The goal is to detect whether or not $G$ contains a triangle as a subgraph in a minimal number of rounds. We prove that any protocol (deterministic or randomized) for distributed triangle detection requires $\\Omega(\\log\\log{n})$ rounds of communication. Prior to our work, only one-round lower bounds were known for this problem. The primary technique for proving these types of distributed lower bounds is via reductions from two-party communication complexity. However, it has been known for a while that this approach is provably incapable of establishing any meaningful lower bounds for distributed triangle detection. Our main technical contribution is a new information theoretic argument which combines recent advances on multi-pass graph streaming lower bounds with the point-to-point communication aspects of distributed models, and can be of independent interest.         ",
    "url": "https://arxiv.org/abs/2504.01802",
    "authors": [
      "Sepehr Assadi",
      "Janani Sundaresan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2504.01811",
    "title": "Inference of hidden common driver dynamics by anisotropic self-organizing neural networks",
    "abstract": "           We are introducing a novel approach to infer the underlying dynamics of hidden common drivers, based on analyzing time series data from two driven dynamical systems. The inference relies on time-delay embedding, estimation of the intrinsic dimension of the observed systems, and their mutual dimension. A key component of our approach is a new anisotropic training technique applied to Kohonen's self-organizing map, which effectively learns the attractor of the driven system and separates it into submanifolds corresponding to the self-dynamics and shared dynamics. To demonstrate the effectiveness of our method, we conducted simulated experiments using different chaotic maps in a setup, where two chaotic maps were driven by a third map with nonlinear coupling. The inferred time series exhibited high correlation with the time series of the actual hidden common driver, in contrast to the observed systems. The quality of our reconstruction were compared and shown to be superior to several other methods that are intended to find the common features behind the observed time series, including linear methods like PCA and ICA as well as nonlinear methods like dynamical component analysis, canonical correlation analysis and even deep canonical correlation analysis.         ",
    "url": "https://arxiv.org/abs/2504.01811",
    "authors": [
      "Zsigmond Benk\u0151",
      "Marcell Stippinger",
      "Zolt\u00e1n Somogyv\u00e1ri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01819",
    "title": "Implicit Bias Injection Attacks against Text-to-Image Diffusion Models",
    "abstract": "           The proliferation of text-to-image diffusion models (T2I DMs) has led to an increased presence of AI-generated images in daily life. However, biased T2I models can generate content with specific tendencies, potentially influencing people's perceptions. Intentional exploitation of these biases risks conveying misleading information to the public. Current research on bias primarily addresses explicit biases with recognizable visual patterns, such as skin color and gender. This paper introduces a novel form of implicit bias that lacks explicit visual features but can manifest in diverse ways across various semantic contexts. This subtle and versatile nature makes this bias challenging to detect, easy to propagate, and adaptable to a wide range of scenarios. We further propose an implicit bias injection attack framework (IBI-Attacks) against T2I diffusion models by precomputing a general bias direction in the prompt embedding space and adaptively adjusting it based on different inputs. Our attack module can be seamlessly integrated into pre-trained diffusion models in a plug-and-play manner without direct manipulation of user input or model retraining. Extensive experiments validate the effectiveness of our scheme in introducing bias through subtle and diverse modifications while preserving the original semantics. The strong concealment and transferability of our attack across various scenarios further underscore the significance of our approach. Code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2504.01819",
    "authors": [
      "Huayang Huang",
      "Xiangye Jin",
      "Jiaxu Miao",
      "Yu Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2504.01850",
    "title": "Code Red! On the Harmfulness of Applying Off-the-shelf Large Language Models to Programming Tasks",
    "abstract": "           Nowadays, developers increasingly rely on solutions powered by Large Language Models (LLM) to assist them with their coding tasks. This makes it crucial to align these tools with human values to prevent malicious misuse. In this paper, we propose a comprehensive framework for assessing the potential harmfulness of LLMs within the software engineering domain. We begin by developing a taxonomy of potentially harmful software engineering scenarios and subsequently, create a dataset of prompts based on this taxonomy. To systematically assess the responses, we design and validate an automatic evaluator that classifies the outputs of a variety of LLMs both open-source and closed-source models, as well as general-purpose and code-specific LLMs. Furthermore, we investigate the impact of models size, architecture family, and alignment strategies on their tendency to generate harmful content. The results show significant disparities in the alignment of various LLMs for harmlessness. We find that some models and model families, such as Openhermes, are more harmful than others and that code-specific models do not perform better than their general-purpose counterparts. Notably, some fine-tuned models perform significantly worse than their base-models due to their design choices. On the other side, we find that larger models tend to be more helpful and are less likely to respond with harmful information. These results highlight the importance of targeted alignment strategies tailored to the unique challenges of software engineering tasks and provide a foundation for future work in this critical area.         ",
    "url": "https://arxiv.org/abs/2504.01850",
    "authors": [
      "Ali Al-Kaswan",
      "Sebastian Deatc",
      "Beg\u00fcm Ko\u00e7",
      "Arie van Deursen",
      "Maliheh Izadi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2504.01851",
    "title": "Virtual Target Trajectory Prediction for Stochastic Targets",
    "abstract": "           Trajectory prediction of other vehicles is crucial for autonomous vehicles, with applications from missile guidance to UAV collision avoidance. Typically, target trajectories are assumed deterministic, but real-world aerial vehicles exhibit stochastic behavior, such as evasive maneuvers or gliders circling in thermals. This paper uses Conditional Normalizing Flows, an unsupervised Machine Learning technique, to learn and predict the stochastic behavior of targets of guided missiles using trajectory data. The trained model predicts the distribution of future target positions based on initial conditions and parameters of the dynamics. Samples from this distribution are clustered using a time series k-means algorithm to generate representative trajectories, termed virtual targets. The method is fast and target-agnostic, requiring only training data in the form of target trajectories. Thus, it serves as a drop-in replacement for deterministic trajectory predictions in guidance laws and path planning. Simulated scenarios demonstrate the approach's effectiveness for aerial vehicles with random maneuvers, bridging the gap between deterministic predictions and stochastic reality, advancing guidance and control algorithms for autonomous vehicles.         ",
    "url": "https://arxiv.org/abs/2504.01851",
    "authors": [
      "Marc Schneider",
      "Renato Loureiro",
      "Torbj\u00f8rn Cunis",
      "Walter Fichter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2504.01861",
    "title": "Corner-Grasp: Multi-Action Grasp Detection and Active Gripper Adaptation for Grasping in Cluttered Environments",
    "abstract": "           Robotic grasping is an essential capability, playing a critical role in enabling robots to physically interact with their surroundings. Despite extensive research, challenges remain due to the diverse shapes and properties of target objects, inaccuracies in sensing, and potential collisions with the environment. In this work, we propose a method for effectively grasping in cluttered bin-picking environments where these challenges intersect. We utilize a multi-functional gripper that combines both suction and finger grasping to handle a wide range of objects. We also present an active gripper adaptation strategy to minimize collisions between the gripper hardware and the surrounding environment by actively leveraging the reciprocating suction cup and reconfigurable finger motion. To fully utilize the gripper's capabilities, we built a neural network that detects suction and finger grasp points from a single input RGB-D image. This network is trained using a larger-scale synthetic dataset generated from simulation. In addition to this, we propose an efficient approach to constructing a real-world dataset that facilitates grasp point detection on various objects with diverse characteristics. Experiment results show that the proposed method can grasp objects in cluttered bin-picking scenarios and prevent collisions with environmental constraints such as a corner of the bin. Our proposed method demonstrated its effectiveness in the 9th Robotic Grasping and Manipulation Competition (RGMC) held at ICRA 2024.         ",
    "url": "https://arxiv.org/abs/2504.01861",
    "authors": [
      "Yeong Gwang Son",
      "Seunghwan Um",
      "Juyong Hong",
      "Tat Hieu Bui",
      "Hyouk Ryeol Choi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01866",
    "title": "From Code Generation to Software Testing: AI Copilot with Context-Based RAG",
    "abstract": "           The rapid pace of large-scale software development places increasing demands on traditional testing methodologies, often leading to bottlenecks in efficiency, accuracy, and coverage. We propose a novel perspective on software testing by positing bug detection and coding with fewer bugs as two interconnected problems that share a common goal, which is reducing bugs with limited resources. We extend our previous work on AI-assisted programming, which supports code auto-completion and chatbot-powered Q&A, to the realm of software testing. We introduce Copilot for Testing, an automated testing system that synchronizes bug detection with codebase updates, leveraging context-based Retrieval Augmented Generation (RAG) to enhance the capabilities of large language models (LLMs). Our evaluation demonstrates a 31.2% improvement in bug detection accuracy, a 12.6% increase in critical test coverage, and a 10.5% higher user acceptance rate, highlighting the transformative potential of AI-driven technologies in modern software development practices.         ",
    "url": "https://arxiv.org/abs/2504.01866",
    "authors": [
      "Yuchen Wang",
      "Shangxin Guo",
      "Chee Wei Tan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2504.01882",
    "title": "CO-DEFEND: Continuous Decentralized Federated Learning for Secure DoH-Based Threat Detection",
    "abstract": "           The use of DNS over HTTPS (DoH) tunneling by an attacker to hide malicious activity within encrypted DNS traffic poses a serious threat to network security, as it allows malicious actors to bypass traditional monitoring and intrusion detection systems while evading detection by conventional traffic analysis techniques. Machine Learning (ML) techniques can be used to detect DoH tunnels; however, their effectiveness relies on large datasets containing both benign and malicious traffic. Sharing such datasets across entities is challenging due to privacy concerns. In this work, we propose CO-DEFEND (Continuous Decentralized Federated Learning for Secure DoH-Based Threat Detection), a Decentralized Federated Learning (DFL) framework that enables multiple entities to collaboratively train a classification machine learning model while preserving data privacy and enhancing resilience against single points of failure. The proposed DFL framework, which is scalable and privacy-preserving, is based on a federation process that allows multiple entities to train online their local models using incoming DoH flows in real time as they are processed by the entity. In addition, we adapt four classical machine learning algorithms, Support Vector Machines (SVM), Logistic Regression (LR), Decision Trees (DT), and Random Forest (RF), for federated scenarios, comparing their results with more computationally complex alternatives such as neural networks. We compare our proposed method by using the dataset CIRA-CIC-DoHBrw-2020 with existing machine learning approaches to demonstrate its effectiveness in detecting malicious DoH tunnels and the benefits it brings.         ",
    "url": "https://arxiv.org/abs/2504.01882",
    "authors": [
      "Diego Cajaraville-Aboy",
      "Marta Moure-Garrido",
      "Carlos Beis-Penedo",
      "Carlos Garcia-Rubio",
      "Rebeca P. D\u00edaz-Redondo",
      "Celeste Campo",
      "Ana Fern\u00e1ndez-Vilas",
      "Manuel Fern\u00e1ndez-Veiga"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01902",
    "title": "Graphically Speaking: Unmasking Abuse in Social Media with Conversation Insights",
    "abstract": "           Detecting abusive language in social media conversations poses significant challenges, as identifying abusiveness often depends on the conversational context, characterized by the content and topology of preceding comments. Traditional Abusive Language Detection (ALD) models often overlook this context, which can lead to unreliable performance metrics. Recent Natural Language Processing (NLP) methods that integrate conversational context often depend on limited and simplified representations, and report inconsistent results. In this paper, we propose a novel approach that utilize graph neural networks (GNNs) to model social media conversations as graphs, where nodes represent comments, and edges capture reply structures. We systematically investigate various graph representations and context windows to identify the optimal configuration for ALD. Our GNN model outperform both context-agnostic baselines and linear context-aware methods, achieving significant improvements in F1 scores. These findings demonstrate the critical role of structured conversational context and establish GNNs as a robust framework for advancing context-aware abusive language detection.         ",
    "url": "https://arxiv.org/abs/2504.01902",
    "authors": [
      "C\u00e9lia Nouri",
      "Jean-Philippe Cointet",
      "Chlo\u00e9 Clavel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01907",
    "title": "Build Code Needs Maintenance Too: A Study on Refactoring and Technical Debt in Build Systems",
    "abstract": "           In modern software engineering, build systems play the crucial role of facilitating the conversion of source code into software artifacts. Recent research has explored high-level causes of build failures, but has largely overlooked the structural properties of build files. Akin to source code, build systems face technical debt challenges that hinder maintenance and optimization. While refactoring is often seen as a key tool for addressing technical debt in source code, there is a significant research gap regarding the specific refactoring changes developers apply to build code and whether these refactorings effectively address technical debt. In this paper, we address this gap by examining refactorings applied to build scripts in open-source projects, covering the widely used build systems of Gradle, Ant, and Maven. Additionally, we investigate whether these refactorings are used to tackle technical debts in build systems. Our analysis was conducted on \\totalCommits examined build-file-related commits. We identified \\totalRefactoringCategories build-related refactorings, which we divided into \\totalCategories main categories. These refactorings are organized into the first empirically derived taxonomy of build system refactorings. Furthermore, we investigate how developers employ these refactoring types to address technical debts via a manual commit-analysis and a developer survey. In this context, we identified \\totalTechnicalDebts technical debts addressed by these refactorings and discussed their correlation with the different refactorings. Finally, we introduce BuildRefMiner, an LLM-powered tool leveraging GPT-4o to automate the detection of refactorings within build systems. We evaluated its performance and found that it achieves an F1 score of \\toolFoneScore across all build systems.         ",
    "url": "https://arxiv.org/abs/2504.01907",
    "authors": [
      "Anwar Ghammam",
      "Dhia Elhaq Rzig",
      "Mohamed Almukhtar",
      "Rania Khalsi",
      "Foyzul Hassan",
      "Marouane Kessentini"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2504.01921",
    "title": "Client Selection in Federated Learning with Data Heterogeneity and Network Latencies",
    "abstract": "           Federated learning (FL) is a distributed machine learning paradigm where multiple clients conduct local training based on their private data, then the updated models are sent to a central server for global aggregation. The practical convergence of FL is challenged by multiple factors, with the primary hurdle being the heterogeneity among clients. This heterogeneity manifests as data heterogeneity concerning local data distribution and latency heterogeneity during model transmission to the server. While prior research has introduced various efficient client selection methods to alleviate the negative impacts of either of these heterogeneities individually, efficient methods to handle real-world settings where both these heterogeneities exist simultaneously do not exist. In this paper, we propose two novel theoretically optimal client selection schemes that can handle both these heterogeneities. Our methods involve solving simple optimization problems every round obtained by minimizing the theoretical runtime to convergence. Empirical evaluations on 9 datasets with non-iid data distributions, 2 practical delay distributions, and non-convex neural network models demonstrate that our algorithms are at least competitive to and at most 20 times better than best existing baselines.         ",
    "url": "https://arxiv.org/abs/2504.01921",
    "authors": [
      "Harsh Vardhan",
      "Xiaofan Yu",
      "Tajana Rosing",
      "Arya Mazumdar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2504.01922",
    "title": "Is Less Really More? Fake News Detection with Limited Information",
    "abstract": "           The threat that online fake news and misinformation pose to democracy, justice, public confidence, and especially to vulnerable populations, has led to a sharp increase in the need for fake news detection and intervention. Whether multi-modal or pure text-based, most fake news detection methods depend on textual analysis of entire articles. However, these fake news detection methods come with certain limitations. For instance, fake news detection methods that rely on full text can be computationally inefficient, demand large amounts of training data to achieve competitive accuracy, and may lack robustness across different datasets. This is because fake news datasets have strong variations in terms of the level and types of information they provide; where some can include large paragraphs of text with images and metadata, others can be a few short sentences. Perhaps if one could only use minimal information to detect fake news, fake news detection methods could become more robust and resilient to the lack of information. We aim to overcome these limitations by detecting fake news using systematically selected, limited information that is both effective and capable of delivering robust, promising performance. We propose a framework called SLIM Systematically-selected Limited Information) for fake news detection. In SLIM, we quantify the amount of information by introducing information-theoretic measures. SLIM leverages limited information to achieve performance in fake news detection comparable to that of state-of-the-art obtained using the full text. Furthermore, by combining various types of limited information, SLIM can perform even better while significantly reducing the quantity of information required for training compared to state-of-the-art language model-based fake news detection techniques.         ",
    "url": "https://arxiv.org/abs/2504.01922",
    "authors": [
      "Zhaoyang Cao",
      "John Nguyen",
      "Reza Zafarani"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2504.01946",
    "title": "Asynchronous Traffic Shaping and Redundancy: Avoiding Unbounded Latencies in In-Car Networks",
    "abstract": "           Time-Sensitive Networking (TSN) enhances Ethernet based In-Vehicle Networks (IVNs) with real-time capabilities. Different traffic shaping algorithms have been proposed for time-critical communication, of which the Asynchronous Traffic Shaper (ATS) is an upcoming candidate. However, recent research has shown that ATS can introduce unbounded latencies when shaping traffic from non-FIFO systems. This impacts the applicability of ATS in IVNs, as these networks often use redundancy mechanisms that can cause non-FIFO behavior. In this paper, we approach the problem of accumulated delays from ATS by analyzing the scenarios that generate latency and by devising placement and configurations of ATS schedulers to prevent this behavior. Our solution successfully mitigates problematic preconditions that lead to unbounded delays, which we evaluate in simulations. Through a realistic IVN simulation case study, we demonstrate the occurrence of unbounded latencies and validate the effectiveness of our approach in avoiding them.         ",
    "url": "https://arxiv.org/abs/2504.01946",
    "authors": [
      "Teresa L\u00fcbeck",
      "Philipp Meyer",
      "Timo H\u00e4ckel",
      "Franz Korf",
      "Thomas C. Schmidt"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2504.01947",
    "title": "Efficient Federated Learning Tiny Language Models for Mobile Network Feature Prediction",
    "abstract": "           In telecommunications, Autonomous Networks (ANs) automatically adjust configurations based on specific requirements (e.g., bandwidth) and available resources. These networks rely on continuous monitoring and intelligent mechanisms for self-optimization, self-repair, and self-protection, nowadays enhanced by Neural Networks (NNs) to enable predictive modeling and pattern recognition. Here, Federated Learning (FL) allows multiple AN cells - each equipped with NNs - to collaboratively train models while preserving data privacy. However, FL requires frequent transmission of large neural data and thus an efficient, standardized compression strategy for reliable communication. To address this, we investigate NNCodec, a Fraunhofer implementation of the ISO/IEC Neural Network Coding (NNC) standard, within a novel FL framework that integrates tiny language models (TLMs) for various mobile network feature prediction (e.g., ping, SNR or band frequency). Our experimental results on the Berlin V2X dataset demonstrate that NNCodec achieves transparent compression (i.e., negligible performance loss) while reducing communication overhead to below 1%, showing the effectiveness of combining NNC with FL in collaboratively learned autonomous mobile networks.         ",
    "url": "https://arxiv.org/abs/2504.01947",
    "authors": [
      "Daniel Becking",
      "Ingo Friese",
      "Karsten M\u00fcller",
      "Thomas Buchholz",
      "Mandy Galkow-Schneider",
      "Wojciech Samek",
      "Detlev Marpe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2504.01953",
    "title": "Deep Representation Learning for Unsupervised Clustering of Myocardial Fiber Trajectories in Cardiac Diffusion Tensor Imaging",
    "abstract": "           Understanding the complex myocardial architecture is critical for diagnosing and treating heart disease. However, existing methods often struggle to accurately capture this intricate structure from Diffusion Tensor Imaging (DTI) data, particularly due to the lack of ground truth labels and the ambiguous, intertwined nature of fiber trajectories. We present a novel deep learning framework for unsupervised clustering of myocardial fibers, providing a data-driven approach to identifying distinct fiber bundles. We uniquely combine a Bidirectional Long Short-Term Memory network to capture local sequential information along fibers, with a Transformer autoencoder to learn global shape features, with pointwise incorporation of essential anatomical context. Clustering these representations using a density-based algorithm identifies 33 to 62 robust clusters, successfully capturing the subtle distinctions in fiber trajectories with varying levels of granularity. Our framework offers a new, flexible, and quantitative way to analyze myocardial structure, achieving a level of delineation that, to our knowledge, has not been previously achieved, with potential applications in improving surgical planning, characterizing disease-related remodeling, and ultimately, advancing personalized cardiac care.         ",
    "url": "https://arxiv.org/abs/2504.01953",
    "authors": [
      "Mohini Anand",
      "Xavier Tricoche"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01025",
    "title": "Diagnosis of Pulmonary Hypertension by Integrating Multimodal Data with a Hybrid Graph Convolutional and Transformer Network",
    "abstract": "           Early and accurate diagnosis of pulmonary hypertension (PH) is essential for optimal patient management. Differentiating between pre-capillary and post-capillary PH is critical for guiding treatment decisions. This study develops and validates a deep learning-based diagnostic model for PH, designed to classify patients as non-PH, pre-capillary PH, or post-capillary PH. This retrospective study analyzed data from 204 patients (112 with pre-capillary PH, 32 with post-capillary PH, and 60 non-PH controls) at the First Affiliated Hospital of Nanjing Medical University. Diagnoses were confirmed through right heart catheterization. We selected 6 samples from each category for the test set (18 samples, 10%), with the remaining 186 samples used for the training set. This process was repeated 35 times for testing. This paper proposes a deep learning model that combines Graph convolutional networks (GCN), Convolutional neural networks (CNN), and Transformers. The model was developed to process multimodal data, including short-axis (SAX) sequences, four-chamber (4CH) sequences, and clinical parameters. Our model achieved a performance of Area under the receiver operating characteristic curve (AUC) = 0.81 +- 0.06(standard deviation) and Accuracy (ACC) = 0.73 +- 0.06 on the test set. The discriminative abilities were as follows: non-PH subjects (AUC = 0.74 +- 0.11), pre-capillary PH (AUC = 0.86 +- 0.06), and post-capillary PH (AUC = 0.83 +- 0.10). It has the potential to support clinical decision-making by effectively integrating multimodal data to assist physicians in making accurate and timely diagnoses.         ",
    "url": "https://arxiv.org/abs/2504.01025",
    "authors": [
      "Fubao Zhu",
      "Yang Zhang",
      "Gengmin Liang",
      "Jiaofen Nan",
      "Yanting Li",
      "Chuang Han",
      "Danyang Sun",
      "Zhiguo Wang",
      "Chen Zhao",
      "Wenxuan Zhou",
      "Jian He",
      "Yi Xu",
      "Iokfai Cheang",
      "Xu Zhu",
      "Yanli Zhou",
      "Weihua Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2504.01030",
    "title": "Fair Sufficient Representation Learning",
    "abstract": "           The main objective of fair statistical modeling and machine learning is to minimize or eliminate biases that may arise from the data or the model itself, ensuring that predictions and decisions are not unjustly influenced by sensitive attributes such as race, gender, age, or other protected characteristics. In this paper, we introduce a Fair Sufficient Representation Learning (FSRL) method that balances sufficiency and fairness. Sufficiency ensures that the representation should capture all necessary information about the target variables, while fairness requires that the learned representation remains independent of sensitive attributes. FSRL is based on a convex combination of an objective function for learning a sufficient representation and an objective function that ensures fairness. Our approach manages fairness and sufficiency at the representation level, offering a novel perspective on fair representation learning. We implement this method using distance covariance, which is effective for characterizing independence between random variables. We establish the convergence properties of the learned representations. Experiments conducted on healthcase and text datasets with diverse structures demonstrate that FSRL achieves a superior trade-off between fairness and accuracy compared to existing approaches.         ",
    "url": "https://arxiv.org/abs/2504.01030",
    "authors": [
      "Xueyu Zhou",
      "Chun Yin IP",
      "Jian Huang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01038",
    "title": "An Integrated AI-Enabled System Using One Class Twin Cross Learning (OCT-X) for Early Gastric Cancer Detection",
    "abstract": "           Early detection of gastric cancer, a leading cause of cancer-related mortality worldwide, remains hampered by the limitations of current diagnostic technologies, leading to high rates of misdiagnosis and missed diagnoses. To address these challenges, we propose an integrated system that synergizes advanced hardware and software technologies to balance speed-accuracy. Our study introduces the One Class Twin Cross Learning (OCT-X) algorithm. Leveraging a novel fast double-threshold grid search strategy (FDT-GS) and a patch-based deep fully convolutional network, OCT-X maximizes diagnostic accuracy through real-time data processing and seamless lesion surveillance. The hardware component includes an all-in-one point-of-care testing (POCT) device with high-resolution imaging sensors, real-time data processing, and wireless connectivity, facilitated by the NI CompactDAQ and LabVIEW software. Our integrated system achieved an unprecedented diagnostic accuracy of 99.70%, significantly outperforming existing models by up to 4.47%, and demonstrated a 10% improvement in multirate adaptability. These findings underscore the potential of OCT-X as well as the integrated system in clinical diagnostics, offering a path toward more accurate, efficient, and less invasive early gastric cancer detection. Future research will explore broader applications, further advancing oncological diagnostics. Code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2504.01038",
    "authors": [
      "Xian-Xian Liu",
      "Yuanyuan Wei",
      "Mingkun Xu",
      "Yongze Guo",
      "Hongwei Zhang",
      "Huicong Dong",
      "Qun Song",
      "Qi Zhao",
      "Wei Luo",
      "Feng Tien",
      "Juntao Gao",
      "Simon Fong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2504.01274",
    "title": "BOLDSimNet: Examining Brain Network Similarity between Task and Resting-State fMRI",
    "abstract": "           Traditional causal connectivity methods in task-based and resting-state functional magnetic resonance imaging (fMRI) face challenges in accurately capturing directed information flow due to their sensitivity to noise and inability to model multivariate dependencies. These limitations hinder the effective comparison of brain networks between cognitive states, making it difficult to analyze network reconfiguration during task and resting states. To address these issues, we propose BOLDSimNet, a novel framework utilizing Multivariate Transfer Entropy (MTE) to measure causal connectivity and network similarity across different cognitive states. Our method groups functionally similar regions of interest (ROIs) rather than spatially adjacent nodes, improving accuracy in network alignment. We applied BOLDSimNet to fMRI data from 40 healthy controls and found that children exhibited higher similarity scores between task and resting states compared to adolescents, indicating reduced variability in attention shifts. In contrast, adolescents showed more differences between task and resting states in the Dorsal Attention Network (DAN) and the Default Mode Network (DMN), reflecting enhanced network adaptability. These findings emphasize developmental variations in the reconfiguration of the causal brain network, showcasing BOLDSimNet's ability to quantify network similarity and identify attentional fluctuations between different cognitive states.         ",
    "url": "https://arxiv.org/abs/2504.01274",
    "authors": [
      "Boseong Kim",
      "Debashis Das Chakladar",
      "Haejun Chung",
      "Ikbeom Jang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2504.01275",
    "title": "A Retina-Inspired Pathway to Real-Time Motion Prediction inside Image Sensors for Extreme-Edge Intelligence",
    "abstract": "           The ability to predict motion in real time is fundamental to many maneuvering activities in animals, particularly those critical for survival, such as attack and escape responses. Given its significance, it is no surprise that motion prediction in animals begins in the retina. Similarly, autonomous systems utilizing computer vision could greatly benefit from the capability to predict motion in real time. Therefore, for computer vision applications, motion prediction should be integrated directly at the camera pixel level. Towards that end, we present a retina-inspired neuromorphic framework capable of performing real-time, energy-efficient MP directly within camera pixels. Our hardware-algorithm framework, implemented using GlobalFoundries 22nm FDSOI technology, integrates key retinal MP compute blocks, including a biphasic filter, spike adder, nonlinear circuit, and a 2D array for multi-directional motion prediction. Additionally, integrating the sensor and MP compute die using a 3D Cu-Cu hybrid bonding approach improves design compactness by minimizing area usage and simplifying routing complexity. Validated on real-world object stimuli, the model delivers efficient, low-latency MP for decision-making scenarios reliant on predictive visual computation, while consuming only 18.56 pJ/MP in our mixed-signal hardware implementation.         ",
    "url": "https://arxiv.org/abs/2504.01275",
    "authors": [
      "Subhradip Chakraborty",
      "Shay Snyder",
      "Md Abdullah-Al Kaiser",
      "Maryam Parsa",
      "Gregory Schwartz",
      "Akhilesh R. Jaiswal"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2504.01446",
    "title": "Deep Graph Reinforcement Learning for UAV-Enabled Multi-User Secure Communications",
    "abstract": "           While unmanned aerial vehicles (UAVs) with flexible mobility are envisioned to enhance physical layer security in wireless communications, the efficient security design that adapts to such high network dynamics is rather challenging. The conventional approaches extended from optimization perspectives are usually quite involved, especially when jointly considering factors in different scales such as deployment and transmission in UAV-related scenarios. In this paper, we address the UAV-enabled multi-user secure communications by proposing a deep graph reinforcement learning framework. Specifically, we reinterpret the security beamforming as a graph neural network (GNN) learning task, where mutual interference among users is managed through the message-passing mechanism. Then, the UAV deployment is obtained through soft actor-critic reinforcement learning, where the GNN-based security beamforming is exploited to guide the deployment strategy update. Simulation results demonstrate that the proposed approach achieves near-optimal security performance and significantly enhances the efficiency of strategy determination. Moreover, the deep graph reinforcement learning framework offers a scalable solution, adaptable to various network scenarios and configurations, establishing a robust basis for information security in UAV-enabled communications.         ",
    "url": "https://arxiv.org/abs/2504.01446",
    "authors": [
      "Xiao Tang",
      "Kexin Zhao",
      "Chao Shen",
      "Qinghe Du",
      "Yichen Wang",
      "Dusit Niyato",
      "Zhu Han"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2504.01532",
    "title": "Incorporating Coupling Knowledge into Echo State Networks for Learning Spatiotemporally Chaotic Dynamics",
    "abstract": "           Machine learning methods have shown promise in learning chaotic dynamical systems, enabling model-free short-term prediction and attractor reconstruction. However, when applied to large-scale, spatiotemporally chaotic systems, purely data-driven machine learning methods often suffer from inefficiencies, as they require a large learning model size and a massive amount of training data to achieve acceptable performance. To address this challenge, we incorporate the spatial coupling structure of the target system as an inductive bias in the network design. Specifically, we introduce physics-guided clustered echo state networks, leveraging the efficiency of the echo state networks as a base model. Experimental results on benchmark chaotic systems demonstrate that our physics-informed method outperforms existing echo state network models in learning the target chaotic systems. Additionally, our models exhibit robustness to noise in training data and remain effective even when prior coupling knowledge is imperfect. This approach has the potential to enhance other machine learning methods.         ",
    "url": "https://arxiv.org/abs/2504.01532",
    "authors": [
      "Kuei-Jan Chu",
      "Nozomi Akashi",
      "Akihiro Yamamoto"
    ],
    "subjectives": [
      "Chaotic Dynamics (nlin.CD)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01561",
    "title": "STPNet: Scale-aware Text Prompt Network for Medical Image Segmentation",
    "abstract": "           Accurate segmentation of lesions plays a critical role in medical image analysis and diagnosis. Traditional segmentation approaches that rely solely on visual features often struggle with the inherent uncertainty in lesion distribution and size. To address these issues, we propose STPNet, a Scale-aware Text Prompt Network that leverages vision-language modeling to enhance medical image segmentation. Our approach utilizes multi-scale textual descriptions to guide lesion localization and employs retrieval-segmentation joint learning to bridge the semantic gap between visual and linguistic modalities. Crucially, STPNet retrieves relevant textual information from a specialized medical text repository during training, eliminating the need for text input during inference while retaining the benefits of cross-modal learning. We evaluate STPNet on three datasets: COVID-Xray, COVID-CT, and Kvasir-SEG. Experimental results show that our vision-language approach outperforms state-of-the-art segmentation methods, demonstrating the effectiveness of incorporating textual semantic knowledge into medical image analysis. The code has been made publicly on this https URL.         ",
    "url": "https://arxiv.org/abs/2504.01561",
    "authors": [
      "Dandan Shan",
      "Zihan Li",
      "Yunxiang Li",
      "Qingde Li",
      "Jie Tian",
      "Qingqi Hong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2504.01650",
    "title": "Sparse Gaussian Neural Processes",
    "abstract": "           Despite significant recent advances in probabilistic meta-learning, it is common for practitioners to avoid using deep learning models due to a comparative lack of interpretability. Instead, many practitioners simply use non-meta-models such as Gaussian processes with interpretable priors, and conduct the tedious procedure of training their model from scratch for each task they encounter. While this is justifiable for tasks with a limited number of data points, the cubic computational cost of exact Gaussian process inference renders this prohibitive when each task has many observations. To remedy this, we introduce a family of models that meta-learn sparse Gaussian process inference. Not only does this enable rapid prediction on new tasks with sparse Gaussian processes, but since our models have clear interpretations as members of the neural process family, it also allows manual elicitation of priors in a neural process for the first time. In meta-learning regimes for which the number of observed tasks is small or for which expert domain knowledge is available, this offers a crucial advantage.         ",
    "url": "https://arxiv.org/abs/2504.01650",
    "authors": [
      "Tommy Rochussen",
      "Vincent Fortuin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01673",
    "title": "K-P Quantum Neural Networks",
    "abstract": "           We present an extension of K-P time-optimal quantum control solutions using global Cartan $KAK$ decompositions for geodesic-based solutions. Extending recent time-optimal \\emph{constant-$\\theta$} control results, we integrate Cartan methods into equivariant quantum neural network (EQNN) for quantum control tasks. We show that a finite-depth limited EQNN ansatz equipped with Cartan layers can replicate the constant-$\\theta$ sub-Riemannian geodesics for K-P problems. We demonstrate how for certain classes of control problem on Riemannian symmetric spaces, gradient-based training using an appropriate cost function converges to certain global time-optimal solutions when satisfying simple regularity conditions. This generalises prior geometric control theory methods and clarifies how optimal geodesic estimation can be performed in quantum machine learning contexts.         ",
    "url": "https://arxiv.org/abs/2504.01673",
    "authors": [
      "Elija Perrier"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2504.01702",
    "title": "A Causal Inference Framework for Data Rich Environments",
    "abstract": "           We propose a formal model for counterfactual estimation with unobserved confounding in \"data-rich\" settings, i.e., where there are a large number of units and a large number of measurements per unit. Our model provides a bridge between the structural causal model view of causal inference common in the graphical models literature with that of the latent factor model view common in the potential outcomes literature. We show how classic models for potential outcomes and treatment assignments fit within our framework. We provide an identification argument for the average treatment effect, the average treatment effect on the treated, and the average treatment effect on the untreated. For any estimator that has a fast enough estimation error rate for a certain nuisance parameter, we establish it is consistent for these various causal parameters. We then show principal component regression is one such estimator that leads to consistent estimation, and we analyze the minimal smoothness required of the potential outcomes function for consistency.         ",
    "url": "https://arxiv.org/abs/2504.01702",
    "authors": [
      "Alberto Abadie",
      "Anish Agarwal",
      "Devavrat Shah"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2504.01767",
    "title": "Leveraging Embedding Techniques in Multimodal Machine Learning for Mental Illness Assessment",
    "abstract": "           The increasing global prevalence of mental disorders, such as depression and PTSD, requires objective and scalable diagnostic tools. Traditional clinical assessments often face limitations in accessibility, objectivity, and consistency. This paper investigates the potential of multimodal machine learning to address these challenges, leveraging the complementary information available in text, audio, and video data. Our approach involves a comprehensive analysis of various data preprocessing techniques, including novel chunking and utterance-based formatting strategies. We systematically evaluate a range of state-of-the-art embedding models for each modality and employ Convolutional Neural Networks (CNNs) and Bidirectional LSTM Networks (BiLSTMs) for feature extraction. We explore data-level, feature-level, and decision-level fusion techniques, including a novel integration of Large Language Model (LLM) predictions. We also investigate the impact of replacing Multilayer Perceptron classifiers with Support Vector Machines. We extend our analysis to severity prediction using PHQ-8 and PCL-C scores and multi-class classification (considering co-occurring conditions). Our results demonstrate that utterance-based chunking significantly improves performance, particularly for text and audio modalities. Decision-level fusion, incorporating LLM predictions, achieves the highest accuracy, with a balanced accuracy of 94.8% for depression and 96.2% for PTSD detection. The combination of CNN-BiLSTM architectures with utterance-level chunking, coupled with the integration of external LLM, provides a powerful and nuanced approach to the detection and assessment of mental health conditions. Our findings highlight the potential of MMML for developing more accurate, accessible, and personalized mental healthcare tools.         ",
    "url": "https://arxiv.org/abs/2504.01767",
    "authors": [
      "Abdelrahaman A. Hassan",
      "Abdelrahman A. Ali",
      "Aya E. Fouda",
      "Radwa J. Hanafy",
      "Mohammed E. Fouda"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2504.01835",
    "title": "Autonomous optical navigation for DESTINY+: Enhancing misalignment robustness in flyby observations with a rotating telescope",
    "abstract": "           DESTINY+ is an upcoming JAXA Epsilon medium-class mission to flyby multiple asteroids including Phaethon. As an asteroid flyby observation instrument, a telescope mechanically capable of single-axis rotation, named TCAP, is mounted on the spacecraft to track and observe the target asteroids during flyby. As in past flyby missions utilizing rotating telescopes, TCAP is also used as a navigation camera for autonomous optical navigation during the closest-approach phase. To mitigate the degradation of the navigation accuracy, past missions performed calibration of the navigation camera's alignment before starting optical navigation. However, such calibration requires significant operational time to complete and imposes constraints on the operation sequence. From the above background, the DESTINY+ team has studied the possibility of reducing operational costs by allowing TCAP alignment errors to remain. This paper describes an autonomous optical navigation algorithm robust to the misalignment of rotating telescopes, proposed in this context. In the proposed method, the misalignment of the telescope is estimated simultaneously with the spacecraft's orbit relative to the flyby target. To deal with the nonlinearity between the misalignment and the observation value, the proposed method utilizes the unscented Kalman filter, instead of the extended Kalman filter widely used in past studies. The proposed method was evaluated with numerical simulations on a PC and with hardware-in-the-loop simulation, taking the Phaethon flyby in the DESTINY+ mission as an example. The validation results suggest that the proposed method can mitigate the misalignment-induced degradation of the optical navigation accuracy with reasonable computational costs suited for onboard computers.         ",
    "url": "https://arxiv.org/abs/2504.01835",
    "authors": [
      "Takayuki Hosonuma",
      "Takeshi Miyabara",
      "Naoya Ozaki",
      "Ko Ishibashi",
      "Yuta Suzaki",
      "Peng Hong",
      "Masayuki Ohta",
      "Takeshi Takashima"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.01839",
    "title": "A Randomized Zeroth-Order Hierarchical Framework for Heterogeneous Federated Learning",
    "abstract": "           Heterogeneity in federated learning (FL) is a critical and challenging aspect that significantly impacts model performance and convergence. In this paper, we propose a novel framework by formulating heterogeneous FL as a hierarchical optimization problem. This new framework captures both local and global training process through a bilevel formulation and is capable of the following: (i) addressing client heterogeneity through a personalized learning framework; (ii) capturing pre-training process on server's side; (iii) updating global model through nonstandard aggregation; (iv) allowing for nonidentical local steps; and (v) capturing clients' local constraints. We design and analyze an implicit zeroth-order FL method (ZO-HFL), provided with nonasymptotic convergence guarantees for both the server-agent and the individual client-agents, and asymptotic guarantees for both the server-agent and client-agents in an almost sure sense. Notably, our method does not rely on standard assumptions in heterogeneous FL, such as the bounded gradient dissimilarity condition. We implement our method on image classification tasks and compare with other methods under different heterogeneous settings.         ",
    "url": "https://arxiv.org/abs/2504.01839",
    "authors": [
      "Yuyang Qiu",
      "Kibaek Kim",
      "Farzad Yousefian"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2005.05274",
    "title": "Normalized Convolutional Neural Network",
    "abstract": "           We introduce a Normalized Convolutional Neural Layer, a novel approach to normalization in convolutional networks. Unlike conventional methods, this layer normalizes the rows of the im2col matrix during convolution, making it inherently adaptive to sliced inputs and better aligned with kernel structures. This distinctive approach differentiates it from standard normalization techniques and prevents direct integration into existing deep learning frameworks optimized for traditional convolution operations. Our method has a universal property, making it applicable to any deep learning task involving convolutional layers. By inherently normalizing within the convolution process, it serves as a convolutional adaptation of Self-Normalizing Networks, maintaining their core principles without requiring additional normalization layers. Notably, in micro-batch training scenarios, it consistently outperforms other batch-independent normalization methods. This performance boost arises from standardizing the rows of the im2col matrix, which theoretically leads to a smoother loss gradient and improved training stability.         ",
    "url": "https://arxiv.org/abs/2005.05274",
    "authors": [
      "Dongsuk Kim",
      "Geonhee Lee",
      "Myungjae Lee",
      "Shin Uk Kang",
      "Dongmin Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.06986",
    "title": "Provable Guarantees for Nonlinear Feature Learning in Three-Layer Neural Networks",
    "abstract": "           One of the central questions in the theory of deep learning is to understand how neural networks learn hierarchical features. The ability of deep networks to extract salient features is crucial to both their outstanding generalization ability and the modern deep learning paradigm of pretraining and finetuneing. However, this feature learning process remains poorly understood from a theoretical perspective, with existing analyses largely restricted to two-layer networks. In this work we show that three-layer neural networks have provably richer feature learning capabilities than two-layer networks. We analyze the features learned by a three-layer network trained with layer-wise gradient descent, and present a general purpose theorem which upper bounds the sample complexity and width needed to achieve low test error when the target has specific hierarchical structure. We instantiate our framework in specific statistical learning settings -- single-index models and functions of quadratic features -- and show that in the latter setting three-layer networks obtain a sample complexity improvement over all existing guarantees for two-layer networks. Crucially, this sample complexity improvement relies on the ability of three-layer networks to efficiently learn nonlinear features. We then establish a concrete optimization-based depth separation by constructing a function which is efficiently learnable via gradient descent on a three-layer network, yet cannot be learned efficiently by a two-layer network. Our work makes progress towards understanding the provable benefit of three-layer neural networks over two-layer networks in the feature learning regime.         ",
    "url": "https://arxiv.org/abs/2305.06986",
    "authors": [
      "Eshaan Nichani",
      "Alex Damian",
      "Jason D. Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.05700",
    "title": "In Pursuit of Privacy: The Value-Centered Privacy Assistant",
    "abstract": "           Many users make quick decisions that affect their data privacy without due consideration of their values. One such decision is whether to download a smartphone app to their device. Previous work has suggested a relationship between values, privacy preferences, and app choices, and proposed a value-centered approach to privacy that conceptually unites these relationships. In this work, we translate this theory into practice by constructing a prototype smartphone value-centered privacy assistant (VcPA) - a privacy assistant system that promotes user privacy decisions based on personal values. To do this, we designed and conducted an online survey that captured values and privacy preferences when considering whether to download an app from 273 smartphone users. Using this data, we constructed VcPA user profiles by clustering survey data based on the value rankings and stated privacy preferences. We then tested the VcPA, using selective notices, a \"suggest alternatives\" feature, and exploratory notices, with 77 users in a synthetic Mock App Store (MAS) setting and conducted follow-up semi-structured interviews. We establish proof-of-concept that a VcPA helps users make more value-centered app choices and identified improvements so that an assistant can be deployed on smartphone app stores.         ",
    "url": "https://arxiv.org/abs/2308.05700",
    "authors": [
      "Sarah E. Carter",
      "Mathieu d'Aquin",
      "Dayana Spagnuelo",
      "Ilaria Tiddi",
      "Kathryn Cormican",
      "Heike Felzmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2312.05276",
    "title": "Making Large Language Models Better Knowledge Miners for Online Marketing with Progressive Prompting Augmentation",
    "abstract": "           Nowadays, the rapid development of mobile economy has promoted the flourishing of online marketing campaigns, whose success greatly hinges on the efficient matching between user preferences and desired marketing campaigns where a well-established Marketing-oriented Knowledge Graph (dubbed as MoKG) could serve as the critical \"bridge\" for preference propagation. In this paper, we seek to carefully prompt a Large Language Model (LLM) with domain-level knowledge as a better marketing-oriented knowledge miner for marketing-oriented knowledge graph construction, which is however non-trivial, suffering from several inevitable issues in real-world marketing scenarios, i.e., uncontrollable relation generation of LLMs,insufficient prompting ability of a single prompt, the unaffordable deployment cost of LLMs. To this end, we propose PAIR, a novel Progressive prompting Augmented mIning fRamework for harvesting marketing-oriented knowledge graph with LLMs. In particular, we reduce the pure relation generation to an LLM based adaptive relation filtering process through the knowledge-empowered prompting technique. Next, we steer LLMs for entity expansion with progressive prompting augmentation,followed by a reliable aggregation with comprehensive consideration of both self-consistency and semantic relatedness. In terms of online serving, we specialize in a small and white-box PAIR (i.e.,LightPAIR),which is fine-tuned with a high-quality corpus provided by a strong teacher-LLM. Extensive experiments and practical applications in audience targeting verify the effectiveness of the proposed (Light)PAIR.         ",
    "url": "https://arxiv.org/abs/2312.05276",
    "authors": [
      "Chunjing Gan",
      "Dan Yang",
      "Binbin Hu",
      "Ziqi Liu",
      "Yue Shen",
      "Zhiqiang Zhang",
      "Jinjie Gu",
      "Jun Zhou",
      "Guannan Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.07261",
    "title": "LookAhead: Preventing DeFi Attacks via Unveiling Adversarial Contracts",
    "abstract": "           Decentralized Finance (DeFi) incidents stemming from the exploitation of smart contract vulnerabilities have culminated in financial damages exceeding 3 billion US dollars. Existing defense mechanisms typically focus on detecting and reacting to malicious transactions executed by attackers that target victim contracts. However, with the emergence of private transaction pools where transactions are sent directly to miners without first appearing in public mempools, current detection tools face significant challenges in identifying attack activities effectively. Based on the fact that most attack logic rely on deploying one or more intermediate smart contracts as supporting components to the exploitation of victim contracts, detection methods have been proposed that focus on identifying these adversarial contracts instead of adversarial transactions. However, previous state-of-the-art approaches in this direction have failed to produce results satisfactory enough for real-world deployment. In this paper, we propose a new framework for effectively detecting DeFi attacks via unveiling adversarial contracts. Our approach allows us to leverage common attack patterns, code semantics and intrinsic characteristics found in malicious smart contracts to build the LookAhead system based on Machine Learning (ML) classifiers and a transformer model that is able to effectively distinguish adversarial contracts from benign ones, and make timely predictions of different types of potential attacks. Experiments show that LookAhead achieves an F1-score as high as 0.8966, which represents an improvement of over 44.4% compared to the previous state-of-the-art solution Forta, with a False Positive Rate (FPR) at only 0.16%.         ",
    "url": "https://arxiv.org/abs/2401.07261",
    "authors": [
      "Shoupeng Ren",
      "Lipeng He",
      "Tianyu Tu",
      "Di Wu",
      "Jian Liu",
      "Kui Ren",
      "Chun Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.18370",
    "title": "Adversarial Example Soups: Improving Transferability and Stealthiness for Free",
    "abstract": "           Transferable adversarial examples cause practical security risks since they can mislead a target model without knowing its internal knowledge. A conventional recipe for maximizing transferability is to keep only the optimal adversarial example from all those obtained in the optimization pipeline. In this paper, for the first time, we revisit this convention and demonstrate that those discarded, sub-optimal adversarial examples can be reused to boost transferability. Specifically, we propose ``Adversarial Example Soups'' (AES), with AES-tune for averaging discarded adversarial examples in hyperparameter tuning and AES-rand for stability testing. In addition, our AES is inspired by ``model soups'', which averages weights of multiple fine-tuned models for improved accuracy without increasing inference time. Extensive experiments validate the global effectiveness of our AES, boosting 10 state-of-the-art transfer attacks and their combinations by up to 13\\% against 10 diverse (defensive) target models. We also show the possibility of generalizing AES to other types, \\textit{e.g.}, directly averaging multiple in-the-wild adversarial examples that yield comparable success. A promising byproduct of AES is the improved stealthiness of adversarial examples since the perturbation variances are naturally reduced.         ",
    "url": "https://arxiv.org/abs/2402.18370",
    "authors": [
      "Bo Yang",
      "Hengwei Zhang",
      "Jindong Wang",
      "Yulong Yang",
      "Chenhao Lin",
      "Chao Shen",
      "Zhengyu Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.02998",
    "title": "Towards Calibrated Deep Clustering Network",
    "abstract": "           Deep clustering has exhibited remarkable performance; however, the over confidence problem, i.e., the estimated confidence for a sample belonging to a particular cluster greatly exceeds its actual prediction accuracy, has been over looked in prior research. To tackle this critical issue, we pioneer the development of a calibrated deep clustering framework. Specifically, we propose a novel dual head (calibration head and clustering head) deep clustering model that can effectively calibrate the estimated confidence and the actual accuracy. The calibration head adjusts the overconfident predictions of the clustering head, generating prediction confidence that matches the model learning status. Then, the clustering head dynamically selects reliable high-confidence samples estimated by the calibration head for pseudo-label self-training. Additionally, we introduce an effective network initialization strategy that enhances both training speed and network robustness. The effectiveness of the proposed calibration approach and initialization strategy are both endorsed with solid theoretical guarantees. Extensive experiments demonstrate the proposed calibrated deep clustering model not only surpasses the state-of-the-art deep clustering methods by 5x on average in terms of expected calibration error, but also significantly outperforms them in terms of clustering accuracy. The code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2403.02998",
    "authors": [
      "Yuheng Jia",
      "Jianhong Cheng",
      "Hui Liu",
      "Junhui Hou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.03876",
    "title": "A Survey on Adversarial Contention Resolution",
    "abstract": "           Contention resolution addresses the challenge of coordinating access by multiple processes to a shared resource such as memory, disk storage, or a communication channel. Originally spurred by challenges in database systems and bus networks, contention resolution has endured as an important abstraction for resource sharing, despite decades of technological change. Here, we survey the literature on resolving worst-case contention, where the number of processes and the time at which each process may start seeking access to the resource is dictated by an adversary. We also highlight the evolution of contention resolution, where new concerns -- such as security, quality of service, and energy efficiency -- are motivated by modern systems. These efforts have yielded insights into the limits of randomized and deterministic approaches, as well as the impact of different model assumptions such as global clock synchronization, knowledge of the number of processors, feedback from access attempts, and attacks on the availability of the shared resource.         ",
    "url": "https://arxiv.org/abs/2403.03876",
    "authors": [
      "Ioana Banicescu",
      "Trisha Chakraborty",
      "Seth Gilbert",
      "Maxwell Young"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2403.04443",
    "title": "FriendNet: Detection-Friendly Dehazing Network",
    "abstract": "           Adverse weather conditions often impair the quality of captured images, inevitably inducing cutting-edge object detection models for advanced driver assistance systems (ADAS) and autonomous driving. In this paper, we raise an intriguing question: can the combination of image restoration and object detection enhance detection performance in adverse weather conditions? To answer it, we propose an effective architecture that bridges image dehazing and object detection together via guidance information and task-driven learning to achieve detection-friendly dehazing, termed FriendNet. FriendNet aims to deliver both high-quality perception and high detection capacity. Different from existing efforts that intuitively treat image dehazing as pre-processing, FriendNet establishes a positive correlation between these two tasks. Clean features generated by the dehazing network potentially contribute to improvements in object detection performance. Conversely, object detection crucially guides the learning process of the image dehazing network under the task-driven learning scheme. We shed light on how downstream tasks can guide upstream dehazing processes, considering both network architecture and learning objectives. We design Guidance Fusion Block (GFB) and Guidance Attention Block (GAB) to facilitate the integration of detection information into the network. Furthermore, the incorporation of the detection task loss aids in refining the optimization process. Additionally, we introduce a new Physics-aware Feature Enhancement Block (PFEB), which integrates physics-based priors to enhance the feature extraction and representation capabilities. Extensive experiments on synthetic and real-world datasets demonstrate the superiority of our method over state-of-the-art methods on both image quality and detection precision. Our source code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2403.04443",
    "authors": [
      "Yihua Fan",
      "Yongzhen Wang",
      "Mingqiang Wei",
      "Fu Lee Wang",
      "Haoran Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2405.14325",
    "title": "Dinomaly: The Less Is More Philosophy in Multi-Class Unsupervised Anomaly Detection",
    "abstract": "           Recent studies highlighted a practical setting of unsupervised anomaly detection (UAD) that builds a unified model for multi-class images. Despite various advancements addressing this challenging task, the detection performance under the multi-class setting still lags far behind state-of-the-art class-separated models. Our research aims to bridge this substantial performance gap. In this paper, we introduce a minimalistic reconstruction-based anomaly detection framework, namely Dinomaly, which leverages pure Transformer architectures without relying on complex designs, additional modules, or specialized tricks. Given this powerful framework consisted of only Attentions and MLPs, we found four simple components that are essential to multi-class anomaly detection: (1) Foundation Transformers that extracts universal and discriminative features, (2) Noisy Bottleneck where pre-existing Dropouts do all the noise injection tricks, (3) Linear Attention that naturally cannot focus, and (4) Loose Reconstruction that does not force layer-to-layer and point-by-point reconstruction. Extensive experiments are conducted across popular anomaly detection benchmarks including MVTec-AD, VisA, and Real-IAD. Our proposed Dinomaly achieves impressive image-level AUROC of 99.6%, 98.7%, and 89.3% on the three datasets respectively, which is not only superior to state-of-the-art multi-class UAD methods, but also achieves the most advanced class-separated UAD records.         ",
    "url": "https://arxiv.org/abs/2405.14325",
    "authors": [
      "Jia Guo",
      "Shuai Lu",
      "Weihang Zhang",
      "Fang Chen",
      "Huiqi Li",
      "Hongen Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.14977",
    "title": "Trustworthy Enhanced Multi-view Multi-modal Alzheimer's Disease Prediction with Brain-wide Imaging Transcriptomics Data",
    "abstract": "           Brain transcriptomics provides insights into the molecular mechanisms by which the brain coordinates its functions and processes. However, existing multimodal methods for predicting Alzheimer's disease (AD) primarily rely on imaging and sometimes genetic data, often neglecting the transcriptomic basis of brain. Furthermore, while striving to integrate complementary information between modalities, most studies overlook the informativeness disparities between modalities. Here, we propose TMM, a trusted multiview multimodal graph attention framework for AD diagnosis, using extensive brain-wide transcriptomics and imaging data. First, we construct view-specific brain regional co-function networks (RRIs) from transcriptomics and multimodal radiomics data to incorporate interaction information from both biomolecular and imaging perspectives. Next, we apply graph attention (GAT) processing to each RRI network to produce graph embeddings and employ cross-modal attention to fuse transcriptomics-derived embedding with each imagingderived embedding. Finally, a novel true-false-harmonized class probability (TFCP) strategy is designed to assess and adaptively adjust the prediction confidence of each modality for AD diagnosis. We evaluate TMM using the AHBA database with brain-wide transcriptomics data and the ADNI database with three imaging modalities (AV45-PET, FDG-PET, and VBM-MRI). The results demonstrate the superiority of our method in identifying AD, EMCI, and LMCI compared to state-of-the-arts. Code and data are available at this https URL.         ",
    "url": "https://arxiv.org/abs/2406.14977",
    "authors": [
      "Shan Cong",
      "Zhoujie Fan",
      "Hongwei Liu",
      "Yinghan Zhang",
      "Xin Wang",
      "Haoran Luo",
      "Xiaohui Yao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2406.16959",
    "title": "Recurrent Stochastic Configuration Networks for Temporal Data Analytics",
    "abstract": "           Temporal data modelling techniques with neural networks are useful in many domain applications, including time-series forecasting and control engineering. This paper aims at developing a recurrent version of stochastic configuration networks (RSCNs) for problem solving, where we have no underlying assumption on the dynamic orders of the input variables. Given a collection of historical data, we first build an initial RSCN model in the light of a supervisory mechanism, followed by an online update of the output weights by using a projection algorithm. Some theoretical results are established, including the echo state property, the universal approximation property of RSCNs for both the offline and online learnings, and the convergence of the output weights. The proposed RSCN model is remarkably distinguished from the well-known echo state networks (ESNs) in terms of the way of assigning the input random weight matrix and a special structure of the random feedback matrix. A comprehensive comparison study among the long short-term memory (LSTM) network, the original ESN, and several state-of-the-art ESN methods such as the simple cycle reservoir (SCR), the polynomial ESN (PESN), the leaky-integrator ESN (LIESN) and RSCN is carried out. Numerical results clearly indicate that the proposed RSCN performs favourably over all of the datasets.         ",
    "url": "https://arxiv.org/abs/2406.16959",
    "authors": [
      "Dianhui Wang",
      "Gang Dang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2407.07065",
    "title": "Distribution System Reconfiguration to Mitigate Load Altering Attacks via Stackelberg Games",
    "abstract": "           The integration of IoT-controllable devices in power systems (such as smart electric vehicle charging stations, heat pumps, etc.), despite their benefits, raises novel cybersecurity concerns. Vulnerabilities in these devices can be leveraged to launch load-altering attacks (LAAs) that can potentially compromise the safety of power systems. In this paper, we analyze the impact of LAAs on the voltage profile of distribution networks (DNs). We first derive closed-form expressions to quantify the attacks' impact. Using the insights derived from this analysis, we then propose a reactive defense method to mitigate LAAs based on reconfiguring the DNs. We also study optimal defense strategies that are robust to LAAs by exploiting non-cooperative sequential game theory. The proposed solution takes into account the potential uncertainties in the attack localization. Furthermore, we propose a Bayesian optimization (BO) approach to compute the equilibrium of the game, which reduces the computational burden. Our results show that attacks launched on the deepest nodes in the DN have the most detrimental effect on the grid voltage profile. Furthermore, the proposed game-theoretic strategy successfully mitigates the effect of the attack while ensuring minimum system reconfiguration.         ",
    "url": "https://arxiv.org/abs/2407.07065",
    "authors": [
      "Sajjad Maleki",
      "E. Veronica Belmaga",
      "Charalambos Konstantinou",
      "Subhash Lakshminarayana"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2408.00490",
    "title": "Graph Representation Learning via Causal Diffusion for Out-of-Distribution Recommendation",
    "abstract": "           Graph Neural Networks (GNNs)-based recommendation algorithms typically assume that training and testing data are drawn from independent and identically distributed (IID) spaces. However, this assumption often fails in the presence of out-of-distribution (OOD) data, resulting in significant performance degradation. In this study, we construct a Structural Causal Model (SCM) to analyze interaction data, revealing that environmental confounders (e.g., the COVID-19 pandemic) lead to unstable correlations in GNN-based models, thus impairing their generalization to OOD data. To address this issue, we propose a novel approach, graph representation learning via causal diffusion (CausalDiffRec) for OOD recommendation. This method enhances the model's generalization on OOD data by eliminating environmental confounding factors and learning invariant graph representations. Specifically, we use backdoor adjustment and variational inference to infer the real environmental distribution, thereby eliminating the impact of environmental confounders. This inferred distribution is then used as prior knowledge to guide the representation learning in the reverse phase of the diffusion process to learn the invariant representation. In addition, we provide a theoretical derivation that proves optimizing the objective function of CausalDiffRec can encourage the model to learn environment-invariant graph representations, thereby achieving excellent generalization performance in recommendations under distribution shifts. Our extensive experiments validate the effectiveness of CausalDiffRec in improving the generalization of OOD data, and the average improvement is up to 10.69% on Food, 18.83% on KuaiRec, 22.41% on Yelp2018, and 11.65% on Douban datasets.         ",
    "url": "https://arxiv.org/abs/2408.00490",
    "authors": [
      "Chu Zhao",
      "Enneng Yang",
      "Yuliang Liang",
      "Pengxiang Lan",
      "Yuting Liu",
      "Jianzhe Zhao",
      "Guibing Guo",
      "Xingwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2408.06481",
    "title": "UniT: Data Efficient Tactile Representation with Generalization to Unseen Objects",
    "abstract": "           UniT is an approach to tactile representation learning, using VQGAN to learn a compact latent space and serve as the tactile representation. It uses tactile images obtained from a single simple object to train the representation with generalizability. This tactile representation can be zero-shot transferred to various downstream tasks, including perception tasks and manipulation policy learning. Our benchmarkings on in-hand 3D pose and 6D pose estimation tasks and a tactile classification task show that UniT outperforms existing visual and tactile representation learning methods. Additionally, UniT's effectiveness in policy learning is demonstrated across three real-world tasks involving diverse manipulated objects and complex robot-object-environment interactions. Through extensive experimentation, UniT is shown to be a simple-to-train, plug-and-play, yet widely effective method for tactile representation learning. For more details, please refer to our open-source repository this https URL and the project website this https URL.         ",
    "url": "https://arxiv.org/abs/2408.06481",
    "authors": [
      "Zhengtong Xu",
      "Raghava Uppuluri",
      "Xinwei Zhang",
      "Cael Fitch",
      "Philip Glen Crandall",
      "Wan Shou",
      "Dongyi Wang",
      "Yu She"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2408.10561",
    "title": "ICSD: An Open-source Dataset for Infant Cry and Snoring Detection",
    "abstract": "           The detection and analysis of infant cry and snoring events are crucial tasks within the field of audio signal processing. While existing datasets for general sound event detection are plentiful, they often fall short in providing sufficient, strongly labeled data specific to infant cries and snoring. To provide a benchmark dataset and thus foster the research of infant cry and snoring detection, this paper introduces the Infant Cry and Snoring Detection (ICSD) dataset, a novel, publicly available dataset specially designed for ICSD tasks. The ICSD comprises three types of subsets: a real strongly labeled subset with event-based labels annotated manually, a weakly labeled subset with only clip-level event annotations, and a synthetic subset generated and labeled with strong annotations. This paper provides a detailed description of the ICSD creation process, including the challenges encountered and the solutions adopted. We offer a comprehensive characterization of the dataset, discussing its limitations and key factors for ICSD usage. Additionally, we conduct extensive experiments on the ICSD dataset to establish baseline systems and offer insights into the main factors when using this dataset for ICSD research. Our goal is to develop a dataset that will be widely adopted by the community as a new open benchmark for future ICSD research.         ",
    "url": "https://arxiv.org/abs/2408.10561",
    "authors": [
      "Qingyu Liu",
      "Longfei Song",
      "Dongxing Xu",
      "Yanhua Long"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2408.16807",
    "title": "STEREO: A Two-Stage Framework for Adversarially Robust Concept Erasing from Text-to-Image Diffusion Models",
    "abstract": "           The rapid proliferation of large-scale text-to-image diffusion (T2ID) models has raised serious concerns about their potential misuse in generating harmful content. Although numerous methods have been proposed for erasing undesired concepts from T2ID models, they often provide a false sense of security; concept-erased models (CEMs) can still be manipulated via adversarial attacks to regenerate the erased concept. While a few robust concept erasure methods based on adversarial training have emerged recently, they compromise on utility (generation quality for benign concepts) to achieve robustness and/or remain vulnerable to advanced embedding space attacks. These limitations stem from the failure of robust CEMs to thoroughly search for \"blind spots\" in the embedding space. To bridge this gap, we propose STEREO, a novel two-stage framework that employs adversarial training as a first step rather than the only step for robust concept erasure. In the first stage, STEREO employs adversarial training as a vulnerability identification mechanism to search thoroughly enough. In the second robustly erase once stage, STEREO introduces an anchor-concept-based compositional objective to robustly erase the target concept in a single fine-tuning stage, while minimizing the degradation of model utility. We benchmark STEREO against seven state-of-the-art concept erasure methods, demonstrating its superior robustness to both white-box and black-box attacks, while largely preserving utility.         ",
    "url": "https://arxiv.org/abs/2408.16807",
    "authors": [
      "Koushik Srivatsan",
      "Fahad Shamshad",
      "Muzammal Naseer",
      "Vishal M. Patel",
      "Karthik Nandakumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2409.00822",
    "title": "RTop-K: Ultra-Fast Row-Wise Top-K Selection for Neural Network Acceleration on GPUs",
    "abstract": "           Top-k selection algorithms are fundamental in a wide range of applications, including high-performance computing, information retrieval, big data processing, and neural network model training. In this paper, we present RTop-K, a highly efficient parallel row-wise top-k selection algorithm specifically designed for GPUs. RTop-K leverages a binary search-based approach to optimize row-wise top-k selection, providing a scalable and accelerated solution. We conduct a detailed analysis of early stopping in our algorithm, showing that it effectively maintains the testing accuracy of neural network models while substantially improving performance. Our GPU implementation of RTop-K demonstrates superior performance over state-of-the-art row-wise top-k GPU implementations, achieving an average speed-up of up to 11.49$\\times$ with early stopping and 7.29$\\times$ without early stopping. Moreover, RTop-K accelerates the overall training workflow of MaxK-GNNs, delivering speed-ups ranging from 11.97% to 33.29% across different models and datasets.         ",
    "url": "https://arxiv.org/abs/2409.00822",
    "authors": [
      "Xi Xie",
      "Yuebo Luo",
      "Hongwu Peng",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2409.06994",
    "title": "Graph sub-sampling for divide-and-conquer algorithms in large networks",
    "abstract": "           As networks continue to increase in size, current methods must be capable of handling large numbers of nodes and edges in order to be practically relevant. Instead of working directly with the entire (large) network, analyzing sub-networks has become a popular approach. Due to a network's inherent inter-connectedness, however, sub-sampling is not a trivial task. While this problem has gained popularity in recent years, it has not received sufficient attention from the statistics community. In this work, we provide a thorough comparison of seven graph sub-sampling algorithms by applying them to divide-and-conquer algorithms for community structure and core-periphery (CP) structure. After discussing the various algorithms and sub-sampling routines, we derive theoretical results for the mis-classification rate of the divide-and-conquer algorithm for CP structure under various sub-sampling schemes. We then perform extensive experiments on both simulated and real-world data to compare the various methods. For the community detection task, we found that sampling nodes uniformly at random yields the best performance, but that sometimes the base algorithm applied to the entire network yields better results both in terms of identification and computational time. For CP structure on the other hand, there was no single winner, but algorithms which sampled core nodes at a higher rate consistently outperformed other sampling routines, e.g., random edge sampling and random walk sampling. Unlike community detection, the CP divide-and-conquer algorithm tends to yield better identification results while also being faster than the base algorithm. The varying performance of the sampling algorithms on different tasks demonstrates the importance of carefully selecting a sub-sampling routine for the specific application.         ",
    "url": "https://arxiv.org/abs/2409.06994",
    "authors": [
      "Eric Yanchenko"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2409.17538",
    "title": "On the Implicit Relation Between Low-Rank Adaptation and Differential Privacy",
    "abstract": "           A significant approach in natural language processing involves large-scale pre-training of models on general domain data followed by their adaptation to specific tasks or domains. As models grow in size, full fine-tuning all of their parameters becomes increasingly impractical. To address this, some methods for low-rank task adaptation of language models have been proposed, e.g., LoRA and FLoRA. These methods keep the pre-trained model weights fixed and incorporate trainable low-rank decomposition matrices into some layers of the transformer architecture, called adapters. This approach significantly reduces the number of trainable parameters required for downstream tasks compared to full fine-tuning all parameters. In this work, we look at low-rank adaptation from the lens of data privacy. We show theoretically that the low-rank adaptation used in LoRA and FLoRA leads to the injection of some random noise into the batch gradients w.r.t the adapter parameters. We quantify the variance of the injected noise and show that the smaller the adaptation rank, the larger the noise variance. By establishing a Berry-Esseen type bound on the total variation distance between distribution of the injected noise and a Gaussian distribution with the same variance, we show that the dynamics of low-rank adaptation is close to that of differentially private fine-tuning of the adapters. Finally, using Johnson-Lindenstrauss lemma, we show that when augmented with gradient scaling, low-rank adaptation is very close to performing DPSGD algorithm with a fixed noise scale to fine-tune the adapters. Suggested by our theoretical findings and approved by our experimental results, we show that low-rank adaptation, besides mitigating the space and computational complexities, implicitly provides a privacy protection w.r.t the fine-tuning data, without inducing the high space complexity of DPSGD.         ",
    "url": "https://arxiv.org/abs/2409.17538",
    "authors": [
      "Saber Malekmohammadi",
      "Golnoosh Farnadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2409.19027",
    "title": "Code Generation and Algorithmic Problem Solving Using Llama 3.1 405B",
    "abstract": "           Code generation by Llama 3.1 models, such as Meta's Llama 3.1 405B, represents a significant advancement in the field of artificial intelligence, particularly in natural language processing and programming automation. This paper explores the capabilities and applications of Llama-driven code generation, highlighting its ability to translate natural language prompts into executable code across multiple programming languages. Key features include contextual awareness, multi-language support, and enhanced debugging and optimization functionalities. By examining these aspects, we illustrate how Llama can serve as a versatile tool for developers of all skill levels, improving productivity and efficiency in software development. The potential implications for education, industry, and the future of coding practices are also discussed, underscoring the transformative impact of AI in programming. Experimentation shows that while Llama 3.1 405B performs well with simple algorithmic and data structure based problems, it still struggles with problems on Quantum Computing, Bioinformatics, and Artificial Intelligence.         ",
    "url": "https://arxiv.org/abs/2409.19027",
    "authors": [
      "Aniket Deroy",
      "Subhankar Maity"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2410.02675",
    "title": "FAN: Fourier Analysis Networks",
    "abstract": "           Despite the remarkable successes of general-purpose neural networks, such as MLPs and Transformers, we find that they exhibit notable shortcomings in modeling and reasoning about periodic phenomena, achieving only marginal performance within the training domain and failing to generalize effectively to out-of-domain (OOD) scenarios. Periodicity is ubiquitous throughout nature and science. Therefore, neural networks should be equipped with the essential ability to model and handle periodicity. In this work, we propose FAN, a novel general-purpose neural network that offers broad applicability similar to MLP while effectively addressing periodicity modeling challenges. Periodicity is naturally integrated into FAN's structure and computational processes by introducing the Fourier Principle. Unlike existing Fourier-based networks, which possess particular periodicity modeling abilities but are typically designed for specific tasks, our approach maintains the general-purpose modeling capability. Therefore, FAN can seamlessly replace MLP in various model architectures with fewer parameters and FLOPs. Through extensive experiments, we demonstrate the superiority of FAN in periodicity modeling tasks and the effectiveness and generalizability of FAN across a range of real-world tasks, e.g., symbolic formula representation, time series forecasting, language modeling, and image recognition.         ",
    "url": "https://arxiv.org/abs/2410.02675",
    "authors": [
      "Yihong Dong",
      "Ge Li",
      "Yongding Tao",
      "Xue Jiang",
      "Kechi Zhang",
      "Jia Li",
      "Jinliang Deng",
      "Jing Su",
      "Jun Zhang",
      "Jingjing Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2410.03862",
    "title": "Improving Mapper's Robustness by Varying Resolution According to Lens-Space Density",
    "abstract": "           We propose a modification of the Mapper algorithm that removes the assumption of a single resolution scale across semantic space and improves the robustness of the results under change of parameters. Our work is motivated by datasets where the density in the image of the Morse-type function (the lens-space density) varies widely. For such datasets, tuning the resolution parameter of Mapper is difficult because small changes can lead to significant variations in the output. By improving the robustness of the output under these variations, our method makes it easier to tune the resolution for datasets with highly variable lens-space density. This improvement is achieved by generalising the type of permitted cover for Mapper and incorporating the lens-space density into the cover. Furthermore, we prove that for covers satisfying natural assumptions, the graph produced by Mapper still converges in bottleneck distance to the Reeb graph of the Rips complex of the data, while possibly capturing more topological features than a standard Mapper cover. Finally, we discuss implementation details and present the results of computational experiments. We also provide an accompanying reference implementation.         ",
    "url": "https://arxiv.org/abs/2410.03862",
    "authors": [
      "Kaleb D. Ruscitti",
      "Leland McInnes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2410.10291",
    "title": "Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspective",
    "abstract": "           Accurate interpretation and visualization of human instructions are crucial for text-to-image (T2I) synthesis. However, current models struggle to capture semantic variations from word order changes, and existing evaluations, relying on indirect metrics like text-image similarity, fail to reliably assess these challenges. This often obscures poor performance on complex or uncommon linguistic patterns by the focus on frequent word combinations. To address these deficiencies, we propose a novel metric called SemVarEffect and a benchmark named SemVarBench, designed to evaluate the causality between semantic variations in inputs and outputs in T2I synthesis. Semantic variations are achieved through two types of linguistic permutations, while avoiding easily predictable literal variations. Experiments reveal that the CogView-3-Plus and Ideogram 2 performed the best, achieving a score of 0.2/1. Semantic variations in object relations are less understood than attributes, scoring 0.07/1 compared to 0.17-0.19/1. We found that cross-modal alignment in UNet or Transformers plays a crucial role in handling semantic variations, a factor previously overlooked by a focus on textual encoders. Our work establishes an effective evaluation framework that advances the T2I synthesis community's exploration of human instruction understanding. Our benchmark and code are available at this https URL .         ",
    "url": "https://arxiv.org/abs/2410.10291",
    "authors": [
      "Xiangru Zhu",
      "Penglei Sun",
      "Yaoxian Song",
      "Yanghua Xiao",
      "Zhixu Li",
      "Chengyu Wang",
      "Jun Huang",
      "Bei Yang",
      "Xiaoxiao Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2410.12189",
    "title": "DocETL: Agentic Query Rewriting and Evaluation for Complex Document Processing",
    "abstract": "           Analyzing unstructured data has been a persistent challenge in data processing. Large Language Models (LLMs) have shown promise in this regard, leading to recent proposals for declarative frameworks for LLM-powered processing of unstructured data. However, these frameworks focus on reducing cost when executing user-specified operations using LLMs, rather than improving accuracy, executing most operations as-is (in a single LLM call). This is problematic for complex tasks and data, where LLM outputs for user-defined operations are often inaccurate, even with optimized prompts. For example, an LLM may struggle to identify {\\em all} instances of specific clauses, like force majeure or indemnification, in lengthy legal documents, requiring decomposition of the data, the task, or both. We present DocETL, a system that optimizes complex document processing pipelines, while accounting for LLM shortcomings. DocETL offers a declarative interface for users to define such pipelines and uses an agent-based approach to automatically optimize them, leveraging novel agent-based rewrites (that we call rewrite directives), as well as an optimization and evaluation framework. We introduce (i) logical rewriting of pipelines, tailored for LLM-based tasks, (ii) an agent-guided plan evaluation mechanism that synthesizes and orchestrates task-specific validation prompts, and (iii) an optimization algorithm that efficiently finds promising plans, considering the latencies of agent-based plan generation and evaluation. Our evaluation on four different unstructured document analysis tasks demonstrates that DocETL finds plans with outputs that are 25 to 80% more accurate than well-engineered baselines, addressing a critical gap in unstructured data analysis. DocETL is open-source at this http URL, and as of March 2025, has amassed over 1.7k GitHub Stars, with users spanning a variety of domains.         ",
    "url": "https://arxiv.org/abs/2410.12189",
    "authors": [
      "Shreya Shankar",
      "Tristan Chambers",
      "Tarak Shah",
      "Aditya G. Parameswaran",
      "Eugene Wu"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2410.12836",
    "title": "EditRoom: LLM-parameterized Graph Diffusion for Composable 3D Room Layout Editing",
    "abstract": "           Given the steep learning curve of professional 3D software and the time-consuming process of managing large 3D assets, language-guided 3D scene editing has significant potential in fields such as virtual reality, augmented reality, and gaming. However, recent approaches to language-guided 3D scene editing either require manual interventions or focus only on appearance modifications without supporting comprehensive scene layout changes. In response, we propose EditRoom, a unified framework capable of executing a variety of layout edits through natural language commands, without requiring manual intervention. Specifically, EditRoom leverages Large Language Models (LLMs) for command planning and generates target scenes using a diffusion-based method, enabling six types of edits: rotate, translate, scale, replace, add, and remove. To address the lack of data for language-guided 3D scene editing, we have developed an automatic pipeline to augment existing 3D scene synthesis datasets and introduced EditRoom-DB, a large-scale dataset with 83k editing pairs, for training and evaluation. Our experiments demonstrate that our approach consistently outperforms other baselines across all metrics, indicating higher accuracy and coherence in language-guided scene layout editing.         ",
    "url": "https://arxiv.org/abs/2410.12836",
    "authors": [
      "Kaizhi Zheng",
      "Xiaotong Chen",
      "Xuehai He",
      "Jing Gu",
      "Linjie Li",
      "Zhengyuan Yang",
      "Kevin Lin",
      "Jianfeng Wang",
      "Lijuan Wang",
      "Xin Eric Wang"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2410.13798",
    "title": "Learning Graph Quantized Tokenizers",
    "abstract": "           Transformers serve as the backbone architectures of Foundational Models, where domain-specific tokenizers allow them to adapt to various domains. Graph Transformers (GTs) have recently emerged as leading models in geometric deep learning, outperforming Graph Neural Networks (GNNs) in various graph learning tasks. However, the development of tokenizers for graphs has lagged behind other modalities. To address this, we introduce GQT (\\textbf{G}raph \\textbf{Q}uantized \\textbf{T}okenizer), which decouples tokenizer training from Transformer training by leveraging multi-task graph self-supervised learning, yielding robust and generalizable graph tokens. Furthermore, the GQT utilizes Residual Vector Quantization (RVQ) to learn hierarchical discrete tokens, resulting in significantly reduced memory requirements and improved generalization capabilities. By combining the GQT with token modulation, a Transformer encoder achieves state-of-the-art performance on 20 out of 22 benchmarks, including large-scale homophilic and heterophilic datasets.         ",
    "url": "https://arxiv.org/abs/2410.13798",
    "authors": [
      "Limei Wang",
      "Kaveh Hassani",
      "Si Zhang",
      "Dongqi Fu",
      "Baichuan Yuan",
      "Weilin Cong",
      "Zhigang Hua",
      "Hao Wu",
      "Ning Yao",
      "Bo Long"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.20072",
    "title": "CGKN: A Deep Learning Framework for Modeling Complex Dynamical Systems and Efficient Data Assimilation",
    "abstract": "           Deep learning is widely used to predict complex dynamical systems in many scientific and engineering areas. However, the black-box nature of these deep learning models presents significant challenges for carrying out simultaneous data assimilation (DA), which is a crucial technique for state estimation, model identification, and reconstructing missing data. Integrating ensemble-based DA methods with nonlinear deep learning models is computationally expensive and may suffer from large sampling errors. To address these challenges, we introduce a deep learning framework designed to simultaneously provide accurate forecasts and efficient DA. It is named Conditional Gaussian Koopman Network (CGKN), which transforms general nonlinear systems into nonlinear neural differential equations with conditional Gaussian structures. CGKN aims to retain essential nonlinear components while applying systematic and minimal simplifications to facilitate the development of analytic formulae for nonlinear DA. This allows for seamless integration of DA performance into the deep learning training process, eliminating the need for empirical tuning as required in ensemble methods. CGKN compensates for structural simplifications by lifting the dimension of the system, which is motivated by Koopman theory. Nevertheless, CGKN exploits special nonlinear dynamics within the lifted space. This enables the model to capture extreme events and strong non-Gaussian features in joint and marginal distributions with appropriate uncertainty quantification. We demonstrate the effectiveness of CGKN for both prediction and DA on three strongly nonlinear and non-Gaussian turbulent systems: the projected stochastic Burgers-Sivashinsky equation, the Lorenz 96 system, and the El Ni\u00f1o-Southern Oscillation. The results justify the robustness and computational efficiency of CGKN.         ",
    "url": "https://arxiv.org/abs/2410.20072",
    "authors": [
      "Chuanqi Chen",
      "Nan Chen",
      "Yinling Zhang",
      "Jin-Long Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2410.22069",
    "title": "Flavors of Margin: Implicit Bias of Steepest Descent in Homogeneous Neural Networks",
    "abstract": "           We study the implicit bias of the general family of steepest descent algorithms with infinitesimal learning rate in deep homogeneous neural networks. We show that: (a) an algorithm-dependent geometric margin starts increasing once the networks reach perfect training accuracy, and (b) any limit point of the training trajectory corresponds to a KKT point of the corresponding margin-maximization problem. We experimentally zoom into the trajectories of neural networks optimized with various steepest descent algorithms, highlighting connections to the implicit bias of popular adaptive methods (Adam and Shampoo).         ",
    "url": "https://arxiv.org/abs/2410.22069",
    "authors": [
      "Nikolaos Tsilivis",
      "Gal Vardi",
      "Julia Kempe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2411.04371",
    "title": "ComFairGNN: Community Fair Graph Neural Network",
    "abstract": "           Graph Neural Networks (GNNs) have become the leading approach for addressing graph analytical problems in various real-world scenarios. However, GNNs may produce biased predictions against certain demographic subgroups due to node attributes and neighbors surrounding a node. Most current research on GNN fairness focuses predominantly on debiasing GNNs using oversimplified fairness evaluation metrics, which can give a misleading impression of fairness. Understanding the potential evaluation paradoxes due to the complicated nature of the graph structure is crucial for developing effective GNN debiasing mechanisms. In this paper, we examine the effectiveness of current GNN debiasing methods in terms of unfairness evaluation. Specifically, we introduce a community-level strategy to measure bias in GNNs and evaluate debiasing methods at this level. Further, We introduce ComFairGNN, a novel framework designed to mitigate community-level bias in GNNs. Our approach employs a learnable coreset-based debiasing function that addresses bias arising from diverse local neighborhood distributions during GNNs neighborhood aggregation. Comprehensive evaluations on three benchmark datasets demonstrate our model's effectiveness in both accuracy and fairness metrics.         ",
    "url": "https://arxiv.org/abs/2411.04371",
    "authors": [
      "Yonas Sium",
      "Qi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2411.10228",
    "title": "Path Assignment in Mesh Networks at the Edge of Wireless Networks",
    "abstract": "           We consider a mesh network at the edge of a wireless network that connects users to the core network via multiple base stations. For this scenario, we present a novel tree-search-based algorithm that strives to identify effective communication path to the core network for each user by maximizing the signal-to-noise-plus-interference ratio (SNIR) along the chosen path. We show that, for three mesh networks of varying sizes, our algorithm selects paths with minimum SNIR values that are 3 dB to 18 dB higher than those obtained through an algorithm that disregards interference within the network, 16 dB to 20 dB higher than those chosen randomly by a random path selection algorithm, and 0.5 dB to 7 dB higher compared to a recently introduced genetic algorithm (GA). Furthermore, we demonstrate that our algorithm has lower computational complexity compared to the GA in networks where its performance is within 2 dB of ours.         ",
    "url": "https://arxiv.org/abs/2411.10228",
    "authors": [
      "Siddhartha Kumar",
      "Mohammad Hossein Moghaddam",
      "Andreas Wolfgang",
      "Tommy Svensson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2411.14720",
    "title": "Optimizing Social Media Annotation of HPV Vaccine Skepticism and Misinformation Using Large Language Models: An Experimental Evaluation of In-Context Learning and Fine-Tuning Stance Detection Across Multiple Models",
    "abstract": "           This paper leverages large-language models (LLMs) to experimentally determine optimal strategies for scaling up social media content annotation for stance detection on HPV vaccine-related tweets. We examine both conventional fine-tuning and emergent in-context learning methods, systematically varying strategies of prompt engineering across widely used LLMs and their variants (e.g., GPT4, Mistral, and Llama3, etc.). Specifically, we varied prompt template design, shot sampling methods, and shot quantity to detect stance on HPV vaccination. Our findings reveal that 1) in general, in-context learning outperforms fine-tuning in stance detection for HPV vaccine social media content; 2) increasing shot quantity does not necessarily enhance performance across models; and 3) different LLMs and their variants present differing sensitivity to in-context learning conditions. We uncovered that the optimal in-context learning configuration for stance detection on HPV vaccine tweets involves six stratified shots paired with detailed contextual prompts. This study highlights the potential and provides an applicable approach for applying LLMs to research on social media stance and skepticism detection.         ",
    "url": "https://arxiv.org/abs/2411.14720",
    "authors": [
      "Luhang Sun",
      "Varsha Pendyala",
      "Yun-Shiuan Chuang",
      "Shanglin Yang",
      "Jonathan Feldman",
      "Andrew Zhao",
      "Munmun De Choudhury",
      "Sijia Yang",
      "Dhavan Shah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2412.09213",
    "title": "Enhancing Implicit Neural Representations via Symmetric Power Transformation",
    "abstract": "           We propose symmetric power transformation to enhance the capacity of Implicit Neural Representation~(INR) from the perspective of data transformation. Unlike prior work utilizing random permutation or index rearrangement, our method features a reversible operation that does not require additional storage consumption. Specifically, we first investigate the characteristics of data that can benefit the training of INR, proposing the Range-Defined Symmetric Hypothesis, which posits that specific range and symmetry can improve the expressive ability of INR. Based on this hypothesis, we propose a nonlinear symmetric power transformation to achieve both range-defined and symmetric properties simultaneously. We use the power coefficient to redistribute data to approximate symmetry within the target range. To improve the robustness of the transformation, we further design deviation-aware calibration and adaptive soft boundary to address issues of extreme deviation boosting and continuity breaking. Extensive experiments are conducted to verify the performance of the proposed method, demonstrating that our transformation can reliably improve INR compared with other data transformations. We also conduct 1D audio, 2D image and 3D video fitting tasks to demonstrate the effectiveness and applicability of our method.         ",
    "url": "https://arxiv.org/abs/2412.09213",
    "authors": [
      "Weixiang Zhang",
      "Shuzhao Xie",
      "Chengwei Ren",
      "Shijia Ge",
      "Mingzi Wang",
      "Zhi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2412.10028",
    "title": "Mr. DETR: Instructive Multi-Route Training for Detection Transformers",
    "abstract": "           Existing methods enhance the training of detection transformers by incorporating an auxiliary one-to-many assignment. In this work, we treat the model as a multi-task framework, simultaneously performing one-to-one and one-to-many predictions. We investigate the roles of each component in the transformer decoder across these two training targets, including self-attention, cross-attention, and feed-forward network. Our empirical results demonstrate that any independent component in the decoder can effectively learn both targets simultaneously, even when other components are shared. This finding leads us to propose a multi-route training mechanism, featuring a primary route for one-to-one prediction and two auxiliary training routes for one-to-many prediction. We enhance the training mechanism with a novel instructive self-attention that dynamically and flexibly guides object queries for one-to-many prediction. The auxiliary routes are removed during inference, ensuring no impact on model architecture or inference cost. We conduct extensive experiments on various baselines, achieving consistent improvements as shown in Figure 1. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2412.10028",
    "authors": [
      "Chang-Bin Zhang",
      "Yujie Zhong",
      "Kai Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2412.10153",
    "title": "EVOS: Efficient Implicit Neural Training via EVOlutionary Selector",
    "abstract": "           We propose EVOlutionary Selector (EVOS), an efficient training paradigm for accelerating Implicit Neural Representation (INR). Unlike conventional INR training that feeds all samples through the neural network in each iteration, our approach restricts training to strategically selected points, reducing computational overhead by eliminating redundant forward passes. Specifically, we treat each sample as an individual in an evolutionary process, where only those fittest ones survive and merit inclusion in training, adaptively evolving with the neural network dynamics. While this is conceptually similar to Evolutionary Algorithms, their distinct objectives (selection for acceleration vs. iterative solution optimization) require a fundamental redefinition of evolutionary mechanisms for our context. In response, we design sparse fitness evaluation, frequency-guided crossover, and augmented unbiased mutation to comprise EVOS. These components respectively guide sample selection with reduced computational cost, enhance performance through frequency-domain balance, and mitigate selection bias from cached evaluation. Extensive experiments demonstrate that our method achieves approximately 48%-66% reduction in training time while ensuring superior convergence without additional cost, establishing state-of-the-art acceleration among recent sampling-based strategies.         ",
    "url": "https://arxiv.org/abs/2412.10153",
    "authors": [
      "Weixiang Zhang",
      "Shuzhao Xie",
      "Chengwei Ren",
      "Siyi Xie",
      "Chen Tang",
      "Shijia Ge",
      "Mingzi Wang",
      "Zhi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2501.00701",
    "title": "ResKoopNet: Learning Koopman Representations for Complex Dynamics with Spectral Residuals",
    "abstract": "           Analyzing long-term behaviors in high-dimensional nonlinear dynamical systems remains challenging, with the Koopman operator framework providing a powerful global linearization approach, though existing methods for approximating its spectral components often suffer from theoretical limitations and reliance on predefined dictionaries. While Residual Dynamic Mode Decomposition (ResDMD) introduced the spectral residual to assess the accuracy of Koopman operator approximation, its only filters precomputed spectra, which prevents it from fully discovering the Koopman operator's complete spectral information (a limitation sometimes referred to as the 'spectral inclusion' problem). We introduce ResKoopNet (Residual-based Koopman-learning Network), a novel method that addresses this limitation by explicitly minimizing the spectral residual to compute Koopman eigenpairs, which can identify a more precise and complete spectrum of the Koopman operator. This approach provides theoretical guarantees while maintaining computational adaptability through a neural network implementation. Experiments on physical and biological systems demonstrate ResKoopNet's superior accuracy in spectral approximation compared to existing methods, particularly for systems with continuous spectra and high dimensional, which makes it as an effective tool for analyzing complex dynamical systems.         ",
    "url": "https://arxiv.org/abs/2501.00701",
    "authors": [
      "Yuanchao Xu",
      "Kaidi Shao",
      "Nikos Logothetis",
      "Zhongwei Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2501.02153",
    "title": "Resolving the Exploration-Exploitation Dilemma in Evolutionary Algorithms: A Novel Human-Centered Framework",
    "abstract": "           Evolutionary Algorithms (EAs) are widely employed tools for complex search and optimization tasks; however, the absence of an overarching operational framework that permits a systematic regulation of the exploration-exploitation tradeoff--critical for efficient convergence--restricts the full actualization of their potential, leading to the so-called exploration-exploitation dilemma in algorithm design. A systematic resolution to this dilemma requires: (1) an independent yet coordinated control over exploration and exploitation, and (2) an explicit, computationally feasible, adaptive regulation mechanism. The current, almost decentralized, traditional parameter tuning-centeric approach--lacks the foundation to satisfy these requirements under encoding-imposed structural constraints. We propose a Human-Centered Two-Phase Search (HCTPS) framework, in which the actualization of (1) and (2) is enabled through an external configuration variable--the Search Space Control Parameter (SSCP). As the sole control knob of HCTPS, the SSCP centralizes exploration adjustments, sparing users from micromanaging traditional parameters with unintelligible interdependencies. To this construct, the human user serves as a meta-parameter, adaptively steering the regulatory process via SSCP adjustments. We prove that the HCTPS strictly surpasses the current approach in terms of search space coverage without disrupting the EAs' inherent convergence mechanisms, demonstrate a concrete instantiation of it--using the Genetic Algorithm as the underlying heuristic on a suite of global benchmark unconstrained optimization problems, provide a through assessment of the proposed framework, and envision future research directions. Any search algorithm prone to this dilemma can be applied in light of the proposed framework, being algorithm-agnostic by design.         ",
    "url": "https://arxiv.org/abs/2501.02153",
    "authors": [
      "Ehsan Shams"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2501.02893",
    "title": "A Volumetric Approach to Privacy of Dynamical Systems",
    "abstract": "           Information-theoretic metrics, such as mutual information, have been widely used to evaluate privacy leakage in dynamic systems. However, these approaches are typically limited to stochastic systems and face computational challenges. In this paper, we introduce a novel volumetric framework for analyzing privacy in systems affected by unknown but bounded noise. Our model considers a dynamic system comprising public and private states, where an observation set of the public state is released. An adversary utilizes the observed public state to infer an uncertainty set of the private state, referred to as the inference attack. We define the evolution dynamics of these inference attacks and quantify the privacy level of the private state using the volume of its uncertainty sets. We then develop an approximate computation method leveraging interval analysis to compute the private state set. We investigate the properties of the proposed volumetric privacy measure and demonstrate that it is bounded by the information gain derived from the observation set. Furthermore, we propose an optimization approach to designing privacy filter using randomization and linear programming based on the proposed privacy measure. The effectiveness of the optimal privacy filter design is evaluated through a production-inventory case study, illustrating its robustness against inference attacks and its superiority compared to a truncated Gaussian mechanism.         ",
    "url": "https://arxiv.org/abs/2501.02893",
    "authors": [
      "Chuanghong Weng",
      "Ehsan Nekouei"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2501.05396",
    "title": "FairCoder: Evaluating Social Bias of LLMs in Code Generation",
    "abstract": "           Large language models (LLMs) have been widely deployed in coding tasks, drawing increasing attention to the evaluation of the quality and safety of LLMs' outputs. However, research on bias in code generation remains limited. Existing studies typically identify bias by applying malicious prompts or reusing tasks and dataset originally designed for discriminative models. Given that prior datasets are not fully optimized for code-related tasks, there is a pressing need for benchmarks specifically designed for evaluating code models. In this study, we introduce FairCoder, a novel benchmark for evaluating social bias in code generation. FairCoder explores the bias issue following the pipeline in software development, from function implementation to unit test, with diverse real-world scenarios. Additionally, three metrics are designed to assess fairness performance on this benchmark. We conduct experiments on widely used LLMs and provide a comprehensive analysis of the results. The findings reveal that all tested LLMs exhibit social bias.         ",
    "url": "https://arxiv.org/abs/2501.05396",
    "authors": [
      "Yongkang Du",
      "Jen-tse Huang",
      "Jieyu Zhao",
      "Lu Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2501.14622",
    "title": "ACT-JEPA: Novel Joint-Embedding Predictive Architecture for Efficient Policy Representation Learning",
    "abstract": "           Learning efficient representations for decision-making policies is a challenge in imitation learning (IL). Current IL methods require expert demonstrations, which are expensive to collect. Consequently, they often have underdeveloped world models. Self-supervised learning (SSL) offers an alternative by allowing models to learn from diverse, unlabeled data, including failures. However, SSL methods often operate in raw input space, making them inefficient. In this work, we propose ACT-JEPA, a novel architecture that integrates IL and SSL to enhance policy representations. We train a policy to predict (1) action sequences and (2) abstract observation sequences. The first objective uses action chunking to improve action prediction and reduce compounding errors. The second objective extends this idea of chunking by predicting abstract observation sequences. We utilize Joint-Embedding Predictive Architecture to predict in abstract representation space, allowing the model to filter out irrelevant details, improve efficiency, and develop a robust world model. Our experiments show that ACT-JEPA improves the quality of representations by learning temporal environment dynamics. Additionally, the model's ability to predict abstract observation sequences results in representations that effectively generalize to action sequence prediction. ACT-JEPA performs on par with established baselines across a range of decision-making tasks.         ",
    "url": "https://arxiv.org/abs/2501.14622",
    "authors": [
      "Aleksandar Vujinovic",
      "Aleksandar Kovacevic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.11570",
    "title": "Towards a Trustworthy Anomaly Detection for Critical Applications through Approximated Partial AUC Loss",
    "abstract": "           Anomaly Detection is a crucial step for critical applications such in the industrial, medical or cybersecurity domains. These sectors share the same requirement of handling differently the different types of classification errors. Indeed, even if false positives are acceptable, false negatives are not, because it would reflect a missed detection of a quality issue, a disease or a cyber threat. To fulfill this requirement, we propose a method that dynamically applies a trustworthy approximated partial AUC ROC loss (tapAUC). A binary classifier is trained to optimize the specific range of the AUC ROC curve that prevents the True Positive Rate (TPR) to reach 100% while minimizing the False Positive Rate (FPR). The optimal threshold that does not trigger any false negative is then kept and used at the test step. The results show a TPR of 92.52% at a 20.43% FPR for an average across 6 datasets, representing a TPR improvement of 4.3% for a FPR cost of 12.2% against other state-of-the-art methods. The code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2502.11570",
    "authors": [
      "Arnaud Bougaham",
      "Beno\u00eet Fr\u00e9nay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2502.13820",
    "title": "Scoring Verifiers: Evaluating Synthetic Verification for Code and Reasoning",
    "abstract": "           Synthetic verification techniques such as generating test cases and reward modelling are common ways to enhance the coding capabilities of large language models (LLM) beyond predefined tests. Additionally, code verification has recently found great success as a critical component in improving reasoning capability of LLMs via reinforcement learning. In this paper, we propose a an approach which can transform existing coding benchmarks into scoring and ranking datasets to evaluate the effectiveness of synthetic verifiers. We also propose multiple metrics to measure different aspects of the synthetic verifiers with the proposed benchmarks. By employing the proposed approach, we release four new benchmarks (HE-R, HE-R+, MBPP-R, and MBPP-R+), and analyzed synthetic verification methods with standard, reasoning-based, and reward-based LLMs. Our experiments show that reasoning can significantly improve test case generation and that scaling the number of test cases enhances the verification accuracy.         ",
    "url": "https://arxiv.org/abs/2502.13820",
    "authors": [
      "Aleksander Ficek",
      "Somshubra Majumdar",
      "Vahid Noroozi",
      "Boris Ginsburg"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2502.18227",
    "title": "Local Differential Privacy for Tensors in Distributed Computing Systems",
    "abstract": "           Tensor-valued data, increasingly common in distributed big data applications like autonomous driving and smart healthcare, poses unique challenges for privacy protection due to its multidimensional structure and the risk of losing critical structural information. Traditional local differential privacy methods, designed for scalars and matrices, are insufficient for tensors, as they fail to preserve essential relationships among tensor elements. We introduce TLDP, a novel LDP algorithm for Tensors, which employs a randomized response mechanism to perturb tensor components while maintaining structural integrity. To strike a better balance between utility and privacy, we incorporate a weight matrix that selectively protects sensitive regions. Both theoretical analysis and empirical findings from real-world datasets show that TLDP achieves superior utility while preserving privacy, making it a robust solution for high-dimensional tensor data.         ",
    "url": "https://arxiv.org/abs/2502.18227",
    "authors": [
      "Yachao Yuan",
      "Xiao Tang",
      "Yu Huang",
      "Jin Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2503.01245",
    "title": "Large Language Models for Code Generation: A Comprehensive Survey of Challenges, Techniques, Evaluation, and Applications",
    "abstract": "           Large Language Models (LLMs) have demonstrated their remarkable capabilities in numerous fields. This survey focuses on how LLMs empower users, regardless of their technical background, to use human languages to automatically generate executable code. We begin with understanding LLMs' limitations and challenges in automated code generation. Subsequently, we review various fine-tuning techniques designed to enhance both the performance and adaptability of LLMs in code generation tasks. We then review the existing metrics and benchmarks for evaluations to assess model performance based on fine-tuning techniques. Finally, we explore the applications of LLMs (e.g. CodeLlama, GitHub Copilot, ToolGen) in code generation tasks to illustrate their roles and functionalities. This survey provides a comprehensive overview of LLMs for code generation, helps researchers in diverse fields better understand the current state-of-the-art technologies, and offers the potential of effectively leveraging LLMs for code generation tasks.         ",
    "url": "https://arxiv.org/abs/2503.01245",
    "authors": [
      "Nam Huynh",
      "Beiyu Lin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.03506",
    "title": "Rethinking Synthetic Data definitions: A privacy driven approach",
    "abstract": "           Synthetic data is gaining traction as a cost-effective solution for the increasing data demands of AI development and can be generated either from existing knowledge or derived data captured from real-world events. The source of the synthetic data generation and the technique used significantly impacts its residual privacy risk and therefore its opportunity for sharing. Traditional classification of synthetic data types no longer fit the newer generation techniques and there is a need to better align the classification with practical needs. We suggest a new way of grouping synthetic data types that better supports privacy evaluations to aid regulatory policymaking. Our novel classification provides flexibility to new advancements like deep generative methods and offers a more practical framework for future applications.         ",
    "url": "https://arxiv.org/abs/2503.03506",
    "authors": [
      "Vibeke Binz Vallevik",
      "Serena Elizabeth Marshall",
      "Aleksandar Babic",
      "Jan Franz Nygaard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.11005",
    "title": "Cyclic Contrastive Knowledge Transfer for Open-Vocabulary Object Detection",
    "abstract": "           In pursuit of detecting unstinted objects that extend beyond predefined categories, prior arts of open-vocabulary object detection (OVD) typically resort to pretrained vision-language models (VLMs) for base-to-novel category generalization. However, to mitigate the misalignment between upstream image-text pretraining and downstream region-level perception, additional supervisions are indispensable, eg, image-text pairs or pseudo annotations generated via self-training strategies. In this work, we propose CCKT-Det trained without any extra supervision. The proposed framework constructs a cyclic and dynamic knowledge transfer from language queries and visual region features extracted from VLMs, which forces the detector to closely align with the visual-semantic space of VLMs. Specifically, 1) we prefilter and inject semantic priors to guide the learning of queries, and 2) introduce a regional contrastive loss to improve the awareness of queries on novel objects. CCKT-Det can consistently improve performance as the scale of VLMs increases, all while requiring the detector at a moderate level of computation overhead. Comprehensive experimental results demonstrate that our method achieves performance gain of +2.9% and +10.2% AP50 over previous state-of-the-arts on the challenging COCO benchmark, both without and with a stronger teacher model.         ",
    "url": "https://arxiv.org/abs/2503.11005",
    "authors": [
      "Chuhan Zhang",
      "Chaoyang Zhu",
      "Pingcheng Dong",
      "Long Chen",
      "Dong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.19474",
    "title": "A-MESS: Anchor based Multimodal Embedding with Semantic Synchronization for Multimodal Intent Recognition",
    "abstract": "           In the domain of multimodal intent recognition (MIR), the objective is to recognize human intent by integrating a variety of modalities, such as language text, body gestures, and tones. However, existing approaches face difficulties adequately capturing the intrinsic connections between the modalities and overlooking the corresponding semantic representations of intent. To address these limitations, we present the Anchor-based Multimodal Embedding with Semantic Synchronization (A-MESS) framework. We first design an Anchor-based Multimodal Embedding (A-ME) module that employs an anchor-based embedding fusion mechanism to integrate multimodal inputs. Furthermore, we develop a Semantic Synchronization (SS) strategy with the Triplet Contrastive Learning pipeline, which optimizes the process by synchronizing multimodal representation with label descriptions produced by the large language model. Comprehensive experiments indicate that our A-MESS achieves state-of-the-art and provides substantial insight into multimodal representation and downstream tasks.         ",
    "url": "https://arxiv.org/abs/2503.19474",
    "authors": [
      "Yaomin Shen",
      "Xiaojian Lin",
      "Wei Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.21225",
    "title": "SEAGET: Seasonal and Active hours guided Graph Enhanced Transformer for the next POI recommendation",
    "abstract": "           One of the most important challenges for improving personalized services in industries like tourism is predicting users' near-future movements based on prior behavior and current circumstances. Next POI (Point of Interest) recommendation is essential for helping users and service providers by providing personalized recommendations. The intricacy of this work, however, stems from the requirement to take into consideration several variables at once, such as user preferences, time contexts, and geographic locations. POI selection is also greatly influenced by elements like a POI's operational status during desired visit times, desirability for visiting during particular seasons, and its dynamic popularity over time. POI popularity is mostly determined by check-in frequency in recent studies, ignoring visitor volumes, operational constraints, and temporal dynamics. These restrictions result in recommendations that are less than ideal and do not take into account actual circumstances. We propose the Seasonal and Active hours-guided Graph-Enhanced Transformer (SEAGET) model as a solution to these problems. By integrating variations in the seasons, operational status, and temporal dynamics into a graph-enhanced transformer framework, SEAGET capitalizes on redefined POI popularity. This invention gives more accurate and context-aware next POI predictions, with potential applications for optimizing tourist experiences and enhancing location-based services in the tourism industry.         ",
    "url": "https://arxiv.org/abs/2503.21225",
    "authors": [
      "Alif Al Hasan",
      "Md. Musfique Anwar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2503.22368",
    "title": "On Finding All Connected Maximum-Sized Common Subgraphs in Multiple Labeled Graphs",
    "abstract": "           We present an exact algorithm for computing all common subgraphs with the maximum number of vertices across multiple graphs. Our approach is further extended to handle the connected Maximum Common Subgraph (MCS), identifying the largest common subgraph in terms of either vertices or edges across multiple graphs, where edges or vertices may additionally be labeled to account for possible atom types or bond types, a classical labeling used in molecular graphs. Our approach leverages modular product graphs and a modified Bron-Kerbosch algorithm to enumerate maximal cliques, ensuring all intermediate solutions are retained. A pruning heuristic efficiently reduces the modular product size, improving computational feasibility. Additionally, we introduce a graph ordering strategy based on graph-kernel similarity measures to optimize the search process. Our method is particularly relevant for bioinformatics and cheminformatics, where identifying conserved structural motifs in molecular graphs is crucial. Empirical results on molecular datasets demonstrate that our approach is scalable and fast.         ",
    "url": "https://arxiv.org/abs/2503.22368",
    "authors": [
      "Johannes B.S. Petersen",
      "Akbar Davoodi",
      "Thomas G\u00e4rtner",
      "Marc Hellmuth",
      "Daniel Merkle"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2503.22405",
    "title": "Modeling Multiple Normal Action Representations for Error Detection in Procedural Tasks",
    "abstract": "           Error detection in procedural activities is essential for consistent and correct outcomes in AR-assisted and robotic systems. Existing methods often focus on temporal ordering errors or rely on static prototypes to represent normal actions. However, these approaches typically overlook the common scenario where multiple, distinct actions are valid following a given sequence of executed actions. This leads to two issues: (1) the model cannot effectively detect errors using static prototypes when the inference environment or action execution distribution differs from training; and (2) the model may also use the wrong prototypes to detect errors if the ongoing action label is not the same as the predicted one. To address this problem, we propose an Adaptive Multiple Normal Action Representation (AMNAR) framework. AMNAR predicts all valid next actions and reconstructs their corresponding normal action representations, which are compared against the ongoing action to detect errors. Extensive experiments demonstrate that AMNAR achieves state-of-the-art performance, highlighting the effectiveness of AMNAR and the importance of modeling multiple valid next actions in error detection. The code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2503.22405",
    "authors": [
      "Wei-Jin Huang",
      "Yuan-Ming Li",
      "Zhi-Wei Xia",
      "Yu-Ming Tang",
      "Kun-Yu Lin",
      "Jian-Fang Hu",
      "Wei-Shi Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.22931",
    "title": "Factored Agents: Decoupling In-Context Learning and Memorization for Robust Tool Use",
    "abstract": "           In this paper, we propose a novel factored agent architecture designed to overcome the limitations of traditional single-agent systems in agentic AI. Our approach decomposes the agent into two specialized components: (1) a large language model (LLM) that serves as a high level planner and in-context learner, which may use dynamically available information in user prompts, (2) a smaller language model which acts as a memorizer of tool format and output. This decoupling addresses prevalent issues in monolithic designs, including malformed, missing, and hallucinated API fields, as well as suboptimal planning in dynamic environments. Empirical evaluations demonstrate that our factored architecture significantly improves planning accuracy and error resilience, while elucidating the inherent trade-off between in-context learning and static memorization. These findings suggest that a factored approach is a promising pathway for developing more robust and adaptable agentic AI systems.         ",
    "url": "https://arxiv.org/abs/2503.22931",
    "authors": [
      "Nicholas Roth",
      "Christopher Hidey",
      "Lucas Spangher",
      "William F. Arnold",
      "Chang Ye",
      "Nick Masiewicki",
      "Jinoo Baek",
      "Peter Grabowski",
      "Eugene Ie"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.23561",
    "title": "Bridging conformal prediction and scenario optimization",
    "abstract": "           Conformal prediction and scenario optimization constitute two important classes of statistical learning frameworks to certify decisions made using data. They have found numerous applications in control theory, machine learning and robotics. Despite intense research in both areas, and apparently similar results, a clear connection between these two frameworks has not been established. By focusing on the so-called vanilla conformal prediction, we show rigorously how to choose appropriate score functions and set predictor map to recover well-known bounds on the probability of constraint violation associated with scenario programs. We also show how to treat ranking of nonconformity scores as a one-dimensional scenario program with discarded constraints, and use such connection to recover vanilla conformal prediction guarantees on the validity of the set predictor. We also capitalize on the main developments of the scenario approach, and show how we could analyze calibration conditional conformal prediction under this lens. Our results establish a theoretical bridge between conformal prediction and scenario optimization.         ",
    "url": "https://arxiv.org/abs/2503.23561",
    "authors": [
      "Niall O'Sullivan",
      "Licio Romao",
      "Kostas Margellos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2503.24115",
    "title": "TeleAntiFraud-28k: An Audio-Text Slow-Thinking Dataset for Telecom Fraud Detection",
    "abstract": "           The detection of telecom fraud faces significant challenges due to the lack of high-quality multimodal training data that integrates audio signals with reasoning-oriented textual analysis. To address this gap, we present TeleAntiFraud-28k, the first open-source audio-text slow-thinking dataset specifically designed for automated telecom fraud analysis. Our dataset is constructed through three strategies: (1) Privacy-preserved text-truth sample generation using automatically speech recognition (ASR)-transcribed call recordings (with anonymized original audio), ensuring real-world consistency through text-to-speech (TTS) model regeneration; (2) Semantic enhancement via large language model (LLM)-based self-instruction sampling on authentic ASR outputs to expand scenario coverage; (3) Multi-agent adversarial synthesis that simulates emerging fraud tactics through predefined communication scenarios and fraud typologies. The generated dataset contains 28,511 rigorously processed speech-text pairs, complete with detailed annotations for fraud reasoning. The dataset is divided into three tasks: scenario classification, fraud detection, fraud type classification. Furthermore, we construct TeleAntiFraud-Bench, a standardized evaluation benchmark comprising proportionally sampled instances from the dataset, to facilitate systematic testing of model performance on telecom fraud detection tasks. We also contribute a production-optimized supervised fine-tuning (SFT) model trained on hybrid real/synthetic data, while open-sourcing the data processing framework to enable community-driven dataset expansion. This work establishes a foundational framework for multimodal anti-fraud research while addressing critical challenges in data privacy and scenario diversity. The project will be released at this https URL.         ",
    "url": "https://arxiv.org/abs/2503.24115",
    "authors": [
      "Zhiming Ma",
      "Peidong Wang",
      "Minhua Huang",
      "Jingpeng Wang",
      "Kai Wu",
      "Xiangzhao Lv",
      "Yachun Pang",
      "Yin Yang",
      "Wenjie Tang",
      "Yuchen Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2504.00336",
    "title": "SeizureTransformer: Scaling U-Net with Transformer for Simultaneous Time-Step Level Seizure Detection from Long EEG Recordings",
    "abstract": "           Epilepsy is a common neurological disorder that affects around 65 million people worldwide. Detecting seizures quickly and accurately is vital, given the prevalence and severity of the associated complications. Recently, deep learning-based automated seizure detection methods have emerged as solutions; however, most existing methods require extensive post-processing and do not effectively handle the crucial long-range patterns in EEG data. In this work, we propose SeizureTransformer, a simple model comprised of (i) a deep encoder comprising 1D convolutions (ii) a residual CNN stack and a transformer encoder to embed previous output into high-level representation with contextual information, and (iii) streamlined decoder which converts these features into a sequence of probabilities, directly indicating the presence or absence of seizures at every time step. Extensive experiments on public and private EEG seizure detection datasets demonstrate that our model significantly outperforms existing approaches (ranked in the first place in the 2025 \"seizure detection challenge\" organized in the International Conference on Artificial Intelligence in Epilepsy and Other Neurological Disorders), underscoring its potential for real-time, precise seizure detection.         ",
    "url": "https://arxiv.org/abs/2504.00336",
    "authors": [
      "Kerui Wu",
      "Ziyue Zhao",
      "B\u00fclent Yener"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2504.00487",
    "title": "FortisAVQA and MAVEN: a Benchmark Dataset and Debiasing Framework for Robust Multimodal Reasoning",
    "abstract": "           Audio-Visual Question Answering (AVQA) is a challenging multimodal reasoning task requiring intelligent systems to answer natural language queries based on paired audio-video inputs accurately. However, existing AVQA approaches often suffer from overfitting to dataset biases, leading to poor robustness. Moreover, current datasets may not effectively diagnose these methods. To address these challenges, we first introduce a novel dataset, FortisAVQA, constructed in two stages: (1) rephrasing questions in the test split of the public MUSIC-AVQA dataset and (2) introducing distribution shifts across questions. The first stage expands the test space with greater diversity, while the second enables a refined robustness evaluation across rare, frequent, and overall question distributions. Second, we introduce a robust Multimodal Audio-Visual Epistemic Network (MAVEN) that leverages a multifaceted cycle collaborative debiasing strategy to mitigate bias learning. Experimental results demonstrate that our architecture achieves state-of-the-art performance on FortisAVQA, with a notable improvement of 7.81\\%. Extensive ablation studies on both datasets validate the effectiveness of our debiasing components. Additionally, our evaluation reveals the limited robustness of existing multimodal QA methods. We also verify the plug-and-play capability of our strategy by integrating it with various baseline models across both datasets. Our dataset and code are available at this https URL.         ",
    "url": "https://arxiv.org/abs/2504.00487",
    "authors": [
      "Jie Ma",
      "Zhitao Gao",
      "Qi Chai",
      "Jun Liu",
      "Pinghui Wang",
      "Jing Tao",
      "Zhou Su"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2504.00540",
    "title": "Adversarial Curriculum Graph-Free Knowledge Distillation for Graph Neural Networks",
    "abstract": "           Data-free Knowledge Distillation (DFKD) is a method that constructs pseudo-samples using a generator without real data, and transfers knowledge from a teacher model to a student by enforcing the student to overcome dimensional differences and learn to mimic the teacher's outputs on these pseudo-samples. In recent years, various studies in the vision domain have made notable advancements in this area. However, the varying topological structures and non-grid nature of graph data render the methods from the vision domain ineffective. Building upon prior research into differentiable methods for graph neural networks, we propose a fast and high-quality data-free knowledge distillation approach in this paper. Without compromising distillation quality, the proposed graph-free KD method (ACGKD) significantly reduces the spatial complexity of pseudo-graphs by leveraging the Binary Concrete distribution to model the graph structure and introducing a spatial complexity tuning parameter. This approach enables efficient gradient computation for the graph structure, thereby accelerating the overall distillation process. Additionally, ACGKD eliminates the dimensional ambiguity between the student and teacher models by increasing the student's dimensions and reusing the teacher's classifier. Moreover, it equips graph knowledge distillation with a CL-based strategy to ensure the student learns graph structures progressively. Extensive experiments demonstrate that ACGKD achieves state-of-the-art performance in distilling knowledge from GNNs without training data.         ",
    "url": "https://arxiv.org/abs/2504.00540",
    "authors": [
      "Yuang Jia",
      "Xiaojuan Shan",
      "Jun Xia",
      "Guancheng Wan",
      "Yuchen Zhang",
      "Wenke Huang",
      "Mang Ye",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.11520",
    "title": "Equitably allocating wildfire resilience investments for power grids: The curse of aggregation and vulnerability indices",
    "abstract": "           Social vulnerability indices have increased traction for guiding infrastructure investment decisions to prioritize communities that need these investments most. One such plan is the Biden-Harris Justice40 initiative, which aims to guide equitable infrastructure investments by ensuring that disadvantaged communities defined by the Climate & Economic Justice Screening Tool (CEJST) receive 40% of the total benefit realized by the investment. However, there is limited research on the practicality of applying vulnerability indices like the CEJST to real-world decision-making for policy outcomes. In this paper, we study this gap by examining the effectiveness of vulnerability indices in a case study focused on power shutoff and undergrounding decisions in wildfire-prone regions. Using a mixed-integer program and a high-fidelity synthetic transmission network in Texas, we model resource allocation policies inspired by Justice40 and evaluate their impact on reducing power outages and mitigating wildfire risk for vulnerable groups. Our analysis reveals that the Justice40 framework may fail to protect certain communities facing high wildfire risk. In our case study, we show that indigenous groups are particularly impacted. We posit that this outcome is likely due to information losses from data aggregation and the use of generalized vulnerability indices. Through the use of explicit group-level protections, we are able to bound the best possible outcome for population groups that are proportionally most affected.         ",
    "url": "https://arxiv.org/abs/2404.11520",
    "authors": [
      "Madeleine Pollack",
      "Ryan Piansky",
      "Swati Gupta",
      "Daniel Molzahn"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2406.00261",
    "title": "Finite groups with geodetic Cayley graphs",
    "abstract": "           A connected undirected graph is called \\emph{geodetic} if for every pair of vertices there is a unique shortest path connecting them. It has been conjectured that for finite groups, the only geodetic Cayley graphs are odd cycles and complete graphs. In this article we present a series of theoretical results which contribute to a computer search verifying this conjecture for all groups of size up to 1024. The conjecture is also verified for several infinite families of groups including dihedral and some families of nilpotent groups. Two key results which enable the computer search to reach as far as it does are: if the center of a group has even order, then the conjecture holds (this eliminates all $2$-groups from our computer search); if a Cayley graph is geodetic then there are bounds relating the size of the group, generating set and center (which significantly cuts down the number of generating sets which must be searched).         ",
    "url": "https://arxiv.org/abs/2406.00261",
    "authors": [
      "Murray Elder",
      "Adam Piggott",
      "Florian Stober",
      "Alexander Thumm",
      "Armin Wei\u00df"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2408.07977",
    "title": "Cortical network reconfiguration aligns with shifts of basal ganglia and cerebellar influence",
    "abstract": "           Mammalian functional architecture flexibly adapts, transitioning from integration where information is distributed across the cortex, to segregation where information is focal in densely connected communities of brain regions. This flexibility in cortical brain networks is hypothesized to be driven by control signals originating from subcortical pathways, with the basal ganglia shifting the cortex towards integrated processing states and the cerebellum towards segregated states. In a sample of healthy human participants (N=242), we used fMRI to measure temporal variation in global brain networks while participants performed two tasks with similar cognitive demands (Stroop and Multi-Source Inference Task (MSIT)). Using the modularity index, we determined cortical networks shifted from integration (low modularity) at rest to high modularity during easier i.e. congruent (segregation). Increased task difficulty (incongruent) resulted in lower modularity in comparison to the easier counterpart indicating more integration of the cortical network. Influence of basal ganglia and cerebellum was measured using eigenvector centrality. Results correlated with decreases and increases in cortical modularity respectively, with only the basal ganglia influence preceding cortical integration. Our results support the theory the basal ganglia shifts cortical networks to integrated states due to environmental demand. Cerebellar influence correlates with shifts to segregated cortical states, though may not play a causal role.         ",
    "url": "https://arxiv.org/abs/2408.07977",
    "authors": [
      "Kimberly Nestor"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2410.10371",
    "title": "Groningen: Spatial Prediction of Rock Gas Saturation by Leveraging Selected and Augmented Well and Seismic Data with Classifier Ensembles",
    "abstract": "           This paper presents a proof of concept for spatial prediction of rock saturation probability using classifier ensemble methods on the example of the giant Groningen gas field. The stages of generating 1481 seismic field attributes and selecting 63 significant attributes are described. The effectiveness of the proposed method of augmentation of well and seismic data is shown, which increased the training sample by 9 times. On a test sample of 42 wells (blind well test), the results demonstrate good accuracy in predicting the ensemble of classifiers: the Matthews correlation coefficient is 0.7689, and the F1-score for the \"gas reservoir\" class is 0.7949. Prediction of gas reservoir thicknesses within the field and adjacent areas is made.         ",
    "url": "https://arxiv.org/abs/2410.10371",
    "authors": [
      "Dmitry Ivlev"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.00022",
    "title": "Autonomous AI for Multi-Pathology Detection in Chest X-Rays: A Multi-Site Study in the Indian Healthcare System",
    "abstract": "           Study Design: The study outlines the development of an autonomous AI system for chest X-ray (CXR) interpretation, trained on a vast dataset of over 5 million X rays sourced from healthcare systems across India. This AI system integrates advanced architectures including Vision Transformers, Faster R-CNN, and various U Net models (such as Attention U-Net, U-Net++, and Dense U-Net) to enable comprehensive classification, detection, and segmentation of 75 distinct pathologies. To ensure robustness, the study design includes subgroup analyses across age, gender, and equipment type, validating the model's adaptability and performance across diverse patient demographics and imaging environments. Performance: The AI system achieved up to 98% precision and over 95% recall for multi pathology classification, with stable performance across demographic and equipment subgroups. For normal vs. abnormal classification, it reached 99.8% precision, 99.6% recall, and 99.9% negative predictive value (NPV). It was deployed in 17 major healthcare systems in India including diagnostic centers, large hospitals, and government hospitals. Over the deployment period, the system processed over 150,000 scans, averaging 2,000 chest X rays daily, resulting in reduced reporting times and improved diagnostic accuracy. Conclusion: The high precision and recall validate the AI's capability as a reliable tool for autonomous normal abnormal classification, pathology localization, and segmentation. This scalable AI model addresses diagnostic gaps in underserved areas, optimizing radiology workflows and enhancing patient care across diverse healthcare settings in India.         ",
    "url": "https://arxiv.org/abs/2504.00022",
    "authors": [
      "Bargava Subramanian",
      "Shajeev Jaikumar",
      "Praveen Shastry",
      "Naveen Kumarasami",
      "Kalyan Sivasailam",
      "Anandakumar D",
      "Keerthana R",
      "Mounigasri M",
      "Kishore Prasath Venkatesh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]