[
  {
    "id": "arXiv:2208.00002",
    "title": "HOB-CNN: Hallucination of Occluded Branches with a Convolutional Neural  Network for 2D Fruit Trees",
    "abstract": "Orchard automation has attracted the attention of researchers recently due to the shortage of global labor force. To automate tasks in orchards such as pruning, thinning, and harvesting, a detailed understanding of the tree structure is required. However, occlusions from foliage and fruits can make it challenging to predict the position of occluded trunks and branches. This work proposes a regression-based deep learning model, Hallucination of Occluded Branch Convolutional Neural Network (HOB-CNN), for tree branch position prediction in varying occluded conditions. We formulate tree branch position prediction as a regression problem towards the horizontal locations of the branch along the vertical direction or vice versa. We present comparative experiments on Y-shaped trees with two state-of-the-art baselines, representing common approaches to the problem. Experiments show that HOB-CNN outperform the baselines at predicting branch position and shows robustness against varying levels of occlusion. We further validated HOB-CNN against two different types of 2D trees, and HOB-CNN shows generalization across different trees and robustness under different occluded conditions. ",
    "url": "https://arxiv.org/abs/2208.00002",
    "authors": [
      "Zijue Chen",
      "Keenan Granland",
      "Rhys Newbury",
      "Chao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2208.00031",
    "title": "Paddy Leaf diseases identification on Infrared Images based on  Convolutional Neural Networks",
    "abstract": "Agriculture is the mainstay of human society because it is an essential need for every organism. Paddy cultivation is very significant so far as humans are concerned, largely in the Asian continent, and it is one of the staple foods. However, plant diseases in agriculture lead to depletion in productivity. Plant diseases are generally caused by pests, insects, and pathogens that decrease productivity to a large scale if not controlled within a particular time. Eventually, one cannot see an increase in paddy yield. Accurate and timely identification of plant diseases can help farmers mitigate losses due to pests and diseases. Recently, deep learning techniques have been used to identify paddy diseases and overcome these problems. This paper implements a convolutional neural network (CNN) based on a model and tests a public dataset consisting of 636 infrared image samples with five paddy disease classes and one healthy class. The proposed model proficiently identified and classified paddy diseases of five different types and achieved an accuracy of 88.28% ",
    "url": "https://arxiv.org/abs/2208.00031",
    "authors": [
      "Petchiammal A",
      "Briskline Kiruba S",
      "D. Murugan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.00033",
    "title": "Personalised recommendations of sleep behaviour with neural networks  using sleep diaries captured in Sleepio",
    "abstract": "SleepioTM is a digital mobile phone and web platform that uses techniques from cognitive behavioural therapy (CBT) to improve sleep in people with sleep difficulty. As part of this process, Sleepio captures data about the sleep behaviour of the users that have consented to such data being processed. For neural networks, the scale of the data is an opportunity to train meaningful models translatable to actual clinical practice. In collaboration with Big Health, the therapeutics company that created and utilizes Sleepio, we have analysed data from a random sample of 401,174 sleep diaries and built a neural network to model sleep behaviour and sleep quality of each individual in a personalised manner. We demonstrate that this neural network is more accurate than standard statistical methods in predicting the sleep quality of an individual based on his/her behaviour from the last 10 days. We compare model performance in a wide range of hyperparameter settings representing various scenarios. We further show that the neural network can be used to produce personalised recommendations of what sleep habits users should follow to maximise sleep quality, and show that these recommendations are substantially better than the ones generated by standard methods. We finally show that the neural network can explain the recommendation given to each participant and calculate confidence intervals for each prediction, all of which are essential for clinicians to be able to adopt such a tool in clinical practice. ",
    "url": "https://arxiv.org/abs/2208.00033",
    "authors": [
      "Alejo Nevado-Holgado",
      "Colin Espie",
      "Maria Liakata",
      "Alasdair Henry",
      "Jenny Gu",
      "Niall Taylor",
      "Kate Saunders",
      "Tom Walker",
      "Chris Miller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.00036",
    "title": "Coordinating Flexible Ramping Products with Dynamics of the Natural Gas  Network",
    "abstract": "In electricity networks with high penetration levels of renewable resources, Flexible Ramping Products (FRPs) are among the utilized measures for dealing with the potential fluctuations in the net demand. This paper investigates the impacts of FRPs on the operation of interdependent electricity and natural gas networks. To accurately model and reflect the effects of variations in the natural gas fuel demand on the natural gas network, a dynamic Optimal Gas Flow (OGF) formulation is utilized. The non-convex dynamic model of the natural gas system is represented in a convex form via a tight relaxation scheme. An improved distributed optimization method is proposed to solve the coordinated operation problem in a privacy-preserving manner, where the two infrastructures only share limited information. We introduce the Inexact Varying Alternating Direction Method of Multipliers (IV-ADMM) and show that compared with the classic ADMM, it converges considerably faster and in fewer iterations. Through a comparison of day-ahead and real-time operation planning results, it is concluded that without accounting for natural gas network dynamics, the FRP model is not a trustworthy tool in day-ahead planning against uncertainties. ",
    "url": "https://arxiv.org/abs/2208.00036",
    "authors": [
      "Reza Bayani",
      "Saeed D. Manshadi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.00050",
    "title": "Generating Complex 4D Expression Transitions by Learning Face Landmark  Trajectories",
    "abstract": "In this work, we address the problem of 4D facial expressions generation. This is usually addressed by animating a neutral 3D face to reach an expression peak, and then get back to the neutral state. In the real world though, people show more complex expressions, and switch from one expression to another. We thus propose a new model that generates transitions between different expressions, and synthesizes long and composed 4D expressions. This involves three sub-problems: (i) modeling the temporal dynamics of expressions, (ii) learning transitions between them, and (iii) deforming a generic mesh. We propose to encode the temporal evolution of expressions using the motion of a set of 3D landmarks, that we learn to generate by training a manifold-valued GAN (Motion3DGAN). To allow the generation of composed expressions, this model accepts two labels encoding the starting and the ending expressions. The final sequence of meshes is generated by a Sparse2Dense mesh Decoder (S2D-Dec) that maps the landmark displacements to a dense, per-vertex displacement of a known mesh topology. By explicitly working with motion trajectories, the model is totally independent from the identity. Extensive experiments on five public datasets show that our proposed approach brings significant improvements with respect to previous solutions, while retaining good generalization to unseen data. ",
    "url": "https://arxiv.org/abs/2208.00050",
    "authors": [
      "Naima Otberdout",
      "Claudio Ferrari",
      "Mohamed Daoudi",
      "Stefano Berretti",
      "Alberto Del Bimbo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00064",
    "title": "Thutmose Tagger: Single-pass neural model for Inverse Text Normalization",
    "abstract": "Inverse text normalization (ITN) is an essential post-processing step in automatic speech recognition (ASR). It converts numbers, dates, abbreviations, and other semiotic classes from the spoken form generated by ASR to their written forms. One can consider ITN as a Machine Translation task and use neural sequence-to-sequence models to solve it. Unfortunately, such neural models are prone to hallucinations that could lead to unacceptable errors. To mitigate this issue, we propose a single-pass token classifier model that regards ITN as a tagging task. The model assigns a replacement fragment to every input token or marks it for deletion or copying without changes. We present a dataset preparation method based on the granular alignment of ITN examples. The proposed model is less prone to hallucination errors. The model is trained on the Google Text Normalization dataset and achieves state-of-the-art sentence accuracy on both English and Russian test sets. One-to-one correspondence between tags and input words improves the interpretability of the model's predictions, simplifies debugging, and allows for post-processing corrections. The model is simpler than sequence-to-sequence models and easier to optimize in production settings. The model and the code to prepare the dataset is published as part of NeMo project. ",
    "url": "https://arxiv.org/abs/2208.00064",
    "authors": [
      "Alexandra Antonova",
      "Evelina Bakhturina",
      "Boris Ginsburg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.00081",
    "title": "Sampling Attacks on Meta Reinforcement Learning: A Minimax Formulation  and Complexity Analysis",
    "abstract": "Meta reinforcement learning (meta RL), as a combination of meta-learning ideas and reinforcement learning (RL), enables the agent to adapt to different tasks using a few samples. However, this sampling-based adaptation also makes meta RL vulnerable to adversarial attacks. By manipulating the reward feedback from sampling processes in meta RL, an attacker can mislead the agent into building wrong knowledge from training experience, which deteriorates the agent's performance when dealing with different tasks after adaptation. This paper provides a game-theoretical underpinning for understanding this type of security risk. In particular, we formally define the sampling attack model as a Stackelberg game between the attacker and the agent, which yields a minimax formulation. It leads to two online attack schemes: Intermittent Attack and Persistent Attack, which enable the attacker to learn an optimal sampling attack, defined by an $\\epsilon$-first-order stationary point, within $\\mathcal{O}(\\epsilon^{-2})$ iterations. These attack schemes freeride the learning progress concurrently without extra interactions with the environment. By corroborating the convergence results with numerical experiments, we observe that a minor effort of the attacker can significantly deteriorate the learning performance, and the minimax approach can also help robustify the meta RL algorithms. ",
    "url": "https://arxiv.org/abs/2208.00081",
    "authors": [
      "Tao Li",
      "Haozhe Lei",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.00087",
    "title": "Low-complexity Approximate Convolutional Neural Networks",
    "abstract": "In this paper, we present an approach for minimizing the computational complexity of trained Convolutional Neural Networks (ConvNet). The idea is to approximate all elements of a given ConvNet and replace the original convolutional filters and parameters (pooling and bias coefficients; and activation function) with efficient approximations capable of extreme reductions in computational complexity. Low-complexity convolution filters are obtained through a binary (zero-one) linear programming scheme based on the Frobenius norm over sets of dyadic rationals. The resulting matrices allow for multiplication-free computations requiring only addition and bit-shifting operations. Such low-complexity structures pave the way for low-power, efficient hardware designs. We applied our approach on three use cases of different complexity: (i) a \"light\" but efficient ConvNet for face detection (with around 1000 parameters); (ii) another one for hand-written digit classification (with more than 180000 parameters); and (iii) a significantly larger ConvNet: AlexNet with $\\approx$1.2 million matrices. We evaluated the overall performance on the respective tasks for different levels of approximations. In all considered applications, very low-complexity approximations have been derived maintaining an almost equal classification performance. ",
    "url": "https://arxiv.org/abs/2208.00087",
    "authors": [
      "R. J. Cintra",
      "S. Duffner",
      "C. Garcia",
      "A. Leite"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2208.00094",
    "title": "Robust Trajectory Prediction against Adversarial Attacks",
    "abstract": "Trajectory prediction using deep neural networks (DNNs) is an essential component of autonomous driving (AD) systems. However, these methods are vulnerable to adversarial attacks, leading to serious consequences such as collisions. In this work, we identify two key ingredients to defend trajectory prediction models against adversarial attacks including (1) designing effective adversarial training methods and (2) adding domain-specific data augmentation to mitigate the performance degradation on clean data. We demonstrate that our method is able to improve the performance by 46% on adversarial data and at the cost of only 3% performance degradation on clean data, compared to the model trained with clean data. Additionally, compared to existing robust methods, our method can improve performance by 21% on adversarial examples and 9% on clean data. Our robust model is evaluated with a planner to study its downstream impacts. We demonstrate that our model can significantly reduce the severe accident rates (e.g., collisions and off-road driving). ",
    "url": "https://arxiv.org/abs/2208.00094",
    "authors": [
      "Yulong Cao",
      "Danfei Xu",
      "Xinshuo Weng",
      "Zhuoqing Mao",
      "Anima Anandkumar",
      "Chaowei Xiao",
      "Marco Pavone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00098",
    "title": "Weakly Supervised Deep Instance Nuclei Detection using Points Annotation  in 3D Cardiovascular Immunofluorescent Images",
    "abstract": "Two major causes of death in the United States and worldwide are stroke and myocardial infarction. The underlying cause of both is thrombi released from ruptured or eroded unstable atherosclerotic plaques that occlude vessels in the heart (myocardial infarction) or the brain (stroke). Clinical studies show that plaque composition plays a more important role than lesion size in plaque rupture or erosion events. To determine the plaque composition, various cell types in 3D cardiovascular immunofluorescent images of plaque lesions are counted. However, counting these cells manually is expensive, time-consuming, and prone to human error. These challenges of manual counting motivate the need for an automated approach to localize and count the cells in images. The purpose of this study is to develop an automatic approach to accurately detect and count cells in 3D immunofluorescent images with minimal annotation effort. In this study, we used a weakly supervised learning approach to train the HoVer-Net segmentation model using point annotations to detect nuclei in fluorescent images. The advantage of using point annotations is that they require less effort as opposed to pixel-wise annotation. To train the HoVer-Net model using point annotations, we adopted a popularly used cluster labeling approach to transform point annotations into accurate binary masks of cell nuclei. Traditionally, these approaches have generated binary masks from point annotations, leaving a region around the object unlabeled (which is typically ignored during model training). However, these areas may contain important information that helps determine the boundary between cells. Therefore, we used the entropy minimization loss function in these areas to encourage the model to output more confident predictions on the unlabeled areas. Our comparison studies indicate that the HoVer-Net model trained using our weakly ... ",
    "url": "https://arxiv.org/abs/2208.00098",
    "authors": [
      "Nazanin Moradinasab",
      "Yash Sharma",
      "Laura S. Shankman",
      "Gary K. Owens",
      "Donald E. Brown"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.00113",
    "title": "Neural Correspondence Field for Object Pose Estimation",
    "abstract": "We propose a method for estimating the 6DoF pose of a rigid object with an available 3D model from a single RGB image. Unlike classical correspondence-based methods which predict 3D object coordinates at pixels of the input image, the proposed method predicts 3D object coordinates at 3D query points sampled in the camera frustum. The move from pixels to 3D points, which is inspired by recent PIFu-style methods for 3D reconstruction, enables reasoning about the whole object, including its (self-)occluded parts. For a 3D query point associated with a pixel-aligned image feature, we train a fully-connected neural network to predict: (i) the corresponding 3D object coordinates, and (ii) the signed distance to the object surface, with the first defined only for query points in the surface vicinity. We call the mapping realized by this network as Neural Correspondence Field. The object pose is then robustly estimated from the predicted 3D-3D correspondences by the Kabsch-RANSAC algorithm. The proposed method achieves state-of-the-art results on three BOP datasets and is shown superior especially in challenging cases with occlusion. The project website is at: linhuang17.github.io/NCF. ",
    "url": "https://arxiv.org/abs/2208.00113",
    "authors": [
      "Lin Huang",
      "Tomas Hodan",
      "Lingni Ma",
      "Linguang Zhang",
      "Luan Tran",
      "Christopher Twigg",
      "Po-Chen Wu",
      "Junsong Yuan",
      "Cem Keskin",
      "Robert Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2208.00146",
    "title": "Reducing Attack Opportunities Through Decentralized Event-Triggered  Control",
    "abstract": "Decentralized control systems are widely used in a number of situations and applications. In order for these systems to function properly and achieve their desired goals, information must be propagated between agents, which requires connecting to a network. To reduce opportunities for attacks that may be carried out through the network, we design an event-triggered mechanism for network connection and communication that minimizes the amount of time agents must be connected to the network, in turn decreasing communication costs. This mechanism is a function of only local information and ensures stability for the overall system in attack-free scenarios. Our approach distinguishes itself from current decentralized event-triggered control strategies by considering scenarios where agents are not always connected to the network to receive critical information from other agents and by considering scenarios where the communication graph is undirected and connected. An algorithm describing this network connection and communication protocol is provided, and our approach is illustrated via simulation. ",
    "url": "https://arxiv.org/abs/2208.00146",
    "authors": [
      "Paul Griffioen",
      "Raffaele Romagnoli",
      "Bruce H. Krogh",
      "Bruno Sinopoli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.00150",
    "title": "Learning Shadow Correspondence for Video Shadow Detection",
    "abstract": "Video shadow detection aims to generate consistent shadow predictions among video frames. However, the current approaches suffer from inconsistent shadow predictions across frames, especially when the illumination and background textures change in a video. We make an observation that the inconsistent predictions are caused by the shadow feature inconsistency, i.e., the features of the same shadow regions show dissimilar proprieties among the nearby frames.In this paper, we present a novel Shadow-Consistent Correspondence method (SC-Cor) to enhance pixel-wise similarity of the specific shadow regions across frames for video shadow detection. Our proposed SC-Cor has three main advantages. Firstly, without requiring the dense pixel-to-pixel correspondence labels, SC-Cor can learn the pixel-wise correspondence across frames in a weakly-supervised manner. Secondly, SC-Cor considers intra-shadow separability, which is robust to the variant textures and illuminations in videos. Finally, SC-Cor is a plug-and-play module that can be easily integrated into existing shadow detectors with no extra computational cost. We further design a new evaluation metric to evaluate the temporal stability of the video shadow detection results. Experimental results show that SC-Cor outperforms the prior state-of-the-art method, by 6.51% on IoU and 3.35% on the newly introduced temporal stability metric. ",
    "url": "https://arxiv.org/abs/2208.00150",
    "authors": [
      "Xinpeng Ding",
      "Jingweng Yang",
      "Xiaowei Hu",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00152",
    "title": "Local Graph Embeddings Based on Neighbors Degree Frequency of Nodes",
    "abstract": "We propose a local-to-global strategy for graph machine learning and network analysis by defining certain local features and vector representations of nodes and then using them to learn globally defined metrics and properties of the nodes by means of deep neural networks. By extending the notion of the degree of a node via Breath-First Search, a general family of {\\bf parametric centrality functions} is defined which are able to reveal the importance of nodes. We introduce the {\\bf neighbors degree frequency (NDF)}, as a locally defined embedding of nodes of undirected graphs into euclidean spaces. This gives rise to a vectorized labeling of nodes which encodes the structure of local neighborhoods of nodes and can be used for graph isomorphism testing. We add flexibility to our construction so that it can handle dynamic graphs as well. Afterwards, the Breadth-First Search is used to extend NDF vector representations into two different matrix representations of nodes which contain higher order information about the neighborhoods of nodes. Our matrix representations of nodes provide us with a new way of visualizing the shape of the neighborhood of a node. Furthermore, we use these matrix representations to obtain feature vectors, which are suitable for typical deep learning algorithms. To demonstrate these node embeddings actually contain some information about the nodes, in a series of examples, we show that PageRank and closeness centrality can be learned by applying deep learning to these local features. Our constructions are flexible enough to handle evolving graphs. Finally, we explain how to adapt our constructions for directed graphs. ",
    "url": "https://arxiv.org/abs/2208.00152",
    "authors": [
      "Vahid Shirbisheh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00164",
    "title": "Distilled Low Rank Neural Radiance Field with Quantization for Light  Field Compression",
    "abstract": "In this paper, we propose a novel light field compression method based on a Quantized Distilled Low Rank Neural Radiance Field (QDLR-NeRF) representation. While existing compression methods encode the set of light field sub-aperture images, our proposed method instead learns an implicit scene representation in the form of a Neural Radiance Field (NeRF), which also enables view synthesis. For reducing its size, the model is first learned under a Low Rank (LR) constraint using a Tensor Train (TT) decomposition in an Alternating Direction Method of Multipliers (ADMM) optimization framework. To further reduce the model size, the components of the tensor train decomposition need to be quantized. However, performing the optimization of the NeRF model by simultaneously taking the low rank constraint and the rate-constrained weight quantization into consideration is challenging. To deal with this difficulty, we introduce a network distillation operation that separates the low rank approximation and the weight quantization in the network training. The information from the initial LR constrained NeRF (LR-NeRF) is distilled to a model of a much smaller dimension (DLR-NeRF) based on the TT decomposition of the LR-NeRF. An optimized global codebook is then learned to quantize all TT components, producing the final QDLRNeRF. Experimental results show that our proposed method yields better compression efficiency compared with state-of-the-art methods, and it additionally has the advantage of allowing the synthesis of any light field view with a high quality. ",
    "url": "https://arxiv.org/abs/2208.00164",
    "authors": [
      "Jinglei Shi",
      "Christine Guillemot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2208.00173",
    "title": "A Survey on Masked Autoencoder for Self-supervised Learning in Vision  and Beyond",
    "abstract": "Masked autoencoders are scalable vision learners, as the title of MAE \\cite{he2022masked}, which suggests that self-supervised learning (SSL) in vision might undertake a similar trajectory as in NLP. Specifically, generative pretext tasks with the masked prediction (e.g., BERT) have become a de facto standard SSL practice in NLP. By contrast, early attempts at generative methods in vision have been buried by their discriminative counterparts (like contrastive learning); however, the success of mask image modeling has revived the masking autoencoder (often termed denoising autoencoder in the past). As a milestone to bridge the gap with BERT in NLP, masked autoencoder has attracted unprecedented attention for SSL in vision and beyond. This work conducts a comprehensive survey of masked autoencoders to shed insight on a promising direction of SSL. As the first to review SSL with masked autoencoders, this work focuses on its application in vision by discussing its historical developments, recent progress, and implications for diverse applications. ",
    "url": "https://arxiv.org/abs/2208.00173",
    "authors": [
      "Chaoning Zhang",
      "Chenshuang Zhang",
      "Junha Song",
      "John Seon Keun Yi",
      "Kang Zhang",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00175",
    "title": "Global, Unified Representation of Heterogenous Robot Dynamics Using  Composition Operators",
    "abstract": "The complexity of robot dynamics often pertains to the hybrid nature of dynamics, where governing dynamic equations consist of heterogenous equations that are switched depending on the state of the system. Legged robots and manipulator robots experience contact-noncontact discrete transitions, causing switching of governing equations. Analysis of these robot systems have been a challenge due to the lack of a global, unified model that is amenable to analysis of the global behaviors. Composition operator theory has the potential to provide a global, unified representation of those heterogenous dynamical systems. It is expected that, if the theory is applicable, those fundamentally challenging robotics systems can be treated as linear dynamical systems in a lifted space. The current work addresses under which conditions a unified linear representation exists in a global sense for a class of heterogenous dynamical systems and how the theory can be applied to those robotics problems. First, a kernel representation of composition operators is obtained, and conditions required for converting the kernel representation to a linear state transition equation are established. This analysis results in an algorithm to convert a class of heterogenous systems including hybrid and switched systems directly to a global, unified linear model. Unlike prevalent data-driven methods and Dynamic Mode Decomposition, where results can vary depending on numerical data, the proposed method does not require numerical simulation of the original dynamics. The implication of the new method and its impact upon robotics are discussed. A few examples validate and demonstrate the method. ",
    "url": "https://arxiv.org/abs/2208.00175",
    "authors": [
      "Harry Asada"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.00183",
    "title": "Few-shot Single-view 3D Reconstruction with Memory Prior Contrastive  Network",
    "abstract": "3D reconstruction of novel categories based on few-shot learning is appealing in real-world applications and attracts increasing research interests. Previous approaches mainly focus on how to design shape prior models for different categories. Their performance on unseen categories is not very competitive. In this paper, we present a Memory Prior Contrastive Network (MPCN) that can store shape prior knowledge in a few-shot learning based 3D reconstruction framework. With the shape memory, a multi-head attention module is proposed to capture different parts of a candidate shape prior and fuse these parts together to guide 3D reconstruction of novel categories. Besides, we introduce a 3D-aware contrastive learning method, which can not only complement the retrieval accuracy of memory network, but also better organize image features for downstream tasks. Compared with previous few-shot 3D reconstruction methods, MPCN can handle the inter-class variability without category annotations. Experimental results on a benchmark synthetic dataset and the Pascal3D+ real-world dataset show that our model outperforms the current state-of-the-art methods significantly. ",
    "url": "https://arxiv.org/abs/2208.00183",
    "authors": [
      "Zhen Xing",
      "Yijiang Chen",
      "Zhixin Ling",
      "Xiangdong Zhou",
      "Yu Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00184",
    "title": "Celeritas: Fast Optimizer for Large Dataflow Graphs",
    "abstract": "The rapidly enlarging neural network models are becoming increasingly challenging to run on a single device. Hence model parallelism over multiple devices is critical to guarantee the efficiency of training large models. Recent proposals fall short either in long processing time or poor performance. Therefore, we propose Celeritas, a fast framework for optimizing device placement for large models. Celeritas employs a simple but efficient model parallelization strategy in the Standard Evaluation, and generates placement policies through a series of scheduling algorithms. We conduct experiments to deploy and evaluate Celeritas on numerous large models. The results show that Celeritas not only reduces the placement policy generation time by 26.4\\% but also improves the model running time by 34.2\\% compared to most advanced methods. ",
    "url": "https://arxiv.org/abs/2208.00184",
    "authors": [
      "Hengwei Xu",
      "Yong Liao",
      "Haiyong Xie",
      "Pengyuan Zhou"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.00203",
    "title": "Adding Context to Source Code Representations for Deep Learning",
    "abstract": "Deep learning models have been successfully applied to a variety of software engineering tasks, such as code classification, summarisation, and bug and vulnerability detection. In order to apply deep learning to these tasks, source code needs to be represented in a format that is suitable for input into the deep learning model. Most approaches to representing source code, such as tokens, abstract syntax trees (ASTs), data flow graphs (DFGs), and control flow graphs (CFGs) only focus on the code itself and do not take into account additional context that could be useful for deep learning models. In this paper, we argue that it is beneficial for deep learning models to have access to additional contextual information about the code being analysed. We present preliminary evidence that encoding context from the call hierarchy along with information from the code itself can improve the performance of a state-of-the-art deep learning model for two software engineering tasks. We outline our research agenda for adding further contextual information to source code representations for deep learning. ",
    "url": "https://arxiv.org/abs/2208.00203",
    "authors": [
      "Fuwei Tian",
      "Christoph Treude"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00204",
    "title": "Tackling Neural Architecture Search With Quality Diversity Optimization",
    "abstract": "Neural architecture search (NAS) has been studied extensively and has grown to become a research field with substantial impact. While classical single-objective NAS searches for the architecture with the best performance, multi-objective NAS considers multiple objectives that should be optimized simultaneously, e.g., minimizing resource usage along the validation error. Although considerable progress has been made in the field of multi-objective NAS, we argue that there is some discrepancy between the actual optimization problem of practical interest and the optimization problem that multi-objective NAS tries to solve. We resolve this discrepancy by formulating the multi-objective NAS problem as a quality diversity optimization (QDO) problem and introduce three quality diversity NAS optimizers (two of them belonging to the group of multifidelity optimizers), which search for high-performing yet diverse architectures that are optimal for application-specific niches, e.g., hardware constraints. By comparing these optimizers to their multi-objective counterparts, we demonstrate that quality diversity NAS in general outperforms multi-objective NAS with respect to quality of solutions and efficiency. We further show how applications and future NAS research can thrive on QDO. ",
    "url": "https://arxiv.org/abs/2208.00204",
    "authors": [
      "Lennart Schneider",
      "Florian Pfisterer",
      "Paul Kent",
      "Juergen Branke",
      "Bernd Bischl",
      "Janek Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2208.00210",
    "title": "Multiple Categories Of Visual Smoke Detection Database",
    "abstract": "Smoke detection has become a significant task in associated industries due to the close relationship between the petrochemical industry's smoke emission and its safety production and environmental damage. There are several production situations in the real industrial production environment, including complete combustion of exhaust gas, inadequate combustion of exhaust gas, direct emission of exhaust gas, etc. We discovered that the datasets used in previous research work can only determine whether smoke is present or not, not its type. That is, the dataset's category does not map to the real-world production situations, which are not conducive to the precise regulation of the production system. As a result, we created a multi-categories smoke detection database that includes a total of 70196 images. We further employed multiple models to conduct the experiment on the proposed database, the results show that the performance of the current algorithms needs to be improved and demonstrate the effectiveness of the proposed database. ",
    "url": "https://arxiv.org/abs/2208.00210",
    "authors": [
      "Y. Gong",
      "X. Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00213",
    "title": "Rapid-Flooding Time Synchronization for Large-Scale Wireless Sensor  Networks",
    "abstract": "Accurate and fast-convergent time synchronization is very important for wireless sensor networks. The flooding time synchronization converges fast, but its transmission delay and by-hop error accumulation seriously reduce the synchronization accuracy. In this article, a rapidflooding multiple one-way broadcast time-synchronization (RMTS) protocol for large-scale wireless sensor networks is proposed. To minimize the by-hop error accumulation, the RMTS uses maximum likelihood estimations for clock skew estimation and clock offset estimation, and quickly shares the estimations among the networks. As a result, the synchronization error resulting from delays is greatly reduced, while faster convergence and higher-accuracy synchronization is achieved. Extensive experimental results demonstrate that, even over 24-hops networks, the RMTS is able to build accurate synchronization at the third synchronization period, and moreover, the by-hop error accumulation is slower when the network diameter increases. ",
    "url": "https://arxiv.org/abs/2208.00213",
    "authors": [
      "Fanrong Shi",
      "Xianguo Tuo",
      "Simon X. Yang",
      "Jing Lu",
      "Huailiang Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.00216",
    "title": "Fast Convergence Time Synchronization in Wireless Sensor Networks Based  on Average Consensus",
    "abstract": "Average consensus theory is intensely popular for building time synchronization in wireless sensor network (WSN). However, the average consensus-based time synchronization algorithm is based on iteration that pose challenges for efficiency, as they entail high communication cost and long convergence time in large-scale WSN. Based on the suggestion that the greater the algebraic connectivity leads to the faster the convergence, a novel multi-hop average consensus time synchronization (MACTS) is developed with innovative implementation in this paper. By employing multi-hop communication model, it shows that virtual communication links among multi-hop nodes are generated and algebraic connectivity of network increases. Meanwhile, a multihop controller is developed to balance the convergence time, accuracy and communication complexity. Moreover, the accurate relative clock offset estimation is yielded by delay compensation. Implementing the MACTS based on the popular one-way broadcast model and taking multi-hop over short distances, we achieve hundreds of times the MACTS convergence rate compared to ATS. ",
    "url": "https://arxiv.org/abs/2208.00216",
    "authors": [
      "Fanrong Shi",
      "Xianguo Tuo",
      "Lili Ran",
      "Zhenwen Ren",
      "Simon X. Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.00219",
    "title": "Meta-DETR: Image-Level Few-Shot Detection with Inter-Class Correlation  Exploitation",
    "abstract": "Few-shot object detection has been extensively investigated by incorporating meta-learning into region-based detection frameworks. Despite its success, the said paradigm is still constrained by several factors, such as (i) low-quality region proposals for novel classes and (ii) negligence of the inter-class correlation among different classes. Such limitations hinder the generalization of base-class knowledge for the detection of novel-class objects. In this work, we design Meta-DETR, which (i) is the first image-level few-shot detector, and (ii) introduces a novel inter-class correlational meta-learning strategy to capture and leverage the correlation among different classes for robust and accurate few-shot object detection. Meta-DETR works entirely at image level without any region proposals, which circumvents the constraint of inaccurate proposals in prevalent few-shot detection frameworks. In addition, the introduced correlational meta-learning enables Meta-DETR to simultaneously attend to multiple support classes within a single feedforward, which allows to capture the inter-class correlation among different classes, thus significantly reducing the misclassification over similar classes and enhancing knowledge generalization to novel classes. Experiments over multiple few-shot object detection benchmarks show that the proposed Meta-DETR outperforms state-of-the-art methods by large margins. The implementation codes are available at https://github.com/ZhangGongjie/Meta-DETR. ",
    "url": "https://arxiv.org/abs/2208.00219",
    "authors": [
      "Gongjie Zhang",
      "Zhipeng Luo",
      "Kaiwen Cui",
      "Shijian Lu",
      "Eric P. Xing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2208.00223",
    "title": "PolarMix: A General Data Augmentation Technique for LiDAR Point Clouds",
    "abstract": "LiDAR point clouds, which are usually scanned by rotating LiDAR sensors continuously, capture precise geometry of the surrounding environment and are crucial to many autonomous detection and navigation tasks. Though many 3D deep architectures have been developed, efficient collection and annotation of large amounts of point clouds remain one major challenge in the analytic and understanding of point cloud data. This paper presents PolarMix, a point cloud augmentation technique that is simple and generic but can mitigate the data constraint effectively across different perception tasks and scenarios. PolarMix enriches point cloud distributions and preserves point cloud fidelity via two cross-scan augmentation strategies that cut, edit, and mix point clouds along the scanning direction. The first is scene-level swapping which exchanges point cloud sectors of two LiDAR scans that are cut along the azimuth axis. The second is instance-level rotation and paste which crops point instances from one LiDAR scan, rotates them by multiple angles (to create multiple copies), and paste the rotated point instances into other scans. Extensive experiments show that PolarMix achieves superior performance consistently across different perception tasks and scenarios. In addition, it can work as plug-and-play for various 3D deep architectures and also performs well for unsupervised domain adaptation. ",
    "url": "https://arxiv.org/abs/2208.00223",
    "authors": [
      "Aoran Xiao",
      "Jiaxing Huang",
      "Dayan Guan",
      "Kaiwen Cui",
      "Shijian Lu",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00231",
    "title": "Masked Autoencoders As The Unified Learners For Pre-Trained Sentence  Representation",
    "abstract": "Despite the progresses on pre-trained language models, there is a lack of unified frameworks for pre-trained sentence representation. As such, it calls for different pre-training methods for specific scenarios, and the pre-trained models are likely to be limited by their universality and representation quality. In this work, we extend the recently proposed MAE style pre-training strategy, RetroMAE, such that it may effectively support a wide variety of sentence representation tasks. The extended framework consists of two stages, with RetroMAE conducted throughout the process. The first stage performs RetroMAE over generic corpora, like Wikipedia, BookCorpus, etc., from which the base model is learned. The second stage takes place on domain-specific data, e.g., MS MARCO and NLI, where the base model is continuingly trained based on RetroMAE and contrastive learning. The pre-training outputs at the two stages may serve different applications, whose effectiveness are verified with comprehensive experiments. Concretely, the base model are proved to be effective for zero-shot retrieval, with remarkable performances achieved on BEIR benchmark. The continuingly pre-trained models further benefit more downstream tasks, including the domain-specific dense retrieval on MS MARCO, Natural Questions, and the sentence embeddings' quality for standard STS and transfer tasks in SentEval. The empirical insights of this work may inspire the future design of sentence representation pre-training. Our pre-trained models and source code will be released to the public communities. ",
    "url": "https://arxiv.org/abs/2208.00231",
    "authors": [
      "Alexander Liu",
      "Samuel Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2208.00238",
    "title": "Improving Fine-tuning of Self-supervised Models with Contrastive  Initialization",
    "abstract": "Self-supervised learning (SSL) has achieved remarkable performance in pretraining the models that can be further used in downstream tasks via fine-tuning. However, these self-supervised models may not capture meaningful semantic information since the images belonging to the same class are always regarded as negative pairs in the contrastive loss. Consequently, the images of the same class are often located far away from each other in learned feature space, which would inevitably hamper the fine-tuning process. To address this issue, we seek to provide a better initialization for the self-supervised models by enhancing the semantic information. To this end, we propose a Contrastive Initialization (COIN) method that breaks the standard fine-tuning pipeline by introducing an extra initialization stage before fine-tuning. Extensive experiments show that, with the enriched semantics, our COIN significantly outperforms existing methods without introducing extra training cost and sets new state-of-the-arts on multiple downstream tasks. ",
    "url": "https://arxiv.org/abs/2208.00238",
    "authors": [
      "Haolin Pan",
      "Yong Guo",
      "Qinyi Deng",
      "Haomin Yang",
      "Yiqun Chen",
      "Jian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00246",
    "title": "Geometric deep learning for computational mechanics Part II: Graph  embedding for interpretable multiscale plasticity",
    "abstract": "The history-dependent behaviors of classical plasticity models are often driven by internal variables evolved according to phenomenological laws. The difficulty to interpret how these internal variables represent a history of deformation, the lack of direct measurement of these internal variables for calibration and validation, and the weak physical underpinning of those phenomenological laws have long been criticized as barriers to creating realistic models. In this work, geometric machine learning on graph data (e.g. finite element solutions) is used as a means to establish a connection between nonlinear dimensional reduction techniques and plasticity models. Geometric learning-based encoding on graphs allows the embedding of rich time-history data onto a low-dimensional Euclidean space such that the evolution of plastic deformation can be predicted in the embedded feature space. A corresponding decoder can then convert these low-dimensional internal variables back into a weighted graph such that the dominating topological features of plastic deformation can be observed and analyzed. ",
    "url": "https://arxiv.org/abs/2208.00246",
    "authors": [
      "Nikolaos N. Vlassis",
      "WaiChing Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)"
    ]
  },
  {
    "id": "arXiv:2208.00262",
    "title": "Energy-Aware, Collision-Free Information Gathering for Heterogeneous  Robot Teams",
    "abstract": "This paper considers the problem of safely coordinating a team of sensor-equipped robots to reduce uncertainty about a dynamical process, where the objective trades off information gain and energy cost. Optimizing this trade-off is desirable, but leads to a non-monotone objective function in the set of robot trajectories. Therefore, common multi-robot planners based on coordinate descent lose their performance guarantees. Furthermore, methods that handle non-monotonicity lose their performance guarantees when subject to inter-robot collision avoidance constraints. As it is desirable to retain both the performance guarantee and safety guarantee, this work proposes a hierarchical approach with a distributed planner that uses local search with a worst-case performance guarantees and a decentralized controller based on control barrier functions that ensures safety and encourages timely arrival at sensing locations. Via extensive simulations, hardware-in-the-loop tests and hardware experiments, we demonstrate that the proposed approach achieves a better trade-off between sensing and energy cost than coordinate descent based algorithms. ",
    "url": "https://arxiv.org/abs/2208.00262",
    "authors": [
      "Xiaoyi Cai",
      "Brent Schlotfeldt",
      "Kasra Khosoussi",
      "Nikolay Atanasov",
      "George J. Pappas",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.00264",
    "title": "Mining unit test cases to synthesize API usage examples",
    "abstract": "Software developers study and reuse existing source code to understand how to properly use application programming interfaces (APIs). However, manually finding sufficient and adequate code examples for a given API is a difficult and a time-consuming activity. Existing approaches to find or generate examples assume availability of a reasonable set of client code that uses the API. This assumption does not hold for newly released API libraries, non-widely used APIs, nor private ones. In this work we reuse the important information that is naturally present in test code to circumvent the lack of usage examples for an API when other sources of client code are not available. We propose an approach for automatically identifying the most representative API uses within each unit test case. We then develop an approach to synthesize API usage examples by extracting relevant statements representing the usage of such APIs. We compare the output of a prototype implementation of our approach to both human-written examples and to a state-of-the-art approach. The obtained results are encouraging; the examples automatically generated with our approach are superior to the state-of-the-art approach and highly similar to the manually constructed examples. ",
    "url": "https://arxiv.org/abs/2208.00264",
    "authors": [
      "Mohammad Ghafari",
      "Konstantin Rubinov",
      "Mohammad Mehdi Pourhashem K"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2208.00273",
    "title": "Optimizing Differentially-Maintained Recursive Queries on Dynamic Graphs",
    "abstract": "Differential computation (DC) is a highly general incremental computation/view maintenance technique that can maintain the output of an arbitrary and possibly recursive dataflow computation upon changes to its base inputs. As such, it is a promising technique for graph database management systems (GDBMS) that support continuous recursive queries over dynamic graphs. Although differential computation can be highly efficient for maintaining these queries, it can require a prohibitively large amount of memory. This paper studies how to reduce the memory overhead of DC with the goal of increasing the scalability of systems that adopt it. We propose a suite of optimizations that are based on dropping the differences of operators, both completely or partially, and recomputing these differences when necessary. We propose deterministic and probabilistic data structures to keep track of the dropped differences. Extensive experiments demonstrate that the optimizations can improve the scalability of a DC-based continuous query processor. ",
    "url": "https://arxiv.org/abs/2208.00273",
    "authors": [
      "Khaled Ammar",
      "Siddhartha Sahu",
      "Semih Salihoglu",
      "M. Tamer Ozsu"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2208.00275",
    "title": "Revisiting the Critical Factors of Augmentation-Invariant Representation  Learning",
    "abstract": "We focus on better understanding the critical factors of augmentation-invariant representation learning. We revisit MoCo v2 and BYOL and try to prove the authenticity of the following assumption: different frameworks bring about representations of different characteristics even with the same pretext task. We establish the first benchmark for fair comparisons between MoCo v2 and BYOL, and observe: (i) sophisticated model configurations enable better adaptation to pre-training dataset; (ii) mismatched optimization strategies of pre-training and fine-tuning hinder model from achieving competitive transfer performances. Given the fair benchmark, we make further investigation and find asymmetry of network structure endows contrastive frameworks to work well under the linear evaluation protocol, while may hurt the transfer performances on long-tailed classification tasks. Moreover, negative samples do not make models more sensible to the choice of data augmentations, nor does the asymmetric network structure. We believe our findings provide useful information for future work. ",
    "url": "https://arxiv.org/abs/2208.00275",
    "authors": [
      "Junqiang Huang",
      "Xiangwen Kong",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00277",
    "title": "MobileNeRF: Exploiting the Polygon Rasterization Pipeline for Efficient  Neural Field Rendering on Mobile Architectures",
    "abstract": "Neural Radiance Fields (NeRFs) have demonstrated amazing ability to synthesize images of 3D scenes from novel views. However, they rely upon specialized volumetric rendering algorithms based on ray marching that are mismatched to the capabilities of widely deployed graphics hardware. This paper introduces a new NeRF representation based on textured polygons that can synthesize novel images efficiently with standard rendering pipelines. The NeRF is represented as a set of polygons with textures representing binary opacities and feature vectors. Traditional rendering of the polygons with a z-buffer yields an image with features at every pixel, which are interpreted by a small, view-dependent MLP running in a fragment shader to produce a final pixel color. This approach enables NeRFs to be rendered with the traditional polygon rasterization pipeline, which provides massive pixel-level parallelism, achieving interactive frame rates on a wide range of compute platforms, including mobile phones. ",
    "url": "https://arxiv.org/abs/2208.00277",
    "authors": [
      "Zhiqin Chen",
      "Thomas Funkhouser",
      "Peter Hedman",
      "Andrea Tagliasacchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00278",
    "title": "Robust Contact State Estimation in Humanoid Walking Gaits",
    "abstract": "In this article, we propose a deep learning framework that provides a unified approach to the problem of leg contact detection in humanoid robot walking gaits. Our formulation accomplishes to accurately and robustly estimate the contact state probability for each leg (i.e., stable or slip/no contact). The proposed framework employs solely proprioceptive sensing and although it relies on simulated ground-truth contact data for the classification process, we demonstrate that it generalizes across varying friction surfaces and different legged robotic platforms and, at the same time, is readily transferred from simulation to practice. The framework is quantitatively and qualitatively assessed in simulation via the use of ground-truth contact data and is contrasted against state of-the-art methods with an ATLAS, a NAO, and a TALOS humanoid robot. Furthermore, its efficacy is demonstrated in base estimation with a real TALOS humanoid. To reinforce further research endeavors, our implementation is offered as an open-source ROS/Python package, coined Legged Contact Detection (LCD). ",
    "url": "https://arxiv.org/abs/2208.00278",
    "authors": [
      "Stylianos Piperakis",
      "Michael Maravgakis",
      "Dimitrios Kanoulas",
      "Panos Trahanias"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00293",
    "title": "Global Attention-based Encoder-Decoder LSTM Model for Temperature  Prediction of Permanent Magnet Synchronous Motors",
    "abstract": "Temperature monitoring is critical for electrical motors to determine if device protection measures should be executed. However, the complexity of the internal structure of Permanent Magnet Synchronous Motors (PMSM) makes the direct temperature measurement of the internal components difficult. This work pragmatically develops three deep learning models to estimate the PMSMs' internal temperature based on readily measurable external quantities. The proposed supervised learning models exploit Long Short-Term Memory (LSTM) modules, bidirectional LSTM, and attention mechanism to form encoder-decoder structures to predict simultaneously the temperatures of the stator winding, tooth, yoke, and permanent magnet. Experiments were conducted in an exhaustive manner on a benchmark dataset to verify the proposed models' performances. The comparative analysis shows that the proposed global attention-based encoder-decoder (EnDec) model provides a competitive overall performance of 1.72 Mean Squared Error (MSE) and 5.34 Mean Absolute Error (MAE). ",
    "url": "https://arxiv.org/abs/2208.00293",
    "authors": [
      "Jun Li",
      "Thangarajah Akilan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.00302",
    "title": "Efficient Compilation and Mapping of Fixed Function Combinational Logic  onto Digital Signal Processors Targeting Neural Network Inference and  Utilizing High-level Synthesis",
    "abstract": "Recent efforts for improving the performance of neural network (NN) accelerators that meet today's application requirements have given rise to a new trend of logic-based NN inference relying on fixed function combinational logic. Mapping such large Boolean functions with many input variables and product terms to digital signal processors (DSPs) on Field-programmable gate arrays (FPGAs) needs a novel framework considering the structure and the reconfigurability of DSP blocks during this process. The proposed methodology in this paper maps the fixed function combinational logic blocks to a set of Boolean functions where Boolean operations corresponding to each function are mapped to DSP devices rather than look-up tables (LUTs) on the FPGAs to take advantage of the high performance, low latency, and parallelism of DSP blocks. % This paper also presents an innovative design and optimization methodology for compilation and mapping of NNs, utilizing fixed function combinational logic to DSPs on FPGAs employing high-level synthesis flow. % Our experimental evaluations across several \\REVone{datasets} and selected NNs demonstrate the comparable performance of our framework in terms of the inference latency and output accuracy compared to prior art FPGA-based NN accelerators employing DSPs. ",
    "url": "https://arxiv.org/abs/2208.00302",
    "authors": [
      "Soheil Nazar Shahsavani",
      "Arash Fayyazi",
      "Mahdi Nazemi",
      "Massoud Pedram"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00312",
    "title": "An Improved A* Search Algorithm for Road Networks Using New Heuristic  Estimation",
    "abstract": "Finding the shortest path between two points in a graph is a fundamental problem that has been well-studied over the past several decades. Shortest path algorithms are commonly applied to modern navigation systems, so our study aims to improve the efficiency of an existing algorithm on large-scale Euclidean networks. The current literature lacks a deep understanding of certain algorithms' performance on these types of networks. Therefore, we incorporate a new heuristic function, called the $k$-step look-ahead, into the A* search algorithm and conduct a computational experiment to evaluate and compare the results on road networks of varying sizes. Our main findings are that this new heuristic yields a significant improvement in runtime, particularly for larger networks when compared to standard A*, as well as that a higher value of $k$ is needed to achieve optimal efficiency as network size increases. Future research can build upon this work by implementing a program that automatically chooses an optimal $k$ value given an input network. The results of this study can be applied to GPS routing technologies or other navigation devices to speed up the time needed to find the shortest path from an origin to a destination, an essential objective in daily life. ",
    "url": "https://arxiv.org/abs/2208.00312",
    "authors": [
      "Kevin Y. Chen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2208.00318",
    "title": "Smoothing Entailment Graphs with Language Models",
    "abstract": "The diversity and Zipfian frequency distribution of natural language predicates in corpora leads to sparsity when learning Entailment Graphs. As symbolic models for natural language inference, an EG cannot recover if missing a novel premise or hypothesis at test-time. In this paper we approach the problem of vertex sparsity by introducing a new method of graph smoothing, using a Language Model to find the nearest approximations of missing predicates. We improve recall by 25.1 and 16.3 absolute percentage points on two difficult directional entailment datasets while exceeding average precision, and show a complementarity with other improvements to edge sparsity. We further analyze language model embeddings and discuss why they are naturally suitable for premise-smoothing, but not hypothesis-smoothing. Finally, we formalize a theory for smoothing a symbolic inference method by constructing transitive chains to smooth both the premise and hypothesis. ",
    "url": "https://arxiv.org/abs/2208.00318",
    "authors": [
      "Nick McKenna",
      "Mark Steedman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2208.00319",
    "title": "Robust Planning for Multi-stage Forceful Manipulation",
    "abstract": "Multi-step forceful manipulation tasks, such as opening a push-and-twist childproof bottle, require a robot to make various planning choices that are substantially impacted by the requirement to exert force during the task. The robot must reason over discrete and continuous choices relating to the sequence of actions, such as whether to pick up an object, and the parameters of each of those actions, such how to grasp the object. To enable planning and executing forceful manipulation, we augment an existing task and motion planner with constraints that explicitly consider torque and frictional limits, captured through the proposed forceful kinematic chain constraint. In three domains, opening a childproof bottle, twisting a nut and cutting a vegetable, we demonstrate how the system selects from among a combinatorial set of strategies.We also show how cost-sensitive planning can be used to find strategies and parameters that are robust to uncertainty in the physical parameters. ",
    "url": "https://arxiv.org/abs/2208.00319",
    "authors": [
      "Rachel Holladay",
      "Tom\u00e1s Lozano-P\u00e9rez",
      "Alberto Rodriguez"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2208.00322",
    "title": "PrePARE: Predictive Proprioception for Agile Failure Event Detection in  Robotic Exploration of Extreme Terrains",
    "abstract": "Legged robots can traverse a wide variety of terrains, some of which may be challenging for wheeled robots, such as stairs or highly uneven surfaces. However, quadruped robots face stability challenges on slippery surfaces. This can be resolved by adjusting the robot's locomotion by switching to more conservative and stable locomotion modes, such as crawl mode (where three feet are in contact with the ground always) or amble mode (where one foot touches down at a time) to prevent potential falls. To tackle these challenges, we propose an approach to learn a model from past robot experience for predictive detection of potential failures. Accordingly, we trigger gait switching merely based on proprioceptive sensory information. To learn this predictive model, we propose a semi-supervised process for detecting and annotating ground truth slip events in two stages: We first detect abnormal occurrences in the time series sequences of the gait data using an unsupervised anomaly detector, and then, the anomalies are verified with expert human knowledge in a replay simulation to assert the event of a slip. These annotated slip events are then used as ground truth examples to train an ensemble decision learner for predicting slip probabilities across terrains for traversability. We analyze our model on data recorded by a legged robot on multiple sites with slippery terrain. We demonstrate that a potential slip event can be predicted up to 720 ms ahead of a potential fall with an average precision greater than 0.95 and an average F-score of 0.82. Finally, we validate our approach in real-time by deploying it on a legged robot and switching its gait mode based on slip event detection. ",
    "url": "https://arxiv.org/abs/2208.00322",
    "authors": [
      "Sharmita Dey",
      "David Fan",
      "Robin Schmid",
      "Anushri Dixit",
      "Kyohei Otsu",
      "Thomas Touma",
      "Arndt F. Schilling",
      "Ali-akbar Agha-mohammadi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2208.00328",
    "title": "enpheeph: A Fault Injection Framework for Spiking and Compressed Deep  Neural Networks",
    "abstract": "Research on Deep Neural Networks (DNNs) has focused on improving performance and accuracy for real-world deployments, leading to new models, such as Spiking Neural Networks (SNNs), and optimization techniques, e.g., quantization and pruning for compressed networks. However, the deployment of these innovative models and optimization techniques introduces possible reliability issues, which is a pillar for DNNs to be widely used in safety-critical applications, e.g., autonomous driving. Moreover, scaling technology nodes have the associated risk of multiple faults happening at the same time, a possibility not addressed in state-of-the-art resiliency analyses. Towards better reliability analysis for DNNs, we present enpheeph, a Fault Injection Framework for Spiking and Compressed DNNs. The enpheeph framework enables optimized execution on specialized hardware devices, e.g., GPUs, while providing complete customizability to investigate different fault models, emulating various reliability constraints and use-cases. Hence, the faults can be executed on SNNs as well as compressed networks with minimal-to-none modifications to the underlying code, a feat that is not achievable by other state-of-the-art tools. To evaluate our enpheeph framework, we analyze the resiliency of different DNN and SNN models, with different compression techniques. By injecting a random and increasing number of faults, we show that DNNs can show a reduction in accuracy with a fault rate as low as 7 x 10 ^ (-7) faults per parameter, with an accuracy drop higher than 40%. Run-time overhead when executing enpheeph is less than 20% of the baseline execution time when executing 100 000 faults concurrently, at least 10x lower than state-of-the-art frameworks, making enpheeph future-proof for complex fault injection scenarios. We release enpheeph at https://github.com/Alexei95/enpheeph. ",
    "url": "https://arxiv.org/abs/2208.00328",
    "authors": [
      "Alessio Colucci",
      "Andreas Steininger",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00331",
    "title": "CoNLoCNN: Exploiting Correlation and Non-Uniform Quantization for  Energy-Efficient Low-precision Deep Convolutional Neural Networks",
    "abstract": "In today's era of smart cyber-physical systems, Deep Neural Networks (DNNs) have become ubiquitous due to their state-of-the-art performance in complex real-world applications. The high computational complexity of these networks, which translates to increased energy consumption, is the foremost obstacle towards deploying large DNNs in resource-constrained systems. Fixed-Point (FP) implementations achieved through post-training quantization are commonly used to curtail the energy consumption of these networks. However, the uniform quantization intervals in FP restrict the bit-width of data structures to large values due to the need to represent most of the numbers with sufficient resolution and avoid high quantization errors. In this paper, we leverage the key insight that (in most of the scenarios) DNN weights and activations are mostly concentrated near zero and only a few of them have large magnitudes. We propose CoNLoCNN, a framework to enable energy-efficient low-precision deep convolutional neural network inference by exploiting: (1) non-uniform quantization of weights enabling simplification of complex multiplication operations; and (2) correlation between activation values enabling partial compensation of quantization errors at low cost without any run-time overheads. To significantly benefit from non-uniform quantization, we also propose a novel data representation format, Encoded Low-Precision Binary Signed Digit, to compress the bit-width of weights while ensuring direct use of the encoded weight for processing using a novel multiply-and-accumulate (MAC) unit design. ",
    "url": "https://arxiv.org/abs/2208.00331",
    "authors": [
      "Muhammad Abdullah Hanif",
      "Giuseppe Maria Sarda",
      "Alberto Marchisio",
      "Guido Masera",
      "Maurizio Martina",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00335",
    "title": "Functional Rule Extraction Method for Artificial Neural Networks",
    "abstract": "The idea I propose in this paper is a method that is based on comprehensive functions for directed and undirected rule extraction from artificial neural network operations. ",
    "url": "https://arxiv.org/abs/2208.00335",
    "authors": [
      "Caleb Princewill Nwokocha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00338",
    "title": "Symmetry Regularization and Saturating Nonlinearity for Robust  Quantization",
    "abstract": "Robust quantization improves the tolerance of networks for various implementations, allowing reliable output in different bit-widths or fragmented low-precision arithmetic. In this work, we perform extensive analyses to identify the sources of quantization error and present three insights to robustify a network against quantization: reduction of error propagation, range clamping for error minimization, and inherited robustness against quantization. Based on these insights, we propose two novel methods called symmetry regularization (SymReg) and saturating nonlinearity (SatNL). Applying the proposed methods during training can enhance the robustness of arbitrary neural networks against quantization on existing post-training quantization (PTQ) and quantization-aware training (QAT) algorithms and enables us to obtain a single weight flexible enough to maintain the output quality under various conditions. We conduct extensive studies on CIFAR and ImageNet datasets and validate the effectiveness of the proposed methods. ",
    "url": "https://arxiv.org/abs/2208.00338",
    "authors": [
      "Sein Park",
      "Yeongsang Jang",
      "Eunhyeok Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.00339",
    "title": "GraphMFT: A Graph Attention based Multimodal Fusion Technique for  Emotion Recognition in Conversation",
    "abstract": "Multimodal machine learning is an emerging area of research, which has received a great deal of scholarly attention in recent years. Up to now, there are few studies on multimodal conversational emotion recognition. Since Graph Neural Networks (GNNs) possess the powerful capacity of relational modeling, they have an inherent advantage in the field of multimodal learning. Multimodal data can be modeled as a graph, where each data object is regarded as a node, and both intra- and inter-modal dependencies existing between data objects can be regarded as edges. GNNs leverage the graph constructed from multimodal data to perform intra- and inter-modal information interaction, which effectively facilitates the integration and complementation of multimodal data. In this work, we propose a novel Graph attention based Multimodal Fusion Technique (GraphMFT) for emotion recognition in conversation. GraphMFT utilizes multiple graph attention networks improved to capture intra-modal contextual information and inter-modal complementary information. In addition, the proposed GraphMFT attempts to address the challenges of existing graph-based multimodal ERC models such as MMGCN. Empirical results on two public multimodal datasets reveal that our model outperforms the State-Of-The-Art (SOTA) approachs with the accuracies of 67.90% and 61.30%. ",
    "url": "https://arxiv.org/abs/2208.00339",
    "authors": [
      "Jiang Li",
      "Xiaoping Wang",
      "Guoqing Lv",
      "Zhigang Zeng"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2208.00343",
    "title": "Electromagnetic Signal Injection Attacks on Differential Signaling",
    "abstract": "Differential signaling is a method of data transmission that uses two complementary electrical signals to encode information. This allows a receiver to reject any noise by looking at the difference between the two signals, assuming the noise affects both signals in the same way. Many protocols such as USB, Ethernet, and HDMI use differential signaling to achieve a robust communication channel in a noisy environment. This generally works well and has led many to believe that it is infeasible to remotely inject attacking signals into such a differential pair. In this paper we challenge this assumption and show that an adversary can in fact inject malicious signals from a distance, purely using common-mode injection, i.e., injecting into both wires at the same time. We show how this allows an attacker to inject bits or even arbitrary messages into a communication line. Such an attack is a significant threat to many applications, from home security and privacy to automotive systems, critical infrastructure, or implantable medical devices; in which incorrect data or unauthorized control could cause significant damage, or even fatal accidents. We show in detail the principles of how an electromagnetic signal can bypass the noise rejection of differential signaling, and eventually result in incorrect bits in the receiver. We show how an attacker can exploit this to achieve a successful injection of an arbitrary bit, and we analyze the success rate of injecting longer arbitrary messages. We demonstrate the attack on a real system and show that the success rate can reach as high as $90\\%$. Finally, we present a case study where we wirelessly inject a message into a Controller Area Network (CAN) bus, which is a differential signaling bus protocol used in many critical applications, including the automotive and aviation sector. ",
    "url": "https://arxiv.org/abs/2208.00343",
    "authors": [
      "Youqian Zhang",
      "Kasper Rasmussen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2208.00348",
    "title": "Random Networks with Heterogeneous Reciprocity",
    "abstract": "Users of social networks display diversified behavior and online habits. For instance, a user's tendency to reply to a post can depend on the user and the person posting. For convenience, we group users into aggregated behavioral patterns, focusing here on the tendency to reply to or reciprocate messages. The reciprocity feature in social networks reflects the information exchange among users. We study the properties of a preferential attachment model with heterogeneous reciprocity levels, give the growth rate of model edge counts, and prove convergence of empirical degree frequencies to a limiting distribution. This limiting distribution is not only multivariate regularly varying, but also has the property of hidden regular variation. ",
    "url": "https://arxiv.org/abs/2208.00348",
    "authors": [
      "Tiandong Wang",
      "Sidney Resnick"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2208.00358",
    "title": "Age of View: A New Metric for Evaluating Heterogeneous Information  Fusion in Vehicular Cyber-Physical Systems",
    "abstract": "Heterogeneous information fusion is one of the most critical issues for realizing vehicular cyber-physical systems (VCPSs). This work makes the first attempt at quantitatively measuring the quality of heterogeneous information fusion in VCPS by designing a new metric called Age of View (AoV). Specifically, we derive a sensing model based on a multi-class M/G/1 priority queue and a transmission model based on Shannon theory. On this basis, we formally define AoV by modeling the timeliness, completeness, and consistency of the heterogeneous information fusion in VCPS and formulate the problem aiming to minimize the system's average AoV. Further, we propose a new solution called Multi-agent Difference-Reward-based deep reinforcement learning with a Greedy Bandwidth Allocation (MDR-GBA) to solve the problem. In particular, each vehicle acts as an independent agent and decides the sensing frequencies and uploading priorities of heterogeneous information. Meanwhile, the roadside unit (RSU) decides the Vehicle-to-Infrastructure (V2I) bandwidth allocation for each vehicle based on a greedy scheme. Finally, we build the simulation model and compare the performance of the proposed solution with state-of-the-art algorithms. The experimental results conclusively demonstrate the significance of the new metric and the superiority of the proposed solution. ",
    "url": "https://arxiv.org/abs/2208.00358",
    "authors": [
      "Xincao Xu",
      "Kai Liu",
      "Qisen Zhang",
      "Hao Jiang",
      "Ke Xiao",
      "Jiangtao Luo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2208.00368",
    "title": "Skeleton-Parted Graph Scattering Networks for 3D Human Motion Prediction",
    "abstract": "Graph convolutional network based methods that model the body-joints' relations, have recently shown great promise in 3D skeleton-based human motion prediction. However, these methods have two critical issues: first, deep graph convolutions filter features within only limited graph spectrums, losing sufficient information in the full band; second, using a single graph to model the whole body underestimates the diverse patterns on various body-parts. To address the first issue, we propose adaptive graph scattering, which leverages multiple trainable band-pass graph filters to decompose pose features into richer graph spectrum bands. To address the second issue, body-parts are modeled separately to learn diverse dynamics, which enables finer feature extraction along the spatial dimensions. Integrating the above two designs, we propose a novel skeleton-parted graph scattering network (SPGSN). The cores of the model are cascaded multi-part graph scattering blocks (MPGSBs), building adaptive graph scattering on diverse body-parts, as well as fusing the decomposed features based on the inferred spectrum importance and body-part interactions. Extensive experiments have shown that SPGSN outperforms state-of-the-art methods by remarkable margins of 13.8%, 9.3% and 2.7% in terms of 3D mean per joint position error (MPJPE) on Human3.6M, CMU Mocap and 3DPW datasets, respectively. ",
    "url": "https://arxiv.org/abs/2208.00368",
    "authors": [
      "Maosen Li",
      "Siheng Chen",
      "Zijing Zhang",
      "Lingxi Xie",
      "Qi Tian",
      "Ya Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00369",
    "title": "Exploring Attention-Aware Network Resource Allocation for Customized  Metaverse Services",
    "abstract": "Emerging with the support of computing and communications technologies, Metaverse is expected to bring users unprecedented service experiences. However, the increase in the number of Metaverse users places a heavy demand on network resources, especially for Metaverse services that are based on graphical extended reality and require rendering a plethora of virtual objects. To make efficient use of network resources and improve the Quality-of-Experience (QoE), we design an attention-aware network resource allocation scheme to achieve customized Metaverse services. The aim is to allocate more network resources to virtual objects in which users are more interested. We first discuss several key techniques related to Metaverse services, including QoE analysis, eye-tracking, and remote rendering. We then review existing datasets and propose the user-object-attention level (UOAL) dataset that contains the ground truth attention of 30 users to 96 objects in 1,000 images. A tutorial on how to use UOAL is presented. With the help of UOAL, we propose an attention-aware network resource allocation algorithm that has two steps, i.e., attention prediction and QoE maximization. Specially, we provide an overview of the designs of two types of attention prediction methods, i.e., interest-aware and time-aware prediction. By using the predicted user-object-attention values, network resources such as the rendering capacity of edge devices can be allocated optimally to maximize the QoE. Finally, we propose promising research directions related to Metaverse services. ",
    "url": "https://arxiv.org/abs/2208.00369",
    "authors": [
      "Hongyang Du",
      "Jiacheng Wang",
      "Dusit Niyato",
      "Jiawen Kang",
      "Zehui Xiong",
      "Xuemin",
      "Shen",
      "Dong In Kim"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.00394",
    "title": "STrajNet: Occupancy Flow Prediction via Multi-modal Swin Transformer",
    "abstract": "Making an accurate prediction of occupancy and flow is essential to enable better safety and interaction for autonomous vehicles under complex traffic scenarios. This work proposes STrajNet: a multi-modal Swin Transformerbased framework for effective scene occupancy and flow predictions. We employ Swin Transformer to encode the image and interaction-aware motion representations and propose a cross-attention module to inject motion awareness into grid cells across different time steps. Flow and occupancy predictions are then decoded through temporalsharing Pyramid decoders. The proposed method shows competitive prediction accuracy and other evaluation metrics in the Waymo Open Dataset benchmark. ",
    "url": "https://arxiv.org/abs/2208.00394",
    "authors": [
      "Haochen Liu",
      "Zhiyu Huang",
      "Chen Lv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.00398",
    "title": "Ultra-low Latency Adaptive Local Binary Spiking Neural Network with  Accuracy Loss Estimator",
    "abstract": "Spiking neural network (SNN) is a brain-inspired model which has more spatio-temporal information processing capacity and computational energy efficiency. However, with the increasing depth of SNNs, the memory problem caused by the weights of SNNs has gradually attracted attention. Inspired by Artificial Neural Networks (ANNs) quantization technology, binarized SNN (BSNN) is introduced to solve the memory problem. Due to the lack of suitable learning algorithms, BSNN is usually obtained by ANN-to-SNN conversion, whose accuracy will be limited by the trained ANNs. In this paper, we propose an ultra-low latency adaptive local binary spiking neural network (ALBSNN) with accuracy loss estimators, which dynamically selects the network layers to be binarized to ensure the accuracy of the network by evaluating the error caused by the binarized weights during the network learning process. Experimental results show that this method can reduce storage space by more than 20 % without losing network accuracy. At the same time, in order to accelerate the training speed of the network, the global average pooling(GAP) layer is introduced to replace the fully connected layers by the combination of convolution and pooling, so that SNNs can use a small number of time steps to obtain better recognition accuracy. In the extreme case of using only one time step, we still can achieve 92.92 %, 91.63 % ,and 63.54 % testing accuracy on three different datasets, FashionMNIST, CIFAR-10, and CIFAR-100, respectively. ",
    "url": "https://arxiv.org/abs/2208.00398",
    "authors": [
      "Changqing Xu",
      "Yijian Pei",
      "Zili Wu",
      "Yi Liu",
      "Yintang Yang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2208.00399",
    "title": "Neural Knowledge Bank for Pretrained Transformers",
    "abstract": "The ability of pretrained Transformers to remember factual knowledge is essential for knowledge-intense downstream tasks such as closed-book question answering. Existing work has shown that pretrained Transformers can recall or leverage factual knowledge that appears in the pretraining corpus to some degree. However, due to the limit of the model capacity, the ability of pretrained models to remember factual knowledge is also limited. Dai et al. (2022) find that the Feed-Forward Networks (FFNs) in pretrained Transformers store factual knowledge in a memory-like manner. Inspired by this finding, we propose a Neural Knowledge Bank (NKB) to store extra factual knowledge for pretrained Transformers. To be specific, we also regard FFNs as key-value memories, and extend them with additional memory slots. During knowledge injection, we fix the original model and inject factual knowledge into the extended memory slots, so there will be no catastrophic forgetting for the pretrained model. In addition, the view of FFNs as key-value memories makes the NKB highly interpretable. We use three closed-book question answering datasets to show our strong ability to store extra factual knowledge. Also, we prove that the NKB will not degrade the general language generation ability of pretrained models through two representative generation tasks, summarization and machine translation. Further, we thoroughly analyze the NKB to reveal its working mechanism and present the meaning of its keys and values in a human-readable way. On top of it, we perform a preliminary attempt to directly update the factual knowledge in the NKB without any additional training. ",
    "url": "https://arxiv.org/abs/2208.00399",
    "authors": [
      "Damai Dai",
      "Wenbin Jiang",
      "Qingxiu Dong",
      "Yajuan Lyu",
      "Qiaoqiao She",
      "Zhifang Sui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.00428",
    "title": "Robust Real-World Image Super-Resolution against Adversarial Attacks",
    "abstract": "Recently deep neural networks (DNNs) have achieved significant success in real-world image super-resolution (SR). However, adversarial image samples with quasi-imperceptible noises could threaten deep learning SR models. In this paper, we propose a robust deep learning framework for real-world SR that randomly erases potential adversarial noises in the frequency domain of input images or features. The rationale is that on the SR task clean images or features have a different pattern from the attacked ones in the frequency domain. Observing that existing adversarial attacks usually add high-frequency noises to input images, we introduce a novel random frequency mask module that blocks out high-frequency components possibly containing the harmful perturbations in a stochastic manner. Since the frequency masking may not only destroys the adversarial perturbations but also affects the sharp details in a clean image, we further develop an adversarial sample classifier based on the frequency domain of images to determine if applying the proposed mask module. Based on the above ideas, we devise a novel real-world image SR framework that combines the proposed frequency mask modules and the proposed adversarial classifier with an existing super-resolution backbone network. Experiments show that our proposed method is more insensitive to adversarial attacks and presents more stable SR results than existing models and defenses. ",
    "url": "https://arxiv.org/abs/2208.00428",
    "authors": [
      "Jiutao Yue",
      "Haofeng Li",
      "Pengxu Wei",
      "Guanbin Li",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2208.00444",
    "title": "BYOLMed3D: Self-Supervised Representation Learning of Medical Videos  using Gradient Accumulation Assisted 3D BYOL Framework",
    "abstract": "Applications on Medical Image Analysis suffer from acute shortage of large volume of data properly annotated by medical experts. Supervised Learning algorithms require a large volumes of balanced data to learn robust representations. Often supervised learning algorithms require various techniques to deal with imbalanced data. Self-supervised learning algorithms on the other hand are robust to imbalance in the data and are capable of learning robust representations. In this work, we train a 3D BYOL self-supervised model using gradient accumulation technique to deal with the large number of samples in a batch generally required in a self-supervised algorithm. To the best of our knowledge, this work is one of the first of its kind in this domain. We compare the results obtained through our experiments in the downstream task of ACL Tear Injury detection with the contemporary self-supervised pre-training methods and also with ResNet3D-18 initialized with the Kinetics-400 pre-trained weights. From the downstream task experiments, it is evident that the proposed framework outperforms the existing baselines. ",
    "url": "https://arxiv.org/abs/2208.00444",
    "authors": [
      "Siladittya Manna",
      "Souvik Chakraborty"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00446",
    "title": "Out-of-Distribution Detection with Semantic Mismatch under Masking",
    "abstract": "This paper proposes a novel out-of-distribution (OOD) detection framework named MoodCat for image classifiers. MoodCat masks a random portion of the input image and uses a generative model to synthesize the masked image to a new image conditioned on the classification result. It then calculates the semantic difference between the original image and the synthesized one for OOD detection. Compared to existing solutions, MoodCat naturally learns the semantic information of the in-distribution data with the proposed mask and conditional synthesis strategy, which is critical to identifying OODs. Experimental results demonstrate that MoodCat outperforms state-of-the-art OOD detection solutions by a large margin. ",
    "url": "https://arxiv.org/abs/2208.00446",
    "authors": [
      "Yijun Yang",
      "Ruiyuan Gao",
      "Qiang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.00457",
    "title": "INSightR-Net: Interpretable Neural Network for Regression using  Similarity-based Comparisons to Prototypical Examples",
    "abstract": "Convolutional neural networks (CNNs) have shown exceptional performance for a range of medical imaging tasks. However, conventional CNNs are not able to explain their reasoning process, therefore limiting their adoption in clinical practice. In this work, we propose an inherently interpretable CNN for regression using similarity-based comparisons (INSightR-Net) and demonstrate our methods on the task of diabetic retinopathy grading. A prototype layer incorporated into the architecture enables visualization of the areas in the image that are most similar to learned prototypes. The final prediction is then intuitively modeled as a mean of prototype labels, weighted by the similarities. We achieved competitive prediction performance with our INSightR-Net compared to a ResNet baseline, showing that it is not necessary to compromise performance for interpretability. Furthermore, we quantified the quality of our explanations using sparsity and diversity, two concepts considered important for a good explanation, and demonstrated the effect of several parameters on the latent space embeddings. ",
    "url": "https://arxiv.org/abs/2208.00457",
    "authors": [
      "Linde S. Hesse",
      "Ana I. L. Namburete"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00461",
    "title": "Adaptive Temperature Scaling for Robust Calibration of Deep Neural  Networks",
    "abstract": "In this paper, we study the post-hoc calibration of modern neural networks, a problem that has drawn a lot of attention in recent years. Many calibration methods of varying complexity have been proposed for the task, but there is no consensus about how expressive these should be. We focus on the task of confidence scaling, specifically on post-hoc methods that generalize Temperature Scaling, we call these the Adaptive Temperature Scaling family. We analyse expressive functions that improve calibration and propose interpretable methods. We show that when there is plenty of data complex models like neural networks yield better performance, but are prone to fail when the amount of data is limited, a common situation in certain post-hoc calibration applications like medical diagnosis. We study the functions that expressive methods learn under ideal conditions and design simpler methods but with a strong inductive bias towards these well-performing functions. Concretely, we propose Entropy-based Temperature Scaling, a simple method that scales the confidence of a prediction according to its entropy. Results show that our method obtains state-of-the-art performance when compared to others and, unlike complex models, it is robust against data scarcity. Moreover, our proposed model enables a deeper interpretation of the calibration process. ",
    "url": "https://arxiv.org/abs/2208.00461",
    "authors": [
      "Sergio A. Balanya",
      "Juan Maro\u00f1as",
      "Daniel Ramos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00479",
    "title": "The impact of Twitter on political influence on the choice of a running  mate: Social Network Analysis and Semantic Analysis -- A Review",
    "abstract": "In this new era of social media, social networks are becoming increasingly important sources of user-generated content on the internet. These kinds of information resources, which include a lot of people's feelings, opinions, feedback, and reviews, are very useful for big businesses, markets, politics, journalism, and many other fields. Politics is one of the most talked-about and popular topics on social media networks right now. Many politicians use micro-blogging services like Twitter because they have a large number of followers and supporters on those networks. Politicians, political parties, political organizations, and foundations use social media networks to communicate with citizens ahead of time. Today, social media is used by hundreds of thousands of political groups and politicians. On these social media networks, every politician and political party has millions of followers, and politicians find new and innovative ways to urge individuals to participate in politics. Furthermore, social media assists politicians in various decision-making processes by providing recommendations, such as developing policies and strategies based on previous experiences, recommending and selecting suitable candidates for a particular constituency, recommending a suitable person for a particular position in the party, and launching a political campaign based on citizen sentiments on various issues and controversies, among other things. This research is a review on the use of social network analysis (SNA) and semantic analysis (SA) on the Twitter platform to study the supporters networks of political leaders because it can help in decision-making when predicting their political futures. ",
    "url": "https://arxiv.org/abs/2208.00479",
    "authors": [
      "Immaculate Wanza",
      "Irad Kamuti",
      "David Gichohi",
      "Kinyua Gikunda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2208.00487",
    "title": "One Object at a Time: Accurate and Robust Structure From Motion for  Robots",
    "abstract": "A gaze-fixating robot perceives distance to the fixated object and relative positions of surrounding objects immediately, accurately, and robustly. We show how fixation, which is the act of looking at one object while moving, exploits regularities in the geometry of 3D space to obtain this information. These regularities introduce rotation-translation couplings that are not commonly used in structure from motion. To validate, we use a Franka Emika Robot with an RGB camera. We a) find that error in distance estimate is less than 5 mm at a distance of 15 cm, and b) show how relative position can be used to find obstacles under challenging scenarios. We combine accurate distance estimates and obstacle information into a reactive robot behavior that is able to pick up objects of unknown size, while impeded by unforeseen obstacles. ",
    "url": "https://arxiv.org/abs/2208.00487",
    "authors": [
      "Aravind Battaje",
      "Oliver Brock"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00497",
    "title": "Fast Floating-Point Filters for Robust Predicates",
    "abstract": "Geometric predicates are at the core of many algorithms, such as the construction of Delaunay triangulations, mesh processing and spatial relation tests. These algorithms have applications in scientific computing, geographic information systems and computer-aided design. With floating-point arithmetic, these geometric predicates can incur round-off errors that may lead to incorrect results and inconsistencies, causing computations to fail. This issue has been addressed using a combination of exact arithmetic for robustness and floating-point filters to mitigate the computational cost of exact computations. The implementation of exact computations and floating-point filters can be a difficult task, and code generation tools have been proposed to address this. We present a new C++ meta-programming framework for the generation of fast, robust predicates for arbitrary geometric predicates based on polynomial expressions. We combine and extend different approaches to filtering, branch reduction, and overflow avoidance that have previously been proposed. We show examples of how this approach produces correct results for data sets that could lead to incorrect predicate results with naive implementations. Our benchmark results demonstrate that our implementation surpasses state-of-the-art implementations. ",
    "url": "https://arxiv.org/abs/2208.00497",
    "authors": [
      "Tinko Bartels",
      "Vissarion Fisikopoulos",
      "Martin Weiser"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2208.00498",
    "title": "DNNShield: Dynamic Randomized Model Sparsification, A Defense Against  Adversarial Machine Learning",
    "abstract": "DNNs are known to be vulnerable to so-called adversarial attacks that manipulate inputs to cause incorrect results that can be beneficial to an attacker or damaging to the victim. Recent works have proposed approximate computation as a defense mechanism against machine learning attacks. We show that these approaches, while successful for a range of inputs, are insufficient to address stronger, high-confidence adversarial attacks. To address this, we propose DNNSHIELD, a hardware-accelerated defense that adapts the strength of the response to the confidence of the adversarial input. Our approach relies on dynamic and random sparsification of the DNN model to achieve inference approximation efficiently and with fine-grain control over the approximation error. DNNSHIELD uses the output distribution characteristics of sparsified inference compared to a dense reference to detect adversarial inputs. We show an adversarial detection rate of 86% when applied to VGG16 and 88% when applied to ResNet50, which exceeds the detection rate of the state of the art approaches, with a much lower overhead. We demonstrate a software/hardware-accelerated FPGA prototype, which reduces the performance impact of DNNSHIELD relative to software-only CPU and GPU implementations. ",
    "url": "https://arxiv.org/abs/2208.00498",
    "authors": [
      "Mohammad Hossein Samavatian",
      "Saikat Majumdar",
      "Kristin Barber",
      "Radu Teodorescu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00511",
    "title": "Aggretriever: A Simple Approach to Aggregate Textual Representation for  Robust Dense Passage Retrieval",
    "abstract": "Pre-trained transformers has declared its success in many NLP tasks. One thread of work focuses on training bi-encoder models (i.e., dense retrievers) to effectively encode sentences or passages into single-vector dense vectors for efficient approximate nearest neighbor (ANN) search. However, recent work has demonstrated that transformers pre-trained with mask language modeling (MLM) are not capable of effectively aggregating text information into a single dense vector due to task-mismatch between pre-training and fine-tuning. Therefore, computationally expensive techniques have been adopted to train dense retrievers, such as large batch size, knowledge distillation or post pre-training. In this work, we present a simple approach to effectively aggregate textual representation from the pre-trained transformer into a dense vector. Extensive experiments show that our approach improves the robustness of the single-vector approach under both in-domain and zero-shot evaluations without any computationally expensive training techniques. Our work demonstrates that MLM pre-trained transformers can be used to effectively encode text information into a single-vector for dense retrieval. Code are available at: https://github.com/castorini/dhr ",
    "url": "https://arxiv.org/abs/2208.00511",
    "authors": [
      "Sheng-Chieh Lin",
      "Minghan Li",
      "Jimmy Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2208.00516",
    "title": "Learning an Interpretable Model for Driver Behavior Prediction with  Inductive Biases",
    "abstract": "To plan safe maneuvers and act with foresight, autonomous vehicles must be capable of accurately predicting the uncertain future. In the context of autonomous driving, deep neural networks have been successfully applied to learning predictive models of human driving behavior from data. However, the predictions suffer from cascading errors, resulting in large inaccuracies over long time horizons. Furthermore, the learned models are black boxes, and thus it is often unclear how they arrive at their predictions. In contrast, rule-based models, which are informed by human experts, maintain long-term coherence in their predictions and are human-interpretable. However, such models often lack the sufficient expressiveness needed to capture complex real-world dynamics. In this work, we begin to close this gap by embedding the Intelligent Driver Model, a popular hand-crafted driver model, into deep neural networks. Our model's transparency can offer considerable advantages, e.g., in debugging the model and more easily interpreting its predictions. We evaluate our approach on a simulated merging scenario, showing that it yields a robust model that is end-to-end trainable and provides greater transparency at no cost to the model's predictive accuracy. ",
    "url": "https://arxiv.org/abs/2208.00516",
    "authors": [
      "Salar Arbabi",
      "Davide Tavernini",
      "Saber Fallah",
      "Richard Bowden"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2208.00539",
    "title": "Is current research on adversarial robustness addressing the right  problem?",
    "abstract": "Short answer: Yes, Long answer: No! Indeed, research on adversarial robustness has led to invaluable insights helping us understand and explore different aspects of the problem. Many attacks and defenses have been proposed over the last couple of years. The problem, however, remains largely unsolved and poorly understood. Here, I argue that the current formulation of the problem serves short term goals, and needs to be revised for us to achieve bigger gains. Specifically, the bound on perturbation has created a somewhat contrived setting and needs to be relaxed. This has misled us to focus on model classes that are not expressive enough to begin with. Instead, inspired by human vision and the fact that we rely more on robust features such as shape, vertices, and foreground objects than non-robust features such as texture, efforts should be steered towards looking for significantly different classes of models. Maybe instead of narrowing down on imperceptible adversarial perturbations, we should attack a more general problem which is finding architectures that are simultaneously robust to perceptible perturbations, geometric transformations (e.g. rotation, scaling), image distortions (lighting, blur), and more (e.g. occlusion, shadow). Only then we may be able to solve the problem of adversarial vulnerability. ",
    "url": "https://arxiv.org/abs/2208.00539",
    "authors": [
      "Ali Borji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00545",
    "title": "Distributed Intelligence in Wireless Networks",
    "abstract": "The cloud-based solutions are becoming inefficient due to considerably large time delays, high power consumption, security and privacy concerns caused by billions of connected wireless devices and typically zillions bytes of data they produce at the network edge. A blend of edge computing and Artificial Intelligence (AI) techniques could optimally shift the resourceful computation servers closer to the network edge, which provides the support for advanced AI applications (e.g., video/audio surveillance and personal recommendation system) by enabling intelligent decision making on computing at the point of data generation as and when it is needed, and distributed Machine Learning (ML) with its potential to avoid the transmission of large dataset and possible compromise of privacy that may exist in cloud-based centralized learning. Therefore, AI is envisioned to become native and ubiquitous in future communication and networking systems. In this paper, we conduct a comprehensive overview of recent advances in distributed intelligence in wireless networks under the umbrella of native-AI wireless networks, with a focus on the basic concepts of native-AI wireless networks, on the AI-enabled edge computing, on the design of distributed learning architectures for heterogeneous networks, on the communication-efficient technologies to support distributed learning, and on the AI-empowered end-to-end communications. We highlight the advantages of hybrid distributed learning architectures compared to the state-of-art distributed learning techniques. We summarize the challenges of existing research contributions in distributed intelligence in wireless networks and identify the potential future opportunities. ",
    "url": "https://arxiv.org/abs/2208.00545",
    "authors": [
      "Xiaolan Liu",
      "Jiadong Yu",
      "Yuanwei Liu",
      "Yue Gao",
      "Toktam Mahmoodi",
      "Sangarapillai Lambotharan",
      "Danny H. K. Tsang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2208.00548",
    "title": "Safer Traffic Recovery from the Pandemic in London -- Spatiotemporal  Data Mining of Car Crashes",
    "abstract": "In the aim to support London's safer recovery from the pandemic by improving road safety intelligently, this study investigated the spatiotemporal patterns of age-involved car crashes and affecting factors, upon answering two main research questions: (1)\"What are the spatial and temporal patterns of car crashes as well as their changes in two typical years, 2019 and 2020, in London, and how the influential factors work?\"; (2)\"What are the spatiotemporal patterns of casualty by age groups, and how people's daily activities affect the patterns pre- and para- the pandemic\"? Three approaches, i.e., spatial analysis (network Kernel Density Estimation, NetKDE), factor analysis, and spatiotemporal data mining (tensor decomposition), had been implemented to identify the temporal patterns of car crashes on weekly and daily basis respectively, detect the crashes' hot spots, and to gain better understanding the effect from citizens' daily activity on crashes' patterns pre- and para- the pandemic. It had been found from the study that car crashes mainly clustered in the central part of London, especially busier areas around denser hubs of point-of-interest (POIs); the POIs, as a reflector for citizens' daily activities and travel behaviours, can be of help to gain a better understanding of the crashes' patterns, upon further assessment on interactions through the geographical detector; the crashes' casualty patterns varied by age group, with distinctive relationships between POIs and crashes' pattern for corresponding age group categorised. In all, the paper provided an in-depth exploratory analysis of car crashes and their casualty patterns in London to facilitate deployment policies towards post-pandemic safer recovery upon COVID-19. ",
    "url": "https://arxiv.org/abs/2208.00548",
    "authors": [
      "Kejiang Qian",
      "Yijing Li"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2208.00563",
    "title": "Backdoor Watermarking Deep Learning Classification Models With Deep  Fidelity",
    "abstract": "Backdoor Watermarking is a promising paradigm to protect the copyright of deep neural network (DNN) models for classification tasks. In the existing works on this subject, researchers have intensively focused on watermarking robustness, while fidelity, which is concerned with the original functionality, has received less attention. In this paper, we show that the existing shared notion of the sole measurement of learning accuracy is insufficient to characterize backdoor fidelity. Meanwhile, we show that the analogous concept of embedding distortion in multimedia watermarking, interpreted as the total weight loss (TWL) in DNN backdoor watermarking, is also unsuitable to measure the fidelity. To solve this problem, we propose the concept of deep fidelity, which states that the backdoor watermarked DNN model should preserve both the feature representation and decision boundary of the unwatermarked host model. Accordingly, to realize deep fidelity, we propose two loss functions termed as penultimate feature loss (PFL) and softmax probability-distribution loss (SPL) to preserve feature representation, while the decision boundary is preserved by the proposed fix last layer (FixLL) treatment, inspired by the recent discovery that deep learning with a fixed classifier causes no loss of learning accuracy. With the above designs, both embedding from scratch and fine-tuning strategies are implemented to evaluate deep fidelity of backdoor embedding, whose advantages over the existing methods are verified via experiments using ResNet18 for MNIST and CIFAR-10 classifications, and wide residual network (i.e., WRN28_10) for CIFAR-100 task. ",
    "url": "https://arxiv.org/abs/2208.00563",
    "authors": [
      "Guang Hua",
      "Andrew Beng Jin Teoh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.00564",
    "title": "Quantum Adaptive Fourier Features for Neural Density Estimation",
    "abstract": "Density estimation is a fundamental task in statistics and machine learning applications. Kernel density estimation is a powerful tool for non-parametric density estimation in low dimensions; however, its performance is poor in higher dimensions. Moreover, its prediction complexity scale linearly with more training data points. This paper presents a method for neural density estimation that can be seen as a type of kernel density estimation, but without the high prediction computational complexity. The method is based on density matrices, a formalism used in quantum mechanics, and adaptive Fourier features. The method can be trained without optimization, but it could be also integrated with deep learning architectures and trained using gradient descent. Thus, it could be seen as a form of neural density estimation method. The method was evaluated in different synthetic and real datasets, and its performance compared against state-of-the-art neural density estimation methods, obtaining competitive results. ",
    "url": "https://arxiv.org/abs/2208.00564",
    "authors": [
      "Joseph A. Gallego M.",
      "Fabio A. Gonz\u00e1lez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2208.00565",
    "title": "Modeling Human Response to Robot Errors for Timely Error Detection",
    "abstract": "In human-robot collaboration, robot errors are inevitable -- damaging user trust, willingness to work together, and task performance. Prior work has shown that people naturally respond to robot errors socially and that in social interactions it is possible to use human responses to detect errors. However, there is little exploration in the domain of non-social, physical human-robot collaboration such as assembly and tool retrieval. In this work, we investigate how people's organic, social responses to robot errors may be used to enable timely automatic detection of errors in physical human-robot interactions. We conducted a data collection study to obtain facial responses to train a real-time detection algorithm and a case study to explore the generalizability of our method with different task settings and errors. Our results show that natural social responses are effective signals for timely detection and localization of robot errors even in non-social contexts and that our method is robust across a variety of task contexts, robot errors, and user responses. This work contributes to robust error detection without detailed task specifications. ",
    "url": "https://arxiv.org/abs/2208.00565",
    "authors": [
      "Maia Stiber",
      "Russell Taylor",
      "Chien-Ming Huang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2208.00584",
    "title": "A sensitivity-based approach to optimal sensor selection for process  networks",
    "abstract": "Sensor selection is critical for state estimation, control and monitoring of nonlinear processes. However, evaluating the performance of each possible combination of $m$ out of $n$ sensors is impractical unless $m$ and $n$ are small. In this paper, we propose a sensitivity-based approach to determine the minimum number of sensors and their optimal locations for state estimation. The local sensitivity matrix of the measured outputs to initial states is used as a measure of the observability. The minimum number of sensors is determined in a way such that the local sensitivity matrix is full column rank. The subset of sensors that satisfies the full-rank condition and provides the maximum degree of observability is considered as the optimal sensor placement. Successive orthogonalization of the sensitivity matrix is conducted in the proposed approach to significantly reduce the computational complexity in selecting the sensors. To validate the effectiveness of the proposed method, it is applied to two processes including a chemical process consisting of four continuous stirred-tank reactors and a wastewater treatment plant. In both cases, the proposed approach can obtain the optimal sensor subsets. ",
    "url": "https://arxiv.org/abs/2208.00584",
    "authors": [
      "Siyu Liu",
      "Xunyuan Yin",
      "Zhichao Pan",
      "Jinfeng Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2208.00615",
    "title": "Computational Models for SA, RA, PC Afferent to Reproduce Neural  Responses to Dynamic Stimulus Using FEM Analysis and a Leaky  Integrate-and-Fire Model",
    "abstract": "Tactile afferents such as (RA), and Pacinian (PC) afferents that respond to external stimuli enable complicated actions such as grasping, stroking and identifying an object. To understand the tactile sensation induced by these actions deeply, the activities of the tactile afferents need to be revealed. For this purpose, we develop a computational model for each tactile afferent for vibration stimuli, combining finite element analysis finite element method (FEM) analysis and a leaky integrate-and-fire model that represents the neural characteristics. This computational model can easily estimate the neural activities of the tactile afferents without measuring biological data. Skin deformation calculated using FEM analysis is substituted into the integrate-and-fire model as current input to calculate the membrane potential of each tactile afferent. We optimized parameters in the integrate-and-fire models using reported biological data. Then, we calculated the responses of the numerical models to sinusoidal, diharmonic, and white-noise-like mechanical stimuli to validate the proposed numerical models. From the result, the computational models well reproduced the neural responses to vibration stimuli such as sinusoidal, diharmonic, and noise stimuli and compare favorably with the similar computational models that can simulate the responses to vibration stimuli. ",
    "url": "https://arxiv.org/abs/2208.00615",
    "authors": [
      "Hiroki Ishizuka",
      "Shoki Kitaguchi",
      "Masashi Nakatani",
      "Hidenori Yoshimura",
      "Fusao Shimokawa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2208.00627",
    "title": "A Rotation Meanout Network with Invariance for Dermoscopy Image  Classification and Retrieval",
    "abstract": "The computer-aided diagnosis (CAD) system can provide a reference basis for the clinical diagnosis of skin diseases. Convolutional neural networks (CNNs) can not only extract visual elements such as colors and shapes but also semantic features. As such they have made great improvements in many tasks of dermoscopy images. The imaging of dermoscopy has no main direction, indicating that there are a large number of skin lesion target rotations in the datasets. However, CNNs lack anti-rotation ability, which is bound to affect the feature extraction ability of CNNs. We propose a rotation meanout (RM) network to extract rotation invariance features from dermoscopy images. In RM, each set of rotated feature maps corresponds to a set of weight-sharing convolution outputs and they are fused using meanout operation to obtain the final feature maps. Through theoretical derivation, the proposed RM network is rotation-equivariant and can extract rotation-invariant features when being followed by the global average pooling (GAP) operation. The extracted rotation-invariant features can better represent the original data in classification and retrieval tasks for dermoscopy images. The proposed RM is a general operation, which does not change the network structure or increase any parameter, and can be flexibly embedded in any part of CNNs. Extensive experiments are conducted on a dermoscopy image dataset. The results show our method outperforms other anti-rotation methods and achieves great improvements in dermoscopy image classification and retrieval tasks, indicating the potential of rotation invariance in the field of dermoscopy images. ",
    "url": "https://arxiv.org/abs/2208.00627",
    "authors": [
      "Yilan Zhang",
      "Fengying Xie",
      "Xuedong Song",
      "Hangning Zhou",
      "Yiguang Yang",
      "Haopeng Zhang",
      "Jie Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00629",
    "title": "XOOD: Extreme Value Based Out-Of-Distribution Detection For Image  Classification",
    "abstract": "Detecting out-of-distribution (OOD) data at inference time is crucial for many applications of machine learning. We present XOOD: a novel extreme value-based OOD detection framework for image classification that consists of two algorithms. The first, XOOD-M, is completely unsupervised, while the second XOOD-L is self-supervised. Both algorithms rely on the signals captured by the extreme values of the data in the activation layers of the neural network in order to distinguish between in-distribution and OOD instances. We show experimentally that both XOOD-M and XOOD-L outperform state-of-the-art OOD detection methods on many benchmark data sets in both efficiency and accuracy, reducing false-positive rate (FPR95) by 50%, while improving the inferencing time by an order of magnitude. ",
    "url": "https://arxiv.org/abs/2208.00629",
    "authors": [
      "Frej Berglind",
      "Haron Temam",
      "Supratik Mukhopadhyay",
      "Kamalika Das",
      "Md Saiful Islam Sajol",
      "Sricharan Kumar",
      "Kumar Kallurupalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00630",
    "title": "Identifying Influential Brokers on Social Media from Social Network  Structure",
    "abstract": "Identifying influencers in a given social network has become an important research problem for various applications, including accelerating the spread of information in viral marketing and preventing the spread of fake news and rumors. The literature contains a rich body of studies on identifying influential source spreaders who can spread their own messages to many other nodes. In contrast, the identification of influential brokers who can spread other nodes' messages to many nodes has not been fully explored. Theoretical and empirical studies suggest that involvement of both influential source spreaders and brokers is a key to facilitating large-scale information diffusion cascades. Therefore, this paper explores ways to identify influential brokers from a given social network. By using three social media datasets, we investigate the characteristics of influential brokers by comparing them with influential source spreaders and central nodes obtained from centrality measures. Our results show that (i) most of the influential source spreaders are not influential brokers (and vice versa) and (ii) the overlap between central nodes and influential brokers is small (less than 15%) in Twitter datasets. We also tackle the problem of identifying influential brokers from centrality measures and node embeddings, and we examine the effectiveness of social network features in the broker identification task. Our results show that (iii) although a single centrality measure cannot characterize influential brokers well, prediction models using node embedding features achieve F$_1$ scores of 0.35--0.68, suggesting the effectiveness of social network features for identifying influential brokers. ",
    "url": "https://arxiv.org/abs/2208.00630",
    "authors": [
      "Sho Tsugawa",
      "Kohei Watabe"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2208.00632",
    "title": "Multi-spectral Vehicle Re-identification with Cross-directional  Consistency Network and a High-quality Benchmark",
    "abstract": "To tackle the challenge of vehicle re-identification (Re-ID) in complex lighting environments and diverse scenes, multi-spectral sources like visible and infrared information are taken into consideration due to their excellent complementary advantages. However, multi-spectral vehicle Re-ID suffers cross-modality discrepancy caused by heterogeneous properties of different modalities as well as a big challenge of the diverse appearance with different views in each identity. Meanwhile, diverse environmental interference leads to heavy sample distributional discrepancy in each modality. In this work, we propose a novel cross-directional consistency network to simultaneously overcome the discrepancies from both modality and sample aspects. In particular, we design a new cross-directional center loss to pull the modality centers of each identity close to mitigate cross-modality discrepancy, while the sample centers of each identity close to alleviate the sample discrepancy. Such strategy can generate discriminative multi-spectral feature representations for vehicle Re-ID. In addition, we design an adaptive layer normalization unit to dynamically adjust individual feature distribution to handle distributional discrepancy of intra-modality features for robust learning. To provide a comprehensive evaluation platform, we create a high-quality RGB-NIR-TIR multi-spectral vehicle Re-ID benchmark (MSVR310), including 310 different vehicles from a broad range of viewpoints, time spans and environmental complexities. Comprehensive experiments on both created and public datasets demonstrate the effectiveness of the proposed approach comparing to the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2208.00632",
    "authors": [
      "Aihua Zheng",
      "Xianpeng Zhu",
      "Chenglong Li",
      "Jin Tang",
      "Jixin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00647",
    "title": "An Evidential Neural Network Model for Regression Based on Random Fuzzy  Numbers",
    "abstract": "We introduce a distance-based neural network model for regression, in which prediction uncertainty is quantified by a belief function on the real line. The model interprets the distances of the input vector to prototypes as pieces of evidence represented by Gaussian random fuzzy numbers (GRFN's) and combined by the generalized product intersection rule, an operator that extends Dempster's rule to random fuzzy sets. The network output is a GRFN that can be summarized by three numbers characterizing the most plausible predicted value, variability around this value, and epistemic uncertainty. Experiments with real datasets demonstrate the very good performance of the method as compared to state-of-the-art evidential and statistical learning algorithms. \\keywords{Evidence theory, Dempster-Shafer theory, belief functions, machine learning, random fuzzy sets. ",
    "url": "https://arxiv.org/abs/2208.00647",
    "authors": [
      "Thierry Denoeux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00651",
    "title": "De-biased Representation Learning for Fairness with Unreliable Labels",
    "abstract": "Removing bias while keeping all task-relevant information is challenging for fair representation learning methods since they would yield random or degenerate representations w.r.t. labels when the sensitive attributes correlate with labels. Existing works proposed to inject the label information into the learning procedure to overcome such issues. However, the assumption that the observed labels are clean is not always met. In fact, label bias is acknowledged as the primary source inducing discrimination. In other words, the fair pre-processing methods ignore the discrimination encoded in the labels either during the learning procedure or the evaluation stage. This contradiction puts a question mark on the fairness of the learned representations. To circumvent this issue, we explore the following question: \\emph{Can we learn fair representations predictable to latent ideal fair labels given only access to unreliable labels?} In this work, we propose a \\textbf{D}e-\\textbf{B}iased \\textbf{R}epresentation Learning for \\textbf{F}airness (DBRF) framework which disentangles the sensitive information from non-sensitive attributes whilst keeping the learned representations predictable to ideal fair labels rather than observed biased ones. We formulate the de-biased learning framework through information-theoretic concepts such as mutual information and information bottleneck. The core concept is that DBRF advocates not to use unreliable labels for supervision when sensitive information benefits the prediction of unreliable labels. Experiment results over both synthetic and real-world data demonstrate that DBRF effectively learns de-biased representations towards ideal labels. ",
    "url": "https://arxiv.org/abs/2208.00651",
    "authors": [
      "Yixuan Zhang",
      "Feng Zhou",
      "Zhidong Li",
      "Yang Wang",
      "Fang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2208.00657",
    "title": "SiamixFormer: A Siamese Transformer Network For Building Detection And  Change Detection From Bi-Temporal Remote Sensing Images",
    "abstract": "Building detection and change detection using remote sensing images can help urban and rescue planning. Moreover, they can be used for building damage assessment after natural disasters. Currently, most of the existing models for building detection use only one image (pre-disaster image) to detect buildings. This is based on the idea that post-disaster images reduce the model's performance because of presence of destroyed buildings. In this paper, we propose a siamese model, called SiamixFormer, which uses pre- and post-disaster images as input. Our model has two encoders and has a hierarchical transformer architecture. The output of each stage in both encoders is given to a temporal transformer for feature fusion in a way that query is generated from pre-disaster images and (key, value) is generated from post-disaster images. To this end, temporal features are also considered in feature fusion. Another advantage of using temporal transformers in feature fusion is that they can better maintain large receptive fields generated by transformer encoders compared with CNNs. Finally, the output of the temporal transformer is given to a simple MLP decoder at each stage. The SiamixFormer model is evaluated on xBD, and WHU datasets, for building detection and on LEVIR-CD and CDD datasets for change detection and could outperform the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2208.00657",
    "authors": [
      "Amir mohammadian",
      "Foad Ghaderi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00659",
    "title": "Model-based graph reinforcement learning for inductive traffic signal  control",
    "abstract": "Most reinforcement learning methods for adaptive-traffic-signal-control require training from scratch to be applied on any new intersection or after any modification to the road network, traffic distribution, or behavioral constraints experienced during training. Considering 1) the massive amount of experience required to train such methods, and 2) that experience must be gathered by interacting in an exploratory fashion with real road-network-users, such a lack of transferability limits experimentation and applicability. Recent approaches enable learning policies that generalize for unseen road-network topologies and traffic distributions, partially tackling this challenge. However, the literature remains divided between the learning of cyclic (the evolution of connectivity at an intersection must respect a cycle) and acyclic (less constrained) policies, and these transferable methods 1) are only compatible with cyclic constraints and 2) do not enable coordination. We introduce a new model-based method, MuJAM, which, on top of enabling explicit coordination at scale for the first time, pushes generalization further by allowing a generalization to the controllers' constraints. In a zero-shot transfer setting involving both road networks and traffic settings never experienced during training, and in a larger transfer experiment involving the control of 3,971 traffic signal controllers in Manhattan, we show that MuJAM, using both cyclic and acyclic constraints, outperforms domain-specific baselines as well as another transferable approach. ",
    "url": "https://arxiv.org/abs/2208.00659",
    "authors": [
      "Fran\u00e7ois-Xavier Devailly",
      "Denis Larocque",
      "Laurent Charlin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2208.00665",
    "title": "Event Notifications in Value-Adding Networks",
    "abstract": "Linkages between research outputs are crucial in the scholarly knowledge graph. They include online citations, but also links between versions that differ according to various dimensions and links to resources that were used to arrive at research results. In current scholarly communication systems this information is only made available post factum and is obtained via elaborate batch processing. In this paper we report on work aimed at making linkages available in real-time, in which an alternative, decentralised scholarly communication network is considered that consists of interacting data nodes that host artifacts and service nodes that add value to artifacts. The first result of this work, the \"Event Notifications in Value-Adding Networks\" specification, details interoperability requirements for the exchange real-time life-cycle information pertaining to artifacts using Linked Data Notifications. In an experiment, we applied our specification to one particular use-case: distributing Scholix data-literature links to a network of Belgian institutional repositories by a national service node. The results of our experiment confirm the potential of our approach and provide a framework to create a network of interacting nodes implementing the core scholarly functions (registration, certification, awareness and archiving) in a decentralized and decoupled way. ",
    "url": "https://arxiv.org/abs/2208.00665",
    "authors": [
      "Patrick Hochstenbach",
      "Herbert Van de Sompel",
      "Miel Vander Sande",
      "Ruben Dedecker",
      "Ruben Verborgh"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2208.00671",
    "title": "RASIPAM: Interactive Pattern Mining of Multivariate Event Sequences in  Racket Sports",
    "abstract": "Experts in racket sports like tennis and badminton use tactical analysis to gain insight into competitors' playing styles. Many data-driven methods apply pattern mining to racket sports data -- which is often recorded as multivariate event sequences -- to uncover sports tactics. However, tactics obtained in this way are often inconsistent with those deduced by experts through their domain knowledge, which can be confusing to those experts. This work introduces RASIPAM, a RAcket-Sports Interactive PAttern Mining system, which allows experts to incorporate their knowledge into data mining algorithms to discover meaningful tactics interactively. RASIPAM consists of a constraint-based pattern mining algorithm that responds to the analysis demands of experts: Experts provide suggestions for finding tactics in intuitive written language, and these suggestions are translated into constraints to run the algorithm. RASIPAM further introduces a tailored visual interface that allows experts to compare the new tactics with the original ones and decide whether to apply a given adjustment. This interactive workflow iteratively progresses until experts are satisfied with all tactics. We conduct a quantitative experiment to show that our algorithm supports real-time interaction. Two case studies in tennis and in badminton respectively, each involving two domain experts, are conducted to show the effectiveness and usefulness of the system. ",
    "url": "https://arxiv.org/abs/2208.00671",
    "authors": [
      "Jiang Wu",
      "Dongyu Liu",
      "Ziyang Guo",
      "Yingcai Wu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2208.00677",
    "title": "Similarity-based web element localization for robust test automation",
    "abstract": "Non-robust (fragile) test execution is a commonly reported challenge in GUI-based test automation, despite much research and several proposed solutions. A test script needs to be resilient to (minor) changes in the tested application but, at the same time, fail when detecting potential issues that require investigation. Test script fragility is a multi-faceted problem, but one crucial challenge is reliably identifying and locating the correct target web elements when the website evolves between releases or otherwise fails and reports an issue. This paper proposes and evaluates a novel approach called similarity-based web element localization (Similo), which leverages information from multiple web element locator parameters to identify a target element using a weighted similarity score. The experimental study compares Similo to a baseline approach for web element localization. To get an extensive empirical basis, we target 40 of the most popular websites on the Internet in our evaluation. Robustness is considered by counting the number of web elements found in a recent website version compared to how many of these existed in an older version. Results of the experiment show that Similo outperforms the baseline representing the current state-of-the-art; it failed to locate the correct target web element in 72 out of 598 considered cases compared to 146 failed cases for the baseline approach. This study presents evidence that quantifying the similarity between multiple attributes of web elements when trying to locate them, as in our proposed Similo approach, is beneficial. With acceptable efficiency, Similo gives significantly higher effectiveness (i.e., robustness) than the baseline web element localization approach. ",
    "url": "https://arxiv.org/abs/2208.00677",
    "authors": [
      "Michel Nass",
      "Emil Al\u00e9groth",
      "Robert Feldt",
      "Maurizio Leotta",
      "Filippo Ricca"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2208.00716",
    "title": "Graph Neural Network with Local Frame for Molecular Potential Energy  Surface",
    "abstract": "Modeling molecular potential energy surface is of pivotal importance in science. Graph Neural Networks have shown great success in this field, especially those using rotation-equivariant representations. However, they either suffer from a complex mathematical form or lack theoretical support and design principle. To avoid using equivariant representations, we introduce a novel local frame method to molecule representation learning and analyze its expressive power. With a frame and the projection of equivariant vectors on the frame, GNNs can map the local environment of an atom to a scalar representation injectively. Messages can also be passed across local environments with frames' projection on frames. We further analyze when and how we can build such local frames. We prove that local frames always exist when the local environments have no symmetry, as is often the case in molecular dynamics simulations. For symmetric molecules, though only degenerate frames can be built, we find that the local frame method may still achieve high expressive power in some common cases due to the reduced degrees of freedom. Using only scalar representations allows us to adopt existing simple and powerful GNN architectures. Our model outperforms a range of state-of-the-art baselines in experiments. Simpler architectures also lead to higher scalability. Our model only takes about 30% inference time compared with the fastest baseline. ",
    "url": "https://arxiv.org/abs/2208.00716",
    "authors": [
      "Xiyuan Wang",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2208.00721",
    "title": "Domain Analysis of Ethical, Social and Environmental Accounting Methods",
    "abstract": "Ethical, social and environmental accounting is the practice of assessing and reporting organisations' performance on environmental, social and governance topics. There are ample methods that describe how to perform such sustainability assessments. This report presents a domain analysis of ethical, social and environmental accounting methods. Our analysis contains 21 methods. Each method is modelled as a process deliverable diagram. The diagrams have been validated by experts in the methods. The diagrams lay the foundation for further analysis and software development. In this report, we touch upon the ethical, social and environmental accounting method ontology that has been created based on the domain analysis. ",
    "url": "https://arxiv.org/abs/2208.00721",
    "authors": [
      "Vijanti Ramautar",
      "Sergio Espa\u00f1a"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2208.00725",
    "title": "Fashion Recommendation Based on Style and Social Events",
    "abstract": "Fashion recommendation is often declined as the task of finding complementary items given a query garment or retrieving outfits that are suitable for a given user. In this work we address the problem by adding an additional semantic layer based on the style of the proposed dressing. We model style according to two important aspects: the mood and the emotion concealed behind color combination patterns and the appropriateness of the retrieved garments for a given type of social event. To address the former we rely on Shigenobu Kobayashi's color image scale, which associated emotional patterns and moods to color triples. The latter instead is analyzed by extracting garments from images of social events. Overall, we integrate in a state of the art garment recommendation framework a style classifier and an event classifier in order to condition recommendation on a given query. ",
    "url": "https://arxiv.org/abs/2208.00725",
    "authors": [
      "Federico Becattini",
      "Lavinia De Divitiis",
      "Claudio Baecchi",
      "Alberto Del Bimbo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2208.00750",
    "title": "Robustness of Greedy Approval Rules",
    "abstract": "We study the robustness of GreedyCC, GreedyPAV, and Phargmen's sequential rule, using the framework introduced by Bredereck et al. for the case of (multiwinner) ordinal elections and adopted to the approval setting by Gawron and Faliszewski. First, we show that for each of our rules and every committee size $k$, there are elections in which adding or removing a certain approval causes the winning committee to completely change (i.e., the winning committee after the operation is disjoint from the one before the operation). Second, we show that the problem of deciding how many approvals need to be added (or removed) from an election to change its outcome is NP-complete for each of our rules. Finally, we experimentally evaluate the robustness of our rules in the presence of random noise. ",
    "url": "https://arxiv.org/abs/2208.00750",
    "authors": [
      "Piotr Faliszewski",
      "Grzegorz Gawron",
      "Bartosz Kusek"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2208.00751",
    "title": "CSDN: Cross-modal Shape-transfer Dual-refinement Network for Point Cloud  Completion",
    "abstract": "How will you repair a physical object with some missings? You may imagine its original shape from previously captured images, recover its overall (global) but coarse shape first, and then refine its local details. We are motivated to imitate the physical repair procedure to address point cloud completion. To this end, we propose a cross-modal shape-transfer dual-refinement network (termed CSDN), a coarse-to-fine paradigm with images of full-cycle participation, for quality point cloud completion. CSDN mainly consists of \"shape fusion\" and \"dual-refinement\" modules to tackle the cross-modal challenge. The first module transfers the intrinsic shape characteristics from single images to guide the geometry generation of the missing regions of point clouds, in which we propose IPAdaIN to embed the global features of both the image and the partial point cloud into completion. The second module refines the coarse output by adjusting the positions of the generated points, where the local refinement unit exploits the geometric relation between the novel and the input points by graph convolution, and the global constraint unit utilizes the input image to fine-tune the generated offset. Different from most existing approaches, CSDN not only explores the complementary information from images but also effectively exploits cross-modal data in the whole coarse-to-fine completion procedure. Experimental results indicate that CSDN performs favorably against ten competitors on the cross-modal benchmark. ",
    "url": "https://arxiv.org/abs/2208.00751",
    "authors": [
      "Zhe Zhu",
      "Liangliang Nan",
      "Haoran Xie",
      "Honghua Chen",
      "Mingqiang Wei",
      "Jun Wang",
      "Jing Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00759",
    "title": "Learning to Navigate using Visual Sensor Networks",
    "abstract": "We consider the problem of navigating a mobile robot towards a target in an unknown environment that is endowed with visual sensors, where neither the robot nor the sensors have access to global positioning information and only use first-person-view images. While prior work in sensor network based navigation uses explicit mapping and planning techniques, and are often aided by external positioning systems, we propose a vision-only based learning approach that leverages a Graph Neural Network (GNN) to encode and communicate relevant viewpoint information to the mobile robot. During navigation, the robot is guided by a model that we train through imitation learning to approximate optimal motion primitives, thereby predicting the effective cost-to-go (to the target). In our experiments, we first demonstrate generalizability to previously unseen environments with various sensor layouts. Simulation results show that by utilizing communication among the sensors and robot, we can achieve a $18.1\\%$ improvement in success rate while decreasing path detour mean by $29.3\\%$ and variability by $48.4\\%$. This is done without requiring a global map, positioning data, nor pre-calibration of the sensor network. Second, we perform a zero-shot transfer of our model from simulation to the real world. To this end, we train a `translator' model that translates between {latent encodings of} real and simulated images so that the navigation policy (which is trained entirely in simulation) can be used directly on the real robot, without additional fine-tuning. Physical experiments demonstrate our effectiveness in various cluttered environments. ",
    "url": "https://arxiv.org/abs/2208.00759",
    "authors": [
      "Jan Blumenkamp",
      "Qingbiao Li",
      "Binyu Wang",
      "Zhe Liu",
      "Amanda Prorok"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.00767",
    "title": "Multimodal Neural Machine Translation with Search Engine Based Image  Retrieval",
    "abstract": "Recently, numbers of works shows that the performance of neural machine translation (NMT) can be improved to a certain extent with using visual information. However, most of these conclusions are drawn from the analysis of experimental results based on a limited set of bilingual sentence-image pairs, such as Multi30K. In these kinds of datasets, the content of one bilingual parallel sentence pair must be well represented by a manually annotated image, which is different with the actual translation situation. Some previous works are proposed to addressed the problem by retrieving images from exiting sentence-image pairs with topic model. However, because of the limited collection of sentence-image pairs they used, their image retrieval method is difficult to deal with the out-of-vocabulary words, and can hardly prove that visual information enhance NMT rather than the co-occurrence of images and sentences. In this paper, we propose an open-vocabulary image retrieval methods to collect descriptive images for bilingual parallel corpus using image search engine. Next, we propose text-aware attentive visual encoder to filter incorrectly collected noise images. Experiment results on Multi30K and other two translation datasets show that our proposed method achieves significant improvements over strong baselines. ",
    "url": "https://arxiv.org/abs/2208.00767",
    "authors": [
      "ZhenHao Tang",
      "XiaoBing Zhang",
      "Zi Long",
      "XiangHua Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2208.00773",
    "title": "Real Time Object Detection System with YOLO and CNN Models: A Review",
    "abstract": "The field of artificial intelligence is built on object detection techniques. YOU ONLY LOOK ONCE (YOLO) algorithm and it's more evolved versions are briefly described in this research survey. This survey is all about YOLO and convolution neural networks (CNN)in the direction of real time object detection.YOLO does generalized object representation more effectively without precision losses than other object detection models.CNN architecture models have the ability to eliminate highlights and identify objects in any given image. When implemented appropriately, CNN models can address issues like deformity diagnosis, creating educational or instructive application, etc. This article reached atnumber of observations and perspective findings through the analysis.Also it provides support for the focused visual information and feature extraction in the financial and other industries, highlights the method of target detection and feature selection, and briefly describe the development process of YOLO algorithm. ",
    "url": "https://arxiv.org/abs/2208.00773",
    "authors": [
      "Viswanatha V",
      "Chandana R K",
      "Ramachandra A.C."
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2208.00774",
    "title": "Interaction Mix and Match: Synthesizing Close Interaction using  Conditional Hierarchical GAN with Multi-Hot Class Embedding",
    "abstract": "Synthesizing multi-character interactions is a challenging task due to the complex and varied interactions between the characters. In particular, precise spatiotemporal alignment between characters is required in generating close interactions such as dancing and fighting. Existing work in generating multi-character interactions focuses on generating a single type of reactive motion for a given sequence which results in a lack of variety of the resultant motions. In this paper, we propose a novel way to create realistic human reactive motions which are not presented in the given dataset by mixing and matching different types of close interactions. We propose a Conditional Hierarchical Generative Adversarial Network with Multi-Hot Class Embedding to generate the Mix and Match reactive motions of the follower from a given motion sequence of the leader. Experiments are conducted on both noisy (depth-based) and high-quality (MoCap-based) interaction datasets. The quantitative and qualitative results show that our approach outperforms the state-of-the-art methods on the given datasets. We also provide an augmented dataset with realistic reactive motions to stimulate future research in this area. The code is available at https://github.com/Aman-Goel1/IMM ",
    "url": "https://arxiv.org/abs/2208.00774",
    "authors": [
      "Aman Goel",
      "Qianhui Men",
      "Edmond S. L. Ho"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00778",
    "title": "SFILES 2.0: An extended text-based flowsheet representation",
    "abstract": "SFILES is a text-based notation for chemical process flowsheets. It was originally proposed by d'Anterroches (2006) who was inspired by the text-based SMILES notation for molecules. The text-based format has several advantages compared to flowsheet images regarding the storage format, computational accessibility, and eventually for data analysis and processing. However, the original SFILES version cannot describe essential flowsheet configurations unambiguously, such as the distinction between top and bottom products. Neither is it capable of describing the control structure required for the safe and reliable operation of chemical processes. Also, there is no publicly available software for decoding or encoding chemical process topologies to SFILES. We propose the SFILES 2.0 with a complete description of the extended notation and naming conventions. Additionally, we provide open-source software for the automated conversion between flowsheet graphs and SFILES 2.0 strings. This way, we hope to encourage researchers and engineers to publish their flowsheet topologies as SFILES 2.0 strings. The ultimate goal is to set the standards for creating a FAIR database of chemical process flowsheets, which would be of great value for future data analysis and processing. ",
    "url": "https://arxiv.org/abs/2208.00778",
    "authors": [
      "Gabriel Vogel",
      "Lukas Schulze Balhorn",
      "Edwin Hirtreiter",
      "Artur M. Schweidtmann"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2208.00780",
    "title": "Visual correspondence-based explanations improve AI robustness and  human-AI team accuracy",
    "abstract": "Explaining artificial intelligence (AI) predictions is increasingly important and even imperative in many high-stakes applications where humans are the ultimate decision-makers. In this work, we propose two novel architectures of self-interpretable image classifiers that first explain, and then predict (as opposed to post-hoc explanations) by harnessing the visual correspondences between a query image and exemplars. Our models consistently improve (by 1 to 4 points) on out-of-distribution (OOD) datasets while performing marginally worse (by 1 to 2 points) on in-distribution tests than ResNet-50 and a $k$-nearest neighbor classifier (kNN). Via a large-scale, human study on ImageNet and CUB, our correspondence-based explanations are found to be more useful to users than kNN explanations. Our explanations help users more accurately reject AI's wrong decisions than all other tested methods. Interestingly, for the first time, we show that it is possible to achieve complementary human-AI team accuracy (i.e., that is higher than either AI-alone or human-alone), in ImageNet and CUB image classification tasks. ",
    "url": "https://arxiv.org/abs/2208.00780",
    "authors": [
      "Giang Nguyen",
      "Mohammad Reza Taesiri",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00785",
    "title": "Verification system based on long-range iris and Graph Siamese Neural  Networks",
    "abstract": "Biometric systems represent valid solutions in tasks like user authentication and verification, since they are able to analyze physical and behavioural features with high precision. However, especially when physical biometrics are used, as is the case of iris recognition, they require specific hardware such as retina scanners, sensors, or HD cameras to achieve relevant results. At the same time, they require the users to be very close to the camera to extract high-resolution information. For this reason, in this work, we propose a novel approach that uses long-range (LR) distance images for implementing an iris verification system. More specifically, we present a novel methodology for converting LR iris images into graphs and then use Graph Siamese Neural Networks (GSNN) to predict whether two graphs belong to the same person. In this study, we not only describe this methodology but also evaluate how the spectral components of these images can be used for improving the graph extraction and the final classification task. Results demonstrate the suitability of this approach, encouraging the community to explore graph application in biometric systems. ",
    "url": "https://arxiv.org/abs/2208.00785",
    "authors": [
      "Francesco Zola",
      "Jose Alvaro Fernandez-Carrasco",
      "Jan Lukas Bruse",
      "Mikel Galar",
      "Zeno Geradts"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00787",
    "title": "On the robustness of self-supervised representations for multi-view  object classification",
    "abstract": "It is known that representations from self-supervised pre-training can perform on par, and often better, on various downstream tasks than representations from fully-supervised pre-training. This has been shown in a host of settings such as generic object classification and detection, semantic segmentation, and image retrieval. However, some issues have recently come to the fore that demonstrate some of the failure modes of self-supervised representations, such as performance on non-ImageNet-like data, or complex scenes. In this paper, we show that self-supervised representations based on the instance discrimination objective lead to better representations of objects that are more robust to changes in the viewpoint and perspective of the object. We perform experiments of modern self-supervised methods against multiple supervised baselines to demonstrate this, including approximating object viewpoint variation through homographies, and real-world tests based on several multi-view datasets. We find that self-supervised representations are more robust to object viewpoint and appear to encode more pertinent information about objects that facilitate the recognition of objects from novel views. ",
    "url": "https://arxiv.org/abs/2208.00787",
    "authors": [
      "David Torpey",
      "Richard Klein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00788",
    "title": "A Hybrid CNN-LSTM model for Video Deepfake Detection by Leveraging  Optical Flow Features",
    "abstract": "Deepfakes are the synthesized digital media in order to create ultra-realistic fake videos to trick the spectator. Deep generative algorithms, such as, Generative Adversarial Networks(GAN) are widely used to accomplish such tasks. This approach synthesizes pseudo-realistic contents that are very difficult to distinguish by traditional detection methods. In most cases, Convolutional Neural Network(CNN) based discriminators are being used for detecting such synthesized media. However, it emphasise primarily on the spatial attributes of individual video frames, thereby fail to learn the temporal information from their inter-frame relations. In this paper, we leveraged an optical flow based feature extraction approach to extract the temporal features, which are then fed to a hybrid model for classification. This hybrid model is based on the combination of CNN and recurrent neural network (RNN) architectures. The hybrid model provides effective performance on open source data-sets such as, DFDC, FF++ and Celeb-DF. This proposed method shows an accuracy of 66.26%, 91.21% and 79.49% in DFDC, FF++, and Celeb-DF respectively with a very reduced No of sample size of approx 100 samples(frames). This promises early detection of fake contents compared to existing modalities. ",
    "url": "https://arxiv.org/abs/2208.00788",
    "authors": [
      "Pallabi Saikia",
      "Dhwani Dholaria",
      "Priyanka Yadav",
      "Vaidehi Patel",
      "Mohendra Roy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.00789",
    "title": "Self-supervised learning with rotation-invariant kernels",
    "abstract": "A major paradigm for learning image representations in a self-supervised manner is to learn a model that is invariant to some predefined image transformations (cropping, blurring, color jittering, etc.), while regularizing the embedding distribution to avoid learning a degenerate solution. Our first contribution is to propose a general kernel framework to design a generic regularization loss that promotes the embedding distribution to be close to the uniform distribution on the hypersphere, with respect to the maximum mean discrepancy pseudometric. Our framework uses rotation-invariant kernels defined on the hypersphere, also known as dot-product kernels. Our second contribution is to show that this flexible kernel approach encompasses several existing self-supervised learning methods, including uniformity-based and information-maximization methods. Finally, by exploring empirically several kernel choices, our experiments demonstrate that using a truncated rotation-invariant kernel provides competitive results compared to state-of-the-art methods, and we show practical situations where our method benefits from the kernel trick to reduce computational complexity. ",
    "url": "https://arxiv.org/abs/2208.00789",
    "authors": [
      "L\u00e9on Zheng",
      "Gilles Puy",
      "Elisa Riccietti",
      "Patrick P\u00e9rez",
      "R\u00e9mi Gribonval"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.00791",
    "title": "Partial Connection Based on Channel Attention for Differentiable Neural  Architecture Search",
    "abstract": "Differentiable neural architecture search (DARTS), as a gradient-guided search method, greatly reduces the cost of computation and speeds up the search. In DARTS, the architecture parameters are introduced to the candidate operations, but the parameters of some weight-equipped operations may not be trained well in the initial stage, which causes unfair competition between candidate operations. The weight-free operations appear in large numbers which results in the phenomenon of performance crash. Besides, a lot of memory will be occupied during training supernet which causes the memory utilization to be low. In this paper, a partial channel connection based on channel attention for differentiable neural architecture search (ADARTS) is proposed. Some channels with higher weights are selected through the attention mechanism and sent into the operation space while the other channels are directly contacted with the processed channels. Selecting a few channels with higher attention weights can better transmit important feature information into the search space and greatly improve search efficiency and memory utilization. The instability of network structure caused by random selection can also be avoided. The experimental results show that ADARTS achieved 2.46% and 17.06% classification error rates on CIFAR-10 and CIFAR-100, respectively. ADARTS can effectively solve the problem that too many skip connections appear in the search process and obtain network structures with better performance. ",
    "url": "https://arxiv.org/abs/2208.00791",
    "authors": [
      "Yu Xue",
      "Jiafeng Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00792",
    "title": "Jazz Contrafact Detection",
    "abstract": "In jazz, a contrafact is a new melody composed over an existing, but often reharmonized chord progression. Because reharmonization can introduce a wide range of variations, detecting contrafacts is a challenging task. This paper develops a novel vector-space model to represent chord progressions, and uses it for contrafact detection. The process applies principles from music theory to reduce the dimensionality of chord space, determine a common key signature representation, and compute a chordal co-occurrence matrix. The rows of the matrix form a basis for the vector space in which chord progressions are represented as piecewise linear functions, and harmonic similarity is evaluated by computing the membrane area, a novel distance metric. To illustrate our method's effectiveness, we apply it to the Impro-Visor corpus of 2,612 chord progressions, and present examples demonstrating its ability to account for reharmonizations and find contrafacts. ",
    "url": "https://arxiv.org/abs/2208.00792",
    "authors": [
      "C. Bunks",
      "T. Weyde"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2208.00800",
    "title": "GANDSE: Generative Adversarial Network based Design Space Exploration  for Neural Network Accelerator Design",
    "abstract": "With the popularity of deep learning, the hardware implementation platform of deep learning has received increasing interest. Unlike the general purpose devices, e.g., CPU, or GPU, where the deep learning algorithms are executed at the software level, neural network hardware accelerators directly execute the algorithms to achieve higher both energy efficiency and performance improvements. However, as the deep learning algorithms evolve frequently, the engineering effort and cost of designing the hardware accelerators are greatly increased. To improve the design quality while saving the cost, design automation for neural network accelerators was proposed, where design space exploration algorithms are used to automatically search the optimized accelerator design within a design space. Nevertheless, the increasing complexity of the neural network accelerators brings the increasing dimensions to the design space. As a result, the previous design space exploration algorithms are no longer effective enough to find an optimized design. In this work, we propose a neural network accelerator design automation framework named GANDSE, where we rethink the problem of design space exploration, and propose a novel approach based on the generative adversarial network (GAN) to support an optimized exploration for high dimension large design space. The experiments show that GANDSE is able to find the more optimized designs in negligible time compared with approaches including multilayer perceptron and deep reinforcement learning. ",
    "url": "https://arxiv.org/abs/2208.00800",
    "authors": [
      "Lang Feng",
      "Wenjian Liu",
      "Chuliang Guo",
      "Ke Tang",
      "Cheng Zhuo",
      "Zhongfeng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2208.00817",
    "title": "DSLA: Dynamic smooth label assignment for efficient anchor-free object  detection",
    "abstract": "Anchor-free detectors basically formulate object detection as dense classification and regression. For popular anchor-free detectors, it is common to introduce an individual prediction branch to estimate the quality of localization. The following inconsistencies are observed when we delve into the practices of classification and quality estimation. Firstly, for some adjacent samples which are assigned completely different labels, the trained model would produce similar classification scores. This violates the training objective and leads to performance degradation. Secondly, it is found that detected bounding boxes with higher confidences contrarily have smaller overlaps with the corresponding ground-truth. Accurately localized bounding boxes would be suppressed by less accurate ones in the Non-Maximum Suppression (NMS) procedure. To address the inconsistency problems, the Dynamic Smooth Label Assignment (DSLA) method is proposed. Based on the concept of centerness originally developed in FCOS, a smooth assignment strategy is proposed. The label is smoothed to a continuous value in [0, 1] to make a steady transition between positive and negative samples. Intersection-of-Union (IoU) is predicted dynamically during training and is coupled with the smoothed label. The dynamic smooth label is assigned to supervise the classification branch. Under such supervision, quality estimation branch is naturally merged into the classification branch, which simplifies the architecture of anchor-free detector. Comprehensive experiments are conducted on the MS COCO benchmark. It is demonstrated that, DSLA can significantly boost the detection accuracy by alleviating the above inconsistencies for anchor-free detectors. Our codes are released at https://github.com/YonghaoHe/DSLA. ",
    "url": "https://arxiv.org/abs/2208.00817",
    "authors": [
      "Hu Su",
      "Yonghao He",
      "Jiabin Zhang",
      "Wei Zou",
      "Bin Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00834",
    "title": "Digital Twin Assisted Task Offloading for Aerial Edge Computing and  Networks",
    "abstract": "Considering the user mobility and unpredictable mobile edge computing (MEC) environments, this paper studies the intelligent task offloading problem in unmanned aerial vehicle (UAV)-enabled MEC with the assistance of digital twin (DT). We aim at minimizing the energy consumption of the entire MEC system by jointly optimizing mobile terminal users (MTUs) association, UAV trajectory, transmission power distribution and computation capacity allocation while respecting the constraints of mission maximum processing delays. Specifically, double deep Q-network (DDQN) algorithm stemming from deep reinforcement learning is first proposed to effectively solve the problem of MTUs association and UAV trajectory. Then, the closed-form expression is employed to handle the problem of transmission power distribution and the computation capacity allocation problem is further addressed via an iterative algorithm. Numerical results show that our proposed scheme is able to converge and significantly reduce the total energy consumption of the MEC system compared to the benchmark schemes. ",
    "url": "https://arxiv.org/abs/2208.00834",
    "authors": [
      "Bin Li",
      "Yufeng Liu",
      "Ling Tan",
      "Heng Pan",
      "Yan Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2208.00850",
    "title": "Subgraph Neighboring Relations Infomax for Inductive Link Prediction on  Knowledge Graphs",
    "abstract": "Inductive link prediction for knowledge graph aims at predicting missing links between unseen entities, those not shown in training stage. Most previous works learn entity-specific embeddings of entities, which cannot handle unseen entities. Recent several methods utilize enclosing subgraph to obtain inductive ability. However, all these works only consider the enclosing part of subgraph without complete neighboring relations, which leads to the issue that partial neighboring relations are neglected, and sparse subgraphs are hard to be handled. To address that, we propose Subgraph Neighboring Relations Infomax, SNRI, which sufficiently exploits complete neighboring relations from two aspects: neighboring relational feature for node feature and neighboring relational path for sparse subgraph. To further model neighboring relations in a global way, we innovatively apply mutual information (MI) maximization for knowledge graph. Experiments show that SNRI outperforms existing state-of-art methods by a large margin on inductive link prediction task, and verify the effectiveness of exploring complete neighboring relations in a global way to characterize node features and reason on sparse subgraphs. ",
    "url": "https://arxiv.org/abs/2208.00850",
    "authors": [
      "Xiaohan Xu",
      "Peng Zhang",
      "Yongquan He",
      "Chengpeng Chao",
      "Chaoyang Yan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00853",
    "title": "Guidance on the Safety Assurance of Autonomous Systems in Complex  Environments (SACE)",
    "abstract": "Autonomous systems (AS) are systems that have the capability to take decisions free from direct human control. AS are increasingly being considered for adoption for applications where their behaviour may cause harm, such as when used for autonomous driving, medical applications or in domestic environments. For such applications, being able to ensure and demonstrate (assure) the safety of the operation of the AS is crucial for their adoption. This can be particularly challenging where AS operate in complex and changing real-world environments. Establishing justified confidence in the safety of AS requires the creation of a compelling safety case. This document introduces a methodology for the Safety Assurance of Autonomous Systems in Complex Environments (SACE). SACE comprises a set of safety case patterns and a process for (1) systematically integrating safety assurance into the development of the AS and (2) for generating the evidence base for explicitly justifying the acceptable safety of the AS. ",
    "url": "https://arxiv.org/abs/2208.00853",
    "authors": [
      "Richard Hawkins",
      "Matt Osborne",
      "Mike Parsons",
      "Mark Nicholson",
      "John McDermid",
      "Ibrahim Habli"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.00861",
    "title": "Continuous locomotion mode recognition and gait phase estimation based  on a shank-mounted IMU with artificial neural networks",
    "abstract": "To improve the control of wearable robotics for gait assistance, we present an approach for continuous locomotion mode recognition as well as gait phase and stair slope estimation based on artificial neural networks that include time history information. The input features consist exclusively of processed variables that can be measured with a single shank-mounted inertial measurement unit. We introduce a wearable device to acquire real-world environment test data to demonstrate the performance and the robustness of the approach. Mean absolute error (gait phase, stair slope) and accuracy (locomotion mode) were determined for steady level walking and steady stair ambulation. Robustness was assessed using test data from different sensor hardware, sensor fixations, ambulation environments and subjects. The mean absolute error from the steady gait test data for the gait phase was 2.0-3.5 % for gait phase estimation and 3.3-3.8{\\deg} for stair slope estimation. The accuracy of classifying the correct locomotion mode on the test data with the utilization of time history information was in between 98.51 % and 99.67 %. Results show high performance and robustness for continuously predicting gait phase, stair slope and locomotion mode during steady gait. As hypothesized, time history information improves the locomotion mode recognition. However, while the gait phase estimation performed well for untrained transitions between locomotion modes, our qualitative analysis revealed that it may be beneficial to include transition data into the training of the neural network to improve the prediction of the slope and the locomotion mode. Our results suggest that artificial neural networks could be used for high level control of wearable lower limb robotics. ",
    "url": "https://arxiv.org/abs/2208.00861",
    "authors": [
      "Florian Weigand",
      "Andreas H\u00f6hl",
      "Julian Zeiss",
      "Ulrich Konigorski",
      "Martin Grimmer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.00862",
    "title": "Attacking Adversarial Defences by Smoothing the Loss Landscape",
    "abstract": "This paper investigates a family of methods for defending against adversarial attacks that owe part of their success to creating a noisy, discontinuous, or otherwise rugged loss landscape that adversaries find difficult to navigate. A common, but not universal, way to achieve this effect is via the use of stochastic neural networks. We show that this is a form of gradient obfuscation, and propose a general extension to gradient-based adversaries based on the Weierstrass transform, which smooths the surface of the loss function and provides more reliable gradient estimates. We further show that the same principle can strengthen gradient-free adversaries. We demonstrate the efficacy of our loss-smoothing method against both stochastic and non-stochastic adversarial defences that exhibit robustness due to this type of obfuscation. Furthermore, we provide analysis of how it interacts with Expectation over Transformation; a popular gradient-sampling method currently used to attack stochastic defences. ",
    "url": "https://arxiv.org/abs/2208.00862",
    "authors": [
      "Panagiotis Eustratiadis",
      "Henry Gouk",
      "Da Li",
      "Timothy Hospedales"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00867",
    "title": "Event-triggered Consensus Control of Heterogeneous Multi-agent Systems:  Model- and Data-based Analysis",
    "abstract": "This article deals with model- and data-based consensus control of heterogenous leader-following multi-agent systems (MASs) under an event-triggering transmission scheme. A dynamic periodic transmission protocol is developed to significantly alleviate the transmission frequency and computational burden, where the followers can interact locally with each other approaching the dynamics of the leader. Capitalizing on a discrete-time looped-functional, a model-based consensus condition for the closed-loop MASs is derived in form of linear matrix inequalities (LMIs), as well as a design method for obtaining the distributed controllers and event-triggering parameters. Upon collecting noise-corrupted state-input measurements during open-loop operation, a data-driven leader-following MAS representation is presented, and employed to solve the data-driven consensus control problem without requiring any knowledge of the agents' models. This result is then extended to the case of guaranteeing an $\\mathcal{H}_{\\infty}$ performance. A simulation example is finally given to corroborate the efficacy of the proposed distributed event-triggering scheme in cutting off data transmissions and the data-driven design method. ",
    "url": "https://arxiv.org/abs/2208.00867",
    "authors": [
      "Xin Wang",
      "Jian Sun",
      "Gang Wang",
      "Jie Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.00874",
    "title": "S$^2$Contact: Graph-based Network for 3D Hand-Object Contact Estimation  with Semi-Supervised Learning",
    "abstract": "Despite the recent efforts in accurate 3D annotations in hand and object datasets, there still exist gaps in 3D hand and object reconstructions. Existing works leverage contact maps to refine inaccurate hand-object pose estimations and generate grasps given object models. However, they require explicit 3D supervision which is seldom available and therefore, are limited to constrained settings, e.g., where thermal cameras observe residual heat left on manipulated objects. In this paper, we propose a novel semi-supervised framework that allows us to learn contact from monocular images. Specifically, we leverage visual and geometric consistency constraints in large-scale datasets for generating pseudo-labels in semi-supervised learning and propose an efficient graph-based network to infer contact. Our semi-supervised learning framework achieves a favourable improvement over the existing supervised learning methods trained on data with `limited' annotations. Notably, our proposed model is able to achieve superior results with less than half the network parameters and memory access cost when compared with the commonly-used PointNet-based approach. We show benefits from using a contact map that rules hand-object interactions to produce more accurate reconstructions. We further demonstrate that training with pseudo-labels can extend contact map estimations to out-of-domain objects and generalise better across multiple datasets. ",
    "url": "https://arxiv.org/abs/2208.00874",
    "authors": [
      "Tze Ho Elden Tse",
      "Zhongqun Zhang",
      "Kwang In Kim",
      "Ales Leonardis",
      "Feng Zheng",
      "Hyung Jin Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00894",
    "title": "Towards Computing an Optimal Abstraction for Structural Causal Models",
    "abstract": "Working with causal models at different levels of abstraction is an important feature of science. Existing work has already considered the problem of expressing formally the relation of abstraction between causal models. In this paper, we focus on the problem of learning abstractions. We start by defining the learning problem formally in terms of the optimization of a standard measure of consistency. We then point out the limitation of this approach, and we suggest extending the objective function with a term accounting for information loss. We suggest a concrete measure of information loss, and we illustrate its contribution to learning new abstractions. ",
    "url": "https://arxiv.org/abs/2208.00894",
    "authors": [
      "Fabio Massimo Zennaro",
      "Paolo Turrini",
      "Theodoros Damoulas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.00901",
    "title": "PSAA: Provable Secure and Anti-Quantum Authentication Based on  Randomized RLWE for Space Information Network",
    "abstract": "Currently, due to the high scalability and global coverage of space information network (SIN), more service providers and users are willing to provide or subscribe to personal services through the satellite network. However, the messages are transmitted in public satellite-ground links, which makes access users vulnerable to various forms of attacks. Existing authentication protocols do not meet the expected security and short delay requirements to ensure the security of real-time user access and the confidentiality of communication content. Moreover, with the development of quantum computers, the difficult problems such as ECDLP and DLP have also been proven to be solvable in polynomial time, leading to new threats. Therefore, in this paper, we propose a provably secure and anti-quantum authentication protocol based on randomized RLWE. The protocol not only meets the pre-defined security requirements, but also reduces the total delay of the authentication phase based on the pre-negotiation and fewer authentication transmission. In addition, a concise handover scheme is designed for signal handover scenarios caused by satellite dynamic topology. Further rigorous formal and informal security proofs and performance analysis show that our proposed protocol is more applicable to SIN, while ensuring higher security and resisting various attacks with lower authentication delay. ",
    "url": "https://arxiv.org/abs/2208.00901",
    "authors": [
      "Junyan Guo",
      "Ye Du",
      "Xuesong Wu",
      "Meihong Li",
      "Runfang Wu",
      "Zhichao Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.00904",
    "title": "Revisiting Information Cascades in Online Social Networks",
    "abstract": "It's by now folklore that to understand the activity pattern of a user in an online social network (OSN) platform, one needs to look at his friends or the ones he follows. The common perception is that these friends exert influence on the user, effecting his decision whether to re-share content or not. Hinging upon this intuition, a variety of models were developed to predict how information propagates in OSN, similar to the way infection spreads in the population. In this paper, we revisit this world view and arrive at new conclusions. Given a set of users $V$, we study the task of predicting whether a user $u \\in V$ will re-share content by some $v \\in V$ at the following time window given the activity of all the users in $V$ in the previous time window. We design several algorithms for this task, ranging from a simple greedy algorithm that only learns $u$'s conditional probability distribution, ignoring the rest of $V$, to a convolutional neural network-based algorithm that receives the activity of all of $V$, but does not receive explicitly the social link structure. We tested our algorithms on four datasets that we collected from Twitter, each revolving around a different popular topic in 2020. The best performance, average F1-score of 0.86 over the four datasets, was achieved by the convolutional neural network. The simple, social-link ignorant, algorithm achieved an average F1-score of 0.78. ",
    "url": "https://arxiv.org/abs/2208.00904",
    "authors": [
      "Michael Sidorov",
      "Dan Vilenchik"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00906",
    "title": "Understanding Adversarial Robustness of Vision Transformers via Cauchy  Problem",
    "abstract": "Recent research on the robustness of deep learning has shown that Vision Transformers (ViTs) surpass the Convolutional Neural Networks (CNNs) under some perturbations, e.g., natural corruption, adversarial attacks, etc. Some papers argue that the superior robustness of ViT comes from the segmentation of its input images; others say that the Multi-head Self-Attention (MSA) is the key to preserving the robustness. In this paper, we aim to introduce a principled and unified theoretical framework to investigate such an argument on ViT's robustness. We first theoretically prove that, unlike Transformers in Natural Language Processing, ViTs are Lipschitz continuous. Then we theoretically analyze the adversarial robustness of ViTs from the perspective of the Cauchy Problem, via which we can quantify how the robustness propagates through layers. We demonstrate that the first and last layers are the critical factors to affect the robustness of ViTs. Furthermore, based on our theory, we empirically show that unlike the claims from existing research, MSA only contributes to the adversarial robustness of ViTs under weak adversarial attacks, e.g., FGSM, and surprisingly, MSA actually comprises the model's adversarial robustness under stronger attacks, e.g., PGD attacks. ",
    "url": "https://arxiv.org/abs/2208.00906",
    "authors": [
      "Zheng Wang",
      "Wenjie Ruan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00945",
    "title": "DoF-NeRF: Depth-of-Field Meets Neural Radiance Fields",
    "abstract": "Neural Radiance Field (NeRF) and its variants have exhibited great success on representing 3D scenes and synthesizing photo-realistic novel views. However, they are generally based on the pinhole camera model and assume all-in-focus inputs. This limits their applicability as images captured from the real world often have finite depth-of-field (DoF). To mitigate this issue, we introduce DoF-NeRF, a novel neural rendering approach that can deal with shallow DoF inputs and can simulate DoF effect. In particular, it extends NeRF to simulate the aperture of lens following the principles of geometric optics. Such a physical guarantee allows DoF-NeRF to operate views with different focus configurations. Benefiting from explicit aperture modeling, DoF-NeRF also enables direct manipulation of DoF effect by adjusting virtual aperture and focus parameters. It is plug-and-play and can be inserted into NeRF-based frameworks. Experiments on synthetic and real-world datasets show that, DoF-NeRF not only performs comparably with NeRF in the all-in-focus setting, but also can synthesize all-in-focus novel views conditioned on shallow DoF inputs. An interesting application of DoF-NeRF to DoF rendering is also demonstrated. The source code will be made available at https://github.com/zijinwuzijin/DoF-NeRF. ",
    "url": "https://arxiv.org/abs/2208.00945",
    "authors": [
      "Zijin Wu",
      "Xingyi Li",
      "Juewen Peng",
      "Hao Lu",
      "Zhiguo Cao",
      "Weicai Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00946",
    "title": "Motion-aware Memory Network for Fast Video Salient Object Detection",
    "abstract": "Previous methods based on 3DCNN, convLSTM, or optical flow have achieved great success in video salient object detection (VSOD). However, they still suffer from high computational costs or poor quality of the generated saliency maps. To solve these problems, we design a space-time memory (STM)-based network, which extracts useful temporal information of the current frame from adjacent frames as the temporal branch of VSOD. Furthermore, previous methods only considered single-frame prediction without temporal association. As a result, the model may not focus on the temporal information sufficiently. Thus, we initially introduce object motion prediction between inter-frame into VSOD. Our model follows standard encoder--decoder architecture. In the encoding stage, we generate high-level temporal features by using high-level features from the current and its adjacent frames. This approach is more efficient than the optical flow-based methods. In the decoding stage, we propose an effective fusion strategy for spatial and temporal branches. The semantic information of the high-level features is used to fuse the object details in the low-level features, and then the spatiotemporal features are obtained step by step to reconstruct the saliency maps. Moreover, inspired by the boundary supervision commonly used in image salient object detection (ISOD), we design a motion-aware loss for predicting object boundary motion and simultaneously perform multitask learning for VSOD and object motion prediction, which can further facilitate the model to extract spatiotemporal features accurately and maintain the object integrity. Extensive experiments on several datasets demonstrated the effectiveness of our method and can achieve state-of-the-art metrics on some datasets. The proposed model does not require optical flow or other preprocessing, and can reach a speed of nearly 100 FPS during inference. ",
    "url": "https://arxiv.org/abs/2208.00946",
    "authors": [
      "Xing Zhao",
      "Haoran Liang",
      "Peipei Li",
      "Guodao Sun",
      "Dongdong Zhao",
      "Ronghua Liang",
      "Xiaofei He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00953",
    "title": "What do Deep Neural Networks Learn in Medical Images?",
    "abstract": "Deep learning is increasingly gaining rapid adoption in healthcare to help improve patient outcomes. This is more so in medical image analysis which requires extensive training to gain the requisite expertise to become a trusted practitioner. However, while deep learning techniques have continued to provide state-of-the-art predictive performance, one of the primary challenges that stands to hinder this progress in healthcare is the opaque nature of the inference mechanism of these models. So, attribution has a vital role in building confidence in stakeholders for the predictions made by deep learning models to inform clinical decisions. This work seeks to answer the question: what do deep neural network models learn in medical images? In that light, we present a novel attribution framework using adaptive path-based gradient integration techniques. Results show a promising direction of building trust in domain experts to improve healthcare outcomes by allowing them to understand the input-prediction correlative structures, discover new bio-markers, and reveal potential model biases. ",
    "url": "https://arxiv.org/abs/2208.00953",
    "authors": [
      "Yusuf Brima",
      "Marcellin Atemkeng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00955",
    "title": "Large-Scale Product Retrieval with Weakly Supervised Representation  Learning",
    "abstract": "Large-scale weakly supervised product retrieval is a practically useful yet computationally challenging problem. This paper introduces a novel solution for the eBay Visual Search Challenge (eProduct) held at the Ninth Workshop on Fine-Grained Visual Categorisation workshop (FGVC9) of CVPR 2022. This competition presents two challenges: (a) E-commerce is a drastically fine-grained domain including many products with subtle visual differences; (b) A lacking of target instance-level labels for model training, with only coarse category labels and product titles available. To overcome these obstacles, we formulate a strong solution by a set of dedicated designs: (a) Instead of using text training data directly, we mine thousands of pseudo-attributes from product titles and use them as the ground truths for multi-label classification. (b) We incorporate several strong backbones with advanced training recipes for more discriminative representation learning. (c) We further introduce a number of post-processing techniques including whitening, re-ranking and model ensemble for retrieval enhancement. By achieving 71.53% MAR, our solution \"Involution King\" achieves the second position on the leaderboard. ",
    "url": "https://arxiv.org/abs/2208.00955",
    "authors": [
      "Xiao Han",
      "Kam Woh Ng",
      "Sauradip Nag",
      "Zhiyu Qu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00963",
    "title": "FrOoDo: Framework for Out-of-Distribution Detection",
    "abstract": "FrOoDo is an easy-to-use and flexible framework for Out-of-Distribution detection tasks in digital pathology. It can be used with PyTorch classification and segmentation models, and its modular design allows for easy extension. The goal is to automate the task of OoD Evaluation such that research can focus on the main goal of either designing new models, new methods or evaluating a new dataset. The code can be found at https://github.com/MECLabTUDA/FrOoDo. ",
    "url": "https://arxiv.org/abs/2208.00963",
    "authors": [
      "Jonathan Stieber",
      "Moritz Fuchs",
      "Anirban Mukhopadhyay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00979",
    "title": "Automatically Discovering Novel Visual Categories with Self-supervised  Prototype Learning",
    "abstract": "This paper tackles the problem of novel category discovery (NCD), which aims to discriminate unknown categories in large-scale image collections. The NCD task is challenging due to the closeness to the real-world scenarios, where we have only encountered some partial classes and images. Unlike other works on the NCD, we leverage the prototypes to emphasize the importance of category discrimination and alleviate the issue of missing annotations of novel classes. Concretely, we propose a novel adaptive prototype learning method consisting of two main stages: prototypical representation learning and prototypical self-training. In the first stage, we obtain a robust feature extractor, which could serve for all images with base and novel categories. This ability of instance and category discrimination of the feature extractor is boosted by self-supervised learning and adaptive prototypes. In the second stage, we utilize the prototypes again to rectify offline pseudo labels and train a final parametric classifier for category clustering. We conduct extensive experiments on four benchmark datasets and demonstrate the effectiveness and robustness of the proposed method with state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2208.00979",
    "authors": [
      "Lu Zhang",
      "Lu Qi",
      "Xu Yang",
      "Hong Qiao",
      "Ming-Hsuan Yang",
      "Zhiyong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00982",
    "title": "Dominant Eigenvalue-Eigenvector Pair Estimation via Graph Infection",
    "abstract": "We present a novel method to estimate the dominant eigenvalue and eigenvector pair of any non-negative real matrix via graph infection. The key idea in our technique lies in approximating the solution to the first-order matrix ordinary differential equation (ODE) with the Euler method. Graphs, which can be weighted, directed, and with loops, are first converted to its adjacency matrix A. Then by a naive infection model for graphs, we establish the corresponding first-order matrix ODE, through which A's dominant eigenvalue is revealed by the fastest growing term. When there are multiple dominant eigenvalues of the same magnitude, the classical power iteration method can fail. In contrast, our method can converge to the dominant eigenvalue even when same-magnitude counterparts exist, be it complex or opposite in sign. We conduct several experiments comparing the convergence between our method and power iteration. Our results show clear advantages over power iteration for tree graphs, bipartite graphs, directed graphs with periods, and Markov chains with spider-traps. To our knowledge, this is the first work that estimates dominant eigenvalue and eigenvector pair from the perspective of a dynamical system and matrix ODE. We believe our method can be adopted as an alternative to power iteration, especially for graphs. ",
    "url": "https://arxiv.org/abs/2208.00982",
    "authors": [
      "Kaiyuan Yang",
      "Li Xia",
      "Y.C. Tay"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2208.01008",
    "title": "CBAG: An Efficient Genetic Algorithm for the Graph Burning Problem",
    "abstract": "Information spread is an intriguing topic to study in network science, which investigates how information, influence, or contagion propagate through networks. Graph burning is a simplified deterministic model for how information spreads within networks. The complicated NP-complete nature of the problem makes it computationally difficult to solve using exact algorithms. Accordingly, a number of heuristics and approximation algorithms have been proposed in the literature for the graph burning problem. In this paper, we propose an efficient genetic algorithm called Centrality BAsed Genetic-algorithm (CBAG) for solving the graph burning problem. Considering the unique characteristics of the graph burning problem, we introduce novel genetic operators, chromosome representation, and evaluation method. In the proposed algorithm, the well-known betweenness centrality is used as the backbone of our chromosome initialization procedure. The proposed algorithm is implemented and compared with previous heuristics and approximation algorithms on 15 benchmark graphs of different sizes. Based on the results, it can be seen that the proposed algorithm achieves better performance in comparison to the previous state-of-the-art heuristics. The complete source code is available online and can be used to find optimal or near-optimal solutions for the graph burning problem. ",
    "url": "https://arxiv.org/abs/2208.01008",
    "authors": [
      "Mahdi Nazeri",
      "Ali Mollahosseini",
      "Iman Izadi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2208.01014",
    "title": "Robust Change Detection Based on Neural Descriptor Fields",
    "abstract": "The ability to reason about changes in the environment is crucial for robots operating over extended periods of time. Agents are expected to capture changes during operation so that actions can be followed to ensure a smooth progression of the working session. However, varying viewing angles and accumulated localization errors make it easy for robots to falsely detect changes in the surrounding world due to low observation overlap and drifted object associations. In this paper, based on the recently proposed category-level Neural Descriptor Fields (NDFs), we develop an object-level online change detection approach that is robust to partially overlapping observations and noisy localization results. Utilizing the shape completion capability and SE(3)-equivariance of NDFs, we represent objects with compact shape codes encoding full object shapes from partial observations. The objects are then organized in a spatial tree structure based on object centers recovered from NDFs for fast queries of object neighborhoods. By associating objects via shape code similarity and comparing local object-neighbor spatial layout, our proposed approach demonstrates robustness to low observation overlap and localization noises. We conduct experiments on both synthetic and real-world sequences and achieve improved change detection results compared to multiple baseline methods. Project webpage: https://yilundu.github.io/ndf_change ",
    "url": "https://arxiv.org/abs/2208.01014",
    "authors": [
      "Jiahui Fu",
      "Yilun Du",
      "Kurran Singh",
      "Joshua B. Tenenbaum",
      "John J. Leonard"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00097",
    "title": "Robust Rayleigh Regression Method for SAR Image Processing in Presence  of Outliers",
    "abstract": "The presence of outliers (anomalous values) in synthetic aperture radar (SAR) data and the misspecification in statistical image models may result in inaccurate inferences. To avoid such issues, the Rayleigh regression model based on a robust estimation process is proposed as a more realistic approach to model this type of data. This paper aims at obtaining Rayleigh regression model parameter estimators robust to the presence of outliers. The proposed approach considered the weighted maximum likelihood method and was submitted to numerical experiments using simulated and measured SAR images. Monte Carlo simulations were employed for the numerical assessment of the proposed robust estimator performance in finite signal lengths, their sensitivity to outliers, and the breakdown point. For instance, the non-robust estimators show a relative bias value $65$-fold larger than the results provided by the robust approach in corrupted signals. In terms of sensitivity analysis and break down point, the robust scheme resulted in a reduction of about $96\\%$ and $10\\%$, respectively, in the mean absolute value of both measures, in compassion to the non-robust estimators. Moreover, two SAR data sets were used to compare the ground type and anomaly detection results of the proposed robust scheme with competing methods in the literature. ",
    "url": "https://arxiv.org/abs/2208.00097",
    "authors": [
      "B. G. Palm",
      "F. M. Bayer",
      "R. Machado",
      "M. I.Pettersson",
      "V. T. Vu",
      "R. J. Cintra"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2208.00111",
    "title": "20 years of network community detection",
    "abstract": "A fundamental technical challenge in the analysis of network data is the automated discovery of communities - groups of nodes that are strongly connected or that share similar features or roles. In this commentary we review progress in the field over the last 20 years. ",
    "url": "https://arxiv.org/abs/2208.00111",
    "authors": [
      "Santo Fortunato",
      "Mark E. J. Newman"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2208.00137",
    "title": "Efficient estimation and inference for the signed $\u03b2$-model in  directed signed networks",
    "abstract": "This paper proposes a novel signed $\\beta$-model for directed signed network, which is frequently encountered in application domains but largely neglected in literature. The proposed signed $\\beta$-model decomposes a directed signed network as the difference of two unsigned networks and embeds each node with two latent factors for in-status and out-status. The presence of negative edges leads to a non-concave log-likelihood, and a one-step estimation algorithm is developed to facilitate parameter estimation, which is efficient both theoretically and computationally. We also develop an inferential procedure for pairwise and multiple node comparisons under the signed $\\beta$-model, which fills the void of lacking uncertainty quantification for node ranking. Theoretical results are established for the coverage probability of confidence interval, as well as the false discovery rate (FDR) control for multiple node comparison. The finite sample performance of the signed $\\beta$-model is also examined through extensive numerical experiments on both synthetic and real-life networks. ",
    "url": "https://arxiv.org/abs/2208.00137",
    "authors": [
      "Haoran Zhang",
      "Junhui Wang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2208.00207",
    "title": "LRIP-Net: Low-Resolution Image Prior based Network for Limited-Angle CT  Reconstruction",
    "abstract": "In the practical applications of computed tomography imaging, the projection data may be acquired within a limited-angle range and corrupted by noises due to the limitation of scanning conditions. The noisy incomplete projection data results in the ill-posedness of the inverse problems. In this work, we theoretically verify that the low-resolution reconstruction problem has better numerical stability than the high-resolution problem. In what follows, a novel low-resolution image prior based CT reconstruction model is proposed to make use of the low-resolution image to improve the reconstruction quality. More specifically, we build up a low-resolution reconstruction problem on the down-sampled projection data, and use the reconstructed low-resolution image as prior knowledge for the original limited-angle CT problem. We solve the constrained minimization problem by the alternating direction method with all subproblems approximated by the convolutional neural networks. Numerical experiments demonstrate that our double-resolution network outperforms both the variational method and popular learning-based reconstruction methods on noisy limited-angle reconstruction problems. ",
    "url": "https://arxiv.org/abs/2208.00207",
    "authors": [
      "Qifeng Gao",
      "Rui Ding",
      "Linyuan Wang",
      "Bin Xue",
      "Yuping Duan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2208.00349",
    "title": "What Do Deep Neural Networks Find in Disordered Structures of Glasses?",
    "abstract": "Glass transitions are widely observed in a range of types of soft matter systems. However, the physical mechanism of these transitions remains unknown, despite years of ambitious research. In particular, an important unanswered question is whether the glass transition is accompanied by a divergence of the correlation lengths of the characteristic static structures. Recently, a method that can predict long-time dynamics from purely static information with high accuracy was proposed; however, even this method is not universal and does not work well for the Kob--Andersen system, which is a typical model of glass-forming liquids. In this study, we developed a method to extract the characteristic structures of glasses using machine learning or, specifically, a convolutional neural network. In particular, we extracted the characteristic structures by quantifying the grounds for the decisions made by the network. We considered two qualitatively different glass-forming binary systems and, through comparisons with several established structural indicators, we demonstrate that our system can identify characteristic structures that depend on the details of the systems. Surprisingly, the extracted structures were strongly correlated with the nonequilibrium aging dynamics on thermal fluctuation. ",
    "url": "https://arxiv.org/abs/2208.00349",
    "authors": [
      "Norihiro Oyama",
      "Shihori Koyama",
      "Takeshi Kawasaki"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00352",
    "title": "Neural Correlates of Face Familiarity Perception",
    "abstract": "In the domain of face recognition, there exists a puzzling timing discrepancy between results from macaque neurophysiology on the one hand and human electrophysiology on the other. Single unit recordings in macaques have demonstrated face identity specific responses in extra-striate visual cortex within 100 milliseconds of stimulus onset. In EEG and MEG experiments with humans, however, a consistent distinction between neural activity corresponding to unfamiliar and familiar faces has been reported to emerge around 250 ms. This points to the possibility that there may be a hitherto undiscovered early correlate of face familiarity perception in human electrophysiological traces. We report here a successful search for such a correlate in dense MEG recordings using pattern classification techniques. Our analyses reveal markers of face familiarity as early as 85 ms after stimulus onset. Low-level attributes of the images, such as luminance and color distributions, are unable to account for this early emerging response difference. These results help reconcile human and macaque data, and provide clues regarding neural mechanisms underlying familiar face perception. ",
    "url": "https://arxiv.org/abs/2208.00352",
    "authors": [
      "Evan Ehrenberg",
      "Kleovoulos Leo Tsourides",
      "Hossein Nejati",
      "Ngai-Man Cheung",
      "Pawan Sinha"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2208.00480",
    "title": "Quantum networks with coherent routing of information through multiple  nodes",
    "abstract": "Large-scale communication networks, such as the internet, achieve the transmission of information from a sender to a distant receiver by routing packets of data through many intermediate nodes. Classically, each packet has to follow a well-defined path through the network. In a quantum network, however, it is in principle possible to route information along multiple paths in a coherent quantum superposition. Here we develop a model of quantum communication network with coherent routing of information through multiple intermediate nodes. In this model, we show that the distance over which information can be transmitted reliably can be significantly extended. Surprisingly, this improvement takes place also for purely classical channels, such as binary asymmetric channels. In the ideal setting where the coherent superposition of paths is not affected by noise, we find that classical data can be reliably transmitted at a constant rate through asymptotically long sequences of binary asymmetric channels, which in normal conditions would lead to an exponential decay of the transmission rate. In more realistic conditions involving decoherence on the paths, we find that the combined use of coherent control on the path and local operations at intermediate nodes achieves significantly higher communication rates over finite distances. ",
    "url": "https://arxiv.org/abs/2208.00480",
    "authors": [
      "Hl\u00e9r Kristj\u00e1nsson",
      "Yan Zhong",
      "Anthony Munson",
      "Giulio Chiribella"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2208.00594",
    "title": "Breast Cancer Classification Based on Histopathological Images Using a  Deep Learning Capsule Network",
    "abstract": "Breast cancer is one of the most serious types of cancer that can occur in women. The automatic diagnosis of breast cancer by analyzing histological images (HIs) is important for patients and their prognosis. The classification of HIs provides clinicians with an accurate understanding of diseases and allows them to treat patients more efficiently. Deep learning (DL) approaches have been successfully employed in a variety of fields, particularly medical imaging, due to their capacity to extract features automatically. This study aims to classify different types of breast cancer using HIs. In this research, we present an enhanced capsule network that extracts multi-scale features using the Res2Net block and four additional convolutional layers. Furthermore, the proposed method has fewer parameters due to using small convolutional kernels and the Res2Net block. As a result, the new method outperforms the old ones since it automatically learns the best possible features. The testing results show that the model outperformed the previous DL methods. ",
    "url": "https://arxiv.org/abs/2208.00594",
    "authors": [
      "Hayder A. Khikani",
      "Naira Elazab",
      "Ahmed Elgarayhi",
      "Mohammed Elmogy",
      "Mohammed Sallah"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00604",
    "title": "Beyond kNN: Adaptive, Sparse Neighborhood Graphs via Optimal Transport",
    "abstract": "Nearest neighbour graphs are widely used to capture the geometry or topology of a dataset. One of the most common strategies to construct such a graph is based on selecting a fixed number k of nearest neighbours (kNN) for each point. However, the kNN heuristic may become inappropriate when sampling density or noise level varies across datasets. Strategies that try to get around this typically introduce additional parameters that need to be tuned. We propose a simple approach to construct an adaptive neighbourhood graph from a single parameter, based on quadratically regularised optimal transport. Our numerical experiments show that graphs constructed in this manner perform favourably in unsupervised and semi-supervised learning applications. ",
    "url": "https://arxiv.org/abs/2208.00604",
    "authors": [
      "Tetsuya Matsumoto",
      "Stephen Zhang",
      "Geoffrey Schiebinger"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00746",
    "title": "Assessing the robustness of critical behavior in stochastic cellular  automata",
    "abstract": "There is evidence that biological systems, such as the brain, work at a critical regime robust to noise, and are therefore able to remain in it under perturbations. In this work, we address the question of robustness of critical systems to noise. In particular, we investigate the robustness of stochastic cellular automata (CAs) at criticality. A stochastic CA is one of the simplest stochastic models showing criticality. The transition state of stochastic CA is defined through a set of probabilities. We systematically perturb the probabilities of an optimal stochastic CA known to produce critical behavior, and we report that such a CA is able to remain in a critical regime up to a certain degree of noise. We present the results using error metrics of the resulting power-law fitting, such as Kolmogorov-Smirnov statistic and Kullback-Leibler divergence. We discuss the implication of our results in regards to future realization of brain-inspired artificial intelligence systems. ",
    "url": "https://arxiv.org/abs/2208.00746",
    "authors": [
      "Sidney Pontes-Filho",
      "Pedro Lind",
      "Stefano Nichele"
    ],
    "subjectives": [
      "Cellular Automata and Lattice Gases (nlin.CG)",
      "Information Theory (cs.IT)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2208.00768",
    "title": "Brain Tumor Diagnosis and Classification via Pre-Trained Convolutional  Neural Networks",
    "abstract": "The brain tumor is the most aggressive kind of tumor and can cause low life expectancy if diagnosed at the later stages. Manual identification of brain tumors is tedious and prone to errors. Misdiagnosis can lead to false treatment and thus reduce the chances of survival for the patient. Medical resonance imaging (MRI) is the conventional method used to diagnose brain tumors and their types. This paper attempts to eliminate the manual process from the diagnosis process and use machine learning instead. We proposed the use of pretrained convolutional neural networks (CNN) for the diagnosis and classification of brain tumors. Three types of tumors were classified with one class of non-tumor MRI images. Networks that has been used are ResNet50, EfficientNetB1, EfficientNetB7, EfficientNetV2B1. EfficientNet has shown promising results due to its scalable nature. EfficientNetB1 showed the best results with training and validation accuracy of 87.67% and 89.55%, respectively. ",
    "url": "https://arxiv.org/abs/2208.00768",
    "authors": [
      "Dmytro Filatov",
      "Ghulam Nabi Ahmad Hassan Yar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00809",
    "title": "Neural network layers as parametric spans",
    "abstract": "Properties such as composability and automatic differentiation made artificial neural networks a pervasive tool in applications. Tackling more challenging problems caused neural networks to progressively become more complex and thus difficult to define from a mathematical perspective. We present a general definition of linear layer arising from a categorical framework based on the notions of integration theory and parametric spans. This definition generalizes and encompasses classical layers (e.g., dense, convolutional), while guaranteeing existence and computability of the layer's derivatives for backpropagation. ",
    "url": "https://arxiv.org/abs/2208.00809",
    "authors": [
      "Mattia G. Bergomi",
      "Pietro Vertechi"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00840",
    "title": "A Transformer-based Neural Language Model that Synthesizes Brain  Activation Maps from Free-Form Text Queries",
    "abstract": "Neuroimaging studies are often limited by the number of subjects and cognitive processes that can be feasibly interrogated. However, a rapidly growing number of neuroscientific studies have collectively accumulated an extensive wealth of results. Digesting this growing literature and obtaining novel insights remains to be a major challenge, since existing meta-analytic tools are constrained to keyword queries. In this paper, we present Text2Brain, an easy to use tool for synthesizing brain activation maps from open-ended text queries. Text2Brain was built on a transformer-based neural network language model and a coordinate-based meta-analysis of neuroimaging studies. Text2Brain combines a transformer-based text encoder and a 3D image generator, and was trained on variable-length text snippets and their corresponding activation maps sampled from 13,000 published studies. In our experiments, we demonstrate that Text2Brain can synthesize meaningful neural activation patterns from various free-form textual descriptions. Text2Brain is available at https://braininterpreter.com as a web-based tool for efficiently searching through the vast neuroimaging literature and generating new hypotheses. ",
    "url": "https://arxiv.org/abs/2208.00840",
    "authors": [
      "Gia H. Ngo",
      "Minh Nguyen",
      "Nancy F. Chen",
      "Mert R. Sabuncu"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2208.00877",
    "title": "Self-supervised Group Meiosis Contrastive Learning for EEG-Based Emotion  Recognition",
    "abstract": "The progress in EEG-based emotion recognition has received widespread attention from the fields of human-machine interactions and cognitive science in recent years. However,the scarcity of high granularity and dense artificial labels contributes to the bottleneck of emotion recognition with high real-time and granularity. Neuroscience studies have discovered exploitable stimuli labels. It reveals that EEG samples recorded when subjects were triggered by the same stimuli share the same stimuli label. This paper proposed a Self-supervised Group Meiosis Contrastive Learning (SGMC) framework to exploit such stimuli labels for emotion recognition. The SGMC adopts a genetic inspired data augmentation method Meiosis. It achieves augmenting a group of samples sharing the same stimuli label to generate two augmented groups by pairing, cross exchanging, and separating. A group-projector-based model is adopted. The model achieves extracting a group-level representation by extracting individual representations from a group and aggregating them into a group-level representation. Contrastive learning is employed to maximize the similarity of group-level representations of augmented groups sharing the same stimuli label. The SGMC achieved the state-of-the-art results on the publicly available DEAP dataset with an accuracy of 94.72% and 95.68% in valence and arousal dimensions. Especially the SGMC shows more excellent performance on limited labeled sample learning. In addition, we verified the rationality of the framework design by control experiment and ablation study, and investigated the cause of the formation of good performance by feature visualization, and hyper parametric analysis. The code is provided publicly online ",
    "url": "https://arxiv.org/abs/2208.00877",
    "authors": [
      "Haoning Kan",
      "Jiale Yu",
      "Jiajin Huang",
      "Zihe Liu",
      "Haiyan Zhou"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2208.00885",
    "title": "Many-to-One Knowledge Distillation of Real-Time Epileptic Seizure  Detection for Low-Power Wearable Internet of Things Systems",
    "abstract": "Integrating low-power wearable Internet of Things (IoT) systems into routine health monitoring is an ongoing challenge. Recent advances in the computation capabilities of wearables make it possible to target complex scenarios by exploiting multiple biosignals and using high-performance algorithms, such as Deep Neural Networks (DNNs). There is, however, a trade-off between performance of the algorithms and the low-power requirements of IoT platforms with limited resources. Besides, physically larger and multi-biosignal-based wearables bring significant discomfort to the patients. Consequently, reducing power consumption and discomfort is necessary for patients to use IoT devices continuously during everyday life. To overcome these challenges, in the context of epileptic seizure detection, we propose a many-to-one signals knowledge distillation approach targeting single-biosignal processing in IoT wearable systems. The starting point is to get a highly-accurate multi-biosignal DNN, then apply our approach to develop a single-biosignal DNN solution for IoT systems that achieves an accuracy comparable to the original multi-biosignal DNN. To assess the practicality of our approach to real-life scenarios, we perform a comprehensive simulation experiment analysis on several state-of-the-art edge computing platforms, such as Kendryte K210 and Raspberry Pi Zero. ",
    "url": "https://arxiv.org/abs/2208.00885",
    "authors": [
      "Saleh Baghersalimi. Alireza Amirshahi",
      "Farnaz Forooghifar",
      "Tomas Teijeiro",
      "Amir Aminifar",
      "David Atienza"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00971",
    "title": "Probabilistic forecasts of extreme heatwaves using convolutional neural  networks in a regime of lack of data",
    "abstract": "Understanding extreme events and their probability is key for the study of climate change impacts, risk assessment, adaptation, and the protection of living beings. In this work we develop a methodology to build forecasting models for extreme heatwaves. These models are based on convolutional neural networks, trained on extremely long 8,000-year climate model outputs. Because the relation between extreme events is intrinsically probabilistic, we emphasise probabilistic forecast and validation. We demonstrate that deep neural networks are suitable for this purpose for long lasting 14-day heatwaves over France, up to 15 days ahead of time for fast dynamical drivers (500 hPa geopotential height fields), and also at much longer lead times for slow physical drivers (soil moisture). The method is easily implemented and versatile. We find that the deep neural network selects extreme heatwaves associated with a North-Hemisphere wavenumber-3 pattern. We find that the 2 meter temperature field does not contain any new useful statistical information for heatwave forecast, when added to the 500 hPa geopotential height and soil moisture fields. The main scientific message is that training deep neural networks for predicting extreme heatwaves occurs in a regime of drastic lack of data. We suggest that this is likely the case for most other applications to large scale atmosphere and climate phenomena. We discuss perspectives for dealing with the lack of data regime, for instance rare event simulations, and how transfer learning may play a role in this latter task. ",
    "url": "https://arxiv.org/abs/2208.00971",
    "authors": [
      "George Miloshevich",
      "Bastien Cozian",
      "Patrice Abry",
      "Pierre Borgnat",
      "Freddy Bouchet"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2208.01001",
    "title": "Two New Characterizations of Path Graphs",
    "abstract": "Path graphs are intersection graphs of paths in a tree. We start from the characterization of path graphs by Monma and Wei [C.L.~Monma,~and~V.K.~Wei, Intersection Graphs of Paths in a Tree, J. Combin. Theory Ser. B, 41:2 (1986) 141--181] and we reduce it to some 2-colorings subproblems, obtaining the first characterization that directly leads to a polynomial recognition algorithm. Then we introduce the collection of the attachedness graphs of a graph and we exhibit a list of minimal forbidden 2-edge colored subgraphs in each of the attachedness graph. ",
    "url": "https://arxiv.org/abs/2208.01001",
    "authors": [
      "Nicola Apollonio",
      "Lorenzo Balzotti"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2208.01003",
    "title": "How Wide Convolutional Neural Networks Learn Hierarchical Tasks",
    "abstract": "Despite their success, understanding how convolutional neural networks (CNNs) can efficiently learn high-dimensional functions remains a fundamental challenge. A popular belief is that these models harness the compositional and hierarchical structure of natural data such as images. Yet, we lack a quantitative understanding of how such structure affects performances, e.g. the rate of decay of the generalisation error with the number of training samples. In this paper we study deep CNNs in the kernel regime: i) we show that the spectrum of the corresponding kernel and its asymptotics inherit the hierarchical structure of the network; ii) we use generalisation bounds to prove that deep CNNs adapt to the spatial scale of the target function; iii) we illustrate this result by computing the rate of decay of the error in a teacher-student setting, where a deep CNN is trained on the output of another deep CNN with randomly-initialised parameters. We find that if the teacher function depends on certain low-dimensional subsets of the input variables, then the rate is controlled by the effective dimensionality of these subsets. Conversely, if the teacher function depends on the full set of input variables, then the error rate is inversely proportional to the input dimension. Interestingly, this implies that despite their hierarchical structure, the functions generated by deep CNNs are too rich to be efficiently learnable in high dimension. ",
    "url": "https://arxiv.org/abs/2208.01003",
    "authors": [
      "Francesco Cagnetta",
      "Alessandro Favero",
      "Matthieu Wyart"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1909.01541",
    "title": "Graph Transfer Learning via Adversarial Domain Adaptation with Graph  Convolution",
    "abstract": " Comments: Accepted by IEEE Transactions on Knowledge and Data Engineering ",
    "url": "https://arxiv.org/abs/1909.01541",
    "authors": [
      "Quanyu Dai",
      "Xiao-Ming Wu",
      "Jiaren Xiao",
      "Xiao Shen",
      "Dan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2011.04107",
    "title": "Graphene-based Wireless Agile Interconnects for Massive Heterogeneous  Multi-chip Processors",
    "abstract": " Comments: 8 pages, 4 figures, 1 table - Accepted at IEEE Wireless Communications Magazine ",
    "url": "https://arxiv.org/abs/2011.04107",
    "authors": [
      "Sergi Abadal",
      "Robert Guirado",
      "Hamidreza Taghvaee",
      "Akshay Jain",
      "Elana Pereira de Santana",
      "Peter Haring Bol\u00edvar",
      "Mohamed Saeed",
      "Renato Negra",
      "Zhenxing Wang",
      "Kun-Ta Wang",
      "Max C. Lemme",
      "Joshua Klein",
      "Marina Zapater",
      "Alexandre Levisse",
      "David Atienza",
      "Davide Rossi",
      "Francesco Conti",
      "Martino Dazzi",
      "Geethan Karunaratne",
      "Irem Boybat",
      "Abu Sebastian"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2011.05801",
    "title": "A Small Survey On Event Detection Using Twitter",
    "abstract": " Title: A Small Survey On Event Detection Using Twitter ",
    "url": "https://arxiv.org/abs/2011.05801",
    "authors": [
      "Debanjan Datta"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.13044",
    "title": "Union-net: A deep neural network model adapted to small data sets",
    "abstract": " Comments: 23 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2012.13044",
    "authors": [
      "Jingyi Zhou",
      "Qingfang He",
      "Zhiying Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2102.05096",
    "title": "Towards Bridging the gap between Empirical and Certified Robustness  against Adversarial Examples",
    "abstract": " Comments: An abridged version of this work has been presented at ICLR 2021 Workshop on Security and Safety in Machine Learning Systems: this https URL ",
    "url": "https://arxiv.org/abs/2102.05096",
    "authors": [
      "Jay Nandy",
      "Sudipan Saha",
      "Wynne Hsu",
      "Mong Li Lee",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2103.12263",
    "title": "Non-Euclidean Contraction Theory for Robust Nonlinear Stability",
    "abstract": " Title: Non-Euclidean Contraction Theory for Robust Nonlinear Stability ",
    "url": "https://arxiv.org/abs/2103.12263",
    "authors": [
      "Alexander Davydov",
      "Saber Jafarpour",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2104.08373",
    "title": "Constructing Robust Emotional State-based Feature with a Novel Voting  Scheme for Multi-modal Deception Detection in Videos",
    "abstract": " Comments: 8 pages, for AAAI23 publication ",
    "url": "https://arxiv.org/abs/2104.08373",
    "authors": [
      "Jun-Teng Yang",
      "Guei-Ming Liu",
      "Scott C.-H Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.00220",
    "title": "Generative Adversarial Networks via a Composite Annealing of Noise and  Diffusion",
    "abstract": " Title: Generative Adversarial Networks via a Composite Annealing of Noise and  Diffusion ",
    "url": "https://arxiv.org/abs/2105.00220",
    "authors": [
      "Kensuke Nakamura",
      "Simon Korman",
      "Byung-Woo Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.03527",
    "title": "Multi-Exit Semantic Segmentation Networks",
    "abstract": " Comments: (Extended version) Accepted at ECCV 2022 ",
    "url": "https://arxiv.org/abs/2106.03527",
    "authors": [
      "Alexandros Kouris",
      "Stylianos I. Venieris",
      "Stefanos Laskaridis",
      "Nicholas D. Lane"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.03722",
    "title": "Error Loss Networks",
    "abstract": " Title: Error Loss Networks ",
    "url": "https://arxiv.org/abs/2106.03722",
    "authors": [
      "Badong Chen",
      "Yunfei Zheng",
      "Pengju Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.06458",
    "title": "Cross-Modal Graph with Meta Concepts for Video Captioning",
    "abstract": " Comments: Accepted at IEEE Transactions on Image Processing ",
    "url": "https://arxiv.org/abs/2108.06458",
    "authors": [
      "Hao Wang",
      "Guosheng Lin",
      "Steven C. H. Hoi",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.00725",
    "title": "Causal Inference in Natural Language Processing: Estimation, Prediction,  Interpretation and Beyond",
    "abstract": " Comments: Accepted to Transactions of the Association for Computational Linguistics (TACL) ",
    "url": "https://arxiv.org/abs/2109.00725",
    "authors": [
      "Amir Feder",
      "Katherine A. Keith",
      "Emaad Manzoor",
      "Reid Pryzant",
      "Dhanya Sridhar",
      "Zach Wood-Doughty",
      "Jacob Eisenstein",
      "Justin Grimmer",
      "Roi Reichart",
      "Margaret E. Roberts",
      "Brandon M. Stewart",
      "Victor Veitch",
      "Diyi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.05580",
    "title": "A Joint Graph and Image Convolution Network for Automatic Brain Tumor  Segmentation",
    "abstract": " Comments: 9 pages, 3 figures, submitted to BrainLes Workshop (MICCAI 2021) as part of BraTS2021 challenge ",
    "url": "https://arxiv.org/abs/2109.05580",
    "authors": [
      "Camillo Saueressig",
      "Adam Berkley",
      "Reshma Munbodh",
      "Ritambhara Singh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Tissues and Organs (q-bio.TO)"
    ]
  },
  {
    "id": "arXiv:2109.12696",
    "title": "PM-FSM: Policies Modulating Finite State Machine for Robust Quadrupedal  Locomotion",
    "abstract": " Title: PM-FSM: Policies Modulating Finite State Machine for Robust Quadrupedal  Locomotion ",
    "url": "https://arxiv.org/abs/2109.12696",
    "authors": [
      "Ren Liu",
      "Nitish Sontakke",
      "Sehoon Ha"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.13208",
    "title": "Spiking neural networks trained via proxy",
    "abstract": " Title: Spiking neural networks trained via proxy ",
    "url": "https://arxiv.org/abs/2109.13208",
    "authors": [
      "Saeed Reza Kheradpisheh",
      "Maryam Mirsadeghi",
      "Timoth\u00e9e Masquelier"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.01359",
    "title": "CENN: Conservative energy method based on neural networks with  subdomains for solving variational problems involving heterogeneous and  complex geometries",
    "abstract": " Comments: 39 pages, 22 figures, 1 graphical abstract ",
    "url": "https://arxiv.org/abs/2110.01359",
    "authors": [
      "Yizheng Wang",
      "Jia Sun",
      "Wei Li",
      "Zaiyuan Lu",
      "Yinghua Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.02125",
    "title": "Adversarial Robustness Verification and Attack Synthesis in Stochastic  Systems",
    "abstract": " Comments: To Appear, 35th IEEE Computer Security Foundations Symposium (2022) ",
    "url": "https://arxiv.org/abs/2110.02125",
    "authors": [
      "Lisa Oakley",
      "Alina Oprea",
      "Stavros Tripakis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2111.01592",
    "title": "Trajectory Prediction with Graph-based Dual-scale Context Fusion",
    "abstract": " Comments: Accepted by IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2022. Code: this https URL ",
    "url": "https://arxiv.org/abs/2111.01592",
    "authors": [
      "Lu Zhang",
      "Peiliang Li",
      "Jing Chen",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.07722",
    "title": "Stacked BNAS: Rethinking Broad Convolutional Neural Network for Neural  Architecture Search",
    "abstract": " Comments: 12 pages, 10 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2111.07722",
    "authors": [
      "Zixiang Ding",
      "Yaran Chen",
      "Nannan Li",
      "Dongbin Zhao",
      "C.L.Philip Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.08117",
    "title": "Neural networks with linear threshold activations: structure and  algorithms",
    "abstract": " Title: Neural networks with linear threshold activations: structure and  algorithms ",
    "url": "https://arxiv.org/abs/2111.08117",
    "authors": [
      "Sammy Khalife",
      "Hongyu Cheng",
      "Amitabh Basu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.11046",
    "title": "FRT-PAD: Effective Presentation Attack Detection Driven by Face Related  Task",
    "abstract": " Comments: Accepted by ECCV 2022 ",
    "url": "https://arxiv.org/abs/2111.11046",
    "authors": [
      "Wentian Zhang",
      "Haozhe Liu",
      "Feng Liu",
      "Raghavendra Ramachandra",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.13613",
    "title": "The Geometry of Adversarial Training in Binary Classification",
    "abstract": " Title: The Geometry of Adversarial Training in Binary Classification ",
    "url": "https://arxiv.org/abs/2111.13613",
    "authors": [
      "Leon Bungert",
      "Nicol\u00e1s Garc\u00eda Trillos",
      "Ryan Murray"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Metric Geometry (math.MG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.07924",
    "title": "Knowledge-Grounded Dialogue Generation with a Unified Knowledge  Representation",
    "abstract": " Comments: Accepted to NAACL 2022 ",
    "url": "https://arxiv.org/abs/2112.07924",
    "authors": [
      "Yu Li",
      "Baolin Peng",
      "Yelong Shen",
      "Yi Mao",
      "Lars Liden",
      "Zhou Yu",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.11397",
    "title": "NN2Poly: A polynomial representation for deep feed-forward artificial  neural networks",
    "abstract": " Title: NN2Poly: A polynomial representation for deep feed-forward artificial  neural networks ",
    "url": "https://arxiv.org/abs/2112.11397",
    "authors": [
      "Pablo Morala",
      "Jenny Alexandra Cifuentes",
      "Rosa E. Lillo",
      "I\u00f1aki Ucar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.15031",
    "title": "Development of a face mask detection pipeline for mask-wearing  monitoring in the era of the COVID-19 pandemic: A modular approach",
    "abstract": " Comments: Accepted at the 19th International Joint Conference on Computer Science and Software Engineering (JCSSE 2022) ",
    "url": "https://arxiv.org/abs/2112.15031",
    "authors": [
      "Benjaphan Sommana",
      "Ukrit Watchareeruetai",
      "Ankush Ganguly",
      "Samuel W.F. Earp",
      "Taya Kitiyakara",
      "Suparee Boonmanunt",
      "Ratchainant Thammasudjarit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.01415",
    "title": "Problem-dependent attention and effort in neural networks with an  application to image resolution",
    "abstract": " Title: Problem-dependent attention and effort in neural networks with an  application to image resolution ",
    "url": "https://arxiv.org/abs/2201.01415",
    "authors": [
      "Chris Rohlfs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2201.04572",
    "title": "Transmission Scheme, Detection and Power Allocation for Uplink User  Cooperation with NOMA and RSMA",
    "abstract": " Comments: 32 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2201.04572",
    "authors": [
      "Omid Abbasi",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2201.06997",
    "title": "Explainable AI Framework for COVID-19 Prediction in Different Provinces  of India",
    "abstract": " Comments: 12 pages ",
    "url": "https://arxiv.org/abs/2201.06997",
    "authors": [
      "Mredulraj S. Pandianchery",
      "Gopalakrishnan E.A",
      "Sowmya V",
      "Vinayakumar Ravi",
      "Soman K.P"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2201.09360",
    "title": "POTHER: Patch-Voted Deep Learning-Based Chest X-ray Bias Analysis for  COVID-19 Detection",
    "abstract": " Comments: Accepted at International Conference on Computational Science (ICCS) 2022, London ",
    "url": "https://arxiv.org/abs/2201.09360",
    "authors": [
      "Tomasz Szczepa\u0144ski",
      "Arkadiusz Sitek",
      "Tomasz Trzci\u0144ski",
      "Szymon P\u0142otka"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05725",
    "title": "On the Detection of Adaptive Adversarial Attacks in Speaker Verification  Systems",
    "abstract": " Title: On the Detection of Adaptive Adversarial Attacks in Speaker Verification  Systems ",
    "url": "https://arxiv.org/abs/2202.05725",
    "authors": [
      "Zesheng Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2202.07706",
    "title": "Misinformation Detection in Social Media Video Posts",
    "abstract": " Comments: We discovered an error in our dataset construction where retweets were not properly filtered. This resulted in test data leakage in training data, and the results reported are affected ",
    "url": "https://arxiv.org/abs/2202.07706",
    "authors": [
      "Kehan Wang",
      "David Chan",
      "Seth Z. Zhao",
      "John Canny",
      "Avideh Zakhor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.02846",
    "title": "Region Proposal Rectification Towards Robust Instance Segmentation of  Biological Images",
    "abstract": " Title: Region Proposal Rectification Towards Robust Instance Segmentation of  Biological Images ",
    "url": "https://arxiv.org/abs/2203.02846",
    "authors": [
      "Qilong Zhangli",
      "Jingru Yi",
      "Di Liu",
      "Xiaoxiao He",
      "Zhaoyang Xia",
      "Qi Chang",
      "Ligong Han",
      "Yunhe Gao",
      "Song Wen",
      "Haiming Tang",
      "He Wang",
      "Mu Zhou",
      "Dimitris Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05698",
    "title": "Learning-based Localizability Estimation for Robust LiDAR Localization",
    "abstract": " Comments: 8 pages, 7 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2203.05698",
    "authors": [
      "Julian Nubert",
      "Etienne Walther",
      "Shehryar Khattak",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07411",
    "title": "On Connecting Deep Trigonometric Networks with Deep Gaussian Processes:  Covariance, Expressivity, and Neural Tangent Kernel",
    "abstract": " Comments: version 2 contains new analysis on finite width effect on kernel and NTK, and more connection to other works; v3 includes numerical simulation connecting exact DGP predictive mean with weight space results ",
    "url": "https://arxiv.org/abs/2203.07411",
    "authors": [
      "Chi-Ken Lu",
      "Patrick Shafto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.07548",
    "title": "Physical Neural Cellular Automata for 2D Shape Classification",
    "abstract": " Title: Physical Neural Cellular Automata for 2D Shape Classification ",
    "url": "https://arxiv.org/abs/2203.07548",
    "authors": [
      "Kathryn Walker",
      "Rasmus Berg Palm",
      "Rodrigo Moreno Garcia",
      "Andres Faina",
      "Kasper Stoy",
      "Sebastian Risi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.08207",
    "title": "SocialVAE: Human Trajectory Prediction using Timewise Latents",
    "abstract": " Comments: In the 17th European Conference on Computer Vision (ECCV 2022). Code: this https URL ",
    "url": "https://arxiv.org/abs/2203.08207",
    "authors": [
      "Pei Xu",
      "Jean-Bernard Hayet",
      "Ioannis Karamouzas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.08302",
    "title": "Internet-based Social Engineering Attacks, Defenses and Psychology: A  Survey",
    "abstract": " Comments: * Shared first-author ",
    "url": "https://arxiv.org/abs/2203.08302",
    "authors": [
      "Theodore Longtchi",
      "Rosana Monta\u00f1ez Rodriguez",
      "Laith Al-Shawaf",
      "Adham Atyabi",
      "Shouhuai Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2203.11183",
    "title": "Masked Discrimination for Self-Supervised Learning on Point Clouds",
    "abstract": " Comments: ECCV 2022; Code: this https URL ",
    "url": "https://arxiv.org/abs/2203.11183",
    "authors": [
      "Haotian Liu",
      "Mu Cai",
      "Yong Jae Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.12273",
    "title": "DAN: a Segmentation-free Document Attention Network for Handwritten  Document Recognition",
    "abstract": " Title: DAN: a Segmentation-free Document Attention Network for Handwritten  Document Recognition ",
    "url": "https://arxiv.org/abs/2203.12273",
    "authors": [
      "Denis Coquenet",
      "Cl\u00e9ment Chatelain",
      "Thierry Paquet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.14221",
    "title": "How Severe is Benchmark-Sensitivity in Video Self-Supervised Learning?",
    "abstract": " Comments: Accepted in ECCV 2022 ",
    "url": "https://arxiv.org/abs/2203.14221",
    "authors": [
      "Fida Mohammad Thoker",
      "Hazel Doughty",
      "Piyush Bagad",
      "Cees Snoek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15854",
    "title": "Locomotion Policy Guided Traversability Learning using Volumetric  Representations of Complex Environments",
    "abstract": " Comments: accepted for 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022) ",
    "url": "https://arxiv.org/abs/2203.15854",
    "authors": [
      "Jonas Frey",
      "David Hoeller",
      "Shehryar Khattak",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.01105",
    "title": "Better Lattice Quantizers Constructed from Complex Integers",
    "abstract": " Comments: 22 pages ",
    "url": "https://arxiv.org/abs/2204.01105",
    "authors": [
      "Shanxiang Lyu",
      "Zheng Wang",
      "Cong Ling",
      "Hao Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2204.04090",
    "title": "Generative Adversarial Method Based On Neural Tangent Kernels",
    "abstract": " Title: Generative Adversarial Method Based On Neural Tangent Kernels ",
    "url": "https://arxiv.org/abs/2204.04090",
    "authors": [
      "Yu-Rong Zhang",
      "Sheng Yen Chou",
      "Shan-Hung Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04444",
    "title": "Path-Tree Optimization in Discrete Partially Observable Environments  using Rapidly-Exploring Belief-Space Graphs",
    "abstract": " Comments: Also submitted to IROS 2022 and RA-L ",
    "url": "https://arxiv.org/abs/2204.04444",
    "authors": [
      "Camille Phiquepal",
      "Andreas Orthey",
      "Nicolas Viennot",
      "Marc Toussaint"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.04944",
    "title": "Semantic Segmentation for Point Cloud Scenes via Dilated Graph Feature  Aggregation and Pyramid Decoders",
    "abstract": " Comments: accepted to AAAI Workshop 2022 ",
    "url": "https://arxiv.org/abs/2204.04944",
    "authors": [
      "Yongqiang Mao",
      "Xian Sun",
      "Wenhui Diao",
      "Kaiqiang Chen",
      "Zonghao Guo",
      "Xiaonan Lu",
      "Kun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05562",
    "title": "FederatedScope-GNN: Towards a Unified, Comprehensive and Efficient  Package for Federated Graph Learning",
    "abstract": " Comments: Accpeted by KDD'2022; We have released FederatedScope for users on this https URL ",
    "url": "https://arxiv.org/abs/2204.05562",
    "authors": [
      "Zhen Wang",
      "Weirui Kuang",
      "Yuexiang Xie",
      "Liuyi Yao",
      "Yaliang Li",
      "Bolin Ding",
      "Jingren Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.06171",
    "title": "Self-Supervised Traffic Advisors: Distributed, Multi-view Traffic  Prediction for Smart Cities",
    "abstract": " Comments: 2022 IEEE 25th International Conference on Intelligent Transportation Systems (ITSC) ",
    "url": "https://arxiv.org/abs/2204.06171",
    "authors": [
      "Jiankai Sun",
      "Shreyas Kousik",
      "David Fridovich-Keil",
      "Mac Schwager"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.08453",
    "title": "Neural Space-filling Curves",
    "abstract": " Comments: ECCV 2022. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2204.08453",
    "authors": [
      "Hanyu Wang",
      "Kamal Gupta",
      "Larry Davis",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08665",
    "title": "Interventional Behavior Prediction: Avoiding Overly Confident  Anticipation in Interactive Prediction",
    "abstract": " Title: Interventional Behavior Prediction: Avoiding Overly Confident  Anticipation in Interactive Prediction ",
    "url": "https://arxiv.org/abs/2204.08665",
    "authors": [
      "Chen Tang",
      "Wei Zhan",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.11231",
    "title": "Do ReLU Networks Have An Edge When Approximating Compactly-Supported  Functions?",
    "abstract": " Comments: 23 Pages: Main Text - 16 pages, Appendix - 7.5 pages, - Bibliography - 5 pages ",
    "url": "https://arxiv.org/abs/2204.11231",
    "authors": [
      "Anastasis Kratsios",
      "Behnoosh Zamanlooy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2204.12231",
    "title": "IRC-safe Graph Autoencoder for unsupervised anomaly detection",
    "abstract": " Comments: 16 pages, 5 figures, Matched with the published version ",
    "url": "https://arxiv.org/abs/2204.12231",
    "authors": [
      "Oliver Atkinson",
      "Akanksha Bhardwaj",
      "Christoph Englert",
      "Partha Konar",
      "Vishal S. Ngairangbam",
      "Michael Spannowsky"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2205.02111",
    "title": "Improved Orientation Estimation and Detection with Hybrid Object  Detection Networks for Automotive Radar",
    "abstract": " Comments: (c) 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works ",
    "url": "https://arxiv.org/abs/2205.02111",
    "authors": [
      "Michael Ulrich",
      "Sascha Braun",
      "Daniel K\u00f6hler",
      "Daniel Niederl\u00f6hner",
      "Florian Faion",
      "Claudius Gl\u00e4ser",
      "Holger Blume"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.05874",
    "title": "Distinction Maximization Loss: Efficiently Improving Out-of-Distribution  Detection and Uncertainty Estimation by Replacing the Loss and Calibrating",
    "abstract": " Title: Distinction Maximization Loss: Efficiently Improving Out-of-Distribution  Detection and Uncertainty Estimation by Replacing the Loss and Calibrating ",
    "url": "https://arxiv.org/abs/2205.05874",
    "authors": [
      "David Mac\u00eado",
      "Cleber Zanchettin",
      "Teresa Ludermir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.09378",
    "title": "Joint Relay Selection and Power Control that aims to Maximize Sum-Rate  in Multi-Hop Networks",
    "abstract": " Comments: Extended Version, Submitted to IEEE Communications Letters ",
    "url": "https://arxiv.org/abs/2205.09378",
    "authors": [
      "Shalanika Dayarathna",
      "Rajitha Senanayake",
      "Jamie Evans"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.11989",
    "title": "Realization Theory Of Recurrent Neural ODEs Using Polynomial System  Embeddings",
    "abstract": " Comments: 10 pages. Corrected typos and added references ",
    "url": "https://arxiv.org/abs/2205.11989",
    "authors": [
      "Martin Gonzalez",
      "Thibault Defourneau",
      "Hatem Hajri",
      "Mihaly Petreczky"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12902",
    "title": "GARDNet: Robust Multi-View Network for Glaucoma Classification in Color  Fundus Images",
    "abstract": " Comments: Keywords: Glaucoma Classification, Color Fundus Images. Computer Aided Diagnosis. Deep Learning ",
    "url": "https://arxiv.org/abs/2205.12902",
    "authors": [
      "Ahmed Al Mahrooqi",
      "Dmitrii Medvedev",
      "Rand Muhtaseb",
      "Mohammad Yaqub"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13522",
    "title": "Dynamically Relative Position Encoding-Based Transformer for Automatic  Code Edit",
    "abstract": " Title: Dynamically Relative Position Encoding-Based Transformer for Automatic  Code Edit ",
    "url": "https://arxiv.org/abs/2205.13522",
    "authors": [
      "Shiyi Qi",
      "Yaoxian Li",
      "Cuiyun Gao",
      "Xiaohong Su",
      "Shuzheng Gao",
      "Zibin Zheng",
      "Chuanyi Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.14548",
    "title": "Image Super-resolution with An Enhanced Group Convolutional Neural  Network",
    "abstract": " Title: Image Super-resolution with An Enhanced Group Convolutional Neural  Network ",
    "url": "https://arxiv.org/abs/2205.14548",
    "authors": [
      "Chunwei Tian",
      "Yixuan Yuan",
      "Shichao Zhang",
      "Chia-Wen Lin",
      "Wangmeng Zuo",
      "David Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.01397",
    "title": "Dynamic Structured Illumination Microscopy with a Neural Space-time  Model",
    "abstract": " Title: Dynamic Structured Illumination Microscopy with a Neural Space-time  Model ",
    "url": "https://arxiv.org/abs/2206.01397",
    "authors": [
      "Ruiming Cao",
      "Fanglin Linda Liu",
      "Li-Hao Yeh",
      "Laura Waller"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.01410",
    "title": "Fair Classification via Transformer Neural Networks: Case Study of an  Educational Domain",
    "abstract": " Comments: 5 pages, 1 figure, 2 tables ",
    "url": "https://arxiv.org/abs/2206.01410",
    "authors": [
      "Modar Sulaiman",
      "Kallol Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.01520",
    "title": "A Survey on Surrogate-assisted Efficient Neural Architecture Search",
    "abstract": " Comments: 18 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2206.01520",
    "authors": [
      "Shiqing Liu",
      "Haoyu Zhang",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.07897",
    "title": "NCAGC: A Neighborhood Contrast Framework for Attributed Graph Clustering",
    "abstract": " Title: NCAGC: A Neighborhood Contrast Framework for Attributed Graph Clustering ",
    "url": "https://arxiv.org/abs/2206.07897",
    "authors": [
      "Tong Wang",
      "Guanyu Yang",
      "Qijia He",
      "Zhenquan Zhang",
      "Junhua Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09509",
    "title": "Hybrid Facial Expression Recognition (FER2013) Model for Real-Time  Emotion Classification and Prediction",
    "abstract": " Comments: 8 Pages, 8 Figures, 5 Tables ",
    "url": "https://arxiv.org/abs/2206.09509",
    "authors": [
      "Ozioma Collins Oguine",
      "Kanyifeechukwu Jane Oguine",
      "Hashim Ibrahim Bisallah",
      "Daniel Ofuani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.12136",
    "title": "Feature Representation Learning for Robust Retinal Disease Detection  from Optical Coherence Tomography Images",
    "abstract": " Comments: Accepted to MICCAI2022 Ophthalmic Medical Image Analysis (OMIA) Workshop ",
    "url": "https://arxiv.org/abs/2206.12136",
    "authors": [
      "Sharif Amit Kamran",
      "Khondker Fariha Hossain",
      "Alireza Tavakkoli",
      "Stewart Lee Zuckerbrod",
      "Salah A. Baker"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.12293",
    "title": "Text and author-level political inference using heterogeneous knowledge  representations",
    "abstract": " Title: Text and author-level political inference using heterogeneous knowledge  representations ",
    "url": "https://arxiv.org/abs/2206.12293",
    "authors": [
      "Samuel Caetano da Silva",
      "Ivandre Paraboni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.14774",
    "title": "TweetNLP: Cutting-Edge Natural Language Processing for Social Media",
    "abstract": " Comments: Demo paper. TweetNLP: this https URL ",
    "url": "https://arxiv.org/abs/2206.14774",
    "authors": [
      "Jose Camacho-Collados",
      "Kiamehr Rezaee",
      "Talayeh Riahi",
      "Asahi Ushio",
      "Daniel Loureiro",
      "Dimosthenis Antypas",
      "Joanne Boisson",
      "Luis Espinosa-Anke",
      "Fangyu Liu",
      "Eugenio Mart\u00ednez-C\u00e1mara",
      "Gonzalo Medina",
      "Thomas Buhrmann",
      "Leonardo Neves",
      "Francesco Barbieri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.15031",
    "title": "Timestamp-Supervised Action Segmentation with Graph Convolutional  Networks",
    "abstract": " Comments: Accepted to IROS 2022 ",
    "url": "https://arxiv.org/abs/2206.15031",
    "authors": [
      "Hamza Khan",
      "Sanjay Haresh",
      "Awais Ahmed",
      "Shakeeb Siddiqui",
      "Andrey Konin",
      "M. Zeeshan Zia",
      "Quoc-Huy Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00762",
    "title": "Backdoor Attack is a Devil in Federated GAN-based Medical Image  Synthesis",
    "abstract": " Comments: 13 pages, 4 figures, Accepted by MICCAI 2022 SASHIMI Workshop ",
    "url": "https://arxiv.org/abs/2207.00762",
    "authors": [
      "Ruinan Jin",
      "Xiaoxiao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.01200",
    "title": "S$^{5}$Mars: Self-Supervised and Semi-Supervised Learning for Mars  Segmentation",
    "abstract": " Title: S$^{5}$Mars: Self-Supervised and Semi-Supervised Learning for Mars  Segmentation ",
    "url": "https://arxiv.org/abs/2207.01200",
    "authors": [
      "Jiahang Zhang",
      "Lilang Lin",
      "Zejia Fan",
      "Wenjing Wang",
      "Jiaying Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01873",
    "title": "ICE-NODE: Integration of Clinical Embeddings with Neural Ordinary  Differential Equations",
    "abstract": " Comments: Accepted at Machine Learning for Healthcare 2022 ",
    "url": "https://arxiv.org/abs/2207.01873",
    "authors": [
      "Asem Alaa",
      "Erik Mayer",
      "Mauricio Barahona"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.03343",
    "title": "Refutation of Spectral Graph Theory Conjectures with Monte Carlo Search",
    "abstract": " Comments: 12 pages, figures and pseudocode in appendix ",
    "url": "https://arxiv.org/abs/2207.03343",
    "authors": [
      "Milo Roucairol",
      "Tristan Cazenave"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2207.05784",
    "title": "Distilled Non-Semantic Speech Embeddings with Binary Neural Networks for  Low-Resource Devices",
    "abstract": " Title: Distilled Non-Semantic Speech Embeddings with Binary Neural Networks for  Low-Resource Devices ",
    "url": "https://arxiv.org/abs/2207.05784",
    "authors": [
      "Harlin Lee",
      "Aaqib Saeed"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.05851",
    "title": "Sockeye 3: Fast Neural Machine Translation with PyTorch",
    "abstract": " Title: Sockeye 3: Fast Neural Machine Translation with PyTorch ",
    "url": "https://arxiv.org/abs/2207.05851",
    "authors": [
      "Felix Hieber",
      "Michael Denkowski",
      "Tobias Domhan",
      "Barbara Darques Barros",
      "Celina Dong Ye",
      "Xing Niu",
      "Cuong Hoang",
      "Ke Tran",
      "Benjamin Hsu",
      "Maria Nadejde",
      "Surafel Lakew",
      "Prashant Mathur",
      "Anna Currey",
      "Marcello Federico"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.09686",
    "title": "Object-Compositional Neural Implicit Surfaces",
    "abstract": " Comments: ECCV2022, Project Page: this https URL Code: this https URL ",
    "url": "https://arxiv.org/abs/2207.09686",
    "authors": [
      "Qianyi Wu",
      "Xian Liu",
      "Yuedong Chen",
      "Kejie Li",
      "Chuanxia Zheng",
      "Jianfei Cai",
      "Jianmin Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11382",
    "title": "Density-Aware Personalized Training for Risk Prediction in Imbalanced  Medical Data",
    "abstract": " Title: Density-Aware Personalized Training for Risk Prediction in Imbalanced  Medical Data ",
    "url": "https://arxiv.org/abs/2207.11382",
    "authors": [
      "Zepeng Huo",
      "Xiaoning Qian",
      "Shuai Huang",
      "Zhangyang Wang",
      "Bobak J. Mortazavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11441",
    "title": "Meta Spatio-Temporal Debiasing for Video Scene Graph Generation",
    "abstract": " Comments: Accepted by ECCV 2022 ",
    "url": "https://arxiv.org/abs/2207.11441",
    "authors": [
      "Li Xu",
      "Haoxuan Qu",
      "Jason Kuen",
      "Jiuxiang Gu",
      "Jun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11837",
    "title": "Inter-model Interpretability: Self-supervised Models as a Case Study",
    "abstract": " Comments: The paper is under consideration at Computer Vision and Image Understanding Journal ",
    "url": "https://arxiv.org/abs/2207.11837",
    "authors": [
      "Ahmad Mustapha",
      "Wael Khreich",
      "Wes Masri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.13317",
    "title": "Convolutional Embedding Makes Hierarchical Vision Transformer Stronger",
    "abstract": " Comments: ECCV 2022 ",
    "url": "https://arxiv.org/abs/2207.13317",
    "authors": [
      "Cong Wang",
      "Hongmin Xu",
      "Xiong Zhang",
      "Li Wang",
      "Zhitong Zheng",
      "Haifeng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.13518",
    "title": "Future Unruptured Intracranial Aneurysm Growth Prediction using Mesh  Convolutional Neural Networks",
    "abstract": " Comments: Accepted for The Second Workshop on Topological Data Analysis for Biomedical Data, MICCAI 2022 ",
    "url": "https://arxiv.org/abs/2207.13518",
    "authors": [
      "Kimberley M. Timmins",
      "Maarten J. Kamphuis",
      "Iris N. Vos",
      "Birgitta K. Velthuis",
      "Irene C. van der Schaaf",
      "Hugo J. Kuijf"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.13586",
    "title": "Encoding Concepts in Graph Neural Networks",
    "abstract": " Title: Encoding Concepts in Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2207.13586",
    "authors": [
      "Lucie Charlotte Magister",
      "Pietro Barbiero",
      "Dmitry Kazhdan",
      "Federico Siciliano",
      "Gabriele Ciravegna",
      "Fabrizio Silvestri",
      "Mateja Jamnik",
      "Pietro Lio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2207.13629",
    "title": "Proprioceptive Slip Detection for Planetary Rovers in Perceptually  Degraded Extraterrestrial Environments",
    "abstract": " Comments: 24 pages, 28 figures. Accepted for publication in Field Robotics ",
    "url": "https://arxiv.org/abs/2207.13629",
    "authors": [
      "Cagri Kilic",
      "Yu Gu",
      "Jason N. Gross"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.13729",
    "title": "Text Classification in Memristor-based Spiking Neural Networks",
    "abstract": " Comments: 23 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2207.13729",
    "authors": [
      "Jinqi Huang",
      "Alex Serb",
      "Spyros Stathopoulos",
      "Themis Prodromakis"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2207.14299",
    "title": "Graph Inverse Reinforcement Learning from Diverse Videos",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2207.14299",
    "authors": [
      "Sateesh Kumar",
      "Jonathan Zamora",
      "Nicklas Hansen",
      "Rishabh Jangir",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.14685",
    "title": "Replacing the Framingham-based equation for prediction of cardiovascular  disease risk and adverse outcome by using artificial intelligence and retinal  imaging",
    "abstract": " Comments: More data to be added ",
    "url": "https://arxiv.org/abs/2207.14685",
    "authors": [
      "Ehsan Vaghefi",
      "David Squirrell",
      "Songyang An",
      "Song Yang",
      "John Marshall"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  }
]