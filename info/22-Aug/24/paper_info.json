[
  {
    "id": "arXiv:2208.10489",
    "title": "System Fingerprints Detection for DeepFake Audio: An Initial Dataset and  Investigation",
    "abstract": "Many effective attempts have been made for deepfake audio detection. However, they can only distinguish between real and fake. For many practical application scenarios, what tool or algorithm generated the deepfake audio also is needed. This raises a question: Can we detect the system fingerprints of deepfake audio? Therefore, this paper conducts a preliminary investigation to detect system fingerprints of deepfake audio. Experiments are conducted on deepfake audio datasets from five latest deep-learning speech synthesis systems. The results show that LFCC features are relatively more suitable for system fingerprints detection. Moreover, the ResNet achieves the best detection results among LCNN and x-vector based models. The t-SNE visualization shows that different speech synthesis systems generate distinct system fingerprints. ",
    "url": "https://arxiv.org/abs/2208.10489",
    "authors": [
      "Xinrui Yan",
      "Jiangyan Yi",
      "Jianhua Tao",
      "Chenglong Wang",
      "Haoxin Ma",
      "Zhengkun Tian",
      "Ruibo Fu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2208.10493",
    "title": "Relational Self-Supervised Learning on Graphs",
    "abstract": "Over the past few years, graph representation learning (GRL) has been a powerful strategy for analyzing graph-structured data. Recently, GRL methods have shown promising results by adopting self-supervised learning methods developed for learning representations of images. Despite their success, existing GRL methods tend to overlook an inherent distinction between images and graphs, i.e., images are assumed to be independently and identically distributed, whereas graphs exhibit relational information among data instances, i.e., nodes. To fully benefit from the relational information inherent in the graph-structured data, we propose a novel GRL method, called RGRL, that learns from the relational information generated from the graph itself. RGRL learns node representations such that the relationship among nodes is invariant to augmentations, i.e., augmentation-invariant relationship, which allows the node representations to vary as long as the relationship among the nodes is preserved. By considering the relationship among nodes in both global and local perspectives, RGRL overcomes limitations of previous contrastive and non-contrastive methods, and achieves the best of both worlds. Extensive experiments on fourteen benchmark datasets over various downstream tasks demonstrate the superiority of RGRL over state-of-the-art baselines. The source code for RGRL is available at https://github.com/Namkyeong/RGRL. ",
    "url": "https://arxiv.org/abs/2208.10493",
    "authors": [
      "Namkyeong Lee",
      "Dongmin Hyun",
      "Junseok Lee",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.10496",
    "title": "Representation Learning of Knowledge Graph for Wireless Communication  Networks",
    "abstract": "With the application of the fifth-generation wireless communication technologies, more smart terminals are being used and generating huge amounts of data, which has prompted extensive research on how to handle and utilize these wireless data. Researchers currently focus on the research on the upper-layer application data or studying the intelligent transmission methods concerning a specific problem based on a large amount of data generated by the Monte Carlo simulations. This article aims to understand the endogenous relationship of wireless data by constructing a knowledge graph according to the wireless communication protocols, and domain expert knowledge and further investigating the wireless endogenous intelligence. We firstly construct a knowledge graph of the endogenous factors of wireless core network data collected via a 5G/B5G testing network. Then, a novel model based on graph convolutional neural networks is designed to learn the representation of the graph, which is used to classify graph nodes and simulate the relation prediction. The proposed model realizes the automatic nodes classification and network anomaly cause tracing. It is also applied to the public datasets in an unsupervised manner. Finally, the results show that the classification accuracy of the proposed model is better than the existing unsupervised graph neural network models, such as VGAE and ARVGE. ",
    "url": "https://arxiv.org/abs/2208.10496",
    "authors": [
      "Shiwen He",
      "Yeyu Ou",
      "Liangpeng Wang",
      "Hang Zhan",
      "Peng Ren",
      "Yongming Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2208.10531",
    "title": "Toward Better Target Representation for Source-Free and Black-Box Domain  Adaptation",
    "abstract": "Domain adaptation aims at aligning the labeled source domain and the unlabeled target domain, and most existing approaches assume the source data is accessible. Unfortunately, this paradigm raises concerns in data privacy and security. Recent studies try to dispel these concerns by the Source-Free setting, which adapts the source-trained model towards target domain without exposing the source data. However, the Source-Free paradigm is still at risk of data leakage due to adversarial attacks to the source model. Hence, the Black-Box setting is proposed, where only the outputs of source model can be utilized. In this paper, we address both the Source-Free adaptation and the Black-Box adaptation, proposing a novel method named better target representation from Frequency Mixup and Mutual Learning (FMML). Specifically, we introduce a new data augmentation technique as Frequency MixUp, which highlights task-relevant objects in the interpolations, thus enhancing class-consistency and linear behavior for target models. Moreover, we introduce a network regularization method called Mutual Learning to the domain adaptation problem. It transfers knowledge inside the target model via self-knowledge distillation and thus alleviates overfitting on the source domain by learning multi-scale target representations. Extensive experiments show that our method achieves state-of-the-art performance on several benchmark datasets under both settings. ",
    "url": "https://arxiv.org/abs/2208.10531",
    "authors": [
      "Qucheng Peng",
      "Zhengming Ding",
      "Lingjuan Lyu",
      "Lichao Sun",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.10550",
    "title": "Atrial Fibrillation Recurrence Risk Prediction from 12-lead ECG Recorded  Pre- and Post-Ablation Procedure",
    "abstract": "Introduction: 12-lead electrocardiogram (ECG) is recorded during atrial fibrillation (AF) catheter ablation procedure (CAP). It is not easy to determine if CAP was successful without a long follow-up assessing for AF recurrence (AFR). Therefore, an AFR risk prediction algorithm could enable a better management of CAP patients. In this research, we extracted features from 12-lead ECG recorded before and after CAP and train an AFR risk prediction machine learning model. Methods: Pre- and post-CAP segments were extracted from 112 patients. The analysis included a signal quality criterion, heart rate variability and morphological biomarkers engineered from the 12-lead ECG (804 features overall). 43 out of the 112 patients (n) had AFR clinical endpoint available. These were utilized to assess the feasibility of AFR risk prediction, using either pre or post CAP features. A random forest classifier was trained within a nested cross validation framework. Results: 36 features were found statistically significant for distinguishing between the pre and post surgery states (n=112). For the classification, an area under the receiver operating characteristic (AUROC) curve was reported with AUROC_pre=0.64 and AUROC_post=0.74 (n=43). Discussion and conclusions: This preliminary analysis showed the feasibility of AFR risk prediction. Such a model could be used to improve CAP management. ",
    "url": "https://arxiv.org/abs/2208.10550",
    "authors": [
      "Eran Zvuloni",
      "Sheina Gendelman",
      "Sanghamitra Mohanty",
      "Jason Lewen",
      "Andrea Natale",
      "Joachim A. Behar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2208.10557",
    "title": "On the characteristic polynomial of the $A_\u03b1$-matrix for some  operations of graphs",
    "abstract": "Let G be a graph of order $n$ with adjacency matrix $A(G)$ and diagonal matrix of degree $D(G)$. For every $\\alpha \\in [0,1]$, Nikiforov \\cite{VN17} defined the matrix $A_\\alpha(G) = \\alpha D(G) + (1-\\alpha)A(G)$. In this paper we present the $A_{\\alpha}(G)$-characteristic polynomial when $G$ is obtained by coalescing two graphs, and if $G$ is a semi-regular bipartite graph we obtain the $A_{\\alpha}$-characteristic polynomial of the line graph associated to $G$. Moreover, if $G$ is a regular graph we exhibit the $A_{\\alpha}$-characteristic polynomial for the graphs obtained from some operations. ",
    "url": "https://arxiv.org/abs/2208.10557",
    "authors": [
      "Jo\u00e3o Domingos G. da Silva Jr.",
      "Carla Silva Oliveira",
      "Liliana Manuela G. C. da Costa"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2208.10564",
    "title": "State Of The Art In Open-Set Iris Presentation Attack Detection",
    "abstract": "Research in presentation attack detection (PAD) for iris recognition has largely moved beyond evaluation in \"closed-set\" scenarios, to emphasize ability to generalize to presentation attack types not present in the training data. This paper offers several contributions to understand and extend the state-of-the-art in open-set iris PAD. First, it describes the most authoritative evaluation to date of iris PAD. We have curated the largest publicly-available image dataset for this problem, drawing from 26 benchmarks previously released by various groups, and adding 150,000 images being released with the journal version of this paper, to create a set of 450,000 images representing authentic iris and seven types of presentation attack instrument (PAI). We formulate a leave-one-PAI-out evaluation protocol, and show that even the best algorithms in the closed-set evaluations exhibit catastrophic failures on multiple attack types in the open-set scenario. This includes algorithms performing well in the most recent LivDet-Iris 2020 competition, which may come from the fact that the LivDet-Iris protocol emphasizes sequestered images rather than unseen attack types. Second, we evaluate the accuracy of five open-source iris presentation attack algorithms available today, one of which is newly-proposed in this paper, and build an ensemble method that beats the winner of the LivDet-Iris 2020 by a substantial margin. This paper demonstrates that closed-set iris PAD, when all PAIs are known during training, is a solved problem, with multiple algorithms showing very high accuracy, while open-set iris PAD, when evaluated correctly, is far from being solved. The newly-created dataset, new open-source algorithms, and evaluation protocol, made publicly available with the journal version of this paper, provide the experimental artifacts that researchers can use to measure progress on this important problem. ",
    "url": "https://arxiv.org/abs/2208.10564",
    "authors": [
      "Aidan Boyd",
      "Jeremy Speth",
      "Lucas Parzianello",
      "Kevin Bowyer",
      "Adam Czajka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10576",
    "title": "Different Spectral Representations in Optimized Artificial Neural  Networks and Brains",
    "abstract": "Recent studies suggest that artificial neural networks (ANNs) that match the spectral properties of the mammalian visual cortex -- namely, the $\\sim 1/n$ eigenspectrum of the covariance matrix of neural activities -- achieve higher object recognition performance and robustness to adversarial attacks than those that do not. To our knowledge, however, no previous work systematically explored how modifying the ANN's spectral properties affects performance. To fill this gap, we performed a systematic search over spectral regularizers, forcing the ANN's eigenspectrum to follow $1/n^\\alpha$ power laws with different exponents $\\alpha$. We found that larger powers (around 2--3) lead to better validation accuracy and more robustness to adversarial attacks on dense networks. This surprising finding applied to both shallow and deep networks and it overturns the notion that the brain-like spectrum (corresponding to $\\alpha \\sim 1$) always optimizes ANN performance and/or robustness. For convolutional networks, the best $\\alpha$ values depend on the task complexity and evaluation metric: lower $\\alpha$ values optimized validation accuracy and robustness to adversarial attack for networks performing a simple object recognition task (categorizing MNIST images of handwritten digits); for a more complex task (categorizing CIFAR-10 natural images), we found that lower $\\alpha$ values optimized validation accuracy whereas higher $\\alpha$ values optimized adversarial robustness. These results have two main implications. First, they cast doubt on the notion that brain-like spectral properties ($\\alpha \\sim 1$) \\emph{always} optimize ANN performance. Second, they demonstrate the potential for fine-tuned spectral regularizers to optimize a chosen design metric, i.e., accuracy and/or robustness. ",
    "url": "https://arxiv.org/abs/2208.10576",
    "authors": [
      "Richard C. Gerum",
      "Cassidy Pirlot",
      "Alona Fyshe",
      "Joel Zylberberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2208.10583",
    "title": "Improving Sample Efficiency in Evolutionary RL Using Off-Policy Ranking",
    "abstract": "Evolution Strategy (ES) is a powerful black-box optimization technique based on the idea of natural evolution. In each of its iterations, a key step entails ranking candidate solutions based on some fitness score. For an ES method in Reinforcement Learning (RL), this ranking step requires evaluating multiple policies. This is presently done via on-policy approaches: each policy's score is estimated by interacting several times with the environment using that policy. This leads to a lot of wasteful interactions since, once the ranking is done, only the data associated with the top-ranked policies is used for subsequent learning. To improve sample efficiency, we propose a novel off-policy alternative for ranking, based on a local approximation for the fitness function. We demonstrate our idea in the context of a state-of-the-art ES method called the Augmented Random Search (ARS). Simulations in MuJoCo tasks show that, compared to the original ARS, our off-policy variant has similar running times for reaching reward thresholds but needs only around 70% as much data. It also outperforms the recent Trust Region ES. We believe our ideas should be extendable to other ES methods as well. ",
    "url": "https://arxiv.org/abs/2208.10583",
    "authors": [
      "Eshwar S R",
      "Shishir Kolathaya",
      "Gugan Thoppe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.10590",
    "title": "A Survey and Framework of Cooperative Perception: From Heterogeneous  Singleton to Hierarchical Cooperation",
    "abstract": "Perceiving the environment is one of the most fundamental keys to enabling Cooperative Driving Automation (CDA), which is regarded as the revolutionary solution to addressing the safety, mobility, and sustainability issues of contemporary transportation systems. Although an unprecedented evolution is now happening in the area of computer vision for object perception, state-of-the-art perception methods are still struggling with sophisticated real-world traffic environments due to the inevitably physical occlusion and limited receptive field of single-vehicle systems. Based on multiple spatially separated perception nodes, Cooperative Perception (CP) is born to unlock the bottleneck of perception for driving automation. In this paper, we comprehensively review and analyze the research progress on CP and, to the best of our knowledge, this is the first time to propose a unified CP framework. Architectures and taxonomy of CP systems based on different types of sensors are reviewed to show a high-level description of the workflow and different structures for CP systems. Node structure, sensor modality, and fusion schemes are reviewed and analyzed with comprehensive literature to provide detailed explanations of specific methods. A Hierarchical CP framework is proposed, followed by a review of existing Datasets and Simulators to sketch an overall landscape of CP. Discussion highlights the current opportunities, open challenges, and anticipated future trends. ",
    "url": "https://arxiv.org/abs/2208.10590",
    "authors": [
      "Zhengwei Bai",
      "Guoyuan Wu",
      "Matthew J. Barth",
      "Yongkang Liu",
      "Emrah Akin Sisbot",
      "Kentaro Oguchi",
      "Zhitong Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10607",
    "title": "Individual Tree Detection in Large-Scale Urban Environments using  High-Resolution Multispectral Imagery",
    "abstract": "We introduce a novel deep learning method for detection of individual trees in urban environments using high-resolution multispectral aerial imagery. We use a convolutional neural network to regress a confidence map indicating the locations of individual trees, which are localized using a peak finding algorithm. Our method provides complete spatial coverage by detecting trees in both public and private spaces, and can scale to very large areas. In our study area spanning five cities in Southern California, we achieved an F-score of 0.735 and an RMSE of 2.157 m. We used our method to produce a map of all trees in the urban forest of California, indicating the potential for our method to support future urban forestry studies at unprecedented scales. ",
    "url": "https://arxiv.org/abs/2208.10607",
    "authors": [
      "Jonathan Ventura",
      "Milo Honsberger",
      "Cameron Gonsalves",
      "Julian Rice",
      "Camille Pawlak",
      "Natalie L.R. Love",
      "Skyler Han",
      "Viet Nguyen",
      "Keilana Sugano",
      "Jacqueline Doremus",
      "G. Andrew Fricker",
      "Jenn Yost",
      "Matt Ritter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10608",
    "title": "RIBAC: Towards Robust and Imperceptible Backdoor Attack against Compact  DNN",
    "abstract": "Recently backdoor attack has become an emerging threat to the security of deep neural network (DNN) models. To date, most of the existing studies focus on backdoor attack against the uncompressed model; while the vulnerability of compressed DNNs, which are widely used in the practical applications, is little exploited yet. In this paper, we propose to study and develop Robust and Imperceptible Backdoor Attack against Compact DNN models (RIBAC). By performing systematic analysis and exploration on the important design knobs, we propose a framework that can learn the proper trigger patterns, model parameters and pruning masks in an efficient way. Thereby achieving high trigger stealthiness, high attack success rate and high model efficiency simultaneously. Extensive evaluations across different datasets, including the test against the state-of-the-art defense mechanisms, demonstrate the high robustness, stealthiness and model efficiency of RIBAC. Code is available at https://github.com/huyvnphan/ECCV2022-RIBAC ",
    "url": "https://arxiv.org/abs/2208.10608",
    "authors": [
      "Huy Phan",
      "Cong Shi",
      "Yi Xie",
      "Tianfang Zhang",
      "Zhuohang Li",
      "Tianming Zhao",
      "Jian Liu",
      "Yan Wang",
      "Yingying Chen",
      "Bo Yuan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10609",
    "title": "Global Concept-Based Interpretability for Graph Neural Networks via  Neuron Analysis",
    "abstract": "Graph neural networks (GNNs) are highly effective on a variety of graph-related tasks; however, they lack interpretability and transparency. Current explainability approaches are typically local and treat GNNs as black-boxes. They do not look inside the model, inhibiting human trust in the model and explanations. Motivated by the ability of neurons to detect high-level semantic concepts in vision models, we perform a novel analysis on the behaviour of individual GNN neurons to answer questions about GNN interpretability, and propose new metrics for evaluating the interpretability of GNN neurons. We propose a novel approach for producing global explanations for GNNs using neuron-level concepts to enable practitioners to have a high-level view of the model. Specifically, (i) to the best of our knowledge, this is the first work which shows that GNN neurons act as concept detectors and have strong alignment with concepts formulated as logical compositions of node degree and neighbourhood properties; (ii) we quantitatively assess the importance of detected concepts, and identify a trade-off between training duration and neuron-level interpretability; (iii) we demonstrate that our global explainability approach has advantages over the current state-of-the-art -- we can disentangle the explanation into individual interpretable concepts backed by logical descriptions, which reduces potential for bias and improves user-friendliness. ",
    "url": "https://arxiv.org/abs/2208.10609",
    "authors": [
      "Han Xuanyuan",
      "Pietro Barbiero",
      "Dobrik Georgiev",
      "Lucie Charlotte Magister",
      "Pietro Li\u00f3"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.10625",
    "title": "Evaluation of group fairness measures in student performance prediction  problems",
    "abstract": "Predicting students' academic performance is one of the key tasks of educational data mining (EDM). Traditionally, the high forecasting quality of such models was deemed critical. More recently, the issues of fairness and discrimination w.r.t. protected attributes, such as gender or race, have gained attention. Although there are several fairness-aware learning approaches in EDM, a comparative evaluation of these measures is still missing. In this paper, we evaluate different group fairness measures for student performance prediction problems on various educational datasets and fairness-aware learning models. Our study shows that the choice of the fairness measure is important, likewise for the choice of the grade threshold. ",
    "url": "https://arxiv.org/abs/2208.10625",
    "authors": [
      "Tai Le Quy",
      "Thi Huyen Nguyen",
      "Gunnar Friege",
      "Eirini Ntoutsi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2208.10627",
    "title": "Targeted Advertising on Social Networks Using Online Variational Tensor  Regression",
    "abstract": "This paper is concerned with online targeted advertising on social networks. The main technical task we address is to estimate the activation probability for user pairs, which quantifies the influence one user may have on another towards purchasing decisions. This is a challenging task because one marketing episode typically involves a multitude of marketing campaigns/strategies of different products for highly diverse customers. In this paper, we propose what we believe is the first tensor-based contextual bandit framework for online targeted advertising. The proposed framework is designed to accommodate any number of feature vectors in the form of multi-mode tensor, thereby enabling to capture the heterogeneity that may exist over user preferences, products, and campaign strategies in a unified manner. To handle inter-dependency of tensor modes, we introduce an online variational algorithm with a mean-field approximation. We empirically confirm that the proposed TensorUCB algorithm achieves a significant improvement in influence maximization tasks over the benchmarks, which is attributable to its capability of capturing the user-product heterogeneity. ",
    "url": "https://arxiv.org/abs/2208.10627",
    "authors": [
      "Tsuyoshi Id\u00e9",
      "Keerthiram Murugesan",
      "Djallel Bouneffouf",
      "Naoki Abe"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.10630",
    "title": "Fault Current-Constrained Optimal Power Flow on Unbalanced Distribution  Networks",
    "abstract": "With the proliferation of distributed generation into distribution networks, the need to consider fault currents in the dispatch problem becomes increasingly relevant. This paper introduces a method for adding fault current constraints into optimal power flow in order to reduce fault currents while minimizing generation cost. The optimal power flow problem is formulated as a single optimization problem with sub-networks representing the faults of interest. Having a single optimization problem allows the decision variables to be coupled across the optimal power flow and the fault current studies without having to iterate over possible solutions. The proposed method is applicable to unbalanced distribution networks, including those with transformers that introduce phase-shifts. ",
    "url": "https://arxiv.org/abs/2208.10630",
    "authors": [
      "Jose E. Tabarez",
      "Arthur K. Barnes",
      "Adam Mate",
      "Russell W. Bent"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.10637",
    "title": "Low Complexity Classification Approach for Faster-than-Nyquist (FTN)  Signalling Detection",
    "abstract": "Faster-than-Nyquist (FTN) signaling can improve the spectral efficiency (SE); however, at the expense of high computational complexity to remove the introduced intersymbol interference (ISI). Motivated by the recent success of ML in physical layer (PHY) problems, in this paper we investigate the use of ML in reducing the detection complexity of FTN signaling. In particular, we view the FTN signaling detection problem as a classification task, where the received signal is considered as an unlabeled class sample that belongs to a set of all possible classes samples. If we use an off-shelf classifier, then the set of all possible classes samples belongs to an $N$-dimensional space, where $N$ is the transmission block length, which has a huge computational complexity. We propose a low-complexity classifier (LCC) that exploits the ISI structure of FTN signaling to perform the classification task in $N_p \\ll N$-dimension space. The proposed LCC consists of two stages: 1) offline pre-classification that constructs the labeled classes samples in the $N_p$-dimensional space and 2) online classification where the detection of the received samples occurs. The proposed LCC is extended to produce soft-outputs as well. Simulation results show the effectiveness of the proposed LCC in balancing performance and complexity. ",
    "url": "https://arxiv.org/abs/2208.10637",
    "authors": [
      "Sina Abbasi",
      "Ebrahim Bedeer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2208.10641",
    "title": "Fake News Identification using Machine Learning Algorithms Based on  Graph Features",
    "abstract": "The spread of fake news has long been a social issue and the necessity of identifying it has become evident since its dangers are well recognized. In addition to causing uneasiness among the public, it has even more devastating consequences. For instance, it might lead to death during pandemics due to unverified medical instructions. This study aims to build a model for identifying fake news using graphs and machine learning algorithms. Instead of scanning the news content or user information, the research explicitly focuses on the spreading network, which shows the interconnection among people, and graph features such as the Eigenvector centrality, Jaccard Coefficient, and the shortest path. Fourteen features are extracted from graphs and tested in thirteen machine learning models. After analyzing these features and comparing the test result of machine learning models, the results reflect that propensity and centrality contribute highly to the classification. The best performing models reach 0.9913 and 0.9987 separately from datasets Twitter15 and Twitter16 using a modified tree classifier and Support Vector Classifier. This model can effectively predict fake news, prevent potential negative social impact caused by fake news, and provide a new perspective on graph feature selection for machine learning models. ",
    "url": "https://arxiv.org/abs/2208.10641",
    "authors": [
      "Yuxuan Tian"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2208.10642",
    "title": "Anatomy-Aware Contrastive Representation Learning for Fetal Ultrasound",
    "abstract": "Self-supervised contrastive representation learning offers the advantage of learning meaningful visual representations from unlabeled medical datasets for transfer learning. However, applying current contrastive learning approaches to medical data without considering its domain-specific anatomical characteristics may lead to visual representations that are inconsistent in appearance and semantics. In this paper, we propose to improve visual representations of medical images via anatomy-aware contrastive learning (AWCL), which incorporates anatomy information to augment the positive/negative pair sampling in a contrastive learning manner. The proposed approach is demonstrated for automated fetal ultrasound imaging tasks, enabling the positive pairs from the same or different ultrasound scans that are anatomically similar to be pulled together and thus improving the representation learning. We empirically investigate the effect of inclusion of anatomy information with coarse- and fine-grained granularity, for contrastive learning and find that learning with fine-grained anatomy information which preserves intra-class difference is more effective than its counterpart. We also analyze the impact of anatomy ratio on our AWCL framework and find that using more distinct but anatomically similar samples to compose positive pairs results in better quality representations. Experiments on a large-scale fetal ultrasound dataset demonstrate that our approach is effective for learning representations that transfer well to three clinical downstream tasks, and achieves superior performance compared to ImageNet supervised and the current state-of-the-art contrastive learning methods. In particular, AWCL outperforms ImageNet supervised method by 13.8% and state-of-the-art contrastive-based method by 7.1% on a cross-domain segmentation task. ",
    "url": "https://arxiv.org/abs/2208.10642",
    "authors": [
      "Zeyu Fu",
      "Jianbo Jiao",
      "Robail Yasrab",
      "Lior Drukker",
      "Aris T. Papageorghiou",
      "J. Alison Noble"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2208.10644",
    "title": "Machine Learning-Enabled Cyber Attack Prediction and Mitigation for EV  Charging Stations",
    "abstract": "Safe and reliable electric vehicle charging stations (EVCSs) have become imperative in an intelligent transportation infrastructure. Over the years, there has been a rapid increase in the deployment of EVCSs to address the upsurging charging demands. However, advances in information and communication technologies (ICT) have rendered this cyber-physical system (CPS) vulnerable to suffering cyber threats, thereby destabilizing the charging ecosystem and even the entire electric grid infrastructure. This paper develops an advanced cybersecurity framework, where STRIDE threat modeling is used to identify potential vulnerabilities in an EVCS. Further, the weighted attack defense tree approach is employed to create multiple attack scenarios, followed by developing Hidden Markov Model (HMM) and Partially Observable Monte-Carlo Planning (POMCP) algorithms for modeling the security attacks. Also, potential mitigation strategies are suggested for the identified threats. ",
    "url": "https://arxiv.org/abs/2208.10644",
    "authors": [
      "Mansi Girdhar",
      "Junho Hong",
      "Yongsik Yoo",
      "Tai-Jin Song"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.10646",
    "title": "The Robustness of Tether Friction in Non-idealized Terrains",
    "abstract": "Reduced traction limits the ability of mobile robotic systems to resist or apply large external loads, such as tugging a massive payload. One simple and versatile solution is to wrap a tether around naturally occurring objects to leverage the capstan effect and create exponentially-amplified holding forces. Experiments show that an idealized capstan model explains force amplification experienced on common irregular outdoor objects - trees, rocks, posts. Robust to variable environmental conditions, this exponential amplification method can harness single or multiple capstan objects, either in series or in parallel with a team of robots. This adaptability allows for a range of potential configurations especially useful for when objects cannot be fully encircled or gripped. These principles are demonstrated with mobile platforms to (1) control the lowering and arrest of a payload, (2) to achieve planar control of a payload, and (3) to act as an anchor point for a more massive platform to winch towards. We show the simple addition of a tether, wrapped around shallow stones in sand, amplifies holding force of a low-traction platform by up to 774x. ",
    "url": "https://arxiv.org/abs/2208.10646",
    "authors": [
      "Justin J. Page",
      "Laura K. Treers",
      "Steven Jens Jorgensen",
      "Ronald S. Fearing",
      "Hannah S. Stuart"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2208.10651",
    "title": "ECU Identification using Neural Network Classification and  Hyperparameter Tuning",
    "abstract": "Intrusion detection for Controller Area Network (CAN) protocol requires modern methods in order to compete with other electrical architectures. Fingerprint Intrusion Detection Systems (IDS) provide a promising new approach to solve this problem. By characterizing network traffic from known ECUs, hazardous messages can be discriminated. In this article, a modified version of Fingerprint IDS is employed utilizing both step response and spectral characterization of network traffic via neural network training. With the addition of feature set reduction and hyperparameter tuning, this method accomplishes a 99.4% detection rate of trusted ECU traffic. ",
    "url": "https://arxiv.org/abs/2208.10651",
    "authors": [
      "Kunaal Verma",
      "Mansi Girdhar",
      "Azeem Hafeez",
      "Selim S. Awad"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.10652",
    "title": "Learning Visibility for Robust Dense Human Body Estimation",
    "abstract": "Estimating 3D human pose and shape from 2D images is a crucial yet challenging task. While prior methods with model-based representations can perform reasonably well on whole-body images, they often fail when parts of the body are occluded or outside the frame. Moreover, these results usually do not faithfully capture the human silhouettes due to their limited representation power of deformable models (e.g., representing only the naked body). An alternative approach is to estimate dense vertices of a predefined template body in the image space. Such representations are effective in localizing vertices within an image but cannot handle out-of-frame body parts. In this work, we learn dense human body estimation that is robust to partial observations. We explicitly model the visibility of human joints and vertices in the x, y, and z axes separately. The visibility in x and y axes help distinguishing out-of-frame cases, and the visibility in depth axis corresponds to occlusions (either self-occlusions or occlusions by other objects). We obtain pseudo ground-truths of visibility labels from dense UV correspondences and train a neural network to predict visibility along with 3D coordinates. We show that visibility can serve as 1) an additional signal to resolve depth ordering ambiguities of self-occluded vertices and 2) a regularization term when fitting a human body model to the predictions. Extensive experiments on multiple 3D human datasets demonstrate that visibility modeling significantly improves the accuracy of human body estimation, especially for partial-body cases. Our project page with code is at: https://github.com/chhankyao/visdb. ",
    "url": "https://arxiv.org/abs/2208.10652",
    "authors": [
      "Chun-Han Yao",
      "Jimei Yang",
      "Duygu Ceylan",
      "Yi Zhou",
      "Yang Zhou",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10658",
    "title": "Survey on Evolutionary Deep Learning: Principles, Algorithms,  Applications and Open Issues",
    "abstract": "Over recent years, there has been a rapid development of deep learning (DL) in both industry and academia fields. However, finding the optimal hyperparameters of a DL model often needs high computational cost and human expertise. To mitigate the above issue, evolutionary computation (EC) as a powerful heuristic search approach has shown significant merits in the automated design of DL models, so-called evolutionary deep learning (EDL). This paper aims to analyze EDL from the perspective of automated machine learning (AutoML). Specifically, we firstly illuminate EDL from machine learning and EC and regard EDL as an optimization problem. According to the DL pipeline, we systematically introduce EDL methods ranging from feature engineering, model generation, to model deployment with a new taxonomy (i.e., what and how to evolve/optimize), and focus on the discussions of solution representation and search paradigm in handling the optimization problem by EC. Finally, key applications, open issues and potentially promising lines of future research are suggested. This survey has reviewed recent developments of EDL and offers insightful guidelines for the development of EDL. ",
    "url": "https://arxiv.org/abs/2208.10658",
    "authors": [
      "Nan Li",
      "Lianbo Ma",
      "Guo Yu",
      "Bing Xue",
      "Mengjie Zhang",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2208.10659",
    "title": "Fall Detection from Audios with Audio Transformers",
    "abstract": "Fall detection for the elderly is a well-researched problem with several proposed solutions, including wearable and non-wearable techniques. While the existing techniques have excellent detection rates, their adoption by the target population is lacking due to the need for wearing devices and user privacy concerns. Our paper provides a novel, non-wearable, non-intrusive, and scalable solution for fall detection, deployed on an autonomous mobile robot equipped with a microphone. The proposed method uses ambient sound input recorded in people's homes. We specifically target the bathroom environment as it is highly prone to falls and where existing techniques cannot be deployed without jeopardizing user privacy. The present work develops a solution based on a Transformer architecture that takes noisy sound input from bathrooms and classifies it into fall/no-fall class with an accuracy of 0.8673. Further, the proposed approach is extendable to other indoor environments, besides bathrooms and is suitable for deploying in elderly homes, hospitals, and rehabilitation facilities without requiring the user to wear any device or be constantly \"watched\" by the sensors. ",
    "url": "https://arxiv.org/abs/2208.10659",
    "authors": [
      "Prabhjot Kaur",
      "Qifan Wang",
      "Weisong Shi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2208.10676",
    "title": "Entropy Enhanced Multi-Agent Coordination Based on Hierarchical Graph  Learning for Continuous Action Space",
    "abstract": "In most existing studies on large-scale multi-agent coordination, the control methods aim to learn discrete policies for agents with finite choices. They rarely consider selecting actions directly from continuous action spaces to provide more accurate control, which makes them unsuitable for more complex tasks. To solve the control issue due to large-scale multi-agent systems with continuous action spaces, we propose a novel MARL coordination control method that derives stable continuous policies. By optimizing policies with maximum entropy learning, agents improve their exploration in execution and acquire an excellent performance after training. We also employ hierarchical graph attention networks (HGAT) and gated recurrent units (GRU) to improve the scalability and transferability of our method. The experiments show that our method consistently outperforms all baselines in large-scale multi-agent cooperative reconnaissance tasks. ",
    "url": "https://arxiv.org/abs/2208.10676",
    "authors": [
      "Yining Chen",
      "Ke Wang",
      "Guanghua Song",
      "Xiaohong Jiang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2208.10677",
    "title": "A Review of Machine Learning-based Failure Management in Optical  Networks",
    "abstract": "Failure management plays a significant role in optical networks. It ensures secure operation, mitigates potential risks, and executes proactive protection. Machine learning (ML) is considered to be an extremely powerful technique for performing comprehensive data analysis and complex network management and is widely utilized for failure management in optical networks to revolutionize the conventional manual methods. In this study, the background of failure management is introduced, where typical failure tasks, physical objects, ML algorithms, data source, and extracted information are illustrated in detail. An overview of the applications of ML in failure management is provided in terms of alarm analysis, failure prediction, failure detection, failure localization, and failure identification. Finally, the future directions on ML for failure management are discussed from the perspective of data, model, task, and emerging techniques. ",
    "url": "https://arxiv.org/abs/2208.10677",
    "authors": [
      "Danshi Wang",
      "Chunyu Zhang",
      "Wenbin Chen",
      "Hui Yang",
      "Min Zhang",
      "Alan Pak Tao Lau"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2208.10682",
    "title": "CAPER: Coarsen, Align, Project, Refine - A General Multilevel Framework  for Network Alignment",
    "abstract": "Network alignment, or the task of finding corresponding nodes in different networks, is an important problem formulation in many application domains. We propose CAPER, a multilevel alignment framework that Coarsens the input graphs, Aligns the coarsened graphs, Projects the alignment solution to finer levels and Refines the alignment solution. We show that CAPER can improve upon many different existing network alignment algorithms by enforcing alignment consistency across multiple graph resolutions: nodes matched at finer levels should also be matched at coarser levels. CAPER also accelerates the use of slower network alignment methods, at the modest cost of linear-time coarsening and refinement steps, by allowing them to be run on smaller coarsened versions of the input graphs. Experiments show that CAPER can improve upon diverse network alignment methods by an average of 33% in accuracy and/or an order of magnitude faster in runtime. ",
    "url": "https://arxiv.org/abs/2208.10682",
    "authors": [
      "Jing Zhu",
      "Danai Koutra",
      "Mark Heimann"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.10684",
    "title": "K-MHaS: A Multi-label Hate Speech Detection Dataset in Korean Online  News Comment",
    "abstract": "Online Hate speech detection has become important with the growth of digital devices, but resources in languages other than English are extremely limited. We introduce K-MHaS, a new multi-label dataset for hate speech detection that effectively handles Korean language patterns. The dataset consists of 109k utterances from news comments and provides multi-label classification from 1 to 4 labels, and handling subjectivity and intersectionality. We evaluate strong baselines on K-MHaS. KR-BERT with sub-character tokenizer outperforms, recognising decomposed characters in each hate speech class. ",
    "url": "https://arxiv.org/abs/2208.10684",
    "authors": [
      "Jean Lee",
      "Taejun Lim",
      "Heejun Lee",
      "Bogeun Jo",
      "Yangsok Kim",
      "Heegeun Yoon",
      "Soyeon Caren Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.10688",
    "title": "Hierarchical Perceptual Noise Injection for Social Media Fingerprint  Privacy Protection",
    "abstract": "Billions of people are sharing their daily life images on social media every day. However, their biometric information (e.g., fingerprint) could be easily stolen from these images. The threat of fingerprint leakage from social media raises a strong desire for anonymizing shared images while maintaining image qualities, since fingerprints act as a lifelong individual biometric password. To guard the fingerprint leakage, adversarial attack emerges as a solution by adding imperceptible perturbations on images. However, existing works are either weak in black-box transferability or appear unnatural. Motivated by visual perception hierarchy (i.e., high-level perception exploits model-shared semantics that transfer well across models while low-level perception extracts primitive stimulus and will cause high visual sensitivities given suspicious stimulus), we propose FingerSafe, a hierarchical perceptual protective noise injection framework to address the mentioned problems. For black-box transferability, we inject protective noises on fingerprint orientation field to perturb the model-shared high-level semantics (i.e., fingerprint ridges). Considering visual naturalness, we suppress the low-level local contrast stimulus by regularizing the response of Lateral Geniculate Nucleus. Our FingerSafe is the first to provide feasible fingerprint protection in both digital (up to 94.12%) and realistic scenarios (Twitter and Facebook, up to 68.75%). Our code can be found at https://github.com/nlsde-safety-team/FingerSafe. ",
    "url": "https://arxiv.org/abs/2208.10688",
    "authors": [
      "Simin Li",
      "Huangxinxin Xu",
      "Jiakai Wang",
      "Aishan Liu",
      "Fazhi He",
      "Xianglong Liu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.10694",
    "title": "Spiral Contrastive Learning: An Efficient 3D Representation Learning  Method for Unannotated CT Lesions",
    "abstract": "Computed tomography (CT) samples with pathological annotations are difficult to obtain. As a result, the computer-aided diagnosis (CAD) algorithms are trained on small datasets (e.g., LIDC-IDRI with 1,018 samples), limiting their accuracies and reliability. In the past five years, several works have tailored for unsupervised representations of CT lesions via two-dimensional (2D) and three-dimensional (3D) self-supervised learning (SSL) algorithms. The 2D algorithms have difficulty capturing 3D information, and existing 3D algorithms are computationally heavy. Light-weight 3D SSL remains the boundary to explore. In this paper, we propose the spiral contrastive learning (SCL), which yields 3D representations in a computationally efficient manner. SCL first transforms 3D lesions to the 2D plane using an information-preserving spiral transformation, and then learn transformation-invariant features using 2D contrastive learning. For the augmentation, we consider natural image augmentations and medical image augmentations. We evaluate SCL by training a classification head upon the embedding layer. Experimental results show that SCL achieves state-of-the-art accuracy on LIDC-IDRI (89.72%), LNDb (82.09%) and TianChi (90.16%) for unsupervised representation learning. With 10% annotated data for fine-tune, the performance of SCL is comparable to that of supervised learning algorithms (85.75% vs. 85.03% on LIDC-IDRI, 78.20% vs. 73.44% on LNDb and 87.85% vs. 83.34% on TianChi, respectively). Meanwhile, SCL reduces the computational effort by 66.98% compared to other 3D SSL algorithms, demonstrating the efficiency of the proposed method in unsupervised pre-training. ",
    "url": "https://arxiv.org/abs/2208.10694",
    "authors": [
      "Penghua Zhai",
      "Enwei Zhu",
      "Baolian Qi",
      "Xin Wei",
      "Jinpeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10695",
    "title": "Structure Regularized Attentive Network for Automatic Femoral Head  Necrosis Diagnosis and Localization",
    "abstract": "In recent years, several works have adopted the convolutional neural network (CNN) to diagnose the avascular necrosis of the femoral head (AVNFH) based on X-ray images or magnetic resonance imaging (MRI). However, due to the tissue overlap, X-ray images are difficult to provide fine-grained features for early diagnosis. MRI, on the other hand, has a long imaging time, is more expensive, making it impractical in mass screening. Computed tomography (CT) shows layer-wise tissues, is faster to image, and is less costly than MRI. However, to our knowledge, there is no work on CT-based automated diagnosis of AVNFH. In this work, we collected and labeled a large-scale dataset for AVNFH ranking. In addition, existing end-to-end CNNs only yields the classification result and are difficult to provide more information for doctors in diagnosis. To address this issue, we propose the structure regularized attentive network (SRANet), which is able to highlight the necrotic regions during classification based on patch attention. SRANet extracts features in chunks of images, obtains weight via the attention mechanism to aggregate the features, and constrains them by a structural regularizer with prior knowledge to improve the generalization. SRANet was evaluated on our AVNFH-CT dataset. Experimental results show that SRANet is superior to CNNs for AVNFH classification, moreover, it can localize lesions and provide more information to assist doctors in diagnosis. Our codes are made public at https://github.com/tomas-lilingfeng/SRANet. ",
    "url": "https://arxiv.org/abs/2208.10695",
    "authors": [
      "Lingfeng Li",
      "Huaiwei Cong",
      "Gangming Zhao",
      "Junran Peng",
      "Zheng Zhang",
      "Jinpeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10704",
    "title": "Delay Minimization for Hybrid BAC-NOMA Offloading in MEC Networks",
    "abstract": "This paper studies the offloading service improvement of multi-access edge computing (MEC) based on backscatter communication (BackCom) assisted non-orthogonal multiple access (BAC-NOMA). A hybrid BAC-NOMA protocol is proposed, where the uplink users backscatter their tasks by leveraging the downlink signal, and then the remaining data is transmitted through uplink NOMA. In particular, a resource allocation problem is formulated to minimize the offloading delay of uplink users. The non-convex problem is transformed into a convex problem, and an iterative algorithm is developed accordingly. Simulation results show that the proposed protocol outperforms the benchmark in terms of offloading delay. ",
    "url": "https://arxiv.org/abs/2208.10704",
    "authors": [
      "Haodong Li",
      "Kaidi Wang",
      "Zhiguo Ding"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2208.10711",
    "title": "A Constrained Deformable Convolutional Network for Efficient Single  Image Dynamic Scene Blind Deblurring with Spatially-Variant Motion Blur  Kernels Estimation",
    "abstract": "Most existing deep-learning-based single image dynamic scene blind deblurring (SIDSBD) methods usually design deep networks to directly remove the spatially-variant motion blurs from one inputted motion blurred image, without blur kernels estimation. In this paper, inspired by the Projective Motion Path Blur (PMPB) model and deformable convolution, we propose a novel constrained deformable convolutional network (CDCN) for efficient single image dynamic scene blind deblurring, which simultaneously achieves accurate spatially-variant motion blur kernels estimation and the high-quality image restoration from only one observed motion blurred image. In our proposed CDCN, we first construct a novel multi-scale multi-level multi-input multi-output (MSML-MIMO) encoder-decoder architecture for more powerful features extraction ability. Second, different from the DLVBD methods that use multiple consecutive frames, a novel constrained deformable convolution reblurring (CDCR) strategy is proposed, in which the deformable convolution is first applied to blurred features of the inputted single motion blurred image for learning the sampling points of motion blur kernel of each pixel, which is similar to the estimation of the motion density function of the camera shake in the PMPB model, and then a novel PMPB-based reblurring loss function is proposed to constrain the learned sampling points convergence, which can make the learned sampling points match with the relative motion trajectory of each pixel better and promote the accuracy of the spatially-variant motion blur kernels estimation. ",
    "url": "https://arxiv.org/abs/2208.10711",
    "authors": [
      "Shu Tang",
      "Yang Wu",
      "Hongxing Qin",
      "Xianzhong Xie",
      "Shuli Yang",
      "Jing Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10723",
    "title": "Security and Reliability Analysis of Satellite-Terrestrial Multi-Relay  Networks with Imperfect CSI",
    "abstract": "This work investigates the security and reliability analysis for a novel satellite-terrestrial (SatTer) network. Specifically, a satellite attempts to transmit confidential information to a ground user (GU) via the support of multiple relay nodes in the presence of an eavesdropper that tries to overhear the information. A friendly jammer is deployed to improve the secure transmission between the satellite and the relays. Furthermore, satellite-to-relay generalized Rician fading channels and imperfect channel state information (CSI) are deployed to examine a general system model. In this context, the closed-formed expressions for the outage probability (OP) and intercept probability (IP) are derived corresponding to an amplify-and-forward (AF)-based relaying scheme, which is challenging and has not been studied before. Finally, the exactness of the mathematical analyses is validated through Monte Carlo simulations. Furthermore, the effects of various key parameters (e.g., channel estimation errors, satellite's transmit power, relay's transmit power, number of relays, and fading severity parameter) are examined. ",
    "url": "https://arxiv.org/abs/2208.10723",
    "authors": [
      "Tan N. Nguyen",
      "Dinh-Hieu Tran",
      "Trinh Van Chien",
      "Van-Duc Phan",
      "Miroslav Voznak",
      "Symeon Chatzinotas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2208.10725",
    "title": "DRL-based Distributed Resource Allocation for Edge Computing in  Cell-Free Massive MIMO Network",
    "abstract": "In this paper, with the aim of addressing the stringent computing and quality-of-service (QoS) requirements of recently introduced advanced multimedia services, we consider a cell-free massive MIMO-enabled mobile edge network. In particular, benefited from the reliable cell-free links to offload intensive computation to the edge server, resource-constrained end-users can augment on-board (local) processing with edge computing. To this end, we formulate a joint communication and computing resource allocation (JCCRA) problem to minimize the total energy consumption of the users, while meeting the respective user-specific deadlines. To tackle the problem, we propose a fully distributed solution approach based on cooperative multi-agent reinforcement learning framework, wherein each user is implemented as a learning agent to make joint resource allocation relying on local information only. The simulation results demonstrate that the performance of the proposed distributed approach outperforms the heuristic baselines, converging to a centralized target benchmark, without resorting to large overhead. Moreover, we showed that the proposed algorithm has performed significantly better in cell-free system as compared with the cellular MEC systems, e.g., a small cell-based MEC system. ",
    "url": "https://arxiv.org/abs/2208.10725",
    "authors": [
      "Fitsum Debebe Tilahun",
      "Ameha Tsegaye Abebe",
      "Chung G. Kang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2208.10727",
    "title": "Homomorphically Full Oriented Graphs",
    "abstract": "Homomorphically full graphs are those for which every homomorphic image is isomorphic to a subgraph. We extend the definition of homomorphically full to oriented graphs in two different ways. For the first of these, we show that homomorphically full oriented graphs arise as quasi-transitive orientations of homomorphically full graphs. This in turn yields an efficient recognition and construction algorithms for these homomorphically full oriented graphs. For the second one, we show that the related recognition problem is GI-hard, and that the problem of deciding if a graph admits a homomorphically full orientation is NP-complete. In doing so we show the problem of deciding if two given oriented cliques are isomorphic is GI-complete. ",
    "url": "https://arxiv.org/abs/2208.10727",
    "authors": [
      "Thomas Bellitto",
      "Christopher Duffy",
      "Gary MacGillivray"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2208.10739",
    "title": "Quality-Constant Per-Shot Encoding by Two-Pass Learning-based Rate  Factor Prediction",
    "abstract": "Providing quality-constant streams can simultaneously guarantee user experience and prevent wasting bit-rate. In this paper, we propose a novel deep learning based two-pass encoder parameter prediction framework to decide rate factor (RF), with which encoder can output streams with constant quality. For each one-shot segment in a video, the proposed method firstly extracts spatial, temporal and pre-coding features by an ultra fast pre-process. Based on these features, a RF parameter is predicted by a deep neural network. Video encoder uses the RF to compress segment as the first encoding pass. Then VMAF quality of the first pass encoding is measured. If the quality doesn't meet target, a second pass RF prediction and encoding will be performed. With the help of first pass predicted RF and corresponding actual quality as feedback, the second pass prediction will be highly accurate. Experiments show the proposed method requires only 1.55 times encoding complexity on average, meanwhile the accuracy, that the compressed video's actual VMAF is within $\\pm1$ around the target VMAF, reaches 98.88%. ",
    "url": "https://arxiv.org/abs/2208.10739",
    "authors": [
      "Chunlei Cai",
      "Yi Wang",
      "Xiaobo Li",
      "Tianxiao Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2208.10741",
    "title": "Hierarchically Decomposed Graph Convolutional Networks for  Skeleton-Based Action Recognition",
    "abstract": "Graph convolutional networks (GCNs) are the most commonly used method for skeleton-based action recognition and have achieved remarkable performance. Generating adjacency matrices with semantically meaningful edges is particularly important for this task, but extracting such edges is challenging problem. To solve this, we propose a hierarchically decomposed graph convolutional network (HD-GCN) architecture with a novel hierarchically decomposed graph (HD-Graph). The proposed HD-GCN effectively decomposes every joint node into several sets to extract major adjacent and distant edges, and uses them to construct an HD-Graph containing those edges in the same semantic spaces of a human skeleton. In addition, we introduce an attention-guided hierarchy aggregation (A-HA) module to highlight the dominant hierarchical edge sets of the HD-Graph. Furthermore, we apply a new two-stream-three-graph ensemble method, which uses only joint and bone stream without any motion stream. The proposed model is evaluated and achieves state-of-the-art performance on three large, popular datasets: NTU-RGB+D 60, NTU-RGB+D 120, and Northwestern-UCLA. Finally, we demonstrate the effectiveness of our model with various comparative experiments. ",
    "url": "https://arxiv.org/abs/2208.10741",
    "authors": [
      "Jungho Lee",
      "Minhyeok Lee",
      "Dogyoon Lee",
      "Sangyoon Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10751",
    "title": "Predicting Query-Item Relationship using Adversarial Training and Robust  Modeling Techniques",
    "abstract": "We present an effective way to predict search query-item relationship. We combine pre-trained transformer and LSTM models, and increase model robustness using adversarial training, exponential moving average, multi-sampled dropout, and diversity based ensemble, to tackle an extremely difficult problem of predicting against queries not seen before. All of our strategies focus on increasing robustness of deep learning models and are applicable in any task where deep learning models are used. Applying our strategies, we achieved 10th place in KDD Cup 2022 Product Substitution Classification task. ",
    "url": "https://arxiv.org/abs/2208.10751",
    "authors": [
      "Min Seok Kim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.10753",
    "title": "Neural PCA for Flow-Based Representation Learning",
    "abstract": "Of particular interest is to discover useful representations solely from observations in an unsupervised generative manner. However, the question of whether existing normalizing flows provide effective representations for downstream tasks remains mostly unanswered despite their strong ability for sample generation and density estimation. This paper investigates this problem for such a family of generative models that admits exact invertibility. We propose Neural Principal Component Analysis (Neural-PCA) that operates in full dimensionality while capturing principal components in \\emph{descending} order. Without exploiting any label information, the principal components recovered store the most informative elements in their \\emph{leading} dimensions and leave the negligible in the \\emph{trailing} ones, allowing for clear performance improvements of $5\\%$-$10\\%$ in downstream tasks. Such improvements are empirically found consistent irrespective of the number of latent trailing dimensions dropped. Our work suggests that necessary inductive bias be introduced into generative modelling when representation quality is of interest. ",
    "url": "https://arxiv.org/abs/2208.10753",
    "authors": [
      "Shen Li",
      "Bryan Hooi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.10759",
    "title": "Survival Mixture Density Networks",
    "abstract": "Survival analysis, the art of time-to-event modeling, plays an important role in clinical treatment decisions. Recently, continuous time models built from neural ODEs have been proposed for survival analysis. However, the training of neural ODEs is slow due to the high computational complexity of neural ODE solvers. Here, we propose an efficient alternative for flexible continuous time models, called Survival Mixture Density Networks (Survival MDNs). Survival MDN applies an invertible positive function to the output of Mixture Density Networks (MDNs). While MDNs produce flexible real-valued distributions, the invertible positive function maps the model into the time-domain while preserving a tractable density. Using four datasets, we show that Survival MDN performs better than, or similarly to continuous and discrete time baselines on concordance, integrated Brier score and integrated binomial log-likelihood. Meanwhile, Survival MDNs are also faster than ODE-based models and circumvent binning issues in discrete models. ",
    "url": "https://arxiv.org/abs/2208.10759",
    "authors": [
      "Xintian Han",
      "Mark Goldstein",
      "Rajesh Ranganath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2208.10761",
    "title": "CRCNet: Few-shot Segmentation with Cross-Reference and Region-Global  Conditional Networks",
    "abstract": "Few-shot segmentation aims to learn a segmentation model that can be generalized to novel classes with only a few training images. In this paper, we propose a Cross-Reference and Local-Global Conditional Networks (CRCNet) for few-shot segmentation. Unlike previous works that only predict the query image's mask, our proposed model concurrently makes predictions for both the support image and the query image. Our network can better find the co-occurrent objects in the two images with a cross-reference mechanism, thus helping the few-shot segmentation task. To further improve feature comparison, we develop a local-global conditional module to capture both global and local relations. We also develop a mask refinement module to refine the prediction of the foreground regions recurrently. Experiments on the PASCAL VOC 2012, MS COCO, and FSS-1000 datasets show that our network achieves new state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2208.10761",
    "authors": [
      "Weide Liu",
      "Chi Zhang",
      "Guosheng Lin",
      "Fayao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10766",
    "title": "We Are in This Together: Quantifying Community Subjective Wellbeing and  Resilience",
    "abstract": "The COVID-19 pandemic disrupted everyone's life across the world. In this work, we characterize the subjective wellbeing patterns of 112 cities across the United States during the pandemic prior to vaccine availability, as exhibited in subreddits corresponding to the cities. We quantify subjective wellbeing using positive and negative affect. We then measure the pandemic's impact by comparing a community's observed wellbeing with its expected wellbeing, as forecasted by time series models derived from prior to the pandemic.We show that general community traits reflected in language can be predictive of community resilience. We predict how the pandemic would impact the wellbeing of each community based on linguistic and interaction features from normal times \\textit{before} the pandemic. We find that communities with interaction characteristics corresponding to more closely connected users and higher engagement were less likely to be significantly impacted. Notably, we find that communities that talked more about social ties normally experienced in-person, such as friends, family, and affiliations, were actually more likely to be impacted. Additionally, we use the same features to also predict how quickly each community would recover after the initial onset of the pandemic. We similarly find that communities that talked more about family, affiliations, and identifying as part of a group had a slower recovery. ",
    "url": "https://arxiv.org/abs/2208.10766",
    "authors": [
      "MeiXing Dong",
      "Ruixuan Sun",
      "Laura Biester",
      "Rada Mihalcea"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2208.10769",
    "title": "PIFu for the Real World: A Self-supervised Framework to Reconstruct  Dressed Human from Single-view Images",
    "abstract": "It is very challenging to accurately reconstruct sophisticated human geometry caused by various poses and garments from a single image. Recently, works based on pixel-aligned implicit function (PIFu) have made a big step and achieved state-of-the-art fidelity on image-based 3D human digitization. However, the training of PIFu relies heavily on expensive and limited 3D ground truth data (i.e. synthetic data), thus hindering its generalization to more diverse real world images. In this work, we propose an end-to-end self-supervised network named SelfPIFu to utilize abundant and diverse in-the-wild images, resulting in largely improved reconstructions when tested on unconstrained in-the-wild images. At the core of SelfPIFu is the depth-guided volume-/surface-aware signed distance fields (SDF) learning, which enables self-supervised learning of a PIFu without access to GT mesh. The whole framework consists of a normal estimator, a depth estimator, and a SDF-based PIFu and better utilizes extra depth GT during training. Extensive experiments demonstrate the effectiveness of our self-supervised framework and the superiority of using depth as input. On synthetic data, our Intersection-Over-Union (IoU) achieves to 93.5%, 18% higher compared with PIFuHD. For in-the-wild images, we conduct user studies on the reconstructed results, the selection rate of our results is over 68% compared with other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2208.10769",
    "authors": [
      "Zhangyang Xiong",
      "Dong Du",
      "Yushuang Wu",
      "Jingqi Dong",
      "Di Kang",
      "Linchao Bao",
      "Xiaoguang Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10773",
    "title": "Adversarial Vulnerability of Temporal Feature Networks for Object  Detection",
    "abstract": "Taking into account information across the temporal domain helps to improve environment perception in autonomous driving. However, it has not been studied so far whether temporally fused neural networks are vulnerable to deliberately generated perturbations, i.e. adversarial attacks, or whether temporal history is an inherent defense against them. In this work, we study whether temporal feature networks for object detection are vulnerable to universal adversarial attacks. We evaluate attacks of two types: imperceptible noise for the whole image and locally-bound adversarial patch. In both cases, perturbations are generated in a white-box manner using PGD. Our experiments confirm, that attacking even a portion of a temporal input suffices to fool the network. We visually assess generated perturbations to gain insights into the functioning of attacks. To enhance the robustness, we apply adversarial training using 5-PGD. Our experiments on KITTI and nuScenes datasets demonstrate, that a model robustified via K-PGD is able to withstand the studied attacks while keeping the mAP-based performance comparable to that of an unattacked model. ",
    "url": "https://arxiv.org/abs/2208.10773",
    "authors": [
      "Svetlana Pavlitskaya",
      "Nikolai Polley",
      "Michael Weber",
      "J.Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.10781",
    "title": "Object Detection in Aerial Images with Uncertainty-Aware Graph Network",
    "abstract": "In this work, we propose a novel uncertainty-aware object detection framework with a structured-graph, where nodes and edges are denoted by objects and their spatial-semantic similarities, respectively. Specifically, we aim to consider relationships among objects for effectively contextualizing them. To achieve this, we first detect objects and then measure their semantic and spatial distances to construct an object graph, which is then represented by a graph neural network (GNN) for refining visual CNN features for objects. However, refining CNN features and detection results of every object are inefficient and may not be necessary, as that include correct predictions with low uncertainties. Therefore, we propose to handle uncertain objects by not only transferring the representation from certain objects (sources) to uncertain objects (targets) over the directed graph, but also improving CNN features only on objects regarded as uncertain with their representational outputs from the GNN. Furthermore, we calculate a training loss by giving larger weights on uncertain objects, to concentrate on improving uncertain object predictions while maintaining high performances on certain objects. We refer to our model as Uncertainty-Aware Graph network for object DETection (UAGDet). We then experimentally validate ours on the challenging large-scale aerial image dataset, namely DOTA, that consists of lots of objects with small to large sizes in an image, on which ours improves the performance of the existing object detection network. ",
    "url": "https://arxiv.org/abs/2208.10781",
    "authors": [
      "Jongha Kim",
      "Jinheon Baek",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10787",
    "title": "Semantic Driven Energy based Out-of-Distribution Detection",
    "abstract": "Detecting Out-of-Distribution (OOD) samples in real world visual applications like classification or object detection has become a necessary precondition in today's deployment of Deep Learning systems. Many techniques have been proposed, of which Energy based OOD methods have proved to be promising and achieved impressive performance. We propose semantic driven energy based method, which is an end-to-end trainable system and easy to optimize. We distinguish in-distribution samples from out-distribution samples with an energy score coupled with a representation score. We achieve it by minimizing the energy for in-distribution samples and simultaneously learn respective class representations that are closer and maximizing energy for out-distribution samples and pushing their representation further out from known class representation. Moreover, we propose a novel loss function which we call Cluster Focal Loss(CFL) that proved to be simple yet very effective in learning better class wise cluster center representations. We find that, our novel approach enhances outlier detection and achieve state-of-the-art as an energy-based model on common benchmarks. On CIFAR-10 and CIFAR-100 trained WideResNet, our model significantly reduces the relative average False Positive Rate(at True Positive Rate of 95%) by 67.2% and 57.4% respectively, compared to the existing energy based approaches. Further, we extend our framework for object detection and achieve improved performance. ",
    "url": "https://arxiv.org/abs/2208.10787",
    "authors": [
      "Abhishek Joshi",
      "Sathish Chalasani",
      "Kiran Nanjunda Iyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10808",
    "title": "Towards Accurate Facial Landmark Detection via Cascaded Transformers",
    "abstract": "Accurate facial landmarks are essential prerequisites for many tasks related to human faces. In this paper, an accurate facial landmark detector is proposed based on cascaded transformers. We formulate facial landmark detection as a coordinate regression task such that the model can be trained end-to-end. With self-attention in transformers, our model can inherently exploit the structured relationships between landmarks, which would benefit landmark detection under challenging conditions such as large pose and occlusion. During cascaded refinement, our model is able to extract the most relevant image features around the target landmark for coordinate prediction, based on deformable attention mechanism, thus bringing more accurate alignment. In addition, we propose a novel decoder that refines image features and landmark positions simultaneously. With few parameter increasing, the detection performance improves further. Our model achieves new state-of-the-art performance on several standard facial landmark detection benchmarks, and shows good generalization ability in cross-dataset evaluation. ",
    "url": "https://arxiv.org/abs/2208.10808",
    "authors": [
      "Hui Li",
      "Zidong Guo",
      "Seon-Min Rhee",
      "Seungju Han",
      "Jae-Joon Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10820",
    "title": "\"Am I Private and If So, how Many?\" - Communicating Privacy Guarantees  of Differential Privacy with Risk Communication Formats",
    "abstract": "Decisions about sharing personal information are not trivial, since there are many legitimate and important purposes for such data collection, but often the collected data can reveal sensitive information about individuals. Privacy-preserving technologies, such as differential privacy (DP), can be employed to protect the privacy of individuals and, furthermore, provide mathematically sound guarantees on the maximum privacy risk. However, they can only support informed privacy decisions, if individuals understand the provided privacy guarantees. This article proposes a novel approach for communicating privacy guarantees to support individuals in their privacy decisions when sharing data. For this, we adopt risk communication formats from the medical domain in conjunction with a model for privacy guarantees of DP to create quantitative privacy risk notifications. We conducted a crowd-sourced study with 343 participants to evaluate how well our notifications conveyed the privacy risk information and how confident participants were about their own understanding of the privacy risk. Our findings suggest that these new notifications can communicate the objective information similarly well to currently used qualitative notifications, but left individuals less confident in their understanding. We also discovered that several of our notifications and the currently used qualitative notification disadvantage individuals with low numeracy: these individuals appear overconfident compared to their actual understanding of the associated privacy risks and are, therefore, less likely to seek the needed additional information before an informed decision. The promising results allow for multiple directions in future research, for example, adding visual aids or tailoring privacy risk communication to characteristics of the individuals. ",
    "url": "https://arxiv.org/abs/2208.10820",
    "authors": [
      "Daniel Franzen",
      "Saskia Nu\u00f1ez von Voigt",
      "Peter S\u00f6rries",
      "Florian Tschorsch",
      "Claudia M\u00fcller-Birn"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.10822",
    "title": "Multimodal Across Domains Gaze Target Detection",
    "abstract": "This paper addresses the gaze target detection problem in single images captured from the third-person perspective. We present a multimodal deep architecture to infer where a person in a scene is looking. This spatial model is trained on the head images of the person-of- interest, scene and depth maps representing rich context information. Our model, unlike several prior art, do not require supervision of the gaze angles, do not rely on head orientation information and/or location of the eyes of person-of-interest. Extensive experiments demonstrate the stronger performance of our method on multiple benchmark datasets. We also investigated several variations of our method by altering joint-learning of multimodal data. Some variations outperform a few prior art as well. First time in this paper, we inspect domain adaption for gaze target detection, and we empower our multimodal network to effectively handle the domain gap across datasets. The code of the proposed method is available at https://github.com/francescotonini/multimodal-across-domains-gaze-target-detection. ",
    "url": "https://arxiv.org/abs/2208.10822",
    "authors": [
      "Francesco Tonini",
      "Cigdem Beyan",
      "Elisa Ricci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2208.10833",
    "title": "LogLG: Weakly Supervised Log Anomaly Detection via Log-Event Graph  Construction",
    "abstract": "Fully supervised log anomaly detection methods require a lot of labeled data to achieve promising performance. Thus, how to alleviate the heavy burden of annotating massive unlabeled log data has received much attention. Recently, many semi-supervised log anomaly detection methods have been proposed to reduce the annotation costs with the help of templates parsed from labeled normal data. However, these methods usually consider each keyword independently, which disregard the correlation among keywords in log events and the contextual relationships among log sequences. In this paper, we propose a novel weakly supervised log anomaly detection framework, named LogLG, to explore the semantic connections among keywords from sequences. Specifically, we design an iterative process, where the keywords of unlabeled logs are first extracted to construct a log-event graph in each iteration. Then, we build a subgraph annotator to alter the purpose of generating pseudo labels for unlabeled log sequences into annotating corresponding log-subgraphs. To ameliorate the annotation quality, we adopt a self-supervised task to pre-train a subgraph annotator. After that, a log anomaly detection model is trained with the pseudo labels generated by the subgraph annotator. Conditioned on the classification results, we re-extract the keywords from the classified log sequences and update the log-event graph for the next iteration. Experiments on five benchmarks validate the effectiveness of LogLG for detecting anomalies on unlabeled log data, and demonstrate that LogLG, as the state-of-the-art weakly supervised method, achieves significant improvements compared to existing semi-supervised methods. ",
    "url": "https://arxiv.org/abs/2208.10833",
    "authors": [
      "Yuhui Guo",
      "Hongcheng Guo",
      "Renjie Chen",
      "Jian Yang",
      "Jiaheng Liu",
      "Zhoujun Li",
      "Tieqiao Zheng",
      "Liangfan Zheng",
      "Weichao Hou",
      "Bo Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.10839",
    "title": "In-Air Imaging Sonar Sensor Network with Real-Time Processing Using GPUs",
    "abstract": "For autonomous navigation and robotic applications, sensing the environment correctly is crucial. Many sensing modalities for this purpose exist. In recent years, one such modality that is being used is in-air imaging sonar. It is ideal in complex environments with rough conditions such as dust or fog. However, like with most sensing modalities, to sense the full environment around the mobile platform, multiple such sensors are needed to capture the full 360-degree range. Currently the processing algorithms used to create this data are insufficient to do so for multiple sensors at a reasonably fast update rate. Furthermore, a flexible and robust framework is needed to easily implement multiple imaging sonar sensors into any setup and serve multiple application types for the data. In this paper we present a sensor network framework designed for this novel sensing modality. Furthermore, an implementation of the processing algorithm on a Graphics Processing Unit is proposed to potentially decrease the computing time to allow for real-time processing of one or more imaging sonar sensors at a sufficiently high update rate. ",
    "url": "https://arxiv.org/abs/2208.10839",
    "authors": [
      "Wouter Jansen",
      "Dennis Laurijssen",
      "Robin Kerstens",
      "Walter Daems",
      "Jan Steckel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Networking and Internet Architecture (cs.NI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2208.10841",
    "title": "Network Slicing for eMBB, URLLC, and mMTC: An Uplink Rate-Splitting  Multiple Access Approach",
    "abstract": "There are three generic services in 5G: enhanced mobile broadband (eMBB), ultra-reliable low-latency communications (URLLC), and massive machine-type communications (mMTC). To guarantee the performance of heterogeneous services, network slicing is proposed to allocate resources to different services. Network slicing is typically done in an orthogonal multiple access (OMA) fashion, which means different services are allocated non-interfering resources. However, as the number of users grows, OMA-based slicing is not always optimal, and a non-orthogonal scheme may achieve a better performance. This work aims to analyse the performances of different slicing schemes in uplink, and a promising scheme based on rate-splitting multiple access (RSMA) is studied. RSMA can provide a more flexible decoding order and theoretically has the largest achievable rate region than OMA and non-orthogonal multiple access (NOMA) without time-sharing. Hence, RSMA has the potential to increase the rate of users requiring different services. In addition, it is not necessary to decode the two split streams of one user successively, so RSMA lets suitable users split messages and designs an appropriate decoding order depending on the service requirements. This work shows that for network slicing RSMA can outperform NOMA counterpart, and obtain significant gains over OMA in some region. ",
    "url": "https://arxiv.org/abs/2208.10841",
    "authors": [
      "Yuanwen Liu",
      "Bruno Clerckx",
      "Petar Popovski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2208.10858",
    "title": "VILT: Video Instructions Linking for Complex Tasks",
    "abstract": "This work addresses challenges in developing conversational assistants that support rich multimodal video interactions to accomplish real-world tasks interactively. We introduce the task of automatically linking instructional videos to task steps as \"Video Instructions Linking for Complex Tasks\" (VILT). Specifically, we focus on the domain of cooking and empowering users to cook meals interactively with a video-enabled Alexa skill. We create a reusable benchmark with 61 queries from recipe tasks and curate a collection of 2,133 instructional \"How-To\" cooking videos. Studying VILT with state-of-the-art retrieval methods, we find that dense retrieval with ANCE is the most effective, achieving an NDCG@3 of 0.566 and P@1 of 0.644. We also conduct a user study that measures the effect of incorporating videos in a real-world task setting, where 10 participants perform several cooking tasks with varying multimodal experimental conditions using a state-of-the-art Alexa TaskBot system. The users interacting with manually linked videos said they learned something new 64% of the time, which is a 9% increase compared to the automatically linked videos (55%), indicating that linked video relevance is important for task learning. ",
    "url": "https://arxiv.org/abs/2208.10858",
    "authors": [
      "Sophie Fischer",
      "Carlos Gemmell",
      "Iain Mackie",
      "Jeffrey Dalton"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2208.10867",
    "title": "A Quinary Coding and Matrix Structure-based Channel Hopping Algorithm  for Blind Rendezvous in Cognitive Radio Networks",
    "abstract": "The multi-channel blind rendezvous problem in distributed cognitive radio networks (DCRNs) refers to how users in the network can hop to the same channel at the same time slot without any prior knowledge (i.e., each user is unaware of other users' information). The channel hopping (CH) technique is a typical solution to this blind rendezvous problem. In this paper, we propose a quinary coding and matrix structure-based CH algorithm called QCMS-CH. The QCMS-CH algorithm can guarantee the rendezvous of users using only one cognitive radio in the scenario of the asynchronous clock (i.e., arbitrary time drift between the users), heterogeneous channels (i.e., the available channel sets of users are distinct), and symmetric role (i.e., all users play a same role). The QCMS-CH algorithm first represents a randomly selected channel (denoted by R) as a fixed-length quaternary number. Then it encodes the quaternary number into a quinary bootstrapping sequence according to a carefully designed quaternary-quinary coding table with the prefix \"R00\". Finally, it builds a CH matrix column by column according to the bootstrapping sequence and six different types of elaborately generated subsequences. The user can access the CH matrix row by row and accordingly perform its channel hopping to attempt to rendezvous with other users. We prove the correctness of QCMS-CH and derive an upper bound on its Maximum Time-to-Rendezvous (MTTR). Simulation results show that the QCMS-CH algorithm outperforms the state-of-the-art in terms of the MTTR and the Expected Time-to-Rendezvous (ETTR). ",
    "url": "https://arxiv.org/abs/2208.10867",
    "authors": [
      "Qinglin Liu",
      "Zhiyong Lin",
      "Zongheng Wei",
      "Jianfeng Wen",
      "Congming Yi",
      "Hai Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2208.10868",
    "title": "AppGNN: Approximation-Aware Functional Reverse Engineering using Graph  Neural Networks",
    "abstract": "The globalization of the Integrated Circuit (IC) market is attracting an ever-growing number of partners, while remarkably lengthening the supply chain. Thereby, security concerns, such as those imposed by functional Reverse Engineering (RE), have become quintessential. RE leads to disclosure of confidential information to competitors, potentially enabling the theft of intellectual property. Traditional functional RE methods analyze a given gate-level netlist through employing pattern matching towards reconstructing the underlying basic blocks, and hence, reverse engineer the circuit's function. In this work, we are the first to demonstrate that applying Approximate Computing (AxC) principles to circuits significantly improves the resiliency against RE. This is attributed to the increased complexity in the underlying pattern-matching process. The resiliency remains effective even for Graph Neural Networks (GNNs) that are presently one of the most powerful state-of-the-art techniques in functional RE. Using AxC, we demonstrate a substantial reduction in GNN average classification accuracy-- from 98% to a mere 53%. To surmount the challenges introduced by AxC in RE, we propose the highly promising AppGNN platform, which enables GNNs (still being trained on exact circuits) to: (i) perform accurate classifications, and (ii) reverse engineer the circuit functionality, notwithstanding the applied approximation technique. AppGNN accomplishes this by implementing a novel graph-based node sampling approach that mimics generic approximation methodologies, requiring zero knowledge of the targeted approximation type. We perform an extensive evaluation and show that, using our method, we can improve the classification accuracy from 53% to 81% when classifying approximate adder circuits that have been generated using evolutionary algorithms, which our method is oblivious of. ",
    "url": "https://arxiv.org/abs/2208.10868",
    "authors": [
      "Tim Bucher",
      "Lilas Alrahis",
      "Guilherme Paim",
      "Sergio Bampi",
      "Ozgur Sinanoglu",
      "Hussam Amrouch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.10878",
    "title": "Transferability Ranking of Adversarial Examples",
    "abstract": "Adversarial examples can be used to maliciously and covertly change a model's prediction. It is known that an adversarial example designed for one model can transfer to other models as well. This poses a major threat because it means that attackers can target systems in a blackbox manner. In the domain of transferability, researchers have proposed ways to make attacks more transferable and to make models more robust to transferred examples. However, to the best of our knowledge, there are no works which propose a means for ranking the transferability of an adversarial example in the perspective of a blackbox attacker. This is an important task because an attacker is likely to use only a select set of examples, and therefore will want to select the samples which are most likely to transfer. In this paper we suggest a method for ranking the transferability of adversarial examples without access to the victim's model. To accomplish this, we define and estimate the expected transferability of a sample given limited information about the victim. We also explore practical scenarios: where the adversary can select the best sample to attack and where the adversary must use a specific sample but can choose different perturbations. Through our experiments, we found that our ranking method can increase an attacker's success rate by up to 80% compared to the baseline (random selection without ranking). ",
    "url": "https://arxiv.org/abs/2208.10878",
    "authors": [
      "Mosh Levy",
      "Yuval Elovici",
      "Yisroel Mirsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.10888",
    "title": "Joint Privacy Enhancement and Quantization in Federated Learning",
    "abstract": "Federated learning (FL) is an emerging paradigm for training machine learning models using possibly private data available at edge devices. The distributed operation of FL gives rise to challenges that are not encountered in centralized machine learning, including the need to preserve the privacy of the local datasets, and the communication load due to the repeated exchange of updated models. These challenges are often tackled individually via techniques that induce some distortion on the updated models, e.g., local differential privacy (LDP) mechanisms and lossy compression. In this work we propose a method coined joint privacy enhancement and quantization (JoPEQ), which jointly implements lossy compression and privacy enhancement in FL settings. In particular, JoPEQ utilizes vector quantization based on random lattice, a universal compression technique whose byproduct distortion is statistically equivalent to additive noise. This distortion is leveraged to enhance privacy by augmenting the model updates with dedicated multivariate privacy preserving noise. We show that JoPEQ simultaneously quantizes data according to a required bit-rate while holding a desired privacy level, without notably affecting the utility of the learned model. This is shown via analytical LDP guarantees, distortion and convergence bounds derivation, and numerical studies. Finally, we empirically assert that JoPEQ demolishes common attacks known to exploit privacy leakage. ",
    "url": "https://arxiv.org/abs/2208.10888",
    "authors": [
      "Natalie Lang",
      "Elad Sofer",
      "Tomer Shaked",
      "Nir Shlezinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.10895",
    "title": "A Comprehensive Study of Real-Time Object Detection Networks Across  Multiple Domains: A Survey",
    "abstract": "Deep neural network based object detectors are continuously evolving and are used in a multitude of applications, each having its own set of requirements. While safety-critical applications need high accuracy and reliability, low-latency tasks need resource and energy-efficient networks. Real-time detectors, which are a necessity in high-impact real-world applications, are continuously proposed, but they overemphasize the improvements in accuracy and speed while other capabilities such as versatility, robustness, resource and energy efficiency are omitted. A reference benchmark for existing networks does not exist, nor does a standard evaluation guideline for designing new networks, which results in ambiguous and inconsistent comparisons. We, thus, conduct a comprehensive study on multiple real-time detectors (anchor-, keypoint-, and transformer-based) on a wide range of datasets and report results on an extensive set of metrics. We also study the impact of variables such as image size, anchor dimensions, confidence thresholds, and architecture layers on the overall performance. We analyze the robustness of detection networks against distribution shifts, natural corruptions, and adversarial attacks. Also, we provide a calibration analysis to gauge the reliability of the predictions. Finally, to highlight the real-world impact, we conduct two unique case studies, on autonomous driving and healthcare applications. To further gauge the capability of networks in critical real-time applications, we report the performance after deploying the detection networks on edge devices. Our extensive empirical study can act as a guideline for the industrial community to make an informed choice on the existing networks. We also hope to inspire the research community towards a new direction in the design and evaluation of networks that focuses on a bigger and holistic overview for a far-reaching impact. ",
    "url": "https://arxiv.org/abs/2208.10895",
    "authors": [
      "Elahe Arani",
      "Shruthi Gowda",
      "Ratnajit Mukherjee",
      "Omar Magdy",
      "Senthilkumar Kathiresan",
      "Bahram Zonooz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.10916",
    "title": "Application of Causal Inference to Analytical Customer Relationship  Management in Banking and Insurance",
    "abstract": "Of late, in order to have better acceptability among various domain, researchers have argued that machine intelligence algorithms must be able to provide explanations that humans can understand causally. This aspect, also known as causability, achieves a specific level of human-level explainability. A specific class of algorithms known as counterfactuals may be able to provide causability. In statistics, causality has been studied and applied for many years, but not in great detail in artificial intelligence (AI). In a first-of-its-kind study, we employed the principles of causal inference to provide explainability for solving the analytical customer relationship management (ACRM) problems. In the context of banking and insurance, current research on interpretability tries to address causality-related questions like why did this model make such decisions, and was the model's choice influenced by a particular factor? We propose a solution in the form of an intervention, wherein the effect of changing the distribution of features of ACRM datasets is studied on the target feature. Subsequently, a set of counterfactuals is also obtained that may be furnished to any customer who demands an explanation of the decision taken by the bank/insurance company. Except for the credit card churn prediction dataset, good quality counterfactuals were generated for the loan default, insurance fraud detection, and credit card fraud detection datasets, where changes in no more than three features are observed. ",
    "url": "https://arxiv.org/abs/2208.10916",
    "authors": [
      "Satyam Kumar",
      "Vadlamani Ravi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2208.10917",
    "title": "Graph Embeddings via Tensor Products and Approximately Orthonormal Codes",
    "abstract": "We introduce a method for embedding graphs as vectors in a structure-preserving manner. In this paper, we showcase its rich representational capacity and give some theoretical properties of our method. In particular, our procedure falls under the bind-and-sum approach, and we show that our binding operation -- the tensor product -- is the most general binding operation that respects the principle of superposition. Similarly, we show that the spherical code achieves optimal compression. We then establish some precise results characterizing the performance our method as well as some experimental results showcasing how it can accurately perform various graph operations even when the number of edges is quite large. Finally, we conclude with establishing a link to adjacency matrices, showing that our method is, in some sense, a generalization of adjacency matrices with applications towards large sparse graphs. ",
    "url": "https://arxiv.org/abs/2208.10917",
    "authors": [
      "Frank Qiu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2208.10925",
    "title": "Vox-Surf: Voxel-based Implicit Surface Representation",
    "abstract": "Virtual content creation and interaction play an important role in modern 3D applications such as AR and VR. Recovering detailed 3D models from real scenes can significantly expand the scope of its applications and has been studied for decades in the computer vision and computer graphics community. We propose Vox-Surf, a voxel-based implicit surface representation. Our Vox-Surf divides the space into finite bounded voxels. Each voxel stores geometry and appearance information in its corner vertices. Vox-Surf is suitable for almost any scenario thanks to sparsity inherited from voxel representation and can be easily trained from multiple view images. We leverage the progressive training procedure to extract important voxels gradually for further optimization so that only valid voxels are preserved, which greatly reduces the number of sampling points and increases rendering speed.The fine voxels can also be considered as the bounding volume for collision detection.The experiments show that Vox-Surf representation can learn delicate surface details and accurate color with less memory and faster rendering speed than other methods.We also show that Vox-Surf can be more practical in scene editing and AR applications. ",
    "url": "https://arxiv.org/abs/2208.10925",
    "authors": [
      "Hai Li",
      "Xingrui Yang",
      "Hongjia Zhai",
      "Yuqian Liu",
      "Hujun Bao",
      "Guofeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10928",
    "title": "Meta Avatar Robot Cafe: Linking Physical and Virtual Cybernetic Avatars  to Provide Physical Augmentation for People with Disabilities",
    "abstract": "Meta avatar robot cafe is a cafe that fuses cyberspace and physical space to create new encounters with people. We create a place where people with disabilities who have difficulty going out can freely switch between their physical bodies and virtual bodies, and communicate their presence and warmth to each other. ",
    "url": "https://arxiv.org/abs/2208.10928",
    "authors": [
      "Yoichi Yamazaki",
      "Tsukuto Yamada",
      "Hiroki Nomura",
      "Nobuaki Hosoda",
      "Ryoma Kawamura",
      "Kazuaki Takeuchi",
      "Hiroaki Kato",
      "Ryuma Niiyama",
      "Kentaro Yoshifuji"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2208.10930",
    "title": "FS-BAN: Born-Again Networks for Domain Generalization Few-Shot  Classification",
    "abstract": "Conventional Few-shot classification (FSC) aims to recognize samples from novel classes given limited labeled data. Recently, domain generalization FSC (DG-FSC) has been proposed with the goal to recognize novel class samples from unseen domains. DG-FSC poses considerable challenges to many models due to the domain shift between base classes (used in training) and novel classes (encountered in evaluation). In this work, we make two novel contributions to tackle DG-FSC. Our first contribution is to propose Born-Again Network (BAN) episodic training and comprehensively investigate its effectiveness for DG-FSC. As a specific form of knowledge distillation, BAN has been shown to achieve improved generalization in conventional supervised classification with a closed-set setup. This improved generalization motivates us to study BAN for DG-FSC, and we show that BAN is promising to address the domain shift encountered in DG-FSC. Building on the encouraging finding, our second (major) contribution is to propose few-shot BAN, FS-BAN, a novel BAN approach for DG-FSC. Our proposed FS-BAN includes novel multi-task learning objectives: Mutual Regularization, Mismatched Teacher and Meta-Control Temperature, each of these is specifically designed to overcome central and unique challenges in DG-FSC, namely overfitting and domain discrepancy. We analyze different design choices of these techniques. We conduct comprehensive quantitative and qualitative analysis and evaluation using six datasets and three baseline models. The results suggest that our proposed FS-BAN consistently improves the generalization performance of baseline models and achieves state-of-the-art accuracy for DG-FSC. ",
    "url": "https://arxiv.org/abs/2208.10930",
    "authors": [
      "Yunqing Zhao",
      "Ngai-Man Cheung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10940",
    "title": "Evaluating Out-of-Distribution Detectors Through Adversarial Generation  of Outliers",
    "abstract": "A reliable evaluation method is essential for building a robust out-of-distribution (OOD) detector. Current robustness evaluation protocols for OOD detectors rely on injecting perturbations to outlier data. However, the perturbations are unlikely to occur naturally or not relevant to the content of data, providing a limited assessment of robustness. In this paper, we propose Evaluation-via-Generation for OOD detectors (EvG), a new protocol for investigating the robustness of OOD detectors under more realistic modes of variation in outliers. EvG utilizes a generative model to synthesize plausible outliers, and employs MCMC sampling to find outliers misclassified as in-distribution with the highest confidence by a detector. We perform a comprehensive benchmark comparison of the performance of state-of-the-art OOD detectors using EvG, uncovering previously overlooked weaknesses. ",
    "url": "https://arxiv.org/abs/2208.10940",
    "authors": [
      "Sangwoong Yoon",
      "Jinwon Choi",
      "Yonghyeon Lee",
      "Yung-Kyun Noh",
      "Frank Chongwoo Park"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.10943",
    "title": "Challenges and Complexities in Machine Learning based Credit Card Fraud  Detection",
    "abstract": "Credit cards play an exploding role in modern economies. Its popularity and ubiquity have created a fertile ground for fraud, assisted by the cross boarder reach and instantaneous confirmation. While transactions are growing, the fraud percentages are also on the rise as well as the true cost of a dollar fraud. Volume of transactions, uniqueness of frauds and ingenuity of the fraudster are main challenges in detecting frauds. The advent of machine learning, artificial intelligence and big data has opened up new tools in the fight against frauds. Given past transactions, a machine learning algorithm has the ability to 'learn' infinitely complex characteristics in order to identify frauds in real-time, surpassing the best human investigators. However, the developments in fraud detection algorithms has been challenging and slow due the massively unbalanced nature of fraud data, absence of benchmarks and standard evaluation metrics to identify better performing classifiers, lack of sharing and disclosure of research findings and the difficulties in getting access to confidential transaction data for research. This work investigates the properties of typical massively imbalanced fraud data sets, their availability, suitability for research use while exploring the widely varying nature of fraud distributions. Furthermore, we show how human annotation errors compound with machine classification errors. We also carry out experiments to determine the effect of PCA obfuscation (as a means of disseminating sensitive transaction data for research and machine learning) on algorithmic performance of classifiers and show that while PCA does not significantly degrade performance, care should be taken to use the appropriate principle component size (dimensions) to avoid overfitting. ",
    "url": "https://arxiv.org/abs/2208.10943",
    "authors": [
      "Gayan K. Kulatilleke"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.10950",
    "title": "Deep Structural Causal Shape Models",
    "abstract": "Causal reasoning provides a language to ask important interventional and counterfactual questions beyond purely statistical association. In medical imaging, for example, we may want to study the causal effect of genetic, environmental, or lifestyle factors on the normal and pathological variation of anatomical phenotypes. However, while anatomical shape models of 3D surface meshes, extracted from automated image segmentation, can be reliably constructed, there is a lack of computational tooling to enable causal reasoning about morphological variations. To tackle this problem, we propose deep structural causal shape models (CSMs), which utilise high-quality mesh generation techniques, from geometric deep learning, within the expressive framework of deep structural causal models. CSMs enable subject-specific prognoses through counterfactual mesh generation (\"How would this patient's brain structure change if they were ten years older?\"), which is in contrast to most current works on purely population-level statistical shape modelling. We demonstrate the capabilities of CSMs at all levels of Pearl's causal hierarchy through a number of qualitative and quantitative experiments leveraging a large dataset of 3D brain structures. ",
    "url": "https://arxiv.org/abs/2208.10950",
    "authors": [
      "Rajat Rasal",
      "Daniel C. Castro",
      "Nick Pawlowski",
      "Ben Glocker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.10970",
    "title": "Doc-GCN: Heterogeneous Graph Convolutional Networks for Document Layout  Analysis",
    "abstract": "Recognizing the layout of unstructured digital documents is crucial when parsing the documents into the structured, machine-readable format for downstream applications. Recent studies in Document Layout Analysis usually rely on computer vision models to understand documents while ignoring other information, such as context information or relation of document components, which are vital to capture. Our Doc-GCN presents an effective way to harmonize and integrate heterogeneous aspects for Document Layout Analysis. We first construct graphs to explicitly describe four main aspects, including syntactic, semantic, density, and appearance/visual information. Then, we apply graph convolutional networks for representing each aspect of information and use pooling to integrate them. Finally, we aggregate each aspect and feed them into 2-layer MLPs for document layout component classification. Our Doc-GCN achieves new state-of-the-art results in three widely used DLA datasets. ",
    "url": "https://arxiv.org/abs/2208.10970",
    "authors": [
      "Siwen Luo",
      "Yihao Ding",
      "Siqu Long",
      "Soyeon Caren Han",
      "Josiah Poon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.10973",
    "title": "Robust DNN Watermarking via Fixed Embedding Weights with Optimized  Distribution",
    "abstract": "Watermarking has been proposed as a way to protect the Intellectual Property Rights (IPR) of Deep Neural Networks (DNNs) and track their use. Several methods have been proposed that embed the watermark into the trainable parameters of the network (white box watermarking) or into the input-output mappping implemented by the network in correspondence to specific inputs (black box watermarking). In both cases, achieving robustness against fine tuning, model compression and, even more, transfer learning, is one of the most difficult challenges researchers are trying to face with. In this paper, we propose a new white-box, multi-bit watermarking algorithm with strong robustness properties, including retraining for transfer learning. Robustness is achieved thanks to a new information coding strategy according to which the watermark message is spread across a number of fixed weights, whose position depends on a secret key. The weights hosting the watermark are set prior to training, and are left unchanged throughout the entire training procedure. The distribution of the weights carrying out the message is theoretically optimised to make sure that the watermarked weights are indistinguishable from the other weights, while at the same time keeping their amplitude as large as possible to improve robustness against retraining. We carried out several experiments demonstrating the capability of the proposed scheme to provide high payloads with practically no impact on the network accuracy, at the same time retaining excellent robustness against network modifications an re-use, including retraining for transfer learning. ",
    "url": "https://arxiv.org/abs/2208.10973",
    "authors": [
      "Benedetta Tondi",
      "Andrea Costanzo",
      "Mauro Barni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.10976",
    "title": "Quality Matters: Embracing Quality Clues for Robust 3D Multi-Object  Tracking",
    "abstract": "3D Multi-Object Tracking (MOT) has achieved tremendous achievement thanks to the rapid development of 3D object detection and 2D MOT. Recent advanced works generally employ a series of object attributes, e.g., position, size, velocity, and appearance, to provide the clues for the association in 3D MOT. However, these cues may not be reliable due to some visual noise, such as occlusion and blur, leading to tracking performance bottleneck. To reveal the dilemma, we conduct extensive empirical analysis to expose the key bottleneck of each clue and how they correlate with each other. The analysis results motivate us to efficiently absorb the merits among all cues, and adaptively produce an optimal tacking manner. Specifically, we present Location and Velocity Quality Learning, which efficiently guides the network to estimate the quality of predicted object attributes. Based on these quality estimations, we propose a quality-aware object association (QOA) strategy to leverage the quality score as an important reference factor for achieving robust association. Despite its simplicity, extensive experiments indicate that the proposed strategy significantly boosts tracking performance by 2.2% AMOTA and our method outperforms all existing state-of-the-art works on nuScenes by a large margin. Moreover, QTrack achieves 48.0% and 51.1% AMOTA tracking performance on the nuScenes validation and test sets, which significantly reduces the performance gap between pure camera and LiDAR based trackers. ",
    "url": "https://arxiv.org/abs/2208.10976",
    "authors": [
      "Jinrong Yang",
      "En Yu",
      "Zeming Li",
      "Xiaoping Li",
      "Wenbing Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10981",
    "title": "Causal Entropy Optimization",
    "abstract": "We study the problem of globally optimizing the causal effect on a target variable of an unknown causal graph in which interventions can be performed. This problem arises in many areas of science including biology, operations research and healthcare. We propose Causal Entropy Optimization (CEO), a framework that generalizes Causal Bayesian Optimization (CBO) to account for all sources of uncertainty, including the one arising from the causal graph structure. CEO incorporates the causal structure uncertainty both in the surrogate models for the causal effects and in the mechanism used to select interventions via an information-theoretic acquisition function. The resulting algorithm automatically trades-off structure learning and causal effect optimization, while naturally accounting for observation noise. For various synthetic and real-world structural causal models, CEO achieves faster convergence to the global optimum compared with CBO while also learning the graph. Furthermore, our joint approach to structure learning and causal optimization improves upon sequential, structure-learning-first approaches. ",
    "url": "https://arxiv.org/abs/2208.10981",
    "authors": [
      "Nicola Branchini",
      "Virginia Aglietti",
      "Neil Dhir",
      "Theodoros Damoulas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.10995",
    "title": "Learning linear modules in a dynamic network with missing node  observations",
    "abstract": "In order to identify a system (module) embedded in a dynamic network, one has to formulate a multiple-input estimation problem that necessitates certain nodes to be measured and included as predictor inputs. However, some of these nodes may not be measurable in many practical cases due to sensor selection and placement issues. This may result in biased estimates of the target module. Furthermore, the identification problem associated with the multiple-input structure may require determining a large number of parameters that are not of particular interest to the experimenter, with increased computational complexity in large-sized networks. In this paper, we tackle these problems by using a data augmentation strategy that allows us to reconstruct the missing node measurements and increase the accuracy of the estimated target module. To this end, we develop a system identification method using regularized kernel-based methods coupled with approximate inference methods. Keeping a parametric model for the module of interest, we model the other modules as Gaussian Processes (GP) with a kernel given by the so-called stable spline kernel. An Empirical Bayes (EB) approach is used to estimate the parameters of the target module. The related optimization problem is solved using an Expectation-Maximization (EM) method, where we employ a Markov-chain Monte Carlo (MCMC) technique to reconstruct the unknown missing node information and the network dynamics. Numerical simulations on dynamic network examples illustrate the potentials of the developed method. ",
    "url": "https://arxiv.org/abs/2208.10995",
    "authors": [
      "Karthik R. Ramaswamy",
      "Giulio Bottegal",
      "Paul M.J. Van den Hof"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.10996",
    "title": "An Evolutionary Approach for Creating of Diverse Classifier Ensembles",
    "abstract": "Classification is one of the most studied tasks in data mining and machine learning areas and many works in the literature have been presented to solve classification problems for multiple fields of knowledge such as medicine, biology, security, and remote sensing. Since there is no single classifier that achieves the best results for all kinds of applications, a good alternative is to adopt classifier fusion strategies. A key point in the success of classifier fusion approaches is the combination of diversity and accuracy among classifiers belonging to an ensemble. With a large amount of classification models available in the literature, one challenge is the choice of the most suitable classifiers to compose the final classification system, which generates the need of classifier selection strategies. We address this point by proposing a framework for classifier selection and fusion based on a four-step protocol called CIF-E (Classifiers, Initialization, Fitness function, and Evolutionary algorithm). We implement and evaluate 24 varied ensemble approaches following the proposed CIF-E protocol and we are able to find the most accurate approach. A comparative analysis has also been performed among the best approaches and many other baselines from the literature. The experiments show that the proposed evolutionary approach based on Univariate Marginal Distribution Algorithm (UMDA) can outperform the state-of-the-art literature approaches in many well-known UCI datasets. ",
    "url": "https://arxiv.org/abs/2208.10996",
    "authors": [
      "Alvaro R. Ferreira Jr",
      "Fabio A. Faria",
      "Gustavo Carneiro",
      "Vinicius V. de Melo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.11011",
    "title": "Adaptation of MobileNetV2 for Face Detection on Ultra-Low Power Platform",
    "abstract": "Designing Deep Neural Networks (DNNs) running on edge hardware remains a challenge. Standard designs have been adopted by the community to facilitate the deployment of Neural Network models. However, not much emphasis is put on adapting the network topology to fit hardware constraints. In this paper, we adapt one of the most widely used architectures for mobile hardware platforms, MobileNetV2, and study the impact of changing its topology and applying post-training quantization. We discuss the impact of the adaptations and the deployment of the model on an embedded hardware platform for face detection. ",
    "url": "https://arxiv.org/abs/2208.11011",
    "authors": [
      "Simon Narduzzi",
      "Engin T\u00fcretken",
      "Jean-Philippe Thiran",
      "L. Andrea Dunbar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.11015",
    "title": "META-CODE: Community Detection via Exploratory Learning in Topologically  Unknown Networks",
    "abstract": "The discovery of community structures in social networks has gained considerable attention as a fundamental problem for various network analysis tasks. However, due to privacy concerns or access restrictions, the network structure is often unknown, thereby rendering established community detection approaches ineffective without costly data acquisition. To tackle this challenge, we present META-CODE, a novel end-to-end solution for detecting overlapping communities in networks with unknown topology via exploratory learning aided by easy-to-collect node metadata. Specifically, META-CODE consists of three steps: 1) initial network inference, 2) node-level community-affiliation embedding based on graph neural networks (GNNs) trained by our new reconstruction loss, and 3) network exploration via community-affiliation-based node queries, where Steps 2 and 3 are performed iteratively. Experimental results demonstrate that META-CODE exhibits (a) superiority over benchmark methods for overlapping community detection, (b) the effectiveness of our training model, and (c) fast network exploration. ",
    "url": "https://arxiv.org/abs/2208.11015",
    "authors": [
      "Yu Hou",
      "Cong Tran",
      "Won-Yong Shin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2208.11020",
    "title": "Gender Representation in Brazilian Computer Science Conferences",
    "abstract": "This study presents an automated bibliometric analysis of 6569 research papers published in thirteen Brazilian Computer Science Society (SBC) conferences from 1999 to 2021. Our primary goal was to gather data to understand the gender representation in publications in the field of Computer Science. We applied a systematic assignment of gender to 23.573 listed papers authorships, finding that the gender gap for women is significant, with female authors being under-represented in all years of the study. ",
    "url": "https://arxiv.org/abs/2208.11020",
    "authors": [
      "Nat\u00e1lia Dal Pizzol",
      "Eduardo Dos Santos Barbosa",
      "Soraia Raupp Musse"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2208.11021",
    "title": "Adversarial Feature Augmentation for Cross-domain Few-shot  Classification",
    "abstract": "Existing methods based on meta-learning predict novel-class labels for (target domain) testing tasks via meta knowledge learned from (source domain) training tasks of base classes. However, most existing works may fail to generalize to novel classes due to the probably large domain discrepancy across domains. To address this issue, we propose a novel adversarial feature augmentation (AFA) method to bridge the domain gap in few-shot learning. The feature augmentation is designed to simulate distribution variations by maximizing the domain discrepancy. During adversarial training, the domain discriminator is learned by distinguishing the augmented features (unseen domain) from the original ones (seen domain), while the domain discrepancy is minimized to obtain the optimal feature encoder. The proposed method is a plug-and-play module that can be easily integrated into existing few-shot learning methods based on meta-learning. Extensive experiments on nine datasets demonstrate the superiority of our method for cross-domain few-shot classification compared with the state of the art. Code is available at https://github.com/youthhoo/AFA_For_Few_shot_learning ",
    "url": "https://arxiv.org/abs/2208.11021",
    "authors": [
      "Yanxu Hu",
      "Andy J. Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.11024",
    "title": "KGxBoard: Explainable and Interactive Leaderboard for Evaluation of  Knowledge Graph Completion Models",
    "abstract": "Knowledge Graphs (KGs) store information in the form of (head, predicate, tail)-triples. To augment KGs with new knowledge, researchers proposed models for KG Completion (KGC) tasks such as link prediction; i.e., answering (h; p; ?) or (?; p; t) queries. Such models are usually evaluated with averaged metrics on a held-out test set. While useful for tracking progress, averaged single-score metrics cannot reveal what exactly a model has learned -- or failed to learn. To address this issue, we propose KGxBoard: an interactive framework for performing fine-grained evaluation on meaningful subsets of the data, each of which tests individual and interpretable capabilities of a KGC model. In our experiments, we highlight the findings that we discovered with the use of KGxBoard, which would have been impossible to detect with standard averaged single-score metrics. ",
    "url": "https://arxiv.org/abs/2208.11024",
    "authors": [
      "Haris Widjaja",
      "Kiril Gashteovski",
      "Wiem Ben Rim",
      "Pengfei Liu",
      "Christopher Malon",
      "Daniel Ruffinelli",
      "Carolin Lawrence",
      "Graham Neubig"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.11025",
    "title": "Grad-Align+: Empowering Gradual Network Alignment Using Attribute  Augmentation",
    "abstract": "Network alignment (NA) is the task of discovering node correspondences across different networks. Although NA methods have achieved remarkable success in a myriad of scenarios, their satisfactory performance is not without prior anchor link information and/or node attributes, which may not always be available. In this paper, we propose Grad-Align+, a novel NA method using node attribute augmentation that is quite robust to the absence of such additional information. Grad-Align+ is built upon a recent state-of-the-art NA method, the so-called Grad-Align, that gradually discovers only a part of node pairs until all node pairs are found. Specifically, Grad-Align+ is composed of the following key components: 1) augmenting node attributes based on nodes' centrality measures, 2) calculating an embedding similarity matrix extracted from a graph neural network into which the augmented node attributes are fed, and 3) gradually discovering node pairs by calculating similarities between cross-network nodes with respect to the aligned cross-network neighbor-pair. Experimental results demonstrate that Grad-Align+ exhibits (a) superiority over benchmark NA methods, (b) empirical validation of our theoretical findings, and (c) the effectiveness of our attribute augmentation module. ",
    "url": "https://arxiv.org/abs/2208.11025",
    "authors": [
      "Jin-Duk Park",
      "Cong Tran",
      "Won-Yong Shin",
      "Xin Cao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2208.11050",
    "title": "Self-Trained Proposal Networks for the Open World",
    "abstract": "Deep learning-based object proposal methods have enabled significant advances in many computer vision pipelines. However, current state-of-the-art proposal networks use a closed-world assumption, meaning they are only trained to detect instances of the training classes while treating every other region as background. This style of solution fails to provide high recall on out-of-distribution objects, rendering it inadequate for use in realistic open-world applications where novel object categories of interest may be observed. To better detect all objects, we propose a classification-free Self-Trained Proposal Network (STPN) that leverages a novel self-training optimization strategy combined with dynamically weighted loss functions that account for challenges such as class imbalance and pseudo-label uncertainty. Not only is our model designed to excel in existing optimistic open-world benchmarks, but also in challenging operating environments where there is significant label bias. To showcase this, we devise two challenges to test the generalization of proposal models when the training data contains (1) less diversity within the labeled classes, and (2) fewer labeled instances. Our results show that STPN achieves state-of-the-art novel object generalization on all tasks. ",
    "url": "https://arxiv.org/abs/2208.11050",
    "authors": [
      "Matthew Inkawhich",
      "Nathan Inkawhich",
      "Hai Li",
      "Yiran Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.11052",
    "title": "IMPaSh: A Novel Domain-shift Resistant Representation for Colorectal  Cancer Tissue Classification",
    "abstract": "The appearance of histopathology images depends on tissue type, staining and digitization procedure. These vary from source to source and are the potential causes for domain-shift problems. Owing to this problem, despite the great success of deep learning models in computational pathology, a model trained on a specific domain may still perform sub-optimally when we apply them to another domain. To overcome this, we propose a new augmentation called PatchShuffling and a novel self-supervised contrastive learning framework named IMPaSh for pre-training deep learning models. Using these, we obtained a ResNet50 encoder that can extract image representation resistant to domain-shift. We compared our derived representation against those acquired based on other domain-generalization techniques by using them for the cross-domain classification of colorectal tissue images. We show that the proposed method outperforms other traditional histology domain-adaptation and state-of-the-art self-supervised learning methods. Code is available at: https://github.com/trinhvg/IMPash . ",
    "url": "https://arxiv.org/abs/2208.11052",
    "authors": [
      "Trinh Thi Le Vuong",
      "Quoc Dang Vu",
      "Mostafa Jahanifar",
      "Simon Graham",
      "Jin Tae Kwak",
      "Nasir Rajpoot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.11058",
    "title": "Neuroevolution-based Classifiers for Deforestation Detection in Tropical  Forests",
    "abstract": "Tropical forests represent the home of many species on the planet for flora and fauna, retaining billions of tons of carbon footprint, promoting clouds and rain formation, implying a crucial role in the global ecosystem, besides representing the home to countless indigenous peoples. Unfortunately, millions of hectares of tropical forests are lost every year due to deforestation or degradation. To mitigate that fact, monitoring and deforestation detection programs are in use, in addition to public policies for the prevention and punishment of criminals. These monitoring/detection programs generally use remote sensing images, image processing techniques, machine learning methods, and expert photointerpretation to analyze, identify and quantify possible changes in forest cover. Several projects have proposed different computational approaches, tools, and models to efficiently identify recent deforestation areas, improving deforestation monitoring programs in tropical forests. In this sense, this paper proposes the use of pattern classifiers based on neuroevolution technique (NEAT) in tropical forest deforestation detection tasks. Furthermore, a novel framework called e-NEAT has been created and achieved classification results above $90\\%$ for balanced accuracy measure in the target application using an extremely reduced and limited training set for learning the classification models. These results represent a relative gain of $6.2\\%$ over the best baseline ensemble method compared in this paper ",
    "url": "https://arxiv.org/abs/2208.11058",
    "authors": [
      "Guilherme A. Pimenta",
      "Fernanda B. J. R. Dallaqua",
      "Alvaro Fazenda",
      "Fabio A. Faria"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.11061",
    "title": "Large-Scale Traffic Congestion Prediction based on Multimodal Fusion and  Representation Mapping",
    "abstract": "With the progress of the urbanisation process, the urban transportation system is extremely critical to the development of cities and the quality of life of the citizens. Among them, it is one of the most important tasks to judge traffic congestion by analysing the congestion factors. Recently, various traditional and machine-learning-based models have been introduced for predicting traffic congestion. However, these models are either poorly aggregated for massive congestion factors or fail to make accurate predictions for every precise location in large-scale space. To alleviate these problems, a novel end-to-end framework based on convolutional neural networks is proposed in this paper. With learning representations, the framework proposes a novel multimodal fusion module and a novel representation mapping module to achieve traffic congestion predictions on arbitrary query locations on a large-scale map, combined with various global reference information. The proposed framework achieves significant results and efficient inference on real-world large-scale datasets. ",
    "url": "https://arxiv.org/abs/2208.11061",
    "authors": [
      "Bodong Zhou",
      "Jiahui Liu",
      "Songyi Cui",
      "Yaping Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.11062",
    "title": "Towards a Formal Approach for Detection of Vulnerabilities in the  Android Permissions System",
    "abstract": "Android is a widely used operating system that employs a permission-based access control model. The Android Permissions System (APS) is responsible for mediating application resource requests. APS is a critical component of the Android security mechanism; hence, a failure in the design of APS can potentially lead to vulnerabilities that grant unauthorized access to resources by malicious applications. In this paper, we present a formal approach for modeling and verifying the security properties of APS. We demonstrate the usability of the proposed approach by showcasing the detection of a well-known vulnerability found in Android's custom permissions. ",
    "url": "https://arxiv.org/abs/2208.11062",
    "authors": [
      "Amirhosein Sayyadabdi",
      "Behrouz Tork Ladani",
      "Bahman Zamani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.11064",
    "title": "Multi-Modal Representation Learning with SAT for Commodity Verification",
    "abstract": "In this paper, we propose a method to identify identical commodities. In e-commerce scenarios, commodities are usually described by both images and text. By definition, identical commodities are those that have identical key attributes and are cognitively identical to consumers. There are two main challenges: 1) The extraction and fusion of multi-modal representation. 2) The ability to verify whether two commodities are identical by comparing the distance between representations with a threshold. To address the above problems, we propose an end-to-end identical commodity verification method based on self-adaptive thresholds. We use a dual-stream network to extract commodity embeddings and threshold embeddings separately and then concatenate them to obtain commodity representation. Our method is able to obtain different thresholds according to different commodities while maintaining the indexability of the entire commodity representation. We experimentally validate the effectiveness of our multimodal feature fusion and the advantages of self-adaptive thresholds. Besides, our method achieves an F1 score of 0.8936 and takes the 3rd place on the leaderboard for the second task of the CCKS-2022 Knowledge Graph Evaluation for Digital Commerce Competition. Code and pretrained models are available at https://github.com/hanchenchen/CCKS2022-track2-solution. ",
    "url": "https://arxiv.org/abs/2208.11064",
    "authors": [
      "Chenchen Han",
      "Heng Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.11069",
    "title": "Asynchronous Execution of Heterogeneous Tasks in AI-coupled HPC  Workflows",
    "abstract": "Heterogeneous scientific workflows consist of numerous types of tasks and dependencies between them. Middleware capable of scheduling and submitting different task types across heterogeneous platforms must permit asynchronous execution of tasks for improved resource utilization, task throughput, and reduced makespan. In this paper we present an analysis of an important class of heterogeneous workflows, viz., AI-driven HPC workflows, to investigate asynchronous task execution requirements and properties. We model the degree of asynchronicity permitted for arbitrary workflows, and propose key metrics that can be used to determine qualitative benefits when employing asynchronous execution. Our experiments represent important scientific drivers, are performed at scale on Summit, and performance enhancements due to asynchronous execution are consistent with our model. ",
    "url": "https://arxiv.org/abs/2208.11069",
    "authors": [
      "Vincent R. Pascuzzi",
      "Matteo Turilli",
      "Shantenu Jha"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.11071",
    "title": "VRBubble: Enhancing Peripheral Awareness of Avatars for People with  Visual Impairments in Social Virtual Reality",
    "abstract": "Social Virtual Reality (VR) is growing for remote socialization and collaboration. However, current social VR applications are not accessible to people with visual impairments (PVI) due to their focus on visual experiences. We aim to facilitate social VR accessibility by enhancing PVI's peripheral awareness of surrounding avatar dynamics. We designed VRBubble, an audio-based VR technique that provides surrounding avatar information based on social distances. Based on Hall's proxemic theory, VRBubble divides the social space with three Bubbles -- Intimate, Conversation, and Social Bubble -- generating spatial audio feedback to distinguish avatars in different bubbles and provide suitable avatar information. We provide three audio alternatives: earcons, verbal notifications, and real-world sound effects. PVI can select and combine their preferred feedback alternatives for different avatars, bubbles, and social contexts. We evaluated VRBubble and an audio beacon baseline with 12 PVI in a navigation and a conversation context. We found that VRBubble significantly enhanced participants' avatar awareness during navigation and enabled avatar identification in both contexts. However, VRBubble was shown to be more distracting in crowded environments. ",
    "url": "https://arxiv.org/abs/2208.11071",
    "authors": [
      "Tiger Ji",
      "Brianna R. Cochran",
      "Yuhang Zhao"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2208.11079",
    "title": "Robot Active Neural Sensing and Planning in Unknown Cluttered  Environments",
    "abstract": "Active sensing and planning in unknown, cluttered environments is an open challenge for robots intending to provide home service, search and rescue, narrow-passage inspection, and medical assistance. Although many active sensing methods exist, they often consider open spaces, assume known settings, or mostly do not generalize to real-world scenarios. We present the active neural sensing approach that generates the kinematically feasible viewpoint sequences for the robot manipulator with an in-hand camera to gather the minimum number of observations needed to reconstruct the underlying environment. Our framework actively collects the visual RGBD observations, aggregates them into scene representation, and performs object shape inference to avoid unnecessary robot interactions with the environment. We train our approach on synthetic data with domain randomization and demonstrate its successful execution via sim-to-real transfer in reconstructing narrow, covered, real-world cabinet environments cluttered with unknown objects. The natural cabinet scenarios impose significant challenges for robot motion and scene reconstruction due to surrounding obstacles and low ambient lighting conditions. However, despite unfavorable settings, our method exhibits high performance compared to its baselines in terms of various environment reconstruction metrics, including planning speed, the number of viewpoints, and overall scene coverage. ",
    "url": "https://arxiv.org/abs/2208.11079",
    "authors": [
      "Hanwen Ren",
      "Ahmed H. Qureshi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.11083",
    "title": "Learn Basic Skills and Reuse: Modularized Adaptive Neural Architecture  Search (MANAS)",
    "abstract": "Human intelligence is able to first learn some basic skills for solving basic problems and then assemble such basic skills into complex skills for solving complex or new problems. For example, the basic skills ``dig hole,'' ``put tree,'' ``backfill'' and ``watering'' compose a complex skill ``plant a tree''. Besides, some basic skills can be reused for solving other problems. For example, the basic skill ``dig hole'' not only can be used for planting a tree, but also can be used for mining treasures, building a drain, or landfilling. The ability to learn basic skills and reuse them for various tasks is very important for humans because it helps to avoid learning too many skills for solving each individual task, and makes it possible to solve a compositional number of tasks by learning just a few number of basic skills, which saves a considerable amount of memory and computation in the human brain. We believe that machine intelligence should also capture the ability of learning basic skills and reusing them by composing into complex skills. In computer science language, each basic skill is a ``module'', which is a reusable network of a concrete meaning and performs a specific basic operation. The modules are assembled into a bigger ``model'' for doing a more complex task. The assembling procedure is adaptive to the input or task, i.e., for a given task, the modules should be assembled into the most suitable model for solving the task. As a result, different inputs or tasks could have different assembled models, which enables self-assembling AI. In this work, we propose Modularized Adaptive Neural Architecture Search (MANAS) to demonstrate the above idea. Experiments on different datasets show that the adaptive architecture assembled by MANAS outperforms static global architectures. Further experiments and empirical analysis provide insights to the effectiveness of MANAS. ",
    "url": "https://arxiv.org/abs/2208.11083",
    "authors": [
      "Hanxiong Chen",
      "Yunqi Li",
      "He Zhu",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Logic in Computer Science (cs.LO)",
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2208.11090",
    "title": "IEEE Trust, Acceptance and Social Cues in Human-Robot Interaction --  SCRITA 2022 Workshop",
    "abstract": "The Trust, Acceptance and Social Cues in Human-Robot Interaction - SCRITA is the 5th edition of a series of workshops held in conjunction with the IEEE RO-MAN conference. This workshop focuses on addressing the challenges and development of the dynamics between people and robots in order to foster short interactions and long-lasting relationships in different fields, from educational, service, collaborative, companion, care-home and medical robotics. In particular, we aimed in investigating how robots can manipulate (i.e. creating, improving, and recovering) people's ability of accepting and trusting them for a fruitful and successful coexistence between humans and people. While advanced progresses are reached in studying and evaluating the factors affecting acceptance and trust of people in robots in controlled or short-term (repeated interactions) setting, developing service and personal robots, that are accepted and trusted by people where the supervision of operators is not possible, still presents an open challenge for scientists in robotics, AI and HRI fields. In such unstructured static and dynamic human-centred environments scenarios, robots should be able to learn and adapt their behaviours to the situational context, but also to people's prior experiences and learned associations, their expectations, and their and the robot's ability to predict and understand each other's behaviours. Although the previous editions valued the participation of leading researchers in the field and several exceptional invited speakers who tackled down some fundamental points in this research domains, we wish to continue to further explore the role of trust in robotics to present groundbreaking research to effectively design and develop socially acceptable and trustable robots to be deployed \"in the wild\". Website: https://scrita.herts.ac.uk ",
    "url": "https://arxiv.org/abs/2208.11090",
    "authors": [
      "Alessandra Rossi",
      "Patrick Holthaus",
      "S\u00eclvia Moros",
      "Gabriella Lakatos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2208.11094",
    "title": "Dynamic Causal Collaborative Filtering",
    "abstract": "Causal graph, as an effective and powerful tool for causal modeling, is usually assumed as a Directed Acyclic Graph (DAG). However, recommender systems usually involve feedback loops, defined as the cyclic process of recommending items, incorporating user feedback in model updates, and repeating the procedure. As a result, it is important to incorporate loops into the causal graphs to accurately model the dynamic and iterative data generation process for recommender systems. However, feedback loops are not always beneficial since over time they may encourage more and more narrowed content exposure, which if left unattended, may results in echo chambers. As a result, it is important to understand when the recommendations will lead to echo chambers and how to mitigate echo chambers without hurting the recommendation performance. In this paper, we design a causal graph with loops to describe the dynamic process of recommendation. We then take Markov process to analyze the mathematical properties of echo chamber such as the conditions that lead to echo chambers. Inspired by the theoretical analysis, we propose a Dynamic Causal Collaborative Filtering ($\\partial$CCF) model, which estimates users' post-intervention preference on items based on back-door adjustment and mitigates echo chamber with counterfactual reasoning. Multiple experiments are conducted on real-world datasets and results show that our framework can mitigate echo chambers better than other state-of-the-art frameworks while achieving comparable recommendation performance with the base recommendation models. ",
    "url": "https://arxiv.org/abs/2208.11094",
    "authors": [
      "Shuyuan Xu",
      "Juntao Tan",
      "Zuohui Fu",
      "Jianchao Ji",
      "Shelby Heinecke",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.11112",
    "title": "DeepInteraction: 3D Object Detection via Modality Interaction",
    "abstract": "Existing top-performance 3D object detectors typically rely on the multi-modal fusion strategy. This design is however fundamentally restricted due to overlooking the modality-specific useful information and finally hampering the model performance. To address this limitation, in this work we introduce a novel modality interaction strategy where individual per-modality representations are learned and maintained throughout for enabling their unique characteristics to be exploited during object detection. To realize this proposed strategy, we design a DeepInteraction architecture characterized by a multi-modal representational interaction encoder and a multi-modal predictive interaction decoder. Experiments on the large-scale nuScenes dataset show that our proposed method surpasses all prior arts often by a large margin. Crucially, our method is ranked at the first position at the highly competitive nuScenes object detection leaderboard. ",
    "url": "https://arxiv.org/abs/2208.11112",
    "authors": [
      "Zeyu Yang",
      "Jiaqi Chen",
      "Zhenwei Miao",
      "Wei Li",
      "Xiatian Zhu",
      "Li Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.11113",
    "title": "Towards Open Set Video Anomaly Detection",
    "abstract": "Open Set Video Anomaly Detection (OpenVAD) aims to identify abnormal events from video data where both known anomalies and novel ones exist in testing. Unsupervised models learned solely from normal videos are applicable to any testing anomalies but suffer from a high false positive rate. In contrast, weakly supervised methods are effective in detecting known anomalies but could fail in an open world. We develop a novel weakly supervised method for the OpenVAD problem by integrating evidential deep learning (EDL) and normalizing flows (NFs) into a multiple instance learning (MIL) framework. Specifically, we propose to use graph neural networks and triplet loss to learn discriminative features for training the EDL classifier, where the EDL is capable of identifying the unknown anomalies by quantifying the uncertainty. Moreover, we develop an uncertainty-aware selection strategy to obtain clean anomaly instances and a NFs module to generate the pseudo anomalies. Our method is superior to existing approaches by inheriting the advantages of both the unsupervised NFs and the weakly-supervised MIL framework. Experimental results on multiple real-world video datasets show the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2208.11113",
    "authors": [
      "Yuansheng Zhu",
      "Wentao Bao",
      "Qi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.11122",
    "title": "Distance-Aware Occlusion Detection with Focused Attention",
    "abstract": "For humans, understanding the relationships between objects using visual signals is intuitive. For artificial intelligence, however, this task remains challenging. Researchers have made significant progress studying semantic relationship detection, such as human-object interaction detection and visual relationship detection. We take the study of visual relationships a step further from semantic to geometric. In specific, we predict relative occlusion and relative distance relationships. However, detecting these relationships from a single image is challenging. Enforcing focused attention to task-specific regions plays a critical role in successfully detecting these relationships. In this work, (1) we propose a novel three-decoder architecture as the infrastructure for focused attention; 2) we use the generalized intersection box prediction task to effectively guide our model to focus on occlusion-specific regions; 3) our model achieves a new state-of-the-art performance on distance-aware relationship detection. Specifically, our model increases the distance F1-score from 33.8% to 38.6% and boosts the occlusion F1-score from 34.4% to 41.2%. Our code is publicly available. ",
    "url": "https://arxiv.org/abs/2208.11122",
    "authors": [
      "Yang Li",
      "Yucheng Tu",
      "Xiaoxue Chen",
      "Hao Zhao",
      "Guyue Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10537",
    "title": "Digraph Networks and Groupoids",
    "abstract": "We answer a question posed by Dougherty and Faber in [3], \"Network routing on regular directed graphs from spanning factorizations.\" We prove that every vertex transitive digraph has a spanning factorization; in fact, this is a necessary and sufficient condition. We show that 1-factorization of a regular digraph is closely related to the notion of a Cayley graph of a groupoid and as such, the theorem we prove on spanning factorizations can be translated to a 2006 theorem of Mwambene [4; Theorem 9] on groupoids. We also show that groupoids are a powerful tool for examining network routing on general regular digraphs. We show there is a 1-1 relation between regular connected digraphs of degree d and the Cayley graphs of groupoids (not necessarily associative but with left identity and right cancellation) with d generators. This enables us to provide compact algebraic definitions for some important graphs that are either given as explicit edge lists or as the Cayley coset graphs of groups larger than the graph. One such example is a single expression for the Hoffman-Singleton graph. ",
    "url": "https://arxiv.org/abs/2208.10537",
    "authors": [
      "Nyumbu Chishwashwa",
      "Vance Faber",
      "Noah Streib"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2208.10588",
    "title": "Widely-Linear MMSE Estimation of Complex-Valued Graph Signals",
    "abstract": "In this paper, we consider the problem of recovering random graph signals with complex values. For general Bayesian estimation of complex-valued vectors, it is known that the widely-linear minimum mean-squared-error (WLMMSE) estimator can achieve a lower mean-squared-error (MSE) than that of the linear minimum MSE (LMMSE) estimator. Inspired by the WLMMSE estimator, in this paper we develop the graph signal processing (GSP)-WLMMSE estimator, which minimizes the MSE among estimators that are represented as a two-channel output of a graph filter, i.e. widely-linear GSP estimators. We discuss the properties of the proposed GSP-WLMMSE estimator. In particular, we show that the MSE of the GSP-WLMMSE estimator is always equal to or lower than the MSE of the GSP-LMMSE estimator. The GSP-WLMMSE estimator is based on diagonal covariance matrices in the graph frequency domain, and thus has reduced complexity compared with the WLMMSE estimator. This property is especially important when using the sample-mean versions of these estimators that are based on a training dataset. We then state conditions under which the low-complexity GSP-WLMMSE estimator coincides with the WLMMSE estimator. In the simulations, we investigate two synthetic estimation problems (with linear and nonlinear models) and the problem of state estimation in power systems. For these problems, it is shown that the GSP-WLMMSE estimator outperforms the GSP-LMMSE estimator and achieves similar performance to that of the WLMMSE estimator. ",
    "url": "https://arxiv.org/abs/2208.10588",
    "authors": [
      "Alon Amar",
      "Tirza Routtenberg"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2208.10708",
    "title": "Convolutional Neural Networks with A Topographic Representation Module  for EEG-Based Brain-Computer Interfaces",
    "abstract": "Objective: Convolutional Neural Networks (CNNs) have shown great potential in the field of Brain-Computer Interface (BCI) due to their ability to directly process the raw Electroencephalogram (EEG) without artificial feature extraction. The raw EEG signal is usually represented as 2-Dimensional (2-D) matrix composed of channels and time points, which ignores the spatial topological information of EEG. Our goal is to make the CNN with the raw EEG signal as input have the ability to learn the EEG spatial topological features, and improve its classification performance while essentially maintaining its original structure. Methods: We propose an EEG Topographic Representation Module (TRM). This module consists of (1) a mapping block from the raw EEG signal to a 3-D topographic map and (2) a convolution block from the topographic map to an output of the same size as the input. We embed the TRM to 3 widely used CNNs, and tested them on 2 different types of publicly available datasets. Results: The results show that the classification accuracies of the 3 CNNs are improved on both datasets after using TRM. The average classification accuracies of DeepConvNet, EEGNet and ShallowConvNet with TRM are improved by 4.70\\%, 1.29\\% and 0.91\\% on Emergency Braking During Simulated Driving Dataset (EBDSDD), and 2.83\\%, 2.17\\% and 2.00\\% on High Gamma Dataset (HGD), respectively. Significance: By using TRM to mine the spatial topological features of EEG, we improve the classification performance of 3 CNNs on 2 datasets. In addition,since the output of TRM has the same size as the input, any CNN with the raw EEG signal as input can use this module without changing the original structure. ",
    "url": "https://arxiv.org/abs/2208.10708",
    "authors": [
      "Xinbin Liang",
      "Yaru Liu",
      "Yang Yu",
      "Kaixuan Liu",
      "Yadong Liu",
      "Zongtan Zhou"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.10745",
    "title": "Retinal Structure Detection in OCTA Image via Voting-based Multi-task  Learning",
    "abstract": "Automated detection of retinal structures, such as retinal vessels (RV), the foveal avascular zone (FAZ), and retinal vascular junctions (RVJ), are of great importance for understanding diseases of the eye and clinical decision-making. In this paper, we propose a novel Voting-based Adaptive Feature Fusion multi-task network (VAFF-Net) for joint segmentation, detection, and classification of RV, FAZ, and RVJ in optical coherence tomography angiography (OCTA). A task-specific voting gate module is proposed to adaptively extract and fuse different features for specific tasks at two levels: features at different spatial positions from a single encoder, and features from multiple encoders. In particular, since the complexity of the microvasculature in OCTA images makes simultaneous precise localization and classification of retinal vascular junctions into bifurcation/crossing a challenging task, we specifically design a task head by combining the heatmap regression and grid classification. We take advantage of three different \\textit{en face} angiograms from various retinal layers, rather than following existing methods that use only a single \\textit{en face}. To facilitate further research, part of these datasets with the source code and evaluation benchmark have been released for public access:https://github.com/iMED-Lab/VAFF-Net. ",
    "url": "https://arxiv.org/abs/2208.10745",
    "authors": [
      "Jinkui Hao",
      "Ting Shen",
      "Xueli Zhu",
      "Yonghuai Liu",
      "Ardhendu Behera",
      "Dan Zhang",
      "Bang Chen",
      "Jiang Liu",
      "Jiong Zhang",
      "Yitian Zhao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10784",
    "title": "Building Robust Machine Learning Models for Small Chemical Science Data:  The Case of Shear Viscosity",
    "abstract": "Shear viscosity, though being a fundamental property of all liquids, is computationally expensive to estimate from equilibrium molecular dynamics simulations. Recently, Machine Learning (ML) methods have been used to augment molecular simulations in many contexts, thus showing promise to estimate viscosity too in a relatively inexpensive manner. However, ML methods face significant challenges like overfitting when the size of the data set is small, as is the case with viscosity. In this work, we train several ML models to predict the shear viscosity of a Lennard-Jones (LJ) fluid, with particular emphasis on addressing issues arising from a small data set. Specifically, the issues related to model selection, performance estimation and uncertainty quantification were investigated. First, we show that the widely used performance estimation procedure of using a single unseen data set shows a wide variability on small data sets. In this context, the common practice of using Cross validation (CV) to select the hyperparameters (model selection) can be adapted to estimate the generalization error (performance estimation) as well. We compare two simple CV procedures for their ability to do both model selection and performance estimation, and find that k-fold CV based procedure shows a lower variance of error estimates. We discuss the role of performance metrics in training and evaluation. Finally, Gaussian Process Regression (GPR) and ensemble methods were used to estimate the uncertainty on individual predictions. The uncertainty estimates from GPR were also used to construct an applicability domain using which the ML models provided more reliable predictions on another small data set generated in this work. Overall, the procedures prescribed in this work, together, lead to robust ML models for small data sets. ",
    "url": "https://arxiv.org/abs/2208.10784",
    "authors": [
      "Nikhil V. S. Avula",
      "Shivanand K. Veesam",
      "Sudarshan Behera",
      "Sundaram Balasubramanian"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.10797",
    "title": "Aging prediction using deep generative model toward the development of  preventive medicine",
    "abstract": "From birth to death, we all experience surprisingly ubiquitous changes over time due to aging. If we can predict aging in the digital domain, that is, the digital twin of the human body, we would be able to detect lesions in their very early stages, thereby enhancing the quality of life and extending the life span. We observed that none of the previously developed digital twins of the adult human body explicitly trained longitudinal conversion rules between volumetric medical images with deep generative models, potentially resulting in poor prediction performance of, for example, ventricular volumes. Here, we establish a new digital twin of an adult human body that adopts longitudinally acquired head computed tomography (CT) images for training, enabling prediction of future volumetric head CT images from a single present volumetric head CT image. We, for the first time, adopt one of the three-dimensional flow-based deep generative models to realize this sequential three-dimensional digital twin. We show that our digital twin outperforms the latest methods of prediction of ventricular volumes in relatively short terms. ",
    "url": "https://arxiv.org/abs/2208.10797",
    "authors": [
      "Hisaichi Shibata",
      "Shouhei Hanaoka",
      "Yukihiro Nomura",
      "Naoto Hayashi",
      "Osamu Abe"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10802",
    "title": "Time-lapse image classification using a diffractive neural network",
    "abstract": "Diffractive deep neural networks (D2NNs) define an all-optical computing framework comprised of spatially engineered passive surfaces that collectively process optical input information by modulating the amplitude and/or the phase of the propagating light. Diffractive optical networks complete their computational tasks at the speed of light propagation through a thin diffractive volume, without any external computing power while exploiting the massive parallelism of optics. Diffractive networks were demonstrated to achieve all-optical classification of objects and perform universal linear transformations. Here we demonstrate, for the first time, a \"time-lapse\" image classification scheme using a diffractive network, significantly advancing its classification accuracy and generalization performance on complex input objects by using the lateral movements of the input objects and/or the diffractive network, relative to each other. In a different context, such relative movements of the objects and/or the camera are routinely being used for image super-resolution applications; inspired by their success, we designed a time-lapse diffractive network to benefit from the complementary information content created by controlled or random lateral shifts. We numerically explored the design space and performance limits of time-lapse diffractive networks, revealing a blind testing accuracy of 62.03% on the optical classification of objects from the CIFAR-10 dataset. This constitutes the highest inference accuracy achieved so far using a single diffractive network on the CIFAR-10 dataset. Time-lapse diffractive networks will be broadly useful for the spatio-temporal analysis of input signals using all-optical processors. ",
    "url": "https://arxiv.org/abs/2208.10802",
    "authors": [
      "Md Sadman Sakib Rahman",
      "Aydogan Ozcan"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2208.10893",
    "title": "Transfer Learning Application of Self-supervised Learning in ARPES",
    "abstract": "Recent development in angle-resolved photoemission spectroscopy (ARPES) technique involves spatially resolving samples while maintaining the high-resolution feature of momentum space. This development easily expands the data size and its complexity for data analysis, where one of it is to label similar dispersion cuts and map them spatially. In this work, we demonstrate that the recent development in representational learning (self-supervised learning) model combined with k-means clustering can help automate that part of data analysis and save precious time, albeit with low performance. Finally, we introduce a few-shot learning (k-nearest neighbour or kNN) in representational space where we selectively choose one (k=1) image reference for each known label and subsequently label the rest of the data with respect to the nearest reference image. This last approach demonstrates the strength of the self-supervised learning to automate the image analysis in ARPES in particular and can be generalized into any science data analysis that heavily involves image data. ",
    "url": "https://arxiv.org/abs/2208.10893",
    "authors": [
      "Sandy Adhitia Ekahana",
      "Genta Indra Winata",
      "Y. Soh",
      "Gabriel Aeppli",
      "Radovic Milan",
      "Ming Shi"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2208.10962",
    "title": "Prediction of good reaction coordinates and future evolution of MD  trajectories using Regularized Sparse Autoencoders: A novel deep learning  approach",
    "abstract": "Identifying reaction coordinates(RCs) is an active area of research, given the crucial role RCs play in determining the progress of a chemical reaction. The choice of the reaction coordinate is often based on heuristic knowledge. However, an essential criterion for the choice is that the coordinate should capture both the reactant and product states unequivocally. Also, the coordinate should be the slowest one so that all the other degrees of freedom can easily equilibrate along the reaction coordinate. Also, the coordinate should be the slowest one so that all the other degrees of freedom can easily equilibrate along the reaction coordinate. We used a regularised sparse autoencoder, an energy-based model, to discover a crucial set of reaction coordinates. Along with discovering reaction coordinates, our model also predicts the evolution of a molecular dynamics(MD) trajectory. We showcased that including sparsity enforcing regularisation helps in choosing a small but important set of reaction coordinates. We used two model systems to demonstrate our approach: alanine dipeptide system and proflavine and DNA system, which exhibited intercalation of proflavine into DNA minor groove in an aqueous environment. We model MD trajectory as a multivariate time series, and our latent variable model performs the task of multi-step time series prediction. This idea is inspired by the popular sparse coding approach - to represent each input sample as a linear combination of few elements taken from a set of representative patterns. ",
    "url": "https://arxiv.org/abs/2208.10962",
    "authors": [
      "Abhijit Gupta",
      "Arnab Mukherjee"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2208.10984",
    "title": "ULISSE: A Tool for One-shot Sky Exploration and its Application to  Active Galactic Nuclei Detection",
    "abstract": "Modern sky surveys are producing ever larger amounts of observational data, which makes the application of classical approaches for the classification and analysis of objects challenging and time-consuming. However, this issue may be significantly mitigated by the application of automatic machine and deep learning methods. We propose ULISSE, a new deep learning tool that, starting from a single prototype object, is capable of identifying objects sharing the same morphological and photometric properties, and hence of creating a list of candidate sosia. In this work, we focus on applying our method to the detection of AGN candidates in a Sloan Digital Sky Survey galaxy sample, since the identification and classification of Active Galactic Nuclei (AGN) in the optical band still remains a challenging task in extragalactic astronomy. Intended for the initial exploration of large sky surveys, ULISSE directly uses features extracted from the ImageNet dataset to perform a similarity search. The method is capable of rapidly identifying a list of candidates, starting from only a single image of a given prototype, without the need for any time-consuming neural network training. Our experiments show ULISSE is able to identify AGN candidates based on a combination of host galaxy morphology, color and the presence of a central nuclear source, with a retrieval efficiency ranging from 21% to 65% (including composite sources) depending on the prototype, where the random guess baseline is 12%. We find ULISSE to be most effective in retrieving AGN in early-type host galaxies, as opposed to prototypes with spiral- or late-type properties. Based on the results described in this work, ULISSE can be a promising tool for selecting different types of astrophysical objects in current and future wide-field surveys (e.g. Euclid, LSST etc.) that target millions of sources every single night. ",
    "url": "https://arxiv.org/abs/2208.10984",
    "authors": [
      "Lars Doorenbos",
      "Olena Torbaniuk",
      "Stefano Cavuoti",
      "Maurizio Paolillo",
      "Giuseppe Longo",
      "Massimo Brescia",
      "Raphael Sznitman",
      "Pablo M\u00e1rquez-Neila"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.11030",
    "title": "Link prediction with continuous-time classical and quantum walks",
    "abstract": "Protein-protein interaction (PPI) networks consist of the physical and/or functional interactions between the proteins of an organism. Since the biophysical and high-throughput methods used to form PPI networks are expensive, time-consuming, and often contain inaccuracies, the resulting networks are usually incomplete. In order to infer missing interactions in these networks, we propose a novel class of link prediction methods based on continuous-time classical and quantum random walks. In the case of quantum walks, we examine the usage of both the network adjacency and Laplacian matrices for controlling the walk dynamics. We define a score function based on the corresponding transition probabilities and perform tests on four real-world PPI datasets. Our results show that continuous-time classical random walks and quantum walks using the network adjacency matrix can successfully predict missing protein-protein interactions, with performance rivalling the state of the art. ",
    "url": "https://arxiv.org/abs/2208.11030",
    "authors": [
      "Mark Goldsmith",
      "Guillermo Garc\u00eda-P\u00e9rez",
      "Joonas Malmi",
      "Matteo A. C. Rossi",
      "Harto Saarinen",
      "Sabrina Maniscalco"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2208.11087",
    "title": "Locally temporal-spatial pattern learning with graph attention mechanism  for EEG-based emotion recognition",
    "abstract": "Technique of emotion recognition enables computers to classify human affective states into discrete categories. However, the emotion may fluctuate instead of maintaining a stable state even within a short time interval. There is also a difficulty to take the full use of the EEG spatial distribution due to its 3-D topology structure. To tackle the above issues, we proposed a locally temporal-spatial pattern learning graph attention network (LTS-GAT) in the present study. In the LTS-GAT, a divide-and-conquer scheme was used to examine local information on temporal and spatial dimensions of EEG patterns based on the graph attention mechanism. A dynamical domain discriminator was added to improve the robustness against inter-individual variations of the EEG statistics to learn robust EEG feature representations across different participants. We evaluated the LTS-GAT on two public datasets for affective computing studies under individual-dependent and independent paradigms. The effectiveness of LTS-GAT model was demonstrated when compared to other existing mainstream methods. Moreover, visualization methods were used to illustrate the relations of different brain regions and emotion recognition. Meanwhile, the weights of different time segments were also visualized to investigate emotion sparsity problems. ",
    "url": "https://arxiv.org/abs/2208.11087",
    "authors": [
      "Yiwen Zhu",
      "Kaiyu Gan",
      "Zhong Yin"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.11119",
    "title": "Limits of Entrainment of Circadian Neuronal Networks",
    "abstract": "Circadian rhythmicity lies at the center of various important physiological and behavioral processes in mammals, such as sleep, metabolism, homeostasis, mood changes and more. It has been shown that this rhythm arises from self-sustained biomolecular oscillations of a neuronal network located in the Suprachiasmatic Nucleus (SCN). Under normal circumstances, this network remains synchronized to the day-night cycle due to signaling from the retina. Misalignment of these neuronal oscillations with the external light signal can disrupt numerous physiological functions and take a long-lasting toll on health and well-being. In this work, we study a modern computational neuroscience model to determine the limits of circadian synchronization to external light signals of different frequency and duty cycle. We employ a matrix-free approach to locate periodic steady states of the high-dimensional model for various driving conditions. Our algorithmic pipeline enables numerical continuation and construction of bifurcation diagrams w.r.t. forcing parameters. We computationally explore the effect of heterogeneity in the circadian neuronal network, as well as the effect of corrective therapeutic interventions, such as that of the drug molecule Longdaysin. Lastly, we employ unsupervised learning to construct a data-driven embedding space for representing neuronal heterogeneity. ",
    "url": "https://arxiv.org/abs/2208.11119",
    "authors": [
      "Yorgos M. Psarellis",
      "Michail Kavousanakis",
      "Michael A. Henson",
      "Ioannis G. Kevrekidis"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2002.08838",
    "title": "On the Decision Boundaries of Neural Networks: A Tropical Geometry  Perspective",
    "abstract": " Comments: First two authors contributed equally to this work ",
    "url": "https://arxiv.org/abs/2002.08838",
    "authors": [
      "Motasem Alfarra",
      "Adel Bibi",
      "Hasan Hammoud",
      "Mohamed Gaafar",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2007.14596",
    "title": "The Contact and Mobility Networks of Mexico City",
    "abstract": " Title: The Contact and Mobility Networks of Mexico City ",
    "url": "https://arxiv.org/abs/2007.14596",
    "authors": [
      "Guillermo de Anda-J\u00e1uregui",
      "Plinio Guzm\u00e1n",
      "Oscar Fontanelli",
      "Amilcar Meneses",
      "Alfredo Hern\u00e1ndez",
      "Janeth de Anda-Gil",
      "Marisol Flores Garrido",
      "Maribel Hern\u00e1ndez-Rosales"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2010.02556",
    "title": "SHERLock: Self-Supervised Hierarchical Event Representation Learning",
    "abstract": " Comments: Accepted at ICPR '22 ",
    "url": "https://arxiv.org/abs/2010.02556",
    "authors": [
      "Sumegh Roychowdhury",
      "Sumedh A. Sontakke",
      "Nikaash Puri",
      "Mausoom Sarkar",
      "Milan Aggarwal",
      "Pinkesh Badjatiya",
      "Balaji Krishnamurthy",
      "Laurent Itti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2105.01563",
    "title": "Fusing Higher-order Features in Graph Neural Networks for Skeleton-based  Action Recognition",
    "abstract": " Comments: Accepted by IEEE Transactions on Neural Networks and Learning Systems ",
    "url": "https://arxiv.org/abs/2105.01563",
    "authors": [
      "Zhenyue Qin",
      "Yang Liu",
      "Pan Ji",
      "Dongwoo Kim",
      "Lei Wang",
      "Bob McKay",
      "Saeed Anwar",
      "Tom Gedeon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.08675",
    "title": "The Computational Complexity of ReLU Network Training Parameterized by  Data Dimensionality",
    "abstract": " Title: The Computational Complexity of ReLU Network Training Parameterized by  Data Dimensionality ",
    "url": "https://arxiv.org/abs/2105.08675",
    "authors": [
      "Vincent Froese",
      "Christoph Hertrich",
      "Rolf Niedermeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2108.09015",
    "title": "Complete Traceability Multimedia Fingerprinting Codes Resistant to  Averaging Attack and Adversarial Noise with Optimal Rate",
    "abstract": " Title: Complete Traceability Multimedia Fingerprinting Codes Resistant to  Averaging Attack and Adversarial Noise with Optimal Rate ",
    "url": "https://arxiv.org/abs/2108.09015",
    "authors": [
      "Ilya Vorobyev"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2109.12298",
    "title": "Opacus: User-Friendly Differential Privacy Library in PyTorch",
    "abstract": " Comments: Privacy in Machine Learning (PriML) workshop, NeurIPS 2021 ",
    "url": "https://arxiv.org/abs/2109.12298",
    "authors": [
      "Ashkan Yousefpour",
      "Igor Shilov",
      "Alexandre Sablayrolles",
      "Davide Testuggine",
      "Karthik Prasad",
      "Mani Malek",
      "John Nguyen",
      "Sayan Ghosh",
      "Akash Bharadwaj",
      "Jessica Zhao",
      "Graham Cormode",
      "Ilya Mironov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2109.13098",
    "title": "One-Hot Graph Encoder Embedding",
    "abstract": " Comments: 7 pages main + 7 pages appendix ",
    "url": "https://arxiv.org/abs/2109.13098",
    "authors": [
      "Cencheng Shen",
      "Qizhe Wang",
      "Carey E. Priebe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.04414",
    "title": "Gated recurrent units and temporal convolutional network for multilabel  classification",
    "abstract": " Title: Gated recurrent units and temporal convolutional network for multilabel  classification ",
    "url": "https://arxiv.org/abs/2110.04414",
    "authors": [
      "Loris Nanni",
      "Alessandra Lumini",
      "Alessandro Manfe",
      "Riccardo Rampon",
      "Sheryl Brahnam",
      "Giorgio Venturin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.06800",
    "title": "SGD-X: A Benchmark for Robust Generalization in Schema-Guided Dialogue  Systems",
    "abstract": " Comments: AAAI 2022 ",
    "url": "https://arxiv.org/abs/2110.06800",
    "authors": [
      "Harrison Lee",
      "Raghav Gupta",
      "Abhinav Rastogi",
      "Yuan Cao",
      "Bin Zhang",
      "Yonghui Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2110.12661",
    "title": "ZerO Initialization: Initializing Residual Networks with only Zeros and  Ones",
    "abstract": " Title: ZerO Initialization: Initializing Residual Networks with only Zeros and  Ones ",
    "url": "https://arxiv.org/abs/2110.12661",
    "authors": [
      "Jiawei Zhao",
      "Florian Sch\u00e4fer",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.14711",
    "title": "A Survey of Self-Supervised and Few-Shot Object Detection",
    "abstract": " Comments: To appear in IEEE Transactions on Pattern Analysis and Machine Intelligence. Awesome Few-Shot Object Detection (Leaderboard) at this https URL ",
    "url": "https://arxiv.org/abs/2110.14711",
    "authors": [
      "Gabriel Huang",
      "Issam Laradji",
      "David Vazquez",
      "Simon Lacoste-Julien",
      "Pau Rodriguez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.03950",
    "title": "Kernel Methods for Multistage Causal Inference: Mediation Analysis and  Dynamic Treatment Effects",
    "abstract": " Comments: 88 pages. Material in this draft previously appeared in a working paper presented at the 2020 NeurIPS Workshop on ML for Economic Policy (arXiv:2010.04855v1). We have divided the original working paper (arXiv:2010.04855v1) into two projects: one paper focusing on static settings (arXiv:2010.04855) and this paper focusing on dynamic settings ",
    "url": "https://arxiv.org/abs/2111.03950",
    "authors": [
      "Rahul Singh",
      "Liyuan Xu",
      "Arthur Gretton"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.12527",
    "title": "MorphMLP: An Efficient MLP-Like Backbone for Spatial-Temporal  Representation Learning",
    "abstract": " Comments: ECCV2022 ",
    "url": "https://arxiv.org/abs/2111.12527",
    "authors": [
      "David Junhao Zhang",
      "Kunchang Li",
      "Yali Wang",
      "Yunpeng Chen",
      "Shashwat Chandra",
      "Yu Qiao",
      "Luoqi Liu",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.14625",
    "title": "Cyclic Graph Attentive Match Encoder (CGAME): A Novel Neural Network For  OD Estimation",
    "abstract": " Title: Cyclic Graph Attentive Match Encoder (CGAME): A Novel Neural Network For  OD Estimation ",
    "url": "https://arxiv.org/abs/2111.14625",
    "authors": [
      "Guanzhou Li",
      "Yujing He",
      "Jianping Wu",
      "Duowei Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.06300",
    "title": "Scalable and Conservative Continuous Collision Detection for Parallel  Architectures",
    "abstract": " Title: Scalable and Conservative Continuous Collision Detection for Parallel  Architectures ",
    "url": "https://arxiv.org/abs/2112.06300",
    "authors": [
      "David Belgrod",
      "Bolun Wang",
      "Zachary Ferguson",
      "Marco Attene",
      "Daniele Panozzo",
      "Teseo Schneider"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2201.00378",
    "title": "Graph Signal Reconstruction Techniques for IoT Air Pollution Monitoring  Platforms",
    "abstract": " Comments: Accepted in IEEE Internet of Things Journal ",
    "url": "https://arxiv.org/abs/2201.00378",
    "authors": [
      "Pau Ferrer-Cid",
      "Jose M. Barcelo-Ordinas",
      "Jorge Garcia-Vidal"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2201.09700",
    "title": "Feature transforms for image data augmentation",
    "abstract": " Title: Feature transforms for image data augmentation ",
    "url": "https://arxiv.org/abs/2201.09700",
    "authors": [
      "Loris Nanni",
      "Michelangelo Paci",
      "Sheryl Brahnam",
      "Alessandra Lumini"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.01897",
    "title": "AtmoDist: Self-supervised Representation Learning for Atmospheric  Dynamics",
    "abstract": " Comments: Submitted to \"Environmental Data Science\", Cambridge University Press. Revised version. Journal-version of \"Towards Representation Learning for Atmospheric Dynamics. arXiv:2109.09076\" ",
    "url": "https://arxiv.org/abs/2202.01897",
    "authors": [
      "Sebastian Hoffmann",
      "Christian Lessig"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.06764",
    "title": "TurbuGAN: An Adversarial Learning Approach to Spatially-Varying  Multiframe Blind Deconvolution with Applications to Imaging Through  Turbulence",
    "abstract": " Title: TurbuGAN: An Adversarial Learning Approach to Spatially-Varying  Multiframe Blind Deconvolution with Applications to Imaging Through  Turbulence ",
    "url": "https://arxiv.org/abs/2203.06764",
    "authors": [
      "Brandon Yushan Feng",
      "Mingyang Xie",
      "Christopher A. Metzler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.15722",
    "title": "Transformer Network-based Reinforcement Learning Method for Power  Distribution Network (PDN) Optimization of High Bandwidth Memory (HBM)",
    "abstract": " Comments: 15 pages, 14 figures, Under review as a journal paper at IEEE Transactions on Microwave and Theory and Techniques (TMTT) Fig. 10 revised; Fig. 14 added ",
    "url": "https://arxiv.org/abs/2203.15722",
    "authors": [
      "Hyunwook Park",
      "Minsu Kim",
      "Seongguk Kim",
      "Keunwoo Kim",
      "Haeyeon Kim",
      "Taein Shin",
      "Keeyoung Son",
      "Boogyo Sim",
      "Subin Kim",
      "Seungtaek Jeong",
      "Chulsoon Hwang",
      "Joungho Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.17031",
    "title": "Adversarial Speaker Distillation for Countermeasure Model on Automatic  Speaker Verification",
    "abstract": " Comments: Accepted by ISCA SPSC 2022 ",
    "url": "https://arxiv.org/abs/2203.17031",
    "authors": [
      "Yen-Lun Liao",
      "Xuanjun Chen",
      "Chung-Che Wang",
      "Jyh-Shing Roger Jang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.01397",
    "title": "Data Determines Distributional Robustness in Contrastive Language Image  Pre-training (CLIP)",
    "abstract": " Title: Data Determines Distributional Robustness in Contrastive Language Image  Pre-training (CLIP) ",
    "url": "https://arxiv.org/abs/2205.01397",
    "authors": [
      "Alex Fang",
      "Gabriel Ilharco",
      "Mitchell Wortsman",
      "Yuhao Wan",
      "Vaishaal Shankar",
      "Achal Dave",
      "Ludwig Schmidt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01945",
    "title": "Optimal Network Charge for Peer-to-Peer Energy Trading: A Grid  Perspective",
    "abstract": " Comments: 12 pages, 16 figures ",
    "url": "https://arxiv.org/abs/2205.01945",
    "authors": [
      "Yu Yang",
      "Yue Chen",
      "Guoqiang Hu",
      "Costas J. Spanos"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2205.02996",
    "title": "Multi-view Point Cloud Registration based on Evolutionary Multitasking  with Bi-Channel Knowledge Sharing Mechanism",
    "abstract": " Title: Multi-view Point Cloud Registration based on Evolutionary Multitasking  with Bi-Channel Knowledge Sharing Mechanism ",
    "url": "https://arxiv.org/abs/2205.02996",
    "authors": [
      "Yue Wu",
      "Yibo Liu",
      "Maoguo Gong",
      "Peiran Gong",
      "Hao Li",
      "Zedong Tang",
      "Qiguang Miao",
      "Wenping Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.04944",
    "title": "Hybrid Far- and Near-Field Channel Estimation for THz Ultra-Massive MIMO  via Fixed Point Networks",
    "abstract": " Comments: 6 pages, 3 figures, accepted by IEEE Globecom 2022 ",
    "url": "https://arxiv.org/abs/2205.04944",
    "authors": [
      "Wentao Yu",
      "Yifei Shen",
      "Hengtao He",
      "Xianghao Yu",
      "Jun Zhang",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.06661",
    "title": "FLAD: Adaptive Federated Learning for DDoS Attack Detection",
    "abstract": " Title: FLAD: Adaptive Federated Learning for DDoS Attack Detection ",
    "url": "https://arxiv.org/abs/2205.06661",
    "authors": [
      "Roberto Doriguzzi-Corin",
      "Domenico Siracusa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.07864",
    "title": "Privacy Enhancement for Cloud-Based Few-Shot Learning",
    "abstract": " Comments: 14 pages, 13 figures, 3 tables. Preprint. Accepted in IEEE WCCI 2022 International Joint Conference on Neural Networks (IJCNN) ",
    "url": "https://arxiv.org/abs/2205.07864",
    "authors": [
      "Archit Parnami",
      "Muhammad Usama",
      "Liyue Fan",
      "Minwoo Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.09612",
    "title": "CLCNet: Rethinking of Ensemble Modeling with Classification Confidence  Network",
    "abstract": " Title: CLCNet: Rethinking of Ensemble Modeling with Classification Confidence  Network ",
    "url": "https://arxiv.org/abs/2205.09612",
    "authors": [
      "Yao-Ching Yu",
      "Shi-Jinn Horng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10122",
    "title": "Stochastic resonance neurons in artificial neural networks",
    "abstract": " Title: Stochastic resonance neurons in artificial neural networks ",
    "url": "https://arxiv.org/abs/2205.10122",
    "authors": [
      "Egor Manuylovich",
      "Diego Arg\u00fcello Ron",
      "Morteza Kamalian-Kopae",
      "Sergei Turitsyn"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2205.10940",
    "title": "Toward smart composites: small-scale, untethered prediction and control  for soft sensor/actuator systems",
    "abstract": " Comments: Accepted for publication at the Journal of Composite Materials. Special Issue: Multifunctional Composites for Autonomic, Adaptive and Self-Sustaining Systems ",
    "url": "https://arxiv.org/abs/2205.10940",
    "authors": [
      "Sarah Aguasvivas Manzano",
      "Vani Sundaram",
      "Artemis Xu",
      "Khoi Ly",
      "Mark Rentschler",
      "Robert Shepherd",
      "Nikolaus Correll"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13253",
    "title": "MALICE: Manipulation Attacks on Learned Image ComprEssion",
    "abstract": " Title: MALICE: Manipulation Attacks on Learned Image ComprEssion ",
    "url": "https://arxiv.org/abs/2205.13253",
    "authors": [
      "Kang Liu",
      "Di Wu",
      "Yiru Wang",
      "Dan Feng",
      "Benjamin Tan",
      "Siddharth Garg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14887",
    "title": "Deep Posterior Distribution-based Embedding for Hyperspectral Image  Super-resolution",
    "abstract": " Comments: Accepted by IEEE Transactions on Image Processing ",
    "url": "https://arxiv.org/abs/2205.14887",
    "authors": [
      "Jinhui Hou",
      "Zhiyu Zhu",
      "Junhui Hou",
      "Huanqiang Zeng",
      "Jinjian Wu",
      "Jiantao Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.00162",
    "title": "PAGER: Progressive Attribute-Guided Extendable Robust Image Generation",
    "abstract": " Comments: 19 pages, 12 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2206.00162",
    "authors": [
      "Zohreh Azizi",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.03111",
    "title": "Medical Image Registration via Neural Fields",
    "abstract": " Title: Medical Image Registration via Neural Fields ",
    "url": "https://arxiv.org/abs/2206.03111",
    "authors": [
      "Shanlin Sun",
      "Kun Han",
      "Hao Tang",
      "Deying Kong",
      "Junayed Naushad",
      "Xiangyi Yan",
      "Xiaohui Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09280",
    "title": "AutoGML: Fast Automatic Model Selection for Graph Machine Learning",
    "abstract": " Title: AutoGML: Fast Automatic Model Selection for Graph Machine Learning ",
    "url": "https://arxiv.org/abs/2206.09280",
    "authors": [
      "Namyong Park",
      "Ryan Rossi",
      "Nesreen Ahmed",
      "Christos Faloutsos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.14282",
    "title": "Neural Integro-Differential Equations",
    "abstract": " Comments: 18 pages (including 8 pages Appendix), 8 figures and 6 tables. Comments are welcome! ",
    "url": "https://arxiv.org/abs/2206.14282",
    "authors": [
      "Emanuele Zappala",
      "Antonio Henrique de Oliveira Fonseca",
      "Andrew Henry Moberly",
      "Michael James Higley",
      "Chadi Abdallah",
      "Jessica Cardin",
      "David van Dijk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00741",
    "title": "A Distributionally Robust Resilience Enhancement Strategy for  Distribution Networks Considering Decision-Dependent Contingencies",
    "abstract": " Title: A Distributionally Robust Resilience Enhancement Strategy for  Distribution Networks Considering Decision-Dependent Contingencies ",
    "url": "https://arxiv.org/abs/2207.00741",
    "authors": [
      "Yujia Li",
      "Shunbo Lei",
      "Wei Sun",
      "Chenxi Hu",
      "Yunhe Hou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.06847",
    "title": "Covy: An AI-powered Robot with a Compound Vision System for Detecting  Breaches in Social Distancing",
    "abstract": " Title: Covy: An AI-powered Robot with a Compound Vision System for Detecting  Breaches in Social Distancing ",
    "url": "https://arxiv.org/abs/2207.06847",
    "authors": [
      "Serge Saaybi",
      "Amjad Yousef Majid",
      "R Venkatesha Prasad",
      "Anis Koubaa",
      "Chris Verhoeven"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.02178",
    "title": "KD-SCFNet: Towards More Accurate and Efficient Salient Object Detection  via Knowledge Distillation",
    "abstract": " Comments: The article was published in error, and the article contained an incorrect description ",
    "url": "https://arxiv.org/abs/2208.02178",
    "authors": [
      "Jin Zhang",
      "Qiuwei Liang",
      "Yanjiao Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.04226",
    "title": "SKDCGN: Source-free Knowledge Distillation of Counterfactual Generative  Networks using cGANs",
    "abstract": " Comments: Accepted at ECCV 2022 Workshop VIPriors ",
    "url": "https://arxiv.org/abs/2208.04226",
    "authors": [
      "Sameer Ambekar",
      "Matteo Tafuro",
      "Ankit Ankit",
      "Diego van der Mast",
      "Mark Alence",
      "Christos Athanasiadis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.05785",
    "title": "Neural Mesh-Based Graphics",
    "abstract": " Comments: ECCV Workshop 2022 CV4Metaverse. The source code and trained models can be obtained at this https URL ",
    "url": "https://arxiv.org/abs/2208.05785",
    "authors": [
      "Shubhendu Jena",
      "Franck Multon",
      "Adnane Boukhayma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.06384",
    "title": "Ensembles of Realistic Power Distribution Networks",
    "abstract": " Title: Ensembles of Realistic Power Distribution Networks ",
    "url": "https://arxiv.org/abs/2208.06384",
    "authors": [
      "Rounak Meyur",
      "Anil Vullikanti",
      "Samarth Swarup",
      "Henning Mortveit",
      "Virgilio Centeno",
      "Arun Phadke",
      "H. Vincent Poor",
      "Madhav Marathe"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.07841",
    "title": "OrthoMAD: Morphing Attack Detection Through Orthogonal Identity  Disentanglement",
    "abstract": " Comments: Accepted at BIOSIG 2022 ",
    "url": "https://arxiv.org/abs/2208.07841",
    "authors": [
      "Pedro C. Neto",
      "Tiago Gon\u00e7alves",
      "Marco Huber",
      "Naser Damer",
      "Ana F. Sequeira",
      "Jaime S. Cardoso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.08085",
    "title": "Efficient Detection and Filtering Systems for Distributed Training",
    "abstract": " Comments: 18 pages, 14 figures, 6 tables. The material in this work appeared in part at arXiv:2108.02416 which has been published at the 2022 IEEE International Symposium on Information Theory ",
    "url": "https://arxiv.org/abs/2208.08085",
    "authors": [
      "Konstantinos Konstantinidis",
      "Aditya Ramamoorthy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2208.08094",
    "title": "SelF-Eval: Self-supervised Fine-grained Dialogue Evaluation",
    "abstract": " Comments: 11 pages, 2 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2208.08094",
    "authors": [
      "Longxuan Ma",
      "Ziyu Zhuang",
      "Weinan Zhang",
      "Mingda Li",
      "Ting Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2208.08138",
    "title": "Shallow neural network representation of polynomials",
    "abstract": " Title: Shallow neural network representation of polynomials ",
    "url": "https://arxiv.org/abs/2208.08138",
    "authors": [
      "Aleksandr Beknazaryan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.09316",
    "title": "UKP-SQuARE v2 Explainability and Adversarial Attacks for Trustworthy QA",
    "abstract": " Title: UKP-SQuARE v2 Explainability and Adversarial Attacks for Trustworthy QA ",
    "url": "https://arxiv.org/abs/2208.09316",
    "authors": [
      "Rachneet Sachdeva",
      "Haritz Puerto",
      "Tim Baumg\u00e4rtner",
      "Sewin Tariverdian",
      "Hao Zhang",
      "Kexin Wang",
      "Hossain Shaikh Saadi",
      "Leonardo F. R. Ribeiro",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2208.09349",
    "title": "DCNNV-19: A Deep Convolutional Neural Network for COVID-19 Detection in  Chest Computed Tomographies",
    "abstract": " Comments: 17 pages, English version ",
    "url": "https://arxiv.org/abs/2208.09349",
    "authors": [
      "Victor Felipe Reis-Silva"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.09929",
    "title": "A Survey of Augmented Piano Prototypes: Has Augmentation Improved  Learning Experiences?",
    "abstract": " Comments: 28 pages, 5 figures, 3 tables, Proceedings of ISS'22 ",
    "url": "https://arxiv.org/abs/2208.09929",
    "authors": [
      "Jordan Aiko Deja",
      "Sven Mayer",
      "Klen \u010copi\u010d Pucihar",
      "Matja\u017e Kljun"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2208.09944",
    "title": "MolGraph: a Python package for the implementation of small molecular  graphs and graph neural networks with TensorFlow and Keras",
    "abstract": " Comments: 19 pages, 4 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2208.09944",
    "authors": [
      "Alexander Kensert",
      "Gert Desmet",
      "Deirdre Cabooter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2208.10056",
    "title": "Minkowski Tracker: A Sparse Spatio-Temporal R-CNN for Joint Object  Detection and Tracking",
    "abstract": " Title: Minkowski Tracker: A Sparse Spatio-Temporal R-CNN for Joint Object  Detection and Tracking ",
    "url": "https://arxiv.org/abs/2208.10056",
    "authors": [
      "JunYoung Gwak",
      "Silvio Savarese",
      "Jeannette Bohg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10091",
    "title": "Incorporating Domain Knowledge through Task Augmentation for Front-End  JavaScript Code Generation",
    "abstract": " Comments: This paper has been accepted at ESEC/FSE 2022 Industry Track ",
    "url": "https://arxiv.org/abs/2208.10091",
    "authors": [
      "Sijie Shen",
      "Xiang Zhu",
      "Yihong Dong",
      "Qizhi Guo",
      "Yankun Zhen",
      "Ge Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.10387",
    "title": "Constants of motion network",
    "abstract": " Title: Constants of motion network ",
    "url": "https://arxiv.org/abs/2208.10387",
    "authors": [
      "Muhammad Firmansyah Kasim",
      "Yi Heng Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Classical Physics (physics.class-ph)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2208.10423",
    "title": "Graph Connectivity with Noisy Queries",
    "abstract": " Comments: 22 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2208.10423",
    "authors": [
      "Dimitris Fotakis",
      "Evangelia Gergatsouli",
      "Charilaos Pipis",
      "Miltiadis Stouras",
      "Christos Tzamos"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  }
]