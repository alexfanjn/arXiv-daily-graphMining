[
  {
    "id": "arXiv:2202.02319",
    "title": "An integrated heterogeneous computing framework for ensemble simulations  of laser-induced ignition",
    "abstract": "An integrated computational framework is introduced to study complex engineering systems through physics-based ensemble simulations on heterogeneous supercomputers. The framework is primarily designed for the quantitative assessment of laser-induced ignition in rocket engines. We develop and combine an implicit programming system, a compressible reacting flow solver, and a data generation/management strategy on a robust and portable platform. We systematically present this framework using test problems on a hybrid CPU/GPU machine. Efficiency, scalability, and accuracy of the solver are comprehensively assessed with canonical unit problems. Ensemble data management and autoencoding are demonstrated using a canonical diffusion flame case. Sensitivity analysis of the ignition of a turbulent, gaseous fuel jet is performed using a simplified, three-dimensional model combustor. Our approach unifies computer science, physics and engineering, and data science to realize a cross-disciplinary workflow. The framework is exascale-oriented and can be considered a benchmark for future computational science studies of real-world systems. ",
    "url": "https://arxiv.org/abs/2202.02319",
    "authors": [
      "Kazuki Maeda",
      "Thiago Teixeira",
      "Jonathan M. Wang",
      "Jeffrey M. Hokanson",
      "Caetano Melone",
      "Mario Di Renzo",
      "Steve Jones",
      "Javier Urzay",
      "Gianluca Iaccarino"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2202.02340",
    "title": "Selective Network Linearization for Efficient Private Inference",
    "abstract": "Private inference (PI) enables inference directly on cryptographically secure data. While promising to address many privacy issues, it has seen limited use due to extreme runtimes. Unlike plaintext inference, where latency is dominated by FLOPs, in PI non-linear functions (namely ReLU) are the bottleneck. Thus, practical PI demands novel ReLU-aware optimizations. To reduce PI latency we propose a gradient-based algorithm that selectively linearizes ReLUs while maintaining prediction accuracy. We evaluate our algorithm on several standard PI benchmarks. The results demonstrate up to $4.25\\%$ more accuracy (iso-ReLU count at 50K) or $2.2\\times$ less latency (iso-accuracy at 70\\%) than the current state of the art and advance the Pareto frontier across the latency-accuracy space. To complement empirical results, we present a \"no free lunch\" theorem that sheds light on how and when network linearization is possible while maintaining prediction accuracy. ",
    "url": "https://arxiv.org/abs/2202.02340",
    "authors": [
      "Minsu Cho",
      "Ameya Joshi",
      "Siddharth Garg",
      "Brandon Reagen",
      "Chinmay Hegde"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02349",
    "title": "Analysis of Independent Learning in Network Agents: A Packet Forwarding  Use Case",
    "abstract": "Multi-Agent Reinforcement Learning (MARL) is nowadays widely used to solve real-world and complex decisions in various domains. While MARL can be categorized into independent and cooperative approaches, we consider the independent approach as a simple, more scalable, and less costly method for large-scale distributed systems, such as network packet forwarding. In this paper, we quantitatively and qualitatively assess the benefits of leveraging such independent agents learning approach, in particular IQL-based algorithm, for packet forwarding in computer networking, using the Named Data Networking (NDN) architecture as a driving example. We put multiple IQL-based forwarding strategies (IDQF) to the test and compare their performances against very basic forwarding schemes and simple topologies/traffic models to highlight major challenges and issues. We discuss the main issues related to the poor performance of IDQF and quantify the impact of these issues on isolation when training and testing the IDQF models under different model tuning parameters and network topologies/characteristics. ",
    "url": "https://arxiv.org/abs/2202.02349",
    "authors": [
      "Abu Saleh Md Tayeen",
      "Milan Biswal",
      "Abderrahmen Mtibaa",
      "Satyajayant Misra"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2202.02354",
    "title": "A note on the complex and bicomplex valued neural networks",
    "abstract": "In this paper we first write a proof of the perceptron convergence algorithm for the complex multivalued neural networks (CMVNNs). Our primary goal is to formulate and prove the perceptron convergence algorithm for the bicomplex multivalued neural networks (BMVNNs) and other important results in the theory of neural networks based on a bicomplex algebra. ",
    "url": "https://arxiv.org/abs/2202.02354",
    "authors": [
      "Daniel Alpay",
      "Kamal Diki",
      "Mihaela Vajiac"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2202.02361",
    "title": "A Fast Network Exploration Strategy to Profile Low Energy Consumption  for Keyword Spotting",
    "abstract": "Keyword Spotting nowadays is an integral part of speech-oriented user interaction targeted for smart devices. To this extent, neural networks are extensively used for their flexibility and high accuracy. However, coming up with a suitable configuration for both accuracy requirements and hardware deployment is a challenge. We propose a regression-based network exploration technique that considers the scaling of the network filters ($s$) and quantization ($q$) of the network layers, leading to a friendly and energy-efficient configuration for FPGA hardware implementation. We experiment with different combinations of $\\mathcal{NN}\\scriptstyle\\langle q,\\,s\\rangle \\displaystyle$ on the FPGA to profile the energy consumption of the deployed network so that the user can choose the most energy-efficient network configuration promptly. Our accelerator design is deployed on the Xilinx AC 701 platform and has at least 2.1$\\times$ and 4$\\times$ improvements on energy and energy efficiency results, respectively, compared to recent hardware implementations for keyword spotting. ",
    "url": "https://arxiv.org/abs/2202.02361",
    "authors": [
      "Arnab Neelim Mazumder",
      "Tinoosh Mohsenin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02365",
    "title": "Marius++: Large-Scale Training of Graph Neural Networks on a Single  Machine",
    "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful model for ML over graph-structured data. Yet, scalability remains a major challenge for using GNNs over billion-edge inputs. The creation of mini-batches used for training incurs computational and data movement costs that grow exponentially with the number of GNN layers as state-of-the-art models aggregate information from the multi-hop neighborhood of each input node. In this paper, we focus on scalable training of GNNs with emphasis on resource efficiency. We show that out-of-core pipelined mini-batch training in a single machine outperforms resource-hungry multi-GPU solutions. We introduce Marius++, a system for training GNNs over billion-scale graphs. Marius++ provides disk-optimized training for GNNs and introduces a series of data organization and algorithmic contributions that 1) minimize the memory-footprint and end-to-end time required for training and 2) ensure that models learned with disk-based training exhibit accuracy similar to those fully trained in mixed CPU/GPU settings. We evaluate Marius++ against PyTorch Geometric and Deep Graph Library using seven benchmark (model, data set) settings and find that Marius++ with one GPU can achieve the same level of model accuracy up to 8$\\times$ faster than these systems when they are using up to eight GPUs. For these experiments, disk-based training allows Marius++ deployments to be up to 64$\\times$ cheaper in monetary cost than those of the competing systems. ",
    "url": "https://arxiv.org/abs/2202.02365",
    "authors": [
      "Roger Waleffe",
      "Jason Mohoney",
      "Theodoros Rekatsinas",
      "Shivaram Venkataraman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2202.02385",
    "title": "Using Large-scale Heterogeneous Graph Representation Learning for Code  Review Recommendations",
    "abstract": "Code review is an integral part of any mature software development process, and identifying the best reviewer for a code change is a well accepted problem within the software engineering community. Selecting a reviewer who lacks expertise and understanding can slow development or result in more defects. To date, most reviewer recommendation systems rely primarily on historical file change and review information; those who changed or reviewed a file in the past are the best positioned to review in the future. We posit that while these approaches are able to identify and suggest qualified reviewers, they may be blind to reviewers who have the needed expertise and have simply never interacted with the changed files before. To address this, we present CORAL, a novel approach to reviewer recommendation that leverages a socio-technical graph built from the rich set of entities (developers, repositories, files, pull requests, work-items, etc.) and their relationships in modern source code management systems. We employ a graph convolutional neural network on this graph and train it on two and a half years of history on 332 repositories. We show that CORAL is able to model the manual history of reviewer selection remarkably well. Further, based on an extensive user study, we demonstrate that this approach identifies relevant and qualified reviewers who traditional reviewer recommenders miss, and that these developers desire to be included in the review process. Finally, we find that \"classical\" reviewer recommendation systems perform better on smaller (in terms of developers) software projects while CORAL excels on larger projects, suggesting that there is \"no one model to rule them all.\" ",
    "url": "https://arxiv.org/abs/2202.02385",
    "authors": [
      "Jiyang Zhang",
      "Chandra Maddila",
      "Ram Bairi",
      "Christian Bird",
      "Ujjwal Raizada",
      "Apoorva Agrawal",
      "Yamini Jhawar",
      "Kim Herzig",
      "Arie van Deursen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02394",
    "title": "JARVix at SemEval-2022 Task 2: It Takes One to Know One? Idiomaticity  Detection using Zero and One Shot Learning",
    "abstract": "Large Language Models have been successful in a wide variety of Natural Language Processing tasks by capturing the compositionality of the text representations. In spite of their great success, these vector representations fail to capture meaning of idiomatic multi-word expressions (MWEs). In this paper, we focus on the detection of idiomatic expressions by using binary classification. We use a dataset consisting of the literal and idiomatic usage of MWEs in English and Portuguese. Thereafter, we perform the classification in two different settings: zero shot and one shot, to determine if a given sentence contains an idiom or not. N shot classification for this task is defined by N number of common idioms between the training and testing sets. In this paper, we train multiple Large Language Models in both the settings and achieve an F1 score (macro) of 0.73 for the zero shot setting and an F1 score (macro) of 0.85 for the one shot setting. An implementation of our work can be found at https://github.com/ashwinpathak20/Idiomaticity_Detection_Using_Few_Shot_Learning . ",
    "url": "https://arxiv.org/abs/2202.02394",
    "authors": [
      "Ashwin Pathak",
      "Raj Shah",
      "Vaibhav Kumar",
      "Yash Jakhotiya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02411",
    "title": "A Novel Service Deployment Policy in Fog Computing Considering The  Degree of Availability and Fog Landscape Utilization Using Multiobjective  Evolutionary Algorithms",
    "abstract": "Fog computing is a promising paradigm for real-time and mission-critical Internet of Things (IoT) applications. Regarding the high distribution, heterogeneity, and limitation of fog resources, applications should be placed in a distributed manner to fully utilize these resources. In this paper, we propose a linear formulation for assuring the different availability requirements of application services while maximizing the utilization of fog resources. We also compare three multiobjective evolutionary algorithms, namely MOPSO, NSGA-II, and MOEA/D for a trade-off between the mentioned optimization goals. The evaluation results in the iFogSim simulator demonstrate the efficiency of all three algorithms and a generally better behavior of MOPSO algorithm in terms of obtained objective values, application deadline satisfaction, and execution time. ",
    "url": "https://arxiv.org/abs/2202.02411",
    "authors": [
      "Maryam Eslami",
      "Mehdi Sakhaei"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2202.02415",
    "title": "On the Efficiency and Quality of Protection of Preprovisioning in  Elastic Optical Networks",
    "abstract": "The study of protection techniques, such as pre-provisioning (off-line) and provisioning (on-line), has been explored in several ways in the optical network literature. In the new Elastic Optical Network (EON) paradigm, the pre-provisioning techniques were still little explored. Preprovisioning implies the prior allocation of resources in the network for the transport and protection of future connection demands, while the provisioning implies the allocation of resources when the demand arrives in the network. Applying preprovisioning reduces the downtime experienced by a connection after a failure, which will reduce unavailability and potentially avoid penalties for violation of Service Level Agreements (SLA) established with client networks. This work aims to explore the main protection techniques and evaluate their efficient in the EON scenario. The performance evaluation show that the use of preprovisioning techniques are more efficient, significantly reducing the network unavailability and bandwidth usage in EON networks. Our solution has an unavailability 40 times lower than shared solutions being only 4% above the optimum. ",
    "url": "https://arxiv.org/abs/2202.02415",
    "authors": [
      "Paulo Jos\u00e9 S. J\u00fanior",
      "Lucas R. Costa",
      "Andr\u00e9 C. Drummond"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2202.02429",
    "title": "Verifying Inverse Model Neural Networks",
    "abstract": "Inverse problems exist in a wide variety of physical domains from aerospace engineering to medical imaging. The goal is to infer the underlying state from a set of observations. When the forward model that produced the observations is nonlinear and stochastic, solving the inverse problem is very challenging. Neural networks are an appealing solution for solving inverse problems as they can be trained from noisy data and once trained are computationally efficient to run. However, inverse model neural networks do not have guarantees of correctness built-in, which makes them unreliable for use in safety and accuracy-critical contexts. In this work we introduce a method for verifying the correctness of inverse model neural networks. Our approach is to overapproximate a nonlinear, stochastic forward model with piecewise linear constraints and encode both the overapproximate forward model and the neural network inverse model as a mixed-integer program. We demonstrate this verification procedure on a real-world airplane fuel gauge case study. The ability to verify and consequently trust inverse model neural networks allows their use in a wide variety of contexts, from aerospace to medicine. ",
    "url": "https://arxiv.org/abs/2202.02429",
    "authors": [
      "Chelsea Sidrane",
      "Sydney Katz",
      "Anthony Corso",
      "Mykel J. Kochenderfer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2202.02430",
    "title": "HENRI: High Efficiency Negotiation-based Robust Interface for  Multi-party Multi-issue Negotiation over the Internet",
    "abstract": "This paper proposes a framework for a full fledged negotiation system that allows multi party multi issue negotiation. It focuses on the negotiation protocol to be observed and provides a platform for concurrent and independent negotiation on individual issues using the concept of multi threading. It depicts the architecture of an agent detailing its components. The paper sets forth a hierarchical pattern for the multiple issues concerning every party. The system also provides enhancements such as the time-to-live counters for every advertisement, refinement of utility considering non-functional attributes, prioritization of issues, by assigning weights to issues. ",
    "url": "https://arxiv.org/abs/2202.02430",
    "authors": [
      "Saurabh Deochake",
      "Shashank Kanth",
      "Subhadip Chakraborty",
      "Suresh Sarode",
      "Vidyasagar Potdar",
      "Debajyoti Mukhopadhyay"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2202.02432",
    "title": "Transformers and the representation of biomedical background knowledge",
    "abstract": "BioBERT and BioMegatron are Transformers models adapted for the biomedical domain based on publicly available biomedical corpora. As such, they have the potential to encode large-scale biological knowledge. We investigate the encoding and representation of biological knowledge in these models, and its potential utility to support inference in cancer precision medicine - namely, the interpretation of the clinical significance of genomic alterations. We compare the performance of different transformer baselines; we use probing to determine the consistency of encodings for distinct entities; and we use clustering methods to compare and contrast the internal properties of the embeddings for genes, variants, drugs and diseases. We show that these models do indeed encode biological knowledge, although some of this is lost in fine-tuning for specific tasks. Finally, we analyse how the models behave with regard to biases and imbalances in the dataset. ",
    "url": "https://arxiv.org/abs/2202.02432",
    "authors": [
      "Oskar Wysocki",
      "Zili Zhou",
      "Paul O'Regan",
      "Deborah Ferreira",
      "Magdalena Wysocka",
      "D\u00f3nal Landers",
      "Andr\u00e9 Freitas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02435",
    "title": "On Neural Differential Equations",
    "abstract": "The conjoining of dynamical systems and deep learning has become a topic of great interest. In particular, neural differential equations (NDEs) demonstrate that neural networks and differential equation are two sides of the same coin. Traditional parameterised differential equations are a special case. Many popular neural network architectures, such as residual networks and recurrent networks, are discretisations. NDEs are suitable for tackling generative problems, dynamical systems, and time series (particularly in physics, finance, ...) and are thus of interest to both modern machine learning and traditional mathematical modelling. NDEs offer high-capacity function approximation, strong priors on model space, the ability to handle irregular data, memory efficiency, and a wealth of available theory on both sides. This doctoral thesis provides an in-depth survey of the field. Topics include: neural ordinary differential equations (e.g. for hybrid neural/mechanistic modelling of physical systems); neural controlled differential equations (e.g. for learning functions of irregular time series); and neural stochastic differential equations (e.g. to produce generative models capable of representing complex stochastic dynamics, or sampling from complex high-dimensional distributions). Further topics include: numerical methods for NDEs (e.g. reversible differential equations solvers, backpropagation through differential equations, Brownian reconstruction); symbolic regression for dynamical systems (e.g. via regularised evolution); and deep implicit models (e.g. deep equilibrium models, differentiable optimisation). We anticipate this thesis will be of interest to anyone interested in the marriage of deep learning with dynamical systems, and hope it will provide a useful reference for the current state of the art. ",
    "url": "https://arxiv.org/abs/2202.02435",
    "authors": [
      "Patrick Kidger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Classical Analysis and ODEs (math.CA)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.02436",
    "title": "Neural Logic Analogy Learning",
    "abstract": "Letter-string analogy is an important analogy learning task which seems to be easy for humans but very challenging for machines. The main idea behind current approaches to solving letter-string analogies is to design heuristic rules for extracting analogy structures and constructing analogy mappings. However, one key problem is that it is difficult to build a comprehensive and exhaustive set of analogy structures which can fully describe the subtlety of analogies. This problem makes current approaches unable to handle complicated letter-string analogy problems. In this paper, we propose Neural logic analogy learning (Noan), which is a dynamic neural architecture driven by differentiable logic reasoning to solve analogy problems. Each analogy problem is converted into logical expressions consisting of logical variables and basic logical operations (AND, OR, and NOT). More specifically, Noan learns the logical variables as vector embeddings and learns each logical operation as a neural module. In this way, the model builds computational graph integrating neural network with logical reasoning to capture the internal logical structure of the input letter strings. The analogy learning problem then becomes a True/False evaluation problem of the logical expressions. Experiments show that our machine learning-based Noan approach outperforms state-of-the-art approaches on standard letter-string analogy benchmark datasets. ",
    "url": "https://arxiv.org/abs/2202.02436",
    "authors": [
      "Yujia Fan",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2202.02441",
    "title": "SEED: Sound Event Early Detection via Evidential Uncertainty",
    "abstract": "Sound Event Early Detection (SEED) is an essential task in recognizing the acoustic environments and soundscapes. However, most of the existing methods focus on the offline sound event detection, which suffers from the over-confidence issue of early-stage event detection and usually yield unreliable results. To solve the problem, we propose a novel Polyphonic Evidential Neural Network (PENet) to model the evidential uncertainty of the class probability with Beta distribution. Specifically, we use a Beta distribution to model the distribution of class probabilities, and the evidential uncertainty enriches uncertainty representation with evidence information, which plays a central role in reliable prediction. To further improve the event detection performance, we design the backtrack inference method that utilizes both the forward and backward audio features of an ongoing event. Experiments on the DESED database show that the proposed method can simultaneously improve 13.0\\% and 3.8\\% in time delay and detection F1 score compared to the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2202.02441",
    "authors": [
      "Xujiang Zhao",
      "Xuchao Zhang",
      "Wei Cheng",
      "Wenchao Yu",
      "Yuncong Chen",
      "Haifeng Chen",
      "Feng Chen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2202.02444",
    "title": "Spelunking the Deep: Guaranteed Queries for General Neural Implicit  Surfaces",
    "abstract": "Neural implicit representations, which encode a surface as the level set of a neural network applied to spatial coordinates, have proven to be remarkably effective for optimizing, compressing, and generating 3D geometry. Although these representations are easy to fit, it is not clear how to best evaluate geometric queries on the shape, such as intersecting against a ray or finding a closest point. The predominant approach is to encourage the network to have a signed distance property. However, this property typically holds only approximately, leading to robustness issues, and holds only at the conclusion of training, inhibiting the use of queries in loss functions. Instead, this work presents a new approach to perform queries directly on general neural implicit functions for a wide range of existing architectures. Our key tool is the application of range analysis to neural networks, using automatic arithmetic rules to bound the output of a network over a region; we conduct a study of range analysis on neural networks, and identify variants of affine arithmetic which are highly effective. We use the resulting bounds to develop geometric queries including ray casting, intersection testing, constructing spatial hierarchies, fast mesh extraction, closest-point evaluation, evaluating bulk properties, and more. Our queries can be efficiently evaluated on GPUs, and offer concrete accuracy guarantees even on randomly-initialized networks, enabling their use in training objectives and beyond. We also show a preliminary application to inverse rendering. ",
    "url": "https://arxiv.org/abs/2202.02444",
    "authors": [
      "Nicholas Sharp",
      "Alec Jacobson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02448",
    "title": "Linear Model with Local Differential Privacy",
    "abstract": "Scientific collaborations benefit from collaborative learning of distributed sources, but remain difficult to achieve when data are sensitive. In recent years, privacy preserving techniques have been widely studied to analyze distributed data across different agencies while protecting sensitive information. Secure multiparty computation has been widely studied for privacy protection with high privacy level but intense computation cost. There are also other security techniques sacrificing partial data utility to reduce disclosure risk. A major challenge is to balance data utility and disclosure risk while maintaining high computation efficiency. In this paper, matrix masking technique is applied to encrypt data such that the secure schemes are against malicious adversaries while achieving local differential privacy. The proposed schemes are designed for linear models and can be implemented for both vertical and horizontal partitioning scenarios. Moreover, cross validation is studied to prevent overfitting and select optimal parameters without additional communication cost. Simulation results present the efficiency of proposed schemes to analyze dataset with millions of records and high-dimensional data (n << p). ",
    "url": "https://arxiv.org/abs/2202.02448",
    "authors": [
      "Guanhong Miao",
      "A. Adam Ding",
      "Samuel S. Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.02452",
    "title": "Security-Aware Virtual Network Embedding Algorithm based on  Reinforcement Learning",
    "abstract": "Virtual network embedding (VNE) algorithm is always the key problem in network virtualization (NV) technology. At present, the research in this field still has the following problems. The traditional way to solve VNE problem is to use heuristic algorithm. However, this method relies on manual embedding rules, which does not accord with the actual situation of VNE. In addition, as the use of intelligent learning algorithm to solve the problem of VNE has become a trend, this method is gradually outdated. At the same time, there are some security problems in VNE. However, there is no intelligent algorithm to solve the security problem of VNE. For this reason, this paper proposes a security-aware VNE algorithm based on reinforcement learning (RL). In the training phase, we use a policy network as a learning agent and take the extracted attributes of the substrate nodes to form a feature matrix as input. The learning agent is trained in this environment to get the mapping probability of each substrate node. In the test phase, we map nodes according to the mapping probability and use the breadth-first strategy (BFS) to map links. For the security problem, we add security requirements level constraint for each virtual node and security level constraint for each substrate node. Virtual nodes can only be embedded on substrate nodes that are not lower than the level of security requirements. Experimental results show that the proposed algorithm is superior to other typical algorithms in terms of long-term average return, long-term revenue consumption ratio and virtual network request (VNR) acceptance rate. ",
    "url": "https://arxiv.org/abs/2202.02452",
    "authors": [
      "Peiying Zhang",
      "Chao Wang",
      "Chunxiao Jiang",
      "Abderrahim Benslimane"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02454",
    "title": "Supervised Learning based QoE Prediction of Video Streaming in Future  Networks: A Tutorial with Comparative Study",
    "abstract": "The Quality of Experience (QoE) based service management remains key for successful provisioning of multimedia services in next-generation networks such as 5G/6G, which requires proper tools for quality monitoring, prediction and resource management where machine learning (ML) can play a crucial role. In this paper, we provide a tutorial on the development and deployment of the QoE measurement and prediction solutions for video streaming services based on supervised learning ML models. Firstly, we provide a detailed pipeline for developing and deploying supervised learning-based video streaming QoE prediction models which covers several stages including data collection, feature engineering, model optimization and training, testing and prediction and evaluation. Secondly, we discuss the deployment of the ML model for the QoE prediction/measurement in the next generation networks (5G/6G) using network enabling technologies such as Software-Defined Networking (SDN), Network Function Virtualization (NFV) and Mobile Edge Computing (MEC) by proposing reference architecture. Thirdly, we present a comparative study of the state-of-the-art supervised learning ML models for QoE prediction of video streaming applications based on multiple performance metrics. ",
    "url": "https://arxiv.org/abs/2202.02454",
    "authors": [
      "Arslan Ahmad",
      "Atif Bin Mansoor",
      "Alcardo Alex Barakabitze",
      "Andrew Hines",
      "Luigi Atzori",
      "Ray Walshe"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2202.02459",
    "title": "Space-Air-Ground Integrated Multi-domain Network Resource Orchestration  based on Virtual Network Architecture: a DRL Method",
    "abstract": "Traditional ground wireless communication networks cannot provide high-quality services for artificial intelligence (AI) applications such as intelligent transportation systems (ITS) due to deployment, coverage and capacity issues. The space-air-ground integrated network (SAGIN) has become a research focus in the industry. Compared with traditional wireless communication networks, SAGIN is more flexible and reliable, and it has wider coverage and higher quality of seamless connection. However, due to its inherent heterogeneity, time-varying and self-organizing characteristics, the deployment and use of SAGIN still faces huge challenges, among which the orchestration of heterogeneous resources is a key issue. Based on virtual network architecture and deep reinforcement learning (DRL), we model SAGIN's heterogeneous resource orchestration as a multi-domain virtual network embedding (VNE) problem, and propose a SAGIN cross-domain VNE algorithm. We model the different network segments of SAGIN, and set the network attributes according to the actual situation of SAGIN and user needs. In DRL, the agent is acted by a five-layer policy network. We build a feature matrix based on network attributes extracted from SAGIN and use it as the agent training environment. Through training, the probability of each underlying node being embedded can be derived. In test phase, we complete the embedding process of virtual nodes and links in turn based on this probability. Finally, we verify the effectiveness of the algorithm from both training and testing. ",
    "url": "https://arxiv.org/abs/2202.02459",
    "authors": [
      "Peiying Zhang",
      "Chao Wang",
      "Neeraj Kumar",
      "Lei Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02467",
    "title": "Group Testing with Correlation under Edge-Faulty Graphs",
    "abstract": "In applications of group testing in networks, e.g. identifying individuals who are infected by a disease spread over a network, exploiting correlation among network nodes provides fundamental opportunities in reducing the number of tests needed. We model and analyze group testing on $n$ correlated nodes whose interactions are specified by a graph $G$. We model correlation through an edge-faulty random graph formed from $G$ in which each edge is dropped with probability $1-r$, and all nodes in the same component have the same state. We consider three classes of graphs: cycles and trees, $d$-regular graphs and stochastic block models or SBM, and obtain lower and upper bounds on the number of tests needed to identify the defective nodes. Our results are expressed in terms of the number of tests needed when the nodes are independent and they are in terms of $n$, $r$, and the target error. In particular, we quantify the fundamental improvements that exploiting correlation offers by the ratio between the total number of nodes $n$ and the equivalent number of independent nodes in a classic group testing algorithm. The lower bounds are derived by illustrating a strong dependence of the number of tests needed on the expected number of components. In this regard, we establish a new approximation for the distribution of component sizes in \"$d$-regular trees\" which may be of independent interest and leads to a lower bound on the expected number of components in $d$-regular graphs. The upper bounds are found by forming dense subgraphs in which nodes are more likely to be in the same state. When $G$ is a cycle or tree, we show an improvement by a factor of $log(1/r)$. For grid, a graph with almost $2n$ edges, the improvement is by a factor of ${(1-r) \\log(1/r)}$, indicating drastic improvement compared to trees. When $G$ has a larger number of edges, as in SBM, the improvement can scale in $n$. ",
    "url": "https://arxiv.org/abs/2202.02467",
    "authors": [
      "Hesam Nikpey",
      "Jungyeol Kim",
      "Xingran Chen",
      "Saswati Sarkar",
      "Shirin Saeedi Bidokhti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.02470",
    "title": "MarkovGNN: Graph Neural Networks on Markov Diffusion",
    "abstract": "Most real-world networks contain well-defined community structures where nodes are densely connected internally within communities. To learn from these networks, we develop MarkovGNN that captures the formation and evolution of communities directly in different convolutional layers. Unlike most Graph Neural Networks (GNNs) that consider a static graph at every layer, MarkovGNN generates different stochastic matrices using a Markov process and then uses these community-capturing matrices in different layers. MarkovGNN is a general approach that could be used with most existing GNNs. We experimentally show that MarkovGNN outperforms other GNNs for clustering, node classification, and visualization tasks. The source code of MarkovGNN is publicly available at \\url{https://github.com/HipGraph/MarkovGNN}. ",
    "url": "https://arxiv.org/abs/2202.02470",
    "authors": [
      "Md. Khaledur Rahman",
      "Abhigya Agrawal",
      "Ariful Azad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02478",
    "title": "Sensing Method for Two-Target Detection in Time-Constrained Vector  Gaussian Channel",
    "abstract": "This paper considers a vector Gaussian channel of fixed identity covariance matrix and binary input signalling as the mean of it. A linear transformation is performed on the vector input signal. The objective is to find the optimal scaling matrix, under the total time constraint, that would: i) maximize the mutual information between the input and output random vectors, ii) maximize the MAP detection. It was found that the two metrics lead to different optimal solutions for our experimental design problem. We have used the Monte Carlo method for our computational work. ",
    "url": "https://arxiv.org/abs/2202.02478",
    "authors": [
      "Muhammad Fahad",
      "Daniel R. Fuhrmann"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.02489",
    "title": "Investigating the Challenges of Class Imbalance and Scale Variation in  Object Detection in Aerial Images",
    "abstract": "While object detection is a common problem in computer vision, it is even more challenging when dealing with aerial satellite images. The variety in object scales and orientations can make them difficult to identify. In addition, there can be large amounts of densely packed small objects such as cars. In this project, we propose a few changes to the Faster-RCNN architecture. First, we experiment with different backbones to extract better features. We also modify the data augmentations and generated anchor sizes for region proposals in order to better handle small objects. Finally, we investigate the effects of different loss functions. Our proposed design achieves an improvement of 4.7 mAP over the baseline which used a vanilla Faster R-CNN with a ResNet-101 FPN backbone. ",
    "url": "https://arxiv.org/abs/2202.02489",
    "authors": [
      "Ahmed Elhagry",
      "Mohamed Saeed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.02500",
    "title": "A Neural Beam Filter for Real-time Multi-channel Speech Enhancement",
    "abstract": "Most deep learning-based multi-channel speech enhancement methods focus on designing a set of beamforming coefficients to directly filter the low signal-to-noise ratio signals received by microphones, which hinders the performance of these approaches. To handle these problems, this paper designs a causal neural beam filter that fully exploits the spatial-spectral information in the beam domain. Specifically, multiple beams are designed to steer towards all directions using a parameterized super-directive beamformer in the first stage. After that, the neural spatial filter is learned by simultaneously modeling the spatial and spectral discriminability of the speech and the interference, so as to extract the desired speech coarsely in the second stage. Finally, to further suppress the interference components especially at low frequencies, a residual estimation module is adopted to refine the output of the second stage. Experimental results demonstrate that the proposed approach outperforms many state-of-the-art multi-channel methods on the generated multi-channel speech dataset based on the DNS-Challenge dataset. ",
    "url": "https://arxiv.org/abs/2202.02500",
    "authors": [
      "Wenzhe Liu",
      "Andong Li",
      "Chengshi Zheng",
      "Xiaodong Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2202.02501",
    "title": "GraphEye: A Novel Solution for Detecting Vulnerable Functions Based on  Graph Attention Network",
    "abstract": "With the continuous extension of the Industrial Internet, cyber incidents caused by software vulnerabilities have been increasing in recent years. However, software vulnerabilities detection is still heavily relying on code review done by experts, and how to automatedly detect software vulnerabilities is an open problem so far. In this paper, we propose a novel solution named GraphEye to identify whether a function of C/C++ code has vulnerabilities, which can greatly alleviate the burden of code auditors. GraphEye is originated from the observation that the code property graph of a non-vulnerable function naturally differs from the code property graph of a vulnerable function with the same functionality. Hence, detecting vulnerable functions is attributed to the graph classification problem.GraphEye is comprised of VecCPG and GcGAT. VecCPG is a vectorization for the code property graph, which is proposed to characterize the key syntax and semantic features of the corresponding source code. GcGAT is a deep learning model based on the graph attention graph, which is proposed to solve the graph classification problem according to VecCPG. Finally, GraphEye is verified by the SARD Stack-based Buffer Overflow, Divide-Zero, Null Pointer Deference, Buffer Error, and Resource Error datasets, the corresponding F1 scores are 95.6%, 95.6%,96.1%,92.6%, and 96.1% respectively, which validate the effectiveness of the proposed solution. ",
    "url": "https://arxiv.org/abs/2202.02501",
    "authors": [
      "Li Zhou",
      "Minhuan Huang",
      "Yujun Li",
      "Yuanping Nie",
      "Jin Li",
      "Yiwei Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02503",
    "title": "Adversarial Detector with Robust Classifier",
    "abstract": "Deep neural network (DNN) models are wellknown to easily misclassify prediction results by using input images with small perturbations, called adversarial examples. In this paper, we propose a novel adversarial detector, which consists of a robust classifier and a plain one, to highly detect adversarial examples. The proposed adversarial detector is carried out in accordance with the logits of plain and robust classifiers. In an experiment, the proposed detector is demonstrated to outperform a state-of-the-art detector without any robust classifier. ",
    "url": "https://arxiv.org/abs/2202.02503",
    "authors": [
      "Takayuki Osakabe",
      "Maungmaung Aprilpyone",
      "Sayaka Shiota",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02510",
    "title": "A Survey on Poisoning Attacks Against Supervised Machine Learning",
    "abstract": "With the rise of artificial intelligence and machine learning in modern computing, one of the major concerns regarding such techniques is to provide privacy and security against adversaries. We present this survey paper to cover the most representative papers in poisoning attacks against supervised machine learning models. We first provide a taxonomy to categorize existing studies and then present detailed summaries for selected papers. We summarize and compare the methodology and limitations of existing literature. We conclude this paper with potential improvements and future directions to further exploit and prevent poisoning attacks on supervised models. We propose several unanswered research questions to encourage and inspire researchers for future work. ",
    "url": "https://arxiv.org/abs/2202.02510",
    "authors": [
      "Wenjun Qiu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02514",
    "title": "Score-based Generative Modeling of Graphs via the System of Stochastic  Differential Equations",
    "abstract": "Generating graph-structured data requires learning the underlying distribution of graphs. Yet, this is a challenging problem, and the previous graph generative methods either fail to capture the permutation-invariance property of graphs or cannot sufficiently model the complex dependency between nodes and edges, which is crucial for generating real-world graphs such as molecules. To overcome such limitations, we propose a novel score-based generative model for graphs with a continuous-time framework. Specifically, we propose a new graph diffusion process that models the joint distribution of the nodes and edges through a system of stochastic differential equations (SDEs). Then, we derive novel score matching objectives tailored for the proposed diffusion process to estimate the gradient of the joint log-density with respect to each component, and introduce a new solver for the system of SDEs to efficiently sample from the reverse diffusion process. We validate our graph generation method on diverse datasets, on which it either achieves significantly superior or competitive performance to the baselines. Further analysis shows that our method is able to generate molecules that lie close to the training distribution yet do not violate the chemical valency rule, demonstrating the effectiveness of the system of SDEs in modeling the node-edge relationships. ",
    "url": "https://arxiv.org/abs/2202.02514",
    "authors": [
      "Jaehyeong Jo",
      "Seul Lee",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02516",
    "title": "A Survey on Automated Sarcasm Detection on Twitter",
    "abstract": "Automatic sarcasm detection is a growing field in computer science. Short text messages are increasingly used for communication, especially over social media platforms such as Twitter. Due to insufficient or missing context, unidentified sarcasm in these messages can invert the meaning of a statement, leading to confusion and communication failures. This paper covers a variety of current methods used for sarcasm detection, including detection by context, posting history and machine learning models. Additionally, a shift towards deep learning methods is observable, likely due to the benefit of using a model with induced instead of discrete features combined with the innovation of transformers. ",
    "url": "https://arxiv.org/abs/2202.02516",
    "authors": [
      "Bleau Moores",
      "Vijay Mago"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.02521",
    "title": "Comparative study of 3D object detection frameworks based on LiDAR data  and sensor fusion techniques",
    "abstract": "Estimating and understanding the surroundings of the vehicle precisely forms the basic and crucial step for the autonomous vehicle. The perception system plays a significant role in providing an accurate interpretation of a vehicle's environment in real-time. Generally, the perception system involves various subsystems such as localization, obstacle (static and dynamic) detection, and avoidance, mapping systems, and others. For perceiving the environment, these vehicles will be equipped with various exteroceptive (both passive and active) sensors in particular cameras, Radars, LiDARs, and others. These systems are equipped with deep learning techniques that transform the huge amount of data from the sensors into semantic information on which the object detection and localization tasks are performed. For numerous driving tasks, to provide accurate results, the location and depth information of a particular object is necessary. 3D object detection methods, by utilizing the additional pose data from the sensors such as LiDARs, stereo cameras, provides information on the size and location of the object. Based on recent research, 3D object detection frameworks performing object detection and localization on LiDAR data and sensor fusion techniques show significant improvement in their performance. In this work, a comparative study of the effect of using LiDAR data for object detection frameworks and the performance improvement seen by using sensor fusion techniques are performed. Along with discussing various state-of-the-art methods in both the cases, performing experimental analysis, and providing future research directions. ",
    "url": "https://arxiv.org/abs/2202.02521",
    "authors": [
      "Sreenivasa Hikkal Venugopala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02526",
    "title": "LyaNet: A Lyapunov Framework for Training Neural ODEs",
    "abstract": "We propose a method for training ordinary differential equations by using a control-theoretic Lyapunov condition for stability. Our approach, called LyaNet, is based on a novel Lyapunov loss formulation that encourages the inference dynamics to converge quickly to the correct prediction. Theoretically, we show that minimizing Lyapunov loss guarantees exponential convergence to the correct solution and enables a novel robustness guarantee. We also provide practical algorithms, including one that avoids the cost of backpropagating through a solver or using the adjoint method. Relative to standard Neural ODE training, we empirically find that LyaNet can offer improved prediction performance, faster convergence of inference dynamics, and improved adversarial robustness. Our code available at https://github.com/ivandariojr/LyapunovLearning . ",
    "url": "https://arxiv.org/abs/2202.02526",
    "authors": [
      "Ivan Dario Jimenez Rodriguez",
      "Aaron D. Ames",
      "Yisong Yue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02529",
    "title": "Graph Neural Network with Curriculum Learning for Imbalanced Node  Classification",
    "abstract": "Graph Neural Network (GNN) is an emerging technique for graph-based learning tasks such as node classification. In this work, we reveal the vulnerability of GNN to the imbalance of node labels. Traditional solutions for imbalanced classification (e.g. resampling) are ineffective in node classification without considering the graph structure. Worse still, they may even bring overfitting or underfitting results due to lack of sufficient prior knowledge. To solve these problems, we propose a novel graph neural network framework with curriculum learning (GNN-CL) consisting of two modules. For one thing, we hope to acquire certain reliable interpolation nodes and edges through the novel graph-based oversampling based on smoothness and homophily. For another, we combine graph classification loss and metric learning loss which adjust the distance between different nodes associated with minority class in feature space. Inspired by curriculum learning, we dynamically adjust the weights of different modules during training process to achieve better ability of generalization and discrimination. The proposed framework is evaluated via several widely used graph datasets, showing that our proposed model consistently outperforms the existing state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2202.02529",
    "authors": [
      "Xiaohe Li",
      "Lijie Wen",
      "Yawen Deng",
      "Fuli Feng",
      "Xuming Hu",
      "Lei Wang",
      "Zide Fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02533",
    "title": "Blue Data Computation Maximization in 6G Space-Air-Sea Non-Terrestrial  Networks",
    "abstract": "Non-terrestrial networks (NTN), encompassing space and air platforms, are a key component of the upcoming sixth-generation (6G) cellular network. Meanwhile, maritime network traffic has grown significantly in recent years due to sea transportation used for national defense, research, recreational activities, domestic and international trade. In this paper, the seamless and reliable demand for communication and computation in maritime wireless networks is investigated. Two types of marine user equipment (UEs), i.e., low-antenna gain and high-antenna gain UEs, are considered. A joint task computation and time allocation problem for weighted sum-rate maximization is formulated as mixed-integer linear programming (MILP). The goal is to design an algorithm that enables the network to efficiently provide backhaul resources to an unmanned aerial vehicle (UAV) and offload HUEs tasks to LEO satellite for blue data (i.e., marine user's data). To solve this MILP, a solution based on the Bender and primal decomposition is proposed. The Bender decomposes MILP into the master problem for binary task decision and subproblem for continuous-time resource allocation. Moreover, primal decomposition deals with a coupling constraint in the subproblem. Finally, numerical results demonstrate that the proposed algorithm provides the maritime UEs coverage demand in polynomial time computational complexity and achieves a near-optimal solution. ",
    "url": "https://arxiv.org/abs/2202.02533",
    "authors": [
      "Sheikh Salman Hassan",
      "Yan Kyaw Tun",
      "Walid Saad",
      "Zhu Han",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.02541",
    "title": "TorchMD-NET: Equivariant Transformers for Neural Network based Molecular  Potentials",
    "abstract": "The prediction of quantum mechanical properties is historically plagued by a trade-off between accuracy and speed. Machine learning potentials have previously shown great success in this domain, reaching increasingly better accuracy while maintaining computational efficiency comparable with classical force fields. In this work we propose TorchMD-NET, a novel equivariant transformer (ET) architecture, outperforming state-of-the-art on MD17, ANI-1, and many QM9 targets in both accuracy and computational efficiency. Through an extensive attention weight analysis, we gain valuable insights into the black box predictor and show differences in the learned representation of conformers versus conformations sampled from molecular dynamics or normal modes. Furthermore, we highlight the importance of datasets including off-equilibrium conformations for the evaluation of molecular potentials. ",
    "url": "https://arxiv.org/abs/2202.02541",
    "authors": [
      "Philipp Th\u00f6lke",
      "Gianni De Fabritiis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2202.02567",
    "title": "Catch Me if You Can: A Novel Task for Detection of Covert Geo-Locations  (CGL)",
    "abstract": "Most visual scene understanding tasks in the field of computer vision involve identification of the objects present in the scene. Image regions like hideouts, turns, & other obscured regions of the scene also contain crucial information, for specific surveillance tasks. Task proposed in this paper involves the design of an intelligent visual aid for identification of such locations in an image, which has either the potential to create an imminent threat from an adversary or appear as the target zones needing further investigation. Covert places (CGL) for hiding behind an occluding object are concealed 3D locations, not detectable from the viewpoint (camera). Hence this involves delineating specific image regions around the projections of outer boundary of the occluding objects, as places to be accessed around the potential hideouts. CGL detection finds applications in military counter-insurgency operations, surveillance with path planning for an exploratory robot. Given an RGB image, the goal is to identify all CGLs in the 2D scene. Identification of such regions would require knowledge about the 3D boundaries of obscuring items (pillars, furniture), their spatial location with respect to the neighboring regions of the scene. We propose this as a novel task, termed Covert Geo-Location (CGL) Detection. Classification of any region of an image as a CGL (as boundary sub-segments of an occluding object that conceals the hideout) requires examining the 3D relation between boundaries of occluding objects and their neighborhoods & surroundings. Our method successfully extracts relevant depth features from a single RGB image and quantitatively yields significant improvement over existing object detection and segmentation models adapted and trained for CGL detection. We also introduce a novel hand-annotated CGL detection dataset containing 1.5K real-world images for experimentation. ",
    "url": "https://arxiv.org/abs/2202.02567",
    "authors": [
      "Binoy Saha",
      "Sukhendu Das"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.02575",
    "title": "Differentially Private Graph Classification with GNNs",
    "abstract": "Graph Neural Networks (GNNs) have established themselves as the state-of-the-art models for many machine learning applications such as the analysis of social networks, protein interactions and molecules. Several among these datasets contain privacy-sensitive data. Machine learning with differential privacy is a promising technique to allow deriving insight from sensitive data while offering formal guarantees of privacy protection. However, the differentially private training of GNNs has so far remained under-explored due to the challenges presented by the intrinsic structural connectivity of graphs. In this work, we introduce differential privacy for graph-level classification, one of the key applications of machine learning on graphs. Our method is applicable to deep learning on multi-graph datasets and relies on differentially private stochastic gradient descent (DP-SGD). We show results on a variety of synthetic and public datasets and evaluate the impact of different GNN architectures and training hyperparameters on model performance for differentially private graph classification. Finally, we apply explainability techniques to assess whether similar representations are learned in the private and non-private settings and establish robust baselines for future work in this area. ",
    "url": "https://arxiv.org/abs/2202.02575",
    "authors": [
      "Tamara T. Mueller",
      "Johannes C. Paetzold",
      "Chinmay Prabhakar",
      "Dmitrii Usynin",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.02576",
    "title": "Causal Disentanglement for Semantics-Aware Intent Learning in  Recommendation",
    "abstract": "Traditional recommendation models trained on observational interaction data have generated large impacts in a wide range of applications, it faces bias problems that cover users' true intent and thus deteriorate the recommendation effectiveness. Existing methods tracks this problem as eliminating bias for the robust recommendation, e.g., by re-weighting training samples or learning disentangled representation. The disentangled representation methods as the state-of-the-art eliminate bias through revealing cause-effect of the bias generation. However, how to design the semantics-aware and unbiased representation for users true intents is largely unexplored. To bridge the gap, we are the first to propose an unbiased and semantics-aware disentanglement learning called CaDSI (Causal Disentanglement for Semantics-Aware Intent Learning) from a causal perspective. Particularly, CaDSI explicitly models the causal relations underlying recommendation task, and thus produces semantics-aware representations via disentangling users true intents aware of specific item context. Moreover, the causal intervention mechanism is designed to eliminate confounding bias stemmed from context information, which further to align the semantics-aware representation with users true intent. Extensive experiments and case studies both validate the robustness and interpretability of our proposed model. ",
    "url": "https://arxiv.org/abs/2202.02576",
    "authors": [
      "Xiangmeng Wang",
      "Qian Li",
      "Dianer Yu",
      "Peng Cui",
      "Zhichao Wang",
      "Guandong Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02583",
    "title": "Temporal Robustness of Stochastic Signals",
    "abstract": "We study the temporal robustness of stochastic signals. This topic is of particular interest in interleaving processes such as multi-agent systems where communication and individual agents induce timing uncertainty. For a deterministic signal and a given specification, we first introduce the synchronous and the asynchronous temporal robustness to quantify the signal's robustness with respect to synchronous and asynchronous time shifts in its sub-signals. We then define the temporal robustness risk by investigating the temporal robustness of the realizations of a stochastic signal. This definition can be interpreted as the risk associated with a stochastic signal to not satisfy a specification robustly in time. In this definition, general forms of specifications such as signal temporal logic specifications are permitted. We show how the temporal robustness risk is estimated from data for the value-at-risk. The usefulness of the temporal robustness risk is underlined by both theoretical and empirical evidence. In particular, we provide various numerical case studies including a T-intersection scenario in autonomous driving. ",
    "url": "https://arxiv.org/abs/2202.02583",
    "authors": [
      "Lars Lindemann",
      "Alena Rodionova",
      "George J. Pappas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2202.02585",
    "title": "GhostTalk: Interactive Attack on Smartphone Voice System Through Power  Line",
    "abstract": "Inaudible voice command injection is one of the most threatening attacks towards voice assistants. Existing attacks aim at injecting the attack signals over the air, but they require the access to the authorized user's voice for activating the voice assistants. Moreover, the effectiveness of the attacks can be greatly deteriorated in a noisy environment. In this paper, we explore a new type of channel, the power line side-channel, to launch the inaudible voice command injection. By injecting the audio signals over the power line through a modified charging cable, the attack becomes more resilient against various environmental factors and liveness detection models. Meanwhile, the smartphone audio output can be eavesdropped through the modified cable, enabling a highly-interactive attack. To exploit the power line side-channel, we present GhostTalk, a new hidden voice attack that is capable of injecting and eavesdropping simultaneously. Via a quick modification of the power bank cables, the attackers could launch interactive attacks by remotely making a phone call or capturing private information from the voice assistants. GhostTalk overcomes the challenge of bypassing the speaker verification system by stealthily triggering a switch component to simulate the press button on the headphone. In case when the smartphones are charged by an unaltered standard cable, we discover that it is possible to recover the audio signal from smartphone loudspeakers by monitoring the charging current on the power line. To demonstrate the feasibility, we design GhostTalk-SC, an adaptive eavesdropper system targeting smartphones charged in the public USB ports. To correctly recognize the private information in the audio, GhostTalk-SC carefully extracts audio spectra and integrates a neural network model to classify spoken digits in the speech. ",
    "url": "https://arxiv.org/abs/2202.02585",
    "authors": [
      "Yuanda Wang",
      "Hanqing Guo",
      "Qiben Yan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.02595",
    "title": "Memory Defense: More Robust Classification via a Memory-Masking  Autoencoder",
    "abstract": "Many deep neural networks are susceptible to minute perturbations of images that have been carefully crafted to cause misclassification. Ideally, a robust classifier would be immune to small variations in input images, and a number of defensive approaches have been created as a result. One method would be to discern a latent representation which could ignore small changes to the input. However, typical autoencoders easily mingle inter-class latent representations when there are strong similarities between classes, making it harder for a decoder to accurately project the image back to the original high-dimensional space. We propose a novel framework, Memory Defense, an augmented classifier with a memory-masking autoencoder to counter this challenge. By masking other classes, the autoencoder learns class-specific independent latent representations. We test the model's robustness against four widely used attacks. Experiments on the Fashion-MNIST & CIFAR-10 datasets demonstrate the superiority of our model. We make available our source code at GitHub repository: https://github.com/eashanadhikarla/MemDefense ",
    "url": "https://arxiv.org/abs/2202.02595",
    "authors": [
      "Eashan Adhikarla",
      "Dan Luo",
      "Brian D. Davison"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02601",
    "title": "Exemplar-Based Contrastive Self-Supervised Learning with Few-Shot Class  Incremental Learning",
    "abstract": "Humans are capable of learning new concepts from only a few (labeled) exemplars, incrementally and continually. This happens within the context that we can differentiate among the exemplars, and between the exemplars and large amounts of other data (unlabeled and labeled). This suggests, in human learning, supervised learning of concepts based on exemplars takes place within the larger context of contrastive self-supervised learning (CSSL) based on unlabeled and labeled data. We discuss extending CSSL (1) to be based mainly on exemplars and only secondly on data augmentation, and (2) to apply to both unlabeled data (a large amount is available in general) and labeled data (a few exemplars can be obtained with valuable supervised knowledge). A major benefit of the extensions is that exemplar-based CSSL, with supervised finetuning, supports few-shot class incremental learning (CIL). Specifically, we discuss exemplar-based CSSL including: nearest-neighbor CSSL, neighborhood CSSL with supervised pretraining, and exemplar CSSL with supervised finetuning. We further discuss using exemplar-based CSSL to facilitate few-shot learning and, in particular, few-shot CIL. ",
    "url": "https://arxiv.org/abs/2202.02601",
    "authors": [
      "Daniel T. Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02626",
    "title": "Layer-wise Regularized Adversarial Training using Layers Sustainability  Analysis (LSA) framework",
    "abstract": "Deep neural network models are used today in various applications of artificial intelligence, the strengthening of which, in the face of adversarial attacks is of particular importance. An appropriate solution to adversarial attacks is adversarial training, which reaches a trade-off between robustness and generalization. This paper introduces a novel framework (Layer Sustainability Analysis (LSA)) for the analysis of layer vulnerability in a given neural network in the scenario of adversarial attacks. LSA can be a helpful toolkit to assess deep neural networks and to extend the adversarial training approaches towards improving the sustainability of model layers via layer monitoring and analysis. The LSA framework identifies a list of Most Vulnerable Layers (MVL list) of a given network. The relative error, as a comparison measure, is used to evaluate representation sustainability of each layer against adversarial attack inputs. The proposed approach for obtaining robust neural networks to fend off adversarial attacks is based on a layer-wise regularization (LR) over LSA proposal(s) for adversarial training (AT); i.e. the AT-LR procedure. AT-LR could be used with any benchmark adversarial attack to reduce the vulnerability of network layers and to improve conventional adversarial training approaches. The proposed idea performs well theoretically and experimentally for state-of-the-art multilayer perceptron and convolutional neural network architectures. Compared with the AT-LR and its corresponding base adversarial training, the classification accuracy of more significant perturbations increased by 16.35%, 21.79%, and 10.730% on Moon, MNIST, and CIFAR-10 benchmark datasets in comparison with the AT-LR and its corresponding base adversarial training, respectively. The LSA framework is available and published at https://github.com/khalooei/LSA. ",
    "url": "https://arxiv.org/abs/2202.02626",
    "authors": [
      "Mohammad Khalooei",
      "Mohammad Mehdi Homayounpour",
      "Maryam Amirmazlaghani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.02628",
    "title": "Improved Certified Defenses against Data Poisoning with (Deterministic)  Finite Aggregation",
    "abstract": "Data poisoning attacks aim at manipulating model behaviors through distorting training data. Previously, an aggregation-based certified defense, Deep Partition Aggregation (DPA), was proposed to mitigate this threat. DPA predicts through an aggregation of base classifiers trained on disjoint subsets of data, thus restricting its sensitivity to dataset distortions. In this work, we propose an improved certified defense against general poisoning attacks, namely Finite Aggregation. In contrast to DPA, which directly splits the training set into disjoint subsets, our method first splits the training set into smaller disjoint subsets and then combines duplicates of them to build larger (but not disjoint) subsets for training base classifiers. This reduces the worst-case impacts of poison samples and thus improves certified robustness bounds. In addition, we offer an alternative view of our method, bridging the designs of deterministic and stochastic aggregation-based certified defenses. Empirically, our proposed Finite Aggregation consistently improves certificates on MNIST, CIFAR-10, and GTSRB, boosting certified fractions by up to 3.05%, 3.87% and 4.77%, respectively, while keeping the same clean accuracies as DPA's, effectively establishing a new state of the art in (pointwise) certified robustness against data poisoning. ",
    "url": "https://arxiv.org/abs/2202.02628",
    "authors": [
      "Wenxiao Wang",
      "Alexander Levine",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.02635",
    "title": "Multilingual Hate Speech and Offensive Content Detection using Modified  Cross-entropy Loss",
    "abstract": "The number of increased social media users has led to a lot of people misusing these platforms to spread offensive content and use hate speech. Manual tracking the vast amount of posts is impractical so it is necessary to devise automated methods to identify them quickly. Large language models are trained on a lot of data and they also make use of contextual embeddings. We fine-tune the large language models to help in our task. The data is also quite unbalanced; so we used a modified cross-entropy loss to tackle the issue. We observed that using a model which is fine-tuned in hindi corpora performs better. Our team (HNLP) achieved the macro F1-scores of 0.808, 0.639 in English Subtask A and English Subtask B respectively. For Hindi Subtask A, Hindi Subtask B our team achieved macro F1-scores of 0.737, 0.443 respectively in HASOC 2021. ",
    "url": "https://arxiv.org/abs/2202.02635",
    "authors": [
      "Arka Mitra",
      "Priyanshu Sankhala"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.02641",
    "title": "Emblaze: Illuminating Machine Learning Representations through  Interactive Comparison of Embedding Spaces",
    "abstract": "Modern machine learning techniques commonly rely on complex, high-dimensional embedding representations to capture underlying structure in the data and improve performance. In order to characterize model flaws and choose a desirable representation, model builders often need to compare across multiple embedding spaces, a challenging analytical task supported by few existing tools. We first interviewed nine embedding experts in a variety of fields to characterize the diverse challenges they face and techniques they use when analyzing embedding spaces. Informed by these perspectives, we developed a novel system called Emblaze that integrates embedding space comparison within a computational notebook environment. Emblaze uses an animated, interactive scatter plot with a novel Star Trail augmentation to enable visual comparison. It also employs novel neighborhood analysis and clustering procedures to dynamically suggest groups of points with interesting changes between spaces. Through a series of case studies with ML experts, we demonstrate how interactive comparison with Emblaze can help gain new insights into embedding space structure. ",
    "url": "https://arxiv.org/abs/2202.02641",
    "authors": [
      "Venkatesh Sivaraman",
      "Yiwei Wu",
      "Adam Perer"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02647",
    "title": "Ethics, Rules of Engagement, and AI: Neural Narrative Mapping Using  Large Transformer Language Models",
    "abstract": "The problem of determining if a military unit has correctly understood an order and is properly executing on it is one that has bedeviled military planners throughout history. The advent of advanced language models such as OpenAI's GPT-series offers new possibilities for addressing this problem. This paper presents a mechanism to harness the narrative output of large language models and produce diagrams or \"maps\" of the relationships that are latent in the weights of such models as the GPT-3. The resulting \"Neural Narrative Maps\" (NNMs), are intended to provide insight into the organization of information, opinion, and belief in the model, which in turn provide means to understand intent and response in the context of physical distance. This paper discusses the problem of mapping information spaces in general, and then presents a concrete implementation of this concept in the context of OpenAI's GPT-3 language model for determining if a subordinate is following a commander's intent in a high-risk situation. The subordinate's locations within the NNM allow a novel capability to evaluate the intent of the subordinate with respect to the commander. We show that is is possible not only to determine if they are nearby in narrative space, but also how they are oriented, and what \"trajectory\" they are on. Our results show that our method is able to produce high-quality maps, and demonstrate new ways of evaluating intent more generally. ",
    "url": "https://arxiv.org/abs/2202.02647",
    "authors": [
      "Philip Feldman",
      "Aaron Dant",
      "David Rosenbluth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02650",
    "title": "Efficient Logistic Regression with Local Differential Privacy",
    "abstract": "Internet of Things devices are expanding rapidly and generating huge amount of data. There is an increasing need to explore data collected from these devices. Collaborative learning provides a strategic solution for the Internet of Things settings but also raises public concern over data privacy. In recent years, large amount of privacy preserving techniques have been developed based on differential privacy and secure multi-party computation. A major challenge of collaborative learning is to balance disclosure risk and data utility while maintaining high computation efficiency. In this paper, we proposed privacy preserving logistic regression model using matrix encryption approach. The secure scheme achieves local differential privacy and can be implemented for both vertical and horizontal partitioning scenarios. Moreover, cross validation is investigated to generate robust model results without increasing the communication cost. Simulation illustrates the high efficiency of proposed scheme to analyze dataset with millions of records. Experimental evaluations further demonstrate high model accuracy while achieving privacy protection. ",
    "url": "https://arxiv.org/abs/2202.02650",
    "authors": [
      "Guanhong Miao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.02652",
    "title": "A Graph Neural Network Framework for Grid-Based Simulation",
    "abstract": "Reservoir simulations are computationally expensive in the well control and well placement optimization. Generally, numerous simulation runs (realizations) are needed in order to achieve the optimal well locations. In this paper, we propose a graph neural network (GNN) framework to build a surrogate feed-forward model which replaces simulation runs to accelerate the optimization process. Our GNN framework includes an encoder, a process, and a decoder which takes input from the processed graph data designed and generated from the simulation raw data. We train the GNN model with 6000 samples (equivalent to 40 well configurations) with each containing the previous step state variable and the next step state variable. We test the GNN model with another 6000 samples and after model tuning, both one-step prediction and rollout prediction achieve a close match with the simulation results. Our GNN framework shows great potential in the application of well-related subsurface optimization including oil and gas as well as carbon capture sequestration (CCS). ",
    "url": "https://arxiv.org/abs/2202.02652",
    "authors": [
      "Haoyu Tang",
      "Wennan Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2202.02660",
    "title": "Leveraging the Power of Graph Algorithms: Efficient Algorithms for  Computer-Aided Verification",
    "abstract": "The goal of the thesis is to leverage fast graph algorithms and modern algorithmic techniques for problems in model checking and synthesis on graphs, MDPs, and game graphs. The results include symbolic algorithms, a well-known class of algorithms in model checking that trades limited access to the input model for an efficient representation. In particular, we present the following results: Algorithms for game graphs with mean-payoff B\\\"uchi objectives and mean-payoff coB\\\"uchi objectives which match one of the best running time bounds for mean-payoff objectives. A near-linear time randomized algorithm for Streett objectives in graphs and MDPs. A sub-cubic time algorithm for bounded B\\\"uchi objectives in graphs and a cubic time algorithm for game graphs. Conditional lower bounds for queries of reachability objectives in game graphs and MDPs. Linear and near-linear time algorithms for sequential reachability objectives in graphs and MDPs respectively. The first quasi-polynomial time symbolic algorithm for parity objectives in game graphs. We break a long-standing running time bound for MEC decomposition from the '90s by providing a sub-quadratic time symbolic algorithm. ",
    "url": "https://arxiv.org/abs/2202.02660",
    "authors": [
      "Alexander Svozil"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2202.02661",
    "title": "LiDAR dataset distillation within bayesian active learning framework:  Understanding the effect of data augmentation",
    "abstract": "Autonomous driving (AD) datasets have progressively grown in size in the past few years to enable better deep representation learning. Active learning (AL) has re-gained attention recently to address reduction of annotation costs and dataset size. AL has remained relatively unexplored for AD datasets, especially on point cloud data from LiDARs. This paper performs a principled evaluation of AL based dataset distillation on (1/4th) of the large Semantic-KITTI dataset. Further on, the gains in model performance due to data augmentation (DA) are demonstrated across different subsets of the AL loop. We also demonstrate how DA improves the selection of informative samples to annotate. We observe that data augmentation achieves full dataset accuracy using only 60\\% of samples from the selected dataset configuration. This provides faster training time and subsequent gains in annotation costs. ",
    "url": "https://arxiv.org/abs/2202.02661",
    "authors": [
      "Ngoc Phuong Anh Duong",
      "Alexandre Almin",
      "L\u00e9o Lemari\u00e9",
      "B Ravi Kiran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02669",
    "title": "SRPCN: Structure Retrieval based Point Completion Network",
    "abstract": "Given partial objects and some complete ones as references, point cloud completion aims to recover authentic shapes. However, existing methods pay little attention to general shapes, which leads to the poor authenticity of completion results. Besides, the missing patterns are diverse in reality, but existing methods can only handle fixed ones, which means a poor generalization ability. Considering that a partial point cloud is a subset of the corresponding complete one, we regard them as different samples of the same distribution and propose Structure Retrieval based Point Completion Network (SRPCN). It first uses k-means clustering to extract structure points and disperses them into distributions, and then KL Divergence is used as a metric to find the complete structure point cloud that best matches the input in a database. Finally, a PCN-like decoder network is adopted to generate the final results based on the retrieved structure point clouds. As structure plays an important role in describing the general shape of an object and the proposed structure retrieval method is robust to missing patterns, experiments show that our method can generate more authentic results and has a stronger generalization ability. ",
    "url": "https://arxiv.org/abs/2202.02669",
    "authors": [
      "Kaiyi Zhang",
      "Ximing Yang",
      "Yuan Wu",
      "Cheng Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.02679",
    "title": "Featherweight Assisted Vulnerability Discovery",
    "abstract": "Predicting vulnerable source code helps to focus attention on those parts of the code that need to be examined with more scrutiny. Recent work proposed the use of function names as semantic cues that can be learned by a deep neural network (DNN) to aid in the hunt for vulnerability of functions. Combining identifier splitting, which splits each function name into its constituent words, with a novel frequency-based algorithm, we explore the extent to which the words that make up a function's name can predict potentially vulnerable functions. In contrast to *lightweight* predictions by a DNN that considers only function names, avoiding the use of a DNN provides *featherweight* predictions. The underlying idea is that function names that contain certain \"dangerous\" words are more likely to accompany vulnerable functions. Of course, this assumes that the frequency-based algorithm can be properly tuned to focus on truly dangerous words. Because it is more transparent than a DNN, the frequency-based algorithm enables us to investigate the inner workings of the DNN. If successful, this investigation into what the DNN does and does not learn will help us train more effective future models. We empirically evaluate our approach on a heterogeneous dataset containing over 73000 functions labeled vulnerable, and over 950000 functions labeled benign. Our analysis shows that words alone account for a significant portion of the DNN's classification ability. We also find that words are of greatest value in the datasets with a more homogeneous vocabulary. Thus, when working within the scope of a given project, where the vocabulary is unavoidably homogeneous, our approach provides a cheaper, potentially complementary, technique to aid in the hunt for source-code vulnerabilities. Finally, this approach has the advantage that it is viable with orders of magnitude less training data. ",
    "url": "https://arxiv.org/abs/2202.02679",
    "authors": [
      "David Binkley",
      "Leon Moonen",
      "Sibren Isaacman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2202.02684",
    "title": "On the Multi-View Information Bottleneck Representation",
    "abstract": "In this work, we generalize the information bottleneck (IB) approach to the multi-view learning context. The exponentially growing complexity of the optimal representation motivates the development of two novel formulations with more favorable performance-complexity tradeoffs. The first approach is based on forming a stochastic consensus and is suited for scenarios with significant {\\em representation overlap} between the different views. The second method, relying on incremental updates, is tailored for the other extreme scenario with minimal representation overlap. In both cases, we extend our earlier work on the alternating directional methods of multiplier (ADMM) solver and establish its convergence and scalability. Empirically, we find that the proposed methods outperform state-of-the-art approaches in multi-view classification problems under a broad range of modelling parameters. ",
    "url": "https://arxiv.org/abs/2202.02684",
    "authors": [
      "Teng-Hui Huang",
      "Aly El Gamal",
      "Hesham El Gamal"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.02688",
    "title": "Joint Pilot Optimization, Target Detection and Channel Estimation for  Integrated Sensing and Communication Systems",
    "abstract": "Radar sensing will be integrated into the 6G communication system to support various applications. In this integrated sensing and communication system, a radar target may also be a communication channel scatterer. In this case, the radar and communication channels exhibit certain joint burst sparsity. We propose a two-stage joint pilot optimization, target detection and channel estimation scheme to exploit such joint burst sparsity and pilot beamforming gain to enhance detection/estimation performance. In Stage 1, the base station (BS) sends downlink pilots (DP) for initial target search, and the user sends uplink pilots (UP) for channel estimation. Then the BS performs joint target detection and channel estimation based on the reflected DP and received UP signals. In Stage 2, the BS exploits the prior information obtained in Stage 1 to optimize the DP signal to achieve beamforming gain and further refine the performance. A Turbo Sparse Bayesian inference algorithm is proposed for joint target detection and channel estimation in both stages. The pilot optimization problem in Stage 2 is a semi-definite programming with rank-1 constraints. By replacing the rank-1 constraint with a tight and smooth approximation, we propose an efficient pilot optimization algorithm based on the majorization-minimization method. Simulations verify the advantages of the proposed scheme. ",
    "url": "https://arxiv.org/abs/2202.02688",
    "authors": [
      "Zhe Huang",
      "Kexuan Wang",
      "An Liu",
      "Yunlong Cai",
      "Rui Du",
      "Tony Xiao Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.02691",
    "title": "TTS-GAN: A Transformer-based Time-Series Generative Adversarial Network",
    "abstract": "Signal measurements appearing in the form of time series are one of the most common types of data used in medical machine learning applications. However, such datasets are often small, making the training of deep neural network architectures ineffective. For time-series, the suite of data augmentation tricks we can use to expand the size of the dataset is limited by the need to maintain the basic properties of the signal. Data generated by a Generative Adversarial Network (GAN) can be utilized as another data augmentation tool. RNN-based GANs suffer from the fact that they cannot effectively model long sequences of data points with irregular temporal relations. To tackle these problems, we introduce TTS-GAN, a transformer-based GAN which can successfully generate realistic synthetic time-series data sequences of arbitrary length, similar to the real ones. Both the generator and discriminator networks of the GAN model are built using a pure transformer encoder architecture. We use visualizations and dimensionality reduction techniques to demonstrate the similarity of real and generated time-series data. We also compare the quality of our generated data with the best existing alternative, which is an RNN-based time-series GAN. ",
    "url": "https://arxiv.org/abs/2202.02691",
    "authors": [
      "Xiaomin Li",
      "Vangelis Metsis",
      "Huangyingrui Wang",
      "Anne Hee Hiong Ngu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02697",
    "title": "Bandwidth-Constrained Distributed Quickest Change Detection in  Heterogeneous Sensor Networks: Anonymous vs Non-Anonymous Settings",
    "abstract": "The heterogeneous distribute quickest changed detection (HetDQCD) problem with 1-bit feedback is studied, in which a fusion center monitors an abrupt change through a bunch of heterogeneous sensors via anonymous 1-bit feedbacks. Two fusion rules, one-shot and voting rules, are considered. We analyze the performance in terms of the worst-case expected detection delay and the average run length to false alarm for the two fusion rules. Our analysis unveils the mixed impact of involving more sensors into the decision and enables us to find near optimal choices of parameters in the two schemes. Notably, it is shown that, in contrast to the homogeneous setting, the first alarm rule may no longer lead to the best performance among one-shot schemes. The non-anonymous setting is also investigated where a simple scheme that only accepts alarms from the most informative sensors is shown to outperform all the above schemes and the mixture CUSUM scheme for the anonymous HetDQCD, hinting at the price of anonymity. ",
    "url": "https://arxiv.org/abs/2202.02697",
    "authors": [
      "Wen-Hsuan Li",
      "Yu-Chih Huang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.02698",
    "title": "Triangle Graph Interest Network for Click-through Rate Prediction",
    "abstract": "Click-through rate prediction is a critical task in online advertising. Currently, many existing methods attempt to extract user potential interests from historical click behavior sequences. However, it is difficult to handle sparse user behaviors or broaden interest exploration. Recently, some researchers incorporate the item-item co-occurrence graph as an auxiliary. Due to the elusiveness of user interests, those works still fail to determine the real motivation of user click behaviors. Besides, those works are more biased towards popular or similar commodities. They lack an effective mechanism to break the diversity restrictions. In this paper, we point out two special properties of triangles in the item-item graphs for recommendation systems: Intra-triangle homophily and Inter-triangle heterophiy. Based on this, we propose a novel and effective framework named Triangle Graph Interest Network (TGIN). For each clicked item in user behavior sequences, we introduce the triangles in its neighborhood of the item-item graphs as a supplement. TGIN regards these triangles as the basic units of user interests, which provide the clues to capture the real motivation for a user clicking an item. We characterize every click behavior by aggregating the information of several interest units to alleviate the elusive motivation problem. The attention mechanism determines users' preference for different interest units. By selecting diverse and relative triangles, TGIN brings in novel and serendipitous items to expand exploration opportunities of user interests. Then, we aggregate the multi-level interests of historical behavior sequences to improve CTR prediction. Extensive experiments on both public and industrial datasets clearly verify the effectiveness of our framework. ",
    "url": "https://arxiv.org/abs/2202.02698",
    "authors": [
      "Wensen Jiang",
      "Yizhu Jiao",
      "Qingqin Wang",
      "Chuanming Liang",
      "Lijie Guo",
      "Yao Zhang",
      "Zhijun Sun",
      "Yun Xiong",
      "Yangyong Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02702",
    "title": "How Effective is Incongruity? Implications for Code-mix Sarcasm  Detection",
    "abstract": "The presence of sarcasm in conversational systems and social media like chatbots, Facebook, Twitter, etc. poses several challenges for downstream NLP tasks. This is attributed to the fact that the intended meaning of a sarcastic text is contrary to what is expressed. Further, the use of code-mix language to express sarcasm is increasing day by day. Current NLP techniques for code-mix data have limited success due to the use of different lexicon, syntax, and scarcity of labeled corpora. To solve the joint problem of code-mixing and sarcasm detection, we propose the idea of capturing incongruity through sub-word level embeddings learned via fastText. Empirical results shows that our proposed model achieves F1-score on code-mix Hinglish dataset comparable to pretrained multilingual models while training 10x faster and using a lower memory footprint ",
    "url": "https://arxiv.org/abs/2202.02702",
    "authors": [
      "Aditya Shah",
      "Chandresh Kumar Maurya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02710",
    "title": "Spectrally Adapted Physics-Informed Neural Networks for Solving  Unbounded Domain Problems",
    "abstract": "Solving analytically intractable partial differential equations (PDEs) that involve at least one variable defined in an unbounded domain requires efficient numerical methods that accurately resolve the dependence of the PDE on that variable over several orders of magnitude. Unbounded domain problems arise in various application areas and solving such problems is important for understanding multi-scale biological dynamics, resolving physical processes at long time scales and distances, and performing parameter inference in engineering problems. In this work, we combine two classes of numerical methods: (i) physics-informed neural networks (PINNs) and (ii) adaptive spectral methods. The numerical methods that we develop take advantage of the ability of physics-informed neural networks to easily implement high-order numerical schemes to efficiently solve PDEs. We then show how recently introduced adaptive techniques for spectral methods can be integrated into PINN-based PDE solvers to obtain numerical solutions of unbounded domain problems that cannot be efficiently approximated by standard PINNs. Through a number of examples, we demonstrate the advantages of the proposed spectrally adapted PINNs (s-PINNs) over standard PINNs in approximating functions, solving PDEs, and estimating model parameters from noisy observations in unbounded domains. ",
    "url": "https://arxiv.org/abs/2202.02710",
    "authors": [
      "Mingtao Xia",
      "Lucas B\u00f6ttcher",
      "Tom Chou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2202.02711",
    "title": "Hydrogen and Battery Storage Technologies for Low Cost Energy  Decarbonization in Distribution Networks",
    "abstract": "Deep energy decarbonization cannot be achieved without high penetration of renewables. At higher renewable energy penetrations, the variability and intermittent nature of solar photovoltaic (PV) electricity can cause ramping issues with existing fossil fuel generation, requiring longer term energy storage to increase the reliability of grid operation. A proton exchange membrane electrolyzer can produce H2and serves as a utility controllable load. The produced H2 can then be stored and converted back into electricity, or mixed with natural gas, or used as transportation fuel, or chemical feedstock. This paper considers the perspective of the distribution system operator that operates the distributed energy resources on a standard IEEE 33-node distribution network considering the technical and physical constraints with the goal of minimizing total investment and operation cost. Different case studies, at very high PV penetrations are considered to show the challenges and path to net-zero emission energy production using H2 energy. Sensitivity of utility PV costs and electrolyzer capital costs on producing H2 at $1/kg are presented showing that the distribution network could produce 100% renewable electricity and H2 could be produced with the same price by 2050 with conservative cost estimates and by 2030 with accelerated cost declines. ",
    "url": "https://arxiv.org/abs/2202.02711",
    "authors": [
      "Hamed Haggi",
      "Paul Brooker",
      "Wei Sun",
      "James M. Fenton"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.02721",
    "title": "Robust Anomaly Detection for Time-series Data",
    "abstract": "Time-series anomaly detection plays a vital role in monitoring complex operation conditions. However, the detection accuracy of existing approaches is heavily influenced by pattern distribution, existence of multiple normal patterns, dynamical features representation, and parameter settings. For the purpose of improving the robustness and guaranteeing the accuracy, this research combined the strengths of negative selection, unthresholded recurrence plots, and an extreme learning machine autoencoder and then proposed robust anomaly detection for time-series data (RADTD), which can automatically learn dynamical features in time series and recognize anomalies with low label dependency and high robustness. Yahoo benchmark datasets and three tunneling engineering simulation experiments were used to evaluate the performance of RADTD. The experiments showed that in benchmark datasets RADTD possessed higher accuracy and robustness than recurrence qualification analysis and extreme learning machine autoencoder, respectively, and that RADTD accurately detected the occurrence of tunneling settlement accidents, indicating its remarkable performance in accuracy and robustness. ",
    "url": "https://arxiv.org/abs/2202.02721",
    "authors": [
      "Min Hu",
      "Yi Wang",
      "Xiaowei Feng",
      "Shengchen Zhou",
      "Zhaoyu Wu",
      "Yuan Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02760",
    "title": "Optimal Correlators and Waveforms for Mismatched Detection",
    "abstract": "We consider the classical Neymann-Pearson hypothesis testing problem of signal detection, where under the null hypothesis ($\\calH_0$), the received signal is white Gaussian noise, and under the alternative hypothesis ($\\calH_1$), the received signal includes also an additional non-Gaussian random signal, which in turn can be viewed as a deterministic waveform plus zero-mean, non-Gaussian noise. However, instead of the classical likelihood ratio test detector, which might be difficult to implement, in general, we impose a (mismatched) correlation detector, which is relatively easy to implement, and we characterize the optimal correlator weights in the sense of the best trade-off between the false-alarm error exponent and the missed-detection error exponent. Those optimal correlator weights depend (non-linearly, in general) on the underlying deterministic waveform under $\\calH_1$. We then assume that the deterministic waveform may also be free to be optimized (subject to a power constraint), jointly with the correlator, and show that both the optimal waveform and the optimal correlator weights may take on values in a small finite set of typically no more than two to four levels, depending on the distribution of the non-Gaussian noise component. Finally, we outline an extension of the scope to a wider class of detectors that are based on linear combinations of the correlation and the energy of the received signal. ",
    "url": "https://arxiv.org/abs/2202.02760",
    "authors": [
      "Neri Merhav"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.02782",
    "title": "The Exponential-Time Complexity of the complex weighted #CSP",
    "abstract": "In this paper, I consider a fine-grained dichotomy of Boolean counting constraint satisfaction problem (#CSP), under the exponential time hypothesis of counting version (#ETH). Suppose $\\mathscr{F}$ is a finite set of algebraic complex-valued functions defined on Boolean domain. When $\\mathscr{F}$ is a subset of either two special function sets, I prove that #CSP($\\mathscr{F}$) is polynomial-time solvable, otherwise it can not be computed in sub-exponential time unless #ETH fails. I also improve the result by proving the same dichotomy holds for #CSP with bounded degree (every variable appears at most constant constraints), even for #R$_3$-CSP. An important preparation before proving the result is to argue that pinning (two special unary functions $[1,0]$ and $[0,1]$ are used to reduce arity) can also keep the sub-exponential lower bound of a Boolean #CSP problem. I discuss this issue by utilizing some common methods in proving #P-hardness of counting problems. The proof illustrates the internal correlation among these commonly used methods. ",
    "url": "https://arxiv.org/abs/2202.02782",
    "authors": [
      "Ying Liu"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2202.02783",
    "title": "Energy awareness in low precision neural networks",
    "abstract": "Power consumption is a major obstacle in the deployment of deep neural networks (DNNs) on end devices. Existing approaches for reducing power consumption rely on quite general principles, including avoidance of multiplication operations and aggressive quantization of weights and activations. However, these methods do not take into account the precise power consumed by each module in the network, and are therefore not optimal. In this paper we develop accurate power consumption models for all arithmetic operations in the DNN, under various working conditions. We reveal several important factors that have been overlooked to date. Based on our analysis, we present PANN (power-aware neural network), a simple approach for approximating any full-precision network by a low-power fixed-precision variant. Our method can be applied to a pre-trained network, and can also be used during training to achieve improved performance. In contrast to previous methods, PANN incurs only a minor degradation in accuracy w.r.t. the full-precision version of the network, even when working at the power-budget of a 2-bit quantized variant. In addition, our scheme enables to seamlessly traverse the power-accuracy trade-off at deployment time, which is a major advantage over existing quantization methods that are constrained to specific bit widths. ",
    "url": "https://arxiv.org/abs/2202.02783",
    "authors": [
      "Nurit Spingarn Eliezer",
      "Ron Banner",
      "Elad Hoffer",
      "Hilla Ben-Yaakov",
      "Tomer Michaeli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.02790",
    "title": "Learning Synthetic Environments and Reward Networks for Reinforcement  Learning",
    "abstract": "We introduce Synthetic Environments (SEs) and Reward Networks (RNs), represented by neural networks, as proxy environment models for training Reinforcement Learning (RL) agents. We show that an agent, after being trained exclusively on the SE, is able to solve the corresponding real environment. While an SE acts as a full proxy to a real environment by learning about its state dynamics and rewards, an RN is a partial proxy that learns to augment or replace rewards. We use bi-level optimization to evolve SEs and RNs: the inner loop trains the RL agent, and the outer loop trains the parameters of the SE / RN via an evolution strategy. We evaluate our proposed new concept on a broad range of RL algorithms and classic control environments. In a one-to-one comparison, learning an SE proxy requires more interactions with the real environment than training agents only on the real environment. However, once such an SE has been learned, we do not need any interactions with the real environment to train new agents. Moreover, the learned SE proxies allow us to train agents with fewer interactions while maintaining the original task performance. Our empirical results suggest that SEs achieve this result by learning informed representations that bias the agents towards relevant states. Moreover, we find that these proxies are robust against hyperparameter variation and can also transfer to unseen agents. ",
    "url": "https://arxiv.org/abs/2202.02790",
    "authors": [
      "Fabio Ferreira",
      "Thomas Nierhoff",
      "Andreas Saelinger",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02791",
    "title": "SFMGNet: A Physics-based Neural Network To Predict Pedestrian  Trajectories",
    "abstract": "Autonomous robots and vehicles are expected to soon become an integral part of our environment. Unsatisfactory issues regarding interaction with existing road users, performance in mixed-traffic areas and lack of interpretable behavior remain key obstacles. To address these, we present a physics-based neural network, based on a hybrid approach combining a social force model extended by group force (SFMG) with Multi-Layer Perceptron (MLP) to predict pedestrian trajectories considering its interaction with static obstacles, other pedestrians and pedestrian groups. We quantitatively and qualitatively evaluate the model with respect to realistic prediction, prediction performance and prediction \"interpretability\". Initial results suggest, the model even when solely trained on a synthetic dataset, can predict realistic and interpretable trajectories with better than state-of-the-art accuracy. ",
    "url": "https://arxiv.org/abs/2202.02791",
    "authors": [
      "Sakif Hossain",
      "Fatema T. Johora",
      "J\u00f6rg P. M\u00fcller",
      "Sven Hartmann",
      "Andreas Reinhardt"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02797",
    "title": "SIGMA: A Structural Inconsistency Reducing Graph Matching Algorithm",
    "abstract": "Graph matching finds the correspondence of nodes across two correlated graphs and lies at the core of many applications. When graph side information is not available, the node correspondence is estimated on the sole basis of network topologies. In this paper, we propose a novel criterion to measure the graph matching accuracy, structural inconsistency (SI), which is defined based on the network topological structure. Specifically, SI incorporates the heat diffusion wavelet to accommodate the multi-hop structure of the graphs. Based on SI, we propose a Structural Inconsistency reducing Graph Matching Algorithm (SIGMA), which improves the alignment scores of node pairs that have low SI values in each iteration. Under suitable assumptions, SIGMA can reduce SI values of true counterparts. Furthermore, we demonstrate that SIGMA can be derived by using a mirror descent method to solve the Gromov-Wasserstein distance with a novel K-hop-structure-based matching costs. Extensive experiments show that our method outperforms state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2202.02797",
    "authors": [
      "Weijie Liu",
      "Chao Zhang",
      "Nenggan Zheng",
      "Hui Qian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02819",
    "title": "Block shuffling learning for Deepfake Detection",
    "abstract": "Although the deepfake detection based on convolutional neural network has achieved good results, the detection results show that these detectors show obvious performance degradation when the input images undergo some common transformations (like resizing, blurring), which indicates that the generalization ability of the detector is insufficient. In this paper, we propose a novel block shuffling learning method to solve this problem. Specifically, we divide the images into blocks and then introduce the random shuffling to intra-block and inter-block. Intra-block shuffling increases the robustness of the detector and we also propose an adversarial loss algorithm to overcome the over-fitting problem brought by the noise introduced by shuffling. Moreover, we encourage the detector to focus on finding differences among the local features through inter-block shuffling, and reconstruct the spatial layout of the blocks to model the semantic associations between them. Especially, our method can be easily integrated with various CNN models. Extensive experiments show that our proposed method achieves state-of-the-art performance in forgery face detection, including good generalization ability in the face of common image transformations. ",
    "url": "https://arxiv.org/abs/2202.02819",
    "authors": [
      "Sitong Liu",
      "Zhichao Lian",
      "Siqi Gu",
      "Liang Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02838",
    "title": "Aligning Eyes between Humans and Deep Neural Network through Interactive  Attention Alignment",
    "abstract": "While Deep Neural Networks (DNNs) are deriving the major innovations in nearly every field through their powerful automation, we are also witnessing the peril behind automation as a form of bias, such as automated racism, gender bias, and adversarial bias. As the societal impact of DNNs grows, finding an effective way to steer DNNs to align their behavior with the human mental model has become indispensable in realizing fair and accountable models. We propose a novel framework of Interactive Attention Alignment (IAA) that aims at realizing human-steerable Deep Neural Networks (DNNs). IAA leverages DNN model explanation method as an interactive medium that humans can use to unveil the cases of biased model attention and directly adjust the attention. In improving the DNN using human-generated adjusted attention, we introduce GRADIA, a novel computational pipeline that jointly maximizes attention quality and prediction accuracy. We evaluated IAA framework in Study 1 and GRADIA in Study 2 in a gender classification problem. Study 1 found applying IAA can significantly improve the perceived quality of model attention from human eyes. In Study 2, we found using GRADIA can (1) significantly improve the perceived quality of model attention and (2) significantly improve model performance in scenarios where the training samples are limited. We present implications for future interactive user interfaces design towards human-alignable AI. ",
    "url": "https://arxiv.org/abs/2202.02838",
    "authors": [
      "Yuyang Gao",
      "Tong Sun",
      "Liang Zhao",
      "Sungsoo Hong"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2202.02851",
    "title": "Machine Learning Aided Holistic Handover Optimization for Emerging  Networks",
    "abstract": "In the wake of network densification and multi-band operation in emerging cellular networks, mobility and handover management is becoming a major bottleneck. The problem is further aggravated by the fact that holistic mobility management solutions for different types of handovers, namely inter-frequency and intra-frequency handovers, remain scarce. This paper presents a first mobility management solution that concurrently optimizes inter-frequency related A5 parameters and intra-frequency related A3 parameters. We analyze and optimize five parameters namely A5-time to trigger (TTT), A5-threshold1, A5-threshold2, A3-TTT, and A3-offset to jointly maximize three critical key performance indicators (KPIs): edge user reference signal received power (RSRP), handover success rate (HOSR) and load between frequency bands. In the absence of tractable analytical models due to system level complexity, we leverage machine learning to quantify the KPIs as a function of the mobility parameters. An XGBoost based model has the best performance for edge RSRP and HOSR while random forest outperforms others for load prediction. An analysis of the mobility parameters provides several insights: 1) there exists a strong coupling between A3 and A5 parameters; 2) an optimal set of parameters exists for each KPI; and 3) the optimal parameters vary for different KPIs. We also perform a SHAP based sensitivity to help resolve the parametric conflict between the KPIs. Finally, we formulate a maximization problem, show it is non-convex, and solve it utilizing simulated annealing (SA). Results indicate that ML-based SA-aided solution is more than 14x faster than the brute force approach with a slight loss in optimality. ",
    "url": "https://arxiv.org/abs/2202.02851",
    "authors": [
      "Muhammad Umar Bin Farooq",
      "Marvin Manalastas",
      "Syed Muhammad Asad Zaidi",
      "Adnan Abu-Dayya",
      "Ali Imran"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02891",
    "title": "Causal Inference Using Tractable Circuits",
    "abstract": "The aim of this paper is to discuss a recent result which shows that probabilistic inference in the presence of (unknown) causal mechanisms can be tractable for models that have traditionally been viewed as intractable. This result was reported recently to facilitate model-based supervised learning but it can be interpreted in a causality context as follows. One can compile a non-parametric causal graph into an arithmetic circuit that supports inference in time linear in the circuit size. The circuit is also non-parametric so it can be used to estimate parameters from data and to further reason (in linear time) about the causal graph parametrized by these estimates. Moreover, the circuit size can sometimes be bounded even when the treewidth of the causal graph is not, leading to tractable inference on models that have been deemed intractable previously. This has been enabled by a new technique that can exploit causal mechanisms computationally but without needing to know their identities (the classical setup in causal inference). Our goal is to provide a causality-oriented exposure to these new results and to speculate on how they may potentially contribute to more scalable and versatile causal inference. ",
    "url": "https://arxiv.org/abs/2202.02891",
    "authors": [
      "Adnan Darwiche"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2202.02892",
    "title": "Learning under Storage and Privacy Constraints",
    "abstract": "Storage-efficient privacy-guaranteed learning is crucial due to enormous amounts of sensitive user data required for increasingly many learning tasks. We propose a framework for reducing the storage cost while at the same time providing privacy guarantees, without essential loss in the utility of the data for learning. Our method comprises noise injection followed by lossy compression. We show that, when appropriately matching the lossy compression to the distribution of the added noise, the compressed examples converge, in distribution, to that of the noise-free training data. In this sense, the utility of the data for learning is essentially maintained, while reducing storage and privacy leakage by quantifiable amounts. We present experimental results on the CelebA dataset for gender classification and find that our suggested pipeline delivers in practice on the promise of the theory: the individuals in the images are unrecognizable (or less recognizable, depending on the noise level), overall storage of the data is substantially reduced, with no essential loss of the classification accuracy. As an added bonus, our experiments suggest that our method yields a substantial boost to robustness in the face of adversarial test data. ",
    "url": "https://arxiv.org/abs/2202.02892",
    "authors": [
      "Berivan Isik",
      "Tsachy Weissman"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.02895",
    "title": "An Automated Approach for Privacy Leakage Identification in IoT Apps",
    "abstract": "This paper presents a fully automated static analysis approach and a tool, Taint-Things, for the identification of tainted flows in SmartThings IoT apps. Taint-Things accurately identifies all tainted flows reported by one of the state-of-the-art tools with at least 4 times improved performance. Our approach reports potential vulnerable tainted flows in a form of a concise security slice, where the relevant parts of the code are given with the lines affecting the sensitive information, which could provide security auditors with an effective and precise tool to pinpoint security issues in SmartThings apps under test. We also present and test ways to add precision to Taint-Things by adding extra sensitivities; we provide different approaches for flow, path and context sensitive analyses through modules that can be added to Taint-Things. We present experiments to evaluate Taint-Things by running it on a SmartThings app dataset as well as testing for precision and recall on a set generated by a mutation framework to see how much coverage is achieved without adding false positives. This shows an improvement in performance both in terms of speed up to 4 folds, as well as improving the precision avoiding false positives by providing a higher level of flow and path sensitivity analysis in comparison with one of state of the art tools. ",
    "url": "https://arxiv.org/abs/2202.02895",
    "authors": [
      "Bara' Nazzal",
      "Manar H. Alalfi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.02896",
    "title": "Evaluation Methods and Measures for Causal Learning Algorithms",
    "abstract": "The convenient access to copious multi-faceted data has encouraged machine learning researchers to reconsider correlation-based learning and embrace the opportunity of causality-based learning, i.e., causal machine learning (causal learning). Recent years have therefore witnessed great effort in developing causal learning algorithms aiming to help AI achieve human-level intelligence. Due to the lack-of ground-truth data, one of the biggest challenges in current causal learning research is algorithm evaluations. This largely impedes the cross-pollination of AI and causal inference, and hinders the two fields to benefit from the advances of the other. To bridge from conventional causal inference (i.e., based on statistical methods) to causal learning with big data (i.e., the intersection of causal inference and machine learning), in this survey, we review commonly-used datasets, evaluation methods, and measures for causal learning using an evaluation pipeline similar to conventional machine learning. We focus on the two fundamental causal-inference tasks and causality-aware machine learning tasks. Limitations of current evaluation procedures are also discussed. We then examine popular causal inference tools/packages and conclude with primary challenges and opportunities for benchmarking causal learning algorithms in the era of big data. The survey seeks to bring to the forefront the urgency of developing publicly available benchmarks and consensus-building standards for causal learning evaluation with observational data. In doing so, we hope to broaden the discussions and facilitate collaboration to advance the innovation and application of causal learning. ",
    "url": "https://arxiv.org/abs/2202.02896",
    "authors": [
      "Lu Cheng",
      "Ruocheng Guo",
      "Raha Moraffah",
      "Paras Sheth",
      "K. Selcuk Candan",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2202.02911",
    "title": "Traffic-aware Gateway Placement and Queue Management in Flying Networks",
    "abstract": "Unmanned Aerial Vehicles (UAVs) have emerged as adequate platforms to carry communications nodes, including Wi-Fi Access Points and cellular Base Stations. This has led to the concept of flying networks composed of UAVs as a flexible and agile solution to provide on-demand wireless connectivity anytime, anywhere. However, state of the art works have been focused on optimizing the placement of the access network providing connectivity to ground users, overlooking the backhaul network design. In order to improve the overall Quality of Service (QoS) offered to ground users, the placement of Flying Gateways (FGWs) and the size of the queues configured in the UAVs need to be carefully defined to meet strict performance requirements. The main contribution of this article is a traffic-aware gateway placement and queue management (GPQM) algorithm for flying networks. GPQM takes advantage of knowing in advance the positions of the UAVs and their traffic demand to determine the FGW position and the queue size of the UAVs, in order to maximize the aggregate throughput and provide stochastic delay guarantees. GPQM is evaluated by means of ns-3 simulations, considering a realistic wireless channel model. The results demonstrate significant gains in the QoS offered when GPQM is used. ",
    "url": "https://arxiv.org/abs/2202.02911",
    "authors": [
      "Andr\u00e9 Coelho",
      "Rui Campos",
      "Manuel Ricardo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2202.02918",
    "title": "Soft Actor-Critic with Inhibitory Networks for Faster Retraining",
    "abstract": "Reusing previously trained models is critical in deep reinforcement learning to speed up training of new agents. However, it is unclear how to acquire new skills when objectives and constraints are in conflict with previously learned skills. Moreover, when retraining, there is an intrinsic conflict between exploiting what has already been learned and exploring new skills. In soft actor-critic (SAC) methods, a temperature parameter can be dynamically adjusted to weight the action entropy and balance the explore $\\times$ exploit trade-off. However, controlling a single coefficient can be challenging within the context of retraining, even more so when goals are contradictory. In this work, inspired by neuroscience research, we propose a novel approach using inhibitory networks to allow separate and adaptive state value evaluations, as well as distinct automatic entropy tuning. Ultimately, our approach allows for controlling inhibition to handle conflict between exploiting less risky, acquired behaviors and exploring novel ones to overcome more challenging tasks. We validate our method through experiments in OpenAI Gym environments. ",
    "url": "https://arxiv.org/abs/2202.02918",
    "authors": [
      "Jaime S. Ide",
      "Daria Mi\u0107ovi\u0107",
      "Michael J. Guarino",
      "Kevin Alcedo",
      "David Rosenbluth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2202.02924",
    "title": "3TO: THz-Enabled Throughput and Trajectory Optimization of UAVs in 6G  Networks by Proximal Policy Optimization Deep Reinforcement Learning",
    "abstract": "Next-generation networks need to meet ubiquitous and high data-rate demand. Therefore, this paper considers the throughput and trajectory optimization of terahertz (THz)-enabled unmanned aerial vehicles (UAVs) in the sixth-generation (6G) communication networks. In the considered scenario, multiple UAVs must provide on-demand terabits per second (TB/s) services to an urban area along with existing terrestrial networks. However, THz-empowered UAVs pose some new constraints, e.g., dynamic THz-channel conditions for ground users (GUs) association and UAV trajectory optimization to fulfill GU's throughput demands. Thus, a framework is proposed to address these challenges, where a joint UAVs-GUs association, transmit power, and the trajectory optimization problem is studied. The formulated problem is mixed-integer non-linear programming (MINLP), which is NP-hard to solve. Consequently, an iterative algorithm is proposed to solve three sub-problems iteratively, i.e., UAVs-GUs association, transmit power, and trajectory optimization. Simulation results demonstrate that the proposed algorithm increased the throughput by up to 10%, 68.9%, and 69.1% respectively compared to baseline algorithms. ",
    "url": "https://arxiv.org/abs/2202.02924",
    "authors": [
      "Sheikh Salman Hassan",
      "Yu Min Park",
      "Yan Kyaw Tun",
      "Walid Saad",
      "Zhu Han",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.02925",
    "title": "Benchmarking Deep Models for Salient Object Detection",
    "abstract": "In recent years, deep network-based methods have continuously refreshed state-of-the-art performance on Salient Object Detection (SOD) task. However, the performance discrepancy caused by different implementation details may conceal the real progress in this task. Making an impartial comparison is required for future researches. To meet this need, we construct a general SALient Object Detection (SALOD) benchmark to conduct a comprehensive comparison among several representative SOD methods. Specifically, we re-implement 14 representative SOD methods by using consistent settings for training. Moreover, two additional protocols are set up in our benchmark to investigate the robustness of existing methods in some limited conditions. In the first protocol, we enlarge the difference between objectness distributions of train and test sets to evaluate the robustness of these SOD methods. In the second protocol, we build multiple train subsets with different scales to validate whether these methods can extract discriminative features from only a few samples. In the above experiments, we find that existing loss functions usually specialized in some metrics but reported inferior results on the others. Therefore, we propose a novel Edge-Aware (EA) loss that promotes deep networks to learn more discriminative features by integrating both pixel- and image-level supervision signals. Experiments prove that our EA loss reports more robust performances compared to existing losses. ",
    "url": "https://arxiv.org/abs/2202.02925",
    "authors": [
      "Huajun Zhou",
      "Yang Lin",
      "Lingxiao Yang",
      "Jianhuang Lai",
      "Xiaohua Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.02930",
    "title": "Towards Micro-video Thumbnail Selection via a Multi-label  Visual-semantic Embedding Model",
    "abstract": "The thumbnail, as the first sight of a micro-video, plays a pivotal role in attracting users to click and watch. While in the real scenario, the more the thumbnails satisfy the users, the more likely the micro-videos will be clicked. In this paper, we aim to select the thumbnail of a given micro-video that meets most users` interests. Towards this end, we present a multi-label visual-semantic embedding model to estimate the similarity between the pair of each frame and the popular topics that users are interested in. In this model, the visual and textual information is embedded into a shared semantic space, whereby the similarity can be measured directly, even the unseen words. Moreover, to compare the frame to all words from the popular topics, we devise an attention embedding space associated with the semantic-attention projection. With the help of these two embedding spaces, the popularity score of a frame, which is defined by the sum of similarity scores over the corresponding visual information and popular topic pairs, is achieved. Ultimately, we fuse the visual representation score and the popularity score of each frame to select the attractive thumbnail for the given micro-video. Extensive experiments conducted on a real-world dataset have well-verified that our model significantly outperforms several state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2202.02930",
    "authors": [
      "Liu Bo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.02947",
    "title": "Parallel Successive Learning for Dynamic Distributed Model Training over  Heterogeneous Wireless Networks",
    "abstract": "Federated learning (FedL) has emerged as a popular technique for distributing model training over a set of wireless devices, via iterative local updates (at devices) and global aggregations (at the server). In this paper, we develop \\textit{parallel successive learning} (PSL), which expands the FedL architecture along three dimensions: (i) Network, allowing decentralized cooperation among the devices via device-to-device (D2D) communications. (ii) Heterogeneity, interpreted at three levels: (ii-a) Learning: PSL considers heterogeneous number of stochastic gradient descent iterations with different mini-batch sizes at the devices; (ii-b) Data: PSL presumes a dynamic environment with data arrival and departure, where the distributions of local datasets evolve over time, captured via a new metric for model/concept drift. (ii-c) Device: PSL considers devices with different computation and communication capabilities. (iii) Proximity, where devices have different distances to each other and the access point. PSL considers the realistic scenario where global aggregations are conducted with idle times in-between them for resource efficiency improvements, and incorporates data dispersion and model dispersion with local model condensation into FedL. Our analysis sheds light on the notion of cold vs. warmed up models, and model inertia in distributed machine learning. We then propose network-aware dynamic model tracking to optimize the model learning vs. resource efficiency tradeoff, which we show is an NP-hard signomial programming problem. We finally solve this problem through proposing a general optimization solver. Our numerical results reveal new findings on the interdependencies between the idle times in-between the global aggregations, model/concept drift, and D2D cooperation configuration. ",
    "url": "https://arxiv.org/abs/2202.02947",
    "authors": [
      "Seyyedali Hosseinalipour",
      "Su Wang",
      "Nicolo Michelusi",
      "Vaneet Aggarwal",
      "Christopher G. Brinton",
      "David J. Love",
      "Mung Chiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.02967",
    "title": "Learning from Imperfect Demonstrations via Adversarial Confidence  Transfer",
    "abstract": "Existing learning from demonstration algorithms usually assume access to expert demonstrations. However, this assumption is limiting in many real-world applications since the collected demonstrations may be suboptimal or even consist of failure cases. We therefore study the problem of learning from imperfect demonstrations by learning a confidence predictor. Specifically, we rely on demonstrations along with their confidence values from a different correspondent environment (source environment) to learn a confidence predictor for the environment we aim to learn a policy in (target environment -- where we only have unlabeled demonstrations.) We learn a common latent space through adversarial distribution matching of multi-length partial trajectories to enable the transfer of confidence across source and target environments. The learned confidence reweights the demonstrations to enable learning more from informative demonstrations and discarding the irrelevant ones. Our experiments in three simulated environments and a real robot reaching task demonstrate that our approach learns a policy with the highest expected return. ",
    "url": "https://arxiv.org/abs/2202.02967",
    "authors": [
      "Zhangjie Cao",
      "Zihan Wang",
      "Dorsa Sadigh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02976",
    "title": "Measuring and Reducing Model Update Regression in Structured Prediction  for NLP",
    "abstract": "Recent advance in deep learning has led to rapid adoption of machine learning based NLP models in a wide range of applications. Despite the continuous gain in accuracy, backward compatibility is also an important aspect for industrial applications, yet it received little research attention. Backward compatibility requires that the new model does not regress on cases that were correctly handled by its predecessor. This work studies model update regression in structured prediction tasks. We choose syntactic dependency parsing and conversational semantic parsing as representative examples of structured prediction tasks in NLP. First, we measure and analyze model update regression in different model update settings. Next, we explore and benchmark existing techniques for reducing model update regression including model ensemble and knowledge distillation. We further propose a simple and effective method, Backward-Congruent Re-ranking (BCR), by taking into account the characteristics of structured output. Experiments show that BCR can better mitigate model update regression than model ensemble and knowledge distillation approaches. ",
    "url": "https://arxiv.org/abs/2202.02976",
    "authors": [
      "Deng Cai",
      "Elman Mansimov",
      "Yi-An Lai",
      "Yixuan Su",
      "Lei Shu",
      "Yi Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02980",
    "title": "3D Object Detection from Images for Autonomous Driving: A Survey",
    "abstract": "3D object detection from images, one of the fundamental and challenging problems in autonomous driving, has received increasing attention from both industry and academia in recent years. Benefiting from the rapid development of deep learning technologies, image-based 3D detection has achieved remarkable progress. Particularly, more than 200 works have studied this problem from 2015 to 2021, encompassing a broad spectrum of theories, algorithms, and applications. However, to date no recent survey exists to collect and organize this knowledge. In this paper, we fill this gap in the literature and provide the first comprehensive survey of this novel and continuously growing research field, summarizing the most commonly used pipelines for image-based 3D detection and deeply analyzing each of their components. Additionally, we also propose two new taxonomies to organize the state-of-the-art methods into different categories, with the intent of providing a more systematic review of existing methods and facilitating fair comparisons with future works. In retrospect of what has been achieved so far, we also analyze the current challenges in the field and discuss future directions for image-based 3D detection research. ",
    "url": "https://arxiv.org/abs/2202.02980",
    "authors": [
      "Xinzhu Ma",
      "Wanli Ouyang",
      "Andrea Simonelli",
      "Elisa Ricci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.02981",
    "title": "Neural Tangent Kernel Analysis of Deep Narrow Neural Networks",
    "abstract": "The tremendous recent progress in analyzing the training dynamics of overparameterized neural networks has primarily focused on wide networks and therefore does not sufficiently address the role of depth in deep learning. In this work, we present the first trainability guarantee of infinitely deep but narrow neural networks. We study the infinite-depth limit of a multilayer perceptron (MLP) with a specific initialization and establish a trainability guarantee using the NTK theory. We then extend the analysis to an infinitely deep convolutional neural network (CNN) and perform brief experiments ",
    "url": "https://arxiv.org/abs/2202.02981",
    "authors": [
      "Jongmin Lee",
      "Joo Young Choi",
      "Ernest K. Ryu",
      "Albert No"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.02989",
    "title": "Graph Self-supervised Learning with Accurate Discrepancy Learning",
    "abstract": "Self-supervised learning of graph neural networks (GNNs) aims to learn an accurate representation of the graphs in an unsupervised manner, to obtain transferable representations of them for diverse downstream tasks. Predictive learning and contrastive learning are the two most prevalent approaches for graph self-supervised learning. However, they have their own drawbacks. While the predictive learning methods can learn the contextual relationships between neighboring nodes and edges, they cannot learn global graph-level similarities. Contrastive learning, while it can learn global graph-level similarities, its objective to maximize the similarity between two differently perturbed graphs may result in representations that cannot discriminate two similar graphs with different properties. To tackle such limitations, we propose a framework that aims to learn the exact discrepancy between the original and the perturbed graphs, coined as Discrepancy-based Self-supervised LeArning (D-SLA). Specifically, we create multiple perturbations of the given graph with varying degrees of similarity and train the model to predict whether each graph is the original graph or a perturbed one. Moreover, we further aim to accurately capture the amount of discrepancy for each perturbed graph using the graph edit distance. We validate our method on various graph-related downstream tasks, including molecular property prediction, protein function prediction, and link prediction tasks, on which our model largely outperforms relevant baselines. ",
    "url": "https://arxiv.org/abs/2202.02989",
    "authors": [
      "Dongki Kim",
      "Jinheon Baek",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.03004",
    "title": "Network Calculus with Flow Prolongation -- A Feedforward FIFO Analysis  enabled by ML",
    "abstract": "The derivation of upper bounds on data flows' worst-case traversal times is an important task in many application areas. For accurate bounds, model simplifications should be avoided even in large networks. Network Calculus (NC) provides a modeling framework and different analyses for delay bounding. We investigate the analysis of feedforward networks where all queues implement First-In First-Out (FIFO) service. Correctly considering the effect of data flows onto each other under FIFO is already a challenging task. Yet, the fastest available NC FIFO analysis suffers from limitations resulting in unnecessarily loose bounds. A feature called Flow Prolongation (FP) has been shown to improve delay bound accuracy significantly. Unfortunately, FP needs to be executed within the NC FIFO analysis very often and each time it creates an exponentially growing set of alternative networks with prolongations. FP therefore does not scale and has been out of reach for the exhaustive analysis of large networks. We introduce DeepFP, an approach to make FP scale by predicting prolongations using machine learning. In our evaluation, we show that DeepFP can improve results in FIFO networks considerably. Compared to the standard NC FIFO analysis, DeepFP reduces delay bounds by 12.1% on average at negligible additional computational cost. ",
    "url": "https://arxiv.org/abs/2202.03004",
    "authors": [
      "Fabien Geyer",
      "Alexander Scheffler",
      "Steffen Bondorf"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03005",
    "title": "B2EA: An Evolutionary Algorithm Assisted by Two Bayesian Optimization  Modules for Neural Architecture Search",
    "abstract": "The early pioneering Neural Architecture Search (NAS) works were multi-trial methods applicable to any general search space. The subsequent works took advantage of the early findings and developed weight-sharing methods that assume a structured search space typically with pre-fixed hyperparameters. Despite the amazing computational efficiency of the weight-sharing NAS algorithms, it is becoming apparent that multi-trial NAS algorithms are also needed for identifying very high-performance architectures, especially when exploring a general search space. In this work, we carefully review the latest multi-trial NAS algorithms and identify the key strategies including Evolutionary Algorithm (EA), Bayesian Optimization (BO), diversification, input and output transformations, and lower fidelity estimation. To accommodate the key strategies into a single framework, we develop B\\textsuperscript{2}EA that is a surrogate assisted EA with two BO surrogate models and a mutation step in between. To show that B\\textsuperscript{2}EA is robust and efficient, we evaluate three performance metrics over 14 benchmarks with general and cell-based search spaces. Comparisons with state-of-the-art multi-trial algorithms reveal that B\\textsuperscript{2}EA is robust and efficient over the 14 benchmarks for three difficulty levels of target performance. The B\\textsuperscript{2}EA code is publicly available at \\url{https://github.com/snu-adsl/BBEA}. ",
    "url": "https://arxiv.org/abs/2202.03005",
    "authors": [
      "Hyunghun Cho",
      "Jungwook Shin",
      "Wonjong Rhee"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03018",
    "title": "Broadcast Approach Meets Network Coding for Data Streaming",
    "abstract": "For data streaming applications, existing solutions are not yet able to close the gap between high data rates and low delay. This work considers the problem of data streaming under mixed delay constraints over a single communication channel with delayed feedback. We propose a novel layered adaptive causal random linear network coding (LAC-RLNC) approach with forward error correction. LAC-RLNC is a variable-to-variable coding scheme, i.e., variable recovered information data at the receiver over variable short block length and rate is proposed. Specifically, for data streaming with base and enhancement layers of content, we characterize a high dimensional throughput-delay trade-off managed by the adaptive causal layering coding scheme. The base layer is designed to satisfy the strict delay constraints, as it contains the data needed to allow the streaming service. Then, the sender can manage the throughput-delay trade-off of the second layer by adjusting the retransmission rate a priori and posterior as the enhancement layer, that contains the remaining data to augment the streaming service's quality, is with the relax delay constraints. We numerically show that the layered network coding approach can dramatically increase performance. We demonstrate that LAC-RLNC compared with the non-layered approach gains a factor of three in mean and maximum delay for the base layer, close to the lower bound, and factor two for the enhancement layer. ",
    "url": "https://arxiv.org/abs/2202.03018",
    "authors": [
      "Alejandro Cohen",
      "Muriel M\u00e9dard",
      "Shlomo Shamai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.03026",
    "title": "Context Autoencoder for Self-Supervised Representation Learning",
    "abstract": "We present a novel masked image modeling (MIM) approach, context autoencoder (CAE), for self-supervised learning. We randomly partition the image into two sets: visible patches and masked patches. The CAE architecture consists of: (i) an encoder that takes visible patches as input and outputs their latent representations, (ii) a latent context regressor that predicts the masked patch representations from the visible patch representations that are not updated in this regressor, (iii) a decoder that takes the estimated masked patch representations as input and makes predictions for the masked patches, and (iv) an alignment module that aligns the masked patch representation estimation with the masked patch representations computed from the encoder. In comparison to previous MIM methods that couple the encoding and decoding roles, e.g., using a single module in BEiT, our approach attempts to~\\emph{separate the encoding role (content understanding) from the decoding role (making predictions for masked patches)} using different modules, improving the content understanding capability. In addition, our approach makes predictions from the visible patches to the masked patches in \\emph{the latent representation space} that is expected to take on semantics. In addition, we present the explanations about why contrastive pretraining and supervised pretraining perform similarly and why MIM potentially performs better. We demonstrate the effectiveness of our CAE through superior transfer performance in downstream tasks: semantic segmentation, and object detection and instance segmentation. ",
    "url": "https://arxiv.org/abs/2202.03026",
    "authors": [
      "Xiaokang Chen",
      "Mingyu Ding",
      "Xiaodi Wang",
      "Ying Xin",
      "Shentong Mo",
      "Yunhao Wang",
      "Shumin Han",
      "Ping Luo",
      "Gang Zeng",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.03033",
    "title": "Mental Stress Detection using Data from Wearable and Non-wearable  Sensors: A Review",
    "abstract": "This paper presents a comprehensive review of methods covering significant subjective and objective human stress detection techniques available in the literature. The methods for measuring human stress responses could include subjective questionnaires (developed by psychologists) and objective markers observed using data from wearable and non-wearable sensors. In particular, wearable sensor-based methods commonly use data from electroencephalography, electrocardiogram, galvanic skin response, electromyography, electrodermal activity, heart rate, heart rate variability, and photoplethysmography both individually and in multimodal fusion strategies. Whereas, methods based on non-wearable sensors include strategies such as analyzing pupil dilation and speech, smartphone data, eye movement, body posture, and thermal imaging. Whenever a stressful situation is encountered by an individual, physiological, physical, or behavioral changes are induced which help in coping with the challenge at hand. A wide range of studies has attempted to establish a relationship between these stressful situations and the response of human beings by using different kinds of psychological, physiological, physical, and behavioral measures. Inspired by the lack of availability of a definitive verdict about the relationship of human stress with these different kinds of markers, a detailed survey about human stress detection methods is conducted in this paper. In particular, we explore how stress detection methods can benefit from artificial intelligence utilizing relevant data from various sources. This review will prove to be a reference document that would provide guidelines for future research enabling effective detection of human stress conditions. ",
    "url": "https://arxiv.org/abs/2202.03033",
    "authors": [
      "Aamir Arsalan",
      "Syed Muhammad Anwar",
      "Muhammad Majid"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.03038",
    "title": "Deep Networks on Toroids: Removing Symmetries Reveals the Structure of  Flat Regions in the Landscape Geometry",
    "abstract": "We systematize the approach to the investigation of deep neural network landscapes by basing it on the geometry of the space of implemented functions rather than the space of parameters. Grouping classifiers into equivalence classes, we develop a standardized parameterization in which all symmetries are removed, resulting in a toroidal topology. On this space, we explore the error landscape rather than the loss. This lets us derive a meaningful notion of the flatness of minimizers and of the geodesic paths connecting them. Using different optimization algorithms that sample minimizers with different flatness we study the mode connectivity and other characteristics. Testing a variety of state-of-the-art architectures and benchmark datasets, we confirm the correlation between flatness and generalization performance; we further show that in function space flatter minima are closer to each other and that the barriers along the geodesics connecting them are small. We also find that minimizers found by variants of gradient descent can be connected by zero-error paths with a single bend. We observe similar qualitative results in neural networks with binary weights and activations, providing one of the first results concerning the connectivity in this setting. Our results hinge on symmetry removal, and are in remarkable agreement with the rich phenomenology described by some recent analytical studies performed on simple shallow models. ",
    "url": "https://arxiv.org/abs/2202.03038",
    "authors": [
      "Fabrizio Pittorino",
      "Antonio Ferraro",
      "Gabriele Perugini",
      "Christoph Feinauer",
      "Carlo Baldassi",
      "Riccardo Zecchina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)"
    ]
  },
  {
    "id": "arXiv:2202.03047",
    "title": "Data set creation and empirical analysis for detecting signs of  depression from social media postings",
    "abstract": "Depression is a common mental illness that has to be detected and treated at an early stage to avoid serious consequences. There are many methods and modalities for detecting depression that involves physical examination of the individual. However, diagnosing mental health using their social media data is more effective as it avoids such physical examinations. Also, people express their emotions well in social media, it is desirable to diagnose their mental health using social media data. Though there are many existing systems that detects mental illness of a person by analysing their social media data, detecting the level of depression is also important for further treatment. Thus, in this research, we developed a gold standard data set that detects the levels of depression as `not depressed', `moderately depressed' and `severely depressed' from the social media postings. Traditional learning algorithms were employed on this data set and an empirical analysis was presented in this paper. Data augmentation technique was applied to overcome the data imbalance. Among the several variations that are implemented, the model with Word2Vec vectorizer and Random Forest classifier on augmented data outperforms the other variations with a score of 0.877 for both accuracy and F1 measure. ",
    "url": "https://arxiv.org/abs/2202.03047",
    "authors": [
      "Kayalvizhi S",
      "Thenmozhi D"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.03055",
    "title": "Enabling Automatic Repair of Source Code Vulnerabilities Using  Data-Driven Methods",
    "abstract": "Users around the world rely on software-intensive systems in their day-to-day activities. These systems regularly contain bugs and security vulnerabilities. To facilitate bug fixing, data-driven models of automatic program repair use pairs of buggy and fixed code to learn transformations that fix errors in code. However, automatic repair of security vulnerabilities remains under-explored. In this work, we propose ways to improve code representations for vulnerability repair from three perspectives: input data type, data-driven models, and downstream tasks. The expected results of this work are improved code representations for automatic program repair and, specifically, fixing security vulnerabilities. ",
    "url": "https://arxiv.org/abs/2202.03055",
    "authors": [
      "Anastasiia Grishina"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03068",
    "title": "Artificial Intelligence based tool wear and defect prediction for  special purpose milling machinery using low-cost acceleration sensor  retrofits",
    "abstract": "Milling machines form an integral part of many industrial processing chains. As a consequence, several machine learning based approaches for tool wear detection have been proposed in recent years, yet these methods mostly deal with standard milling machines, while machinery designed for more specialized tasks has gained only limited attention so far. This paper demonstrates the application of an acceleration sensor to allow for convenient condition monitoring of such a special purpose machine, i.e. round seam milling machine. We examine a variety of conditions including blade wear and blade breakage as well as improper machine mounting or insufficient transmission belt tension. In addition, we presents different approaches to supervised failure recognition with limited amounts of training data. Hence, aside theoretical insights, our analysis is of high, practical importance, since retrofitting older machines with acceleration sensors and an on-edge classification setup comes at low cost and effort, yet provides valuable insights into the state of the machine and tools in particular and the production process in general. ",
    "url": "https://arxiv.org/abs/2202.03068",
    "authors": [
      "Mahmoud Kheir-Eddine",
      "Michael Banf",
      "Gregor Steinhagen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.03071",
    "title": "Distributionally Robust Fair Principal Components via Geodesic Descents",
    "abstract": "Principal component analysis is a simple yet useful dimensionality reduction technique in modern machine learning pipelines. In consequential domains such as college admission, healthcare and credit approval, it is imperative to take into account emerging criteria such as the fairness and the robustness of the learned projection. In this paper, we propose a distributionally robust optimization problem for principal component analysis which internalizes a fairness criterion in the objective function. The learned projection thus balances the trade-off between the total reconstruction error and the reconstruction error gap between subgroups, taken in the min-max sense over all distributions in a moment-based ambiguity set. The resulting optimization problem over the Stiefel manifold can be efficiently solved by a Riemannian subgradient descent algorithm with a sub-linear convergence rate. Our experimental results on real-world datasets show the merits of our proposed method over state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2202.03071",
    "authors": [
      "Hieu Vu",
      "Toan Tran",
      "Man-Chung Yue",
      "Viet Anh Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.03077",
    "title": "Adversarial Attacks and Defense for Non-Parametric Two-Sample Tests",
    "abstract": "Non-parametric two-sample tests (TSTs) that judge whether two sets of samples are drawn from the same distribution, have been widely used in the analysis of critical data. People tend to employ TSTs as trusted basic tools and rarely have any doubt about their reliability. This paper systematically uncovers the failure mode of non-parametric TSTs through adversarial attacks and then proposes corresponding defense strategies. First, we theoretically show that an adversary can upper-bound the distributional shift which guarantees the attack's invisibility. Furthermore, we theoretically find that the adversary can also degrade the lower bound of a TST's test power, which enables us to iteratively minimize the test criterion in order to search for adversarial pairs. To enable TST-agnostic attacks, we propose an ensemble attack (EA) framework that jointly minimizes the different types of test criteria. Second, to robustify TSTs, we propose a max-min optimization that iteratively generates adversarial pairs to train the deep kernels. Extensive experiments on both simulated and real-world datasets validate the adversarial vulnerabilities of non-parametric TSTs and the effectiveness of our proposed defense. ",
    "url": "https://arxiv.org/abs/2202.03077",
    "authors": [
      "Xilie Xu",
      "Jingfeng Zhang",
      "Feng Liu",
      "Masashi Sugiyama",
      "Mohan Kankanhalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.03078",
    "title": "Fair Interpretable Representation Learning with Correction Vectors",
    "abstract": "Neural network architectures have been extensively employed in the fair representation learning setting, where the objective is to learn a new representation for a given vector which is independent of sensitive information. Various representation debiasing techniques have been proposed in the literature. However, as neural networks are inherently opaque, these methods are hard to comprehend, which limits their usefulness. We propose a new framework for fair representation learning that is centered around the learning of \"correction vectors\", which have the same dimensionality as the given data vectors. Correction vectors may be computed either explicitly via architectural constraints or implicitly by training an invertible model based on Normalizing Flows. We show experimentally that several fair representation learning models constrained in such a way do not exhibit losses in ranking or classification performance. Furthermore, we demonstrate that state-of-the-art results can be achieved by the invertible model. Finally, we discuss the law standing of our methodology in light of recent legislation in the European Union. ",
    "url": "https://arxiv.org/abs/2202.03078",
    "authors": [
      "Mattia Cerrato",
      "Alesia Vallenas Coronel",
      "Marius K\u00f6ppel",
      "Alexander Segner",
      "Roberto Esposito",
      "Stefan Kramer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2202.03103",
    "title": "Combining Deep Learning and Reasoning for Address Detection in  Unstructured Text Documents",
    "abstract": "Extracting information from unstructured text documents is a demanding task, since these documents can have a broad variety of different layouts and a non-trivial reading order, like it is the case for multi-column documents or nested tables. Additionally, many business documents are received in paper form, meaning that the textual contents need to be digitized before further analysis. Nonetheless, automatic detection and capturing of crucial document information like the sender address would boost many companies' processing efficiency. In this work we propose a hybrid approach that combines deep learning with reasoning for finding and extracting addresses from unstructured text documents. We use a visual deep learning model to detect the boundaries of possible address regions on the scanned document images and validate these results by analyzing the containing text using domain knowledge represented as a rule based system. ",
    "url": "https://arxiv.org/abs/2202.03103",
    "authors": [
      "Matthias Engelbach",
      "Dennis Klau",
      "Jens Drawehn",
      "Maximilien Kintz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03104",
    "title": "SimGRACE: A Simple Framework for Graph Contrastive Learning without Data  Augmentation",
    "abstract": "Graph contrastive learning (GCL) has emerged as a dominant technique for graph representation learning which maximizes the mutual information between paired graph augmentations that share the same semantics. Unfortunately, it is difficult to preserve semantics well during augmentations in view of the diverse nature of graph data. Currently, data augmentations in GCL that are designed to preserve semantics broadly fall into three unsatisfactory ways. First, the augmentations can be manually picked per dataset by trial-and-errors. Second, the augmentations can be selected via cumbersome search. Third, the augmentations can be obtained by introducing expensive domain-specific knowledge as guidance. All of these limit the efficiency and more general applicability of existing GCL methods. To circumvent these crucial issues, we propose a \\underline{Sim}ple framework for \\underline{GRA}ph \\underline{C}ontrastive l\\underline{E}arning, \\textbf{SimGRACE} for brevity, which does not require data augmentations. Specifically, we take original graph as input and GNN model with its perturbed version as two encoders to obtain two correlated views for contrast. SimGRACE is inspired by the observation that graph data can preserve their semantics well during encoder perturbations while not requiring manual trial-and-errors, cumbersome search or expensive domain knowledge for augmentations selection. Also, we explain why SimGRACE can succeed. Furthermore, we devise adversarial training scheme, dubbed \\textbf{AT-SimGRACE}, to enhance the robustness of graph contrastive learning and theoretically explain the reasons. Albeit simple, we show that SimGRACE can yield competitive or better performance compared with state-of-the-art methods in terms of generalizability, transferability and robustness, while enjoying unprecedented degree of flexibility and efficiency. ",
    "url": "https://arxiv.org/abs/2202.03104",
    "authors": [
      "Jun Xia",
      "Lirong Wu",
      "Jintao Chen",
      "Bozhen Hu",
      "Stan Z.Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2202.03126",
    "title": "Reasoning for Complex Data through Ensemble-based Self-Supervised  Learning",
    "abstract": "Self-supervised learning deals with problems that have little or no available labeled data. Recent work has shown impressive results when underlying classes have significant semantic differences. One important dataset in which this technique thrives is ImageNet, as intra-class distances are substantially lower than inter-class distances. However, this is not the case for several critical tasks, and general self-supervised learning methods fail to learn discriminative features when classes have closer semantics, thus requiring more robust strategies. We propose a strategy to tackle this problem, and to enable learning from unlabeled data even when samples from different classes are not prominently diverse. We approach the problem by leveraging a novel ensemble-based clustering strategy where clusters derived from different configurations are combined to generate a better grouping for the data samples in a fully-unsupervised way. This strategy allows clusters with different densities and higher variability to emerge, which in turn reduces intra-class discrepancies, without requiring the burden of finding an optimal configuration per dataset. We also consider different Convolutional Neural Networks to compute distances between samples. We refine these distances by performing context analysis and group them to capture complementary information. We consider two applications to validate our pipeline: Person Re-Identification and Text Authorship Verification. These are challenging applications considering that classes are semantically close to each other and that training and test sets have disjoint identities. Our method is robust across different modalities and outperforms state-of-the-art results with a fully-unsupervised solution without any labeling or human intervention. ",
    "url": "https://arxiv.org/abs/2202.03126",
    "authors": [
      "Gabriel Bertocco",
      "Ant\u00f4nio The\u00f3filo",
      "Fernanda Andal\u00f3",
      "Anderson Rocha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.03129",
    "title": "Over-the-Air Ensemble Inference with Model Privacy",
    "abstract": "We consider distributed inference at the wireless edge, where multiple clients with an ensemble of models, each trained independently on a local dataset, are queried in parallel to make an accurate decision on a new sample. In addition to maximizing inference accuracy, we also want to maximize the privacy of local models. We exploit the superposition property of the air to implement bandwidth-efficient ensemble inference methods. We introduce different over-the-air ensemble methods and show that these schemes perform significantly better than their orthogonal counterparts, while using less resources and providing privacy guarantees. We also provide experimental results verifying the benefits of the proposed over-the-air inference approach, whose source code is shared publicly on Github. ",
    "url": "https://arxiv.org/abs/2202.03129",
    "authors": [
      "Selim F. Yilmaz",
      "Burak Hasircioglu",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.03131",
    "title": "Transformers in Self-Supervised Monocular Depth Estimation with Unknown  Camera Intrinsics",
    "abstract": "The advent of autonomous driving and advanced driver assistance systems necessitates continuous developments in computer vision for 3D scene understanding. Self-supervised monocular depth estimation, a method for pixel-wise distance estimation of objects from a single camera without the use of ground truth labels, is an important task in 3D scene understanding. However, existing methods for this task are limited to convolutional neural network (CNN) architectures. In contrast with CNNs that use localized linear operations and lose feature resolution across the layers, vision transformers process at constant resolution with a global receptive field at every stage. While recent works have compared transformers against their CNN counterparts for tasks such as image classification, no study exists that investigates the impact of using transformers for self-supervised monocular depth estimation. Here, we first demonstrate how to adapt vision transformers for self-supervised monocular depth estimation. Thereafter, we compare the transformer and CNN-based architectures for their performance on KITTI depth prediction benchmarks, as well as their robustness to natural corruptions and adversarial attacks, including when the camera intrinsics are unknown. Our study demonstrates how transformer-based architecture, though lower in run-time efficiency, achieves comparable performance while being more robust and generalizable. ",
    "url": "https://arxiv.org/abs/2202.03131",
    "authors": [
      "Arnav Varma",
      "Hemang Chawla",
      "Bahram Zonooz",
      "Elahe Arani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.03133",
    "title": "Rate Coding or Direct Coding: Which One is Better for Accurate, Robust,  and Energy-efficient Spiking Neural Networks?",
    "abstract": "Recent Spiking Neural Networks (SNNs) works focus on an image classification task, therefore various coding techniques have been proposed to convert an image into temporal binary spikes. Among them, rate coding and direct coding are regarded as prospective candidates for building a practical SNN system as they show state-of-the-art performance on large-scale datasets. Despite their usage, there is little attention to comparing these two coding schemes in a fair manner. In this paper, we conduct a comprehensive analysis of the two codings from three perspectives: accuracy, adversarial robustness, and energy-efficiency. First, we compare the performance of two coding techniques with various architectures and datasets. Then, we measure the robustness of the coding techniques on two adversarial attack methods. Finally, we compare the energy-efficiency of two coding schemes on a digital hardware platform. Our results show that direct coding can achieve better accuracy especially for a small number of timesteps. In contrast, rate coding shows better robustness to adversarial attacks owing to the non-differentiable spike generation process. Rate coding also yields higher energy-efficiency than direct coding which requires multi-bit precision for the first layer. Our study explores the characteristics of two codings, which is an important design consideration for building SNNs. The code is made available at https://github.com/Intelligent-Computing-Lab-Yale/Rate-vs-Direct. ",
    "url": "https://arxiv.org/abs/2202.03133",
    "authors": [
      "Youngeun Kim",
      "Hyoungseob Park",
      "Abhishek Moitra",
      "Abhiroop Bhattacharjee",
      "Yeshwanth Venkatesha",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.03140",
    "title": "OPP-Miner: Order-preserving sequential pattern mining",
    "abstract": "A time series is a collection of measurements in chronological order. Discovering patterns from time series is useful in many domains, such as stock analysis, disease detection, and weather forecast. To discover patterns, existing methods often convert time series data into another form, such as nominal/symbolic format, to reduce dimensionality, which inevitably deviates the data values. Moreover, existing methods mainly neglect the order relationships between time series values. To tackle these issues, inspired by order-preserving matching, this paper proposes an Order-Preserving sequential Pattern (OPP) mining method, which represents patterns based on the order relationships of the time series data. An inherent advantage of such representation is that the trend of a time series can be represented by the relative order of the values underneath the time series data. To obtain frequent trends in time series, we propose the OPP-Miner algorithm to mine patterns with the same trend (sub-sequences with the same relative order). OPP-Miner employs the filtration and verification strategies to calculate the support and uses pattern fusion strategy to generate candidate patterns. To compress the result set, we also study finding the maximal OPPs. Experiments validate that OPP-Miner is not only efficient and scalable but can also discover similar sub-sequences in time series. In addition, case studies show that our algorithms have high utility in analyzing the COVID-19 epidemic by identifying critical trends and improve the clustering performance. ",
    "url": "https://arxiv.org/abs/2202.03140",
    "authors": [
      "Youxi Wu",
      "Qian Hu",
      "Yan Li",
      "Lei Guo",
      "Xingquan Zhu",
      "Xindong Wu"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.03150",
    "title": "Modular representation and control of floppy networks",
    "abstract": "Geometric graph models of systems as diverse as proteins, robots, and mechanical structures from DNA assemblies to architected materials point towards a unified way to represent and control them in space and time. While much work has been done in the context of characterizing the behavior of these networks close to critical points associated with bond and rigidity percolation, isostaticity, etc., much less is known about floppy, under-constrained networks that are far more common in nature and technology. Here we combine geometric rigidity and algebraic sparsity to provide a framework for identifying the zero-energy floppy modes via a representation that illuminates the underlying hierarchy and modularity of the network, and thence the control of its nestedness and locality. Our framework allows us to demonstrate a range of applications of this approach that include robotic reaching tasks with motion primitives, and predicting the linear and nonlinear response of elastic networks based solely on infinitesimal rigidity and sparsity, which we test using physical experiments. Our approach is thus likely to be of use broadly in dissecting the geometrical properties of floppy networks using algebraic sparsity to optimize their function and performance. ",
    "url": "https://arxiv.org/abs/2202.03150",
    "authors": [
      "Siheng Chen",
      "Fabio Giardina",
      "Gary P. T. Choi",
      "L. Mahadevan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2202.03157",
    "title": "T-Plots: A Novel Approach to Network Design",
    "abstract": "It is accepted wisdom that changes in the traffic matrix entail capacity over-provisioning, but there is no simple measure of just how much over-provisioning can buy. In this Thesis, we aim to provide the network designer with a simple view of the network robustness to traffic matrix changes. We first present the Traffic Load Distribution Plots, or T-Plots, a class of plots illustrating the percentage of traffic matrices that can be serviced as a function of the capacity over-provisioning. For instance, from a simple look at their T- Plots, network designers can guarantee that their network services all admissible traffic matrices, or 99% of permutation traffic matrices, or all traffic matrices with ingress/egress load at most half the maximum. We further show that, unfortunately, in the general case plotting T-Plots is #P-Complete, i.e., that it is impossible to plot a T-plot in a polynomial time by the noon tools. However, we show that T-Plots can sometimes be closely modeled as Gaussian, thus only using two values (mean and variance) to quantify the robustness of a capacity allocation to traffic matrix changes. We further utilize these Gaussian T-Plots to provide a more robust capacity allocation. Finally, we demonstrate the benefits of using T-Plots by showing results of extensive Monte Carlo simulations in a real backbone network. This Thesis was submitted in 2007. Since then, the results that appeared in it were applied in various networking environments. In this newer version, we revisit the results 13 years later and explain their relevance to state-of-the-art problems in network design. ",
    "url": "https://arxiv.org/abs/2202.03157",
    "authors": [
      "Itamar Cohen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2202.03169",
    "title": "CITRIS: Causal Identifiability from Temporal Intervened Sequences",
    "abstract": "Understanding the latent causal factors of a dynamical system from visual observations is a crucial step towards agents reasoning in complex environments. In this paper, we propose CITRIS, a variational autoencoder framework that learns causal representations from temporal sequences of images in which underlying causal factors have possibly been intervened upon. In contrast to the recent literature, CITRIS exploits temporality and observing intervention targets to identify scalar and multidimensional causal factors, such as 3D rotation angles. Furthermore, by introducing a normalizing flow, CITRIS can be easily extended to leverage and disentangle representations obtained by already pretrained autoencoders. Extending previous results on scalar causal factors, we prove identifiability in a more general setting, in which only some components of a causal factor are affected by interventions. In experiments on 3D rendered image sequences, CITRIS outperforms previous methods on recovering the underlying causal variables. Moreover, using pretrained autoencoders, CITRIS can even generalize to unseen instantiations of causal factors, opening future research areas in sim-to-real generalization for causal representation learning. ",
    "url": "https://arxiv.org/abs/2202.03169",
    "authors": [
      "Phillip Lippe",
      "Sara Magliacane",
      "Sindy L\u00f6we",
      "Yuki M. Asano",
      "Taco Cohen",
      "Efstratios Gavves"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2202.03173",
    "title": "Towards Loosely-Coupling Knowledge Graph Embeddings and Ontology-based  Reasoning",
    "abstract": "Knowledge graph completion (a.k.a.~link prediction), i.e.,~the task of inferring missing information from knowledge graphs, is a widely used task in many applications, such as product recommendation and question answering. The state-of-the-art approaches of knowledge graph embeddings and/or rule mining and reasoning are data-driven and, thus, solely based on the information the input knowledge graph contains. This leads to unsatisfactory prediction results which make such solutions inapplicable to crucial domains such as healthcare. To further enhance the accuracy of knowledge graph completion we propose to loosely-couple the data-driven power of knowledge graph embeddings with domain-specific reasoning stemming from experts or entailment regimes (e.g., OWL2). In this way, we not only enhance the prediction accuracy with domain knowledge that may not be included in the input knowledge graph but also allow users to plugin their own knowledge graph embedding and reasoning method. Our initial results show that we enhance the MRR accuracy of vanilla knowledge graph embeddings by up to 3x and outperform hybrid solutions that combine knowledge graph embeddings with rule mining and reasoning up to 3.5x MRR. ",
    "url": "https://arxiv.org/abs/2202.03173",
    "authors": [
      "Zoi Kaoudi",
      "Abelardo Carlos Martinez Lorenzo",
      "Volker Markl"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03176",
    "title": "Field-of-View IoU for Object Detection in 360\u00b0 Images",
    "abstract": "360{\\deg} cameras have gained popularity over the last few years. In this paper, we propose two fundamental techniques -- Field-of-View IoU (FoV-IoU) and 360Augmentation for object detection in 360{\\deg} images. Although most object detection neural networks designed for the perspective images are applicable to 360{\\deg} images in equirectangular projection (ERP) format, their performance deteriorates owing to the distortion in ERP images. Our method can be readily integrated with existing perspective object detectors and significantly improves the performance. The FoV-IoU computes the intersection-over-union of two Field-of-View bounding boxes in a spherical image which could be used for training, inference, and evaluation while 360Augmentation is a data augmentation technique specific to 360{\\deg} object detection task which randomly rotates a spherical image and solves the bias due to the sphere-to-plane projection. We conduct extensive experiments on the 360indoor dataset with different types of perspective object detectors and show the consistent effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2202.03176",
    "authors": [
      "Miao Cao",
      "Satoshi Ikehata",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.03179",
    "title": "A Tensor Based Regression Approach for Human Motion Prediction",
    "abstract": "Collaborative robotic systems will be a key enabling technology for current and future industrial applications. The main aspect of such applications is to guarantee safety for humans. To detect hazardous situations, current commercially available robotic systems rely on direct physical contact to the co-working person. To further advance this technology, there are multiple efforts to develop predictive capabilities for such systems. Using motion tracking sensors and pose estimation systems combined with adequate predictive models, potential episodes of hazardous collisions between humans and robots can be predicted. Based on the provided predictive information, the robotic system can avoid physical contact by adjusting speed or position. A potential approach for such systems is to perform human motion prediction with machine learning methods like Artificial Neural Networks. In our approach, the motion patterns of past seconds are used to predict future ones by applying a linear Tensor-on-Tensor regression model, selected according to a similarity measure between motion sequences obtained by Dynamic TimeWarping. For test and validation of our proposed approach, industrial pseudo assembly tasks were recorded with a motion capture system, providing unique traceable Cartesian coordinates $(x, y, z)$ for each human joint. The prediction of repetitive human motions associated with assembly tasks, whose data vary significantly in length and have highly correlated variables, has been achieved in real time. ",
    "url": "https://arxiv.org/abs/2202.03179",
    "authors": [
      "Lorena Gril",
      "Philipp Wedenig",
      "Chris Torkar",
      "Ulrike Kleb"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.03183",
    "title": "TransFollower: Long-Sequence Car-Following Trajectory Prediction through  Transformer",
    "abstract": "Car-following refers to a control process in which the following vehicle (FV) tries to keep a safe distance between itself and the lead vehicle (LV) by adjusting its acceleration in response to the actions of the vehicle ahead. The corresponding car-following models, which describe how one vehicle follows another vehicle in the traffic flow, form the cornerstone for microscopic traffic simulation and intelligent vehicle development. One major motivation of car-following models is to replicate human drivers' longitudinal driving trajectories. To model the long-term dependency of future actions on historical driving situations, we developed a long-sequence car-following trajectory prediction model based on the attention-based Transformer model. The model follows a general format of encoder-decoder architecture. The encoder takes historical speed and spacing data as inputs and forms a mixed representation of historical driving context using multi-head self-attention. The decoder takes the future LV speed profile as input and outputs the predicted future FV speed profile in a generative way (instead of an auto-regressive way, avoiding compounding errors). Through cross-attention between encoder and decoder, the decoder learns to build a connection between historical driving and future LV speed, based on which a prediction of future FV speed can be obtained. We train and test our model with 112,597 real-world car-following events extracted from the Shanghai Naturalistic Driving Study (SH-NDS). Results show that the model outperforms the traditional intelligent driver model (IDM), a fully connected neural network model, and a long short-term memory (LSTM) based model in terms of long-sequence trajectory prediction accuracy. We also visualized the self-attention and cross-attention heatmaps to explain how the model derives its predictions. ",
    "url": "https://arxiv.org/abs/2202.03183",
    "authors": [
      "Meixin Zhu",
      "Simon S. Du",
      "Xuesong Wang",
      "Yang",
      "Ziyuan Pu",
      "Yinhai Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03193",
    "title": "Network Resource Allocation Strategy Based on Deep Reinforcement  Learning",
    "abstract": "The traditional Internet has encountered a bottleneck in allocating network resources for emerging technology needs. Network virtualization (NV) technology as a future network architecture, the virtual network embedding (VNE) algorithm it supports shows great potential in solving resource allocation problems. Combined with the efficient machine learning (ML) algorithm, a neural network model close to the substrate network environment is constructed to train the reinforcement learning agent. This paper proposes a two-stage VNE algorithm based on deep reinforcement learning (DRL) (TS-DRL-VNE) for the problem that the mapping result of existing heuristic algorithm is easy to converge to the local optimal solution. For the problem that the existing VNE algorithm based on ML often ignores the importance of substrate network representation and training mode, a DRL VNE algorithm based on full attribute matrix (FAM-DRL-VNE) is proposed. In view of the problem that the existing VNE algorithm often ignores the underlying resource changes between virtual network requests, a DRL VNE algorithm based on matrix perturbation theory (MPT-DRL-VNE) is proposed. Experimental results show that the above algorithm is superior to other algorithms. ",
    "url": "https://arxiv.org/abs/2202.03193",
    "authors": [
      "Shidong Zhang",
      "Chao Wang",
      "Junsan Zhang",
      "Youxiang Duan",
      "Xinhong You",
      "Peiying Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2202.03195",
    "title": "More is Better (Mostly): On the Backdoor Attacks in Federated Graph  Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) are a class of deep learning-based methods for processing graph domain information. GNNs have recently become a widely used graph analysis method due to their superior ability to learn representations for complex graph data. However, due to privacy concerns and regulation restrictions, centralized GNNs can be difficult to apply to data-sensitive scenarios. Federated learning (FL) is an emerging technology developed for privacy-preserving settings when several parties need to train a shared global model collaboratively. Although many research works have applied FL to train GNNs (Federated GNNs), there is no research on their robustness to backdoor attacks. This paper bridges this gap by conducting two types of backdoor attacks in Federated GNNs: centralized backdoor attacks (CBA) and distributed backdoor attacks (DBA). CBA is conducted by embedding the same global trigger during training for every malicious party, while DBA is conducted by decomposing a global trigger into separate local triggers and embedding them into the training dataset of different malicious parties, respectively. Our experiments show that the DBA attack success rate is higher than CBA in almost all evaluated cases, while rarely, the DBA attack performance is close to CBA. For CBA, the attack success rate of all local triggers is similar to the global trigger even if the training set of the adversarial party is embedded with the global trigger. To further explore the properties of two backdoor attacks in Federated GNNs, we evaluate the attack performance for different trigger sizes, poisoning intensities, and trigger densities, with trigger density being the most influential. ",
    "url": "https://arxiv.org/abs/2202.03195",
    "authors": [
      "Jing Xu",
      "Rui Wang",
      "Kaitai Liang",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03206",
    "title": "Recent Trends in 2D Object Detection and Applications in Video Event  Recognition",
    "abstract": "Object detection serves as a significant step in improving performance of complex downstream computer vision tasks. It has been extensively studied for many years now and current state-of-the-art 2D object detection techniques proffer superlative results even in complex images. In this chapter, we discuss the geometry-based pioneering works in object detection, followed by the recent breakthroughs that employ deep learning. Some of these use a monolithic architecture that takes a RGB image as input and passes it to a feed-forward ConvNet or vision Transformer. These methods, thereby predict class-probability and bounding-box coordinates, all in a single unified pipeline. Two-stage architectures on the other hand, first generate region proposals and then feed it to a CNN to extract features and predict object category and bounding-box. We also elaborate upon the applications of object detection in video event recognition, to achieve better fine-grained video classification performance. Further, we highlight recent datasets for 2D object detection both in images and videos, and present a comparative performance summary of various state-of-the-art object detection techniques. ",
    "url": "https://arxiv.org/abs/2202.03206",
    "authors": [
      "Prithwish Jana",
      "Partha Pratim Mohanta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.03218",
    "title": "Efficient Adapter Transfer of Self-Supervised Speech Models for  Automatic Speech Recognition",
    "abstract": "Self-supervised learning (SSL) is a powerful tool that allows learning of underlying representations from unlabeled data. Transformer based models such as wav2vec 2.0 and HuBERT are leading the field in the speech domain. Generally these models are fine-tuned on a small amount of labeled data for a downstream task such as Automatic Speech Recognition (ASR). This involves re-training the majority of the model for each task. Adapters are small lightweight modules which are commonly used in Natural Language Processing (NLP) to adapt pre-trained models to new tasks. In this paper we propose applying adapters to wav2vec 2.0 to reduce the number of parameters required for downstream ASR tasks, and increase scalability of the model to multiple tasks or languages. Using adapters we can perform ASR while training fewer than 10% of parameters per task compared to full fine-tuning with little degradation of performance. Ablations show that applying adapters into just the top few layers of the pre-trained network gives similar performance to full transfer, supporting the theory that higher pre-trained layers encode more phonemic information, and further optimizing efficiency. ",
    "url": "https://arxiv.org/abs/2202.03218",
    "authors": [
      "Bethan Thomas",
      "Samuel Kessler",
      "Salah Karout"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2202.03229",
    "title": "Neural Models for Output-Space Invariance in Combinatorial Problems",
    "abstract": "Recently many neural models have been proposed to solve combinatorial puzzles by implicitly learning underlying constraints using their solved instances, such as sudoku or graph coloring (GCP). One drawback of the proposed architectures, which are often based on Graph Neural Networks (GNN), is that they cannot generalize across the size of the output space from which variables are assigned a value, for example, set of colors in a GCP, or board-size in sudoku. We call the output space for the variables as 'value-set'. While many works have demonstrated generalization of GNNs across graph size, there has been no study on how to design a GNN for achieving value-set invariance for problems that come from the same domain. For example, learning to solve 16 x 16 sudoku after being trained on only 9 x 9 sudokus. In this work, we propose novel methods to extend GNN based architectures to achieve value-set invariance. Specifically, our model builds on recently proposed Recurrent Relational Networks. Our first approach exploits the graph-size invariance of GNNs by converting a multi-class node classification problem into a binary node classification problem. Our second approach works directly with multiple classes by adding multiple nodes corresponding to the values in the value-set, and then connecting variable nodes to value nodes depending on the problem initialization. Our experimental evaluation on three different combinatorial problems demonstrates that both our models perform well on our novel problem, compared to a generic neural reasoner. Between two of our models, we observe an inherent trade-off: while the binarized model gives better performance when trained on smaller value-sets, multi-valued model is much more memory efficient, resulting in improved performance when trained on larger value-sets, where binarized model fails to train. ",
    "url": "https://arxiv.org/abs/2202.03229",
    "authors": [
      "Yatin Nandwani",
      "Vidit Jain",
      "Mausam",
      "Parag Singla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.03240",
    "title": "Minimization of the Worst-Case Average Energy Consumption in  UAV-Assisted IoT Networks",
    "abstract": "The Internet of Things (IoT) brings connectivity to a massive number of devices that demand energy-efficient solutions to deal with limited battery capacities, uplink-dominant traffic, and channel impairments. In this work, we explore the use of Unmanned Aerial Vehicles (UAVs) equipped with configurable antennas as a flexible solution for serving low-power IoT networks. We formulate an optimization problem to set the position and antenna beamwidth of the UAV, and the transmit power of the IoT devices subject to average-Signal-to-average-Interference-plus-Noise Ratio ($\\bar{\\text{S}}\\overline{\\text{IN}}\\text{R}$) Quality of Service (QoS) constraints. We minimize the worst-case average energy consumption of the latter, thus, targeting the fairest allocation of the energy resources. The problem is non-convex and highly non-linear; therefore, we re-formulate it as a series of three geometric programs that can be solved iteratively. Results reveal the benefits of planning the network compared to a random deployment in terms of reducing the worst-case average energy consumption. Furthermore, we show that the target $\\bar{\\text{S}}\\overline{\\text{IN}}\\text{R}$ is limited by the number of IoT devices, and highlight the dominant impact of the UAV hovering height when serving wider areas. Our proposed algorithm outperforms other optimization benchmarks in terms of minimizing the average energy consumption at the most energy-demanding IoT device, and convergence time. ",
    "url": "https://arxiv.org/abs/2202.03240",
    "authors": [
      "Osmel Mart\u00ednez Rosabal",
      "Onel Alcaraz L\u00f3pez",
      "Dian Echevarr\u00eda P\u00e9rez",
      "Mohammad Shehab",
      "Henrique Hilleshein",
      "Hirley Alves"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2202.03244",
    "title": "Online Deep Neural Network for Optimization in Wireless Communications",
    "abstract": "Recently, deep neural network (DNN) has been widely adopted in the design of intelligent communication systems thanks to its strong learning ability and low testing complexity. However, most current offline DNN-based methods still suffer from unsatisfactory performance, limited generalization ability, and poor interpretability. In this article, we propose an online DNN-based approach to solve general optimization problems in wireless communications, where a dedicated DNN is trained for each data sample. By treating the optimization variables and the objective function as network parameters and loss function, respectively, the optimization problem can be solved equivalently through network training. Thanks to the online optimization nature and meaningful network parameters, the proposed approach owns strong generalization ability and interpretability, while its superior performance is demonstrated through a practical example of joint beamforming in intelligent reflecting surface (IRS)-aided multi-user multiple-input multiple-output (MIMO) systems. Simulation results show that the proposed online DNN outperforms conventional offline DNN and state-of-the-art iterative optimization algorithm, but with low complexity. ",
    "url": "https://arxiv.org/abs/2202.03244",
    "authors": [
      "Jiabao Gao",
      "Caijun Zhong",
      "Geoffrey Ye Li",
      "Zhaoyang Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.03246",
    "title": "AI-based artistic representation of emotions from EEG signals: a  discussion on fairness, inclusion, and aesthetics",
    "abstract": "While Artificial Intelligence (AI) technologies are being progressively developed, artists and researchers are investigating their role in artistic practices. In this work, we present an AI-based Brain-Computer Interface (BCI) in which humans and machines interact to express feelings artistically. This system and its production of images give opportunities to reflect on the complexities and range of human emotions and their expressions. In this discussion, we seek to understand the dynamics of this interaction to reach better co-existence in fairness, inclusion, and aesthetics. ",
    "url": "https://arxiv.org/abs/2202.03246",
    "authors": [
      "Piera Riccio",
      "Kristin Bergaust",
      "Boel Christensen-Scheel",
      "Juan-Carlos De Martin",
      "Maria A. Zuluaga",
      "Stefano Nichele"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.03257",
    "title": "Confidence Guided Depth Completion Network",
    "abstract": "The paper proposes an image-guided depth completion method to estimate accurate dense depth maps with fast computation time. The proposed network has two-stage structure. The first stage predicts a first depth map. Then, the second stage further refines the first depth map using the confidence maps. The second stage consists of two layers, each of which focuses on different regions and generates a refined depth map and a confidence map. The final depth map is obtained by combining two depth maps from the second stage using the corresponding confidence maps. Compared with the top-ranked models on the KITTI depth completion online leaderboard, the proposed model shows much faster computation time and competitive performance. ",
    "url": "https://arxiv.org/abs/2202.03257",
    "authors": [
      "Yongjin Lee",
      "Seokjun Park",
      "Beomgu Kang",
      "Hyunwook Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.03277",
    "title": "On The Empirical Effectiveness of Unrealistic Adversarial Hardening  Against Realistic Adversarial Attacks",
    "abstract": "While the literature on security attacks and defense of Machine Learning (ML) systems mostly focuses on unrealistic adversarial examples, recent research has raised concern about the under-explored field of realistic adversarial attacks and their implications on the robustness of real-world systems. Our paper paves the way for a better understanding of adversarial robustness against realistic attacks and makes two major contributions. First, we conduct a study on three real-world use cases (text classification, botnet detection, malware detection)) and five datasets in order to evaluate whether unrealistic adversarial examples can be used to protect models against realistic examples. Our results reveal discrepancies across the use cases, where unrealistic examples can either be as effective as the realistic ones or may offer only limited improvement. Second, to explain these results, we analyze the latent representation of the adversarial examples generated with realistic and unrealistic attacks. We shed light on the patterns that discriminate which unrealistic examples can be used for effective hardening. We release our code, datasets and models to support future research in exploring how to reduce the gap between unrealistic and realistic adversarial attacks. ",
    "url": "https://arxiv.org/abs/2202.03277",
    "authors": [
      "Salijona Dyrmishi",
      "Salah Ghamizi",
      "Thibault Simonetto",
      "Yves Le Traon",
      "Maxime Cordy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.03278",
    "title": "Crafting Better Contrastive Views for Siamese Representation Learning",
    "abstract": "Recent self-supervised contrastive learning methods greatly benefit from the Siamese structure that aims at minimizing distances between positive pairs. For high performance Siamese representation learning, one of the keys is to design good contrastive pairs. Most previous works simply apply random sampling to make different crops of the same image, which overlooks the semantic information that may degrade the quality of views. In this work, we propose ContrastiveCrop, which could effectively generate better crops for Siamese representation learning. Firstly, a semantic-aware object localization strategy is proposed within the training process in a fully unsupervised manner. This guides us to generate contrastive views which could avoid most false positives (i.e., object vs. background). Moreover, we empirically find that views with similar appearances are trivial for the Siamese model training. Thus, a center-suppressed sampling is further designed to enlarge the variance of crops. Remarkably, our method takes a careful consideration of positive pairs for contrastive learning with negligible extra training overhead. As a plug-and-play and framework-agnostic module, ContrastiveCrop consistently improves SimCLR, MoCo, BYOL, SimSiam by 0.4% ~ 2.0% classification accuracy on CIFAR-10, CIFAR-100, Tiny ImageNet and STL-10. Superior results are also achieved on downstream detection and segmentation tasks when pre-trained on ImageNet-1K. ",
    "url": "https://arxiv.org/abs/2202.03278",
    "authors": [
      "Xiangyu Peng",
      "Kai Wang",
      "Zheng Zhu",
      "Yang You"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.03281",
    "title": "Personalized Public Policy Analysis in Social Sciences using  Causal-Graphical Normalizing Flows",
    "abstract": "Structural Equation/Causal Models (SEMs/SCMs) are widely used in epidemiology and social sciences to identify and analyze the average treatment effect (ATE) and conditional ATE (CATE). Traditional causal effect estimation methods such as Inverse Probability Weighting (IPW) and more recently Regression-With-Residuals (RWR) are widely used - as they avoid the challenging task of identifying the SCM parameters - to estimate ATE and CATE. However, much work remains before traditional estimation methods can be used for counterfactual inference, and for the benefit of Personalized Public Policy Analysis (P$^3$A) in the social sciences. While doctors rely on personalized medicine to tailor treatments to patients in laboratory settings (relatively closed systems), P$^3$A draws inspiration from such tailoring but adapts it for open social systems. In this article, we develop a method for counterfactual inference that we name causal-Graphical Normalizing Flow (c-GNF), facilitating P$^3$A. First, we show how c-GNF captures the underlying SCM without making any assumption about functional forms. Second, we propose a novel dequantization trick to deal with discrete variables, which is a limitation of normalizing flows in general. Third, we demonstrate in experiments that c-GNF performs on-par with IPW and RWR in terms of bias and variance for estimating the ATE, when the true functional forms are known, and better when they are unknown. Fourth and most importantly, we conduct counterfactual inference with c-GNFs, demonstrating promising empirical performance. Because IPW and RWR, like other traditional methods, lack the capability of counterfactual inference, c-GNFs will likely play a major role in tailoring personalized treatment, facilitating P$^3$A, optimizing social interventions - in contrast to the current `one-size-fits-all' approach of existing methods. ",
    "url": "https://arxiv.org/abs/2202.03281",
    "authors": [
      "Sourabh Balgi",
      "Jose M. Pena",
      "Adel Daoud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.03289",
    "title": "Approximation error of single hidden layer neural networks with fixed  weights",
    "abstract": "This paper provides an explicit formula for the approximation error of single hidden layer neural networks with two fixed weights. ",
    "url": "https://arxiv.org/abs/2202.03289",
    "authors": [
      "Vugar Ismailov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Classical Analysis and ODEs (math.CA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.03291",
    "title": "Mental Disorders on Online Social Media Through the Lens of Language and  Behaviour: Analysis and Visualisation",
    "abstract": "Due to the worldwide accessibility to the Internet along with the continuous advances in mobile technologies, physical and digital worlds have become completely blended, and the proliferation of social media platforms has taken a leading role over this evolution. In this paper, we undertake a thorough analysis towards better visualising and understanding the factors that characterise and differentiate social media users affected by mental disorders. We perform different experiments studying multiple dimensions of language, including vocabulary uniqueness, word usage, linguistic style, psychometric attributes, emotions' co-occurrence patterns, and online behavioural traits, including social engagement and posting trends. Our findings reveal significant differences on the use of function words, such as adverbs and verb tense, and topic-specific vocabulary, such as biological processes. As for emotional expression, we observe that affected users tend to share emotions more regularly than control individuals on average. Overall, the monthly posting variance of the affected groups is higher than the control groups. Moreover, we found evidence suggesting that language use on micro-blogging platforms is less distinguishable for users who have a mental disorder than other less restrictive platforms. In particular, we observe on Twitter less quantifiable differences between affected and control groups compared to Reddit. ",
    "url": "https://arxiv.org/abs/2202.03291",
    "authors": [
      "Esteban A. R\u00edssola",
      "Mohammad Aliannejadi",
      "Fabio Crestani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.03293",
    "title": "Composable and Modular Code Generation in MLIR: A Structured and  Retargetable Approach to Tensor Compiler Construction",
    "abstract": "Despite significant investment in software infrastructure, machine learning systems, runtimes and compilers do not compose properly. We propose a new design aiming at providing unprecedented degrees of modularity, composability and genericity. This paper discusses a structured approach to the construction of domain-specific code generators for tensor compilers, with the stated goal of improving the productivity of both compiler engineers and end-users. The approach leverages the natural structure of tensor algebra. It has been the main driver for the design of progressive lowering paths in \\MLIR. The proposed abstractions and transformations span data structures and control flow with both functional (SSA form) and imperative (side-effecting) semantics. We discuss the implications of this infrastructure on compiler construction and present preliminary experimental results. ",
    "url": "https://arxiv.org/abs/2202.03293",
    "authors": [
      "Nicolas Vasilache",
      "Oleksandr Zinenko",
      "Aart J.C. Bik",
      "Mahesh Ravishankar",
      "Thomas Raoux",
      "Alexander Belyaev",
      "Matthias Springer",
      "Tobias Gysi",
      "Diego Caballero",
      "Stephan Herhut",
      "Stella Laurenzo",
      "Albert Cohen"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2202.03325",
    "title": "Differential Privacy for Symbolic Systems with Application to Markov  Chains",
    "abstract": "Data-driven systems are gathering increasing amounts of data from users, and sensitive user data requires privacy protections. In some cases, the data gathered is non-numerical or symbolic, and conventional approaches to privacy, e.g., adding noise, do not apply, though such systems still require privacy protections. Accordingly, we present a novel differential privacy framework for protecting trajectories generated by symbolic systems. These trajectories can be represented as words or strings over a finite alphabet. We develop new differential privacy mechanisms that approximate a sensitive word using a random word that is likely to be near it. An offline mechanism is implemented efficiently using a Modified Hamming Distance Automaton to generate whole privatized output words over a finite time horizon. Then, an online mechanism is implemented by taking in a sensitive symbol and generating a randomized output symbol at each timestep. This work is extended to Markov chains to generate differentially private state sequences that a given Markov chain could have produced. Statistical accuracy bounds are developed to quantify the accuracy of these mechanisms, and numerical results validate the accuracy of these techniques for strings of English words. ",
    "url": "https://arxiv.org/abs/2202.03325",
    "authors": [
      "Bo Chen",
      "Kevin Leahy",
      "Austin Jones",
      "Matthew Hale"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Symbolic Computation (cs.SC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.03335",
    "title": "Membership Inference Attacks and Defenses in Neural Network Pruning",
    "abstract": "Neural network pruning has been an essential technique to reduce the computation and memory requirements for using deep neural networks for resource-constrained devices. Most existing research focuses primarily on balancing the sparsity and accuracy of a pruned neural network by strategically removing insignificant parameters and retraining the pruned model. Such efforts on reusing training samples pose serious privacy risks due to increased memorization, which, however, has not been investigated yet. In this paper, we conduct the first analysis of privacy risks in neural network pruning. Specifically, we investigate the impacts of neural network pruning on training data privacy, i.e., membership inference attacks. We first explore the impact of neural network pruning on prediction divergence, where the pruning process disproportionately affects the pruned model's behavior for members and non-members. Meanwhile, the influence of divergence even varies among different classes in a fine-grained manner. Enlighten by such divergence, we proposed a self-attention membership inference attack against the pruned neural networks. Extensive experiments are conducted to rigorously evaluate the privacy impacts of different pruning approaches, sparsity levels, and adversary knowledge. The proposed attack shows the higher attack performance on the pruned models when compared with eight existing membership inference attacks. In addition, we propose a new defense mechanism to protect the pruning process by mitigating the prediction divergence based on KL-divergence distance, whose effectiveness has been experimentally demonstrated to effectively mitigate the privacy risks while maintaining the sparsity and accuracy of the pruned models. ",
    "url": "https://arxiv.org/abs/2202.03335",
    "authors": [
      "Xiaoyong Yuan",
      "Lan Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.03341",
    "title": "Neighbor2Seq: Deep Learning on Massive Graphs by Transforming Neighbors  to Sequences",
    "abstract": "Modern graph neural networks (GNNs) use a message passing scheme and have achieved great success in many fields. However, this recursive design inherently leads to excessive computation and memory requirements, making it not applicable to massive real-world graphs. In this work, we propose the Neighbor2Seq to transform the hierarchical neighborhood of each node into a sequence. This novel transformation enables the subsequent mini-batch training for general deep learning operations, such as convolution and attention, that are designed for grid-like data and are shown to be powerful in various domains. Therefore, our Neighbor2Seq naturally endows GNNs with the efficiency and advantages of deep learning operations on grid-like data by precomputing the Neighbor2Seq transformations. We evaluate our method on a massive graph, with more than 111 million nodes and 1.6 billion edges, as well as several medium-scale graphs. Results show that our proposed method is scalable to massive graphs and achieves superior performance across massive and medium-scale graphs. Our code is available at https://github.com/divelab/Neighbor2Seq. ",
    "url": "https://arxiv.org/abs/2202.03341",
    "authors": [
      "Meng Liu",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03347",
    "title": "FrePGAN: Robust Deepfake Detection Using Frequency-level Perturbations",
    "abstract": "Various deepfake detectors have been proposed, but challenges still exist to detect images of unknown categories or GAN models outside of the training settings. Such issues arise from the overfitting issue, which we discover from our own analysis and the previous studies to originate from the frequency-level artifacts in generated images. We find that ignoring the frequency-level artifacts can improve the detector's generalization across various GAN models, but it can reduce the model's performance for the trained GAN models. Thus, we design a framework to generalize the deepfake detector for both the known and unseen GAN models. Our framework generates the frequency-level perturbation maps to make the generated images indistinguishable from the real images. By updating the deepfake detector along with the training of the perturbation generator, our model is trained to detect the frequency-level artifacts at the initial iterations and consider the image-level irregularities at the last iterations. For experiments, we design new test scenarios varying from the training settings in GAN models, color manipulations, and object categories. Numerous experiments validate the state-of-the-art performance of our deepfake detector. ",
    "url": "https://arxiv.org/abs/2202.03347",
    "authors": [
      "Yonghyun Jeong",
      "Doyeon Kim",
      "Youngmin Ro",
      "Jongwon Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2202.03348",
    "title": "Failure and success of the spectral bias prediction for Kernel Ridge  Regression: the case of low-dimensional data",
    "abstract": "Recently, several theories including the replica method made predictions for the generalization error of Kernel Ridge Regression. In some regimes, they predict that the method has a `spectral bias': decomposing the true function $f^*$ on the eigenbasis of the kernel, it fits well the coefficients associated with the O(P) largest eigenvalues, where $P$ is the size of the training set. This prediction works very well on benchmark data sets such as images, yet the assumptions these approaches make on the data are never satisfied in practice. To clarify when the spectral bias prediction holds, we first focus on a one-dimensional model where rigorous results are obtained and then use scaling arguments to generalize and test our findings in higher dimensions. Our predictions include the classification case $f(x)=$sign$(x_1)$ with a data distribution that vanishes at the decision boundary $p(x)\\sim x_1^{\\chi}$. For $\\chi>0$ and a Laplace kernel, we find that (i) there exists a cross-over ridge $\\lambda^*_{d,\\chi}(P)\\sim P^{-\\frac{1}{d+\\chi}}$ such that for $\\lambda\\gg \\lambda^*_{d,\\chi}(P)$, the replica method applies, but not for $\\lambda\\ll\\lambda^*_{d,\\chi}(P)$, (ii) in the ridge-less case, spectral bias predicts the correct training curve exponent only in the limit $d\\rightarrow\\infty$. ",
    "url": "https://arxiv.org/abs/2202.03348",
    "authors": [
      "Umberto M. Tomasini",
      "Antonio Sclocchi",
      "Matthieu Wyart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ]
  },
  {
    "id": "arXiv:2202.03352",
    "title": "Analog Secure Distributed Matrix Multiplication over Complex Numbers",
    "abstract": "This work considers the problem of distributing matrix multiplication over the real or complex numbers to helper servers, such that the information leakage to these servers is close to being information-theoretically secure. These servers are assumed to be honest-but-curious, i.e., they work according to the protocol, but try to deduce information about the data. The problem of secure distributed matrix multiplication (SDMM) has been considered in the context of matrix multiplication over finite fields, which is not always feasible in real world applications. We present two schemes, which allow for variable degree of security based on the use case and allow for colluding and straggling servers. We analyze the security and the numerical accuracy of the schemes and observe a trade-off between accuracy and security. ",
    "url": "https://arxiv.org/abs/2202.03352",
    "authors": [
      "Okko Makkonen",
      "Camilla Hollanti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.03354",
    "title": "Robust Dialogue State Tracking with Weak Supervision and Sparse Data",
    "abstract": "Generalising dialogue state tracking (DST) to new data is especially challenging due to the strong reliance on abundant and fine-grained supervision during training. Sample sparsity, distributional shift and the occurrence of new concepts and topics frequently lead to severe performance degradation during inference. In this paper we propose a training strategy to build extractive DST models without the need for fine-grained manual span labels. Two novel input-level dropout methods mitigate the negative impact of sample sparsity. We propose a new model architecture with a unified encoder that supports value as well as slot independence by leveraging the attention mechanism. We combine the strengths of triple copy strategy DST and value matching to benefit from complementary predictions without violating the principle of ontology independence. Our experiments demonstrate that an extractive DST model can be trained without manual span labels. Our architecture and training strategies improve robustness towards sample sparsity, new concepts and topics, leading to state-of-the-art performance on a range of benchmarks. We further highlight our model's ability to effectively learn from non-dialogue data. ",
    "url": "https://arxiv.org/abs/2202.03354",
    "authors": [
      "Michael Heck",
      "Nurul Lubis",
      "Carel van Niekerk",
      "Shutong Feng",
      "Christian Geishauser",
      "Hsien-Chin Lin",
      "Milica Ga\u0161i\u0107"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.03376",
    "title": "Message Passing Neural PDE Solvers",
    "abstract": "The numerical solution of partial differential equations (PDEs) is difficult, having led to a century of research so far. Recently, there have been pushes to build neural--numerical hybrid solvers, which piggy-backs the modern trend towards fully end-to-end learned systems. Most works so far can only generalize over a subset of properties to which a generic solver would be faced, including: resolution, topology, geometry, boundary conditions, domain discretization regularity, dimensionality, etc. In this work, we build a solver, satisfying these properties, where all the components are based on neural message passing, replacing all heuristically designed components in the computation graph with backprop-optimized neural function approximators. We show that neural message passing solvers representationally contain some classical methods, such as finite differences, finite volumes, and WENO schemes. In order to encourage stability in training autoregressive models, we put forward a method that is based on the principle of zero-stability, posing stability as a domain adaptation problem. We validate our method on various fluid-like flow problems, demonstrating fast, stable, and accurate performance across different domain topologies, discretization, etc. in 1D and 2D. Our model outperforms state-of-the-art numerical solvers in the low resolution regime in terms of speed and accuracy. ",
    "url": "https://arxiv.org/abs/2202.03376",
    "authors": [
      "Johannes Brandstetter",
      "Daniel Worrall",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2202.03382",
    "title": "Corrupted Image Modeling for Self-Supervised Visual Pre-Training",
    "abstract": "We introduce Corrupted Image Modeling (CIM) for self-supervised visual pre-training. CIM uses an auxiliary generator with a small trainable BEiT to corrupt the input image instead of using artificial mask tokens, where some patches are randomly selected and replaced with plausible alternatives sampled from the BEiT output distribution. Given this corrupted image, an enhancer network learns to either recover all the original image pixels, or predict whether each visual token is replaced by a generator sample or not. The generator and the enhancer are simultaneously trained and synergistically updated. After pre-training, the enhancer can be used as a high-capacity visual encoder for downstream tasks. CIM is a general and flexible visual pre-training framework that is suitable for various network architectures. For the first time, CIM demonstrates that both ViT and CNN can learn rich visual representations using a unified, non-Siamese framework. Experimental results show that our approach achieves compelling results in vision benchmarks, such as ImageNet classification and ADE20K semantic segmentation. For example, 300-epoch CIM pre-trained vanilla ViT-Base/16 and ResNet-50 obtain 83.3 and 80.6 Top-1 fine-tuning accuracy on ImageNet-1K image classification respectively. ",
    "url": "https://arxiv.org/abs/2202.03382",
    "authors": [
      "Yuxin Fang",
      "Li Dong",
      "Hangbo Bao",
      "Xinggang Wang",
      "Furu Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03390",
    "title": "GMC -- Geometric Multimodal Contrastive Representation Learning",
    "abstract": "Learning representations of multimodal data that are both informative and robust to missing modalities at test time remains a challenging problem due to the inherent heterogeneity of data obtained from different channels. To address it, we present a novel Geometric Multimodal Contrastive (GMC) representation learning method comprised of two main components: i) a two-level architecture consisting of modality-specific base encoder, allowing to process an arbitrary number of modalities to an intermediate representation of fixed dimensionality, and a shared projection head, mapping the intermediate representations to a latent representation space; ii) a multimodal contrastive loss function that encourages the geometric alignment of the learned representations. We experimentally demonstrate that GMC representations are semantically rich and achieve state-of-the-art performance with missing modality information on three different learning problems including prediction and reinforcement learning tasks. ",
    "url": "https://arxiv.org/abs/2202.03390",
    "authors": [
      "Petra Poklukar",
      "Miguel Vasco",
      "Hang Yin",
      "Francisco S. Melo",
      "Ana Paiva",
      "Danica Kragic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.03392",
    "title": "Large-scale Personalized Video Game Recommendation via Social-aware  Contextualized Graph Neural Network",
    "abstract": "Because of the large number of online games available nowadays, online game recommender systems are necessary for users and online game platforms. The former can discover more potential online games of their interests, and the latter can attract users to dwell longer in the platform. This paper investigates the characteristics of user behaviors with respect to the online games on the Steam platform. Based on the observations, we argue that a satisfying recommender system for online games is able to characterize: personalization, game contextualization and social connection. However, simultaneously solving all is rather challenging for game recommendation. Firstly, personalization for game recommendation requires the incorporation of the dwelling time of engaged games, which are ignored in existing methods. Secondly, game contextualization should reflect the complex and high-order properties of those relations. Last but not least, it is problematic to use social connections directly for game recommendations due to the massive noise within social connections. To this end, we propose a Social-aware Contextualized Graph Neural Recommender System (SCGRec), which harnesses three perspectives to improve game recommendation. We conduct a comprehensive analysis of users' online game behaviors, which motivates the necessity of handling those three characteristics in the online game recommendation. ",
    "url": "https://arxiv.org/abs/2202.03392",
    "authors": [
      "Liangwei Yang",
      "Zhiwei Liu",
      "Yu Wang",
      "Chen Wang",
      "Ziwei Fan",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2202.03393",
    "title": "Link Prediction of Artificial Intelligence Concepts using Low  Computational Power",
    "abstract": "This paper presents an approach proposed for the Science4cast 2021 competition, organized by the Institute of Advanced Research in Artificial Intelligence, whose main goal was to predict the likelihood of future associations between machine learning concepts in a semantic network. The developed methodology corresponds to a solution for a scenario of availability of low computational power only, exploiting the extraction of low order topological features and its incorporation in an optimized classifier to estimate the degree of future connections between the nodes. The reasons that motivated the developed methodologies will be discussed, as well as some results, limitations and suggestions of improvements. ",
    "url": "https://arxiv.org/abs/2202.03393",
    "authors": [
      "Francisco Valente"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03402",
    "title": "Preserving Privacy and Security in Federated Learning",
    "abstract": "Federated learning is known to be vulnerable to security and privacy issues. Existing research has focused either on preventing poisoning attacks from users or on protecting user privacy of model updates. However, integrating these two lines of research remains a crucial challenge since they often conflict with one another with respect to the threat model. In this work, we develop a framework to combine secure aggregation with defense mechanisms against poisoning attacks from users, while maintaining their respective privacy guarantees. We leverage zero-knowledge proof protocol to let users run the defense mechanisms locally and attest the result to the central server without revealing any information about their model updates. Furthermore, we propose a new secure aggregation protocol for federated learning using homomorphic encryption that is robust against malicious users. Our framework enables the central server to identify poisoned model updates without violating the privacy guarantees of secure aggregation. Finally, we analyze the computation and communication complexity of our proposed solution and benchmark its performance. ",
    "url": "https://arxiv.org/abs/2202.03402",
    "authors": [
      "Truc Nguyen",
      "My T. Thai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.03415",
    "title": "PopNet: Real-Time Population-Level Disease Prediction with Data Latency",
    "abstract": "Population-level disease prediction estimates the number of potential patients of particular diseases in some location at a future time based on (frequently updated) historical disease statistics. Existing approaches often assume the existing disease statistics are reliable and will not change. However, in practice, data collection is often time-consuming and has time delays, with both historical and current disease statistics being updated continuously. In this work, we propose a real-time population-level disease prediction model which captures data latency (PopNet) and incorporates the updated data for improved predictions. To achieve this goal, PopNet models real-time data and updated data using two separate systems, each capturing spatial and temporal effects using hybrid graph attention networks and recurrent neural networks. PopNet then fuses the two systems using both spatial and temporal latency-aware attentions in an end-to-end manner. We evaluate PopNet on real-world disease datasets and show that PopNet consistently outperforms all baseline disease prediction and general spatial-temporal prediction models, achieving up to 47% lower root mean squared error and 24% lower mean absolute error compared with the best baselines. ",
    "url": "https://arxiv.org/abs/2202.03415",
    "authors": [
      "Junyi Gao",
      "Cao Xiao",
      "Lucas M. Glass",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2202.03416",
    "title": "Deep Impulse Responses: Estimating and Parameterizing Filters with Deep  Networks",
    "abstract": "Impulse response estimation in high noise and in-the-wild settings, with minimal control of the underlying data distributions, is a challenging problem. We propose a novel framework for parameterizing and estimating impulse responses based on recent advances in neural representation learning. Our framework is driven by a carefully designed neural network that jointly estimates the impulse response and the (apriori unknown) spectral noise characteristics of an observed signal given the source signal. We demonstrate robustness in estimation, even under low signal-to-noise ratios, and show strong results when learning from spatio-temporal real-world speech data. Our framework provides a natural way to interpolate impulse responses on a spatial grid, while also allowing for efficiently compressing and storing them for real-time rendering applications in augmented and virtual reality. ",
    "url": "https://arxiv.org/abs/2202.03416",
    "authors": [
      "Alexander Richard",
      "Peter Dodds",
      "Vamsi Krishna Ithapu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2202.02371",
    "title": "Boundary-aware Information Maximization for Self-supervised Medical  Image Segmentation",
    "abstract": "Unsupervised pre-training has been proven as an effective approach to boost various downstream tasks given limited labeled data. Among various methods, contrastive learning learns a discriminative representation by constructing positive and negative pairs. However, it is not trivial to build reasonable pairs for a segmentation task in an unsupervised way. In this work, we propose a novel unsupervised pre-training framework that avoids the drawback of contrastive learning. Our framework consists of two principles: unsupervised over-segmentation as a pre-train task using mutual information maximization and boundary-aware preserving learning. Experimental results on two benchmark medical segmentation datasets reveal our method's effectiveness in improving segmentation performance when few annotated images are available. ",
    "url": "https://arxiv.org/abs/2202.02371",
    "authors": [
      "Jizong Peng",
      "Ping Wang",
      "Marco Pedersoli",
      "Christian Desrosiers"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.02372",
    "title": "Direct observation of a dynamical glass transition in a nanomagnetic  artificial Hopfield network",
    "abstract": "Spin glasses, generally defined as disordered systems with randomized competing interactions, are a widely investigated complex system. Theoretical models describing spin glasses are broadly used in other complex systems, such as those describing brain function, error-correcting codes, or stock-market dynamics. This wide interest in spin glasses provides strong motivation to generate an artificial spin glass within the framework of artificial spin ice systems. Here, we present the experimental realization of an artificial spin glass consisting of dipolar coupled single-domain Ising-type nanomagnets arranged onto an interaction network that replicates the aspects of a Hopfield neural network. Using cryogenic x-ray photoemission electron microscopy (XPEEM), we performed temperature-dependent imaging of thermally driven moment fluctuations within these networks and observed characteristic features of a two-dimensional Ising spin glass. Specifically, the temperature dependence of the spin glass correlation function follows a power law trend predicted from theoretical models on two-dimensional spin glasses. Furthermore, we observe clear signatures of the hard to observe rugged spin glass free energy in the form of sub-aging, out of equilibrium autocorrelations and a transition from stable to unstable dynamics. ",
    "url": "https://arxiv.org/abs/2202.02372",
    "authors": [
      "Michael Saccone",
      "Francesco Caravelli",
      "Kevin Hofhuis",
      "Sergii Parchenko",
      "Yorick A. Birkh\u00f6lzer",
      "Scott Dhuey",
      "Armin Kleibert",
      "Sebastiaan van Dijken",
      "Cristiano Nisoli",
      "Alan Farhan"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2202.02439",
    "title": "Multistability and Paradoxes in Lossy Oscillator Networks",
    "abstract": "The analysis of dissipatively coupled oscillators is a challenging problem with high stakes in actual applications, such as large scale physical systems. Many standard mathematical methods are not applicable to such systems, due to the lack of symmetry of the network induced by dissipative couplings. Here we emphasize that the synchronization of coupled oscillators can be equivalently interpreted as the problem of flow distribution over a network. Based on these equivalent interpretations, we demonstrate a close correspondence between multiple stable synchronous states and \\emph{winding cells} in systems of dissipatively coupled oscillators. The recently introduced notion of winding cells, associated to a graph, forms a natural winding partition of the $n$-torus and capture essential characteristics of synchronous states in lossless systems. Leveraging the winding partition of the $n$-torus, we provide algorithms to compute the synchronous solutions of general networks of coupled oscillators. Furthermore, we identify three paradoxical behaviors of lossy networked systems, to be contrasted with the behavior lossless systems. Namely, we show that loop flows and dissipation can increase the system's transfer capacity, and that dissipation can promote multistability. ",
    "url": "https://arxiv.org/abs/2202.02439",
    "authors": [
      "Robin Delabays",
      "Saber Jafarpour",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.02509",
    "title": "Asymptotic Critical Radii in Random Geometric Graphs over 3-Dimensional  Convex regions",
    "abstract": "This article presents the precise asymptotical distribution of two types of critical transmission radii, defined in terms of k-connectivity and the minimum vertex degree, for a random geometry graph distributed over a 3-Dimensional Convex region. ",
    "url": "https://arxiv.org/abs/2202.02509",
    "authors": [
      "Jie Ding",
      "Xiaohua Xu",
      "Shuai Ma",
      "Xinshan Zhu"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2202.02549",
    "title": "A Practical Vehicle Routing Problem for Monitoring Water Distribution  Networks",
    "abstract": "In this work, we introduce a generalization of the well-known Vehicle Routing Problem (VRP) for a specific application in the monitoring of a Water Distribution Network (WDN). In this problem, for each day over a planning period, multiple technicians must visit a sequence of nodes in the WDN and perform a series of tests to check the quality of water. Some special nodes (i.e., wells) require technicians to first collect a key from a key center. The key must then be returned to the same key center after the test has been performed, thus introducing precedence constraints and multiple visits in the routes. To solve the problem, three mathematical models and an Iterated Local Search have been implemented. The efficiency of the proposed methods is demonstrated by means of extensive computational tests on randomly created instances, as well as on instances derived from a real-world case study. ",
    "url": "https://arxiv.org/abs/2202.02549",
    "authors": [
      "Reza Atefi",
      "Manuel Iori",
      "Majid Salari",
      "Dario Vezzali"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2202.02570",
    "title": "Proper conflict-free and unique-maximum colorings of planar graphs with  respect to neighborhoods",
    "abstract": "A {\\em conflict-free coloring} of a graph {\\em with respect to open} (resp., {\\em closed}) {\\em neighborhood} is a coloring of vertices such that for every vertex there is a color appearing exactly once in its open (resp., closed) neighborhood. Similarly, a {\\em unique-maximum coloring} of a graph {\\em with respect to open} (resp., {\\em closed}) {\\em neighborhood} is a coloring of vertices such that for every vertex the maximum color appearing in its open (resp., closed) neighborhood appears exactly once. There is a vast amount of literature on both notions where the colorings need not be proper, i.e., adjacent vertices are allowed to have the same color. In this paper, we initiate a study of both colorings in the proper settings with the focus given mainly to planar graphs. We establish upper bounds for the number of colors in the class of planar graphs for all considered colorings and provide constructions of planar graphs attaining relatively high values of the corresponding chromatic numbers. As a main result, we prove that every planar graph admits a proper unique-maximum coloring with respect to open neighborhood with at most 10 colors, and give examples of planar graphs needing at least $6$ colors for such a coloring. We also establish tight upper bounds for outerplanar graphs. Finally, we provide several new bounds also for the improper setting of considered colorings. ",
    "url": "https://arxiv.org/abs/2202.02570",
    "authors": [
      "Igor Fabrici",
      "Borut Lu\u017ear",
      "Simona Rindo\u0161ov\u00e1",
      "Roman Sot\u00e1k"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2202.02599",
    "title": "Path eccentricity of graphs",
    "abstract": "Let $G$ be a connected graph. The eccentricity of a path $P$, denoted by ecc$_G(P)$, is the maximum distance from $P$ to any vertex in $G$. In the \\textsc{Central path} (CP) problem our aim is to find a path of minimum eccentricity. This problem was introduced by Cockayne et al., in 1981, in the study of different centrality measures on graphs. They showed that CP can be solved in linear time in trees, but it is known to be NP-hard in many classes of graphs such as chordal bipartite graphs, planar 3-connected graphs, split graphs, etc. We investigate the path eccentricity of a connected graph~$G$ as a parameter. Let pe$(G)$ denote the value of ecc$_G(P)$ for a central path $P$ of $G$. We obtain tight upper bounds for pe$(G)$ in some graph classes. We show that pe$(G) \\leq 1$ on biconvex graphs and that pe$(G) \\leq 2$ on bipartite convex graphs. Moreover, we design algorithms that find such a path in linear time. On the other hand, by investigating the longest paths of a graph, we obtain tight upper bounds for pe$(G)$ on general graphs and $k$-connected graphs. Finally, we study the relation between a central path and a longest path in a graph. We show that on trees, and bipartite permutation graphs, a longest path is also a central path. Furthermore, for superclasses of these graphs, we exhibit counterexamples for this property. ",
    "url": "https://arxiv.org/abs/2202.02599",
    "authors": [
      "Renzo G\u00f3mez",
      "Juan Guti\u00e9rrez"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2202.02620",
    "title": "Graphical parameters for classes of tumbling block graphs",
    "abstract": "The infinite tumbling block graph is a bipartite graph, where each vertex in one partite set is of degree 3 and each vertex in the other partite set is of degree 6. It is a 2-dimensional array of blocks of seven vertices and nine edges, a planar graph that has 3-D looks. This paper introduces tumbling block graphs and considers various graphical parameters for different classes of infinite and finite tumbling blocks. ",
    "url": "https://arxiv.org/abs/2202.02620",
    "authors": [
      "Suk J. Seo",
      "Peter J. Slater"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2202.02649",
    "title": "The Implicit Bias of Gradient Descent on Generalized Gated Linear  Networks",
    "abstract": "Understanding the asymptotic behavior of gradient-descent training of deep neural networks is essential for revealing inductive biases and improving network performance. We derive the infinite-time training limit of a mathematically tractable class of deep nonlinear neural networks, gated linear networks (GLNs), and generalize these results to gated networks described by general homogeneous polynomials. We study the implications of our results, focusing first on two-layer GLNs. We then apply our theoretical predictions to GLNs trained on MNIST and show how architectural constraints and the implicit bias of gradient descent affect performance. Finally, we show that our theory captures a substantial portion of the inductive bias of ReLU networks. By making the inductive bias explicit, our framework is poised to inform the development of more efficient, biologically plausible, and robust learning algorithms. ",
    "url": "https://arxiv.org/abs/2202.02649",
    "authors": [
      "Samuel Lippl",
      "L. F. Abbott",
      "SueYeon Chung"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2202.02764",
    "title": "On Smart Gaze based Annotation of Histopathology Images for Training of  Deep Convolutional Neural Networks",
    "abstract": "Unavailability of large training datasets is a bottleneck that needs to be overcome to realize the true potential of deep learning in histopathology applications. Although slide digitization via whole slide imaging scanners has increased the speed of data acquisition, labeling of virtual slides requires a substantial time investment from pathologists. Eye gaze annotations have the potential to speed up the slide labeling process. This work explores the viability and timing comparisons of eye gaze labeling compared to conventional manual labeling for training object detectors. Challenges associated with gaze based labeling and methods to refine the coarse data annotations for subsequent object detection are also discussed. Results demonstrate that gaze tracking based labeling can save valuable pathologist time and delivers good performance when employed for training a deep object detector. Using the task of localization of Keratin Pearls in cases of oral squamous cell carcinoma as a test case, we compare the performance gap between deep object detectors trained using hand-labelled and gaze-labelled data. On average, compared to `Bounding-box' based hand-labeling, gaze-labeling required $57.6\\%$ less time per label and compared to `Freehand' labeling, gaze-labeling required on average $85\\%$ less time per label. ",
    "url": "https://arxiv.org/abs/2202.02764",
    "authors": [
      "Komal Mariam",
      "Osama Mohammed Afzal",
      "Wajahat Hussain",
      "Muhammad Umar Javed",
      "Amber Kiyani",
      "Nasir Rajpoot",
      "Syed Ali Khurram",
      "Hassan Aqeel Khan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.02815",
    "title": "Learning Sparse Graphs via Majorization-Minimization for Smooth Node  Signals",
    "abstract": "In this letter, we propose an algorithm for learning a sparse weighted graph by estimating its adjacency matrix under the assumption that the observed signals vary smoothly over the nodes of the graph. The proposed algorithm is based on the principle of majorization-minimization (MM), wherein we first obtain a tight surrogate function for the graph learning objective and then solve the resultant surrogate problem which has a simple closed form solution. The proposed algorithm does not require tuning of any hyperparameter and it has the desirable feature of eliminating the inactive variables in the course of the iterations - which can help speeding up the algorithm. The numerical simulations conducted using both synthetic and real world (brain-network) data show that the proposed algorithm converges faster, in terms of the average number of iterations, than several existing methods in the literature. ",
    "url": "https://arxiv.org/abs/2202.02815",
    "authors": [
      "Ghania Fatima",
      "Aakash Arora",
      "Prabhu Babu",
      "Petre Stoica"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02832",
    "title": "Detecting Melanoma Fairly: Skin Tone Detection and Debiasing for Skin  Lesion Classification",
    "abstract": "Convolutional Neural Networks have demonstrated human-level performance in the classification of melanoma and other skin lesions, but evident performance disparities between differing skin tones should be addressed before widespread deployment. In this work, we utilise a modified variational autoencoder to uncover skin tone bias in datasets commonly used as benchmarks. We propose an efficient yet effective algorithm for automatically labelling the skin tone of lesion images, and use this to annotate the benchmark ISIC dataset. We subsequently use two leading bias unlearning techniques to mitigate skin tone bias. Our experimental results provide evidence that our skin tone detection algorithm outperforms existing solutions and that unlearning skin tone improves generalisation and can reduce the performance disparity between melanoma detection in lighter and darker skin tones. ",
    "url": "https://arxiv.org/abs/2202.02832",
    "authors": [
      "Peter J. Bevan",
      "Amir Atapour-Abarghouei"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.02833",
    "title": "CheXstray: Real-time Multi-Modal Data Concordance for Drift Detection in  Medical Imaging AI",
    "abstract": "Rapidly expanding Clinical AI applications worldwide have the potential to impact to all areas of medical practice. Medical imaging applications constitute a vast majority of approved clinical AI applications. Though healthcare systems are eager to adopt AI solutions a fundamental question remains: \\textit{what happens after the AI model goes into production?} We use the CheXpert and PadChest public datasets to build and test a medical imaging AI drift monitoring workflow that tracks data and model drift without contemporaneous ground truth. We simulate drift in multiple experiments to compare model performance with our novel multi-modal drift metric, which uses DICOM metadata, image appearance representation from a variational autoencoder (VAE), and model output probabilities as input. Through experimentation, we demonstrate a strong proxy for ground truth performance using unsupervised distributional shifts in relevant metadata, predicted probabilities, and VAE latent representation. Our key contributions include (1) proof-of-concept for medical imaging drift detection including use of VAE and domain specific statistical methods (2) a multi-modal methodology for measuring and unifying drift metrics (3) new insights into the challenges and solutions for observing deployed medical imaging AI (4) creation of open-source tools enabling others to easily run their own workflows or scenarios. This work has important implications for addressing the translation gap related to continuous medical imaging AI model monitoring in dynamic healthcare environments. ",
    "url": "https://arxiv.org/abs/2202.02833",
    "authors": [
      "Arjun Soin",
      "Jameson Merkow",
      "Jin Long",
      "Joesph Paul Cohen",
      "Smitha Saligrama",
      "Stephen Kaiser",
      "Steven Borg",
      "Ivan Tarapov",
      "Matthew P Lungren"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02876",
    "title": "Deep Convolutional Learning-Aided Detector for Generalized Frequency  Division Multiplexing with Index Modulation",
    "abstract": "In this paper, a deep convolutional neural network-based symbol detection and demodulation is proposed for generalized frequency division multiplexing with index modulation (GFDM-IM) scheme in order to improve the error performance of the system. The proposed method first pre-processes the received signal by using a zero-forcing (ZF) detector and then uses a neural network consisting of a convolutional neural network (CNN) followed by a fully-connected neural network (FCNN). The FCNN part uses only two fully-connected layers, which can be adapted to yield a trade-off between complexity and bit error rate (BER) performance. This two-stage approach prevents the getting stuck of neural network in a saddle point and enables IM blocks processing independently. It has been demonstrated that the proposed deep convolutional neural network-based detection and demodulation scheme provides better BER performance compared to ZF detector with a reasonable complexity increase. We conclude that non-orthogonal waveforms combined with IM schemes with the help of deep learning is a promising physical layer (PHY) scheme for future wireless networks ",
    "url": "https://arxiv.org/abs/2202.02876",
    "authors": [
      "Merve Turhan",
      "Ersin \u00d6zt\u00fcrk",
      "Hakan Ali \u00c7\u0131rpan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02943",
    "title": "Learning fair representation with a parametric integral probability  metric",
    "abstract": "As they have a vital effect on social decision-making, AI algorithms should be not only accurate but also fair. Among various algorithms for fairness AI, learning fair representation (LFR), whose goal is to find a fair representation with respect to sensitive variables such as gender and race, has received much attention. For LFR, the adversarial training scheme is popularly employed as is done in the generative adversarial network type algorithms. The choice of a discriminator, however, is done heuristically without justification. In this paper, we propose a new adversarial training scheme for LFR, where the integral probability metric (IPM) with a specific parametric family of discriminators is used. The most notable result of the proposed LFR algorithm is its theoretical guarantee about the fairness of the final prediction model, which has not been considered yet. That is, we derive theoretical relations between the fairness of representation and the fairness of the prediction model built on the top of the representation (i.e., using the representation as the input). Moreover, by numerical experiments, we show that our proposed LFR algorithm is computationally lighter and more stable, and the final prediction model is competitive or superior to other LFR algorithms using more complex discriminators. ",
    "url": "https://arxiv.org/abs/2202.02943",
    "authors": [
      "Dongha Kim",
      "Kunwoong Kim",
      "Insung Kong",
      "Ilsang Ohn",
      "Yongdai Kim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02984",
    "title": "Deep Residual Shrinkage Networks for EMG-based Gesture Identification",
    "abstract": "This work introduces a method for high-accuracy EMG based gesture identification. A newly developed deep learning method, namely, deep residual shrinkage network is applied to perform gesture identification. Based on the feature of EMG signal resulting from gestures, optimizations are made to improve the identification accuracy. Finally, three different algorithms are applied to compare the accuracy of EMG signal recognition with that of DRSN. The result shows that DRSN excel traditional neural networks in terms of EMG recognition accuracy. This paper provides a reliable way to classify EMG signals, as well as exploring possible applications of DRSN. ",
    "url": "https://arxiv.org/abs/2202.02984",
    "authors": [
      "Yueying Ma",
      "Chengbo Wang",
      "Chengbo Wang",
      "Zimo Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03036",
    "title": "Structure-Aware Transformer for Graph Representation Learning",
    "abstract": "The Transformer architecture has gained growing attention in graph representation learning recently, as it naturally overcomes several limitations of graph neural networks (GNNs) by avoiding their strict structural inductive biases and instead only encoding the graph structure via positional encoding. Here, we show that the node representations generated by the Transformer with positional encoding do not necessarily capture structural similarity between them. To address this issue, we propose the Structure-Aware Transformer, a class of simple and flexible graph transformers built upon a new self-attention mechanism. This new self-attention incorporates structural information into the original self-attention by extracting a subgraph representation rooted at each node before computing the attention. We propose several methods for automatically generating the subgraph representation and show theoretically that the resulting representations are at least as expressive as the subgraph representations. Empirically, our method achieves state-of-the-art performance on five graph prediction benchmarks. Our structure-aware framework can leverage any existing GNN to extract the subgraph representation, and we show that it systematically improves performance relative to the base GNN model, successfully combining the advantages of GNNs and transformers. ",
    "url": "https://arxiv.org/abs/2202.03036",
    "authors": [
      "Dexiong Chen",
      "Leslie O'Bray",
      "Karsten Borgwardt"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03101",
    "title": "NUQ: Nonparametric Uncertainty Quantification for Deterministic Neural  Networks",
    "abstract": "This paper proposes a fast and scalable method for uncertainty quantification of machine learning models' predictions. First, we show the principled way to measure the uncertainty of predictions for a classifier based on Nadaraya-Watson's nonparametric estimate of the conditional label distribution. Importantly, the approach allows to disentangle explicitly aleatoric and epistemic uncertainties. The resulting method works directly in the feature space. However, one can apply it to any neural network by considering an embedding of the data induced by the network. We demonstrate the strong performance of the method in uncertainty estimation tasks on a variety of real-world image datasets, such as MNIST, SVHN, CIFAR-100 and several versions of ImageNet. ",
    "url": "https://arxiv.org/abs/2202.03101",
    "authors": [
      "Nikita Kotelevskii",
      "Aleksandr Artemenkov",
      "Kirill Fedyanin",
      "Fedor Noskov",
      "Alexander Fishkov",
      "Aleksandr Petiushko",
      "Maxim Panov"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03149",
    "title": "Neural Network based Inter bi-prediction Blending",
    "abstract": "This paper presents a learning-based method to improve bi-prediction in video coding. In conventional video coding solutions, the motion compensation of blocks from already decoded reference pictures stands out as the principal tool used to predict the current frame. Especially, the bi-prediction, in which a block is obtained by averaging two different motion-compensated prediction blocks, significantly improves the final temporal prediction accuracy. In this context, we introduce a simple neural network that further improves the blending operation. A complexity balance, both in terms of network size and encoder mode selection, is carried out. Extensive tests on top of the recently standardized VVC codec are performed and show a BD-rate improvement of -1.4% in random access configuration for a network size of fewer than 10k parameters. We also propose a simple CPU-based implementation and direct network quantization to assess the complexity/gains tradeoff in a conventional codec framework. ",
    "url": "https://arxiv.org/abs/2202.03149",
    "authors": [
      "Franck Galpin",
      "Philippe Bordes",
      "Thierry Dumas",
      "Pavel Nikitin",
      "Fabrice Le Leannec"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03156",
    "title": "Comparative Study of Machine Learning Models for Stock Price Prediction",
    "abstract": "In this work, we apply machine learning techniques to historical stock prices to forecast future prices. To achieve this, we use recursive approaches that are appropriate for handling time series data. In particular, we apply a linear Kalman filter and different varieties of long short-term memory (LSTM) architectures to historical stock prices over a 10-year range (1/1/2011 - 1/1/2021). We quantify the results of these models by computing the error of the predicted values versus the historical values of each stock. We find that of the algorithms we investigated, a simple linear Kalman filter can predict the next-day value of stocks with low-volatility (e.g., Microsoft) surprisingly well. However, in the case of high-volatility stocks (e.g., Tesla) the more complex LSTM algorithms significantly outperform the Kalman filter. Our results show that we can classify different types of stocks and then train an LSTM for each stock type. This method could be used to automate portfolio generation for a target return rate. ",
    "url": "https://arxiv.org/abs/2202.03156",
    "authors": [
      "Ogulcan E. Orsel",
      "Sasha S. Yamada"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03181",
    "title": "On chromatic parameters of some Regular graphs",
    "abstract": "In this work, we try to enunciate the Total chromatic number of some Cayley graphs like the Cayley graph on Symmetric group, Alternating group, Dihedral group with respect to some generating sets and some other regular graphs. ",
    "url": "https://arxiv.org/abs/2202.03181",
    "authors": [
      "Prajnanaswaroopa S"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2202.03204",
    "title": "T-NGA: Temporal Network Grafting Algorithm for Learning to Process  Spiking Audio Sensor Events",
    "abstract": "Spiking silicon cochlea sensors encode sound as an asynchronous stream of spikes from different frequency channels. The lack of labeled training datasets for spiking cochleas makes it difficult to train deep neural networks on the outputs of these sensors. This work proposes a self-supervised method called Temporal Network Grafting Algorithm (T-NGA), which grafts a recurrent network pretrained on spectrogram features so that the network works with the cochlea event features. T-NGA training requires only temporally aligned audio spectrograms and event features. Our experiments show that the accuracy of the grafted network was similar to the accuracy of a supervised network trained from scratch on a speech recognition task using events from a software spiking cochlea model. Despite the circuit non-idealities of the spiking silicon cochlea, the grafted network accuracy on the silicon cochlea spike recordings was only about 5% lower than the supervised network accuracy using the N-TIDIGITS18 dataset. T-NGA can train networks to process spiking audio sensor events in the absence of large labeled spike datasets. ",
    "url": "https://arxiv.org/abs/2202.03204",
    "authors": [
      "Shu Wang",
      "Yuhuang Hu",
      "Shih-Chii Liu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2202.03223",
    "title": "SODA: Self-organizing data augmentation in deep neural networks --  Application to biomedical image segmentation tasks",
    "abstract": "In practice, data augmentation is assigned a predefined budget in terms of newly created samples per epoch. When using several types of data augmentation, the budget is usually uniformly distributed over the set of augmentations but one can wonder if this budget should not be allocated to each type in a more efficient way. This paper leverages online learning to allocate on the fly this budget as part of neural network training. This meta-algorithm can be run at almost no extra cost as it exploits gradient based signals to determine which type of data augmentation should be preferred. Experiments suggest that this strategy can save computation time and thus goes in the way of greener machine learning practices. ",
    "url": "https://arxiv.org/abs/2202.03223",
    "authors": [
      "Arnaud Deleruyelle",
      "John Klein",
      "Cristian Versari"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2202.03233",
    "title": "A Variational Edge Partition Model for Supervised Graph Representation  Learning",
    "abstract": "Graph neural networks (GNNs), which propagate the node features through the edges and learn how to transform the aggregated features under label supervision, have achieved great success in supervised feature extraction for both node-level and graph-level classification tasks. However, GNNs typically treat the graph structure as given and ignore how the edges are formed. This paper introduces a graph generative process to model how the observed edges are generated by aggregating the node interactions over a set of overlapping node communities, each of which contributes to the edges via a logical OR mechanism. Based on this generative model, we partition each edge into the summation of multiple community-specific weighted edges and use them to define community-specific GNNs. A variational inference framework is proposed to jointly learn a GNN based inference network that partitions the edges into different communities, these community-specific GNNs, and a GNN based predictor that combines community-specific GNNs for the end classification task. Extensive evaluations on real-world graph datasets have verified the effectiveness of the proposed method in learning discriminative representations for both node-level and graph-level classification tasks. ",
    "url": "https://arxiv.org/abs/2202.03233",
    "authors": [
      "Yilin He",
      "Chaojie Wang",
      "Hao Zhang",
      "Bo Chen",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2202.03268",
    "title": "Cyber-resilience for marine navigation by information fusion and change  detection",
    "abstract": "Cyber-resilience is an increasing concern in developing autonomous navigation solutions for marine vessels. This paper scrutinizes cyber-resilience properties of marine navigation through a prism with three edges: multiple sensor information fusion, diagnosis of not-normal behaviours, and change detection. It proposes a two-stage estimator for diagnosis and mitigation of sensor signals used for coastal navigation. Developing a Likelihood Field approach, a first stage extracts shoreline features from radar and matches them to the electronic navigation chart. A second stage associates buoy and beacon features from the radar with chart information. Using real data logged at sea tests combined with simulated spoofing, the paper verifies the ability to timely diagnose and isolate an attempt to compromise position measurements. A new approach is suggested for high level processing of received data to evaluate their consistency, that is agnostic to the underlying technology of the individual sensory input. A combined parametric Gaussian modelling and Kernel Density Estimation is suggested and compared with a generalized likelihood ratio change detector that uses sliding windows. The paper shows how deviations from nominal behaviour and isolation of the components is possible when under attack or when defects in sensors occur. ",
    "url": "https://arxiv.org/abs/2202.03268",
    "authors": [
      "Dimitrios Dagdilelis",
      "Mogens Blanke",
      "Rasmus Hjorth Andersen",
      "Roberto Galeazzi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2202.03274",
    "title": "Human Activity Recognition Using Tools of Convolutional Neural Networks:  A State of the Art Review, Data Sets, Challenges and Future Prospects",
    "abstract": "Human Activity Recognition (HAR) plays a significant role in the everyday life of people because of its ability to learn extensive high-level information about human activity from wearable or stationary devices. A substantial amount of research has been conducted on HAR and numerous approaches based on deep learning and machine learning have been exploited by the research community to classify human activities. The main goal of this review is to summarize recent works based on a wide range of deep neural networks architecture, namely convolutional neural networks (CNNs) for human activity recognition. The reviewed systems are clustered into four categories depending on the use of input devices like multimodal sensing devices, smartphones, radar, and vision devices. This review describes the performances, strengths, weaknesses, and the used hyperparameters of CNN architectures for each reviewed system with an overview of available public data sources. In addition, a discussion with the current challenges to CNN-based HAR systems is presented. Finally, this review is concluded with some potential future directions that would be of great assistance for the researchers who would like to contribute to this field. ",
    "url": "https://arxiv.org/abs/2202.03274",
    "authors": [
      "Md. Milon Islam",
      "Sheikh Nooruddin",
      "Fakhri Karray",
      "Ghulam Muhammad"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03323",
    "title": "Motion-Plane-Adaptive Inter Prediction in 360-Degree Video Coding",
    "abstract": "Inter prediction is one of the key technologies enabling the high compression efficiency of modern video coding standards. 360-degree video needs to be mapped to the 2D image plane prior to coding in order to allow compression using existing video coding standards. The distortions that inevitably occur when mapping spherical data onto the 2D image plane, however, impair the performance of classical inter prediction techniques. In this paper, we propose a motion-plane-adaptive inter prediction technique (MPA) for 360-degree video that takes the spherical characteristics of 360-degree video into account. Based on the known projection format of the video, MPA allows to perform inter prediction on different motion planes in 3D space instead of having to work on the - in theory arbitrarily mapped - 2D image representation directly. We furthermore derive a motion-plane-adaptive motion vector prediction technique (MPA-MVP) that allows to translate motion information between different motion planes and motion models. Our proposed integration of MPA together with MPA-MVP into the state-of-the-art H.266/VVC video coding standard shows significant Bjontegaard Delta rate savings of 1.72% with a peak of 3.97% based on PSNR and 1.56% with a peak of 3.40% based on WS-PSNR compared to the VTM-14.2 baseline on average. ",
    "url": "https://arxiv.org/abs/2202.03323",
    "authors": [
      "Andy Regensky",
      "Christian Herglotz",
      "Andr\u00e9 Kaup"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.03338",
    "title": "Robust Semantic Communications Against Semantic Noise",
    "abstract": "Although the semantic communications have exhibited satisfactory performance in a large number of tasks, the impact of semantic noise and the robustness of the systems have not been well investigated. Semantic noise is a particular kind of noise in semantic communication systems, which refers to the misleading between the intended semantic symbols and received ones. In this paper, we first propose a framework for the robust end-to-end semantic communication systems to combat the semantic noise. Particularly, we analyze the causes of semantic noise and propose a practical method to generate it. To remove the effect of semantic noise, adversarial training is proposed to incorporate the samples with semantic noise in the training dataset. Then, the masked autoencoder is designed as the architecture of a robust semantic communication system, where a portion of the input is masked. To further improve the robustness of semantic communication systems, we design a discrete codebook shared by the transmitter and the receiver for encoded feature representation. Thus, the transmitter simply needs to transmit the indices of these features in the codebook. Simulation results show that our proposed method significantly improves the robustness of semantic communication systems against semantic noise with significant reduction on the transmission overhead. ",
    "url": "https://arxiv.org/abs/2202.03338",
    "authors": [
      "Qiyu Hu",
      "Guangyi Zhang",
      "Zhijin Qin",
      "Yunlong Cai",
      "Guanding Yu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03346",
    "title": "Variance reduced stochastic optimization over directed graphs with row  and column stochastic weights",
    "abstract": "This paper proposes AB-SAGA, a first-order distributed stochastic optimization method to minimize a finite-sum of smooth and strongly convex functions distributed over an arbitrary directed graph. AB-SAGA removes the uncertainty caused by the stochastic gradients using a node-level variance reduction and subsequently employs network-level gradient tracking to address the data dissimilarity across the nodes. Unlike existing methods that use the nonlinear push-sum correction to cancel the imbalance caused by the directed communication, the consensus updates in AB-SAGA are linear and uses both row and column stochastic weights. We show that for a constant step-size, AB-SAGA converges linearly to the global optimal. We quantify the directed nature of the underlying graph using an explicit directivity constant and characterize the regimes in which AB-SAGA achieves a linear speed-up over its centralized counterpart. Numerical experiments illustrate the convergence of AB-SAGA for strongly convex and nonconvex problems. ",
    "url": "https://arxiv.org/abs/2202.03346",
    "authors": [
      "Muhammad I. Qureshi",
      "Ran Xin",
      "Soummya Kar",
      "Usman A. Khan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.03407",
    "title": "Investigating the fidelity of explainable artificial intelligence  methods for applications of convolutional neural networks in geoscience",
    "abstract": "Convolutional neural networks (CNNs) have recently attracted great attention in geoscience due to their ability to capture non-linear system behavior and extract predictive spatiotemporal patterns. Given their black-box nature however, and the importance of prediction explainability, methods of explainable artificial intelligence (XAI) are gaining popularity as a means to explain the CNN decision-making strategy. Here, we establish an intercomparison of some of the most popular XAI methods and investigate their fidelity in explaining CNN decisions for geoscientific applications. Our goal is to raise awareness of the theoretical limitations of these methods and gain insight into the relative strengths and weaknesses to help guide best practices. The considered XAI methods are first applied to an idealized attribution benchmark, where the ground truth of explanation of the network is known a priori, to help objectively assess their performance. Secondly, we apply XAI to a climate-related prediction setting, namely to explain a CNN that is trained to predict the number of atmospheric rivers in daily snapshots of climate simulations. Our results highlight several important issues of XAI methods (e.g., gradient shattering, inability to distinguish the sign of attribution, ignorance to zero input) that have previously been overlooked in our field and, if not considered cautiously, may lead to a distorted picture of the CNN decision-making strategy. We envision that our analysis will motivate further investigation into XAI fidelity and will help towards a cautious implementation of XAI in geoscience, which can lead to further exploitation of CNNs and deep learning for prediction problems. ",
    "url": "https://arxiv.org/abs/2202.03407",
    "authors": [
      "Antonios Mamalakis",
      "Elizabeth A. Barnes",
      "Imme Ebert-Uphoff"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1903.11394",
    "title": "Motion Deblurring with an Adaptive Network",
    "abstract": " Title: Motion Deblurring with an Adaptive Network ",
    "url": "https://arxiv.org/abs/1903.11394",
    "authors": [
      "Kuldeep Purohit",
      "A. N. Rajagopalan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:1906.02869",
    "title": "One-Shot Neural Architecture Search via Compressive Sensing",
    "abstract": " Comments: 2nd Workshop on Neural Architecture Search at ICLR 2021 ",
    "url": "https://arxiv.org/abs/1906.02869",
    "authors": [
      "Minsu Cho",
      "Mohammadreza Soltani",
      "Chinmay Hegde"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1909.11193",
    "title": "Scaling-Translation-Equivariant Networks with Decomposed Convolutional  Filters",
    "abstract": " Title: Scaling-Translation-Equivariant Networks with Decomposed Convolutional  Filters ",
    "url": "https://arxiv.org/abs/1909.11193",
    "authors": [
      "Wei Zhu",
      "Qiang Qiu",
      "Robert Calderbank",
      "Guillermo Sapiro",
      "Xiuyuan Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1912.12257",
    "title": "Performance Analysis of TLS for Quantum Robust Cryptography on a  Constrained Device",
    "abstract": " Title: Performance Analysis of TLS for Quantum Robust Cryptography on a  Constrained Device ",
    "url": "https://arxiv.org/abs/1912.12257",
    "authors": [
      "Jon Barton",
      "William J Buchanan",
      "Nikolaos Pitropakis",
      "Sarwar Sayeed",
      "Will Abramson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2006.08539",
    "title": "Deep Layer-wise Networks Have Closed-Form Weights",
    "abstract": " Comments: This version will be published in AIStats 2022 ",
    "url": "https://arxiv.org/abs/2006.08539",
    "authors": [
      "Chieh Wu",
      "Aria Masoomi",
      "Arthur Gretton",
      "Jennifer Dy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2008.05214",
    "title": "REMAX: Relational Representation for Multi-Agent Exploration",
    "abstract": " Comments: Accepted as a full paper at the Twenty-First International Conference on Autonomous Agents and Multiagent Systems (AAMAS-22), Virtual Conference ",
    "url": "https://arxiv.org/abs/2008.05214",
    "authors": [
      "Heechang Ryu",
      "Hayong Shin",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2009.00606",
    "title": "Semi-Supervised Empirical Risk Minimization: Using unlabeled data to  improve prediction",
    "abstract": " Comments: 39 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2009.00606",
    "authors": [
      "Oren Yuval",
      "Saharon Rosset"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2009.09612",
    "title": "Improving Ensemble Robustness by Collaboratively Promoting and Demoting  Adversarial Robustness",
    "abstract": " Title: Improving Ensemble Robustness by Collaboratively Promoting and Demoting  Adversarial Robustness ",
    "url": "https://arxiv.org/abs/2009.09612",
    "authors": [
      "Anh Bui",
      "Trung Le",
      "He Zhao",
      "Paul Montague",
      "Olivier deVel",
      "Tamas Abraham",
      "Dinh Phung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2010.06163",
    "title": "Bridging 2D and 3D Segmentation Networks for Computation Efficient  Volumetric Medical Image Segmentation: An Empirical Study of 2.5D Solutions",
    "abstract": " Comments: Computerized Medical Imaging and Graphics ",
    "url": "https://arxiv.org/abs/2010.06163",
    "authors": [
      "Yichi Zhang",
      "Qingcheng Liao",
      "Le Ding",
      "Jicong Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2011.14229",
    "title": "Deep Learning for Regularization Prediction in Diffeomorphic Image  Registration",
    "abstract": " Comments: 20 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2011.14229",
    "authors": [
      "Jian Wang",
      "Miaomiao Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.07244",
    "title": "Bayesian Neural Ordinary Differential Equations",
    "abstract": " Comments: 16 pages, 10 figures, 3 tables; added new inference methods, substantially improved MNIST accuracy, revised author affiliations ",
    "url": "https://arxiv.org/abs/2012.07244",
    "authors": [
      "Raj Dandekar",
      "Karen Chung",
      "Vaibhav Dixit",
      "Mohamed Tarek",
      "Aslan Garcia-Valadez",
      "Krishna Vishal Vemula",
      "Chris Rackauckas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.15834",
    "title": "Topological obstructions in neural networks learning",
    "abstract": " Title: Topological obstructions in neural networks learning ",
    "url": "https://arxiv.org/abs/2012.15834",
    "authors": [
      "Serguei Barannikov",
      "Daria Voronkova",
      "Ilya Trofimov",
      "Alexander Korotin",
      "Grigorii Sotnikov",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2101.00078",
    "title": "Controlled Analyses of Social Biases in Wikipedia Bios",
    "abstract": " Comments: Accepted to the Web Conference 2022 (WWW '22) ",
    "url": "https://arxiv.org/abs/2101.00078",
    "authors": [
      "Anjalie Field",
      "Chan Young Park",
      "Kevin Z. Lin",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2101.09193",
    "title": "Dense outlier detection and open-set recognition based on training with  noisy negative images",
    "abstract": " Title: Dense outlier detection and open-set recognition based on training with  noisy negative images ",
    "url": "https://arxiv.org/abs/2101.09193",
    "authors": [
      "Petra Bevandi\u0107",
      "Ivan Kre\u0161o",
      "Marin Or\u0161i\u0107",
      "Sini\u0161a \u0160egvi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2102.02515",
    "title": "HYDRA: Hypergradient Data Relevance Analysis for Interpreting Deep  Neural Networks",
    "abstract": " Title: HYDRA: Hypergradient Data Relevance Analysis for Interpreting Deep  Neural Networks ",
    "url": "https://arxiv.org/abs/2102.02515",
    "authors": [
      "Yuanyuan Chen",
      "Boyang Li",
      "Han Yu",
      "Pengcheng Wu",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.00778",
    "title": "Explaining Adversarial Vulnerability with a Data Sparsity Hypothesis",
    "abstract": " Title: Explaining Adversarial Vulnerability with a Data Sparsity Hypothesis ",
    "url": "https://arxiv.org/abs/2103.00778",
    "authors": [
      "Mahsa Paknezhad",
      "Cuong Phuc Ngo",
      "Amadeus Aristo Winarto",
      "Alistair Cheong",
      "Chuen Yang Beh",
      "Jiayang Wu",
      "Hwee Kuan Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2104.01847",
    "title": "Reddit's self-organised bull runs: Social contagion and asset prices",
    "abstract": " Comments: This paper was originally put online as a departmental pre-print on the departmental website at this https URL and on MPRA on February 2, 2021 ",
    "url": "https://arxiv.org/abs/2104.01847",
    "authors": [
      "Valentina Semenova",
      "Julian Winkler"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2105.03918",
    "title": "Opening the Blackbox: Accelerating Neural Differential Equations by  Regularizing Internal Solver Heuristics",
    "abstract": " Comments: Proceedings of the 38 th International Conference on Machine Learning, 2021 ",
    "url": "https://arxiv.org/abs/2105.03918",
    "authors": [
      "Avik Pal",
      "Yingbo Ma",
      "Viral Shah",
      "Christopher Rackauckas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2105.07574",
    "title": "SoundFence: Securing Ultrasonic Sensors in Vehicles Using Physical-Layer  Defense",
    "abstract": " Comments: have some unresolved issues ",
    "url": "https://arxiv.org/abs/2105.07574",
    "authors": [
      "Jianzhi Lou",
      "Qiben Yan",
      "Qing Hui",
      "Huacheng Zeng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2106.04477",
    "title": "MoCo-Flow: Neural Motion Consensus Flow for Dynamic Humans in Stationary  Monocular Cameras",
    "abstract": " Title: MoCo-Flow: Neural Motion Consensus Flow for Dynamic Humans in Stationary  Monocular Cameras ",
    "url": "https://arxiv.org/abs/2106.04477",
    "authors": [
      "Xuelin Chen",
      "Weiyu Li",
      "Daniel Cohen-Or",
      "Niloy J. Mitra",
      "Baoquan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.08253",
    "title": "A Syntax-Guided Edit Decoder for Neural Program Repair",
    "abstract": " Comments: 10 pages ",
    "url": "https://arxiv.org/abs/2106.08253",
    "authors": [
      "Qihao Zhu",
      "Zeyu Sun",
      "Yuan-an Xiao",
      "Wenjie Zhang",
      "Kang Yuan",
      "Yingfei Xiong",
      "Lu Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.08704",
    "title": "Memorization and Generalization in Neural Code Intelligence Models",
    "abstract": " Comments: Under Review ",
    "url": "https://arxiv.org/abs/2106.08704",
    "authors": [
      "Md Rafiqul Islam Rabin",
      "Aftab Hussain",
      "Mohammad Amin Alipour",
      "Vincent J. Hellendoorn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2106.11892",
    "title": "Making Invisible Visible: Data-Driven Seismic Inversion with  Spatio-temporally Constrained Data Augmentation",
    "abstract": " Comments: 15 pages, 15 figures, accepted by IEEE Transactions on Geoscience and Remote Sensing, available as early access ",
    "url": "https://arxiv.org/abs/2106.11892",
    "authors": [
      "Yuxin Yang",
      "Xitong Zhang",
      "Qiang Guan",
      "Youzuo Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.03694",
    "title": "Network and Sequence-Based Prediction of Protein-Protein Interactions",
    "abstract": " Title: Network and Sequence-Based Prediction of Protein-Protein Interactions ",
    "url": "https://arxiv.org/abs/2107.03694",
    "authors": [
      "Leonardo Martini",
      "Adriano Fazzone",
      "Luca Becchetti"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Other Computer Science (cs.OH)"
    ]
  },
  {
    "id": "arXiv:2107.13530",
    "title": "An Adapter Based Pre-Training for Efficient and Scalable Self-Supervised  Speech Representation Learning",
    "abstract": " Comments: 5 pages, 6 figures. Accepted at ICASSP 2022. This version replaces an earlier version of paper accepted at an ICML 2021 workshop ",
    "url": "https://arxiv.org/abs/2107.13530",
    "authors": [
      "Samuel Kessler",
      "Bethan Thomas",
      "Salah Karout"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2108.02113",
    "title": "Hyperparameter-free and Explainable Whole Graph Embedding",
    "abstract": " Title: Hyperparameter-free and Explainable Whole Graph Embedding ",
    "url": "https://arxiv.org/abs/2108.02113",
    "authors": [
      "Hao Wang",
      "Yue Deng",
      "Linyuan L\u00fc",
      "Guanrong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2108.03710",
    "title": "Online Admission Control and Resource Allocation in Network Slicing  under Demand Uncertainties",
    "abstract": " Title: Online Admission Control and Resource Allocation in Network Slicing  under Demand Uncertainties ",
    "url": "https://arxiv.org/abs/2108.03710",
    "authors": [
      "Sajjad Gholamipour",
      "Behzad Akbari",
      "Nader Mokari",
      "Mohammad Mahdi Tajiki",
      "Eduard Axel Jorswieck"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2108.04951",
    "title": "A Brief Review of Machine Learning Techniques for Protein  Phosphorylation Sites Prediction",
    "abstract": " Title: A Brief Review of Machine Learning Techniques for Protein  Phosphorylation Sites Prediction ",
    "url": "https://arxiv.org/abs/2108.04951",
    "authors": [
      "Farzaneh Esmaili",
      "Mahdi Pourmirzaei",
      "Shahin Ramazi",
      "Elham Yavari"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.08467",
    "title": "Medical Image Segmentation using 3D Convolutional Neural Networks: A  Review",
    "abstract": " Comments: 17 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2108.08467",
    "authors": [
      "S Niyas",
      "S J Pawan",
      "M Anand Kumar",
      "Jeny Rajan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.05668",
    "title": "UMPNet: Universal Manipulation Policy Network for Articulated Objects",
    "abstract": " Comments: RA-L/ICRA 2022. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2109.05668",
    "authors": [
      "Zhenjia Xu",
      "Zhanpeng He",
      "Shuran Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2109.11192",
    "title": "Predicting the Timing of Camera Movements From the Kinematics of  Instruments in Robotic-Assisted Surgery Using Artificial Neural Networks",
    "abstract": " Title: Predicting the Timing of Camera Movements From the Kinematics of  Instruments in Robotic-Assisted Surgery Using Artificial Neural Networks ",
    "url": "https://arxiv.org/abs/2109.11192",
    "authors": [
      "Hanna Kossowsky",
      "Ilana Nisky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2109.14128",
    "title": "Grouptron: Dynamic Multi-Scale Graph Convolutional Networks for  Group-Aware Dense Crowd Trajectory Forecasting",
    "abstract": " Comments: ICRA 2022 Accepted ",
    "url": "https://arxiv.org/abs/2109.14128",
    "authors": [
      "Rui Zhou",
      "Hongyu Zhou",
      "Masayoshi Tomizuka",
      "Jiachen Li",
      "Zhuo Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2110.01712",
    "title": "Feedback control of social distancing for COVID-19 via elementary  formulae",
    "abstract": " Comments: 10th Vienna International Conference on Mathematical Modelling (MATHMOD 2022) -- July 27-29, 2022 -- Vienna, Austria ",
    "url": "https://arxiv.org/abs/2110.01712",
    "authors": [
      "Michel Fliess",
      "C\u00e9dric Join",
      "Alberto d'Onofrio"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2110.02423",
    "title": "Geometric Transformers for Protein Interface Contact Prediction",
    "abstract": " Comments: 18 pages, 5 figures, and 9 tables. Camera-ready version for ICLR 2022, with a minor update in the conclusion section ",
    "url": "https://arxiv.org/abs/2110.02423",
    "authors": [
      "Alex Morehead",
      "Chen Chen",
      "Jianlin Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2110.03301",
    "title": "EvadeDroid: A Practical Evasion Attack on Machine Learning for Black-box  Android Malware Detection",
    "abstract": " Title: EvadeDroid: A Practical Evasion Attack on Machine Learning for Black-box  Android Malware Detection ",
    "url": "https://arxiv.org/abs/2110.03301",
    "authors": [
      "Hamid Bostani",
      "Veelasha Moonsamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2110.03442",
    "title": "A Comparison of Neural Network Architectures for Data-Driven  Reduced-Order Modeling",
    "abstract": " Title: A Comparison of Neural Network Architectures for Data-Driven  Reduced-Order Modeling ",
    "url": "https://arxiv.org/abs/2110.03442",
    "authors": [
      "Anthony Gruber",
      "Max Gunzburger",
      "Lili Ju",
      "Zhu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2110.03735",
    "title": "Adversarial Unlearning of Backdoors via Implicit Hypergradient",
    "abstract": " Comments: In proceeding of the Tenth International Conference on Learning Representations (ICLR 2022) ",
    "url": "https://arxiv.org/abs/2110.03735",
    "authors": [
      "Yi Zeng",
      "Si Chen",
      "Won Park",
      "Z. Morley Mao",
      "Ming Jin",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.04057",
    "title": "FAST-RIR: Fast neural diffuse room impulse response generator",
    "abstract": " Comments: Accepted to ICASSP 2022. More results and source code is available at this https URL ",
    "url": "https://arxiv.org/abs/2110.04057",
    "authors": [
      "Anton Ratnarajah",
      "Shi-Xiong Zhang",
      "Meng Yu",
      "Zhenyu Tang",
      "Dinesh Manocha",
      "Dong Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2110.04488",
    "title": "Demystifying the Transferability of Adversarial Attacks in Computer  Networks",
    "abstract": " Comments: 15 pages ",
    "url": "https://arxiv.org/abs/2110.04488",
    "authors": [
      "Ehsan Nowroozi",
      "Yassine Mekdad",
      "Mohammad Hajian Berenjestanaki",
      "Mauro Conti",
      "Abdeslam EL Fergougui"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2110.06986",
    "title": "ADMM-DAD net: a deep unfolding network for analysis compressed sensing",
    "abstract": " Comments: to appear in 2022 International Conference on Acoustics, Speech and Signal Processing (ICASSP) ",
    "url": "https://arxiv.org/abs/2110.06986",
    "authors": [
      "Vasiliki Kouni",
      "Georgios Paraskevopoulos",
      "Holger Rauhut",
      "George C. Alexandropoulos"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.07317",
    "title": "ReGVD: Revisiting Graph Neural Networks for Vulnerability Detection",
    "abstract": " Comments: Accepted to ICSE 2022 (Demonstrations). The first two authors contributed equally to this work ",
    "url": "https://arxiv.org/abs/2110.07317",
    "authors": [
      "Van-Anh Nguyen",
      "Dai Quoc Nguyen",
      "Van Nguyen",
      "Trung Le",
      "Quan Hung Tran",
      "Dinh Phung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2110.09022",
    "title": "Demystifying How Self-Supervised Features Improve Training from Noisy  Labels",
    "abstract": " Title: Demystifying How Self-Supervised Features Improve Training from Noisy  Labels ",
    "url": "https://arxiv.org/abs/2110.09022",
    "authors": [
      "Hao Cheng",
      "Zhaowei Zhu",
      "Xing Sun",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.10298",
    "title": "Incorporating Rich Social Interactions Into MDPs",
    "abstract": " Comments: Accepted to the 39th International Conference on Robotics and Automation (ICRA 2022) ",
    "url": "https://arxiv.org/abs/2110.10298",
    "authors": [
      "Ravi Tejwani",
      "Yen-Ling Kuo",
      "Tianmin Shu",
      "Bennett Stankovits",
      "Dan Gutfreund",
      "Joshua B. Tenenbaum",
      "Boris Katz",
      "Andrei Barbu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2110.10721",
    "title": "Learning quantum dynamics with latent neural ODEs",
    "abstract": " Comments: 11 Pages. 8 Figures. This is a resubmission. We added more results and plots for more quantitative analysis ",
    "url": "https://arxiv.org/abs/2110.10721",
    "authors": [
      "Matthew Choi",
      "Daniel Flam-Shepherd",
      "Thi Ha Kyaw",
      "Al\u00e1n Aspuru-Guzik"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.11198",
    "title": "Temporal Motifs in Patent Opposition and Collaboration Networks",
    "abstract": " Title: Temporal Motifs in Patent Opposition and Collaboration Networks ",
    "url": "https://arxiv.org/abs/2110.11198",
    "authors": [
      "Penghang Liu",
      "Naoki Masuda",
      "Tomomi Kito",
      "A. Erdem Sar\u0131y\u00fcce"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2110.13424",
    "title": "Precise URL Phishing Detection Using Neural Networks",
    "abstract": " Comments: 10 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2110.13424",
    "authors": [
      "Aman Rangapur",
      "Dr Ajith Jubilson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2110.14953",
    "title": "Multi-Task Neural Processes",
    "abstract": " Comments: 33 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2110.14953",
    "authors": [
      "Donggyun Kim",
      "Seongwoong Cho",
      "Wonkwang Lee",
      "Seunghoon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.00083",
    "title": "A Scalable AutoML Approach Based on Graph Neural Networks",
    "abstract": " Comments: 14 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2111.00083",
    "authors": [
      "Mossad Helali",
      "Essam Mansour",
      "Ibrahim Abdelaziz",
      "Julian Dolby",
      "Kavitha Srinivas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.06020",
    "title": "csBoundary: City-scale Road-boundary Detection in Aerial Images for  High-definition Maps",
    "abstract": " Comments: Accepted by IEEE Robotics and Automation Letters and IEEE International Conference on Robotics and Automation (ICRA) 2022 ",
    "url": "https://arxiv.org/abs/2111.06020",
    "authors": [
      "Zhenhua Xu",
      "Yuxuan Liu",
      "Lu Gan",
      "Xiangcheng Hu",
      "Yuxiang Sun",
      "Ming Liu",
      "Lujia Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2111.07016",
    "title": "Robust Multi-Robot Trajectory Optimization Using Alternating Direction  Method of Multiplier",
    "abstract": " Title: Robust Multi-Robot Trajectory Optimization Using Alternating Direction  Method of Multiplier ",
    "url": "https://arxiv.org/abs/2111.07016",
    "authors": [
      "Ruiqi Ni",
      "Zherong Pan",
      "Xifeng Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2111.07113",
    "title": "Novel Weight Update Scheme for Hardware Neural Network based on Synaptic  Devices Having Abrupt LTP or LTD Characteristics",
    "abstract": " Comments: 10 pages, 13 figures, 1 table ",
    "url": "https://arxiv.org/abs/2111.07113",
    "authors": [
      "Junmo Lee",
      "Joon Hwang",
      "Youngwoon Cho",
      "Sangbum Kim",
      "Jongho Lee"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2111.07865",
    "title": "Achievable Rates for Short-Reach Fiber-Optic Channels with Direct  Detection",
    "abstract": " Comments: Submitted to J. Lightw. Technol. on November 15, 2021; revised January 7, 2022; accepted January 22, 2022 ",
    "url": "https://arxiv.org/abs/2111.07865",
    "authors": [
      "Daniel Plabst",
      "Tobias Prinz",
      "Thomas Wiegart",
      "Talha Rahman",
      "Neboj\u0161a Stojanovi\u0107",
      "Stefano Calabr\u00f2",
      "Norbert Hanik",
      "Gerhard Kramer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2111.07958",
    "title": "Short-Term Power Prediction for Renewable Energy Using Hybrid Graph  Convolutional Network and Long Short-Term Memory Approach",
    "abstract": " Comments: This paper was accepted the 22nd Power Systems Computation Conference (PSCC 2022) ",
    "url": "https://arxiv.org/abs/2111.07958",
    "authors": [
      "Wenlong Liao",
      "Birgitte Bak-Jensen",
      "Jayakrishnan Radhakrishna Pillai",
      "Zhe Yang",
      "Kuangpu Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.08123",
    "title": "The Bubble Transform and the de Rham Complex",
    "abstract": " Comments: Some typos and other minor errors corrected and additional explanations included ",
    "url": "https://arxiv.org/abs/2111.08123",
    "authors": [
      "Richard S. Falk",
      "Ragnar Winther"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2111.11840",
    "title": "Local Permutation Equivariance For Graph Neural Networks",
    "abstract": " Comments: Permutation equivariant update function on sub-graphs ",
    "url": "https://arxiv.org/abs/2111.11840",
    "authors": [
      "Joshua Mitton",
      "Roderick Murray-Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.12950",
    "title": "Deep Representation Learning with an Information-theoretic Loss",
    "abstract": " Title: Deep Representation Learning with an Information-theoretic Loss ",
    "url": "https://arxiv.org/abs/2111.12950",
    "authors": [
      "Shin Ando"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.13164",
    "title": "L\u00e9vy Induced Stochastic Differential Equation Equipped with Neural  Network for Time Series Forecasting",
    "abstract": " Comments: 20 pages, 41 figures ",
    "url": "https://arxiv.org/abs/2111.13164",
    "authors": [
      "Luxuan Yang",
      "Ting Gao",
      "Yubin Lu",
      "Jinqiao Duan",
      "Tao Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Finance (q-fin.MF)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.02906",
    "title": "ALIKE: Accurate and Lightweight Keypoint Detection and Descriptor  Extraction",
    "abstract": " Comments: 11 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2112.02906",
    "authors": [
      "Xiaoming Zhao",
      "Xingming Wu",
      "Jinyu Miao",
      "Weihai Chen",
      "Peter C. Y. Chen",
      "Zhengguo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.03405",
    "title": "A Novel Deep Parallel Time-series Relation Network for Fault Diagnosis",
    "abstract": " Title: A Novel Deep Parallel Time-series Relation Network for Fault Diagnosis ",
    "url": "https://arxiv.org/abs/2112.03405",
    "authors": [
      "Chun Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.06096",
    "title": "Selecting Parallel In-domain Sentences for Neural Machine Translation  Using Monolingual Texts",
    "abstract": " Comments: Accepted to the CLIN Journal on Dec 6, 2021 (Camera-ready Version) ",
    "url": "https://arxiv.org/abs/2112.06096",
    "authors": [
      "Javad Pourmostafa Roshan Sharami",
      "Dimitar Shterionov",
      "Pieter Spronck"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.10885",
    "title": "PRONTO: Preamble Overhead Reduction with Neural Networks for Coarse  Synchronization",
    "abstract": " Title: PRONTO: Preamble Overhead Reduction with Neural Networks for Coarse  Synchronization ",
    "url": "https://arxiv.org/abs/2112.10885",
    "authors": [
      "Nasim Soltani",
      "Debashri Roy",
      "Kaushik Chowdhury"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2201.06126",
    "title": "Solving Inventory Management Problems with Inventory-dynamics-informed  Neural Networks",
    "abstract": " Comments: 34 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2201.06126",
    "authors": [
      "Lucas B\u00f6ttcher",
      "Thomas Asikis",
      "Ioannis Fragkos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2201.06652",
    "title": "Equitable Community Resilience: The Case of Winter Storm Uri in Texas",
    "abstract": " Title: Equitable Community Resilience: The Case of Winter Storm Uri in Texas ",
    "url": "https://arxiv.org/abs/2201.06652",
    "authors": [
      "Ali Nejat",
      "Laura Solitare",
      "Edward Pettitt",
      "Hamed Mohsenian-Rad"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2201.06854",
    "title": "Convergence of a robust deep FBSDE method for stochastic control",
    "abstract": " Comments: 26 pages, 4 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2201.06854",
    "authors": [
      "Kristoffer Andersson",
      "Adam Andersson",
      "Cornelis W. Oosterlee"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.10361",
    "title": "Reinforcement Learning-Based Deadline and Battery-Aware Offloading in  Smart Farm IoT-UAV Networks",
    "abstract": " Comments: Accepted Paper. Please check footnote in Page 1 for copyright ",
    "url": "https://arxiv.org/abs/2201.10361",
    "authors": [
      "Anne Catherine Nguyen",
      "Turgay Pamuklu",
      "Aisha Syed",
      "W. Sean Kennedy",
      "Melike Erol-Kantarci"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2201.10967",
    "title": "Physics-informed ConvNet: Learning Physical Field from a Shallow Neural  Network",
    "abstract": " Title: Physics-informed ConvNet: Learning Physical Field from a Shallow Neural  Network ",
    "url": "https://arxiv.org/abs/2201.10967",
    "authors": [
      "Pengpeng Shi",
      "Zhi Zeng",
      "Tianshou Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.11670",
    "title": "Strong Converse Theorem for Source Encryption under Side-Channel Attacks",
    "abstract": " Comments: 9 pages, 6 figures. The short version of this paper was submitted to ISIT2022, arXiv admin note: text overlap with arXiv:1801.02563 ",
    "url": "https://arxiv.org/abs/2201.11670",
    "authors": [
      "Yasutada Oohama",
      "Bagus Santoso"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.11711",
    "title": "Algorithm Selection for Software Verification using Graph Attention  Networks",
    "abstract": " Comments: 29 pages, 7 figures, 5 tables, submitted to ACM Transactions on Software Engineering and Methodology; Updated Symbiotic reference and description in Table 1 ",
    "url": "https://arxiv.org/abs/2201.11711",
    "authors": [
      "Will Leeson",
      "Matthew B Dwyer"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2201.11980",
    "title": "Differential Privacy Guarantees for Stochastic Gradient Langevin  Dynamics",
    "abstract": " Title: Differential Privacy Guarantees for Stochastic Gradient Langevin  Dynamics ",
    "url": "https://arxiv.org/abs/2201.11980",
    "authors": [
      "Th\u00e9o Ryffel",
      "Francis Bach",
      "David Pointcheval"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12240",
    "title": "Mixing Implicit and Explicit Deep Learning with Skip DEQs and Infinite  Time Neural ODEs (Continuous DEQs)",
    "abstract": " Title: Mixing Implicit and Explicit Deep Learning with Skip DEQs and Infinite  Time Neural ODEs (Continuous DEQs) ",
    "url": "https://arxiv.org/abs/2201.12240",
    "authors": [
      "Avik Pal",
      "Alan Edelman",
      "Christopher Rackauckas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2201.12898",
    "title": "Clearing Payments in Dynamic Financial Networks",
    "abstract": " Title: Clearing Payments in Dynamic Financial Networks ",
    "url": "https://arxiv.org/abs/2201.12898",
    "authors": [
      "Giuseppe C. Calafiore",
      "Giulia Fracastoro",
      "Anton V. Proskurnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Systems and Control (eess.SY)",
      "Mathematical Finance (q-fin.MF)",
      "Risk Management (q-fin.RM)"
    ]
  },
  {
    "id": "arXiv:2201.13001",
    "title": "Out-of-distribution Detection Using Kernel Density Polytopes",
    "abstract": " Title: Out-of-distribution Detection Using Kernel Density Polytopes ",
    "url": "https://arxiv.org/abs/2201.13001",
    "authors": [
      "Jayanta Dey",
      "Ashwin De Silva",
      "Will LeVine",
      "Jong M. Shin",
      "Haoyin Xu",
      "Ali Geisa",
      "Tiffany Chu",
      "Leyla Isik",
      "Joshua T. Vogelstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.13013",
    "title": "Filtering In Neural Implicit Functions",
    "abstract": " Comments: 8 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2201.13013",
    "authors": [
      "Yixin Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.13180",
    "title": "Learning on Arbitrary Graph Topologies via Predictive Coding",
    "abstract": " Comments: 15 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2201.13180",
    "authors": [
      "Tommaso Salvatori",
      "Luca Pinchetti",
      "Beren Millidge",
      "Yuhang Song",
      "Tianyi Bao",
      "Rafal Bogacz",
      "Thomas Lukasiewicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.13357",
    "title": "DNS: Determinantal Point Process Based Neural Network Sampler for  Ensemble Reinforcement Learning",
    "abstract": " Title: DNS: Determinantal Point Process Based Neural Network Sampler for  Ensemble Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2201.13357",
    "authors": [
      "Hassam Sheikh",
      "Kizza Frisbee",
      "Mariano Phielipp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.13392",
    "title": "MHSnet: Multi-head and Spatial Attention Network with False-Positive  Reduction for Pulmonary Nodules Detection",
    "abstract": " Title: MHSnet: Multi-head and Spatial Attention Network with False-Positive  Reduction for Pulmonary Nodules Detection ",
    "url": "https://arxiv.org/abs/2201.13392",
    "authors": [
      "Juanyun Mai",
      "Minghao Wang",
      "Jiayin Zheng",
      "Yanbo Shao",
      "Zhaoqi Diao",
      "Xinliang Fu",
      "Yulong Chen",
      "Jianyu Xiao",
      "Jian You",
      "Airu Yin",
      "Yang Yang",
      "Xiangcheng Qiu",
      "Jinsheng Tao",
      "Bo Wang",
      "Hua Ji"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.00964",
    "title": "Understanding Knowledge Integration in Language Models with Graph  Convolutions",
    "abstract": " Comments: Code is available: this https URL ",
    "url": "https://arxiv.org/abs/2202.00964",
    "authors": [
      "Yifan Hou",
      "Guoji Fu",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01059",
    "title": "PINNs and GaLS: An Priori Error Estimates for Shallow Physically  Informed Neural Network Applied to Elliptic Problems",
    "abstract": " Comments: This work has been submitted to IFAC for possible publication ",
    "url": "https://arxiv.org/abs/2202.01059",
    "authors": [
      "Umberto Zerbinati"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2202.01210",
    "title": "Deep Layer-wise Networks Have Closed-Form Weights",
    "abstract": " Comments: Since this version is similar to an older version, I should have updated the older version instead of creating a new version. I will now retract this version, and update a previous version to this ",
    "url": "https://arxiv.org/abs/2202.01210",
    "authors": [
      "Chieh Wu",
      "Aria Masoomi",
      "Arthur Gretton",
      "Jennifer Dy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2202.01841",
    "title": "Transport Score Climbing: Variational Inference Using Forward KL and  Adaptive Neural Transport",
    "abstract": " Comments: 14 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2202.01841",
    "authors": [
      "Liyi Zhang",
      "Christian A. Naesseth",
      "David M. Blei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2202.02006",
    "title": "5G Network on Wings: A Deep Reinforcement Learning Approach to UAV-based  Integrated Access and Backhaul",
    "abstract": " Title: 5G Network on Wings: A Deep Reinforcement Learning Approach to UAV-based  Integrated Access and Backhaul ",
    "url": "https://arxiv.org/abs/2202.02006",
    "authors": [
      "Hongyi Zhang",
      "Jingya Li",
      "Zhiqiang Qi",
      "Xingqin Lin",
      "Anders Aronsson",
      "Jan Bosch",
      "Helena Holmstr\u00f6m Olsson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]