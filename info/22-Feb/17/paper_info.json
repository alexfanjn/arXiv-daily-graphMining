[
  {
    "id": "arXiv:2202.07682",
    "title": "Better Together? An Evaluation of AI-Supported Code Translation",
    "abstract": "Generative machine learning models have recently been applied to source code, for use cases including translating code between programming languages, creating documentation from code, and auto-completing methods. Yet, state-of-the-art models often produce code that is erroneous or incomplete. In a controlled study with 32 software engineers, we examined whether such imperfect outputs are helpful in the context of Java-to-Python code translation. When aided by the outputs of a code translation model, participants produced code with fewer errors than when working alone. We also examined how the quality and quantity of AI translations affected the work process and quality of outcomes, and observed that providing multiple translations had a larger impact on the translation process than varying the quality of provided translations. Our results tell a complex, nuanced story about the benefits of generative code models and the challenges software engineers face when working with their outputs. Our work motivates the need for intelligent user interfaces that help software engineers effectively work with generative code models in order to understand and evaluate their outputs and achieve superior outcomes to working alone. ",
    "url": "https://arxiv.org/abs/2202.07682",
    "authors": [
      "Justin D. Weisz",
      "Michael Muller",
      "Steven I. Ross",
      "Fernando Martinez",
      "Stephanie Houde",
      "Mayank Agarwal",
      "Kartik Talamadupula",
      "John T. Richards"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2202.07704",
    "title": "Simulating Malicious Attacks on VANETs for Connected and Autonomous  Vehicle Cybersecurity: A Machine Learning Dataset",
    "abstract": "Connected and Autonomous Vehicles (CAVs) rely on Vehicular Adhoc Networks with wireless communication between vehicles and roadside infrastructure to support safe operation. However, cybersecurity attacks pose a threat to VANETs and the safe operation of CAVs. This study proposes the use of simulation for modelling typical communication scenarios which may be subject to malicious attacks. The Eclipse MOSAIC simulation framework is used to model two typical road scenarios, including messaging between the vehicles and infrastructure - and both replay and bogus information cybersecurity attacks are introduced. The model demonstrates the impact of these attacks, and provides an open dataset to inform the development of machine learning algorithms to provide anomaly detection and mitigation solutions for enhancing secure communications and safe deployment of CAVs on the road. ",
    "url": "https://arxiv.org/abs/2202.07704",
    "authors": [
      "Safras Iqbal",
      "Peter Ball",
      "Muhammad H Kamarudin",
      "Andrew Bradley"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07706",
    "title": "Misinformation Detection in Social Media Video Posts",
    "abstract": "With the growing adoption of short-form video by social media platforms, reducing the spread of misinformation through video posts has become a critical challenge for social media providers. In this paper, we develop methods to detect misinformation in social media posts, exploiting modalities such as video and text. Due to the lack of large-scale public data for misinformation detection in multi-modal datasets, we collect 160,000 video posts from Twitter, and leverage self-supervised learning to learn expressive representations of joint visual and textual data. In this work, we propose two new methods for detecting semantic inconsistencies within short-form social media video posts, based on contrastive learning and masked language modeling. We demonstrate that our new approaches outperform current state-of-the-art methods on both artificial data generated by random-swapping of positive samples and in the wild on a new manually-labeled test set for semantic misinformation. ",
    "url": "https://arxiv.org/abs/2202.07706",
    "authors": [
      "Kehan Wang",
      "David Chan",
      "Seth Z. Zhao",
      "John Canny",
      "Avideh Zakhor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07712",
    "title": "Privacy Preserving Visual Question Answering",
    "abstract": "We introduce a novel privacy-preserving methodology for performing Visual Question Answering on the edge. Our method constructs a symbolic representation of the visual scene, using a low-complexity computer vision model that jointly predicts classes, attributes and predicates. This symbolic representation is non-differentiable, which means it cannot be used to recover the original image, thereby keeping the original image private. Our proposed hybrid solution uses a vision model which is more than 25 times smaller than the current state-of-the-art (SOTA) vision models, and 100 times smaller than end-to-end SOTA VQA models. We report detailed error analysis and discuss the trade-offs of using a distilled vision model and a symbolic representation of the visual scene. ",
    "url": "https://arxiv.org/abs/2202.07712",
    "authors": [
      "Cristian-Paul Bara",
      "Qing Ping",
      "Abhinav Mathur",
      "Govind Thattai",
      "Rohith MV",
      "Gaurav S. Sukhatme"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07728",
    "title": "Don't Lie to Me! Robust and Efficient Explainability with Verified  Perturbation Analysis",
    "abstract": "A variety of methods have been proposed to try to explain how deep neural networks make their decisions. Key to those approaches is the need to sample the pixel space efficiently in order to derive importance maps. However, it has been shown that the sampling methods used to date introduce biases and other artifacts, leading to inaccurate estimates of the importance of individual pixels and severely limit the reliability of current explainability methods. Unfortunately, the alternative -- to exhaustively sample the image space is computationally prohibitive. In this paper, we introduce EVA (Explaining using Verified perturbation Analysis) -- the first explainability method guarantee to have an exhaustive exploration of a perturbation space. Specifically, we leverage the beneficial properties of verified perturbation analysis -- time efficiency, tractability and guaranteed complete coverage of a manifold -- to efficiently characterize the input variables that are most likely to drive the model decision. We evaluate the approach systematically and demonstrate state-of-the-art results on multiple benchmarks. ",
    "url": "https://arxiv.org/abs/2202.07728",
    "authors": [
      "Thomas Fel",
      "Melanie Ducoffe",
      "David Vigouroux",
      "Remi Cadene",
      "Mikael Capelle",
      "Claire Nicodeme",
      "Thomas Serre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07730",
    "title": "Rankings in the Zerkani network by a game theoretical approach",
    "abstract": "This paper introduces the Banzhaf and Banzhaf-Owen values as novel centrality measures for ranking terrorists in a network. This new approach let integrate the complete topology (i.e. nodes and edges) of the network and a coalitional structure on the nodes of the network. More precisely, the characteristics of the nodes (e.g., terrorists) of the network and their possible relationships (e.g., types of communication links), as well as coalitional information (e.g. level of hierarchies) independent of the network. First, for both centrality measures, we provide approximation algorithms and the corresponding R-codes. Second, as illustration, we rank the members of the Zerkani network, responsible for the attacks in Paris (2015) and Brussels (2016). Finally, we give a comparison between the rankings established by Banzhaf and Banzhaf-Owen and the rankings obtained when using the Shapley value (cf. Hamers et al., 2019) and the Owen value as centrality measures ",
    "url": "https://arxiv.org/abs/2202.07730",
    "authors": [
      "Encarnaci\u00f3n Algaba",
      "Andrea Prieto",
      "Alejandro Saavedra-Nieves"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2202.07757",
    "title": "Architecture Agnostic Federated Learning for Neural Networks",
    "abstract": "With growing concerns regarding data privacy and rapid increase in data volume, Federated Learning(FL) has become an important learning paradigm. However, jointly learning a deep neural network model in a FL setting proves to be a non-trivial task because of the complexities associated with the neural networks, such as varied architectures across clients, permutation invariance of the neurons, and presence of non-linear transformations in each layer. This work introduces a novel Federated Heterogeneous Neural Networks (FedHeNN) framework that allows each client to build a personalised model without enforcing a common architecture across clients. This allows each client to optimize with respect to local data and compute constraints, while still benefiting from the learnings of other (potentially more powerful) clients. The key idea of FedHeNN is to use the instance-level representations obtained from peer clients to guide the simultaneous training on each client. The extensive experimental results demonstrate that the FedHeNN framework is capable of learning better performing models on clients in both the settings of homogeneous and heterogeneous architectures across clients. ",
    "url": "https://arxiv.org/abs/2202.07757",
    "authors": [
      "Disha Makhija",
      "Xing Han",
      "Nhat Ho",
      "Joydeep Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07792",
    "title": "Efficient Content Delivery in Cache-Enabled VEN with  Deadline-Constrained Heterogeneous Demands: A User-Centric Approach",
    "abstract": "Modern connected vehicles (CVs) frequently require diverse types of content for mission-critical decision-making and onboard users' entertainment. These contents are required to be fully delivered to the requester CVs within stringent deadlines that the existing radio access technology (RAT) solutions may fail to ensure. Motivated by the above consideration, this paper exploits content caching with a software-defined user-centric virtual cell (VC) based RAT solution for delivering the requested contents from a proximity edge server. Moreover, to capture the heterogeneous demands of the CVs, we introduce a preference-popularity tradeoff in their content request model. To that end, we formulate a joint optimization problem for content placement, CV scheduling, VC configuration, VC-CV association and radio resource allocation to minimize long-term content delivery delay. However, the joint problem is highly complex and cannot be solved efficiently in polynomial time. As such, we decompose the original problem into a cache placement problem and a content delivery delay minimization problem given the cache placement policy. We use deep reinforcement learning (DRL) as a learning solution for the first sub-problem. Furthermore, we transform the delay minimization problem into a priority-based weighted sum rate (WSR) maximization problem, which is solved leveraging maximum bipartite matching (MWBM) and a simple linear search algorithm. Our extensive simulation results demonstrate the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2202.07792",
    "authors": [
      "Md Ferdous Pervej",
      "Richeng Jin",
      "Shih-Chun Lin",
      "Huaiyu Dai"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.07798",
    "title": "BB-ML: Basic Block Performance Prediction using Machine Learning  Techniques",
    "abstract": "Recent years have seen the adoption of Machine Learning (ML) techniques to predict the performance of large-scale applications, mostly at a coarse level. In contrast, we propose to use ML techniques for performance prediction at much finer granularity, namely at the levels of Basic Block (BB), which are the single entry-single exit code blocks that are used as analysis tools by all compilers to break down a large code into manageable pieces. Utilizing ML and BB analysis together can enable scalable hardware-software co-design beyond the current state of the art. In this work, we extrapolate the basic block execution counts of GPU applications for large inputs sizes from the counts of smaller input sizes of the same application. We employ two ML models, a Poisson Neural Network (PNN) and a Bayesian Regularization Backpropagation Neural Network (BR-BPNN). We train both models using the lowest input values of the application and random input values to predict basic block counts. Results show that our models accurately predict the basic block execution counts of 16 benchmark applications. For PNN and BR-BPNN models, we achieve an average accuracy of 93.5% and 95.6%, respectively, while extrapolating the basic block counts for large input sets when the model is trained using smaller input sets. Additionally, the models show an average accuracy of 97.7% and 98.1%, respectively, while predicting basic block counts on random instances. ",
    "url": "https://arxiv.org/abs/2202.07798",
    "authors": [
      "Shamminuj Aktar",
      "Hamdy Abdelkhalik",
      "Nazmul Haque Turja",
      "Yehia Arafa",
      "Atanu Barai",
      "Nishant Panda",
      "Gopinath Chennupati",
      "Nandakishore Santhi",
      "Abdel-Hameed Badawy",
      "Stephan Eidenbenz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2202.07802",
    "title": "Generative Adversarial Network-Driven Detection of Adversarial Tasks in  Mobile Crowdsensing",
    "abstract": "Mobile Crowdsensing systems are vulnerable to various attacks as they build on non-dedicated and ubiquitous properties. Machine learning (ML)-based approaches are widely investigated to build attack detection systems and ensure MCS systems security. However, adversaries that aim to clog the sensing front-end and MCS back-end leverage intelligent techniques, which are challenging for MCS platform and service providers to develop appropriate detection frameworks against these attacks. Generative Adversarial Networks (GANs) have been applied to generate synthetic samples, that are extremely similar to the real ones, deceiving classifiers such that the synthetic samples are indistinguishable from the originals. Previous works suggest that GAN-based attacks exhibit more crucial devastation than empirically designed attack samples, and result in low detection rate at the MCS platform. With this in mind, this paper aims to detect intelligently designed illegitimate sensing service requests by integrating a GAN-based model. To this end, we propose a two-level cascading classifier that combines the GAN discriminator with a binary classifier to prevent adversarial fake tasks. Through simulations, we compare our results to a single-level binary classifier, and the numeric results show that proposed approach raises Adversarial Attack Detection Rate (AADR), from $0\\%$ to $97.5\\%$ by KNN/NB, from $45.9\\%$ to $100\\%$ by Decision Tree. Meanwhile, with two-levels classifiers, Original Attack Detection Rate (OADR) improves for the three binary classifiers, with comparison, such as NB from $26.1\\%$ to $61.5\\%$. ",
    "url": "https://arxiv.org/abs/2202.07802",
    "authors": [
      "Zhiyan Chen",
      "Burak Kantarci"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07806",
    "title": "Code Generation for Unknown Libraries via Reading API Documentations",
    "abstract": "Open-domain code generation is a challenging problem because the set of functions and classes that we use are frequently changed and extended in programming communities. We consider the challenge of code generation for unknown libraries without additional training. In this paper, we explore a framework of code generation that can refer to relevant API documentations like human programmers to handle unknown libraries. As a first step of this direction, we implement a model that can extract relevant code signatures from API documentations based on a natural language intent and copy primitives from the extracted signatures. Moreover, to evaluate code generation for unknown libraries and our framework, we extend an existing dataset of open-domain code generation and resplit it so that the evaluation data consist of only examples using the libraries that do not appear in the training data. Experiments on our new split show that baseline encoder-decoder models cannot generate code using primitives of unknown libraries as expected. In contrast, our model outperforms the baseline on the new split and can properly generate unknown primitives when extracted code signatures are noiseless. ",
    "url": "https://arxiv.org/abs/2202.07806",
    "authors": [
      "Koki Washio",
      "Yusuke Miyao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.07815",
    "title": "Applying adversarial networks to increase the data efficiency and  reliability of Self-Driving Cars",
    "abstract": "Convolutional Neural Networks (CNNs) are vulnerable to misclassifying images when small perturbations are present. With the increasing prevalence of CNNs in self-driving cars, it is vital to ensure these algorithms are robust to prevent collisions from occurring due to failure in recognizing a situation. In the Adversarial Self-Driving framework, a Generative Adversarial Network (GAN) is implemented to generate realistic perturbations in an image that cause a classifier CNN to misclassify data. This perturbed data is then used to train the classifier CNN further. The Adversarial Self-driving framework is applied to an image classification algorithm to improve the classification accuracy on perturbed images and is later applied to train a self-driving car to drive in a simulation. A small-scale self-driving car is also built to drive around a track and classify signs. The Adversarial Self-driving framework produces perturbed images through learning a dataset, as a result removing the need to train on significant amounts of data. Experiments demonstrate that the Adversarial Self-driving framework identifies situations where CNNs are vulnerable to perturbations and generates new examples of these situations for the CNN to train on. The additional data generated by the Adversarial Self-driving framework provides sufficient data for the CNN to generalize to the environment. Therefore, it is a viable tool to increase the resilience of CNNs to perturbations. Particularly, in the real-world self-driving car, the application of the Adversarial Self-Driving framework resulted in an 18 % increase in accuracy, and the simulated self-driving model had no collisions in 30 minutes of driving. ",
    "url": "https://arxiv.org/abs/2202.07815",
    "authors": [
      "Aakash Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2202.07824",
    "title": "RNGDet: Road Network Graph Detection by Transformer in Aerial Images",
    "abstract": "Road network graphs provide critical information for autonomous vehicle applications, such as motion planning on drivable areas. However, manually annotating road network graphs is inefficient and labor-intensive. Automatically detecting road network graphs could alleviate this issue, but existing works are either segmentation-based approaches that could not ensure satisfactory topology correctness, or graph-based approaches that could not present precise enough detection results. To provide a solution to these problems, we propose a novel approach based on transformer and imitation learning named RNGDet (\\underline{R}oad \\underline{N}etwork \\underline{G}raph \\underline{Det}ection by Transformer) in this paper. In view of that high-resolution aerial images could be easily accessed all over the world nowadays, we make use of aerial images in our approach. Taken as input an aerial image, our approach iteratively generates road network graphs vertex-by-vertex. Our approach can handle complicated intersection points of various numbers of road segments. We evaluate our approach on a publicly available dataset. The superiority of our approach is demonstrated through the comparative experiments. ",
    "url": "https://arxiv.org/abs/2202.07824",
    "authors": [
      "Zhenhua Xu",
      "Yuxuan Liu",
      "Lu Gan",
      "Yuxiang Sun",
      "Ming Liu",
      "Lujia Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07826",
    "title": "CenGCN: Centralized Convolutional Networks with Vertex Imbalance for  Scale-Free Graphs",
    "abstract": "Graph Convolutional Networks (GCNs) have achieved impressive performance in a wide variety of areas, attracting considerable attention. The core step of GCNs is the information-passing framework that considers all information from neighbors to the central vertex to be equally important. Such equal importance, however, is inadequate for scale-free networks, where hub vertices propagate more dominant information due to vertex imbalance. In this paper, we propose a novel centrality-based framework named CenGCN to address the inequality of information. This framework first quantifies the similarity between hub vertices and their neighbors by label propagation with hub vertices. Based on this similarity and centrality indices, the framework transforms the graph by increasing or decreasing the weights of edges connecting hub vertices and adding self-connections to vertices. In each non-output layer of the GCN, this framework uses a hub attention mechanism to assign new weights to connected non-hub vertices based on their common information with hub vertices. We present two variants CenGCN\\_D and CenGCN\\_E, based on degree centrality and eigenvector centrality, respectively. We also conduct comprehensive experiments, including vertex classification, link prediction, vertex clustering, and network visualization. The results demonstrate that the two variants significantly outperform state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2202.07826",
    "authors": [
      "Feng Xia",
      "Lei Wang",
      "Tao Tang",
      "Xin Chen",
      "Xiangjie Kong",
      "Giles Oatley",
      "Irwin King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2202.07831",
    "title": "CycleGAN for Undamaged-to-Damaged Domain Translation for Structural  Health Monitoring and Damage Detection",
    "abstract": "The accelerated advancements in the data science field in the last few decades has benefitted many other fields including Structural Health Monitoring (SHM). Particularly, the employment of Artificial Intelligence (AI) such as Machine Learning (ML) and Deep Learning (DL) methods towards vibration-based damage diagnostics of civil structures have seen a great interest due to their nature of supreme performance in learning from data. Along with diagnostics, damage prognostics also hold a vital prominence, such as estimating the remaining useful life of civil structures. Currently used AI-based data-driven methods for damage diagnostics and prognostics are centered on historical data of the structures and require a substantial amount of data to directly form the prediction models. Although some of these methods are generative-based models, after learning the distribution of the data, they are used to perform ML or DL tasks such as classification, regression, clustering, etc. In this study, a variant of Generative Adversarial Networks (GAN), Cycle-Consistent Wasserstein Deep Convolutional GAN with Gradient Penalty (CycleWDCGAN-GP) model is used to answer some of the most important questions in SHM: \"How does the dynamic signature of a structure transition from undamaged to damaged conditions?\" and \"What is the nature of such transition?\". The outcomes of this study demonstrate that the proposed model can accurately generate the possible future responses of a structure for potential future damaged conditions. In other words, with the proposed methodology, the stakeholders will be able to understand the damaged condition of structures while the structures are still in healthy (undamaged) conditions. This tool will enable them to be more proactive in overseeing the life cycle performance of structures as well as assist in remaining useful life predictions. ",
    "url": "https://arxiv.org/abs/2202.07831",
    "authors": [
      "Furkan Luleci",
      "F. Necati Catbas",
      "Onur Avci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.07832",
    "title": "Heterogeneous Graph Learning for Explainable Recommendation over  Academic Networks",
    "abstract": "With the explosive growth of new graduates with research degrees every year, unprecedented challenges arise for early-career researchers to find a job at a suitable institution. This study aims to understand the behavior of academic job transition and hence recommend suitable institutions for PhD graduates. Specifically, we design a deep learning model to predict the career move of early-career researchers and provide suggestions. The design is built on top of scholarly/academic networks, which contains abundant information about scientific collaboration among scholars and institutions. We construct a heterogeneous scholarly network to facilitate the exploring of the behavior of career moves and the recommendation of institutions for scholars. We devise an unsupervised learning model called HAI (Heterogeneous graph Attention InfoMax) which aggregates attention mechanism and mutual information for institution recommendation. Moreover, we propose scholar attention and meta-path attention to discover the hidden relationships between several meta-paths. With these mechanisms, HAI provides ordered recommendations with explainability. We evaluate HAI upon a real-world dataset against baseline methods. Experimental results verify the effectiveness and efficiency of our approach. ",
    "url": "https://arxiv.org/abs/2202.07832",
    "authors": [
      "Xiangtai Chen",
      "Tao Tang",
      "Jing Ren",
      "Ivan Lee",
      "Honglong Chen",
      "Feng Xia"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07835",
    "title": "Privacy-Preserving Graph Neural Network Training and Inference as a  Cloud Service",
    "abstract": "Graphs are widely used to model the complex relationships among entities. As a powerful tool for graph analytics, graph neural networks (GNNs) have recently gained wide attention due to its end-to-end processing capabilities. With the proliferation of cloud computing, it is increasingly popular to deploy the services of complex and resource-intensive model training and inference in the cloud due to its prominent benefits. However, GNN training and inference services, if deployed in the cloud, will raise critical privacy concerns about the information-rich and proprietary graph data (and the resulting model). While there has been some work on secure neural network training and inference, they all focus on convolutional neural networks handling images and text rather than complex graph data with rich structural information. In this paper, we design, implement, and evaluate SecGNN, the first system supporting privacy-preserving GNN training and inference services in the cloud. SecGNN is built from a synergy of insights on lightweight cryptography and machine learning techniques. We deeply examine the procedure of GNN training and inference, and devise a series of corresponding secure customized protocols to support the holistic computation. Extensive experiments demonstrate that SecGNN achieves comparable plaintext training and inference accuracy, with practically affordable performance. ",
    "url": "https://arxiv.org/abs/2202.07835",
    "authors": [
      "Songlei Wang",
      "Yifeng Zheng",
      "Xiaohua Jia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07837",
    "title": "Application of Long Short-Term Memory Recurrent Neural Networks Based on  the BAT-MCS for Binary-State Network Approximated Time-Dependent Reliability  Problems",
    "abstract": "Reliability is an important tool for evaluating the performance of modern networks. Currently, it is NP-hard and #P-hard to calculate the exact reliability of a binary-state network when the reliability of each component is assumed to be fixed. However, this assumption is unrealistic because the reliability of each component always varies with time. To meet this practical requirement, we propose a new algorithm called the LSTM-BAT-MCS, based on long short-term memory (LSTM), the Monte Carlo simulation (MCS), and the binary-adaption-tree algorithm (BAT). The superiority of the proposed LSTM-BAT-MCS was demonstrated by experimental results of three benchmark networks with at most 10-4 mean square error. ",
    "url": "https://arxiv.org/abs/2202.07837",
    "authors": [
      "Wei-Chang Yeh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07845",
    "title": "Near-optimal Top-k Pattern Mining",
    "abstract": "Nowadays, frequent pattern mining (FPM) on large graphs receives increasing attention, since it is crucial to a variety of applications, e.g., social analysis. Informally, the FPM problem is defined as finding all the patterns in a large graph with frequency above a user-defined threshold. However, this problem is nontrivial due to the unaffordable computational and space costs in the mining process. In light of this, we propose a cost-effective approach to mining near-optimal top-k patterns. Our approach applies a \"level-wise\" strategy to incrementally detect frequent patterns, hence is able to terminate as soon as top-k patterns are discovered. Moreover, we develop a technique to compute the lower bound of support with smart traverse strategy and compact data structures. Extensive experimental studies on real-life and synthetic graphs show that our approach performs well, i.e., it outperforms traditional counterparts in efficiency, memory footprint, recall and scalability. ",
    "url": "https://arxiv.org/abs/2202.07845",
    "authors": [
      "Xin Wang",
      "Zhuo Lan",
      "Yu-Ang He",
      "Yang Wang",
      "Zhi-Gui Liu",
      "Wen-Bo Xie"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2202.07857",
    "title": "Graph-Augmented Normalizing Flows for Anomaly Detection of Multiple Time  Series",
    "abstract": "Anomaly detection is a widely studied task for a broad variety of data types; among them, multiple time series appear frequently in applications, including for example, power grids and traffic networks. Detecting anomalies for multiple time series, however, is a challenging subject, owing to the intricate interdependencies among the constituent series. We hypothesize that anomalies occur in low density regions of a distribution and explore the use of normalizing flows for unsupervised anomaly detection, because of their superior quality in density estimation. Moreover, we propose a novel flow model by imposing a Bayesian network among constituent series. A Bayesian network is a directed acyclic graph (DAG) that models causal relationships; it factorizes the joint probability of the series into the product of easy-to-evaluate conditional probabilities. We call such a graph-augmented normalizing flow approach GANF and propose joint estimation of the DAG with flow parameters. We conduct extensive experiments on real-world datasets and demonstrate the effectiveness of GANF for density estimation, anomaly detection, and identification of time series distribution drift. ",
    "url": "https://arxiv.org/abs/2202.07857",
    "authors": [
      "Enyan Dai",
      "Jie Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.07861",
    "title": "Practical Network Acceleration with Tiny Sets",
    "abstract": "Network compression is effective in accelerating the inference of deep neural networks, but often requires finetuning with all the training data to recover from the accuracy loss. It is impractical in some applications, however, due to data privacy issues or constraints in compression time budget. To deal with the above issues, we propose a method named PRACTISE to accelerate the network with tiny sets of training images. By considering both the pruned part and the unpruned part of a compressed model, PRACTISE alleviates layer-wise error accumulation, which is the main drawback of previous methods. Furthermore, existing methods are confined to few compression schemes, have limited speedup in terms of latency, and are unstable. In contrast, PRACTISE is stable, fast to train, versatile to handle various compression schemes, and achieves low latency. We also propose that dropping entire blocks is a better way than existing compression schemes when only tiny sets of training data are available. Extensive experiments demonstrate that PRACTISE achieves much higher accuracy and more stable models than state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2202.07861",
    "authors": [
      "Guo-Hua Wang",
      "Jianxin Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.07872",
    "title": "An efficient distributed scheduling algorithm for relay-assisted mmWave  backhaul networks",
    "abstract": "In this paper, a novel distributed scheduling algorithm is proposed, which aims to efficiently schedule both the uplink and downlink backhaul traffic in the relay-assisted mmWave backhaul network with a tree topology. The handshaking of control messages, calculation of local schedules, and the determination of final valid schedule are all discussed. Simulation results show that the performance of the distributed algorithm can reach very close to the maximum traffic demand of the backhaul network, and it can also adapt to the dynamic traffic with sharp traffic demand change of small-cell BSs quickly and accurately. ",
    "url": "https://arxiv.org/abs/2202.07872",
    "authors": [
      "Qiang Hu",
      "Yuchen Liu",
      "Yan Yan",
      "Miao Liu",
      "Jun Zheng",
      "Douglas M. Blough"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.07883",
    "title": "CGraph: Graph Based Extensible Predictive Domain Threat Intelligence  Platform",
    "abstract": "Ability to effectively investigate indicators of compromise and associated network resources involved in cyber attacks is paramount not only to identify affected network resources but also to detect related malicious resources. Today, most of the cyber threat intelligence platforms are reactive in that they can identify attack resources only after the attack is carried out. Further, these systems have limited functionality to investigate associated network resources. In this work, we propose an extensible predictive cyber threat intelligence platform called cGraph that addresses the above limitations. cGraph is built as a graph-first system where investigators can explore network resources utilizing a graph based API. Further, cGraph provides real-time predictive capabilities based on state-of-the-art inference algorithms to predict malicious domains from network graphs with a few known malicious and benign seeds. To the best of our knowledge, cGraph is the only threat intelligence platform to do so. cGraph is extensible in that additional network resources can be added to the system transparently. ",
    "url": "https://arxiv.org/abs/2202.07883",
    "authors": [
      "Wathsara Daluwatta",
      "Ravindu De Silva",
      "Sanduni Kariyawasam",
      "Mohamed Nabeel",
      "Charith Elvitigala",
      "Kasun De Zoysa",
      "Chamath Keppitiyagama"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.07901",
    "title": "Cross-Modal Common Representation Learning with Triplet Loss Functions",
    "abstract": "Common representation learning (CRL) learns a shared embedding between two or more modalities to improve in a given task over using only one of the modalities. CRL from different data types such as images and time-series data (e.g., audio or text data) requires a deep metric learning loss that minimizes the distance between the modality embeddings. In this paper, we propose to use the triplet loss, which uses positive and negative identities to create sample pairs with different labels, for CRL between image and time-series modalities. By adapting the triplet loss for CRL, higher accuracy in the main (time-series classification) task can be achieved by exploiting additional information of the auxiliary (image classification) task. Our experiments on synthetic data and handwriting recognition data from sensor-enhanced pens show an improved classification accuracy, faster convergence, and a better generalizability. ",
    "url": "https://arxiv.org/abs/2202.07901",
    "authors": [
      "Felix Ott",
      "David R\u00fcgamer",
      "Lucas Heublein",
      "Bernd Bischl",
      "Christopher Mutschler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07902",
    "title": "When Does A Spectral Graph Neural Network Fail in Node Classification?",
    "abstract": "Spectral Graph Neural Networks (GNNs) with various graph filters have received extensive affirmation due to their promising performance in graph learning problems. However, it is known that GNNs do not always perform well. Although graph filters provide theoretical foundations for model explanations, it is unclear when a spectral GNN will fail. In this paper, focusing on node classification problems, we conduct a theoretical analysis of spectral GNNs performance by investigating their prediction error. With the aid of graph indicators including homophily degree and response efficiency we proposed, we establish a comprehensive understanding of complex relationships between graph structure, node labels, and graph filters. We indicate that graph filters with low response efficiency on label difference are prone to fail. To enhance GNNs performance, we provide a provably better strategy for filter design from our theoretical analysis - using data-driven filter banks, and propose simple models for empirical validation. Experimental results show consistency with our theoretical results and support our strategy. ",
    "url": "https://arxiv.org/abs/2202.07902",
    "authors": [
      "Zhixian Chen",
      "Tengfei Ma",
      "Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07919",
    "title": "HousE: Knowledge Graph Embedding with Householder Parameterization",
    "abstract": "The effectiveness of knowledge graph embedding (KGE) largely depends on the ability to model intrinsic relation patterns and mapping properties. However, existing approaches can only capture some of them with insufficient modeling capacity. In this work, we propose a more powerful KGE framework named HousE, which involves a novel parameterization based on two kinds of Householder transformations: (1) Householder rotations to achieve superior capacity of modeling relation patterns; (2) Householder projections to handle sophisticated relation mapping properties. Theoretically, HousE is capable of modeling crucial relation patterns and mapping properties simultaneously. Besides, HousE is a generalization of existing rotation-based models while extending the rotations to high-dimensional spaces. Empirically, HousE achieves new state-of-the-art performance on five benchmark datasets. Our code is available at https://github.com/anrep/HousE. ",
    "url": "https://arxiv.org/abs/2202.07919",
    "authors": [
      "Rui Li",
      "Jianan Zhao",
      "Chaozhuo Li",
      "Di He",
      "Yiqi Wang",
      "Yuming Liu",
      "Hao Sun",
      "Senzhang Wang",
      "Weiwei Deng",
      "Yanming Shen",
      "Xing Xie",
      "Qi Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.07946",
    "title": "Turn Tree into Graph: Automatic Code Review via Simplified AST Driven  Graph Convolutional Network",
    "abstract": "Automatic code review (ACR), which can relieve the costs of manual inspection, is an indispensable and essential task in software engineering. To deal with ACR, existing work is to serialize the abstract syntax tree (AST). However, making sense of the whole AST with sequence encoding approach is a daunting task, mostly due to some redundant nodes in AST hinder the transmission of node information. Not to mention that the serialized representation is inadequate to grasp the information of tree structure in AST. In this paper, we first present a new large-scale Apache Automatic Code Review (AACR) dataset for ACR task since there is still no publicly available dataset in this task. The release of this dataset would push forward the research in this field. Based on it, we propose a novel Simplified AST based Graph Convolutional Network (SimAST-GCN) to deal with ACR task. Concretely, to improve the efficiency of node information dissemination, we first simplify the AST of code by deleting the redundant nodes that do not contain connection attributes, and thus deriving a Simplified AST. Then, we construct a relation graph for each code based on the Simplified AST to properly embody the relations among code fragments of the tree structure into the graph. Subsequently, in the light of the merit of graph structure, we explore a graph convolution networks architecture that follows an attention mechanism to leverage the crucial implications of code fragments to derive code representations. Finally, we exploit a simple but effective subtraction operation in the representations between the original and revised code, enabling the revised difference to be preferably learned for deciding the results of ACR. Experimental results on the AACR dataset illustrate that our proposed model outperforms the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2202.07946",
    "authors": [
      "B. Wu",
      "B. Liang",
      "X. Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2202.07954",
    "title": "Unified smoke and fire detection in an evolutionary framework with  self-supervised progressive data augment",
    "abstract": "Few researches have studied simultaneous detection of smoke and flame accompanying fires due to their different physical natures that lead to uncertain fluid patterns. In this study, we collect a large image data set to re-label them as a multi-label image classification problem so as to identify smoke and flame simultaneously. In order to solve the generalization ability of the detection model on account of the movable fluid objects with uncertain shapes like fire and smoke, and their not compactible natures as well as the complex backgrounds with high variations, we propose a data augment method by random image stitch to deploy resizing, deforming, position variation, and background altering so as to enlarge the view of the learner. Moreover, we propose a self-learning data augment method by using the class activation map to extract the highly trustable region as new data source of positive examples to further enhance the data augment. By the mutual reinforcement between the data augment and the detection model that are performed iteratively, both modules make progress in an evolutionary manner. Experiments show that the proposed method can effectively improve the generalization performance of the model for concurrent smoke and fire detection. ",
    "url": "https://arxiv.org/abs/2202.07954",
    "authors": [
      "Hang Zhang",
      "Su Yang",
      "Hongyong Wang",
      "zhongyan lu",
      "helin sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07991",
    "title": "ADIMA: Abuse Detection In Multilingual Audio",
    "abstract": "Abusive content detection in spoken text can be addressed by performing Automatic Speech Recognition (ASR) and leveraging advancements in natural language processing. However, ASR models introduce latency and often perform sub-optimally for profane words as they are underrepresented in training corpora and not spoken clearly or completely. Exploration of this problem entirely in the audio domain has largely been limited by the lack of audio datasets. Building on these challenges, we propose ADIMA, a novel, linguistically diverse, ethically sourced, expert annotated and well-balanced multilingual profanity detection audio dataset comprising of 11,775 audio samples in 10 Indic languages spanning 65 hours and spoken by 6,446 unique users. Through quantitative experiments across monolingual and cross-lingual zero-shot settings, we take the first step in democratizing audio based content moderation in Indic languages and set forth our dataset to pave future work. ",
    "url": "https://arxiv.org/abs/2202.07991",
    "authors": [
      "Vikram Gupta",
      "Rini Sharon",
      "Ramit Sawhney",
      "Debdoot Mukherjee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2202.07993",
    "title": "Planckian jitter: enhancing the color quality of self-supervised visual  representations",
    "abstract": "Several recent works on self-supervised learning are trained by mapping different augmentations of the same image to the same feature representation. The set of used data augmentations is of crucial importance for the quality of the learned feature representation. We analyze how the traditionally used color jitter negatively impacts the quality of the color features in the learned feature representation. To address this problem, we replace this module with physics-based color augmentation, called Planckian jitter, which creates realistic variations in chromaticity, producing a model robust to llumination changes that can be commonly observed in real life, while maintaining the ability to discriminate the image content based on color information. We further improve the performance by introducing a latent space combination of color-sensitive and non-color-sensitive features. These are found to be complementary and the combination leads to large absolute performance gains over the default data augmentation on color classification tasks, including on Flowers-102 (+15%), Cub200 (+11%), VegFru (+15%), and T1K+ (+12%). Finally, we present a color sensitivity analysis to document the impact of different training methods on the model neurons and we show that the performance of the learned features is robust with respect to illuminant variations. ",
    "url": "https://arxiv.org/abs/2202.07993",
    "authors": [
      "Simone Zini",
      "Marco Buzzelli",
      "Bart\u0142omiej Twardowski",
      "Joost van de Weijer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.08006",
    "title": "Recoloring Unit Interval Graphs with Logarithmic Recourse Budget",
    "abstract": "In this paper we study the problem of coloring a unit interval graph which changes dynamically. In our model the unit intervals are added or removed one at the time, and have to be colored immediately, so that no two overlapping intervals share the same color. After each update only a limited number of intervals is allowed to be recolored. The limit on the number of recolorings per update is called the recourse budget. In this paper we show, that if the graph remains $k$-colorable at all times, and the updates consist of insertions only, then we can achieve the amortized recourse budget of $O(k^7 \\log n)$ while maintaining a proper coloring with $k$ colors. This is an exponential improvement over the result in [Bosek et al., Recoloring Interval Graphs with Limited Recourse Budget. SWAT 2020] in terms of both $k$ and $n$. We complement this result by showing the lower bound of $\\Omega(n)$ on the amortized recourse budget in the fully dynamic setting. Our incremental algorithm can be efficiently implemented. As a byproduct of independent interest we include a new result on coloring proper circular arc graphs. Let $L$ be the maximum number of arcs intersecting in one point for some set of unit circular arcs $\\mathcal{A}$. We show that if there is a set $\\mathcal{A}'$ of non-intersecting unit arcs of size $L^2-1$ such that $\\mathcal{A} \\cup \\mathcal{A}'$ does not contain $L+1$ arcs intersecting in one point, then it is possible to color $\\mathcal{A}$ with $L$ colors. This complements the work on unit circular arc coloring, which specifies sufficient conditions needed to color $\\mathcal{A}$ with $L+1$ colors or more. ",
    "url": "https://arxiv.org/abs/2202.08006",
    "authors": [
      "Bart\u0142omiej Bosek",
      "Anna Zych-Pawlewicz"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2202.08008",
    "title": "Near-Shortest Path Routing in Hybrid Communication Networks",
    "abstract": "Hybrid networks, i.e., networks that leverage different means of communication, become ever more widespread. To allow theoretical study of such networks, [Augustine et al., SODA'20] introduced the $\\mathsf{HYBRID}$ model, which is based on the concept of synchronous message passing and uses two fundamentally different principles of communication: a local mode, which allows every node to exchange one message per round with each neighbor in a local communication graph; and a global mode where any pair of nodes can exchange messages, but only few such exchanges can take place per round. A sizable portion of the previous research for the $\\mathsf{HYBRID}$ model revolves around basic communication primitives and computing distances or shortest paths in networks. In this paper, we extend this study to a related fundamental problem of computing compact routing schemes for near-shortest paths in the local communication graph. We demonstrate that, for the case where the local communication graph is a unit-disc graph with $n$ nodes that is realized in the plane and has no radio holes, we can deterministically compute a routing scheme that has constant stretch and uses labels and local routing tables of size $O(\\log n)$ bits in only $O(\\log n)$ rounds. ",
    "url": "https://arxiv.org/abs/2202.08008",
    "authors": [
      "Sam Coy",
      "Artur Czumaj",
      "Michael Feldmann",
      "Kristian Hinnenthal",
      "Fabian Kuhn",
      "Christian Scheideler",
      "Philipp Schneider",
      "Martijn Struijs"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2202.08010",
    "title": "360 Depth Estimation in the Wild -- The Depth360 Dataset and the SegFuse  Network",
    "abstract": "Single-view depth estimation from omnidirectional images has gained popularity with its wide range of applications such as autonomous driving and scene reconstruction. Although data-driven learning-based methods demonstrate significant potential in this field, scarce training data and ineffective 360 estimation algorithms are still two key limitations hindering accurate estimation across diverse domains. In this work, we first establish a large-scale dataset with varied settings called Depth360 to tackle the training data problem. This is achieved by exploring the use of a plenteous source of data, 360 videos from the internet, using a test-time training method that leverages unique information in each omnidirectional sequence. With novel geometric and temporal constraints, our method generates consistent and convincing depth samples to facilitate single-view estimation. We then propose an end-to-end two-branch multi-task learning network, SegFuse, that mimics the human eye to effectively learn from the dataset and estimate high-quality depth maps from diverse monocular RGB images. With a peripheral branch that uses equirectangular projection for depth estimation and a foveal branch that uses cubemap projection for semantic segmentation, our method predicts consistent global depth while maintaining sharp details at local regions. Experimental results show favorable performance against the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2202.08010",
    "authors": [
      "Qi Feng",
      "Hubert P. H. Shum",
      "Shigeo Morishima"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.08011",
    "title": "Towards Identifying Social Bias in Dialog Systems: Frame, Datasets, and  Benchmarks",
    "abstract": "The research of open-domain dialog systems has been greatly prospered by neural models trained on large-scale corpora, however, such corpora often introduce various safety problems (e.g., offensive languages, biases, and toxic behaviors) that significantly hinder the deployment of dialog systems in practice. Among all these unsafe issues, addressing social bias is more complex as its negative impact on marginalized populations is usually expressed implicitly, thus requiring normative reasoning and rigorous analysis. In this paper, we focus our investigation on social bias detection of dialog safety problems. We first propose a novel Dial-Bias Frame for analyzing the social bias in conversations pragmatically, which considers more comprehensive bias-related analyses rather than simple dichotomy annotations. Based on the proposed framework, we further introduce CDail-Bias Dataset that, to our knowledge, is the first well-annotated Chinese social bias dialog dataset. In addition, we establish several dialog bias detection benchmarks at different label granularities and input types (utterance-level and context-level). We show that the proposed in-depth analyses together with these benchmarks in our Dial-Bias Frame are necessary and essential to bias detection tasks and can benefit building safe dialog systems in practice. ",
    "url": "https://arxiv.org/abs/2202.08011",
    "authors": [
      "Jingyan Zhou",
      "Jiawen Deng",
      "Fei Mi",
      "Yitong Li",
      "Yasheng Wang",
      "Minlie Huang",
      "Xin Jiang",
      "Qun Liu",
      "Helen Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.08029",
    "title": "Code Search based on Context-aware Code Translation",
    "abstract": "Code search is a widely used technique by developers during software development. It provides semantically similar implementations from a large code corpus to developers based on their queries. Existing techniques leverage deep learning models to construct embedding representations for code snippets and queries, respectively. Features such as abstract syntactic trees, control flow graphs, etc., are commonly employed for representing the semantics of code snippets. However, the same structure of these features does not necessarily denote the same semantics of code snippets, and vice versa. In addition, these techniques utilize multiple different word mapping functions that map query words/code tokens to embedding representations. This causes diverged embeddings of the same word/token in queries and code snippets. We propose a novel context-aware code translation technique that translates code snippets into natural language descriptions (called translations). The code translation is conducted on machine instructions, where the context information is collected by simulating the execution of instructions. We further design a shared word mapping function using one single vocabulary for generating embeddings for both translations and queries. We evaluate the effectiveness of our technique, called TranCS, on the CodeSearchNet corpus with 1,000 queries. Experimental results show that TranCS significantly outperforms state-of-the-art techniques by 49.31% to 66.50% in terms of MRR (mean reciprocal rank). ",
    "url": "https://arxiv.org/abs/2202.08029",
    "authors": [
      "Weisong Sun",
      "Chunrong Fang",
      "Yuchen Chen",
      "Guanhong Tao",
      "Tingxu Han",
      "Quanjun Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.08036",
    "title": "No One Left Behind: Inclusive Federated Learning over Heterogeneous  Devices",
    "abstract": "Federated learning (FL) is an important paradigm for training global models from decentralized data in a privacy-preserving way. Existing FL methods usually assume the global model can be trained on any participating client. However, in real applications, the devices of clients are usually heterogeneous, and have different computing power. Although big models like BERT have achieved huge success in AI, it is difficult to apply them to heterogeneous FL with weak clients. The straightforward solutions like removing the weak clients or using a small model to fit all clients will lead to some problems, such as under-representation of dropped clients and inferior accuracy due to data loss or limited model representation ability. In this work, we propose InclusiveFL, a client-inclusive federated learning method to handle this problem. The core idea of InclusiveFL is to assign models of different sizes to clients with different computing capabilities, bigger models for powerful clients and smaller ones for weak clients. We also propose an effective method to share the knowledge among multiple local models with different sizes. In this way, all the clients can participate in the model learning in FL, and the final model can be big and powerful enough. Besides, we propose a momentum knowledge distillation method to better transfer knowledge in big models on powerful clients to the small models on weak clients. Extensive experiments on many real-world benchmark datasets demonstrate the effectiveness of the proposed method in learning accurate models from clients with heterogeneous devices under the FL framework. ",
    "url": "https://arxiv.org/abs/2202.08036",
    "authors": [
      "Ruixuan Liu",
      "Fangzhao Wu",
      "Chuhan Wu",
      "Yanlin Wang",
      "Lingjuan Lyu",
      "Hong Chen",
      "Xing Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2202.08057",
    "title": "Understanding and Improving Graph Injection Attack by Promoting  Unnoticeability",
    "abstract": "Recently Graph Injection Attack (GIA) emerges as a practical attack scenario on Graph Neural Networks (GNNs), where the adversary can merely inject few malicious nodes instead of modifying existing nodes or edges, i.e., Graph Modification Attack (GMA). Although GIA has achieved promising results, little is known about why it is successful and whether there is any pitfall behind the success. To understand the power of GIA, we compare it with GMA and find that GIA can be provably more harmful than GMA due to its relatively high flexibility. However, the high flexibility will also lead to great damage to the homophily distribution of the original graph, i.e., similarity among neighbors. Consequently, the threats of GIA can be easily alleviated or even prevented by homophily-based defenses designed to recover the original homophily. To mitigate the issue, we introduce a novel constraint -- homophily unnoticeability that enforces GIA to preserve the homophily, and propose Harmonious Adversarial Objective (HAO) to instantiate it. Extensive experiments verify that GIA with HAO can break homophily-based defenses and outperform previous GIA attacks by a significant margin. We believe our methods can serve for a more reliable evaluation of the robustness of GNNs. ",
    "url": "https://arxiv.org/abs/2202.08057",
    "authors": [
      "Yongqiang Chen",
      "Han Yang",
      "Yonggang Zhang",
      "Kaili Ma",
      "Tongliang Liu",
      "Bo Han",
      "James Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.08065",
    "title": "Graph Neural Network and Koopman Models for Learning Networked Dynamics:  A Comparative Study on Power Grid Transients Prediction",
    "abstract": "Continuous monitoring of the spatio-temporal dynamic behavior of critical infrastructure networks, such as the power systems, is a challenging but important task. In particular, accurate and timely prediction of the (electro-mechanical) transient dynamic trajectories of the power grid is necessary for early detection of any instability and prevention of catastrophic failures. Existing approaches for the prediction of dynamic trajectories either rely on the availability of accurate physical models of the system, use computationally expensive time-domain simulations, or are applicable only at local prediction problems (e.g., a single generator). In this paper, we report the application of two broad classes of data-driven learning models -- along with their algorithmic implementation and performance evaluation -- in predicting transient trajectories in power networks using only streaming measurements and the network topology as input. One class of models is based on the Koopman operator theory which allows for capturing the nonlinear dynamic behavior via an infinite-dimensional linear operator. The other class of models is based on the graph convolutional neural networks which are adept at capturing the inherent spatio-temporal correlations within the power network. Transient dynamic datasets for training and testing the models are synthesized by simulating a wide variety of load change events in the IEEE 68-bus system, categorized by the load change magnitudes, as well as by the degree of connectivity and the distance to nearest generator nodes. The results confirm that the proposed predictive models can successfully predict the post-disturbance transient evolution of the system with a high level of accuracy. ",
    "url": "https://arxiv.org/abs/2202.08065",
    "authors": [
      "Sai Pushpak Nandanoori",
      "Sheng Guan",
      "Soumya Kundu",
      "Seemita Pal",
      "Khushbu Agarwal",
      "Yinghui Wu",
      "Sutanay Choudhury"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2202.08070",
    "title": "On Measuring Excess Capacity in Neural Networks",
    "abstract": "We study the excess capacity of deep networks in the context of supervised classification. That is, given a capacity measure of the underlying hypothesis class -- in our case, Rademacher complexity -- how much can we (a-priori) constrain this class while maintaining an empirical error comparable to the unconstrained setting. To assess excess capacity in modern architectures, we first extend an existing generalization bound to accommodate function composition and addition, as well as the specific structure of convolutions. This then facilitates studying residual networks through the lens of the accompanying capacity measure. The key quantities driving this measure are the Lipschitz constants of the layers and the (2,1) group norm distance to the initializations of the convolution weights. We show that these quantities (1) can be kept surprisingly small and, (2) since excess capacity unexpectedly increases with task difficulty, this points towards an unnecessarily large capacity of unconstrained models. ",
    "url": "https://arxiv.org/abs/2202.08070",
    "authors": [
      "Florian Graf",
      "Sebastian Zeng",
      "Marc Niethammer",
      "Roland Kwitt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.08087",
    "title": "Extended Unconstrained Features Model for Exploring Deep Neural Collapse",
    "abstract": "The modern strategy for training deep neural networks for classification tasks includes optimizing the network's weights even after the training error vanishes to further push the training loss toward zero. Recently, a phenomenon termed \"neural collapse\" (NC) has been empirically observed in this training procedure. Specifically, it has been shown that the learned features (the output of the penultimate layer) of within-class samples converge to their mean, and the means of different classes exhibit a certain tight frame structure, which is also aligned with the last layer's weights. Recent papers have shown that minimizers with this structure emerge when optimizing a simplified \"unconstrained features model\" (UFM) with a regularized cross-entropy loss. In this paper, we further analyze and extend the UFM. First, we study the UFM for the regularized MSE loss, and show that the minimizers' features can be more structured than in the cross-entropy case. This affects also the structure of the weights. Then, we extend the UFM by adding another layer of weights as well as ReLU nonlinearity to the model and generalize our previous results. Finally, we empirically demonstrate the usefulness of our nonlinear extended UFM in modeling the NC phenomenon that occurs with practical networks. ",
    "url": "https://arxiv.org/abs/2202.08087",
    "authors": [
      "Tom Tirer",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.08088",
    "title": "Latent Outlier Exposure for Anomaly Detection with Contaminated Data",
    "abstract": "Anomaly detection aims at identifying data points that show systematic deviations from the majority of data in an unlabeled dataset. A common assumption is that clean training data (free of anomalies) is available, which is often violated in practice. We propose a strategy for training an anomaly detector in the presence of unlabeled anomalies that is compatible with a broad class of models. The idea is to jointly infer binary labels to each datum (normal vs. anomalous) while updating the model parameters. Inspired by outlier exposure (Hendrycks et al., 2018) that considers synthetically created, labeled anomalies, we thereby use a combination of two losses that share parameters: one for the normal and one for the anomalous data. We then iteratively proceed with block coordinate updates on the parameters and the most likely (latent) labels. Our experiments with several backbone models on three image datasets, 30 tabular data sets, and a video anomaly detection benchmark showed consistent and significant improvements over the baselines. ",
    "url": "https://arxiv.org/abs/2202.08088",
    "authors": [
      "Chen Qiu",
      "Aodong Li",
      "Marius Kloft",
      "Maja Rudolph",
      "Stephan Mandt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.08099",
    "title": "Measuring Unintended Memorisation of Unique Private Features in Neural  Networks",
    "abstract": "Neural networks pose a privacy risk to training data due to their propensity to memorise and leak information. Focusing on image classification, we show that neural networks also unintentionally memorise unique features even when they occur only once in training data. An example of a unique feature is a person's name that is accidentally present on a training image. Assuming access to the inputs and outputs of a trained model, the domain of the training data, and knowledge of unique features, we develop a score estimating the model's sensitivity to a unique feature by comparing the KL divergences of the model's output distributions given modified out-of-distribution images. Our results suggest that unique features are memorised by multi-layer perceptrons and convolutional neural networks trained on benchmark datasets, such as MNIST, Fashion-MNIST and CIFAR-10. We find that strategies to prevent overfitting (e.g.\\ early stopping, regularisation, batch normalisation) do not prevent memorisation of unique features. These results imply that neural networks pose a privacy risk to rarely occurring private information. These risks can be more pronounced in healthcare applications if patient information is present in the training data. ",
    "url": "https://arxiv.org/abs/2202.08099",
    "authors": [
      "John Hartley",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.08100",
    "title": "Reversible data hiding with dual pixel-value-ordering and1minimum  prediction error expansion",
    "abstract": "Pixel Value Ordering (PVO) holds an impressive property for high fidelity Reversible Data Hiding (RDH). In this paper, we introduce a dual-PVO (dPVO) for Prediction Error Expansion(PEE), and thereby develop a new RDH scheme to offer a better rate-distortion performance. Particularly, we propose to embed in two phases: forward and backward. In the forward phase, PVO with classic PEE is applied to every non-overlapping image block of size 1x3. In the backward phase,minimum-set and maximum-set of pixels are determined from the pixels predicted in the forward phase. The minimum set only contains the lowest predicted pixels and the maximum set contains the largest predicted pixels of each image block. Proposed dPVO withPEE is then applied to both sets, so that the pixel values of the minimum set are increased and that of the maximum set are decreased by a unit value. Thereby, the pixels predicted in the forward embedding can partially be restored to their original values resulting in both better-embedded image quality and a higher embedding rate. Experimental results have recorded a promising rate-distortion performance of our scheme with a significant improvement of embedded image quality at higher embedding rates compared to the popular and state-of-the-art PVO-based RDHschemes. ",
    "url": "https://arxiv.org/abs/2202.08100",
    "authors": [
      "Md. Abdul Wahed",
      "Hussain Nyeem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2202.08146",
    "title": "A Prospective Approach for Human-to-Human Interaction Recognition from  Wi-Fi Channel Data using Attention Bidirectional Gated Recurrent Neural  Network with GUI Application Implementation",
    "abstract": "With the recent advances in multi-disciplinary human activity recognition techniques, it has become inevitable to find an efficient, economical & privacy-friendly approach for human-to-human mutual interaction recognition in order to breakthrough the modern artificial intelligence centric indoor monitoring & surveillance system. This study initially attempted to set its sights on the already proposed human activity recognition mechanisms and found a void in mutual interaction recognition from Wi-Fi channel information which is convenient & affordable to be utilized. Then it elucidated on the corresponding components of wireless local area network gadgets along with the channel properties, and notable underlying causes of signal & channel perturbation. Thenceforth the study conducted three experiments on human-to-human mutual interaction recognition using the proposed Self-Attention furnished Bidirectional Gated Recurrent Neural Network deep learning model which is perceived to become emergent nowadays for time-series data classification through automated temporal feature extraction. Single pair mutual interaction recognition experiment achieved a maximum of 94% test benchmark while the experiment involving ten subject-pairs secured 88% benchmark with improved classification around interaction-transition region. Demonstration of a graphical user interface executable software designed using PyQt5 python module subsequently portrayed the overall mutual human-interaction recognition procedure, and finally the study concluded with a brief discourse regarding the possible solutions to the handicaps that resulted in curtailments observed in the case of cross-test experiment. ",
    "url": "https://arxiv.org/abs/2202.08146",
    "authors": [
      "Md. Mohi Uddin Khan",
      "Abdullah Bin Shams",
      "Md. Mohsin Sarker Raihan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.08149",
    "title": "Self-Supervised Class-Cognizant Few-Shot Classification",
    "abstract": "Unsupervised learning is argued to be the dark matter of human intelligence. To build in this direction, this paper focuses on unsupervised learning from an abundance of unlabeled data followed by few-shot fine-tuning on a downstream classification task. To this aim, we extend a recent study on adopting contrastive learning for self-supervised pre-training by incorporating class-level cognizance through iterative clustering and re-ranking and by expanding the contrastive optimization loss to account for it. To our knowledge, our experimentation both in standard and cross-domain scenarios demonstrate that we set a new state-of-the-art (SoTA) in (5-way, 1 and 5-shot) settings of standard mini-ImageNet benchmark as well as the (5-way, 5 and 20-shot) settings of cross-domain CDFSL benchmark. Our code and experimentation can be found in our GitHub repository: https://github.com/ojss/c3lr. ",
    "url": "https://arxiv.org/abs/2202.08149",
    "authors": [
      "Ojas Kishore Shirekar",
      "Hadi Jamali-Rad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.08159",
    "title": "Domain Adaptive Fake News Detection via Reinforcement Learning",
    "abstract": "With social media being a major force in information consumption, accelerated propagation of fake news has presented new challenges for platforms to distinguish between legitimate and fake news. Effective fake news detection is a non-trivial task due to the diverse nature of news domains and expensive annotation costs. In this work, we address the limitations of existing automated fake news detection models by incorporating auxiliary information (e.g., user comments and user-news interactions) into a novel reinforcement learning-based model called \\textbf{RE}inforced \\textbf{A}daptive \\textbf{L}earning \\textbf{F}ake \\textbf{N}ews \\textbf{D}etection (REAL-FND). REAL-FND exploits cross-domain and within-domain knowledge that makes it robust in a target domain, despite being trained in a different source domain. Extensive experiments on real-world datasets illustrate the effectiveness of the proposed model, especially when limited labeled data is available in the target domain. ",
    "url": "https://arxiv.org/abs/2202.08159",
    "authors": [
      "Ahmadreza Mosallanezhad",
      "Mansooreh Karami",
      "Kai Shu",
      "Michelle V. Mancenido",
      "Huan Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.08175",
    "title": "GraphNLI: A Graph-based Natural Language Inference Model for Polarity  Prediction in Online Debates",
    "abstract": "Online forums that allow participatory engagement between users have been transformative for public discussion of important issues. However, debates on such forums can sometimes escalate into full blown exchanges of hate or misinformation. An important tool in understanding and tackling such problems is to be able to infer the argumentative relation of whether a reply is supporting or attacking the post it is replying to. This so called polarity prediction task is difficult because replies may be based on external context beyond a post and the reply whose polarity is being predicted. We propose GraphNLI, a novel graph-based deep learning architecture that uses graph walk techniques to capture the wider context of a discussion thread in a principled fashion. Specifically, we propose methods to perform root-seeking graph walks that start from a post and captures its surrounding context to generate additional embeddings for the post. We then use these embeddings to predict the polarity relation between a reply and the post it is replying to. We evaluate the performance of our models on a curated debate dataset from Kialo, an online debating platform. Our model outperforms relevant baselines, including S-BERT, with an overall accuracy of 83%. ",
    "url": "https://arxiv.org/abs/2202.08175",
    "authors": [
      "Vibhor Agarwal",
      "Sagar Joglekar",
      "Anthony P. Young",
      "Nishanth Sastry"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.08185",
    "title": "The Adversarial Security Mitigations of mmWave Beamforming Prediction  Models using Defensive Distillation and Adversarial Retraining",
    "abstract": "The design of a security scheme for beamforming prediction is critical for next-generation wireless networks (5G, 6G, and beyond). However, there is no consensus about protecting the beamforming prediction using deep learning algorithms in these networks. This paper presents the security vulnerabilities in deep learning for beamforming prediction using deep neural networks (DNNs) in 6G wireless networks, which treats the beamforming prediction as a multi-output regression problem. It is indicated that the initial DNN model is vulnerable against adversarial attacks, such as Fast Gradient Sign Method (FGSM), Basic Iterative Method (BIM), Projected Gradient Descent (PGD), and Momentum Iterative Method (MIM), because the initial DNN model is sensitive to the perturbations of the adversarial samples of the training data. This study also offers two mitigation methods, such as adversarial training and defensive distillation, for adversarial attacks against artificial intelligence (AI)-based models used in the millimeter-wave (mmWave) beamforming prediction. Furthermore, the proposed scheme can be used in situations where the data are corrupted due to the adversarial examples in the training data. Experimental results show that the proposed methods effectively defend the DNN models against adversarial attacks in next-generation wireless networks. ",
    "url": "https://arxiv.org/abs/2202.08185",
    "authors": [
      "Murat Kuzlu",
      "Ferhat Ozgur Catak",
      "Umit Cali",
      "Evren Catak",
      "Ozgur Guler"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2202.08187",
    "title": "Differential Privacy and Fairness in Decisions and Learning Tasks: A  Survey",
    "abstract": "This paper surveys recent work in the intersection of differential privacy (DP) and fairness. It reviews the conditions under which privacy and fairness may have aligned or contrasting goals, analyzes how and why DP may exacerbate bias and unfairness in decision problems and learning tasks, and describes available mitigation measures for the fairness issues arising in DP systems. The survey provides a unified understanding of the main challenges and potential risks arising when deploying privacy-preserving machine-learning or decisions-making tasks under a fairness lens. ",
    "url": "https://arxiv.org/abs/2202.08187",
    "authors": [
      "Ferdinando Fioretto",
      "Cuong Tran",
      "Pascal Van Hentenryck",
      "Keyu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.08205",
    "title": "SemiRetro: Semi-template framework boosts deep retrosynthesis prediction",
    "abstract": "Recently, template-based (TB) and template-free (TF) molecule graph learning methods have shown promising results to retrosynthesis. TB methods are more accurate using pre-encoded reaction templates, and TF methods are more scalable by decomposing retrosynthesis into subproblems, i.e., center identification and synthon completion. To combine both advantages of TB and TF, we suggest breaking a full-template into several semi-templates and embedding them into the two-step TF framework. Since many semi-templates are reduplicative, the template redundancy can be reduced while the essential chemical knowledge is still preserved to facilitate synthon completion. We call our method SemiRetro, introduce a new GNN layer (DRGAT) to enhance center identification, and propose a novel self-correcting module to improve semi-template classification. Experimental results show that SemiRetro significantly outperforms both existing TB and TF methods. In scalability, SemiRetro covers 98.9\\% data using 150 semi-templates, while previous template-based GLN requires 11,647 templates to cover 93.3\\% data. In top-1 accuracy, SemiRetro exceeds template-free G2G 4.8\\% (class known) and 6.0\\% (class unknown). Besides, SemiRetro has better training efficiency than existing methods. ",
    "url": "https://arxiv.org/abs/2202.08205",
    "authors": [
      "Zhangyang Gao",
      "Cheng Tan",
      "Lirong Wu",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.08208",
    "title": "Front Transport Reduction for Complex Moving Fronts",
    "abstract": "This work addresses model order reduction for complex moving fronts, which are transported by advection or through a reaction-diffusion process. Such systems are especially challenging for model order reduction since the transport cannot be captured by linear reduction methods. Moreover, topological changes, such as splitting or merging of fronts pose difficulties for many nonlinear reduction methods and the small non-vanishing support of the underlying partial differential equations dynamics makes most nonlinear hyper-reduction methods infeasible. We propose a new decomposition method together with a hyper-reduction scheme that addresses these shortcomings. The decomposition uses a level-set function to parameterize the transport and a nonlinear activation function that captures the structure of the front. This approach is similar to autoencoder artificial neural networks, but additionally provides insights into the system, which can be used for efficient reduced order models. We make use of this property and are thus able to solve the advection equation with the same complexity as the POD-Galerkin approach while obtaining errors of less than one percent for representative examples. Furthermore, we outline a special hyper-reduction method for more complicated advection-reaction-diffusion systems. The capability of the approach is illustrated by various numerical examples in one and two spatial dimensions, including real-life applications to a two-dimensional Bunsen flame. ",
    "url": "https://arxiv.org/abs/2202.08208",
    "authors": [
      "Philipp Krah",
      "Steffen B\u00fcchholz",
      "Matthias H\u00e4ringer",
      "Julius Reiss"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2202.08221",
    "title": "Evolutionary Construction of Perfectly Balanced Boolean Functions",
    "abstract": "Finding Boolean functions suitable for cryptographic primitives is a complex combinatorial optimization problem, since they must satisfy several properties to resist cryptanalytic attacks, and the space is very large, which grows super exponentially with the number of input variables. Recent research has focused on the study of Boolean functions that satisfy properties on restricted sets of inputs due to their importance in the development of the FLIP stream cipher. In this paper, we consider one such property, perfect balancedness, and investigate the use of Genetic Programming (GP) and Genetic Algorithms (GA) to construct Boolean functions that satisfy this property along with a good nonlinearity profile. We formulate the related optimization problem and define two encodings for the candidate solutions, namely the truth table and the weightwise balanced representations. Somewhat surprisingly, the results show that GA with the weightwise balanced representation outperforms GP with the classical truth table phenotype in finding highly nonlinear WPB functions. This finding is in stark contrast to previous findings on the evolution of globally balanced Boolean functions, where GP always performs best. ",
    "url": "https://arxiv.org/abs/2202.08221",
    "authors": [
      "Luca Mariot",
      "Stjepan Picek",
      "Domagoj Jakobovic",
      "Marko Djurasevic",
      "Alberto Leporati"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.08235",
    "title": "Data Augmentation for Deep Graph Learning: A Survey",
    "abstract": "Graph neural networks, as powerful deep learning tools to model graph-structured data, have demonstrated remarkable performance on numerous graph learning tasks. To counter the data noise and data scarcity issues in deep graph learning (DGL), increasing graph data augmentation research has been conducted lately. However, conventional data augmentation methods can hardly handle graph-structured data which is defined on non-Euclidean space with multi-modality. In this survey, we formally formulate the problem of graph data augmentation and further review the representative techniques in this field. Specifically, we first propose a taxonomy for graph data augmentation and then provide a structured review by categorizing the related work based on the augmented information modalities. Focusing on the two challenging problems in DGL (i.e., optimal graph learning and low-resource graph learning), we also discuss and review the existing learning paradigms which are based on graph data augmentation. Finally, we point out a few directions and challenges on promising future works. ",
    "url": "https://arxiv.org/abs/2202.08235",
    "authors": [
      "Kaize Ding",
      "Zhe Xu",
      "Hanghang Tong",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07679",
    "title": "Taking a Step Back with KCal: Multi-Class Kernel-Based Calibration for  Deep Neural Networks",
    "abstract": "Deep neural network (DNN) classifiers are often overconfident, producing miscalibrated class probabilities. Most existing calibration methods either lack theoretical guarantees for producing calibrated outputs or reduce the classification accuracy in the process. This paper proposes a new Kernel-based calibration method called KCal. Unlike other calibration procedures, KCal does not operate directly on the logits or softmax outputs of the DNN. Instead, it uses the penultimate-layer latent embedding to train a metric space in a supervised manner. In effect, KCal amounts to a supervised dimensionality reduction of the neural network embedding, and generates a prediction using kernel density estimation on a holdout calibration set. We first analyze KCal theoretically, showing that it enjoys a provable asymptotic calibration guarantee. Then, through extensive experiments, we confirm that KCal consistently outperforms existing calibration methods in terms of both the classification accuracy and the (confidence and class-wise) calibration error. ",
    "url": "https://arxiv.org/abs/2202.07679",
    "authors": [
      "Zhen Lin",
      "Shubhendu Trivedi",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2202.07750",
    "title": "Nonverbal Sound Detection for Disordered Speech",
    "abstract": "Voice assistants have become an essential tool for people with various disabilities because they enable complex phone- or tablet-based interactions without the need for fine-grained motor control, such as with touchscreens. However, these systems are not tuned for the unique characteristics of individuals with speech disorders, including many of those who have a motor-speech disorder, are deaf or hard of hearing, have a severe stutter, or are minimally verbal. We introduce an alternative voice-based input system which relies on sound event detection using fifteen nonverbal mouth sounds like \"pop,\" \"click,\" or \"eh.\" This system was designed to work regardless of ones' speech abilities and allows full access to existing technology. In this paper, we describe the design of a dataset, model considerations for real-world deployment, and efforts towards model personalization. Our fully-supervised model achieves segment-level precision and recall of 88.6% and 88.4% on an internal dataset of 710 adults, while achieving 0.31 false positives per hour on aggressors such as speech. Five-shot personalization enables satisfactory performance in 84.5% of cases where the generic model fails. ",
    "url": "https://arxiv.org/abs/2202.07750",
    "authors": [
      "Colin Lea",
      "Zifang Huang",
      "Dhruv Jain",
      "Lauren Tooley",
      "Zeinab Liaghat",
      "Shrinath Thelapurath",
      "Leah Findlater",
      "Jeffrey P. Bigham"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2202.07752",
    "title": "The treewidth and pathwidth of graph unions",
    "abstract": "For two graphs $G_1$ and $G_2$ on the same vertex set $[n]:=\\{1,2, \\ldots, n\\}$, and a permutation $\\varphi$ of $[n]$, the union of $G_1$ and $G_2$ along $\\varphi$ is the graph which is the union of $G_2$ and the graph obtained from $G_1$ by renaming its vertices according to $\\varphi$. We examine the behaviour of the treewidth and pathwidth of graphs under this \"gluing\" operation. We show that under certain conditions on $G_1$ and $G_2$, we may bound those parameters for such unions in terms of their values for the original graphs, regardless of what permutation $\\varphi$ we choose. In some cases, however, this is only achievable if $\\varphi$ is chosen carefully, while yet in others, it is always impossible to achieve boundedness. More specifically, among other results, we prove that if $G_1$ has treewidth $k$ and $G_2$ has pathwidth $\\ell$, then they can be united into a graph of treewidth at most $k + 3 \\ell + 1$. On the other hand, we show that for any natural number $c$ there exists a pair of trees $G_1$ and $G_2$ whose every union has treewidth more than $c$. ",
    "url": "https://arxiv.org/abs/2202.07752",
    "authors": [
      "Bogdan Alecu",
      "Vadim Lozin",
      "Daniel A. Quiroz",
      "Roman Rabinovich",
      "Igor Razgon",
      "Viktor Zamaraev"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2202.07796",
    "title": "Low Latency Real-Time Seizure Detection Using Transfer Deep Learning",
    "abstract": "Scalp electroencephalogram (EEG) signals inherently have a low signal-to-noise ratio due to the way the signal is electrically transduced. Temporal and spatial information must be exploited to achieve accurate detection of seizure events. Most popular approaches to seizure detection using deep learning do not jointly model this information or require multiple passes over the signal, which makes the systems inherently non-causal. In this paper, we exploit both simultaneously by converting the multichannel signal to a grayscale image and using transfer learning to achieve high performance. The proposed system is trained end-to-end with only very simple pre- and postprocessing operations which are computationally lightweight and have low latency, making them conducive to clinical applications that require real-time processing. We have achieved a performance of 42.05% sensitivity with 5.78 false alarms per 24 hours on the development dataset of v1.5.2 of the Temple University Hospital Seizure Detection Corpus. On a single-core CPU operating at 1.7 GHz, the system runs faster than real-time (0.58 xRT), uses 16 Gbytes of memory, and has a latency of 300 msec. ",
    "url": "https://arxiv.org/abs/2202.07796",
    "authors": [
      "Vahid Khalkhali",
      "Nabila Shawki",
      "Vinit Shah",
      "Meysam Golmohammadi",
      "Iyad Obeid",
      "Joseph Picone"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07823",
    "title": "Segmentation and Risk Score Prediction of Head and Neck Cancers in  PET/CT Volumes with 3D U-Net and Cox Proportional Hazard Neural Networks",
    "abstract": "We utilized a 3D nnU-Net model with residual layers supplemented by squeeze and excitation (SE) normalization for tumor segmentation from PET/CT images provided by the Head and Neck Tumor segmentation chal-lenge (HECKTOR). Our proposed loss function incorporates the Unified Fo-cal and Mumford-Shah losses to take the advantage of distribution, region, and boundary-based loss functions. The results of leave-one-out-center-cross-validation performed on different centers showed a segmentation performance of 0.82 average Dice score (DSC) and 3.16 median Hausdorff Distance (HD), and our results on the test set achieved 0.77 DSC and 3.01 HD. Following lesion segmentation, we proposed training a case-control proportional hazard Cox model with an MLP neural net backbone to predict the hazard risk score for each discrete lesion. This hazard risk prediction model (CoxCC) was to be trained on a number of PET/CT radiomic features extracted from the segmented lesions, patient and lesion demographics, and encoder features provided from the penultimate layer of a multi-input 2D PET/CT convolutional neural network tasked with predicting time-to-event for each lesion. A 10-fold cross-validated CoxCC model resulted in a c-index validation score of 0.89, and a c-index score of 0.61 on the HECKTOR challenge test dataset. ",
    "url": "https://arxiv.org/abs/2202.07823",
    "authors": [
      "Fereshteh Yousefirizi",
      "Ian Janzen",
      "Natalia Dubljevic",
      "Yueh-En Liu",
      "Chloe Hill",
      "Calum MacAulay",
      "Arman Rahmim"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2202.07955",
    "title": "Robust Nonparametric Distribution Forecast with Backtest-based Bootstrap  and Adaptive Residual Selection",
    "abstract": "Distribution forecast can quantify forecast uncertainty and provide various forecast scenarios with their corresponding estimated probabilities. Accurate distribution forecast is crucial for planning - for example when making production capacity or inventory allocation decisions. We propose a practical and robust distribution forecast framework that relies on backtest-based bootstrap and adaptive residual selection. The proposed approach is robust to the choice of the underlying forecasting model, accounts for uncertainty around the input covariates, and relaxes the independence between residuals and covariates assumption. It reduces the Absolute Coverage Error by more than 63% compared to the classic bootstrap approaches and by 2% - 32% compared to a variety of State-of-the-Art deep learning approaches on in-house product sales data and M4-hourly competition data. ",
    "url": "https://arxiv.org/abs/2202.07955",
    "authors": [
      "Longshaokan Wang",
      "Lingda Wang",
      "Mina Georgieva",
      "Paulo Machado",
      "Abinaya Ulagappa",
      "Safwan Ahmed",
      "Yan Lu",
      "Arjun Bakshi",
      "Farhad Ghassemi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07998",
    "title": "DeepTx: Deep Learning Beamforming with Channel Prediction",
    "abstract": "Machine learning algorithms have recently been considered for many tasks in the field of wireless communications. Previously, we have proposed the use of a deep fully convolutional neural network (CNN) for receiver processing and shown it to provide considerable performance gains. In this study, we focus on machine learning algorithms for the transmitter. In particular, we consider beamforming and propose a CNN which, for a given uplink channel estimate as input, outputs downlink channel information to be used for beamforming. The CNN is trained in a supervised manner considering both uplink and downlink transmissions with a loss function that is based on UE receiver performance. The main task of the neural network is to predict the channel evolution between uplink and downlink slots, but it can also learn to handle inefficiencies and errors in the whole chain, including the actual beamforming phase. The provided numerical experiments demonstrate the improved beamforming performance. ",
    "url": "https://arxiv.org/abs/2202.07998",
    "authors": [
      "Janne M.J. Huttunen",
      "Dani Korpi",
      "Mikko~Honkala"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.08147",
    "title": "Modular multi-source prediction of drug side-effects with DruGNN",
    "abstract": "Drug Side-Effects (DSEs) have a high impact on public health, care system costs, and drug discovery processes. Predicting the probability of side-effects, before their occurrence, is fundamental to reduce this impact, in particular on drug discovery. Candidate molecules could be screened before undergoing clinical trials, reducing the costs in time, money, and health of the participants. Drug side-effects are triggered by complex biological processes involving many different entities, from drug structures to protein-protein interactions. To predict their occurrence, it is necessary to integrate data from heterogeneous sources. In this work, such heterogeneous data is integrated into a graph dataset, expressively representing the relational information between different entities, such as drug molecules and genes. The relational nature of the dataset represents an important novelty for drug side-effect predictors. Graph Neural Networks (GNNs) are exploited to predict DSEs on our dataset with very promising results. GNNs are deep learning models that can process graph-structured data, with minimal information loss, and have been applied on a wide variety of biological tasks. Our experimental results confirm the advantage of using relationships between data entities, suggesting interesting future developments in this scope. The experimentation also shows the importance of specific subsets of data in determining associations between drugs and side-effects. ",
    "url": "https://arxiv.org/abs/2202.08147",
    "authors": [
      "Pietro Bongini",
      "Franco Scarselli",
      "Monica Bianchini",
      "Giovanna Maria Dimitri",
      "Niccol\u00f2 Pancino",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2006.04004",
    "title": "Distributionally Robust Weighted $k$-Nearest Neighbors",
    "abstract": " Title: Distributionally Robust Weighted $k$-Nearest Neighbors ",
    "url": "https://arxiv.org/abs/2006.04004",
    "authors": [
      "Shixiang Zhu",
      "Liyan Xie",
      "Minghe Zhang",
      "Rui Gao",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2006.10564",
    "title": "Distribution-free binary classification: prediction sets, confidence  intervals and calibration",
    "abstract": " Comments: 34 pages; significant updates from previous version (unambiguous notation, better exposition, and cleaner results); originally appeared as a spotlight at Neural Information Processing Systems (NeurIPS) '20 ",
    "url": "https://arxiv.org/abs/2006.10564",
    "authors": [
      "Chirag Gupta",
      "Aleksandr Podkopaev",
      "Aaditya Ramdas"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2007.06169",
    "title": "An Adversarial Approach to Structural Estimation",
    "abstract": " Comments: 70 pages, 4 tables, 16 figures ",
    "url": "https://arxiv.org/abs/2007.06169",
    "authors": [
      "Tetsuya Kaji",
      "Elena Manresa",
      "Guillaume Pouliot"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2007.08745",
    "title": "Backdoor Learning: A Survey",
    "abstract": " Comments: 17 pages. A curated list of backdoor learning resources in this paper is presented in the Github Repo (this https URL). We will try our best to continuously maintain this Github Repo ",
    "url": "https://arxiv.org/abs/2007.08745",
    "authors": [
      "Yiming Li",
      "Yong Jiang",
      "Zhifeng Li",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2007.13374",
    "title": "Decomposing Generation Networks with Structure Prediction for Recipe  Generation",
    "abstract": " Comments: Accepted at Pattern Recognition ",
    "url": "https://arxiv.org/abs/2007.13374",
    "authors": [
      "Hao Wang",
      "Guosheng Lin",
      "Steven C. H. Hoi",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2009.00774",
    "title": "Vulnerability-Aware Poisoning Mechanism for Online RL with Unknown  Dynamics",
    "abstract": " Title: Vulnerability-Aware Poisoning Mechanism for Online RL with Unknown  Dynamics ",
    "url": "https://arxiv.org/abs/2009.00774",
    "authors": [
      "Yanchao Sun",
      "Da Huo",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2010.05429",
    "title": "TUTOR: Training Neural Networks Using Decision Rules as Model Priors",
    "abstract": " Comments: 14 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2010.05429",
    "authors": [
      "Shayan Hassantabar",
      "Prerit Terway",
      "Niraj K. Jha"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2010.09895",
    "title": "Multi-Window Data Augmentation Approach for Speech Emotion Recognition",
    "abstract": " Title: Multi-Window Data Augmentation Approach for Speech Emotion Recognition ",
    "url": "https://arxiv.org/abs/2010.09895",
    "authors": [
      "Sarala Padi",
      "Dinesh Manocha",
      "Ram D.Sriram"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2011.00444",
    "title": "Discriminative Adversarial Domain Generalization with Meta-learning  based Cross-domain Validation",
    "abstract": " Title: Discriminative Adversarial Domain Generalization with Meta-learning  based Cross-domain Validation ",
    "url": "https://arxiv.org/abs/2011.00444",
    "authors": [
      "Keyu Chen",
      "Di Zhuang",
      "J. Morris Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2011.11198",
    "title": "Complex-valued Iris Recognition Network",
    "abstract": " Comments: This paper has been accepted for publication in T-PAMI ",
    "url": "https://arxiv.org/abs/2011.11198",
    "authors": [
      "Kien Nguyen",
      "Clinton Fookes",
      "Sridha Sridharan",
      "Arun Ross"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2012.00936",
    "title": "MAUIL: Multi-level Attribute Embedding for Semi-supervised User Identity  Linkage",
    "abstract": " Comments: Accepted by Information Sciences in Feb. 2022 ",
    "url": "https://arxiv.org/abs/2012.00936",
    "authors": [
      "Baiyang Chen",
      "Xiaoliang Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2012.14048",
    "title": "Learning to predict synchronization of coupled oscillators on  heterogeneous graphs",
    "abstract": " Comments: 17 pages, 12 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2012.14048",
    "authors": [
      "Hardeep Bassi",
      "Richard Yim",
      "Rohith Kodukula",
      "Joshua Vendrow",
      "Cherlin Zhu",
      "Hanbaek Lyu"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2101.05519",
    "title": "BiGCN: A Bi-directional Low-Pass Filtering Graph Neural Network",
    "abstract": " Title: BiGCN: A Bi-directional Low-Pass Filtering Graph Neural Network ",
    "url": "https://arxiv.org/abs/2101.05519",
    "authors": [
      "Zhixian Chen",
      "Tengfei Ma",
      "Zhihua Jin",
      "Yangqiu Song",
      "Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2101.12614",
    "title": "Modeling blood flow in networks of viscoelastic vessels with the 1-D  augmented fluid-structure interaction system",
    "abstract": " Comments: 42 pages, 19 figures ",
    "url": "https://arxiv.org/abs/2101.12614",
    "authors": [
      "Francesco Piccioli",
      "Giulia Bertaglia",
      "Alessandro Valiani",
      "Valerio Caleffi"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2102.00082",
    "title": "Settling the Sharp Reconstruction Thresholds of Random Graph Matching",
    "abstract": " Title: Settling the Sharp Reconstruction Thresholds of Random Graph Matching ",
    "url": "https://arxiv.org/abs/2102.00082",
    "authors": [
      "Yihong Wu",
      "Jiaming Xu",
      "Sophie H. Yu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2102.01229",
    "title": "Doubly robust Thompson sampling for linear payoffs",
    "abstract": " Comments: Accepted for NeurIPS 2021 (Spotlight) ",
    "url": "https://arxiv.org/abs/2102.01229",
    "authors": [
      "Wonyoung Kim",
      "Gi-soo Kim",
      "Myunghee Cho Paik"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2102.03450",
    "title": "Wasserstein Graph Neural Networks for Graphs with Missing Attributes",
    "abstract": " Title: Wasserstein Graph Neural Networks for Graphs with Missing Attributes ",
    "url": "https://arxiv.org/abs/2102.03450",
    "authors": [
      "Zhixian Chen",
      "Tengfei Ma",
      "Yangqiu Song",
      "Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2102.09844",
    "title": "E(n) Equivariant Graph Neural Networks",
    "abstract": " Title: E(n) Equivariant Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2102.09844",
    "authors": [
      "Victor Garcia Satorras",
      "Emiel Hoogeboom",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2102.10757",
    "title": "Self-Supervised Learning of Graph Neural Networks: A Unified Review",
    "abstract": " Comments: 26 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2102.10757",
    "authors": [
      "Yaochen Xie",
      "Zhao Xu",
      "Jingtun Zhang",
      "Zhengyang Wang",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2104.07794",
    "title": "An $L^2$ Analysis of Reinforcement Learning in High Dimensions with  Kernel and Neural Network Approximation",
    "abstract": " Title: An $L^2$ Analysis of Reinforcement Learning in High Dimensions with  Kernel and Neural Network Approximation ",
    "url": "https://arxiv.org/abs/2104.07794",
    "authors": [
      "Jihao Long",
      "Jiequn Han",
      "Weinan E"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2104.10150",
    "title": "Bayesian subset selection and variable importance for interpretable  prediction and classification",
    "abstract": " Title: Bayesian subset selection and variable importance for interpretable  prediction and classification ",
    "url": "https://arxiv.org/abs/2104.10150",
    "authors": [
      "Daniel R. Kowal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2105.01976",
    "title": "GRAPHOPT: constrained-optimization-based parallelization of irregular  graphs",
    "abstract": " Title: GRAPHOPT: constrained-optimization-based parallelization of irregular  graphs ",
    "url": "https://arxiv.org/abs/2105.01976",
    "authors": [
      "Nimish Shah",
      "Wannes Meert",
      "Marian Verhelst"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2105.14490",
    "title": "Relational Graph Neural Network Design via Progressive Neural  Architecture Search",
    "abstract": " Title: Relational Graph Neural Network Design via Progressive Neural  Architecture Search ",
    "url": "https://arxiv.org/abs/2105.14490",
    "authors": [
      "Ailing Zeng",
      "Minhao Liu",
      "Zhiwei Liu",
      "Ruiyuan Gao",
      "Jing Qin",
      "Qiang Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.01981",
    "title": "ProtoRes: Proto-Residual Network for Pose Authoring via Learned Inverse  Kinematics",
    "abstract": " Title: ProtoRes: Proto-Residual Network for Pose Authoring via Learned Inverse  Kinematics ",
    "url": "https://arxiv.org/abs/2106.01981",
    "authors": [
      "Boris N. Oreshkin",
      "Florent Bocquelet",
      "F\u00e9lix G. Harvey",
      "Bay Raitt",
      "Dominic Laflamme"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.04405",
    "title": "Federated Neural Collaborative Filtering",
    "abstract": " Title: Federated Neural Collaborative Filtering ",
    "url": "https://arxiv.org/abs/2106.04405",
    "authors": [
      "Vasileios Perifanis",
      "Pavlos S. Efraimidis"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.06768",
    "title": "Planning Spatial Networks with Monte Carlo Tree Search",
    "abstract": " Title: Planning Spatial Networks with Monte Carlo Tree Search ",
    "url": "https://arxiv.org/abs/2106.06768",
    "authors": [
      "Victor-Alexandru Darvariu",
      "Stephen Hailes",
      "Mirco Musolesi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.07990",
    "title": "The Connection between Process Complexity of Event Sequences and Models  discovered by Process Mining",
    "abstract": " Title: The Connection between Process Complexity of Event Sequences and Models  discovered by Process Mining ",
    "url": "https://arxiv.org/abs/2106.07990",
    "authors": [
      "Adriano Augusto",
      "Jan Mendling",
      "Maxim Vidgof",
      "Bastian Wurm"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2107.05899",
    "title": "Speech Representation Learning Combining Conformer CPC with Deep Cluster  for the ZeroSpeech Challenge 2021",
    "abstract": " Title: Speech Representation Learning Combining Conformer CPC with Deep Cluster  for the ZeroSpeech Challenge 2021 ",
    "url": "https://arxiv.org/abs/2107.05899",
    "authors": [
      "Takashi Maekaku",
      "Xuankai Chang",
      "Yuya Fujita",
      "Li-Wei Chen",
      "Shinji Watanabe",
      "Alexander Rudnicky"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2107.07623",
    "title": "Correlation detection in trees for planted graph alignment",
    "abstract": " Comments: 39 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2107.07623",
    "authors": [
      "Luca Ganassali",
      "Laurent Massouli\u00e9",
      "Marc Lelarge"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.13282",
    "title": "Dense Graph Partitioning on sparse and dense graphs",
    "abstract": " Title: Dense Graph Partitioning on sparse and dense graphs ",
    "url": "https://arxiv.org/abs/2107.13282",
    "authors": [
      "Cristina Bazgan",
      "Katrin Casel",
      "Pierre Cazals"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2107.13659",
    "title": "Quantum Annealing Algorithms for Boolean Tensor Networks",
    "abstract": " Comments: Reduced size to 14 pages ",
    "url": "https://arxiv.org/abs/2107.13659",
    "authors": [
      "Elijah Pelofske",
      "Georg Hahn",
      "Daniel O'Malley",
      "Hristo N. Djidjev",
      "Boian S. Alexandrov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2107.14293",
    "title": "Self-Supervised Transformer for Sparse and Irregularly Sampled  Multivariate Clinical Time-Series",
    "abstract": " Comments: Changed title to better reflect the challenges dealt with in the paper. Improved section 4.6. Changed the format to use ACM camera-ready template ",
    "url": "https://arxiv.org/abs/2107.14293",
    "authors": [
      "Sindhu Tipirneni",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.06891",
    "title": "Efficient Network Analysis Under Single Link Deletion",
    "abstract": " Comments: Found previous published results with similar findings ",
    "url": "https://arxiv.org/abs/2108.06891",
    "authors": [
      "Max Ward",
      "Amitava Datta",
      "Hung X. Nguyen",
      "Jason Eshraghian"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2109.04784",
    "title": "A Dynamic Scheduling Policy for a Network with Heterogeneous  Time-Sensitive Traffic",
    "abstract": " Comments: Submitted in a journal ",
    "url": "https://arxiv.org/abs/2109.04784",
    "authors": [
      "Emmanouil Fountoulakis",
      "Themistoklis Charalambous",
      "Anthony Ephremides",
      "Nikolaos Pappas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2109.08776",
    "title": "Exploring the Training Robustness of Distributional Reinforcement  Learning against Noisy State Observations",
    "abstract": " Title: Exploring the Training Robustness of Distributional Reinforcement  Learning against Noisy State Observations ",
    "url": "https://arxiv.org/abs/2109.08776",
    "authors": [
      "Ke Sun",
      "Yi Liu",
      "Yingnan Zhao",
      "Hengshuai Yao",
      "Shangling Jui",
      "Linglong Kong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.11576",
    "title": "Efficient, Interpretable Graph Neural Network Representation for  Angle-dependent Properties and its Application to Optical Spectroscopy",
    "abstract": " Title: Efficient, Interpretable Graph Neural Network Representation for  Angle-dependent Properties and its Application to Optical Spectroscopy ",
    "url": "https://arxiv.org/abs/2109.11576",
    "authors": [
      "Tim Hsu",
      "Tuan Anh Pham",
      "Nathan Keilbart",
      "Stephen Weitzner",
      "James Chapman",
      "Penghao Xiao",
      "S. Roger Qiu",
      "Xiao Chen",
      "Brandon C. Wood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2110.06773",
    "title": "Leveraging Automated Unit Tests for Unsupervised Code Translation",
    "abstract": " Title: Leveraging Automated Unit Tests for Unsupervised Code Translation ",
    "url": "https://arxiv.org/abs/2110.06773",
    "authors": [
      "Baptiste Roziere",
      "Jie M. Zhang",
      "Francois Charton",
      "Mark Harman",
      "Gabriel Synnaeve",
      "Guillaume Lample"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.08128",
    "title": "Label-Wise Message Passing Graph Neural Network on Heterophilic Graphs",
    "abstract": " Title: Label-Wise Message Passing Graph Neural Network on Heterophilic Graphs ",
    "url": "https://arxiv.org/abs/2110.08128",
    "authors": [
      "Enyan Dai",
      "Shijie Zhou",
      "Zhimeng Guo",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.12919",
    "title": "WOLF: A modular estimation framework for robotics based on factor graphs",
    "abstract": " Comments: 8 pages, 12 figures. v1: removed repository link. v2: add TERRINET thanks. v3: full review, authors addition and fix. v4: Fix one citation ",
    "url": "https://arxiv.org/abs/2110.12919",
    "authors": [
      "Joan Sola",
      "Joan Vallve",
      "Joaquim Casals",
      "Jeremie Deray",
      "Mederic Fourmy",
      "Dinesh Atchuthan",
      "Andreu Corominas-Murtra",
      "Juan Andrade-Cetto"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2110.13786",
    "title": "Diversity and Generalization in Neural Network Ensembles",
    "abstract": " Title: Diversity and Generalization in Neural Network Ensembles ",
    "url": "https://arxiv.org/abs/2110.13786",
    "authors": [
      "Luis A. Ortega",
      "Rafael Caba\u00f1as",
      "Andr\u00e9s R. Masegosa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2110.14728",
    "title": "Lung Cancer Lesion Detection in Histopathology Images Using Graph-Based  Sparse PCA Network",
    "abstract": " Comments: 10 pages, 9 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2110.14728",
    "authors": [
      "Sundaresh Ram",
      "Wenfei Tang",
      "Alexander J. Bell",
      "Cara Spencer",
      "Alexander Buschhaus",
      "Charles R. Hatt",
      "Marina Pasca diMagliano",
      "Jeffrey J. Rodriguez",
      "Stefanie Galban",
      "Craig J. Galban"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.14953",
    "title": "Multi-Task Neural Processes",
    "abstract": " Comments: 33 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2110.14953",
    "authors": [
      "Donggyun Kim",
      "Seongwoong Cho",
      "Wonkwang Lee",
      "Seunghoon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.06839",
    "title": "The self-supervised spectral-spatial attention-based transformer network  for automated, accurate prediction of crop nitrogen status from UAV imagery",
    "abstract": " Title: The self-supervised spectral-spatial attention-based transformer network  for automated, accurate prediction of crop nitrogen status from UAV imagery ",
    "url": "https://arxiv.org/abs/2111.06839",
    "authors": [
      "Xin Zhang",
      "Liangxiu Han",
      "Tam Sobeih",
      "Lewis Lappin",
      "Mark Lee",
      "Andew Howard",
      "Aron Kisdi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.07401",
    "title": "Neural Capacity Estimators: How Reliable Are They?",
    "abstract": " Comments: 7 pages, 5 figures, accepted for publication at the 2022 IEEE International Conference on Communications (ICC) ",
    "url": "https://arxiv.org/abs/2111.07401",
    "authors": [
      "Farhad Mirkarimi",
      "Stefano Rini",
      "Nariman Farsad"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2111.08211",
    "title": "FedCG: Leverage Conditional GAN for Protecting Privacy and Maintaining  Competitive Performance in Federated Learning",
    "abstract": " Title: FedCG: Leverage Conditional GAN for Protecting Privacy and Maintaining  Competitive Performance in Federated Learning ",
    "url": "https://arxiv.org/abs/2111.08211",
    "authors": [
      "Yuezhou Wu",
      "Yan Kang",
      "Jiahuan Luo",
      "Yuanqin He",
      "Qiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.08410",
    "title": "Thoughts on the Consistency between Ricci Flow and Neural Network  Behavior",
    "abstract": " Title: Thoughts on the Consistency between Ricci Flow and Neural Network  Behavior ",
    "url": "https://arxiv.org/abs/2111.08410",
    "authors": [
      "Jun Chen",
      "Tianxin Huang",
      "Wenzhou Chen",
      "Yong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2112.03120",
    "title": "Faster Cut Sparsification of Weighted Graphs",
    "abstract": " Title: Faster Cut Sparsification of Weighted Graphs ",
    "url": "https://arxiv.org/abs/2112.03120",
    "authors": [
      "Sebastian Forster",
      "Tijn de Vos"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2112.06428",
    "title": "Holistic Interpretation of Public Scenes Using Computer Vision and  Temporal Graphs to Identify Social Distancing Violations",
    "abstract": " Comments: 35 pages, 22 figures ",
    "url": "https://arxiv.org/abs/2112.06428",
    "authors": [
      "Gihan Jayatilaka",
      "Jameel Hassan",
      "Suren Sritharan",
      "Janith Bandara Senananayaka",
      "Harshana Weligampola",
      "Roshan Godaliyadda",
      "Parakrama Ekanayake",
      "Vijitha Herath",
      "Janaka Ekanayake",
      "Samath Dharmaratne"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.11172",
    "title": "Dynamically Stable Poincar\u00e9 Embeddings for Neural Manifolds",
    "abstract": " Title: Dynamically Stable Poincar\u00e9 Embeddings for Neural Manifolds ",
    "url": "https://arxiv.org/abs/2112.11172",
    "authors": [
      "Jun Chen",
      "Yuang Liu",
      "Xiangrui Zhao",
      "Mengmeng Wang",
      "Yong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)"
    ]
  },
  {
    "id": "arXiv:2112.13747",
    "title": "Scenario Adaptive Mixture-of-Experts for Promotion-Aware Click-Through  Rate Prediction",
    "abstract": " Title: Scenario Adaptive Mixture-of-Experts for Promotion-Aware Click-Through  Rate Prediction ",
    "url": "https://arxiv.org/abs/2112.13747",
    "authors": [
      "Xiaofeng Pan",
      "Yibin Shen",
      "Jing Zhang",
      "Keren Yu",
      "Hong Wen",
      "Shui Liu",
      "Chengjun Mao",
      "Bo Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2112.14233",
    "title": "Learning Across Bandits in High Dimension via Robust Statistics",
    "abstract": " Title: Learning Across Bandits in High Dimension via Robust Statistics ",
    "url": "https://arxiv.org/abs/2112.14233",
    "authors": [
      "Kan Xu",
      "Hamsa Bastani"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2201.02993",
    "title": "Rethink the Evaluation for Attack Strength of Backdoor Attacks in  Natural Language Processing",
    "abstract": " Title: Rethink the Evaluation for Attack Strength of Backdoor Attacks in  Natural Language Processing ",
    "url": "https://arxiv.org/abs/2201.02993",
    "authors": [
      "Lingfeng Shen",
      "Haiyun Jiang",
      "Lemao Liu",
      "Shuming Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.03681",
    "title": "FairEdit: Preserving Fairness in Graph Neural Networks through Greedy  Graph Editing",
    "abstract": " Title: FairEdit: Preserving Fairness in Graph Neural Networks through Greedy  Graph Editing ",
    "url": "https://arxiv.org/abs/2201.03681",
    "authors": [
      "Donald Loveland",
      "Jiayi Pan",
      "Aaresh Farrokh Bhathena",
      "Yiyang Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08093",
    "title": "AirPose: Multi-View Fusion Network for Aerial 3D Human Pose and Shape  Estimation",
    "abstract": " Title: AirPose: Multi-View Fusion Network for Aerial 3D Human Pose and Shape  Estimation ",
    "url": "https://arxiv.org/abs/2201.08093",
    "authors": [
      "Nitin Saini",
      "Elia Bonetto",
      "Eric Price",
      "Aamir Ahmad",
      "Michael J. Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.08996",
    "title": "Linear Array Network for Low-light Image Enhancement",
    "abstract": " Title: Linear Array Network for Low-light Image Enhancement ",
    "url": "https://arxiv.org/abs/2201.08996",
    "authors": [
      "Keqi Wang",
      "Ziteng Cui",
      "Jieru Jia",
      "Hao Xu",
      "Ge Wu",
      "Yin Zhuang",
      "Lu Chen",
      "Zhiguo Hu",
      "Yuhua Qian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2201.12165",
    "title": "Graph autoencoder with constant dimensional latent space",
    "abstract": " Title: Graph autoencoder with constant dimensional latent space ",
    "url": "https://arxiv.org/abs/2201.12165",
    "authors": [
      "Adam Ma\u0142kowski",
      "Jakub Grzechoci\u0144ski",
      "Pawe\u0142 Wawrzy\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12433",
    "title": "FedGCN: Convergence and Communication Tradeoffs in Federated Training of  Graph Convolutional Networks",
    "abstract": " Title: FedGCN: Convergence and Communication Tradeoffs in Federated Training of  Graph Convolutional Networks ",
    "url": "https://arxiv.org/abs/2201.12433",
    "authors": [
      "Yuhang Yao",
      "Carlee Joe-Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2201.12738",
    "title": "AutoSNN: Towards Energy-Efficient Spiking Neural Networks",
    "abstract": " Title: AutoSNN: Towards Energy-Efficient Spiking Neural Networks ",
    "url": "https://arxiv.org/abs/2201.12738",
    "authors": [
      "Byunggook Na",
      "Jisoo Mok",
      "Seongsik Park",
      "Dongjin Lee",
      "Hyeokjun Choe",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12994",
    "title": "GSN: A Universal Graph Neural Network Inspired by Spring Network",
    "abstract": " Comments: 15 pages. Preprint, under review ",
    "url": "https://arxiv.org/abs/2201.12994",
    "authors": [
      "Guanyu Cui",
      "Zhewei Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2201.13392",
    "title": "MHSnet: Multi-head and Spatial Attention Network with False-Positive  Reduction for Pulmonary Nodules Detection",
    "abstract": " Title: MHSnet: Multi-head and Spatial Attention Network with False-Positive  Reduction for Pulmonary Nodules Detection ",
    "url": "https://arxiv.org/abs/2201.13392",
    "authors": [
      "Juanyun Mai",
      "Minghao Wang",
      "Jiayin Zheng",
      "Yanbo Shao",
      "Zhaoqi Diao",
      "Xinliang Fu",
      "Yulong Chen",
      "Jianyu Xiao",
      "Jian You",
      "Airu Yin",
      "Yang Yang",
      "Xiangcheng Qiu",
      "Jinsheng Tao",
      "Bo Wang",
      "Hua Ji"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.00789",
    "title": "Team Belief DAG Form: A Concise Representation for Team-Correlated  Game-Theoretic Decision Making",
    "abstract": " Title: Team Belief DAG Form: A Concise Representation for Team-Correlated  Game-Theoretic Decision Making ",
    "url": "https://arxiv.org/abs/2202.00789",
    "authors": [
      "Brian Hu Zhang",
      "Gabriele Farina",
      "Tuomas Sandholm"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2202.02142",
    "title": "Deep invariant networks with differentiable augmentation layers",
    "abstract": " Title: Deep invariant networks with differentiable augmentation layers ",
    "url": "https://arxiv.org/abs/2202.02142",
    "authors": [
      "C\u00e9dric Rommel",
      "Thomas Moreau",
      "Alexandre Gramfort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02371",
    "title": "Boundary-aware Information Maximization for Self-supervised Medical  Image Segmentation",
    "abstract": " Title: Boundary-aware Information Maximization for Self-supervised Medical  Image Segmentation ",
    "url": "https://arxiv.org/abs/2202.02371",
    "authors": [
      "Jizong Peng",
      "Ping Wang",
      "Marco Pedersoli",
      "Christian Desrosiers"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.02514",
    "title": "Score-based Generative Modeling of Graphs via the System of Stochastic  Differential Equations",
    "abstract": " Title: Score-based Generative Modeling of Graphs via the System of Stochastic  Differential Equations ",
    "url": "https://arxiv.org/abs/2202.02514",
    "authors": [
      "Jaehyeong Jo",
      "Seul Lee",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03169",
    "title": "CITRIS: Causal Identifiability from Temporal Intervened Sequences",
    "abstract": " Comments: 47 pages ",
    "url": "https://arxiv.org/abs/2202.03169",
    "authors": [
      "Phillip Lippe",
      "Sara Magliacane",
      "Sindy L\u00f6we",
      "Yuki M. Asano",
      "Taco Cohen",
      "Efstratios Gavves"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2202.03348",
    "title": "Failure and success of the spectral bias prediction for Kernel Ridge  Regression: the case of low-dimensional data",
    "abstract": " Comments: 34 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2202.03348",
    "authors": [
      "Umberto M. Tomasini",
      "Antonio Sclocchi",
      "Matthieu Wyart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ]
  },
  {
    "id": "arXiv:2202.03580",
    "title": "Convolutional Neural Networks on Graphs with Chebyshev Approximation,  Revisited",
    "abstract": " Comments: 16 pages ",
    "url": "https://arxiv.org/abs/2202.03580",
    "authors": [
      "Mingguo He",
      "Zhewei Wei",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.03813",
    "title": "Learning to Predict Graphs with Fused Gromov-Wasserstein Barycenters",
    "abstract": " Title: Learning to Predict Graphs with Fused Gromov-Wasserstein Barycenters ",
    "url": "https://arxiv.org/abs/2202.03813",
    "authors": [
      "Luc Brogat-Motte",
      "R\u00e9mi Flamary",
      "C\u00e9line Brouard",
      "Juho Rousu",
      "Florence d'Alch\u00e9-Buc"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03903",
    "title": "KENN: Enhancing Deep Neural Networks by Leveraging Knowledge for Time  Series Forecasting",
    "abstract": " Title: KENN: Enhancing Deep Neural Networks by Leveraging Knowledge for Time  Series Forecasting ",
    "url": "https://arxiv.org/abs/2202.03903",
    "authors": [
      "Muhammad Ali Chattha",
      "Ludger van Elst",
      "Muhammad Imran Malik",
      "Andreas Dengel",
      "Sheraz Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.04124",
    "title": "A Mini-Block Natural Gradient Method for Deep Neural Networks",
    "abstract": " Title: A Mini-Block Natural Gradient Method for Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2202.04124",
    "authors": [
      "Achraf Bahamou",
      "Donald Goldfarb",
      "Yi Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.04206",
    "title": "Covariate-informed Representation Learning with Samplewise Optimal  Identifiable Variational Autoencoders",
    "abstract": " Title: Covariate-informed Representation Learning with Samplewise Optimal  Identifiable Variational Autoencoders ",
    "url": "https://arxiv.org/abs/2202.04206",
    "authors": [
      "Young-geun Kim",
      "Ying Liu",
      "Xuexin Wei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04476",
    "title": "Counting Kernels in Directed Graphs with Arbitrary Orientations",
    "abstract": " Comments: 18 pages, 3 figures, added: analysis of running times ",
    "url": "https://arxiv.org/abs/2202.04476",
    "authors": [
      "Bruno Jartoux"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2202.04770",
    "title": "Iterative Bilinear Temporal-Spectral Fusion for Unsupervised Time-Series  Representation Learning",
    "abstract": " Title: Iterative Bilinear Temporal-Spectral Fusion for Unsupervised Time-Series  Representation Learning ",
    "url": "https://arxiv.org/abs/2202.04770",
    "authors": [
      "Ling Yang",
      "Shenda Hong",
      "Luxia Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.04828",
    "title": "Learning Latent Causal Dynamics",
    "abstract": " Title: Learning Latent Causal Dynamics ",
    "url": "https://arxiv.org/abs/2202.04828",
    "authors": [
      "Weiran Yao",
      "Guangyi Chen",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04936",
    "title": "Graph Neural Network for Local Corruption Recovery",
    "abstract": " Title: Graph Neural Network for Local Corruption Recovery ",
    "url": "https://arxiv.org/abs/2202.04936",
    "authors": [
      "Bingxin Zhou",
      "Yuanhong Jiang",
      "Yu Guang Wang",
      "Jingwei Liang",
      "Junbin Gao",
      "Shirui Pan",
      "Xiaoqun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06159",
    "title": "Robust alignment of cross-session recordings of neural population  activity by behaviour via unsupervised domain adaptation",
    "abstract": " Title: Robust alignment of cross-session recordings of neural population  activity by behaviour via unsupervised domain adaptation ",
    "url": "https://arxiv.org/abs/2202.06159",
    "authors": [
      "Justin Jude",
      "Matthew G Perich",
      "Lee E Miller",
      "Matthias H Hennig"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06163",
    "title": "Evolving Neural Networks with Optimal Balance between Information Flow  and Connections Cost",
    "abstract": " Title: Evolving Neural Networks with Optimal Balance between Information Flow  and Connections Cost ",
    "url": "https://arxiv.org/abs/2202.06163",
    "authors": [
      "Abdullah Khalili",
      "Abdelhamid Bouchachia"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06382",
    "title": "Neural Network Trojans Analysis and Mitigation from the Input Domain",
    "abstract": " Title: Neural Network Trojans Analysis and Mitigation from the Input Domain ",
    "url": "https://arxiv.org/abs/2202.06382",
    "authors": [
      "Zhenting Wang",
      "Hailun Ding",
      "Juan Zhai",
      "Shiqing Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.06488",
    "title": "Finding Dynamics Preserving Adversarial Winning Tickets",
    "abstract": " Comments: Accepted by AISTATS2022 ",
    "url": "https://arxiv.org/abs/2202.06488",
    "authors": [
      "Xupeng Shi",
      "Pengfei Zheng",
      "A. Adam Ding",
      "Yuan Gao",
      "Weizhong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06539",
    "title": "Deduplicating Training Data Mitigates Privacy Risks in Language Models",
    "abstract": " Title: Deduplicating Training Data Mitigates Privacy Risks in Language Models ",
    "url": "https://arxiv.org/abs/2202.06539",
    "authors": [
      "Nikhil Kandpal",
      "Eric Wallace",
      "Colin Raffel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06558",
    "title": "SAUTE RL: Almost Surely Safe Reinforcement Learning Using State  Augmentation",
    "abstract": " Title: SAUTE RL: Almost Surely Safe Reinforcement Learning Using State  Augmentation ",
    "url": "https://arxiv.org/abs/2202.06558",
    "authors": [
      "Aivar Sootla",
      "Alexander I. Cowen-Rivers",
      "Taher Jafferjee",
      "Ziyan Wang",
      "David Mguni",
      "Jun Wang",
      "Haitham Bou-Ammar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.07170",
    "title": "Fairness Amidst Non-IID Graph Data: A Literature Review",
    "abstract": " Title: Fairness Amidst Non-IID Graph Data: A Literature Review ",
    "url": "https://arxiv.org/abs/2202.07170",
    "authors": [
      "Wenbin Zhang",
      "Jeremy C. Weiss",
      "Shuigeng Zhou",
      "Toby Walsh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.07179",
    "title": "G-Mixup: Graph Data Augmentation for Graph Classification",
    "abstract": " Title: G-Mixup: Graph Data Augmentation for Graph Classification ",
    "url": "https://arxiv.org/abs/2202.07179",
    "authors": [
      "Xiaotian Han",
      "Zhimeng Jiang",
      "Ninghao Liu",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.07230",
    "title": "Geometrically Equivariant Graph Neural Networks: A Survey",
    "abstract": " Comments: 8 pages ",
    "url": "https://arxiv.org/abs/2202.07230",
    "authors": [
      "Jiaqi Han",
      "Yu Rong",
      "Tingyang Xu",
      "Wenbing Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07261",
    "title": "Exploring the Devil in Graph Spectral Domain for 3D Point Cloud Attacks",
    "abstract": " Title: Exploring the Devil in Graph Spectral Domain for 3D Point Cloud Attacks ",
    "url": "https://arxiv.org/abs/2202.07261",
    "authors": [
      "Qianjiang Hu",
      "Daizong Liu",
      "Wei Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2202.07532",
    "title": "Closing the Management Gap for Satellite-Integrated Community Networks:  A Hierarchical Approach to Self-Maintenance",
    "abstract": " Title: Closing the Management Gap for Satellite-Integrated Community Networks:  A Hierarchical Approach to Self-Maintenance ",
    "url": "https://arxiv.org/abs/2202.07532",
    "authors": [
      "Peng Hu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07549",
    "title": "Robust Multi-Objective Bayesian Optimization Under Input Noise",
    "abstract": " Comments: 41 pages. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2202.07549",
    "authors": [
      "Samuel Daulton",
      "Sait Cakmak",
      "Maximilian Balandat",
      "Michael A. Osborne",
      "Enlu Zhou",
      "Eytan Bakshy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.07648",
    "title": "EvoKG: Jointly Modeling Event Time and Network Structure for Reasoning  over Temporal Knowledge Graphs",
    "abstract": " Comments: WSDM 2022 ",
    "url": "https://arxiv.org/abs/2202.07648",
    "authors": [
      "Namyong Park",
      "Fuchen Liu",
      "Purvanshi Mehta",
      "Dana Cristofor",
      "Christos Faloutsos",
      "Yuxiao Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  }
]