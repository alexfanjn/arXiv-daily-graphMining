[
  {
    "id": "arXiv:2202.01784",
    "title": "Robust Audio Anomaly Detection",
    "abstract": "We propose an outlier robust multivariate time series model which can be used for detecting previously unseen anomalous sounds based on noisy training data. The presented approach doesn't assume the presence of labeled anomalies in the training dataset and uses a novel deep neural network architecture to learn the temporal dynamics of the multivariate time series at multiple resolutions while being robust to contaminations in the training dataset. The temporal dynamics are modeled using recurrent layers augmented with attention mechanism. These recurrent layers are built on top of convolutional layers allowing the network to extract features at multiple resolutions. The output of the network is an outlier robust probability density function modeling the conditional probability of future samples given the time series history. State-of-the-art approaches using other multiresolution architectures are contrasted with our proposed approach. We validate our solution using publicly available machine sound datasets. We demonstrate the effectiveness of our approach in anomaly detection by comparing against several state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2202.01784",
    "authors": [
      "Wo Jae Lee",
      "Karim Helwani",
      "Arvindh Krishnaswamy",
      "Srikanth Tenneti"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2202.01806",
    "title": "Answering Count Queries for Genomic Data with Perfect Privacy",
    "abstract": "In this paper, we consider the problem of answering count queries for genomic data subject to perfect privacy constraints. Count queries are often used in applications that collect aggregate (population-wide) information from biomedical Databases (DBs) for analysis, such as Genome-wide association studies. Our goal is to design mechanisms for answering count queries of the following form: How many users in the database have a specific set of genotypes at certain locations in their genome? At the same time, we aim to achieve perfect privacy (zero information leakage) of the sensitive genotypes at a pre-specified set of secret locations. The sensitive genotypes could indicate rare diseases and/or other health traits that one may want to keep private. We present two local count-query mechanisms for the above problem that achieve perfect privacy for sensitive genotypes while minimizing the expected absolute error (or per-user error probability) of the query answer. We also derived a lower bound of the per-user probability of error for an arbitrary query answering mechanism that satisfies perfect privacy. We show that our mechanisms achieve error that is close to the lower bound, and are match the lower bound for some special cases. We numerically show that the performance of each mechanism depends on the data prior distribution, the intersection between the queried and sensitive data, and the strength of the correlation in the genomic data sequence. ",
    "url": "https://arxiv.org/abs/2202.01806",
    "authors": [
      "Bo Jiang",
      "Mohamed Seif",
      "Ravi Tandon",
      "Ming Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.01811",
    "title": "ObjectSeeker: Certifiably Robust Object Detection against Patch Hiding  Attacks via Patch-agnostic Masking",
    "abstract": "Object detectors, which are widely deployed in security-critical systems such as autonomous vehicles, have been found vulnerable to physical-world patch hiding attacks. The attacker can use a single physically-realizable adversarial patch to make the object detector miss the detection of victim objects and completely undermines the functionality of object detection applications. In this paper, we propose ObjectSeeker as a defense framework for building certifiably robust object detectors against patch hiding attacks. The core operation of ObjectSeeker is patch-agnostic masking: we aim to mask out the entire adversarial patch without any prior knowledge of the shape, size, and location of the patch. This masking operation neutralizes the adversarial effect and allows any vanilla object detector to safely detect objects on the masked images. Remarkably, we develop a certification procedure to determine if ObjectSeeker can detect certain objects with a provable guarantee against any adaptive attacker within the threat model. Our evaluation with two object detectors and three datasets demonstrates a significant (~10%-40% absolute and ~2-6x relative) improvement in certified robustness over the prior work, as well as high clean performance (~1% performance drop compared with vanilla undefended models). ",
    "url": "https://arxiv.org/abs/2202.01811",
    "authors": [
      "Chong Xiang",
      "Alexander Valtchanov",
      "Saeed Mahloujifar",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.01832",
    "title": "Adversarially Robust Models may not Transfer Better: Sufficient  Conditions for Domain Transferability from the View of Regularization",
    "abstract": "Machine learning (ML) robustness and domain generalization are fundamentally correlated: they essentially concern data distribution shifts under adversarial and natural settings, respectively. On one hand, recent studies show that more robust (adversarially trained) models are more generalizable. On the other hand, there is a lack of theoretical understanding of their fundamental connections. In this paper, we explore the relationship between regularization and domain transferability considering different factors such as norm regularization and data augmentations (DA). We propose a general theoretical framework proving that factors involving the model function class regularization are sufficient conditions for relative domain transferability. Our analysis implies that \"robustness\" is neither necessary nor sufficient for transferability; rather, robustness induced by adversarial training is a by-product of such function class regularization. We then discuss popular DA protocols and show when they can be viewed as the function class regularization under certain conditions and therefore improve generalization. We conduct extensive experiments to verify our theoretical findings and show several counterexamples where robustness and generalization are negatively correlated on different datasets. ",
    "url": "https://arxiv.org/abs/2202.01832",
    "authors": [
      "Xiaojun Xu",
      "Jacky Yibo Zhang",
      "Evelyn Ma",
      "Danny Son",
      "Oluwasanmi Koyejo",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01842",
    "title": "Distributed State Estimation with Deep Neural Networks for Uncertain  Nonlinear Systems under Event-Triggered Communication",
    "abstract": "Distributed state estimation is examined for a sensor network tasked with reconstructing a system's state through the use of a distributed and event-triggered observer. Each agent in the sensor network employs a deep neural network (DNN) to approximate the uncertain nonlinear dynamics of the system, which is trained using a multiple timescale approach. Specifically, the outer weights of each DNN are updated online using a Lyapunov-based gradient descent update law, while the inner weights and biases are trained offline using a supervised learning method and collected input-output data. The observer utilizes event-triggered communication to promote the efficient use of network resources. A nonsmooth Lyapunov analysis shows the distributed event-triggered observer has a uniformly ultimately bounded state reconstruction error. A simulation study is provided to validate the result and demonstrate the performance improvements afforded by the DNNs. ",
    "url": "https://arxiv.org/abs/2202.01842",
    "authors": [
      "Federico M. Zegers",
      "Runhan Sun",
      "Girish Chowdhary",
      "Warren E. Dixon"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.01855",
    "title": "Self-supervised Learning with Random-projection Quantizer for Speech  Recognition",
    "abstract": "We present a simple and effective self-supervised learning approach for speech recognition. The approach learns a model to predict the masked speech signals, in the form of discrete labels generated with a random-projection quantizer. In particular the quantizer projects speech inputs with a randomly initialized matrix, and does a nearest-neighbor lookup in a randomly-initialized codebook. Neither the matrix nor the codebook is updated during self-supervised learning. Since the random-projection quantizer is not trained and is separated from the speech recognition model, the design makes the approach flexible and is compatible with universal speech recognition architecture. On LibriSpeech our approach achieves similar word-error-rates as previous work using self-supervised learning with non-streaming models, and provides lower word-error-rates and latency than wav2vec 2.0 and w2v-BERT with streaming models. On multilingual tasks the approach also provides significant improvement over wav2vec 2.0 and w2v-BERT. ",
    "url": "https://arxiv.org/abs/2202.01855",
    "authors": [
      "Chung-Cheng Chiu",
      "James Qin",
      "Yu Zhang",
      "Jiahui Yu",
      "Yonghui Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2202.01871",
    "title": "A Bibliometric Perspective of Social Science Scientific Communities of  Pakistan and India",
    "abstract": "In this study, we use research publication data from the field of social science to identify collaboration networks among social science research communities of India and Pakistan. We have used Scopus database to extract information of social science journals for both countries India and Pakistan. Study of this data is significant as both countries have common social issues and many of common social values. Keywords analysis has been done to see common research areas in both communities like poverty, education, the issue of gender etc. Despite having many of the common social issues, collaboration among social science research communities of both countries is not strong. ",
    "url": "https://arxiv.org/abs/2202.01871",
    "authors": [
      "Sami Ul-Haq",
      "Saeed-Ul Hassan"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2202.01877",
    "title": "Stackelberg Strategic Guidance for Heterogeneous Robots Collaboration",
    "abstract": "In this study, we explore the application of game theory, in particular Stackelberg games, to address the issue of effective coordination strategy generation for heterogeneous robots with one-way communication. To that end, focusing on the task of multi-object rearrangement, we develop a theoretical and algorithmic framework that provides strategic guidance for a pair of robot arms, a leader and a follower where the leader has a model of the follower's decision-making process, through the computation of a feedback Stackelberg equilibrium. With built-in tolerance of model uncertainty, the strategic guidance generated by our planning algorithm not only improves the overall efficiency in solving the rearrangement tasks, but is also robust to common pitfalls in collaboration, e.g., chattering. ",
    "url": "https://arxiv.org/abs/2202.01877",
    "authors": [
      "Yuhan Zhao",
      "Baichuan Huang",
      "Jingjin Yu",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.01878",
    "title": "On the Benefit of Cooperation in Relay Networks",
    "abstract": "This work addresses the cooperation facilitator (CF) model, in which network nodes coordinate through a rate limited communication device. For independent multiple-access channel (MAC) encoders, the CF model is known to show significant rate benefits, even when the rate of cooperation is negligible. Specifically, the benefit in MAC sum-rate, as a function of the cooperation rate $C_{CF}$, sometimes has an infinite slope at $C_{CF}=0$. This work studies the question of whether cooperation through a CF can yield similar infinite-slope benefits when applied to internal network encoders in which dependence among MAC transmitters can be established without the help of the CF. Towards this end, this work studies the CF model when applied to relay nodes of a single-source, single-terminal, diamond network consisting of a broadcast channel followed by a MAC. In the relay channel with orthogonal receiver components, careful generalization of the partial-decode-forward/compress-forward lower bound to the CF model yields sufficient conditions for an infinite-slope benefit. Additional results include derivation of a family of diamond networks for which the infinite-slope rate-benefit derives directly from the properties of the corresponding MAC component when studied in isolation. ",
    "url": "https://arxiv.org/abs/2202.01878",
    "authors": [
      "Oliver Kosut",
      "Michelle Effros",
      "Michael Langberg"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.01884",
    "title": "Research on Patch Attentive Neural Process",
    "abstract": "Attentive Neural Process (ANP) improves the fitting ability of Neural Process (NP) and improves its prediction accuracy, but the higher time complexity of the model imposes a limitation on the length of the input sequence. Inspired by models such as Vision Transformer (ViT) and Masked Auto-Encoder (MAE), we propose Patch Attentive Neural Process (PANP) using image patches as input and improve the structure of deterministic paths based on ANP, which allows the model to extract image features more accurately and efficiently reconstruction. ",
    "url": "https://arxiv.org/abs/2202.01884",
    "authors": [
      "Xiaohan Yu",
      "Shaochen Mao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.01907",
    "title": "Unified Fake News Detection using Transfer Learning of Bidirectional  Encoder Representation from Transformers model",
    "abstract": "Automatic detection of fake news is needed for the public as the accessibility of social media platforms has been increasing rapidly. Most of the prior models were designed and validated on individual datasets separately. But the lack of generalization in models might lead to poor performance when deployed in real-world applications since the individual datasets only cover limited subjects and sequence length over the samples. This paper attempts to develop a unified model by combining publicly available datasets to detect fake news samples effectively. ",
    "url": "https://arxiv.org/abs/2202.01907",
    "authors": [
      "Vijay Srinivas Tida",
      "Dr. Sonya Hsu",
      "Dr. Xiali Hei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01919",
    "title": "Theoretical Exploration of Solutions of Feedforward ReLU networks",
    "abstract": "This paper aims to interpret the mechanism of feedforward ReLU networks by exploring their solutions for piecewise linear functions through basic rules. The constructed solutions should be universal enough to explain the network architectures of engineering. In order for that, we borrow the methodology of theoretical physics to develop the theories. Some of the consequences of our theories include: Under geometric backgrounds, the solutions of both three-layer networks and deep-layer networks are presented, and the solution universality is ensured by several ways; We give clear and intuitive interpretations of each component of network architectures, such as the parameter-sharing mechanism for multi-output, the function of each layer, the advantage of deep layers, the redundancy of parameters, and so on. We explain three typical network architectures: the subnetwork of last three layers of convolutional networks, multi-layer feedforward networks, and the decoder of autoencoders. This paper is expected to provide a basic foundation of theories of feedforward ReLU networks for further investigations. ",
    "url": "https://arxiv.org/abs/2202.01919",
    "authors": [
      "Changcun Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.01934",
    "title": "Smartphone-based Hard-braking Event Detection at Scale for Road Safety  Services",
    "abstract": "Road crashes are the sixth leading cause of lost disability-adjusted life-years (DALYs) worldwide. One major challenge in traffic safety research is the sparsity of crashes, which makes it difficult to achieve a fine-grain understanding of crash causations and predict future crash risk in a timely manner. Hard-braking events have been widely used as a safety surrogate due to their relatively high prevalence and ease of detection with embedded vehicle sensors. As an alternative to using sensors fixed in vehicles, this paper presents a scalable approach for detecting hard-braking events using the kinematics data collected from smartphone sensors. We train a Transformer-based machine learning model for hard-braking event detection using concurrent sensor readings from smartphones and vehicle sensors from drivers who connect their phone to the vehicle while navigating in Google Maps. The detection model shows superior performance with a $0.83$ Area under the Precision-Recall Curve (PR-AUC), which is $3.8\\times$better than a GPS speed-based heuristic model, and $166.6\\times$better than an accelerometer-based heuristic model. The detected hard-braking events are strongly correlated with crashes from publicly available datasets, supporting their use as a safety surrogate. In addition, we conduct model fairness and selection bias evaluation to ensure that the safety benefits are equally shared. The developed methodology can benefit many safety applications such as identifying safety hot spots at road network level, evaluating the safety of new user interfaces, as well as using routing to improve traffic safety. ",
    "url": "https://arxiv.org/abs/2202.01934",
    "authors": [
      "Luyang Liu",
      "David Racz",
      "Kara Vaillancourt",
      "Julie Michelman",
      "Matt Barnes",
      "Stefan Mellem",
      "Paul Eastham",
      "Bradley Green",
      "Charles Armstrong",
      "Rishi Bal",
      "Shawn O'Banion",
      "Feng Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01935",
    "title": "Robust Dynamic State Estimator of Integrated Energy Systems based on  Natural Gas Partial Differential Equations",
    "abstract": "The reliability and precision of dynamic database are vital for the optimal operating and global control of integrated energy systems. One of the effective ways to obtain the accurate states is state estimations. A novel robust dynamic state estimation methodology for integrated natural gas and electric power systems is proposed based on Kalman filter. To take full advantage of measurement redundancies and predictions for enhancing the estimating accuracy, the dynamic state estimation model coupling gas and power systems by gas turbine units is established. The exponential smoothing technique and gas physical model are integrated in Kalman filter. Additionally, the time-varying scalar matrix is proposed to conquer bad data in Kalman filter algorithm. The proposed method is applied to an integrated gas and power systems formed by GasLib-40 and IEEE 39-bus system with five gas turbine units. The simulating results show that the method can obtain the accurate dynamic states under three different measurement error conditions, and the filtering performance are better than separate estimation methods. Additionally, the proposed method is robust when the measurements experience bad data. ",
    "url": "https://arxiv.org/abs/2202.01935",
    "authors": [
      "Liang Chen",
      "Yang Li",
      "Manyun Huang",
      "Xinxin Hui",
      "Songlin Gu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.01943",
    "title": "PSO-PINN: Physics-Informed Neural Networks Trained with Particle Swarm  Optimization",
    "abstract": "Physics-informed neural networks (PINNs) have recently emerged as a promising application of deep learning in a wide range of engineering and scientific problems based on partial differential equation models. However, evidence shows that PINN training by gradient descent displays pathologies and stiffness in gradient flow dynamics. In this paper, we propose the use of a hybrid particle swarm optimization and gradient descent approach to train PINNs. The resulting PSO-PINN algorithm not only mitigates the undesired behaviors of PINNs trained with standard gradient descent, but also presents an ensemble approach to PINN that affords the possibility of robust predictions with quantified uncertainty. Experimental results using the Poisson, advection, and Burgers equations show that PSO-PINN consistently outperforms a baseline PINN trained with Adam gradient descent. ",
    "url": "https://arxiv.org/abs/2202.01943",
    "authors": [
      "Caio Davi",
      "Ulisses Braga-Neto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2202.01944",
    "title": "Learning Representation from Neural Fisher Kernel with Low-rank  Approximation",
    "abstract": "In this paper, we study the representation of neural networks from the view of kernels. We first define the Neural Fisher Kernel (NFK), which is the Fisher Kernel applied to neural networks. We show that NFK can be computed for both supervised and unsupervised learning models, which can serve as a unified tool for representation extraction. Furthermore, we show that practical NFKs exhibit low-rank structures. We then propose an efficient algorithm that computes a low rank approximation of NFK, which scales to large datasets and networks. We show that the low-rank approximation of NFKs derived from unsupervised generative models and supervised learning models gives rise to high-quality compact representations of data, achieving competitive results on a variety of machine learning tasks. ",
    "url": "https://arxiv.org/abs/2202.01944",
    "authors": [
      "Ruixiang Zhang",
      "Shuangfei Zhai",
      "Etai Littwin",
      "Josh Susskind"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01966",
    "title": "Predictive Closed-Loop Service Automation in O-RAN based Network Slicing",
    "abstract": "Network slicing provides introduces customized and agile network deployment for managing different service types for various verticals under the same infrastructure. To cater to the dynamic service requirements of these verticals and meet the required quality-of-service (QoS) mentioned in the service-level agreement (SLA), network slices need to be isolated through dedicated elements and resources. Additionally, allocated resources to these slices need to be continuously monitored and intelligently managed. This enables immediate detection and correction of any SLA violation to support automated service assurance in a closed-loop fashion. By reducing human intervention, intelligent and closed-loop resource management reduces the cost of offering flexible services. Resource management in a network shared among verticals (potentially administered by different providers), would be further facilitated through open and standardized interfaces. Open radio access network (O-RAN) is perhaps the most promising RAN architecture that inherits all the aforementioned features, namely intelligence, open and standard interfaces, and closed control loop. Inspired by this, in this article we provide a closed-loop and intelligent resource provisioning scheme for O-RAN slicing to prevent SLA violations. In order to maintain realism, a real-world dataset of a large operator is used to train a learning solution for optimizing resource utilization in the proposed closed-loop service automation process. Moreover, the deployment architecture and the corresponding flow that are cognizant of the O-RAN requirements are also discussed. ",
    "url": "https://arxiv.org/abs/2202.01966",
    "authors": [
      "Joseph Thaliath",
      "Solmaz Niknam",
      "Sukhdeep Singh",
      "Rahul Banerji",
      "Navrati Saxena",
      "Harpreet S. Dhillon",
      "Jeffrey H. Reed",
      "Ali Kashif Bashir",
      "Avinash Bhat",
      "Abhishek Roy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.01972",
    "title": "Hybrid Neural Coded Modulation: Design and Training Methods",
    "abstract": "We propose a hybrid coded modulation scheme which composes of inner and outer codes. The outer-code can be any standard binary linear code with efficient soft decoding capability (e.g. low-density parity-check (LDPC) codes). The inner code is designed using a deep neural network (DNN) which takes the channel coded bits and outputs modulated symbols. For training the DNN, we propose to use a loss function that is inspired by the generalized mutual information. The resulting constellations are shown to outperform the conventional quadrature amplitude modulation (QAM) based coding scheme for modulation order 16 and 64 with 5G standard LDPC codes. ",
    "url": "https://arxiv.org/abs/2202.01972",
    "authors": [
      "Sung Hoon Lim",
      "Jiyong Han",
      "Wonjong Noh",
      "Yujae Song",
      "Sang-Woon Jeon"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01980",
    "title": "Multi-Output Gaussian Process-Based Data Augmentation for Multi-Building  and Multi-Floor Indoor Localization",
    "abstract": "Location fingerprinting based on RSSI becomes a mainstream indoor localization technique due to its advantage of not requiring the installation of new infrastructure and the modification of existing devices, especially given the prevalence of Wi-Fi-enabled devices and the ubiquitous Wi-Fi access in modern buildings. The use of AI/ML technologies like DNNs makes location fingerprinting more accurate and reliable, especially for large-scale multi-building and multi-floor indoor localization. The application of DNNs for indoor localization, however, depends on a large amount of preprocessed and deliberately-labeled data for their training. Considering the difficulty of the data collection in an indoor environment, especially under the current epidemic situation of COVID-19, we investigate three different methods of RSSI data augmentation based on Multi-Output Gaussian Process (MOGP), i.e., by a single floor, by neighboring floors, and by a single building; unlike Single-Output Gaussian Process (SOGP), MOGP can take into account the correlation among RSSI observations from multiple Access Points (APs) deployed closely to each other (e.g., APs on the same floor of a building) by collectively handling them. The feasibility of the MOGP-based RSSI data augmentation is demonstrated through experiments based on the state-of-the-art RNN indoor localization model and the UJIIndoorLoc, i.e., the most popular publicly-available multi-building and multi-floor indoor localization database, where the RNN model trained with the UJIIndoorLoc database augmented by using the whole RSSI data of a building in fitting an MOGP model (i.e., by a single building) outperforms the other two augmentation methods as well as the RNN model trained with the original UJIIndoorLoc database, resulting in the mean three-dimensional positioning error of 8.42 m. ",
    "url": "https://arxiv.org/abs/2202.01980",
    "authors": [
      "Zhe Tang",
      "Sihao Li",
      "Kyeong Soo Kim",
      "Jeremy Smith"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.01987",
    "title": "Robust Vector Quantized-Variational Autoencoder",
    "abstract": "Image generative models can learn the distributions of the training data and consequently generate examples by sampling from these distributions. However, when the training dataset is corrupted with outliers, generative models will likely produce examples that are also similar to the outliers. In fact, a small portion of outliers may induce state-of-the-art generative models, such as Vector Quantized-Variational AutoEncoder (VQ-VAE), to learn a significant mode from the outliers. To mitigate this problem, we propose a robust generative model based on VQ-VAE, which we name Robust VQ-VAE (RVQ-VAE). In order to achieve robustness, RVQ-VAE uses two separate codebooks for the inliers and outliers. To ensure the codebooks embed the correct components, we iteratively update the sets of inliers and outliers during each training epoch. To ensure that the encoded data points are matched to the correct codebooks, we quantize using a weighted Euclidean distance, whose weights are determined by directional variances of the codebooks. Both codebooks, together with the encoder and decoder, are trained jointly according to the reconstruction loss and the quantization loss. We experimentally demonstrate that RVQ-VAE is able to generate examples from inliers even if a large portion of the training data points are corrupted. ",
    "url": "https://arxiv.org/abs/2202.01987",
    "authors": [
      "Chieh-Hsin Lai",
      "Dongmian Zou",
      "Gilad Lerman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.01999",
    "title": "Neural Dual Contouring",
    "abstract": "We introduce neural dual contouring (NDC), a new data-driven approach to mesh reconstruction based on dual contouring (DC). Like traditional DC, it produces exactly one vertex per grid cell and one quad for each grid edge intersection, a natural and efficient structure for reproducing sharp features. However, rather than computing vertex locations and edge crossings with hand-crafted functions that depend directly on difficult-to-obtain surface gradients, NDC uses a neural network to predict them. As a result, NDC can be trained to produce meshes from signed or unsigned distance fields, binary voxel grids, or point clouds (with or without normals); and it can produce open surfaces in cases where the input represents a sheet or partial surface. During experiments with five prominent datasets, we find that NDC, when trained on one of the datasets, generalizes well to the others. Furthermore, NDC provides better surface reconstruction accuracy, feature preservation, output complexity, triangle quality, and inference time in comparison to previous learned (e.g., neural marching cubes, convolutional occupancy networks) and traditional (e.g., Poisson) methods. ",
    "url": "https://arxiv.org/abs/2202.01999",
    "authors": [
      "Zhiqin Chen",
      "Andrea Tagliasacchi",
      "Thomas Funkhouser",
      "Hao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02003",
    "title": "Capturing and incorporating expert knowledge into machine learning  models for quality prediction in manufacturing",
    "abstract": "Increasing digitalization enables the use of machine learning methods for analyzing and optimizing manufacturing processes. A main application of machine learning is the construction of quality prediction models, which can be used, among other things, for documentation purposes, as assistance systems for process operators, or for adaptive process control. The quality of such machine learning models typically strongly depends on the amount and the quality of data used for training. In manufacturing, the size of available datasets before start of production is often limited. In contrast to data, expert knowledge commonly is available in manufacturing. Therefore, this study introduces a general methodology for building quality prediction models with machine learning methods on small datasets by integrating shape expert knowledge, that is, prior knowledge about the shape of the input-output relationship to be learned. The proposed methodology is applied to a brushing process with $125$ data points for predicting the surface roughness as a function of five process variables. As opposed to conventional machine learning methods for small datasets, the proposed methodology produces prediction models that strictly comply with all the expert knowledge specified by the involved process specialists. In particular, the direct involvement of process experts in the training of the models leads to a very clear interpretation and, by extension, to a high acceptance of the models. Another merit of the proposed methodology is that, in contrast to most conventional machine learning methods, it involves no time-consuming and often heuristic hyperparameter tuning or model selection step. ",
    "url": "https://arxiv.org/abs/2202.02003",
    "authors": [
      "Patrick Link",
      "Miltiadis Poursanidis",
      "Jochen Schmid",
      "Rebekka Zache",
      "Martin von Kurnatowski",
      "Uwe Teicher",
      "Steffen Ihlenfeldt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02006",
    "title": "5G Network on Wings: A Deep Reinforcement Learning Approach to UAV-based  Integrated Access and Backhaul",
    "abstract": "Fast and reliable wireless communication has become a critical demand in human life. When natural disasters strike, providing ubiquitous connectivity becomes challenging by using traditional wireless networks. In this context, unmanned aerial vehicle (UAV) based aerial networks offer a promising alternative for fast, flexible, and reliable wireless communications in mission-critical (MC) scenarios. Due to the unique characteristics such as mobility, flexible deployment, and rapid reconfiguration, drones can readily change location dynamically to provide on-demand communications to users on the ground in emergency scenarios. As a result, the usage of UAV base stations (UAV-BSs) has been considered as an appropriate approach for providing rapid connection in MC scenarios. In this paper, we study how to control a UAV-BS in both static and dynamic environments. We investigate a situation in which a macro BS is destroyed as a result of a natural disaster and a UAV-BS is deployed using integrated access and backhaul (IAB) technology to provide coverage for users in the disaster area. We present a data collection system, signaling procedures and machine learning applications for this use case. A deep reinforcement learning algorithm is developed to jointly optimize the tilt of the access and backhaul antennas of the UAV-BS as well as its three-dimensional placement. Evaluation results show that the proposed algorithm can autonomously navigate and configure the UAV-BS to satisfactorily serve the MC users on the ground. ",
    "url": "https://arxiv.org/abs/2202.02006",
    "authors": [
      "Hongyi Zhang",
      "Jingya Li",
      "Zhiqiang Qi",
      "Xingqin Lin",
      "Anders Aronsson",
      "Jan Bosch",
      "Helena Holmstr\u00f6m Olsson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02013",
    "title": "A Benchmark Corpus for the Detection of Automatically Generated Text in  Academic Publications",
    "abstract": "Automatic text generation based on neural language models has achieved performance levels that make the generated text almost indistinguishable from those written by humans. Despite the value that text generation can have in various applications, it can also be employed for malicious tasks. The diffusion of such practices represent a threat to the quality of academic publishing. To address these problems, we propose in this paper two datasets comprised of artificially generated research content: a completely synthetic dataset and a partial text substitution dataset. In the first case, the content is completely generated by the GPT-2 model after a short prompt extracted from original papers. The partial or hybrid dataset is created by replacing several sentences of abstracts with sentences that are generated by the Arxiv-NLP model. We evaluate the quality of the datasets comparing the generated texts to aligned original texts using fluency metrics such as BLEU and ROUGE. The more natural the artificial texts seem, the more difficult they are to detect and the better is the benchmark. We also evaluate the difficulty of the task of distinguishing original from generated text by using state-of-the-art classification models. ",
    "url": "https://arxiv.org/abs/2202.02013",
    "authors": [
      "Vijini Liyanage",
      "Davide Buscaldi",
      "Adeline Nazarenko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.02015",
    "title": "Energy-Efficient High-Accuracy Spiking Neural Network Inference Using  Time-Domain Neurons",
    "abstract": "Due to the limitations of realizing artificial neural networks on prevalent von Neumann architectures, recent studies have presented neuromorphic systems based on spiking neural networks (SNNs) to reduce power and computational cost. However, conventional analog voltage-domain integrate-and-fire (I&F) neuron circuits, based on either current mirrors or op-amps, pose serious issues such as nonlinearity or high power consumption, thereby degrading either inference accuracy or energy efficiency of the SNN. To achieve excellent energy efficiency and high accuracy simultaneously, this paper presents a low-power highly linear time-domain I&F neuron circuit. Designed and simulated in a 28nm CMOS process, the proposed neuron leads to more than 4.3x lower error rate on the MNIST inference over the conventional current-mirror-based neurons. In addition, the power consumed by the proposed neuron circuit is simulated to be 0.230uW per neuron, which is orders of magnitude lower than the existing voltage-domain neurons. ",
    "url": "https://arxiv.org/abs/2202.02015",
    "authors": [
      "Joonghyun Song",
      "Jiwon Shin",
      "Hanseok Kim",
      "Woo-Seok Choi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.02063",
    "title": "Color Image Inpainting via Robust Pure Quaternion Matrix Completion:  Error Bound and Weighted Loss",
    "abstract": "In this paper, we study color image inpainting as a pure quaternion matrix completion problem. In the literature, the theoretical guarantee for quaternion matrix completion is not well-established. Our main aim is to propose a new minimization problem with an objective combining nuclear norm and a quadratic loss weighted among three channels. To fill the theoretical vacancy, we obtain the error bound in both clean and corrupted regimes, which relies on some new results of quaternion matrices. A general Gaussian noise is considered in robust completion where all observations are corrupted. Motivated by the error bound, we propose to handle unbalanced or correlated noise via a cross-channel weight in the quadratic loss, with the main purpose of rebalancing noise level, or removing noise correlation. Extensive experimental results on synthetic and color image data are presented to confirm and demonstrate our theoretical findings. ",
    "url": "https://arxiv.org/abs/2202.02063",
    "authors": [
      "Junren Chen",
      "Michael K. Ng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2202.02074",
    "title": "Urban Region Profiling via A Multi-Graph Representation Learning  Framework",
    "abstract": "Urban region profiling can benefit urban analytics. Although existing studies have made great efforts to learn urban region representation from multi-source urban data, there are still three limitations: (1) Most related methods focused merely on global-level inter-region relations while overlooking local-level geographical contextual signals and intra-region information; (2) Most previous works failed to develop an effective yet integrated fusion module which can deeply fuse multi-graph correlations; (3) State-of-the-art methods do not perform well in regions with high variance socioeconomic attributes. To address these challenges, we propose a multi-graph representative learning framework, called Region2Vec, for urban region profiling. Specifically, except that human mobility is encoded for inter-region relations, geographic neighborhood is introduced for capturing geographical contextual information while POI side information is adopted for representing intra-region information by knowledge graph. Then, graphs are used to capture accessibility, vicinity, and functionality correlations among regions. To consider the discriminative properties of multiple graphs, an encoder-decoder multi-graph fusion module is further proposed to jointly learn comprehensive representations. Experiments on real-world datasets show that Region2Vec can be employed in three applications and outperforms all state-of-the-art baselines. Particularly, Region2Vec has better performance than previous studies in regions with high variance socioeconomic attributes. ",
    "url": "https://arxiv.org/abs/2202.02074",
    "authors": [
      "Y. Luo",
      "F. Chung",
      "K. Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02078",
    "title": "Heed the Noise in Performance Evaluations in Neural Architecture Search",
    "abstract": "Neural Architecture Search (NAS) has recently become a topic of great interest. However, there is a potentially impactful issue within NAS that remains largely unrecognized: noise. Due to stochastic factors in neural network initialization, training, and the chosen train/validation dataset split, the performance evaluation of a neural network architecture, which is often based on a single learning run, is also stochastic. This may have a particularly large impact if a dataset is small. We therefore propose to reduce the noise by having architecture evaluations comprise averaging of scores over multiple network training runs using different random seeds and cross-validation. We perform experiments for a combinatorial optimization formulation of NAS in which we vary noise reduction levels. We use the same computational budget for each noise level in terms of network training runs, i.e., we allow less architecture evaluations when averaging over more training runs. Multiple search algorithms are considered, including evolutionary algorithms which generally perform well for NAS. We use two publicly available datasets from the medical image segmentation domain where datasets are often limited and variability among samples is often high. Our results show that reducing noise in architecture evaluations enables finding better architectures by all considered search algorithms. ",
    "url": "https://arxiv.org/abs/2202.02078",
    "authors": [
      "Arkadiy Dushatskiy",
      "Tanja Alderliesten",
      "Peter A. N. Bosman"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2202.02080",
    "title": "Robust Linear Regression for General Feature Distribution",
    "abstract": "We investigate robust linear regression where data may be contaminated by an oblivious adversary, i.e., an adversary than may know the data distribution but is otherwise oblivious to the realizations of the data samples. This model has been previously analyzed under strong assumptions. Concretely, $\\textbf{(i)}$ all previous works assume that the covariance matrix of the features is positive definite; and $\\textbf{(ii)}$ most of them assume that the features are centered (i.e. zero mean). Additionally, all previous works make additional restrictive assumption, e.g., assuming that the features are Gaussian or that the corruptions are symmetrically distributed. In this work we go beyond these assumptions and investigate robust regression under a more general set of assumptions: $\\textbf{(i)}$ we allow the covariance matrix to be either positive definite or positive semi definite, $\\textbf{(ii)}$ we do not necessarily assume that the features are centered, $\\textbf{(iii)}$ we make no further assumption beyond boundedness (sub-Gaussianity) of features and measurement noise. Under these assumption we analyze a natural SGD variant for this problem and show that it enjoys a fast convergence rate when the covariance matrix is positive definite. In the positive semi definite case we show that there are two regimes: if the features are centered we can obtain a standard convergence rate; otherwise the adversary can cause any learner to fail arbitrarily. ",
    "url": "https://arxiv.org/abs/2202.02080",
    "authors": [
      "Tom Norman",
      "Nir Weinberger",
      "Kfir Y. Levy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02086",
    "title": "About Code Equivalence -- a Geometric Approach",
    "abstract": "The equivalence test is a main part in any classification problem. It helps to prove bounds for the main parameters of the considered combinatorial structures and to study their properties. In this paper, we present algorithms for equivalence of linear codes, based on their relation to multisets of points in a projective geometry. ",
    "url": "https://arxiv.org/abs/2202.02086",
    "authors": [
      "Iliya Bouyukliev",
      "Stefka Bouyuklieva"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2202.02095",
    "title": "Fixed-Point Code Synthesis For Neural Networks",
    "abstract": "Over the last few years, neural networks have started penetrating safety critical systems to take decisions in robots, rockets, autonomous driving car, etc. A problem is that these critical systems often have limited computing resources. Often, they use the fixed-point arithmetic for its many advantages (rapidity, compatibility with small memory devices.) In this article, a new technique is introduced to tune the formats (precision) of already trained neural networks using fixed-point arithmetic, which can be implemented using integer operations only. The new optimized neural network computes the output with fixed-point numbers without modifying the accuracy up to a threshold fixed by the user. A fixed-point code is synthesized for the new optimized neural network ensuring the respect of the threshold for any input vector belonging the range [xmin, xmax] determined during the analysis. From a technical point of view, we do a preliminary analysis of our floating neural network to determine the worst cases, then we generate a system of linear constraints among integer variables that we can solve by linear programming. The solution of this system is the new fixed-point format of each neuron. The experimental results obtained show the efficiency of our method which can ensure that the new fixed-point neural network has the same behavior as the initial floating-point neural network. ",
    "url": "https://arxiv.org/abs/2202.02095",
    "authors": [
      "Hanane Benmaghnia",
      "Matthieu Martel",
      "Yassamine Seladji"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02107",
    "title": "Implementation of a Type-2 Fuzzy Logic Based Prediction System for the  Nigerian Stock Exchange",
    "abstract": "Stock Market can be easily seen as one of the most attractive places for investors, but it is also very complex in terms of making trading decisions. Predicting the market is a risky venture because of the uncertainties and nonlinear nature of the market. Deciding on the right time to trade is key to every successful trader as it can lead to either a huge gain of money or totally a loss in investment that will be recorded as a careless trade. The aim of this research is to develop a prediction system for stock market using Fuzzy Logic Type2 which will handle these uncertainties and complexities of human behaviour in general when it comes to buy, hold or sell decision making in stock trading. The proposed system was developed using VB.NET programming language as frontend and Microsoft SQL Server as backend. A total of four different technical indicators were selected for this research. The selected indicators are the Relative Strength Index, William Average, Moving Average Convergence and Divergence, and Stochastic Oscillator. These indicators serve as input variable to the Fuzzy System. The MACD and SO are deployed as primary indicators, while the RSI and WA are used as secondary indicators. Fibonacci retracement ratio was adopted for the secondary indicators to determine their support and resistance level in terms of making trading decisions. The input variables to the Fuzzy System is fuzzified to Low, Medium, and High using the Triangular and Gaussian Membership Function. The Mamdani Type Fuzzy Inference rules were used for combining the trading rules for each input variable to the fuzzy system. The developed system was tested using sample data collected from ten different companies listed on the Nigerian Stock Exchange for a total of fifty two periods. The dataset collected are Opening, High, Low, and Closing prices of each security. ",
    "url": "https://arxiv.org/abs/2202.02107",
    "authors": [
      "Isobo Nelson Davies",
      "Donald Ene",
      "Ibiere Boma Cookey",
      "Godwin Fred Lenu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2202.02110",
    "title": "New Inner and Outer Bounds for 2-User Gaussian Broadcast Channels with  Heterogeneous Blocklength Constraints",
    "abstract": "We investigate both a novel inner and outer bound on the rate region of a 2-user Gaussian broadcast channel with finite, heterogeneous blocklength constraints (HB-GBC). In particular, we introduce a new, modified Sato-type outer bound that can be applied in the finite blocklength regime and does not require the same marginal property. We then develop and analyze concatenated shell codes, which are suitable for the HB-GBC. Especially, to achieve a smaller decoding latency for the user with shorter blocklength constraint when successive interference cancellation is used, we derive the number of symbols needed to successfully early decode the other user's message. We numerically compare our derived outer bound to the best known achievable rate regions. Numerical results show that the new early decoding performance is significantly improved compared to the state of the art, and performs very close to the asymptotic limit. ",
    "url": "https://arxiv.org/abs/2202.02110",
    "authors": [
      "Marcel Mross",
      "Pin-Hsun Lin",
      "Eduard A. Jorswieck"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.02112",
    "title": "Musical Audio Similarity with Self-supervised Convolutional Neural  Networks",
    "abstract": "We have built a music similarity search engine that lets video producers search by listenable music excerpts, as a complement to traditional full-text search. Our system suggests similar sounding track segments in a large music catalog by training a self-supervised convolutional neural network with triplet loss terms and musical transformations. Semi-structured user interviews demonstrate that we can successfully impress professional video producers with the quality of the search experience, and perceived similarities to query tracks averaged 7.8/10 in user testing. We believe this search tool will make for a more natural search experience that is easier to find music to soundtrack videos with. ",
    "url": "https://arxiv.org/abs/2202.02112",
    "authors": [
      "Carl Thom\u00e9",
      "Sebastian Piwell",
      "Oscar Utterb\u00e4ck"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2202.02113",
    "title": "From Discrimination to Generation: Knowledge Graph Completion with  Generative Transformer",
    "abstract": "Knowledge graph completion aims to address the problem of extending a KG with missing triples. In this paper, we provide an approach GenKGC, which converts knowledge graph completion to sequence-to-sequence generation task with the pre-trained language model. We further introduce relation-guided demonstration and entity-aware hierarchical decoding for better representation learning and fast inference. Experimental results on three datasets show that our approach can obtain better or comparable performance than baselines and achieve faster inference speed compared with previous methods with pre-trained language models. We also release a new large-scale Chinese knowledge graph dataset AliopenKG500 for research purpose. Code and datasets are available in https://github.com/zjunlp/PromptKGC/tree/main/GenKGC. ",
    "url": "https://arxiv.org/abs/2202.02113",
    "authors": [
      "Xin Xie",
      "Ningyu Zhang",
      "Zhoubo Li",
      "Shumin Deng",
      "Hui Chen",
      "Feiyu Xiong",
      "Mosha Chen",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.02115",
    "title": "Polyphonic pitch detection with convolutional recurrent neural networks",
    "abstract": "Recent directions in automatic speech recognition (ASR) research have shown that applying deep learning models from image recognition challenges in computer vision is beneficial. As automatic music transcription (AMT) is superficially similar to ASR, in the sense that methods often rely on transforming spectrograms to symbolic sequences of events (e.g. words or notes), deep learning should benefit AMT as well. In this work, we outline an online polyphonic pitch detection system that streams audio to MIDI by ConvLSTMs. Our system achieves state-of-the-art results on the 2007 MIREX multi-F0 development set, with an F-measure of 83\\% on the bassoon, clarinet, flute, horn and oboe ensemble recording without requiring any musical language modelling or assumptions of instrument timbre. ",
    "url": "https://arxiv.org/abs/2202.02115",
    "authors": [
      "Carl Thom\u00e9",
      "Sven Ahlb\u00e4ck"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2202.02139",
    "title": "Multi Objective Resource Optimization of Wireless Network Based on Cross  Domain Virtual Network Embedding",
    "abstract": "The rapid development of virtual network architecture makes it possible for wireless network to be widely used. With the popularity of artificial intelligence (AI) industry in daily life, efficient resource allocation of wireless network has become a problem. Especially when network users request wireless network resources from different management domains, they still face many practical problems. From the perspective of virtual network embedding (VNE), this paper designs and implements a multi-objective optimization VNE algorithm for wireless network resource allocation. Resource allocation in virtual network is essentially a problem of allocating underlying resources for virtual network requests (VNRs). According to the proposed objective formula, we consider the optimization mapping cost, network delay and VNR acceptance rate. VNE is completed by node mapping and link mapping. In the experiment and simulation stage, it is compared with other VNE algorithms, the cross domain VNE algorithm proposed in this paper is optimal in the above three indicators. This shows the effectiveness of the algorithm in wireless network resource allocation. ",
    "url": "https://arxiv.org/abs/2202.02139",
    "authors": [
      "Chao Wang",
      "Tao Dong",
      "Youxiang Duan",
      "Qifeng Sun",
      "Peiying Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02140",
    "title": "Dynamic Virtual Network Embedding Algorithm based on Graph Convolution  Neural Network and Reinforcement Learning",
    "abstract": "Network virtualization (NV) is a technology with broad application prospects. Virtual network embedding (VNE) is the core orientation of VN, which aims to provide more flexible underlying physical resource allocation for user function requests. The classical VNE problem is usually solved by heuristic method, but this method often limits the flexibility of the algorithm and ignores the time limit. In addition, the partition autonomy of physical domain and the dynamic characteristics of virtual network request (VNR) also increase the difficulty of VNE. This paper proposed a new type of VNE algorithm, which applied reinforcement learning (RL) and graph neural network (GNN) theory to the algorithm, especially the combination of graph convolutional neural network (GCNN) and RL algorithm. Based on a self-defined fitness matrix and fitness value, we set up the objective function of the algorithm implementation, realized an efficient dynamic VNE algorithm, and effectively reduced the degree of resource fragmentation. Finally, we used comparison algorithms to evaluate the proposed method. Simulation experiments verified that the dynamic VNE algorithm based on RL and GCNN has good basic VNE characteristics. By changing the resource attributes of physical network and virtual network, it can be proved that the algorithm has good flexibility. ",
    "url": "https://arxiv.org/abs/2202.02140",
    "authors": [
      "Peiying Zhang",
      "Chao Wang",
      "Neeraj Kumar",
      "Weishan Zhang",
      "Lei Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02141",
    "title": "Incorporating Distributed DRL into Storage Resource Optimization of  Space-Air-Ground Integrated Wireless Communication Network",
    "abstract": "Space-air-ground integrated network (SAGIN) is a new type of wireless network mode. The effective management of SAGIN resources is a prerequisite for high-reliability communication. However, the storage capacity of space-air network segment is extremely limited. The air servers also do not have sufficient storage resources to centrally accommodate the information uploaded by each edge server. So the problem of how to coordinate the storage resources of SAGIN has arisen. This paper proposes a SAGIN storage resource management algorithm based on distributed deep reinforcement learning (DRL). The resource management process is modeled as a Markov decision model. In each edge physical domain, we extract the network attributes represented by storage resources for the agent to build a training environment, so as to realize the distributed training. In addition, we propose a SAGIN resource management framework based on distributed DRL. Simulation results show that the agent has an ideal training effect. Compared with other algorithms, the resource allocation revenue and user request acceptance rate of the proposed algorithm are increased by about 18.15\\% and 8.35\\% respectively. Besides, the proposed algorithm has good flexibility in dealing with the changes of resource conditions. ",
    "url": "https://arxiv.org/abs/2202.02141",
    "authors": [
      "Chao Wang",
      "Lei Liu",
      "Chunxiao Jiang",
      "Shangguang Wang",
      "Peiying Zhang",
      "Shigen Shen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2202.02142",
    "title": "Deep invariant networks with differentiable augmentation layers",
    "abstract": "Designing learning systems which are invariant to certain data transformations is critical in machine learning. Practitioners can typically enforce a desired invariance on the trained model through the choice of a network architecture, e.g. using convolutions for translations, or using data augmentation. Yet, enforcing true invariance in the network can be difficult, and data invariances are not always known a piori. State-of-the-art methods for learning data augmentation policies require held-out data and are based on bilevel optimization problems, which are complex to solve and often computationally demanding. In this work we investigate new ways of learning invariances only from the training data. Using learnable augmentation layers built directly in the network, we demonstrate that our method is very versatile. It can incorporate any type of differentiable augmentation and be applied to a broad class of learning problems beyond computer vision. We provide empirical evidence showing that our approach is easier and faster to train than modern automatic data augmentation techniques based on bilevel optimization, while achieving comparable results. Experiments show that while the invariances transferred to a model through automatic data augmentation are limited by the model expressivity, the invariance yielded by our approach is insensitive to it by design. ",
    "url": "https://arxiv.org/abs/2202.02142",
    "authors": [
      "C\u00e9dric Rommel",
      "Thomas Moreau",
      "Alexandre Gramfort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02145",
    "title": "Generative Modeling of Complex Data",
    "abstract": "In recent years, several models have improved the capacity to generate synthetic tabular datasets. However, such models focus on synthesizing simple columnar tables and are not useable on real-life data with complex structures. This paper puts forward a generic framework to synthesize more complex data structures with composite and nested types. It then proposes one practical implementation, built with causal transformers, for struct (mappings of types) and lists (repeated instances of a type). The results on standard benchmark datasets show that such implementation consistently outperforms current state-of-the-art models both in terms of machine learning utility and statistical similarity. Moreover, it shows very strong results on two complex hierarchical datasets with multiple nesting and sparse data, that were previously out of reach. ",
    "url": "https://arxiv.org/abs/2202.02145",
    "authors": [
      "Luca Canale",
      "Nicolas Grislain",
      "Gr\u00e9goire Lothe",
      "Johan Leduc"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.02170",
    "title": "The Ecological Footprint of Neural Machine Translation Systems",
    "abstract": "Over the past decade, deep learning (DL) has led to significant advancements in various fields of artificial intelligence, including machine translation (MT). These advancements would not be possible without the ever-growing volumes of data and the hardware that allows large DL models to be trained efficiently. Due to the large amount of computing cores as well as dedicated memory, graphics processing units (GPUs) are a more effective hardware solution for training and inference with DL models than central processing units (CPUs). However, the former is very power demanding. The electrical power consumption has economical as well as ecological implications. This chapter focuses on the ecological footprint of neural MT systems. It starts from the power drain during the training of and the inference with neural MT models and moves towards the environment impact, in terms of carbon dioxide emissions. Different architectures (RNN and Transformer) and different GPUs (consumer-grate NVidia 1080Ti and workstation-grade NVidia P100) are compared. Then, the overall CO2 offload is calculated for Ireland and the Netherlands. The NMT models and their ecological impact are compared to common household appliances to draw a more clear picture. The last part of this chapter analyses quantization, a technique for reducing the size and complexity of models, as a way to reduce power consumption. As quantized models can run on CPUs, they present a power-efficient inference solution without depending on a GPU. ",
    "url": "https://arxiv.org/abs/2202.02170",
    "authors": [
      "Dimitar Sherionov",
      "Eva Vanmassenhove"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.02171",
    "title": "NeAT: Neural Adaptive Tomography",
    "abstract": "In this paper, we present Neural Adaptive Tomography (NeAT), the first adaptive, hierarchical neural rendering pipeline for multi-view inverse rendering. Through a combination of neural features with an adaptive explicit representation, we achieve reconstruction times far superior to existing neural inverse rendering methods. The adaptive explicit representation improves efficiency by facilitating empty space culling and concentrating samples in complex regions, while the neural features act as a neural regularizer for the 3D reconstruction. The NeAT framework is designed specifically for the tomographic setting, which consists only of semi-transparent volumetric scenes instead of opaque objects. In this setting, NeAT outperforms the quality of existing optimization-based tomography solvers while being substantially faster. ",
    "url": "https://arxiv.org/abs/2202.02171",
    "authors": [
      "Darius R\u00fcckert",
      "Yuanhao Wang",
      "Rui Li",
      "Ramzi Idoughi",
      "Wolfgang Heidrich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2202.02232",
    "title": "Bootstrapped Representation Learning for Skeleton-Based Action  Recognition",
    "abstract": "In this work, we study self-supervised representation learning for 3D skeleton-based action recognition. We extend Bootstrap Your Own Latent (BYOL) for representation learning on skeleton sequence data and propose a new data augmentation strategy including two asymmetric transformation pipelines. We also introduce a multi-viewpoint sampling method that leverages multiple viewing angles of the same action captured by different cameras. In the semi-supervised setting, we show that the performance can be further improved by knowledge distillation from wider networks, leveraging once more the unlabeled samples. We conduct extensive experiments on the NTU-60 and NTU-120 datasets to demonstrate the performance of our proposed method. Our method consistently outperforms the current state of the art on both linear evaluation and semi-supervised benchmarks. ",
    "url": "https://arxiv.org/abs/2202.02232",
    "authors": [
      "Olivier Moliner",
      "Sangxia Huang",
      "Kalle \u00c5str\u00f6m"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.02236",
    "title": "Pixle: a fast and effective black-box attack based on rearranging pixels",
    "abstract": "Recent research has found that neural networks are vulnerable to several types of adversarial attacks, where the input samples are modified in such a way that the model produces a wrong prediction that misclassifies the adversarial sample. In this paper we focus on black-box adversarial attacks, that can be performed without knowing the inner structure of the attacked model, nor the training procedure, and we propose a novel attack that is capable of correctly attacking a high percentage of samples by rearranging a small number of pixels within the attacked image. We demonstrate that our attack works on a large number of datasets and models, that it requires a small number of iterations, and that the distance between the original sample and the adversarial one is negligible to the human eye. ",
    "url": "https://arxiv.org/abs/2202.02236",
    "authors": [
      "Jary Pomponi",
      "Simone Scardapane",
      "Aurelio Uncini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.02241",
    "title": "Sparse Polynomial Optimisation for Neural Network Verification",
    "abstract": "The prevalence of neural networks in society is expanding at an increasing rate. It is becoming clear that providing robust guarantees on systems that use neural networks is very important, especially in safety-critical applications. A trained neural network's sensitivity to adversarial attacks is one of its greatest shortcomings. To provide robust guarantees, one popular method that has seen success is to bound the activation functions using equality and inequality constraints. However, there are numerous ways to form these bounds, providing a trade-off between conservativeness and complexity. Depending on the complexity of these bounds, the computational time of the optimisation problem varies, with longer solve times often leading to tighter bounds. We approach the problem from a different perspective, using sparse polynomial optimisation theory and the Positivstellensatz, which derives from the field of real algebraic geometry. The former exploits the natural cascading structure of the neural network using ideas from chordal sparsity while the later asserts the emptiness of a semi-algebraic set with a nested family of tests of non-decreasing accuracy to provide tight bounds. We show that bounds can be tightened significantly, whilst the computational time remains reasonable. We compare the solve times of different solvers and show how the accuracy can be improved at the expense of increased computation time. We show that by using this sparse polynomial framework the solve time and accuracy can be improved over other methods for neural network verification with ReLU, sigmoid and tanh activation functions. ",
    "url": "https://arxiv.org/abs/2202.02241",
    "authors": [
      "Matthew Newton",
      "Antonis Papachristodoulou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.02242",
    "title": "Dikaios: Privacy Auditing of Algorithmic Fairness via Attribute  Inference Attacks",
    "abstract": "Machine learning (ML) models have been deployed for high-stakes applications. Due to class imbalance in the sensitive attribute observed in the datasets, ML models are unfair on minority subgroups identified by a sensitive attribute, such as race and sex. In-processing fairness algorithms ensure model predictions are independent of sensitive attribute. Furthermore, ML models are vulnerable to attribute inference attacks where an adversary can identify the values of sensitive attribute by exploiting their distinguishable model predictions. Despite privacy and fairness being important pillars of trustworthy ML, the privacy risk introduced by fairness algorithms with respect to attribute leakage has not been studied. We identify attribute inference attacks as an effective measure for auditing blackbox fairness algorithms to enable model builder to account for privacy and fairness in the model design. We proposed Dikaios, a privacy auditing tool for fairness algorithms for model builders which leveraged a new effective attribute inference attack that account for the class imbalance in sensitive attributes through an adaptive prediction threshold. We evaluated Dikaios to perform a privacy audit of two in-processing fairness algorithms over five datasets. We show that our attribute inference attacks with adaptive prediction threshold significantly outperform prior attacks. We highlighted the limitations of in-processing fairness algorithms to ensure indistinguishable predictions across different values of sensitive attributes. Indeed, the attribute privacy risk of these in-processing fairness schemes is highly variable according to the proportion of the sensitive attributes in the dataset. This unpredictable effect of fairness mechanisms on the attribute privacy risk is an important limitation on their utilization which has to be accounted by the model builder. ",
    "url": "https://arxiv.org/abs/2202.02242",
    "authors": [
      "Jan Aalmoes",
      "Vasisht Duddu",
      "Antoine Boutet"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02248",
    "title": "Backpropagation Neural Tree",
    "abstract": "We propose a novel algorithm called Backpropagation Neural Tree (BNeuralT), which is a stochastic computational dendritic tree. BNeuralT takes random repeated inputs through its leaves and imposes dendritic nonlinearities through its internal connections like a biological dendritic tree would do. Considering the dendritic-tree like plausible biological properties, BNeuralT is a single neuron neural tree model with its internal sub-trees resembling dendritic nonlinearities. BNeuralT algorithm produces an ad hoc neural tree which is trained using a stochastic gradient descent optimizer like gradient descent (GD), momentum GD, Nesterov accelerated GD, Adagrad, RMSprop, or Adam. BNeuralT training has two phases, each computed in a depth-first search manner: the forward pass computes neural tree's output in a post-order traversal, while the error backpropagation during the backward pass is performed recursively in a pre-order traversal. A BNeuralT model can be considered a minimal subset of a neural network (NN), meaning it is a \"thinned\" NN whose complexity is lower than an ordinary NN. Our algorithm produces high-performing and parsimonious models balancing the complexity with descriptive ability on a wide variety of machine learning problems: classification, regression, and pattern recognition. ",
    "url": "https://arxiv.org/abs/2202.02248",
    "authors": [
      "Varun Ojha",
      "Giuseppe Nicosia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02259",
    "title": "Targeted Code Inspection based on Human Errors",
    "abstract": "As a direct cause of software defects, human error is the key to understanding and identifying defects. We propose a new code inspection method: targeted code inspection based on human error mechanisms of software engineers. Based on the common erroneous mechanisms of human cognition, the method targets error-prone codes with high efficiency and minimum effort. The proposed method is supported by preliminary evidence in a pilot study. ",
    "url": "https://arxiv.org/abs/2202.02259",
    "authors": [
      "Fuqun Huang",
      "Henrique Madeira"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2202.02294",
    "title": "Pre-Trained Neural Language Models for Automatic Mobile App User  Feedback Answer Generation",
    "abstract": "Studies show that developers' answers to the mobile app users' feedbacks on app stores can increase the apps' star rating. To help app developers generate answers that are related to the users' issues, recent studies develop models to generate the answers automatically. Aims: The app response generation models use deep neural networks and require training data. Pre-Trained neural language Models (PTM) used in Natural Language Processing (NLP) take advantage of the information they learned from a large corpora in an unsupervised manner, and can reduce the amount of required training data. In this paper, we evaluate PTMs to generate replies to the mobile app user feedbacks. Method: We train a Transformer model from scratch and fine-tune two PTMs to evaluate the generated responses, which are compared to RRGEN, a current app response model. We also evaluate the models with different portions of the training data. Results: The results on a large dataset evaluated by automatic metrics show that PTMs obtain lower scores than the baselines. However, our human evaluation confirms that PTMs can generate more relevant and meaningful responses to the posted feedbacks. Moreover, the performance of PTMs has less drop compared to other models when the amount of training data is reduced to 1/3. Conclusion: PTMs are useful in generating responses to app reviews and are more robust models to the amount of training data provided. However, the prediction time is 19X than RRGEN. This study can provide new avenues for research in adapting the PTMs for analyzing mobile app user feedbacks. Index Terms-mobile app user feedback analysis, neural pre-trained language models, automatic answer generation ",
    "url": "https://arxiv.org/abs/2202.02294",
    "authors": [
      "Yue Cao",
      "Fatemeh H. Fard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2202.02296",
    "title": "Graph-Coupled Oscillator Networks",
    "abstract": "We propose Graph-Coupled Oscillator Networks (GraphCON), a novel framework for deep learning on graphs. It is based on discretizations of a second-order system of ordinary differential equations (ODEs), which model a network of nonlinear forced and damped oscillators, coupled via the adjacency structure of the underlying graph. The flexibility of our framework permits any basic GNN layer (e.g. convolutional or attentional) as the coupling function, from which a multi-layer deep neural network is built up via the dynamics of the proposed ODEs. We relate the oversmoothing problem, commonly encountered in GNNs, to the stability of steady states of the underlying ODE and show that zero-Dirichlet energy steady states are not stable for our proposed ODEs. This demonstrates that the proposed framework mitigates the oversmoothing problem. Finally, we show that our approach offers competitive performance with respect to the state-of-the-art on a variety of graph-based learning tasks. ",
    "url": "https://arxiv.org/abs/2202.02296",
    "authors": [
      "T. Konstantin Rusch",
      "Benjamin P. Chamberlain",
      "James Rowbottom",
      "Siddhartha Mishra",
      "Michael M. Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.02300",
    "title": "On Robust Optimal Linear Feedback Stock Trading",
    "abstract": "The take-off point for this paper is the Simultaneous Long-Short (SLS) control class, which is known to guarantee the so-called robust positive expectation (RPE) property. That is, the expected cumulative trading gain-loss function is guaranteed to be positive for a broad class of stock price processes. This fact attracts many new extensions and ramifications to the SLS theory. However, it is arguable that \"systematic\" way to select an optimal decision variable that is robust in the RPE sense is still unresolved. To this end, we propose a modified SLS control structure, which we call the {double linear feedback control scheme}, that allows us to solve the issue above for stock price processes involving independent returns. In this paper, we go beyond the existing literature by not only deriving explicit expressions for the expected value and variance of cumulative gain-loss function but also proving various theoretical results regarding {robust positive expected growth} and {monotonicity}. Subsequently, we propose a new {robust optimal gain selection problem} that seeks a solution maximizing the expected trading gain-loss subject to the prespecified standard deviation {and} RPE constraints. Under some mild conditions, we show that the optimal solution exists and is unique. Moreover, a simple graphical approach that allows one to systematically determine the optimal solution is also proposed. Finally, some numerical and empirical studies using historical price data are also provided to support our theory. ",
    "url": "https://arxiv.org/abs/2202.02300",
    "authors": [
      "Chung-Han Hsieh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Computational Finance (q-fin.CP)",
      "Mathematical Finance (q-fin.MF)"
    ]
  },
  {
    "id": "arXiv:2202.02307",
    "title": "Privacy-aware Distributed Hypothesis Testing in Gray-Wyner Network with  Side Information",
    "abstract": "The problem of distributed binary hypothesis testing in the Gray-Wyner network with side information is studied in this paper. An observer has access to a discrete memoryless and stationary source and describes its observation to two detectors via one common and two private channels. The channels are considered error-free but rate-limited. Each detector also has access to its own discrete memoryless and stationary source, i.e., the side information. The goal is to perform two distinct binary hypothesis testings on the joint distribution of observations at detectors. Additionally, the observer aims to keep a correlated latent source private against the detectors. Equivocation is used as the measure of the privacy preserved for the latent source. An achievable inner bound is derived for the general case by introducing a non-asymptotic account of the output statistics of the random binning. ",
    "url": "https://arxiv.org/abs/2202.02307",
    "authors": [
      "Reza Abbasalipour",
      "Mahtab Mirmohseni"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.02309",
    "title": "Neural Collision Detection for Deformable Objects",
    "abstract": "We propose a neural network-based approach for collision detection with deformable objects. Unlike previous approaches based on bounding volume hierarchies, our neural approach does not require an update of the spatial data structure when the object deforms. Our network is trained on the reduced degrees of freedom of the object, so that we can use the same network to query for collisions even when the object deforms. Our approach is simple to use and implement, and it can readily be employed on the GPU. We demonstrate our approach with two concrete examples: a haptics application with a finite element mesh, and cloth simulation with a skinned character. ",
    "url": "https://arxiv.org/abs/2202.02309",
    "authors": [
      "Ryan S. Zesch",
      "Bethany R. Witemeyer",
      "Ziyan Xiong",
      "David I.W. Levin",
      "Shinjiro Sueda"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2202.02310",
    "title": "EcoFlow: Efficient Convolutional Dataflows for Low-Power Neural Network  Accelerators",
    "abstract": "Dilated and transposed convolutions are widely used in modern convolutional neural networks (CNNs). These kernels are used extensively during CNN training and inference of applications such as image segmentation and high-resolution image generation. Although these kernels have grown in popularity, they stress current compute systems due to their high memory intensity, exascale compute demands, and large energy consumption. We find that commonly-used low-power CNN inference accelerators based on spatial architectures are not optimized for both of these convolutional kernels. Dilated and transposed convolutions introduce significant zero padding when mapped to the underlying spatial architecture, significantly degrading performance and energy efficiency. Existing approaches that address this issue require significant design changes to the otherwise simple, efficient, and well-adopted architectures used to compute direct convolutions. To address this challenge, we propose EcoFlow, a new set of dataflows and mapping algorithms for dilated and transposed convolutions. These algorithms are tailored to execute efficiently on existing low-cost, small-scale spatial architectures and requires minimal changes to the network-on-chip of existing accelerators. EcoFlow eliminates zero padding through careful dataflow orchestration and data mapping tailored to the spatial architecture. EcoFlow enables flexible and high-performance transpose and dilated convolutions on architectures that are otherwise optimized for CNN inference. We evaluate the efficiency of EcoFlow on CNN training workloads and Generative Adversarial Network (GAN) training workloads. Experiments in our new cycle-accurate simulator show that EcoFlow 1) reduces end-to-end CNN training time between 7-85%, and 2) improves end-to-end GAN training performance between 29-42%, compared to state-of-the-art CNN inference accelerators. ",
    "url": "https://arxiv.org/abs/2202.02310",
    "authors": [
      "Lois Orosa",
      "Skanda Koppula",
      "Yaman Umuroglu",
      "Konstantinos Kanellopoulos",
      "Juan Gomez-Luna",
      "Michaela Blott",
      "Kees Vissers",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2202.01783",
    "title": "Oral cancer detection and interpretation: Deep multiple instance  learning versus conventional deep single instance learning",
    "abstract": "The current medical standard for setting an oral cancer (OC) diagnosis is histological examination of a tissue sample from the oral cavity. This process is time consuming and more invasive than an alternative approach of acquiring a brush sample followed by cytological analysis. Skilled cytotechnologists are able to detect changes due to malignancy, however, to introduce this approach into clinical routine is associated with challenges such as a lack of experts and labour-intensive work. To design a trustworthy OC detection system that would assist cytotechnologists, we are interested in AI-based methods that reliably can detect cancer given only per-patient labels (minimizing annotation bias), and also provide information on which cells are most relevant for the diagnosis (enabling supervision and understanding). We, therefore, perform a comparison of a conventional single instance learning (SIL) approach and a modern multiple instance learning (MIL) method suitable for OC detection and interpretation, utilizing three different neural network architectures. To facilitate systematic evaluation of the considered approaches, we introduce a synthetic PAP-QMNIST dataset, that serves as a model of OC data, while offering access to per-instance ground truth. Our study indicates that on PAP-QMNIST, the SIL performs better, on average, than the MIL approach. Performance at the bag level on real-world cytological data is similar for both methods, yet the single instance approach performs better on average. Visual examination by cytotechnologist indicates that the methods manage to identify cells which deviate from normality, including malignant cells as well as those suspicious for dysplasia. We share the code as open source at https://github.com/MIDA-group/OralCancerMILvsSIL ",
    "url": "https://arxiv.org/abs/2202.01783",
    "authors": [
      "Nadezhda Koriakina",
      "Nata\u0161a Sladoje",
      "Vladimir Ba\u0161i\u0107",
      "Joakim Lindblad"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01816",
    "title": "SAFE-OCC: A Novelty Detection Framework for Convolutional Neural Network  Sensors and its Application in Process Control",
    "abstract": "We present a novelty detection framework for Convolutional Neural Network (CNN) sensors that we call Sensor-Activated Feature Extraction One-Class Classification (SAFE-OCC). We show that this framework enables the safe use of computer vision sensors in process control architectures. Emergent control applications use CNN models to map visual data to a state signal that can be interpreted by the controller. Incorporating such sensors introduces a significant system operation vulnerability because CNN sensors can exhibit high prediction errors when exposed to novel (abnormal) visual data. Unfortunately, identifying such novelties in real-time is nontrivial. To address this issue, the SAFE-OCC framework leverages the convolutional blocks of the CNN to create an effective feature space to conduct novelty detection using a desired one-class classification technique. This approach engenders a feature space that directly corresponds to that used by the CNN sensor and avoids the need to derive an independent latent space. We demonstrate the effectiveness of SAFE-OCC via simulated control environments. ",
    "url": "https://arxiv.org/abs/2202.01816",
    "authors": [
      "Joshua L. Pulsipher",
      "Luke D. J. Coutinho",
      "Tyler A. Soderstrom",
      "Victor M. Zavala"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.01841",
    "title": "Transport Score Climbing: Variational Inference using Forward KL and  Adaptive Neural Transport",
    "abstract": "Variational inference often minimizes the \"reverse\" Kullbeck-Leibler (KL) KL(q||p) from the approximate distribution q to the posterior p. Recent work studies the \"forward\" KL KL(p||q), which unlike reverse KL does not lead to variational approximations that underestimate uncertainty. This paper introduces Transport Score Climbing (TSC), a method that optimizes KL(p||q) by using Hamiltonian Monte Carlo (HMC) and a novel adaptive transport map. The transport map improves the trajectory of HMC by acting as a change of variable between the latent variable space and a warped space. TSC uses HMC samples to dynamically train the transport map while optimizing KL(p||q). TSC leverages synergies, where better transport maps lead to better HMC sampling, which then leads to better transport maps. We demonstrate TSC on synthetic and real data. We find that TSC achieves competitive performance when training variational autoencoders on large-scale data. ",
    "url": "https://arxiv.org/abs/2202.01841",
    "authors": [
      "Liyi Zhang",
      "Christian A. Naesseth",
      "David M. Blei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2202.01850",
    "title": "A Robust Phased Elimination Algorithm for Corruption-Tolerant Gaussian  Process Bandits",
    "abstract": "We consider the sequential optimization of an unknown, continuous, and expensive to evaluate reward function, from noisy and adversarially corrupted observed rewards. When the corruption attacks are subject to a suitable budget $C$ and the function lives in a Reproducing Kernel Hilbert Space (RKHS), the problem can be posed as corrupted Gaussian process (GP) bandit optimization. We propose a novel robust elimination-type algorithm that runs in epochs, combines exploration with infrequent switching to select a small subset of actions, and plays each action for multiple time instants. Our algorithm, Robust GP Phased Elimination (RGP-PE), successfully balances robustness to corruptions with exploration and exploitation such that its performance degrades minimally in the presence (or absence) of adversarial corruptions. When $T$ is the number of samples and $\\gamma_T$ is the maximal information gain, the corruption-dependent term in our regret bound is $O(C \\gamma_T^{3/2})$, which is significantly tighter than the existing $O(C \\sqrt{T \\gamma_T})$ for several commonly-considered kernels. We perform the first empirical study of robustness in the corrupted GP bandit setting, and show that our algorithm is robust against a variety of adversarial attacks. ",
    "url": "https://arxiv.org/abs/2202.01850",
    "authors": [
      "Ilija Bogunovic",
      "Zihan Li",
      "Andreas Krause",
      "Jonathan Scarlett"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01854",
    "title": "Causal emergence is widespread across measures of causation",
    "abstract": "Causal emergence is the theory that macroscales can reduce the noise in causal relationships, leading to stronger causes at the macroscale. First identified using the effective information and later the integrated information in model systems, causal emergence has been analyzed in real data across the sciences since. But is it simply a quirk of these original measures? To answer this question we examined over a dozen popular measures of causation, all independently developed and widely used, and spanning different fields from philosophy to statistics to psychology to genetics. All showed cases of causal emergence. This is because, we prove, measures of causation are based on a small set of related \"causal primitives.\" This consilience of independently-developed measures of causation shows that macroscale causation is a general fact about causal relationships, is scientifically detectable, and is not a quirk of any particular measure of causation. This finding sets the science of emergence on firmer ground, opening the door for the detection of intrinsic scales of function in complex systems, as well as assisting with scientific modeling and experimental interventions. ",
    "url": "https://arxiv.org/abs/2202.01854",
    "authors": [
      "Renzo Comolatti",
      "Erik Hoel"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.01857",
    "title": "Brain Cancer Survival Prediction on Treatment-na ive MRI using Deep  Anchor Attention Learning with Vision Transformer",
    "abstract": "Image-based brain cancer prediction models, based on radiomics, quantify the radiologic phenotype from magnetic resonance imaging (MRI). However, these features are difficult to reproduce because of variability in acquisition and preprocessing pipelines. Despite evidence of intra-tumor phenotypic heterogeneity, the spatial diversity between different slices within an MRI scan has been relatively unexplored using such methods. In this work, we propose a deep anchor attention aggregation strategy with a Vision Transformer to predict survival risk for brain cancer patients. A Deep Anchor Attention Learning (DAAL) algorithm is proposed to assign different weights to slice-level representations with trainable distance measurements. We evaluated our method on N = 326 MRIs. Our results outperformed attention multiple instance learning-based techniques. DAAL highlights the importance of critical slices and corroborates the clinical intuition that inter-slice spatial diversity can reflect disease severity and is implicated in outcome. ",
    "url": "https://arxiv.org/abs/2202.01857",
    "authors": [
      "Xuan Xu",
      "Prateek Prasanna"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.01866",
    "title": "Enhancing Organ at Risk Segmentation with Improved Deep Neural Networks",
    "abstract": "Organ at risk (OAR) segmentation is a crucial step for treatment planning and outcome determination in radiotherapy treatments of cancer patients. Several deep learning based segmentation algorithms have been developed in recent years, however, U-Net remains the de facto algorithm designed specifically for biomedical image segmentation and has spawned many variants with known weaknesses. In this study, our goal is to present simple architectural changes in U-Net to improve its accuracy and generalization properties. Unlike many other available studies evaluating their algorithms on single center data, we thoroughly evaluate several variations of U-Net as well as our proposed enhanced architecture on multiple data sets for an extensive and reliable study of the OAR segmentation problem. Our enhanced segmentation model includes (a)architectural changes in the loss function, (b)optimization framework, and (c)convolution type. Testing on three publicly available multi-object segmentation data sets, we achieved an average of 80% dice score compared to the baseline U-Net performance of 63%. ",
    "url": "https://arxiv.org/abs/2202.01866",
    "authors": [
      "Ilkin Isler",
      "Curtis Lisle",
      "Justin Rineer",
      "Patrick Kelly",
      "Damla Turgut",
      "Jacob Ricci",
      "Ulas Bagci"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.01897",
    "title": "AtmoDist: Self-supervised Representation Learning for Atmospheric  Dynamics",
    "abstract": "Representation learning has proven to be a powerful methodology in a wide variety of machine learning applications. For atmospheric dynamics, however, it has so far not been considered, arguably due to the lack of large-scale, labeled datasets that could be used for training. In this work, we show that the difficulty is benign and introduce a self-supervised learning task that defines a categorical loss for a wide variety of unlabeled atmospheric datasets. Specifically, we train a neural network on the simple yet intricate task of predicting the temporal distance between atmospheric fields, e.g. the components of the wind field, from distinct but nearby times. Despite this simplicity, a neural network will provide good predictions only when it develops an internal representation that captures intrinsic aspects of atmospheric dynamics. We demonstrate this by introducing a data-driven distance metric for atmospheric states based on representations learned from ERA5 reanalysis. When employ as a loss function for downscaling, this Atmodist distance leads to downscaled fields that match the true statistics more closely than the previous state-of-the-art based on an l2-loss and whose local behavior is more realistic. Since it is derived from observational data, AtmoDist also provides a novel perspective on atmospheric predictability. ",
    "url": "https://arxiv.org/abs/2202.01897",
    "authors": [
      "Sebastian Hoffmann",
      "Christian Lessig"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01899",
    "title": "DeepQMLP: A Scalable Quantum-Classical Hybrid DeepNeural Network  Architecture for Classification",
    "abstract": "Quantum machine learning (QML) is promising for potential speedups and improvements in conventional machine learning (ML) tasks (e.g., classification/regression). The search for ideal QML models is an active research field. This includes identification of efficient classical-to-quantum data encoding scheme, construction of parametric quantum circuits (PQC) with optimal expressivity and entanglement capability, and efficient output decoding scheme to minimize the required number of measurements, to name a few. However, most of the empirical/numerical studies lack a clear path towards scalability. Any potential benefit observed in a simulated environment may diminish in practical applications due to the limitations of noisy quantum hardware (e.g., under decoherence, gate-errors, and crosstalk). We present a scalable quantum-classical hybrid deep neural network (DeepQMLP) architecture inspired by classical deep neural network architectures. In DeepQMLP, stacked shallow Quantum Neural Network (QNN) models mimic the hidden layers of a classical feed-forward multi-layer perceptron network. Each QNN layer produces a new and potentially rich representation of the input data for the next layer. This new representation can be tuned by the parameters of the circuit. Shallow QNN models experience less decoherence, gate errors, etc. which make them (and the network) more resilient to quantum noise. We present numerical studies on a variety of classification problems to show the trainability of DeepQMLP. We also show that DeepQMLP performs reasonably well on unseen data and exhibits greater resilience to noise over QNN models that use a deep quantum circuit. DeepQMLP provided up to 25.3% lower loss and 7.92% higher accuracy during inference under noise than QMLP. ",
    "url": "https://arxiv.org/abs/2202.01899",
    "authors": [
      "Mahabubul Alam",
      "Swaroop Ghosh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01926",
    "title": "Knowledge Graph Based Waveform Recommendation: A New Communication  Waveform Design Paradigm",
    "abstract": "Traditionally, a communication waveform is designed by experts based on communication theory and their experiences on a case-by-case basis, which is usually laborious and time-consuming. In this paper, we investigate the waveform design from a novel perspective and propose a new waveform design paradigm with the knowledge graph (KG)-based intelligent recommendation system. The proposed paradigm aims to improve the design efficiency by structural characterization and representations of existing waveforms and intelligently utilizing the knowledge learned from them. To achieve this goal, we first build a communication waveform knowledge graph (CWKG) with a first-order neighbor node, for which both structured semantic knowledge and numerical parameters of a waveform are integrated by representation learning. Based on the developed CWKG, we further propose an intelligent communication waveform recommendation system (CWRS) to generate waveform candidates. In the CWRS, an improved involution1D operator, which is channel-agnostic and space-specific, is introduced according to the characteristics of KG-based waveform representation for feature extraction, and the multi-head self-attention is adopted to weigh the influence of various components for feature fusion. Meanwhile, multilayer perceptron-based collaborative filtering is used to evaluate the matching degree between the requirement and the waveform candidate. Simulation results show that the proposed CWKG-based CWRS can automatically recommend waveform candidates with high reliability. ",
    "url": "https://arxiv.org/abs/2202.01926",
    "authors": [
      "Wei Huang",
      "Tianfu Qi",
      "Yundi Guan",
      "Qihang Peng",
      "Jun Wang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01933",
    "title": "Identifying stimulus-driven neural activity patterns in multi-patient  intracranial recordings",
    "abstract": "Identifying stimulus-driven neural activity patterns is critical for studying the neural basis of cognition. This can be particularly challenging in intracranial datasets, where electrode locations typically vary across patients. This chapter first presents an overview of the major challenges to identifying stimulus-driven neural activity patterns in the general case. Next, we will review several modality-specific considerations and approaches, along with a discussion of several issues that are particular to intracranial recordings. Against this backdrop, we will consider a variety of within-subject and across-subject approaches to identifying and modeling stimulus-driven neural activity patterns in multi-patient intracranial recordings. These approaches include generalized linear models, multivariate pattern analysis, representational similarity analysis, joint stimulus-activity models, hierarchical matrix factorization models, Gaussian process models, geometric alignment models, inter-subject correlations, and inter-subject functional correlations. Examples from the recent literature serve to illustrate the major concepts and provide the conceptual intuitions for each approach. ",
    "url": "https://arxiv.org/abs/2202.01933",
    "authors": [
      "Jeremy R. Manning"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01940",
    "title": "Distribution Embedding Networks for Meta-Learning with Heterogeneous  Covariate Spaces",
    "abstract": "We propose Distribution Embedding Networks (DEN) for classification with small data using meta-learning techniques. Unlike existing meta-learning approaches that focus on image recognition tasks and require the training and target tasks to be similar, DEN is specifically designed to be trained on a diverse set of training tasks and applied on tasks whose number and distribution of covariates differ vastly from its training tasks. Such property of DEN is enabled by its three-block architecture: a covariate transformation block followed by a distribution embedding block and then a classification block. We provide theoretical insights to show that this architecture allows the embedding and classification blocks to be fixed after pre-training on a diverse set of tasks; only the covariate transformation block with relatively few parameters needs to be updated for each new task. To facilitate the training of DEN, we also propose an approach to synthesize binary classification training tasks, and demonstrate that DEN outperforms existing methods in a number of synthetic and real tasks in numerical studies. ",
    "url": "https://arxiv.org/abs/2202.01940",
    "authors": [
      "Lang Liu",
      "Mahdi Milani Fard",
      "Sen Zhao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01954",
    "title": "Multi-task graph neural networks for simultaneous prediction of global  and atomic properties in ferromagnetic systems",
    "abstract": "We introduce a multi-tasking graph convolutional neural network, HydraGNN, to simultaneously predict both global and atomic physical properties and demonstrate with ferromagnetic materials. We train HydraGNN on an open-source ab initio density functional theory (DFT) dataset for iron-platinum (FePt) with a fixed body centered tetragonal (BCT) lattice structure and fixed volume to simultaneously predict the mixing enthalpy (a global feature of the system), the atomic charge transfer, and the atomic magnetic moment across configurations that span the entire compositional range. By taking advantage of underlying physical correlations between material properties, multi-task learning (MTL) with HydraGNN provides effective training even with modest amounts of data. Moreover, this is achieved with just one architecture instead of three, as required by single-task learning (STL). The first convolutional layers of the HydraGNN architecture are shared by all learning tasks and extract features common to all material properties. The following layers discriminate the features of the different properties, the results of which are fed to the separate heads of the final layer to produce predictions. Numerical results show that HydraGNN effectively captures the relation between the configurational entropy and the material properties over the entire compositional range. Overall, the accuracy of simultaneous MTL predictions is comparable to the accuracy of the STL predictions. In addition, the computational cost of training HydraGNN for MTL is much lower than the original DFT calculations and also lower than training separate STL models for each property. ",
    "url": "https://arxiv.org/abs/2202.01954",
    "authors": [
      "Massimiliano Lupo Pasini",
      "Pei Zhang",
      "Samuel Temple Reeve",
      "Jong Youl Choi"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2202.02000",
    "title": "Cross-Modality Multi-Atlas Segmentation Using Deep Neural Networks",
    "abstract": "Multi-atlas segmentation (MAS) is a promising framework for medical image segmentation. Generally, MAS methods register multiple atlases, i.e., medical images with corresponding labels, to a target image; and the transformed atlas labels can be combined to generate target segmentation via label fusion schemes. Many conventional MAS methods employed the atlases from the same modality as the target image. However, the number of atlases with the same modality may be limited or even missing in many clinical applications. Besides, conventional MAS methods suffer from the computational burden of registration or label fusion procedures. In this work, we design a novel cross-modality MAS framework, which uses available atlases from a certain modality to segment a target image from another modality. To boost the computational efficiency of the framework, both the image registration and label fusion are achieved by well-designed deep neural networks. For the atlas-to-target image registration, we propose a bi-directional registration network (BiRegNet), which can efficiently align images from different modalities. For the label fusion, we design a similarity estimation network (SimNet), which estimates the fusion weight of each atlas by measuring its similarity to the target image. SimNet can learn multi-scale information for similarity estimation to improve the performance of label fusion. The proposed framework was evaluated by the left ventricle and liver segmentation tasks on the MM-WHS and CHAOS datasets, respectively. Results have shown that the framework is effective for cross-modality MAS in both registration and label fusion. The code will be released publicly on \\url{https://github.com/NanYoMy/cmmas} once the manuscript is accepted. ",
    "url": "https://arxiv.org/abs/2202.02000",
    "authors": [
      "Wangbin Ding",
      "Lei Li",
      "Xiahai Zhuang",
      "Liqin Huang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02195",
    "title": "Deep End-to-end Causal Inference",
    "abstract": "Causal inference is essential for data-driven decision making across domains such as business engagement, medical treatment or policy making. However, research on causal discovery and inference has evolved separately, and the combination of the two domains is not trivial. In this work, we develop Deep End-to-end Causal Inference (DECI), a single flow-based method that takes in observational data and can perform both causal discovery and inference, including conditional average treatment effect (CATE) estimation. We provide a theoretical guarantee that DECI can recover the ground truth causal graph under mild assumptions. In addition, our method can handle heterogeneous, real-world, mixed-type data with missing values, allowing for both continuous and discrete treatment decisions. Moreover, the design principle of our method can generalize beyond DECI, providing a general End-to-end Causal Inference (ECI) recipe, which enables different ECI frameworks to be built using existing methods. Our results show the superior performance of DECI when compared to relevant baselines for both causal discovery and (C)ATE estimation in over a thousand experiments on both synthetic datasets and other causal machine learning benchmark datasets. ",
    "url": "https://arxiv.org/abs/2202.02195",
    "authors": [
      "Tomas Geffner",
      "Javier Antoran",
      "Adam Foster",
      "Wenbo Gong",
      "Chao Ma",
      "Emre Kiciman",
      "Amit Sharma",
      "Angus Lamb",
      "Martin Kukla",
      "Nick Pawlowski",
      "Miltiadis Allamanis",
      "Cheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02228",
    "title": "Uncertainty in fMRI Functional Networks of Autism Brain Imaging Data",
    "abstract": "In this paper we review the preprocessing pipeline through which fMRI data is transformed into a network. We discuss three parameters that mostly affect our understanding of the existence of functional correlations between the brain regions. In the end, we conclude that the existence of functional correlations between pairs of the brain's regions can be modeled with probabilistic edges, not to lose the uncertainty that is inherent in the network generation process. ",
    "url": "https://arxiv.org/abs/2202.02228",
    "authors": [
      "Amin Kaveh",
      "Matteo Magnani",
      "Christian Rohner"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Other Computer Science (cs.OH)"
    ]
  },
  {
    "id": "arXiv:2202.02261",
    "title": "Infinite-horizon risk-sensitive performance criteria for translation  invariant networks of linear quantum stochastic systems",
    "abstract": "This paper is concerned with networks of identical linear quantum stochastic systems which interact with each other and external bosonic fields in a translation invariant fashion. The systems are associated with sites of a multidimensional lattice and are governed by coupled linear quantum stochastic differential equations (QSDEs). The block Toeplitz coefficients of these QSDEs are specified by the energy and coupling matrices which quantify the Hamiltonian and coupling operators for the component systems. We discuss the invariant Gaussian quantum state of the network when it satisfies a stability condition and is driven by statistically independent vacuum fields. A quadratic-exponential functional (QEF) is considered as a risk-sensitive performance criterion for a finite fragment of the network over a bounded time interval. This functional involves a quadratic function of dynamic variables of the component systems with a block Toeplitz weighting matrix. Assuming the invariant state, we study the spatio-temporal asymptotic rate of the QEF per unit time and per lattice site in the thermodynamic limit of unboundedly growing time horizons and fragments of the lattice. A spatio-temporal frequency-domain formula is obtained for the QEF rate in terms of two spectral functions associated with the real and imaginary parts of the invariant quantum covariance kernel of the network variables. A homotopy method and asymptotic expansions for evaluating the QEF rate are also discussed. ",
    "url": "https://arxiv.org/abs/2202.02261",
    "authors": [
      "Igor G. Vladimirov",
      "Ian R. Petersen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:1904.00326",
    "title": "MedGCN: Medication recommendation and lab test imputation via graph  convolutional networks",
    "abstract": " Title: MedGCN: Medication recommendation and lab test imputation via graph  convolutional networks ",
    "url": "https://arxiv.org/abs/1904.00326",
    "authors": [
      "Chengsheng Mao",
      "Liang Yao",
      "Yuan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2003.01492",
    "title": "Contention Window Optimization in IEEE 802.11ax Networks with Deep  Reinforcement Learning",
    "abstract": " Comments: 6 pages, 6 figures, published in 2021 IEEE Wireless Communications and Networking Conference (WCNC) ",
    "url": "https://arxiv.org/abs/2003.01492",
    "authors": [
      "Witold Wydma\u0144ski",
      "Szymon Szott"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2008.01681",
    "title": "Multimodal Image-to-Image Translation via a Single Generative  Adversarial Network",
    "abstract": " Comments: pages 13, 15 figures ",
    "url": "https://arxiv.org/abs/2008.01681",
    "authors": [
      "Shihua Huang",
      "Cheng He",
      "Ran Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2008.10937",
    "title": "A Survey on Evolutionary Neural Architecture Search",
    "abstract": " Comments: this paper has been accepted for publication by IEEE Transactions on Neural Networks and Learning Systems (2021) ",
    "url": "https://arxiv.org/abs/2008.10937",
    "authors": [
      "Yuqiao Liu",
      "Yanan Sun",
      "Bing Xue",
      "Mengjie Zhang",
      "Gary G. Yen",
      "Kay Chen Tan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2012.00113",
    "title": "The FEDHC Bayesian network learning algorithm",
    "abstract": " Title: The FEDHC Bayesian network learning algorithm ",
    "url": "https://arxiv.org/abs/2012.00113",
    "authors": [
      "Michail Tsagris"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2101.09162",
    "title": "A Robust Blockchain Readiness Index Model",
    "abstract": " Comments: The final authenticated version is available online at this https URL ",
    "url": "https://arxiv.org/abs/2101.09162",
    "authors": [
      "Elias Iosif",
      "Klitos Christodoulou",
      "Andreas Vlachos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2102.06966",
    "title": "Graph Convolution for Semi-Supervised Classification: Improved Linear  Separability and Out-of-Distribution Generalization",
    "abstract": " Comments: 30 pages, 9 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2102.06966",
    "authors": [
      "Aseem Baranwal",
      "Kimon Fountoulakis",
      "Aukosh Jagannath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2105.04137",
    "title": "On the inversion number of oriented graphs",
    "abstract": " Title: On the inversion number of oriented graphs ",
    "url": "https://arxiv.org/abs/2105.04137",
    "authors": [
      "J\u00f8rgen Bang-Jensen",
      "Jonas Costa Ferreira da Silva",
      "Fr\u00e9d\u00e9ric Havet"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2106.00906",
    "title": "Learn to Predict Equilibria via Fixed Point Networks",
    "abstract": " Title: Learn to Predict Equilibria via Fixed Point Networks ",
    "url": "https://arxiv.org/abs/2106.00906",
    "authors": [
      "Howard Heaton",
      "Daniel McKenzie",
      "Qiuwei Li",
      "Samy Wu Fung",
      "Stanley Osher",
      "Wotao Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2106.01513",
    "title": "Granger Causality from Quantized Measurements",
    "abstract": " Title: Granger Causality from Quantized Measurements ",
    "url": "https://arxiv.org/abs/2106.01513",
    "authors": [
      "Salman Ahmadi",
      "Girish N. Nair",
      "Erik Weyer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2106.03496",
    "title": "Self-Supervision & Meta-Learning for One-Shot Unsupervised Cross-Domain  Detection",
    "abstract": " Comments: This paper is under consideration for publication at Computer Vision and Image Understanding ",
    "url": "https://arxiv.org/abs/2106.03496",
    "authors": [
      "F. Cappio Borlino",
      "S. Polizzotto",
      "A. D'Innocente",
      "S. Bucci",
      "B. Caputo",
      "T. Tommasi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.09256",
    "title": "Seeing Differently, Acting Similarly: Imitation Learning with  Heterogeneous Observations",
    "abstract": " Title: Seeing Differently, Acting Similarly: Imitation Learning with  Heterogeneous Observations ",
    "url": "https://arxiv.org/abs/2106.09256",
    "authors": [
      "Xin-Qiang Cai",
      "Yao-Xiang Ding",
      "Zi-Xuan Chen",
      "Yuan Jiang",
      "Masashi Sugiyama",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.10994",
    "title": "BernNet: Learning Arbitrary Graph Spectral Filters via Bernstein  Approximation",
    "abstract": " Comments: NeurIPS 2021 ",
    "url": "https://arxiv.org/abs/2106.10994",
    "authors": [
      "Mingguo He",
      "Zhewei Wei",
      "Zengfeng Huang",
      "Hongteng Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.13695",
    "title": "CADDA: Class-wise Automatic Differentiable Data Augmentation for EEG  Signals",
    "abstract": " Title: CADDA: Class-wise Automatic Differentiable Data Augmentation for EEG  Signals ",
    "url": "https://arxiv.org/abs/2106.13695",
    "authors": [
      "C\u00e9dric Rommel",
      "Thomas Moreau",
      "Joseph Paillard",
      "Alexandre Gramfort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.03428",
    "title": "Management of Resource at the Network Edge for Federated Learning",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:1803.05255 by other authors ",
    "url": "https://arxiv.org/abs/2107.03428",
    "authors": [
      "Silvana Trindade",
      "Luiz F. Bittencourt",
      "Nelson L. S. da Fonseca"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.08374",
    "title": "Detecting Braess Routes: an Algorithm Accounting for Queuing Delays With  an Extended Graph",
    "abstract": " Title: Detecting Braess Routes: an Algorithm Accounting for Queuing Delays With  an Extended Graph ",
    "url": "https://arxiv.org/abs/2107.08374",
    "authors": [
      "Mikhail Burov",
      "Can Kizilkale",
      "Alexander Kurzhanskiy",
      "Murat Arcak"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2108.01775",
    "title": "Solo-learn: A Library of Self-supervised Methods for Visual  Representation Learning",
    "abstract": " Comments: Accepted to JMLR ",
    "url": "https://arxiv.org/abs/2108.01775",
    "authors": [
      "Victor G. Turrisi da Costa",
      "Enrico Fini",
      "Moin Nabi",
      "Nicu Sebe",
      "Elisa Ricci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.03702",
    "title": "BIGRoC: Boosting Image Generation via a Robust Classifier",
    "abstract": " Title: BIGRoC: Boosting Image Generation via a Robust Classifier ",
    "url": "https://arxiv.org/abs/2108.03702",
    "authors": [
      "Roy Ganz",
      "Michael Elad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.13233",
    "title": "Whole Brain Vessel Graphs: A Dataset and Benchmark for Graph Learning  and Neuroscience (VesselGraph)",
    "abstract": " Comments: Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track ",
    "url": "https://arxiv.org/abs/2108.13233",
    "authors": [
      "Johannes C. Paetzold",
      "Julian McGinnis",
      "Suprosanna Shit",
      "Ivan Ezhov",
      "Paul B\u00fcschl",
      "Chinmay Prabhakar",
      "Mihail I. Todorov",
      "Anjany Sekuboyina",
      "Georgios Kaissis",
      "Ali Ert\u00fcrk",
      "Stephan G\u00fcnnemann",
      "Bjoern H. Menze"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2109.02839",
    "title": "Self-adaptive deep neural network: Numerical approximation to functions  and PDEs",
    "abstract": " Comments: Published in Journal of Computational Physics ",
    "url": "https://arxiv.org/abs/2109.02839",
    "authors": [
      "Zhiqiang Cai",
      "Jingshuang Chen",
      "Min Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.09901",
    "title": "Modeling Adversarial Noise for Adversarial Training",
    "abstract": " Title: Modeling Adversarial Noise for Adversarial Training ",
    "url": "https://arxiv.org/abs/2109.09901",
    "authors": [
      "Dawei Zhou",
      "Nannan Wang",
      "Bo Han",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.03002",
    "title": "Multi-Scale Convolutional Neural Network for Automated AMD  Classification using Retinal OCT Images",
    "abstract": " Title: Multi-Scale Convolutional Neural Network for Automated AMD  Classification using Retinal OCT Images ",
    "url": "https://arxiv.org/abs/2110.03002",
    "authors": [
      "Saman Sotoudeh-Paima",
      "Ata Jodeiri",
      "Fedra Hajizadeh",
      "Hamid Soltanian-Zadeh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.03243",
    "title": "Sound Event Detection Guided by Semantic Contexts of Scenes",
    "abstract": " Comments: Accepted to ICASSP 2022 ",
    "url": "https://arxiv.org/abs/2110.03243",
    "authors": [
      "Noriyuki Tonami",
      "Keisuke Imoto",
      "Ryotaro Nagase",
      "Yuki Okamoto",
      "Takahiro Fukumori",
      "Yoichi Yamashita"
    ],
    "subjectives": [
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2110.04267",
    "title": "Exploring Heterogeneous Characteristics of Layers in ASR Models for More  Efficient Training",
    "abstract": " Comments: \\c{opyright} 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works ",
    "url": "https://arxiv.org/abs/2110.04267",
    "authors": [
      "Lillian Zhou",
      "Dhruv Guliani",
      "Andreas Kabel",
      "Giovanni Motta",
      "Fran\u00e7oise Beaufays"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2110.08500",
    "title": "On Model Selection Consistency of Lasso for High-Dimensional Ising  Models on Tree-like Graphs",
    "abstract": " Comments: 27 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2110.08500",
    "authors": [
      "Xiangming Meng",
      "Tomoyuki Obuchi",
      "Yoshiyuki Kabashima"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2110.14789",
    "title": "Millimeter Wave Wireless Assisted Robot Navigation with Link State  Classification",
    "abstract": " Comments: 14 pages, 20 figures ",
    "url": "https://arxiv.org/abs/2110.14789",
    "authors": [
      "Mingsheng Yin",
      "Akshaj Veldanda",
      "Amee Trivedi",
      "Jeff Zhang",
      "Kai Pfeiffer",
      "Yaqi Hu",
      "Siddharth Garg",
      "Elza Erkip",
      "Ludovic Righetti",
      "Sundeep Rangan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2111.01363",
    "title": "Knowledge Cross-Distillation for Membership Privacy",
    "abstract": " Comments: Accepted by PETS 2022 ",
    "url": "https://arxiv.org/abs/2111.01363",
    "authors": [
      "Rishav Chourasia",
      "Batnyam Enkhtaivan",
      "Kunihiro Ito",
      "Junki Mori",
      "Isamu Teranishi",
      "Hikaru Tsuchida"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.07725",
    "title": "Investigating self-supervised front ends for speech spoofing  countermeasures",
    "abstract": " Comments: V3: added sub-band analysis, submitted to ISCA Odyssey2022; V2: added min tDCF results on 2019 and 2021 LA. EERs on LA 2021 were slightly updated to fix one glitch in the score file. EERs and min tDCFs on 2021 LA and DF can be computed using the latest official code this https URL Work in progress. Feedback is welcome! ",
    "url": "https://arxiv.org/abs/2111.07725",
    "authors": [
      "Xin Wang",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2111.10985",
    "title": "Efficient Non-Compression Auto-Encoder for Driving Noise-based Road  Surface Anomaly Detection",
    "abstract": " Comments: 8 pages, 5 figures, 6 tables ",
    "url": "https://arxiv.org/abs/2111.10985",
    "authors": [
      "YeongHyeon Park",
      "JongHee Jung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2111.12193",
    "title": "Multiset-Equivariant Set Prediction with Approximate Implicit  Differentiation",
    "abstract": " Comments: Published at International Conference on Learning Representations (ICLR) 2022 ",
    "url": "https://arxiv.org/abs/2111.12193",
    "authors": [
      "Yan Zhang",
      "David W. Zhang",
      "Simon Lacoste-Julien",
      "Gertjan J. Burghouts",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.05139",
    "title": "CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields",
    "abstract": " Comments: updated missing references ",
    "url": "https://arxiv.org/abs/2112.05139",
    "authors": [
      "Can Wang",
      "Menglei Chai",
      "Mingming He",
      "Dongdong Chen",
      "Jing Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2201.05275",
    "title": "Deep Leaning-Based Ultra-Fast Stair Detection",
    "abstract": " Title: Deep Leaning-Based Ultra-Fast Stair Detection ",
    "url": "https://arxiv.org/abs/2201.05275",
    "authors": [
      "Chen Wang",
      "Zhongcai Pei",
      "Shuang Qiu",
      "Zhiyong Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.09693",
    "title": "Shape-consistent Generative Adversarial Networks for multi-modal Medical  segmentation maps",
    "abstract": " Title: Shape-consistent Generative Adversarial Networks for multi-modal Medical  segmentation maps ",
    "url": "https://arxiv.org/abs/2201.09693",
    "authors": [
      "Leo Segre",
      "Or Hirschorn",
      "Dvir Ginzburg",
      "Dan Raviv"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.09862",
    "title": "Learning to Act with Affordance-Aware Multimodal Neural SLAM",
    "abstract": " Title: Learning to Act with Affordance-Aware Multimodal Neural SLAM ",
    "url": "https://arxiv.org/abs/2201.09862",
    "authors": [
      "Zhiwei Jia",
      "Kaixiang Lin",
      "Yizhou Zhao",
      "Qiaozi Gao",
      "Govind Thattai",
      "Gaurav Sukhatme"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.10147",
    "title": "TGFuse: An Infrared and Visible Image Fusion Approach Based on  Transformer and Generative Adversarial Network",
    "abstract": " Title: TGFuse: An Infrared and Visible Image Fusion Approach Based on  Transformer and Generative Adversarial Network ",
    "url": "https://arxiv.org/abs/2201.10147",
    "authors": [
      "Dongyu Rao",
      "Xiao-Jun Wu",
      "Tianyang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.00645",
    "title": "Stability and Generalization Capabilities of Message Passing Graph  Neural Networks",
    "abstract": " Comments: typos corrected ",
    "url": "https://arxiv.org/abs/2202.00645",
    "authors": [
      "Sohir Maskey",
      "Yunseok Lee",
      "Ron Levie",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2202.00838",
    "title": "Finding Biological Plausibility for Adversarially Robust Features via  Metameric Tasks",
    "abstract": " Comments: Accepted to ICLR 2022 as a Spotlight ",
    "url": "https://arxiv.org/abs/2202.00838",
    "authors": [
      "Anne Harrington",
      "Arturo Deza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2202.01300",
    "title": "Causal Inference Through the Structural Causal Marginal Problem",
    "abstract": " Comments: 31 pages (9 pages main paper + bibliography and appendix), 6 figures ",
    "url": "https://arxiv.org/abs/2202.01300",
    "authors": [
      "Luigi Gresele",
      "Julius von K\u00fcgelgen",
      "Jonas M. K\u00fcbler",
      "Elke Kirschbaum",
      "Bernhard Sch\u00f6lkopf",
      "Dominik Janzing"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01627",
    "title": "Non-Vacuous Generalisation Bounds for Shallow Neural Networks",
    "abstract": " Comments: 25 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2202.01627",
    "authors": [
      "Felix Biggs",
      "Benjamin Guedj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.01649",
    "title": "HECO: Automatic Code Optimizations for Efficient Fully Homomorphic  Encryption",
    "abstract": " Comments: (this version addresses some arxiv-specific layout issues with the initial upload) ",
    "url": "https://arxiv.org/abs/2202.01649",
    "authors": [
      "Alexander Viand",
      "Patrick Jattke",
      "Miro Haller",
      "Anwar Hithnawi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.01725",
    "title": "RipsNet: a general architecture for fast and robust estimation of the  persistent homology of point clouds",
    "abstract": " Comments: 23 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2202.01725",
    "authors": [
      "Thibault de Surrel",
      "Felix Hensel",
      "Mathieu Carri\u00e8re",
      "Th\u00e9o Lacombe",
      "Yuichi Ike",
      "Hiroaki Kurihara",
      "Marc Glisse",
      "Fr\u00e9d\u00e9ric Chazal"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ]
  }
]