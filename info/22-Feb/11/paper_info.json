[
  {
    "id": "arXiv:2202.04703",
    "title": "Improving Content-Aware Video Streaming in Congested Networks with  In-Network Computing",
    "abstract": "Network congestion and packet loss pose an ever-increasing challenge to video streaming. Despite the research efforts toward making video encoding schemes resilient to lossy network conditions, forwarding devices have not considered monitoring packet content to prioritize packets and minimize the impact of packet loss on video transmission. In this work, we advocate in favor of in-network computing employing a packet drop algorithm and an in-network hardware module to devise a solution for improving content-aware video streaming in congested network. Results show that our approach can reduce intra-predicted packet loss by over 80% at negligible resource usage and performance costs. ",
    "url": "https://arxiv.org/abs/2202.04703",
    "authors": [
      "Leonardo Gobatto",
      "Mateus Saquetti",
      "Claudio Diniz",
      "Bruno Zatt",
      "Weverton Cordeiro",
      "Jose Rodrigo Azambuja"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Hardware Architecture (cs.AR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2202.04713",
    "title": "PINs: Progressive Implicit Networks for Multi-Scale Neural  Representations",
    "abstract": "Multi-layer perceptrons (MLP) have proven to be effective scene encoders when combined with higher-dimensional projections of the input, commonly referred to as \\textit{positional encoding}. However, scenes with a wide frequency spectrum remain a challenge: choosing high frequencies for positional encoding introduces noise in low structure areas, while low frequencies result in poor fitting of detailed regions. To address this, we propose a progressive positional encoding, exposing a hierarchical MLP structure to incremental sets of frequency encodings. Our model accurately reconstructs scenes with wide frequency bands and learns a scene representation at progressive level of detail \\textit{without explicit per-level supervision}. The architecture is modular: each level encodes a continuous implicit representation that can be leveraged separately for its respective resolution, meaning a smaller network for coarser reconstructions. Experiments on several 2D and 3D datasets show improvements in reconstruction accuracy, representational capacity and training speed compared to baselines. ",
    "url": "https://arxiv.org/abs/2202.04713",
    "authors": [
      "Zoe Landgraf",
      "Alexander Sorkine Hornung",
      "Ricardo Silveira Cabral"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.04725",
    "title": "TamilEmo: Finegrained Emotion Detection Dataset for Tamil",
    "abstract": "Emotional Analysis from textual input has been considered both a challenging and interesting task in Natural Language Processing. However, due to the lack of datasets in low-resource languages (i.e. Tamil), it is difficult to conduct research of high standard in this area. Therefore we introduce this labelled dataset (a largest manually annotated dataset of more than 42k Tamil YouTube comments, labelled for 31 emotions including neutral) for emotion recognition. The goal of this dataset is to improve emotion detection in multiple downstream tasks in Tamil. We have also created three different groupings of our emotions (3-class, 7-class and 31-class) and evaluated the model's performance on each category of the grouping. Our MURIL-base model has achieved a 0.60 macro average F1-score across our 3-class group dataset. With 7-class and 31-class groups, the Random Forest model performed well with a macro average F1-scores of 0.42 and 0.29 respectively. ",
    "url": "https://arxiv.org/abs/2202.04725",
    "authors": [
      "Charangan Vasantharajan",
      "Sean Benhur",
      "Prasanna Kumar Kumarasen",
      "Rahul Ponnusamy",
      "Sathiyaraj Thangasamy",
      "Ruba Priyadharshini",
      "Thenmozhi Durairaj",
      "Kanchana Sivanraju",
      "Anbukkarasi Sampath",
      "Bharathi Raja Chakravarthi",
      "John Phillip McCrae"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.04731",
    "title": "Graph Neural Network for Cell Tracking in Microscopy Videos",
    "abstract": "We present a novel graph neural network (GNN) approach for cell tracking in high-throughput microscopy videos. By modeling the entire time-lapse sequence as a direct graph where cell instances are represented by its nodes and their associations by its edges, we extract the entire set of cell trajectories by looking for the maximal paths in the graph. This is accomplished by several key contributions incorporated into an end-to-end deep learning framework. We exploit a deep metric learning algorithm to extract cell feature vectors that distinguish between instances of different biological cells and assemble same cell instances. We introduce a new GNN block type which enables a mutual update of node and edge feature vectors, thus facilitating the underlying message passing process. The message passing concept, whose extent is determined by the number of GNN blocks, is of fundamental importance as it enables the `flow' of information between nodes and edges much behind their neighbors in consecutive frames. Finally, we solve an edge classification problem and use the identified active edges to construct the cells' tracks and lineage trees. We demonstrate the strengths of the proposed cell tracking approach by applying it to 2D and 3D datasets of different cell types, imaging setups, and experimental conditions. We show that our framework outperforms most of the current state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2202.04731",
    "authors": [
      "Tal Ben-Haim",
      "Tammy Riklin-Raviv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.04755",
    "title": "DeepSSN: a deep convolutional neural network to assess spatial scene  similarity",
    "abstract": "Spatial-query-by-sketch is an intuitive tool to explore human spatial knowledge about geographic environments and to support communication with scene database queries. However, traditional sketch-based spatial search methods perform insufficiently due to their inability to find hidden multi-scale map features from mental sketches. In this research, we propose a deep convolutional neural network, namely Deep Spatial Scene Network (DeepSSN), to better assess the spatial scene similarity. In DeepSSN, a triplet loss function is designed as a comprehensive distance metric to support the similarity assessment. A positive and negative example mining strategy using qualitative constraint networks in spatial reasoning is designed to ensure a consistently increasing distinction of triplets during the training process. Moreover, we develop a prototype spatial scene search system using the proposed DeepSSN, in which the users input spatial query via sketch maps and the system can automatically augment the sketch training data. The proposed model is validated using multi-source conflated map data including 131,300 labeled scene samples after data augmentation. The empirical results demonstrate that the DeepSSN outperforms baseline methods including k-nearest-neighbors, multilayer perceptron, AlexNet, DenseNet, and ResNet using mean reciprocal rank and precision metrics. This research advances geographic information retrieval studies by introducing a novel deep learning method tailored to spatial scene queries. ",
    "url": "https://arxiv.org/abs/2202.04755",
    "authors": [
      "Danhuai Guo",
      "Shiyin Ge",
      "Shu Zhang",
      "Song Gao",
      "Ran Tao",
      "Yangang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.04757",
    "title": "A Novel Encoder-Decoder Network with Guided Transmission Map for Single  Image Dehazing",
    "abstract": "A novel Encoder-Decoder Network with Guided Transmission Map (EDN-GTM) for single image dehazing scheme is proposed in this paper. The proposed EDN-GTM takes conventional RGB hazy image in conjunction with its transmission map estimated by adopting dark channel prior as the inputs of the network. The proposed EDN-GTM utilizes U-Net for image segmentation as the core network and utilizes various modifications including spatial pyramid pooling module and Swish activation to achieve state-of-the-art dehazing performance. Experiments on benchmark datasets show that the proposed EDN-GTM outperforms most of traditional and deep learning-based image dehazing schemes in terms of PSNR and SSIM metrics. The proposed EDN-GTM furthermore proves its applicability to object detection problems. Specifically, when applied to an image preprocessing tool for driving object detection, the proposed EDN-GTM can efficiently remove haze and significantly improve detection accuracy by 4.73% in terms of mAP measure. The code is available at: https://github.com/tranleanh/edn-gtm. ",
    "url": "https://arxiv.org/abs/2202.04757",
    "authors": [
      "Le-Anh Tran",
      "Seokyong Moon",
      "Dong-Chul Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.04768",
    "title": "Boosting Graph Neural Networks by Injecting Pooling in Message Passing",
    "abstract": "There has been tremendous success in the field of graph neural networks (GNNs) as a result of the development of the message-passing (MP) layer, which updates the representation of a node by combining it with its neighbors to address variable-size and unordered graphs. Despite the fruitful progress of MP GNNs, their performance can suffer from over-smoothing, when node representations become too similar and even indistinguishable from one another. Furthermore, it has been reported that intrinsic graph structures are smoothed out as the GNN layer increases. Inspired by the edge-preserving bilateral filters used in image processing, we propose a new, adaptable, and powerful MP framework to prevent over-smoothing. Our bilateral-MP estimates a pairwise modular gradient by utilizing the class information of nodes, and further preserves the global graph structure by using the gradient when the aggregating function is applied. Our proposed scheme can be generalized to all ordinary MP GNNs. Experiments on five medium-size benchmark datasets using four state-of-the-art MP GNNs indicate that the bilateral-MP improves performance by alleviating over-smoothing. By inspecting quantitative measurements, we additionally validate the effectiveness of the proposed mechanism in preventing the over-smoothing issue. ",
    "url": "https://arxiv.org/abs/2202.04768",
    "authors": [
      "Hyeokjin Kwon",
      "Jong-Min Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.04769",
    "title": "Spectral Propagation Graph Network for Few-shot Time Series  Classification",
    "abstract": "Few-shot Time Series Classification (few-shot TSC) is a challenging problem in time series analysis. It is more difficult to classify when time series of the same class are not completely consistent in spectral domain or time series of different classes are partly consistent in spectral domain. To address this problem, we propose a novel method named Spectral Propagation Graph Network (SPGN) to explicitly model and propagate the spectrum-wise relations between different time series with graph network. To the best of our knowledge, SPGN is the first to utilize spectral comparisons in different intervals and involve spectral propagation across all time series with graph networks for few-shot TSC. SPGN first uses bandpass filter to expand time series in spectral domain for calculating spectrum-wise relations between time series. Equipped with graph networks, SPGN then integrates spectral relations with label information to make spectral propagation. The further study conveys the bi-directional effect between spectral relations acquisition and spectral propagation. We conduct extensive experiments on few-shot TSC benchmarks. SPGN outperforms state-of-the-art results by a large margin in $4\\% \\sim 13\\%$. Moreover, SPGN surpasses them by around $12\\%$ and $9\\%$ under cross-domain and cross-way settings respectively. ",
    "url": "https://arxiv.org/abs/2202.04769",
    "authors": [
      "Ling Yang",
      "Shenda Hong",
      "Luxia Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.04770",
    "title": "Unsupervised Time-Series Representation Learning with Iterative Bilinear  Temporal-Spectral Fusion",
    "abstract": "Unsupervised/self-supervised time series representation learning is a challenging problem because of its complex dynamics and sparse annotations. Existing works mainly adopt the framework of contrastive learning with the time-based augmentation techniques to sample positives and negatives for contrastive training. Nevertheless, they mostly use segment-level augmentation derived from time slicing, which may bring about sampling bias and incorrect optimization with false negatives due to the loss of global context. Besides, they all pay no attention to incorporate the spectral information in feature representation. In this paper, we propose a unified framework, namely Bilinear Temporal-Spectral Fusion (BTSF). Specifically, we firstly utilize the instance-level augmentation with a simple dropout on the entire time series for maximally capturing long-term dependencies. We devise a novel iterative bilinear temporal-spectral fusion to explicitly encode the affinities of abundant time-frequency pairs, and iteratively refines representations in a fusion-and-squeeze manner with Spectrum-to-Time (S2T) and Time-to-Spectrum (T2S) Aggregation modules. We firstly conducts downstream evaluations on three major tasks for time series including classification, forecasting and anomaly detection. Experimental results shows that our BTSF consistently significantly outperforms the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2202.04770",
    "authors": [
      "Ling Yang",
      "Shenda Hong",
      "Luxia Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.04771",
    "title": "Orthogonal Matrices for MBAT Vector Symbolic Architectures, and a \"Soft\"  VSA Representation for JSON",
    "abstract": "Vector Symbolic Architectures (VSAs) give a way to represent a complex object as a single fixed-length vector, so that similar objects have similar vector representations. These vector representations then become easy to use for machine learning or nearest-neighbor search. We review a previously proposed VSA method, MBAT (Matrix Binding of Additive Terms), which uses multiplication by random matrices for binding related terms. However, multiplying by such matrices introduces instabilities which can harm performance. Making the random matrices be orthogonal matrices provably fixes this problem. With respect to larger scale applications, we see how to apply MBAT vector representations for any data expressed in JSON. JSON is used in numerous programming languages to express complex data, but its native format appears highly unsuited for machine learning. Expressing JSON as a fixed-length vector makes it readily usable for machine learning and nearest-neighbor search. Creating such JSON vectors also shows that a VSA needs to employ binding operations that are non-commutative. VSAs are now ready to try with full-scale practical applications, including healthcare, pharmaceuticals, and genomics. Keywords: MBAT (Matrix Binding of Additive Terms), VSA (Vector Symbolic Architecture), HDC (Hyperdimensional Computing), Distributed Representations, Binding, Orthogonal Matrices, Recurrent Connections, Machine Learning, Search, JSON, VSA Applications ",
    "url": "https://arxiv.org/abs/2202.04771",
    "authors": [
      "Stephen I. Gallant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2202.04781",
    "title": "Adversarial Attack and Defense of YOLO Detectors in Autonomous Driving  Scenarios",
    "abstract": "Visual detection is a key task in autonomous driving, and it serves as one foundation for self-driving planning and control. Deep neural networks have achieved promising results in various computer vision tasks, but they are known to be vulnerable to adversarial attacks. A comprehensive understanding of deep visual detectors' vulnerability is required before people can improve their robustness. However, only a few adversarial attack/defense works have focused on object detection, and most of them employed only classification and/or localization losses, ignoring the objectness aspect. In this paper, we identify a serious objectness-related adversarial vulnerability in YOLO detectors and present an effective attack strategy aiming the objectness aspect of visual detection in autonomous vehicles. Furthermore, to address such vulnerability, we propose a new objectness-aware adversarial training approach for visual detection. Experiments show that the proposed attack targeting the objectness aspect is 45.17% and 43.50% more effective than those generated from classification and/or localization losses on the KITTI and COCO_traffic datasets, respectively. Also, the proposed adversarial defense approach can improve the detectors' robustness against objectness-oriented attacks by up to 21% and 12% mAP on KITTI and COCO_traffic, respectively. ",
    "url": "https://arxiv.org/abs/2202.04781",
    "authors": [
      "Jung Im Choi",
      "Qing Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.04787",
    "title": "Proceedings of the Robust Artificial Intelligence System Assurance  (RAISA) Workshop 2022",
    "abstract": "The Robust Artificial Intelligence System Assurance (RAISA) workshop will focus on research, development and application of robust artificial intelligence (AI) and machine learning (ML) systems. Rather than studying robustness with respect to particular ML algorithms, our approach will be to explore robustness assurance at the system architecture level, during both development and deployment, and within the human-machine teaming context. While the research community is converging on robust solutions for individual AI models in specific scenarios, the problem of evaluating and assuring the robustness of an AI system across its entire life cycle is much more complex. Moreover, the operational context in which AI systems are deployed necessitates consideration of robustness and its relation to principles of fairness, privacy, and explainability. ",
    "url": "https://arxiv.org/abs/2202.04787",
    "authors": [
      "Olivia Brown",
      "Brad Dillman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.04798",
    "title": "Augmenting Neural Networks with Priors on Function Values",
    "abstract": "The need for function estimation in label-limited settings is common in the natural sciences. At the same time, prior knowledge of function values is often available in these domains. For example, data-free biophysics-based models can be informative on protein properties, while quantum-based computations can be informative on small molecule properties. How can we coherently leverage such prior knowledge to help improve a neural network model that is quite accurate in some regions of input space -- typically near the training data -- but wildly wrong in other regions? Bayesian neural networks (BNN) enable the user to specify prior information only on the neural network weights, not directly on the function values. Moreover, there is in general no clear mapping between these. Herein, we tackle this problem by developing an approach to augment BNNs with prior information on the function values themselves. Our probabilistic approach yields predictions that rely more heavily on the prior information when the epistemic uncertainty is large, and more heavily on the neural network when the epistemic uncertainty is small. ",
    "url": "https://arxiv.org/abs/2202.04798",
    "authors": [
      "Hunter Nisonoff",
      "Yixin Wang",
      "Jennifer Listgarten"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.04821",
    "title": "Measuring disentangled generative spatio-temporal representation",
    "abstract": "Disentangled representation learning offers useful properties such as dimension reduction and interpretability, which are essential to modern deep learning approaches. Although deep learning techniques have been widely applied to spatio-temporal data mining, there has been little attention to further disentangle the latent features and understanding their contribution to the model performance, particularly their mutual information and correlation across features. In this study, we adopt two state-of-the-art disentangled representation learning methods and apply them to three large-scale public spatio-temporal datasets. To evaluate their performance, we propose an internal evaluation metric focusing on the degree of correlations among latent variables of the learned representations and the prediction performance of the downstream tasks. Empirical results show that our modified method can learn disentangled representations that achieve the same level of performance as existing state-of-the-art ST deep learning methods in a spatio-temporal sequence forecasting problem. Additionally, we find that our methods can be used to discover real-world spatial-temporal semantics to describe the variables in the learned representation. ",
    "url": "https://arxiv.org/abs/2202.04821",
    "authors": [
      "Sichen Zhao",
      "Wei Shao",
      "Jeffrey Chan",
      "Flora D. Salim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04822",
    "title": "Survey on Graph Neural Network Acceleration: An Algorithmic Perspective",
    "abstract": "Graph neural networks (GNNs) have been a hot spot of recent research and are widely utilized in diverse applications. However, with the use of huger data and deeper models, an urgent demand is unsurprisingly made to accelerate GNNs for more efficient execution. In this paper, we provide a comprehensive survey on acceleration methods for GNNs from an algorithmic perspective. We first present a new taxonomy to classify existing acceleration methods into five categories. Based on the classification, we systematically discuss these methods and highlight their correlations. Next, we provide comparisons from aspects of the efficiency and characteristics of these methods. Finally, we suggest some promising prospects for future research. ",
    "url": "https://arxiv.org/abs/2202.04822",
    "authors": [
      "Xin Liu",
      "Mingyu Yan",
      "Lei Deng",
      "Guoqi Li",
      "Xiaochun Ye",
      "Dongrui Fan",
      "Shirui Pan",
      "Yuan Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.04829",
    "title": "Target-aware Molecular Graph Generation",
    "abstract": "Generating molecules with desired biological activities has attracted growing attention in drug discovery. Previous molecular generation models are designed as chemocentric methods that hardly consider the drug-target interaction, limiting their practical applications. In this paper, we aim to generate molecular drugs in a target-aware manner that bridges biological activity and molecular design. To solve this problem, we compile a benchmark dataset from several publicly available datasets and build baselines in a unified framework. Building on the recent advantages of flow-based molecular generation models, we propose SiamFlow, which forces the flow to fit the distribution of target sequence embeddings in latent space. Specifically, we employ an alignment loss and a uniform loss to bring target sequence embeddings and drug graph embeddings into agreements while avoiding collapse. Furthermore, we formulate the alignment into a one-to-many problem by learning spaces of target sequence embeddings. Experiments quantitatively show that our proposed method learns meaningful representations in the latent space toward the target-aware molecular graph generation and provides an alternative approach to bridge biology and chemistry in drug discovery. ",
    "url": "https://arxiv.org/abs/2202.04829",
    "authors": [
      "Cheng Tan",
      "Zhangyang Gao",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.04836",
    "title": "Deconstructing The Inductive Biases Of Hamiltonian Neural Networks",
    "abstract": "Physics-inspired neural networks (NNs), such as Hamiltonian or Lagrangian NNs, dramatically outperform other learned dynamics models by leveraging strong inductive biases. These models, however, are challenging to apply to many real world systems, such as those that don't conserve energy or contain contacts, a common setting for robotics and reinforcement learning. In this paper, we examine the inductive biases that make physics-inspired models successful in practice. We show that, contrary to conventional wisdom, the improved generalization of HNNs is the result of modeling acceleration directly and avoiding artificial complexity from the coordinate system, rather than symplectic structure or energy conservation. We show that by relaxing the inductive biases of these models, we can match or exceed performance on energy-conserving systems while dramatically improving performance on practical, non-conservative systems. We extend this approach to constructing transition models for common Mujoco environments, showing that our model can appropriately balance inductive biases with the flexibility required for model-based control. ",
    "url": "https://arxiv.org/abs/2202.04836",
    "authors": [
      "Nate Gruver",
      "Marc Finzi",
      "Samuel Stanton",
      "Andrew Gordon Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.04842",
    "title": "Networks and Identity Drive Geographic Properties of the Diffusion of  Linguistic Innovation",
    "abstract": "Adoption of cultural innovation (e.g., music, beliefs, language) is often geographically correlated, with adopters largely residing within the boundaries of relatively few well-studied, socially significant areas. These cultural regions are often hypothesized to be the result of either (i) identity performance driving the adoption of cultural innovation, or (ii) homophily in the networks underlying diffusion. In this study, we show that demographic identity and network topology are both required to model the diffusion of innovation, as they play complementary roles in producing its spatial properties. We develop an agent-based model of cultural adoption, and validate geographic patterns of transmission in our model against a novel dataset of innovative words that we identify from a 10% sample of Twitter. Using our model, we are able to directly compare a combined network + identity model of diffusion to simulated network-only and identity-only counterfactuals -- allowing us to test the separate and combined roles of network and identity. While social scientists often treat either network or identity as the core social structure in modeling culture change, we show that key geographic properties of diffusion actually depend on both factors as each one influences different mechanisms of diffusion. Specifically, the network principally drives spread among urban counties via weak-tie diffusion, while identity plays a disproportionate role in transmission among rural counties via strong-tie diffusion. Diffusion between urban and rural areas, a key component in innovation diffusing nationally, requires both network and identity. Our work suggests that models must integrate both factors in order to understand and reproduce the adoption of innovation. ",
    "url": "https://arxiv.org/abs/2202.04842",
    "authors": [
      "Aparna Ananthasubramaniam",
      "David Jurgens",
      "Daniel M. Romero"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2202.04856",
    "title": "PPA: Preference Profiling Attack Against Federated Learning",
    "abstract": "Federated learning (FL) trains a global model across a number of decentralized participants, each with a local dataset. Compared to traditional centralized learning, FL does not require direct local datasets access and thus mitigates data security and privacy concerns. However, data privacy concerns for FL still exist due to inference attacks, including known membership inference, property inference, and data inversion. In this work, we reveal a new type of privacy inference attack, coined Preference Profiling Attack (PPA), that accurately profiles private preferences of a local user. In general, the PPA can profile top-k, especially for top-1, preferences contingent on the local user's characteristics. Our key insight is that the gradient variation of a local user's model has a distinguishable sensitivity to the sample proportion of a given class, especially the majority/minority class. By observing a user model's gradient sensitivity to a class, the PPA can profile the sample proportion of the class in the user's local dataset and thus the user's preference of the class is exposed. The inherent statistical heterogeneity of FL further facilitates the PPA. We have extensively evaluated the PPA's effectiveness using four datasets from the image domains of MNIST, CIFAR10, Products-10K and RAF-DB. Our results show that the PPA achieves 90% and 98% top-1 attack accuracy to the MNIST and CIFAR10, respectively. More importantly, in the real-world commercial scenarios of shopping (i.e., Products-10K) and the social network (i.e., RAF-DB), the PPA gains a top-1 attack accuracy of 78% in the former case to infer the most ordered items, and 88% in the latter case to infer a victim user's emotions. Although existing countermeasures such as dropout and differential privacy protection can lower the PPA's accuracy to some extent, they unavoidably incur notable global model deterioration. ",
    "url": "https://arxiv.org/abs/2202.04856",
    "authors": [
      "Chunyi Zhou",
      "Yansong Gao",
      "Anmin Fu",
      "Kai Chen",
      "Zhiyang Dai",
      "Zhi Zhang",
      "Minhui Xue",
      "Yuqing Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04872",
    "title": "A Note on the Misinterpretation of the US Census Re-identification  Attack",
    "abstract": "In 2018, the US Census Bureau designed a new data reconstruction and re-identification attack and tested it against their 2010 data release. The specific attack executed by the Bureau allows an attacker to infer the race and ethnicity of respondents with average 75% precision for 85% of the respondents, assuming that the attacker knows the correct age, sex, and address of the respondents. They interpreted the attack as exceeding the Bureau's privacy standards, and so introduced stronger privacy protections for the 2020 Census in the form of the TopDown Algorithm (TDA). This paper demonstrates that race and ethnicity can be inferred from the TDA-protected census data with substantially better precision and recall, using less prior knowledge: only the respondents' address. Race and ethnicity can be inferred with average 75% precision for 98% of the respondents, and can be inferred with 100% precision for 11% of the respondents. The inference is done by simply assuming that the race/ethnicity of the respondent is that of the majority race/ethnicity for the respondent's census block. The conclusion to draw from this simple demonstration is NOT that the Bureau's data releases lack adequate privacy protections. Indeed it is the purpose of the data releases to allow this kind of inference. The problem, rather, is that the Bureau's criteria for measuring privacy is flawed and overly pessimistic. ",
    "url": "https://arxiv.org/abs/2202.04872",
    "authors": [
      "Paul Francis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.04877",
    "title": "Memory-based gaze prediction in deep imitation learning for robot  manipulation",
    "abstract": "Deep imitation learning is a promising approach that does not require hard-coded control rules in autonomous robot manipulation. The current applications of deep imitation learning to robot manipulation have been limited to reactive control based on the states at the current time step. However, future robots will also be required to solve tasks utilizing their memory obtained by experience in complicated environments (e.g., when the robot is asked to find a previously used object on a shelf). In such a situation, simple deep imitation learning may fail because of distractions caused by complicated environments. We propose that gaze prediction from sequential visual input enables the robot to perform a manipulation task that requires memory. The proposed algorithm uses a Transformer-based self-attention architecture for the gaze estimation based on sequential data to implement memory. The proposed method was evaluated with a real robot multi-object manipulation task that requires memory of the previous states. ",
    "url": "https://arxiv.org/abs/2202.04877",
    "authors": [
      "Heecheol Kim",
      "Yoshiyuki Ohmura",
      "Yasuo Kuniyoshi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.04883",
    "title": "Towards the automated large-scale reconstruction of past road networks  from historical maps",
    "abstract": "Transportation infrastructure, such as road or railroad networks, represent a fundamental component of our civilization. For sustainable planning and informed decision making, a thorough understanding of the long-term evolution of transportation infrastructure such as road networks is crucial. However, spatially explicit, multi-temporal road network data covering large spatial extents are scarce and rarely available prior to the 2000s. Herein, we propose a framework that employs increasingly available scanned and georeferenced historical map series to reconstruct past road networks, by integrating abundant, contemporary road network data and color information extracted from historical maps. Specifically, our method uses contemporary road segments as analytical units and extracts historical roads by inferring their existence in historical map series based on image processing and clustering techniques. We tested our method on over 300,000 road segments representing more than 50,000 km of the road network in the United States, extending across three study areas that cover 53 historical topographic map sheets dated between 1890 and 1950. We evaluated our approach by comparison to other historical datasets and against manually created reference data, achieving F-1 scores of up to 0.95, and showed that the extracted road network statistics are highly plausible over time, i.e., following general growth patterns. We demonstrated that contemporary geospatial data integrated with information extracted from historical map series open up new avenues for the quantitative analysis of long-term urbanization processes and landscape changes far beyond the era of operational remote sensing and digital cartography. ",
    "url": "https://arxiv.org/abs/2202.04883",
    "authors": [
      "Johannes H. Uhl",
      "Stefan Leyk",
      "Yao-Yi Chiang",
      "Craig A. Knoblock"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2202.04887",
    "title": "TaxoEnrich: Self-Supervised Taxonomy Completion via Structure-Semantic  Representations",
    "abstract": "Taxonomies are fundamental to many real-world applications in various domains, serving as structural representations of knowledge. To deal with the increasing volume of new concepts needed to be organized as taxonomies, researchers turn to automatically completion of an existing taxonomy with new concepts. In this paper, we propose TaxoEnrich, a new taxonomy completion framework, which effectively leverages both semantic features and structural information in the existing taxonomy and offers a better representation of candidate position to boost the performance of taxonomy completion. Specifically, TaxoEnrich consists of four components: (1) taxonomy-contextualized embedding which incorporates both semantic meanings of concept and taxonomic relations based on powerful pretrained language models; (2) a taxonomy-aware sequential encoder which learns candidate position representations by encoding the structural information of taxonomy; (3) a query-aware sibling encoder which adaptively aggregates candidate siblings to augment candidate position representations based on their importance to the query-position matching; (4) a query-position matching model which extends existing work with our new candidate position representations. Extensive experiments on four large real-world datasets from different domains show that \\TaxoEnrich achieves the best performance among all evaluation metrics and outperforms previous state-of-the-art methods by a large margin. ",
    "url": "https://arxiv.org/abs/2202.04887",
    "authors": [
      "Minhao Jiang",
      "Xiangchen Song",
      "Jieyu Zhang",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2202.04890",
    "title": "Improving performance of aircraft detection in satellite imagery while  limiting the labelling effort: Hybrid active learning",
    "abstract": "The earth observation industry provides satellite imagery with high spatial resolution and short revisit time. To allow efficient operational employment of these images, automating certain tasks has become necessary. In the defense domain, aircraft detection on satellite imagery is a valuable tool for analysts. Obtaining high performance detectors on such a task can only be achieved by leveraging deep learning and thus us-ing a large amount of labeled data. To obtain labels of a high enough quality, the knowledge of military experts is needed.We propose a hybrid clustering active learning method to select the most relevant data to label, thus limiting the amount of data required and further improving the performances. It combines diversity- and uncertainty-based active learning selection methods. For aircraft detection by segmentation, we show that this method can provide better or competitive results compared to other active learning methods. ",
    "url": "https://arxiv.org/abs/2202.04890",
    "authors": [
      "Julie Imbert",
      "Gohar Dashyan",
      "Alex Goupilleau",
      "Tugdual Ceillier",
      "Marie-Caroline Corbineau"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2202.04891",
    "title": "Case-based reasoning for rare events prediction on strategic sites",
    "abstract": "Satellite imagery is now widely used in the defense sector for monitoring locations of interest. Although the increasing amount of data enables pattern identification and therefore prediction, carrying this task manually is hardly feasible. We hereby propose a cased-based reasoning approach for automatic prediction of rare events on strategic sites. This method allows direct incorporation of expert knowledge, and is adapted to irregular time series and small-size datasets. Experiments are carried out on two use-cases using real satellite images: the prediction of submarines arrivals and departures from a naval base, and the forecasting of imminent rocket launches on two space bases. The proposed method significantly outperforms a random selection of reference cases on these challenging applications, showing its strong potential. ",
    "url": "https://arxiv.org/abs/2202.04891",
    "authors": [
      "Vincent Vidal",
      "Marie-Caroline Corbineau",
      "Tugdual Ceillier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.04897",
    "title": "InterHT: Knowledge Graph Embeddings by Interaction between Head and Tail  Entities",
    "abstract": "Knowledge graph embedding (KGE) models learn the representation of entities and relations in knowledge graphs. Distance-based methods show promising performance on link prediction task, which predicts the result by the distance between two entity representations. However, most of these methods represent the head entity and tail entity separately, which limits the model capacity. We propose a novel distance-based method named InterHT that allows the head and tail entities to interact better and get better entity representation. Experimental results show that our proposed method achieves the best results on ogbl-wikikg2 dataset. ",
    "url": "https://arxiv.org/abs/2202.04897",
    "authors": [
      "Baoxin Wang",
      "Qingye Meng",
      "Ziyue Wang",
      "Dayong Wu",
      "Wanxiang Che",
      "Shijin Wang",
      "Zhigang Chen",
      "Cong Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.04903",
    "title": "Investigating Explainability of Generative AI for Code through  Scenario-based Design",
    "abstract": "What does it mean for a generative AI model to be explainable? The emergent discipline of explainable AI (XAI) has made great strides in helping people understand discriminative models. Less attention has been paid to generative models that produce artifacts, rather than decisions, as output. Meanwhile, generative AI (GenAI) technologies are maturing and being applied to application domains such as software engineering. Using scenario-based design and question-driven XAI design approaches, we explore users' explainability needs for GenAI in three software engineering use cases: natural language to code, code translation, and code auto-completion. We conducted 9 workshops with 43 software engineers in which real examples from state-of-the-art generative AI models were used to elicit users' explainability needs. Drawing from prior work, we also propose 4 types of XAI features for GenAI for code and gathered additional design ideas from participants. Our work explores explainability needs for GenAI for code and demonstrates how human-centered approaches can drive the technical development of XAI in novel domains. ",
    "url": "https://arxiv.org/abs/2202.04903",
    "authors": [
      "Jiao Sun",
      "Q. Vera Liao",
      "Michael Muller",
      "Mayank Agarwal",
      "Stephanie Houde",
      "Kartik Talamadupula",
      "Justin D. Weisz"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2202.04910",
    "title": "Instance-wise algorithm configuration with graph neural networks",
    "abstract": "We present our submission for the configuration task of the Machine Learning for Combinatorial Optimization (ML4CO) NeurIPS 2021 competition. The configuration task is to predict a good configuration of the open-source solver SCIP to solve a mixed integer linear program (MILP) efficiently. We pose this task as a supervised learning problem: First, we compile a large dataset of the solver performance for various configurations and all provided MILP instances. Second, we use this data to train a graph neural network that learns to predict a good configuration for a specific instance. The submission was tested on the three problem benchmarks of the competition and improved solver performance over the default by 12% and 35% and 8% across the hidden test instances. We ranked 3rd out of 15 on the global leaderboard and won the student leaderboard. We make our code publicly available at \\url{https://github.com/RomeoV/ml4co-competition} . ",
    "url": "https://arxiv.org/abs/2202.04910",
    "authors": [
      "Romeo Valentin",
      "Claudio Ferrari",
      "J\u00e9r\u00e9my Scheurer",
      "Andisheh Amrollahi",
      "Chris Wendler",
      "Max B. Paulus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2202.04932",
    "title": "Robust Sylvester-Gallai type theorem for quadratic polynomials",
    "abstract": "In this work, we extend the robust version of the Sylvester-Gallai theorem, obtained by Barak, Dvir, Wigderson and Yehudayoff, and by Dvir, Saraf and Wigderson, to the case of quadratic polynomials. Specifically, we prove that if $\\mathcal{Q}\\subset \\mathbb{C}[x_1.\\ldots,x_n]$ is a finite set, $|\\mathcal{Q}|=m$, of irreducible quadratic polynomials that satisfy the following condition: There is $\\delta>0$ such that for every $Q\\in\\mathcal{Q}$ there are at least $\\delta m$ polynomials $P\\in \\mathcal{Q}$ such that whenever $Q$ and $P$ vanish then so does a third polynomial in $\\mathcal{Q}\\setminus\\{Q,P\\}$, then $\\dim(\\text{span}({\\mathcal{Q}}))=\\text{poly}(1/\\delta)$. The work of Barak et al. and Dvir et al. studied the case of linear polynomials and proved an upper bound of $O(1/\\delta)$ on the dimension (in the first work an upper bound of $O(1/\\delta^2)$ was given, which was improved to $O(1/\\delta)$ in the second work). ",
    "url": "https://arxiv.org/abs/2202.04932",
    "authors": [
      "Shir Peleg",
      "Amir Shpilka"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2202.04936",
    "title": "Graph Neural Network for Local Corruption Recovery",
    "abstract": "Graph neural networks (GNNs) have seen a surge of development for exploiting the relational information of input graphs. Nevertheless, messages propagating through a graph contain both interpretable patterns and small perturbations. Despite global noise could be distributed over the entire graph data, it is not uncommon that corruptions appear well-concealed and merely pollute local regions while still having a vital influence on the GNN learning and prediction performance. This work tackles the graph recovery problem from local poisons by a robustness representation learning. Our developed strategy identifies regional graph perturbations and formulates a robust hidden feature representation for GNNs. A mask function pinpointed the anomalies without prior knowledge, and an $\\ell_{p,q}$ regularizer defends local poisonings through pursuing sparsity in the framelet domain while maintaining a conditional closeness between the observation and new representation. The proposed robust computational unit alleviates the inertial alternating direction method of multipliers to achieve an efficient solution. Extensive experiments show that our new model recovers graph representations from local pollution and achieves excellent performance. ",
    "url": "https://arxiv.org/abs/2202.04936",
    "authors": [
      "Bingxin Zhou",
      "Yuanhong Jiang",
      "Yu Guang Wang",
      "Jingwei Liang",
      "Junbin Gao",
      "Shirui Pan",
      "Xiaoqun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04964",
    "title": "Forecasting large-scale circulation regimes using deformable  convolutional neural networks and global spatiotemporal climate data",
    "abstract": "Classifying the state of the atmosphere into a finite number of large-scale circulation regimes is a popular way of investigating teleconnections, the predictability of severe weather events, and climate change. Here, we investigate a supervised machine learning approach based on deformable convolutional neural networks (deCNNs) and transfer learning to forecast the North Atlantic-European weather regimes during extended boreal winter for 1 to 15 days into the future. We apply state-of-the-art interpretation techniques from the machine learning literature to attribute particular regions of interest or potential teleconnections relevant for any given weather cluster prediction or regime transition. We demonstrate superior forecasting performance relative to several classical meteorological benchmarks, as well as logistic regression and random forests. Due to its wider field of view, we also observe deCNN achieving considerably better performance than regular convolutional neural networks at lead times beyond 5-6 days. Finally, we find transfer learning to be of paramount importance, similar to previous data-driven atmospheric forecasting studies. ",
    "url": "https://arxiv.org/abs/2202.04964",
    "authors": [
      "Andreas Holm Nielsen",
      "Alexandros Iosifidis",
      "Henrik Karstoft"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04972",
    "title": "IHGNN: Interactive Hypergraph Neural Network for Personalized Product  Search",
    "abstract": "A good personalized product search (PPS) system should not only focus on retrieving relevant products, but also consider user personalized preference. Recent work on PPS mainly adopts the representation learning paradigm, e.g., learning representations for each entity (including user, product and query) from historical user behaviors (aka. user-product-query interactions). However, we argue that existing methods do not sufficiently exploit the crucial collaborative signal, which is latent in historical interactions to reveal the affinity between the entities. Collaborative signal is quite helpful for generating high-quality representation, exploiting which would benefit the representation learning of one node from its connected nodes. To tackle this limitation, in this work, we propose a new model IHGNN for personalized product search. IHGNN resorts to a hypergraph constructed from the historical user-product-query interactions, which could completely preserve ternary relations and express collaborative signal based on the topological structure. On this basis, we develop a specific interactive hypergraph neural network to explicitly encode the structure information (i.e., collaborative signal) into the embedding process. It collects the information from the hypergraph neighbors and explicitly models neighbor feature interaction to enhance the representation of the target entity. Extensive experiments on three real-world datasets validate the superiority of our proposal over the state-of-the-arts. ",
    "url": "https://arxiv.org/abs/2202.04972",
    "authors": [
      "Dian Cheng",
      "Jiawei Chen",
      "Wenjun Peng",
      "Wenqin Ye",
      "Fuyu Lv",
      "Tao Zhuang",
      "Xiaoyi Zeng",
      "Xiangnan He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2202.04975",
    "title": "FedAttack: Effective and Covert Poisoning Attack on Federated  Recommendation via Hard Sampling",
    "abstract": "Federated learning (FL) is a feasible technique to learn personalized recommendation models from decentralized user data. Unfortunately, federated recommender systems are vulnerable to poisoning attacks by malicious clients. Existing recommender system poisoning methods mainly focus on promoting the recommendation chances of target items due to financial incentives. In fact, in real-world scenarios, the attacker may also attempt to degrade the overall performance of recommender systems. However, existing general FL poisoning methods for degrading model performance are either ineffective or not concealed in poisoning federated recommender systems. In this paper, we propose a simple yet effective and covert poisoning attack method on federated recommendation, named FedAttack. Its core idea is using globally hardest samples to subvert model training. More specifically, the malicious clients first infer user embeddings based on local user profiles. Next, they choose the candidate items that are most relevant to the user embeddings as hardest negative samples, and find the candidates farthest from the user embeddings as hardest positive samples. The model gradients inferred from these poisoned samples are then uploaded to the server for aggregation and model update. Since the behaviors of malicious clients are somewhat similar to users with diverse interests, they cannot be effectively distinguished from normal clients by the server. Extensive experiments on two benchmark datasets show that FedAttack can effectively degrade the performance of various federated recommender systems, meanwhile cannot be effectively detected nor defended by many existing methods. ",
    "url": "https://arxiv.org/abs/2202.04975",
    "authors": [
      "Chuhan Wu",
      "Fangzhao Wu",
      "Tao Qi",
      "Yongfeng Huang",
      "Xing Xie"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2202.04978",
    "title": "Towards Assessing and Characterizing the Semantic Robustness of Face  Recognition",
    "abstract": "Deep Neural Networks (DNNs) lack robustness against imperceptible perturbations to their input. Face Recognition Models (FRMs) based on DNNs inherit this vulnerability. We propose a methodology for assessing and characterizing the robustness of FRMs against semantic perturbations to their input. Our methodology causes FRMs to malfunction by designing adversarial attacks that search for identity-preserving modifications to faces. In particular, given a face, our attacks find identity-preserving variants of the face such that an FRM fails to recognize the images belonging to the same identity. We model these identity-preserving semantic modifications via direction- and magnitude-constrained perturbations in the latent space of StyleGAN. We further propose to characterize the semantic robustness of an FRM by statistically describing the perturbations that induce the FRM to malfunction. Finally, we combine our methodology with a certification technique, thus providing (i) theoretical guarantees on the performance of an FRM, and (ii) a formal description of how an FRM may model the notion of face identity. ",
    "url": "https://arxiv.org/abs/2202.04978",
    "authors": [
      "Juan C. P\u00e9rez",
      "Motasem Alfarra",
      "Ali Thabet",
      "Pablo Arbel\u00e1ez",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.04982",
    "title": "A Robust Version of Heged\u0171s's Lemma, with Applications",
    "abstract": "Heged\\H{u}s's lemma is the following combinatorial statement regarding polynomials over finite fields. Over a field $\\F$ of characteristic $p > 0$ and for $q$ a power of $p$, the lemma says that any multilinear polynomial $P\\in \\F[x_1,\\ldots,x_n]$ of degree less than $q$ that vanishes at all points in $\\{0,1\\}^n$ of Hamming weight $k\\in [q,n-q]$ must also vanish at all points in $\\{0,1\\}^n$ of weight $k + q$. This lemma was used by Heged\\H{u}s (2009) to give a solution to \\emph{Galvin's problem}, an extremal problem about set systems; by Alon, Kumar and Volk (2018) to improve the best-known multilinear circuit lower bounds; and by Hrube\\v{s}, Ramamoorthy, Rao and Yehudayoff (2019) to prove optimal lower bounds against depth-$2$ threshold circuits for computing some symmetric functions. In this paper, we formulate a robust version of Heged\\H{u}s's lemma. Informally, this version says that if a polynomial of degree $o(q)$ vanishes at most points of weight $k$, then it vanishes at many points of weight $k+q$. We prove this lemma and give three different applications. ",
    "url": "https://arxiv.org/abs/2202.04982",
    "authors": [
      "Srikanth Srinivasan"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2202.05014",
    "title": "Coverage Probability and Spectral Efficiency Analysis of Multi-Gateway  Downlink LoRa Networks",
    "abstract": "The system-level performance of multi-gateway downlink long-range (LoRa) networks is investigated in the present paper. Specifically, we first compute the active probability of a channel and the selection probability of an active end-device (ED) in the closed-form expressions. We then derive the coverage probability (Pcov) and the area spectral efficiency (ASE) under the impact of the capture effects and different spreading factor (SF) allocation schemes. Our findings show that both the Pcov and the ASE of the considered networks can be enhanced significantly by increasing both the duty cycle and the transmit power. Finally, Monte-Carlo simulations are provided to verify the accuracy of the proposed mathematical frameworks. ",
    "url": "https://arxiv.org/abs/2202.05014",
    "authors": [
      "Lam-Thanh Tu",
      "Abbas Bradai",
      "Yannis Pousset"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.05048",
    "title": "Quantune: Post-training Quantization of Convolutional Neural Networks  using Extreme Gradient Boosting for Fast Deployment",
    "abstract": "To adopt convolutional neural networks (CNN) for a range of resource-constrained targets, it is necessary to compress the CNN models by performing quantization, whereby precision representation is converted to a lower bit representation. To overcome problems such as sensitivity of the training dataset, high computational requirements, and large time consumption, post-training quantization methods that do not require retraining have been proposed. In addition, to compensate for the accuracy drop without retraining, previous studies on post-training quantization have proposed several complementary methods: calibration, schemes, clipping, granularity, and mixed-precision. To generate a quantized model with minimal error, it is necessary to study all possible combinations of the methods because each of them is complementary and the CNN models have different characteristics. However, an exhaustive or a heuristic search is either too time-consuming or suboptimal. To overcome this challenge, we propose an auto-tuner known as Quantune, which builds a gradient tree boosting model to accelerate the search for the configurations of quantization and reduce the quantization error. We evaluate and compare Quantune with the random, grid, and genetic algorithms. The experimental results show that Quantune reduces the search time for quantization by approximately 36.5x with an accuracy loss of 0.07 ~ 0.65% across six CNN models, including the fragile ones (MobileNet, SqueezeNet, and ShuffleNet). To support multiple targets and adopt continuously evolving quantization works, Quantune is implemented on a full-fledged compiler for deep learning as an open-sourced project. ",
    "url": "https://arxiv.org/abs/2202.05048",
    "authors": [
      "Jemin Lee",
      "Misun Yu",
      "Yongin Kwon",
      "Teaho Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05089",
    "title": "Backpropagation Clipping for Deep Learning with Differential Privacy",
    "abstract": "We present backpropagation clipping, a novel variant of differentially private stochastic gradient descent (DP-SGD) for privacy-preserving deep learning. Our approach clips each trainable layer's inputs (during the forward pass) and its upstream gradients (during the backward pass) to ensure bounded global sensitivity for the layer's gradient; this combination replaces the gradient clipping step in existing DP-SGD variants. Our approach is simple to implement in existing deep learning frameworks. The results of our empirical evaluation demonstrate that backpropagation clipping provides higher accuracy at lower values for the privacy parameter $\\epsilon$ compared to previous work. We achieve 98.7% accuracy for MNIST with $\\epsilon = 0.07$ and 74% accuracy for CIFAR-10 with $\\epsilon = 3.64$. ",
    "url": "https://arxiv.org/abs/2202.05089",
    "authors": [
      "Timothy Stevens",
      "Ivoline C. Ngong",
      "David Darais",
      "Calvin Hirsch",
      "David Slater",
      "Joseph P. Near"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05093",
    "title": "Two-Stage Deep Anomaly Detection with Heterogeneous Time Series Data",
    "abstract": "We introduce a data-driven anomaly detection framework using a manufacturing dataset collected from a factory assembly line. Given heterogeneous time series data consisting of operation cycle signals and sensor signals, we aim at discovering abnormal events. Motivated by our empirical findings that conventional single-stage benchmark approaches may not exhibit satisfactory performance under our challenging circumstances, we propose a two-stage deep anomaly detection (TDAD) framework in which two different unsupervised learning models are adopted depending on types of signals. In Stage I, we select anomaly candidates by using a model trained by operation cycle signals; in Stage II, we finally detect abnormal events out of the candidates by using another model, which is suitable for taking advantage of temporal continuity, trained by sensor signals. A distinguishable feature of our framework is that operation cycle signals are exploited first to find likely anomalous points, whereas sensor signals are leveraged to filter out unlikely anomalous points afterward. Our experiments comprehensively demonstrate the superiority over single-stage benchmark approaches, the model-agnostic property, and the robustness to difficult situations. ",
    "url": "https://arxiv.org/abs/2202.05093",
    "authors": [
      "Kyeong-Joong Jeong",
      "Jin-Duk Park",
      "Kyusoon Hwang",
      "Seong-Lyun Kim",
      "Won-Yong Shin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.05094",
    "title": "Hardware calibrated learning to compensate heterogeneity in analog  RRAM-based Spiking Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs) can unleash the full power of analog Resistive Random Access Memories (RRAMs) based circuits for low power signal processing. Their inherent computational sparsity naturally results in energy efficiency benefits. The main challenge implementing robust SNNs is the intrinsic variability (heterogeneity) of both analog CMOS circuits and RRAM technology. In this work, we assessed the performance and variability of RRAM-based neuromorphic circuits that were designed and fabricated using a 130\\,nm technology node. Based on these results, we propose a Neuromorphic Hardware Calibrated (NHC) SNN, where the learning circuits are calibrated on the measured data. We show that by taking into account the measured heterogeneity characteristics in the off-chip learning phase, the NHC SNN self-corrects its hardware non-idealities and learns to solve benchmark tasks with high accuracy. This work demonstrates how to cope with the heterogeneity of neurons and synapses for increasing classification accuracy in temporal tasks. ",
    "url": "https://arxiv.org/abs/2202.05094",
    "authors": [
      "Filippo Moro",
      "E. Esmanhotto",
      "T. Hirtzlin",
      "N. Castellani",
      "A. Trabelsi",
      "T. Dalgaty",
      "G. Molas",
      "F. Andrieu",
      "S. Brivio",
      "S. Spiga",
      "G. Indiveri",
      "M. Payvand",
      "E. Vianello"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.05101",
    "title": "Characterizations of Adjoint Sobolev Embedding Operators for Inverse  Problems",
    "abstract": "We consider the Sobolev embedding operator $E_s : H^s(\\Omega) \\to L_2(\\Omega)$ and its role in the solution of inverse problems. In particular, we collect various properties and representations of its adjoint operator $E_s^*$, which is a common component in both iterative and variational regularization methods. These include e.g. variational representations and connections to boundary value problems, Fourier and wavelet representations, as well as connections to spatial filters. While many of these results are already known to researchers from different fields, an overview or reference work is still missing. Hence, in this paper we aim to fill this gap, providing a collection of representations of $E_s^*$ which can serve both as a reference as well as a useful guide for its efficient numerical implementation in practice. ",
    "url": "https://arxiv.org/abs/2202.05101",
    "authors": [
      "Simon Hubmer",
      "Ekaterina Sherina"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2202.05107",
    "title": "Machine Learning-based Urban Canyon Path Loss Prediction using 28 GHz  Manhattan Measurements",
    "abstract": "Large bandwidth at mm-wave is crucial for 5G and beyond but the high path loss (PL) requires highly accurate PL prediction for network planning and optimization. Statistical models with slope-intercept fit fall short in capturing large variations seen in urban canyons, whereas ray-tracing, capable of characterizing site-specific features, faces challenges in describing foliage and street clutter and associated reflection/diffraction ray calculation. Machine learning (ML) is promising but faces three key challenges in PL prediction: 1) insufficient measurement data; 2) lack of extrapolation to new streets; 3) overwhelmingly complex features/models. We propose an ML-based urban canyon PL prediction model based on extensive 28 GHz measurements from Manhattan where street clutters are modeled via a LiDAR point cloud dataset and buildings by a mesh-grid building dataset. We extract expert knowledge-driven street clutter features from the point cloud and aggressively compress 3D-building information using convolutional-autoencoder. Using a new street-by-street training and testing procedure to improve generalizability, the proposed model using both clutter and building features achieves a prediction error (RMSE) of $4.8 \\pm 1.1$ dB compared to $10.6 \\pm 4.4$ dB and $6.5 \\pm 2.0$ dB for 3GPP LOS and slope-intercept prediction, respectively, where the standard deviation indicates street-by-street variation. By only using four most influential clutter features, RMSE of $5.5\\pm 1.1$ dB is achieved. ",
    "url": "https://arxiv.org/abs/2202.05107",
    "authors": [
      "Ankit Gupta",
      "Jinfeng Du",
      "Dmitry Chizhik",
      "Reinaldo A. Valenzuela",
      "Mathini Sellathurai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.05123",
    "title": "Unaligned but Safe -- Formally Compensating Performance Limitations for  Imprecise 2D Object Detection",
    "abstract": "In this paper, we consider the imperfection within machine learning-based 2D object detection and its impact on safety. We address a special sub-type of performance limitations: the prediction bounding box cannot be perfectly aligned with the ground truth, but the computed Intersection-over-Union metric is always larger than a given threshold. Under such type of performance limitation, we formally prove the minimum required bounding box enlargement factor to cover the ground truth. We then demonstrate that the factor can be mathematically adjusted to a smaller value, provided that the motion planner takes a fixed-length buffer in making its decisions. Finally, observing the difference between an empirically measured enlargement factor and our formally derived worst-case enlargement factor offers an interesting connection between the quantitative evidence (demonstrated by statistics) and the qualitative evidence (demonstrated by worst-case analysis). ",
    "url": "https://arxiv.org/abs/2202.05123",
    "authors": [
      "Tobias Schuster",
      "Emmanouil Seferis",
      "Simon Burton",
      "Chih-Hong Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2202.05129",
    "title": "Help Me Explore: Minimal Social Interventions for Graph-Based Autotelic  Agents",
    "abstract": "In the quest for autonomous agents learning open-ended repertoires of skills, most works take a Piagetian perspective: learning trajectories are the results of interactions between developmental agents and their physical environment. The Vygotskian perspective, on the other hand, emphasizes the centrality of the socio-cultural environment: higher cognitive functions emerge from transmissions of socio-cultural processes internalized by the agent. This paper argues that both perspectives could be coupled within the learning of autotelic agents to foster their skill acquisition. To this end, we make two contributions: 1) a novel social interaction protocol called Help Me Explore (HME), where autotelic agents can benefit from both individual and socially guided exploration. In social episodes, a social partner suggests goals at the frontier of the learning agent knowledge. In autotelic episodes, agents can either learn to master their own discovered goals or autonomously rehearse failed social goals; 2) GANGSTR, a graph-based autotelic agent for manipulation domains capable of decomposing goals into sequences of intermediate sub-goals. We show that when learning within HME, GANGSTR overcomes its individual learning limits by mastering the most complex configurations (e.g. stacks of 5 blocks) with only few social interventions. ",
    "url": "https://arxiv.org/abs/2202.05129",
    "authors": [
      "Ahmed Akakzia",
      "Olivier Serris",
      "Olivier Sigaud",
      "C\u00e9dric Colas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2202.05139",
    "title": "Game of Privacy: Towards Better Federated Platform Collaboration under  Privacy Restriction",
    "abstract": "Vertical federated learning (VFL) aims to train models from cross-silo data with different feature spaces stored on different platforms. Existing VFL methods usually assume all data on each platform can be used for model training. However, due to the intrinsic privacy risks of federated learning, the total amount of involved data may be constrained. In addition, existing VFL studies usually assume only one platform has task labels and can benefit from the collaboration, making it difficult to attract other platforms to join in the collaborative learning. In this paper, we study the platform collaboration problem in VFL under privacy constraint. We propose to incent different platforms through a reciprocal collaboration, where all platforms can exploit multi-platform information in the VFL framework to benefit their own tasks. With limited privacy budgets, each platform needs to wisely allocate its data quotas for collaboration with other platforms. Thereby, they naturally form a multi-party game. There are two core problems in this game, i.e., how to appraise other platforms' data value to compute game rewards and how to optimize policies to solve the game. To evaluate the contributions of other platforms' data, each platform offers a small amount of \"deposit\" data to participate in the VFL. We propose a performance estimation method to predict the expected model performance when involving different amount combinations of inter-platform data. To solve the game, we propose a platform negotiation method that simulates the bargaining among platforms and locally optimizes their policies via gradient descent. Extensive experiments on two real-world datasets show that our approach can effectively facilitate the collaborative exploitation of multi-platform data in VFL under privacy restrictions. ",
    "url": "https://arxiv.org/abs/2202.05139",
    "authors": [
      "Chuhan Wu",
      "Fangzhao Wu",
      "Tao Qi",
      "Yanlin Wang",
      "Yongfeng Huang",
      "Xing Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05140",
    "title": "Transferable and Adaptable Driving Behavior Prediction",
    "abstract": "While autonomous vehicles still struggle to solve challenging situations during on-road driving, humans have long mastered the essence of driving with efficient, transferable, and adaptable driving capability. By mimicking humans' cognition model and semantic understanding during driving, we propose HATN, a hierarchical framework to generate high-quality, transferable, and adaptable predictions for driving behaviors in multi-agent dense-traffic environments. Our hierarchical method consists of a high-level intention identification policy and a low-level trajectory generation policy. We introduce a novel semantic sub-task definition and generic state representation for each sub-task. With these techniques, the hierarchical framework is transferable across different driving scenarios. Besides, our model is able to capture variations of driving behaviors among individuals and scenarios by an online adaptation module. We demonstrate our algorithms in the task of trajectory prediction for real traffic data at intersections and roundabouts from the INTERACTION dataset. Through extensive numerical studies, it is evident that our method significantly outperformed other methods in terms of prediction accuracy, transferability, and adaptability. Pushing the state-of-the-art performance by a considerable margin, we also provide a cognitive view of understanding the driving behavior behind such improvement. We highlight that in the future, more research attention and effort are deserved for transferability and adaptability. It is not only due to the promising performance elevation of prediction and planning algorithms, but more fundamentally, they are crucial for the scalable and general deployment of autonomous vehicles. ",
    "url": "https://arxiv.org/abs/2202.05140",
    "authors": [
      "Letian Wang",
      "Yeping Hu",
      "Liting Sun",
      "Wei Zhan",
      "Masayoshi Tomizuka",
      "Changliu Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.05144",
    "title": "InPars: Data Augmentation for Information Retrieval using Large Language  Models",
    "abstract": "The information retrieval community has recently witnessed a revolution due to large pretrained transformer models. Another key ingredient for this revolution was the MS MARCO dataset, whose scale and diversity has enabled zero-shot transfer learning to various tasks. However, not all IR tasks and domains can benefit from one single dataset equally. Extensive research in various NLP tasks has shown that using domain-specific training data, as opposed to a general-purpose one, improves the performance of neural models. In this work, we harness the few-shot capabilities of large pretrained language models as synthetic data generators for IR tasks. We show that models finetuned solely on our unsupervised dataset outperform strong baselines such as BM25 as well as recently proposed self-supervised dense retrieval methods. Furthermore, retrievers finetuned on both supervised and our synthetic data achieve better zero-shot transfer than models finetuned only on supervised data. Code, models, and data are available at https://github.com/zetaalphavector/inpars . ",
    "url": "https://arxiv.org/abs/2202.05144",
    "authors": [
      "Luiz Bonifacio",
      "Hugo Abonizio",
      "Marzieh Fadaee",
      "Rodrigo Nogueira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.05152",
    "title": "Feature-level augmentation to improve robustness of deep neural networks  to affine transformations",
    "abstract": "Recent studies revealed that convolutional neural networks do not generalize well to small image transformations, e.g. rotations by a few degrees or translations of a few pixels. To improve the robustness to such transformations, we propose to introduce data augmentation at intermediate layers of the neural architecture, in addition to the common data augmentation applied on the input images. By introducing small perturbations to activation maps (features) at various levels, we develop the capacity of the neural network to cope with such transformations. We conduct experiments on three image classification benchmarks (Tiny ImageNet, Caltech-256 and Food-101), considering two different convolutional architectures (ResNet-18 and DenseNet-121). When compared with two state-of-the-art methods, the empirical results show that our approach consistently attains the best trade-off between accuracy and mean flip rate. ",
    "url": "https://arxiv.org/abs/2202.05152",
    "authors": [
      "Adrian Sandru",
      "Mariana-Iuliana Georgescu",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05155",
    "title": "DeepCENT: Prediction of Censored Event Time via Deep Learning",
    "abstract": "With the rapid advances of deep learning, many computational methods have been developed to analyze nonlinear and complex right censored data via deep learning approaches. However, the majority of the methods focus on predicting survival function or hazard function rather than predicting a single valued time to an event. In this paper, we propose a novel method, DeepCENT, to directly predict the individual time to an event. It utilizes the deep learning framework with an innovative loss function that combines the mean square error and the concordance index. Most importantly, DeepCENT can handle competing risks, where one type of event precludes the other types of events from being observed. The validity and advantage of DeepCENT were evaluated using simulation studies and illustrated with three publicly available cancer data sets. ",
    "url": "https://arxiv.org/abs/2202.05155",
    "authors": [
      "Jong-Hyeon Jeong",
      "Yichen Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05189",
    "title": "Understanding Rare Spurious Correlations in Neural Networks",
    "abstract": "Neural networks are known to use spurious correlations for classification; for example, they commonly use background information to classify objects. But how many examples does it take for a network to pick up these correlations? This is the question that we empirically investigate in this work. We introduce spurious patterns correlated with a specific class to a few examples and find that it takes only a handful of such examples for the network to pick up on the spurious correlation. Through extensive experiments, we show that (1) spurious patterns with a larger $\\ell_2$ norm are learnt to correlate with the specified class more easily; (2) network architectures that are more sensitive to the input are more susceptible to learning these rare spurious correlations; (3) standard data deletion methods, including incremental retraining and influence functions, are unable to forget these rare spurious correlations through deleting the examples that cause these spurious correlations to be learnt. Code available at https://github.com/yangarbiter/rare-spurious-correlation. ",
    "url": "https://arxiv.org/abs/2202.05189",
    "authors": [
      "Yao-Yuan Yang",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.05194",
    "title": "Robust and fair work allocation",
    "abstract": "In today's digital world, interaction with online platforms is ubiquitous, and thus content moderation is important for protecting users from content that do not comply with pre-established community guidelines. Having a robust content moderation system throughout every stage of planning is particularly important. We study the short-term planning problem of allocating human content reviewers to different harmful content categories. We use tools from fair division and study the application of competitive equilibrium and leximin allocation rules. Furthermore, we incorporate, to the traditional Fisher market setup, novel aspects that are of practical importance. The first aspect is the forecasted workload of different content categories. We show how a formulation that is inspired by the celebrated Eisenberg-Gale program allows us to find an allocation that not only satisfies the forecasted workload, but also fairly allocates the remaining reviewing hours among all content categories. The resulting allocation is also robust as the additional allocation provides a guardrail in cases where the actual workload deviates from the predicted workload. The second practical consideration is time dependent allocation that is motivated by the fact that partners need scheduling guidance for the reviewers across days to achieve efficiency. To address the time component, we introduce new extensions of the various fair allocation approaches for the single-time period setting, and we show that many properties extend in essence, albeit with some modifications. Related to the time component, we additionally investigate how to satisfy markets' desire for smooth allocation (e.g., partners for content reviewers prefer an allocation that does not vary much from time to time, to minimize staffing switch). We demonstrate the performance of our proposed approaches through real-world data obtained from Meta. ",
    "url": "https://arxiv.org/abs/2202.05194",
    "authors": [
      "Amine Allouah",
      "Christian Kroer",
      "Xuan Zhang",
      "Vashist Avadhanula",
      "Anil Dania",
      "Caner Gocmen",
      "Sergey Pupyrev",
      "Parikshit Shah",
      "Nicolas Stier"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2202.05204",
    "title": "Towards Predicting Fine Finger Motions from Ultrasound Images via  Kinematic Representation",
    "abstract": "A central challenge in building robotic prostheses is the creation of a sensor-based system able to read physiological signals from the lower limb and instruct a robotic hand to perform various tasks. Existing systems typically perform discrete gestures such as pointing or grasping, by employing electromyography (EMG) or ultrasound (US) technologies to analyze the state of the muscles. In this work, we study the inference problem of identifying the activation of specific fingers from a sequence of US images when performing dexterous tasks such as keyboard typing or playing the piano. While estimating finger gestures has been done in the past by detecting prominent gestures, we are interested in classification done in the context of fine motions that evolve over time. We consider this task as an important step towards higher adoption rates of robotic prostheses among arm amputees, as it has the potential to dramatically increase functionality in performing daily tasks. Our key observation, motivating this work, is that modeling the hand as a robotic manipulator allows to encode an intermediate representation wherein US images are mapped to said configurations. Given a sequence of such learned configurations, coupled with a neural-network architecture that exploits temporal coherence, we are able to infer fine finger motions. We evaluated our method by collecting data from a group of subjects and demonstrating how our framework can be used to replay music played or text typed. To the best of our knowledge, this is the first study demonstrating these downstream tasks within an end-to-end system. ",
    "url": "https://arxiv.org/abs/2202.05204",
    "authors": [
      "Dean Zadok",
      "Oren Salzman",
      "Alon Wolf",
      "Alex M. Bronstein"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.05207",
    "title": "Vehicle: Interfacing Neural Network Verifiers with Interactive Theorem  Provers",
    "abstract": "Verification of neural networks is currently a hot topic in automated theorem proving. Progress has been rapid and there are now a wide range of tools available that can verify properties of networks with hundreds of thousands of nodes. In theory this opens the door to the verification of larger control systems that make use of neural network components. However, although work has managed to incorporate the results of these verifiers to prove larger properties of individual systems, there is currently no general methodology for bridging the gap between verifiers and interactive theorem provers (ITPs). In this paper we present Vehicle, our solution to this problem. Vehicle is equipped with an expressive domain specific language for stating neural network specifications which can be compiled to both verifiers and ITPs. It overcomes previous issues with maintainability and scalability in similar ITP formalisations by using a standard ONNX file as the single canonical representation of the network. We demonstrate its utility by using it to connect the neural network verifier Marabou to Agda and then formally verifying that a car steered by a neural network never leaves the road, even in the face of an unpredictable cross wind and imperfect sensors. The network has over 20,000 nodes, and therefore this proof represents an improvement of 3 orders of magnitude over prior proofs about neural network enhanced systems in ITPs. ",
    "url": "https://arxiv.org/abs/2202.05207",
    "authors": [
      "Matthew L. Daggitt",
      "Wen Kokke",
      "Robert Atkey",
      "Luca Arnaboldi",
      "Ekaterina Komendantskya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2202.05211",
    "title": "Behavior-Semantic Scenery Description (BSSD) of Road Networks for  Automated Driving",
    "abstract": "The safety approval of Highly Automated Vehicles (HAV) is economically infeasible with current approaches. For verification and validation, it is essential to describe the intended behavior of an HAV in the development process in order to prove safety. The demand for this behavior comes from the traffic rules which are instantiated by the present scenery around the vehicle (e.g. traffic signs or road markings). The Operational Design Domain (ODD) specifies the scenery in which an HAV may operate, but current descriptions fail to explicitly represent the associated behavioral demand of the scenery. We propose a new approach for a Behavior-Semantic Scenery Description (BSSD) in order to describe the behavior space of a present scenery. A behavior space represents the delimitation of the legally possible behavior. The BSSD explicitly links the scenery with the behavioral demand for HAV. Based on identified goals and challenges for such an approach, we derive requirements for a generic structure of the description for complete road networks. All required elements to represent the behavior space of the scenery are identified. Within real world examples, we present an instance of the BSSD integrated into the HD-map framework Lanelet2 to prove the applicability of the description. The presented approach supports development, test and operation of HAV by closing the knowledge gap of where a vehicle has to behave in which limits within an ODD. ",
    "url": "https://arxiv.org/abs/2202.05211",
    "authors": [
      "Moritz Lippert",
      "Felix Glatzki",
      "Hermann Winner"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.05226",
    "title": "Deadwooding: Robust Global Pruning for Deep Neural Networks",
    "abstract": "The ability of Deep Neural Networks to approximate highly complex functions is the key to their success. This benefit, however, often comes at the cost of a large model size, which challenges their deployment in resource-constrained environments. To limit this issue, pruning techniques can introduce sparsity in the models, but at the cost of accuracy and adversarial robustness. This paper addresses these critical issues and introduces Deadwooding, a novel pruning technique that exploits a Lagrangian Dual method to encourage model sparsity while retaining accuracy and ensuring robustness. The resulting model is shown to significantly outperform the state-of-the-art studies in measures of robustness and accuracy. ",
    "url": "https://arxiv.org/abs/2202.05226",
    "authors": [
      "Sawinder Kaur",
      "Ferdinando Fioretto",
      "Asif Salekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05233",
    "title": "Game Theoretic Analysis of an Adversarial Status Updating System",
    "abstract": "We investigate the game theoretic equilibrium points of a status updating system with an adversary that jams the updates in the downlink. We consider the system models with and without diversity. The adversary can jam up to $\\alpha$ proportion of the entire communication window. In the model without diversity, in each time slot, the base station schedules a user from $N$ users according to a stationary distribution. The adversary blocks (jams) $\\alpha T$ time slots of its choosing out of the total $T$ time slots. For this system, we show that a Nash equilibrium does not exist, however, a Stackelberg equilibrium exists when the scheduling algorithm of the base station acts as the leader and the adversary acts as the follower. In the model with diversity, in each time slot, the base station schedules a user from $N$ users and chooses a sub-carrier from $N_{sub}$ sub-carriers to transmit update packets to the scheduled user according to a stationary distribution. The adversary blocks $\\alpha T$ time slots of its choosing out of $T$ time slots at the sub-carriers of its choosing. For this system, we show that a Nash equilibrium exists and identify the Nash equilibrium. ",
    "url": "https://arxiv.org/abs/2202.05233",
    "authors": [
      "Subhankar Banerjee",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.05236",
    "title": "Learnable Nonlinear Compression for Robust Speaker Verification",
    "abstract": "In this study, we focus on nonlinear compression methods in spectral features for speaker verification based on deep neural network. We consider different kinds of channel-dependent (CD) nonlinear compression methods optimized in a data-driven manner. Our methods are based on power nonlinearities and dynamic range compression (DRC). We also propose multi-regime (MR) design on the nonlinearities, at improving robustness. Results on VoxCeleb1 and VoxMovies data demonstrate improvements brought by proposed compression methods over both the commonly-used logarithm and their static counterparts, especially for ones based on power function. While CD generalization improves performance on VoxCeleb1, MR provides more robustness on VoxMovies, with a maximum relative equal error rate reduction of 21.6%. ",
    "url": "https://arxiv.org/abs/2202.05236",
    "authors": [
      "Xuechen Liu",
      "Md Sahidullah",
      "Tomi Kinnunen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2202.05239",
    "title": "F8Net: Fixed-Point 8-bit Only Multiplication for Network Quantization",
    "abstract": "Neural network quantization is a promising compression technique to reduce memory footprint and save energy consumption, potentially leading to real-time inference. However, there is a performance gap between quantized and full-precision models. To reduce it, existing quantization approaches require high-precision INT32 or full-precision multiplication during inference for scaling or dequantization. This introduces a noticeable cost in terms of memory, speed, and required energy. To tackle these issues, we present F8Net, a novel quantization framework consisting of only fixed-point 8-bit multiplication. To derive our method, we first discuss the advantages of fixed-point multiplication with different formats of fixed-point numbers and study the statistical behavior of the associated fixed-point numbers. Second, based on the statistical and algorithmic analysis, we apply different fixed-point formats for weights and activations of different layers. We introduce a novel algorithm to automatically determine the right format for each layer during training. Third, we analyze a previous quantization algorithm -- parameterized clipping activation (PACT) -- and reformulate it using fixed-point arithmetic. Finally, we unify the recently proposed method for quantization fine-tuning and our fixed-point approach to show the potential of our method. We verify F8Net on ImageNet for MobileNet V1/V2 and ResNet18/50. Our approach achieves comparable and better performance, when compared not only to existing quantization techniques with INT32 multiplication or floating-point arithmetic, but also to the full-precision counterparts, achieving state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2202.05239",
    "authors": [
      "Qing Jin",
      "Jian Ren",
      "Richard Zhuang",
      "Sumant Hanumante",
      "Zhengang Li",
      "Zhiyu Chen",
      "Yanzhi Wang",
      "Kaiyuan Yang",
      "Sergey Tulyakov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2202.05244",
    "title": "REvolveR: Continuous Evolutionary Models for Robot-to-robot Policy  Transfer",
    "abstract": "A popular paradigm in robotic learning is to train a policy from scratch for every new robot. This is not only inefficient but also often impractical for complex robots. In this work, we consider the problem of transferring a policy across two different robots with significantly different parameters such as kinematics and morphology. Existing approaches that train a new policy by matching the action or state transition distribution, including imitation learning methods, fail due to optimal action and/or state distribution being mismatched in different robots. In this paper, we propose a novel method named $REvolveR$ of using continuous evolutionary models for robotic policy transfer implemented in a physics simulator. We interpolate between the source robot and the target robot by finding a continuous evolutionary change of robot parameters. An expert policy on the source robot is transferred through training on a sequence of intermediate robots that gradually evolve into the target robot. Experiments show that the proposed continuous evolutionary model can effectively transfer the policy across robots and achieve superior sample efficiency on new robots using a physics simulator. The proposed method is especially advantageous in sparse reward settings where exploration can be significantly reduced. ",
    "url": "https://arxiv.org/abs/2202.05244",
    "authors": [
      "Xingyu Liu",
      "Deepak Pathak",
      "Kris M. Kitani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.05252",
    "title": "SA-HMTS: A Secure and Adaptive Hierarchical Multi-timescale Framework  for Resilient Load Restoration Using A Community Microgrid",
    "abstract": "Distribution system integrated community microgrids (CMGs) can partake in restoring loads during extended duration outages. At such times, the CMG is challenged with limited resource availability, absence of robust grid support, and heightened demand-supply uncertainty. This paper proposes a secure and adaptive three-stage hierarchical multi-timescale framework for scheduling and real-time (RT) dispatch of CMGs with hybrid PV systems to address these challenges. The framework enables the CMG to dynamically expand its boundary to support the neighboring grid sections and is adaptive to the changing forecast error impacts. The first stage solves a stochastic extended duration scheduling (EDS) problem to obtain referral plans for optimal resource rationing. The intermediate near-real-time (NRT) scheduling stage updates the EDS schedule closer to the dispatch time using newly obtained forecasts, followed by the RT dispatch stage. To make the dispatch decisions more secure and robust against forecast errors, a novel concept called delayed recourse is proposed. The methodology is evaluated via numerical simulations on a modified IEEE 123-bus system and validated using OpenDSS/hardware-in-loop simulations. The results show superior performance in maximizing load supply and continuous secure CMG operation under numerous operating scenarios. ",
    "url": "https://arxiv.org/abs/2202.05252",
    "authors": [
      "Ashwin Shirsat",
      "Valliappan Muthukaruppan",
      "Rongxing Hu",
      "Victor Paduani",
      "Bei Xu",
      "Lidong Song",
      "Yiyan Li",
      "Ning Lu",
      "Mesut Baran",
      "David Lubkeman",
      "Wenyuan Tang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2202.05254",
    "title": "Deep Learning in Random Neural Fields: Numerical Experiments via Neural  Tangent Kernel",
    "abstract": "A biological neural network in the cortex forms a neural field. Neurons in the field have their own receptive fields, and connection weights between two neurons are random but highly correlated when they are in close proximity in receptive fields. In this paper, we investigate such neural fields in a multilayer architecture to investigate the supervised learning of the fields. We empirically compare the performances of our field model with those of randomly connected deep networks. The behavior of a randomly connected network is investigated on the basis of the key idea of the neural tangent kernel regime, a recent development in the machine learning theory of over-parameterized networks; for most randomly connected neural networks, it is shown that global minima always exist in their small neighborhoods. We numerically show that this claim also holds for our neural fields. In more detail, our model has two structures: i) each neuron in a field has a continuously distributed receptive field, and ii) the initial connection weights are random but not independent, having correlations when the positions of neurons are close in each layer. We show that such a multilayer neural field is more robust than conventional models when input patterns are deformed by noise disturbances. Moreover, its generalization ability can be slightly superior to that of conventional models. ",
    "url": "https://arxiv.org/abs/2202.05254",
    "authors": [
      "Kaito Watanabe",
      "Kotaro Sakamoto",
      "Ryo Karakida",
      "Sho Sonoda",
      "Shun-ichi Amari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05257",
    "title": "Characterizing, Detecting, and Predicting Online Ban Evasion",
    "abstract": "Moderators and automated methods enforce bans on malicious users who engage in disruptive behavior. However, malicious users can easily create a new account to evade such bans. Previous research has focused on other forms of online deception, like the simultaneous operation of multiple accounts by the same entities (sockpuppetry), impersonation of other individuals, and studying the effects of de-platforming individuals and communities. Here we conduct the first data-driven study of ban evasion, i.e., the act of circumventing bans on an online platform, leading to temporally disjoint operation of accounts by the same user. We curate a novel dataset of 8,551 ban evasion pairs (parent, child) identified on Wikipedia and contrast their behavior with benign users and non-evading malicious users. We find that evasion child accounts demonstrate similarities with respect to their banned parent accounts on several behavioral axes - from similarity in usernames and edited pages to similarity in content added to the platform and its psycholinguistic attributes. We reveal key behavioral attributes of accounts that are likely to evade bans. Based on the insights from the analyses, we train logistic regression classifiers to detect and predict ban evasion at three different points in the ban evasion lifecycle. Results demonstrate the effectiveness of our methods in predicting future evaders (AUC = 0.78), early detection of ban evasion (AUC = 0.85), and matching child accounts with parent accounts (MRR = 0.97). Our work can aid moderators by reducing their workload and identifying evasion pairs faster and more efficiently than current manual and heuristic-based approaches. Dataset is available $\\href{https://github.com/srijankr/ban_evasion}{\\text{here}}$. ",
    "url": "https://arxiv.org/abs/2202.05257",
    "authors": [
      "Manoj Niverthi",
      "Gaurav Verma",
      "Srijan Kumar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05258",
    "title": "Hardness of Noise-Free Learning for Two-Hidden-Layer Neural Networks",
    "abstract": "We give exponential statistical query (SQ) lower bounds for learning two-hidden-layer ReLU networks with respect to Gaussian inputs in the standard (noise-free) model. No general SQ lower bounds were known for learning ReLU networks of any depth in this setting: previous SQ lower bounds held only for adversarial noise models (agnostic learning) or restricted models such as correlational SQ. Prior work hinted at the impossibility of our result: Vempala and Wilmes showed that general SQ lower bounds cannot apply to any real-valued family of functions that satisfies a simple non-degeneracy condition. To circumvent their result, we refine a lifting procedure due to Daniely and Vardi that reduces Boolean PAC learning problems to Gaussian ones. We show how to extend their technique to other learning models and, in many well-studied cases, obtain a more efficient reduction. As such, we also prove new cryptographic hardness results for PAC learning two-hidden-layer ReLU networks, as well as new lower bounds for learning constant-depth ReLU networks from membership queries. ",
    "url": "https://arxiv.org/abs/2202.05258",
    "authors": [
      "Sitan Chen",
      "Aravind Gollakota",
      "Adam R. Klivans",
      "Raghu Meka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.05263",
    "title": "Block-NeRF: Scalable Large Scene Neural View Synthesis",
    "abstract": "We present Block-NeRF, a variant of Neural Radiance Fields that can represent large-scale environments. Specifically, we demonstrate that when scaling NeRF to render city-scale scenes spanning multiple blocks, it is vital to decompose the scene into individually trained NeRFs. This decomposition decouples rendering time from scene size, enables rendering to scale to arbitrarily large environments, and allows per-block updates of the environment. We adopt several architectural changes to make NeRF robust to data captured over months under different environmental conditions. We add appearance embeddings, learned pose refinement, and controllable exposure to each individual NeRF, and introduce a procedure for aligning appearance between adjacent NeRFs so that they can be seamlessly combined. We build a grid of Block-NeRFs from 2.8 million images to create the largest neural scene representation to date, capable of rendering an entire neighborhood of San Francisco. ",
    "url": "https://arxiv.org/abs/2202.05263",
    "authors": [
      "Matthew Tancik",
      "Vincent Casser",
      "Xinchen Yan",
      "Sabeek Pradhan",
      "Ben Mildenhall",
      "Pratul P. Srinivasan",
      "Jonathan T. Barron",
      "Henrik Kretzschmar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2202.04650",
    "title": "Semantic Segmentation of Anaemic RBCs Using Multilevel Deep  Convolutional Encoder-Decoder Network",
    "abstract": "Pixel-level analysis of blood images plays a pivotal role in diagnosing blood-related diseases, especially Anaemia. These analyses mainly rely on an accurate diagnosis of morphological deformities like shape, size, and precise pixel counting. In traditional segmentation approaches, instance or object-based approaches have been adopted that are not feasible for pixel-level analysis. The convolutional neural network (CNN) model required a large dataset with detailed pixel-level information for the semantic segmentation of red blood cells in the deep learning domain. In current research work, we address these problems by proposing a multi-level deep convolutional encoder-decoder network along with two state-of-the-art healthy and Anaemic-RBC datasets. The proposed multi-level CNN model preserved pixel-level semantic information extracted in one layer and then passed to the next layer to choose relevant features. This phenomenon helps to precise pixel-level counting of healthy and anaemic-RBC elements along with morphological analysis. For experimental purposes, we proposed two state-of-the-art RBC datasets, i.e., Healthy-RBCs and Anaemic-RBCs dataset. Each dataset contains 1000 images, ground truth masks, relevant, complete blood count (CBC), and morphology reports for performance evaluation. The proposed model results were evaluated using crossmatch analysis with ground truth mask by finding IoU, individual training, validation, testing accuracies, and global accuracies using a 05-fold training procedure. This model got training, validation, and testing accuracies as 0.9856, 0.9760, and 0.9720 on the Healthy-RBC dataset and 0.9736, 0.9696, and 0.9591 on an Anaemic-RBC dataset. The IoU and BFScore of the proposed model were 0.9311, 0.9138, and 0.9032, 0.8978 on healthy and anaemic datasets, respectively. ",
    "url": "https://arxiv.org/abs/2202.04650",
    "authors": [
      "Muhammad Shahzad",
      "Arif Iqbal Umar",
      "Syed Hamad Shirazi",
      "Israr Ahmed Shaikh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04719",
    "title": "A Coupled CP Decomposition for Principal Components Analysis of  Symmetric Networks",
    "abstract": "In a number of application domains, one observes a sequence of network data; for example, repeated measurements between users interactions in social media platforms, financial correlation networks over time, or across subjects, as in multi-subject studies of brain connectivity. One way to analyze such data is by stacking networks into a third-order array or tensor. We propose a principal components analysis (PCA) framework for sequence network data, based on a novel decomposition for semi-symmetric tensors. We derive efficient algorithms for computing our proposed \"Coupled CP\" decomposition and establish estimation consistency of our approach under an analogue of the spiked covariance model with rates the same as the matrix case up to a logarithmic term. Our framework inherits many of the strengths of classical PCA and is suitable for a wide range of unsupervised learning tasks, including identifying principal networks, isolating meaningful changepoints or outliers across observations, and for characterizing the \"variability network\" of the most varying edges. Finally, we demonstrate the effectiveness of our proposal on simulated data and on examples from political science and financial economics. The proof techniques used to establish our main consistency results are surprisingly straight-forward and may find use in a variety of other matrix and tensor decomposition problems. ",
    "url": "https://arxiv.org/abs/2202.04719",
    "authors": [
      "Michael Weylandt",
      "George Michailidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2202.04744",
    "title": "Robust Bayesian Inference for Simulator-based Models via the MMD  Posterior Bootstrap",
    "abstract": "Simulator-based models are models for which the likelihood is intractable but simulation of synthetic data is possible. They are often used to describe complex real-world phenomena, and as such can often be misspecified in practice. Unfortunately, existing Bayesian approaches for simulators are known to perform poorly in those cases. In this paper, we propose a novel algorithm based on the posterior bootstrap and maximum mean discrepancy estimators. This leads to a highly-parallelisable Bayesian inference algorithm with strong robustness properties. This is demonstrated through an in-depth theoretical study which includes generalisation bounds and proofs of frequentist consistency and robustness of our posterior. The approach is then assessed on a range of examples including a g-and-k distribution and a toggle-switch model. ",
    "url": "https://arxiv.org/abs/2202.04744",
    "authors": [
      "Charita Dellaporta",
      "Jeremias Knoblauch",
      "Theodoros Damoulas",
      "Fran\u00e7ois-Xavier Briol"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.04773",
    "title": "A Neural Network Model of Continual Learning with Cognitive Control",
    "abstract": "Neural networks struggle in continual learning settings from catastrophic forgetting: when trials are blocked, new learning can overwrite the learning from previous blocks. Humans learn effectively in these settings, in some cases even showing an advantage of blocking, suggesting the brain contains mechanisms to overcome this problem. Here, we build on previous work and show that neural networks equipped with a mechanism for cognitive control do not exhibit catastrophic forgetting when trials are blocked. We further show an advantage of blocking over interleaving when there is a bias for active maintenance in the control signal, implying a tradeoff between maintenance and the strength of control. Analyses of map-like representations learned by the networks provided additional insights into these mechanisms. Our work highlights the potential of cognitive control to aid continual learning in neural networks, and offers an explanation for the advantage of blocking that has been observed in humans. ",
    "url": "https://arxiv.org/abs/2202.04773",
    "authors": [
      "Jacob Russin",
      "Maryam Zolfaghar",
      "Seongmin A. Park",
      "Erie Boorman",
      "Randall C. O'Reilly"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2202.04777",
    "title": "Exact Solutions of a Deep Linear Network",
    "abstract": "This work finds the exact solutions to a deep linear network with weight decay and stochastic neurons, a fundamental model for understanding the landscape of neural networks. Our result implies that weight decay strongly interacts with the model architecture and can create bad minima in a network with more than $1$ hidden layer, qualitatively different for a network with only $1$ hidden layer. As an application, we also analyze stochastic nets and show that their prediction variance vanishes to zero as the stochasticity, the width, or the depth tends to infinity. ",
    "url": "https://arxiv.org/abs/2202.04777",
    "authors": [
      "Liu Ziyin",
      "Botao Li",
      "Xiangming Meng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04828",
    "title": "Learning Latent Causal Dynamics",
    "abstract": "One critical challenge of time-series modeling is how to learn and quickly correct the model under unknown distribution shifts. In this work, we propose a principled framework, called LiLY, to first recover time-delayed latent causal variables and identify their relations from measured temporal data under different distribution shifts. The correction step is then formulated as learning the low-dimensional change factors with a few samples from the new environment, leveraging the identified causal structure. Specifically, the framework factorizes unknown distribution shifts into transition distribution changes caused by fixed dynamics and time-varying latent causal relations, and by global changes in observation. We establish the identifiability theories of nonparametric latent causal dynamics from their nonlinear mixtures under fixed dynamics and under changes. Through experiments, we show that time-delayed latent causal influences are reliably identified from observed variables under different distribution changes. By exploiting this modular representation of changes, we can efficiently learn to correct the model under unknown distribution shifts with only a few samples. ",
    "url": "https://arxiv.org/abs/2202.04828",
    "authors": [
      "Weiran Yao",
      "Guangyi Chen",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04837",
    "title": "Heterogeneous Calibration: A post-hoc model-agnostic framework for  improved generalization",
    "abstract": "We introduce the notion of heterogeneous calibration that applies a post-hoc model-agnostic transformation to model outputs for improving AUC performance on binary classification tasks. We consider overconfident models, whose performance is significantly better on training vs test data and give intuition onto why they might under-utilize moderately effective simple patterns in the data. We refer to these simple patterns as heterogeneous partitions of the feature space and show theoretically that perfectly calibrating each partition separately optimizes AUC. This gives a general paradigm of heterogeneous calibration as a post-hoc procedure by which heterogeneous partitions of the feature space are identified through tree-based algorithms and post-hoc calibration techniques are applied to each partition to improve AUC. While the theoretical optimality of this framework holds for any model, we focus on deep neural networks (DNNs) and test the simplest instantiation of this paradigm on a variety of open-source datasets. Experiments demonstrate the effectiveness of this framework and the future potential for applying higher-performing partitioning schemes along with more effective calibration techniques. ",
    "url": "https://arxiv.org/abs/2202.04837",
    "authors": [
      "David Durfee",
      "Aman Gupta",
      "Kinjal Basu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04962",
    "title": "Feasible Low-thrust Trajectory Identification via a Deep Neural Network  Classifier",
    "abstract": "In recent years, deep learning techniques have been introduced into the field of trajectory optimization to improve convergence and speed. Training such models requires large trajectory datasets. However, the convergence of low thrust (LT) optimizations is unpredictable before the optimization process ends. For randomly initialized low thrust transfer data generation, most of the computation power will be wasted on optimizing infeasible low thrust transfers, which leads to an inefficient data generation process. This work proposes a deep neural network (DNN) classifier to accurately identify feasible LT transfer prior to the optimization process. The DNN-classifier achieves an overall accuracy of 97.9%, which has the best performance among the tested algorithms. The accurate low-thrust trajectory feasibility identification can avoid optimization on undesired samples, so that the majority of the optimized samples are LT trajectories that converge. This technique enables efficient dataset generation for different mission scenarios with different spacecraft configurations. ",
    "url": "https://arxiv.org/abs/2202.04962",
    "authors": [
      "Ruida Xie",
      "Andrew G. Dempster"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.05049",
    "title": "Fair When Trained, Unfair When Deployed: Observable Fairness Measures  are Unstable in Performative Prediction Settings",
    "abstract": "Many popular algorithmic fairness measures depend on the joint distribution of predictions, outcomes, and a sensitive feature like race or gender. These measures are sensitive to distribution shift: a predictor which is trained to satisfy one of these fairness definitions may become unfair if the distribution changes. In performative prediction settings, however, predictors are precisely intended to induce distribution shift. For example, in many applications in criminal justice, healthcare, and consumer finance, the purpose of building a predictor is to reduce the rate of adverse outcomes such as recidivism, hospitalization, or default on a loan. We formalize the effect of such predictors as a type of concept shift-a particular variety of distribution shift-and show both theoretically and via simulated examples how this causes predictors which are fair when they are trained to become unfair when they are deployed. We further show how many of these issues can be avoided by using fairness definitions that depend on counterfactual rather than observable outcomes. ",
    "url": "https://arxiv.org/abs/2202.05049",
    "authors": [
      "Alan Mishler",
      "Niccol\u00f2 Dalmasso"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05073",
    "title": "Computer Validation of Neural Network Dynamics: A First Case Study",
    "abstract": "A large number of current machine learning methods rely upon deep neural networks. Yet, viewing neural networks as nonlinear dynamical systems, it becomes quickly apparent that mathematically rigorously establishing certain patterns generated by the nodes in the network is extremely difficult. Indeed, it is well-understood in the nonlinear dynamics of complex systems that, even in low-dimensional models, analytical techniques rooted in pencil-and-paper approaches reach their limits quickly. In this work, we propose a completely different perspective via the paradigm of rigorous numerical methods of nonlinear dynamics. The idea is to use computer-assisted proofs to validate mathematically the existence of nonlinear patterns in neural networks. As a case study, we consider a class of recurrent neural networks, where we prove via computer assistance the existence of several hundred Hopf bifurcation points, their non-degeneracy, and hence also the existence of several hundred periodic orbits. Our paradigm has the capability to rigorously verify complex nonlinear behaviour of neural networks, which provides a first step to explain the full abilities, as well as potential sensitivities, of machine learning methods via computer-assisted proofs. ",
    "url": "https://arxiv.org/abs/2202.05073",
    "authors": [
      "Christian Kuehn",
      "Elena Queirolo"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2202.05083",
    "title": "Cross-speaker style transfer for text-to-speech using data augmentation",
    "abstract": "We address the problem of cross-speaker style transfer for text-to-speech (TTS) using data augmentation via voice conversion. We assume to have a corpus of neutral non-expressive data from a target speaker and supporting conversational expressive data from different speakers. Our goal is to build a TTS system that is expressive, while retaining the target speaker's identity. The proposed approach relies on voice conversion to first generate high-quality data from the set of supporting expressive speakers. The voice converted data is then pooled with natural data from the target speaker and used to train a single-speaker multi-style TTS system. We provide evidence that this approach is efficient, flexible, and scalable. The method is evaluated using one or more supporting speakers, as well as a variable amount of supporting data. We further provide evidence that this approach allows some controllability of speaking style, when using multiple supporting speakers. We conclude by scaling our proposed technology to a set of 14 speakers across 7 languages. Results indicate that our technology consistently improves synthetic samples in terms of style similarity, while retaining the target speaker's identity. ",
    "url": "https://arxiv.org/abs/2202.05083",
    "authors": [
      "Manuel Sam Ribeiro",
      "Julian Roth",
      "Giulia Comini",
      "Goeric Huybrechts",
      "Adam Gabrys",
      "Jaime Lorenzo-Trueba"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2202.05099",
    "title": "Social interactions affect discovery processes",
    "abstract": "Our network of acquaintances determines how we get exposed to ideas, products, or cultural artworks (books, music, movies, etc.). Though this principle is part of our common sense, little is known about the specific pathways through which our peers influence our discovery processes and our experience of the new. Here, we fill this gap by investigating a data set containing the whole listening histories of a large, socially connected sample of users from the online music platform \\emph{Last.fm}. We demonstrate that users exhibit highly heterogeneous discovery rates of new songs and artists and that their social neighborhood significantly influences their behavior. More explorative users tend to interact with peers more prone to explore new content. We capture this phenomenology in a modeling scheme where users are represented by random walkers exploring a graph of songs or artists and interacting with each other through their social links. Even starting from a uniform population of agents (no natural differences among the individuals), our model predicts the emergence of strong heterogeneous exploration patterns, with users clustered according to their musical tastes and propensity to explore. We contend our approach can pave the way to a quantitative approach to collective discovery processes. ",
    "url": "https://arxiv.org/abs/2202.05099",
    "authors": [
      "Gabriele Di Bona",
      "Enrico Ubaldi",
      "Iacopo Iacopini",
      "Bernardo Monechi",
      "Vito Latora",
      "Vittorio Loreto"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2202.05100",
    "title": "Adaptively Exploiting d-Separators with Causal Bandits",
    "abstract": "Multi-armed bandit problems provide a framework to identify the optimal intervention over a sequence of repeated experiments. Without additional assumptions, minimax optimal performance (measured by cumulative regret) is well-understood. With access to additional observed variables that d-separate the intervention from the outcome (i.e., they are a d-separator), recent causal bandit algorithms provably incur less regret. However, in practice it is desirable to be agnostic to whether observed variables are a d-separator. Ideally, an algorithm should be adaptive; that is, perform nearly as well as an algorithm with oracle knowledge of the presence or absence of a d-separator. In this work, we formalize and study this notion of adaptivity, and provide a novel algorithm that simultaneously achieves (a) optimal regret when a d-separator is observed, improving on classical minimax algorithms, and (b) significantly smaller regret than recent causal bandit algorithms when the observed variables are not a d-separator. Crucially, our algorithm does not require any oracle knowledge of whether a d-separator is observed. We also generalize this adaptivity to other conditions, such as the front-door criterion. ",
    "url": "https://arxiv.org/abs/2202.05100",
    "authors": [
      "Blair Bilodeau",
      "Linbo Wang",
      "Daniel M. Roy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05146",
    "title": "EquiBind: Geometric Deep Learning for Drug Binding Structure Prediction",
    "abstract": "Predicting how a drug-like molecule binds to a specific protein target is a core problem in drug discovery. An extremely fast computational binding method would enable key applications such as fast virtual screening or drug engineering. Existing methods are computationally expensive as they rely on heavy candidate sampling coupled with scoring, ranking, and fine-tuning steps. We challenge this paradigm with EquiBind, an SE(3)-equivariant geometric deep learning model performing direct-shot prediction of both i) the receptor binding location (blind docking) and ii) the ligand's bound pose and orientation. EquiBind achieves significant speed-ups and better quality compared to traditional and recent baselines. Further, we show extra improvements when coupling it with existing fine-tuning techniques at the cost of increased running time. Finally, we propose a novel and fast fine-tuning model that adjusts torsion angles of a ligand's rotatable bonds based on closed-form global minima of the von Mises angular distance to a given input atomic point cloud, avoiding previous expensive differential evolution strategies for energy minimization. ",
    "url": "https://arxiv.org/abs/2202.05146",
    "authors": [
      "Hannes St\u00e4rk",
      "Octavian-Eugen Ganea",
      "Lagnajit Pattanaik",
      "Regina Barzilay",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05154",
    "title": "Effective classification of ecg signals using enhanced convolutional  neural network in iot",
    "abstract": "In this paper, a novel ECG monitoring approach based on IoT technology is suggested. This paper proposes a routing system for IoT healthcare platforms based on Dynamic Source Routing (DSR) and Routing by Energy and Link Quality (REL). In addition, the Artificial Neural Network (ANN), Support Vector Machine (SVM), and Convolution Neural Networks (CNNs)-based approaches for ECG signal categorization were tested in this study. Deep-ECG will employ a deep CNN to extract important characteristics, which will then be compared using simple and fast distance functions in order to classify cardiac problems efficiently. This work has suggested algorithms for the categorization of ECG data acquired from mobile watch users in order to identify aberrant data. The Massachusetts Institute of Technology (MIT) and Beth Israel Hospital (MIT/BIH) Arrhythmia Database have been used for experimental verification of the suggested approaches. The results show that the proposed strategy outperforms others in terms of classification accuracy. ",
    "url": "https://arxiv.org/abs/2202.05154",
    "authors": [
      "Ahmad M. Karim"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05158",
    "title": "SUMO: Advanced sleep spindle identification with neural networks",
    "abstract": "Sleep spindles are neurophysiological phenomena that appear to be linked to memory formation and other functions of the central nervous system, and that can be observed in electroencephalographic recordings (EEG) during sleep. Manually identified spindle annotations in EEG recordings suffer from substantial intra- and inter-rater variability, even if raters have been highly trained, which reduces the reliability of spindle measures as a research and diagnostic tool. The Massive Online Data Annotation (MODA) project has recently addressed this problem by forming a consensus from multiple such rating experts, thus providing a corpus of spindle annotations of enhanced quality. Based on this dataset, we present a U-Net-type deep neural network model to automatically detect sleep spindles. Our model's performance exceeds that of the state-of-the-art detector and of most experts in the MODA dataset. We observed improved detection accuracy in subjects of all ages, including older individuals whose spindles are particularly challenging to detect reliably. Our results underline the potential of automated methods to do repetitive cumbersome tasks with super-human performance. ",
    "url": "https://arxiv.org/abs/2202.05158",
    "authors": [
      "Lars Kaulen",
      "Justus T. C. Schwabedal",
      "Jules Schneider",
      "Philipp Ritter",
      "Stephan Bialonski"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2202.05166",
    "title": "Design of Flexible Meander Line Antenna for Healthcare for Wireless  Medical Body Area Networks",
    "abstract": "A flexible meander line monopole antenna (MMA) is presented in this paper. The antenna can be worn for on-and off-body applications. The overall dimension of the MMA is 37 mm x 50 mm x2.37 mm3. The MMA was manufactured and measured, and the results matched with simulation results. The MMA design shows a bandwidth of up to 1282.4 (450.5) MHz and provides gains of 3.03 (4.85) dBi in the lower and upper operating bands, respectively, showing omnidirectional radiation patterns in free space. While worn on the chest or arm, bandwidths as high as 688.9 (500.9) MHz and 1261.7 (524.2) MHz, and the gains of 3.80 (4.67) dBi and 3.00 (4.55) dBi were observed. The experimental measurements of the read range confirmed the results of the coverage range of up to 11 meters. ",
    "url": "https://arxiv.org/abs/2202.05166",
    "authors": [
      "Shahid M Ali",
      "Cheab Sovuthy",
      "Sima Noghanian",
      "Qammer H. Abbasi",
      "Tatjana Asenova",
      "Peter Derleth",
      "Alex Casson",
      "Tughrul Arslan",
      "Amir Hussain"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2202.05170",
    "title": "Efficacy of Transformer Networks for Classification of Raw EEG Data",
    "abstract": "With the unprecedented success of transformer networks in natural language processing (NLP), recently, they have been successfully adapted to areas like computer vision, generative adversarial networks (GAN), and reinforcement learning. Classifying electroencephalogram (EEG) data has been challenging and researchers have been overly dependent on pre-processing and hand-crafted feature extraction. Despite having achieved automated feature extraction in several other domains, deep learning has not yet been accomplished for EEG. In this paper, the efficacy of the transformer network for the classification of raw EEG data (cleaned and pre-processed) is explored. The performance of transformer networks was evaluated on a local (age and gender data) and a public dataset (STEW). First, a classifier using a transformer network is built to classify the age and gender of a person with raw resting-state EEG data. Second, the classifier is tuned for mental workload classification with open access raw multi-tasking mental workload EEG data (STEW). The network achieves an accuracy comparable to state-of-the-art accuracy on both the local (Age and Gender dataset; 94.53% (gender) and 87.79% (age)) and the public (STEW dataset; 95.28% (two workload levels) and 88.72% (three workload levels)) dataset. The accuracy values have been achieved using raw EEG data without feature extraction. Results indicate that the transformer-based deep learning models can successfully abate the need for heavy feature-extraction of EEG data for successful classification. ",
    "url": "https://arxiv.org/abs/2202.05170",
    "authors": [
      "Gourav Siddhad",
      "Anmol Gupta",
      "Debi Prosad Dogra",
      "Partha Pratim Roy"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05177",
    "title": "Automated Atrial Fibrillation Classification Based on Denoising Stacked  Autoencoder and Optimized Deep Network",
    "abstract": "The incidences of atrial fibrillation (AFib) are increasing at a daunting rate worldwide. For the early detection of the risk of AFib, we have developed an automatic detection system based on deep neural networks. For achieving better classification, it is mandatory to have good pre-processing of physiological signals. Keeping this in mind, we have proposed a two-fold study. First, an end-to-end model is proposed to denoise the electrocardiogram signals using denoising autoencoders (DAE). To achieve denoising, we have used three networks including, convolutional neural network (CNN), dense neural network (DNN), and recurrent neural networks (RNN). Compared the three models and CNN based DAE performance is found to be better than the other two. Therefore, the signals denoised by the CNN based DAE were used to train the deep neural networks for classification. Three neural networks' performance has been evaluated using accuracy, specificity, sensitivity, and signal to noise ratio (SNR) as the evaluation criteria. The proposed end-to-end deep learning model for detecting atrial fibrillation in this study has achieved an accuracy rate of 99.20%, a specificity of 99.50%, a sensitivity of 99.50%, and a true positive rate of 99.00%. The average accuracy of the algorithms we compared is 96.26%, and our algorithm's accuracy is 3.2% higher than this average of the other algorithms. The CNN classification network performed better as compared to the other two. Additionally, the model is computationally efficient for real-time applications, and it takes approx 1.3 seconds to process 24 hours ECG signal. The proposed model was also tested on unseen dataset with different proportions of arrhythmias to examine the model's robustness, which resulted in 99.10% of recall and 98.50% of precision. ",
    "url": "https://arxiv.org/abs/2202.05177",
    "authors": [
      "Prateek Singh",
      "Ambalika Sharma",
      "Shreesha Maiya"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2202.05245",
    "title": "Benign-Overfitting in Conditional Average Treatment Effect Prediction  with Linear Regression",
    "abstract": "We study the benign overfitting theory in the prediction of the conditional average treatment effect (CATE), with linear regression models. As the development of machine learning for causal inference, a wide range of large-scale models for causality are gaining attention. One problem is that suspicions have been raised that the large-scale models are prone to overfitting to observations with sample selection, hence the large models may not be suitable for causal prediction. In this study, to resolve the suspicious, we investigate on the validity of causal inference methods for overparameterized models, by applying the recent theory of benign overfitting (Bartlett et al., 2020). Specifically, we consider samples whose distribution switches depending on an assignment rule, and study the prediction of CATE with linear models whose dimension diverges to infinity. We focus on two methods: the T-learner, which based on a difference between separately constructed estimators with each treatment group, and the inverse probability weight (IPW)-learner, which solves another regression problem approximated by a propensity score. In both methods, the estimator consists of interpolators that fit the samples perfectly. As a result, we show that the T-learner fails to achieve the consistency except the random assignment, while the IPW-learner converges the risk to zero if the propensity score is known. This difference stems from that the T-learner is unable to preserve eigenspaces of the covariances, which is necessary for benign overfitting in the overparameterized setting. Our result provides new insights into the usage of causal inference methods in the overparameterizated setting, in particular, doubly robust estimators. ",
    "url": "https://arxiv.org/abs/2202.05245",
    "authors": [
      "Masahiro Kato",
      "Masaaki Imaizumi"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.05250",
    "title": "Adaptive and Robust Multi-task Learning",
    "abstract": "We study the multi-task learning problem that aims to simultaneously analyze multiple datasets collected from different sources and learn one model for each of them. We propose a family of adaptive methods that automatically utilize possible similarities among those tasks while carefully handling their differences. We derive sharp statistical guarantees for the methods and prove their robustness against outlier tasks. Numerical experiments on synthetic and real datasets demonstrate the efficacy of our new methods. ",
    "url": "https://arxiv.org/abs/2202.05250",
    "authors": [
      "Yaqi Duan",
      "Kaizheng Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2001.04216",
    "title": "Cycles in synchronous iterative voting: general robustness and examples  in Approval Voting",
    "abstract": " Comments: v2: added a numerical study of rarity of bad cycles and equilibriums, and a case of chaotic Continuous Polling Dynamics. Many other improvements throughout the text. v3: reorganization and change of order. The robustness result is generalized to all voting systems. v4 Added a simple example to the stability Theorem, various other small modifications ",
    "url": "https://arxiv.org/abs/2001.04216",
    "authors": [
      "Beno\u00eet Kloeckner"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2006.05531",
    "title": "GEOM: Energy-annotated molecular conformations for property prediction  and molecular generation",
    "abstract": " Title: GEOM: Energy-annotated molecular conformations for property prediction  and molecular generation ",
    "url": "https://arxiv.org/abs/2006.05531",
    "authors": [
      "Simon Axelrod",
      "Rafael Gomez-Bombarelli"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2011.11198",
    "title": "Complex-valued Iris Recognition Network",
    "abstract": " Title: Complex-valued Iris Recognition Network ",
    "url": "https://arxiv.org/abs/2011.11198",
    "authors": [
      "Kien Nguyen",
      "Clinton Fookes",
      "Sridha Sridharan",
      "Arun Ross"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2012.06568",
    "title": "Analyzing and Improving Adversarial Training for Generative Modeling",
    "abstract": " Title: Analyzing and Improving Adversarial Training for Generative Modeling ",
    "url": "https://arxiv.org/abs/2012.06568",
    "authors": [
      "Xuwang Yin",
      "Shiying Li",
      "Gustavo K. Rohde"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2103.10453",
    "title": "A massively parallel evolutionary algorithm for the partial Latin square  extension problem",
    "abstract": " Title: A massively parallel evolutionary algorithm for the partial Latin square  extension problem ",
    "url": "https://arxiv.org/abs/2103.10453",
    "authors": [
      "Olivier Goudet",
      "Jin-Kao Hao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2103.13650",
    "title": "A General Approach to Robust Controller Analysis and Synthesis",
    "abstract": " Title: A General Approach to Robust Controller Analysis and Synthesis ",
    "url": "https://arxiv.org/abs/2103.13650",
    "authors": [
      "Shih-Hao Tseng"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2105.14301",
    "title": "A Theory of Neural Tangent Kernel Alignment and Its Influence on  Training",
    "abstract": " Title: A Theory of Neural Tangent Kernel Alignment and Its Influence on  Training ",
    "url": "https://arxiv.org/abs/2105.14301",
    "authors": [
      "Haozhe Shan",
      "Blake Bordelon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.04982",
    "title": "Cooperative Online Learning with Feedback Graphs",
    "abstract": " Title: Cooperative Online Learning with Feedback Graphs ",
    "url": "https://arxiv.org/abs/2106.04982",
    "authors": [
      "Nicol\u00f2 Cesa-Bianchi",
      "Tommaso R. Cesari",
      "Riccardo Della Vecchia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.07438",
    "title": "Convolutional Neural Bandit for Visual-aware Recommendation",
    "abstract": " Comments: In submission ",
    "url": "https://arxiv.org/abs/2107.07438",
    "authors": [
      "Yikun Ban",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.00298",
    "title": "Filling the G_ap_s: Multivariate Time Series Imputation by Graph Neural  Networks",
    "abstract": " Comments: Accepted at ICLR 2022 ",
    "url": "https://arxiv.org/abs/2108.00298",
    "authors": [
      "Andrea Cini",
      "Ivan Marisca",
      "Cesare Alippi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2108.02423",
    "title": "Automatic Rail Component Detection Based on AttnConv-Net",
    "abstract": " Title: Automatic Rail Component Detection Based on AttnConv-Net ",
    "url": "https://arxiv.org/abs/2108.02423",
    "authors": [
      "Tiange Wang",
      "Zijun Zhang",
      "Fangfang Yang",
      "Kwok-Leung Tsui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.11157",
    "title": "Cob: a Leaderless Protocol for Parallel Byzantine Agreement in  Incomplete Networks",
    "abstract": " Comments: 40 pages, 2 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2108.11157",
    "authors": [
      "Andrea Flamini",
      "Riccardo Longo",
      "Alessio Meneghetti"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2108.13714",
    "title": "Competing control scenarios in probabilistic SIR epidemics on  social-contact networks",
    "abstract": " Comments: preprint submitted to journal \\ competing control scenarios \\ compounded payoff matrices ",
    "url": "https://arxiv.org/abs/2108.13714",
    "authors": [
      "Jan B. Broekaert",
      "Davide La Torre",
      "Faizal Hafiz"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2109.01411",
    "title": "An Exploratory Study on Utilising the Web of Linked Data for Product  Data Mining",
    "abstract": " Comments: Currently under review at LRE journal ",
    "url": "https://arxiv.org/abs/2109.01411",
    "authors": [
      "Ziqi Zhang",
      "Xingyi Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2109.06452",
    "title": "Spiking Neural Networks for Visual Place Recognition via Weighted  Neuronal Assignments",
    "abstract": " Comments: 8 pages, 6 figures, IEEE Robotics and Automation Letters (RA-L), also accepted to IEEE International Conference on Robotics and Automation (ICRA 2022) ",
    "url": "https://arxiv.org/abs/2109.06452",
    "authors": [
      "Somayeh Hussaini",
      "Michael Milford",
      "Tobias Fischer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2109.08266",
    "title": "Hard to Forget: Poisoning Attacks on Certified Machine Unlearning",
    "abstract": " Comments: Align with camera-ready submission to AAAI-22. Changes include: switched to row-wise normalization in Algorithm 3, added link to GitHub repository, added Appendix C with additional results on long-term effectiveness ",
    "url": "https://arxiv.org/abs/2109.08266",
    "authors": [
      "Neil G. Marchant",
      "Benjamin I. P. Rubinstein",
      "Scott Alfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2109.08991",
    "title": "The Undecidability of Network Coding with some Fixed-Size Messages and  Edges",
    "abstract": " Comments: 12 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2109.08991",
    "authors": [
      "Cheuk Ting Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2109.13479",
    "title": "Knowledge Transfer based Evolutionary Deep Neural Network for  Intelligent Fault Diagnosis",
    "abstract": " Title: Knowledge Transfer based Evolutionary Deep Neural Network for  Intelligent Fault Diagnosis ",
    "url": "https://arxiv.org/abs/2109.13479",
    "authors": [
      "Arun K. Sharma",
      "Nishchal K. Verma"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2109.14290",
    "title": "Residual-based adaptivity for two-phase flow simulation in porous media  using Physics-informed Neural Networks",
    "abstract": " Title: Residual-based adaptivity for two-phase flow simulation in porous media  using Physics-informed Neural Networks ",
    "url": "https://arxiv.org/abs/2109.14290",
    "authors": [
      "John Hanna",
      "Jose V. Aguado",
      "Sebastien Comas-Cardona",
      "Ramzi Askri",
      "Domenico Borzacchiello"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2110.03576",
    "title": "Training Stable Graph Neural Networks Through Constrained Learning",
    "abstract": " Title: Training Stable Graph Neural Networks Through Constrained Learning ",
    "url": "https://arxiv.org/abs/2110.03576",
    "authors": [
      "Juan Cervino",
      "Luana Ruiz",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2110.04621",
    "title": "Universal Paralinguistic Speech Representations Using Self-Supervised  Conformers",
    "abstract": " Title: Universal Paralinguistic Speech Representations Using Self-Supervised  Conformers ",
    "url": "https://arxiv.org/abs/2110.04621",
    "authors": [
      "Joel Shor",
      "Aren Jansen",
      "Wei Han",
      "Daniel Park",
      "Yu Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2110.07875",
    "title": "Graph Neural Networks with Learnable Structural and Positional  Representations",
    "abstract": " Comments: Code at this https URL ",
    "url": "https://arxiv.org/abs/2110.07875",
    "authors": [
      "Vijay Prakash Dwivedi",
      "Anh Tuan Luu",
      "Thomas Laurent",
      "Yoshua Bengio",
      "Xavier Bresson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.08802",
    "title": "Coordinated Multi-Agent Pathfinding for Drones and Trucks over Road  Networks",
    "abstract": " Comments: Accepted to Autonomous Agents and Multiagent Systems, 2022 ",
    "url": "https://arxiv.org/abs/2110.08802",
    "authors": [
      "Shushman Choudhury",
      "Kiril Solovey",
      "Mykel Kochenderfer",
      "Marco Pavone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2111.09372",
    "title": "BLOOM-Net: Blockwise Optimization for Masking Networks Toward Scalable  and Efficient Speech Enhancement",
    "abstract": " Comments: 5 pages, 3 figures, ICASSP 2022 ",
    "url": "https://arxiv.org/abs/2111.09372",
    "authors": [
      "Sunwoo Kim",
      "Minje Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2112.07159",
    "title": "Birds Eye View Social Distancing Analysis System",
    "abstract": " Title: Birds Eye View Social Distancing Analysis System ",
    "url": "https://arxiv.org/abs/2112.07159",
    "authors": [
      "Zhengye Yang",
      "Mingfei Sun",
      "Hongzhe Ye",
      "Zihao Xiong",
      "Gil Zussman",
      "Zoran Kostic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2201.01384",
    "title": "Sparse-Dyn: Sparse Dynamic Graph Multi-representation Learning via  Event-based Sparse Temporal Attention Network",
    "abstract": " Title: Sparse-Dyn: Sparse Dynamic Graph Multi-representation Learning via  Event-based Sparse Temporal Attention Network ",
    "url": "https://arxiv.org/abs/2201.01384",
    "authors": [
      "Yan Pang",
      "Chao Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.01549",
    "title": "SPT-Code: Sequence-to-Sequence Pre-Training for Learning Source Code  Representations",
    "abstract": " Comments: Accepted by ICSE 2022, not the final version ",
    "url": "https://arxiv.org/abs/2201.01549",
    "authors": [
      "Changan Niu",
      "Chuanyi Li",
      "Vincent Ng",
      "Jidong Ge",
      "Liguo Huang",
      "Bin Luo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2201.06628",
    "title": "Learning Wave Propagation with Attention-Based Convolutional Recurrent  Autoencoder Net",
    "abstract": " Comments: 23 pages ",
    "url": "https://arxiv.org/abs/2201.06628",
    "authors": [
      "Indu Kant Deo",
      "Rajeev Jaiman"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11528",
    "title": "Beyond ImageNet Attack: Towards Crafting Adversarial Examples for  Black-box Domains",
    "abstract": " Comments: Accepted by ICLR 2022 ",
    "url": "https://arxiv.org/abs/2201.11528",
    "authors": [
      "Qilong Zhang",
      "Xiaodan Li",
      "Yuefeng Chen",
      "Jingkuan Song",
      "Lianli Gao",
      "Yuan He",
      "Hui Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.01478",
    "title": "Trajectory Forecasting from Detection with Uncertainty-Aware Motion  Encoding",
    "abstract": " Comments: 11 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2202.01478",
    "authors": [
      "Pu Zhang",
      "Lei Bai",
      "Jianru Xue",
      "Jianwu Fang",
      "Nanning Zheng",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.02585",
    "title": "GhostTalk: Interactive Attack on Smartphone Voice System Through Power  Line",
    "abstract": " Title: GhostTalk: Interactive Attack on Smartphone Voice System Through Power  Line ",
    "url": "https://arxiv.org/abs/2202.02585",
    "authors": [
      "Yuanda Wang",
      "Hanqing Guo",
      "Qiben Yan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.02626",
    "title": "Layer-wise Regularized Adversarial Training using Layers Sustainability  Analysis (LSA) framework",
    "abstract": " Comments: Layers Sustainability Analysis (LSA) framework ",
    "url": "https://arxiv.org/abs/2202.02626",
    "authors": [
      "Mohammad Khalooei",
      "Mohammad Mehdi Homayounpour",
      "Maryam Amirmazlaghani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.02947",
    "title": "Parallel Successive Learning for Dynamic Distributed Model Training over  Heterogeneous Wireless Networks",
    "abstract": " Title: Parallel Successive Learning for Dynamic Distributed Model Training over  Heterogeneous Wireless Networks ",
    "url": "https://arxiv.org/abs/2202.02947",
    "authors": [
      "Seyyedali Hosseinalipour",
      "Su Wang",
      "Nicolo Michelusi",
      "Vaneet Aggarwal",
      "Christopher G. Brinton",
      "David J. Love",
      "Mung Chiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.03152",
    "title": "Optimizing Age of Information in Wireless Uplink Networks with Partial  Observations",
    "abstract": " Comments: Submitted for possible IEEE publication ",
    "url": "https://arxiv.org/abs/2202.03152",
    "authors": [
      "Jingwei Liu",
      "Rui Zhang",
      "Aoyu Gong",
      "He Chen"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2202.03613",
    "title": "Conformal prediction for the design problem",
    "abstract": " Comments: 30 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2202.03613",
    "authors": [
      "Clara Fannjiang",
      "Stephen Bates",
      "Anastasios Angelopoulos",
      "Jennifer Listgarten",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2202.03652",
    "title": "Real-time disease prediction with local differential privacy in Internet  of Medical Things",
    "abstract": " Title: Real-time disease prediction with local differential privacy in Internet  of Medical Things ",
    "url": "https://arxiv.org/abs/2202.03652",
    "authors": [
      "Guanhong Miao",
      "A. Adam Ding",
      "Samuel S. Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Other Statistics (stat.OT)"
    ]
  },
  {
    "id": "arXiv:2202.03861",
    "title": "Targeted Trojan-Horse Attacks on Language-based Image Retrieval",
    "abstract": " Title: Targeted Trojan-Horse Attacks on Language-based Image Retrieval ",
    "url": "https://arxiv.org/abs/2202.03861",
    "authors": [
      "Fan Hu",
      "Aozhu Chen",
      "Xirong Li"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2202.04000",
    "title": "Learning Sinkhorn divergences for supervised change point detection",
    "abstract": " Comments: 19 pages, 13 figures. Reorganized figures and text for improved readability ",
    "url": "https://arxiv.org/abs/2202.04000",
    "authors": [
      "Nauman Ahad",
      "Eva L. Dyer",
      "Keith B. Hengen",
      "Yao Xie",
      "Mark A. Davenport"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04208",
    "title": "Evaluating Causal Inference Methods",
    "abstract": " Comments: 5 figures, 13 pages ",
    "url": "https://arxiv.org/abs/2202.04208",
    "authors": [
      "Harsh Parikh",
      "Carlos Varjao",
      "Louise Xu",
      "Eric Tchetgen Tchetgen"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ]
  },
  {
    "id": "arXiv:2202.04488",
    "title": "CRAT-Pred: Vehicle Trajectory Prediction with Crystal Graph  Convolutional Neural Networks and Multi-Head Self-Attention",
    "abstract": " Comments: To appear in the proceedings of 2022 IEEE International Conference on Robotics and Automation (ICRA) ",
    "url": "https://arxiv.org/abs/2202.04488",
    "authors": [
      "Julian Schmidt",
      "Julian Jordan",
      "Franz Gritschneder",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.04514",
    "title": "A Model-Agnostic Causal Learning Framework for Recommendation using  Search Data",
    "abstract": " Comments: 9 pages, 7 figures, accepted by The Web Conference 2022 ",
    "url": "https://arxiv.org/abs/2202.04514",
    "authors": [
      "Zihua Si",
      "Xueran Han",
      "Xiao Zhang",
      "Jun Xu",
      "Yue Yin",
      "Yang Song",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2202.04567",
    "title": "Optimal Hyperparameters and Structure Setting of Multi-Objective Robust  CNN Systems via Generalized Taguchi Method and Objective Vector Norm",
    "abstract": " Comments: 10 pages. Corresponding Author: Sheng-Guo Wang, swang@uncc.edu. To add the arXiv stamp to the first page ",
    "url": "https://arxiv.org/abs/2202.04567",
    "authors": [
      "Sheng-Guo Wang",
      "Shanshan Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2202.04595",
    "title": "Exploring Structural Sparsity in Neural Image Compression",
    "abstract": " Comments: 5 pages, 5 figures, submitted to ICIP 2022 ",
    "url": "https://arxiv.org/abs/2202.04595",
    "authors": [
      "Shanzhi Yin",
      "Fanyang Meng",
      "Wen Tan",
      "Chao Li",
      "Youneng Bao",
      "Yongsheng Liang",
      "Wei Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04632",
    "title": "A Local Geometric Interpretation of Feature Extraction in Deep  Feedforward Neural Networks",
    "abstract": " Title: A Local Geometric Interpretation of Feature Extraction in Deep  Feedforward Neural Networks ",
    "url": "https://arxiv.org/abs/2202.04632",
    "authors": [
      "Md Kamran Chowdhury Shisher",
      "Tasmeen Zaman Ornee",
      "Yin Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.04641",
    "title": "Unconditionally secure digital signatures implemented in an 8-user  quantum network",
    "abstract": " Comments: Preprint, 9 pages, 7 figures, 1 table ",
    "url": "https://arxiv.org/abs/2202.04641",
    "authors": [
      "Yoann Pelet",
      "Ittoop Vergheese Puthoor",
      "Natarajan Venkatachalam",
      "S\u00f6ren Wengerowsky",
      "Martin Lon\u010dari\u0107",
      "Sebastian Philipp Neumann",
      "Bo Liu",
      "\u017deljko Samec",
      "Mario Stip\u010devi\u0107",
      "Rupert Ursin",
      "Erika Andersson",
      "John G. Rarity",
      "Djeylan Aktas",
      "Siddarth Koduru Joshi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ]
  }
]