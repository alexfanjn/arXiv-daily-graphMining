[
  {
    "id": "arXiv:2202.01211",
    "title": "A Flexible Clustering Pipeline for Mining Text Intentions",
    "abstract": "Mining the latent intentions from large volumes of natural language inputs is a key step to help data analysts design and refine Intelligent Virtual Assistants (IVAs) for customer service and sales support. We created a flexible and scalable clustering pipeline within the Verint Intent Manager (VIM) that integrates the fine-tuning of language models, a high performing k-NN library and community detection techniques to help analysts quickly surface and organize relevant user intentions from conversational texts. The fine-tuning step is necessary because pre-trained language models cannot encode texts to efficiently surface particular clustering structures when the target texts are from an unseen domain or the clustering task is not topic detection. We describe the pipeline and demonstrate its performance using BERT on three real-world text mining tasks. As deployed in the VIM application, this clustering pipeline produces high quality results, improving the performance of data analysts and reducing the time it takes to surface intentions from customer service data, thereby reducing the time it takes to build and deploy IVAs in new domains. ",
    "url": "https://arxiv.org/abs/2202.01211",
    "authors": [
      "Xinyu Chen",
      "Ian Beaver"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01214",
    "title": "Approximate Bisimulation Relations for Neural Networks and Application  to Assured Neural Network Compression",
    "abstract": "In this paper, we propose a concept of approximate bisimulation relation for feedforward neural networks. In the framework of approximate bisimulation relation, a novel neural network merging method is developed to compute the approximate bisimulation error between two neural networks based on reachability analysis of neural networks. The developed method is able to quantitatively measure the distance between the outputs of two neural networks with the same inputs. Then, we apply the approximate bisimulation relation results to perform neural networks model reduction and compute the compression precision, i.e., assured neural networks compression. At last, using the assured neural network compression, we accelerate the verification processes of ACAS Xu neural networks to illustrate the effectiveness and advantages of our proposed approximate bisimulation approach. ",
    "url": "https://arxiv.org/abs/2202.01214",
    "authors": [
      "Weiming Xiang",
      "Zhongzhu Shao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.01248",
    "title": "Passing the Limits of Pure Local Search for the Maximum Weight  Independent Set Problem in d-Claw Free Graphs",
    "abstract": "In this paper, we consider the task of computing an independent set of maximum weight in a given $d$-claw free graph $G=(V,E)$ equipped with a positive weight function $w:V\\rightarrow\\mathbb{R}_{>0}$. Recently, Neuwohner has shown how to obtain approximation ratios of $\\frac{d-1+\\epsilon_d}{2}$ in quasi-polynomial time, where $0\\leq \\epsilon_d\\leq 1$ and $\\lim_{d\\rightarrow\\infty}\\epsilon_d = 0$. For the special case of the $d-1$-Set Packing Problem, she showed how to get down to a polynomial running time. On the other hand, she provided examples showing that no local improvement algorithm considering local improvements of logarithmic size can yield an approximation guarantee better than $\\frac{d-1}{2}$. However, it turns out that if one considers local improvements that arise by dropping vertex weights and running an algorithm devised for the unweighted setting on certain sub-instances of the given one, one can get beyond the $\\frac{d-1}{2}$-threshold and obtain approximation guarantees of $\\frac{d}{2}-\\Omega(d)$ in quasi-polynomial time. For $d-1$-Set Packing instances, we can guarantee a polynomial running time. We also conduct a more general investigation of the relation between approximation guarantees for the unweighted and weighted variants of both the Maximum Weight Independent Set Problem in $d$-claw free graphs and the $d-1$-Set Packing problem. In doing so, we can show that for any constant $\\sigma > 0$, there exists a constant $\\tau > 0$ such that a (quasi-)polynomial time $1+\\tau\\cdot (d-2)$-approximation for the unweighted $d-1$-Set Packing Problem (the Maximum Cardinality Independent Set problem in $d$-claw free graphs) implies a (quasi-)-polynomial time $1+\\sigma\\cdot (d-2)$-approximation for the weighted $d-1$-Set Packing Problem (the Maximum Weight Independent Set problem in $d$-claw free graphs). ",
    "url": "https://arxiv.org/abs/2202.01248",
    "authors": [
      "Meike Neuwohner"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2202.01252",
    "title": "Speaker Normalization for Self-supervised Speech Emotion Recognition",
    "abstract": "Large speech emotion recognition datasets are hard to obtain, and small datasets may contain biases. Deep-net-based classifiers, in turn, are prone to exploit those biases and find shortcuts such as speaker characteristics. These shortcuts usually harm a model's ability to generalize. To address this challenge, we propose a gradient-based adversary learning framework that learns a speech emotion recognition task while normalizing speaker characteristics from the feature representation. We demonstrate the efficacy of our method on both speaker-independent and speaker-dependent settings and obtain new state-of-the-art results on the challenging IEMOCAP dataset. ",
    "url": "https://arxiv.org/abs/2202.01252",
    "authors": [
      "Itai Gat",
      "Hagai Aronowitz",
      "Weizhong Zhu",
      "Edmilson Morais",
      "Ron Hoory"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01260",
    "title": "Shannon Bounds on Lossy Gray-Wyner Networks",
    "abstract": "The Gray-Wyner network subject to a fidelity criterion is studied. Upper and lower bounds for the trade-offs between the private sum-rate and the common rate are obtained for arbitrary sources subject to mean-squared error distortion. The bounds meet exactly, leading to the computation of the rate region, when the source is jointly Gaussian. They meet partially when the sources are modeled via an additive Gaussian \"channel\". The bounds are inspired from the Shannon bounds on the rate-distortion problem. ",
    "url": "https://arxiv.org/abs/2202.01260",
    "authors": [
      "Erixhen Sula",
      "Michael Gastpar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.01263",
    "title": "NoisyMix: Boosting Robustness by Combining Data Augmentations, Stability  Training, and Noise Injections",
    "abstract": "For many real-world applications, obtaining stable and robust statistical performance is more important than simply achieving state-of-the-art predictive test accuracy, and thus robustness of neural networks is an increasingly important topic. Relatedly, data augmentation schemes have been shown to improve robustness with respect to input perturbations and domain shifts. Motivated by this, we introduce NoisyMix, a training scheme that combines data augmentations with stability training and noise injections to improve both model robustness and in-domain accuracy. This combination promotes models that are consistently more robust and that provide well-calibrated estimates of class membership probabilities. We demonstrate the benefits of NoisyMix on a range of benchmark datasets, including ImageNet-C, ImageNet-R, and ImageNet-P. Moreover, we provide theory to understand implicit regularization and robustness of NoisyMix. ",
    "url": "https://arxiv.org/abs/2202.01263",
    "authors": [
      "N. Benjamin Erichson",
      "Soon Hoe Lim",
      "Francisco Utrera",
      "Winnie Xu",
      "Ziang Cao",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.01269",
    "title": "Robust Estimation for Nonparametric Families via Generative Adversarial  Networks",
    "abstract": "We provide a general framework for designing Generative Adversarial Networks (GANs) to solve high dimensional robust statistics problems, which aim at estimating unknown parameter of the true distribution given adversarially corrupted samples. Prior work focus on the problem of robust mean and covariance estimation when the true distribution lies in the family of Gaussian distributions or elliptical distributions, and analyze depth or scoring rule based GAN losses for the problem. Our work extend these to robust mean estimation, second moment estimation, and robust linear regression when the true distribution only has bounded Orlicz norms, which includes the broad family of sub-Gaussian, sub-Exponential and bounded moment distributions. We also provide a different set of sufficient conditions for the GAN loss to work: we only require its induced distance function to be a cumulative density function of some light-tailed distribution, which is easily satisfied by neural networks with sigmoid activation. In terms of techniques, our proposed GAN losses can be viewed as a smoothed and generalized Kolmogorov-Smirnov distance, which overcomes the computational intractability of the original Kolmogorov-Smirnov distance used in the prior work. ",
    "url": "https://arxiv.org/abs/2202.01269",
    "authors": [
      "Banghua Zhu",
      "Jiantao Jiao",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Statistics Theory (math.ST)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.01286",
    "title": "ASR-Aware End-to-end Neural Diarization",
    "abstract": "We present a Conformer-based end-to-end neural diarization (EEND) model that uses both acoustic input and features derived from an automatic speech recognition (ASR) model. Two categories of features are explored: features derived directly from ASR output (phones, position-in-word and word boundaries) and features derived from a lexical speaker change detection model, trained by fine-tuning a pretrained BERT model on the ASR output. Three modifications to the Conformer-based EEND architecture are proposed to incorporate the features. First, ASR features are concatenated with acoustic features. Second, we propose a new attention mechanism called contextualized self-attention that utilizes ASR features to build robust speaker representations. Finally, multi-task learning is used to train the model to minimize classification loss for the ASR features along with diarization loss. Experiments on the two-speaker English conversations of Switchboard+SRE data sets show that multi-task learning with position-in-word information is the most effective way of utilizing ASR features, reducing the diarization error rate (DER) by 20% relative to the baseline. ",
    "url": "https://arxiv.org/abs/2202.01286",
    "authors": [
      "Aparna Khare",
      "Eunjung Han",
      "Yuguang Yang",
      "Andreas Stolcke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2202.01289",
    "title": "Systems Mining with Heraklit: The Next Step",
    "abstract": "We suggest systems mining as the next step after process mining. Systems mining starts with a more careful investigation of runs, and constructs a detailed model of behavior, more subtle than classical process mining. The resulting model is enriched with information about data. From this model, a system model can be deduced in a systematic way. ",
    "url": "https://arxiv.org/abs/2202.01289",
    "authors": [
      "Peter Fettke",
      "Wolfgang Reisig"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2202.01290",
    "title": "Cyclical Pruning for Sparse Neural Networks",
    "abstract": "Current methods for pruning neural network weights iteratively apply magnitude-based pruning on the model weights and re-train the resulting model to recover lost accuracy. In this work, we show that such strategies do not allow for the recovery of erroneously pruned weights. To enable weight recovery, we propose a simple strategy called \\textit{cyclical pruning} which requires the pruning schedule to be periodic and allows for weights pruned erroneously in one cycle to recover in subsequent ones. Experimental results on both linear models and large-scale deep neural networks show that cyclical pruning outperforms existing pruning algorithms, especially at high sparsity ratios. Our approach is easy to tune and can be readily incorporated into existing pruning pipelines to boost performance. ",
    "url": "https://arxiv.org/abs/2202.01290",
    "authors": [
      "Suraj Srinivas",
      "Andrey Kuzmin",
      "Markus Nagel",
      "Mart van Baalen",
      "Andrii Skliar",
      "Tijmen Blankevoort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.01297",
    "title": "Age Distribution in Arbitrary Preemptive Memoryless Networks",
    "abstract": "We study the probability distribution of age of information (AoI) in arbitrary networks with memoryless service times. A source node generates packets following a Poisson process, and then the packets are forwarded across the network in such a way that newer updates preempt older ones. This model is equivalent to gossip networks that was recently studied by Yates, and for which he obtained a recursive formula allowing the computation for the average AoI. In this paper, we obtain a very simple characterization of the stationary distribution of AoI at every node in the network. This allows for the computation of the average of an arbitrary function of the age. In particular, we can compute age-violation probabilities. Furthermore, we show how it is possible to use insights from our simple characterization in order to substantially reduce the computation time of average AoIs in some structured networks. Finally, we describe how it is possible to use our characterization in order to obtain faster and more accurate Monte Carlo simulations estimating the average AoI, or the average of an arbitrary function of the age. ",
    "url": "https://arxiv.org/abs/2202.01297",
    "authors": [
      "Rajai Nasser",
      "Ibrahim Issa",
      "Ibrahim Abou-Faycal"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.01300",
    "title": "Causal Inference Through the Structural Causal Marginal Problem",
    "abstract": "We introduce an approach to counterfactual inference based on merging information from multiple datasets. We consider a causal reformulation of the statistical marginal problem: given a collection of marginal structural causal models (SCMs) over distinct but overlapping sets of variables, determine the set of joint SCMs that are counterfactually consistent with the marginal ones. We formalise this approach for categorical SCMs using the response function formulation and show that it reduces the space of allowed marginal and joint SCMs. Our work thus highlights a new mode of falsifiability through additional variables, in contrast to the statistical one via additional data. ",
    "url": "https://arxiv.org/abs/2202.01300",
    "authors": [
      "Luigi Gresele",
      "Julius von K\u00fcgelgen",
      "Jonas M. K\u00fcbler",
      "Elke Kirschbaum",
      "Bernhard Sch\u00f6lkopf",
      "Dominik Janzing"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01308",
    "title": "Impact Analysis of Harassment Against Women Using Association Rule  Mining Approaches: Bangladesh Prospective",
    "abstract": "In recent years, it has been noticed that women are making progress in every sector of society. Their involvement in every field, such as education, job market, social work, etc., is increasing at a remarkable rate. For the last several years, the government has been trying its level best for the advancement of women in every sector by doing several research work and activities and funding several organizations to motivate women. Although women's involvement in several fields is increasing, the big concern is they are facing several barriers in their advancement, and it is not surprising that sexual harassment is one of them. In Bangladesh, harassment against women, especially students, is a common phenomenon, and it is increasing. In this paper, a survey-based and Apriori algorithm are used to analyze the several impacts of harassment among several age groups. Also, several factors such as frequent impacts of harassment, most vulnerable groups, women mostly facing harassment, the alleged person behind harassment, etc., are analyzed through association rule mining of Apriori algorithm and F.P. Growth algorithm. And then, a comparison of performance between both algorithms has been shown briefly. For this analysis, data have been carefully collected from all ages. ",
    "url": "https://arxiv.org/abs/2202.01308",
    "authors": [
      "Bahar Uddin Mahmud",
      "Afsana Sharmin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01309",
    "title": "Multi-Resolution Factor Graph Based Stereo Correspondence Algorithm",
    "abstract": "A dense depth-map of a scene at an arbitrary view orientation can be estimated from dense view correspondences among multiple lower-dimensional views of the scene. These low-dimensional view correspondences are dependent on the geometrical relationship among the views and the scene. Determining dense view correspondences is difficult in part due to presence of homogeneous regions in the scene and due to presence of occluded regions and illumination differences among the views. We present a new multi-resolution factor graph-based stereo matching algorithm (MR-FGS) that utilizes both intra- and inter-resolution dependencies among the views as well as among the disparity estimates. The proposed framework allows exchange of information among multiple resolutions of the correspondence problem and is useful for handling larger homogeneous regions in a scene. The MR-FGS algorithm was evaluated qualitatively and quantitatively using stereo pairs in the Middlebury stereo benchmark dataset based on commonly used performance measures. When compared to a recently developed factor graph model (FGS), the MR-FGS algorithm provided more accurate disparity estimates without requiring the commonly used post-processing procedure known as the left-right consistency check. The multi-resolution dependency constraint within the factor-graph model significantly improved contrast along depth boundaries in the MR-FGS generated disparity maps. ",
    "url": "https://arxiv.org/abs/2202.01309",
    "authors": [
      "Hanieh Shabanian",
      "Madhusudhanan Balasubramanian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01312",
    "title": "Causal Imitation Learning under Temporally Correlated Noise",
    "abstract": "We develop algorithms for imitation learning from policy data that was corrupted by temporally correlated noise in expert actions. When noise affects multiple timesteps of recorded data, it can manifest as spurious correlations between states and actions that a learner might latch on to, leading to poor policy performance. To break up these spurious correlations, we apply modern variants of the instrumental variable regression (IVR) technique of econometrics, enabling us to recover the underlying policy without requiring access to an interactive expert. In particular, we present two techniques, one of a generative-modeling flavor (DoubIL) that can utilize access to a simulator, and one of a game-theoretic flavor (ResiduIL) that can be run entirely offline. We find both of our algorithms compare favorably to behavioral cloning on simulated control tasks. ",
    "url": "https://arxiv.org/abs/2202.01312",
    "authors": [
      "Gokul Swamy",
      "Sanjiban Choudhury",
      "J. Andrew Bagnell",
      "Zhiwei Steven Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.01315",
    "title": "Approximating Full Conformal Prediction at Scale via Influence Functions",
    "abstract": "Conformal prediction (CP) is a wrapper around traditional machine learning models, giving coverage guarantees under the sole assumption of exchangeability; in classification problems, for a chosen significance level $\\varepsilon$, CP guarantees that the number of errors is at most $\\varepsilon$, irrespective of whether the underlying model is misspecified. However, the prohibitive computational costs of full CP led researchers to design scalable alternatives, which alas do not attain the same guarantees or statistical power of full CP. In this paper, we use influence functions to efficiently approximate full CP. We prove that our method is a consistent approximation of full CP, and empirically show that the approximation error becomes smaller as the training set increases; e.g., for $10^{3}$ training points the two methods output p-values that are $<10^{-3}$ apart: a negligible error for any practical application. Our methods enable scaling full CP to large real-world datasets. We compare our full CP approximation ACP to mainstream CP alternatives, and observe that our method is computationally competitive whilst enjoying the statistical predictive power of full CP. ",
    "url": "https://arxiv.org/abs/2202.01315",
    "authors": [
      "Javier Abad",
      "Umang Bhatt",
      "Adrian Weller",
      "Giovanni Cherubin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2202.01319",
    "title": "Deep Learning for Epidemiologists: An Introduction to Neural Networks",
    "abstract": "Deep learning methods are increasingly being applied to problems in medicine and healthcare. However, few epidemiologists have received formal training in these methods. To bridge this gap, this article introduces to the fundamentals of deep learning from an epidemiological perspective. Specifically, this article reviews core concepts in machine learning (overfitting, regularization, hyperparameters), explains several fundamental deep learning architectures (convolutional neural networks, recurrent neural networks), and summarizes training, evaluation, and deployment of models. We aim to enable the reader to engage with and critically evaluate medical applications of deep learning, facilitating a dialogue between computer scientists and epidemiologists that will improve the safety and efficacy of applications of this technology. ",
    "url": "https://arxiv.org/abs/2202.01319",
    "authors": [
      "Stylianos Serghiou",
      "Kathryn Rough"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01322",
    "title": "How to Improve Deep Learning for Software Analytics (a case study with  code smell detection)",
    "abstract": "To reduce technical debt and make code more maintainable, it is important to be able to warn programmers about code smells. State-of-the-art code small detectors use deep learners, without much exploration of alternatives within that technology. One promising alternative for software analytics and deep learning is GHOST (from TSE'21) that relies on a combination of hyper-parameter optimization of feedforward neural networks and a novel oversampling technique to deal with class imbalance. The prior study from TSE'21 proposing this novel \"fuzzy sampling\" was somewhat limited in that the method was tested on defect prediction, but nothing else. Like defect prediction, code smell detection datasets have a class imbalance (which motivated \"fuzzy sampling\"). Hence, in this work we test if fuzzy sampling is useful for code smell detection. The results of this paper show that we can achieve better than state-of-the-art results on code smell detection with fuzzy oversampling. For example, for \"feature envy\", we were able to achieve 99+\\% AUC across all our datasets, and on 8/10 datasets for \"misplaced class\". While our specific results refer to code smell detection, they do suggest other lessons for other kinds of analytics. For example: (a) try better preprocessing before trying complex learners (b) include simpler learners as a baseline in software analytics (c) try \"fuzzy sampling\" as one such baseline. ",
    "url": "https://arxiv.org/abs/2202.01322",
    "authors": [
      "Rahul Yedida",
      "Tim Menzies"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2202.01332",
    "title": "Training a Bidirectional GAN-based One-Class Classifier for Network  Intrusion Detection",
    "abstract": "The network intrusion detection task is challenging because of the imbalanced and unlabeled nature of the dataset it operates on. Existing generative adversarial networks (GANs), are primarily used for creating synthetic samples from reals. They also have been proved successful in anomaly detection tasks. In our proposed method, we construct the trained encoder-discriminator as a one-class classifier based on Bidirectional GAN (Bi-GAN) for detecting anomalous traffic from normal traffic other than calculating expensive and complex anomaly scores or thresholds. Our experimental result illustrates that our proposed method is highly effective to be used in network intrusion detection tasks and outperforms other similar generative methods on the NSL-KDD dataset. ",
    "url": "https://arxiv.org/abs/2202.01332",
    "authors": [
      "Wen Xu",
      "Julian Jang-Jaccard",
      "Tong Liu",
      "Fariza Sabrina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01341",
    "title": "Robust Binary Models by Pruning Randomly-initialized Networks",
    "abstract": "We propose ways to obtain robust models against adversarial attacks from randomly-initialized binary networks. Unlike adversarial training, which learns the model parameters, we in contrast learn the structure of the robust model by pruning a randomly-initialized binary network. Our method confirms the strong lottery ticket hypothesis in the presence of adversarial attacks. Compared to the results obtained in a non-adversarial setting, we in addition improve the performance and compression of the model by 1) using an adaptive pruning strategy for different layers, and 2) using a different initialization scheme such that all model parameters are initialized either to +1 or -1. Our extensive experiments demonstrate that our approach performs not only better than the state-of-the art for robust binary networks; it also achieves comparable or even better performance than full-precision network training methods. ",
    "url": "https://arxiv.org/abs/2202.01341",
    "authors": [
      "Chen Liu",
      "Ziqi Zhao",
      "Sabine S\u00fcsstrunk",
      "Mathieu Salzmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01348",
    "title": "VindiCo: Privacy Safeguard Against Adaptation Based Spyware in  Human-in-the-Loop IoT",
    "abstract": "Personalized IoT adapts their behavior based on contextual information, such as user behavior and location. Unfortunately, the fact that personalized IoT adapts to user context opens a side-channel that leaks private information about the user. To that end, we start by studying the extent to which a malicious eavesdropper can monitor the actions taken by an IoT system and extract users' private information. In particular, we show two concrete instantiations (in the context of mobile phones and smart homes) of a new category of spyware which we refer to as Context-Aware Adaptation Based Spyware (SpyCon). Experimental evaluations show that the developed SpyCon can predict users' daily behavior with an accuracy of 90.3%. The rest of this paper is devoted to introducing VindiCo, a software mechanism designed to detect and mitigate possible SpyCon. Being new spyware with no known prior signature or behavior, traditional spyware detection that is based on code signature or app behavior is not adequate to detect SpyCon. Therefore, VindiCo proposes a novel information-based detection engine along with several mitigation techniques to restrain the ability of the detected SpyCon to extract private information. By having general detection and mitigation engines, VindiCo is agnostic to the inference algorithm used by SpyCon. Our results show that VindiCo reduces the ability of SpyCon to infer user context from 90.3% to the baseline accuracy (accuracy based on random guesses) with negligible execution overhead. ",
    "url": "https://arxiv.org/abs/2202.01348",
    "authors": [
      "Salma Elmalaki",
      "Bo-Jhang Ho",
      "Moustafa Alzantot",
      "Yasser Shoukry",
      "Mani Srivastava"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.01361",
    "title": "Generative Flow Networks for Discrete Probabilistic Modeling",
    "abstract": "We present energy-based generative flow networks (EB-GFN), a novel probabilistic modeling algorithm for high-dimensional discrete data. Building upon the theory of generative flow networks (GFlowNets), we model the generation process by a stochastic data construction policy and thus amortize expensive MCMC exploration into a fixed number of actions sampled from a GFlowNet. We show how GFlowNets can approximately perform large-block Gibbs sampling to mix between modes. We propose a framework to jointly train a GFlowNet with an energy function, so that the GFlowNet learns to sample from the energy distribution, while the energy learns with an approximate MLE objective with negative samples from the GFlowNet. We demonstrate EB-GFN's effectiveness on various probabilistic modeling tasks. ",
    "url": "https://arxiv.org/abs/2202.01361",
    "authors": [
      "Dinghuai Zhang",
      "Nikolay Malkin",
      "Zhen Liu",
      "Alexandra Volokhova",
      "Aaron Courville",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.01362",
    "title": "VNE Solution for Network Differentiated QoS and Security Requirements:  From the Perspective of Deep Reinforcement Learning",
    "abstract": "The rapid development and deployment of network services has brought a series of challenges to researchers. On the one hand, the needs of Internet end users/applications reflect the characteristics of travel alienation, and they pursue different perspectives of service quality. On the other hand, with the explosive growth of information in the era of big data, a lot of private information is stored in the network. End users/applications naturally start to pay attention to network security. In order to solve the requirements of differentiated quality of service (QoS) and security, this paper proposes a virtual network embedding (VNE) algorithm based on deep reinforcement learning (DRL), aiming at the CPU, bandwidth, delay and security attributes of substrate network. DRL agent is trained in the network environment constructed by the above attributes. The purpose is to deduce the mapping probability of each substrate node and map the virtual node according to this probability. Finally, the breadth first strategy (BFS) is used to map the virtual links. In the experimental stage, the algorithm based on DRL is compared with other representative algorithms in three aspects: long term average revenue, long term revenue consumption ratio and acceptance rate. The results show that the algorithm proposed in this paper has achieved good experimental results, which proves that the algorithm can be effectively applied to solve the end user/application differentiated QoS and security requirements. ",
    "url": "https://arxiv.org/abs/2202.01362",
    "authors": [
      "Chao Wang",
      "Ranbir Singh Batth",
      "Peiying Zhang",
      "Gagangeet Singh Aujla",
      "Youxiang Duan",
      "Lihua Ren"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2202.01367",
    "title": "Real-time Emergency Vehicle Event Detection Using Audio Data",
    "abstract": "In this work, we focus on detecting emergency vehicles using only audio data. Improved and quick detection can help in faster preemption of these vehicles at signalized intersections thereby reducing overall response time in case of emergencies. Important audio features were extracted from raw data and passed into extreme learning machines (ELM) for training. ELMs have been used in this work because of its simplicity and shorter run-time which can therefore be used for online learning. Recently, there have been many studies that focus on sound classification but most of the methods used are complex to train and implement. The results from this paper show that ELM can achieve similar performance with exceptionally shorter training times. The accuracy reported for ELM is about 97% for emergency vehicle detection (EVD). ",
    "url": "https://arxiv.org/abs/2202.01367",
    "authors": [
      "Zubayer Islam",
      "Mohamed Abdel-Aty"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2202.01380",
    "title": "Learning Mechanically Driven Emergent Behavior with Message Passing  Neural Networks",
    "abstract": "From designing architected materials to connecting mechanical behavior across scales, computational modeling is a critical tool in solid mechanics. Recently, there has been a growing interest in using machine learning to reduce the computational cost of physics-based simulations. Notably, while machine learning approaches that rely on Graph Neural Networks (GNNs) have shown success in learning mechanics, the performance of GNNs has yet to be investigated on a myriad of solid mechanics problems. In this work, we examine the ability of GNNs to predict a fundamental aspect of mechanically driven emergent behavior: the connection between a column's geometric structure and the direction that it buckles. To accomplish this, we introduce the Asymmetric Buckling Columns (ABC) dataset, a dataset comprised of three sub-datasets of asymmetric and heterogeneous column geometries where the goal is to classify the direction of symmetry breaking (left or right) under compression after the onset of instability. Because of complex local geometry, the \"image-like\" data representations required for implementing standard convolutional neural network based metamodels are not ideal, thus motivating the use of GNNs. In addition to investigating GNN model architecture, we study the effect of different input data representation approaches, data augmentation, and combining multiple models as an ensemble. While we were able to obtain good results, we also showed that predicting solid mechanics based emergent behavior is non-trivial. Because both our model implementation and dataset are distributed under open-source licenses, we hope that future researchers can build on our work to create enhanced mechanics-specific machine learning pipelines for capturing the behavior of complex geometric structures. ",
    "url": "https://arxiv.org/abs/2202.01380",
    "authors": [
      "Peerasait Prachaseree",
      "Emma Lejeune"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2202.01391",
    "title": "Fair Representation Clustering with Several Protected Classes",
    "abstract": "We study the problem of fair $k$-median where each cluster is required to have a fair representation of individuals from different groups. In the fair representation $k$-median problem, we are given a set of points $X$ in a metric space. Each point $x\\in X$ belongs to one of $\\ell$ groups. Further, we are given fair representation parameters $\\alpha_j$ and $\\beta_j$ for each group $j\\in [\\ell]$. We say that a $k$-clustering $C_1, \\cdots, C_k$ fairly represents all groups if the number of points from group $j$ in cluster $C_i$ is between $\\alpha_j |C_i|$ and $\\beta_j |C_i|$ for every $j\\in[\\ell]$ and $i\\in [k]$. The goal is to find a set $\\mathcal{C}$ of $k$ centers and an assignment $\\phi: X\\rightarrow \\mathcal{C}$ such that the clustering defined by $(\\mathcal{C}, \\phi)$ fairly represents all groups and minimizes the $\\ell_1$-objective $\\sum_{x\\in X} d(x, \\phi(x))$. We present an $O(\\log k)$-approximation algorithm that runs in time $n^{O(\\ell)}$. Note that the known algorithms for the problem either (i) violate the fairness constraints by an additive term or (ii) run in time that is exponential in both $k$ and $\\ell$. We also consider an important special case of the problem where $\\alpha_j = \\beta_j = \\frac{f_j}{f}$ and $f_j, f \\in \\mathbb{N}$ for all $j\\in [\\ell]$. For this special case, we present an $O(\\log k)$-approximation algorithm that runs in $(kf)^{O(\\ell)}\\log n + poly(n)$ time. ",
    "url": "https://arxiv.org/abs/2202.01391",
    "authors": [
      "Zhen Dai",
      "Yury Makarychev",
      "Ali Vakilian"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01414",
    "title": "DocBed: A Multi-Stage OCR Solution for Documents with Complex Layouts",
    "abstract": "Digitization of newspapers is of interest for many reasons including preservation of history, accessibility and search ability, etc. While digitization of documents such as scientific articles and magazines is prevalent in literature, one of the main challenges for digitization of newspaper lies in its complex layout (e.g. articles spanning multiple columns, text interrupted by images) analysis, which is necessary to preserve human read-order. This work provides a major breakthrough in the digitization of newspapers on three fronts: first, releasing a dataset of 3000 fully-annotated, real-world newspaper images from 21 different U.S. states representing an extensive variety of complex layouts for document layout analysis; second, proposing layout segmentation as a precursor to existing optical character recognition (OCR) engines, where multiple state-of-the-art image segmentation models and several post-processing methods are explored for document layout segmentation; third, providing a thorough and structured evaluation protocol for isolated layout segmentation and end-to-end OCR. ",
    "url": "https://arxiv.org/abs/2202.01414",
    "authors": [
      "Wenzhen Zhu",
      "Negin Sokhandan",
      "Guang Yang",
      "Sujitha Martin",
      "Suchitra Sathyanarayana"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.01417",
    "title": "Generalized Omega Turn Gait Enables Agile Limbless Robot Turning in  Complex Environments",
    "abstract": "Reorientation (turning in plane) plays a critical role for all robots in any field application, especially those that in confined spaces. While important, reorientation remains a relatively unstudied problem for robots, including limbless mechanisms, often called snake robots. Instead of looking at snakes, we take inspiration from observations of the turning behavior of tiny nematode worms C. elegans. Our previous work presented an in-place and in-plane turning gait for limbless robots, called an omega turn, and prescribed it using a novel two-wave template. In this work, we advance omega turn-inspired controllers in three aspects: 1) we use geometric methods to vary joint angle amplitudes and forward wave spatial frequency in our turning equation to establish a wide and precise amplitude modulation and frequency modulation on omega turn; 2) we use this new relationship to enable robots with fewer internal degrees of freedom (i.e., fewer joints in the body) to achieve desirable performance, and 3) we apply compliant control methods to this relationship to handle unmodelled effects in the environment. We experimentally validate our approach on a limbless robot that the omega turn can produce effective and robust turning motion in various types of environments, such as granular media and rock pile. ",
    "url": "https://arxiv.org/abs/2202.01417",
    "authors": [
      "Tianyu Wang",
      "Baxi Chong",
      "Yuelin Deng",
      "Ruijie Fu",
      "Howie Choset",
      "Daniel I. Goldman"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.01426",
    "title": "Self-Supervised Monte Carlo Tree Search Learning for Object Retrieval in  Clutter",
    "abstract": "In this study, working with the task of object retrieval in clutter, we have developed a robot learning framework in which Monte Carlo Tree Search (MCTS) is first applied to enable a Deep Neural Network (DNN) to learn the intricate interactions between a robot arm and a complex scene containing many objects, allowing the DNN to partially clone the behavior of MCTS. In turn, the trained DNN is integrated into MCTS to help guide its search effort. We call this approach Monte Carlo tree search and learning for Object REtrieval (MORE), which delivers significant computational efficiency gains and added solution optimality. MORE is a self-supervised robotics framework/pipeline capable of working in the real world that successfully embodies the System 2 $\\to$ System 1 learning philosophy proposed by Kahneman, where learned knowledge, used properly, can help greatly speed up a time-consuming decision process over time. Videos and supplementary material can be found at https://github.com/arc-l/more ",
    "url": "https://arxiv.org/abs/2202.01426",
    "authors": [
      "Baichuan Huang",
      "Teng Guo",
      "Abdeslam Boularias",
      "Jingjin Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.01427",
    "title": "SparGE: Sparse Coding-based Patient Similarity Learning via Low-rank  Constraints and Graph Embedding",
    "abstract": "Patient similarity assessment (PSA) is pivotal to evidence-based and personalized medicine, enabled by analyzing the increasingly available electronic health records (EHRs). However, machine learning approaches for PSA has to deal with inherent data deficiencies of EHRs, namely missing values, noise, and small sample sizes. In this work, an end-to-end discriminative learning framework, called SparGE, is proposed to address these data challenges of EHR for PSA. SparGE measures similarity by jointly sparse coding and graph embedding. First, we use low-rank constrained sparse coding to identify and calculate weight for similar patients, while denoising against missing values. Then, graph embedding on sparse representations is adopted to measure the similarity between patient pairs via preserving local relationships defined by distances. Finally, a global cost function is constructed to optimize related parameters. Experimental results on two private and public real-world healthcare datasets, namely SingHEART and MIMIC-III, show that the proposed SparGE significantly outperforms other machine learning patient similarity methods. ",
    "url": "https://arxiv.org/abs/2202.01427",
    "authors": [
      "Xian Wei",
      "See Kiong Ng",
      "Tongtong Zhang",
      "Yingjie Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01440",
    "title": "Optimized Potential Initialization for Low-latency Spiking Neural  Networks",
    "abstract": "Spiking Neural Networks (SNNs) have been attached great importance due to the distinctive properties of low power consumption, biological plausibility, and adversarial robustness. The most effective way to train deep SNNs is through ANN-to-SNN conversion, which have yielded the best performance in deep network structure and large-scale datasets. However, there is a trade-off between accuracy and latency. In order to achieve high precision as original ANNs, a long simulation time is needed to match the firing rate of a spiking neuron with the activation value of an analog neuron, which impedes the practical application of SNN. In this paper, we aim to achieve high-performance converted SNNs with extremely low latency (fewer than 32 time-steps). We start by theoretically analyzing ANN-to-SNN conversion and show that scaling the thresholds does play a similar role as weight normalization. Instead of introducing constraints that facilitate ANN-to-SNN conversion at the cost of model capacity, we applied a more direct way by optimizing the initial membrane potential to reduce the conversion loss in each layer. Besides, we demonstrate that optimal initialization of membrane potentials can implement expected error-free ANN-to-SNN conversion. We evaluate our algorithm on the CIFAR-10, CIFAR-100 and ImageNet datasets and achieve state-of-the-art accuracy, using fewer time-steps. For example, we reach top-1 accuracy of 93.38\\% on CIFAR-10 with 16 time-steps. Moreover, our method can be applied to other ANN-SNN conversion methodologies and remarkably promote performance when the time-steps is small. ",
    "url": "https://arxiv.org/abs/2202.01440",
    "authors": [
      "Tong Bu",
      "Jianhao Ding",
      "Zhaofei Yu",
      "Tiejun Huang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01448",
    "title": "Deep Learning Algorithm for Threat Detection in Hackers Forum (Deep Web)",
    "abstract": "In our current society, the inter-connectivity of devices provides easy access for netizens to utilize cyberspace technology for illegal activities. The deep web platform is a consummative ecosystem shielded by boundaries of trust, information sharing, trade-off, and review systems. Domain knowledge is shared among experts in hacker's forums which contain indicators of compromise that can be explored for cyberthreat intelligence. Developing tools that can be deployed for threat detection is integral in securing digital communication in cyberspace. In this paper, we addressed the use of TOR relay nodes for anonymizing communications in deep web forums. We propose a novel approach for detecting cyberthreats using a deep learning algorithm Long Short-Term Memory (LSTM). The developed model outperformed the experimental results of other researchers in this problem domain with an accuracy of 94\\% and precision of 90\\%. Our model can be easily deployed by organizations in securing digital communications and detection of vulnerability exposure before cyberattack. ",
    "url": "https://arxiv.org/abs/2202.01448",
    "authors": [
      "Victor Adewopo",
      "Bilal Gonen",
      "Nelly Elsayed",
      "Murat Ozer",
      "Zaghloul Saad Elsayed"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01473",
    "title": "A multi-domain virtual network embedding algorithm with delay prediction",
    "abstract": "Virtual network embedding (VNE) is an crucial part of network virtualization (NV), which aims to map the virtual networks (VNs) to a shared substrate network (SN). With the emergence of various delay-sensitive applications, how to improve the delay performance of the system has become a hot topic in academic circles. Based on extensive research, we proposed a multi-domain virtual network embedding algorithm based on delay prediction (DP-VNE). Firstly, the candidate physical nodes are selected by estimating the delay of virtual requests, then particle swarm optimization (PSO) algorithm is used to optimize the mapping process, so as to reduce the delay of the system. The simulation results show that compared with the other three advanced algorithms, the proposed algorithm can significantly reduce the system delay while keeping other indicators unaffected. ",
    "url": "https://arxiv.org/abs/2202.01473",
    "authors": [
      "Peiying Zhang",
      "Xue Pang",
      "Yongjing Ni",
      "Haipeng Yao",
      "Xin Li"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.01478",
    "title": "Trajectory Forecasting from Detection with Uncertainty-Aware Motion  Encoding",
    "abstract": "Trajectory forecasting is critical for autonomous platforms to make safe planning and actions. Currently, most trajectory forecasting methods assume that object trajectories have been extracted and directly develop trajectory predictors based on the ground truth trajectories. However, this assumption does not hold in practical situations. Trajectories obtained from object detection and tracking are inevitably noisy, which could cause serious forecasting errors to predictors built on ground truth trajectories. In this paper, we propose a trajectory predictor directly based on detection results without relying on explicitly formed trajectories. Different from the traditional methods which encode the motion cue of an agent based on its clearly defined trajectory, we extract the motion information only based on the affinity cues among detection results, in which an affinity-aware state update mechanism is designed to take the uncertainty of association into account. In addition, considering that there could be multiple plausible matching candidates, we aggregate the states of them. This design relaxes the undesirable effect of noisy trajectory obtained from data association. Extensive ablation experiments validate the effectiveness of our method and its generalization ability on different detectors. Cross-comparison to other forecasting schemes further proves the superiority of our method. Code will be released upon acceptance. ",
    "url": "https://arxiv.org/abs/2202.01478",
    "authors": [
      "Pu Zhang",
      "Lei Bai",
      "Jianru Xue",
      "Jianwu Fang",
      "Nanning Zheng",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.01490",
    "title": "On the Utility of Marrying GIN and PMD for Improving Stack Overflow Code  Snippets",
    "abstract": "Software developers are increasingly dependent on question and answer portals and blogs for coding solutions. While such interfaces provide useful information, there are concerns that code hosted here is often incorrect, insecure or incomplete. Previous work indeed detected a range of faults in code provided on Stack Overflow through the use of static analysis. Static analysis may go a far way towards quickly establishing the health of software code available online. In addition, mechanisms that enable rapid automated program improvement may then enhance such code. Accordingly, we present this proof of concept. We use the PMD static analysis tool to detect performance faults for a sample of Stack Overflow Java code snippets, before performing mutations on these snippets using GIN. We then re-analyse the performance faults in these snippets after the GIN mutations. GIN's RandomSampler was used to perform 17,986 unique line and statement patches on 3,034 snippets where PMD violations were removed from 770 patched versions. Our outcomes indicate that static analysis techniques may be combined with automated program improvement methods to enhance publicly available code with very little resource requirements. We discuss our planned research agenda in this regard. ",
    "url": "https://arxiv.org/abs/2202.01490",
    "authors": [
      "Sherlock A. Licorish",
      "Markus Wagner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2202.01503",
    "title": "Global sensitivity analysis based on Gaussian-process metamodelling for  complex biomechanical problems",
    "abstract": "Biomechanical models often need to describe very complex systems, organs or diseases, and hence also include a large number of parameters. One of the attractive features of physics-based models is that in those models (most) parameters have a clear physical meaning. Nevertheless, the determination of these parameters is often very elaborate and costly and shows a large scatter within the population. Hence, it is essential to identify the most important parameter for a particular problem at hand. In order to distinguish parameters which have a significant influence on a specific model output from non-influential parameters, we use sensitivity analysis, in particular the Sobol method as a global variance-based method. However, the Sobol method requires a large number of model evaluations, which is prohibitive for computationally expensive models. We therefore employ Gaussian processes as a metamodel for the underlying full model. Metamodelling introduces further uncertainty, which we also quantify. We demonstrate the approach by applying it to two different problems: nanoparticle-mediated drug delivery in a multiphase tumour-growth model, and arterial growth and remodelling. Even relatively small numbers of evaluations of the full model suffice to identify the influential parameters in both cases and to separate them from non-influential parameters. The approach also allows the quantification of higher-order interaction effects. We thus show that a variance-based global sensitivity analysis is feasible for computationally expensive biomechanical models. Different aspects of sensitivity analysis are covered including a transparent declaration of the uncertainties involved in the estimation process. Such a global sensitivity analysis not only helps to massively reduce costs for experimental determination of parameters but is also highly beneficial for inverse analysis of such complex models. ",
    "url": "https://arxiv.org/abs/2202.01503",
    "authors": [
      "Barbara Wirthl",
      "Sebastian Brandstaeter",
      "Jonas Nitzler",
      "Bernhard A. Schrefler",
      "Wolfgang A. Wall"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2202.01507",
    "title": "Comparison of Intelligent Approaches for Cycle Time Prediction in  Injection Moulding of a Medical Device Product",
    "abstract": "Injection moulding is an increasingly automated industrial process, particularly when used for the production of high-value precision components such as polymeric medical devices. In such applications, achieving stringent product quality demands whilst also ensuring a highly efficient process can be challenging. Cycle time is one of the most critical factors which directly affects the throughput rate of the process and hence is a key indicator of process efficiency. In this work, we examine a production data set from a real industrial injection moulding process for manufacture of a high precision medical device. The relationship between the process input variables and the resulting cycle time is mapped with an artificial neural network (ANN) and an adaptive neuro-fuzzy system (ANFIS). The predictive performance of different training methods and neuron numbers in ANN and the impact of model type and the numbers of membership functions in ANFIS has been investigated. The strengths and limitations of the approaches are presented and the further research and development needed to ensure practical on-line use of these methods for dynamic process optimisation in the industrial process are discussed. ",
    "url": "https://arxiv.org/abs/2202.01507",
    "authors": [
      "Mandana Kariminejad",
      "David Tormey",
      "Saif Huq",
      "Jim Morrison",
      "Marion McAfee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.01525",
    "title": "Reliable Community Search in Dynamic Networks",
    "abstract": "Local community search is an important research topic to support complex network data analysis in various scenarios like social networks, collaboration networks, and cellular networks. The evolution of networks over time has motivated several recent studies to identify local communities from dynamic networks. However, they only utilized the aggregation of disjoint structural information to measure the quality of communities, which ignores the reliability of communities in a continuous time interval. To fill this research gap, we propose a novel $(\\theta,k)$-$core$ reliable community (CRC) model in the weighted dynamic networks, and define the problem of the most reliable community search that couples the desirable properties of connection strength, cohesive structure continuity, and the maximal member engagement. To solve this problem, we first develop an online CRC search algorithm by proposing a definition of eligible edge set and deriving the eligible edge set based pruning rules. % called the Eligible Edge Filtering-based CRC algorithm. After that, we devise a Weighted Core Forest-Index and index-based dynamic programming CRC search algorithm, which can prune a large number of insignificant intermediate results according to the maintained weight and structure information in the index, as well as the proposed upper bound properties. % our proposed pruning properties and upper bound properties. Finally, we conduct extensive experiments to verify the efficiency of our proposed algorithms and the effectiveness of our proposed community model on eight real datasets under different parameter settings. ",
    "url": "https://arxiv.org/abs/2202.01525",
    "authors": [
      "Yifu Tang",
      "Jianxin Li",
      "Nur Al Hasan Haldar",
      "Ziyu Guan",
      "Jiajie Xu",
      "Chengfei Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2202.01563",
    "title": "On the Number of Graphs with a Given Histogram",
    "abstract": "Let $G$ be a large (simple, unlabeled) dense graph on $n$ vertices. Suppose that we only know, or can estimate, the empirical distribution of the number of subgraphs $F$ that each vertex in $G$ participates in, for some fixed small graph $F$. How many other graphs would look essentially the same to us, i.e., would have a similar local structure? In this paper, we derive upper and lower bounds on the number graphs whose empirical distribution lies close (in the Kolmogorov-Smirnov distance) to that of $G$. Our bounds are given as solutions to a maximum entropy problem on random graphs of a fixed size $k$ that does not depend on $n$, under $d$ global density constraints. The bounds are asymptotically close, with a gap that vanishes with $d$ at a rate that depends on the concentration function of the center of the Kolmogorov-Smirnov ball. ",
    "url": "https://arxiv.org/abs/2202.01563",
    "authors": [
      "Shahar Stein Ioushua",
      "Ofer Shayevitz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.01600",
    "title": "Context-Based MEC Platform for Augmented-Reality Services in 5G Networks",
    "abstract": "Augmented reality (AR) has drawn great attention in recent years. However, current AR devices have drawbacks, e.g., weak computation ability and large power consumption. To solve the problem, mobile edge computing (MEC) can be introduced as a key technology to offload data and computation from AR devices to MEC servers via 5th Generation Mobile Communication Technology (5G) networks. To this end, a context-based MEC platform for AR services in 5G networks is proposed in this paper. On the platform, MEC is employed as a data processing center while AR devices are simplified as universal input/output devices, which overcomes their limitations and achieves better user experience. Moreover, the proof-of-concept (PoC) hardware prototype of the platform, and two typical use cases providing AR services of navigation and face recognition respectively are implemented to demonstrate the feasibility and effectiveness of the platform. Finally, the performance of the platform is also numerically evaluated, and the results validate the system design and agree well with the design expectations. ",
    "url": "https://arxiv.org/abs/2202.01600",
    "authors": [
      "Yue Wang",
      "Tao Yu",
      "Kei Sakaguchi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2202.01606",
    "title": "Graph Coloring with Physics-Inspired Graph Neural Networks",
    "abstract": "We show how graph neural networks can be used to solve the canonical graph coloring problem. We frame graph coloring as a multi-class node classification problem and utilize an unsupervised training strategy based on the statistical physics Potts model. Generalizations to other multi-class problems such as community detection, data clustering, and the minimum clique cover problem are straightforward. We provide numerical benchmark results and illustrate our approach with an end-to-end application for a real-world scheduling use case within a comprehensive encode-process-decode framework. Our optimization approach performs on par or outperforms existing solvers, with the ability to scale to problems with millions of variables. ",
    "url": "https://arxiv.org/abs/2202.01606",
    "authors": [
      "Martin J. A. Schuetz",
      "J. Kyle Brubaker",
      "Zhihuai Zhu",
      "Helmut G. Katzgraber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2202.01619",
    "title": "On Manifold Hypothesis: Hypersurface Submanifold Embedding Using  Osculating Hyperspheres",
    "abstract": "Consider a set of $n$ data points in the Euclidean space $\\mathbb{R}^d$. This set is called dataset in machine learning and data science. Manifold hypothesis states that the dataset lies on a low-dimensional submanifold with high probability. All dimensionality reduction and manifold learning methods have the assumption of manifold hypothesis. In this paper, we show that the dataset lies on an embedded hypersurface submanifold which is locally $(d-1)$-dimensional. Hence, we show that the manifold hypothesis holds at least for the embedding dimensionality $d-1$. Using an induction in a pyramid structure, we also extend the embedding dimensionality to lower embedding dimensionalities to show the validity of manifold hypothesis for embedding dimensionalities $\\{1, 2, \\dots, d-1\\}$. For embedding the hypersurface, we first construct the $d$ nearest neighbors graph for data. For every point, we fit an osculating hypersphere $S^{d-1}$ using its neighbors where this hypersphere is osculating to a hypothetical hypersurface. Then, using surgery theory, we apply surgery on the osculating hyperspheres to obtain $n$ hyper-caps. We connect the hyper-caps to one another using partial hyper-cylinders. By connecting all parts, the embedded hypersurface is obtained as the disjoint union of these elements. We discuss the geometrical characteristics of the embedded hypersurface, such as having boundary, its topology, smoothness, boundedness, orientability, compactness, and injectivity. Some discussion are also provided for the linearity and structure of data. This paper is the intersection of several fields of science including machine learning, differential geometry, and algebraic topology. ",
    "url": "https://arxiv.org/abs/2202.01619",
    "authors": [
      "Benyamin Ghojogh",
      "Fakhri Karray",
      "Mark Crowley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Differential Geometry (math.DG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.01627",
    "title": "Non-Vacuous Generalisation Bounds for Shallow Neural Networks",
    "abstract": "We focus on a specific class of shallow neural networks with a single hidden layer, namely those with $L_2$-normalised data and either a sigmoid-shaped Gaussian error function (\"erf\") activation or a Gaussian Error Linear Unit (GELU) activation. For these networks, we derive new generalisation bounds through the PAC-Bayesian theory; unlike most existing such bounds they apply to neural networks with deterministic rather than randomised parameters. Our bounds are empirically non-vacuous when the network is trained with vanilla stochastic gradient descent on MNIST and Fashion-MNIST. ",
    "url": "https://arxiv.org/abs/2202.01627",
    "authors": [
      "Felix Biggs",
      "Benjamin Guedj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.01646",
    "title": "Improving Lyrics Alignment through Joint Pitch Detection",
    "abstract": "In recent years, the accuracy of automatic lyrics alignment methods has increased considerably. Yet, many current approaches employ frameworks designed for automatic speech recognition (ASR) and do not exploit properties specific to music. Pitch is one important musical attribute of singing voice but it is often ignored by current systems as the lyrics content is considered independent of the pitch. In practice, however, there is a temporal correlation between the two as note starts often correlate with phoneme starts. At the same time the pitch is usually annotated with high temporal accuracy in ground truth data while the timing of lyrics is often only available at the line (or word) level. In this paper, we propose a multi-task learning approach for lyrics alignment that incorporates pitch and thus can make use of a new source of highly accurate temporal information. Our results show that the accuracy of the alignment result is indeed improved by our approach. As an additional contribution, we show that integrating boundary detection in the forced-alignment algorithm reduces cross-line errors, which improves the accuracy even further. ",
    "url": "https://arxiv.org/abs/2202.01646",
    "authors": [
      "Jiawen Huang",
      "Emmanouil Benetos",
      "Sebastian Ewert"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.01649",
    "title": "HECO: Automatic Code Optimizations for Efficient Fully Homomorphic  Encryption",
    "abstract": "In recent years, Fully Homomorphic Encryption (FHE) has undergone several breakthroughs and advancements leading to a leap in performance. Today, performance is no longer a major barrier to adoption. Instead, it is the complexity of developing an efficient FHE application that currently limits deploying FHE in practice and at scale. Several FHE compilers have emerged recently to ease FHE development. However, none of these answer how to automatically transform imperative programs to secure and efficient FHE implementations. This is a fundamental issue that needs to be addressed before we can realistically expect broader use of FHE. Automating these transformations is challenging because the restrictive set of operations in FHE and their non-intuitive performance characteristics require programs to be drastically transformed to achieve efficiency. In addition, existing tools are monolithic and focus on individual optimizations. Therefore, they fail to fully address the needs of end-to-end FHE development. In this paper, we present HECO, a new end-to-end design for FHE compilers that takes high-level imperative programs and emits efficient and secure FHE implementations. In our design, we take a broader view of FHE development, extending the scope of optimizations beyond the cryptographic challenges existing tools focus on. ",
    "url": "https://arxiv.org/abs/2202.01649",
    "authors": [
      "Alexander Viand",
      "Patrick Jattke",
      "Miro Haller",
      "Anwar Hithnawi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.01653",
    "title": "Learning strides in convolutional neural networks",
    "abstract": "Convolutional neural networks typically contain several downsampling operators, such as strided convolutions or pooling layers, that progressively reduce the resolution of intermediate representations. This provides some shift-invariance while reducing the computational complexity of the whole architecture. A critical hyperparameter of such layers is their stride: the integer factor of downsampling. As strides are not differentiable, finding the best configuration either requires cross-validation or discrete optimization (e.g. architecture search), which rapidly become prohibitive as the search space grows exponentially with the number of downsampling layers. Hence, exploring this search space by gradient descent would allow finding better configurations at a lower computational cost. This work introduces DiffStride, the first downsampling layer with learnable strides. Our layer learns the size of a cropping mask in the Fourier domain, that effectively performs resizing in a differentiable way. Experiments on audio and image classification show the generality and effectiveness of our solution: we use DiffStride as a drop-in replacement to standard downsampling layers and outperform them. In particular, we show that introducing our layer into a ResNet-18 architecture allows keeping consistent high performance on CIFAR10, CIFAR100 and ImageNet even when training starts from poor random stride configurations. Moreover, formulating strides as learnable variables allows us to introduce a regularization term that controls the computational complexity of the architecture. We show how this regularization allows trading off accuracy for efficiency on ImageNet. ",
    "url": "https://arxiv.org/abs/2202.01653",
    "authors": [
      "Rachid Riad",
      "Olivier Teboul",
      "David Grangier",
      "Neil Zeghidour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01672",
    "title": "SubOmiEmbed: Self-supervised Representation Learning of Multi-omics Data  for Cancer Type Classification",
    "abstract": "For personalized medicines, very crucial intrinsic information is present in high dimensional omics data which is difficult to capture due to the large number of molecular features and small number of available samples. Different types of omics data show various aspects of samples. Integration and analysis of multi-omics data give us a broad view of tumours, which can improve clinical decision making. Omics data, mainly DNA methylation and gene expression profiles are usually high dimensional data with a lot of molecular features. In recent years, variational autoencoders (VAE) have been extensively used in embedding image and text data into lower dimensional latent spaces. In our project, we extend the idea of using a VAE model for low dimensional latent space extraction with the self-supervised learning technique of feature subsetting. With VAEs, the key idea is to make the model learn meaningful representations from different types of omics data, which could then be used for downstream tasks such as cancer type classification. The main goals are to overcome the curse of dimensionality and integrate methylation and expression data to combine information about different aspects of same tissue samples, and hopefully extract biologically relevant features. Our extension involves training encoder and decoder to reconstruct the data from just a subset of it. By doing this, we force the model to encode most important information in the latent representation. We also added an identity to the subsets so that the model knows which subset is being fed into it during training and testing. We experimented with our approach and found that SubOmiEmbed produces comparable results to the baseline OmiEmbed with a much smaller network and by using just a subset of the data. This work can be improved to integrate mutation-based genomic data as well. ",
    "url": "https://arxiv.org/abs/2202.01672",
    "authors": [
      "Sayed Hashim",
      "Muhammad Ali",
      "Karthik Nandakumar",
      "Mohammad Yaqub"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2202.01678",
    "title": "Recognising the overlap graphs of subtrees of restricted trees is hard",
    "abstract": "The overlap graphs of subtrees in a tree (SOGs) generalise many other graphs classes with set representation characterisations. The complexity of recognising SOGs in open. The complexities of recognising many subclasses of SOGs are known. We consider several subclasses of SOGs by restricting the underlying tree. For a fixed integer $k \\geq 3$, we consider: \\begin{my_itemize} \\item The overlap graphs of subtrees in a tree where that tree has $k$ leaves \\item The overlap graphs of subtrees in trees that can be derived from a given input tree by subdivision and have at least 3 leaves \\item The overlap and intersection graphs of paths in a tree where that tree has maximum degree $k$ \\end{my_itemize} We show that the recognition problems of these classes are NP-complete. For all other parameters we get circle graphs, well known to be polynomially recognizable. ",
    "url": "https://arxiv.org/abs/2202.01678",
    "authors": [
      "Jessica Enright",
      "Martin Pergel"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2202.01690",
    "title": "Machine Learning and Artificial Intelligence in Next-Generation Wireless  Network",
    "abstract": "Due to the advancement in technologies, the next-generation wireless network will be very diverse, complicated, and according to the changed demands of the consumers. The current network operator methodologies and approaches are traditional and cannot help the next generation networks to utilize their resources most appropriately. The limited capability of the traditional tools will not allow the network providers to fulfill the demands of the network's subscribers in the future. Therefore, this paper will focus on machine learning, automation, artificial intelligence, and big data analytics for improving the capacity and effectiveness of next-generation wireless networks. The paper will discuss the role of these new technologies in improving the service and performance of the network providers in the future. The paper will find out that machine learning, big data analytics, and artificial intelligence will help in making the next-generation wireless network self-adaptive, self-aware, prescriptive, and proactive. At the end of the paper, it will be provided that future wireless network operators cannot work without shifting their operational framework to AI and machine learning technologies. ",
    "url": "https://arxiv.org/abs/2202.01690",
    "authors": [
      "Wafeeq Iqbal",
      "Wei Wang",
      "Ting Zhu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.01710",
    "title": "Multi-Output Physics-Informed Neural Networks for Forward and Inverse  PDE Problems with Uncertainties",
    "abstract": "Physics-informed neural networks (PINNs) have recently been used to solve various computational problems which are governed by partial differential equations (PDEs). In this paper, we propose a multi-output physics-informed neural network (MO-PINN) which can provide solutions with uncertainty distributions for both forward and inverse PDE problems with noisy data. In this framework, the uncertainty arising from the noisy data is first translated into multiple measurements regarding the prior noise distribution using the bootstrap method, and then the outputs of neural networks are designed to satisfy the measurements as well as the underlying physical laws.The posterior estimation of target parameters can be obtained at the end of training, which can be further used for uncertainty quantification and decision making. In this paper, MO-PINNs are demonstrated with a series of numerical experiments including both linear and nonlinear, forward and inverse problems. The results show that MO-PINN is able to provide accurate predictions with noisy data.In addition, we also demonstrate that the prediction and posterior distributions from MO-PINNs are consistent with the solutions from traditional a finite element method (FEM) solver and Monte Carlo methods given the same data and prior knowledge. Finally, we show that additional statistical knowledge can be incorporated into the training to improve the prediction if available. ",
    "url": "https://arxiv.org/abs/2202.01710",
    "authors": [
      "Mingyuan Yang",
      "John T. Foster"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2202.01721",
    "title": "Variance-Optimal Augmentation Logging for Counterfactual Evaluation in  Contextual Bandits",
    "abstract": "Methods for offline A/B testing and counterfactual learning are seeing rapid adoption in search and recommender systems, since they allow efficient reuse of existing log data. However, there are fundamental limits to using existing log data alone, since the counterfactual estimators that are commonly used in these methods can have large bias and large variance when the logging policy is very different from the target policy being evaluated. To overcome this limitation, we explore the question of how to design data-gathering policies that most effectively augment an existing dataset of bandit feedback with additional observations for both learning and evaluation. To this effect, this paper introduces Minimum Variance Augmentation Logging (MVAL), a method for constructing logging policies that minimize the variance of the downstream evaluation or learning problem. We explore multiple approaches to computing MVAL policies efficiently, and find that they can be substantially more effective in decreasing the variance of an estimator than na\\\"ive approaches. ",
    "url": "https://arxiv.org/abs/2202.01721",
    "authors": [
      "Aaron David Tucker",
      "Thorsten Joachims"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2202.01725",
    "title": "RipsNet: a general architecture for fast and robust estimation of the  persistent homology of point clouds",
    "abstract": "The use of topological descriptors in modern machine learning applications, such as Persistence Diagrams (PDs) arising from Topological Data Analysis (TDA), has shown great potential in various domains. However, their practical use in applications is often hindered by two major limitations: the computational complexity required to compute such descriptors exactly, and their sensitivity to even low-level proportions of outliers. In this work, we propose to bypass these two burdens in a data-driven setting by entrusting the estimation of (vectorization of) PDs built on top of point clouds to a neural network architecture that we call RipsNet. Once trained on a given data set, RipsNet can estimate topological descriptors on test data very efficiently with generalization capacity. Furthermore, we prove that RipsNet is robust to input perturbations in terms of the 1-Wasserstein distance, a major improvement over the standard computation of PDs that only enjoys Hausdorff stability, yielding RipsNet to substantially outperform exactly-computed PDs in noisy settings. We showcase the use of RipsNet on both synthetic and real-world data. Our open-source implementation is publicly available at https://github.com/hensel-f/ripsnet and will be included in the Gudhi library. ",
    "url": "https://arxiv.org/abs/2202.01725",
    "authors": [
      "Thibault de Surrel",
      "Felix Hensel",
      "Mathieu Carri\u00e8re",
      "Th\u00e9o Lacombe",
      "Yuichi Ike",
      "Hiroaki Kurihara",
      "Marc Glisse",
      "Fr\u00e9d\u00e9ric Chazal"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01727",
    "title": "Skeleton-Based Action Segmentation with Multi-Stage Spatial-Temporal  Graph Convolutional Neural Networks",
    "abstract": "The ability to identify and temporally segment fine-grained actions in motion capture sequences is crucial for applications in human movement analysis. Motion capture is typically performed with optical or inertial measurement systems, which encode human movement as a time series of human joint locations and orientations or their higher-order representations. State-of-the-art action segmentation approaches use multiple stages of temporal convolutions. The main idea is to generate an initial prediction with several layers of temporal convolutions and refine these predictions over multiple stages, also with temporal convolutions. Although these approaches capture long-term temporal patterns, the initial predictions do not adequately consider the spatial hierarchy among the human joints. To address this limitation, we present multi-stage spatial-temporal graph convolutional neural networks (MS-GCN). Our framework decouples the architecture of the initial prediction generation stage from the refinement stages. Specifically, we replace the initial stage of temporal convolutions with spatial-temporal graph convolutions, which better exploit the spatial configuration of the joints and their temporal dynamics. Our framework was compared to four strong baselines on five tasks. Experimental results demonstrate that our framework achieves state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2202.01727",
    "authors": [
      "Benjamin Filtjens",
      "Bart Vanrumste",
      "Peter Slaets"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.01746",
    "title": "Pivot Gray Codes for the Spanning Trees of a Graph ft. the Fan",
    "abstract": "We consider the problem of listing all spanning trees of a graph $G$ such that successive trees differ by pivoting a single edge around a vertex. Such a listing is called a \"pivot Gray code\", and it has more stringent conditions than known \"revolving-door\" Gray codes for spanning trees. Most revolving-door algorithms employ a standard edge-deletion/edge-contraction recursive approach which we demonstrate presents natural challenges when requiring the \"pivot\" property. Our main result is the discovery of a greedy strategy to list the spanning trees of the fan graph in a pivot Gray code order. It is the first greedy algorithm for exhaustively generating spanning trees using such a minimal change operation. The resulting listing is then studied to find a recursive algorithm that produces the same listing in $O(1)$-amortized time using $O(n)$ space. Additionally, we present $O(n)$-time algorithms for ranking and unranking the spanning trees for our listing; an improvement over the generic $O(n^3)$-time algorithm for ranking and unranking spanning trees of an arbitrary graph. Finally, we discuss how our listing can be applied to find a pivot Gray code for the wheel graph. ",
    "url": "https://arxiv.org/abs/2202.01746",
    "authors": [
      "Ben Cameron",
      "Aaron Grubb",
      "Joe Sawada"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2202.01758",
    "title": "PRUNIX: Non-Ideality Aware Convolutional Neural Network Pruning for  Memristive Accelerators",
    "abstract": "In this work, PRUNIX, a framework for training and pruning convolutional neural networks is proposed for deployment on memristor crossbar based accelerators. PRUNIX takes into account the numerous non-ideal effects of memristor crossbars including weight quantization, state-drift, aging and stuck-at-faults. PRUNIX utilises a novel Group Sawtooth Regularization intended to improve non-ideality tolerance as well as sparsity, and a novel Adaptive Pruning Algorithm (APA) intended to minimise accuracy loss by considering the sensitivity of different layers of a CNN to pruning. We compare our regularization and pruning methods with other standards on multiple CNN architectures, and observe an improvement of 13% test accuracy when quantization and other non-ideal effects are accounted for with an overall sparsity of 85%, which is similar to other methods ",
    "url": "https://arxiv.org/abs/2202.01758",
    "authors": [
      "Ali Alshaarawy",
      "Amirali Amirsoleimani",
      "Roman Genov"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01208",
    "title": "Deep Learning for Ultrasound Speed-of-Sound Reconstruction: Impacts of  Training Data Diversity on Stability and Robustness",
    "abstract": "Ultrasound b-mode imaging is a qualitative approach and diagnostic quality strongly depends on operators' training and experience. Quantitative approaches can provide information about tissue properties; therefore, can be used for identifying various tissue types, e.g., speed-of-sound in the tissue can be used as a biomarker for tissue malignancy, especially in breast imaging. Recent studies showed the possibility of speed-of-sound reconstruction using deep neural networks that are fully trained on simulated data. However, because of the ever present domain shift between simulated and measured data, the stability and performance of these models in real setups are still under debate. In this study, we investigated the impacts of training data diversity on the robustness of these networks by using multiple kinds of geometrical and natural simulated phantom structures. On the simulated data, we investigated the performance of the networks on out-of-domain echogenicity, geometries, and in the presence of noise. We further inspected the stability of employing such tissue modeling in a real data acquisition setup. We demonstrated that training the network with a joint set of datasets including both geometrical and natural tissue models improves the stability of the predicted speed-of-sound values both on simulated and measured data. ",
    "url": "https://arxiv.org/abs/2202.01208",
    "authors": [
      "Farnaz Khun Jush",
      "Markus Biele",
      "Peter M. Dueppenbecker",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.01210",
    "title": "Deep Layer-wise Networks Have Closed-Form Weights",
    "abstract": "There is currently a debate within the neuroscience community over the likelihood of the brain performing backpropagation (BP). To better mimic the brain, training a network \\textit{one layer at a time} with only a \"single forward pass\" has been proposed as an alternative to bypass BP; we refer to these networks as \"layer-wise\" networks. We continue the work on layer-wise networks by answering two outstanding questions. First, $\\textit{do they have a closed-form solution?}$ Second, $\\textit{how do we know when to stop adding more layers?}$ This work proves that the Kernel Mean Embedding is the closed-form weight that achieves the network global optimum while driving these networks to converge towards a highly desirable kernel for classification; we call it the $\\textit{Neural Indicator Kernel}$. ",
    "url": "https://arxiv.org/abs/2202.01210",
    "authors": [
      "Chieh Wu",
      "Aria Masoomi",
      "Arthur Gretton",
      "Jennifer Dy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2202.01274",
    "title": "Principled Graph Management",
    "abstract": "Graph Generation is a recently introduced enhanced Column Generation algorithm for solving expanded Linear Programming relaxations of mixed integer linear programs without weakening the expanded relaxations which characterize these methods. To apply Graph Generation we must be able to map any given column generated during pricing to a small directed acyclic graph for which any path from source to sink describes a feasible column. This structure is easily satisfied for vehicle routing, crew scheduling and various logistics problems where pricing is a constrained shortest path problem. The construction of such graphs trades off the size/diversity of a subset of columns modeled by the graphs versus the additional computational time required to solve the problems induced by larger graphs. Graph Generation (GG) has two computational bottlenecks. The first is pricing. Pricing in GG and Column Generation (CG) is identical because of the structure of the problems solved. The second bottleneck is the restricted master problem (RMP), which is more computationally intensive in GG than in CG given the same number of columns generated. By design GG converges in fewer iterations than CG, and hence requires fewer calls to pricing. Therefore, when the computation time of GG is dominated by pricing, as opposed to solving the RMP, GG converges much faster than CG in terms of time. However GG need not converge faster than CG when the GG RMP, rather than pricing, dominates computation. In this paper we introduce Principled Graph Management (PGM), which is an algorithm to solve the GG RMP rapidly by exploiting its special structure. We demonstrate the effectiveness of PGM inside a GG solution to the classical Capacitated Vehicle Routing Problem. We demonstrate that PGM solves the GG RMP hundreds of times faster than the baseline solver and that the improvement in speed increases with problem size. ",
    "url": "https://arxiv.org/abs/2202.01274",
    "authors": [
      "Julian Yarkony",
      "Amelia Regan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2202.01277",
    "title": "Global Optimization Networks",
    "abstract": "We consider the problem of estimating a good maximizer of a black-box function given noisy examples. To solve such problems, we propose to fit a new type of function which we call a global optimization network (GON), defined as any composition of an invertible function and a unimodal function, whose unique global maximizer can be inferred in $\\mathcal{O}(D)$ time. In this paper, we show how to construct invertible and unimodal functions by using linear inequality constraints on lattice models. We also extend to \\emph{conditional} GONs that find a global maximizer conditioned on specified inputs of other dimensions. Experiments show the GON maximizers are statistically significantly better predictions than those produced by convex fits, GPR, or DNNs, and are more reasonable predictions for real-world problems. ",
    "url": "https://arxiv.org/abs/2202.01277",
    "authors": [
      "Sen Zhao",
      "Erez Louidor",
      "Olexander Mangylov",
      "Maya Gupta"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01487",
    "title": "A benchmark of state-of-the-art sound event detection systems evaluated  on synthetic soundscapes",
    "abstract": "This paper proposes a benchmark of submissions to Detection and Classification Acoustic Scene and Events 2021 Challenge (DCASE) Task 4 representing a sampling of the state-of-the-art in Sound Event Detection task. The submissions are evaluated according to the two polyphonic sound detection score scenarios proposed for the DCASE 2021 Challenge Task 4, which allow to make an analysis on whether submissions are designed to perform fine-grained temporal segmentation, coarse-grained temporal segmentation, or have been designed to be polyvalent on the scenarios proposed. We study the solutions proposed by participants to analyze their robustness to varying level target to non-target signal-to-noise ratio and to temporal localization of target sound events. A last experiment is proposed in order to study the impact of non-target events on systems outputs. Results show that systems adapted to provide coarse segmentation outputs are more robust to different target to non-target signal-to-noise ratio and, with the help of specific data augmentation methods, they are more robust to time localization of the original event. Results of the last experiment display that systems tend to spuriously predict short events when non-target events are present. This is particularly true for systems that are tailored to have a fine segmentation. ",
    "url": "https://arxiv.org/abs/2202.01487",
    "authors": [
      "Francesca Ronchini",
      "Romain Serizel"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2202.01494",
    "title": "PARCEL: Physics-based unsupervised contrastive representation learning  for parallel MR imaging",
    "abstract": "With the successful application of deep learning in magnetic resonance imaging, parallel imaging techniques based on neural networks have attracted wide attentions. However, without high-quality fully sampled datasets for training, the performance of these methods tends to be limited. To address this issue, this paper proposes a physics based unsupervised contrastive representation learning (PARCEL) method to speed up parallel MR imaging. Specifically, PARCEL has three key ingredients to achieve direct deep learning from the undersampled k-space data. Namely, a parallel framework has been developed by learning two branches of model-based networks unrolled with the conjugate gradient algorithm; Augmented undersampled k-space data randomly drawn from the obtained k-space data are used to help the parallel network to capture the detailed information. A specially designed co-training loss is designed to guide the two networks to capture the inherent features and representations of the-to-be-reconstructed MR image. The proposed method has been evaluated on in vivo datasets and compared to five state-of-the-art methods, whose results show PARCEL is able to learn useful representations for more accurate MR reconstructions without the reliance on the fully-sampled datasets. ",
    "url": "https://arxiv.org/abs/2202.01494",
    "authors": [
      "Shanshan Wang",
      "Ruoyou Wu",
      "Cheng Li",
      "Juan Zou",
      "Hairong Zheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.01562",
    "title": "Doubly Robust Off-Policy Evaluation for Ranking Policies under the  Cascade Behavior Model",
    "abstract": "In real-world recommender systems and search engines, optimizing ranking decisions to present a ranked list of relevant items is critical. Off-policy evaluation (OPE) for ranking policies is thus gaining a growing interest because it enables performance estimation of new ranking policies using only logged data. Although OPE in contextual bandits has been studied extensively, its naive application to the ranking setting faces a critical variance issue due to the huge item space. To tackle this problem, previous studies introduce some assumptions on user behavior to make the combinatorial item space tractable. However, an unrealistic assumption may, in turn, cause serious bias. Therefore, appropriately controlling the bias-variance tradeoff by imposing a reasonable assumption is the key for success in OPE of ranking policies. To achieve a well-balanced bias-variance tradeoff, we propose the Cascade Doubly Robust estimator building on the cascade assumption, which assumes that a user interacts with items sequentially from the top position in a ranking. We show that the proposed estimator is unbiased in more cases compared to existing estimators that make stronger assumptions. Furthermore, compared to a previous estimator based on the same cascade assumption, the proposed estimator reduces the variance by leveraging a control variate. Comprehensive experiments on both synthetic and real-world data demonstrate that our estimator leads to more accurate OPE than existing estimators in a variety of settings. ",
    "url": "https://arxiv.org/abs/2202.01562",
    "authors": [
      "Haruka Kiyohara",
      "Yuta Saito",
      "Tatsuya Matsuhiro",
      "Yusuke Narita",
      "Nobuyuki Shimizu",
      "Yasuo Yamamoto"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01566",
    "title": "Unified theory of atom-centered representations and graph convolutional  machine-learning schemes",
    "abstract": "Data-driven schemes that associate molecular and crystal structures with their microscopic properties share the need for a concise, effective description of the arrangement of their atomic constituents. Many types of models rely on descriptions of atom-centered environments, that are associated with an atomic property or with an atomic contribution to an extensive macroscopic quantity. Frameworks in this class can be understood in terms of atom-centered density correlations (ACDC), that are used as a basis for a body-ordered, symmetry-adapted expansion of the targets. Several other schemes, that gather information on the relationship between neighboring atoms using graph-convolutional (or message-passing) ideas, cannot be directly mapped to correlations centered around a single atom. We generalize the ACDC framework to include multi-centered information, generating representations that provide a complete linear basis to regress symmetric functions of atomic coordinates, and form the basis to systematize our understanding of both atom-centered and graph-convolutional machine-learning schemes. ",
    "url": "https://arxiv.org/abs/2202.01566",
    "authors": [
      "Jigyasa Nigam",
      "Guillaume Fraux",
      "Michele Ceriotti"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2202.01630",
    "title": "A deep complex network with multi-frame filtering for stereophonic  acoustic echo cancellation",
    "abstract": "In hands-free communication system, the coupling between the loudspeaker and the microphone will generate echo signal, which can severely impair the quality of communication. Meanwhile, various types of noise in the communication environment further destroy the speech quality and intelligibility. It is hard to extract the near-end signal from the microphone input signal within one step, especially in low signal-to-noise ratios. In this paper, we propose a multi-stage approach to address this issue. On the one hand, we decompose the echo cancellation into two stages, including linear echo cancellation module and residual echo suppression module. A multi-frame filtering strategy is introduced to benefit estimating linear echo by utilizing more inter-frame information. On the other hand, we decouple the complex spectral mapping into magnitude estimation and complex spectra refine. Experimental results demonstrate that our proposed approach achieves stage-of-the-art performance over previous advanced algorithms under various conditions. ",
    "url": "https://arxiv.org/abs/2202.01630",
    "authors": [
      "Linjuan Cheng",
      "Chengshi Zheng",
      "Andong Li",
      "Renhua Peng",
      "Xiaodong Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2202.01636",
    "title": "On constant-time quantum annealing and guaranteed approximations for  graph optimization problems",
    "abstract": "Quantum Annealing (QA) is a computational framework where a quantum system's continuous evolution is used to find the global minimum of an objective function over an unstructured search space. It can be seen as a general metaheuristic for optimization problems, including NP-hard ones if we allow an exponentially large running time. While QA is widely studied from a heuristic point of view, little is known about theoretical guarantees on the quality of the solutions obtained in polynomial time. In this paper we use a technique borrowed from theoretical physics, the Lieb-Robinson (LR) bound, and develop new tools proving that short, constant time quantum annealing guarantees constant factor approximations ratios for some optimization problems when restricted to bounded degree graphs. Informally, on bounded degree graphs the LR bound allows us to retrieve a (relaxed) locality argument, through which the approximation ratio can be deduced by studying subgraphs of bounded radius. We illustrate our tools on problems MaxCut and Maximum Independent Set for cubic graphs, providing explicit approximation ratios and the runtimes needed to obtain them. Our results are of similar flavor to the well-known ones obtained in the different but related QAOA (quantum optimization algorithms) framework. Eventually, we discuss theoretical and experimental arguments for further improvements. ",
    "url": "https://arxiv.org/abs/2202.01636",
    "authors": [
      "Arthur Braida",
      "Simon Martiel",
      "Ioan Todinca"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2202.01664",
    "title": "Removing Distortion Effects in Music Using Deep Neural Networks",
    "abstract": "Audio effects are an essential element in the context of music production, and therefore, modeling analog audio effects has been extensively researched for decades using system-identification methods, circuit simulation, and recently, deep learning. However, only few works tackled the reconstruction of signals that were processed using an audio effect unit. Given the recent advances in music source separation and automatic mixing, the removal of audio effects could facilitate an automatic remixing system. This paper focuses on removing distortion and clipping applied to guitar tracks for music production while presenting a comparative investigation of different deep neural network (DNN) architectures on this task. We achieve exceptionally good results in distortion removal using DNNs for effects that superimpose the clean signal to the distorted signal, while the task is more challenging if the clean signal is not superimposed. Nevertheless, in the latter case, the neural models under evaluation surpass one state-of-the-art declipping system in terms of source-to-distortion ratio, leading to better quality and faster inference. ",
    "url": "https://arxiv.org/abs/2202.01664",
    "authors": [
      "Johannes Imort",
      "Giorgio Fabbro",
      "Marco A. Mart\u00ednez Ram\u00edrez",
      "Stefan Uhlich",
      "Yuichiro Koyama",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2202.01723",
    "title": "Systems Biology: Identifiability analysis and parameter identification  via systems-biology informed neural networks",
    "abstract": "The dynamics of systems biological processes are usually modeled by a system of ordinary differential equations (ODEs) with many unknown parameters that need to be inferred from noisy and sparse measurements. Here, we introduce systems-biology informed neural networks for parameter estimation by incorporating the system of ODEs into the neural networks. To complete the workflow of system identification, we also describe structural and practical identifiability analysis to analyze the identifiability of parameters. We use the ultridian endocrine model for glucose-insulin interaction as the example to demonstrate all these methods and their implementation. ",
    "url": "https://arxiv.org/abs/2202.01723",
    "authors": [
      "Mitchell Daneker",
      "Zhen Zhang",
      "George Em Karniadakis",
      "Lu Lu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2006.07082",
    "title": "Resource dependency and survivability in complex networks",
    "abstract": " Comments: 8 pages, 9 figures. Code is freely available at this https URL ",
    "url": "https://arxiv.org/abs/2006.07082",
    "authors": [
      "Madhusudan Ingale",
      "Snehal M. Shekatkar"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2008.03626",
    "title": "Directed hypergraph neural network",
    "abstract": " Comments: There are some errors in the experiments. I will re-submit it later ",
    "url": "https://arxiv.org/abs/2008.03626",
    "authors": [
      "Loc Hoang Tran",
      "Linh Hoang Tran"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2008.08733",
    "title": "Optimal Network Compression",
    "abstract": " Comments: 32 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2008.08733",
    "authors": [
      "Hamed Amini",
      "Zachary Feinstein"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2009.09205",
    "title": "Adversarial Rain Attack and Defensive Deraining for DNN Perception",
    "abstract": " Title: Adversarial Rain Attack and Defensive Deraining for DNN Perception ",
    "url": "https://arxiv.org/abs/2009.09205",
    "authors": [
      "Liming Zhai",
      "Felix Juefei-Xu",
      "Qing Guo",
      "Xiaofei Xie",
      "Lei Ma",
      "Wei Feng",
      "Shengchao Qin",
      "Yang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2010.03393",
    "title": "Complexity of the list homomorphism problem in hereditary graph classes",
    "abstract": " Title: Complexity of the list homomorphism problem in hereditary graph classes ",
    "url": "https://arxiv.org/abs/2010.03393",
    "authors": [
      "Karolina Okrasa",
      "Pawe\u0142 Rz\u0105\u017cewski"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2102.01934",
    "title": "Noise-robust classification with hypergraph neural network",
    "abstract": " Comments: There are some errors in the experiments. I will re-submit it later ",
    "url": "https://arxiv.org/abs/2102.01934",
    "authors": [
      "Nguyen Trinh Vu Dang",
      "Loc Tran",
      "Linh Tran"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2102.02705",
    "title": "EFloat: Entropy-coded Floating Point Format for Compressing Vector  Embedding Models",
    "abstract": " Title: EFloat: Entropy-coded Floating Point Format for Compressing Vector  Embedding Models ",
    "url": "https://arxiv.org/abs/2102.02705",
    "authors": [
      "Rajesh Bordawekar",
      "Bulent Abali",
      "Ming-Hung Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2102.07389",
    "title": "And/or trade-off in artificial neurons: impact on adversarial robustness",
    "abstract": " Title: And/or trade-off in artificial neurons: impact on adversarial robustness ",
    "url": "https://arxiv.org/abs/2102.07389",
    "authors": [
      "Alessandro Fontana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2102.07869",
    "title": "Technical Report -- Expected Exploitability: Predicting the Development  of Functional Vulnerability Exploits",
    "abstract": " Title: Technical Report -- Expected Exploitability: Predicting the Development  of Functional Vulnerability Exploits ",
    "url": "https://arxiv.org/abs/2102.07869",
    "authors": [
      "Octavian Suciu",
      "Connor Nelson",
      "Zhuoer Lyu",
      "Tiffany Bao",
      "Tudor Dumitras"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2103.01710",
    "title": "Autobahn: Automorphism-based Graph Neural Nets",
    "abstract": " Comments: 10 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2103.01710",
    "authors": [
      "Erik Henning Thiede",
      "Wenda Zhou",
      "Risi Kondor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.07853",
    "title": "Membership Inference Attacks on Machine Learning: A Survey",
    "abstract": " Comments: Accepted by ACM Computing Surveys ",
    "url": "https://arxiv.org/abs/2103.07853",
    "authors": [
      "Hongsheng Hu",
      "Zoran Salcic",
      "Lichao Sun",
      "Gillian Dobbie",
      "Philip S. Yu",
      "Xuyun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2103.15449",
    "title": "Automated freezing of gait assessment with marker-based motion capture  and multi-stage spatial-temporal graph convolutional neural networks",
    "abstract": " Title: Automated freezing of gait assessment with marker-based motion capture  and multi-stage spatial-temporal graph convolutional neural networks ",
    "url": "https://arxiv.org/abs/2103.15449",
    "authors": [
      "Benjamin Filtjens",
      "Pieter Ginis",
      "Alice Nieuwboer",
      "Peter Slaets",
      "Bart Vanrumste"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2103.16440",
    "title": "Neural Transformation Learning for Deep Anomaly Detection Beyond Images",
    "abstract": " Title: Neural Transformation Learning for Deep Anomaly Detection Beyond Images ",
    "url": "https://arxiv.org/abs/2103.16440",
    "authors": [
      "Chen Qiu",
      "Timo Pfrommer",
      "Marius Kloft",
      "Stephan Mandt",
      "Maja Rudolph"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2105.02103",
    "title": "Prototype Memory for Large-scale Face Representation Learning",
    "abstract": " Title: Prototype Memory for Large-scale Face Representation Learning ",
    "url": "https://arxiv.org/abs/2105.02103",
    "authors": [
      "Evgeny Smirnov",
      "Nikita Garaev",
      "Vasiliy Galyuk",
      "Evgeny Lukyanets"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.02522",
    "title": "Neural graphical modelling in continuous-time: consistency guarantees  and algorithms",
    "abstract": " Title: Neural graphical modelling in continuous-time: consistency guarantees  and algorithms ",
    "url": "https://arxiv.org/abs/2105.02522",
    "authors": [
      "Alexis Bellot",
      "Kim Branson",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2105.14933",
    "title": "The use of Generative Adversarial Networks to characterise new physics  in multi-lepton final states at the LHC",
    "abstract": " Comments: 18 pages, 5 figures, 1 table, journal (JHEP) ",
    "url": "https://arxiv.org/abs/2105.14933",
    "authors": [
      "Thabang Lebese",
      "Xifeng Ruan"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2106.03186",
    "title": "Reverse Engineering the Neural Tangent Kernel",
    "abstract": " Comments: 13 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2106.03186",
    "authors": [
      "James B. Simon",
      "Sajant Anand",
      "Michael R. DeWeese"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.10466",
    "title": "TS2Vec: Towards Universal Representation of Time Series",
    "abstract": " Comments: Appears in AAAI-2022 ",
    "url": "https://arxiv.org/abs/2106.10466",
    "authors": [
      "Zhihan Yue",
      "Yujing Wang",
      "Juanyong Duan",
      "Tianmeng Yang",
      "Congrui Huang",
      "Yunhai Tong",
      "Bixiong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.10771",
    "title": "Multirate Training of Neural Networks",
    "abstract": " Title: Multirate Training of Neural Networks ",
    "url": "https://arxiv.org/abs/2106.10771",
    "authors": [
      "Tiffany Vlaar",
      "Benedict Leimkuhler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.16004",
    "title": "What can linear interpolation of neural network loss landscapes tell us?",
    "abstract": " Title: What can linear interpolation of neural network loss landscapes tell us? ",
    "url": "https://arxiv.org/abs/2106.16004",
    "authors": [
      "Tiffany Vlaar",
      "Jonathan Frankle"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.03311",
    "title": "RoFL: Attestable Robustness for Secure Federated Learning",
    "abstract": " Comments: 21 pages, 21 figures ",
    "url": "https://arxiv.org/abs/2107.03311",
    "authors": [
      "Lukas Burkhalter",
      "Hidde Lycklama",
      "Alexander Viand",
      "Nicolas K\u00fcchler",
      "Anwar Hithnawi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.07056",
    "title": "Learning Sparse Interaction Graphs of Partially Detected Pedestrians for  Trajectory Prediction",
    "abstract": " Comments: 8 pages, 6 figures, Accepted by RA-L with ICRA 2022 presentation option ",
    "url": "https://arxiv.org/abs/2107.07056",
    "authors": [
      "Zhe Huang",
      "Ruohua Li",
      "Kazuki Shin",
      "Katherine Driggs-Campbell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.07699",
    "title": "A Comparative Study of Deep Learning Classification Methods on a Small  Environmental Microorganism Image Dataset (EMDS-6): from Convolutional Neural  Networks to Visual Transformers",
    "abstract": " Title: A Comparative Study of Deep Learning Classification Methods on a Small  Environmental Microorganism Image Dataset (EMDS-6): from Convolutional Neural  Networks to Visual Transformers ",
    "url": "https://arxiv.org/abs/2107.07699",
    "authors": [
      "Peng Zhao",
      "Chen Li",
      "Md Mamunur Rahaman",
      "Hao Xu",
      "Hechen Yang",
      "Hongzan Sun",
      "Tao Jiang",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.02234",
    "title": "Multi-Branch with Attention Network for Hand-Based Person Recognition",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2101.05260 ",
    "url": "https://arxiv.org/abs/2108.02234",
    "authors": [
      "Nathanael L. Baisa",
      "Bryan Williams",
      "Hossein Rahmani",
      "Plamen Angelov",
      "Sue Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.08230",
    "title": "Predicting Dynamic Stability of Power Grids using Graph Neural Networks",
    "abstract": " Comments: 8 pages, 13 pages including appendix, 31 pictures plus tikz pictures ",
    "url": "https://arxiv.org/abs/2108.08230",
    "authors": [
      "Christian Nauck",
      "Michael Lindner",
      "Konstantin Sch\u00fcrholt",
      "Haoming Zhang",
      "Paul Schultz",
      "J\u00fcrgen Kurths",
      "Ingrid Isenhardt",
      "Frank Hellmann"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2109.01262",
    "title": "On the Accuracy of Analog Neural Network Inference Accelerators",
    "abstract": " Comments: Changes in v3: modified definition of state-independent error (factor of 2) for fairer comparison to state-proportional. Added more results on INT4 network ",
    "url": "https://arxiv.org/abs/2109.01262",
    "authors": [
      "T. Patrick Xiao",
      "Ben Feinberg",
      "Christopher H. Bennett",
      "Venkatraman Prabhakar",
      "Prashant Saxena",
      "Vineet Agrawal",
      "Sapan Agarwal",
      "Matthew J. Marinella"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.05759",
    "title": "Global-Local Dynamic Feature Alignment Network for Person  Re-Identification",
    "abstract": " Comments: 28 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2109.05759",
    "authors": [
      "Zhangqiang Ming",
      "Yong Yang",
      "Xiaoyong Wei",
      "Jianrong Yan",
      "Xiangkun Wang",
      "Fengjie Wang",
      "Min Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.06715",
    "title": "IGNNITION: Bridging the Gap Between Graph Neural Networks and Networking  Systems",
    "abstract": " Title: IGNNITION: Bridging the Gap Between Graph Neural Networks and Networking  Systems ",
    "url": "https://arxiv.org/abs/2109.06715",
    "authors": [
      "David Pujol-Perich",
      "Jos\u00e9 Su\u00e1rez-Varela",
      "Miquel Ferriol",
      "Shihan Xiao",
      "Bo Wu",
      "Albert Cabellos-Aparicio",
      "Pere Barlet-Ros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2109.07744",
    "title": "Disaggregating and Consolidating Network Functionalities with SuperNIC",
    "abstract": " Comments: 17 pages, 22 figures ",
    "url": "https://arxiv.org/abs/2109.07744",
    "authors": [
      "Yizhou Shan",
      "Will Lin",
      "Ryan Kosta",
      "Arvind Krishnamurthy",
      "Yiying Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2110.02375",
    "title": "Interpreting intermediate convolutional layers in unsupervised acoustic  word classification",
    "abstract": " Comments: ICASSP 2022 ",
    "url": "https://arxiv.org/abs/2110.02375",
    "authors": [
      "Ga\u0161per Begu\u0161",
      "Alan Zhou"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2110.02798",
    "title": "Dynamics of hot random hyperbolic graphs",
    "abstract": " Title: Dynamics of hot random hyperbolic graphs ",
    "url": "https://arxiv.org/abs/2110.02798",
    "authors": [
      "Fragkiskos Papadopoulos",
      "Sofoclis Zambirinis"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2110.06765",
    "title": "libdlr: Efficient imaginary time calculations using the discrete Lehmann  representation",
    "abstract": " Title: libdlr: Efficient imaginary time calculations using the discrete Lehmann  representation ",
    "url": "https://arxiv.org/abs/2110.06765",
    "authors": [
      "Jason Kaye",
      "Kun Chen",
      "Hugo U. R. Strand"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Mathematical Software (cs.MS)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2110.07570",
    "title": "MGC: A Complex-Valued Graph Convolutional Network for Directed Graphs",
    "abstract": " Comments: 11 pages, 4 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2110.07570",
    "authors": [
      "Jie Zhang",
      "Bo Hui",
      "Po-Wei Harn",
      "Min-Te Sun",
      "Wei-Shinn Ku"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2110.07683",
    "title": "Toward Realistic Backdoor Injection Attacks on DNNs using Rowhammer",
    "abstract": " Title: Toward Realistic Backdoor Injection Attacks on DNNs using Rowhammer ",
    "url": "https://arxiv.org/abs/2110.07683",
    "authors": [
      "M. Caner Tol",
      "Saad Islam",
      "Berk Sunar",
      "Ziming Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2110.09348",
    "title": "Understanding Dimensional Collapse in Contrastive Self-supervised  Learning",
    "abstract": " Comments: In Proceedings of the 10th International Conference on Learning Representations (ICLR) 2022 ",
    "url": "https://arxiv.org/abs/2110.09348",
    "authors": [
      "Li Jing",
      "Pascal Vincent",
      "Yann LeCun",
      "Yuandong Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.13970",
    "title": "Rademacher Random Projections with Tensor Networks",
    "abstract": " Title: Rademacher Random Projections with Tensor Networks ",
    "url": "https://arxiv.org/abs/2110.13970",
    "authors": [
      "Beheshteh T. Rakhshan",
      "Guillaume Rabusseau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.14068",
    "title": "Drawing Robust Scratch Tickets: Subnetworks with Inborn Robustness Are  Found within Randomly Initialized Networks",
    "abstract": " Comments: Accepted at NeurIPS 2021 ",
    "url": "https://arxiv.org/abs/2110.14068",
    "authors": [
      "Yonggan Fu",
      "Qixuan Yu",
      "Yang Zhang",
      "Shang Wu",
      "Xu Ouyang",
      "David Cox",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.12281",
    "title": "Locality-based Graph Reordering for Processing Speed-Ups and Impact of  Diameter",
    "abstract": " Comments: 20 pages. Bachelor's thesis ",
    "url": "https://arxiv.org/abs/2111.12281",
    "authors": [
      "Vedant Satav"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2111.15208",
    "title": "HRNET: AI on Edge for mask detection and social distancing",
    "abstract": " Title: HRNET: AI on Edge for mask detection and social distancing ",
    "url": "https://arxiv.org/abs/2111.15208",
    "authors": [
      "Kinshuk Sengupta",
      "Praveen Ranjan Srivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.15379",
    "title": "Text classification problems via BERT embedding method and graph  convolutional neural network",
    "abstract": " Comments: There are some errors in the experiments. I will re-submit it later ",
    "url": "https://arxiv.org/abs/2111.15379",
    "authors": [
      "Loc Hoang Tran",
      "Tuan Tran",
      "An Mai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.05290",
    "title": "Image-to-Image Translation-based Data Augmentation for Robust EV  Charging Inlet Detection",
    "abstract": " Comments: 8 pages ",
    "url": "https://arxiv.org/abs/2112.05290",
    "authors": [
      "Yeonjun Bang",
      "Yeejin Lee",
      "Byeongkeun Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.05677",
    "title": "Concept Representation Learning with Contrastive Self-Supervised  Learning",
    "abstract": " Title: Concept Representation Learning with Contrastive Self-Supervised  Learning ",
    "url": "https://arxiv.org/abs/2112.05677",
    "authors": [
      "Daniel T. Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.09071",
    "title": "A Deep Learning Based Multitask Network for Respiration Rate Estimation  -- A Practical Perspective",
    "abstract": " Comments: Preprint Only ",
    "url": "https://arxiv.org/abs/2112.09071",
    "authors": [
      "Kapil Singh Rathore",
      "Sricharan Vijayarangan",
      "Preejith SP",
      "Mohanasankar Sivaprakasam"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.12376",
    "title": "Revisiting and Advancing Fast Adversarial Training Through The Lens of  Bi-Level Optimization",
    "abstract": " Title: Revisiting and Advancing Fast Adversarial Training Through The Lens of  Bi-Level Optimization ",
    "url": "https://arxiv.org/abs/2112.12376",
    "authors": [
      "Yihua Zhang",
      "Guanhua Zhang",
      "Prashant Khanduri",
      "Mingyi Hong",
      "Shiyu Chang",
      "Sijia Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.00001",
    "title": "Modeling Advection on Directed Graphs using Mat\u00e9rn Gaussian Processes  for Traffic Flow",
    "abstract": " Comments: Accepted at the Machine Learning and Physical Sciences NeurIPS 2021 Workshop this https URL ",
    "url": "https://arxiv.org/abs/2201.00001",
    "authors": [
      "Danielle C Maddix",
      "Nadim Saad",
      "Yuyang Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.11650",
    "title": "Incremental Mining of Frequent Serial Episodes Considering Multiple  Occurrence",
    "abstract": " Title: Incremental Mining of Frequent Serial Episodes Considering Multiple  Occurrence ",
    "url": "https://arxiv.org/abs/2201.11650",
    "authors": [
      "Thomas Guyet",
      "Wenbin Zhang",
      "Albert Bifet"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.11670",
    "title": "Strong Converse Theorem for Source Encryption under Side-Channel Attacks",
    "abstract": " Comments: 9 pages, 6 figures. arXiv admin note: text overlap with arXiv:1801.02563 ",
    "url": "https://arxiv.org/abs/2201.11670",
    "authors": [
      "Yasutada Oohama",
      "Bagus Santoso"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.12674",
    "title": "Rewiring with Positional Encodings for Graph Neural Networks",
    "abstract": " Title: Rewiring with Positional Encodings for Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2201.12674",
    "authors": [
      "Rickard Br\u00fcel-Gabrielsson",
      "Mikhail Yurochkin",
      "Justin Solomon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.13402",
    "title": "Privacy Limitations Of Interest-based Advertising On The Web: A  Post-mortem Empirical Analysis Of Google's FLoC",
    "abstract": " Title: Privacy Limitations Of Interest-based Advertising On The Web: A  Post-mortem Empirical Analysis Of Google's FLoC ",
    "url": "https://arxiv.org/abs/2201.13402",
    "authors": [
      "Alex Berke",
      "Dan Calacci"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2202.00063",
    "title": "Efficient Reinforcement Learning in Block MDPs: A Model-free  Representation Learning Approach",
    "abstract": " Title: Efficient Reinforcement Learning in Block MDPs: A Model-free  Representation Learning Approach ",
    "url": "https://arxiv.org/abs/2202.00063",
    "authors": [
      "Xuezhou Zhang",
      "Yuda Song",
      "Masatoshi Uehara",
      "Mengdi Wang",
      "Alekh Agarwal",
      "Wen Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.00448",
    "title": "Sim2Real Object-Centric Keypoint Detection and Description",
    "abstract": " Comments: accepted to AAAI2022 ",
    "url": "https://arxiv.org/abs/2202.00448",
    "authors": [
      "Chengliang Zhong",
      "Chao Yang",
      "Jinshan Qi",
      "Fuchun Sun",
      "Huaping Liu",
      "Xiaodong Mu",
      "Wenbing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.00834",
    "title": "Algorithms for Efficiently Learning Low-Rank Neural Networks",
    "abstract": " Comments: 52 pages, 4 figures, in submission ",
    "url": "https://arxiv.org/abs/2202.00834",
    "authors": [
      "Kiran Vodrahalli",
      "Rakesh Shivanna",
      "Maheswaran Sathiamoorthy",
      "Sagar Jain",
      "Ed H. Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  }
]