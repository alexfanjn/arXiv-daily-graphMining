[
  {
    "id": "arXiv:2202.07006",
    "title": "A Survey of Visual Sensory Anomaly Detection",
    "abstract": "Visual sensory anomaly detection (AD) is an essential problem in computer vision, which is gaining momentum recently thanks to the development of AI for good. Compared with semantic anomaly detection which detects anomaly at the label level (semantic shift), visual sensory AD detects the abnormal part of the sample (covariate shift). However, no thorough review has been provided to summarize this area for the computer vision community. In this survey, we are the first one to provide a comprehensive review of visual sensory AD and category into three levels according to the form of anomalies. Furthermore, we classify each kind of anomaly according to the level of supervision. Finally, we summarize the challenges and provide open directions for this community. All resources are available at https://github.com/M-3LAB/awesome-visual-sensory-anomaly-detection. ",
    "url": "https://arxiv.org/abs/2202.07006",
    "authors": [
      "Xi Jiang",
      "Guoyang Xie",
      "Jinbao Wang",
      "Yong Liu",
      "Chengjie Wang",
      "Feng Zheng",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07013",
    "title": "Robust Policy Learning over Multiple Uncertainty Sets",
    "abstract": "Reinforcement learning (RL) agents need to be robust to variations in safety-critical environments. While system identification methods provide a way to infer the variation from online experience, they can fail in settings where fast identification is not possible. Another dominant approach is robust RL which produces a policy that can handle worst-case scenarios, but these methods are generally designed to achieve robustness to a single uncertainty set that must be specified at train time. Towards a more general solution, we formulate the multi-set robustness problem to learn a policy robust to different perturbation sets. We then design an algorithm that enjoys the benefits of both system identification and robust RL: it reduces uncertainty where possible given a few interactions, but can still act robustly with respect to the remaining uncertainty. On a diverse set of control tasks, our approach demonstrates improved worst-case performance on new environments compared to prior methods based on system identification and on robust RL alone. ",
    "url": "https://arxiv.org/abs/2202.07013",
    "authors": [
      "Annie Xie",
      "Shagun Sodhani",
      "Chelsea Finn",
      "Joelle Pineau",
      "Amy Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.07014",
    "title": "Strategy Discovery and Mixture in Lifelong Learning from Heterogeneous  Demonstration",
    "abstract": "Learning from Demonstration (LfD) approaches empower end-users to teach robots novel tasks via demonstrations of the desired behaviors, democratizing access to robotics. A key challenge in LfD research is that users tend to provide heterogeneous demonstrations for the same task due to various strategies and preferences. Therefore, it is essential to develop LfD algorithms that ensure \\textit{flexibility} (the robot adapts to personalized strategies), \\textit{efficiency} (the robot achieves sample-efficient adaptation), and \\textit{scalability} (robot reuses a concise set of strategies to represent a large amount of behaviors). In this paper, we propose a novel algorithm, Dynamic Multi-Strategy Reward Distillation (DMSRD), which distills common knowledge between heterogeneous demonstrations, leverages learned strategies to construct mixture policies, and continues to improve by learning from all available data. Our personalized, federated, and lifelong LfD architecture surpasses benchmarks in two continuous control problems with an average 77\\% improvement in policy returns and 42\\% improvement in log likelihood, alongside stronger task reward correlation and more precise strategy rewards. ",
    "url": "https://arxiv.org/abs/2202.07014",
    "authors": [
      "Sravan Jayanthi",
      "Letian Chen",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07025",
    "title": "Box Supervised Video Segmentation Proposal Network",
    "abstract": "Video Object Segmentation (VOS) has been targeted by various fully-supervised and self-supervised approaches. While fully-supervised methods demonstrate excellent results, self-supervised ones, which do not use pixel-level ground truth, attract much attention. However, self-supervised approaches pose a significant performance gap. Box-level annotations provide a balanced compromise between labeling effort and result quality for image segmentation but have not been exploited for the video domain. In this work, we propose a box-supervised video object segmentation proposal network, which takes advantage of intrinsic video properties. Our method incorporates object motion in the following way: first, motion is computed using a bidirectional temporal difference and a novel bounding box-guided motion compensation. Second, we introduce a novel motion-aware affinity loss that encourages the network to predict positive pixel pairs if they share similar motion and color. The proposed method outperforms the state-of-the-art self-supervised benchmark by 16.4% and 6.9% $\\mathcal{J}$ &$\\mathcal{F}$ score and the majority of fully supervised methods on the DAVIS and Youtube-VOS dataset without imposing network architectural specifications. We provide extensive tests and ablations on the datasets, demonstrating the robustness of our method. ",
    "url": "https://arxiv.org/abs/2202.07025",
    "authors": [
      "Tanveer Hannan",
      "Rajat Koner",
      "Jonathan Kobold",
      "Matthias Schubert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07026",
    "title": "Analysis of Neural Fragility: Bounding the Norm of a Rank-One  Perturbation Matrix",
    "abstract": "Over 15 million epilepsy patients worldwide do not respond to drugs and require surgical treatment. Successful surgical treatment requires complete removal, or disconnection of the epileptogenic zone (EZ), but without a prospective biomarker of the EZ, surgical success rates vary between 30%-70%. Neural fragility is a model recently proposed to localize the EZ. Neural fragility is computed as the l2 norm of a structured rank-one perturbation of an estimated linear dynamical system. However, an analysis of its numerical properties have not been explored. We show that neural fragility is a well-defined model given a good estimator of the linear dynamical system from data. Specifically, we provide bounds on neural fragility as a function of the underlying linear system and noise. ",
    "url": "https://arxiv.org/abs/2202.07026",
    "authors": [
      "Adam Li",
      "Chester Huynh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2202.07052",
    "title": "Orthogonalising gradients to speed up neural network optimisation",
    "abstract": "The optimisation of neural networks can be sped up by orthogonalising the gradients before the optimisation step, ensuring the diversification of the learned representations. We orthogonalise the gradients of the layer's components/filters with respect to each other to separate out the intermediate representations. Our method of orthogonalisation allows the weights to be used more flexibly, in contrast to restricting the weights to an orthogonalised sub-space. We tested this method on ImageNet and CIFAR-10 resulting in a large decrease in learning time, and also obtain a speed-up on the semi-supervised learning BarlowTwins. We obtain similar accuracy to SGD without fine-tuning and better accuracy for na\\\"ively chosen hyper-parameters. ",
    "url": "https://arxiv.org/abs/2202.07052",
    "authors": [
      "Mark Tuddenham",
      "Adam Pr\u00fcgel-Bennett",
      "Jonathan Hare"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07054",
    "title": "Universal Adversarial Examples in Remote Sensing: Methodology and  Benchmark",
    "abstract": "Deep neural networks have achieved great success in many important remote sensing tasks. Nevertheless, their vulnerability to adversarial examples should not be neglected. In this study, we systematically analyze the universal adversarial examples in remote sensing data for the first time, without any knowledge from the victim model. Specifically, we propose a novel black-box adversarial attack method, namely Mixup-Attack, and its simple variant Mixcut-Attack, for remote sensing data. The key idea of the proposed methods is to find common vulnerabilities among different networks by attacking the features in the shallow layer of a given surrogate model. Despite their simplicity, the proposed methods can generate transferable adversarial examples that deceive most of the state-of-the-art deep neural networks in both scene classification and semantic segmentation tasks with high success rates. We further provide the generated universal adversarial examples in the dataset named UAE-RS, which is the first dataset that provides black-box adversarial samples in the remote sensing field. We hope UAE-RS may serve as a benchmark that helps researchers to design deep neural networks with strong resistance toward adversarial attacks in the remote sensing field. Codes and the UAE-RS dataset will be available online. ",
    "url": "https://arxiv.org/abs/2202.07054",
    "authors": [
      "Yonghao Xu",
      "Pedram Ghamisi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07073",
    "title": "Discriminability-enforcing loss to improve representation learning",
    "abstract": "During the training process, deep neural networks implicitly learn to represent the input data samples through a hierarchy of features, where the size of the hierarchy is determined by the number of layers. In this paper, we focus on enforcing the discriminative power of the high-level representations, that are typically learned by the deeper layers (closer to the output). To this end, we introduce a new loss term inspired by the Gini impurity, which is aimed at minimizing the entropy (increasing the discriminative power) of individual high-level features with respect to the class labels. Although our Gini loss induces highly-discriminative features, it does not ensure that the distribution of the high-level features matches the distribution of the classes. As such, we introduce another loss term to minimize the Kullback-Leibler divergence between the two distributions. We conduct experiments on two image classification data sets (CIFAR-100 and Caltech 101), considering multiple neural architectures ranging from convolutional networks (ResNet-17, ResNet-18, ResNet-50) to transformers (CvT). Our empirical results show that integrating our novel loss terms into the training objective consistently outperforms the models trained with cross-entropy alone. ",
    "url": "https://arxiv.org/abs/2202.07073",
    "authors": [
      "Florinel-Alin Croitoru",
      "Diana-Nicoleta Grigore",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07075",
    "title": "Regional Differences in Information Privacy Concerns After the  Facebook-Cambridge Analytica Data Scandal",
    "abstract": "While there is increasing global attention to data privacy, most of their current theoretical understanding is based on research conducted in a few countries. Prior work argues that people's cultural backgrounds might shape their privacy concerns; thus, we could expect people from different world regions to conceptualize them in diverse ways. We collected and analyzed a large-scale dataset of tweets about the #CambridgeAnalytica scandal in Spanish and English to start exploring this hypothesis. We employed word embeddings and qualitative analysis to identify which information privacy concerns are present and characterize language and regional differences in emphasis on these concerns. Our results suggest that related concepts, such as regulations, can be added to current information privacy frameworks. We also observe a greater emphasis on data collection in English than in Spanish. Additionally, data from North America exhibits a narrower focus on awareness compared to other regions under study. Our results call for more diverse sources of data and nuanced analysis of data privacy concerns around the globe. ",
    "url": "https://arxiv.org/abs/2202.07075",
    "authors": [
      "Felipe Gonz\u00e1lez-Pizarro",
      "Andrea Figueroa",
      "Claudia L\u00f3pez",
      "Cecilia Aragon"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2202.07082",
    "title": "Graph Neural Networks for Graphs with Heterophily: A Survey",
    "abstract": "Recent years have witnessed fast developments of graph neural networks (GNNs) that have benefited myriads of graph analytic tasks and applications. In general, most GNNs depend on the homophily assumption that nodes belonging to the same class are more likely to be connected. However, as a ubiquitous graph property in numerous real-world scenarios, heterophily, i.e., nodes with different labels tend to be linked, significantly limits the performance of tailor-made homophilic GNNs. Hence, \\textit{GNNs for heterophilic graphs} are gaining increasing attention in this community. To the best of our knowledge, in this paper, we provide a comprehensive review of GNNs for heterophilic graphs for the first time. Specifically, we propose a systematic taxonomy that essentially governs existing heterophilic GNN models, along with a general summary and detailed analysis. Furthermore, we summarize the mainstream heterophilic graph benchmarks to facilitate robust and fair evaluations. In the end, we point out the potential directions to advance and stimulate future research and applications on heterophilic graphs. ",
    "url": "https://arxiv.org/abs/2202.07082",
    "authors": [
      "Xin Zheng",
      "Yixin Liu",
      "Shirui Pan",
      "Miao Zhang",
      "Di Jin",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07088",
    "title": "Scaling up Ranking under Constraints for Live Recommendations by  Replacing Optimization with Prediction",
    "abstract": "Many important multiple-objective decision problems can be cast within the framework of ranking under constraints and solved via a weighted bipartite matching linear program. Some of these optimization problems, such as personalized content recommendations, may need to be solved in real time and thus must comply with strict time requirements to prevent the perception of latency by consumers. Classical linear programming is too computationally inefficient for such settings. We propose a novel approach to scale up ranking under constraints by replacing the weighted bipartite matching optimization with a prediction problem in the algorithm deployment stage. We show empirically that the proposed approximate solution to the ranking problem leads to a major reduction in required computing resources without much sacrifice in constraint compliance and achieved utility, allowing us to solve larger constrained ranking problems real-time, within the required 50 milliseconds, than previously reported. ",
    "url": "https://arxiv.org/abs/2202.07088",
    "authors": [
      "Yegor Tkachenko",
      "Wassim Dhaouadi",
      "Kamel Jedidi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07101",
    "title": "A Survey on Dynamic Neural Networks for Natural Language Processing",
    "abstract": "Effectively scaling large Transformer models is a main driver of recent advances in natural language processing. Dynamic neural networks, as an emerging research direction, are capable of scaling up neural networks with sub-linear increases in computation and time by dynamically adjusting their computational path based on the input. Dynamic neural networks could be a promising solution to the growing parameter numbers of pretrained language models, allowing both model pretraining with trillions of parameters and faster inference on mobile devices. In this survey, we summarize progress of three types of dynamic neural networks in NLP: skimming, mixture of experts, and early exit. We also highlight current challenges in dynamic neural networks and directions for future research. ",
    "url": "https://arxiv.org/abs/2202.07101",
    "authors": [
      "Canwen Xu",
      "Julian McAuley"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07114",
    "title": "Recent Advances in Reliable Deep Graph Learning: Adversarial Attack,  Inherent Noise, and Distribution Shift",
    "abstract": "Deep graph learning (DGL) has achieved remarkable progress in both business and scientific areas ranging from finance and e-commerce to drug and advanced material discovery. Despite the progress, applying DGL to real-world applications faces a series of reliability threats including adversarial attacks, inherent noise, and distribution shift. This survey aims to provide a comprehensive review of recent advances for improving the reliability of DGL algorithms against the above threats. In contrast to prior related surveys which mainly focus on adversarial attacks and defense, our survey covers more reliability-related aspects of DGL, i.e., inherent noise and distribution shift. Additionally, we discuss the relationships among above aspects and highlight some important issues to be explored in future research. ",
    "url": "https://arxiv.org/abs/2202.07114",
    "authors": [
      "Bingzhe Wu",
      "Jintang Li",
      "Chengbin Hou",
      "Guoji Fu",
      "Yatao Bian",
      "Liang Chen",
      "Junzhou Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2202.07115",
    "title": "Graph Neural Network-Based Scheduling for Multi-UAV-Enabled  Communications in D2D Networks",
    "abstract": "In this paper, we jointly design the power control and position dispatch for Multi-unmanned aerial vehicle (UAV)-enabled communication in device-to-device (D2D) networks. Our objective is to maximize the total transmission rate of downlink users (DUs). Meanwhile, the quality of service (QoS) of all D2D users must be satisfied. We comprehensively considered the interference among D2D communications and downlink transmissions. The original problem is strongly non-convex, which requires high computational complexity for traditional optimization methods. And to make matters worse, the results are not necessarily globally optimal. In this paper, we propose a novel graph neural networks (GNN) based approach that can map the considered system into a specific graph structure and achieve the optimal solution in a low complexity manner. Particularly, we first construct a GNN-based model for the proposed network, in which the transmission links and interference links are formulated as vertexes and edges, respectively. Then, by taking the channel state information and the coordinates of ground users as the inputs, as well as the location of UAVs and the transmission power of all transmitters as outputs, we obtain the mapping from inputs to outputs through training the parameters of GNN. Simulation results verified that the way to maximize the total transmission rate of DUs can be extracted effectively via the training on samples. Moreover, it also shows that the performance of proposed GNN-based method is better than that of traditional means. ",
    "url": "https://arxiv.org/abs/2202.07115",
    "authors": [
      "Pei Li",
      "Lingyi Wang",
      "Wei Wu",
      "Fuhui Zhou",
      "Baoyun Wang",
      "Qihui Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.07123",
    "title": "Rethinking Network Design and Local Geometry in Point Cloud: A Simple  Residual MLP Framework",
    "abstract": "Point cloud analysis is challenging due to irregularity and unordered data structure. To capture the 3D geometries, prior works mainly rely on exploring sophisticated local geometric extractors using convolution, graph, or attention mechanisms. These methods, however, incur unfavorable latency during inference, and the performance saturates over the past few years. In this paper, we present a novel perspective on this task. We notice that detailed local geometrical information probably is not the key to point cloud analysis -- we introduce a pure residual MLP network, called PointMLP, which integrates no sophisticated local geometrical extractors but still performs very competitively. Equipped with a proposed lightweight geometric affine module, PointMLP delivers the new state-of-the-art on multiple datasets. On the real-world ScanObjectNN dataset, our method even surpasses the prior best method by 3.3% accuracy. We emphasize that PointMLP achieves this strong performance without any sophisticated operations, hence leading to a superior inference speed. Compared to most recent CurveNet, PointMLP trains 2x faster, tests 7x faster, and is more accurate on ModelNet40 benchmark. We hope our PointMLP may help the community towards a better understanding of point cloud analysis. The code is available at https://github.com/ma-xu/pointMLP-pytorch. ",
    "url": "https://arxiv.org/abs/2202.07123",
    "authors": [
      "Xu Ma",
      "Can Qin",
      "Haoxuan You",
      "Haoxi Ran",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.07130",
    "title": "STaR: Knowledge Graph Embedding by Scaling, Translation and Rotation",
    "abstract": "The bilinear method is mainstream in Knowledge Graph Embedding (KGE), aiming to learn low-dimensional representations for entities and relations in Knowledge Graph (KG) and complete missing links. Most of the existing works are to find patterns between relationships and effectively model them to accomplish this task. Previous works have mainly discovered 6 important patterns like non-commutativity. Although some bilinear methods succeed in modeling these patterns, they neglect to handle 1-to-N, N-to-1, and N-to-N relations (or complex relations) concurrently, which hurts their expressiveness. To this end, we integrate scaling, the combination of translation and rotation that can solve complex relations and patterns, respectively, where scaling is a simplification of projection. Therefore, we propose a corresponding bilinear model Scaling Translation and Rotation (STaR) consisting of the above two parts. Besides, since translation cannot be incorporated into the bilinear model directly, we introduce translation matrix as the equivalent. Theoretical analysis proves that STaR is capable of modeling all patterns and handling complex relations simultaneously, and experiments demonstrate its effectiveness on commonly used benchmarks for link prediction. ",
    "url": "https://arxiv.org/abs/2202.07130",
    "authors": [
      "Jiayi Li",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07132",
    "title": "Memory via Temporal Delays in weightless Spiking Neural Network",
    "abstract": "A common view in the neuroscience community is that memory is encoded in the connection strength between neurons. This perception led artificial neural network models to focus on connection weights as the key variables to modulate learning. In this paper, we present a prototype for weightless spiking neural networks that can perform a simple classification task. The memory in this network is stored in the timing between neurons, rather than the strength of the connection, and is trained using a Hebbian Spike Timing Dependent Plasticity (STDP), which modulates the delays of the connection. ",
    "url": "https://arxiv.org/abs/2202.07132",
    "authors": [
      "Hananel Hazan",
      "Simon Caby",
      "Christopher Earl",
      "Hava Siegelmann",
      "Michael Levin"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07133",
    "title": "Sim-to-Real Domain Adaptation for Lane Detection and Classification in  Autonomous Driving",
    "abstract": "While supervised detection and classification frameworks in autonomous driving require large labelled datasets to converge, Unsupervised Domain Adaptation (UDA) approaches, facilitated by synthetic data generated from photo-real simulated environments, are considered low-cost and less time-consuming solutions. In this paper, we propose UDA schemes using adversarial discriminative and generative methods for lane detection and classification applications in autonomous driving. We also present Simulanes dataset generator to create a synthetic dataset that is naturalistic utilizing CARLA's vast traffic scenarios and weather conditions. The proposed UDA frameworks take the synthesized dataset with labels as the source domain, whereas the target domain is the unlabelled real-world data. Using adversarial generative and feature discriminators, the learnt models are tuned to predict the lane location and class in the target domain. The proposed techniques are evaluated using both real-world and our synthetic datasets. The results manifest that the proposed methods have shown superiority over other baseline schemes in terms of detection and classification accuracy and consistency. The ablation study reveals that the size of the simulation dataset plays important roles in the classification performance of the proposed methods. Our UDA frameworks are available at https://github.com/anita-hu/sim2real-lane-detection and our dataset generator is released at https://github.com/anita-hu/simulanes ",
    "url": "https://arxiv.org/abs/2202.07133",
    "authors": [
      "Chuqing Hu",
      "Sinclair Hudson",
      "Martin Ethier",
      "Mohammad Al-Sharman",
      "Derek Rayside",
      "William Melek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07135",
    "title": "Compositional Scene Representation Learning via Reconstruction: A Survey",
    "abstract": "Visual scene representation learning is an important research problem in the field of computer vision. The performance on vision tasks could be improved if more suitable representations are learned for visual scenes. Complex visual scenes are the composition of relatively simple visual concepts, and have the property of combinatorial explosion. Compared with directly representing the entire visual scene, extracting compositional scene representations can better cope with the diverse combination of background and objects. Because compositional scene representations abstract the concept of objects, performing visual scene analysis and understanding based on these representations could be easier and more interpretable. Moreover, learning compositional scene representations via reconstruction can greatly reduce the need for training data annotations. Therefore, compositional scene representation learning via reconstruction has important research significance. In this survey, we first discuss representative methods that either learn from a single viewpoint or multiple viewpoints without object-level supervision, then the applications of compositional scene representations, and finally the future directions on this topic. ",
    "url": "https://arxiv.org/abs/2202.07135",
    "authors": [
      "Jinyang Yuan",
      "Tonglin Chen",
      "Bin Li",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07140",
    "title": "Securing Reconfigurable Intelligent Surface-Aided Cell-Free Networks",
    "abstract": "In this paper, we investigate the physical layer security in the reconfigurable intelligent surface (RIS)-aided cell-free networks. A maximum weighted sum secrecy rate problem is formulated by jointly optimizing the active beamforming (BF) at the base stations and passive BF at the RISs. To handle this non-trivial problem, we adopt the alternating optimization to decouple the original problem into two sub-ones, which are solved using the semidefinite relaxation and continuous convex approximation theory. To decrease the complexity for obtaining overall channel state information (CSI), we extend the proposed framework to the case that only requires part of the RIS' CSI. This is achieved via deliberately discarding the RIS that has a small contribution to the user's secrecy rate. Based on this, we formulate a mixed integer non-linear programming problem, and the linear conic relaxation is used to obtained the solutions. Finally, the simulation results show that the proposed schemes can obtain a higher secrecy rate than the existing ones. ",
    "url": "https://arxiv.org/abs/2202.07140",
    "authors": [
      "Wanming Hao",
      "Junjie Li",
      "Gangcan Sun",
      "Ming Zeng",
      "Octavia A. Dobre"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.07147",
    "title": "Graph Meta-Reinforcement Learning for Transferable Autonomous  Mobility-on-Demand",
    "abstract": "Autonomous Mobility-on-Demand (AMoD) systems represent an attractive alternative to existing transportation paradigms, currently challenged by urbanization and increasing travel needs. By centrally controlling a fleet of self-driving vehicles, these systems provide mobility service to customers and are currently starting to be deployed in a number of cities around the world. Current learning-based approaches for controlling AMoD systems are limited to the single-city scenario, whereby the service operator is allowed to take an unlimited amount of operational decisions within the same transportation system. However, real-world system operators can hardly afford to fully re-train AMoD controllers for every city they operate in, as this could result in a high number of poor-quality decisions during training, making the single-city strategy a potentially impractical solution. To address these limitations, we propose to formalize the multi-city AMoD problem through the lens of meta-reinforcement learning (meta-RL) and devise an actor-critic algorithm based on recurrent graph neural networks. In our approach, AMoD controllers are explicitly trained such that a small amount of experience within a new city will produce good system performance. Empirically, we show how control policies learned through meta-RL are able to achieve near-optimal performance on unseen cities by learning rapidly adaptable policies, thus making them more robust not only to novel environments, but also to distribution shifts common in real-world operations, such as special events, unexpected congestion, and dynamic pricing schemes. ",
    "url": "https://arxiv.org/abs/2202.07147",
    "authors": [
      "Daniele Gammelli",
      "Kaidi Yang",
      "James Harrison",
      "Filipe Rodrigues",
      "Francisco C. Pereira",
      "Marco Pavone"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.07170",
    "title": "Fairness Amidst Non-IID Graph Data: A Literature Review",
    "abstract": "Fairness in machine learning (ML), the process to understand and correct algorithmic bias, has gained increasing attention with numerous literature being carried out, commonly assume the underlying data is independent and identically distributed (IID). On the other hand, graphs are a ubiquitous data structure to capture connections among individual units and is non-IID by nature. It is therefore of great importance to bridge the traditional fairness literature designed on IID data and ubiquitous non-IID graph representations to tackle bias in ML systems. In this survey, we review such recent advance in fairness amidst non-IID graph data and identify datasets and evaluation metrics available for future research. We also point out the limitations of existing work as well as promising future directions. ",
    "url": "https://arxiv.org/abs/2202.07170",
    "authors": [
      "Wenbin Zhang",
      "Jeremy C. Weiss",
      "Shuigeng Zhou",
      "Toby Walsh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.07178",
    "title": "Federated Learning with Sparsified Model Perturbation: Improving  Accuracy under Client-Level Differential Privacy",
    "abstract": "Federated learning (FL) that enables distributed clients to collaboratively learn a shared statistical model while keeping their training data locally has received great attention recently and can improve privacy and communication efficiency in comparison with traditional centralized machine learning paradigm. However, sensitive information about the training data can still be inferred from model updates shared in FL. Differential privacy (DP) is the state-of-the-art technique to defend against those attacks. The key challenge to achieve DP in FL lies in the adverse impact of DP noise on model accuracy, particularly for deep learning models with large numbers of model parameters. This paper develops a novel differentially-private FL scheme named Fed-SMP that provides client-level DP guarantee while maintaining high model accuracy. To mitigate the impact of privacy protection on model accuracy, Fed-SMP leverages a new technique called Sparsified Model Perturbation (SMP), where local models are sparsified first before being perturbed with additive Gaussian noise. Two sparsification strategies are considered in Fed-SMP: random sparsification and top-$k$ sparsification. We also apply R{\\'e}nyi differential privacy to providing a tight analysis for the end-to-end DP guarantee of Fed-SMP and prove the convergence of Fed-SMP with general loss functions. Extensive experiments on real-world datasets are conducted to demonstrate the effectiveness of Fed-SMP in largely improving model accuracy with the same level of DP guarantee and saving communication cost simultaneously. ",
    "url": "https://arxiv.org/abs/2202.07178",
    "authors": [
      "Rui Hu",
      "Yanmin Gong",
      "Yuanxiong Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.07179",
    "title": "G-Mixup: Graph Data Augmentation for Graph Classification",
    "abstract": "This work develops \\emph{mixup for graph data}. Mixup has shown superiority in improving the generalization and robustness of neural networks by interpolating features and labels between two random samples. Traditionally, Mixup can work on regular, grid-like, and Euclidean data such as image or tabular data. However, it is challenging to directly adopt Mixup to augment graph data because different graphs typically: 1) have different numbers of nodes; 2) are not readily aligned; and 3) have unique typologies in non-Euclidean space. To this end, we propose $\\mathcal{G}$-Mixup to augment graphs for graph classification by interpolating the generator (i.e., graphon) of different classes of graphs. Specifically, we first use graphs within the same class to estimate a graphon. Then, instead of directly manipulating graphs, we interpolate graphons of different classes in the Euclidean space to get mixed graphons, where the synthetic graphs are generated through sampling based on the mixed graphons. Extensive experiments show that $\\mathcal{G}$-Mixup substantially improves the generalization and robustness of GNNs. ",
    "url": "https://arxiv.org/abs/2202.07179",
    "authors": [
      "Xiaotian Han",
      "Zhimeng Jiang",
      "Ninghao Liu",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.07183",
    "title": "A Survey of Neural Trojan Attacks and Defenses in Deep Learning",
    "abstract": "Artificial Intelligence (AI) relies heavily on deep learning - a technology that is becoming increasingly popular in real-life applications of AI, even in the safety-critical and high-risk domains. However, it is recently discovered that deep learning can be manipulated by embedding Trojans inside it. Unfortunately, pragmatic solutions to circumvent the computational requirements of deep learning, e.g. outsourcing model training or data annotation to third parties, further add to model susceptibility to the Trojan attacks. Due to the key importance of the topic in deep learning, recent literature has seen many contributions in this direction. We conduct a comprehensive review of the techniques that devise Trojan attacks for deep learning and explore their defenses. Our informative survey systematically organizes the recent literature and discusses the key concepts of the methods while assuming minimal knowledge of the domain on the readers part. It provides a comprehensible gateway to the broader community to understand the recent developments in Neural Trojans. ",
    "url": "https://arxiv.org/abs/2202.07183",
    "authors": [
      "Jie Wang",
      "Ghulam Mubashar Hassan",
      "Naveed Akhtar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07184",
    "title": "On the Origins of the Block Structure Phenomenon in Neural Network  Representations",
    "abstract": "Recent work has uncovered a striking phenomenon in large-capacity neural networks: they contain blocks of contiguous hidden layers with highly similar representations. This block structure has two seemingly contradictory properties: on the one hand, its constituent layers exhibit highly similar dominant first principal components (PCs), but on the other hand, their representations, and their common first PC, are highly dissimilar across different random seeds. Our work seeks to reconcile these discrepant properties by investigating the origin of the block structure in relation to the data and training methods. By analyzing properties of the dominant PCs, we find that the block structure arises from dominant datapoints - a small group of examples that share similar image statistics (e.g. background color). However, the set of dominant datapoints, and the precise shared image statistic, can vary across random seeds. Thus, the block structure reflects meaningful dataset statistics, but is simultaneously unique to each model. Through studying hidden layer activations and creating synthetic datapoints, we demonstrate that these simple image statistics dominate the representational geometry of the layers inside the block structure. We explore how the phenomenon evolves through training, finding that the block structure takes shape early in training, but the underlying representations and the corresponding dominant datapoints continue to change substantially. Finally, we study the interplay between the block structure and different training mechanisms, introducing a targeted intervention to eliminate the block structure, as well as examining the effects of pretraining and Shake-Shake regularization. ",
    "url": "https://arxiv.org/abs/2202.07184",
    "authors": [
      "Thao Nguyen",
      "Maithra Raghu",
      "Simon Kornblith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07188",
    "title": "Survivable Free Space Optical Mesh Network using High-Altitude Platforms",
    "abstract": "Free space optical (FSO) communication refers to the information transmission technology based on the propagation of optical signals in space. FSO communication requires that the transmitter and receiver directly see each other. High-altitude platforms (HAPs) have been proposed for carrying FSO transceivers in the stratosphere. A multihop HAP network with FSO links can relay traffic between ground FSO nodes. In this study, we propose an end-to-end switching model for forwarding traffic between massive pairs of ground FSO nodes over a HAP network. A protection mechanism is employed for improving the communication survivability in the presence of clouds, which may break the line of sight (LoS) between HAPs and ground nodes. We propose an algorithm for designing the topology of the survivable HAP network, given a set of ground FSO nodes. The results demonstrate that, even though networks with survivable capacity use more resources, they are not necessary much more expensive than those without survivability in terms of equipment, i.e., HAPs and FSO devices, and in terms of wavelength resource utilization. ",
    "url": "https://arxiv.org/abs/2202.07188",
    "authors": [
      "Dieu Linh Truong",
      "Xuan Vuong Dang",
      "Ngoc Dang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2202.07190",
    "title": "Pruning Networks with Cross-Layer Ranking & k-Reciprocal Nearest Filters",
    "abstract": "This paper focuses on filter-level network pruning. A novel pruning method, termed CLR-RNF, is proposed. We first reveal a \"long-tail\" long-tail pruning problem in magnitude-based weight pruning methods, and then propose a computation-aware measurement for individual weight importance, followed by a Cross-Layer Ranking (CLR) of weights to identify and remove the bottom-ranked weights. Consequently, the per-layer sparsity makes up of the pruned network structure in our filter pruning. Then, we introduce a recommendation-based filter selection scheme where each filter recommends a group of its closest filters. To pick the preserved filters from these recommended groups, we further devise a k-Reciprocal Nearest Filter (RNF) selection scheme where the selected filters fall into the intersection of these recommended groups. Both our pruned network structure and the filter selection are non-learning processes, which thus significantly reduce the pruning complexity, and differentiate our method from existing works. We conduct image classification on CIFAR-10 and ImageNet to demonstrate the superiority of our CLR-RNF over the state-of-the-arts. For example, on CIFAR-10, CLR-RNF removes 74.1% FLOPs and 95.0% parameters from VGGNet-16 with even 0.3\\% accuracy improvements. On ImageNet, it removes 70.2% FLOPs and 64.8% parameters from ResNet-50 with only 1.7% top-5 accuracy drops. Our project is at https://github.com/lmbxmu/CLR-RNF. ",
    "url": "https://arxiv.org/abs/2202.07190",
    "authors": [
      "Mingbao Lin",
      "Liujuan Cao",
      "Yuxin Zhang",
      "Ling Shao",
      "Chia-Wen Lin",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07201",
    "title": "Holistic Adversarial Robustness of Deep Learning Models",
    "abstract": "Adversarial robustness studies the worst-case performance of a machine learning model to ensure safety and reliability. With the proliferation of deep-learning based technology, the potential risks associated with model development and deployment can be amplified and become dreadful vulnerabilities. This paper provides a comprehensive overview of research topics and foundational principles of research methods for adversarial robustness of deep learning models, including attacks, defenses, verification, and novel applications. ",
    "url": "https://arxiv.org/abs/2202.07201",
    "authors": [
      "Pin-Yu Chen",
      "Sijia Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.07221",
    "title": "Navigating Local Minima in Quantized Spiking Neural Networks",
    "abstract": "Spiking and Quantized Neural Networks (NNs) are becoming exceedingly important for hyper-efficient implementations of Deep Learning (DL) algorithms. However, these networks face challenges when trained using error backpropagation, due to the absence of gradient signals when applying hard thresholds. The broadly accepted trick to overcoming this is through the use of biased gradient estimators: surrogate gradients which approximate thresholding in Spiking Neural Networks (SNNs), and Straight-Through Estimators (STEs), which completely bypass thresholding in Quantized Neural Networks (QNNs). While noisy gradient feedback has enabled reasonable performance on simple supervised learning tasks, it is thought that such noise increases the difficulty of finding optima in loss landscapes, especially during the later stages of optimization. By periodically boosting the Learning Rate (LR) during training, we expect the network can navigate unexplored solution spaces that would otherwise be difficult to reach due to local minima, barriers, or flat surfaces. This paper presents a systematic evaluation of a cosine-annealed LR schedule coupled with weight-independent adaptive moment estimation as applied to Quantized SNNs (QSNNs). We provide a rigorous empirical evaluation of this technique on high precision and 4-bit quantized SNNs across three datasets, demonstrating (close to) state-of-the-art performance on the more complex datasets. Our source code is available at this link: https://github.com/jeshraghian/QSNNs. ",
    "url": "https://arxiv.org/abs/2202.07221",
    "authors": [
      "Jason K. Eshraghian",
      "Corey Lammie",
      "Mostafa Rahimi Azghadi",
      "Wei D. Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2202.07230",
    "title": "Geometrically Equivariant Graph Neural Networks: A Survey",
    "abstract": "Many scientific problems require to process data in the form of geometric graphs. Unlike generic graph data, geometric graphs exhibit symmetries of translations, rotations, and/or reflections. Researchers have leveraged such inductive bias and developed geometrically equivariant Graph Neural Networks (GNNs) to better characterize the geometry and topology of geometric graphs. Despite fruitful achievements, it still lacks a survey to depict how equivariant GNNs are progressed, which in turn hinders the further development of equivariant GNNs. To this end, based on the necessary but concise mathematical preliminaries, we analyze and classify existing methods into three groups regarding how the message passing and aggregation in GNNs are represented. We also summarize the benchmarks as well as the related datasets to facilitate later researches for methodology development and experimental evaluation. The prospect for future potential directions is also provided. ",
    "url": "https://arxiv.org/abs/2202.07230",
    "authors": [
      "Jiaqi Han",
      "Yu Rong",
      "Tingyang Xu",
      "Wenbing Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07241",
    "title": "Learning to Solve Routing Problems via Distributionally Robust  Optimization",
    "abstract": "Recent deep models for solving routing problems always assume a single distribution of nodes for training, which severely impairs their cross-distribution generalization ability. In this paper, we exploit group distributionally robust optimization (group DRO) to tackle this issue, where we jointly optimize the weights for different groups of distributions and the parameters for the deep model in an interleaved manner during training. We also design a module based on convolutional neural network, which allows the deep model to learn more informative latent pattern among the nodes. We evaluate the proposed approach on two types of well-known deep models including GCN and POMO. The experimental results on the randomly synthesized instances and the ones from two benchmark dataset (i.e., TSPLib and CVRPLib) demonstrate that our approach could significantly improve the cross-distribution generalization performance over the original models. ",
    "url": "https://arxiv.org/abs/2202.07241",
    "authors": [
      "Yuan Jiang",
      "Yaoxin Wu",
      "Zhiguang Cao",
      "Jie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.07242",
    "title": "Neural Architecture Search for Dense Prediction Tasks in Computer Vision",
    "abstract": "The success of deep learning in recent years has lead to a rising demand for neural network architecture engineering. As a consequence, neural architecture search (NAS), which aims at automatically designing neural network architectures in a data-driven manner rather than manually, has evolved as a popular field of research. With the advent of weight sharing strategies across architectures, NAS has become applicable to a much wider range of problems. In particular, there are now many publications for dense prediction tasks in computer vision that require pixel-level predictions, such as semantic segmentation or object detection. These tasks come with novel challenges, such as higher memory footprints due to high-resolution data, learning multi-scale representations, longer training times, and more complex and larger neural architectures. In this manuscript, we provide an overview of NAS for dense prediction tasks by elaborating on these novel challenges and surveying ways to address them to ease future research and application of existing methods to novel problems. ",
    "url": "https://arxiv.org/abs/2202.07242",
    "authors": [
      "Thomas Elsken",
      "Arber Zela",
      "Jan Hendrik Metzen",
      "Benedikt Staffler",
      "Thomas Brox",
      "Abhinav Valada",
      "Frank Hutter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07247",
    "title": "CommerceMM: Large-Scale Commerce MultiModal Representation Learning with  Omni Retrieval",
    "abstract": "We introduce CommerceMM - a multimodal model capable of providing a diverse and granular understanding of commerce topics associated to the given piece of content (image, text, image+text), and having the capability to generalize to a wide range of tasks, including Multimodal Categorization, Image-Text Retrieval, Query-to-Product Retrieval, Image-to-Product Retrieval, etc. We follow the pre-training + fine-tuning training regime and present 5 effective pre-training tasks on image-text pairs. To embrace more common and diverse commerce data with text-to-multimodal, image-to-multimodal, and multimodal-to-multimodal mapping, we propose another 9 novel cross-modal and cross-pair retrieval tasks, called Omni-Retrieval pre-training. The pre-training is conducted in an efficient manner with only two forward/backward updates for the combined 14 tasks. Extensive experiments and analysis show the effectiveness of each task. When combining all pre-training tasks, our model achieves state-of-the-art performance on 7 commerce-related downstream tasks after fine-tuning. Additionally, we propose a novel approach of modality randomization to dynamically adjust our model under different efficiency constraints. ",
    "url": "https://arxiv.org/abs/2202.07247",
    "authors": [
      "Licheng Yu",
      "Jun Chen",
      "Animesh Sinha",
      "Mengjiao MJ Wang",
      "Hugo Chen",
      "Tamara L. Berg",
      "Ning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2202.07253",
    "title": "Exploiting Data Sparsity in Secure Cross-Platform Social Recommendation",
    "abstract": "Social recommendation has shown promising improvements over traditional systems since it leverages social correlation data as an additional input. Most existing work assumes that all data are available to the recommendation platform. However, in practice, user-item interaction data (e.g.,rating) and user-user social data are usually generated by different platforms, and both of which contain sensitive information. Therefore, \"How to perform secure and efficient social recommendation across different platforms, where the data are highly-sparse in nature\" remains an important challenge. In this work, we bring secure computation techniques into social recommendation, and propose S3Rec, a sparsity-aware secure cross-platform social recommendation framework. As a result, our model can not only improve the recommendation performance of the rating platform by incorporating the sparse social data on the social platform, but also protect data privacy of both platforms. Moreover, to further improve model training efficiency, we propose two secure sparse matrix multiplication protocols based on homomorphic encryption and private information retrieval. Our experiments on two benchmark datasets demonstrate the effectiveness of S3Rec. ",
    "url": "https://arxiv.org/abs/2202.07253",
    "authors": [
      "Jamie Cui",
      "Chaochao Chen",
      "Lingjuan Lyu",
      "Carl Yang",
      "Li Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.07255",
    "title": "Enhancing Cross-lingual Prompting with Mask Token Augmentation",
    "abstract": "Prompting shows promising results in few-shot scenarios. However, its strength for multilingual/cross-lingual problems has not been fully exploited. Zhao and Sch\\\"utze (2021) made initial explorations in this direction by presenting that cross-lingual prompting outperforms cross-lingual finetuning. In this paper, we conduct empirical analysis on the effect of each component in cross-lingual prompting and derive Universal Prompting across languages, which helps alleviate the discrepancies between source-language training and target-language inference. Based on this, we propose a mask token augmentation framework to further improve the performance of prompt-based cross-lingual transfer. Notably, for XNLI, our method achieves 46.54% with only 16 English training examples per class, significantly better than 34.99% of finetuning. ",
    "url": "https://arxiv.org/abs/2202.07255",
    "authors": [
      "Meng Zhou",
      "Xin Li",
      "Yue Jiang",
      "Lidong Bing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.07256",
    "title": "Federated Graph Neural Networks: Overview, Techniques and Challenges",
    "abstract": "With its powerful capability to deal with graph data widely found in practical applications, graph neural networks (GNNs) have received significant research attention. However, as societies become increasingly concerned with data privacy, GNNs face the need to adapt to this new normal. This has led to the rapid development of federated graph neural networks (FedGNNs) research in recent years. Although promising, this interdisciplinary field is highly challenging for interested researchers to enter into. The lack of an insightful survey on this topic only exacerbates this problem. In this paper, we bridge this gap by offering a comprehensive survey of this emerging field. We propose a unique 3-tiered taxonomy of the FedGNNs literature to provide a clear view into how GNNs work in the context of Federated Learning (FL). It puts existing works into perspective by analyzing how graph data manifest themselves in FL settings, how GNN training is performed under different FL system architectures and degrees of graph data overlap across data silo, and how GNN aggregation is performed under various FL settings. Through discussions of the advantages and limitations of existing works, we envision future research directions that can help build more robust, dynamic, efficient, and interpretable FedGNNs. ",
    "url": "https://arxiv.org/abs/2202.07256",
    "authors": [
      "Rui Liu",
      "Han Yu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07259",
    "title": "Review of the Fingerprint Liveness Detection (LivDet) competition  series: from 2009 to 2021",
    "abstract": "Fingerprint authentication systems are highly vulnerable to artificial reproductions of fingerprint, called fingerprint presentation attacks. Detecting presentation attacks is not trivial because attackers refine their replication techniques from year to year. The International Fingerprint liveness Detection Competition (LivDet), an open and well-acknowledged meeting point of academies and private companies that deal with the problem of presentation attack detection, has the goal to assess the performance of fingerprint presentation attack detection (FPAD) algorithms by using standard experimental protocols and data sets. Each LivDet edition, held biannually since 2009, is characterized by a different set of challenges against which competitors must be dealt with. The continuous increase of competitors and the noticeable decrease in error rates across competitions demonstrate a growing interest in the topic. This paper reviews the LivDet editions from 2009 to 2021 and points out their evolution over the years. ",
    "url": "https://arxiv.org/abs/2202.07259",
    "authors": [
      "Marco Micheletto",
      "Giulia Orr\u00f9",
      "Roberto Casula",
      "David Yambay",
      "Gian Luca Marcialis",
      "Stephanie C. Schuckers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07261",
    "title": "Exploring the Devil in Graph Spectral Domain for 3D Point Cloud Attacks",
    "abstract": "3D dynamic point clouds provide a discrete representation of real-world objects or scenes in motion, which have been widely applied in immersive telepresence, autonomous driving, surveillance, \\textit{etc}. However, point clouds acquired from sensors are usually perturbed by noise, which affects downstream tasks such as surface reconstruction and analysis. Although many efforts have been made for static point cloud denoising, few works address dynamic point cloud denoising. In this paper, we propose a novel gradient-based dynamic point cloud denoising method, exploiting the temporal correspondence for the estimation of gradient fields -- also a fundamental problem in dynamic point cloud processing and analysis. The gradient field is the gradient of the log-probability function of the noisy point cloud, based on which we perform gradient ascent so as to converge each point to the underlying clean surface. We estimate the gradient of each surface patch by exploiting the temporal correspondence, where the temporally corresponding patches are searched leveraging on rigid motion in classical mechanics. In particular, we treat each patch as a rigid object, which moves in the gradient field of an adjacent frame via force until reaching a balanced state, i.e., when the sum of gradients over the patch reaches 0. Since the gradient would be smaller when the point is closer to the underlying surface, the balanced patch would fit the underlying surface well, thus leading to the temporal correspondence. Finally, the position of each point in the patch is updated along the direction of the gradient averaged from corresponding patches in adjacent frames. Experimental results demonstrate that the proposed model outperforms state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2202.07261",
    "authors": [
      "Qianjiang Hu",
      "Daizong Liu",
      "Wei Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2202.07265",
    "title": "A data availability attack on a blockchain protocol based on LDPC codes",
    "abstract": "In a blockchain Data Availability Attack (DAA), a malicious node publishes a block header but withholds part of the block, which contains invalid transactions. Honest full nodes, which can download and store the full blockchain, are aware that some data are not available but they have no formal way to prove it to light nodes, i.e., nodes that have limited resources and are not able to access the whole blockchain data. A common solution to counter these attacks exploits linear error correcting codes to encode the block content. A recent protocol, called SPAR, employs coded Merkle trees and low-density parity-check (LDPC) codes to counter DAAs. We show that the sparse nature of LDPC matrices and the use of the so-called peeling decoder make the protocol less secure than expected, owing to a new possible attack strategy that can be followed by malicious nodes. ",
    "url": "https://arxiv.org/abs/2202.07265",
    "authors": [
      "Massimo Battaglioni",
      "Paolo Santini",
      "Giulia Rafaiani",
      "Franco Chiaraluce",
      "Marco Baldi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.07268",
    "title": "Convolutional Network Fabric Pruning With Label Noise",
    "abstract": "This paper presents an iterative pruning strategy for Convolutional Network Fabrics (CNF) in presence of noisy training and testing data. With the continuous increase in size of neural network models, various authors have developed pruning approaches to build more compact network structures requiring less resources, while preserving performance. As we show in this paper, because of their intrinsic structure and function, Convolutional Network Fabrics are ideal candidates for pruning. We present a series of pruning strategies that can significantly reduce both the final network size and required training time by pruning either entire convolutional filters or individual weights, so that the grid remains visually understandable but that overall execution quality stays within controllable boundaries. Our approach can be iteratively applied during training so that the network complexity decreases rapidly, saving computational time. The paper addresses both data-dependent and dataindependent strategies, and also experimentally establishes the most efficient approaches when training or testing data contain annotation errors. ",
    "url": "https://arxiv.org/abs/2202.07268",
    "authors": [
      "Ilias Benjelloun",
      "Bart Lamiroy",
      "Efoevi Koudou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2202.07271",
    "title": "Hyper-relationship Learning Network for Scene Graph Generation",
    "abstract": "Generating informative scene graphs from images requires integrating and reasoning from various graph components, i.e., objects and relationships. However, current scene graph generation (SGG) methods, including the unbiased SGG methods, still struggle to predict informative relationships due to the lack of 1) high-level inference such as transitive inference between relationships and 2) efficient mechanisms that can incorporate all interactions of graph components. To address the issues mentioned above, we devise a hyper-relationship learning network, termed HLN, for SGG. Specifically, the proposed HLN stems from hypergraphs and two graph attention networks (GATs) are designed to infer relationships: 1) the object-relationship GAT or OR-GAT to explore interactions between objects and relationships, and 2) the hyper-relationship GAT or HR-GAT to integrate transitive inference of hyper-relationships, i.e., the sequential relationships between three objects for transitive reasoning. As a result, HLN significantly improves the performance of scene graph generation by integrating and reasoning from object interactions, relationship interactions, and transitive inference of hyper-relationships. We evaluate HLN on the most popular SGG dataset, i.e., the Visual Genome dataset, and the experimental results demonstrate its great superiority over recent state-of-the-art methods. For example, the proposed HLN improves the recall per relationship from 11.3\\% to 13.1\\%, and maintains the recall per image from 19.8\\% to 34.9\\%. We will release the source code and pretrained models on GitHub. ",
    "url": "https://arxiv.org/abs/2202.07271",
    "authors": [
      "Yibing Zhan",
      "Zhi Chen",
      "Jun Yu",
      "BaoSheng Yu",
      "Dacheng Tao",
      "Yong Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07275",
    "title": "HiMA: A Fast and Scalable History-based Memory Access Engine for  Differentiable Neural Computer",
    "abstract": "Memory-augmented neural networks (MANNs) provide better inference performance in many tasks with the help of an external memory. The recently developed differentiable neural computer (DNC) is a MANN that has been shown to outperform in representing complicated data structures and learning long-term dependencies. DNC's higher performance is derived from new history-based attention mechanisms in addition to the previously used content-based attention mechanisms. History-based mechanisms require a variety of new compute primitives and state memories, which are not supported by existing neural network (NN) or MANN accelerators. We present HiMA, a tiled, history-based memory access engine with distributed memories in tiles. HiMA incorporates a multi-mode network-on-chip (NoC) to reduce the communication latency and improve scalability. An optimal submatrix-wise memory partition strategy is applied to reduce the amount of NoC traffic; and a two-stage usage sort method leverages distributed tiles to improve computation speed. To make HiMA fundamentally scalable, we create a distributed version of DNC called DNC-D to allow almost all memory operations to be applied to local memories with trainable weighted summation to produce the global memory output. Two approximation techniques, usage skimming and softmax approximation, are proposed to further enhance hardware efficiency. HiMA prototypes are created in RTL and synthesized in a 40nm technology. By simulations, HiMA running DNC and DNC-D demonstrates 6.47x and 39.1x higher speed, 22.8x and 164.3x better area efficiency, and 6.1x and 61.2x better energy efficiency over the state-of-the-art MANN accelerator. Compared to an Nvidia 3080Ti GPU, HiMA demonstrates speedup by up to 437x and 2,646x when running DNC and DNC-D, respectively. ",
    "url": "https://arxiv.org/abs/2202.07275",
    "authors": [
      "Yaoyu Tao",
      "Zhengya Zhang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07278",
    "title": "Worldwide Gender Differences in Public Code Contributions",
    "abstract": "Gender imbalance is a well-known phenomenon observed throughout sciences which is particularly severe in software development and Free/Open Source Software communities. Little is know yet about the geography of this phenomenon in particular when considering large scales for both its time and space dimensions. We contribute to fill this gap with a longitudinal study of the population of contributors to publicly available software source code. We analyze the development history of 160 million software projects for a total of 2.2 billion commits contributed by 43 million distinct authors over a period of 50 years. We classify author names by gender using name frequencies and author geographical locations using heuristics based on email addresses and time zones. We study the evolution over time of contributions to public code by gender and by world region. For the world overall, we confirm previous findings about the low but steadily increasing ratio of contributions by female authors. When breaking down by world regions we find that the long-term growth of female participation is a worldwide phenomenon. We also observe a decrease in the ratio of female participation during the COVID-19 pandemic, suggesting that women's ability to contribute to public code has been more hindered than that of men. ",
    "url": "https://arxiv.org/abs/2202.07278",
    "authors": [
      "Davide Rossi",
      "Stefano Zacchiroli"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2202.07281",
    "title": "Towards Effective Multi-Task Interaction for Entity-Relation Extraction:  A Unified Framework with Selection Recurrent Network",
    "abstract": "Entity-relation extraction aims to jointly solve named entity recognition (NER) and relation extraction (RE). Recent approaches use either one-way sequential information propagation in a pipeline manner or two-way implicit interaction with a shared encoder. However, they still suffer from poor information interaction due to the gap between the different task forms of NER and RE, raising a controversial question whether RE is really beneficial to NER. Motivated by this, we propose a novel and unified cascade framework that combines the advantages of both sequential information propagation and implicit interaction. Meanwhile, it eliminates the gap between the two tasks by reformulating entity-relation extraction as unified span-extraction tasks. Specifically, we propose a selection recurrent network as a shared encoder to encode task-specific independent and shared representations and design two sequential information propagation strategies to realize the sequential information flow between NER and RE. Extensive experiments demonstrate that our approaches can achieve state-of-the-art results on two common benchmarks, ACE05 and SciERC, and effectively model the multi-task interaction, which realizes significant mutual benefits of NER and RE. ",
    "url": "https://arxiv.org/abs/2202.07281",
    "authors": [
      "An Wang",
      "Ao Liu",
      "Hieu Hanh Le",
      "Haruo Yokota"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.07283",
    "title": "A Simple LP-Based Approximation Algorithm for the Matching Augmentation  Problem",
    "abstract": "The Matching Augmentation Problem (MAP) has recently received significant attention as an important step towards better approximation algorithms for finding cheap $2$-edge connected subgraphs. This has culminated in a $\\frac{5}{3}$-approximation algorithm. However, the algorithm and its analysis are fairly involved and do not compare against the problem's well-known LP relaxation called the cut LP. In this paper, we propose a simple algorithm that, guided by an optimal solution to the cut LP, first selects a DFS tree and then finds a solution to MAP by computing an optimum augmentation of this tree. Using properties of extreme point solutions, we show that our algorithm always returns (in polynomial time) a better than $2$-approximation when compared to the cut LP. We thereby also obtain an improved upper bound on the integrality gap of this natural relaxation. ",
    "url": "https://arxiv.org/abs/2202.07283",
    "authors": [
      "Etienne Bamas",
      "Marina Drygala",
      "Ola Svensson"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2202.07301",
    "title": "User-Oriented Robust Reinforcement Learning",
    "abstract": "Recently, improving the robustness of policies across different environments attracts increasing attention in the reinforcement learning (RL) community. Existing robust RL methods mostly aim to achieve the max-min robustness by optimizing the policy's performance in the worst-case environment. However, in practice, a user that uses an RL policy may have different preferences over its performance across environments. Clearly, the aforementioned max-min robustness is oftentimes too conservative to satisfy user preference. Therefore, in this paper, we integrate user preference into policy learning in robust RL, and propose a novel User-Oriented Robust RL (UOR-RL) framework. Specifically, we define a new User-Oriented Robustness (UOR) metric for RL, which allocates different weights to the environments according to user preference and generalizes the max-min robustness metric. To optimize the UOR metric, we develop two different UOR-RL training algorithms for the scenarios with or without a priori known environment distribution, respectively. Theoretically, we prove that our UOR-RL training algorithms converge to near-optimal policies even with inaccurate or completely no knowledge about the environment distribution. Furthermore, we carry out extensive experimental evaluations in 4 MuJoCo tasks. The experimental results demonstrate that UOR-RL is comparable to the state-of-the-art baselines under the average and worst-case performance metrics, and more importantly establishes new state-of-the-art performance under the UOR metric. ",
    "url": "https://arxiv.org/abs/2202.07301",
    "authors": [
      "Haoyi You",
      "Beichen Yu",
      "Haiming Jin",
      "Zhaoxing Yang",
      "Jiahui Sun",
      "Xinbing Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07315",
    "title": "Using Social Media Images for Building Function Classification",
    "abstract": "Urban land use on a building instance level is crucial geo-information for many applications, yet difficult to obtain. An intuitive approach to close this gap is predicting building functions from ground level imagery. Social media image platforms contain billions of images, with a large variety of motifs including but not limited to street perspectives. To cope with this issue this study proposes a filtering pipeline to yield high quality, ground level imagery from large social media image datasets. The pipeline ensures that all resulting images have full and valid geotags with a compass direction to relate image content and spatial objects from maps. We analyze our method on a culturally diverse social media dataset from Flickr with more than 28 million images from 42 cities around the world. The obtained dataset is then evaluated in a context of 3-classes building function classification task. The three building classes that are considered in this study are: commercial, residential, and other. Fine-tuned state-of-the-art architectures yield F1-scores of up to 0.51 on the filtered images. Our analysis shows that the performance is highly limited by the quality of the labels obtained from OpenStreetMap, as the metrics increase by 0.2 if only human validated labels are considered. Therefore, we consider these labels to be weak and publish the resulting images from our pipeline together with the buildings they are showing as a weakly labeled dataset. ",
    "url": "https://arxiv.org/abs/2202.07315",
    "authors": [
      "Eike Jens Hoffmann",
      "Karam Abdulahhad",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07327",
    "title": "Treating Interference as Noise in Cell-Free Massive MIMO Networks",
    "abstract": "How to manage the interference introduced by the enormous wireless devices is a crucial issue to address in the prospective sixth-generation (6G) communications. The treating interference as noise (TIN) optimality conditions are commonly used for interference management and thus attract significant interest in existing wireless systems. Cell-free massive multiple-input multiple-output (CF mMIMO) is a promising technology in 6G that exhibits high system throughput and excellent interference management by exploiting a large number of access points (APs) to serve the users collaboratively. In this paper, we take the first step on studying TIN in CF mMIMO systems from a stochastic geometry perspective by investigating the probability that the TIN conditions hold with spatially distributed network nodes. We propose a novel analytical framework for TIN in a CF mMIMO system with both Binomial Point Process (BPP) and Poisson Point Process (PPP) approximations. We derive the probability that the TIN conditions hold in close form using the PPP approximation. Numerical results validate our derived expressions and illustrate the impact of various system parameters on the probability that the TIN conditions hold. ",
    "url": "https://arxiv.org/abs/2202.07327",
    "authors": [
      "Shuaifei Chen",
      "Jiayi Zhang",
      "Zheng Chen",
      "Bo Ai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.07361",
    "title": "Deep Learning-based Anomaly Detection on X-ray Images of Fuel Cell  Electrodes",
    "abstract": "Anomaly detection in X-ray images has been an active and lasting research area in the last decades, especially in the domain of medical X-ray images. For this work, we created a real-world labeled anomaly dataset, consisting of 16-bit X-ray image data of fuel cell electrodes coated with a platinum catalyst solution and perform anomaly detection on the dataset using a deep learning approach. The dataset contains a diverse set of anomalies with 11 identified common anomalies where the electrodes contain e.g. scratches, bubbles, smudges etc. We experiment with 16-bit image to 8-bit image conversion methods to utilize pre-trained Convolutional Neural Networks as feature extractors (transfer learning) and find that we achieve the best performance by maximizing the contrasts globally across the dataset during the 16-bit to 8-bit conversion, through histogram equalization. We group the fuel cell electrodes with anomalies into a single class called abnormal and the normal fuel cell electrodes into a class called normal, thereby abstracting the anomaly detection problem into a binary classification problem. We achieve a balanced accuracy of 85.18\\%. The anomaly detection is used by the company, Serenergy, for optimizing the time spend on the quality control of the fuel cell electrodes ",
    "url": "https://arxiv.org/abs/2202.07361",
    "authors": [
      "Simon B. Jensen",
      "Thomas B. Moeslund",
      "S\u00f8ren J. Andreasen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2202.07376",
    "title": "Deep-QPP: A Pairwise Interaction-based Deep Learning Model for  Supervised Query Performance Prediction",
    "abstract": "Motivated by the recent success of end-to-end deep neural models for ranking tasks, we present here a supervised end-to-end neural approach for query performance prediction (QPP). In contrast to unsupervised approaches that rely on various statistics of document score distributions, our approach is entirely data-driven. Further, in contrast to weakly supervised approaches, our method also does not rely on the outputs from different QPP estimators. In particular, our model leverages information from the semantic interactions between the terms of a query and those in the top-documents retrieved with it. The architecture of the model comprises multiple layers of 2D convolution filters followed by a feed-forward layer of parameters. Experiments on standard test collections demonstrate that our proposed supervised approach outperforms other state-of-the-art supervised and unsupervised approaches. ",
    "url": "https://arxiv.org/abs/2202.07376",
    "authors": [
      "Suchana Datta",
      "Debasis Ganguly",
      "Derek Greene",
      "Mandar Mitra"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2202.07412",
    "title": "Knowledge Graph Reasoning with Logics and Embeddings: Survey and  Perspective",
    "abstract": "Knowledge graph (KG) reasoning is becoming increasingly popular in both academia and industry. Conventional KG reasoning based on symbolic logic is deterministic, with reasoning results being explainable, while modern embedding-based reasoning can deal with uncertainty and predict plausible knowledge, often with high efficiency via vector computation. A promising direction is to integrate both logic-based and embedding-based methods, with the vision to have advantages of both. It has attracted wide research attention with more and more works published in recent years. In this paper, we comprehensively survey these works, focusing on how logics and embeddings are integrated. We first briefly introduce preliminaries, then systematically categorize and discuss works of logic and embedding-aware KG reasoning from different perspectives, and finally conclude and discuss the challenges and further directions. ",
    "url": "https://arxiv.org/abs/2202.07412",
    "authors": [
      "Wen Zhang",
      "Jiaoyan Chen",
      "Juan Li",
      "Zezhong Xu",
      "Jeff Z. Pan",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.07415",
    "title": "NeuPL: Neural Population Learning",
    "abstract": "Learning in strategy games (e.g. StarCraft, poker) requires the discovery of diverse policies. This is often achieved by iteratively training new policies against existing ones, growing a policy population that is robust to exploit. This iterative approach suffers from two issues in real-world games: a) under finite budget, approximate best-response operators at each iteration needs truncating, resulting in under-trained good-responses populating the population; b) repeated learning of basic skills at each iteration is wasteful and becomes intractable in the presence of increasingly strong opponents. In this work, we propose Neural Population Learning (NeuPL) as a solution to both issues. NeuPL offers convergence guarantees to a population of best-responses under mild assumptions. By representing a population of policies within a single conditional model, NeuPL enables transfer learning across policies. Empirically, we show the generality, improved performance and efficiency of NeuPL across several test domains. Most interestingly, we show that novel strategies become more accessible, not less, as the neural population expands. ",
    "url": "https://arxiv.org/abs/2202.07415",
    "authors": [
      "Siqi Liu",
      "Luke Marris",
      "Daniel Hennes",
      "Josh Merel",
      "Nicolas Heess",
      "Thore Graepel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.07421",
    "title": "Adversarial Attacks and Defense Methods for Power Quality Recognition",
    "abstract": "Vulnerability of various machine learning methods to adversarial examples has been recently explored in the literature. Power systems which use these vulnerable methods face a huge threat against adversarial examples. To this end, we first propose a signal-specific method and a universal signal-agnostic method to attack power systems using generated adversarial examples. Black-box attacks based on transferable characteristics and the above two methods are also proposed and evaluated. We then adopt adversarial training to defend systems against adversarial attacks. Experimental analyses demonstrate that our signal-specific attack method provides less perturbation compared to the FGSM (Fast Gradient Sign Method), and our signal-agnostic attack method can generate perturbations fooling most natural signals with high probability. What's more, the attack method based on the universal signal-agnostic algorithm has a higher transfer rate of black-box attacks than the attack method based on the signal-specific algorithm. In addition, the results show that the proposed adversarial training improves robustness of power systems to adversarial examples. ",
    "url": "https://arxiv.org/abs/2202.07421",
    "authors": [
      "Jiwei Tian",
      "Buhong Wang",
      "Jing Li",
      "Zhen Wang",
      "Mete Ozay"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07427",
    "title": "On the Complementarity of Images and Text for the Expression of Emotions  in Social Media",
    "abstract": "Authors of posts in social media communicate their emotions and what causes them with text and images. While there is work on emotion and stimulus detection for each modality separately, it is yet unknown if the modalities contain complementary emotion information in social media. We aim at filling this research gap and contribute a novel, annotated corpus of English multimodal Reddit posts. On this resource, we develop models to automatically detect the relation between image and text, an emotion stimulus category and the emotion class. We evaluate if these tasks require both modalities and find for the image-text relations, that text alone is sufficient for most categories (complementary, illustrative, opposing): the information in the text allows to predict if an image is required for emotion understanding. The emotions of anger and sadness are best predicted with a multimodal model, while text alone is sufficient for disgust, joy, and surprise. Stimuli depicted by objects, animals, food, or a person are best predicted by image-only models, while multimodal models are most effective on art, events, memes, places, or screenshots. ",
    "url": "https://arxiv.org/abs/2202.07427",
    "authors": [
      "Anna Khlyzova",
      "Carina Silberer",
      "Roman Klinger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.07432",
    "title": "A precortical module for robust CNNs to light variations",
    "abstract": "We present a simple mathematical model for the mammalian low visual pathway, taking into account its key elements: retina, lateral geniculate nucleus (LGN), primary visual cortex (V1). The analogies between the cortical level of the visual system and the structure of popular CNNs, used in image classification tasks, suggests the introduction of an additional preliminary convolutional module inspired to precortical neuronal circuits to improve robustness with respect to global light intensity and contrast variations in the input images. We validate our hypothesis on the popular databases MNIST, FashionMNIST and SVHN, obtaining significantly more robust CNNs with respect to these variations, once such extra module is added. ",
    "url": "https://arxiv.org/abs/2202.07432",
    "authors": [
      "R. Fioresi",
      "J. Petkovic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Differential Geometry (math.DG)"
    ]
  },
  {
    "id": "arXiv:2202.07453",
    "title": "Random Walks for Adversarial Meshes",
    "abstract": "A polygonal mesh is the most-commonly used representation of surfaces in computer graphics; thus, a variety of classification networks have been recently proposed. However, while adversarial attacks are wildly researched in 2D, almost no works on adversarial meshes exist. This paper proposes a novel, unified, and general adversarial attack, which leads to misclassification of numerous state-of-the-art mesh classification neural networks. Our attack approach is black-box, i.e. it has access only to the network's predictions, but not to the network's full architecture or gradients. The key idea is to train a network to imitate a given classification network. This is done by utilizing random walks along the mesh surface, which gather geometric information. These walks provide insight onto the regions of the mesh that are important for the correct prediction of the given classification network. These mesh regions are then modified more than other regions in order to attack the network in a manner that is barely visible to the naked eye. ",
    "url": "https://arxiv.org/abs/2202.07453",
    "authors": [
      "Amir Belder",
      "Gal Yefet",
      "Ran Ben Izhak",
      "Ayellet Tal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07475",
    "title": "A Real-time System for Detecting Landslide Reports on Social Media using  Artificial Intelligence",
    "abstract": "This paper presents an online system that leverages social media data in real time to identify landslide-related information automatically using state-of-the-art artificial intelligence techniques. The designed system can (i) reduce the information overload by eliminating duplicate and irrelevant content, (ii) identify landslide images, (iii) infer geolocation of the images, and (iv) categorize the user type (organization or person) of the account sharing the information. The system was deployed in February 2020 online at https://landslide-aidr.qcri.org/landslide_system.php to monitor live Twitter data stream and has been running continuously since then to provide time-critical information to partners such as British Geological Survey and European Mediterranean Seismological Centre. We trust this system can both contribute to harvesting of global landslide data for further research and support global landslide maps to facilitate emergency response and decision making. ",
    "url": "https://arxiv.org/abs/2202.07475",
    "authors": [
      "Ferda Ofli",
      "Umair Qazi",
      "Muhammad Imran",
      "Julien Roch",
      "Catherine Pennington",
      "Vanessa Banks",
      "Remy Bossu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07476",
    "title": "MGCVAE: Multi-objective Inverse Design via Molecular Graph Conditional  Variational Autoencoder",
    "abstract": "The ultimate goal of various fields is to directly generate molecules with desired properties, such as finding water-soluble molecules in drug development and finding molecules suitable for organic light-emitting diode (OLED) or photosensitizers in the field of development of new organic materials. In this respect, this study proposes a molecular graph generative model based on the autoencoder for de novo design. The performance of molecular graph conditional variational autoencoder (MGCVAE) for generating molecules having specific desired properties is investigated by comparing it to molecular graph variational autoencoder (MGVAE). Furthermore, multi-objective optimization for MGCVAE was applied to satisfy two selected properties simultaneously. In this study, two physical properties -- logP and molar refractivity -- were used as optimization targets for the purpose of designing de novo molecules, especially in drug discovery. As a result, it was confirmed that among generated molecules, 25.89% optimized molecules were generated in MGCVAE compared to 0.66% in MGVAE. Hence, it demonstrates that MGCVAE effectively produced drug-like molecules with two target properties. The results of this study suggest that these graph-based data-driven models are one of the effective methods of designing new molecules that fulfill various physical properties, such as drug discovery. ",
    "url": "https://arxiv.org/abs/2202.07476",
    "authors": [
      "Myeonghun Lee",
      "Kyoungmin Min"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2202.07481",
    "title": "DualConv: Dual Convolutional Kernels for Lightweight Deep Neural  Networks",
    "abstract": "CNN architectures are generally heavy on memory and computational requirements which makes them infeasible for embedded systems with limited hardware resources. We propose dual convolutional kernels (DualConv) for constructing lightweight deep neural networks. DualConv combines 3$\\times$3 and 1$\\times$1 convolutional kernels to process the same input feature map channels simultaneously and exploits the group convolution technique to efficiently arrange convolutional filters. DualConv can be employed in any CNN model such as VGG-16 and ResNet-50 for image classification, YOLO and R-CNN for object detection, or FCN for semantic segmentation. In this paper, we extensively test DualConv for classification since these network architectures form the backbones for many other tasks. We also test DualConv for image detection on YOLO-V3. Experimental results show that, combined with our structural innovations, DualConv significantly reduces the computational cost and number of parameters of deep neural networks while surprisingly achieving slightly higher accuracy than the original models in some cases. We use DualConv to further reduce the number of parameters of the lightweight MobileNetV2 by 54% with only 0.68% drop in accuracy on CIFAR-100 dataset. When the number of parameters is not an issue, DualConv increases the accuracy of MobileNetV1 by 4.11% on the same dataset. Furthermore, DualConv significantly improves the YOLO-V3 object detection speed and improves its accuracy by 4.4% on PASCAL VOC dataset. ",
    "url": "https://arxiv.org/abs/2202.07481",
    "authors": [
      "Jiachen Zhong",
      "Junying Chen",
      "Ajmal Mian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07503",
    "title": "BED: A Real-Time Object Detection System for Edge Devices",
    "abstract": "Deploying machine learning models to edge devices has many real-world applications, especially for the scenarios that demand low latency, low power, or data privacy. However, it requires substantial research and engineering efforts due to the limited computational resources and memory of edge devices. In this demo, we present BED, an object detection system for edge devices practiced on the MAX78000 DNN accelerator. BED integrates on-device DNN inference with a camera and a screen for image acquisition and output exhibition, respectively. Experiment results indicate BED can provide accurate detection with an only 300KB tiny DNN model. ",
    "url": "https://arxiv.org/abs/2202.07503",
    "authors": [
      "Guanchu Wang",
      "Zaid Pervaiz Bhat",
      "Zhimeng Jiang",
      "Yi-Wei Chen",
      "Daochen Zha",
      "Alfredo Costilla Reyes",
      "Afshin Niktash",
      "Gorkem Ulkar",
      "Erman Okman",
      "Xia Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07504",
    "title": "vue4logs -- Automatic Structuring of Heterogeneous Computer System Logs",
    "abstract": "Computer system log data is commonly used in system monitoring, performance characteristic investigation, workflow modeling and anomaly detection. Log data is inherently unstructured or semi-structured, which makes it harder to understand the event flow or other important information of a system by reading raw logs. The process of structuring log files first identifies the log message groups based on the system events that triggered them, and extracts an event template to represent the log messages of each event. This paper introduces a novel method to extract event templates from raw system log files, by using the vector space model commonly used in the field of Information Retrieval to vectorize log data and group log messages into event templates based on their vector similarity. Template extraction process is further enhanced with the use of character and length based filters. When evaluated on publicly available real-world log data benchmarks, this proposed method outperforms all the available state-of-the-art systems in terms of accuracy and robustness. ",
    "url": "https://arxiv.org/abs/2202.07504",
    "authors": [
      "Isuru Boyagane",
      "Oshadha Katulanda",
      "Surangika Ranathunga",
      "Srinath Perera"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2202.07519",
    "title": "Social Science Theories in Software Engineering Research",
    "abstract": "As software engineering research becomes more concerned with the psychological, sociological and managerial aspects of software development, relevant theories from reference disciplines are increasingly important for understanding the field's core phenomena of interest. However, the degree to which software engineering research draws on relevant social sciences remains unclear. This study therefore investigates the use of social science theories in five influential software engineering journals over 13 years. It analyzes not only the extent of theory use but also what, how and where these theories are used. While 87 different theories are used, less than two percent of papers use a social science theory, most theories are used in only one paper, most social sciences are ignored, and the theories are rarely tested for applicability to software engineering contexts. Ignoring relevant social science theories may (1) undermine the community's ability to generate, elaborate and maintain a cumulative body of knowledge; and (2) lead to oversimplified models of software engineering phenomena. More attention to theory is needed for software engineering to mature as a scientific discipline. ",
    "url": "https://arxiv.org/abs/2202.07519",
    "authors": [
      "Tobias Lorey",
      "Paul Ralph",
      "Michael Felderer"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2202.07521",
    "title": "5G Enabled Fault Detection and Diagnostics: How Do We Achieve  Efficiency?",
    "abstract": "The 5th-generation wireless networks (5G) technologies and mobile edge computing (MEC) provide great promises of enabling new capabilities for the industrial Internet of Things. However, the solutions enabled by the 5G ultra-reliable low-latency communication (URLLC) paradigm come with challenges, where URLLC alone does not necessarily guarantee the efficient execution of time-critical fault detection and diagnostics (FDD) applications. Based on the Tennessee Eastman Process model, we propose the concept of the communication-edge-computing (CEC) loop and a system model for evaluating the efficiency of FDD applications. We then formulate an optimization problem for achieving the defined CEC efficiency and discuss some typical solutions to the generic CEC-based FDD services, and propose a new uplink-based communication protocol called \"ReFlexUp\". From the performance analysis and numerical results, the proposed ReFlexUp protocol shows its effectiveness compared to the typical protocols such as Selective Repeat ARQ, HARQ, and \"Occupy CoW\" in terms of the key metrics such as latency, reliability, and efficiency. These results are further convinced from the mmWave-based simulations in a typical 5G MEC-based implementation. ",
    "url": "https://arxiv.org/abs/2202.07521",
    "authors": [
      "Peng Hu",
      "Jinhuan Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.07532",
    "title": "Closing the Management Gap for Satellite-Integrated Community Networks:  A Hierarchical Approach to Self-Maintenance",
    "abstract": "Community networks (CNs) have become an important paradigm for providing essential Internet connectivity in unserved and underserved areas across the world. However, an indispensable part for CNs is network management, where responsive and autonomous maintenance is much needed. With the technological advancement in telecommunications networks, a classical satellite-dependent CN is envisioned to be transformed into a satellite-integrated CN (SICN), which will embrace significant autonomy, intelligence, and scalability in network management. This article discusses the machine-learning (ML) based hierarchical approach to enabling autonomous self-maintenance for SICNs. The approach is split into the anomaly identification and anomaly mitigation phases, where the related ML methods, data collection means, deployment options, and mitigation schemes are presented. With the case study, we discuss a typical scenario using satellite and fixed connections as backhaul options and show the effectiveness \\hl{and performance improvements} of the proposed approach \\hl{with recurrent neural network and ensemble methods ",
    "url": "https://arxiv.org/abs/2202.07532",
    "authors": [
      "Peng Hu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07549",
    "title": "Robust Multi-Objective Bayesian Optimization Under Input Noise",
    "abstract": "Bayesian optimization (BO) is a sample-efficient approach for tuning design parameters to optimize expensive-to-evaluate, black-box performance metrics. In many manufacturing processes, the design parameters are subject to random input noise, resulting in a product that is often less performant than expected. Although BO methods have been proposed for optimizing a single objective under input noise, no existing method addresses the practical scenario where there are multiple objectives that are sensitive to input perturbations. In this work, we propose the first multi-objective BO method that is robust to input noise. We formalize our goal as optimizing the multivariate value-at-risk (MVaR), a risk measure of the uncertain objectives. Since directly optimizing MVaR is computationally infeasible in many settings, we propose a scalable, theoretically-grounded approach for optimizing MVaR using random scalarizations. Empirically, we find that our approach significantly outperforms alternative methods and efficiently identifies optimal robust designs that will satisfy specifications across multiple metrics with high probability. ",
    "url": "https://arxiv.org/abs/2202.07549",
    "authors": [
      "Samuel Daulton",
      "Sait Cakmak",
      "Maximilian Balandat",
      "Michael A. Osborne",
      "Enlu Zhou",
      "Eytan Bakshy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.07554",
    "title": "Between Stochastic and Adversarial Online Convex Optimization: Improved  Regret Bounds via Smoothness",
    "abstract": "Stochastic and adversarial data are two widely studied settings in online learning. But many optimization tasks are neither i.i.d. nor fully adversarial, which makes it of fundamental interest to get a better theoretical understanding of the world between these extremes. In this work we establish novel regret bounds for online convex optimization in a setting that interpolates between stochastic i.i.d. and fully adversarial losses. By exploiting smoothness of the expected losses, these bounds replace a dependence on the maximum gradient length by the variance of the gradients, which was previously known only for linear losses. In addition, they weaken the i.i.d. assumption by allowing adversarially poisoned rounds or shifts in the data distribution. To accomplish this goal, we introduce two key quantities associated with the loss sequence, that we call the cumulative stochastic variance and the adversarial variation. Our upper bounds are attained by instances of optimistic follow the regularized leader, and we design adaptive learning rates that automatically adapt to the cumulative stochastic variance and adversarial variation. In the fully i.i.d. case, our bounds match the rates one would expect from results in stochastic acceleration, and in the fully adversarial case they gracefully deteriorate to match the minimax regret. We further provide lower bounds showing that our regret upper bounds are tight for all intermediate regimes for the cumulative stochastic variance and the adversarial variation. ",
    "url": "https://arxiv.org/abs/2202.07554",
    "authors": [
      "Sarah Sachs",
      "H\u00e9di Hadiji",
      "Tim van Erven",
      "Crist\u00f3bal Guzm\u00e1n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.07568",
    "title": "StratDef: a strategic defense against adversarial attacks in malware  detection",
    "abstract": "Over the years, most research towards defenses against adversarial attacks on machine learning models has been in the image processing domain. The malware detection domain has received less attention despite its importance. Moreover, most work exploring defenses focuses on feature-based, gradient-based or randomized methods but with no strategy when applying them. In this paper, we introduce StratDef, which is a strategic defense system tailored for the malware detection domain based on a Moving Target Defense and Game Theory approach. We overcome challenges related to the systematic construction, selection and strategic use of models to maximize adversarial robustness. StratDef dynamically and strategically chooses the best models to increase the uncertainty for the attacker, whilst minimizing critical aspects in the adversarial ML domain like attack transferability. We provide the first comprehensive evaluation of defenses against adversarial attacks on machine learning for malware detection, where our threat model explores different levels of threat, attacker knowledge, capabilities, and attack intensities. We show that StratDef performs better than other defenses even when facing the peak adversarial threat. We also show that, from the existing defenses, only a few adversarially-trained models provide substantially better protection than just using vanilla models but are still outperformed by StratDef. ",
    "url": "https://arxiv.org/abs/2202.07568",
    "authors": [
      "Aqib Rashid",
      "Jose Such"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07570",
    "title": "ScoreNet: Learning Non-Uniform Attention and Augmentation for  Transformer-Based Histopathological Image Classification",
    "abstract": "Progress in digital pathology is hindered by high-resolution images and the prohibitive cost of exhaustive localized annotations. The commonly used paradigm to categorize pathology images is patch-based processing, which often incorporates multiple instance learning (MIL) to aggregate local patch-level representations yielding image-level prediction. Nonetheless, diagnostically relevant regions may only take a small fraction of the whole tissue, and MIL-based aggregation operation assumes that all patch representations are independent and thus mislays the contextual information from adjacent cell and tissue microenvironments. Consequently, the computational resources dedicated to a specific region are independent of its information contribution. This paper proposes a transformer-based architecture specifically tailored for histopathological image classification, which combines fine-grained local attention with a coarse global attention mechanism to learn meaningful representations of high-resolution images at an efficient computational cost. More importantly, based on the observation above, we propose a novel mixing-based data-augmentation strategy, namely ScoreMix, by leveraging the distribution of the semantic regions of images during the training and carefully guiding the data mixing via sampling the locations of discriminative image content. Thorough experiments and ablation studies on three challenging representative cohorts of Haematoxylin & Eosin (H&E) tumour regions-of-interest (TRoIs) datasets have validated the superiority of our approach over existing state-of-the-art methods and effectiveness of our proposed components, e.g., data augmentation in improving classification performance. We also demonstrate our method's interpretability, robustness, and cross-domain generalization capability. ",
    "url": "https://arxiv.org/abs/2202.07570",
    "authors": [
      "Thomas Stegm\u00fcller",
      "Antoine Spahr",
      "Behzad Bozorgtabar",
      "Jean-Philippe Thiran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07572",
    "title": "On Representation Learning with Feedback",
    "abstract": "This note complements the author's recent paper \"Robust representation learning with feedback for single image deraining\" by providing heuristically theoretical explanations on the mechanism of representation learning with feedback, namely an essential merit of the works presented in this recent article. This note facilitates understanding of key points in the mechanism of representation learning with feedback. ",
    "url": "https://arxiv.org/abs/2202.07572",
    "authors": [
      "Hao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07583",
    "title": "Crypto-ransomware detection using machine learning models in  file-sharing network scenario with encrypted traffic",
    "abstract": "Ransomware is considered as a significant threat for most enterprises since the past few years. In scenarios wherein users can access all files on a shared server, one infected host can lock the access to all shared files. We propose a tool to detect ransomware infection based on file-sharing traffic analysis. The tool monitors the traffic exchanged between the clients and the file servers and using machine learning techniques it searches for patterns in the traffic that betray ransomware actions while reading and overwriting files. The proposal is designed to work for clear text and for encrypted file-sharing protocols. We compare three machine learning models and choose the best for validation. We train and test the detection model using more than 70 ransomware binaries from 26 different strains and more than 2500 hours of not infected traffic from real users. The results reveal that the proposed tool can detect all ransomware binaries, including those not used in training phase (unseen). This paper provides a validation of the algorithm by studying the false positive rate and the amount of information from user files that the ransomware could encrypt before being detected. ",
    "url": "https://arxiv.org/abs/2202.07583",
    "authors": [
      "Eduardo Berrueta",
      "Daniel Morato",
      "Eduardo Maga\u00f1a",
      "Mikel Izal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2202.07586",
    "title": "Deep Generative model with Hierarchical Latent Factors for Time Series  Anomaly Detection",
    "abstract": "Multivariate time series anomaly detection has become an active area of research in recent years, with Deep Learning models outperforming previous approaches on benchmark datasets. Among reconstruction-based models, most previous work has focused on Variational Autoencoders and Generative Adversarial Networks. This work presents DGHL, a new family of generative models for time series anomaly detection, trained by maximizing the observed likelihood by posterior sampling and alternating back-propagation. A top-down Convolution Network maps a novel hierarchical latent space to time series windows, exploiting temporal dynamics to encode information efficiently. Despite relying on posterior sampling, it is computationally more efficient than current approaches, with up to 10x shorter training times than RNN based models. Our method outperformed current state-of-the-art models on four popular benchmark datasets. Finally, DGHL is robust to variable features between entities and accurate even with large proportions of missing values, settings with increasing relevance with the advent of IoT. We demonstrate the superior robustness of DGHL with novel occlusion experiments in this literature. Our code is available at https://github.com/cchallu/dghl. ",
    "url": "https://arxiv.org/abs/2202.07586",
    "authors": [
      "Cristian Challu",
      "Peihong Jiang",
      "Ying Nian Wu",
      "Laurent Callot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07592",
    "title": "Deep Convolutional Autoencoder for Assessment of Anomalies in  Multi-stream Sensor Data",
    "abstract": "A fully convolutional autoencoder is developed for the detection of anomalies in multi-sensor vehicle drive-cycle data from the powertrain domain. Preliminary results collected on real-world powertrain data show that the reconstruction error of faulty drive cycles deviates significantly relative to the reconstruction of healthy drive cycles using the trained autoencoder. The results demonstrate applicability for identifying faulty drive-cycles, and for improving the accuracy of system prognosis and predictive maintenance in connected vehicles. ",
    "url": "https://arxiv.org/abs/2202.07592",
    "authors": [
      "Anthony Geglio",
      "Eisa Hedayati",
      "Mark Tascillo",
      "Dyche Anderson",
      "Jonathan Barker",
      "Timothy C. Havens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2202.07606",
    "title": "Improving Pedestrian Prediction Models with Self-Supervised Continual  Learning",
    "abstract": "Autonomous mobile robots require accurate human motion predictions to safely and efficiently navigate among pedestrians, whose behavior may adapt to environmental changes. This paper introduces a self-supervised continual learning framework to improve data-driven pedestrian prediction models online across various scenarios continuously. In particular, we exploit online streams of pedestrian data, commonly available from the robot's detection and tracking pipeline, to refine the prediction model and its performance in unseen scenarios. To avoid the forgetting of previously learned concepts, a problem known as catastrophic forgetting, our framework includes a regularization loss to penalize changes of model parameters that are important for previous scenarios and retrains on a set of previous examples to retain past knowledge. Experimental results on real and simulation data show that our approach can improve prediction performance in unseen scenarios while retaining knowledge from seen scenarios when compared to naively training the prediction model online. ",
    "url": "https://arxiv.org/abs/2202.07606",
    "authors": [
      "Luzia Knoedler",
      "Chadi Salmi",
      "Hai Zhu",
      "Bruno Brito",
      "Javier Alonso-Mora"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.07612",
    "title": "CodeGen-Test: An Automatic Code Generation Model Integrating Program  Test Information",
    "abstract": "Automatic code generation is to generate the program code according to the given natural language description. The current mainstream approach uses neural networks to encode natural language descriptions, and output abstract syntax trees (AST) at the decoder, then convert the AST into program code. While the generated code largely conforms to specific syntax rules, two problems are still ignored. One is missing program testing, an essential step in the process of complete code implementation; the other is only focusing on the syntax compliance of the generated code, while ignoring the more important program functional requirements. The paper proposes a CodeGen-Test model, which adds program testing steps and incorporates program testing information to iteratively generate code that meets the functional requirements of the program, thereby improving the quality of code generation. At the same time, the paper proposes a new evaluation metric, test accuracy (Test-Acc), which represents the proportion of passing program test in generated code. Different from the previous evaluation metric, which only evaluates the quality of code generation from the perspective of character similarity, the Test-Acc can evaluate the quality of code generation from the Program functions. Moreover, the paper evaluates the CodeGen-test model on a python data set \"hearthstone legend\". The experimental results show the proposed method can effectively improve the quality of generated code. Compared with the existing optimal model, CodeGen-Test model improves the Bleu value by 0.2%, Rouge-L value by 0.3% and Test-Acc by 6%. ",
    "url": "https://arxiv.org/abs/2202.07612",
    "authors": [
      "Maosheng Zhong",
      "Gen Liu",
      "Hongwei Li",
      "Jiangling Kuang",
      "Jinshan Zeng",
      "Mingwen Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2202.07615",
    "title": "PILED: An Identify-and-Localize Framework for Few-Shot Event Detection",
    "abstract": "Practical applications of event extraction systems have long been hindered by their need for heavy human annotation. In order to scale up to new domains and event types, models must learn to cope with limited supervision, as in few-shot learning settings. To this end, the major challenge is to let the model master the semantics of event types, without requiring abundant event mention annotations. In our study, we employ cloze prompts to elicit event-related knowledge from pretrained language models and further use event definitions and keywords to pinpoint the trigger word. By formulating the event detection task as an identify-then-localize procedure, we minimize the number of type-specific parameters, enabling our model to quickly adapt to event detection tasks for new types. Experiments on three event detection benchmark datasets (ACE, FewEvent, MAVEN) show that our proposed method performs favorably under fully supervised settings and surpasses existing few-shot methods by 21% F1 on the FewEvent dataset and 20% on the MAVEN dataset when only 5 examples are provided for each event type. ",
    "url": "https://arxiv.org/abs/2202.07615",
    "authors": [
      "Sha Li",
      "Liyuan Liu",
      "Yiqing Xie",
      "Heng Ji",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.07623",
    "title": "Defending against Reconstruction Attacks with R\u00e9nyi Differential  Privacy",
    "abstract": "Reconstruction attacks allow an adversary to regenerate data samples of the training set using access to only a trained model. It has been recently shown that simple heuristics can reconstruct data samples from language models, making this threat scenario an important aspect of model release. Differential privacy is a known solution to such attacks, but is often used with a relatively large privacy budget (epsilon > 8) which does not translate to meaningful guarantees. In this paper we show that, for a same mechanism, we can derive privacy guarantees for reconstruction attacks that are better than the traditional ones from the literature. In particular, we show that larger privacy budgets do not protect against membership inference, but can still protect extraction of rare secrets. We show experimentally that our guarantees hold against various language models, including GPT-2 finetuned on Wikitext-103. ",
    "url": "https://arxiv.org/abs/2202.07623",
    "authors": [
      "Pierre Stock",
      "Igor Shilov",
      "Ilya Mironov",
      "Alexandre Sablayrolles"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.07626",
    "title": "Random Feature Amplification: Feature Learning and Generalization in  Neural Networks",
    "abstract": "In this work, we provide a characterization of the feature-learning process in two-layer ReLU networks trained by gradient descent on the logistic loss following random initialization. We consider data with binary labels that are generated by an XOR-like function of the input features. We permit a constant fraction of the training labels to be corrupted by an adversary. We show that, although linear classifiers are no better than random guessing for the distribution we consider, two-layer ReLU networks trained by gradient descent achieve generalization error close to the label noise rate, refuting the conjecture of Malach and Shalev-Shwartz that 'deeper is better only when shallow is good'. We develop a novel proof technique that shows that at initialization, the vast majority of neurons function as random features that are only weakly correlated with useful features, and the gradient descent dynamics 'amplify' these weak, random features to strong, useful features. ",
    "url": "https://arxiv.org/abs/2202.07626",
    "authors": [
      "Spencer Frei",
      "Niladri S. Chatterji",
      "Peter L. Bartlett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.07632",
    "title": "Wireless Resource Management in Intelligent Semantic Communication  Networks",
    "abstract": "The prosperity of artificial intelligence (AI) has laid a promising paradigm of communication system, i.e., intelligent semantic communication (ISC), where semantic contents, instead of traditional bit sequences, are coded by AI models for efficient communication. Due to the unique demand of background knowledge for semantic recovery, wireless resource management faces new challenges in ISC. In this paper, we address the user association (UA) and bandwidth allocation (BA) problems in an ISC-enabled heterogeneous network (ISC-HetNet). We first introduce the auxiliary knowledge base (KB) into the system model, and develop a new performance metric for the ISC-HetNet, named system throughput in message (STM). Joint optimization of UA and BA is then formulated with the aim of STM maximization subject to KB matching and wireless bandwidth constraints. To this end, we propose a two-stage solution, including a stochastic programming method in the first stage to obtain a deterministic objective with semantic confidence, and a heuristic algorithm in the second stage to reach the optimality of UA and BA. Numerical results show great superiority and reliability of our proposed solution on the STM performance when compared with two baseline algorithms. ",
    "url": "https://arxiv.org/abs/2202.07632",
    "authors": [
      "Le Xia",
      "Yao Sun",
      "Xiaoqian Li",
      "Gang Feng",
      "Muhammad Ali Imran"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.07638",
    "title": "On the design of scalable networks to reject polynomial disturbances",
    "abstract": "This paper is concerned with the problem of designing distributed control protocols for network systems affected by delays and disturbances consisting of a polynomial component and a residual signal. We propose the use of a multiplex architecture to design distributed control protocols to reject polynomial disturbances up to ramps and guarantee a scalability property that prohibits the amplification of residual disturbances. For this architecture, we give a delay-independent sufficient condition on the control protocols to guarantee scalability and ramps rejection. The effectiveness of the result, which can be used to study networks of nonlinearly coupled nonlinear agents, is illustrated via a robot formation control problem. ",
    "url": "https://arxiv.org/abs/2202.07638",
    "authors": [
      "Shihao Xie",
      "Giovanni Russo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.07643",
    "title": "Lie Point Symmetry Data Augmentation for Neural PDE Solvers",
    "abstract": "Neural networks are increasingly being used to solve partial differential equations (PDEs), replacing slower numerical solvers. However, a critical issue is that neural PDE solvers require high-quality ground truth data, which usually must come from the very solvers they are designed to replace. Thus, we are presented with a proverbial chicken-and-egg problem. In this paper, we present a method, which can partially alleviate this problem, by improving neural PDE solver sample complexity -- Lie point symmetry data augmentation (LPSDA). In the context of PDEs, it turns out that we are able to quantitatively derive an exhaustive list of data transformations, based on the Lie point symmetry group of the PDEs in question, something not possible in other application areas. We present this framework and demonstrate how it can easily be deployed to improve neural PDE solver sample complexity by an order of magnitude. ",
    "url": "https://arxiv.org/abs/2202.07643",
    "authors": [
      "Johannes Brandstetter",
      "Max Welling",
      "Daniel E. Worrall"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07646",
    "title": "Quantifying Memorization Across Neural Language Models",
    "abstract": "Large language models (LMs) have been shown to memorize parts of their training data, and when prompted appropriately, they will emit the memorized training data verbatim. This is undesirable because memorization violates privacy (exposing user data), degrades utility (repeated easy-to-memorize text is often low quality), and hurts fairness (some texts are memorized over others). We describe three log-linear relationships that quantify the degree to which LMs emit memorized training data. Memorization significantly grows as we increase (1) the capacity of a model, (2) the number of times an example has been duplicated, and (3) the number of tokens of context used to prompt the model. Surprisingly, we find the situation becomes complicated when generalizing these results across model families. On the whole, we find that memorization in LMs is more prevalent than previously believed and will likely get worse as models continues to scale, at least without active mitigations. ",
    "url": "https://arxiv.org/abs/2202.07646",
    "authors": [
      "Nicholas Carlini",
      "Daphne Ippolito",
      "Matthew Jagielski",
      "Katherine Lee",
      "Florian Tramer",
      "Chiyuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.07648",
    "title": "EvoKG: Jointly Modeling Event Time and Network Structure for Reasoning  over Temporal Knowledge Graphs",
    "abstract": "How can we perform knowledge reasoning over temporal knowledge graphs (TKGs)? TKGs represent facts about entities and their relations, where each fact is associated with a timestamp. Reasoning over TKGs, i.e., inferring new facts from time-evolving KGs, is crucial for many applications to provide intelligent services. However, despite the prevalence of real-world data that can be represented as TKGs, most methods focus on reasoning over static knowledge graphs, or cannot predict future events. In this paper, we present a problem formulation that unifies the two major problems that need to be addressed for an effective reasoning over TKGs, namely, modeling the event time and the evolving network structure. Our proposed method EvoKG jointly models both tasks in an effective framework, which captures the ever-changing structural and temporal dynamics in TKGs via recurrent event modeling, and models the interactions between entities based on the temporal neighborhood aggregation framework. Further, EvoKG achieves an accurate modeling of event time, using flexible and efficient mechanisms based on neural density estimation. Experiments show that EvoKG outperforms existing methods in terms of effectiveness (up to 77% and 116% more accurate time and link prediction) and efficiency. ",
    "url": "https://arxiv.org/abs/2202.07648",
    "authors": [
      "Namyong Park",
      "Fuchen Liu",
      "Purvanshi Mehta",
      "Dana Cristofor",
      "Christos Faloutsos",
      "Yuxiao Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2202.07650",
    "title": "Conformal Prediction Sets with Limited False Positives",
    "abstract": "We develop a new approach to multi-label conformal prediction in which we aim to output a precise set of promising prediction candidates with a bounded number of incorrect answers. Standard conformal prediction provides the ability to adapt to model uncertainty by constructing a calibrated candidate set in place of a single prediction, with guarantees that the set contains the correct answer with high probability. In order to obey this coverage property, however, conformal sets can become inundated with noisy candidates -- which can render them unhelpful in practice. This is particularly relevant to practical applications where there is a limited budget, and the cost (monetary or otherwise) associated with false positives is non-negligible. We propose to trade coverage for a notion of precision by enforcing that the presence of incorrect candidates in the predicted conformal sets (i.e., the total number of false positives) is bounded according to a user-specified tolerance. Subject to this constraint, our algorithm then optimizes for a generalized notion of set coverage (i.e., the true positive rate) that allows for any number of true answers for a given query (including zero). We demonstrate the effectiveness of this approach across a number of classification tasks in natural language processing, computer vision, and computational chemistry. ",
    "url": "https://arxiv.org/abs/2202.07650",
    "authors": [
      "Adam Fisch",
      "Tal Schuster",
      "Tommi Jaakkola",
      "Regina Barzilay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06804",
    "title": "Flexible learning of quantum states with generative query neural  networks",
    "abstract": "Deep neural networks are a powerful tool for characterizing quantum states. In this task, neural networks are typically trained with measurement data gathered from the quantum state to be characterized. But is it possible to train a neural network in a general-purpose way, which makes it applicable to multiple unknown quantum states? Here we show that learning across multiple quantum states and different measurement settings can be achieved by a generative query neural network, a type of neural network originally used in the classical domain for learning 3D scenes from 2D pictures. Our network can be trained offline with classically simulated data, and later be used to characterize unknown quantum states from real experimental data. With little guidance of quantum physics, the network builds its own data-driven representation of quantum states, and then uses it to predict the outcome probabilities of requested quantum measurements on the states of interest. This approach can be applied to state learning scenarios where quantum measurement settings are not informationally complete and predictions must be given in real time, as experimental data become available, as well as to adversarial scenarios where measurement choices and prediction requests are designed to expose learning inaccuracies. The internal representation produced by the network can be used for other tasks beyond state characterization, including clustering of states and prediction of physical properties. The features of our method are illustrated on many-qubit ground states of Ising model and continuous-variable non-Gaussian states. ",
    "url": "https://arxiv.org/abs/2202.06804",
    "authors": [
      "Yan Zhu",
      "Ya-Dong Wu",
      "Ge Bai",
      "Yuexuan Wang",
      "Giulio Chiribella"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06996",
    "title": "Unlabeled Data Help: Minimax Analysis and Adversarial Robustness",
    "abstract": "The recent proposed self-supervised learning (SSL) approaches successfully demonstrate the great potential of supplementing learning algorithms with additional unlabeled data. However, it is still unclear whether the existing SSL algorithms can fully utilize the information of both labelled and unlabeled data. This paper gives an affirmative answer for the reconstruction-based SSL algorithm \\citep{lee2020predicting} under several statistical models. While existing literature only focuses on establishing the upper bound of the convergence rate, we provide a rigorous minimax analysis, and successfully justify the rate-optimality of the reconstruction-based SSL algorithm under different data generation models. Furthermore, we incorporate the reconstruction-based SSL into the existing adversarial training algorithms and show that learning from unlabeled data helps improve the robustness. ",
    "url": "https://arxiv.org/abs/2202.06996",
    "authors": [
      "Yue Xing",
      "Qifan Song",
      "Guang Cheng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07001",
    "title": "Handcrafted Histological Transformer (H2T): Unsupervised Representation  of Whole Slide Images",
    "abstract": "Diagnostic, prognostic and therapeutic decision-making of cancer in pathology clinics can now be carried out based on analysis of multi-gigapixel tissue images, also known as whole-slide images (WSIs). Recently, deep convolutional neural networks (CNNs) have been proposed to derive unsupervised WSI representations; these are attractive as they rely less on expert annotation which is cumbersome. However, a major trade-off is that higher predictive power generally comes at the cost of interpretability, posing a challenge to their clinical use where transparency in decision-making is generally expected. To address this challenge, we present a handcrafted framework based on deep CNN for constructing holistic WSI-level representations. Building on recent findings about the internal working of the Transformer in the domain of natural language processing, we break down its processes and handcraft them into a more transparent framework that we term as the Handcrafted Histological Transformer or H2T. Based on our experiments involving various datasets consisting of a total of 5,306 WSIs, the results demonstrate that H2T based holistic WSI-level representations offer competitive performance compared to recent state-of-the-art methods and can be readily utilized for various downstream analysis tasks. Finally, our results demonstrate that the H2T framework can be up to 14 times faster than the Transformer models. ",
    "url": "https://arxiv.org/abs/2202.07001",
    "authors": [
      "Quoc Dang Vu",
      "Kashif Rajpoot",
      "Shan E Ahmed Raza",
      "Nasir Rajpoot"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07022",
    "title": "Recurrent Neural Networks for Dynamical Systems: Applications to  Ordinary Differential Equations, Collective Motion, and Hydrological Modeling",
    "abstract": "Classical methods of solving spatiotemporal dynamical systems include statistical approaches such as autoregressive integrated moving average, which assume linear and stationary relationships between systems' previous outputs. Development and implementation of linear methods are relatively simple, but they often do not capture non-linear relationships in the data. Thus, artificial neural networks (ANNs) are receiving attention from researchers in analyzing and forecasting dynamical systems. Recurrent neural networks (RNN), derived from feed-forward ANNs, use internal memory to process variable-length sequences of inputs. This allows RNNs to applicable for finding solutions for a vast variety of problems in spatiotemporal dynamical systems. Thus, in this paper, we utilize RNNs to treat some specific issues associated with dynamical systems. Specifically, we analyze the performance of RNNs applied to three tasks: reconstruction of correct Lorenz solutions for a system with a formulation error, reconstruction of corrupted collective motion trajectories, and forecasting of streamflow time series possessing spikes, representing three fields, namely, ordinary differential equations, collective motion, and hydrological modeling, respectively. We train and test RNNs uniquely in each task to demonstrate the broad applicability of RNNs in reconstruction and forecasting the dynamics of dynamical systems. ",
    "url": "https://arxiv.org/abs/2202.07022",
    "authors": [
      "Yonggi Park",
      "Kelum Gajamannage",
      "Dilhani I. Jayathilake",
      "Erik M. Bollt"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2202.07035",
    "title": "Testing the Tools of Systems Neuroscience on Artificial Neural Networks",
    "abstract": "Neuroscientists apply a range of common analysis tools to recorded neural activity in order to glean insights into how neural circuits implement computations. Despite the fact that these tools shape the progress of the field as a whole, we have little empirical evidence that they are effective at quickly identifying the phenomena of interest. Here I argue that these tools should be explicitly tested and that artificial neural networks (ANNs) are an appropriate testing grounds for them. The recent resurgence of the use of ANNs as models of everything from perception to memory to motor control stems from a rough similarity between artificial and biological neural networks and the ability to train these networks to perform complex high-dimensional tasks. These properties, combined with the ability to perfectly observe and manipulate these systems, makes them well-suited for vetting the tools of systems and cognitive neuroscience. I provide here both a roadmap for performing this testing and a list of tools that are suitable to be tested on ANNs. Using ANNs to reflect on the extent to which these tools provide a productive understanding of neural systems -- and on exactly what understanding should mean here -- has the potential to expedite progress in the study of the brain. ",
    "url": "https://arxiv.org/abs/2202.07035",
    "authors": [
      "Grace W. Lindsay"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2202.07107",
    "title": "Gaze-Guided Class Activation Mapping: Leveraging Human Attention for  Network Attention in Chest X-rays Classification",
    "abstract": "The increased availability and accuracy of eye-gaze tracking technology has sparked attention-related research in psychology, neuroscience, and, more recently, computer vision and artificial intelligence. The attention mechanism in artificial neural networks is known to improve learning tasks. However, no previous research has combined the network attention and human attention. This paper describes a gaze-guided class activation mapping (GG-CAM) method to directly regulate the formation of network attention based on expert radiologists' visual attention for the chest X-ray pathology classification problem, which remains challenging due to the complex and often nuanced differences among images. GG-CAM is a lightweight ($3$ additional trainable parameters for regulating the learning process) and generic extension that can be easily applied to most classification convolutional neural networks (CNN). GG-CAM-modified CNNs do not require human attention as an input when fully trained. Comparative experiments suggest that two standard CNNs with the GG-CAM extension achieve significantly greater classification performance. The median area under the curve (AUC) metrics for ResNet50 increases from $0.721$ to $0.776$. For EfficientNetv2 (s), the median AUC increases from $0.723$ to $0.801$. The GG-CAM also brings better interpretability of the network that facilitates the weakly-supervised pathology localization and analysis. ",
    "url": "https://arxiv.org/abs/2202.07107",
    "authors": [
      "Hongzhi Zhu",
      "Septimiu Salcudean",
      "Robert Rohling"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07118",
    "title": "Multi-task UNet: Jointly Boosting Saliency Prediction and Disease  Classification on Chest X-ray Images",
    "abstract": "Human visual attention has recently shown its distinct capability in boosting machine learning models. However, studies that aim to facilitate medical tasks with human visual attention are still scarce. To support the use of visual attention, this paper describes a novel deep learning model for visual saliency prediction on chest X-ray (CXR) images. To cope with data deficiency, we exploit the multi-task learning method and tackles disease classification on CXR simultaneously. For a more robust training process, we propose a further optimized multi-task learning scheme to better handle model overfitting. Experiments show our proposed deep learning model with our new learning scheme can outperform existing methods dedicated either for saliency prediction or image classification. The code used in this paper is available at https://github.com/hz-zhu/MT-UNet. ",
    "url": "https://arxiv.org/abs/2202.07118",
    "authors": [
      "Hongzhi Zhu",
      "Robert Rohling",
      "Septimiu Salcudean"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07173",
    "title": "To what extent can Plug-and-Play methods outperform neural networks  alone in low-dose CT reconstruction",
    "abstract": "The Plug-and-Play (PnP) framework was recently introduced for low-dose CT reconstruction to leverage the interpretability and the flexibility of model-based methods to incorporate various plugins, such as trained deep learning (DL) neural networks. However, the benefits of PnP vs. state-of-the-art DL methods have not been clearly demonstrated. In this work, we proposed an improved PnP framework to address the previous limitations and develop clinical-relevant segmentation metrics for quantitative result assessment. Compared with the DL alone methods, our proposed PnP framework was slightly inferior in MSE and PSNR. However, the power spectrum of the resulting images better matched that of full-dose images than that of DL denoised images. The resulting images supported higher accuracy in airway segmentation than DL denoised images for all the ten patients in the test set, more substantially on the airways with a cross-section smaller than 0.61cm$^2$, and outperformed the DL denoised images for 45 out of 50 lung lobes in lobar segmentation. Our PnP method proved to be significantly better at preserving the image texture, which translated to task-specific benefits in automated structure segmentation and detection. ",
    "url": "https://arxiv.org/abs/2202.07173",
    "authors": [
      "Qifan Xu",
      "Qihui Lyu",
      "Dan Ruan",
      "Ke Sheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07254",
    "title": "REPID: Regional Effect Plots with implicit Interaction Detection",
    "abstract": "Machine learning models can automatically learn complex relationships, such as non-linear and interaction effects. Interpretable machine learning methods such as partial dependence plots visualize marginal feature effects but may lead to misleading interpretations when feature interactions are present. Hence, employing additional methods that can detect and measure the strength of interactions is paramount to better understand the inner workings of machine learning models. We demonstrate several drawbacks of existing global interaction detection approaches, characterize them theoretically, and evaluate them empirically. Furthermore, we introduce regional effect plots with implicit interaction detection, a novel framework to detect interactions between a feature of interest and other features. The framework also quantifies the strength of interactions and provides interpretable and distinct regions in which feature effects can be interpreted more reliably, as they are less confounded by interactions. We prove the theoretical eligibility of our method and show its applicability on various simulation and real-world examples. ",
    "url": "https://arxiv.org/abs/2202.07254",
    "authors": [
      "Julia Herbinger",
      "Bernd Bischl",
      "Giuseppe Casalicchio"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07290",
    "title": "Don't stop the training: continuously-updating self-supervised  algorithms best account for auditory responses in the cortex",
    "abstract": "Over the last decade, numerous studies have shown that deep neural networks exhibit sensory representations similar to those of the mammalian brain, in that their activations linearly map onto cortical responses to the same sensory inputs. However, it remains unknown whether these artificial networks also learn like the brain. To address this issue, we analyze the brain responses of two ferret auditory cortices recorded with functional UltraSound imaging (fUS), while the animals were presented with 320 10\\,s sounds. We compare these brain responses to the activations of Wav2vec 2.0, a self-supervised neural network pretrained with 960\\,h of speech, and input with the same 320 sounds. Critically, we evaluate Wav2vec 2.0 under two distinct modes: (i) \"Pretrained\", where the same model is used for all sounds, and (ii) \"Continuous Update\", where the weights of the pretrained model are modified with back-propagation after every sound, presented in the same order as the ferrets. Our results show that the Continuous-Update mode leads Wav2Vec 2.0 to generate activations that are more similar to the brain than a Pretrained Wav2Vec 2.0 or than other control models using different training modes. These results suggest that the trial-by-trial modifications of self-supervised algorithms induced by back-propagation aligns with the corresponding fluctuations of cortical responses to sounds. Our finding thus provides empirical evidence of a common learning mechanism between self-supervised models and the mammalian cortex during sound processing. ",
    "url": "https://arxiv.org/abs/2202.07290",
    "authors": [
      "Pierre Orhan",
      "Yves Boubenec",
      "Jean-R\u00e9mi King"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07423",
    "title": "DeepPAMM: Deep Piecewise Exponential Additive Mixed Models for Complex  Hazard Structures in Survival Analysis",
    "abstract": "Survival analysis (SA) is an active field of research that is concerned with time-to-event outcomes and is prevalent in many domains, particularly biomedical applications. Despite its importance, SA remains challenging due to small-scale data sets and complex outcome distributions, concealed by truncation and censoring processes. The piecewise exponential additive mixed model (PAMM) is a model class addressing many of these challenges, yet PAMMs are not applicable in high-dimensional feature settings or in the case of unstructured or multimodal data. We unify existing approaches by proposing DeepPAMM, a versatile deep learning framework that is well-founded from a statistical point of view, yet with enough flexibility for modeling complex hazard structures. We illustrate that DeepPAMM is competitive with other machine learning approaches with respect to predictive performance while maintaining interpretability through benchmark experiments and an extended case study. ",
    "url": "https://arxiv.org/abs/2202.07423",
    "authors": [
      "Philipp Kopper",
      "Simon Wiegrebe",
      "Bernd Bischl",
      "Andreas Bender",
      "David R\u00fcgamer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07425",
    "title": "Algebraic function based Banach space valued ordinary and fractional  neural network approximations",
    "abstract": "Here we research the univariate quantitative approximation, ordinary and fractional, of Banach space valued continuous functions on a compact interval or all the real line by quasi-interpolation Banach space valued neural network operators. These approximations are derived by establishing Jackson type inequalities involving the modulus of continuity of the engaged function or its Banach space valued high order derivative of fractional derivatives. Our operators are defined by using a density function generated by an algebraic sigmoid function. The approximations are pointwise and of the uniform norm. The related Banach space valued feed-forward neural networks are with one hidden layer. ",
    "url": "https://arxiv.org/abs/2202.07425",
    "authors": [
      "George A Anastassiou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Classical Analysis and ODEs (math.CA)"
    ]
  },
  {
    "id": "arXiv:2202.07506",
    "title": "Confidence Threshold Neural Diving",
    "abstract": "Finding a better feasible solution in a shorter time is an integral part of solving Mixed Integer Programs. We present a post-hoc method based on Neural Diving to build heuristics more flexibly. We hypothesize that variables with higher confidence scores are more definite to be included in the optimal solution. For our hypothesis, we provide empirical evidence that confidence threshold technique produces partial solutions leading to final solutions with better primal objective values. Our method won 2nd place in the primal task on the NeurIPS 2021 ML4CO competition. Also, our method shows the best score among other learning-based methods in the competition. ",
    "url": "https://arxiv.org/abs/2202.07506",
    "authors": [
      "Taehyun Yoon"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2202.07550",
    "title": "Label fusion and training methods for reliable representation of  inter-rater uncertainty",
    "abstract": "Medical tasks are prone to inter-rater variability due to multiple factors such as image quality, professional experience and training, or guideline clarity. Training deep learning networks with annotations from multiple raters is a common practice that mitigates the model's bias towards a single expert. Reliable models generating calibrated outputs and reflecting the inter-rater disagreement are key to the integration of artificial intelligence in clinical practice. Various methods exist to take into account different expert labels. We focus on comparing three label fusion methods: STAPLE, average of the rater's segmentation, and random sampling each rater's segmentation during training. Each label fusion method is studied using the conventional training framework or the recently published SoftSeg framework that limits information loss by treating the segmentation task as a regression. Our results, across 10 data splittings on two public datasets, indicate that SoftSeg models, regardless of the ground truth fusion method, had better calibration and preservation of the inter-rater rater variability compared with their conventional counterparts without impacting the segmentation performance. Conventional models, i.e., trained with a Dice loss, with binary inputs, and sigmoid/softmax final activate, were overconfident and underestimated the uncertainty associated with inter-rater variability. Conversely, fusing labels by averaging with the SoftSeg framework led to underconfident outputs and overestimation of the rater disagreement. In terms of segmentation performance, the best label fusion method was different for the two datasets studied, indicating this parameter might be task-dependent. However, SoftSeg had segmentation performance systematically superior or equal to the conventionally trained models and had the best calibration and preservation of the inter-rater variability. ",
    "url": "https://arxiv.org/abs/2202.07550",
    "authors": [
      "Andreanne Lemay",
      "Charley Gros",
      "Julien Cohen-Adad"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07575",
    "title": "Forecasting Global Weather with Graph Neural Networks",
    "abstract": "We present a data-driven approach for forecasting global weather using graph neural networks. The system learns to step forward the current 3D atmospheric state by six hours, and multiple steps are chained together to produce skillful forecasts going out several days into the future. The underlying model is trained on reanalysis data from ERA5 or forecast data from GFS. Test performance on metrics such as Z500 (geopotential height) and T850 (temperature) improves upon previous data-driven approaches and is comparable to operational, full-resolution, physical models from GFS and ECMWF, at least when evaluated on 1-degree scales and when using reanalysis initial conditions. We also show results from connecting this data-driven model to live, operational forecasts from GFS. ",
    "url": "https://arxiv.org/abs/2202.07575",
    "authors": [
      "Ryan Keisler"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07608",
    "title": "Graphs of bounded twin-width are quasi-polynomially $\u03c7$-bounded",
    "abstract": "We prove that for every $t\\in \\mathbb{N}$ there is a constant $\\gamma_t$ such that every graph with twin-width at most $t$ and clique number $\\omega$ has chromatic number bounded by $2^{\\gamma_t \\log^{4t+3} \\omega}$. In other words, we prove that graph classes of bounded twin-width are quasi-polynomially $\\chi$-bounded. This provides a significant step towards resolving the question of Bonnet et al. [ICALP 2021] about whether they are polynomially $\\chi$-bounded. ",
    "url": "https://arxiv.org/abs/2202.07608",
    "authors": [
      "Micha\u0142 Pilipczuk",
      "Marek Soko\u0142owski"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:1609.02000",
    "title": "Cybernetic Cities: Designing and controlling adaptive and robust urban  systems",
    "abstract": " Title: Cybernetic Cities: Designing and controlling adaptive and robust urban  systems ",
    "url": "https://arxiv.org/abs/1609.02000",
    "authors": [
      "Carlos Gershenson",
      "Paolo Santi",
      "Carlo Ratti"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2004.01079",
    "title": "Understanding Linearity of Cross-Lingual Word Embedding Mappings",
    "abstract": " Title: Understanding Linearity of Cross-Lingual Word Embedding Mappings ",
    "url": "https://arxiv.org/abs/2004.01079",
    "authors": [
      "Xutan Peng",
      "Mark Stevenson",
      "Chenghua Lin",
      "Chen Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2005.12419",
    "title": "Network Comparison with Interpretable Contrastive Network Representation  Learning",
    "abstract": " Comments: To appear in Journal of Data Science, Statistics, and Visualisation. The previous preprint version was titled \"Interpretable Contrastive Learning for Networks\" (arXiv:2005.12419v1) ",
    "url": "https://arxiv.org/abs/2005.12419",
    "authors": [
      "Takanori Fujiwara",
      "Jian Zhao",
      "Francine Chen",
      "Yaoliang Yu",
      "Kwan-Liu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2006.07540",
    "title": "MetaPerturb: Transferable Regularizer for Heterogeneous Tasks and  Architectures",
    "abstract": " Title: MetaPerturb: Transferable Regularizer for Heterogeneous Tasks and  Architectures ",
    "url": "https://arxiv.org/abs/2006.07540",
    "authors": [
      "Jeongun Ryu",
      "Jaewoong Shin",
      "Hae Beom Lee",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2102.05082",
    "title": "Domain Invariant Representation Learning with Domain Density  Transformations",
    "abstract": " Comments: NeurIPS 2021 ",
    "url": "https://arxiv.org/abs/2102.05082",
    "authors": [
      "A. Tuan Nguyen",
      "Toan Tran",
      "Yarin Gal",
      "At\u0131l\u0131m G\u00fcne\u015f Baydin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.03036",
    "title": "A Survey on Graph Structure Learning: Progress and Opportunities",
    "abstract": " Comments: Work in progress, in submission to IJCAI 2022 (Survey Track) ",
    "url": "https://arxiv.org/abs/2103.03036",
    "authors": [
      "Yanqiao Zhu",
      "Weizhi Xu",
      "Jinghao Zhang",
      "Yuanqi Du",
      "Jieyu Zhang",
      "Qiang Liu",
      "Carl Yang",
      "Shu Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2104.11725",
    "title": "SpectralFly: Ramanujan Graphs as Flexible and Efficient Interconnection  Networks",
    "abstract": " Title: SpectralFly: Ramanujan Graphs as Flexible and Efficient Interconnection  Networks ",
    "url": "https://arxiv.org/abs/2104.11725",
    "authors": [
      "Stephen Young",
      "Sinan Aksoy",
      "Jesun Firoz",
      "Roberto Gioiosa",
      "Tobias Hagge",
      "Mark Kempton",
      "Juan Escobedo",
      "Mark Raugas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2105.10368",
    "title": "Development and evaluation of an Explainable Prediction Model for  Chronic Kidney Disease Patients based on Ensemble Trees",
    "abstract": " Title: Development and evaluation of an Explainable Prediction Model for  Chronic Kidney Disease Patients based on Ensemble Trees ",
    "url": "https://arxiv.org/abs/2105.10368",
    "authors": [
      "Pedro A. Moreno-Sanchez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.05319",
    "title": "Stein Latent Optimization for Generative Adversarial Networks",
    "abstract": " Comments: ICLR 2022 camera ready ",
    "url": "https://arxiv.org/abs/2106.05319",
    "authors": [
      "Uiwon Hwang",
      "Heeseung Kim",
      "Dahuin Jung",
      "Hyemi Jang",
      "Hyungyu Lee",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.09408",
    "title": "Predicting cognitive scores with graph neural networks through sample  selection learning",
    "abstract": " Comments: Corrected two typos (dimension of weight matrix and i -&gt; i+1) in description of GNN architecture ",
    "url": "https://arxiv.org/abs/2106.09408",
    "authors": [
      "Martin Hanik",
      "Mehmet Arif Demirta\u015f",
      "Mohammed Amine Gharsallaoui",
      "Islem Rekik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2106.14465",
    "title": "Exploring convolutional neural networks with transfer learning for  diagnosing Lyme disease from skin lesion images",
    "abstract": " Title: Exploring convolutional neural networks with transfer learning for  diagnosing Lyme disease from skin lesion images ",
    "url": "https://arxiv.org/abs/2106.14465",
    "authors": [
      "Sk Imran Hossain",
      "Jocelyn de Go\u00ebr de Herve",
      "Md Shahriar Hassan",
      "Delphine Martineau",
      "Evelina Petrosyan",
      "Violaine Corbain",
      "Jean Beytout",
      "Isabelle Lebert",
      "Elisabeth Baux",
      "C\u00e9line Cazorla",
      "Carole Eldin",
      "Yves Hansmann",
      "Solene Patrat-Delon",
      "Thierry Prazuck",
      "Alice Raffetin",
      "Pierre Tattevin",
      "Gwena\u00ebl Vourc'H",
      "Olivier Lesens",
      "Engelbert Nguifo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.05134",
    "title": "Dual Training of Energy-Based Models with Overparametrized Shallow  Neural Networks",
    "abstract": " Title: Dual Training of Energy-Based Models with Overparametrized Shallow  Neural Networks ",
    "url": "https://arxiv.org/abs/2107.05134",
    "authors": [
      "Carles Domingo-Enrich",
      "Alberto Bietti",
      "Marylou Gabri\u00e9",
      "Joan Bruna",
      "Eric Vanden-Eijnden"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.10689",
    "title": "Testing isomorphism of chordal graphs of bounded leafage is  fixed-parameter tractable",
    "abstract": " Title: Testing isomorphism of chordal graphs of bounded leafage is  fixed-parameter tractable ",
    "url": "https://arxiv.org/abs/2107.10689",
    "authors": [
      "Vikraman Arvind",
      "Roman Nedela",
      "Ilia Ponomarenko",
      "Peter Zeman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2108.03900",
    "title": "Multi-Scale STATCN: Self-Attention based Spatiotemporal Model for  Short-Term Metro Origin-Destination Matrix Prediction",
    "abstract": " Comments: 12 pages, 6 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2108.03900",
    "authors": [
      "Jiexia Ye",
      "Furong Zheng",
      "Juanjuan Zhao",
      "Chengzhong Xu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2109.02473",
    "title": "A Robust Cybersecurity Topic Classification Tool",
    "abstract": " Comments: Extended journal version for IJNSA (this https URL) ",
    "url": "https://arxiv.org/abs/2109.02473",
    "authors": [
      "Elijah Pelofske",
      "Lorie M. Liebrock",
      "Vincent Urias"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.03011",
    "title": "LEAF: Navigating Concept Drift in Cellular Networks",
    "abstract": " Title: LEAF: Navigating Concept Drift in Cellular Networks ",
    "url": "https://arxiv.org/abs/2109.03011",
    "authors": [
      "Shinan Liu",
      "Francesco Bronzino",
      "Paul Schmitt",
      "Arjun Nitin Bhagoji",
      "Nick Feamster",
      "Hector Garcia Crespo",
      "Timothy Coyle",
      "Brian Ward"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2109.09828",
    "title": "iRNN: Integer-only Recurrent Neural Network",
    "abstract": " Title: iRNN: Integer-only Recurrent Neural Network ",
    "url": "https://arxiv.org/abs/2109.09828",
    "authors": [
      "Eyy\u00fcb Sari",
      "Vanessa Courville",
      "Vahid Partovi Nia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2109.11615",
    "title": "Keypoints-Based Deep Feature Fusion for Cooperative Vehicle Detection of  Autonomous Driving",
    "abstract": " Title: Keypoints-Based Deep Feature Fusion for Cooperative Vehicle Detection of  Autonomous Driving ",
    "url": "https://arxiv.org/abs/2109.11615",
    "authors": [
      "Yunshuang Yuan",
      "Hao Cheng",
      "Monika Sester"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.13596",
    "title": "Exploratory State Representation Learning",
    "abstract": " Title: Exploratory State Representation Learning ",
    "url": "https://arxiv.org/abs/2109.13596",
    "authors": [
      "Astrid Merckling",
      "Nicolas Perrin-Gilbert",
      "Alex Coninx",
      "St\u00e9phane Doncieux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2110.00957",
    "title": "Graph Representation Learning for Spatial Image Steganalysis",
    "abstract": " Comments: this https URL&hl=en ",
    "url": "https://arxiv.org/abs/2110.00957",
    "authors": [
      "Qiyun Liu",
      "Hanzhou Wu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2110.06084",
    "title": "Implicit Bias of Linear Equivariant Networks",
    "abstract": " Comments: 21 pages, 19 figures ",
    "url": "https://arxiv.org/abs/2110.06084",
    "authors": [
      "Hannah Lawrence",
      "Kristian Georgiev",
      "Andrew Dienes",
      "Bobak T. Kiani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.08128",
    "title": "Label-Wise Message Passing Graph Neural Network on Heterophilic Graphs",
    "abstract": " Title: Label-Wise Message Passing Graph Neural Network on Heterophilic Graphs ",
    "url": "https://arxiv.org/abs/2110.08128",
    "authors": [
      "Enyan Dai",
      "Shijie Zhou",
      "Zhimeng Guo",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.10457",
    "title": "Knowledge Graph informed Fake News Classification via Heterogeneous  Representation Ensembles",
    "abstract": " Title: Knowledge Graph informed Fake News Classification via Heterogeneous  Representation Ensembles ",
    "url": "https://arxiv.org/abs/2110.10457",
    "authors": [
      "Boshko Koloski",
      "Timen Stepi\u0161nik-Perdih",
      "Marko Robnik-\u0160ikonja",
      "Senja Pollak",
      "Bla\u017e \u0160krlj"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2110.11499",
    "title": "Wav2CLIP: Learning Robust Audio Representations From CLIP",
    "abstract": " Comments: Copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works ",
    "url": "https://arxiv.org/abs/2110.11499",
    "authors": [
      "Ho-Hsiang Wu",
      "Prem Seetharaman",
      "Kundan Kumar",
      "Juan Pablo Bello"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2110.14879",
    "title": "Pilot Optimization and Channel Estimation for Two-way Relaying Network  Aided by IRS with Finite Discrete Phase Shifters",
    "abstract": " Comments: 5 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2110.14879",
    "authors": [
      "Zhongwen Sun",
      "Xuehui Wang",
      "Siling Feng",
      "Xinrong Guan",
      "Feng Shu",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2111.02020",
    "title": "Analysis of Receiver Covered by Heterogeneous Receptors in Molecular  Communications",
    "abstract": " Comments: 6 pages, 4 figures. Accepted by IEEE International Conference on Communications (ICC) 2022 ",
    "url": "https://arxiv.org/abs/2111.02020",
    "authors": [
      "Xinyu Huang",
      "Yuting Fang",
      "Stuart T. Johnston",
      "Matthew Faria",
      "Nan Yang",
      "Robert Schober"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2111.05320",
    "title": "Robust Estimation for Random Graphs",
    "abstract": " Title: Robust Estimation for Random Graphs ",
    "url": "https://arxiv.org/abs/2111.05320",
    "authors": [
      "Jayadev Acharya",
      "Ayush Jain",
      "Gautam Kamath",
      "Ananda Theertha Suresh",
      "Huanyu Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.08177",
    "title": "Score-Based Generative Models for Robust Channel Estimation",
    "abstract": " Title: Score-Based Generative Models for Robust Channel Estimation ",
    "url": "https://arxiv.org/abs/2111.08177",
    "authors": [
      "Marius Arvinte",
      "Jonathan I Tamir"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.10272",
    "title": "Resilience from Diversity: Population-based approach to harden models  against adversarial attacks",
    "abstract": " Comments: 12 pages, 6 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2111.10272",
    "authors": [
      "Jasser Jasser",
      "Ivan Garibay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.12389",
    "title": "Track Boosting and Synthetic Data Aided Drone Detection",
    "abstract": " Comments: Published at AVSS 2022 ",
    "url": "https://arxiv.org/abs/2111.12389",
    "authors": [
      "Fatih Cagatay Akyon",
      "Ogulcan Eryuksel",
      "Kamil Anil Ozfuttu",
      "Sinan Onur Altinuc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.12631",
    "title": "Unity is strength: Improving the Detection of Adversarial Examples with  Ensemble Approaches",
    "abstract": " Comments: Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2111.12631",
    "authors": [
      "Francesco Craighero",
      "Fabrizio Angaroni",
      "Fabio Stella",
      "Chiara Damiani",
      "Marco Antoniotti",
      "Alex Graudenzi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.13057",
    "title": "Evaluating the Robustness of Retrieval Pipelines with Query Variation  Generators",
    "abstract": " Comments: Accepted for publication in the 44nd European Conference on Information Retrieval (ECIR'22). V3: Fixed Table 2 ",
    "url": "https://arxiv.org/abs/2111.13057",
    "authors": [
      "Gustavo Penha",
      "Arthur C\u00e2mara",
      "Claudia Hauff"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2201.06210",
    "title": "Deep convolutional neural network for shape optimization using level-set  approach",
    "abstract": " Title: Deep convolutional neural network for shape optimization using level-set  approach ",
    "url": "https://arxiv.org/abs/2201.06210",
    "authors": [
      "Wrik Mallik",
      "Neil Farvolden",
      "Jasmin Jelovica",
      "Rajeev K. Jaiman"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.09429",
    "title": "End-to-End Neural Speech Coding for Real-Time Communications",
    "abstract": " Comments: ICASSP 2022 (Accepted) ",
    "url": "https://arxiv.org/abs/2201.09429",
    "authors": [
      "Xue Jiang",
      "Xiulian Peng",
      "Chengyu Zheng",
      "Huaying Xue",
      "Yuan Zhang",
      "Yan Lu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2201.09815",
    "title": "Analytic Mutual Information in Bayesian Neural Networks",
    "abstract": " Title: Analytic Mutual Information in Bayesian Neural Networks ",
    "url": "https://arxiv.org/abs/2201.09815",
    "authors": [
      "Jae Oh Woo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11147",
    "title": "OntoProtein: Protein Pretraining With Gene Ontology Embedding",
    "abstract": " Comments: Accepted by ICLR 2022 ",
    "url": "https://arxiv.org/abs/2201.11147",
    "authors": [
      "Ningyu Zhang",
      "Zhen Bi",
      "Xiaozhuan Liang",
      "Siyuan Cheng",
      "Haosen Hong",
      "Shumin Deng",
      "Jiazhang Lian",
      "Qiang Zhang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.00075",
    "title": "SUGAR: Efficient Subgraph-level Training via Resource-aware Graph  Partitioning",
    "abstract": " Title: SUGAR: Efficient Subgraph-level Training via Resource-aware Graph  Partitioning ",
    "url": "https://arxiv.org/abs/2202.00075",
    "authors": [
      "Zihui Xue",
      "Yuedong Yang",
      "Mengtian Yang",
      "Radu Marculescu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.00113",
    "title": "Imbedding Deep Neural Networks",
    "abstract": " Comments: Accepted as a spotlight paper at the 10th International Conference on Learning Representations (ICLR), 2022 ",
    "url": "https://arxiv.org/abs/2202.00113",
    "authors": [
      "Andrew Corbett",
      "Dmitry Kangin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2202.00964",
    "title": "Understanding Knowledge Integration in Language Models with Graph  Convolutions",
    "abstract": " Comments: Code is available: this https URL ",
    "url": "https://arxiv.org/abs/2202.00964",
    "authors": [
      "Yifan Hou",
      "Guoji Fu",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02626",
    "title": "Layer-wise Regularized Adversarial Training using Layers Sustainability  Analysis (LSA) framework",
    "abstract": " Comments: Layers Sustainability Analysis (LSA) framework ",
    "url": "https://arxiv.org/abs/2202.02626",
    "authors": [
      "Mohammad Khalooei",
      "Mohammad Mehdi Homayounpour",
      "Maryam Amirmazlaghani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.04301",
    "title": "Log-based Anomaly Detection with Deep Learning: How Far Are We?",
    "abstract": " Comments: Accepted by The 44th International Conference on Software Engineering (ICSE 2022) ",
    "url": "https://arxiv.org/abs/2202.04301",
    "authors": [
      "Van-Hoang Le",
      "Hongyu Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05152",
    "title": "Feature-level augmentation to improve robustness of deep neural networks  to affine transformations",
    "abstract": " Title: Feature-level augmentation to improve robustness of deep neural networks  to affine transformations ",
    "url": "https://arxiv.org/abs/2202.05152",
    "authors": [
      "Adrian Sandru",
      "Mariana-Iuliana Georgescu",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06003",
    "title": "Robust Learning from Observation with Model Misspecification",
    "abstract": " Comments: accepted to AAMAS 2022 (camera-ready version) ",
    "url": "https://arxiv.org/abs/2202.06003",
    "authors": [
      "Luca Viano",
      "Yu-Ting Huang",
      "Parameswaran Kamalaruban",
      "Craig Innes",
      "Subramanian Ramamoorthy",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06200",
    "title": "Improving Graph Collaborative Filtering with Neighborhood-enriched  Contrastive Learning",
    "abstract": " Comments: 10 pages, 6 figures. Accepted by TheWebConf 2022 ",
    "url": "https://arxiv.org/abs/2202.06200",
    "authors": [
      "Zihan Lin",
      "Changxin Tian",
      "Yupeng Hou",
      "Wayne Xin Zhao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.06483",
    "title": "BiFSMN: Binary Neural Network for Keyword Spotting",
    "abstract": " Comments: request from company ",
    "url": "https://arxiv.org/abs/2202.06483",
    "authors": [
      "Haotong Qin",
      "Xudong Ma",
      "Yifu Ding",
      "Xiaoyang Li",
      "Yang Zhang",
      "Yao Tian",
      "Zejun Ma",
      "Jie Luo",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.06495",
    "title": "HUT: Enabling High-UTility, Batched Queries under Differential Privacy  Protection for Internet-of-Vehicles",
    "abstract": " Comments: Technical Report-Feb-02 at User-Centric Computing Group, University of Nottingham Ningbo China ",
    "url": "https://arxiv.org/abs/2202.06495",
    "authors": [
      "Junyu Liu",
      "Wangkai Jin",
      "Zhenyong He",
      "Xiaoxing Ming",
      "Yicun Duan",
      "Zeyu Xiong",
      "Xiangjun Peng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.06684",
    "title": "Partially Fake Audio Detection by Self-attention-based Fake Span  Discovery",
    "abstract": " Comments: Submitted to ICASSP 2022 ",
    "url": "https://arxiv.org/abs/2202.06684",
    "authors": [
      "Haibin Wu",
      "Heng-Cheng Kuo",
      "Naijun Zheng",
      "Kuo-Hsuan Hung",
      "Hung-Yi Lee",
      "Yu Tsao",
      "Hsin-Min Wang",
      "Helen Meng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2202.06934",
    "title": "Slicing Aided Hyper Inference and Fine-tuning for Small Object Detection",
    "abstract": " Comments: Submitted to ICIP 2022, 5 pages, 4 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2202.06934",
    "authors": [
      "Fatih Cagatay Akyon",
      "Sinan Onur Altinuc",
      "Alptekin Temizel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  }
]