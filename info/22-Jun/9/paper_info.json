[
  {
    "id": "arXiv:2206.03488",
    "title": "Towards Practical Differential Privacy in Data Analysis: Understanding  the Effect of Epsilon on Utility in Private ERM",
    "abstract": "In this paper, we focus our attention on private Empirical Risk Minimization (ERM), which is one of the most commonly used data analysis method. We take the first step towards solving the above problem by theoretically exploring the effect of epsilon (the parameter of differential privacy that determines the strength of privacy guarantee) on utility of the learning model. We trace the change of utility with modification of epsilon and reveal an established relationship between epsilon and utility. We then formalize this relationship and propose a practical approach for estimating the utility under an arbitrary value of epsilon. Both theoretical analysis and experimental results demonstrate high estimation accuracy and broad applicability of our approach in practical applications. As providing algorithms with strong utility guarantees that also give privacy when possible becomes more and more accepted, our approach would have high practical value and may be likely to be adopted by companies and organizations that would like to preserve privacy but are unwilling to compromise on utility. ",
    "url": "https://arxiv.org/abs/2206.03488",
    "authors": [
      "Yuzhe Li",
      "Yong Liu",
      "Bo Li",
      "Weiping Wang",
      "Nan Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03491",
    "title": "EiX-GNN : Concept-level eigencentrality explainer for graph neural  networks",
    "abstract": "Explaining is a human knowledge transfer process regarding a phenomenon between an explainer and an explainee. Each word used to explain this phenomenon must be carefully selected by the explainer in accordance with the current explainee phenomenon-related knowledge level and the phenomenon itself in order to have a high understanding from the explainee of the phenomenon. Nowadays, deep models, especially graph neural networks, have a major place in daily life even in critical applications. In such context, those models need to have a human high interpretability also referred as being explainable, in order to improve usage trustability of them in sensitive cases. Explaining is also a human dependent task and methods that explain deep model behavior must include these social-related concerns for providing profitable and quality explanations. Current explaining methods often occlude such social aspect for providing their explanations and only focus on the signal aspect of the question. In this contribution we propose a reliable social-aware explaining method suited for graph neural network that includes this social feature as a modular concept generator and by both leveraging signal and graph domain aspect thanks to an eigencentrality concept ordering approach. Besides our method takes into account the human-dependent aspect underlying any explanation process, we also reach high score regarding state-of-the-art objective metrics assessing explanation methods for graph neural networks models. ",
    "url": "https://arxiv.org/abs/2206.03491",
    "authors": [
      "Pascal Bourdon",
      "David Helbert",
      "Adrien Raison"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03492",
    "title": "A Privacy-Preserving Subgraph-Level Federated Graph Neural Network via  Differential Privacy",
    "abstract": "Currently, the federated graph neural network (GNN) has attracted a lot of attention due to its wide applications in reality without violating the privacy regulations. Among all the privacy-preserving technologies, the differential privacy (DP) is the most promising one due to its effectiveness and light computational overhead. However, the DP-based federated GNN has not been well investigated, especially in the sub-graph-level setting, such as the scenario of recommendation system. The biggest challenge is how to guarantee the privacy and solve the non independent and identically distributed (non-IID) data in federated GNN simultaneously. In this paper, we propose DP-FedRec, a DP-based federated GNN to fill the gap. Private Set Intersection (PSI) is leveraged to extend the local graph for each client, and thus solve the non-IID problem. Most importantly, DP is applied not only on the weights but also on the edges of the intersection graph from PSI to fully protect the privacy of clients. The evaluation demonstrates DP-FedRec achieves better performance with the graph extension and DP only introduces little computations overhead. ",
    "url": "https://arxiv.org/abs/2206.03492",
    "authors": [
      "Yeqing Qiu",
      "Chenyu Huang",
      "Jianzong Wang",
      "Zhangcheng Huang",
      "Jing Xiao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03529",
    "title": "How to Dissect a Muppet: The Structure of Transformer Embedding Spaces",
    "abstract": "Pretrained embeddings based on the Transformer architecture have taken the NLP community by storm. We show that they can mathematically be reframed as a sum of vector factors and showcase how to use this reframing to study the impact of each component. We provide evidence that multi-head attentions and feed-forwards are not equally useful in all downstream applications, as well as a quantitative overview of the effects of finetuning on the overall embedding space. This approach allows us to draw connections to a wide range of previous studies, from vector space anisotropy to attention weights. ",
    "url": "https://arxiv.org/abs/2206.03529",
    "authors": [
      "Timothee Mickus",
      "Denis Paperno",
      "Mathieu Constant"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.03535",
    "title": "On the Design of Integral Multiplex Control Protocols for Nonlinear  Network Systems with Delays",
    "abstract": "We consider the problem of designing control protocols for possibly nonlinear networks with delays that not only allow the fulfillment of some desired behaviour, but also simultaneously guarantee the rejection of polynomial disturbances and the non-amplification of other classes of disturbances across the network. To address this problem, we propose the systematic use of multiplex architectures to deliver integral control protocols ensuring the desired disturbance rejection and non-amplification properties. We then present a set of sufficient conditions to assess these properties and hence to design the multiplex architecture for both leaderless and leader-follower networks with time-varying references consisting of possibly heterogeneous nonlinearly coupled agents affected by communication delays. The effectiveness of our conditions, which are also turned into an optimisation problem allowing protocol design, is illustrated via both in-silico and experimental validations with a real hardware set-up. ",
    "url": "https://arxiv.org/abs/2206.03535",
    "authors": [
      "Shihao Xie",
      "Giovanni Russo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.03538",
    "title": "WIDESim: A toolkit for simulating resource management techniques of  Workflows in Distributed Environments with Graph Topology",
    "abstract": "This paper presents a toolkit for simulating resource management of scientific workflows in distributed environments with graph topology called WIDESim. WIDESim can work with all three different structures of scientific workflows: single, multiple workflows, and workflow ensembles. Also, unlike most existing network simulators, there is no constraint on the topology of the distributed environment. We have analyzed the performance of WIDESim in comparison to standard simulators and workflow management tools. The comparison indicates that WIDESim's performance is close to existing standard simulators besides its improvements ",
    "url": "https://arxiv.org/abs/2206.03538",
    "authors": [
      "Mohammad Amin Rayej",
      "Hajar Siar",
      "Mohammad Izadi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2206.03544",
    "title": "A Penny for Your (visual) Thoughts: Self-Supervised Reconstruction of  Natural Movies from Brain Activity",
    "abstract": "Reconstructing natural videos from fMRI brain recordings is very challenging, for two main reasons: (i) As fMRI data acquisition is diffcult, we only have a limited amount of supervised samples, which is not enough to cover the huge space of natural videos; and (ii) The temporal resolution of fMRI recordings is much lower than the frame rate of natural videos. In this paper, we propose a selfsupervised approach for natural movie reconstruction. By employing cycle consistency over Encoding-Decoding natural videos, we can: (i) exploit the full framerate of the training videos, and not be limited only to clips that correspond to fMRI recordings; (ii) exploit massive amounts of external natural videos which the subjects never saw inside the fMRI machine. These enable increasing the applicable training data by several orders of magnitude, introducing natural video priors to the decoding network, as well as temporal coherence. Our approach signifcantly outperforms competing methods, since those train only on the limited supervised data. We further introduce a new and simple temporal prior of natural videos, which when folded into our fMRI decoder further allows us to reconstruct videos at a higher framerate (HFR) of up to x8 of the original fMRI sample rate. ",
    "url": "https://arxiv.org/abs/2206.03544",
    "authors": [
      "Ganit Kupershmidt",
      "Roman Beliy",
      "Guy Gaziv",
      "Michal Irani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03555",
    "title": "A generative recommender system with GMM prior for cancer drug  generation and sensitivity prediction",
    "abstract": "Recent emergence of high-throughput drug screening assays sparkled an intensive development of machine learning methods, including models for prediction of sensitivity of cancer cell lines to anti-cancer drugs, as well as methods for generation of potential drug candidates. However, a concept of generation of compounds with specific properties and simultaneous modeling of their efficacy against cancer cell lines has not been comprehensively explored. To address this need, we present VADEERS, a Variational Autoencoder-based Drug Efficacy Estimation Recommender System. The generation of compounds is performed by a novel variational autoencoder with a semi-supervised Gaussian Mixture Model (GMM) prior. The prior defines a clustering in the latent space, where the clusters are associated with specific drug properties. In addition, VADEERS is equipped with a cell line autoencoder and a sensitivity prediction network. The model combines data for SMILES string representations of anti-cancer drugs, their inhibition profiles against a panel of protein kinases, cell lines biological features and measurements of the sensitivity of the cell lines to the drugs. The evaluated variants of VADEERS achieve a high r=0.87 Pearson correlation between true and predicted drug sensitivity estimates. We train the GMM prior in such a way that the clusters in the latent space correspond to a pre-computed clustering of the drugs by their inhibitory profiles. We show that the learned latent representations and new generated data points accurately reflect the given clustering. In summary, VADEERS offers a comprehensive model of drugs and cell lines properties and relationships between them, as well as a guided generation of novel compounds. ",
    "url": "https://arxiv.org/abs/2206.03555",
    "authors": [
      "Krzysztof Koras",
      "Marcin Mo\u017cejko",
      "Paulina Szymczak",
      "Eike Staub",
      "Ewa Szczurek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Other Quantitative Biology (q-bio.OT)"
    ]
  },
  {
    "id": "arXiv:2206.03575",
    "title": "Certifying Data-Bias Robustness in Linear Regression",
    "abstract": "Datasets typically contain inaccuracies due to human error and societal biases, and these inaccuracies can affect the outcomes of models trained on such datasets. We present a technique for certifying whether linear regression models are pointwise-robust to label bias in the training dataset, i.e., whether bounded perturbations to the labels of a training dataset result in models that change the prediction of test points. We show how to solve this problem exactly for individual test points, and provide an approximate but more scalable method that does not require advance knowledge of the test point. We extensively evaluate both techniques and find that linear models -- both regression- and classification-based -- often display high levels of bias-robustness. However, we also unearth gaps in bias-robustness, such as high levels of non-robustness for certain bias assumptions on some datasets. Overall, our approach can serve as a guide for when to trust, or question, a model's output. ",
    "url": "https://arxiv.org/abs/2206.03575",
    "authors": [
      "Anna P. Meyer",
      "Aws Albarghouthi",
      "Loris D'Antoni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03581",
    "title": "Compromised account detection using authorship verification: a novel  approach",
    "abstract": "Compromising legitimate accounts is a way of disseminating malicious content to a large user base in Online Social Networks (OSNs). Since the accounts cause lots of damages to the user and consequently to other users on OSNs, early detection is very important. This paper proposes a novel approach based on authorship verification to identify compromised twitter accounts. As the approach only uses the features extracted from the last user's post, it helps to early detection to control the damage. As a result, the malicious message without a user profile can be detected with satisfying accuracy. Experiments were constructed using a real-world dataset of compromised accounts on Twitter. The result showed that the model is suitable for detection due to achieving an accuracy of 89%. ",
    "url": "https://arxiv.org/abs/2206.03581",
    "authors": [
      "Forough Farazmanesh",
      "Fateme Foroutan",
      "Amir Jalaly Bidgoly"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.03583",
    "title": "Contributor-Aware Defenses Against Adversarial Backdoor Attacks",
    "abstract": "Deep neural networks for image classification are well-known to be vulnerable to adversarial attacks. One such attack that has garnered recent attention is the adversarial backdoor attack, which has demonstrated the capability to perform targeted misclassification of specific examples. In particular, backdoor attacks attempt to force a model to learn spurious relations between backdoor trigger patterns and false labels. In response to this threat, numerous defensive measures have been proposed; however, defenses against backdoor attacks focus on backdoor pattern detection, which may be unreliable against novel or unexpected types of backdoor pattern designs. We introduce a novel re-contextualization of the adversarial setting, where the presence of an adversary implicitly admits the existence of multiple database contributors. Then, under the mild assumption of contributor awareness, it becomes possible to exploit this knowledge to defend against backdoor attacks by destroying the false label associations. We propose a contributor-aware universal defensive framework for learning in the presence of multiple, potentially adversarial data sources that utilizes semi-supervised ensembles and learning from crowds to filter the false labels produced by adversarial triggers. Importantly, this defensive strategy is agnostic to backdoor pattern design, as it functions without needing -- or even attempting -- to perform either adversary identification or backdoor pattern detection during either training or inference. Our empirical studies demonstrate the robustness of the proposed framework against adversarial backdoor attacks from multiple simultaneous adversaries. ",
    "url": "https://arxiv.org/abs/2206.03583",
    "authors": [
      "Glenn Dawson",
      "Muhammad Umer",
      "Robi Polikar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03584",
    "title": "White-box Membership Attack Against Machine Learning Based Retinopathy  Classification",
    "abstract": "The advances in machine learning (ML) have greatly improved AI-based diagnosis aid systems in medical imaging. However, being based on collecting medical data specific to individuals induces several security issues, especially in terms of privacy. Even though the owner of the images like a hospital put in place strict privacy protection provisions at the level of its information system, the model trained over his images still holds disclosure potential. The trained model may be accessible to an attacker as: 1) White-box: accessing to the model architecture and parameters; 2) Black box: where he can only query the model with his own inputs through an appropriate interface. Existing attack methods include: feature estimation attacks (FEA), membership inference attack (MIA), model memorization attack (MMA) and identification attacks (IA). In this work we focus on MIA against a model that has been trained to detect diabetic retinopathy from retinal images. Diabetic retinopathy is a condition that can cause vision loss and blindness in the people who have diabetes. MIA is the process of determining whether a data sample comes from the training data set of a trained ML model or not. From a privacy perspective in our use case where a diabetic retinopathy classification model is given to partners that have at their disposal images along with patients' identifiers, inferring the membership status of a data sample can help to state if a patient has contributed or not to the training of the model. ",
    "url": "https://arxiv.org/abs/2206.03584",
    "authors": [
      "Mounia Hamidouche",
      "Reda Bellafqira",
      "Gwenol\u00e9 Quellec",
      "Gouenou Coatrieux"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03592",
    "title": "Click Prediction Boosting via Ensemble Learning Pipelines",
    "abstract": "Online travel agencies (OTA's) advertise their website offers on meta-search bidding engines. The problem of predicting the number of clicks a hotel would receive for a given bid amount is an important step in the management of an OTA's advertisement campaign on a meta-search engine because bid times number of clicks defines the cost to be generated. Various regressors are ensembled in this work to improve click prediction performance. Following the preprocessing procedures, the feature set is divided into train and test groups depending on the samples' logging dates. The data collection is then subjected to XGBoost-based dimension reduction, which significantly reduces the dimension of features. The optimum hyper-parameters are then found by applying Bayesian Hyper-parameter optimization to the XGBoost, LightGBM, and SGD models. Individually, ten distinct machine learning models are tested, as well as combining them to create ensemble models. Three alternative ensemble solutions have been suggested. The same test set is used to test both individual and ensemble models, and the results of 46 model combinations demonstrate that stack ensemble models yield the desired R2 score of all. In conclusion, the ensemble model improves the prediction performance by about 10%. ",
    "url": "https://arxiv.org/abs/2206.03592",
    "authors": [
      "\u00c7a\u011fatay Demirel",
      "A. Aylin Toku\u00e7",
      "Ahmet Tezcan Tekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03596",
    "title": "Neural Network Compression via Effective Filter Analysis and  Hierarchical Pruning",
    "abstract": "Network compression is crucial to making the deep networks to be more efficient, faster, and generalizable to low-end hardware. Current network compression methods have two open problems: first, there lacks a theoretical framework to estimate the maximum compression rate; second, some layers may get over-prunned, resulting in significant network performance drop. To solve these two problems, this study propose a gradient-matrix singularity analysis-based method to estimate the maximum network redundancy. Guided by that maximum rate, a novel and efficient hierarchical network pruning algorithm is developed to maximally condense the neuronal network structure without sacrificing network performance. Substantial experiments are performed to demonstrate the efficacy of the new method for pruning several advanced convolutional neural network (CNN) architectures. Compared to existing pruning methods, the proposed pruning algorithm achieved state-of-the-art performance. At the same or similar compression ratio, the new method provided the highest network prediction accuracy as compared to other methods. ",
    "url": "https://arxiv.org/abs/2206.03596",
    "authors": [
      "Ziqi Zhou",
      "Li Lian",
      "Yilong Yin",
      "Ze Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.03601",
    "title": "Decoupled Self-supervised Learning for Non-Homophilous Graphs",
    "abstract": "In this paper, we study the problem of conducting self-supervised learning for node representation learning on non-homophilous graphs. Existing self-supervised learning methods typically assume the graph is homophilous where linked nodes often belong to the same class or have similar features. However, such assumptions of homophily do not always hold true in real-world graphs. We address this problem by developing a decoupled self-supervised learning (DSSL) framework for graph neural networks. DSSL imitates a generative process of nodes and links from latent variable modeling of the semantic structure, which decouples different underlying semantics between different neighborhoods into the self-supervised node learning process. Our DSSL framework is agnostic to the encoders and does not need prefabricated augmentations, thus is flexible to different graphs. To effectively optimize the framework with latent variables, we derive the evidence lower-bound of the self-supervised objective and develop a scalable training algorithm with variational inference. We provide a theoretical analysis to justify that DSSL enjoys better downstream performance. Extensive experiments on various types of graph benchmarks demonstrate that our proposed framework can significantly achieve better performance compared with competitive self-supervised learning baselines. ",
    "url": "https://arxiv.org/abs/2206.03601",
    "authors": [
      "Teng Xiao",
      "Zhengyu Chen",
      "Zhimeng Guo",
      "Zeyang Zhuang",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.03610",
    "title": "Towards Scalable Hyperbolic Neural Networks using Taylor Series  Approximations",
    "abstract": "Hyperbolic networks have shown prominent improvements over their Euclidean counterparts in several areas involving hierarchical datasets in various domains such as computer vision, graph analysis, and natural language processing. However, their adoption in practice remains restricted due to (i) non-scalability on accelerated deep learning hardware, (ii) vanishing gradients due to the closure of hyperbolic space, and (iii) information loss due to frequent mapping between local tangent space and fully hyperbolic space. To tackle these issues, we propose the approximation of hyperbolic operators using Taylor series expansions, which allows us to reformulate the computationally expensive tangent and cosine hyperbolic functions into their polynomial equivariants which are more efficient. This allows us to retain the benefits of preserving the hierarchical anatomy of the hyperbolic space, while maintaining the scalability over current accelerated deep learning infrastructure. The polynomial formulation also enables us to utilize the advancements in Euclidean networks such as gradient clipping and ReLU activation to avoid vanishing gradients and remove errors due to frequent switching between tangent space and hyperbolic space. Our empirical evaluation on standard benchmarks in the domain of graph analysis and computer vision shows that our polynomial formulation is as scalable as Euclidean architectures, both in terms of memory and time complexity, while providing results as effective as hyperbolic models. Moreover, our formulation also shows a considerable improvement over its baselines due to our solution to vanishing gradients and information loss. ",
    "url": "https://arxiv.org/abs/2206.03610",
    "authors": [
      "Nurendra Choudhary",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03617",
    "title": "Subject Granular Differential Privacy in Federated Learning",
    "abstract": "This paper introduces subject granular privacy in the Federated Learning (FL) setting, where a subject is an individual whose private information is embodied by several data items either confined within a single federation user or distributed across multiple federation users. We formally define the notion of subject level differential privacy for FL. We propose three new algorithms that enforce subject level DP. Two of these algorithms are based on notions of user level local differential privacy (LDP) and group differential privacy respectively. The third algorithm is based on a novel idea of hierarchical gradient averaging (HiGradAvgDP) for subjects participating in a training mini-batch. We also introduce horizontal composition of privacy loss for a subject across multiple federation users. We show that horizontal composition is equivalent to sequential composition in the worst case. We prove the subject level DP guarantee for all our algorithms and empirically analyze them using the FEMNIST and Shakespeare datasets. Our evaluation shows that, of our three algorithms, HiGradAvgDP delivers the best model performance, approaching that of a model trained using a DP-SGD based algorithm that provides a weaker item level privacy guarantee. ",
    "url": "https://arxiv.org/abs/2206.03617",
    "authors": [
      "Virendra J. Marathe",
      "Pallika Kanani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.03635",
    "title": "Network Report: A Structured Description for Network Datasets",
    "abstract": "The rapid development of network science and technologies depends on shareable datasets. Currently, there is no standard practice for reporting and sharing network datasets. Some network dataset providers only share links, while others provide some contexts or basic statistics. As a result, critical information may be unintentionally dropped, and network dataset consumers may misunderstand or overlook critical aspects. Inappropriately using a network dataset can lead to severe consequences (e.g., discrimination) especially when machine learning models on networks are deployed in high-stake domains. Challenges arise as networks are often used across different domains (e.g., network science, physics, etc) and have complex structures. To facilitate the communication between network dataset providers and consumers, we propose network report. A network report is a structured description that summarizes and contextualizes a network dataset. Network report extends the idea of dataset reports (e.g., Datasheets for Datasets) from prior work with network-specific descriptions of the non-i.i.d. nature, demographic information, network characteristics, etc. We hope network reports encourage transparency and accountability in network research and development across different fields. ",
    "url": "https://arxiv.org/abs/2206.03635",
    "authors": [
      "Xinyi Zheng",
      "Ryan A. Rossi",
      "Nesreen Ahmed",
      "Dominik Moritz"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03638",
    "title": "Alternately Optimized Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have demonstrated powerful representation capability in numerous graph-based tasks. Specifically, the decoupled structures of GNNs such as APPNP become popular due to their simplicity and performance advantages. However, the end-to-end training of these GNNs makes them inefficient in computation and memory consumption. In order to deal with these limitations, in this work, we propose an alternating optimization framework for graph neural networks that does not require end-to-end training. Extensive experiments under different settings demonstrate that the performance of the proposed algorithm is comparable to existing state-of-the-art algorithms but has significantly better computation and memory efficiency. Additionally, we show that our framework can be taken advantage to enhance existing decoupled GNNs. ",
    "url": "https://arxiv.org/abs/2206.03638",
    "authors": [
      "Haoyu Han",
      "Xiaorui Liu",
      "Torkamani Ali",
      "Feng Shi",
      "Victor Lee",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03644",
    "title": "Neural Bandit with Arm Group Graph",
    "abstract": "Contextual bandits aim to identify among a set of arms the optimal one with the highest reward based on their contextual information. Motivated by the fact that the arms usually exhibit group behaviors and the mutual impacts exist among groups, we introduce a new model, Arm Group Graph (AGG), where the nodes represent the groups of arms and the weighted edges formulate the correlations among groups. To leverage the rich information in AGG, we propose a bandit algorithm, AGG-UCB, where the neural networks are designed to estimate rewards, and we propose to utilize graph neural networks (GNN) to learn the representations of arm groups with correlations. To solve the exploitation-exploration dilemma in bandits, we derive a new upper confidence bound (UCB) built on neural networks (exploitation) for exploration. Furthermore, we prove that AGG-UCB can achieve a near-optimal regret bound with over-parameterized neural networks, and provide the convergence analysis of GNN with fully-connected layers which may be of independent interest. In the end, we conduct extensive experiments against state-of-the-art baselines on multiple public data sets, showing the effectiveness of the proposed algorithm. ",
    "url": "https://arxiv.org/abs/2206.03644",
    "authors": [
      "Yunzhe Qi",
      "Yikun Ban",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.03654",
    "title": "Solving the Spike Feature Information Vanishing Problem in Spiking Deep  Q Network with Potential Based Normalization",
    "abstract": "Brain inspired spiking neural networks (SNNs) have been successfully applied to many pattern recognition domains. The SNNs based deep structure have achieved considerable results in perceptual tasks, such as image classification, target detection. However, the application of deep SNNs in reinforcement learning (RL) tasks is still a problem to be explored. Although there have been previous studies on the combination of SNNs and RL, most of them focus on robotic control problems with shallow networks or using ANN-SNN conversion method to implement spiking deep Q Network (SDQN). In this work, we mathematically analyzed the problem of the disappearance of spiking signal features in SDQN and proposed a potential based layer normalization(pbLN) method to directly train spiking deep Q networks. Experiment shows that compared with state-of-art ANN-SNN conversion method and other SDQN works, the proposed pbLN spiking deep Q networks (PL-SDQN) achieved better performance on Atari game tasks. ",
    "url": "https://arxiv.org/abs/2206.03654",
    "authors": [
      "Yinqian Sun",
      "Yi Zeng",
      "Yang Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03656",
    "title": "Joint Adversarial Learning for Cross-domain Fair Classification",
    "abstract": "Modern machine learning (ML) models are becoming increasingly popular and are widely used in decision-making systems. However, studies have shown critical issues of ML discrimination and unfairness, which hinder their adoption on high-stake applications. Recent research on fair classifiers has drawn significant attention to develop effective algorithms to achieve fairness and good classification performance. Despite the great success of these fairness-aware machine learning models, most of the existing models require sensitive attributes to preprocess the data, regularize the model learning or postprocess the prediction to have fair predictions. However, sensitive attributes are often incomplete or even unavailable due to privacy, legal or regulation restrictions. Though we lack the sensitive attribute for training a fair model in the target domain, there might exist a similar domain that has sensitive attributes. Thus, it is important to exploit auxiliary information from the similar domain to help improve fair classification in the target domain. Therefore, in this paper, we study a novel problem of exploring domain adaptation for fair classification. We propose a new framework that can simultaneously estimate the sensitive attributes while learning a fair classifier in the target domain. Extensive experiments on real-world datasets illustrate the effectiveness of the proposed model for fair classification, even when no sensitive attributes are available in the target domain. ",
    "url": "https://arxiv.org/abs/2206.03656",
    "authors": [
      "Yueqing Liang",
      "Canyu Chen",
      "Tian Tian",
      "Kai Shu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.03657",
    "title": "Delving into the Pre-training Paradigm of Monocular 3D Object Detection",
    "abstract": "The labels of monocular 3D object detection (M3OD) are expensive to obtain. Meanwhile, there usually exists numerous unlabeled data in practical applications, and pre-training is an efficient way of exploiting the knowledge in unlabeled data. However, the pre-training paradigm for M3OD is hardly studied. We aim to bridge this gap in this work. To this end, we first draw two observations: (1) The guideline of devising pre-training tasks is imitating the representation of the target task. (2) Combining depth estimation and 2D object detection is a promising M3OD pre-training baseline. Afterwards, following the guideline, we propose several strategies to further improve this baseline, which mainly include target guided semi-dense depth estimation, keypoint-aware 2D object detection, and class-level loss adjustment. Combining all the developed techniques, the obtained pre-training framework produces pre-trained backbones that improve M3OD performance significantly on both the KITTI-3D and nuScenes benchmarks. For example, by applying a DLA34 backbone to a naive center-based M3OD detector, the moderate ${\\rm AP}_{3D}70$ score of Car on the KITTI-3D testing set is boosted by 18.71\\% and the NDS score on the nuScenes validation set is improved by 40.41\\% relatively. ",
    "url": "https://arxiv.org/abs/2206.03657",
    "authors": [
      "Zhuoling Li",
      "Chuanrui Zhang",
      "En Yu",
      "Haoqian Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03661",
    "title": "One Hyper-Initializer for All Network Architectures in Medical Image  Analysis",
    "abstract": "Pre-training is essential to deep learning model performance, especially in medical image analysis tasks where limited training data are available. However, existing pre-training methods are inflexible as the pre-trained weights of one model cannot be reused by other network architectures. In this paper, we propose an architecture-irrelevant hyper-initializer, which can initialize any given network architecture well after being pre-trained for only once. The proposed initializer is a hypernetwork which takes a downstream architecture as input graphs and outputs the initialization parameters of the respective architecture. We show the effectiveness and efficiency of the hyper-initializer through extensive experimental results on multiple medical imaging modalities, especially in data-limited fields. Moreover, we prove that the proposed algorithm can be reused as a favorable plug-and-play initializer for any downstream architecture and task (both classification and segmentation) of the same modality. ",
    "url": "https://arxiv.org/abs/2206.03661",
    "authors": [
      "Fangxin Shang",
      "Yehui Yang",
      "Dalu Yang",
      "Junde Wu",
      "Xiaorong Wang",
      "Yanwu Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03666",
    "title": "Depth Estimation Matters Most: Improving Per-Object Depth Estimation for  Monocular 3D Detection and Tracking",
    "abstract": "Monocular image-based 3D perception has become an active research area in recent years owing to its applications in autonomous driving. Approaches to monocular 3D perception including detection and tracking, however, often yield inferior performance when compared to LiDAR-based techniques. Through systematic analysis, we identified that per-object depth estimation accuracy is a major factor bounding the performance. Motivated by this observation, we propose a multi-level fusion method that combines different representations (RGB and pseudo-LiDAR) and temporal information across multiple frames for objects (tracklets) to enhance per-object depth estimation. Our proposed fusion method achieves the state-of-the-art performance of per-object depth estimation on the Waymo Open Dataset, the KITTI detection dataset, and the KITTI MOT dataset. We further demonstrate that by simply replacing estimated depth with fusion-enhanced depth, we can achieve significant improvements in monocular 3D perception tasks, including detection and tracking. ",
    "url": "https://arxiv.org/abs/2206.03666",
    "authors": [
      "Longlong Jing",
      "Ruichi Yu",
      "Henrik Kretzschmar",
      "Kang Li",
      "Charles R. Qi",
      "Hang Zhao",
      "Alper Ayvaci",
      "Xu Chen",
      "Dillon Cower",
      "Yingwei Li",
      "Yurong You",
      "Han Deng",
      "Congcong Li",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03669",
    "title": "Toward Certified Robustness Against Real-World Distribution Shifts",
    "abstract": "We consider the problem of certifying the robustness of deep neural networks against real-world distribution shifts. To do so, we bridge the gap between hand-crafted specifications and realistic deployment settings by proposing a novel neural-symbolic verification framework, in which we train a generative model to learn perturbations from data and define specifications with respect to the output of the learned model. A unique challenge arising from this setting is that existing verifiers cannot tightly approximate sigmoid activations, which are fundamental to many state-of-the-art generative models. To address this challenge, we propose a general meta-algorithm for handling sigmoid activations which leverages classical notions of counter-example-guided abstraction refinement. The key idea is to \"lazily\" refine the abstraction of sigmoid functions to exclude spurious counter-examples found in the previous abstraction, thus guaranteeing progress in the verification process while keeping the state-space small. Experiments on the MNIST and CIFAR-10 datasets show that our framework significantly outperforms existing methods on a range of challenging distribution shifts. ",
    "url": "https://arxiv.org/abs/2206.03669",
    "authors": [
      "Haoze Wu",
      "Teruhiro Tagomori",
      "Alexander Robey",
      "Fengjun Yang",
      "Nikolai Matni",
      "George Pappas",
      "Hamed Hassani",
      "Corina Pasareanu",
      "Clark Barrett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2206.03687",
    "title": "A Unified Model for Multi-class Anomaly Detection",
    "abstract": "Despite the rapid advance of unsupervised anomaly detection, existing methods require to train separate models for different objects. In this work, we present UniAD that accomplishes anomaly detection for multiple classes with a unified framework. Under such a challenging setting, popular reconstruction networks may fall into an \"identical shortcut\", where both normal and anomalous samples can be well recovered, and hence fail to spot outliers. To tackle this obstacle, we make three improvements. First, we revisit the formulations of fully-connected layer, convolutional layer, as well as attention layer, and confirm the important role of query embedding (i.e., within attention layer) in preventing the network from learning the shortcut. We therefore come up with a layer-wise query decoder to help model the multi-class distribution. Second, we employ a neighbor masked attention module to further avoid the information leak from the input feature to the reconstructed output feature. Third, we propose a feature jittering strategy that urges the model to recover the correct message even with noisy inputs. We evaluate our algorithm on MVTec-AD and CIFAR-10 datasets, where we surpass the state-of-the-art alternatives by a sufficiently large margin. For example, when learning a unified model for 15 categories in MVTec-AD, we surpass the second competitor on the tasks of both anomaly detection (from 88.1% to 96.5%) and anomaly localization (from 89.5% to 96.8%). Code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2206.03687",
    "authors": [
      "Zhiyuan You",
      "Lei Cui",
      "Yujun Shen",
      "Kai Yang",
      "Xin Lu",
      "Yu Zheng",
      "Xinyi Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03691",
    "title": "Robust Deep Ensemble Method for Real-world Image Denoising",
    "abstract": "Recently, deep learning-based image denoising methods have achieved promising performance on test data with the same distribution as training set, where various denoising models based on synthetic or collected real-world training data have been learned. However, when handling real-world noisy images, the denoising performance is still limited. In this paper, we propose a simple yet effective Bayesian deep ensemble (BDE) method for real-world image denoising, where several representative deep denoisers pre-trained with various training data settings can be fused to improve robustness. The foundation of BDE is that real-world image noises are highly signal-dependent, and heterogeneous noises in a real-world noisy image can be separately handled by different denoisers. In particular, we take well-trained CBDNet, NBNet, HINet, Uformer and GMSNet into denoiser pool, and a U-Net is adopted to predict pixel-wise weighting maps to fuse these denoisers. Instead of solely learning pixel-wise weighting maps, Bayesian deep learning strategy is introduced to predict weighting uncertainty as well as weighting map, by which prediction variance can be modeled for improving robustness on real-world noisy images. Extensive experiments have shown that real-world noises can be better removed by fusing existing denoisers instead of training a big denoiser with expensive cost. On DND dataset, our BDE achieves +0.28~dB PSNR gain over the state-of-the-art denoising method. Moreover, we note that our BDE denoiser based on different Gaussian noise levels outperforms state-of-the-art CBDNet when applying to real-world noisy images. Furthermore, our BDE can be extended to other image restoration tasks, and achieves +0.30dB, +0.18dB and +0.12dB PSNR gains on benchmark datasets for image deblurring, image deraining and single image super-resolution, respectively. ",
    "url": "https://arxiv.org/abs/2206.03691",
    "authors": [
      "Pengju Liu",
      "Hongzhi Zhang",
      "Jinghui Wang",
      "Yuzhi Wang",
      "Dongwei Ren",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.03693",
    "title": "Autoregressive Perturbations for Data Poisoning",
    "abstract": "The prevalence of data scraping from social media as a means to obtain datasets has led to growing concerns regarding unauthorized use of data. Data poisoning attacks have been proposed as a bulwark against scraping, as they make data \"unlearnable\" by adding small, imperceptible perturbations. Unfortunately, existing methods require knowledge of both the target architecture and the complete dataset so that a surrogate network can be trained, the parameters of which are used to generate the attack. In this work, we introduce autoregressive (AR) poisoning, a method that can generate poisoned data without access to the broader dataset. The proposed AR perturbations are generic, can be applied across different datasets, and can poison different architectures. Compared to existing unlearnable methods, our AR poisons are more resistant against common defenses such as adversarial training and strong data augmentations. Our analysis further provides insight into what makes an effective data poison. ",
    "url": "https://arxiv.org/abs/2206.03693",
    "authors": [
      "Pedro Sandoval-Segura",
      "Vasu Singla",
      "Jonas Geiping",
      "Micah Goldblum",
      "Tom Goldstein",
      "David W. Jacobs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.03695",
    "title": "Metric Based Few-Shot Graph Classification",
    "abstract": "Many modern deep-learning techniques do not work without enormous datasets. At the same time, several fields demand methods working in scarcity of data. This problem is even more complex when the samples have varying structures, as in the case of graphs. Graph representation learning techniques have recently proven successful in a variety of domains. Nevertheless, the employed architectures perform miserably when faced with data scarcity. On the other hand, few-shot learning allows employing modern deep learning models in scarce data regimes without waiving their effectiveness. In this work, we tackle the problem of few-shot graph classification, showing that equipping a simple distance metric learning baseline with a state-of-the-art graph embedder allows to obtain competitive results on the task.While the simplicity of the architecture is enough to outperform more complex ones, it also allows straightforward additions. To this end, we show that additional improvements may be obtained by encouraging a task-conditioned embedding space. Finally, we propose a MixUp-based online data augmentation technique acting in the latent space and show its effectiveness on the task. ",
    "url": "https://arxiv.org/abs/2206.03695",
    "authors": [
      "Donato Crisostomi",
      "Simone Antonelli",
      "Valentino Maiorca",
      "Luca Moschella",
      "Riccardo Marin",
      "Emanuele Rodol\u00e0"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.03698",
    "title": "What do we learn? Debunking the Myth of Unsupervised Outlier Detection",
    "abstract": "Even though auto-encoders (AEs) have the desirable property of learning compact representations without labels and have been widely applied to out-of-distribution (OoD) detection, they are generally still poorly understood and are used incorrectly in detecting outliers where the normal and abnormal distributions are strongly overlapping. In general, the learned manifold is assumed to contain key information that is only important for describing samples within the training distribution, and that the reconstruction of outliers leads to high residual errors. However, recent work suggests that AEs are likely to be even better at reconstructing some types of OoD samples. In this work, we challenge this assumption and investigate what auto-encoders actually learn when they are posed to solve two different tasks. First, we propose two metrics based on the Fr\\'echet inception distance (FID) and confidence scores of a trained classifier to assess whether AEs can learn the training distribution and reliably recognize samples from other domains. Second, we investigate whether AEs are able to synthesize normal images from samples with abnormal regions, on a more challenging lung pathology detection task. We have found that state-of-the-art (SOTA) AEs are either unable to constrain the latent manifold and allow reconstruction of abnormal patterns, or they are failing to accurately restore the inputs from their latent distribution, resulting in blurred or misaligned reconstructions. We propose novel deformable auto-encoders (MorphAEus) to learn perceptually aware global image priors and locally adapt their morphometry based on estimated dense deformation fields. We demonstrate superior performance over unsupervised methods in detecting OoD and pathology. ",
    "url": "https://arxiv.org/abs/2206.03698",
    "authors": [
      "Cosmin I. Bercea",
      "Daniel Rueckert",
      "Julia A. Schnabel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.03715",
    "title": "Modularized Transfer Learning with Multiple Knowledge Graphs for  Zero-shot Commonsense Reasoning",
    "abstract": "Commonsense reasoning systems should be able to generalize to diverse reasoning cases. However, most state-of-the-art approaches depend on expensive data annotations and overfit to a specific benchmark without learning how to perform general semantic reasoning. To overcome these drawbacks, zero-shot QA systems have shown promise as a robust learning scheme by transforming a commonsense knowledge graph (KG) into synthetic QA-form samples for model training. Considering the increasing type of different commonsense KGs, this paper aims to extend the zero-shot transfer learning scenario into multiple-source settings, where different KGs can be utilized synergetically. Towards this goal, we propose to mitigate the loss of knowledge from the interference among the different knowledge sources, by developing a modular variant of the knowledge aggregation as a new zero-shot commonsense reasoning framework. Results on five commonsense reasoning benchmarks demonstrate the efficacy of our framework, improving the performance with multiple KGs. ",
    "url": "https://arxiv.org/abs/2206.03715",
    "authors": [
      "Yu Jin Kim",
      "Beong-woo Kwak",
      "Youngwook Kim",
      "Reinald Kim Amplayo",
      "Seung-won Hwang",
      "Jinyoung Yeo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03717",
    "title": "Latent Boundary-guided Adversarial Training",
    "abstract": "Deep Neural Networks (DNNs) have recently achieved great success in many classification tasks. Unfortunately, they are vulnerable to adversarial attacks that generate adversarial examples with a small perturbation to fool DNN models, especially in model sharing scenarios. Adversarial training is proved to be the most effective strategy that injects adversarial examples into model training to improve the robustness of DNN models to adversarial attacks. However, adversarial training based on the existing adversarial examples fails to generalize well to standard, unperturbed test data. To achieve a better trade-off between standard accuracy and adversarial robustness, we propose a novel adversarial training framework called LAtent bounDary-guided aDvErsarial tRaining (LADDER) that adversarially trains DNN models on latent boundary-guided adversarial examples. As opposed to most of the existing methods that generate adversarial examples in the input space, LADDER generates a myriad of high-quality adversarial examples through adding perturbations to latent features. The perturbations are made along the normal of the decision boundary constructed by an SVM with an attention mechanism. We analyze the merits of our generated boundary-guided adversarial examples from a boundary field perspective and visualization view. Extensive experiments and detailed analysis on MNIST, SVHN, CelebA, and CIFAR-10 validate the effectiveness of LADDER in achieving a better trade-off between standard accuracy and adversarial robustness as compared with vanilla DNNs and competitive baselines. ",
    "url": "https://arxiv.org/abs/2206.03717",
    "authors": [
      "Xiaowei Zhou",
      "Ivor W. Tsang",
      "Jie Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03720",
    "title": "Set Interdependence Transformer: Set-to-Sequence Neural Networks for  Permutation Learning and Structure Prediction",
    "abstract": "The task of learning to map an input set onto a permuted sequence of its elements is challenging for neural networks. Set-to-sequence problems occur in natural language processing, computer vision and structure prediction, where interactions between elements of large sets define the optimal output. Models must exhibit relational reasoning, handle varying cardinalities and manage combinatorial complexity. Previous attention-based methods require $n$ layers of their set transformations to explicitly represent $n$-th order relations. Our aim is to enhance their ability to efficiently model higher-order interactions through an additional interdependence component. We propose a novel neural set encoding method called the Set Interdependence Transformer, capable of relating the set's permutation invariant representation to its elements within sets of any cardinality. We combine it with a permutation learning module into a complete, 3-part set-to-sequence model and demonstrate its state-of-the-art performance on a number of tasks. These range from combinatorial optimization problems, through permutation learning challenges on both synthetic and established NLP datasets for sentence ordering, to a novel domain of product catalog structure prediction. Additionally, the network's ability to generalize to unseen sequence lengths is investigated and a comparative empirical analysis of the existing methods' ability to learn higher-order interactions is provided. ",
    "url": "https://arxiv.org/abs/2206.03720",
    "authors": [
      "Mateusz Jurewicz",
      "Leon Derczynski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.03721",
    "title": "Stabilizing Voltage in Power Distribution Networks via Multi-Agent  Reinforcement Learning with Transformer",
    "abstract": "The increased integration of renewable energy poses a slew of technical challenges for the operation of power distribution networks. Among them, voltage fluctuations caused by the instability of renewable energy are receiving increasing attention. Utilizing MARL algorithms to coordinate multiple control units in the grid, which is able to handle rapid changes of power systems, has been widely studied in active voltage control task recently. However, existing approaches based on MARL ignore the unique nature of the grid and achieve limited performance. In this paper, we introduce the transformer architecture to extract representations adapting to power network problems and propose a Transformer-based Multi-Agent Actor-Critic framework (T-MAAC) to stabilize voltage in power distribution networks. In addition, we adopt a novel auxiliary-task training process tailored to the voltage control task, which improves the sample efficiency and facilitating the representation learning of the transformer-based model. We couple T-MAAC with different multi-agent actor-critic algorithms, and the consistent improvements on the active voltage control task demonstrate the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2206.03721",
    "authors": [
      "Minrui Wang",
      "Mingxiao Feng",
      "Wengang Zhou",
      "Houqiang Li"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03727",
    "title": "Wavelet Regularization Benefits Adversarial Training",
    "abstract": "Adversarial training methods are state-of-the-art (SOTA) empirical defense methods against adversarial examples. Many regularization methods have been proven to be effective with the combination of adversarial training. Nevertheless, such regularization methods are implemented in the time domain. Since adversarial vulnerability can be regarded as a high-frequency phenomenon, it is essential to regulate the adversarially-trained neural network models in the frequency domain. Faced with these challenges, we make a theoretical analysis on the regularization property of wavelets which can enhance adversarial training. We propose a wavelet regularization method based on the Haar wavelet decomposition which is named Wavelet Average Pooling. This wavelet regularization module is integrated into the wide residual neural network so that a new WideWaveletResNet model is formed. On the datasets of CIFAR-10 and CIFAR-100, our proposed Adversarial Wavelet Training method realizes considerable robustness under different types of attacks. It verifies the assumption that our wavelet regularization method can enhance adversarial robustness especially in the deep wide neural networks. The visualization experiments of the Frequency Principle (F-Principle) and interpretability are implemented to show the effectiveness of our method. A detailed comparison based on different wavelet base functions is presented. The code is available at the repository: \\url{https://github.com/momo1986/AdversarialWaveletTraining}. ",
    "url": "https://arxiv.org/abs/2206.03727",
    "authors": [
      "Jun Yan",
      "Huilin Yin",
      "Xiaoyang Deng",
      "Ziming Zhao",
      "Wancheng Ge",
      "Hao Zhang",
      "Gerhard Rigoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03735",
    "title": "Motiflets -- Fast and Accurate Detection of Motifs in Time Series",
    "abstract": "A motif intuitively is a short time series that repeats itself approximately the same within a larger time series. Such motifs often represent concealed structures, such as heart beats in an ECG recording, or sleep spindles in EEG sleep data. Motif discovery (MD) is the task of finding such motifs in a given input series. As there are varying definitions of what exactly a motif is, a number of algorithms exist. As central parameters they all take the length l of the motif and the maximal distance r between the motif's occurrences. In practice, however, suitable values for r are very hard to determine upfront, and the found motifs show a high variability. Setting the wrong input value will result in a motif that is not distinguishable from noise. Accordingly, finding an interesting motif with these methods requires extensive trial-and-error. We present a different approach to the MD problem. We define k-Motiflets as the set of exactly k occurrences of a motif of length l, whose maximum pairwise distance is minimal. This turns the MD problem upside-down: Our central parameter is not the distance threshold r, but the desired size k of a motif set, which we show is considerably more intuitive and easier to set. Based on this definition, we present exact and approximate algorithms for finding k-Motiflets and analyze their complexity. To further ease the use of our method, we describe extensions to automatically determine the right/suitable values for its input parameters. Thus, for the first time, extracting meaningful motif sets without any a-priori knowledge becomes feasible. By evaluating real-world use cases and comparison to 4 state-of-the-art MD algorithms, we show that our proposed algorithm is (a) quantitatively superior, finding larger motif sets at higher similarity, (b) qualitatively better, leading to clearer and easier to interpret motifs, and (c) has the lowest runtime. ",
    "url": "https://arxiv.org/abs/2206.03735",
    "authors": [
      "Patrick Sch\u00e4fer",
      "Ulf Leser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2206.03739",
    "title": "Disentangled Ontology Embedding for Zero-shot Learning",
    "abstract": "Knowledge Graph (KG) and its variant of ontology have been widely used for knowledge representation, and have shown to be quite effective in augmenting Zero-shot Learning (ZSL). However, existing ZSL methods that utilize KGs all neglect the intrinsic complexity of inter-class relationships represented in KGs. One typical feature is that a class is often related to other classes in different semantic aspects. In this paper, we focus on ontologies for augmenting ZSL, and propose to learn disentangled ontology embeddings guided by ontology properties to capture and utilize more fine-grained class relationships in different aspects. We also contribute a new ZSL framework named DOZSL, which contains two new ZSL solutions based on generative models and graph propagation models, respectively, for effectively utilizing the disentangled ontology embeddings. Extensive evaluations have been conducted on five benchmarks across zero-shot image classification (ZS-IMGC) and zero-shot KG completion (ZS-KGC). DOZSL often achieves better performance than the state-of-the-art, and its components have been verified by ablation studies and case studies. Our codes and datasets are available at https://github.com/zjukg/DOZSL. ",
    "url": "https://arxiv.org/abs/2206.03739",
    "authors": [
      "Yuxia Geng",
      "Jiaoyan Chen",
      "Wen Zhang",
      "Yajing Xu",
      "Zhuo Chen",
      "Jeff Z. Pan",
      "Yufeng Huang",
      "Feiyu Xiong",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03745",
    "title": "Probing for Passwords -- Privacy Implications of SSIDs in Probe Requests",
    "abstract": "Probe requests help mobile devices discover active Wi-Fi networks. They often contain a multitude of data that can be used to identify and track devices and thereby their users. The past years have been a cat-and-mouse game of improving fingerprinting and introducing countermeasures against fingerprinting. This paper analyses the content of probe requests sent by mobile devices and operating systems in a field experiment. In it, we discover that users (probably by accident) input a wealth of data into the SSID field and find passwords, e-mail addresses, names and holiday locations. With these findings we underline that probe requests should be considered sensitive data and be well protected. To preserve user privacy, we suggest and evaluate a privacy-friendly hash-based construction of probe requests and improved user controls. ",
    "url": "https://arxiv.org/abs/2206.03745",
    "authors": [
      "Johanna Ansohn McDougall",
      "Christian Burkert",
      "Daniel Demmler",
      "Monina Schwarz",
      "Vincent Hubbe",
      "Hannes Federrath"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.03757",
    "title": "On the quick search for the shortest paths in an unweighted dynamic  graph by its projections in brief",
    "abstract": "For the first time proposed: a method for representing the projections of a graph in computer memory and a description based on it of a quick search for shortest paths in unweighted dynamic graphs. The spatial complexity of the projection description does not exceed $(d + 1)\\times n$ words, where $d$ is the diameter and $n$ is the number of vertices of the graph. The temporal difficulty of finding one shortest path between two vertices does not exceed d steps with the duration of elementary time of sampling a machine word. The solution can be applied in time delay-critical routing protocols of computer networks and supercomputers. ",
    "url": "https://arxiv.org/abs/2206.03757",
    "authors": [
      "V.A. Melent'ev"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2206.03796",
    "title": "Adaptive Neural Network-based Unscented Kalman Filter for Spacecraft  Pose Tracking at Rendezvous",
    "abstract": "This paper presents a neural network-based Unscented Kalman Filter (UKF) to track the pose (i.e., position and orientation) of a known, noncooperative, tumbling target spacecraft in a close-proximity rendezvous scenario. The UKF estimates the relative orbital and attitude states of the target with respect to the servicer based on the pose information extracted from incoming monocular images of the target spacecraft with a Convolutional Neural Network (CNN). In order to enable reliable tracking, the process noise covariance matrix of the UKF is tuned online using adaptive state noise compensation. Specifically, the closed-form process noise model for the relative attitude dynamics is newly derived and implemented. In order to enable a comprehensive analysis of the performance and robustness of the proposed CNN-powered UKF, this paper also introduces the Satellite Hardware-In-the-loop Rendezvous Trajectories (SHIRT) dataset which comprises the labeled imagery of two representative rendezvous trajectories in low Earth orbit. For each trajectory, two sets of images are respectively created from a graphics renderer and a robotic testbed to allow testing the filter's robustness across domain gap. The proposed UKF is evaluated on both domains of the trajectories in SHIRT and is shown to have sub-decimeter-level position and degree-level orientation errors at steady-state. ",
    "url": "https://arxiv.org/abs/2206.03796",
    "authors": [
      "Tae Ha Park",
      "Simone D'Amico"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.03799",
    "title": "Dyna-DM: Dynamic Object-aware Self-supervised Monocular Depth Maps",
    "abstract": "Self-supervised monocular depth estimation has been a subject of intense study in recent years, because of its applications in robotics and autonomous driving. Much of the recent work focuses on improving depth estimation by increasing architecture complexity. This paper shows that state-of-the-art performance can also be achieved by improving the learning process rather than increasing model complexity. More specifically, we propose (i) only using invariant pose loss for the first few epochs during training, (ii) disregarding small potentially dynamic objects when training, and (iii) employing an appearance-based approach to separately estimate object pose for truly dynamic objects. We demonstrate that these simplifications reduce GPU memory usage by 29% and result in qualitatively and quantitatively improved depth maps ",
    "url": "https://arxiv.org/abs/2206.03799",
    "authors": [
      "Kieran Saunders",
      "George Vogiatzis",
      "Luis J. Manso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03800",
    "title": "Optimal User Load and Energy Efficiency in User-Centric Cell-Free  Wireless Networks",
    "abstract": "Cell-free massive MIMO is a variant of multiuser MIMO and massive MIMO, in which the total number of antennas $LM$ is distributed among the $L$ remote radio units (RUs) in the system, enabling macrodiversity and joint processing. Due to pilot contamination and system scalability, each RU can only serve a limited number of users. Obtaining the optimal number of users simultaneously served on one resource block (RB) by the $L$ RUs regarding the sum spectral efficiency (SE) is not a simple challenge though, as many of the system parameters are intertwined. For example, the dimension $\\tau_p$ of orthogonal Demodulation Reference Signal (DMRS) pilots limits the number of users that an RU can serve. Thus, depending on $\\tau_p$, the optimal user load yielding the maximum sum SE will vary. Another key parameter is the users' uplink transmit power $P^{\\rm ue}_{\\rm tx}$, where a trade-off between users in outage, interference and energy inefficiency exists. We study the effect of multiple parameters in cell-free massive MIMO on the sum SE and user outage, as well as the performance of different levels of RU antenna distribution. We provide extensive numerical investigations to illuminate the behavior of the system SE with respect to the various parameters, including the effect of the system load, i.e., the number of active users to be served on any RB. The results show that in general a system with many RUs and few RU antennas yields the largest sum SE, where the benefits of distributed antennas reduce in very dense networks. ",
    "url": "https://arxiv.org/abs/2206.03800",
    "authors": [
      "Fabian G\u00f6ttsch",
      "Noboru Osawa",
      "Takeo Ohseki",
      "Kosuke Yamazaki",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.03801",
    "title": "Robust PCA for Subspace Estimation in User-Centric Cell-Free Wireless  Networks",
    "abstract": "We consider a scalable user-centric cell-free massive MIMO network with distributed remote radio units (RUs), enabling macrodiversity and joint processing. Due to the limited uplink (UL) pilot dimension, multiuser interference in the UL pilot transmission phase makes channel estimation a non-trivial problem. We make use of two types of UL pilot signals, sounding reference signal (SRS) and demodulation reference signal (DMRS) pilots, for the estimation of the channel subspace and its instantaneous realization, respectively. The SRS pilots are transmitted over multiple time slots and resource blocks according to a Latin squares based hopping scheme, which aims at averaging out the interference of different SRS co-pilot users. We propose a robust principle component analysis approach for channel subspace estimation from the SRS signal samples, employed at the RUs for each associated user. The estimated subspace is further used at the RUs for DMRS pilot decontamination and instantaneous channel estimation. We provide numerical simulations to compare the system performance using our subspace and channel estimation scheme with the cases of ideal partial subspace/channel knowledge and pilot matching channel estimation. The results show that a system with a properly designed SRS pilot hopping scheme can closely approximate the performance of a genie-aided system. ",
    "url": "https://arxiv.org/abs/2206.03801",
    "authors": [
      "Fabian G\u00f6ttsch",
      "Noboru Osawa",
      "Takeo Ohseki",
      "Kosuke Yamazaki",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.03838",
    "title": "Efficient reversible data hiding via two layers of double-peak embedding",
    "abstract": "Reversible data hiding continues to attract significant attention in recent years. In particular, an increasing number of authors focus on the higher significant bit (HSB) plane of an image which can yield more redundant space. On the other hand, the lower significant bit plane is often discarded in existing schemes due to their harm to the embedding rate. This paper proposes an efficient reversible data hiding scheme via a double-peak two-layer embedding (DTLE) strategy with prediction error expansion. The higher six-bit planes of the image are assigned as the HSB plane, and double prediction error peaks are applied in either embedding layer. This makes fuller use of the redundancy space of images compared with the one error peak strategy. Moreover, we carry out the median-edge detector pre-processing for complex images to reduce the size of the auxiliary information. A series of experimental results show that our DTLE approach achieves up to 83% higher embedding rate on real-world data while providing better image quality. ",
    "url": "https://arxiv.org/abs/2206.03838",
    "authors": [
      "Fuhu Wu",
      "Jian Sun",
      "Shun Zhang",
      "Zhili Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.03846",
    "title": "Sim2real for Reinforcement Learning Driven Next Generation Networks",
    "abstract": "The next generation of networks will actively embrace artificial intelligence (AI) and machine learning (ML) technologies for automation networks and optimal network operation strategies. The emerging network structure represented by Open RAN (O-RAN) conforms to this trend, and the radio intelligent controller (RIC) at the centre of its specification serves as an ML applications host. Various ML models, especially Reinforcement Learning (RL) models, are regarded as the key to solving RAN-related multi-objective optimization problems. However, it should be recognized that most of the current RL successes are confined to abstract and simplified simulation environments, which may not directly translate to high performance in complex real environments. One of the main reasons is the modelling gap between the simulation and the real environment, which could make the RL agent trained by simulation ill-equipped for the real environment. This issue is termed as the sim2real gap. This article brings to the fore the sim2real challenge within the context of O-RAN. Specifically, it emphasizes the characteristics, and benefits that the digital twins (DT) could have as a place for model development and verification. Several use cases are presented to exemplify and demonstrate failure modes of the simulations trained RL model in real environments. The effectiveness of DT in assisting the development of RL algorithms is discussed. Then the current state of the art learning-based methods commonly used to overcome the sim2real challenge are presented. Finally, the development and deployment concerns for the RL applications realisation in O-RAN are discussed from the view of the potential issues like data interaction, environment bottlenecks, and algorithm design. ",
    "url": "https://arxiv.org/abs/2206.03846",
    "authors": [
      "Peizheng Li",
      "Jonathan Thomas",
      "Xiaoyang Wang",
      "Hakan Erdol",
      "Abdelrahim Ahmad",
      "Rui Inacio",
      "Shipra Kapoor",
      "Arjun Parekh",
      "Angela Doufexi",
      "Arman Shojaeifard",
      "Robert Piechocki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2206.03858",
    "title": "Rotation-Equivariant Conditional Spherical Neural Fields for Learning a  Natural Illumination Prior",
    "abstract": "Inverse rendering is an ill-posed problem. Previous work has sought to resolve this by focussing on priors for object or scene shape or appearance. In this work, we instead focus on a prior for natural illuminations. Current methods rely on spherical harmonic lighting or other generic representations and, at best, a simplistic prior on the parameters. We propose a conditional neural field representation based on a variational auto-decoder with a SIREN network and, extending Vector Neurons, build equivariance directly into the network. Using this we develop a rotation-equivariant, high dynamic range (HDR) neural illumination model that is compact and able to express complex, high-frequency features of natural environment maps. Training our model on a curated dataset of 1.6K HDR environment maps of natural scenes, we compare it against traditional representations, demonstrate its applicability for an inverse rendering task and show environment map completion from partial observations. A PyTorch implementation, our dataset and trained models can be found at jadgardner.github.io/RENI. ",
    "url": "https://arxiv.org/abs/2206.03858",
    "authors": [
      "James A. D. Gardner",
      "Bernhard Egger",
      "William A. P. Smith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03861",
    "title": "Decentralized Online Regularized Learning Over Random Time-Varying  Graphs",
    "abstract": "We study the decentralized online regularized linear regression algorithm over random time-varying graphs. At each time step, every node runs an online estimation algorithm consisting of an innovation term processing its own new measurement, a consensus term taking a weighted sum of estimations of its own and its neighbors with additive and multiplicative communication noises and a regularization term preventing over-fitting. It is not required that the regression matrices and graphs satisfy special statistical assumptions such as mutual independence, spatio-temporal independence or stationarity. We develop the nonnegative supermartingale inequality of the estimation error, and prove that the estimations of all nodes converge to the unknown true parameter vector almost surely if the algorithm gains, graphs and regression matrices jointly satisfy the sample path spatio-temporal persistence of excitation condition. Especially, this condition holds by choosing appropriate algorithm gains if the graphs are uniformly conditionally jointly connected and conditionally balanced, and the regression models of all nodes are uniformly conditionally spatio-temporally jointly observable, under which the algorithm converges in mean square and almost surely. In addition, we prove that the regret upper bound $\\mathcal O(T^{1-\\tau}\\ln T)$, where $\\tau\\in (0.5,1)$ is a constant depending on the algorithm gains. ",
    "url": "https://arxiv.org/abs/2206.03861",
    "authors": [
      "Xiwei Zhang",
      "Tao Li",
      "Xiaozheng Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.03865",
    "title": "Fault-Aware Neural Code Rankers",
    "abstract": "Large language models (LLMs) have demonstrated an impressive ability to generate code for various programming tasks. In many instances, LLMs can generate a correct program for a task when given numerous trials. Consequently, a recent trend is to do large scale sampling of programs using a model and then filtering/ranking the programs based on the program execution on a small number of known unit tests to select one candidate solution. However, these approaches assume that the unit tests are given and assume the ability to safely execute the generated programs (which can do arbitrary dangerous operations such as file manipulations). Both of the above assumptions are impractical in real-world software development. In this paper, we propose fault-aware neural code rankers that can predict the correctness of a sampled program without executing it. The fault-aware rankers are trained to predict different kinds of execution information such as predicting the exact compile/runtime error type (e.g., an IndexError or a TypeError). We show that our fault-aware rankers can significantly increase the pass@1 accuracy of various code generation models (including Codex, GPT-Neo, GPT-J) on APPS, HumanEval and MBPP datasets. ",
    "url": "https://arxiv.org/abs/2206.03865",
    "authors": [
      "Jeevana Priya Inala",
      "Chenglong Wang",
      "Mei Yang",
      "Andres Codas",
      "Mark Encarnaci\u00f3n",
      "Shuvendu K Lahiri",
      "Madanlal Musuvathi",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2206.03876",
    "title": "Progressive GANomaly: Anomaly detection with progressively growing GANs",
    "abstract": "In medical imaging, obtaining large amounts of labeled data is often a hurdle, because annotations and pathologies are scarce. Anomaly detection is a method that is capable of detecting unseen abnormal data while only being trained on normal (unannotated) data. Several algorithms based on generative adversarial networks (GANs) exist to perform this task, yet certain limitations are in place because of the instability of GANs. This paper proposes a new method by combining an existing method, GANomaly, with progressively growing GANs. The latter is known to be more stable, considering its ability to generate high-resolution images. The method is tested using Fashion MNIST, Medical Out-of-Distribution Analysis Challenge (MOOD), and in-house brain MRI; using patches of sizes 16x16 and 32x32. Progressive GANomaly outperforms a one-class SVM or regular GANomaly on Fashion MNIST. Artificial anomalies are created in MOOD images with varying intensities and diameters. Progressive GANomaly detected the most anomalies with varying intensity and size. Additionally, the intermittent reconstructions are proven to be better from progressive GANomaly. On the in-house brain MRI dataset, regular GANomaly outperformed the other methods. ",
    "url": "https://arxiv.org/abs/2206.03876",
    "authors": [
      "Djennifer K. Madzia-Madzou",
      "Hugo J. Kuijf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.03933",
    "title": "TURJUMAN: A Public Toolkit for Neural Arabic Machine Translation",
    "abstract": "We present TURJUMAN, a neural toolkit for translating from 20 languages into Modern Standard Arabic (MSA). TURJUMAN exploits the recently-introduced text-to-text Transformer AraT5 model, endowing it with a powerful ability to decode into Arabic. The toolkit offers the possibility of employing a number of diverse decoding methods, making it suited for acquiring paraphrases for the MSA translations as an added value. To train TURJUMAN, we sample from publicly available parallel data employing a simple semantic similarity method to ensure data quality. This allows us to prepare and release AraOPUS-20, a new machine translation benchmark. We publicly release our translation toolkit (TURJUMAN) as well as our benchmark dataset (AraOPUS-20). ",
    "url": "https://arxiv.org/abs/2206.03933",
    "authors": [
      "El Moatez Billah Nagoudi",
      "AbdelRahim Elmadany",
      "Muhammad Abdul-Mageed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03943",
    "title": "Robust Environment Perception for Automated Driving: A Unified Learning  Pipeline for Visual-Infrared Object Detection",
    "abstract": "The RGB complementary metal-oxidesemiconductor (CMOS) sensor works within the visible light spectrum. Therefore it is very sensitive to environmental light conditions. On the contrary, a long-wave infrared (LWIR) sensor operating in 8-14 micro meter spectral band, functions independent of visible light. In this paper, we exploit both visual and thermal perception units for robust object detection purposes. After delicate synchronization and (cross-) labeling of the FLIR [1] dataset, this multi-modal perception data passes through a convolutional neural network (CNN) to detect three critical objects on the road, namely pedestrians, bicycles, and cars. After evaluation of RGB and infrared (thermal and infrared are often used interchangeably) sensors separately, various network structures are compared to fuse the data at the feature level effectively. Our RGB-thermal (RGBT) fusion network, which takes advantage of a novel entropy-block attention module (EBAM), outperforms the state-of-the-art network [2] by 10% with 82.9% mAP. ",
    "url": "https://arxiv.org/abs/2206.03943",
    "authors": [
      "Mohsen Vadidar",
      "Ali Kariminezhad",
      "Christian Mayr",
      "Laurent Kloeker",
      "Lutz Eckstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2206.03957",
    "title": "Construction of a spike-based memory using neural-like logic gates based  on Spiking Neural Networks on SpiNNaker",
    "abstract": "Neuromorphic engineering concentrates the efforts of a large number of researchers due to its great potential as a field of research, in a search for the exploitation of the advantages of the biological nervous system and the brain as a whole for the design of more efficient and real-time capable applications. For the development of applications as close to biology as possible, Spiking Neural Networks (SNNs) are used, considered biologically-plausible and that form the third generation of Artificial Neural Networks (ANNs). Since some SNN-based applications may need to store data in order to use it later, something that is present both in digital circuits and, in some form, in biology, a spiking memory is needed. This work presents a spiking implementation of a memory, which is one of the most important components in the computer architecture, and which could be essential in the design of a fully spiking computer. In the process of designing this spiking memory, different intermediate components were also implemented and tested. The tests were carried out on the SpiNNaker neuromorphic platform and allow to validate the approach used for the construction of the presented blocks. In addition, this work studies in depth how to build spiking blocks using this approach and includes a comparison between it and those used in other similar works focused on the design of spiking components, which include both spiking logic gates and spiking memory. All implemented blocks and developed tests are available in a public repository. ",
    "url": "https://arxiv.org/abs/2206.03957",
    "authors": [
      "Alvaro Ayuso-Martinez",
      "Daniel Casanueva-Morato",
      "Juan P. Dominguez-Morales",
      "Angel Jimenez-Fernandez",
      "Gabriel Jimenez-Moreno"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.03970",
    "title": "Narrowing the Coordinate-frame Gap in Behavior Prediction Models:  Distillation for Efficient and Accurate Scene-centric Motion Forecasting",
    "abstract": "Behavior prediction models have proliferated in recent years, especially in the popular real-world robotics application of autonomous driving, where representing the distribution over possible futures of moving agents is essential for safe and comfortable motion planning. In these models, the choice of coordinate frames to represent inputs and outputs has crucial trade offs which broadly fall into one of two categories. Agent-centric models transform inputs and perform inference in agent-centric coordinates. These models are intrinsically invariant to translation and rotation between scene elements, are best-performing on public leaderboards, but scale quadratically with the number of agents and scene elements. Scene-centric models use a fixed coordinate system to process all agents. This gives them the advantage of sharing representations among all agents, offering efficient amortized inference computation which scales linearly with the number of agents. However, these models have to learn invariance to translation and rotation between scene elements, and typically underperform agent-centric models. In this work, we develop knowledge distillation techniques between probabilistic motion forecasting models, and apply these techniques to close the gap in performance between agent-centric and scene-centric models. This improves scene-centric model performance by 13.2% on the public Argoverse benchmark, 7.8% on Waymo Open Dataset and up to 9.4% on a large In-House dataset. These improved scene-centric models rank highly in public leaderboards and are up to 15 times more efficient than their agent-centric teacher counterparts in busy scenes. ",
    "url": "https://arxiv.org/abs/2206.03970",
    "authors": [
      "DiJia Su",
      "Bertrand Douillard",
      "Rami Al-Rfou",
      "Cheolho Park",
      "Benjamin Sapp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.03990",
    "title": "Data-driven hysteretic behavior simulation based on weighted stacked  pyramid neural network architecture",
    "abstract": "An accurate and efficient simulation of the hysteretic behavior of materials and components is essential for structural analysis. The surrogate model based on neural networks shows significant potential in balancing efficiency and accuracy. However, its serial information flow and prediction based on single-level features adversely affect the network performance. Therefore, a weighted stacked pyramid neural network architecture is proposed herein. This network establishes a pyramid architecture by introducing multi-level shortcuts to directly integrate features in the output module. In addition, a weighted stacked strategy is proposed to replace the conventional feature fusion method. The weights of the features are determined based on their levels. These basic principles are verified, and key network settings are discussed. Subsequently, the redesigned architectures are compared with other commonly used algorithms. Results show that the testing mean-square error (MSE) loss of the networks on varied datasets can be reduced by an average of 34.7%. The redesigned architectures outperform 87.5% of cases, and the proposed Pyramid-GA network has the best overall performance. ",
    "url": "https://arxiv.org/abs/2206.03990",
    "authors": [
      "Yongjia Xu",
      "Xinzheng Lu",
      "Yifan Fei",
      "Yuli Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.04028",
    "title": "CO^3: Cooperative Unsupervised 3D Representation Learning for Autonomous  Driving",
    "abstract": "Unsupervised contrastive learning for indoor-scene point clouds has achieved great successes. However, unsupervised learning point clouds in outdoor scenes remains challenging because previous methods need to reconstruct the whole scene and capture partial views for the contrastive objective. This is infeasible in outdoor scenes with moving objects, obstacles, and sensors. In this paper, we propose CO^3, namely Cooperative Contrastive Learning and Contextual Shape Prediction, to learn 3D representation for outdoor-scene point clouds in an unsupervised manner. CO^3 has several merits compared to existing methods. (1) It utilizes LiDAR point clouds from vehicle-side and infrastructure-side to build views that differ enough but meanwhile maintain common semantic information for contrastive learning, which are more appropriate than views built by previous methods. (2) Alongside the contrastive objective, shape context prediction is proposed as pre-training goal and brings more task-relevant information for unsupervised 3D point cloud representation learning, which are beneficial when transferring the learned representation to downstream detection tasks. (3) As compared to previous methods, representation learned by CO^3 is able to be transferred to different outdoor scene dataset collected by different type of LiDAR sensors. (4) CO^3 improves current state-of-the-art methods on both Once and KITTI datasets by up to 2.58 mAP. Codes and models will be released. We believe CO^3 will facilitate understanding LiDAR point clouds in outdoor scene. ",
    "url": "https://arxiv.org/abs/2206.04028",
    "authors": [
      "Runjian Chen",
      "Yao Mu",
      "Runsen Xu",
      "Wenqi Shao",
      "Chenhan Jiang",
      "Hang Xu",
      "Zhenguo Li",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.04041",
    "title": "Neural Collapse: A Review on Modelling Principles and Generalization",
    "abstract": "With a recent observation of the \"Neural Collapse (NC)\" phenomena by Papyan et al., various efforts have been made to model it and analyse the implications. Neural collapse describes that in deep classifier networks, the class features of the final hidden layer associated with training data tend to collapse to the respective class feature means. Thus, simplifying the behaviour of the last layer classifier to that of a nearest-class center decision rule. In this work, we analyse the principles which aid in modelling such a phenomena from the ground up and show how they can build a common understanding of the recently proposed models that try to explain NC. We hope that our analysis presents a multifaceted perspective on modelling NC and aids in forming connections with the generalization capabilities of neural networks. Finally, we conclude by discussing the avenues for further research and propose potential research problems. ",
    "url": "https://arxiv.org/abs/2206.04041",
    "authors": [
      "Vignesh Kothapalli",
      "Ebrahim Rasromani",
      "Vasudev Awatramani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.04042",
    "title": "Learning Ego 3D Representation as Ray Tracing",
    "abstract": "A self-driving perception model aims to extract 3D semantic representations from multiple cameras collectively into the bird's-eye-view (BEV) coordinate frame of the ego car in order to ground downstream planner. Existing perception methods often rely on error-prone depth estimation of the whole scene or learning sparse virtual 3D representations without the target geometry structure, both of which remain limited in performance and/or capability. In this paper, we present a novel end-to-end architecture for ego 3D representation learning from an arbitrary number of unconstrained camera views. Inspired by the ray tracing principle, we design a polarized grid of \"imaginary eyes\" as the learnable ego 3D representation and formulate the learning process with the adaptive attention mechanism in conjunction with the 3D-to-2D projection. Critically, this formulation allows extracting rich 3D representation from 2D images without any depth supervision, and with the built-in geometry structure consistent w.r.t. BEV. Despite its simplicity and versatility, extensive experiments on standard BEV visual tasks (e.g., camera-based 3D object detection and BEV segmentation) show that our model outperforms all state-of-the-art alternatives significantly, with an extra advantage in computational efficiency from multi-task learning. ",
    "url": "https://arxiv.org/abs/2206.04042",
    "authors": [
      "Jiachen Lu",
      "Zheyuan Zhou",
      "Xiatian Zhu",
      "Hang Xu",
      "Li Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03563",
    "title": "Two Ways of Understanding Social Dynamics: Analyzing the Predictability  of Emergent of Objects in Reddit r/place Dependent on Locality in Space and  Time",
    "abstract": "Lately, studying social dynamics in interacting agents has been boosted by the power of computer models, which bring the richness of qualitative work, while offering the precision, transparency, extensiveness, and replicability of statistical and mathematical approaches. A particular set of phenomena for the study of social dynamics is Web collaborative platforms. A dataset of interest is r/place, a collaborative social experiment held in 2017 on Reddit, which consisted of a shared online canvas of 1000 pixels by 1000 pixels co-edited by over a million recorded users over 72 hours. In this paper, we designed and compared two methods to analyze the dynamics of this experiment. Our first method consisted in approximating the set of 2D cellular-automata-like rules used to generate the canvas images and how these rules change over time. The second method consisted in a convolutional neural network (CNN) that learned an approximation to the generative rules in order to generate the complex outcomes of the canvas. Our results indicate varying context-size dependencies for the predictability of different objects in r/place in time and space. They also indicate a surprising peak in difficulty to statistically infer behavioral rules towards the middle of the social experiment, while user interactions did not drop until before the end. The combination of our two approaches, one rule-based and the other statistical CNN-based, shows the ability to highlight diverse aspects of analyzing social dynamics. ",
    "url": "https://arxiv.org/abs/2206.03563",
    "authors": [
      "Alyssa M Adams",
      "Javier Fernandez",
      "Olaf Witkowski"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)",
      "Cellular Automata and Lattice Gases (nlin.CG)"
    ]
  },
  {
    "id": "arXiv:2206.03587",
    "title": "ABC(T)-graphs: an axiomatic characterization of the median procedure in  graphs with connected and G$^2$-connected medians",
    "abstract": "The median function is a location/consensus function that maps any profile $\\pi$ (a finite multiset of vertices) to the set of vertices that minimize the distance sum to vertices from $\\pi$. The median function satisfies several simple axioms: Anonymity (A), Betweeness (B), and Consistency (C). McMorris, Mulder, Novick and Powers (2015) defined the ABC-problem for consensus functions on graphs as the problem of characterizing the graphs (called, ABC-graphs) for which the unique consensus function satisfying the axioms (A), (B), and (C) is the median function. In this paper, we show that modular graphs with $G^2$-connected medians (in particular, bipartite Helly graphs) are ABC-graphs. On the other hand, the addition of some simple local axioms satisfied by the median function in all graphs (axioms (T), and (T$_2$)) enables us to show that all graphs with connected median (comprising Helly graphs, median graphs, basis graphs of matroids and even $\\Delta$-matroids) are ABCT-graphs and that benzenoid graphs are ABCT$_2$-graphs. McMorris et al (2015) proved that the graphs satisfying the pairing property (called the intersecting-interval property in their paper) are ABC-graphs. We prove that graphs with the pairing property constitute a proper subclass of bipartite Helly graphs and we discuss the complexity status of the recognition problem of such graphs. ",
    "url": "https://arxiv.org/abs/2206.03587",
    "authors": [
      "Laurine B\u00e9n\u00e9teau",
      "J\u00e9r\u00e9mie Chalopin",
      "Victor Chepoi",
      "Yann Vax\u00e8s"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2206.03734",
    "title": "On gradient descent training under data augmentation with on-line noisy  copies",
    "abstract": "In machine learning, data augmentation (DA) is a technique for improving the generalization performance. In this paper, we mainly considered gradient descent of linear regression under DA using noisy copies of datasets, in which noise is injected into inputs. We analyzed the situation where random noisy copies are newly generated and used at each epoch; i.e., the case of using on-line noisy copies. Therefore, it is viewed as an analysis on a method using noise injection into training process by DA manner; i.e., on-line version of DA. We derived the averaged behavior of training process under three situations which are the full-batch training under the sum of squared errors, the full-batch and mini-batch training under the mean squared error. We showed that, in all cases, training for DA with on-line copies is approximately equivalent to a ridge regression training whose regularization parameter corresponds to the variance of injected noise. On the other hand, we showed that the learning rate is multiplied by the number of noisy copies plus one in full-batch under the sum of squared errors and the mini-batch under the mean squared error; i.e., DA with on-line copies yields apparent acceleration of training. The apparent acceleration and regularization effect come from the original part and noise in a copy data respectively. These results are confirmed in a numerical experiment. In the numerical experiment, we found that our result can be approximately applied to usual off-line DA in under-parameterization scenario and can not in over-parametrization scenario. Moreover, we experimentally investigated the training process of neural networks under DA with off-line noisy copies and found that our analysis on linear regression is possible to be applied to neural networks. ",
    "url": "https://arxiv.org/abs/2206.03734",
    "authors": [
      "Katsuyuki Hagiwara"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03743",
    "title": "Using Mixed-Effect Models to Learn Bayesian Networks from Related Data  Sets",
    "abstract": "We commonly assume that data are a homogeneous set of observations when learning the structure of Bayesian networks. However, they often comprise different data sets that are related but not homogeneous because they have been collected in different ways or from different populations. In our previous work (Azzimonti, Corani and Scutari, 2021), we proposed a closed-form Bayesian Hierarchical Dirichlet score for discrete data that pools information across related data sets to learn a single encompassing network structure, while taking into account the differences in their probabilistic structures. In this paper, we provide an analogous solution for learning a Bayesian network from continuous data using mixed-effects models to pool information across the related data sets. We study its structural, parametric, predictive and classification accuracy and we show that it outperforms both conditional Gaussian Bayesian networks (that do not perform any pooling) and classical Gaussian Bayesian networks (that disregard the heterogeneous nature of the data). The improvement is marked for low sample sizes and for unbalanced data sets. ",
    "url": "https://arxiv.org/abs/2206.03743",
    "authors": [
      "Marco Scutari",
      "Christopher Marquis",
      "Laura Azzimonti"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03823",
    "title": "Multi-channel neural networks for predicting influenza A virus hosts and  antigenic types",
    "abstract": "Influenza occurs every season and occasionally causes pandemics. Despite its low mortality rate, influenza is a major public health concern, as it can be complicated by severe diseases like pneumonia. A fast, accurate and low-cost method to predict the origin host and subtype of influenza viruses could help reduce virus transmission and benefit resource-poor areas. In this work, we propose multi-channel neural networks to predict antigenic types and hosts of influenza A viruses with hemagglutinin and neuraminidase protein sequences. An integrated data set containing complete protein sequences were used to produce a pre-trained model, and two other data sets were used for testing the model's performance. One test set contained complete protein sequences, and another test set contained incomplete protein sequences. The results suggest that multi-channel neural networks are applicable and promising for predicting influenza A virus hosts and antigenic subtypes with complete and partial protein sequences. ",
    "url": "https://arxiv.org/abs/2206.03823",
    "authors": [
      "Yanhua Xu",
      "Dominik Wojtczak"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03927",
    "title": "Boundary between noise and information applied to filtering neural  network weight matrices",
    "abstract": "Deep neural networks have been successfully applied to a broad range of problems where overparametrization yields weight matrices which are partially random. A comparison of weight matrix singular vectors to the Porter-Thomas distribution suggests that there is a boundary between randomness and learned information in the singular value spectrum. Inspired by this finding, we introduce an algorithm for noise filtering, which both removes small singular values and reduces the magnitude of large singular values to counteract the effect of level repulsion between the noise and the information part of the spectrum. For networks trained in the presence of label noise, we indeed find that the generalization performance improves significantly due to noise filtering. ",
    "url": "https://arxiv.org/abs/2206.03927",
    "authors": [
      "Max Staats",
      "Matthias Thamm",
      "Bernd Rosenow"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03935",
    "title": "Dual-Distribution Discrepancy for Anomaly Detection in Chest X-Rays",
    "abstract": "Chest X-ray (CXR) is the most typical radiological exam for diagnosis of various diseases. Due to the expensive and time-consuming annotations, detecting anomalies in CXRs in an unsupervised fashion is very promising. However, almost all of the existing methods consider anomaly detection as a One-Class Classification (OCC) problem. They model the distribution of only known normal images during training and identify the samples not conforming to normal profile as anomalies in the testing phase. A large number of unlabeled images containing anomalies are thus ignored in the training phase, although they are easy to obtain in clinical practice. In this paper, we propose a novel strategy, Dual-distribution Discrepancy for Anomaly Detection (DDAD), utilizing both known normal images and unlabeled images. The proposed method consists of two modules, denoted as A and B. During training, module A takes both known normal and unlabeled images as inputs, capturing anomalous features from unlabeled images in some way, while module B models the distribution of only known normal images. Subsequently, the inter-discrepancy between modules A and B, and intra-discrepancy inside module B are designed as anomaly scores to indicate anomalies. Experiments on three CXR datasets demonstrate that the proposed DDAD achieves consistent, significant gains and outperforms state-of-the-art methods. Code is available at https://github.com/caiyu6666/DDAD. ",
    "url": "https://arxiv.org/abs/2206.03935",
    "authors": [
      "Yu Cai",
      "Hao Chen",
      "Xin Yang",
      "Yu Zhou",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03955",
    "title": "Out-of-Distribution Detection with Class Ratio Estimation",
    "abstract": "Density-based Out-of-distribution (OOD) detection has recently been shown unreliable for the task of detecting OOD images. Various density ratio based approaches achieve good empirical performance, however methods typically lack a principled probabilistic modelling explanation. In this work, we propose to unify density ratio based methods under a novel framework that builds energy-based models and employs differing base distributions. Under our framework, the density ratio can be viewed as the unnormalized density of an implicit semantic distribution. Further, we propose to directly estimate the density ratio of a data sample through class ratio estimation. We report competitive results on OOD image problems in comparison with recent work that alternatively requires training of deep generative models for the task. Our approach enables a simple and yet effective path towards solving the OOD detection problem. ",
    "url": "https://arxiv.org/abs/2206.03955",
    "authors": [
      "Mingtian Zhang",
      "Andi Zhang",
      "Tim Z. Xiao",
      "Yitong Sun",
      "Steven McDonagh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03956",
    "title": "The number of small-degree vertices in matchstick graphs",
    "abstract": "A matchstick graph is a crossing-free unit-distance graph in the plane. Harborth (1981) proposed the problem of determining whether there exists a matchstick graph in which every vertex has degree exactly $5$. In 1982, Blokhuis gave a proof of non-existence. A shorter proof was found by Kurz and Pinchasi (2011) using a charging method. We combine their method with the isoperimetric inequality to show that there are $\\Omega(\\sqrt{n})$ vertices in a matchstick graph on $n$ vertices that are of degree at most $4$, which is asymptotically tight. ",
    "url": "https://arxiv.org/abs/2206.03956",
    "authors": [
      "J\u00e9r\u00e9my Lavoll\u00e9e",
      "Konrad J. Swanepoel"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2206.03992",
    "title": "Neural Diffusion Processes",
    "abstract": "Gaussian processes provide an elegant framework for specifying prior and posterior distributions over functions. They are, however, also computationally expensive, and limited by the expressivity of their covariance function. We propose Neural Diffusion Processes (NDPs), a novel approach based upon diffusion models, that learn to sample from distributions over functions. Using a novel attention block, we can incorporate properties of stochastic processes, such as exchangeability, directly into the NDP's architecture. We empirically show that NDPs are able to capture functional distributions that are close to the true Bayesian posterior of a Gaussian process. This enables a variety of downstream tasks, including hyperparameter marginalisation and Bayesian optimisation. ",
    "url": "https://arxiv.org/abs/2206.03992",
    "authors": [
      "Vincent Dutordoir",
      "Alan Saul",
      "Zoubin Ghahramani",
      "Fergus Simpson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.04011",
    "title": "Robust Semantic Communications with Masked VQ-VAE Enabled Codebook",
    "abstract": "Although semantic communications have exhibited satisfactory performance for a large number of tasks, the impact of semantic noise and the robustness of the systems have not been well investigated. Semantic noise refers to the misleading between the intended semantic symbols and received ones, thus cause the failure of tasks. In this paper, we first propose a framework for the robust end-to-end semantic communication systems to combat the semantic noise. In particular, we analyze sample-dependent and sample-independent semantic noise. To combat the semantic noise, the adversarial training with weight perturbation is developed to incorporate the samples with semantic noise in the training dataset. Then, we propose to mask a portion of the input, where the semantic noise appears frequently, and design the masked vector quantized-variational autoencoder (VQ-VAE) with the noise-related masking strategy. We use a discrete codebook shared by the transmitter and the receiver for encoded feature representation. To further improve the system robustness, we develop a feature importance module (FIM) to suppress the noise-related and task-unrelated features. Thus, the transmitter simply needs to transmit the indices of these important task-related features in the codebook. Simulation results show that the proposed method can be applied in many downstream tasks and significantly improve the robustness against semantic noise with remarkable reduction on the transmission overhead. ",
    "url": "https://arxiv.org/abs/2206.04011",
    "authors": [
      "Qiyu Hu",
      "Guangyi Zhang",
      "Zhijin Qin",
      "Yunlong Cai",
      "Guanding Yu",
      "Geoffrey Ye Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1907.09320",
    "title": "An Efficient Target Detection and Recognition Method in Aerial  Remote-sensing Images Based on Multiangle Regions-of-Interest",
    "abstract": " Comments: 5 pages, 3 figures ",
    "url": "https://arxiv.org/abs/1907.09320",
    "authors": [
      "Guangcun Shan",
      "Hongyu Wang",
      "Wei Liang",
      "Congcong Liu",
      "Qizi Ma",
      "Quan Quan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2006.14042",
    "title": "Blacklight: Defending Black-Box Adversarial Attacks on Deep Neural  Networks",
    "abstract": " Title: Blacklight: Defending Black-Box Adversarial Attacks on Deep Neural  Networks ",
    "url": "https://arxiv.org/abs/2006.14042",
    "authors": [
      "Huiying Li",
      "Shawn Shan",
      "Emily Wenger",
      "Jiayun Zhang",
      "Haitao Zheng",
      "Ben Y. Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2008.02965",
    "title": "Improve Generalization and Robustness of Neural Networks via Weight  Scale Shifting Invariant Regularizations",
    "abstract": " Comments: 14 pages, 5 figures, Accepted by ICML 2021 Workshop on Adversarial Machine Learning ",
    "url": "https://arxiv.org/abs/2008.02965",
    "authors": [
      "Ziquan Liu",
      "Yufei Cui",
      "Antoni B. Chan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2011.13492",
    "title": "Dissipative Deep Neural Dynamical Systems",
    "abstract": " Comments: Under review at IEEE Open Journal of Control Systems ",
    "url": "https://arxiv.org/abs/2011.13492",
    "authors": [
      "Jan Drgona",
      "Soumya Vasisht",
      "Aaron Tuor",
      "Draguna Vrabie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2101.12673",
    "title": "Topological Interference Management with Adversarial Topology  Perturbation: An Algorithmic Perspective",
    "abstract": " Title: Topological Interference Management with Adversarial Topology  Perturbation: An Algorithmic Perspective ",
    "url": "https://arxiv.org/abs/2101.12673",
    "authors": [
      "Ya-Chun Liang",
      "Chung-Shou Liao",
      "Xinping Yi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2102.07990",
    "title": "Through-the-Wall Radar under Electromagnetic Complex Wall: A Deep  Learning Approach",
    "abstract": " Title: Through-the-Wall Radar under Electromagnetic Complex Wall: A Deep  Learning Approach ",
    "url": "https://arxiv.org/abs/2102.07990",
    "authors": [
      "Fardin Ghorbani",
      "Hossein Soleimani"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2103.06727",
    "title": "Hybrid Physics and Deep Learning Model for Interpretable Vehicle State  Prediction",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2103.06727",
    "authors": [
      "Alexandra Baier",
      "Zeyd Boukhers",
      "Steffen Staab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.08482",
    "title": "Surface Topography Characterization Using a Simple Optical Device and  Artificial Neural Networks",
    "abstract": " Comments: Submitted to Mechanical Systems and Signal Processing (MSSP) ",
    "url": "https://arxiv.org/abs/2103.08482",
    "authors": [
      "Christoph Angermann",
      "Markus Haltmeier",
      "Christian Laubichler",
      "Steinbj\u00f6rn J\u00f3nsson",
      "Matthias Schwab",
      "Ad\u00e9la Moravov\u00e1",
      "Constantin Kiesling",
      "Martin Kober",
      "Wolfgang Fimml"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.08323",
    "title": "Random and Adversarial Bit Error Robustness: Energy-Efficient and Secure  DNN Accelerators",
    "abstract": " Title: Random and Adversarial Bit Error Robustness: Energy-Efficient and Secure  DNN Accelerators ",
    "url": "https://arxiv.org/abs/2104.08323",
    "authors": [
      "David Stutz",
      "Nandhini Chandramoorthy",
      "Matthias Hein",
      "Bernt Schiele"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.09650",
    "title": "Mapping the Internet: Modelling Entity Interactions in Complex  Heterogeneous Networks",
    "abstract": " Comments: Master thesis, 108 page, 56 figures ",
    "url": "https://arxiv.org/abs/2104.09650",
    "authors": [
      "Simon Mandlik",
      "Tomas Pevny"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2106.14922",
    "title": "Cosmic-CoNN: A Cosmic Ray Detection Deep-Learning Framework, Dataset,  and Toolkit",
    "abstract": " Comments: 18 pages, 12 figures, 3 tables. Submitted to AAS Journals. See this https URL for the open-source software and this https URL for the dataset ",
    "url": "https://arxiv.org/abs/2106.14922",
    "authors": [
      "Chengyuan Xu",
      "Curtis McCully",
      "Boning Dong",
      "D. Andrew Howell",
      "Pradeep Sen"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.03019",
    "title": "SelfCF: A Simple Framework for Self-supervised Collaborative Filtering",
    "abstract": " Comments: 23 pages ",
    "url": "https://arxiv.org/abs/2107.03019",
    "authors": [
      "Xin Zhou",
      "Aixin Sun",
      "Yong Liu",
      "Jie Zhang",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.03605",
    "title": "PNC Enabled IIoT: A General Framework for Channel-Coded Asymmetric  Physical-Layer Network Coding",
    "abstract": " Comments: To appear in IEEE TWC ",
    "url": "https://arxiv.org/abs/2107.03605",
    "authors": [
      "Zhaorui Wang",
      "Ling Liu",
      "Shengli Zhang",
      "Pengpeng Dong",
      "Qing Yang",
      "Taotao Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2107.05455",
    "title": "A Local Diagnosis Algorithm for Hypercube-like Networks under the BGM  Diagnosis Model",
    "abstract": " Title: A Local Diagnosis Algorithm for Hypercube-like Networks under the BGM  Diagnosis Model ",
    "url": "https://arxiv.org/abs/2107.05455",
    "authors": [
      "Cheng-Kuan Lin",
      "Tzu-Liang Kung",
      "Chun-Nan Hung",
      "Yuan-Hsiang Teng"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2107.05893",
    "title": "PU-Flow: a Point Cloud Upsampling Network with Normalizing Flows",
    "abstract": " Title: PU-Flow: a Point Cloud Upsampling Network with Normalizing Flows ",
    "url": "https://arxiv.org/abs/2107.05893",
    "authors": [
      "Aihua Mao",
      "Zihui Du",
      "Junhui Hou",
      "Yaqi Duan",
      "Yong-jin Liu",
      "Ying He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.01538",
    "title": "Geometry of Linear Convolutional Networks",
    "abstract": " Comments: 38 pages, 3 figures, 2 tables; appearing in SIAM Journal on Applied Algebra and Geometry (SIAGA) ",
    "url": "https://arxiv.org/abs/2108.01538",
    "authors": [
      "Kathl\u00e9n Kohn",
      "Thomas Merkh",
      "Guido Mont\u00fafar",
      "Matthew Trager"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Geometry (math.AG)"
    ]
  },
  {
    "id": "arXiv:2109.03127",
    "title": "Rare Tokens Degenerate All Tokens: Improving Neural Text Generation via  Adaptive Gradient Gating for Rare Token Embeddings",
    "abstract": " Comments: ACL 2022 Main Conference Camera-Ready Version ",
    "url": "https://arxiv.org/abs/2109.03127",
    "authors": [
      "Sangwon Yu",
      "Jongyoon Song",
      "Heeseung Kim",
      "Seong-min Lee",
      "Woo-Jong Ryu",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2109.06979",
    "title": "CORNET 2.0: A Co-Simulation Middleware for Robot Networks",
    "abstract": " Title: CORNET 2.0: A Co-Simulation Middleware for Robot Networks ",
    "url": "https://arxiv.org/abs/2109.06979",
    "authors": [
      "Srikrishna Acharya",
      "Bharadwaj Amrutur",
      "Mukunda Bharatheesha",
      "Yogesh Simmhan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2110.00719",
    "title": "One-Bit Matrix Completion with Differential Privacy",
    "abstract": " Comments: In this version, we have fixed some typos and updated references ",
    "url": "https://arxiv.org/abs/2110.00719",
    "authors": [
      "Zhengpin Li",
      "Zheng Wei",
      "Zengfeng Huang",
      "Xiaojun Mao",
      "Jian Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.12735",
    "title": "Practical Galaxy Morphology Tools from Deep Supervised Representation  Learning",
    "abstract": " Comments: 20 pages plus appendix. Accepted to MNRAS (open-access DOI below). Code, documentation, pretrained models: this https URL (PyTorch and TensorFlow) ",
    "url": "https://arxiv.org/abs/2110.12735",
    "authors": [
      "Mike Walmsley",
      "Anna M. M. Scaife",
      "Chris Lintott",
      "Michelle Lochner",
      "Verlon Etsebeth",
      "Tobias G\u00e9ron",
      "Hugh Dickinson",
      "Lucy Fortson",
      "Sandor Kruk",
      "Karen L. Masters",
      "Kameswara Bharadwaj Mantha",
      "Brooke D. Simmons"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.14768",
    "title": "Distributed Asynchronous Games With Causal Memory are Undecidable",
    "abstract": " Title: Distributed Asynchronous Games With Causal Memory are Undecidable ",
    "url": "https://arxiv.org/abs/2110.14768",
    "authors": [
      "Hugo Gimbert"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2111.05535",
    "title": "Optimal Delay-Outage Analysis for Noise-Limited Wireless Networks with  Caching, Computing, and Communications -- Derivations and Proofs",
    "abstract": " Title: Optimal Delay-Outage Analysis for Noise-Limited Wireless Networks with  Caching, Computing, and Communications -- Derivations and Proofs ",
    "url": "https://arxiv.org/abs/2111.05535",
    "authors": [
      "Ming-Chun Lee",
      "Andreas F. Molisch"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2111.07929",
    "title": "High-Rate Convolutional Codes with CRC-Aided List Decoding for Short  Blocklengths",
    "abstract": " Comments: 6 pages; submitted to 2022 IEEE International Conference on Communications (ICC 2022) ",
    "url": "https://arxiv.org/abs/2111.07929",
    "authors": [
      "Wenhui Sui",
      "Hengjie Yang",
      "Brendan Towell",
      "Ava Asmani",
      "Richard D. Wesel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2111.09834",
    "title": "Error estimation for the time to a threshold value in evolutionary  partial differential equations",
    "abstract": " Title: Error estimation for the time to a threshold value in evolutionary  partial differential equations ",
    "url": "https://arxiv.org/abs/2111.09834",
    "authors": [
      "Jehanzeb Chaudhry",
      "Don Estep",
      "Trevor Giannini",
      "Zachary Stevens",
      "Simon Tavener"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2111.15537",
    "title": "Model-Free $\u03bc$ Synthesis via Adversarial Reinforcement Learning",
    "abstract": " Comments: Accepted to ACC 2022 ",
    "url": "https://arxiv.org/abs/2111.15537",
    "authors": [
      "Darioush Keivan",
      "Aaron Havens",
      "Peter Seiler",
      "Geir Dullerud",
      "Bin Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2112.03045",
    "title": "3D Hierarchical Refinement and Augmentation for Unsupervised Learning of  Depth and Pose from Monocular Video",
    "abstract": " Comments: 10 pages, 7 figures, under review ",
    "url": "https://arxiv.org/abs/2112.03045",
    "authors": [
      "Guangming Wang",
      "Jiquan Zhong",
      "Shijie Zhao",
      "Wenhua Wu",
      "Zhe Liu",
      "Hesheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.05935",
    "title": "Nonsmooth Control Barrier Function Design of Continuous Constraints for  Network Connectivity Maintenance",
    "abstract": " Comments: submitted to IEEE Transactions on Robotics ",
    "url": "https://arxiv.org/abs/2112.05935",
    "authors": [
      "Pio Ong",
      "Beatrice Capelli",
      "Lorenzo Sabattini",
      "Jorge Cortes"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2112.09078",
    "title": "SenSnake: A snake robot with contact force sensing for studying  locomotion in complex 3-D terrain",
    "abstract": " Title: SenSnake: A snake robot with contact force sensing for studying  locomotion in complex 3-D terrain ",
    "url": "https://arxiv.org/abs/2112.09078",
    "authors": [
      "Divya Ramesh",
      "Qiyuan Fu",
      "Chen Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Biological Physics (physics.bio-ph)"
    ]
  },
  {
    "id": "arXiv:2201.04756",
    "title": "Roadside Lidar Vehicle Detection and Tracking Using Range And Intensity  Background Subtraction",
    "abstract": " Title: Roadside Lidar Vehicle Detection and Tracking Using Range And Intensity  Background Subtraction ",
    "url": "https://arxiv.org/abs/2201.04756",
    "authors": [
      "Tianya Zhang",
      "Peter J. Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2201.08336",
    "title": "Influences of social media usage on public attitudes and behavior  towards COVID-19 vaccine in the Arab world",
    "abstract": " Title: Influences of social media usage on public attitudes and behavior  towards COVID-19 vaccine in the Arab world ",
    "url": "https://arxiv.org/abs/2201.08336",
    "authors": [
      "Md. Rafiul Biswas",
      "Hazrat Ali",
      "Raian Ali",
      "Zubair Shah"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2202.01136",
    "title": "Probabilistically Robust Learning: Balancing Average- and Worst-case  Performance",
    "abstract": " Title: Probabilistically Robust Learning: Balancing Average- and Worst-case  Performance ",
    "url": "https://arxiv.org/abs/2202.01136",
    "authors": [
      "Alexander Robey",
      "Luiz F. O. Chamon",
      "George J. Pappas",
      "Hamed Hassani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.02340",
    "title": "Selective Network Linearization for Efficient Private Inference",
    "abstract": " Comments: Published in ICML 2022 ",
    "url": "https://arxiv.org/abs/2202.02340",
    "authors": [
      "Minsu Cho",
      "Ameya Joshi",
      "Siddharth Garg",
      "Brandon Reagen",
      "Chinmay Hegde"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03036",
    "title": "Structure-Aware Transformer for Graph Representation Learning",
    "abstract": " Comments: To appear in ICML 2022 ",
    "url": "https://arxiv.org/abs/2202.03036",
    "authors": [
      "Dexiong Chen",
      "Leslie O'Bray",
      "Karsten Borgwardt"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03596",
    "title": "MOST-Net: A Memory Oriented Style Transfer Network for Face Sketch  Synthesis",
    "abstract": " Comments: 7 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2202.03596",
    "authors": [
      "Fan Ji",
      "Muyi Sun",
      "Xingqun Qi",
      "Qi Li",
      "Zhenan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.07554",
    "title": "Between Stochastic and Adversarial Online Convex Optimization: Improved  Regret Bounds via Smoothness",
    "abstract": " Title: Between Stochastic and Adversarial Online Convex Optimization: Improved  Regret Bounds via Smoothness ",
    "url": "https://arxiv.org/abs/2202.07554",
    "authors": [
      "Sarah Sachs",
      "H\u00e9di Hadiji",
      "Tim van Erven",
      "Crist\u00f3bal Guzm\u00e1n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.00203",
    "title": "Graph Enhanced Contrastive Learning for Radiology Findings Summarization",
    "abstract": " Comments: 9 pages, 5 figures, Accepted to ACL 2022 Main Conference ",
    "url": "https://arxiv.org/abs/2204.00203",
    "authors": [
      "Jinpeng Hu",
      "Zhuo Li",
      "Zhihong Chen",
      "Zhen Li",
      "Xiang Wan",
      "Tsung-Hui Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.01321",
    "title": "PRADA: Practical Black-Box Adversarial Attacks against Neural Ranking  Models",
    "abstract": " Title: PRADA: Practical Black-Box Adversarial Attacks against Neural Ranking  Models ",
    "url": "https://arxiv.org/abs/2204.01321",
    "authors": [
      "Chen Wu",
      "Ruqing Zhang",
      "Jiafeng Guo",
      "Maarten de Rijke",
      "Yixing Fan",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2204.08977",
    "title": "Disappeared Command: Spoofing Attack On Automatic Speech Recognition  Systems with Sound Masking",
    "abstract": " Comments: 13 pages, 4 figures. arXiv admin note: text overlap with arXiv:1903.10346 by other authors ",
    "url": "https://arxiv.org/abs/2204.08977",
    "authors": [
      "Jinghui Xu",
      "Jifeng Zhu",
      "Yong Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.13594",
    "title": "Poisoning Deep Learning Based Recommender Model in Federated Learning  Scenarios",
    "abstract": " Comments: This paper has been accepted by the 31st International Joint Conference on Artificial Intelligence (IJCAI-22, Main Track) ",
    "url": "https://arxiv.org/abs/2204.13594",
    "authors": [
      "Dazhong Rong",
      "Qinming He",
      "Jianhai Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.13734",
    "title": "Flexible and scalable privacy assessment for very large datasets, with  an application to official governmental microdata",
    "abstract": " Title: Flexible and scalable privacy assessment for very large datasets, with  an application to official governmental microdata ",
    "url": "https://arxiv.org/abs/2204.13734",
    "authors": [
      "M\u00e1rio S. Alvim",
      "Natasha Fernandes",
      "Annabelle McIver",
      "Carroll Morgan",
      "Gabriel H. Nunes"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.08625",
    "title": "Generic and Trend-aware Curriculum Learning for Relation Extraction in  Graph Neural Networks",
    "abstract": " Comments: Long paper accepted at NAACL 2022 ",
    "url": "https://arxiv.org/abs/2205.08625",
    "authors": [
      "Nidhi Vakil",
      "Hadi Amiri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13933",
    "title": "Standalone Neural ODEs with Sensitivity Analysis",
    "abstract": " Comments: 25 pages, 15 figures; typos corrected ",
    "url": "https://arxiv.org/abs/2205.13933",
    "authors": [
      "Rym Jaroudi",
      "Luk\u00e1\u0161 Mal\u00fd",
      "Gabriel Eilertsen",
      "B. Tomas Johansson",
      "Jonas Unger",
      "George Baravdish"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2205.14120",
    "title": "Neural Basis Models for Interpretability",
    "abstract": " Comments: 17 pages including appendix. v2 includes link to source code available at this https URL ",
    "url": "https://arxiv.org/abs/2205.14120",
    "authors": [
      "Filip Radenovic",
      "Abhimanyu Dubey",
      "Dhruv Mahajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14249",
    "title": "Experience report of physics-informed neural networks in fluid  simulations: pitfalls and frustration",
    "abstract": " Comments: 8 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2205.14249",
    "authors": [
      "Pi-Yueh Chuang",
      "Lorena A. Barba"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14328",
    "title": "Point RCNN: An Angle-Free Framework for Rotated Object Detection",
    "abstract": " Title: Point RCNN: An Angle-Free Framework for Rotated Object Detection ",
    "url": "https://arxiv.org/abs/2205.14328",
    "authors": [
      "Qiang Zhou",
      "Chaohui Yu",
      "Zhibin Wang",
      "Hao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.01992",
    "title": "CAINNFlow: Convolutional block Attention modules and Invertible Neural  Networks Flow for anomaly detection and localization tasks",
    "abstract": " Title: CAINNFlow: Convolutional block Attention modules and Invertible Neural  Networks Flow for anomaly detection and localization tasks ",
    "url": "https://arxiv.org/abs/2206.01992",
    "authors": [
      "Ruiqing Yan",
      "Fan Zhang",
      "Mengyuan Huang",
      "Wu Liu",
      "Dongyu Hu",
      "Jinfeng Li",
      "Qiang Liu",
      "Jingrong Jiang",
      "Qianjin Guo",
      "Linghan Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.02353",
    "title": "Beyond Just Vision: A Review on Self-Supervised Representation Learning  on Multimodal and Temporal Data",
    "abstract": " Comments: 36 pages, 5 figures, 9 tables, Survey paper ",
    "url": "https://arxiv.org/abs/2206.02353",
    "authors": [
      "Shohreh Deldari",
      "Hao Xue",
      "Aaqib Saeed",
      "Jiayuan He",
      "Daniel V. Smith",
      "Flora D. Salim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.02443",
    "title": "Spam Detection Using BERT",
    "abstract": " Comments: 6 pages, 8 figures and 2 tabels ",
    "url": "https://arxiv.org/abs/2206.02443",
    "authors": [
      "Thaer Sahmoud",
      "Dr. Mohammad Mikki"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03179",
    "title": "TSFEDL: A Python Library for Time Series Spatio-Temporal Feature  Extraction and Prediction using Deep Learning (with Appendices on Detailed  Network Architectures and Experimental Cases of Study)",
    "abstract": " Comments: 26 pages, 33 figures ",
    "url": "https://arxiv.org/abs/2206.03179",
    "authors": [
      "Ignacio Aguilera-Martos",
      "\u00c1ngel M. Garc\u00eda-Vico",
      "Juli\u00e1n Luengo",
      "Sergio Damas",
      "Francisco J. Melero",
      "Jos\u00e9 Javier Valle-Alonso",
      "Francisco Herrera"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.03410",
    "title": "Fast and Robust Non-Rigid Registration Using Accelerated  Majorization-Minimization",
    "abstract": " Title: Fast and Robust Non-Rigid Registration Using Accelerated  Majorization-Minimization ",
    "url": "https://arxiv.org/abs/2206.03410",
    "authors": [
      "Yuxin Yao",
      "Bailin Deng",
      "Weiwei Xu",
      "Juyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  }
]