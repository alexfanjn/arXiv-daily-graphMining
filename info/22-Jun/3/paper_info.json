[
  {
    "id": "arXiv:2206.00679",
    "title": "Why Did This Model Forecast This Future? Closed-Form Temporal Saliency  Towards Causal Explanations of Probabilistic Forecasts",
    "abstract": "Forecasting tasks surrounding the dynamics of low-level human behavior are of significance to multiple research domains. In such settings, methods for explaining specific forecasts can enable domain experts to gain insights into the predictive relationships between behaviors. In this work, we introduce and address the following question: given a probabilistic forecasting model how can we identify observed windows that the model considers salient when making its forecasts? We build upon a general definition of information-theoretic saliency grounded in human perception and extend it to forecasting settings by leveraging a crucial attribute of the domain: a single observation can result in multiple valid futures. We propose to express the saliency of an observed window in terms of the differential entropy of the resulting predicted future distribution. In contrast to existing methods that either require explicit training of the saliency mechanism or access to the internal states of the forecasting model, we obtain a closed-form solution for the saliency map for commonly used density functions in probabilistic forecasting. We empirically demonstrate how our framework can recover salient observed windows from head pose features for the sample task of speaking-turn forecasting using a synthesized conversation dataset. ",
    "url": "https://arxiv.org/abs/2206.00679",
    "authors": [
      "Chirag Raman",
      "Hayley Hung",
      "Marco Loog"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2206.00694",
    "title": "Meta-SysId: A Meta-Learning Approach for Simultaneous Identification and  Prediction",
    "abstract": "In this paper, we propose Meta-SysId, a meta-learning approach to model sets of systems that have behavior governed by common but unknown laws and that differentiate themselves by their context. Inspired by classical modeling-and-identification approaches, Meta-SysId learns to represent the common law through shared parameters and relies on online optimization to compute system-specific context. Compared to optimization-based meta-learning methods, the separation between class parameters and context variables reduces the computational burden while allowing batch computations and a simple training scheme. We test Meta-SysId on polynomial regression, time-series prediction, model-based control, and real-world traffic prediction domains, empirically finding it outperforms or is competitive with meta-learning baselines. ",
    "url": "https://arxiv.org/abs/2206.00694",
    "authors": [
      "Junyoung Park",
      "Federico Berto",
      "Arec Jamgochian",
      "Mykel J. Kochenderfer",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00700",
    "title": "RoCourseNet: Distributionally Robust Training of a Prediction Aware  Recourse Model",
    "abstract": "Counterfactual (CF) explanations for machine learning (ML) models are preferred by end-users, as they explain the predictions of ML models by providing a recourse case to individuals who are adversely impacted by predicted outcomes. Existing CF explanation methods generate recourses under the assumption that the underlying target ML model remains stationary over time. However, due to commonly occurring distributional shifts in training data, ML models constantly get updated in practice, which might render previously generated recourses invalid and diminish end-users trust in our algorithmic framework. To address this problem, we propose RoCourseNet, a training framework that jointly optimizes for predictions and robust recourses to future data shifts. We have three main contributions: (i) We propose a novel virtual data shift (VDS) algorithm to find worst-case shifted ML models by explicitly considering the worst-case data shift in the training dataset. (ii) We leverage adversarial training to solve a novel tri-level optimization problem inside RoCourseNet, which simultaneously generates predictions and corresponding robust recourses. (iii) Finally, we evaluate RoCourseNet's performance on three real-world datasets and show that RoCourseNet outperforms state-of-the-art baselines by 10% in generating robust CF explanations. ",
    "url": "https://arxiv.org/abs/2206.00700",
    "authors": [
      "Hangzhi Guo",
      "Feiran Jia",
      "Jinghui Chen",
      "Anna Squicciarini",
      "Amulya Yadav"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00701",
    "title": "What Changed? Investigating Debiasing Methods using Causal Mediation  Analysis",
    "abstract": "Previous work has examined how debiasing language models affect downstream tasks, specifically, how debiasing techniques influence task performance and whether debiased models also make impartial predictions in downstream tasks or not. However, what we don't understand well yet is why debiasing methods have varying impacts on downstream tasks and how debiasing techniques affect internal components of language models, i.e., neurons, layers, and attentions. In this paper, we decompose the internal mechanisms of debiasing language models with respect to gender by applying causal mediation analysis to understand the influence of debiasing methods on toxicity detection as a downstream task. Our findings suggest a need to test the effectiveness of debiasing methods with different bias metrics, and to focus on changes in the behavior of certain components of the models, e.g.,first two layers of language models, and attention heads. ",
    "url": "https://arxiv.org/abs/2206.00701",
    "authors": [
      "Sullam Jeoung",
      "Jana Diesner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.00711",
    "title": "Learning to Solve PDE-constrained Inverse Problems with Graph Networks",
    "abstract": "Learned graph neural networks (GNNs) have recently been established as fast and accurate alternatives for principled solvers in simulating the dynamics of physical systems. In many application domains across science and engineering, however, we are not only interested in a forward simulation but also in solving inverse problems with constraints defined by a partial differential equation (PDE). Here we explore GNNs to solve such PDE-constrained inverse problems. Given a sparse set of measurements, we are interested in recovering the initial condition or parameters of the PDE. We demonstrate that GNNs combined with autodecoder-style priors are well-suited for these tasks, achieving more accurate estimates of initial conditions or physical parameters than other learned approaches when applied to the wave equation or Navier-Stokes equations. We also demonstrate computational speedups of up to 90x using GNNs compared to principled solvers. Project page: https://cyanzhao42.github.io/LearnInverseProblem ",
    "url": "https://arxiv.org/abs/2206.00711",
    "authors": [
      "Qingqing Zhao",
      "David B. Lindell",
      "Gordon Wetzstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00718",
    "title": "Context-Driven Detection of Invertebrate Species in Deep-Sea Video",
    "abstract": "Each year, underwater remotely operated vehicles (ROVs) collect thousands of hours of video of unexplored ocean habitats revealing a plethora of information regarding biodiversity on Earth. However, fully utilizing this information remains a challenge as proper annotations and analysis require trained scientists time, which is both limited and costly. To this end, we present a Dataset for Underwater Substrate and Invertebrate Analysis (DUSIA), a benchmark suite and growing large-scale dataset to train, validate, and test methods for temporally localizing four underwater substrates as well as temporally and spatially localizing 59 underwater invertebrate species. DUSIA currently includes over ten hours of footage across 25 videos captured in 1080p at 30 fps by an ROV following pre planned transects across the ocean floor near the Channel Islands of California. Each video includes annotations indicating the start and end times of substrates across the video in addition to counts of species of interest. Some frames are annotated with precise bounding box locations for invertebrate species of interest, as seen in Figure 1. To our knowledge, DUSIA is the first dataset of its kind for deep sea exploration, with video from a moving camera, that includes substrate annotations and invertebrate species that are present at significant depths where sunlight does not penetrate. Additionally, we present the novel context-driven object detector (CDD) where we use explicit substrate classification to influence an object detection network to simultaneously predict a substrate and species class influenced by that substrate. We also present a method for improving training on partially annotated bounding box frames. Finally, we offer a baseline method for automating the counting of invertebrate species of interest. ",
    "url": "https://arxiv.org/abs/2206.00718",
    "authors": [
      "R. Austin McEver",
      "Bowen Zhang",
      "Connor Levenson",
      "A S M Iftekhar",
      "B.S. Manjunath"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00719",
    "title": "Dataset Distillation using Neural Feature Regression",
    "abstract": "Dataset distillation aims to learn a small synthetic dataset that preserves most of the information from the original dataset. Dataset distillation can be formulated as a bi-level meta-learning problem where the outer loop optimizes the meta-dataset and the inner loop trains a model on the distilled data. Meta-gradient computation is one of the key challenges in this formulation, as differentiating through the inner loop learning procedure introduces significant computation and memory costs. In this paper, we address these challenges using neural Feature Regression with Pooling (FRePo), achieving the state-of-the-art performance with an order of magnitude less memory requirement and two orders of magnitude faster training than previous methods. The proposed algorithm is analogous to truncated backpropagation through time with a pool of models to alleviate various types of overfitting in dataset distillation. FRePo significantly outperforms the previous methods on CIFAR100, Tiny ImageNet, and ImageNet-1K. Furthermore, we show that high-quality distilled data can greatly improve various downstream applications, such as continual learning and membership inference defense. ",
    "url": "https://arxiv.org/abs/2206.00719",
    "authors": [
      "Yongchao Zhou",
      "Ehsan Nezhadarya",
      "Jimmy Ba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00737",
    "title": "Walk for Learning: A Random Walk Approach for Federated Learning from  Heterogeneous Data",
    "abstract": "We consider the problem of a Parameter Server (PS) that wishes to learn a model that fits data distributed on the nodes of a graph. We focus on Federated Learning (FL) as a canonical application. One of the main challenges of FL is the communication bottleneck between the nodes and the parameter server. A popular solution in the literature is to allow each node to do several local updates on the model in each iteration before sending it back to the PS. While this mitigates the communication bottleneck, the statistical heterogeneity of the data owned by the different nodes has proven to delay convergence and bias the model. In this work, we study random walk (RW) learning algorithms for tackling the communication and data heterogeneity problems. The main idea is to leverage available direct connections among the nodes themselves, which are typically \"cheaper\" than the communication to the PS. In a random walk, the model is thought of as a \"baton\" that is passed from a node to one of its neighbors after being updated in each iteration. The challenge in designing the RW is the data heterogeneity and the uncertainty about the data distributions. Ideally, we would want to visit more often nodes that hold more informative data. We cast this problem as a sleeping multi-armed bandit (MAB) to design a near-optimal node sampling strategy that achieves variance-reduced gradient estimates and approaches sub-linearly the optimal sampling strategy. Based on this framework, we present an adaptive random walk learning algorithm. We provide theoretical guarantees on its convergence. Our numerical results validate our theoretical findings and show that our algorithm outperforms existing random walk algorithms. ",
    "url": "https://arxiv.org/abs/2206.00737",
    "authors": [
      "Ghadir Ayache",
      "Venkat Dassari",
      "Salim El Rouayheb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2206.00746",
    "title": "Residual Multiplicative Filter Networks for Multiscale Reconstruction",
    "abstract": "Coordinate networks like Multiplicative Filter Networks (MFNs) and BACON offer some control over the frequency spectrum used to represent continuous signals such as images or 3D volumes. Yet, they are not readily applicable to problems for which coarse-to-fine estimation is required, including various inverse problems in which coarse-to-fine optimization plays a key role in avoiding poor local minima. We introduce a new coordinate network architecture and training scheme that enables coarse-to-fine optimization with fine-grained control over the frequency support of learned reconstructions. This is achieved with two key innovations. First, we incorporate skip connections so that structure at one scale is preserved when fitting finer-scale structure. Second, we propose a novel initialization scheme to provide control over the model frequency spectrum at each stage of optimization. We demonstrate how these modifications enable multiscale optimization for coarse-to-fine fitting to natural images. We then evaluate our model on synthetically generated datasets for the the problem of single-particle cryo-EM reconstruction. We learn high resolution multiscale structures, on par with the state-of-the art. ",
    "url": "https://arxiv.org/abs/2206.00746",
    "authors": [
      "Shayan Shekarforoush",
      "David B. Lindell",
      "David J. Fleet",
      "Marcus A. Brubaker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00747",
    "title": "SolarGAN: Synthetic Annual Solar Irradiance Time Series on Urban  Building Facades via Deep Generative Networks",
    "abstract": "Building Integrated Photovoltaics (BIPV) is a promising technology to decarbonize urban energy systems via harnessing solar energy available on building envelopes. While methods to assess solar irradiation, especially on rooftops, are well established, the assessment on building facades usually involves a higher effort due to more complex urban features and obstructions. The drawback of existing physics-based simulation programs is that they require significant manual modelling effort and computing time for generating time resolved deterministic results. Yet, solar irradiation is highly intermittent and representing its inherent uncertainty may be required for designing robust BIPV energy systems. Targeting on these drawbacks, this paper proposes a data-driven model based on Deep Generative Networks (DGN) to efficiently generate high-fidelity stochastic ensembles of annual hourly solar irradiance time series on building facades with uncompromised spatiotemporal resolution at the urban scale. The only input required is easily obtainable, simple fisheye images as categorical shading masks captured from 3D models. In principle, even actual photographs of urban contexts can be utilized, given they are semantically segmented. Our validations exemplify the high fidelity of the generated time series when compared to the physics-based simulator. To demonstrate the model's relevance for urban energy planning, we showcase its potential for generative design by parametrically altering characteristic features of the urban environment and producing corresponding time series on building facades under different climatic contexts in real-time. ",
    "url": "https://arxiv.org/abs/2206.00747",
    "authors": [
      "Yufei Zhang",
      "Arno Schl\u00fcter",
      "Christoph Waibel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00769",
    "title": "Defense Against Gradient Leakage Attacks via Learning to Obscure Data",
    "abstract": "Federated learning is considered as an effective privacy-preserving learning mechanism that separates the client's data and model training process. However, federated learning is still under the risk of privacy leakage because of the existence of attackers who deliberately conduct gradient leakage attacks to reconstruct the client data. Recently, popular strategies such as gradient perturbation methods and input encryption methods have been proposed to defend against gradient leakage attacks. Nevertheless, these defenses can either greatly sacrifice the model performance, or be evaded by more advanced attacks. In this paper, we propose a new defense method to protect the privacy of clients' data by learning to obscure data. Our defense method can generate synthetic samples that are totally distinct from the original samples, but they can also maximally preserve their predictive features and guarantee the model performance. Furthermore, our defense strategy makes the gradient leakage attack and its variants extremely difficult to reconstruct the client data. Through extensive experiments, we show that our proposed defense method obtains better privacy protection while preserving high accuracy compared with state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2206.00769",
    "authors": [
      "Yuxuan Wan",
      "Han Xu",
      "Xiaorui Liu",
      "Jie Ren",
      "Wenqi Fan",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.00772",
    "title": "On the reversibility of adversarial attacks",
    "abstract": "Adversarial attacks modify images with perturbations that change the prediction of classifiers. These modified images, known as adversarial examples, expose the vulnerabilities of deep neural network classifiers. In this paper, we investigate the predictability of the mapping between the classes predicted for original images and for their corresponding adversarial examples. This predictability relates to the possibility of retrieving the original predictions and hence reversing the induced misclassification. We refer to this property as the reversibility of an adversarial attack, and quantify reversibility as the accuracy in retrieving the original class or the true class of an adversarial example. We present an approach that reverses the effect of an adversarial attack on a classifier using a prior set of classification results. We analyse the reversibility of state-of-the-art adversarial attacks on benchmark classifiers and discuss the factors that affect the reversibility. ",
    "url": "https://arxiv.org/abs/2206.00772",
    "authors": [
      "Chau Yi Li",
      "Ricardo S\u00e1nchez-Matilla",
      "Ali Shahin Shamsabadi",
      "Riccardo Mazzon",
      "Andrea Cavallaro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.00773",
    "title": "Assessing the trade-off between prediction accuracy and interpretability  for topic modeling on energetic materials corpora",
    "abstract": "As the amount and variety of energetics research increases, machine aware topic identification is necessary to streamline future research pipelines. The makeup of an automatic topic identification process consists of creating document representations and performing classification. However, the implementation of these processes on energetics research imposes new challenges. Energetics datasets contain many scientific terms that are necessary to understand the context of a document but may require more complex document representations. Secondly, the predictions from classification must be understandable and trusted by the chemists within the pipeline. In this work, we study the trade-off between prediction accuracy and interpretability by implementing three document embedding methods that vary in computational complexity. With our accuracy results, we also introduce local interpretability model-agnostic explanations (LIME) of each prediction to provide a localized understanding of each prediction and to validate classifier decisions with our team of energetics experts. This study was carried out on a novel labeled energetics dataset created and validated by our team of energetics experts. ",
    "url": "https://arxiv.org/abs/2206.00773",
    "authors": [
      "Monica Puerto",
      "Mason Kellett",
      "Rodanthi Nikopoulou",
      "Mark D. Fuge",
      "Ruth Doherty",
      "Peter W. Chung",
      "Zois Boukouvalas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00774",
    "title": "Distributed Training for Deep Learning Models On An Edge Computing  Network Using ShieldedReinforcement Learning",
    "abstract": "Edge devices with local computation capability has made distributed deep learning training on edges possible. In such method, the cluster head of a cluster of edges schedules DL training jobs from the edges. Using such centralized scheduling method, the cluster head knows all loads of edges, which can avoid overloading the cluster edges, but the head itself may become overloaded. To handle this problem, we propose a multi-agent RL (MARL) system that enables each edge to schedule its jobs using RL. However, without coordination among edges, action collision may occur, in which multiple edges schedule tasks to the same edge and make it overloaded. For this reason, we propose a system called Shielded ReinfOrcement learning (RL) based DL training on Edges (SROLE). In SROLE, the shield deployed in an edge checks action collisions and provides alternative actions to avoid collisions. As the central shield for entire cluster may become a bottleneck, we further propose a decentralized shielding method, where different shields are responsible for different regions in the cluster and they coordinate to avoid action collisions on the region boundaries. Our emulation and real device experiments show SROLE reduces training time by 59% compared to MARL and centralized RL. ",
    "url": "https://arxiv.org/abs/2206.00774",
    "authors": [
      "Tanmoy Sen",
      "Haiying Shen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2206.00786",
    "title": "Neural Decoding with Optimization of Node Activations",
    "abstract": "The problem of maximum likelihood decoding with a neural decoder for error-correcting code is considered. It is shown that the neural decoder can be improved with two novel loss terms on the node's activations. The first loss term imposes a sparse constraint on the node's activations. Whereas, the second loss term tried to mimic the node's activations from a teacher decoder which has better performance. The proposed method has the same run time complexity and model size as the neural Belief Propagation decoder, while improving the decoding performance by up to $1.1dB$ on BCH codes. ",
    "url": "https://arxiv.org/abs/2206.00786",
    "authors": [
      "Eliya Nachmani",
      "Yair Be'ery"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.00787",
    "title": "On the Generalization of Neural Combinatorial Optimization Heuristics",
    "abstract": "Neural Combinatorial Optimization approaches have recently leveraged the expressiveness and flexibility of deep neural networks to learn efficient heuristics for hard Combinatorial Optimization (CO) problems. However, most of the current methods lack generalization: for a given CO problem, heuristics which are trained on instances with certain characteristics underperform when tested on instances with different characteristics. While some previous works have focused on varying the training instances properties, we postulate that a one-size-fit-all model is out of reach. Instead, we formalize solving a CO problem over a given instance distribution as a separate learning task and investigate meta-learning techniques to learn a model on a variety of tasks, in order to optimize its capacity to adapt to new tasks. Through extensive experiments, on two CO problems, using both synthetic and realistic instances, we show that our proposed meta-learning approach significantly improves the generalization of two state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2206.00787",
    "authors": [
      "Sahil Manchanda",
      "Sofia Michel",
      "Darko Drakulic",
      "Jean-Marc Andreoli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.00790",
    "title": "Efficient Self-supervised Vision Pretraining with Local Masked  Reconstruction",
    "abstract": "Self-supervised learning for computer vision has achieved tremendous progress and improved many downstream vision tasks such as image classification, semantic segmentation, and object detection. Among these, generative self-supervised vision learning approaches such as MAE and BEiT show promising performance. However, their global masked reconstruction mechanism is computationally demanding. To address this issue, we propose local masked reconstruction (LoMaR), a simple yet effective approach that performs masked reconstruction within a small window of 7$\\times$7 patches on a simple Transformer encoder, improving the trade-off between efficiency and accuracy compared to global masked reconstruction over the entire image. Extensive experiments show that LoMaR reaches 84.1% top-1 accuracy on ImageNet-1K classification, outperforming MAE by 0.5%. After finetuning the pretrained LoMaR on 384$\\times$384 images, it can reach 85.4% top-1 accuracy, surpassing MAE by 0.6%. On MS COCO, LoMaR outperforms MAE by 0.5 $\\text{AP}^\\text{box}$ on object detection and 0.5 $\\text{AP}^\\text{mask}$ on instance segmentation. LoMaR is especially more computation-efficient on pretraining high-resolution images, e.g., it is 3.1$\\times$ faster than MAE with 0.2% higher classification accuracy on pretraining 448$\\times$448 images. This local masked reconstruction learning mechanism can be easily integrated into any other generative self-supervised learning approach. Our code will be publicly available. ",
    "url": "https://arxiv.org/abs/2206.00790",
    "authors": [
      "Jun Chen",
      "Ming Hu",
      "Boyang Li",
      "Mohamed Elhoseiny"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00792",
    "title": "Channel Codes for Relayless Networks with General Message Access  Structure",
    "abstract": "Channel codes for relayless networks with the general message access structure is introduced. It is shown that the multi-letter characterized capacity region of this network is achievable with this code. The capacity region is characterized in terms of entropy functions and provides an alternative to the regions introduced by [Somekh-Baruch and Verd\\'u, ISIT2006][Muramatsu and Miyake, ISITA2018]. ",
    "url": "https://arxiv.org/abs/2206.00792",
    "authors": [
      "Jun Muramatsu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2206.00798",
    "title": "Multi-scale frequency separation network for image deblurring",
    "abstract": "Image deblurring aims to restore the detailed texture information or structures from the blurry images, which has become an indispensable step in many computer-vision tasks. Although various methods have been proposed to deal with the image deblurring problem, most of them treated the blurry image as a whole and neglected the characteristics of different image frequencies. In this paper, we present a new method called multi-scale frequency separation network (MSFS-Net) for image deblurring. MSFS-Net introduces the frequency separation module (FSM) into an encoder-decoder network architecture to capture the low and high-frequency information of image at multiple scales. Then, a simple cycle-consistency strategy and a sophisticated contrastive learning module (CLM) are respectively designed to retain the low-frequency information and recover the high-frequency information during deblurring. At last, the features of different scales are fused by a cross-scale feature fusion module (CSFFM). Extensive experiments on benchmark datasets show that the proposed network achieves state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2206.00798",
    "authors": [
      "Yanni Zhang",
      "Qiang Li",
      "Miao Qi",
      "Di Liu",
      "Jun Kong",
      "Jianzhong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00803",
    "title": "Robust recovery of low-rank matrices and low-tubal-rank tensors from  noisy sketches",
    "abstract": "A common approach for compressing large-scale data is through matrix sketching. In this work, we consider the problem of recovering low-rank matrices from two noisy sketches using the double sketching algorithm discussed in Fazel et al. (2008). Using tools from non-asymptotic random matrix theory, we provide the first theoretical guarantees characterizing the error between the output of the double sketch algorithm and the ground truth low-rank matrix. We apply our result to the problems of low-rank matrix approximation and low-tubal-rank tensor recovery. ",
    "url": "https://arxiv.org/abs/2206.00803",
    "authors": [
      "Anna Ma",
      "Dominik St\u00f6ger",
      "Yizhe Zhu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2206.00804",
    "title": "Learning code summarization from a small and local dataset",
    "abstract": "Foundation models (e.g., CodeBERT, GraphCodeBERT, CodeT5) work well for many software engineering tasks. These models are pre-trained (using self-supervision) with billions of code tokens, and then fine-tuned with hundreds of thousands of labeled examples, typically drawn from many projects. However, software phenomena can be very project-specific. Vocabulary, and other phenomena vary substantially with each project. Thus, training on project-specific data, and testing on the same project, is a promising idea. This hypothesis has to be evaluated carefully, e.g., in a time-series setting, to prevent training-test leakage. We compare several models and training approaches, including same-project training, cross-project training, training a model especially designed to be sample efficient (and thus prima facie well-suited for learning in a limited-sample same-project setting) and a maximalist hybrid approach, fine-tuning first on many projects in many languages and then training on the same-project. We find that the maximalist hybrid setting provides consistent, substantial gains over the state-of-the-art, on many different projects in both Java and Python. ",
    "url": "https://arxiv.org/abs/2206.00804",
    "authors": [
      "Toufique Ahmed",
      "Premkumar Devanbu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00807",
    "title": "Applied Federated Learning: Architectural Design for Robust and  Efficient Learning in Privacy Aware Settings",
    "abstract": "The classical machine learning paradigm requires the aggregation of user data in a central location where machine learning practitioners can preprocess data, calculate features, tune models and evaluate performance. The advantage of this approach includes leveraging high performance hardware (such as GPUs) and the ability of machine learning practitioners to do in depth data analysis to improve model performance. However, these advantages may come at a cost to data privacy. User data is collected, aggregated, and stored on centralized servers for model development. Centralization of data poses risks, including a heightened risk of internal and external security incidents as well as accidental data misuse. Federated learning with differential privacy is designed to avoid the server-side centralization pitfall by bringing the ML learning step to users' devices. Learning is done in a federated manner where each mobile device runs a training loop on a local copy of a model. Updates from on-device models are sent to the server via encrypted communication and through differential privacy to improve the global model. In this paradigm, users' personal data remains on their devices. Surprisingly, model training in this manner comes at a fairly minimal degradation in model performance. However, federated learning comes with many other challenges due to its distributed nature, heterogeneous compute environments and lack of data visibility. This paper explores those challenges and outlines an architectural design solution we are exploring and testing to productionize federated learning at Meta scale. ",
    "url": "https://arxiv.org/abs/2206.00807",
    "authors": [
      "Branislav Stojkovic",
      "Jonathan Woodbridge",
      "Zhihan Fang",
      "Jerry Cai",
      "Andrey Petrov",
      "Sathya Iyer",
      "Daoyu Huang",
      "Patrick Yau",
      "Arvind Sastha Kumar",
      "Hitesh Jawa",
      "Anamita Guha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00810",
    "title": "Offline Reinforcement Learning with Differential Privacy",
    "abstract": "The offline reinforcement learning (RL) problem is often motivated by the need to learn data-driven decision policies in financial, legal and healthcare applications. However, the learned policy could retain sensitive information of individuals in the training data (e.g., treatment and outcome of patients), thus susceptible to various privacy risks. We design offline RL algorithms with differential privacy guarantees which provably prevent such risks. These algorithms also enjoy strong instance-dependent learning bounds under both tabular and linear Markov decision process (MDP) settings. Our theory and simulation suggest that the privacy guarantee comes at (almost) no drop in utility comparing to the non-private counterpart for a medium-size dataset. ",
    "url": "https://arxiv.org/abs/2206.00810",
    "authors": [
      "Dan Qiao",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.00833",
    "title": "Finite-Time Analysis of Entropy-Regularized Neural Natural Actor-Critic  Algorithm",
    "abstract": "Natural actor-critic (NAC) and its variants, equipped with the representation power of neural networks, have demonstrated impressive empirical success in solving Markov decision problems with large state spaces. In this paper, we present a finite-time analysis of NAC with neural network approximation, and identify the roles of neural networks, regularization and optimization techniques (e.g., gradient clipping and averaging) to achieve provably good performance in terms of sample complexity, iteration complexity and overparametrization bounds for the actor and the critic. In particular, we prove that (i) entropy regularization and averaging ensure stability by providing sufficient exploration to avoid near-deterministic and strictly suboptimal policies and (ii) regularization leads to sharp sample complexity and network width bounds in the regularized MDPs, yielding a favorable bias-variance tradeoff in policy optimization. In the process, we identify the importance of uniform approximation power of the actor neural network to achieve global optimality in policy optimization due to distributional shift. ",
    "url": "https://arxiv.org/abs/2206.00833",
    "authors": [
      "Semih Cayci",
      "Niao He",
      "R. Srikant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.00843",
    "title": "DepthShrinker: A New Compression Paradigm Towards Boosting Real-Hardware  Efficiency of Compact Neural Networks",
    "abstract": "Efficient deep neural network (DNN) models equipped with compact operators (e.g., depthwise convolutions) have shown great potential in reducing DNNs' theoretical complexity (e.g., the total number of weights/operations) while maintaining a decent model accuracy. However, existing efficient DNNs are still limited in fulfilling their promise in boosting real-hardware efficiency, due to their commonly adopted compact operators' low hardware utilization. In this work, we open up a new compression paradigm for developing real-hardware efficient DNNs, leading to boosted hardware efficiency while maintaining model accuracy. Interestingly, we observe that while some DNN layers' activation functions help DNNs' training optimization and achievable accuracy, they can be properly removed after training without compromising the model accuracy. Inspired by this observation, we propose a framework dubbed DepthShrinker, which develops hardware-friendly compact networks via shrinking the basic building blocks of existing efficient DNNs that feature irregular computation patterns into dense ones with much improved hardware utilization and thus real-hardware efficiency. Excitingly, our DepthShrinker framework delivers hardware-friendly compact networks that outperform both state-of-the-art efficient DNNs and compression techniques, e.g., a 3.06\\% higher accuracy and 1.53$\\times$ throughput on Tesla V100 over SOTA channel-wise pruning method MetaPruning. Our codes are available at: https://github.com/RICE-EIC/DepthShrinker. ",
    "url": "https://arxiv.org/abs/2206.00843",
    "authors": [
      "Yonggan Fu",
      "Haichuan Yang",
      "Jiayi Yuan",
      "Meng Li",
      "Cheng Wan",
      "Raghuraman Krishnamoorthi",
      "Vikas Chandra",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00859",
    "title": "Disentangled Generation Network for Enlarged License Plate Recognition  and A Unified Dataset",
    "abstract": "License plate recognition plays a critical role in many practical applications, but license plates of large vehicles are difficult to be recognized due to the factors of low resolution, contamination, low illumination, and occlusion, to name a few. To overcome the above factors, the transportation management department generally introduces the enlarged license plate behind the rear of a vehicle. However, enlarged license plates have high diversity as they are non-standard in position, size, and style. Furthermore, the background regions contain a variety of noisy information which greatly disturbs the recognition of license plate characters. Existing works have not studied this challenging problem. In this work, we first address the enlarged license plate recognition problem and contribute a dataset containing 9342 images, which cover most of the challenges of real scenes. However, the created data are still insufficient to train deep methods of enlarged license plate recognition, and building large-scale training data is very time-consuming and high labor cost. To handle this problem, we propose a novel task-level disentanglement generation framework based on the Disentangled Generation Network (DGNet), which disentangles the generation into the text generation and background generation in an end-to-end manner to effectively ensure diversity and integrity, for robust enlarged license plate recognition. Extensive experiments on the created dataset are conducted, and we demonstrate the effectiveness of the proposed approach in three representative text recognition frameworks. ",
    "url": "https://arxiv.org/abs/2206.00859",
    "authors": [
      "Chenglong Li",
      "Xiaobin Yang",
      "Guohao Wang",
      "Aihua Zheng",
      "Chang Tan",
      "Ruoran Jia",
      "Jin Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00873",
    "title": "Nearly Optimal Best-of-Both-Worlds Algorithms for Online Learning with  Feedback Graphs",
    "abstract": "This study considers online learning with general directed feedback graphs. For this problem, we present best-of-both-worlds algorithms that achieve nearly tight regret bounds for adversarial environments as well as poly-logarithmic regret bounds for stochastic environments. As Alon et al. [2015] have shown, tight regret bounds depend on the structure of the feedback graph: \\textit{strongly observable} graphs yield minimax regret of $\\tilde{\\Theta}( \\alpha^{1/2} T^{1/2} )$, while \\textit{weakly observable} graphs induce minimax regret of $\\tilde{\\Theta}( \\delta^{1/3} T^{2/3} )$, where $\\alpha$ and $\\delta$, respectively, represent the independence number of the graph and the domination number of a certain portion of the graph. Our proposed algorithm for strongly observable graphs has a regret bound of $\\tilde{O}( \\alpha^{1/2} T^{1/2} ) $ for adversarial environments, as well as of $ {O} ( \\frac{\\alpha (\\ln T)^3 }{\\Delta_{\\min}} ) $ for stochastic environments, where $\\Delta_{\\min}$ expresses the minimum suboptimality gap. This result resolves an open question raised by Erez and Koren [2021]. We also provide an algorithm for weakly observable graphs that achieves a regret bound of $\\tilde{O}( \\delta^{1/3}T^{2/3} )$ for adversarial environments and poly-logarithmic regret for stochastic environments. The proposed algorithms are based on the follow-the-perturbed-leader approach combined with newly designed update rules for learning rates. ",
    "url": "https://arxiv.org/abs/2206.00873",
    "authors": [
      "Shinji Ito",
      "Taira Tsuchiya",
      "Junya Honda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00874",
    "title": "Age of Information in Reservation Multi-Access Networks with Stochastic  Arrivals",
    "abstract": "This paper investigates the Age of Information (AoI) performance of Frame Slotted ALOHA with Reservation and Data slots (FSA-RD). We consider a symmetric multi-access network where each user transmits its randomly generated status updates to an access point in a framed manner. Each frame consists of one reservation slot and several data slots. The reservation slot is made up of some mini-slots. In each reservation slot, users, with a status update packet to transmit, randomly send short reservation packets in one of the mini-slots to contend for data slots of the frame. The data slots are assigned to those users that succeed in reservation slot. To provide insights in optimizing the information freshness of FSA-RD, we manage to derive a closed-form expression of the average AoI under FSA-RD by applying a recursive method. Numerical results validate the analytical expression and demonstrate the influence of the frame size and reservation probability on the average AoI. We finally perform a comparison between the AoI performance of FSA-RD with optimized frame size and reservation probability, and that of slotted ALOHA with optimized transmission probability. The comparison results show that FSA-RD can effectively reduce the AoI performance of multi-access networks, especially when the status arrival rate of the network becomes large. ",
    "url": "https://arxiv.org/abs/2206.00874",
    "authors": [
      "Qian Wang",
      "He Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2206.00878",
    "title": "EfficientNeRF: Efficient Neural Radiance Fields",
    "abstract": "Neural Radiance Fields (NeRF) has been wildly applied to various tasks for its high-quality representation of 3D scenes. It takes long per-scene training time and per-image testing time. In this paper, we present EfficientNeRF as an efficient NeRF-based method to represent 3D scene and synthesize novel-view images. Although several ways exist to accelerate the training or testing process, it is still difficult to much reduce time for both phases simultaneously. We analyze the density and weight distribution of the sampled points then propose valid and pivotal sampling at the coarse and fine stage, respectively, to significantly improve sampling efficiency. In addition, we design a novel data structure to cache the whole scene during testing to accelerate the rendering speed. Overall, our method can reduce over 88\\% of training time, reach rendering speed of over 200 FPS, while still achieving competitive accuracy. Experiments prove that our method promotes the practicality of NeRF in the real world and enables many applications. ",
    "url": "https://arxiv.org/abs/2206.00878",
    "authors": [
      "Tao Hu",
      "Shu Liu",
      "Yilun Chen",
      "Tiancheng Shen",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00906",
    "title": "NeuralSympCheck: A Symptom Checking and Disease Diagnostic Neural Model  with Logic Regularization",
    "abstract": "The symptom checking systems inquire users for their symptoms and perform a rapid and affordable medical assessment of their condition. The basic symptom checking systems based on Bayesian methods, decision trees, or information gain methods are easy to train and do not require significant computational resources. However, their drawbacks are low relevance of proposed symptoms and insufficient quality of diagnostics. The best results on these tasks are achieved by reinforcement learning models. Their weaknesses are the difficulty of developing and training such systems and limited applicability to cases with large and sparse decision spaces. We propose a new approach based on the supervised learning of neural models with logic regularization that combines the advantages of the different methods. Our experiments on real and synthetic data show that the proposed approach outperforms the best existing methods in the accuracy of diagnosis when the number of diagnoses and symptoms is large. ",
    "url": "https://arxiv.org/abs/2206.00906",
    "authors": [
      "Aleksandr Nesterov",
      "Bulat Ibragimov",
      "Dmitriy Umerenkov",
      "Artem Shelmanov",
      "Galina Zubkova",
      "Vladimir Kokh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.00913",
    "title": "Mask-Guided Divergence Loss Improves the Generalization and Robustness  of Deep Neural Network",
    "abstract": "Deep neural network (DNN) with dropout can be regarded as an ensemble model consisting of lots of sub-DNNs (i.e., an ensemble sub-DNN where the sub-DNN is the remaining part of the DNN after dropout), and through increasing the diversity of the ensemble sub-DNN, the generalization and robustness of the DNN can be effectively improved. In this paper, a mask-guided divergence loss function (MDL), which consists of a cross-entropy loss term and an orthogonal term, is proposed to increase the diversity of the ensemble sub-DNN by the added orthogonal term. Particularly, the mask technique is introduced to assist in generating the orthogonal term for avoiding overfitting of the diversity learning. The theoretical analysis and extensive experiments on 4 datasets (i.e., MNIST, FashionMNIST, CIFAR10, and CIFAR100) manifest that MDL can improve the generalization and robustness of standard training and adversarial training. For CIFAR10 and CIFAR100, in standard training, the maximum improvement of accuracy is $1.38\\%$ on natural data, $30.97\\%$ on FGSM (i.e., Fast Gradient Sign Method) attack, $38.18\\%$ on PGD (i.e., Projected Gradient Descent) attack. While in adversarial training, the maximum improvement is $1.68\\%$ on natural data, $4.03\\%$ on FGSM attack and $2.65\\%$ on PGD attack. ",
    "url": "https://arxiv.org/abs/2206.00913",
    "authors": [
      "Xiangyuan Yang",
      "Jie Lin",
      "Hanlin Zhang",
      "Xinyu Yang",
      "Peng Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00923",
    "title": "Modeling Image Composition for Complex Scene Generation",
    "abstract": "We present a method that achieves state-of-the-art results on challenging (few-shot) layout-to-image generation tasks by accurately modeling textures, structures and relationships contained in a complex scene. After compressing RGB images into patch tokens, we propose the Transformer with Focal Attention (TwFA) for exploring dependencies of object-to-object, object-to-patch and patch-to-patch. Compared to existing CNN-based and Transformer-based generation models that entangled modeling on pixel-level&patch-level and object-level&patch-level respectively, the proposed focal attention predicts the current patch token by only focusing on its highly-related tokens that specified by the spatial layout, thereby achieving disambiguation during training. Furthermore, the proposed TwFA largely increases the data efficiency during training, therefore we propose the first few-shot complex scene generation strategy based on the well-trained TwFA. Comprehensive experiments show the superiority of our method, which significantly increases both quantitative metrics and qualitative visual realism with respect to state-of-the-art CNN-based and transformer-based methods. Code is available at https://github.com/JohnDreamer/TwFA. ",
    "url": "https://arxiv.org/abs/2206.00923",
    "authors": [
      "Zuopeng Yang",
      "Daqing Liu",
      "Chaoyue Wang",
      "Jie Yang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00924",
    "title": "FACM: Correct the Output of Deep Neural Network with Middle Layers  Features against Adversarial Samples",
    "abstract": "In the strong adversarial attacks against deep neural network (DNN), the output of DNN will be misclassified if and only if the last feature layer of the DNN is completely destroyed by adversarial samples, while our studies found that the middle feature layers of the DNN can still extract the effective features of the original normal category in these adversarial attacks. To this end, in this paper, a middle $\\bold{F}$eature layer $\\bold{A}$nalysis and $\\bold{C}$onditional $\\bold{M}$atching prediction distribution (FACM) model is proposed to increase the robustness of the DNN against adversarial samples through correcting the output of DNN with the features extracted by the middle layers of DNN. In particular, the middle $\\bold{F}$eature layer $\\bold{A}$nalysis (FA) module, the conditional matching prediction distribution (CMPD) module and the output decision module are included in our FACM model to collaboratively correct the classification of adversarial samples. The experiments results show that, our FACM model can significantly improve the robustness of the naturally trained model against various attacks, and our FA model can significantly improve the robustness of the adversarially trained model against white-box attacks with weak transferability and black box attacks where FA model includes the FA module and the output decision module, not the CMPD module. ",
    "url": "https://arxiv.org/abs/2206.00924",
    "authors": [
      "Xiangyuan Yang",
      "Jie Lin",
      "Hanlin Zhang",
      "Xinyu Yang",
      "Peng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00934",
    "title": "Deep neural networks can stably solve high-dimensional, noisy,  non-linear inverse problems",
    "abstract": "We study the problem of reconstructing solutions of inverse problems with neural networks when only noisy data is available. We assume the problem can be modeled with an infinite-dimensional forward operator that is not continuously invertible. Then, we restrict this forward operator to finite-dimensional spaces so that the inverse is Lipschitz continuous. For the inverse operator, we demonstrate that there exists a neural network which is a robust-to-noise approximation of the function. In addition, we show that these neural networks can be learned from appropriately perturbed training data. We demonstrate the admissibility of this approach to a wide range of inverse problems of practical interest. Numerical examples are given that support the theoretical findings. ",
    "url": "https://arxiv.org/abs/2206.00934",
    "authors": [
      "Andr\u00e9s Felipe Lerma Pineda",
      "Philipp Christian Petersen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.00944",
    "title": "Feature Space Particle Inference for Neural Network Ensembles",
    "abstract": "Ensembles of deep neural networks demonstrate improved performance over single models. For enhancing the diversity of ensemble members while keeping their performance, particle-based inference methods offer a promising approach from a Bayesian perspective. However, the best way to apply these methods to neural networks is still unclear: seeking samples from the weight-space posterior suffers from inefficiency due to the over-parameterization issues, while seeking samples directly from the function-space posterior often results in serious underfitting. In this study, we propose optimizing particles in the feature space where the activation of a specific intermediate layer lies to address the above-mentioned difficulties. Our method encourages each member to capture distinct features, which is expected to improve ensemble prediction robustness. Extensive evaluation on real-world datasets shows that our model significantly outperforms the gold-standard Deep Ensembles on various metrics, including accuracy, calibration, and robustness. Code is available at https://github.com/DensoITLab/featurePI . ",
    "url": "https://arxiv.org/abs/2206.00944",
    "authors": [
      "Shingo Yashima",
      "Teppei Suzuki",
      "Kohta Ishikawa",
      "Ikuro Sato",
      "Rei Kawakami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.00960",
    "title": "SparseDet: Towards End-to-End 3D Object Detection",
    "abstract": "In this paper, we propose SparseDet for end-to-end 3D object detection from point cloud. Existing works on 3D object detection rely on dense object candidates over all locations in a 3D or 2D grid following the mainstream methods for object detection in 2D images. However, this dense paradigm requires expertise in data to fulfill the gap between label and detection. As a new detection paradigm, SparseDet maintains a fixed set of learnable proposals to represent latent candidates and directly perform classification and localization for 3D objects through stacked transformers. It demonstrates that effective 3D object detection can be achieved with none of post-processing such as redundant removal and non-maximum suppression. With a properly designed network, SparseDet achieves highly competitive detection accuracy while running with a more efficient speed of 34.5 FPS. We believe this end-to-end paradigm of SparseDet will inspire new thinking on the sparsity of 3D object detection. ",
    "url": "https://arxiv.org/abs/2206.00960",
    "authors": [
      "Jianhong Han",
      "Zhaoyi Wan",
      "Zhe Liu",
      "Jie Feng",
      "Bingfeng Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.00962",
    "title": "Transfer Language Selection for Zero-Shot Cross-Lingual Abusive Language  Detection",
    "abstract": "We study the selection of transfer languages for automatic abusive language detection. Instead of preparing a dataset for every language, we demonstrate the effectiveness of cross-lingual transfer learning for zero-shot abusive language detection. This way we can use existing data from higher-resource languages to build better detection systems for low-resource languages. Our datasets are from seven different languages from three language families. We measure the distance between the languages using several language similarity measures, especially by quantifying the World Atlas of Language Structures. We show that there is a correlation between linguistic similarity and classifier performance. This discovery allows us to choose an optimal transfer language for zero shot abusive language detection. ",
    "url": "https://arxiv.org/abs/2206.00962",
    "authors": [
      "Juuso Eronen",
      "Michal Ptaszynski",
      "Fumito Masui",
      "Masaki Arata",
      "Gniewosz Leliwa",
      "Michal Wroczynski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.00979",
    "title": "Graph Kernels Based on Multi-scale Graph Embeddings",
    "abstract": "Graph kernels are conventional methods for computing graph similarities. However, most of the R-convolution graph kernels face two challenges: 1) They cannot compare graphs at multiple different scales, and 2) they do not consider the distributions of substructures when computing the kernel matrix. These two challenges limit their performances. To mitigate the two challenges, we propose a novel graph kernel called the Multi-scale Path-pattern Graph kernel (MPG), at the heart of which is the multi-scale path-pattern node feature map. Each element of the path-pattern node feature map is the number of occurrences of a path-pattern around a node. A path-pattern is constructed by the concatenation of all the node labels in a path of a truncated BFS tree rooted at each node. Since the path-pattern node feature map can only compare graphs at local scales, we incorporate into it the multiple different scales of the graph structure, which are captured by the truncated BFS trees of different depth. We use the Wasserstein distance to compute the similarity between the multi-scale path-pattern node feature maps of two graphs, considering the distributions of substructures. We empirically validate MPG on various benchmark graph datasets and demonstrate that it achieves state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2206.00979",
    "authors": [
      "Wei Ye",
      "Hao Tian",
      "Qijun Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.00983",
    "title": "On the Effectiveness of Knowledge Graph Embeddings: a Rule Mining  Approach",
    "abstract": "We study the effectiveness of Knowledge Graph Embeddings (KGE) for knowledge graph (KG) completion with rule mining. More specifically, we mine rules from KGs before and after they have been completed by a KGE to compare possible differences in the rules extracted. We apply this method to classical KGEs approaches, in particular, TransE, DistMult and ComplEx. Our experiments indicate that there can be huge differences between the extracted rules, depending on the KGE approach for KG completion. In particular, after the TransE completion, several spurious rules were extracted. ",
    "url": "https://arxiv.org/abs/2206.00983",
    "authors": [
      "Johanna J\u00f8sang",
      "Ricardo Guimar\u00e3es",
      "Ana Ozaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.00991",
    "title": "StopNet: Scalable Trajectory and Occupancy Prediction for Urban  Autonomous Driving",
    "abstract": "We introduce a motion forecasting (behavior prediction) method that meets the latency requirements for autonomous driving in dense urban environments without sacrificing accuracy. A whole-scene sparse input representation allows StopNet to scale to predicting trajectories for hundreds of road agents with reliable latency. In addition to predicting trajectories, our scene encoder lends itself to predicting whole-scene probabilistic occupancy grids, a complementary output representation suitable for busy urban environments. Occupancy grids allow the AV to reason collectively about the behavior of groups of agents without processing their individual trajectories. We demonstrate the effectiveness of our sparse input representation and our model in terms of computation and accuracy over three datasets. We further show that co-training consistent trajectory and occupancy predictions improves upon state-of-the-art performance under standard metrics. ",
    "url": "https://arxiv.org/abs/2206.00991",
    "authors": [
      "Jinkyu Kim",
      "Reza Mahjourian",
      "Scott Ettinger",
      "Mayank Bansal",
      "Brandyn White",
      "Ben Sapp",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.01002",
    "title": "Introducing One Sided Margin Loss for Solving Classification Problems in  Deep Networks",
    "abstract": "This paper introduces a new loss function, OSM (One-Sided Margin), to solve maximum-margin classification problems effectively. Unlike the hinge loss, in OSM the margin is explicitly determined with corresponding hyperparameters and then the classification problem is solved. In experiments, we observe that using OSM loss leads to faster training speeds and better accuracies than binary and categorical cross-entropy in several commonly used deep models for classification and optical character recognition problems. OSM has consistently shown better classification accuracies over cross-entropy and hinge losses for small to large neural networks. it has also led to a more efficient training procedure. We achieved state-of-the-art accuracies for small networks on several benchmark datasets of CIFAR10(98.82\\%), CIFAR100(91.56\\%), Flowers(98.04\\%), Stanford Cars(93.91\\%) with considerable improvements over other loss functions. Moreover, the accuracies are rather better than cross-entropy and hinge loss for large networks. Therefore, we strongly believe that OSM is a powerful alternative to hinge and cross-entropy losses to train deep neural networks on classification tasks. ",
    "url": "https://arxiv.org/abs/2206.01002",
    "authors": [
      "Ali Karimi",
      "Zahra Mousavi Kouzehkanan",
      "Reshad Hosseini",
      "Hadi Asheri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.01003",
    "title": "Shortest Path Networks for Graph Property Prediction",
    "abstract": "Most graph neural network models rely on a particular message passing paradigm, where the idea is to iteratively propagate node representations of a graph to each node in the direct neighborhood. While very prominent, this paradigm leads to information propagation bottlenecks, as information is repeatedly compressed at intermediary node representations, which causes loss of information, making it practically impossible to gather meaningful signals from distant nodes. To address this issue, we propose shortest path message passing neural networks, where the node representations of a graph are propagated to each node in the shortest path neighborhoods. In this setting, nodes can directly communicate between each other even if they are not neighbors, breaking the information bottleneck and hence leading to more adequately learned representations. Theoretically, our framework generalizes message passing neural networks, resulting in provably more expressive models. Empirically, we verify the capacity of a basic model of this framework on dedicated synthetic experiments, and on real-world graph classification and regression benchmarks, obtaining several state-of-the-art results. ",
    "url": "https://arxiv.org/abs/2206.01003",
    "authors": [
      "Ralph Abboud",
      "Radoslav Dimitrov",
      "\u0130smail \u0130lkan Ceylan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.01008",
    "title": "Approximate Network Motif Mining Via Graph Learning",
    "abstract": "Frequent and structurally related subgraphs, also known as network motifs, are valuable features of many graph datasets. However, the high computational complexity of identifying motif sets in arbitrary datasets (motif mining) has limited their use in many real-world datasets. By automatically leveraging statistical properties of datasets, machine learning approaches have shown promise in several tasks with combinatorial complexity and are therefore a promising candidate for network motif mining. In this work we seek to facilitate the development of machine learning approaches aimed at motif mining. We propose a formulation of the motif mining problem as a node labelling task. In addition, we build benchmark datasets and evaluation metrics which test the ability of models to capture different aspects of motif discovery such as motif number, size, topology, and scarcity. Next, we propose MotiFiesta, a first attempt at solving this problem in a fully differentiable manner with promising results on challenging baselines. Finally, we demonstrate through MotiFiesta that this learning setting can be applied simultaneously to general-purpose data mining and interpretable feature extraction for graph classification tasks. ",
    "url": "https://arxiv.org/abs/2206.01008",
    "authors": [
      "Carlos Oliver",
      "Dexiong Chen",
      "Vincent Mallet",
      "Pericles Philippopoulos",
      "Karsten Borgwardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.01017",
    "title": "Structured Two-stream Attention Network for Video Question Answering",
    "abstract": "To date, visual question answering (VQA) (i.e., image QA and video QA) is still a holy grail in vision and language understanding, especially for video QA. Compared with image QA that focuses primarily on understanding the associations between image region-level details and corresponding questions, video QA requires a model to jointly reason across both spatial and long-range temporal structures of a video as well as text to provide an accurate answer. In this paper, we specifically tackle the problem of video QA by proposing a Structured Two-stream Attention network, namely STA, to answer a free-form or open-ended natural language question about the content of a given video. First, we infer rich long-range temporal structures in videos using our structured segment component and encode text features. Then, our structured two-stream attention component simultaneously localizes important visual instance, reduces the influence of background video and focuses on the relevant text. Finally, the structured two-stream fusion component incorporates different segments of query and video aware context representation and infers the answers. Experiments on the large-scale video QA dataset \\textit{TGIF-QA} show that our proposed method significantly surpasses the best counterpart (i.e., with one representation for the video input) by 13.0%, 13.5%, 11.0% and 0.3 for Action, Trans., TrameQA and Count tasks. It also outperforms the best competitor (i.e., with two representations) on the Action, Trans., TrameQA tasks by 4.1%, 4.7%, and 5.1%. ",
    "url": "https://arxiv.org/abs/2206.01017",
    "authors": [
      "Lianli Gao",
      "Pengpeng Zeng",
      "Jingkuan Song",
      "Yuan-Fang Li",
      "Wu Liu",
      "Tao Mei",
      "Heng Tao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.01034",
    "title": "Adversarial Laser Spot: Robust and Covert Physical Adversarial Attack to  DNNs",
    "abstract": "Most existing deep neural networks (DNNs) are easily disturbed by slight noise. As far as we know, there are few researches on physical adversarial attack technology by deploying lighting equipment. The light-based physical adversarial attack technology has excellent covertness, which brings great security risks to many applications based on deep neural networks (such as automatic driving technology). Therefore, we propose a robust physical adversarial attack technology with excellent covertness, called adversarial laser point (AdvLS), which optimizes the physical parameters of laser point through genetic algorithm to perform physical adversarial attack. It realizes robust and covert physical adversarial attack by using low-cost laser equipment. As far as we know, AdvLS is the first light-based adversarial attack technology that can perform physical adversarial attacks in the daytime. A large number of experiments in the digital and physical environments show that AdvLS has excellent robustness and concealment. In addition, through in-depth analysis of the experimental data, we find that the adversarial perturbations generated by AdvLS have superior adversarial attack migration. The experimental results show that AdvLS impose serious interference to the advanced deep neural networks, we call for the attention of the proposed physical adversarial attack technology. ",
    "url": "https://arxiv.org/abs/2206.01034",
    "authors": [
      "Chengyin Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.01041",
    "title": "End-to-End Security for Distributed Event-Driven Enclave Applications on  Heterogeneous TEEs",
    "abstract": "This paper presents an approach to provide strong assurance of the secure execution of distributed event-driven applications on shared infrastructures, while relying on a small Trusted Computing Base. We build upon and extend security primitives provided by Trusted Execution Environments (TEEs) to guarantee authenticity and integrity properties of applications, and to secure control of input and output devices. More specifically, we guarantee that if an output is produced by the application, it was allowed to be produced by the application's source code based on an authentic trace of inputs. We present an integrated open-source framework to develop, deploy, and use such applications across heterogeneous TEEs. Beyond authenticity and integrity, our framework optionally provides confidentiality and a notion of availability, and facilitates software development at a high level of abstraction over the platform-specific TEE layer. We support event-driven programming to develop distributed enclave applications in Rust and C for heterogeneous TEE, including Intel SGX, ARM TrustZone and Sancus. In this article we discuss the workings of our approach, the extensions we made to the Sancus processor, and the integration of our development model with commercial TEEs. Our evaluation of security and performance aspects show that TEEs, together with our programming model, form a basis for powerful security architectures for dependable systems in domains such as Industrial Control Systems and the Internet of Things, illustrating our framework's unique suitability for a broad range of use cases which combine cloud processing, mobile and edge devices, and lightweight sensing and actuation. ",
    "url": "https://arxiv.org/abs/2206.01041",
    "authors": [
      "Gianluca Scopelliti",
      "Sepideh Pouyanrad",
      "Job Noorman",
      "Fritz Alder",
      "Christoph Baumann",
      "Frank Piessens",
      "Jan Tobias M\u00fchlberg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.01067",
    "title": "Practical Adversarial Multivalid Conformal Prediction",
    "abstract": "We give a simple, generic conformal prediction method for sequential prediction that achieves target empirical coverage guarantees against adversarially chosen data. It is computationally lightweight -- comparable to split conformal prediction -- but does not require having a held-out validation set, and so all data can be used for training models from which to derive a conformal score. It gives stronger than marginal coverage guarantees in two ways. First, it gives threshold calibrated prediction sets that have correct empirical coverage even conditional on the threshold used to form the prediction set from the conformal score. Second, the user can specify an arbitrary collection of subsets of the feature space -- possibly intersecting -- and the coverage guarantees also hold conditional on membership in each of these subsets. We call our algorithm MVP, short for MultiValid Prediction. We give both theory and an extensive set of empirical evaluations. ",
    "url": "https://arxiv.org/abs/2206.01067",
    "authors": [
      "Osbert Bastani",
      "Varun Gupta",
      "Christopher Jung",
      "Georgy Noarov",
      "Ramya Ramalingam",
      "Aaron Roth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.01077",
    "title": "The Power of Amortized Recourse for Online Graph Problems",
    "abstract": "In this work, we study graph problems with monotone-sum objectives. We propose a general two-fold greedy algorithm that references $\\alpha$-approximation algorithms (where $\\alpha \\ge 1$) to achieve $(t \\cdot \\alpha)$-competitiveness while incurring at most $\\frac{w_{\\text{max}}\\cdot(t+1)}{\\min\\{1, w_\\text{min}\\}\\cdot(t-1)}$ amortized recourse, where $w_{\\text{max}}$ and $w_{\\text{min}}$ are the largest value and the smallest positive value that can be assigned to an element in the sum. We further refine this trade-off between competitive ratio and amortized recourse for three classical graph problems. For Independent Set, we refine the analysis of our general algorithm and show that $t$-competitiveness can be achieved with $\\frac{t}{t-1}$ amortized recourse. For Maximum Matching, we use an existing algorithm with limited greed to show that $t$-competitiveness can be achieved with $\\frac{(2-t^*)}{(t^*-1)(3-t^*)}+\\frac{t^*-1}{3-t^*}$ amortized recourse, where $t^*$ is the largest number such that $t^*= 1 +\\frac{1}{j} \\leq t$ for some integer $j$. For Vertex Cover, we introduce a polynomial-time algorithm that further limits greed to show that $(2 - \\frac{2}{\\texttt{OPT}})$-competitiveness, where $\\texttt{OPT}$ is the size of the optimal vertex cover, can be achieved with at most $\\frac{10}{3}$ amortized recourse by a potential function argument. We remark that this online result can be used as an offline approximation result (without violating the unique games conjecture) to improve upon that of Monien and Speckenmeyer for graphs containing odd cycles of length no less than $2k + 3$, using an algorithm that is also constructive. ",
    "url": "https://arxiv.org/abs/2206.01077",
    "authors": [
      "Hsiang-Hsuan Liu",
      "Jonathan Toole-Charignon"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2206.01087",
    "title": "Enriching a Fashion Knowledge Graph from Product Textual Descriptions",
    "abstract": "Knowledge Graphs offer a very useful and powerful structure for representing information, consequently, they have been adopted as the backbone for many applications in e-commerce scenarios. In this paper, we describe an application of existing techniques for enriching thelarge-scale Fashion Knowledge Graph (FKG) that we build at Farfetch. In particular, we apply techniques for named entity recognition (NER) and entity linking (EL) in order to extract and link rich metadata from product textual descriptions to entities in the FKG. Having a complete and enriched FKG as an e-commerce backbone can have a highly valuable impact on downstream applications such as search and recommendations. However, enriching a Knowledge Graph in the fashion domain has its own challenges. Data representation is different from a more generic KG, like Wikidata and Yago, as entities (e.g. product attributes) are too specific to the domain, and long textual descriptions are not readily available. Data itself is also scarce, as labelling datasets to train supervised models is a very laborious task. Even more, fashion products display a high variability and require an intricate ontology of attributes to link to. We use a transfer learning based approach to train an NER module on a small amount of manually labeled data, followed by an EL module that links the previously identified named entities to the appropriate entities within the FKG. Experiments using a pre-trained model show that it is possible to achieve 89.75% accuracy in NER even with a small manually labeled dataset. Moreover, the EL module, despite relying on simple rule-based or ML models (due to lack of training data), is able to link relevant attributes to products, thus automatically enriching the FKG. ",
    "url": "https://arxiv.org/abs/2206.01087",
    "authors": [
      "Jo\u00e3o Barroca",
      "Abhishek Shivkumar",
      "Beatriz Quintino Ferreira",
      "Evgeny Sherkhonov",
      "Jo\u00e3o Faria"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.01101",
    "title": "Weakly Supervised Representation Learning with Sparse Perturbations",
    "abstract": "The theory of representation learning aims to build methods that provably invert the data generating process with minimal domain knowledge or any source of supervision. Most prior approaches require strong distributional assumptions on the latent variables and weak supervision (auxiliary information such as timestamps) to provide provable identification guarantees. In this work, we show that if one has weak supervision from observations generated by sparse perturbations of the latent variables--e.g. images in a reinforcement learning environment where actions move individual sprites--identification is achievable under unknown continuous latent distributions. We show that if the perturbations are applied only on mutually exclusive blocks of latents, we identify the latents up to those blocks. We also show that if these perturbation blocks overlap, we identify latents up to the smallest blocks shared across perturbations. Consequently, if there are blocks that intersect in one latent variable only, then such latents are identified up to permutation and scaling. We propose a natural estimation procedure based on this theory and illustrate it on low-dimensional synthetic and image-based experiments. ",
    "url": "https://arxiv.org/abs/2206.01101",
    "authors": [
      "Kartik Ahuja",
      "Jason Hartford",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.01102",
    "title": "A temporal chrominance trigger for clean-label backdoor attack against  anti-spoof rebroadcast detection",
    "abstract": "We propose a stealthy clean-label video backdoor attack against Deep Learning (DL)-based models aiming at detecting a particular class of spoofing attacks, namely video rebroadcast attacks. The injected backdoor does not affect spoofing detection in normal conditions, but induces a misclassification in the presence of a specific triggering signal. The proposed backdoor relies on a temporal trigger altering the average chrominance of the video sequence. The backdoor signal is designed by taking into account the peculiarities of the Human Visual System (HVS) to reduce the visibility of the trigger, thus increasing the stealthiness of the backdoor. To force the network to look at the presence of the trigger in the challenging clean-label scenario, we choose the poisoned samples used for the injection of the backdoor following a so-called Outlier Poisoning Strategy (OPS). According to OPS, the triggering signal is inserted in the training samples that the network finds more difficult to classify. The effectiveness of the proposed backdoor attack and its generality are validated experimentally on different datasets and anti-spoofing rebroadcast detection architectures. ",
    "url": "https://arxiv.org/abs/2206.01102",
    "authors": [
      "Wei Guo",
      "Benedetta Tondi",
      "Mauro Barni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.01106",
    "title": "Robustness to Label Noise Depends on the Shape of the Noise Distribution  in Feature Space",
    "abstract": "Machine learning classifiers have been demonstrated, both empirically and theoretically, to be robust to label noise under certain conditions -- notably the typical assumption is that label noise is independent of the features given the class label. We provide a theoretical framework that generalizes beyond this typical assumption by modeling label noise as a distribution over feature space. We show that both the scale and the shape of the noise distribution influence the posterior likelihood; and the shape of the noise distribution has a stronger impact on classification performance if the noise is concentrated in feature space where the decision boundary can be moved. For the special case of uniform label noise (independent of features and the class label), we show that the Bayes optimal classifier for $c$ classes is robust to label noise until the ratio of noisy samples goes above $\\frac{c-1}{c}$ (e.g. 90% for 10 classes), which we call the tipping point. However, for the special case of class-dependent label noise (independent of features given the class label), the tipping point can be as low as 50%. Most importantly, we show that when the noise distribution targets decision boundaries (label noise is directly dependent on feature space), classification robustness can drop off even at a small scale of noise. Even when evaluating recent label-noise mitigation methods we see reduced accuracy when label noise is dependent on features. These findings explain why machine learning often handles label noise well if the noise distribution is uniform in feature-space; yet it also points to the difficulty of overcoming label noise when it is concentrated in a region of feature space where a decision boundary can move. ",
    "url": "https://arxiv.org/abs/2206.01106",
    "authors": [
      "Diane Oyen",
      "Michal Kucer",
      "Nick Hengartner",
      "Har Simrat Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.01137",
    "title": "Finding the Right Recipe for Low Resource Domain Adaptation in Neural  Machine Translation",
    "abstract": "General translation models often still struggle to generate accurate translations in specialized domains. To guide machine translation practitioners and characterize the effectiveness of domain adaptation methods under different data availability scenarios, we conduct an in-depth empirical exploration of monolingual and parallel data approaches to domain adaptation of pre-trained, third-party, NMT models in settings where architecture change is impractical. We compare data centric adaptation methods in isolation and combination. We study method effectiveness in very low resource (8k parallel examples) and moderately low resource (46k parallel examples) conditions and propose an ensemble approach to alleviate reductions in original domain translation quality. Our work includes three domains: consumer electronic, clinical, and biomedical and spans four language pairs - Zh-En, Ja-En, Es-En, and Ru-En. We also make concrete recommendations for achieving high in-domain performance and release our consumer electronic and medical domain datasets for all languages and make our code publicly available. ",
    "url": "https://arxiv.org/abs/2206.01137",
    "authors": [
      "Virginia Adams",
      "Sandeep Subramanian",
      "Mike Chrzanowski",
      "Oleksii Hrinchuk",
      "Oleksii Kuchaiev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.01146",
    "title": "Block-Parallel Systolic-Array Architecture for 2-D NTT-based Fragile  Watermark Embedding",
    "abstract": "Number-theoretic transforms (NTTs) have been applied in the fragile watermarking of digital images. A block-parallel systolic-array architecture is proposed for watermarking based on the 2-D special Hartley NTT (HNTT). The proposed core employs two 2-D special HNTT hardware cores, each using digital arithmetic over $\\mathrm{GF}(3)$, and processes $4\\times4$ blocks of pixels in parallel every clock cycle. Prototypes are operational on a Xilinx Sx35-10ff668 FPGA device. The maximum estimated throughput of the FPGA circuit is 100 million $4\\times4$ HNTT fragile watermarked blocks per second, when clocked at 100 MHz. Potential applications exist in high-traffic back-end servers dealing with large amounts of protected digital images requiring authentication, in remote-sensing for high-security surveillance applications, in real-time video processing of information of a sensitive nature or matters of national security, in video/photographic content management of corporate clients, in authenticating multimedia for the entertainment industry, in the authentication of electronic evidence material, and in real-time news streaming. ",
    "url": "https://arxiv.org/abs/2206.01146",
    "authors": [
      "H. P. L. Arjuna Madanayake",
      "R. J. Cintra",
      "V. S. Dimitrov",
      "L. Bruton"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.01160",
    "title": "DE-Net: Dynamic Text-guided Image Editing Adversarial Networks",
    "abstract": "Text-guided image editing models have shown remarkable results. However, there remain two problems. First, they employ fixed manipulation modules for various editing requirements (e.g., color changing, texture changing, content adding and removing), which result in over-editing or insufficient editing. Second, they do not clearly distinguish between text-required parts and text-irrelevant parts, which leads to inaccurate editing. To solve these limitations, we propose: (i) a Dynamic Editing Block (DEBlock) which combines spatial- and channel-wise manipulations dynamically for various editing requirements. (ii) a Combination Weights Predictor (CWP) which predicts the combination weights for DEBlock according to the inference on text and visual features. (iii) a Dynamic text-adaptive Convolution Block (DCBlock) which queries source image features to distinguish text-required parts and text-irrelevant parts. Extensive experiments demonstrate that our DE-Net achieves excellent performance and manipulates source images more effectively and accurately. Code is available at \\url{https://github.com/tobran/DE-Net}. ",
    "url": "https://arxiv.org/abs/2206.01160",
    "authors": [
      "Ming Tao",
      "Bing-Kun Bao",
      "Hao Tang",
      "Fei Wu",
      "Longhui Wei",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2206.01161",
    "title": "Optimizing Relevance Maps of Vision Transformers Improves Robustness",
    "abstract": "It has been observed that visual classification models often rely mostly on the image background, neglecting the foreground, which hurts their robustness to distribution changes. To alleviate this shortcoming, we propose to monitor the model's relevancy signal and manipulate it such that the model is focused on the foreground object. This is done as a finetuning step, involving relatively few samples consisting of pairs of images and their associated foreground masks. Specifically, we encourage the model's relevancy map (i) to assign lower relevance to background regions, (ii) to consider as much information as possible from the foreground, and (iii) we encourage the decisions to have high confidence. When applied to Vision Transformer (ViT) models, a marked improvement in robustness to domain shifts is observed. Moreover, the foreground masks can be obtained automatically, from a self-supervised variant of the ViT model itself; therefore no additional supervision is required. ",
    "url": "https://arxiv.org/abs/2206.01161",
    "authors": [
      "Hila Chefer",
      "Idan Schwartz",
      "Lior Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.01175",
    "title": "Robust Longitudinal Control for Vehicular Autonomous Platoons Using Deep  Reinforcement Learning",
    "abstract": "In the last few years, researchers have applied machine learning strategies in the context of vehicular platoons to increase the safety and efficiency of cooperative transportation. Reinforcement Learning methods have been employed in the longitudinal spacing control of Cooperative Adaptive Cruise Control systems, but to date, none of those studies have addressed problems of disturbance rejection in such scenarios. Characteristics such as uncertain parameters in the model and external interferences may prevent agents from reaching null-spacing errors when traveling at cruising speed. On the other hand, complex communication topologies lead to specific training processes that can not be generalized to other contexts, demanding re-training every time the configuration changes. Therefore, in this paper, we propose an approach to generalize the training process of a vehicular platoon, such that the acceleration command of each agent becomes independent of the network topology. Also, we have modeled the acceleration input as a term with integral action, such that the Convolutional Neural Network is capable of learning corrective actions when the states are disturbed by unknown effects. We illustrate the effectiveness of our proposal with experiments using different network topologies, uncertain parameters, and external forces. Comparative analyses, in terms of the steady-state error and overshoot response, were conducted against the state-of-the-art literature. The findings offer new insights concerning generalization and robustness of using Reinforcement Learning in the control of autonomous platoons. ",
    "url": "https://arxiv.org/abs/2206.01175",
    "authors": [
      "Armando Alves Neto",
      "Leonardo Amaral Mozelli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.01176",
    "title": "From Cities to Series: Complex Networks and Deep Learning for Improved  Spatial and Temporal Analytics*",
    "abstract": "Graphs have often been used to answer questions about the interaction between real-world entities by taking advantage of their capacity to represent complex topologies. Complex networks are known to be graphs that capture such non-trivial topologies; they are able to represent human phenomena such as epidemic processes, the dynamics of populations, and the urbanization of cities. The investigation of complex networks has been extrapolated to many fields of science, with particular emphasis on computing techniques, including artificial intelligence. In such a case, the analysis of the interaction between entities of interest is transposed to the internal learning of algorithms, a paradigm whose investigation is able to expand the state of the art in Computer Science. By exploring this paradigm, this thesis puts together complex networks and machine learning techniques to improve the understanding of the human phenomena observed in pandemics, pendular migration, and street networks. Accordingly, we contribute with: (i) a new neural network architecture capable of modeling dynamic processes observed in spatial and temporal data with applications in epidemics propagation, weather forecasting, and patient monitoring in intensive care units; (ii) a machine-learning methodology for analyzing and predicting links in the scope of human mobility between all the cities of Brazil; and, (iii) techniques for identifying inconsistencies in the urban planning of cities while tracking the most influential vertices, with applications over Brazilian and worldwide cities. We obtained results sustained by sound evidence of advances to the state of the art in artificial intelligence, rigorous formalisms, and ample experimentation. Our findings rely upon real-world applications in a range of domains, demonstrating the applicability of our methodologies. ",
    "url": "https://arxiv.org/abs/2206.01176",
    "authors": [
      "Gabriel Spadon",
      "Jose F. Rodrigues-Jr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.01178",
    "title": "Deep Learning on Implicit Neural Datasets",
    "abstract": "Implicit neural representations (INRs) have become fast, lightweight tools for storing continuous data, but to date there is no general method for learning directly with INRs as a data representation. We introduce a principled deep learning framework for learning and inference directly with INRs of any type without reverting to grid-based features or operations. Our INR-Nets evaluate INRs on a low discrepancy sequence, enabling quasi-Monte Carlo (QMC) integration throughout the network. We prove INR-Nets are universal approximators on a large class of maps between $L^2$ functions. Additionally, INR-Nets have convergent gradients under the empirical measure, enabling backpropagation. We design INR-Nets as a continuous generalization of discrete networks, enabling them to be initialized with pre-trained models. We demonstrate learning of INR-Nets on classification (INR$\\to$label) and segmentation (INR$\\to$INR) tasks. ",
    "url": "https://arxiv.org/abs/2206.01178",
    "authors": [
      "Clinton J. Wang",
      "Polina Golland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.01186",
    "title": "ORC: Network Group-based Knowledge Distillation using Online Role Change",
    "abstract": "In knowledge distillation, since a single, omnipotent teacher network cannot solve all problems, multiple teacher-based knowledge distillations have been studied recently. However, sometimes their improvements are not as good as expected because some immature teachers may transfer the false knowledge to the student. In this paper, to overcome this limitation and take the efficacy of the multiple networks, we divide the multiple networks into teacher and student groups, respectively. That is, the student group is a set of immature networks that require learning the teacher's knowledge, while the teacher group consists of the selected networks that have performed well. Furthermore, according to our online role change strategy, the top-ranked networks in the student group are able to promote to the teacher group at every iteration and vice versa. After training the teacher group using the error images of the student group to refine the teacher group's knowledge, we transfer the collective knowledge from the teacher group to the student group successfully. We verify the superiority of the proposed method on CIFAR-10 and CIFAR-100, which achieves high performance. We further show the generality of our method with various backbone architectures such as resent, wrn, vgg, mobilenet, and shufflenet. ",
    "url": "https://arxiv.org/abs/2206.01186",
    "authors": [
      "Junyong Choi",
      "Hyeon Cho",
      "Seockhwa Jeong",
      "Wonjun Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.01188",
    "title": "Control hubs of complex networks and a polynomial-time identification  algorithm",
    "abstract": "Unveiling the underlying control principles of complex networks is one of the ultimate goals of network science. We introduce a novel concept, control hub, to reveal a cornerstone of the control structure of a network. The control hubs of a network are the nodes that lie in the middle of a control path in every control scheme of the network. We present a theorem based on graph theory for identifying control hubs without computing all control schemes. We develop an algorithm to identify all control hubs in O(N0.5L) time complexity for a network of N nodes and L links. ",
    "url": "https://arxiv.org/abs/2206.01188",
    "authors": [
      "Xizhe Zhang",
      "Chunyu Pan",
      "Weixiong Zhang"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.01197",
    "title": "Hard Negative Sampling Strategies for Contrastive Representation  Learning",
    "abstract": "One of the challenges in contrastive learning is the selection of appropriate \\textit{hard negative} examples, in the absence of label information. Random sampling or importance sampling methods based on feature similarity often lead to sub-optimal performance. In this work, we introduce UnReMix, a hard negative sampling strategy that takes into account anchor similarity, model uncertainty and representativeness. Experimental results on several benchmarks show that UnReMix improves negative sample selection, and subsequently downstream performance when compared to state-of-the-art contrastive learning methods. ",
    "url": "https://arxiv.org/abs/2206.01197",
    "authors": [
      "Afrina Tabassum",
      "Muntasir Wahed",
      "Hoda Eldardiry",
      "Ismini Lourentzou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.01198",
    "title": "Pruning-as-Search: Efficient Neural Architecture Search via Channel  Pruning and Structural Reparameterization",
    "abstract": "Neural architecture search (NAS) and network pruning are widely studied efficient AI techniques, but not yet perfect. NAS performs exhaustive candidate architecture search, incurring tremendous search cost. Though (structured) pruning can simply shrink model dimension, it remains unclear how to decide the per-layer sparsity automatically and optimally. In this work, we revisit the problem of layer-width optimization and propose Pruning-as-Search (PaS), an end-to-end channel pruning method to search out desired sub-network automatically and efficiently. Specifically, we add a depth-wise binary convolution to learn pruning policies directly through gradient descent. By combining the structural reparameterization and PaS, we successfully searched out a new family of VGG-like and lightweight networks, which enable the flexibility of arbitrary width with respect to each layer instead of each stage. Experimental results show that our proposed architecture outperforms prior arts by around $1.0\\%$ top-1 accuracy under similar inference speed on ImageNet-1000 classification task. Furthermore, we demonstrate the effectiveness of our width search on complex tasks including instance segmentation and image translation. Code and models are released. ",
    "url": "https://arxiv.org/abs/2206.01198",
    "authors": [
      "Yanyu Li",
      "Pu Zhao",
      "Geng Yuan",
      "Xue Lin",
      "Yanzhi Wang",
      "Xin Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.01201",
    "title": "REVIVE: Regional Visual Representation Matters in Knowledge-Based Visual  Question Answering",
    "abstract": "This paper revisits visual representation in knowledge-based visual question answering (VQA) and demonstrates that using regional information in a better way can significantly improve the performance. While visual representation is extensively studied in traditional VQA, it is under-explored in knowledge-based VQA even though these two tasks share the common spirit, i.e., rely on visual input to answer the question. Specifically, we observe that in most state-of-the-art knowledge-based VQA methods: 1) visual features are extracted either from the whole image or in a sliding window manner for retrieving knowledge, and the important relationship within/among object regions is neglected; 2) visual features are not well utilized in the final answering model, which is counter-intuitive to some extent. Based on these observations, we propose a new knowledge-based VQA method REVIVE, which tries to utilize the explicit information of object regions not only in the knowledge retrieval stage but also in the answering model. The key motivation is that object regions and inherent relationships are important for knowledge-based VQA. We perform extensive experiments on the standard OK-VQA dataset and achieve new state-of-the-art performance, i.e., 58.0% accuracy, surpassing previous state-of-the-art method by a large margin (+3.6%). We also conduct detailed analysis and show the necessity of regional information in different framework components for knowledge-based VQA. ",
    "url": "https://arxiv.org/abs/2206.01201",
    "authors": [
      "Yuanze Lin",
      "Yujia Xie",
      "Dongdong Chen",
      "Yichong Xu",
      "Chenguang Zhu",
      "Lu Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.01204",
    "title": "Siamese Image Modeling for Self-Supervised Vision Representation  Learning",
    "abstract": "Self-supervised learning (SSL) has delivered superior performance on a variety of downstream vision tasks. Two main-stream SSL frameworks have been proposed, i.e., Instance Discrimination (ID) and Masked Image Modeling (MIM). ID pulls together the representations of different views from the same image, while avoiding feature collapse. It does well on linear probing but is inferior in detection performance. On the other hand, MIM reconstructs the original content given a masked image. It excels at dense prediction but fails to perform well on linear probing. Their distinctions are caused by neglecting the representation requirements of either semantic alignment or spatial sensitivity. Specifically, we observe that (1) semantic alignment demands semantically similar views to be projected into nearby representation, which can be achieved by contrasting different views with strong augmentations; (2) spatial sensitivity requires to model the local structure within an image. Predicting dense representations with masked image is therefore beneficial because it models the conditional distribution of image content. Driven by these analysis, we propose Siamese Image Modeling (SIM), which predicts the dense representations of an augmented view, based on another masked view from the same image but with different augmentations. Our method uses a Siamese network with two branches. The online branch encodes the first view, and predicts the second view's representation according to the relative positions between these two views. The target branch produces the target by encoding the second view. In this way, we are able to achieve comparable linear probing and dense prediction performances with ID and MIM, respectively. We also demonstrate that decent linear probing result can be obtained without a global loss. Code shall be released. ",
    "url": "https://arxiv.org/abs/2206.01204",
    "authors": [
      "Chenxin Tao",
      "Xizhou Zhu",
      "Gao Huang",
      "Yu Qiao",
      "Xiaogang Wang",
      "Jifeng Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2012.05503",
    "title": "Geometric algorithms for sampling the flux space of metabolic networks",
    "abstract": "Systems Biology is a fundamental field and paradigm that introduces a new era in Biology. The crux of its functionality and usefulness relies on metabolic networks that model the reactions occurring inside an organism and provide the means to understand the underlying mechanisms that govern biological systems. Even more, metabolic networks have a broader impact that ranges from resolution of ecosystems to personalized medicine.The analysis of metabolic networks is a computational geometry oriented field as one of the main operations they depend on is sampling uniformly points from polytopes; the latter provides a representation of the steady states of the metabolic networks. However, the polytopes that result from biological data are of very high dimension (to the order of thousands) and in most, if not all, the cases are considerably skinny. Therefore, to perform uniform random sampling efficiently in this setting, we need a novel algorithmic and computational framework specially tailored for the properties of metabolic networks.We present a complete software framework to handle sampling in metabolic networks. Its backbone is a Multiphase Monte Carlo Sampling (MMCS) algorithm that unifies rounding and sampling in one pass, obtaining both upon termination. It exploits an improved variant of the Billiard Walk that enjoys faster arithmetic complexity per step. We demonstrate the efficiency of our approach by performing extensive experiments on various metabolic networks. Notably, sampling on the most complicated human metabolic network accessible today, Recon3D, corresponding to a polytope of dimension 5 335 took less than 30 hours. To our knowledge, that is out of reach for existing software. ",
    "url": "https://arxiv.org/abs/2012.05503",
    "authors": [
      "Apostolos Chalkis",
      "Vissarion Fisikopoulos",
      "Elias Tsigaridas",
      "Haris Zafeiropoulos"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computational Geometry (cs.CG)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2206.00668",
    "title": "Learning to Untangle Genome Assembly with Graph Convolutional Networks",
    "abstract": "A quest to determine the complete sequence of a human DNA from telomere to telomere started three decades ago and was finally completed in 2021. This accomplishment was a result of a tremendous effort of numerous experts who engineered various tools and performed laborious manual inspection to achieve the first gapless genome sequence. However, such method can hardly be used as a general approach to assemble different genomes, especially when the assembly speed is critical given the large amount of data. In this work, we explore a different approach to the central part of the genome assembly task that consists of untangling a large assembly graph from which a genomic sequence needs to be reconstructed. Our main motivation is to reduce human-engineered heuristics and use deep learning to develop more generalizable reconstruction techniques. Precisely, we introduce a new learning framework to train a graph convolutional network to resolve assembly graphs by finding a correct path through them. The training is supervised with a dataset generated from the resolved CHM13 human sequence and tested on assembly graphs built using real human PacBio HiFi reads. Experimental results show that a model, trained on simulated graphs generated solely from a single chromosome, is able to remarkably resolve all other chromosomes. Moreover, the model outperforms hand-crafted heuristics from a state-of-the-art \\textit{de novo} assembler on the same graphs. Reconstructed chromosomes with graph networks are more accurate on nucleotide level, report lower number of contigs, higher genome reconstructed fraction and NG50/NGA50 assessment metrics. ",
    "url": "https://arxiv.org/abs/2206.00668",
    "authors": [
      "Lovro Vr\u010dek",
      "Xavier Bresson",
      "Thomas Laurent",
      "Martin Schmitz",
      "Mile \u0160iki\u0107"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00775",
    "title": "Adaptive Local Neighborhood-based Neural Networks for MR Image  Reconstruction from Undersampled Data",
    "abstract": "Recent medical image reconstruction techniques focus on generating high-quality medical images suitable for clinical use at the lowest possible cost and with the fewest possible adverse effects on patients. Recent works have shown significant promise for reconstructing MR images from sparsely sampled k-space data using deep learning. In this work, we propose a technique that rapidly estimates deep neural networks directly at reconstruction time by fitting them on small adaptively estimated neighborhoods of a training set. In brief, our algorithm alternates between searching for neighbors in a data set that are similar to the test reconstruction, and training a local network on these neighbors followed by updating the test reconstruction. Because our reconstruction model is learned on a dataset that is structurally similar to the image being reconstructed rather than being fit on a large, diverse training set, it is more adaptive to new scans. It can also handle changes in training sets and flexible scan settings, while being relatively fast. Our approach, dubbed LONDN-MRI, was validated on the FastMRI multi-coil knee data set using deep unrolled reconstruction networks. Reconstructions were performed at four fold and eight fold undersampling of k-space with 1D variable-density random phase-encode undersampling masks. Our results demonstrate that our proposed locally-trained method produces higher-quality reconstructions compared to models trained globally on larger datasets. ",
    "url": "https://arxiv.org/abs/2206.00775",
    "authors": [
      "Shijun Liang",
      "Anish Lahiri",
      "Saiprasad Ravishankar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00794",
    "title": "Sequential Bayesian Neural Subnetwork Ensembles",
    "abstract": "Deep neural network ensembles that appeal to model diversity have been used successfully to improve predictive performance and model robustness in several applications. Whereas, it has recently been shown that sparse subnetworks of dense models can match the performance of their dense counterparts and increase their robustness while effectively decreasing the model complexity. However, most ensembling techniques require multiple parallel and costly evaluations and have been proposed primarily with deterministic models, whereas sparsity induction has been mostly done through ad-hoc pruning. We propose sequential ensembling of dynamic Bayesian neural subnetworks that systematically reduce model complexity through sparsity-inducing priors and generate diverse ensembles in a single forward pass of the model. The ensembling strategy consists of an exploration phase that finds high-performing regions of the parameter space and multiple exploitation phases that effectively exploit the compactness of the sparse model to quickly converge to different minima in the energy landscape corresponding to high-performing subnetworks yielding diverse ensembles. We empirically demonstrate that our proposed approach surpasses the baselines of the dense frequentist and Bayesian ensemble models in prediction accuracy, uncertainty estimation, and out-of-distribution (OoD) robustness on CIFAR10, CIFAR100 datasets, and their out-of-distribution variants: CIFAR10-C, CIFAR100-C induced by corruptions. Furthermore, we found that our approach produced the most diverse ensembles compared to the approaches with a single forward pass and even compared to the approaches with multiple forward passes in some cases. ",
    "url": "https://arxiv.org/abs/2206.00794",
    "authors": [
      "Sanket Jantre",
      "Sandeep Madireddy",
      "Shrijita Bhattacharya",
      "Tapabrata Maiti",
      "Prasanna Balaprakash"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2206.00850",
    "title": "Dynamic MRI using Learned Transform-based Deep Tensor Low-Rank Network  (DTLR-Net)",
    "abstract": "While low-rank matrix prior has been exploited in dynamic MR image reconstruction and has obtained satisfying performance, low-rank tensors models have recently emerged as powerful alternative representations for three-dimensional dynamic MR datasets. In this paper, we introduce a model-based deep learning network by learning the tensor low-rank prior of the cardiac dynamic MR images. Instead of representing the dynamic dataset as a low-rank tensor directly, we propose a learned transformation operator to exploit the tensor low-rank property in a transform domain. In particular, by generalizing the t-SVD tensor decomposition into a unitary transformed t-SVD, we define a transformed tensor nuclear norm (TTNN) to enforce the tensor low-rankness. The dynamic MRI reconstruction problem is thus formulated using a TTNN regularized optimization problem. An iterative algorithm based on ADMM used to minimize the cost is unrolled into a deep network, where the transform is learned using convolutional neural networks (CNNs) to promote the reconstruction quality in the feature domain. Experimental results on cardiac cine MRI reconstruction demonstrate that the proposed framework is able to provide improved recovery results compared with the state-of-the-art algorithms. ",
    "url": "https://arxiv.org/abs/2206.00850",
    "authors": [
      "Yinghao Zhang",
      "Peng Li",
      "Yue Hu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00853",
    "title": "Masked Bayesian Neural Networks : Computation and Optimality",
    "abstract": "As data size and computing power increase, the architectures of deep neural networks (DNNs) have been getting more complex and huge, and thus there is a growing need to simplify such complex and huge DNNs. In this paper, we propose a novel sparse Bayesian neural network (BNN) which searches a good DNN with an appropriate complexity. We employ the masking variables at each node which can turn off some nodes according to the posterior distribution to yield a nodewise sparse DNN. We devise a prior distribution such that the posterior distribution has theoretical optimalities (i.e. minimax optimality and adaptiveness), and develop an efficient MCMC algorithm. By analyzing several benchmark datasets, we illustrate that the proposed BNN performs well compared to other existing methods in the sense that it discovers well condensed DNN architectures with similar prediction accuracy and uncertainty quantification compared to large DNNs. ",
    "url": "https://arxiv.org/abs/2206.00853",
    "authors": [
      "Insung Kong",
      "Dongyoon Yang",
      "Jongjin Lee",
      "Ilsang Ohn",
      "Yongdai Kim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00858",
    "title": "Bayesian Inference of Stochastic Dynamical Networks",
    "abstract": "Network inference has been extensively studied in several fields, such as systems biology and social sciences. Learning network topology and internal dynamics is essential to understand mechanisms of complex systems. In particular, sparse topologies and stable dynamics are fundamental features of many real-world continuous-time networks. Given that usually only a partial set of nodes are able to observe, in this paper, we consider linear continuous-time systems to depict networks since they can model unmeasured nodes via transfer functions. Additionally, measurements tend to be noisy and with low and varying sampling frequencies. For this reason, we consider continuous-time models (CT) since discrete-time approximations often require fine-grained measurements and uniform sampling steps. The developed method applies dynamical structure functions (DSFs) derived from linear stochastic differential equations (SDEs) to describe networks of measured nodes. Further, a numerical sampling method, preconditioned Crank-Nicolson (pCN), is used to refine coarse-grained trajectories to improve inference accuracy. The simulation conducted on random and ring networks, and a synthetic biological network illustrate that our method achieves state-of-the-art performance compared with group sparse Bayesian learning (GSBL), BINGO, kernel-based methods, dynGENIE3, GENIE3 and ARNI. In particular, these are challenging networks, suggesting that the developed method can be applied under a wide range of contexts. ",
    "url": "https://arxiv.org/abs/2206.00858",
    "authors": [
      "Yasen Wang",
      "Junyang Jin",
      "Jorge Goncalves"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00939",
    "title": "Gradient flow dynamics of shallow ReLU networks for square loss and  orthogonal inputs",
    "abstract": "The training of neural networks by gradient descent methods is a cornerstone of the deep learning revolution. Yet, despite some recent progress, a complete theory explaining its success is still missing. This article presents, for orthogonal input vectors, a precise description of the gradient flow dynamics of training one-hidden layer ReLU neural networks for the mean squared error at small initialisation. In this setting, despite non-convexity, we show that the gradient flow converges to zero loss and characterise its implicit bias towards minimum variation norm. Furthermore, some interesting phenomena are highlighted: a quantitative description of the initial alignment phenomenon and a proof that the process follows a specific saddle to saddle dynamics. ",
    "url": "https://arxiv.org/abs/2206.00939",
    "authors": [
      "Etienne Boursier",
      "Loucas Pillaud-Vivien",
      "Nicolas Flammarion"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00970",
    "title": "Self-supervised Learning of Audio Representations from Audio-Visual Data  using Spatial Alignment",
    "abstract": "Learning from audio-visual data offers many possibilities to express correspondence between the audio and visual content, similar to the human perception that relates aural and visual information. In this work, we present a method for self-supervised representation learning based on audio-visual spatial alignment (AVSA), a more sophisticated alignment task than the audio-visual correspondence (AVC). In addition to the correspondence, AVSA also learns from the spatial location of acoustic and visual content. Based on 360$^\\text{o}$ video and Ambisonics audio, we propose selection of visual objects using object detection, and beamforming of the audio signal towards the detected objects, attempting to learn the spatial alignment between objects and the sound they produce. We investigate the use of spatial audio features to represent the audio input, and different audio formats: Ambisonics, mono, and stereo. Experimental results show a 10 $\\%$ improvement on AVSA for the first order ambisonics intensity vector (FOA-IV) in comparison with log-mel spectrogram features; the addition of object-oriented crops also brings significant performance increases for the human action recognition downstream task. A number of audio-only downstream tasks are devised for testing the effectiveness of the learnt audio feature representation, obtaining performance comparable to state-of-the-art methods on acoustic scene classification from ambisonic and binaural audio. ",
    "url": "https://arxiv.org/abs/2206.00970",
    "authors": [
      "Shanshan Wang",
      "Archontis Politis",
      "Annamaria Mesaros",
      "Tuomas Virtanen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2206.01059",
    "title": "Recognizing the Commuting Graph of a Finite Group",
    "abstract": "In this paper we study the realizability question for commuting graphs of finite groups: Given an undirected graph $X$ is it the commuting graph of a group $G$? And if so, to determine such a group. We seek efficient algorithms for this problem. We make some general observations on this problem, and obtain a polynomial-time algorithm for the case of extraspecial groups. ",
    "url": "https://arxiv.org/abs/2206.01059",
    "authors": [
      "V. Arvind",
      "Peter. J. Cameron"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2206.01068",
    "title": "Min orderings and list homomorphism dichotomies for signed and unsigned  graphs",
    "abstract": "The CSP dichotomy conjecture has been recently established, but a number of other dichotomy questions remain open, including the dichotomy classification of list homomorphism problems for signed graphs. Signed graphs arise naturally in many contexts, including for instance nowhere-zero flows for graphs embedded in non-orientable surfaces. For a fixed signed graph $\\widehat{H}$, the list homomorphism problem asks whether an input signed graph $\\widehat{G}$ with lists $L(v) \\subseteq V(\\widehat{H}), v \\in V(\\widehat{G}),$ admits a homomorphism $f$ to $\\widehat{H}$ with all $f(v) \\in L(v), v \\in V(\\widehat{G})$. Usually, a dichotomy classification is easier to obtain for list homomorphisms than for homomorphisms, but in the context of signed graphs a structural classification of the complexity of list homomorphism problems has not even been conjectured, even though the classification of the complexity of homomorphism problems is known. Kim and Siggers have conjectured a structural classification in the special case of \"weakly balanced\" signed graphs, and proved it for reflexive signed graphs. We confirm the conjecture for irreflexive signed graphs; this generalizes previous results on weakly balanced signed trees, and weakly balanced separable signed graphs. Our proof depends on first deriving a new result on extensions of min orderings of (unsigned) bipartite graphs. ",
    "url": "https://arxiv.org/abs/2206.01068",
    "authors": [
      "Jan Bok",
      "Richard Brewster",
      "Pavol Hell",
      "Nikola Jedli\u010dkov\u00e1",
      "Arash Rafiey"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2206.01088",
    "title": "Machine Learning-based Lung and Colon Cancer Detection using Deep  Feature Extraction and Ensemble Learning",
    "abstract": "Cancer is a fatal disease caused by a combination of genetic diseases and a variety of biochemical abnormalities. Lung and colon cancer have emerged as two of the leading causes of death and disability in humans. The histopathological detection of such malignancies is usually the most important component in determining the best course of action. Early detection of the ailment on either front considerably decreases the likelihood of mortality. Machine learning and deep learning techniques can be utilized to speed up such cancer detection, allowing researchers to study a large number of patients in a much shorter amount of time and at a lower cost. In this research work, we introduced a hybrid ensemble feature extraction model to efficiently identify lung and colon cancer. It integrates deep feature extraction and ensemble learning with high-performance filtering for cancer image datasets. The model is evaluated on histopathological (LC25000) lung and colon datasets. According to the study findings, our hybrid model can detect lung, colon, and (lung and colon) cancer with accuracy rates of 99.05%, 100%, and 99.30%, respectively. The study's findings show that our proposed strategy outperforms existing models significantly. Thus, these models could be applicable in clinics to support the doctor in the diagnosis of cancers. ",
    "url": "https://arxiv.org/abs/2206.01088",
    "authors": [
      "Md. Alamin Talukder",
      "Md. Manowarul Islam",
      "Md Ashraf Uddin",
      "Arnisha Akhter",
      "Khondokar Fida Hasan",
      "Mohammad Ali Moni"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.01152",
    "title": "Causal Structure Learning: a Combinatorial Perspective",
    "abstract": "In this review, we discuss approaches for learning causal structure from data, also called causal discovery. In particular, we focus on approaches for learning directed acyclic graphs (DAGs) and various generalizations which allow for some variables to be unobserved in the available data. We devote special attention to two fundamental combinatorial aspects of causal structure learning. First, we discuss the structure of the search space over causal graphs. Second, we discuss the structure of equivalence classes over causal graphs, i.e., sets of graphs which represent what can be learned from observational data alone, and how these equivalence classes can be refined by adding interventional data. ",
    "url": "https://arxiv.org/abs/2206.01152",
    "authors": [
      "Chandler Squires",
      "Caroline Uhler"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.01163",
    "title": "Invertible Neural Networks for Graph Prediction",
    "abstract": "In this work, we address conditional generation using deep invertible neural networks. This is a type of problem where one aims to infer the most probable inputs $X$ given outcomes $Y$. We call our method \\textit{invertible graph neural network} (iGNN) due to the primary focus on generating node features on graph data. A notable feature of our proposed methods is that during network training, we revise the typically-used loss objective in normalizing flow and consider Wasserstein-2 regularization to facilitate the training process. Algorithmic-wise, we adopt an end-to-end training approach since our objective is to address prediction and generation in the forward and backward processes at once through a single model. Theoretically, we characterize the conditions for identifiability of a true mapping, the existence and invertibility of the mapping, and the expressiveness of iGNN in learning the mapping. Experimentally, we verify the performance of iGNN on both simulated and real-data datasets. We demonstrate through extensive numerical experiments that iGNN shows clear improvement over competing conditional generation benchmarks on high-dimensional and/or non-convex data. ",
    "url": "https://arxiv.org/abs/2206.01163",
    "authors": [
      "Chen Xu",
      "Xiuyuan Cheng",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.01164",
    "title": "Authentication of quantum key distribution with post-quantum  cryptography and replay attacks",
    "abstract": "With the development of quantum computers, traditional cryptographic systems are facing more and more serious security threats. Fortunately, quantum key distribution (QKD) and post-quantum cryptography (PQC) are two cryptographic mechanisms with quantum-resistant security, and both will become important solutions for future information security. However, neither of them is perfect, and they are complementary. Quantum key distribution has unconditional security that post-quantum cryptography does not have, and PQC can provide secure and convenient authentication for QKD networks. In this paper, we propose two protocols based on PQC to realize the full authentication of the QKD data post-processing, and we only need to assume the short-term security of PQC algorithm to ensure the long-term quantum resistant security of distributed keys. We found that for the above two authentication protocols, attackers cannot successfully implement replay attacks. These authentication protocols can solve the problems of the current pre-shared key authentication in the application of large-scale quantum key distribution networks, and are expected to realize a key distribution mechanism with practical operability and quantum resistant security, which will be beneficial to promote the deployment and application of quantum key distribution networks. ",
    "url": "https://arxiv.org/abs/2206.01164",
    "authors": [
      "Liu-Jun Wang",
      "You-Yang Zhou",
      "Jian-Ming Yin",
      "Qing Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:1810.09177",
    "title": "Compositional Coding Capsule Network with K-Means Routing for Text  Classification",
    "abstract": " Comments: the paper is accepted by Pattern Recognition Letters, please refer this https URL for an updated version ",
    "url": "https://arxiv.org/abs/1810.09177",
    "authors": [
      "Hao Ren",
      "Hong Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2009.01367",
    "title": "Bridging the Gap: Unifying the Training and Evaluation of Neural Network  Binary Classifiers",
    "abstract": " Title: Bridging the Gap: Unifying the Training and Evaluation of Neural Network  Binary Classifiers ",
    "url": "https://arxiv.org/abs/2009.01367",
    "authors": [
      "Nathan Tsoi",
      "Kate Candon",
      "Deyuan Li",
      "Yofti Milkessa",
      "Marynel V\u00e1zquez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2101.05151",
    "title": "Temporal Knowledge Graph Forecasting with Neural ODE",
    "abstract": " Comments: accepted at EMNLP 2021 ",
    "url": "https://arxiv.org/abs/2101.05151",
    "authors": [
      "Zhen Han",
      "Zifeng Ding",
      "Yunpu Ma",
      "Yujia Gu",
      "Volker Tresp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2101.07413",
    "title": "Dynamic Privacy Budget Allocation Improves Data Efficiency of  Differentially Private Gradient Descent",
    "abstract": " Comments: Accepted to FAccT'22 ",
    "url": "https://arxiv.org/abs/2101.07413",
    "authors": [
      "Junyuan Hong",
      "Zhangyang Wang",
      "Jiayu Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2104.07719",
    "title": "Meta Faster R-CNN: Towards Accurate Few-Shot Object Detection with  Attentive Feature Alignment",
    "abstract": " Comments: AAAI 2022 (Oral). Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2104.07719",
    "authors": [
      "Guangxing Han",
      "Shiyuan Huang",
      "Jiawei Ma",
      "Yicheng He",
      "Shih-Fu Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2105.13015",
    "title": "A recursive representation for decoupling time-state dependent jumps  from jump-diffusion processes",
    "abstract": " Comments: 21 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2105.13015",
    "authors": [
      "Qinjing Qiu",
      "Reiichiro Kawai"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2106.08171",
    "title": "Evaluating Modules in Graph Contrastive Learning",
    "abstract": " Title: Evaluating Modules in Graph Contrastive Learning ",
    "url": "https://arxiv.org/abs/2106.08171",
    "authors": [
      "Ganqu Cui",
      "Yufeng Du",
      "Cheng Yang",
      "Jie Zhou",
      "Liang Xu",
      "Xing Zhou",
      "Xingyi Cheng",
      "Zhiyuan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.08928",
    "title": "RNNs of RNNs: Recursive Construction of Stable Assemblies of Recurrent  Neural Networks",
    "abstract": " Title: RNNs of RNNs: Recursive Construction of Stable Assemblies of Recurrent  Neural Networks ",
    "url": "https://arxiv.org/abs/2106.08928",
    "authors": [
      "Leo Kozachkov",
      "Michaela Ennis",
      "Jean-Jacques Slotine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2106.09517",
    "title": "Dynamic Knowledge Distillation With Noise Elimination for RGB-D Salient  Object Detection",
    "abstract": " Title: Dynamic Knowledge Distillation With Noise Elimination for RGB-D Salient  Object Detection ",
    "url": "https://arxiv.org/abs/2106.09517",
    "authors": [
      "Guangyu Ren",
      "Yinxiao Yu",
      "Hengyan Liu",
      "Tania Stathaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.11299",
    "title": "Boundary Graph Neural Networks for 3D Simulations",
    "abstract": " Title: Boundary Graph Neural Networks for 3D Simulations ",
    "url": "https://arxiv.org/abs/2106.11299",
    "authors": [
      "Andreas Mayr",
      "Sebastian Lehner",
      "Arno Mayrhofer",
      "Christoph Kloss",
      "Sepp Hochreiter",
      "Johannes Brandstetter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.15910",
    "title": "Graph Signal Restoration Using Nested Deep Algorithm Unrolling",
    "abstract": " Title: Graph Signal Restoration Using Nested Deep Algorithm Unrolling ",
    "url": "https://arxiv.org/abs/2106.15910",
    "authors": [
      "Masatoshi Nagahama",
      "Koki Yamada",
      "Yuichi Tanaka",
      "Stanley H. Chan",
      "Yonina C. Eldar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.12838",
    "title": "Graph Autoencoders for Embedding Learning in Brain Networks and Major  Depressive Disorder Identification",
    "abstract": " Title: Graph Autoencoders for Embedding Learning in Brain Networks and Major  Depressive Disorder Identification ",
    "url": "https://arxiv.org/abs/2107.12838",
    "authors": [
      "Fuad Noman",
      "Chee-Ming Ting",
      "Hakmook Kang",
      "Raphael C.-W. Phan",
      "Brian D. Boyd",
      "Warren D. Taylor",
      "Hernando Ombao"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.14126",
    "title": "The Complexity of Growing a Graph",
    "abstract": " Comments: 27 pages ",
    "url": "https://arxiv.org/abs/2107.14126",
    "authors": [
      "George B. Mertzios",
      "Othon Michail",
      "George Skretas",
      "Paul G. Spirakis",
      "Michail Theofilatos"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2109.00389",
    "title": "Optimization problems in graphs with locational uncertainty",
    "abstract": " Title: Optimization problems in graphs with locational uncertainty ",
    "url": "https://arxiv.org/abs/2109.00389",
    "authors": [
      "Marin Bougeret",
      "J\u00e9r\u00e9my Omer",
      "Michael Poss"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2109.04566",
    "title": "SanitAIs: Unsupervised Data Augmentation to Sanitize Trojaned Neural  Networks",
    "abstract": " Comments: 7 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2109.04566",
    "authors": [
      "Kiran Karra",
      "Chace Ashcraft",
      "Cash Costello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.02027",
    "title": "ProGCL: Rethinking Hard Negative Mining in Graph Contrastive Learning",
    "abstract": " Comments: Accetpted at ICML 2022 ",
    "url": "https://arxiv.org/abs/2110.02027",
    "authors": [
      "Jun Xia",
      "Lirong Wu",
      "Ge Wang",
      "Jintao Chen",
      "Stan Z.Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.02711",
    "title": "DiffusionCLIP: Text-Guided Diffusion Models for Robust Image  Manipulation",
    "abstract": " Comments: Accepted to CVPR 2022 ",
    "url": "https://arxiv.org/abs/2110.02711",
    "authors": [
      "Gwanghyun Kim",
      "Taesung Kwon",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.03605",
    "title": "Robust Feature-Level Adversaries are Interpretability Tools",
    "abstract": " Comments: Code available at this https URL ",
    "url": "https://arxiv.org/abs/2110.03605",
    "authors": [
      "Stephen Casper",
      "Max Nadeau",
      "Dylan Hadfield-Menell",
      "Gabriel Kreiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.04079",
    "title": "A Hybrid Spatial-temporal Deep Learning Architecture for Lane Detection",
    "abstract": " Comments: 18 pages, 5 figures. Published by Computer-Aided Civil and Infrastructure Engineering (CACIE). Open access from this https URL ",
    "url": "https://arxiv.org/abs/2110.04079",
    "authors": [
      "Yongqi Dong",
      "Sandeep Patil",
      "Bart van Arem",
      "Haneen Farah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2110.11524",
    "title": "Sequential Voting with Relational Box Fields for Active Object Detection",
    "abstract": " Comments: In CVPR 2022. Project: this https URL ",
    "url": "https://arxiv.org/abs/2110.11524",
    "authors": [
      "Qichen Fu",
      "Xingyu Liu",
      "Kris M. Kitani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.00898",
    "title": "Availability Attacks Create Shortcuts",
    "abstract": " Comments: Published as a research track paper at KDD 2022 ",
    "url": "https://arxiv.org/abs/2111.00898",
    "authors": [
      "Da Yu",
      "Huishuai Zhang",
      "Wei Chen",
      "Jian Yin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2111.07845",
    "title": "Metric dimension on sparse graphs and its applications to zero forcing  sets",
    "abstract": " Title: Metric dimension on sparse graphs and its applications to zero forcing  sets ",
    "url": "https://arxiv.org/abs/2111.07845",
    "authors": [
      "Nicolas Bousquet",
      "Quentin Deschamps",
      "Aline Parreau",
      "Ignacio M. Pelayo"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2112.05141",
    "title": "Exploring the Equivalence of Siamese Self-Supervised Learning via A  Unified Gradient Framework",
    "abstract": " Comments: CVPR2022 ",
    "url": "https://arxiv.org/abs/2112.05141",
    "authors": [
      "Chenxin Tao",
      "Honghui Wang",
      "Xizhou Zhu",
      "Jiahua Dong",
      "Shiji Song",
      "Gao Huang",
      "Jifeng Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.15577",
    "title": "How Infinitely Wide Neural Networks Benefit from Multi-task Learning --  an Exact Macroscopic Characterization",
    "abstract": " Comments: 9 pages + appendix ",
    "url": "https://arxiv.org/abs/2112.15577",
    "authors": [
      "Jakob Heiss",
      "Josef Teichmann",
      "Hanna Wutte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.06446",
    "title": "Privacy-Preserving Maximum Matching on General Graphs and its  Application to Enable Privacy-Preserving Kidney Exchange",
    "abstract": " Comments: This is the extended version of the paper that appeared in the 12th ACM Conference on Data and Application Security and Privacy (CODASPY'22), April 24-26, 2022, Baltimore-Washington DC Area, United States, this https URL ",
    "url": "https://arxiv.org/abs/2201.06446",
    "authors": [
      "Malte Breuer",
      "Ulrike Meyer",
      "Susanne Wetzel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.08418",
    "title": "SoftDropConnect (SDC) -- Effective and Efficient Quantification of the  Network Uncertainty in Deep MR Image Analysis",
    "abstract": " Title: SoftDropConnect (SDC) -- Effective and Efficient Quantification of the  Network Uncertainty in Deep MR Image Analysis ",
    "url": "https://arxiv.org/abs/2201.08418",
    "authors": [
      "Qing Lyu",
      "Christopher T. Whitlow",
      "Ge Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2201.11300",
    "title": "Geo-obfuscation Mechanisms for Spatial Crowdsourcing via Multi-Objective  Evolutionary Optimization",
    "abstract": " Title: Geo-obfuscation Mechanisms for Spatial Crowdsourcing via Multi-Objective  Evolutionary Optimization ",
    "url": "https://arxiv.org/abs/2201.11300",
    "authors": [
      "Shun Zhang",
      "Tao Zhang",
      "Zhili Chen",
      "Stan Z. Li",
      "Shenghui Cheng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.00293",
    "title": "Phase diagram of Stochastic Gradient Descent in high-dimensional  two-layer neural networks",
    "abstract": " Comments: 27 pages ",
    "url": "https://arxiv.org/abs/2202.00293",
    "authors": [
      "Rodrigo Veiga",
      "Ludovic Stephan",
      "Bruno Loureiro",
      "Florent Krzakala",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02110",
    "title": "New Inner and Outer Bounds for Gaussian Broadcast Channels with  Heterogeneous Blocklength Constraints",
    "abstract": " Comments: 4 Figures ",
    "url": "https://arxiv.org/abs/2202.02110",
    "authors": [
      "Marcel Mross",
      "Pin-Hsun Lin",
      "Eduard A. Jorswieck"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.02989",
    "title": "Graph Self-supervised Learning with Accurate Discrepancy Learning",
    "abstract": " Comments: 9 pages ",
    "url": "https://arxiv.org/abs/2202.02989",
    "authors": [
      "Dongki Kim",
      "Jinheon Baek",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.13884",
    "title": "Numeric Lyndon-based feature embedding of sequencing reads for machine  learning approaches",
    "abstract": " Title: Numeric Lyndon-based feature embedding of sequencing reads for machine  learning approaches ",
    "url": "https://arxiv.org/abs/2202.13884",
    "authors": [
      "Paola Bonizzoni",
      "Matteo Costantini",
      "Clelia De Felice",
      "Alessia Petescia",
      "Yuri Pirola",
      "Marco Previtali",
      "Raffaella Rizzi",
      "Jens Stoye",
      "Rocco Zaccagnino",
      "Rosalba Zizza"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09210",
    "title": "Universal Conditional Masked Language Pre-training for Neural Machine  Translation",
    "abstract": " Comments: Accepted to ACL 2022 Main conference ",
    "url": "https://arxiv.org/abs/2203.09210",
    "authors": [
      "Pengfei Li",
      "Liangyou Li",
      "Meng Zhang",
      "Minghao Wu",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.13262",
    "title": "Interpretability of Neural Network With Physiological Mechanisms",
    "abstract": " Comments: Updated a new version ",
    "url": "https://arxiv.org/abs/2203.13262",
    "authors": [
      "Anna Zou",
      "Zhiyuan Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2205.03960",
    "title": "$\u03b1$NAS: Neural Architecture Search using Property Guided Synthesis",
    "abstract": " Comments: Our code is available at this https URL ",
    "url": "https://arxiv.org/abs/2205.03960",
    "authors": [
      "Charles Jin",
      "Phitchaya Mangpo Phothilimthana",
      "Sudip Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2205.04774",
    "title": "Automorphism Shuffles for Graphs and Hypergraphs and Its Applications",
    "abstract": " Comments: 12 pages ",
    "url": "https://arxiv.org/abs/2205.04774",
    "authors": [
      "Kazumasa Shinagawa",
      "Kengo Miyamoto"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.07890",
    "title": "On the Difficulty of Defending Self-Supervised Learning against Model  Extraction",
    "abstract": " Comments: Accepted at ICML 2022 ",
    "url": "https://arxiv.org/abs/2205.07890",
    "authors": [
      "Adam Dziedzic",
      "Nikita Dhawan",
      "Muhammad Ahmad Kaleem",
      "Jonas Guan",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.13219",
    "title": "Penalizing Proposals using Classifiers for Semi-Supervised Object  Detection",
    "abstract": " Comments: The paper is under consideration at Computer Vision and Image Understanding ",
    "url": "https://arxiv.org/abs/2205.13219",
    "authors": [
      "Somnath Hazra",
      "Pallab Dasgupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14118",
    "title": "Efficient textual explanations for complex road and traffic scenarios  based on semantic segmentation",
    "abstract": " Title: Efficient textual explanations for complex road and traffic scenarios  based on semantic segmentation ",
    "url": "https://arxiv.org/abs/2205.14118",
    "authors": [
      "Yiyue Zhao",
      "Xinyu Yun",
      "Chen Chai",
      "Zhiyu Liu",
      "Wenxuan Fan",
      "Xiao Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.15747",
    "title": "Adversarial synthesis based data-augmentation for code-switched spoken  language identification",
    "abstract": " Comments: 9 pages, 8 figures, updated ",
    "url": "https://arxiv.org/abs/2205.15747",
    "authors": [
      "Parth Shastri",
      "Chirag Patil",
      "Poorval Wanere",
      "Dr. Shrinivas Mahajan",
      "Dr. Abhishek Bhatt",
      "Dr. Hardik Sailor"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00252",
    "title": "Interpretable Deep Learning Classifier by Detection of Prototypical  Parts on Kidney Stones Images",
    "abstract": " Comments: Extended abstract accepted at LatinX in Computer Vision Research Workshop, at CVPR 2022 ",
    "url": "https://arxiv.org/abs/2206.00252",
    "authors": [
      "Daniel Flores-Araiza",
      "Francisco Lopez-Tiro",
      "Elias Villalvazo-Avila",
      "Jonathan El-Beze",
      "Jacques Hubert",
      "Gilberto Ochoa-Ruiz",
      "Christian Daul"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00381",
    "title": "The statistical nature of h-index of a network node",
    "abstract": " Title: The statistical nature of h-index of a network node ",
    "url": "https://arxiv.org/abs/2206.00381",
    "authors": [
      "Yan Liu",
      "Mudi Jiang",
      "Lianyu Hu",
      "Zengyou He"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2206.00535",
    "title": "Deepfake Caricatures: Amplifying attention to artifacts increases  deepfake detection by humans and machines",
    "abstract": " Comments: 9 pages, 5 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2206.00535",
    "authors": [
      "Camilo Fosco",
      "Emilie Josephs",
      "Alex Andonian",
      "Allen Lee",
      "Xi Wang",
      "Aude Oliva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ]
  }
]