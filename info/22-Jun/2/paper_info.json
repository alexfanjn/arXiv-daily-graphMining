[
  {
    "id": "arXiv:2206.00005",
    "title": "Are classical neural networks quantum?",
    "abstract": "Neural networks are being used to improve the probing of the state spaces of many particle systems as approximations to wavefunctions and in order to avoid the recurring sign problem of quantum monte-carlo. One may ask whether the usual classical neural networks have some actual hidden quantum properties that make them such suitable tools for a highly coupled quantum problem. I discuss here what makes a system quantum and to what extent we can interpret a neural network as having quantum remnants. ",
    "url": "https://arxiv.org/abs/2206.00005",
    "authors": [
      "Andrei T. Patrascu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "High Energy Physics - Theory (hep-th)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2206.00006",
    "title": "COIN: Co-Cluster Infomax for Bipartite Graphs",
    "abstract": "Bipartite graphs are powerful data structures to model interactions between two types of nodes, which have been used in a variety of applications, such as recommender systems, information retrieval, and drug discovery. A fundamental challenge for bipartite graphs is how to learn informative node embeddings. Despite the success of recent self-supervised learning methods on bipartite graphs, their objectives are discriminating instance-wise positive and negative node pairs, which could contain cluster-level errors. In this paper, we introduce a novel co-cluster infomax (COIN) framework, which captures the cluster-level information by maximizing the mutual information of co-clusters. Different from previous infomax methods which estimate mutual information by neural networks, COIN could easily calculate mutual information. Besides, COIN is an end-to-end co-clustering method which can be trained jointly with other objective functions and optimized via back-propagation. Furthermore, we also provide theoretical analysis for COIN. We theoretically prove that COIN is able to effectively maximize the mutual information of node embeddings and COIN is upper-bounded by the prior distributions of nodes. We extensively evaluate the proposed COIN framework on various benchmark datasets and tasks to demonstrate the effectiveness of COIN. ",
    "url": "https://arxiv.org/abs/2206.00006",
    "authors": [
      "Baoyu Jing",
      "Yuchen Yan",
      "Yada Zhu",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.00026",
    "title": "Network Cards: concise, readable summaries of network data",
    "abstract": "The deluge of network datasets demands a standard way to effectively and succinctly summarize network datasets. Building on similar efforts to standardize the documentation of models and datasets in machine learning, here we propose *network cards*, short summaries of network datasets that can capture not only the basic statistics of the network but also information about the data construction process, provenance, ethical considerations, and other metadata. In this paper, we lay out (i) the rationales and objectives for network cards, (ii) key elements that should be included in network cards, and (iii) example network cards to underscore their benefits across a variety of research domains. We also provide a schema, templates, and a software package for generating network cards. ",
    "url": "https://arxiv.org/abs/2206.00026",
    "authors": [
      "James Bagrow",
      "Yong-Yeol Ahn"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2206.00035",
    "title": "Weaving Privacy and Power: On the Privacy Practices of Labor Organizers  in the U.S. Technology Industry",
    "abstract": "We investigate the privacy practices of labor organizers in the computing technology industry and explore the changes in these practices as a response to remote work. Our study is situated at the intersection of two pivotal shifts in workplace dynamics: (a) the increase in online workplace communications due to remote work, and (b) the resurgence of the labor movement and an increase in collective action in workplaces -- especially in the tech industry, where this phenomenon has been dubbed the tech worker movement. Through a series of qualitative interviews with 29 tech workers involved in collective action, we investigate how labor organizers assess and mitigate risks to privacy while engaging in these actions. Among the most common risks that organizers experienced are retaliation from their employer, lateral worker conflict, emotional burnout, and the possibility of information about the collective effort leaking to management. Depending on the nature and source of the risk, organizers use a blend of digital security practices and community-based mechanisms. We find that digital security practices are more relevant when the threat comes from management, while community management and moderation are central to protecting organizers from lateral worker conflict. Since labor organizing is a collective rather than individual project, individual privacy and collective privacy are intertwined, sometimes in conflict and often mutually constitutive. Notions of privacy that solely center individuals are often incompatible with the needs of organizers, who noted that safety in numbers could only be achieved when workers presented a united front to management. We conclude with design recommendations that can help create safer, more secure and more private tools to better address the risks that organizers face. ",
    "url": "https://arxiv.org/abs/2206.00035",
    "authors": [
      "Sayash Kapoor",
      "Matthew Sun",
      "Mona Wang",
      "Klaudia Ja\u017awi\u0144ska",
      "Elizabeth Anne Watkins"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2206.00052",
    "title": "CodeAttack: Code-based Adversarial Attacks for Pre-Trained Programming  Language Models",
    "abstract": "Pre-trained programming language (PL) models (such as CodeT5, CodeBERT, GraphCodeBERT, etc.,) have the potential to automate software engineering tasks involving code understanding and code generation. However, these models are not robust to changes in the input and thus, are potentially susceptible to adversarial attacks. We propose, CodeAttack, a simple yet effective black-box attack model that uses code structure to generate imperceptible, effective, and minimally perturbed adversarial code samples. We demonstrate the vulnerabilities of the state-of-the-art PL models to code-specific adversarial attacks. We evaluate the transferability of CodeAttack on several code-code (translation and repair) and code-NL (summarization) tasks across different programming languages. CodeAttack outperforms state-of-the-art adversarial NLP attack models to achieve the best overall performance while being more efficient and imperceptible. ",
    "url": "https://arxiv.org/abs/2206.00052",
    "authors": [
      "Akshita Jha",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.00057",
    "title": "Distributed Graph Neural Network Training with Periodic Historical  Embedding Synchronization",
    "abstract": "Despite the recent success of Graph Neural Networks (GNNs), it remains challenging to train a GNN on large graphs, which are prevalent in various applications such as social network, recommender systems, and knowledge graphs. Traditional sampling-based methods accelerate GNN by dropping edges and nodes, which impairs the graph integrity and model performance. Differently, distributed GNN algorithms, which accelerate GNN training by utilizing multiple computing devices, can be classified into two types: \"partition-based\" methods enjoy low communication costs but suffer from information loss due to dropped edges, while \"propagation-based\" methods avoid information loss but suffer prohibitive communication overhead. To jointly address these problems, this paper proposes DIstributed Graph Embedding SynchronizaTion (DIGEST), a novel distributed GNN training framework that synergizes the complementary strength of both categories of existing methods. During subgraph parallel training, we propose to let each device store the historical embedding of its neighbors in other subgraphs. Therefore, our method does not discard any neighbors in other subgraphs, nor does it updates them intensively. This effectively avoids (1) the intensive computation on explosively-increasing neighbors and (2) excessive communications across different devices. We proved that the approximation error induced by the staleness of historical embedding can be upper bounded and it does NOT affect the GNN model's expressiveness. More importantly, our convergence analysis demonstrates that DIGEST enjoys a state-of-the-art convergence rate. Extensive experimental evaluation on large, real-world graph datasets shows that DIGEST achieves up to $21.82\\times$ speedup without compromising the performance compared to state-of-the-art distributed GNN training frameworks. ",
    "url": "https://arxiv.org/abs/2206.00057",
    "authors": [
      "Zheng Chai",
      "Guangji Bai",
      "Liang Zhao",
      "Yue Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2206.00065",
    "title": "FELARE: Fair Scheduling of Machine Learning Applications on  Heterogeneous Edge Systems",
    "abstract": "Edge computing enables smart IoT-based systems via concurrent and continuous execution of latency-sensitive machine learning (ML) applications. These edge-based machine learning systems are often battery-powered (i.e., energy-limited). They use heterogeneous resources with diverse computing performance (e.g., CPU, GPU, and/or FPGAs) to fulfill the latency constraints of ML applications. The challenge is to allocate user requests for different ML applications on the Heterogeneous Edge Computing Systems (HEC) with respect to both the energy and latency constraints of these systems. To this end, we study and analyze resource allocation solutions that can increase the on-time task completion rate while considering the energy constraint. Importantly, we investigate edge-friendly (lightweight) multi-objective mapping heuristics that do not become biased toward a particular application type to achieve the objectives; instead, the heuristics consider \"fairness\" across the concurrent ML applications in their mapping decisions. Performance evaluations demonstrate that the proposed heuristic outperforms widely-used heuristics in heterogeneous systems in terms of the latency and energy objectives, particularly, at low to moderate request arrival rates. We observed 8.9% improvement in on-time task completion rate and 12.6% in energy-saving without imposing any significant overhead on the edge system. ",
    "url": "https://arxiv.org/abs/2206.00065",
    "authors": [
      "Ali Mokhtari",
      "Pooyan Jamshidi",
      "Mohsen Amini Salehi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2206.00071",
    "title": "Generative Models with Information-Theoretic Protection Against  Membership Inference Attacks",
    "abstract": "Deep generative models, such as Generative Adversarial Networks (GANs), synthesize diverse high-fidelity data samples by estimating the underlying distribution of high dimensional data. Despite their success, GANs may disclose private information from the data they are trained on, making them susceptible to adversarial attacks such as membership inference attacks, in which an adversary aims to determine if a record was part of the training set. We propose an information theoretically motivated regularization term that prevents the generative model from overfitting to training data and encourages generalizability. We show that this penalty minimizes the JensenShannon divergence between components of the generator trained on data with different membership, and that it can be implemented at low cost using an additional classifier. Our experiments on image datasets demonstrate that with the proposed regularization, which comes at only a small added computational cost, GANs are able to preserve privacy and generate high-quality samples that achieve better downstream classification performance compared to non-private and differentially private generative models. ",
    "url": "https://arxiv.org/abs/2206.00071",
    "authors": [
      "Parisa Hassanzadeh",
      "Robert E. Tillman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.00097",
    "title": "Real-time motion planning and decision-making for a group of  differential drive robots under connectivity constraints using robust MPC and  mixed-integer programming",
    "abstract": "This work is concerned with the problem of planning trajectories and assigning tasks for a Multi-Agent System (MAS) comprised of differential drive robots. We propose a multirate hierarchical control structure that employs a planner based on robust Model Predictive Control (MPC) with mixed-integer programming (MIP) encoding. The planner computes trajectories and assigns tasks for each element of the group in real-time, while also guaranteeing the communication network of the MAS to be robustly connected at all times. Additionally, we provide a data-based methodology to estimate the disturbances sets required by the robust MPC formulation. The results are demonstrated with experiments in two obstacle-filled scenarios ",
    "url": "https://arxiv.org/abs/2206.00097",
    "authors": [
      "Angelo Caregnato-Neto",
      "Marcos Ricardo Omena de Albuquerque Maximo",
      "Rubens Junqueira Magalh\u00e3es Afonso"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.00101",
    "title": "MAD-EN: Microarchitectural Attack Detection through System-wide Energy  Consumption",
    "abstract": "Microarchitectural attacks have become more threatening the hardware security than before with the increasing diversity of attacks such as Spectre and Meltdown. Vendor patches cannot keep up with the pace of the new threats, which makes the dynamic anomaly detection tools more evident than before. Unfortunately, previous studies utilize hardware performance counters that lead to high performance overhead and profile limited number of microarchitectural attacks due to the small number of counters that can be profiled concurrently. This yields those detection tools inefficient in real-world scenarios. In this study, we introduce MAD-EN dynamic detection tool that leverages system-wide energy consumption traces collected from a generic Intel RAPL tool to detect ongoing anomalies in a system. In our experiments, we show that CNN-based MAD-EN can detect 10 different microarchitectural attacks with a total of 15 variants with the highest F1 score of 0.999, which makes our tool the most generic attack detection tool so far. Moreover, individual attacks can be distinguished with a 98% accuracy after an anomaly is detected in a system. We demonstrate that MAD-EN introduces 69.3% less performance overhead compared to performance counter-based detection mechanisms. ",
    "url": "https://arxiv.org/abs/2206.00101",
    "authors": [
      "Debopriya Roy Dipta",
      "Berk Gulmezoglu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00118",
    "title": "Principle of Relevant Information for Graph Sparsification",
    "abstract": "Graph sparsification aims to reduce the number of edges of a graph while maintaining its structural properties. In this paper, we propose the first general and effective information-theoretic formulation of graph sparsification, by taking inspiration from the Principle of Relevant Information (PRI). To this end, we extend the PRI from a standard scalar random variable setting to structured data (i.e., graphs). Our Graph-PRI objective is achieved by operating on the graph Laplacian, made possible by expressing the graph Laplacian of a subgraph in terms of a sparse edge selection vector $\\mathbf{w}$. We provide both theoretical and empirical justifications on the validity of our Graph-PRI approach. We also analyze its analytical solutions in a few special cases. We finally present three representative real-world applications, namely graph sparsification, graph regularized multi-task learning, and medical imaging-derived brain network classification, to demonstrate the effectiveness, the versatility and the enhanced interpretability of our approach over prevalent sparsification techniques. Code of Graph-PRI is available at https://github.com/SJYuCNEL/PRI-Graphs ",
    "url": "https://arxiv.org/abs/2206.00118",
    "authors": [
      "Shujian Yu",
      "Francesco Alesiani",
      "Wenzhe Yin",
      "Robert Jenssen",
      "Jose C. Principe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2206.00123",
    "title": "Glo-In-One: Holistic Glomerular Detection, Segmentation, and Lesion  Characterization with Large-scale Web Image Mining",
    "abstract": "The quantitative detection, segmentation, and characterization of glomeruli from high-resolution whole slide imaging (WSI) play essential roles in the computer-assisted diagnosis and scientific research in digital renal pathology. Historically, such comprehensive quantification requires extensive programming skills in order to be able to handle heterogeneous and customized computational tools. To bridge the gap of performing glomerular quantification for non-technical users, we develop the Glo-In-One toolkit to achieve holistic glomerular detection, segmentation, and characterization via a single line of command. Additionally, we release a large-scale collection of 30,000 unlabeled glomerular images to further facilitate the algorithmic development of self-supervised deep learning. The inputs of the Glo-In-One toolkit are WSIs, while the outputs are (1) WSI-level multi-class circle glomerular detection results (which can be directly manipulated with ImageScope), (2) glomerular image patches with segmentation masks, and (3) different lesion types. To leverage the performance of the Glo-In-One toolkit, we introduce self-supervised deep learning to glomerular quantification via large-scale web image mining. The GGS fine-grained classification model achieved a decent performance compared with baseline supervised methods while only using 10% of the annotated data. The glomerular detection achieved an average precision of 0.627 with circle representations, while the glomerular segmentation achieved a 0.955 patch-wise Dice Similarity Coefficient (DSC). ",
    "url": "https://arxiv.org/abs/2206.00123",
    "authors": [
      "Tianyuan Yao",
      "Yuzhe Lu",
      "Jun Long",
      "Aadarsh Jha",
      "Zheyu Zhu",
      "Zuhayr Asad",
      "Haichun Yang",
      "Agnes B. Fogo",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00133",
    "title": "Pre-training via Denoising for Molecular Property Prediction",
    "abstract": "Many important problems involving molecular property prediction from 3D structures have limited data, posing a generalization challenge for neural networks. In this paper, we describe a pre-training technique that utilizes large datasets of 3D molecular structures at equilibrium to learn meaningful representations for downstream tasks. Inspired by recent advances in noise regularization, our pre-training objective is based on denoising. Relying on the well-known link between denoising autoencoders and score-matching, we also show that the objective corresponds to learning a molecular force field -- arising from approximating the physical state distribution with a mixture of Gaussians -- directly from equilibrium structures. Our experiments demonstrate that using this pre-training objective significantly improves performance on multiple benchmarks, achieving a new state-of-the-art on the majority of targets in the widely used QM9 dataset. Our analysis then provides practical insights into the effects of different factors -- dataset sizes, model size and architecture, and the choice of upstream and downstream datasets -- on pre-training. ",
    "url": "https://arxiv.org/abs/2206.00133",
    "authors": [
      "Sheheryar Zaidi",
      "Michael Schaarschmidt",
      "James Martens",
      "Hyunjik Kim",
      "Yee Whye Teh",
      "Alvaro Sanchez-Gonzalez",
      "Peter Battaglia",
      "Razvan Pascanu",
      "Jonathan Godwin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.00136",
    "title": "End-to-end Optimization of Machine Learning Prediction Queries",
    "abstract": "Prediction queries are widely used across industries to perform advanced analytics and draw insights from data. They include a data processing part (e.g., for joining, filtering, cleaning, featurizing the datasets) and a machine learning (ML) part invoking one or more trained models to perform predictions. These parts have so far been optimized in isolation, leaving significant opportunities for optimization unexplored. We present Raven, a production-ready system for optimizing prediction queries. Raven follows the enterprise architectural trend of collocating data and ML runtimes. It relies on a unified intermediate representation that captures both data and ML operators in a single graph structure to unlock two families of optimizations. First, it employs logical optimizations that pass information between the data part (and the properties of the underlying data) and the ML part to optimize each other. Second, it introduces logical-to-physical transformations that allow operators to be executed on different runtimes (relational, ML, and DNN) and hardware (CPU, GPU). Novel data-driven optimizations determine the runtime to be used for each part of the query to achieve optimal performance. Our evaluation shows that Raven improves performance of prediction queries on Apache Spark and SQL Server by up to 13.1x and 330x, respectively. For complex models where GPU acceleration is beneficial, Raven provides up to 8x speedup compared to state-of-the-art systems. ",
    "url": "https://arxiv.org/abs/2206.00136",
    "authors": [
      "Kwanghyun Park",
      "Karla Saur",
      "Dalitso Banda",
      "Rathijit Sen",
      "Matteo Interlandi",
      "Konstantinos Karanasos"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00137",
    "title": "Social Bias Meets Data Bias: The Impacts of Labeling and Measurement  Errors on Fairness Criteria",
    "abstract": "Although many fairness criteria have been proposed to ensure that machine learning algorithms do not exhibit or amplify our existing social biases, these algorithms are trained on datasets that can themselves be statistically biased. In this paper, we investigate the robustness of a number of existing (demographic) fairness criteria when the algorithm is trained on biased data. We consider two forms of dataset bias: errors by prior decision makers in the labeling process, and errors in measurement of the features of disadvantaged individuals. We analytically show that some constraints (such as Demographic Parity) can remain robust when facing certain statistical biases, while others (such as Equalized Odds) are significantly violated if trained on biased data. We also analyze the sensitivity of these criteria and the decision maker's utility to biases. We provide numerical experiments based on three real-world datasets (the FICO, Adult, and German credit score datasets) supporting our analytical findings. Our findings present an additional guideline for choosing among existing fairness criteria, or for proposing new criteria, when available datasets may be biased. ",
    "url": "https://arxiv.org/abs/2206.00137",
    "authors": [
      "Yiqiao Liao",
      "Parinaz Naghizadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2206.00145",
    "title": "CASSOCK: Viable Backdoor Attacks against DNN in The Wall of  Source-Specific Backdoor Defences",
    "abstract": "Backdoor attacks have been a critical threat to deep neural network (DNN). However, most existing countermeasures focus on source-agnostic backdoor attacks (SABAs) and fail to defeat source-specific backdoor attacks (SSBAs). Compared to an SABA, an SSBA activates a backdoor when an input from attacker-chosen class(es) is stamped with an attacker-specified trigger, making itself stealthier and thus evade most existing backdoor mitigation. Nonetheless, existing SSBAs have trade-offs on attack success rate (ASR, a backdoor is activated by a trigger input from a source class as expected) and false positive rate (FPR, a backdoor is activated unexpectedly by a trigger input from a non-source class). Significantly, they can still be effectively detected by the state-of-the-art (SOTA) countermeasures targeting SSBAs. This work overcomes efficiency and effectiveness deficiencies of existing SSBAs, thus bypassing the SOTA defences. The key insight is to construct desired poisoned and cover data during backdoor training by characterising SSBAs in-depth. Both data are samples with triggers: the cover/poisoned data from non-source/source class(es) holds ground-truth/target labels. Therefore, two cover/poisoned data enhancements are developed from trigger style and content, respectively, coined CASSOCK. First, we leverage trigger patterns with discrepant transparency to craft cover/poisoned data, enforcing triggers with heterogeneous sensitivity on different classes. The second enhancement chooses the target class features as triggers to craft these samples, entangling trigger features with the target class heavily. Compared with existing SSBAs, CASSOCK-based attacks have higher ASR and low FPR on four popular tasks: MNIST, CIFAR10, GTSRB, and LFW. More importantly, CASSOCK has effectively evaded three defences (SCAn, Februus and extended Neural Cleanse) already defeat existing SSBAs effectively. ",
    "url": "https://arxiv.org/abs/2206.00145",
    "authors": [
      "Shang Wang",
      "Yansong Gao",
      "Anmin Fu",
      "Zhi Zhang",
      "Yuqing Zhang",
      "Willy Susilo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00148",
    "title": "Hands-Up: Leveraging Synthetic Data for Hands-On-Wheel Detection",
    "abstract": "Over the past few years there has been major progress in the field of synthetic data generation using simulation based techniques. These methods use high-end graphics engines and physics-based ray-tracing rendering in order to represent the world in 3D and create highly realistic images. Datagen has specialized in the generation of high-quality 3D humans, realistic 3D environments and generation of realistic human motion. This technology has been developed into a data generation platform which we used for these experiments. This work demonstrates the use of synthetic photo-realistic in-cabin data to train a Driver Monitoring System that uses a lightweight neural network to detect whether the driver's hands are on the wheel. We demonstrate that when only a small amount of real data is available, synthetic data can be a simple way to boost performance. Moreover, we adopt the data-centric approach and show how performing error analysis and generating the missing edge-cases in our platform boosts performance. This showcases the ability of human-centric synthetic data to generalize well to the real world, and help train algorithms in computer vision settings where data from the target domain is scarce or hard to collect. ",
    "url": "https://arxiv.org/abs/2206.00148",
    "authors": [
      "Paul Yudkin",
      "Eli Friedman",
      "Orly Zvitia",
      "Gil Elbaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00162",
    "title": "PAGER: Progressive Attribute-Guided Extendable Robust Image Generation",
    "abstract": "This work presents a generative modeling approach based on successive subspace learning (SSL). Unlike most generative models in the literature, our method does not utilize neural networks to analyze the underlying source distribution and synthesize images. The resulting method, called the progressive attribute-guided extendable robust image generative (PAGER) model, has advantages in mathematical transparency, progressive content generation, lower training time, robust performance with fewer training samples, and extendibility to conditional image generation. PAGER consists of three modules: core generator, resolution enhancer, and quality booster. The core generator learns the distribution of low-resolution images and performs unconditional image generation. The resolution enhancer increases image resolution via conditional generation. Finally, the quality booster adds finer details to generated images. Extensive experiments on MNIST, Fashion-MNIST, and CelebA datasets are conducted to demonstrate generative performance of PAGER. ",
    "url": "https://arxiv.org/abs/2206.00162",
    "authors": [
      "Zohreh Azizi",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.00212",
    "title": "Negative Sampling for Contrastive Representation Learning: A Review",
    "abstract": "The learn-to-compare paradigm of contrastive representation learning (CRL), which compares positive samples with negative ones for representation learning, has achieved great success in a wide range of domains, including natural language processing, computer vision, information retrieval and graph learning. While many research works focus on data augmentations, nonlinear transformations or other certain parts of CRL, the importance of negative sample selection is usually overlooked in literature. In this paper, we provide a systematic review of negative sampling (NS) techniques and discuss how they contribute to the success of CRL. As the core part of this paper, we summarize the existing NS methods into four categories with pros and cons in each genre, and further conclude with several open research questions as future directions. By generalizing and aligning the fundamental NS ideas across multiple domains, we hope this survey can accelerate cross-domain knowledge sharing and motivate future researches for better CRL. ",
    "url": "https://arxiv.org/abs/2206.00212",
    "authors": [
      "Lanling Xu",
      "Jianxun Lian",
      "Wayne Xin Zhao",
      "Ming Gong",
      "Linjun Shou",
      "Daxin Jiang",
      "Xing Xie",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.00214",
    "title": "LiDAR-MIMO: Efficient Uncertainty Estimation for LiDAR-based 3D Object  Detection",
    "abstract": "The estimation of uncertainty in robotic vision, such as 3D object detection, is an essential component in developing safe autonomous systems aware of their own performance. However, the deployment of current uncertainty estimation methods in 3D object detection remains challenging due to timing and computational constraints. To tackle this issue, we propose LiDAR-MIMO, an adaptation of the multi-input multi-output (MIMO) uncertainty estimation method to the LiDAR-based 3D object detection task. Our method modifies the original MIMO by performing multi-input at the feature level to ensure the detection, uncertainty estimation, and runtime performance benefits are retained despite the limited capacity of the underlying detector and the large computational costs of point cloud processing. We compare LiDAR-MIMO with MC dropout and ensembles as baselines and show comparable uncertainty estimation results with only a small number of output heads. Further, LiDAR-MIMO can be configured to be twice as fast as MC dropout and ensembles, while achieving higher mAP than MC dropout and approaching that of ensembles. ",
    "url": "https://arxiv.org/abs/2206.00214",
    "authors": [
      "Matthew Pitropov",
      "Chengjie Huang",
      "Vahdat Abdelzad",
      "Krzysztof Czarnecki",
      "Steven Waslander"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00222",
    "title": "Cross-domain Detection Transformer based on Spatial-aware and  Semantic-aware Token Alignment",
    "abstract": "Detection transformers like DETR have recently shown promising performance on many object detection tasks, but the generalization ability of those methods is still quite challenging for cross-domain adaptation scenarios. To address the cross-domain issue, a straightforward way is to perform token alignment with adversarial training in transformers. However, its performance is often unsatisfactory as the tokens in detection transformers are quite diverse and represent different spatial and semantic information. In this paper, we propose a new method called Spatial-aware and Semantic-aware Token Alignment (SSTA) for cross-domain detection transformers. In particular, we take advantage of the characteristics of cross-attention as used in detection transformer and propose the spatial-aware token alignment (SpaTA) and the semantic-aware token alignment (SemTA) strategies to guide the token alignment across domains. For spatial-aware token alignment, we can extract the information from the cross-attention map (CAM) to align the distribution of tokens according to their attention to object queries. For semantic-aware token alignment, we inject the category information into the cross-attention map and construct domain embedding to guide the learning of a multi-class discriminator so as to model the category relationship and achieve category-level token alignment during the entire adaptation process. We conduct extensive experiments on several widely-used benchmarks, and the results clearly show the effectiveness of our proposed method over existing state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2206.00222",
    "authors": [
      "Jinhong Deng",
      "Xiaoyue Zhang",
      "Wen Li",
      "Lixin Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00227",
    "title": "Rethinking the Augmentation Module in Contrastive Learning: Learning  Hierarchical Augmentation Invariance with Expanded Views",
    "abstract": "A data augmentation module is utilized in contrastive learning to transform the given data example into two views, which is considered essential and irreplaceable. However, the predetermined composition of multiple data augmentations brings two drawbacks. First, the artificial choice of augmentation types brings specific representational invariances to the model, which have different degrees of positive and negative effects on different downstream tasks. Treating each type of augmentation equally during training makes the model learn non-optimal representations for various downstream tasks and limits the flexibility to choose augmentation types beforehand. Second, the strong data augmentations used in classic contrastive learning methods may bring too much invariance in some cases, and fine-grained information that is essential to some downstream tasks may be lost. This paper proposes a general method to alleviate these two problems by considering where and what to contrast in a general contrastive learning framework. We first propose to learn different augmentation invariances at different depths of the model according to the importance of each data augmentation instead of learning representational invariances evenly in the backbone. We then propose to expand the contrast content with augmentation embeddings to reduce the misleading effects of strong data augmentations. Experiments based on several baseline methods demonstrate that we learn better representations for various benchmarks on classification, detection, and segmentation downstream tasks. ",
    "url": "https://arxiv.org/abs/2206.00227",
    "authors": [
      "Junbo Zhang",
      "Kaisheng Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00228",
    "title": "Lower and Upper Bounds for Numbers of Linear Regions of Graph  Convolutional Networks",
    "abstract": "The research for characterizing GNN expressiveness attracts much attention as graph neural networks achieve a champion in the last five years. The number of linear regions has been considered a good measure for the expressivity of neural networks with piecewise linear activation. In this paper, we present some estimates for the number of linear regions of the classic graph convolutional networks (GCNs) with one layer and multiple-layer scenarios. In particular, we obtain an optimal upper bound for the maximum number of linear regions for one-layer GCNs, and the upper and lower bounds for multi-layer GCNs. The simulated estimate shows that the true maximum number of linear regions is possibly closer to our estimated lower bound. These results imply that the number of linear regions of multi-layer GCNs is exponentially greater than one-layer GCNs per parameter in general. This suggests that deeper GCNs have more expressivity than shallow GCNs. ",
    "url": "https://arxiv.org/abs/2206.00228",
    "authors": [
      "Hao Chen",
      "Yu Guang Wang",
      "Huan Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.00236",
    "title": "Continuous Prediction with Experts' Advice",
    "abstract": "Prediction with experts' advice is one of the most fundamental problems in online learning and captures many of its technical challenges. A recent line of work has looked at online learning through the lens of differential equations and continuous-time analysis. This viewpoint has yielded optimal results for several problems in online learning. In this paper, we employ continuous-time stochastic calculus in order to study the discrete-time experts' problem. We use these tools to design a continuous-time, parameter-free algorithm with improved guarantees for the quantile regret. We then develop an analogous discrete-time algorithm with a very similar analysis and identical quantile regret bounds. Finally, we design an anytime continuous-time algorithm with regret matching the optimal fixed-time rate when the gains are independent Brownian Motions; in many settings, this is the most difficult case. This gives some evidence that, even with adversarial gains, the optimal anytime and fixed-time regrets may coincide. ",
    "url": "https://arxiv.org/abs/2206.00236",
    "authors": [
      "Victor Sanches Portella",
      "Christopher Liaw",
      "Nicholas J. A. Harvey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.00240",
    "title": "Privacy for Free: How does Dataset Condensation Help Privacy?",
    "abstract": "To prevent unintentional data leakage, research community has resorted to data generators that can produce differentially private data for model training. However, for the sake of the data privacy, existing solutions suffer from either expensive training cost or poor generalization performance. Therefore, we raise the question whether training efficiency and privacy can be achieved simultaneously. In this work, we for the first time identify that dataset condensation (DC) which is originally designed for improving training efficiency is also a better solution to replace the traditional data generators for private data generation, thus providing privacy for free. To demonstrate the privacy benefit of DC, we build a connection between DC and differential privacy, and theoretically prove on linear feature extractors (and then extended to non-linear feature extractors) that the existence of one sample has limited impact ($O(m/n)$) on the parameter distribution of networks trained on $m$ samples synthesized from $n (n \\gg m)$ raw samples by DC. We also empirically validate the visual privacy and membership privacy of DC-synthesized data by launching both the loss-based and the state-of-the-art likelihood-based membership inference attacks. We envision this work as a milestone for data-efficient and privacy-preserving machine learning. ",
    "url": "https://arxiv.org/abs/2206.00240",
    "authors": [
      "Tian Dong",
      "Bo Zhao",
      "Lingjuan Lyu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00250",
    "title": "Time-multiplexed In-memory computation scheme for mapping Quantized  Neural Networks on hybrid CMOS-OxRAM building blocks",
    "abstract": "In this work, we experimentally demonstrate two key building blocks for realizing Binary/Ternary Neural Networks (BNNs/TNNs): (i) 130 nm CMOS based sigmoidal neurons and (ii) HfOx based multi-level (MLC) OxRAM-synaptic blocks. An optimized vector matrix multiplication programming scheme that utilizes the two building blocks is also presented. Compared to prior approaches that utilize differential synaptic structures, a single device per synapse with two sets of READ operations is used. Proposed hardware mapping strategy shows performance change of <5% (decrease of 2-5% for TNN, increase of 0.2% for BNN) compared to ideal quantized neural networks (QNN) with significant memory savings in the order of 16-32x for classification problem on Fashion MNIST (FMNIST) dataset. Impact of OxRAM device variability on the performance of Hardware QNN (BNN/TNN) is also analyzed. ",
    "url": "https://arxiv.org/abs/2206.00250",
    "authors": [
      "Sandeep Kaur Kingra",
      "Vivek Parmar",
      "Manoj Sharma",
      "Manan Suri"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2206.00252",
    "title": "Interpretable Deep Learning Classifier by Detection of Prototypical  Parts on Kidney Stones Images",
    "abstract": "Identifying the type of kidney stones can allow urologists to determine their formation cause, improving the early prescription of appropriate treatments to diminish future relapses. However, currently, the associated ex-vivo diagnosis (known as morpho-constitutional analysis, MCA) is time-consuming, expensive, and requires a great deal of experience, as it requires a visual analysis component that is highly operator dependant. Recently, machine learning methods have been developed for in-vivo endoscopic stone recognition. Shallow methods have been demonstrated to be reliable and interpretable but exhibit low accuracy, while deep learning-based methods yield high accuracy but are not explainable. However, high stake decisions require understandable computer-aided diagnosis (CAD) to suggest a course of action based on reasonable evidence, rather than merely prescribe one. Herein, we investigate means for learning part-prototypes (PPs) that enable interpretable models. Our proposal suggests a classification for a kidney stone patch image and provides explanations in a similar way as those used on the MCA method. ",
    "url": "https://arxiv.org/abs/2206.00252",
    "authors": [
      "Daniel Flores-Araiza",
      "Francisco Lopez-Tiro",
      "Elias Villalvazo-Avila",
      "Jonathan El-Beze",
      "Jacques Hubert",
      "Gilberto Ochoa-Ruiz",
      "Cristian Daul"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00257",
    "title": "CoNSoLe: Convex Neural Symbolic Learning",
    "abstract": "Learning the underlying equation from data is a fundamental problem in many disciplines. Recent advances rely on Neural Networks (NNs) but do not provide theoretical guarantees in obtaining the exact equations owing to the non-convexity of NNs. In this paper, we propose Convex Neural Symbolic Learning (CoNSoLe) to seek convexity under mild conditions. The main idea is to decompose the recovering process into two steps and convexify each step. In the first step of searching for right symbols, we convexify the deep Q-learning. The key is to maintain double convexity for both the negative Q-function and the negative reward function in each iteration, leading to provable convexity of the negative optimal Q function to learn the true symbol connections. Conditioned on the exact searching result, we construct a Locally Convex equation Learner (LoCaL) neural network to convexify the estimation of symbol coefficients. With such a design, we quantify a large region with strict convexity in the loss surface of LoCaL for commonly used physical functions. Finally, we demonstrate the superior performance of the CoNSoLe framework over the state-of-the-art on a diverse set of datasets. ",
    "url": "https://arxiv.org/abs/2206.00257",
    "authors": [
      "Haoran Li",
      "Yang Weng",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.00262",
    "title": "Self-supervised Learning for Label Sparsity in Computational Drug  Repositioning",
    "abstract": "The computational drug repositioning aims to discover new uses for marketed drugs, which can accelerate the drug development process and play an important role in the existing drug discovery system. However, the number of validated drug-disease associations is scarce compared to the number of drugs and diseases in the real world. Too few labeled samples will make the classification model unable to learn effective latent factors of drugs, resulting in poor generalization performance. In this work, we propose a multi-task self-supervised learning framework for computational drug repositioning. The framework tackles label sparsity by learning a better drug representation. Specifically, we take the drug-disease association prediction problem as the main task, and the auxiliary task is to use data augmentation strategies and contrast learning to mine the internal relationships of the original drug features, so as to automatically learn a better drug representation without supervised labels. And through joint training, it is ensured that the auxiliary task can improve the prediction accuracy of the main task. More precisely, the auxiliary task improves drug representation and serving as additional regularization to improve generalization. Furthermore, we design a multi-input decoding network to improve the reconstruction ability of the autoencoder model. We evaluate our model using three real-world datasets. The experimental results demonstrate the effectiveness of the multi-task self-supervised learning framework, and its predictive ability is superior to the state-of-the-art model. ",
    "url": "https://arxiv.org/abs/2206.00262",
    "authors": [
      "Xinxing Yang",
      "Genke Yang",
      "Jian Chu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2206.00265",
    "title": "InducT-GCN: Inductive Graph Convolutional Networks for Text  Classification",
    "abstract": "Text classification aims to assign labels to textual units by making use of global information. Recent studies have applied graph neural network (GNN) to capture the global word co-occurrence in a corpus. Existing approaches require that all the nodes (training and test) in a graph are present during training, which are transductive and do not naturally generalise to unseen nodes. To make those models inductive, they use extra resources, like pretrained word embedding. However, high-quality resource is not always available and hard to train. Under the extreme settings with no extra resource and limited amount of training set, can we still learn an inductive graph-based text classification model? In this paper, we introduce a novel inductive graph-based text classification framework, InducT-GCN (InducTive Graph Convolutional Networks for Text classification). Compared to transductive models that require test documents in training, we construct a graph based on the statistics of training documents only and represent document vectors with a weighted sum of word vectors. We then conduct one-directional GCN propagation during testing. Across five text classification benchmarks, our InducT-GCN outperformed state-of-the-art methods that are either transductive in nature or pre-trained additional resources. We also conducted scalability testing by gradually increasing the data size and revealed that our InducT-GCN can reduce the time and space complexity. The code is available on: https://github.com/usydnlp/InductTGCN. ",
    "url": "https://arxiv.org/abs/2206.00265",
    "authors": [
      "Kunze Wang",
      "Soyeon Caren Han",
      "Josiah Poon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.00266",
    "title": "PaGO-LOAM: Robust Ground-Optimized LiDAR Odometry",
    "abstract": "Numerous researchers have conducted studies to achieve fast and robust ground-optimized LiDAR odometry methods for terrestrial mobile platforms. In particular, ground-optimized LiDAR odometry usually employs ground segmentation as a preprocessing method. This is because most of the points in a 3D point cloud captured by a 3D LiDAR sensor on a terrestrial platform are from the ground. However, the effect of the performance of ground segmentation on LiDAR odometry is still not closely examined. In this paper, a robust ground-optimized LiDAR odometry framework is proposed to facilitate the study to check the effect of ground segmentation on LiDAR SLAM based on the state-of-the-art (SOTA) method. By using our proposed odometry framework, it is easy and straightforward to test whether ground segmentation algorithms help extract well-described features and thus improve SLAM performance. In addition, by leveraging the SOTA ground segmentation method called Patchwork, which shows robust ground segmentation even in complex and uneven urban environments with little performance perturbation, a novel ground-optimized LiDAR odometry is proposed, called PaGO-LOAM. The methods were tested using the KITTI odometry dataset. \\textit{PaGO-LOAM} shows robust and accurate performance compared with the baseline method. Our code is available at https://github.com/url-kaist/AlterGround-LeGO-LOAM. ",
    "url": "https://arxiv.org/abs/2206.00266",
    "authors": [
      "Dong-Uk Seo",
      "Hyungtae Lim",
      "Seungjae Lee",
      "Hyun Myung"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00267",
    "title": "LPFS: Learnable Polarizing Feature Selection for Click-Through Rate  Prediction",
    "abstract": "In industry, feature selection is a standard but necessary step to search for an optimal set of informative feature fields for efficient and effective training of deep Click-Through Rate (CTR) models. Most previous works measure the importance of feature fields by using their corresponding continuous weights from the model, then remove the feature fields with small weight values. However, removing many features that correspond to small but not exact zero weights will inevitably hurt model performance and not be friendly to hot-start model training. There is also no theoretical guarantee that the magnitude of weights can represent the importance, thus possibly leading to sub-optimal results if using these methods. To tackle this problem, we propose a novel Learnable Polarizing Feature Selection (LPFS) method using a smoothed-$\\ell^0$ function in literature. Furthermore, we extend LPFS to LPFS++ by our newly designed smoothed-$\\ell^0$-liked function to select a more informative subset of features. LPFS and LPFS++ can be used as gates inserted at the input of the deep network to control the active and inactive state of each feature. When training is finished, some gates are exact zero, while others are around one, which is particularly favored by the practical hot-start training in the industry, due to no damage to the model performance before and after removing the features corresponding to exact-zero gates. Experiments show that our methods outperform others by a clear margin, and have achieved great A/B test results in KuaiShou Technology. ",
    "url": "https://arxiv.org/abs/2206.00267",
    "authors": [
      "Yi Guo",
      "Zhaocheng Liu",
      "Jianchao Tan",
      "Chao Liao",
      "Daqing Chang",
      "Qiang Liu",
      "Sen Yang",
      "Ji Liu",
      "Dongying Kong",
      "Zhi Chen",
      "Chengru Song"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.00272",
    "title": "Vision GNN: An Image is Worth Graph of Nodes",
    "abstract": "Network architecture plays a key role in the deep learning-based computer vision system. The widely-used convolutional neural network and transformer treat the image as a grid or sequence structure, which is not flexible to capture irregular and complex objects. In this paper, we propose to represent the image as a graph structure and introduce a new Vision GNN (ViG) architecture to extract graph-level feature for visual tasks. We first split the image to a number of patches which are viewed as nodes, and construct a graph by connecting the nearest neighbors. Based on the graph representation of images, we build our ViG model to transform and exchange information among all the nodes. ViG consists of two basic modules: Grapher module with graph convolution for aggregating and updating graph information, and FFN module with two linear layers for node feature transformation. Both isotropic and pyramid architectures of ViG are built with different model sizes. Extensive experiments on image recognition and object detection tasks demonstrate the superiority of our ViG architecture. We hope this pioneering study of GNN on general visual tasks will provide useful inspiration and experience for future research. The PyTroch code will be available at https://github.com/huawei-noah/CV-Backbones and the MindSpore code will be avaiable at https://gitee.com/mindspore/models. ",
    "url": "https://arxiv.org/abs/2206.00272",
    "authors": [
      "Kai Han",
      "Yunhe Wang",
      "Jianyuan Guo",
      "Yehui Tang",
      "Enhua Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00273",
    "title": "A reinforcement learning-based link quality estimation strategy for RPL  and its impact on topology management",
    "abstract": "Over the last few years, standardisation efforts are consolidating the role of the Routing Protocol for LowPower and Lossy Networks (RPL) as the standard routing protocol for IPv6 based Wireless Sensor Networks (WSNs). Although many core functionalities are well defined, others are left implementation dependent. Among them, the definition of an efficient link quality estimation (LQE) strategy is of paramount importance, as it influences significantly both the quality of the selected network routes and nodes' energy consumption. In this paper, we present RLProbe, a novel strategy for link quality monitoring in RPL, which accurately measures link quality with minimal overhead and energy waste. To achieve this goal, RLProbe leverages both synchronous and asynchronous monitoring schemes to maintain up-to-date information on link quality and to promptly react to sudden topology changes, e.g. due to mobility. Our solution relies on a reinforcement learning model to drive the monitoring procedures in order to minimise the overhead caused by active probing operations. The performance of the proposed solution is assessed by means of simulations and real experiments. Results demonstrated that RLProbe helps in effectively improving packet loss rates, allowing nodes to promptly react to link quality variations as well as to link failures due to node mobility. ",
    "url": "https://arxiv.org/abs/2206.00273",
    "authors": [
      "Emilio Ancillotti",
      "Carlo Vallati",
      "Raffaele Bruno",
      "Enzo Mingozzi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2206.00274",
    "title": "Point-Teaching: Weakly Semi-Supervised Object Detection with Point  Annotations",
    "abstract": "Point annotations are considerably more time-efficient than bounding box annotations. However, how to use cheap point annotations to boost the performance of semi-supervised object detection remains largely unsolved. In this work, we present Point-Teaching, a weakly semi-supervised object detection framework to fully exploit the point annotations. Specifically, we propose a Hungarian-based point matching method to generate pseudo labels for point annotated images. We further propose multiple instance learning (MIL) approaches at the level of images and points to supervise the object detector with point annotations. Finally, we propose a simple-yet-effective data augmentation, termed point-guided copy-paste, to reduce the impact of the unmatched points. Experiments demonstrate the effectiveness of our method on a few datasets and various data regimes. ",
    "url": "https://arxiv.org/abs/2206.00274",
    "authors": [
      "Yongtao Ge",
      "Qiang Zhou",
      "Xinlong Wang",
      "Chunhua Shen",
      "Zhibin Wang",
      "Hao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00278",
    "title": "On the Perils of Cascading Robust Classifiers",
    "abstract": "Ensembling certifiably robust neural networks has been shown to be a promising approach for improving the \\emph{certified robust accuracy} of neural models. Black-box ensembles that assume only query-access to the constituent models (and their robustness certifiers) during prediction are particularly attractive due to their modular structure. Cascading ensembles are a popular instance of black-box ensembles that appear to improve certified robust accuracies in practice. However, we find that the robustness certifier used by a cascading ensemble is unsound. That is, when a cascading ensemble is certified as locally robust at an input $x$, there can, in fact, be inputs $x'$ in the $\\epsilon$-ball centered at $x$, such that the cascade's prediction at $x'$ is different from $x$. We present an alternate black-box ensembling mechanism based on weighted voting which we prove to be sound for robustness certification. Via a thought experiment, we demonstrate that if the constituent classifiers are suitably diverse, voting ensembles can improve certified performance. Our code is available at \\url{https://github.com/TristaChi/ensembleKW}. ",
    "url": "https://arxiv.org/abs/2206.00278",
    "authors": [
      "Ravi Mangal",
      "Zifan Wang",
      "Chi Zhang",
      "Klas Leino",
      "Corina Pasareanu",
      "Matt Fredrikson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00279",
    "title": "Defensive Design of Saturating Counters Based on Differential Privacy",
    "abstract": "The saturating counter is the basic module of the dynamic branch predictor, which involves the core technique to improve instruction level parallelism performance in modern processors. However, most studies focus on the performance improvement and hardware consumption of saturating counters, while ignoring the security problems they may cause. In this paper, we creatively propose to study and design saturating counters from the defense perspective of differential privacy, so that attackers cannot distinguish the states that saturating counters are in and further infer sensitive information. To obtain theoretical guarantees, we use Markov chain to formalize the attack algorithm applied to the saturating counter, investigate into the optimal attack strategy and calculate the probability of successful attack. Furthermore, we find that the attacker is able to accurately guess the branch execution of the victim's process in the existing saturating counters. To avoid this, we design a new probabilistic saturating counter, which generalizes the existing conventional and probabilistic saturating counters. The guarantee of differential privacy is applied to deduce parameters of the new saturating counters so that the security requirement can be satisfied. We also theoretically calculate the misprediction rate when the saturating counter reaches the steady state. The experimental results on testing programs show that the calculated theoretical results agree with the experimental performances. Compared with the existing conventional and probabilistic saturating counters, when the parameters of our designed models are selected appropriately, the new saturating counters can not only ensure similar operational performance, but also establish strict security guarantee. ",
    "url": "https://arxiv.org/abs/2206.00279",
    "authors": [
      "Depeng Liu",
      "Lutan Zhao",
      "Pengfei Yang",
      "Bow-Yaw Wang",
      "Rui Hou",
      "Lijun Zhang",
      "Naijun Zhan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2206.00290",
    "title": "Discrete Gradient Flow Approximations of High Dimensional Evolution  Partial Differential Equations via Deep Neural Networks",
    "abstract": "We consider the approximation of initial/boundary value problems involving, possibly high-dimensional, dissipative evolution partial differential equations (PDEs) using a deep neural network framework. More specifically, we first propose discrete gradient flow approximations based on non-standard Dirichlet energies for problems involving essential boundary conditions posed on bounded spatial domains. The imposition of the boundary conditions is realized weakly via non-standard functionals; the latter classically arise in the construction of Galerkin-type numerical methods and are often referred to as \"Nitsche-type\" methods. Moreover, inspired by the seminal work of Jordan, Kinderleher, and Otto (JKO) \\cite{jko}, we consider the second class of discrete gradient flows for special classes of dissipative evolution PDE problems with non-essential boundary conditions. These JKO-type gradient flows are solved via deep neural network approximations. A key, distinct aspect of the proposed methods is that the discretization is constructed via a sequence of residual-type deep neural networks (DNN) corresponding to implicit time-stepping. As a result, a DNN represents the PDE problem solution at each time node. This approach offers several advantages in the training of each DNN. We present a series of numerical experiments which showcase the good performance of Dirichlet-type energy approximations for lower space dimensions and the excellent performance of the JKO-type energies for higher spatial dimensions. ",
    "url": "https://arxiv.org/abs/2206.00290",
    "authors": [
      "Emmanuil H. Georgoulis",
      "Michail Loulakis",
      "Asterios Tsiourvas"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2206.00302",
    "title": "Multi-Complexity-Loss DNAS for Energy-Efficient and Memory-Constrained  Deep Neural Networks",
    "abstract": "Neural Architecture Search (NAS) is increasingly popular to automatically explore the accuracy versus computational complexity trade-off of Deep Learning (DL) architectures. When targeting tiny edge devices, the main challenge for DL deployment is matching the tight memory constraints, hence most NAS algorithms consider model size as the complexity metric. Other methods reduce the energy or latency of DL models by trading off accuracy and number of inference operations. Energy and memory are rarely considered simultaneously, in particular by low-search-cost Differentiable NAS (DNAS) solutions. We overcome this limitation proposing the first DNAS that directly addresses the most realistic scenario from a designer's perspective: the co-optimization of accuracy and energy (or latency) under a memory constraint, determined by the target HW. We do so by combining two complexity-dependent loss functions during training, with independent strength. Testing on three edge-relevant tasks from the MLPerf Tiny benchmark suite, we obtain rich Pareto sets of architectures in the energy vs. accuracy space, with memory footprints constraints spanning from 75% to 6.25% of the baseline networks. When deployed on a commercial edge device, the STM NUCLEO-H743ZI2, our networks span a range of 2.18x in energy consumption and 4.04% in accuracy for the same memory constraint, and reduce energy by up to 2.2x with negligible accuracy drop with respect to the baseline. ",
    "url": "https://arxiv.org/abs/2206.00302",
    "authors": [
      "Matteo Risso",
      "Alessio Burrello",
      "Luca Benini",
      "Enrico Macii",
      "Massimo Poncino",
      "Daniele Jahier Pagliari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00308",
    "title": "Content Distribution based on Joint V2I and V2V Scheduling in mmWave  Vehicular Networks",
    "abstract": "With the explosive growth of vehicle applications, vehicular networks based on millimeter wave (mmWave) bands have attracted interests from both academia and industry. mmWave communications are able to utilize the huge available bandwidth to provide multiple Gbps transmission rates among vehicles. In this paper, we address the content distribution scheduling problem in mmWave vehicular networks. It has been challenging for all vehicles in the same network to complete content downloading due to the limited communication resources of roadside units (RSUs) and the high mobility of vehicles. We propose a joint vehicle-to-infrastructure (V2I) and vehicle-tovehicle (V2V) scheduling scheme to minimize the total number of content distribution time slots from a global optimization perspective. In the V2I phase, the RSU serially transmits integrity content to vehicles, which are selected according to the vehicular network topology and transmission scheduling scheme. In the V2V phase, full-duplex communications and concurrent transmissions are exploited to achieve content sharing between vehicles and improve transmission efficiency. Performance evaluations demonstrate that our proposed scheme reduces the number of time slots and significantly improves system throughput when compared with other schemes, especially under large-size file transfers and a large number of vehicles. ",
    "url": "https://arxiv.org/abs/2206.00308",
    "authors": [
      "Lan Su",
      "Yong Niu",
      "Zhu Han",
      "Bo Ai",
      "Ruisi He",
      "Yibing Wang",
      "Ning Wang",
      "Xiang Su"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2206.00309",
    "title": "Label-Efficient Online Continual Object Detection in Streaming Video",
    "abstract": "To thrive in evolving environments, humans are capable of continual acquisition and transfer of new knowledge, from a continuous video stream, with minimal supervisions, while retaining previously learnt experiences. In contrast to human learning, most standard continual learning benchmarks focus on learning from static iid images in fully supervised settings. Here, we examine a more realistic and challenging problem$\\unicode{x2014}$Label-Efficient Online Continual Object Detection (LEOCOD) in video streams. By addressing this problem, it would greatly benefit many real-world applications with reduced annotation costs and retraining time. To tackle this problem, we seek inspirations from complementary learning systems (CLS) in human brains and propose a computational model, dubbed as Efficient-CLS. Functionally correlated with the hippocampus and the neocortex in CLS, Efficient-CLS posits a memory encoding mechanism involving bidirectional interaction between fast and slow learners via synaptic weight transfers and pattern replays. We test Efficient-CLS and competitive baselines in two challenging real-world video stream datasets. Like humans, Efficient-CLS learns to detect new object classes incrementally from a continuous temporal stream of non-repeating video with minimal forgetting. Remarkably, with only 25% annotated video frames, our Efficient-CLS still leads among all comparative models, which are trained with 100% annotations on all video frames. The data and source code will be publicly available at https://github.com/showlab/Efficient-CLS. ",
    "url": "https://arxiv.org/abs/2206.00309",
    "authors": [
      "Jay Zhangjie Wu",
      "David Junhao Zhang",
      "Wynne Hsu",
      "Mengmi Zhang",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00317",
    "title": "Temporal Characterization of VR Traffic for Network Slicing Requirement  Definition",
    "abstract": "Over the past few years, the concept of VR has attracted increasing interest thanks to its extensive industrial and commercial applications. Currently, the 3D models of the virtual scenes are generally stored in the VR visor itself, which operates as a standalone device. However, applications that entail multi-party interactions will likely require the scene to be processed by an external server and then streamed to the visors. However, the stringent Quality of Service (QoS) constraints imposed by VR's interactive nature require Network Slicing (NS) solutions, for which profiling the traffic generated by the VR application is crucial. To this end, we collected more than 4 hours of traces in a real setup and analyzed their temporal correlation. More specifically, we focused on the CBR encoding mode, which should generate more predictable traffic streams. From the collected data, we then distilled two prediction models for future frame size, which can be instrumental in the design of dynamic resource allocation algorithms. Our results show that even the state-of-the-art H.264 CBR mode can have significant fluctuations, which can impact the NS optimization. We then exploited the proposed models to dynamically determine the Service Level Agreement (SLA) parameters in an NS scenario, providing service with the required QoS while minimizing resource usage. ",
    "url": "https://arxiv.org/abs/2206.00317",
    "authors": [
      "Federico Chiariotti",
      "Matteo Drago",
      "Paolo Testolina",
      "Mattia Lecci",
      "Andrea Zanella",
      "Michele Zorzi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.00325",
    "title": "LDoS attack detection method based on traffic time-frequency  characteristics",
    "abstract": "For the traditional denial-of-service attack detection methods have complex algorithms and high computational overhead, which are difficult to meet the demand of online detection; and the experimental environment is mostly a simulation platform, which is difficult to deploy in real network environment, we propose a real network environment-oriented LDoS attack detection method based on the time-frequency characteristics of traffic data. All the traffic data flowing through the Web server is obtained through the acquisition storage system, and the detection data set is constructed using pre-processing; the simple features of the flow fragments are used as input, and the deep neural network is used to learn the time-frequency domain features of normal traffic features and generate reconstructed sequences, and the LDoS attack is discriminated based on the differences between the reconstructed sequences and the input data in the time-frequency domain. The experimental results show that the proposed method can accurately detect the attack features in the flow fragments in a very short time and achieve high detection accuracy for complex and diverse LDoS attacks; since only the statistical features of the packets are used, there is no need to parse the packet data, which can be adapted to different network environments. ",
    "url": "https://arxiv.org/abs/2206.00325",
    "authors": [
      "Yu Fu",
      "Xueyuan Duan",
      "Kun Wang",
      "Bin Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2206.00343",
    "title": "Towards view-invariant vehicle speed detection from driving simulator  images",
    "abstract": "The use of cameras for vehicle speed measurement is much more cost effective compared to other technologies such as inductive loops, radar or laser. However, accurate speed measurement remains a challenge due to the inherent limitations of cameras to provide accurate range estimates. In addition, classical vision-based methods are very sensitive to extrinsic calibration between the camera and the road. In this context, the use of data-driven approaches appears as an interesting alternative. However, data collection requires a complex and costly setup to record videos under real traffic conditions from the camera synchronized with a high-precision speed sensor to generate the ground truth speed values. It has recently been demonstrated that the use of driving simulators (e.g., CARLA) can serve as a robust alternative for generating large synthetic datasets to enable the application of deep learning techniques for vehicle speed estimation for a single camera. In this paper, we study the same problem using multiple cameras in different virtual locations and with different extrinsic parameters. We address the question of whether complex 3D-CNN architectures are capable of implicitly learning view-invariant speeds using a single model, or whether view-specific models are more appropriate. The results are very promising as they show that a single model with data from multiple views reports even better accuracy than camera-specific models, paving the way towards a view-invariant vehicle speed measurement system. ",
    "url": "https://arxiv.org/abs/2206.00343",
    "authors": [
      "Antonio Hern\u00e1ndez Mart\u00ednez",
      "David Fernandez Llorca",
      "Iv\u00e1n Garc\u00eda Daza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.00344",
    "title": "Self-Supervised Learning as a Means To Reduce the Need for Labeled Data  in Medical Image Analysis",
    "abstract": "One of the largest problems in medical image processing is the lack of annotated data. Labeling medical images often requires highly trained experts and can be a time-consuming process. In this paper, we evaluate a method of reducing the need for labeled data in medical image object detection by using self-supervised neural network pretraining. We use a dataset of chest X-ray images with bounding box labels for 13 different classes of anomalies. The networks are pretrained on a percentage of the dataset without labels and then fine-tuned on the rest of the dataset. We show that it is possible to achieve similar performance to a fully supervised model in terms of mean average precision and accuracy with only 60\\% of the labeled data. We also show that it is possible to increase the maximum performance of a fully-supervised model by adding a self-supervised pretraining step, and this effect can be observed with even a small amount of unlabeled data for pretraining. ",
    "url": "https://arxiv.org/abs/2206.00344",
    "authors": [
      "Marin Ben\u010devi\u0107",
      "Marija Habijan",
      "Irena Gali\u0107",
      "Aleksandra Pizurica"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00352",
    "title": "Support Vector Machines under Adversarial Label Contamination",
    "abstract": "Machine learning algorithms are increasingly being applied in security-related tasks such as spam and malware detection, although their security properties against deliberate attacks have not yet been widely understood. Intelligent and adaptive attackers may indeed exploit specific vulnerabilities exposed by machine learning techniques to violate system security. Being robust to adversarial data manipulation is thus an important, additional requirement for machine learning algorithms to successfully operate in adversarial settings. In this work, we evaluate the security of Support Vector Machines (SVMs) to well-crafted, adversarial label noise attacks. In particular, we consider an attacker that aims to maximize the SVM's classification error by flipping a number of labels in the training data. We formalize a corresponding optimal attack strategy, and solve it by means of heuristic approaches to keep the computational complexity tractable. We report an extensive experimental analysis on the effectiveness of the considered attacks against linear and non-linear SVMs, both on synthetic and real-world datasets. We finally argue that our approach can also provide useful insights for developing more secure SVM learning algorithms, and also novel techniques in a number of related research areas, such as semi-supervised and active learning. ",
    "url": "https://arxiv.org/abs/2206.00352",
    "authors": [
      "Huang Xiao",
      "Battista Biggio",
      "Blaine Nelson",
      "Han Xiao",
      "Claudia Eckert",
      "Fabio Roli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00359",
    "title": "DeepCluE: Enhanced Image Clustering via Multi-layer Ensembles in Deep  Neural Networks",
    "abstract": "Deep clustering has recently emerged as a promising technique for complex image clustering. Despite the significant progress, previous deep clustering works mostly tend to construct the final clustering by utilizing a single layer of representation, e.g., by performing $K$-means on the last fully-connected layer or by associating some clustering loss to a specific layer. However, few of them have considered the possibilities and potential benefits of jointly leveraging multi-layer representations for enhancing the deep clustering performance. In light of this, this paper presents a Deep Clustering via Ensembles (DeepCluE) approach, which bridges the gap between deep clustering and ensemble clustering by harnessing the power of multiple layers in deep neural networks. Particularly, we utilize a weight-sharing convolutional neural network as the backbone, which is trained with both the instance-level contrastive learning (via an instance projector) and the cluster-level contrastive learning (via a cluster projector) in an unsupervised manner. Thereafter, multiple layers of feature representations are extracted from the trained network, upon which a set of diversified base clusterings can be generated via a highly efficient clusterer. Then, the reliability of the clusters in multiple base clusterings is automatically estimated by exploiting an entropy-based criterion, based on which the multiple base clusterings are further formulated into a weighted-cluster bipartite graph. By partitioning this bipartite graph via transfer cut, the final image clustering result can therefore be obtained. Experimental results on six image datasets confirm the advantages of our DeepCluE approach over the state-of-the-art deep clustering approaches. ",
    "url": "https://arxiv.org/abs/2206.00359",
    "authors": [
      "Dong Huang",
      "Ding-Hua Chen",
      "Xiangji Chen",
      "Chang-Dong Wang",
      "Jian-Huang Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00362",
    "title": "Augmenting Message Passing by Retrieving Similar Graphs",
    "abstract": "Graph Neural Networks (GNNs) are effective tools for graph representation learning. Most GNNs rely on a recursive neighborhood aggregation scheme, named message passing. In this paper, motivated by the success of retrieval-based models, we propose a non-parametric scheme called GraphRetrieval, in which similar training graphs associated with their ground-truth labels are retrieved to be jointly utilized with the input graph representation to complete various graph-based predictive tasks. In particular, we take a well-trained model with its parameters fixed and then we add an adapter based on self-attention with only a few trainable parameters per task to explicitly learn the interaction between an input graph and its retrieved similar graphs. Our experiments on 12 different datasets involving different tasks (classification and regression) show that GraphRetrieval is able to achieve substantial improvements on all twelve datasets compared to three strong GNN baseline models. Our work demonstrates that GraphRetrieval is a promising augmentation for message passing. ",
    "url": "https://arxiv.org/abs/2206.00362",
    "authors": [
      "Dingmin Wang",
      "Shengchao Liu",
      "Hanchen Wang",
      "Linfeng Song",
      "Jian Tang",
      "Song Le",
      "Bernardo Cuenca Grau",
      "Qi Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.00365",
    "title": "ORKA: Object reconstruction using a K-approximation graph",
    "abstract": "Data processing has to deal with many practical difficulties. Data is often corrupted by artifacts or noise and acquiring data can be expensive and difficult. Thus, the given data is often incomplete and inaccurate. To overcome these problems, it is often assumed that the data is sparse or low-dimensional in some domain. When multiple measurements are taken, this sparsity often appears in a structured manner. We propose a new model that assumes the data only contains a few relevant objects, i.e., it is sparse in some object domain. We model an object as a structure that can only change slightly in form and continuously in position over different measurements. This can be modeled by a matrix with highly correlated columns and a column shift operator that we introduce in this work. We present an efficient algorithm to solve the object reconstruction problem based on a K-approximation graph. We prove optimal approximation bounds and perform a numerical evaluation of the method. Examples from applications including Geophysics, video processing, and others will be given. ",
    "url": "https://arxiv.org/abs/2206.00365",
    "authors": [
      "Florian Bossmann",
      "Jianwei Ma"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2206.00372",
    "title": "BD-SHS: A Benchmark Dataset for Learning to Detect Online Bangla Hate  Speech in Different Social Contexts",
    "abstract": "Social media platforms and online streaming services have spawned a new breed of Hate Speech (HS). Due to the massive amount of user-generated content on these sites, modern machine learning techniques are found to be feasible and cost-effective to tackle this problem. However, linguistically diverse datasets covering different social contexts in which offensive language is typically used are required to train generalizable models. In this paper, we identify the shortcomings of existing Bangla HS datasets and introduce a large manually labeled dataset BD-SHS that includes HS in different social contexts. The labeling criteria were prepared following a hierarchical annotation process, which is the first of its kind in Bangla HS to the best of our knowledge. The dataset includes more than 50,200 offensive comments crawled from online social networking sites and is at least 60% larger than any existing Bangla HS datasets. We present the benchmark result of our dataset by training different NLP models resulting in the best one achieving an F1-score of 91.0%. In our experiments, we found that a word embedding trained exclusively using 1.47 million comments from social media and streaming sites consistently resulted in better modeling of HS detection in comparison to other pre-trained embeddings. Our dataset and all accompanying codes is publicly available at github.com/naurosromim/hate-speech-dataset-for-Bengali-social-media ",
    "url": "https://arxiv.org/abs/2206.00372",
    "authors": [
      "Nauros Romim",
      "Mosahed Ahmed",
      "Md. Saiful Islam",
      "Arnab Sen Sharma",
      "Hriteshwar Talukder",
      "Mohammad Ruhul Amin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.00373",
    "title": "A Flexible and Robust Vision Trap for Automated Part Feeder Design",
    "abstract": "Fast, robust, and flexible part feeding is essential for enabling automation of low volume, high variance assembly tasks. An actuated vision-based solution on a traditional vibratory feeder, referred to here as a vision trap, should in principle be able to meet these demands for a wide range of parts. However, in practice, the flexibility of such a trap is limited as an expert is needed to both identify manageable tasks and to configure the vision system. We propose a novel approach to vision trap design in which the identification of manageable tasks is automatic and the configuration of these tasks can be delegated to an automated feeder design system. We show that the trap's capabilities can be formalized in such a way that it integrates seamlessly into the ecosystem of automated feeder design. Our results on six canonical parts show great promise for autonomous configuration of feeder systems. ",
    "url": "https://arxiv.org/abs/2206.00373",
    "authors": [
      "Rasmus Laurvig Haugaard",
      "Thorbj\u00f8rn Mosekj\u00e6r Iversen",
      "Anders Glent Buch",
      "Aljaz Kramberger",
      "Simon Faarvang Mathiesen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.00378",
    "title": "Smartphone-based crowdsourcing for estimating the bottleneck capacity in  wireless networks",
    "abstract": "Crowdsourcing enables the fine-grained characterization and performance evaluation of today's large-scale networks using the power of the masses and distributed intelligence. This paper presents SmartProbe, a system that assesses the bottleneck capacity of Internet paths using smartphones, from a mobile crowdsourcing perspective. With SmartProbe measurement activities are more bandwidth efficient compared to similar systems, and a larger number of users can be supported. An application based on SmartProbe is also presented: georeferenced measurements are mapped and used to compare the performance of mobile broadband operators in wide areas. Results from one year of operation are included. ",
    "url": "https://arxiv.org/abs/2206.00378",
    "authors": [
      "Enrico Gregori",
      "Alessandro Improta",
      "Luciano Lenzini",
      "Valerio Luconi",
      "Nilo Redini",
      "Alessio Vecchio"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2206.00379",
    "title": "YOLoC: DeploY Large-Scale Neural Network by ROM-based  Computing-in-Memory using ResiduaL Branch on a Chip",
    "abstract": "Computing-in-memory (CiM) is a promising technique to achieve high energy efficiency in data-intensive matrix-vector multiplication (MVM) by relieving the memory bottleneck. Unfortunately, due to the limited SRAM capacity, existing SRAM-based CiM needs to reload the weights from DRAM in large-scale networks. This undesired fact weakens the energy efficiency significantly. This work, for the first time, proposes the concept, design, and optimization of computing-in-ROM to achieve much higher on-chip memory capacity, and thus less DRAM access and lower energy consumption. Furthermore, to support different computing scenarios with varying weights, a weight fine-tune technique, namely Residual Branch (ReBranch), is also proposed. ReBranch combines ROM-CiM and assisting SRAM-CiM to ahieve high versatility. YOLoC, a ReBranch-assisted ROM-CiM framework for object detection is presented and evaluated. With the same area in 28nm CMOS, YOLoC for several datasets has shown significant energy efficiency improvement by 14.8x for YOLO (Darknet-19) and 4.8x for ResNet-18, with <8% latency overhead and almost no mean average precision (mAP) loss (-0.5% ~ +0.2%), compared with the fully SRAM-based CiM. ",
    "url": "https://arxiv.org/abs/2206.00379",
    "authors": [
      "Yiming Chen",
      "Guodong Yin",
      "Zhanhong Tan",
      "Mingyen Lee",
      "Zekun Yang",
      "Yongpan Liu",
      "Huazhong Yang",
      "Kaisheng Ma",
      "Xueqing Li"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2206.00383",
    "title": "Neural Improvement Heuristics for Preference Ranking",
    "abstract": "In recent years, Deep Learning based methods have been a revolution in the field of combinatorial optimization. They learn to approximate solutions and constitute an interesting choice when dealing with repetitive problems drawn from similar distributions. Most effort has been devoted to investigating neural constructive methods, while the works that propose neural models to iteratively improve a candidate solution are less frequent. In this paper, we present a Neural Improvement (NI) model for graph-based combinatorial problems that, given an instance and a candidate solution, encodes the problem information by means of edge features. Our model proposes a modification on the pairwise precedence of items to increase the quality of the solution. We demonstrate the practicality of the model by applying it as the building block of a Neural Hill Climber and other trajectory-based methods. The algorithms are used to solve the Preference Ranking Problem and results show that they outperform conventional alternatives in simulated and real-world data. Conducted experiments also reveal that the proposed model can be a milestone in the development of efficiently guided trajectory-based optimization algorithms. ",
    "url": "https://arxiv.org/abs/2206.00383",
    "authors": [
      "Andoni I. Garmendia",
      "Josu Ceberio",
      "Alexander Mendiburu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00385",
    "title": "Mining Function Homology of Bot Loaders from Honeypot Logs",
    "abstract": "Self-contained loaders are widely adopted in botnets for injecting loading commands and spawning new bots. While researchers can dissect bot clients to get various information of botnets, the cloud-based and self-contained design of loaders effectively hinders researchers from understanding the loaders' evolution and variation using classic methods. The decoupled nature of bot loaders also dramatically reduces the feasibility of investigating relationships among clients and infrastructures. In this paper, we propose a text-based method to investigate and analyze details of bot loaders using honeypots. We leverage high interaction honeypots to collect request logs and define eight families of bot loaders based on the result of agglomerative clustering. At the function level, we push our study further to explore their homological relationship based on similarity analysis of request logs using sequence aligning techniques. This further exploration discloses that the released code of Mirai keeps spawning new generations of botnets both on the client and the server side. This paper uncovers the homology of active botnet infrastructures, providing a new prospect on finding covert relationships among cybercrimes. Bot loaders are precisely investigated at the function level to yield a new insight for researchers to identify the botnet's infrastructures and track their evolution over time. ",
    "url": "https://arxiv.org/abs/2206.00385",
    "authors": [
      "Yuhui Zhu",
      "Zhenxiang Chen",
      "Qiben Yan",
      "Shanshan Wang",
      "Enlong Li",
      "Lizhi Peng",
      "Chuan Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.00390",
    "title": "Attention-embedded Quadratic Network (Qttention) for Effective and  Interpretable Bearing Fault Diagnosis",
    "abstract": "Bearing fault diagnosis is of great importance to decrease the damage risk of rotating machines and further improve economic profits. Recently, machine learning, represented by deep learning, has made great progress in bearing fault diagnosis. However, applying deep learning to such a task still faces two major problems. On the one hand, deep learning loses its effectiveness when bearing data are noisy or big data are unavailable, making deep learning hard to implement in industrial fields. On the other hand, a deep network is notoriously a black box. It is difficult to know how a model classifies faulty signals from the normal and the physics principle behind the classification. To solve the effectiveness and interpretability issues, we prototype a convolutional network with recently-invented quadratic neurons. This quadratic neuron empowered network can qualify the noisy and small bearing data due to the strong feature representation ability of quadratic neurons. Moreover, we independently derive the attention mechanism from a quadratic neuron, referred to as qttention, by factorizing the learned quadratic function in analogue to the attention, making the model with quadratic neurons inherently interpretable. Experiments on the public and our datasets demonstrate that the proposed network can facilitate effective and interpretable bearing fault diagnosis. ",
    "url": "https://arxiv.org/abs/2206.00390",
    "authors": [
      "Jing-Xiao Liao",
      "Hang-Cheng Dong",
      "Zhi-Qi Sun",
      "Jinwei Sun",
      "Shiping Zhang",
      "Feng-Lei Fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.00402",
    "title": "NeuroUnlock: Unlocking the Architecture of Obfuscated Deep Neural  Networks",
    "abstract": "The advancements of deep neural networks (DNNs) have led to their deployment in diverse settings, including safety and security-critical applications. As a result, the characteristics of these models have become sensitive intellectual properties that require protection from malicious users. Extracting the architecture of a DNN through leaky side-channels (e.g., memory access) allows adversaries to (i) clone the model, and (ii) craft adversarial attacks. DNN obfuscation thwarts side-channel-based architecture stealing (SCAS) attacks by altering the run-time traces of a given DNN while preserving its functionality. In this work, we expose the vulnerability of state-of-the-art DNN obfuscation methods to these attacks. We present NeuroUnlock, a novel SCAS attack against obfuscated DNNs. Our NeuroUnlock employs a sequence-to-sequence model that learns the obfuscation procedure and automatically reverts it, thereby recovering the original DNN architecture. We demonstrate the effectiveness of NeuroUnlock by recovering the architecture of 200 randomly generated and obfuscated DNNs running on the Nvidia RTX 2080 TI graphics processing unit (GPU). Moreover, NeuroUnlock recovers the architecture of various other obfuscated DNNs, such as the VGG-11, VGG-13, ResNet-20, and ResNet-32 networks. After recovering the architecture, NeuroUnlock automatically builds a near-equivalent DNN with only a 1.4% drop in the testing accuracy. We further show that launching a subsequent adversarial attack on the recovered DNNs boosts the success rate of the adversarial attack by 51.7% in average compared to launching it on the obfuscated versions. Additionally, we propose a novel methodology for DNN obfuscation, ReDLock, which eradicates the deterministic nature of the obfuscation and achieves 2.16X more resilience to the NeuroUnlock attack. We release the NeuroUnlock and the ReDLock as open-source frameworks. ",
    "url": "https://arxiv.org/abs/2206.00402",
    "authors": [
      "Mahya Morid Ahmadi",
      "Lilas Alrahis",
      "Alessio Colucci",
      "Ozgur Sinanoglu",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00416",
    "title": "In the Eye of the Beholder: Robust Prediction with Causal User Modeling",
    "abstract": "Accurately predicting the relevance of items to users is crucial to the success of many social platforms. Conventional approaches train models on logged historical data; but recommendation systems, media services, and online marketplaces all exhibit a constant influx of new content -- making relevancy a moving target, to which standard predictive models are not robust. In this paper, we propose a learning framework for relevance prediction that is robust to changes in the data distribution. Our key observation is that robustness can be obtained by accounting for how users causally perceive the environment. We model users as boundedly-rational decision makers whose causal beliefs are encoded by a causal graph, and show how minimal information regarding the graph can be used to contend with distributional changes. Experiments in multiple settings demonstrate the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2206.00416",
    "authors": [
      "Amir Feder",
      "Guy Horowitz",
      "Yoav Wald",
      "Roi Reichart",
      "Nir Rosenfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.00421",
    "title": "The Use of NLP-Based Text Representation Techniques to Support  Requirement Engineering Tasks: A Systematic Mapping Review",
    "abstract": "Natural Language Processing (NLP) is widely used to support the automation of different Requirements Engineering (RE) tasks. Most of the proposed approaches start with various NLP steps that analyze requirements statements, extract their linguistic information, and convert them to easy-to-process representations, such as lists of features or embedding-based vector representations. These NLP-based representations are usually used at a later stage as inputs for machine learning techniques or rule-based methods. Thus, requirements representations play a major role in determining the accuracy of different approaches. In this paper, we conducted a survey in the form of a systematic literature mapping (classification) to find out (1) what are the representations used in RE tasks literature, (2) what is the main focus of these works, (3) what are the main research directions in this domain, and (4) what are the gaps and potential future directions. After compiling an initial pool of 2,227 papers, and applying a set of inclusion/exclusion criteria, we obtained a final pool containing 104 relevant papers. Our survey shows that the research direction has changed from the use of lexical and syntactic features to the use of advanced embedding techniques, especially in the last two years. Using advanced embedding representations has proved its effectiveness in most RE tasks (such as requirement analysis, extracting requirements from reviews and forums, and semantic-level quality tasks). However, representations that are based on lexical and syntactic features are still more appropriate for other RE tasks (such as modeling and syntax-level quality tasks) since they provide the required information for the rules and regular expressions used when handling these tasks. In addition, we identify four gaps in the existing literature, why they matter, and how future research can begin to address them. ",
    "url": "https://arxiv.org/abs/2206.00421",
    "authors": [
      "Riad Sonbol",
      "Ghaida Rebdawi",
      "Nada Ghneim"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.00422",
    "title": "Edge Learning for B5G Networks with Distributed Signal Processing:  Semantic Communication, Edge Computing, and Wireless Sensing",
    "abstract": "To process and transfer large amounts of data in emerging wireless services, it has become increasingly appealing to exploit distributed data communication and learning. Specifically, edge learning (EL) enables local model training on geographically disperse edge nodes and minimizes the need for frequent data exchange. However, the current design of separating EL deployment and communication optimization does not yet reap the promised benefits of distributed signal processing, and sometimes suffers from excessive signalling overhead, long processing delay, and unstable learning convergence. In this paper, we provide an overview on practical distributed EL techniques and their interplay with advanced communication optimization designs. In particular, typical performance metrics for dual-functional learning and communication networks are discussed. Also, recent achievements of enabling techniques for the dual-functional design are surveyed with exemplifications from the mutual perspectives of \"communications for learning\" and \"learning for communications.\" The application of EL techniques within a variety of future communication systems are also envisioned for beyond 5G (B5G) wireless networks. For the application in goal-oriented semantic communication, we present a first mathematical model of the goal-oriented source entropy as an optimization problem. In addition, from the viewpoint of information theory, we identify fundamental open problems of characterizing rate regions for communication networks supporting distributed learning-and-computing tasks. We also present technical challenges as well as emerging application opportunities in this field, with the aim of inspiring future research and promoting widespread developments of EL in B5G. ",
    "url": "https://arxiv.org/abs/2206.00422",
    "authors": [
      "Wei Xu",
      "Zhaohui Yang",
      "Derrick Wing Kwan Ng",
      "Marco Levorato",
      "Yonina C. Eldar",
      "M'erouane Debbah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2206.00449",
    "title": "Ultrahyperbolic Knowledge Graph Embeddings",
    "abstract": "Recent knowledge graph (KG) embeddings have been advanced by hyperbolic geometry due to its superior capability for representing hierarchies. The topological structures of real-world KGs, however, are rather heterogeneous, i.e., a KG is composed of multiple distinct hierarchies and non-hierarchical graph structures. Therefore, a homogeneous (either Euclidean or hyperbolic) geometry is not sufficient for fairly representing such heterogeneous structures. To capture the topological heterogeneity of KGs, we present an ultrahyperbolic KG embedding (UltraE) in an ultrahyperbolic (or pseudo-Riemannian) manifold that seamlessly interleaves hyperbolic and spherical manifolds. In particular, we model each relation as a pseudo-orthogonal transformation that preserves the pseudo-Riemannian bilinear form. The pseudo-orthogonal transformation is decomposed into various operators (i.e., circular rotations, reflections and hyperbolic rotations), allowing for simultaneously modeling heterogeneous structures as well as complex relational patterns. Experimental results on three standard KGs show that UltraE outperforms previous Euclidean- and hyperbolic-based approaches. ",
    "url": "https://arxiv.org/abs/2206.00449",
    "authors": [
      "Bo Xiong",
      "Shichao Zhu",
      "Mojtaba Nayyeri",
      "Chengjin Xu",
      "Shirui Pan",
      "Chuan Zhou",
      "Steffen Staab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.00454",
    "title": "Towards Context-Aware Neural Performance-Score Synchronisation",
    "abstract": "Music can be represented in multiple forms, such as in the audio form as a recording of a performance, in the symbolic form as a computer readable score, or in the image form as a scan of the sheet music. Music synchronisation provides a way to navigate among multiple representations of music in a unified manner by generating an accurate mapping between them, lending itself applicable to a myriad of domains like music education, performance analysis, automatic accompaniment and music editing. Traditional synchronisation methods compute alignment using knowledge-driven and stochastic approaches, typically employing handcrafted features. These methods are often unable to generalise well to different instruments, acoustic environments and recording conditions, and normally assume complete structural agreement between the performances and the scores. This PhD furthers the development of performance-score synchronisation research by proposing data-driven, context-aware alignment approaches, on three fronts: Firstly, I replace the handcrafted features by employing a metric learning based approach that is adaptable to different acoustic settings and performs well in data-scarce conditions. Secondly, I address the handling of structural differences between the performances and scores, which is a common limitation of standard alignment methods. Finally, I eschew the reliance on both feature engineering and dynamic programming, and propose a completely data-driven synchronisation method that computes alignments using a neural framework, whilst also being robust to structural differences between the performances and scores. ",
    "url": "https://arxiv.org/abs/2206.00454",
    "authors": [
      "Ruchit Agrawal"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00471",
    "title": "Contrastive Principal Component Learning: Modeling Similarity by  Augmentation Overlap",
    "abstract": "Traditional self-supervised contrastive learning methods learn embeddings by pulling views of the same sample together and pushing views of different samples away. Since views of a sample are usually generated via data augmentations, the semantic relationship between samples is ignored. Based on the observation that semantically similar samples are more likely to have similar augmentations, we propose to measure similarity via the distribution of augmentations, i.e., how much the augmentations of two samples overlap. To handle the dimensional and computational complexity, we propose a novel Contrastive Principal Component Learning (CPCL) method composed of a contrastive-like loss and an on-the-fly projection loss to efficiently perform PCA on the augmentation feature, which encodes the augmentation distribution. By CPCL, the learned low-dimensional embeddings theoretically preserve the similarity of augmentation distribution between samples. Empirical results show our method can achieve competitive results against various traditional contrastive learning methods on different benchmarks. ",
    "url": "https://arxiv.org/abs/2206.00471",
    "authors": [
      "Lu Han",
      "Han-Jia Ye",
      "De-Chuan Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00477",
    "title": "Anti-Forgery: Towards a Stealthy and Robust DeepFake Disruption Attack  via Adversarial Perceptual-aware Perturbations",
    "abstract": "DeepFake is becoming a real risk to society and brings potential threats to both individual privacy and political security due to the DeepFaked multimedia are realistic and convincing. However, the popular DeepFake passive detection is an ex-post forensics countermeasure and failed in blocking the disinformation spreading in advance. To address this limitation, researchers study the proactive defense techniques by adding adversarial noises into the source data to disrupt the DeepFake manipulation. However, the existing studies on proactive DeepFake defense via injecting adversarial noises are not robust, which could be easily bypassed by employing simple image reconstruction revealed in a recent study MagDR. In this paper, we investigate the vulnerability of the existing forgery techniques and propose a novel \\emph{anti-forgery} technique that helps users protect the shared facial images from attackers who are capable of applying the popular forgery techniques. Our proposed method generates perceptual-aware perturbations in an incessant manner which is vastly different from the prior studies by adding adversarial noises that is sparse. Experimental results reveal that our perceptual-aware perturbations are robust to diverse image transformations, especially the competitive evasion technique, MagDR via image reconstruction. Our findings potentially open up a new research direction towards thorough understanding and investigation of perceptual-aware adversarial attack for protecting facial images against DeepFakes in a proactive and robust manner. We open-source our tool to foster future research. Code is available at https://github.com/AbstractTeen/AntiForgery/. ",
    "url": "https://arxiv.org/abs/2206.00477",
    "authors": [
      "Run Wang",
      "Ziheng Huang",
      "Zhikai Chen",
      "Li Liu",
      "Jing Chen",
      "Lina Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.00478",
    "title": "Weak consistency of P-time event graphs",
    "abstract": "P-time event graphs (P-TEGs) are event graphs where the residence time of tokens in places is bounded by specified time windows. In this paper, we define a new property of PTEGs, called weak consistency. In weakly consistent P-TEGs, the amount of times a transition can fire before the first violation of a time constraint can be made as large as desired. We show the practical implications of this property and, based on previous results in graph theory, we formulate an algorithm of strongly polynomial time complexity that verifies it. From this algorithm, it is possible to determine, in pseudo-polynomial time, the maximum number of firings before the first constraint violation in a P-TEG. ",
    "url": "https://arxiv.org/abs/2206.00478",
    "authors": [
      "Davide Zorzenon",
      "Ji\u0159\u00ed Balun",
      "J\u00f6rg Raisch"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2206.00481",
    "title": "Where are my Neighbors? Exploiting Patches Relations in Self-Supervised  Vision Transformer",
    "abstract": "Vision Transformers (ViTs) enabled the use of transformer architecture on vision tasks showing impressive performances when trained on big datasets. However, on relatively small datasets, ViTs are less accurate given their lack of inductive bias. To this end, we propose a simple but still effective self-supervised learning (SSL) strategy to train ViTs, that without any external annotation, can significantly improve the results. Specifically, we define a set of SSL tasks based on relations of image patches that the model has to solve before or jointly during the downstream training. Differently from ViT, our RelViT model optimizes all the output tokens of the transformer encoder that are related to the image patches, thus exploiting more training signal at each training step. We investigated our proposed methods on several image benchmarks finding that RelViT improves the SSL state-of-the-art methods by a large margin, especially on small datasets. ",
    "url": "https://arxiv.org/abs/2206.00481",
    "authors": [
      "Guglielmo Camporese",
      "Elena Izzo",
      "Lamberto Ballan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00488",
    "title": "Rotate the ReLU to implicitly sparsify deep networks",
    "abstract": "In the era of Deep Neural Network based solutions for a variety of real-life tasks, having a compact and energy-efficient deployable model has become fairly important. Most of the existing deep architectures use Rectifier Linear Unit (ReLU) activation. In this paper, we propose a novel idea of rotating the ReLU activation to give one more degree of freedom to the architecture. We show that this activation wherein the rotation is learned via training results in the elimination of those parameters/filters in the network which are not important for the task. In other words, rotated ReLU seems to be doing implicit sparsification. The slopes of the rotated ReLU activations act as coarse feature extractors and unnecessary features can be eliminated before retraining. Our studies indicate that features always choose to pass through a lesser number of filters in architectures such as ResNet and its variants. Hence, by rotating the ReLU, the weights or the filters that are not necessary are automatically identified and can be dropped thus giving rise to significant savings in memory and computation. Furthermore, in some cases, we also notice that along with saving in memory and computation we also obtain improvement over the reported performance of the corresponding baseline work in the popular datasets such as MNIST, CIFAR-10, CIFAR-100, and SVHN. ",
    "url": "https://arxiv.org/abs/2206.00488",
    "authors": [
      "Nancy Nayak",
      "Sheetal Kalyani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00489",
    "title": "Attack-Agnostic Adversarial Detection",
    "abstract": "The growing number of adversarial attacks in recent years gives attackers an advantage over defenders, as defenders must train detectors after knowing the types of attacks, and many models need to be maintained to ensure good performance in detecting any upcoming attacks. We propose a way to end the tug-of-war between attackers and defenders by treating adversarial attack detection as an anomaly detection problem so that the detector is agnostic to the attack. We quantify the statistical deviation caused by adversarial perturbations in two aspects. The Least Significant Component Feature (LSCF) quantifies the deviation of adversarial examples from the statistics of benign samples and Hessian Feature (HF) reflects how adversarial examples distort the landscape of the model's optima by measuring the local loss curvature. Empirical results show that our method can achieve an overall ROC AUC of 94.9%, 89.7%, and 94.6% on CIFAR10, CIFAR100, and SVHN, respectively, and has comparable performance to adversarial detectors trained with adversarial examples on most of the attacks. ",
    "url": "https://arxiv.org/abs/2206.00489",
    "authors": [
      "Jiaxin Cheng",
      "Mohamed Hussein",
      "Jay Billa",
      "Wael AbdAlmageed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00491",
    "title": "Semantic Room Wireframe Detection from a Single View",
    "abstract": "Reconstruction of indoor surfaces with limited texture information or with repeated textures, a situation common in walls and ceilings, may be difficult with a monocular Structure from Motion system. We propose a Semantic Room Wireframe Detection task to predict a Semantic Wireframe from a single perspective image. Such predictions may be used with shape priors to estimate the Room Layout and aid reconstruction. To train and test the proposed algorithm we create a new set of annotations from the simulated Structured3D dataset. We show qualitatively that the SRW-Net handles complex room geometries better than previous Room Layout Estimation algorithms while quantitatively out-performing the baseline in non-semantic Wireframe Detection. ",
    "url": "https://arxiv.org/abs/2206.00491",
    "authors": [
      "David Gillsj\u00f6",
      "Gabrielle Flood",
      "Kalle \u00c5str\u00f6m"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00502",
    "title": "Fast generation of simple directed social network graphs with reciprocal  edges and high clustering",
    "abstract": "Online social networks have emerged as useful tools to communicate or share information and news on a daily basis. One of the most popular networks is Twitter, where users connect to each other via directed follower relationships. Researchers have studied Twitter follower graphs and described them with various topological features. Collecting Twitter data, especially crawling the followers of users, is a tedious and time-consuming process and the data needs to be treated carefully due to its sensitive nature, containing personal user information. We therefore aim at the fast generation of synthetic directed social network graphs with reciprocal edges and high clustering. Our proposed method is based on a previously developed model, but relies on less hyperparameters and has a significantly lower runtime. Results show that the method does not only replicate the crawled directed Twitter graphs well w.r.t. several topological features and the application of an epidemics spreading process, but that it is also highly scalable which allows the fast creation of bigger graphs that exhibit similar properties as real-world networks. ",
    "url": "https://arxiv.org/abs/2206.00502",
    "authors": [
      "Christoph Schweimer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.00506",
    "title": "Proximally Sensitive Error for Anomaly Detection and Feature Learning",
    "abstract": "Mean squared error (MSE) is one of the most widely used metrics to expression differences between multi-dimensional entities, including images. However, MSE is not locally sensitive as it does not take into account the spatial arrangement of the (pixel) differences, which matters for structured data types like images. Such spatial arrangements carry information about the source of the differences; therefore, an error function that also incorporates the location of errors can lead to a more meaningful distance measure. We introduce Proximally Sensitive Error (PSE), through which we suggest that a regional emphasis in the error measure can 'highlight' semantic differences between images over syntactic/random deviations. We demonstrate that this emphasis can be leveraged upon for the task of anomaly/occlusion detection. We further explore its utility as a loss function to help a model focus on learning representations of semantic objects instead of minimizing syntactic reconstruction noise. ",
    "url": "https://arxiv.org/abs/2206.00506",
    "authors": [
      "Amogh Gudi",
      "Fritjof B\u00fcttner",
      "Jan van Gemert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00510",
    "title": "HIEN: Hierarchical Intention Embedding Network for Click-Through Rate  Prediction",
    "abstract": "Click-through rate (CTR) prediction plays an important role in online advertising and recommendation systems, which aims at estimating the probability of a user clicking on a specific item. Feature interaction modeling and user interest modeling methods are two popular domains in CTR prediction, and they have been studied extensively in recent years. However, these methods still suffer from two limitations. First, traditional methods regard item attributes as ID features, while neglecting structure information and relation dependencies among attributes. Second, when mining user interests from user-item interactions, current models ignore user intents and item intents for different attributes, which lacks interpretability. Based on this observation, in this paper, we propose a novel approach Hierarchical Intention Embedding Network (HIEN), which considers dependencies of attributes based on bottom-up tree aggregation in the constructed attribute graph. HIEN also captures user intents for different item attributes as well as item intents based on our proposed hierarchical attention mechanism. Extensive experiments on both public and production datasets show that the proposed model significantly outperforms the state-of-the-art methods. In addition, HIEN can be applied as an input module to state-of-the-art CTR prediction methods, bringing further performance lift for these existing models that might already be intensively used in real systems. ",
    "url": "https://arxiv.org/abs/2206.00510",
    "authors": [
      "Zuowu Zheng",
      "Changwang Zhang",
      "Xiaofeng Gao",
      "Guihai Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.00512",
    "title": "Neural Network Verification with Proof Production",
    "abstract": "Deep neural networks (DNNs) are increasingly being employed in safety-critical systems, and there is an urgent need to guarantee their correctness. Consequently, the verification community has devised multiple techniques and tools for verifying DNNs. When DNN verifiers discover an input that triggers an error, that is easy to confirm; but when they report that no error exists, there is no way to ensure that the verification tool itself is not flawed. As multiple errors have already been observed in DNN verification tools, this calls the applicability of DNN verification into question. In this work, we present a novel mechanism for enhancing Simplex-based DNN verifiers with proof production capabilities: the generation of an easy-to-check witness of unsatisfiability, which attests to the absence of errors. Our proof production is based on an efficient adaptation of the well-known Farkas' lemma, combined with mechanisms for handling piecewise-linear functions and numerical precision errors. As a proof of concept, we implemented our technique on top of the Marabou DNN verifier. Our evaluation on a safety-critical system for airborne collision avoidance shows that proof production succeeds in almost all cases and requires only minimal overhead. ",
    "url": "https://arxiv.org/abs/2206.00512",
    "authors": [
      "Omri Isac",
      "Clark Barrett",
      "Min Zhang",
      "Guy Katz"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00513",
    "title": "The robust way to stack and bag: the local Lipschitz way",
    "abstract": "Recent research has established that the local Lipschitz constant of a neural network directly influences its adversarial robustness. We exploit this relationship to construct an ensemble of neural networks which not only improves the accuracy, but also provides increased adversarial robustness. The local Lipschitz constants for two different ensemble methods - bagging and stacking - are derived and the architectures best suited for ensuring adversarial robustness are deduced. The proposed ensemble architectures are tested on MNIST and CIFAR-10 datasets in the presence of white-box attacks, FGSM and PGD. The proposed architecture is found to be more robust than a) a single network and b) traditional ensemble methods. ",
    "url": "https://arxiv.org/abs/2206.00513",
    "authors": [
      "Thulasi Tholeti",
      "Sheetal Kalyani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.00515",
    "title": "Landslide4Sense: Reference Benchmark Data and Deep Learning Models for  Landslide Detection",
    "abstract": "This study introduces \\textit{Landslide4Sense}, a reference benchmark for landslide detection from remote sensing. The repository features 3,799 image patches fusing optical layers from Sentinel-2 sensors with the digital elevation model and slope layer derived from ALOS PALSAR. The added topographical information facilitates an accurate detection of landslide borders, which recent researches have shown to be challenging using optical data alone. The extensive data set supports deep learning (DL) studies in landslide detection and the development and validation of methods for the systematic update of landslide inventories. The benchmark data set has been collected at four different times and geographical locations: Iburi (September 2018), Kodagu (August 2018), Gorkha (April 2015), and Taiwan (August 2009). Each image pixel is labelled as belonging to a landslide or not, incorporating various sources and thorough manual annotation. We then evaluate the landslide detection performance of 11 state-of-the-art DL segmentation models: U-Net, ResU-Net, PSPNet, ContextNet, DeepLab-v2, DeepLab-v3+, FCN-8s, LinkNet, FRRN-A, FRRN-B, and SQNet. All models were trained from scratch on patches from one quarter of each study area and tested on independent patches from the other three quarters. Our experiments demonstrate that ResU-Net outperformed the other models for the landslide detection task. We make the multi-source landslide benchmark data (Landslide4Sense) and the tested DL models publicly available at \\url{www.landslide4sense.org}, establishing an important resource for remote sensing, computer vision, and machine learning communities in studies of image classification in general and applications to landslide detection in particular. ",
    "url": "https://arxiv.org/abs/2206.00515",
    "authors": [
      "Omid Ghorbanzadeh",
      "Yonghao Xu",
      "Pedram Ghamis",
      "Michael Kopp",
      "David Kreil"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.00518",
    "title": "Efficient Scheduling of Data Augmentation for Deep Reinforcement  Learning",
    "abstract": "In deep reinforcement learning (RL), data augmentation is widely considered as a tool to induce a set of useful priors about semantic consistency and improve sample efficiency and generalization performance. However, even when the prior is useful for generalization, distilling it to RL agent often interferes with RL training and degenerates sample efficiency. Meanwhile, the agent is forgetful of the prior due to the non-stationary nature of RL. These observations suggest two extreme schedules of distillation: (i) over the entire training; or (ii) only at the end. Hence, we devise a stand-alone network distillation method to inject the consistency prior at any time (even after RL), and a simple yet efficient framework to automatically schedule the distillation. Specifically, the proposed framework first focuses on mastering train environments regardless of generalization by adaptively deciding which {\\it or no} augmentation to be used for the training. After this, we add the distillation to extract the remaining benefits for generalization from all the augmentations, which requires no additional new samples. In our experiments, we demonstrate the utility of the proposed framework, in particular, that considers postponing the augmentation to the end of RL training. ",
    "url": "https://arxiv.org/abs/2206.00518",
    "authors": [
      "Byungchan Ko",
      "Jungseul Ok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.00524",
    "title": "Vietnamese Hate and Offensive Detection using PhoBERT-CNN and Social  Media Streaming Data",
    "abstract": "Society needs to develop a system to detect hate and offense to build a healthy and safe environment. However, current research in this field still faces four major shortcomings, including deficient pre-processing techniques, indifference to data imbalance issues, modest performance models, and lacking practical applications. This paper focused on developing an intelligent system capable of addressing these shortcomings. Firstly, we proposed an efficient pre-processing technique to clean comments collected from Vietnamese social media. Secondly, a novel hate speech detection (HSD) model, which is the combination of a pre-trained PhoBERT model and a Text-CNN model, was proposed for solving tasks in Vietnamese. Thirdly, EDA techniques are applied to deal with imbalanced data to improve the performance of classification models. Besides, various experiments were conducted as baselines to compare and investigate the proposed model's performance against state-of-the-art methods. The experiment results show that the proposed PhoBERT-CNN model outperforms SOTA methods and achieves an F1-score of 67,46% and 98,45% on two benchmark datasets, ViHSD and HSD-VLSP, respectively. Finally, we also built a streaming HSD application to demonstrate the practicality of our proposed system. ",
    "url": "https://arxiv.org/abs/2206.00524",
    "authors": [
      "Khanh Q. Tran",
      "An T. Nguyen",
      "Phu Gia Hoang",
      "Canh Duc Luu",
      "Trong-Hop Do",
      "Kiet Van Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00535",
    "title": "Deepfake Caricatures: Amplifying attention to artifacts increases  deepfake detection by humans and machines",
    "abstract": "Deepfakes pose a serious threat to our digital society by fueling the spread of misinformation. It is essential to develop techniques that both detect them, and effectively alert the human user to their presence. Here, we introduce a novel deepfake detection framework that meets both of these needs. Our approach learns to generate attention maps of video artifacts, semi-supervised on human annotations. These maps make two contributions. First, they improve the accuracy and generalizability of a deepfake classifier, demonstrated across several deepfake detection datasets. Second, they allow us to generate an intuitive signal for the human user, in the form of \"Deepfake Caricatures\": transformations of the original deepfake video where attended artifacts are exacerbated to improve human recognition. Our approach, based on a mixture of human and artificial supervision, aims to further the development of countermeasures against fake visual content, and grants humans the ability to make their own judgment when presented with dubious visual media. ",
    "url": "https://arxiv.org/abs/2206.00535",
    "authors": [
      "Camilo Fosco",
      "Emilie Josephs",
      "Alex Andonian",
      "Allen Lee",
      "Xi Wang",
      "Aude Oliva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.00539",
    "title": "Privacy-Preserving Epidemiological Modeling on Mobile Graphs",
    "abstract": "Over the last two years, governments all over the world have used a variety of containment measures to control the spread of COVID-19, such as contact tracing, social distance regulations, and curfews. Epidemiological simulations are commonly used to assess the impact of those policies before they are implemented in actuality. Unfortunately, their predictive accuracy is hampered by the scarcity of relevant empirical data, concretely detailed social contact graphs. As this data is inherently privacy-critical, there is an urgent need for a method to perform powerful epidemiological simulations on real-world contact graphs without disclosing sensitive information. In this work, we present RIPPLE, a privacy-preserving epidemiological modeling framework that enables the execution of a wide range of standard epidemiological models for any infectious disease on a population's most recent real contact graph while keeping all contact information private locally on the participants' devices. In this regard, we also present PIR-SUM, a novel extension to private information retrieval that allows users to securely download the sum of a set of elements from a database rather than individual elements. Our theoretical constructs are supported by a proof-of-concept implementation in which we show that a 2-week simulation over a population of half a million can be finished in 7 minutes with each participant consuming less than 50 KB of data. ",
    "url": "https://arxiv.org/abs/2206.00539",
    "authors": [
      "Daniel G\u00fcnther",
      "Marco Holz",
      "Benjamin Judkewitz",
      "Helen M\u00f6llering",
      "Benny Pinkas",
      "Thomas Schneider",
      "Ajith Suresh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.00553",
    "title": "FETA: Fairness Enforced Verifying, Training, and Predicting Algorithms  for Neural Networks",
    "abstract": "Algorithmic decision making driven by neural networks has become very prominent in applications that directly affect people's quality of life. In this paper, we study the problem of verifying, training, and guaranteeing individual fairness of neural network models. A popular approach for enforcing fairness is to translate a fairness notion into constraints over the parameters of the model. However, such a translation does not always guarantee fair predictions of the trained neural network model. To address this challenge, we develop a counterexample-guided post-processing technique to provably enforce fairness constraints at prediction time. Contrary to prior work that enforces fairness only on points around test or train data, we are able to enforce and guarantee fairness on all points in the input domain. Additionally, we propose an in-processing technique to use fairness as an inductive bias by iteratively incorporating fairness counterexamples in the learning process. We have implemented these techniques in a tool called FETA. Empirical evaluation on real-world datasets indicates that FETA is not only able to guarantee fairness on-the-fly at prediction time but also is able to train accurate models exhibiting a much higher degree of individual fairness. ",
    "url": "https://arxiv.org/abs/2206.00553",
    "authors": [
      "Kiarash Mohammadi",
      "Aishwarya Sivaraman",
      "Golnoosh Farnadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2206.00557",
    "title": "A Near-Optimal Best-of-Both-Worlds Algorithm for Online Learning with  Feedback Graphs",
    "abstract": "We consider online learning with feedback graphs, a sequential decision-making framework where the learner's feedback is determined by a directed graph over the action set. We present a computationally efficient algorithm for learning in this framework that simultaneously achieves near-optimal regret bounds in both stochastic and adversarial environments. The bound against oblivious adversaries is $\\tilde{O} (\\sqrt{\\alpha T})$, where $T$ is the time horizon and $\\alpha$ is the independence number of the feedback graph. The bound against stochastic environments is $O\\big( (\\ln T)^2 \\max_{S\\in \\mathcal I(G)} \\sum_{i \\in S} \\Delta_i^{-1}\\big)$ where $\\mathcal I(G)$ is the family of all independent sets in a suitably defined undirected version of the graph and $\\Delta_i$ are the suboptimality gaps. The algorithm combines ideas from the EXP3++ algorithm for stochastic and adversarial bandits and the EXP3.G algorithm for feedback graphs with a novel exploration scheme. The scheme, which exploits the structure of the graph to reduce exploration, is key to obtain best-of-both-worlds guarantees with feedback graphs. We also extend our algorithm and results to a setting where the feedback graphs are allowed to change over time. ",
    "url": "https://arxiv.org/abs/2206.00557",
    "authors": [
      "Chlo\u00e9 Rouyer",
      "Dirk van der Hoeven",
      "Nicol\u00f2 Cesa-Bianchi",
      "Yevgeny Seldin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00568",
    "title": "RMT-Net: Reject-aware Multi-Task Network for Modeling  Missing-not-at-random Data in Financial Credit Scoring",
    "abstract": "In financial credit scoring, loan applications may be approved or rejected. We can only observe default/non-default labels for approved samples but have no observations for rejected samples, which leads to missing-not-at-random selection bias. Machine learning models trained on such biased data are inevitably unreliable. In this work, we find that the default/non-default classification task and the rejection/approval classification task are highly correlated, according to both real-world data study and theoretical analysis. Consequently, the learning of default/non-default can benefit from rejection/approval. Accordingly, we for the first time propose to model the biased credit scoring data with Multi-Task Learning (MTL). Specifically, we propose a novel Reject-aware Multi-Task Network (RMT-Net), which learns the task weights that control the information sharing from the rejection/approval task to the default/non-default task by a gating network based on rejection probabilities. RMT-Net leverages the relation between the two tasks that the larger the rejection probability, the more the default/non-default task needs to learn from the rejection/approval task. Furthermore, we extend RMT-Net to RMT-Net++ for modeling scenarios with multiple rejection/approval strategies. Extensive experiments are conducted on several datasets, and strongly verifies the effectiveness of RMT-Net on both approved and rejected samples. In addition, RMT-Net++ further improves RMT-Net's performances. ",
    "url": "https://arxiv.org/abs/2206.00568",
    "authors": [
      "Qiang Liu",
      "Yingtao Luo",
      "Shu Wu",
      "Zhen Zhang",
      "Xiangnan Yue",
      "Hong Jin",
      "Liang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)"
    ]
  },
  {
    "id": "arXiv:2206.00583",
    "title": "Calibrate and Debias Layer-wise Sampling for Graph Convolutional  Networks",
    "abstract": "To accelerate the training of graph convolutional networks (GCNs), many sampling-based methods have been developed for approximating the embedding aggregation. Among them, a layer-wise approach recursively performs importance sampling to select neighbors jointly for existing nodes in each layer. This paper revisits the approach from a matrix approximation perspective. We identify two issues in the existing layer-wise sampling methods: sub-optimal sampling probabilities and the approximation bias induced by sampling without replacement. We propose two remedies: new sampling probabilities and a debiasing algorithm, to address these issues, and provide the statistical analysis of the estimation variance. The improvements are demonstrated by extensive analyses and experiments on common benchmarks. ",
    "url": "https://arxiv.org/abs/2206.00583",
    "authors": [
      "Yifan Chen",
      "Tianning Xu",
      "Dilek Hakkani-Tur",
      "Di Jin",
      "Yun Yang",
      "Ruoqing Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00588",
    "title": "VTOL Failure Detection and Recovery by Utilizing Redundancy",
    "abstract": "Offering vertical take-off and landing (VTOL) capabilities and the ability to travel great distances are crucial for Urban Air Mobility (UAM) vehicles. These capabilities make hybrid VTOLs the clear front-runners among UAM platforms. On the other hand, concerns regarding the safety and reliability of autonomous aircraft have grown in response to the recent growth in aerial vehicle usage. As a result, monitoring the aircraft status to report any failures and recovering to prevent the loss of control when a failure happens are becoming increasingly important. Hybrid VTOLs can withstand some degree of actuator failure due to their intrinsic redundancy. Their aerodynamic performance, design, modeling, and control have all been addressed in the previous studies. However, research on their potential fault tolerance is still a less investigated field. In this workshop, we will present a summary of our work on aircraft fault detection and the recovery of our hybrid VTOL. First, we will go over our real-time aircraft-independent system for detecting actuator failures and abnormal behaviors. Then, in the context of our custom tiltrotor VTOL aircraft design, we talk about our optimization-based control allocation system, which utilizes the vehicle's configuration redundancy to recover from different actuation failures. Finally, we explore the ideas of how these parts can work together to provide a fail-safe system. We present our simulation and real-life experiments. ",
    "url": "https://arxiv.org/abs/2206.00588",
    "authors": [
      "Mohammadreza Mousaei",
      "Azarakhsh Keipour",
      "Junyi Geng",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.00606",
    "title": "Higher-Order Attention Networks",
    "abstract": "This paper introduces higher-order attention networks (HOANs), a novel class of attention-based neural networks defined on a generalized higher-order domain called a combinatorial complex (CC). Similar to hypergraphs, CCs admit arbitrary set-like relations between a collection of abstract entities. Simultaneously, CCs permit the construction of hierarchical higher-order relations analogous to those supported by cell complexes. Thus, CCs effectively generalize both hypergraphs and cell complexes and combine their desirable characteristics. By exploiting the rich combinatorial nature of CCs, HOANs define a new class of message-passing attention-based networks that unifies higher-order neural networks. Our evaluation on tasks related to mesh shape analysis and graph learning demonstrates that HOANs attain competitive, and in some examples superior, predictive performance in comparison to state-of-the-art neural networks. ",
    "url": "https://arxiv.org/abs/2206.00606",
    "authors": [
      "Mustafa Hajij",
      "Ghada Zamzmi",
      "Theodore Papamarkou",
      "Nina Miolane",
      "Aldo Guzm\u00e1n-S\u00e1enz",
      "Karthikeyan Natesan Ramamurthy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.00614",
    "title": "Dual-stream spatiotemporal networks with feature sharing for monitoring  animals in the home cage",
    "abstract": "This paper presents a spatiotemporal deep learning approach for mouse behavioural classification in the home cage. Using a series of dual-stream architectures with assorted modifications to increase performance, we introduce a novel feature-sharing approach that jointly processes the streams at regular intervals throughout the network. Using a publicly available labelled dataset of singly-housed mice, we achieve a prediction accuracy of 86.47% using an ensemble of Inception-based networks that utilize feature sharing. We also demonstrate through ablation studies that for all models, the feature-sharing architectures consistently perform better than conventional ones having separate streams. The best performing models were further evaluated on other activity datasets, both mouse and human, and achieved state-of-the-art results. Future work will investigate the effectiveness of feature sharing in behavioural classification in the unsupervised anomaly detection domain. ",
    "url": "https://arxiv.org/abs/2206.00614",
    "authors": [
      "Ezechukwu I. Nwokedi",
      "Rasneer S. Bains",
      "Luc Bidaut",
      "Xujiong Ye",
      "Sara Wells",
      "James M. Brown"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00619",
    "title": "Graph Machine Learning for Design of High-Octane Fuels",
    "abstract": "Fuels with high-knock resistance enable modern spark-ignition engines to achieve high efficiency and thus low CO2 emissions. Identification of molecules with desired autoignition properties indicated by a high research octane number and a high octane sensitivity is therefore of great practical relevance and can be supported by computer-aided molecular design (CAMD). Recent developments in the field of graph machine learning (graph-ML) provide novel, promising tools for CAMD. We propose a modular graph-ML CAMD framework that integrates generative graph-ML models with graph neural networks and optimization, enabling the design of molecules with desired ignition properties in a continuous molecular space. In particular, we explore the potential of Bayesian optimization and genetic algorithms in combination with generative graph-ML models. The graph-ML CAMD framework successfully identifies well-established high-octane components. It also suggests new candidates, one of which we experimentally investigate and use to illustrate the need for further auto-ignition training data. ",
    "url": "https://arxiv.org/abs/2206.00619",
    "authors": [
      "Jan G. Rittig",
      "Martin Ritzert",
      "Artur M. Schweidtmann",
      "Stefanie Winkler",
      "Jana M. Weber",
      "Philipp Morsch",
      "K. Alexander Heufer",
      "Martin Grohe",
      "Alexander Mitsos",
      "Manuel Dahmen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00630",
    "title": "Unifying Voxel-based Representation with Transformer for 3D Object  Detection",
    "abstract": "In this work, we present a unified framework for multi-modality 3D object detection, named UVTR. The proposed method aims to unify multi-modality representations in the voxel space for accurate and robust single- or cross-modality 3D detection. To this end, the modality-specific space is first designed to represent different inputs in the voxel feature space. Different from previous work, our approach preserves the voxel space without height compression to alleviate semantic ambiguity and enable spatial interactions. Benefit from the unified manner, cross-modality interaction is then proposed to make full use of inherent properties from different sensors, including knowledge transfer and modality fusion. In this way, geometry-aware expressions in point clouds and context-rich features in images are well utilized for better performance and robustness. The transformer decoder is applied to efficiently sample features from the unified space with learnable positions, which facilitates object-level interactions. In general, UVTR presents an early attempt to represent different modalities in a unified framework. It surpasses previous work in single- and multi-modality entries and achieves leading performance in the nuScenes test set with 69.7%, 55.1%, and 71.1% NDS for LiDAR, camera, and multi-modality inputs, respectively. Code is made available at https://github.com/dvlab-research/UVTR. ",
    "url": "https://arxiv.org/abs/2206.00630",
    "authors": [
      "Yanwei Li",
      "Yilun Chen",
      "Xiaojuan Qi",
      "Zeming Li",
      "Jian Sun",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00637",
    "title": "Graph Neural Networks with Precomputed Node Features",
    "abstract": "Most Graph Neural Networks (GNNs) cannot distinguish some graphs or indeed some pairs of nodes within a graph. This makes it impossible to solve certain classification tasks. However, adding additional node features to these models can resolve this problem. We introduce several such augmentations, including (i) positional node embeddings, (ii) canonical node IDs, and (iii) random features. These extensions are motivated by theoretical results and corroborated by extensive testing on synthetic subgraph detection tasks. We find that positional embeddings significantly outperform other extensions in these tasks. Moreover, positional embeddings have better sample efficiency, perform well on different graph distributions and even outperform learning with ground truth node positions. Finally, we show that the different augmentations perform competitively on established GNN benchmarks, and advise on when to use them. ",
    "url": "https://arxiv.org/abs/2206.00637",
    "authors": [
      "Beni Egressy",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00664",
    "title": "Hopular: Modern Hopfield Networks for Tabular Data",
    "abstract": "While Deep Learning excels in structured data as encountered in vision and natural language processing, it failed to meet its expectations on tabular data. For tabular data, Support Vector Machines (SVMs), Random Forests, and Gradient Boosting are the best performing techniques with Gradient Boosting in the lead. Recently, we saw a surge of Deep Learning methods that were tailored to tabular data but still underperform compared to Gradient Boosting on small-sized datasets. We suggest \"Hopular\", a novel Deep Learning architecture for medium- and small-sized datasets, where each layer is equipped with continuous modern Hopfield networks. The modern Hopfield networks use stored data to identify feature-feature, feature-target, and sample-sample dependencies. Hopular's novelty is that every layer can directly access the original input as well as the whole training set via stored data in the Hopfield networks. Therefore, Hopular can step-wise update its current model and the resulting prediction at every layer like standard iterative learning algorithms. In experiments on small-sized tabular datasets with less than 1,000 samples, Hopular surpasses Gradient Boosting, Random Forests, SVMs, and in particular several Deep Learning methods. In experiments on medium-sized tabular data with about 10,000 samples, Hopular outperforms XGBoost, CatBoost, LightGBM and a state-of-the art Deep Learning method designed for tabular data. Thus, Hopular is a strong alternative to these methods on tabular data. ",
    "url": "https://arxiv.org/abs/2206.00664",
    "authors": [
      "Bernhard Sch\u00e4fl",
      "Lukas Gruber",
      "Angela Bitto-Nemling",
      "Sepp Hochreiter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00665",
    "title": "MonoSDF: Exploring Monocular Geometric Cues for Neural Implicit Surface  Reconstruction",
    "abstract": "In recent years, neural implicit surface reconstruction methods have become popular for multi-view 3D reconstruction. In contrast to traditional multi-view stereo methods, these approaches tend to produce smoother and more complete reconstructions due to the inductive smoothness bias of neural networks. State-of-the-art neural implicit methods allow for high-quality reconstructions of simple scenes from many input views. Yet, their performance drops significantly for larger and more complex scenes and scenes captured from sparse viewpoints. This is caused primarily by the inherent ambiguity in the RGB reconstruction loss that does not provide enough constraints, in particular in less-observed and textureless areas. Motivated by recent advances in the area of monocular geometry prediction, we systematically explore the utility these cues provide for improving neural implicit surface reconstruction. We demonstrate that depth and normal cues, predicted by general-purpose monocular estimators, significantly improve reconstruction quality and optimization time. Further, we analyse and investigate multiple design choices for representing neural implicit surfaces, ranging from monolithic MLP models over single-grid to multi-resolution grid representations. We observe that geometric monocular priors improve performance both for small-scale single-object as well as large-scale multi-object scenes, independent of the choice of representation. ",
    "url": "https://arxiv.org/abs/2206.00665",
    "authors": [
      "Zehao Yu",
      "Songyou Peng",
      "Michael Niemeyer",
      "Torsten Sattler",
      "Andreas Geiger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00031",
    "title": "On the coset graph construction of distance-regular graphs",
    "abstract": "We show that no more new distance-regular graphs in the tables of the book of (Brouwer, Cohen, Neumaier, 1989) can be produced by using the coset graph of additive completely regular codes over finite fields. ",
    "url": "https://arxiv.org/abs/2206.00031",
    "authors": [
      "Minjia Shi",
      "Denis S. Krotov",
      "Patrick Sol\u00e9"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2206.00086",
    "title": "Extensive Study of Multiple Deep Neural Networks for Complex Random  Telegraph Signals",
    "abstract": "Time-fluctuating signals are ubiquitous and diverse in many physical, chemical, and biological systems, among which random telegraph signals (RTSs) refer to a series of instantaneous switching events between two discrete levels from single-particle movements. Reliable RTS analyses are crucial prerequisite to identify underlying mechanisms related to performance sensitivity. When numerous levels partake, complex patterns of multilevel RTSs occur, making their quantitative analysis exponentially difficult, hereby systematic approaches are found elusive. Here, we present a three-step analysis protocol via progressive knowledge-transfer, where the outputs of early step are passed onto a subsequent step. Especially, to quantify complex RTSs, we build three deep neural network architectures that can process temporal data well and demonstrate the model accuracy extensively with a large dataset of different RTS types affected by controlling background noise size. Our protocol offers structured schemes to quantify complex RTSs from which meaningful interpretation and inference can ensue. ",
    "url": "https://arxiv.org/abs/2206.00086",
    "authors": [
      "Marcel Robitaille",
      "HeeBong Yang",
      "Lu Wang",
      "Na Young Kim"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2206.00099",
    "title": "Provably and Practically Efficient Neural Contextual Bandits",
    "abstract": "We consider the neural contextual bandit problem. In contrast to the existing work which primarily focuses on ReLU neural nets, we consider a general set of smooth activation functions. Under this more general setting, (i) we derive non-asymptotic error bounds on the difference between an overparameterized neural net and its corresponding neural tangent kernel, (ii) we propose an algorithm with a provably sublinear regret bound that is also efficient in the finite regime as demonstrated by empirical studies. The non-asymptotic error bounds may be of broader interest as a tool to establish the relation between the smoothness of the activation functions in neural contextual bandits and the smoothness of the kernels in kernel bandits. ",
    "url": "https://arxiv.org/abs/2206.00099",
    "authors": [
      "Sudeep Salgia",
      "Sattar Vakili",
      "Qing Zhao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00241",
    "title": "Asymptotic Properties for Bayesian Neural Network in Besov Space",
    "abstract": "Neural networks have shown great predictive power when dealing with various unstructured data such as images and natural languages. The Bayesian neural network captures the uncertainty of prediction by putting a prior distribution for the parameter of the model and computing the posterior distribution. In this paper, we show that the Bayesian neural network using spike-and-slab prior has consistency with nearly minimax convergence rate when the true regression function is in the Besov space. Even when the smoothness of the regression function is unknown the same posterior convergence rate holds and thus the spike and slab prior is adaptive to the smoothness of the regression function. We also consider the shrinkage prior and show that it has the same convergence rate. In other words, we propose a practical Bayesian neural network with guaranteed asymptotic properties. ",
    "url": "https://arxiv.org/abs/2206.00241",
    "authors": [
      "Kyeongwon Lee",
      "Jaeyong Lee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2206.00305",
    "title": "Supervised Denoising of Diffusion-Weighted Magnetic Resonance Images  Using a Convolutional Neural Network and Transfer Learning",
    "abstract": "In this paper, we propose a method for denoising diffusion-weighted images (DWI) of the brain using a convolutional neural network trained on realistic, synthetic MR data. We compare our results to averaging of repeated scans, a widespread method used in clinics to improve signal-to-noise ratio of MR images. To obtain training data for transfer learning, we model, in a data-driven fashion, the effects of echo-planar imaging (EPI): Nyquist ghosting and ramp sampling. We introduce these effects to the digital phantom of brain anatomy (BrainWeb). Instead of simulating pseudo-random noise with a defined probability distribution, we perform noise scans with a brain-DWI-designed protocol to obtain realistic noise maps. We combine them with the simulated, noise-free EPI images. We also measure the Point Spread Function in a DW image of an AJR-approved geometrical phantom and inter-scan movement in a brain scan of a healthy volunteer. Their influence on image denoising and averaging of repeated images is investigated at different signal-to-noise ratio levels. Denoising performance is evaluated quantitatively using the simulated EPI images and qualitatively in real EPI DWI of the brain. We show that the application of our method allows for a significant reduction in scan time by lowering the number of repeated scans. Visual comparisons made in the acquired brain images indicate that the denoised single-repetition images are less noisy than multi-repetition averaged images. We also analyse the convolutional neural network denoiser and point out the challenges accompanying this denoising method. ",
    "url": "https://arxiv.org/abs/2206.00305",
    "authors": [
      "Jakub Jurek",
      "Andrzej Materka",
      "Kamil Ludwisiak",
      "Agata Majos",
      "Kamil Gorczewski",
      "Kamil Cepuch",
      "Agata Zawadzka"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00338",
    "title": "CellCentroidFormer: Combining Self-attention and Convolution for Cell  Detection",
    "abstract": "Cell detection in microscopy images is important to study how cells move and interact with their environment. Most recent deep learning-based methods for cell detection use convolutional neural networks (CNNs). However, inspired by the success in other computer vision applications, vision transformers (ViTs) are also used for this purpose. We propose a novel hybrid CNN-ViT model for cell detection in microscopy images to exploit the advantages of both types of deep learning models. We employ an efficient CNN, that was pre-trained on the ImageNet dataset, to extract image features and utilize transfer learning to reduce the amount of required training data. Extracted image features are further processed by a combination of convolutional and transformer layers, so that the convolutional layers can focus on local information and the transformer layers on global information. Our centroid-based cell detection method represents cells as ellipses and is end-to-end trainable. Furthermore, we show that our proposed model can outperform a fully convolutional baseline model on four different 2D microscopy datasets. Code is available at: https://github.com/roydenwa/cell-centroid-former ",
    "url": "https://arxiv.org/abs/2206.00338",
    "authors": [
      "Royden Wagner",
      "Karl Rohr"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00381",
    "title": "The statistical nature of h-index of a network node",
    "abstract": "Evaluating the importance of a network node is a crucial task in network science and graph data mining. H-index is a popular centrality measure for this task, however, there is still a lack of its interpretation from a rigorous statistical aspect. Here we show the statistical nature of h-index from the perspective of order statistics, and we obtain a new family of centrality indices by generalizing the h-index along this direction. The theoretical and empirical evidences show that such a statistical interpretation enables us to obtain a general and versatile framework for quantifying the importance of a network node. Under this framework, many new centrality indices can be derived and some of which can be more accurate and robust than h-index. We believe that this research opens up new avenues for developing more effective indices for node importance quantification from a viewpoint that still remains unexplored. ",
    "url": "https://arxiv.org/abs/2206.00381",
    "authors": [
      "Yan Liua",
      "Mudi Jianga",
      "Lianyu Hua",
      "Zengyou He"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2206.00455",
    "title": "A robust and lightweight deep attention multiple instance learning  algorithm for predicting genetic alterations",
    "abstract": "Deep-learning models based on whole-slide digital pathology images (WSIs) become increasingly popular for predicting molecular biomarkers. Instance-based models has been the mainstream strategy for predicting genetic alterations using WSIs although bag-based models along with self-attention mechanism-based algorithms have been proposed for other digital pathology applications. In this paper, we proposed a novel Attention-based Multiple Instance Mutation Learning (AMIML) model for predicting gene mutations. AMIML was comprised of successive 1-D convolutional layers, a decoder, and a residual weight connection to facilitate further integration of a lightweight attention mechanism to detect the most predictive image patches. Using data for 24 clinically relevant genes from four cancer cohorts in The Cancer Genome Atlas (TCGA) studies (UCEC, BRCA, GBM and KIRC), we compared AMIML with one popular instance-based model and four recently published bag-based models (e.g., CHOWDER, HE2RNA, etc.). AMIML demonstrated excellent robustness, not only outperforming all the five baseline algorithms in the vast majority of the tested genes (17 out of 24), but also providing near-best-performance for the other seven genes. Conversely, the performance of the baseline published algorithms varied across different cancers/genes. In addition, compared to the published models for genetic alterations, AMIML provided a significant improvement for predicting a wide range of genes (e.g., KMT2C, TP53, and SETD2 for KIRC; ERBB2, BRCA1, and BRCA2 for BRCA; JAK1, POLE, and MTOR for UCEC) as well as produced outstanding predictive models for other clinically relevant gene mutations, which have not been reported in the current literature. Furthermore, with the flexible and interpretable attention-based MIL pooling mechanism, AMIML could further zero-in and detect predictive image patches. ",
    "url": "https://arxiv.org/abs/2206.00455",
    "authors": [
      "Bangwei Guo",
      "Xingyu Li",
      "Miaomiao Yang",
      "Hong Zhang",
      "Xu Steven Xu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ]
  },
  {
    "id": "arXiv:2206.00566",
    "title": "The Fully Convolutional Transformer for Medical Image Segmentation",
    "abstract": "We propose a novel transformer model, capable of segmenting medical images of varying modalities. Challenges posed by the fine grained nature of medical image analysis mean that the adaptation of the transformer for their analysis is still at nascent stages. The overwhelming success of the UNet lay in its ability to appreciate the fine-grained nature of the segmentation task, an ability which existing transformer based models do not currently posses. To address this shortcoming, we propose The Fully Convolutional Transformer (FCT), which builds on the proven ability of Convolutional Neural Networks to learn effective image representations, and combines them with the ability of Transformers to effectively capture long-term dependencies in its inputs. The FCT is the first fully convolutional Transformer model in medical imaging literature. It processes its input in two stages, where first, it learns to extract long range semantic dependencies from the input image, and then learns to capture hierarchical global attributes from the features. FCT is compact, accurate and robust. Our results show that it outperforms all existing transformer architectures by large margins across multiple medical image segmentation datasets of varying data modalities without the need for any pre-training. FCT outperforms its immediate competitor on the ACDC dataset by 1.3%, on the Synapse dataset by 4.4%, on the Spleen dataset by 1.2% and on ISIC 2017 dataset by 1.1% on the dice metric, with up to five times fewer parameters. Our code, environments and models will be available via GitHub. ",
    "url": "https://arxiv.org/abs/2206.00566",
    "authors": [
      "Athanasios Tragakis",
      "Chaitanya Kaul",
      "Roderick Murray-Smith",
      "Dirk Husmeier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00579",
    "title": "Subexponential mixing for partition chains on grid-like graphs",
    "abstract": "We consider the problem of generating uniformly random partitions of the vertex set of a graph such that every piece induces a connected subgraph. For the case where we want to have partitions with linearly many pieces of bounded size, we obtain approximate sampling algorithms based on Glauber dynamics which are fixed-parameter tractable with respect to the bandwidth of $G$, with simple-exponential dependence on the bandwidth. For example, for rectangles of constant or logarithmic width this gives polynomial-time sampling algorithms. More generally, this gives sub-exponential algorithms for bounded-degree graphs without large expander subgraphs (for example, we obtain $O(2^{\\sqrt n})$ time algorithms for square grids). In the case where we instead want partitions with a small number of pieces of linear size, we show that Glauber dynamics can have exponential mixing time, even just for the case of 2 pieces, and even for 2-connected subgraphs of the grid with bounded bandwidth. ",
    "url": "https://arxiv.org/abs/2206.00579",
    "authors": [
      "Alan Frieze",
      "Wesley Pegden"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2206.00594",
    "title": "Sparse graphs with bounded induced cycle packing number have logarithmic  treewidth",
    "abstract": "A graph is $O_k$-free if it does not contain $k$ pairwise vertex-disjoint and non-adjacent cycles. We prove that \"sparse\" (here, not containing large complete bipartite graphs as subgraphs) $O_k$-free graphs have treewidth (even, feedback vertex set number) at most logarithmic in the number of vertices, which is sharp already for $k=2$. As a consequence, most of the central NP-complete problems (such as Maximum Independent Set, Minimum Vertex Cover, Minimum Dominating Set, Minimum Coloring) can be solved in polynomial time in these graphs, and in particular deciding the $O_k$-freeness of sparse graphs is polytime. ",
    "url": "https://arxiv.org/abs/2206.00594",
    "authors": [
      "Marthe Bonamy",
      "\u00c9douard Bonnet",
      "Hugues D\u00e9pr\u00e9s",
      "Louis Esperet",
      "Colin Geniet",
      "Claire Hilaire",
      "St\u00e9phan Thomass\u00e9",
      "Alexandra Wesolek"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2206.00648",
    "title": "A multimodal model with Twitter FinBERT embeddings for extreme price  movement prediction of Bitcoin",
    "abstract": "Bitcoin, with its ever-growing popularity, has demonstrated extreme price volatility since its origin. This volatility, together with its decentralised nature, make Bitcoin highly subjective to speculative trading as compared to more traditional assets. In this paper, we propose a multimodal model for predicting extreme price fluctuations. This model takes as input a variety of correlated assets, technical indicators, as well as Twitter content. In an in-depth study, we explore whether social media discussions from the general public on Bitcoin have predictive power for extreme price movements. A dataset of 5,000 tweets per day containing the keyword `Bitcoin' was collected from 2015 to 2021. This dataset, called PreBit, is made available online. In our hybrid model, we use sentence-level FinBERT embeddings, pretrained on financial lexicons, so as to capture the full contents of the tweets and feed it to the model in an understandable way. By combining these embeddings with a Convolutional Neural Network, we built a predictive model for significant market movements. The final multimodal ensemble model includes this NLP model together with a model based on candlestick data, technical indicators and correlated asset prices. In an ablation study, we explore the contribution of the individual modalities. Finally, we propose and backtest a trading strategy based on the predictions of our models with varying prediction threshold and show that it can used to build a profitable trading strategy with a reduced risk over a `hold' or moving average strategy. ",
    "url": "https://arxiv.org/abs/2206.00648",
    "authors": [
      "Yanzhao Zou",
      "Dorien Herremans"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1910.06708",
    "title": "Efficiently Embedding Dynamic Knowledge Graphs",
    "abstract": " Comments: 46 pages ",
    "url": "https://arxiv.org/abs/1910.06708",
    "authors": [
      "Tianxing Wu",
      "Arijit Khan",
      "Melvin Yong",
      "Guilin Qi",
      "Meng Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2009.13243",
    "title": "Generating End-to-End Adversarial Examples for Malware Classifiers Using  Explainability",
    "abstract": " Comments: Accepted as a conference paper at IJCNN 2020 ",
    "url": "https://arxiv.org/abs/2009.13243",
    "authors": [
      "Ishai Rosenberg",
      "Shai Meir",
      "Jonathan Berrebi",
      "Ilay Gordon",
      "Guillaume Sicard",
      "Eli David"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2011.10487",
    "title": "Normalization effects on shallow neural networks and related asymptotic  expansions",
    "abstract": " Comments: Added link to code on GitHub: this https URL ",
    "url": "https://arxiv.org/abs/2011.10487",
    "authors": [
      "Jiahui Yu",
      "Konstantinos Spiliopoulos"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2012.10559",
    "title": "Identifying the latent space geometry of network models through analysis  of curvature",
    "abstract": " Title: Identifying the latent space geometry of network models through analysis  of curvature ",
    "url": "https://arxiv.org/abs/2012.10559",
    "authors": [
      "Shane Lubold",
      "Arun G. Chandrasekhar",
      "Tyler H. McCormick"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)",
      "Geometric Topology (math.GT)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2104.00432",
    "title": "Anchor Pruning for Object Detection",
    "abstract": " Title: Anchor Pruning for Object Detection ",
    "url": "https://arxiv.org/abs/2104.00432",
    "authors": [
      "Maxim Bonnaerens",
      "Matthias Freiberger",
      "Joni Dambre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.02556",
    "title": "Physics-Informed Neural Nets for Control of Dynamical Systems",
    "abstract": " Title: Physics-Informed Neural Nets for Control of Dynamical Systems ",
    "url": "https://arxiv.org/abs/2104.02556",
    "authors": [
      "Eric Aislan Antonelo",
      "Eduardo Camponogara",
      "Laio Oriel Seman",
      "Eduardo Rehbein de Souza",
      "Jean P. Jordanou",
      "Jomi F. Hubner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.08567",
    "title": "Optimal Accounting of Differential Privacy via Characteristic Function",
    "abstract": " Title: Optimal Accounting of Differential Privacy via Characteristic Function ",
    "url": "https://arxiv.org/abs/2106.08567",
    "authors": [
      "Yuqing Zhu",
      "Jinshuo Dong",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2106.10151",
    "title": "The Dimpled Manifold Model of Adversarial Examples in Machine Learning",
    "abstract": " Title: The Dimpled Manifold Model of Adversarial Examples in Machine Learning ",
    "url": "https://arxiv.org/abs/2106.10151",
    "authors": [
      "Adi Shamir",
      "Odelia Melamed",
      "Oriel BenShmuel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.02363",
    "title": "Asymptotics of Network Embeddings Learned via Subsampling",
    "abstract": " Comments: 117 pages, 3 figures, 1 table ",
    "url": "https://arxiv.org/abs/2107.02363",
    "authors": [
      "Andrew Davison",
      "Morgane Austern"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2108.00356",
    "title": "Improving Social Meaning Detection with Pragmatic Masking and Surrogate  Fine-Tuning",
    "abstract": " Comments: 12th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis at ACL 2022 (corrected typos) ",
    "url": "https://arxiv.org/abs/2108.00356",
    "authors": [
      "Chiyu Zhang",
      "Muhammad Abdul-Mageed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2108.07467",
    "title": "Neonatal Bowel Sound Detection Using Convolutional Neural Network and  Laplace Hidden Semi-Markov Model",
    "abstract": " Comments: Published in IEEE/ACM Transactions on Audio Speech and Language Processing journal ",
    "url": "https://arxiv.org/abs/2108.07467",
    "authors": [
      "Chiranjibi Sitaula",
      "Jinyuan He",
      "Archana Priyadarshi",
      "Mark Tracy",
      "Omid Kavehei",
      "Murray Hinder",
      "Anusha Withana",
      "Alistair McEwan",
      "Faezeh Marzbanrad"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2108.07689",
    "title": "A multimodal sensor dataset for continuous stress detection of nurses in  a hospital",
    "abstract": " Comments: 14 pages, 9 images ",
    "url": "https://arxiv.org/abs/2108.07689",
    "authors": [
      "Seyedmajid Hosseini",
      "Satya Katragadda",
      "Ravi Teja Bhupatiraju",
      "Ziad Ashkar",
      "Christoph W. Borst",
      "Kenneth Cochran",
      "Raju Gottumukkala"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2109.03878",
    "title": "Unsupervised Detection and Clustering of Malicious TLS Flows",
    "abstract": " Title: Unsupervised Detection and Clustering of Malicious TLS Flows ",
    "url": "https://arxiv.org/abs/2109.03878",
    "authors": [
      "Gibran Gomez",
      "Platon Kotzias",
      "Matteo Dell'Amico",
      "Leyla Bilge",
      "Juan Caballero"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2109.08475",
    "title": "GoG: Relation-aware Graph-over-Graph Network for Visual Dialog",
    "abstract": " Comments: ACL Findings 2021. arXiv admin note: text overlap with arXiv:2109.06013 ",
    "url": "https://arxiv.org/abs/2109.08475",
    "authors": [
      "Feilong Chen",
      "Xiuyi Chen",
      "Fandong Meng",
      "Peng Li",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.08449",
    "title": "Adversarial Attacks on Gaussian Process Bandits",
    "abstract": " Comments: Accepted to ICML 2022 ",
    "url": "https://arxiv.org/abs/2110.08449",
    "authors": [
      "Eric Han",
      "Jonathan Scarlett"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.01526",
    "title": "A modified gravity model based on network efficiency for vital nodes  identification in complex networks",
    "abstract": " Title: A modified gravity model based on network efficiency for vital nodes  identification in complex networks ",
    "url": "https://arxiv.org/abs/2111.01526",
    "authors": [
      "Hanwen Li",
      "Qiuyan Shang",
      "Yong Deng"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.06682",
    "title": "A Bayesian Nash equilibrium-based moving target defense against stealthy  sensor attacks",
    "abstract": " Comments: 16 pages, 4 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2111.06682",
    "authors": [
      "David Umsonst",
      "Serkan Sar\u0131ta\u015f",
      "Gy\u00f6rgy D\u00e1n",
      "Henrik Sandberg"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2111.13149",
    "title": "A Comparative Analysis of Machine Learning Techniques for IoT Intrusion  Detection",
    "abstract": " Comments: 16 pages, 12 tables, 4 figures, FPS 2021 conference ",
    "url": "https://arxiv.org/abs/2111.13149",
    "authors": [
      "Jo\u00e3o Vitorino",
      "Rui Andrade",
      "Isabel Pra\u00e7a",
      "Orlando Sousa",
      "Eva Maia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.01583",
    "title": "The Representation Jensen-R\u00e9nyi Divergence",
    "abstract": " Comments: We added acknowledgments ",
    "url": "https://arxiv.org/abs/2112.01583",
    "authors": [
      "Jhoan Keider Hoyos Osorio",
      "Oscar Skean",
      "Austin J. Brockmeier",
      "Luis Gonzalo Sanchez Giraldo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2112.04150",
    "title": "BA-Net: Bridge Attention for Deep Convolutional Neural Networks",
    "abstract": " Title: BA-Net: Bridge Attention for Deep Convolutional Neural Networks ",
    "url": "https://arxiv.org/abs/2112.04150",
    "authors": [
      "Yue Zhao",
      "Junzhou Chen",
      "Zirui Zhang",
      "Ronghui Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.10325",
    "title": "Incremental Cross-view Mutual Distillation for Self-supervised Medical  CT Synthesis",
    "abstract": " Comments: Accepted by CVPR2022 ",
    "url": "https://arxiv.org/abs/2112.10325",
    "authors": [
      "Chaowei Fang",
      "Liang Wang",
      "Dingwen Zhang",
      "Jun Xu",
      "Yixuan Yuan",
      "Junwei Han"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.01689",
    "title": "Asymptotics of $\\ell_2$ Regularized Network Embeddings",
    "abstract": " Comments: 40 pages, 2 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2201.01689",
    "authors": [
      "Andrew Davison"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2201.06262",
    "title": "Optimisation of Structured Neural Controller Based on Continuous-Time  Policy Gradient",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2201.06262",
    "authors": [
      "Namhoon Cho",
      "Hyo-Sang Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2201.07459",
    "title": "Using Self-Supervised Pretext Tasks for Active Learning",
    "abstract": " Title: Using Self-Supervised Pretext Tasks for Active Learning ",
    "url": "https://arxiv.org/abs/2201.07459",
    "authors": [
      "John Seon Keun Yi",
      "Minseok Seo",
      "Jongchan Park",
      "Dong-Geol Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.09555",
    "title": "A Knowledge Graph Embeddings based Approach for Author Name  Disambiguation using Literals",
    "abstract": " Title: A Knowledge Graph Embeddings based Approach for Author Name  Disambiguation using Literals ",
    "url": "https://arxiv.org/abs/2201.09555",
    "authors": [
      "Cristian Santini",
      "Genet Asefa Gesese",
      "Silvio Peroni",
      "Aldo Gangemi",
      "Harald Sack",
      "Mehwish Alam"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2202.01999",
    "title": "Neural Dual Contouring",
    "abstract": " Comments: Accepted to SIGGRAPH (journal) 2022. Code: this https URL ",
    "url": "https://arxiv.org/abs/2202.01999",
    "authors": [
      "Zhiqin Chen",
      "Andrea Tagliasacchi",
      "Thomas Funkhouser",
      "Hao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02989",
    "title": "Graph Self-supervised Learning with Accurate Discrepancy Learning",
    "abstract": " Comments: 9 pages ",
    "url": "https://arxiv.org/abs/2202.02989",
    "authors": [
      "Dongki Kim",
      "Jinheon Baek",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.03613",
    "title": "Conformal prediction for the design problem",
    "abstract": " Comments: for associated code, see this https URL ",
    "url": "https://arxiv.org/abs/2202.03613",
    "authors": [
      "Clara Fannjiang",
      "Stephen Bates",
      "Anastasios N. Angelopoulos",
      "Jennifer Listgarten",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2202.03841",
    "title": "Width is Less Important than Depth in ReLU Neural Networks",
    "abstract": " Comments: Camera ready version in COLT 2022 ",
    "url": "https://arxiv.org/abs/2202.03841",
    "authors": [
      "Gal Vardi",
      "Gilad Yehudai",
      "Ohad Shamir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.12104",
    "title": "A Transformer-based Network for Deformable Medical Image Registration",
    "abstract": " Comments: 5 pages, 4 figures, 18 conferences ",
    "url": "https://arxiv.org/abs/2202.12104",
    "authors": [
      "Yibo Wang",
      "Wen Qian",
      "Xuming Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00551",
    "title": "Bayesian Optimisation for Robust Model Predictive Control under Model  Parameter Uncertainty",
    "abstract": " Comments: To appear in the 2022 IEEE International Conference on Robotics and Automation (ICRA), Philadelphia (PA), USA ",
    "url": "https://arxiv.org/abs/2203.00551",
    "authors": [
      "Rel Guzman",
      "Rafael Oliveira",
      "Fabio Ramos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.01845",
    "title": "MooAFEM: An object oriented Matlab code for higher-order adaptive FEM  for (nonlinear) elliptic PDEs",
    "abstract": " Title: MooAFEM: An object oriented Matlab code for higher-order adaptive FEM  for (nonlinear) elliptic PDEs ",
    "url": "https://arxiv.org/abs/2203.01845",
    "authors": [
      "Michael Innerberger",
      "Dirk Praetorius"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)"
    ]
  },
  {
    "id": "arXiv:2203.03673",
    "title": "AgraSSt: Approximate Graph Stein Statistics for Interpretable Assessment  of Implicit Graph Generators",
    "abstract": " Title: AgraSSt: Approximate Graph Stein Statistics for Interpretable Assessment  of Implicit Graph Generators ",
    "url": "https://arxiv.org/abs/2203.03673",
    "authors": [
      "Wenkai Xu",
      "Gesine Reinert"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.06925",
    "title": "WCL-BBCD: A Contrastive Learning and Knowledge Graph Approach to Named  Entity Recognition",
    "abstract": " Title: WCL-BBCD: A Contrastive Learning and Knowledge Graph Approach to Named  Entity Recognition ",
    "url": "https://arxiv.org/abs/2203.06925",
    "authors": [
      "Renjie Zhou",
      "Qiang Hu",
      "Jian Wan",
      "Jilin Zhang",
      "Qiang Liu",
      "Tianxiang Hu",
      "Jianjun Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.07524",
    "title": "Convolutional-Recurrent Neural Network Proxy for Robust Optimization and  Closed-Loop Reservoir Management",
    "abstract": " Comments: Corrected a typo (page 9, from '400 bar' to '320 bar') ",
    "url": "https://arxiv.org/abs/2203.07524",
    "authors": [
      "Yong Do Kim",
      "Louis J. Durlofsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10912",
    "title": "Depth Completion using Geometry-Aware Embedding",
    "abstract": " Comments: Accepted by ICRA22 ",
    "url": "https://arxiv.org/abs/2203.10912",
    "authors": [
      "Wenchao Du",
      "Hu Chen",
      "Hongyu Yang",
      "Yi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11055",
    "title": "backbone: An R package to extract network backbones",
    "abstract": " Title: backbone: An R package to extract network backbones ",
    "url": "https://arxiv.org/abs/2203.11055",
    "authors": [
      "Zachary P. Neal"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.13544",
    "title": "Performance evaluation of switching between WiFi and LiFi under a common  virtual network interface",
    "abstract": " Comments: 6 pages, 12 figures (including subfigures), 2 tables, conference paper ",
    "url": "https://arxiv.org/abs/2203.13544",
    "authors": [
      "Loreto Pescosolido",
      "Emilio Ancillotti",
      "Andrea Passarella"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.14260",
    "title": "Unsupervised Vision-Language Parsing: Seamlessly Bridging Visual Scene  Graphs with Language Structures via Dependency Relationships",
    "abstract": " Comments: Updated ",
    "url": "https://arxiv.org/abs/2203.14260",
    "authors": [
      "Chao Lou",
      "Wenjuan Han",
      "Yuhuan Lin",
      "Zilong Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.15177",
    "title": "Min-Max Similarity: A Contrastive Semi-Supervised Deep Learning Network  for Surgical Tools Segmentation",
    "abstract": " Title: Min-Max Similarity: A Contrastive Semi-Supervised Deep Learning Network  for Surgical Tools Segmentation ",
    "url": "https://arxiv.org/abs/2203.15177",
    "authors": [
      "Ange Lou",
      "Kareem Tawfik",
      "Xing Yao",
      "Ziteng Liu",
      "Jack Noble"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.15544",
    "title": "Graph Neural Networks are Dynamic Programmers",
    "abstract": " Comments: 15 pages, 2 figures. A significant extension of our contribution at ICLR'22 GroundedML and GTRL Workshops. Work in progress -- comments welcome! ",
    "url": "https://arxiv.org/abs/2203.15544",
    "authors": [
      "Andrew Dudzik",
      "Petar Veli\u010dkovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Category Theory (math.CT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.16027",
    "title": "Clozer: Adaptable Data Augmentation for Cloze-style Reading  Comprehension",
    "abstract": " Title: Clozer: Adaptable Data Augmentation for Cloze-style Reading  Comprehension ",
    "url": "https://arxiv.org/abs/2203.16027",
    "authors": [
      "Holy Lovenia",
      "Bryan Wilie",
      "Willy Chung",
      "Min Zeng",
      "Samuel Cahyawijaya",
      "Su Dan",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.02078",
    "title": "Semi-supervised Semantic Segmentation with Error Localization Network",
    "abstract": " Title: Semi-supervised Semantic Segmentation with Error Localization Network ",
    "url": "https://arxiv.org/abs/2204.02078",
    "authors": [
      "Donghyeon Kwon",
      "Suha Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05381",
    "title": "Self-supervised Vision Transformers for Joint SAR-optical Representation  Learning",
    "abstract": " Comments: 4 pages, 1 figure; IGARSS 2022 ",
    "url": "https://arxiv.org/abs/2204.05381",
    "authors": [
      "Yi Wang",
      "Conrad M Albrecht",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08612",
    "title": "Metamorphic Testing-based Adversarial Attack to Fool Deepfake Detectors",
    "abstract": " Comments: paper accepted at 26TH International Conference on Pattern Recognition (ICPR2022) ",
    "url": "https://arxiv.org/abs/2204.08612",
    "authors": [
      "Nyee Thoang Lim",
      "Meng Yi Kuan",
      "Muxin Pu",
      "Mei Kuan Lim",
      "Chun Yong Chong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08663",
    "title": "Pre-training of Equivariant Graph Matching Networks with Conformation  Flexibility for Drug Binding",
    "abstract": " Title: Pre-training of Equivariant Graph Matching Networks with Conformation  Flexibility for Drug Binding ",
    "url": "https://arxiv.org/abs/2204.08663",
    "authors": [
      "Fang Wu",
      "Shuting Jin",
      "Xurui Jin",
      "Xiangrong Liu",
      "Yinghui Jiang",
      "Zhangming Niu",
      "Qiang Zhang",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2204.10125",
    "title": "Physical Modeling using Recurrent Neural Networks with Fast  Convolutional Layers",
    "abstract": " Comments: Accepted to DAFx2022 ",
    "url": "https://arxiv.org/abs/2204.10125",
    "authors": [
      "Julian D. Parker",
      "Sebastian J. Schlecht",
      "Rudolf Rabenstein",
      "Maximilian Sch\u00e4fer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2204.11596",
    "title": "A Simple Structure For Building A Robust Model",
    "abstract": " Comments: Accepted by Fifth International Conference on Intelligence Science (ICIS2022); 10 pages, 3 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2204.11596",
    "authors": [
      "Xiao Tan",
      "Jingbo Gao",
      "Ruolin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01240",
    "title": "Using Constraint Programming and Graph Representation Learning for  Generating Interpretable Cloud Security Policies",
    "abstract": " Comments: to be published in IJCAI/ECAI'22 ",
    "url": "https://arxiv.org/abs/2205.01240",
    "authors": [
      "Mikhail Kazdagli",
      "Mohit Tiwari",
      "Akshat Kumar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.01681",
    "title": "Growing Isotropic Neural Cellular Automata",
    "abstract": " Title: Growing Isotropic Neural Cellular Automata ",
    "url": "https://arxiv.org/abs/2205.01681",
    "authors": [
      "Alexander Mordvintsev",
      "Ettore Randazzo",
      "Craig Fouts"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Cell Behavior (q-bio.CB)"
    ]
  },
  {
    "id": "arXiv:2205.04263",
    "title": "Spiking Neural Network Equalization for IM/DD Optical Communication",
    "abstract": " Title: Spiking Neural Network Equalization for IM/DD Optical Communication ",
    "url": "https://arxiv.org/abs/2205.04263",
    "authors": [
      "Elias Arnold",
      "Georg B\u00f6cherer",
      "Eric M\u00fcller",
      "Philipp Spilger",
      "Johannes Schemmel",
      "Stefano Calabr\u00f2",
      "Maxim Kuschnerov"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.06131",
    "title": "Framework for inferring empirical causal graphs from binary data to  support multidimensional poverty analysis",
    "abstract": " Comments: Revised some typos. The latest version of R package can be found at this https URL ",
    "url": "https://arxiv.org/abs/2205.06131",
    "authors": [
      "Chainarong Amornbunchornvej",
      "Navaporn Surasvadi",
      "Anon Plangprasopchok",
      "Suttipong Thajchayapong"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.09607",
    "title": "LAGr: Label Aligned Graphs for Better Systematic Generalization in  Semantic Parsing",
    "abstract": " Comments: published latest version of a paper that's already on arxiv instead of adding it as a new version. Please see arXiv:2110.07572 ",
    "url": "https://arxiv.org/abs/2205.09607",
    "authors": [
      "Dora Jambor",
      "Dzmitry Bahdanau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12493",
    "title": "Federated Self-supervised Learning for Heterogeneous Clients",
    "abstract": " Title: Federated Self-supervised Learning for Heterogeneous Clients ",
    "url": "https://arxiv.org/abs/2205.12493",
    "authors": [
      "Disha Makhija",
      "Nhat Ho",
      "Joydeep Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.13523",
    "title": "PerDoor: Persistent Non-Uniform Backdoors in Federated Learning using  Adversarial Perturbations",
    "abstract": " Title: PerDoor: Persistent Non-Uniform Backdoors in Federated Learning using  Adversarial Perturbations ",
    "url": "https://arxiv.org/abs/2205.13523",
    "authors": [
      "Manaar Alam",
      "Esha Sarkar",
      "Michail Maniatakos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.14109",
    "title": "Bayesian Robust Graph Contrastive Learning",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2106.04714 by other authors ",
    "url": "https://arxiv.org/abs/2205.14109",
    "authors": [
      "Yancheng Wang",
      "Yingzhen Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14375",
    "title": "WaveMix-Lite: A Resource-efficient Neural Network for Image Analysis",
    "abstract": " Comments: 17 pages, 5 figures. arXiv admin note: text overlap with arXiv:2203.03689 ",
    "url": "https://arxiv.org/abs/2205.14375",
    "authors": [
      "Pranav Jeevan",
      "Kavitha Viswanathan",
      "Amit Sethi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14625",
    "title": "Cervical Glandular Cell Detection from Whole Slide Image with  Out-Of-Distribution Data",
    "abstract": " Comments: 11 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2205.14625",
    "authors": [
      "Ziquan Wei",
      "Shenghua Cheng",
      "Jing Cai",
      "Shaoqun Zeng",
      "Xiuli Liu",
      "Zehua Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14831",
    "title": "Temporal Multiresolution Graph Neural Networks For Epidemic Prediction",
    "abstract": " Title: Temporal Multiresolution Graph Neural Networks For Epidemic Prediction ",
    "url": "https://arxiv.org/abs/2205.14831",
    "authors": [
      "Truong Son Hy",
      "Viet Bach Nguyen",
      "Long Tran-Thanh",
      "Risi Kondor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2205.15117",
    "title": "OOD Link Prediction Generalization Capabilities of Message-Passing GNNs  in Larger Test Graphs",
    "abstract": " Comments: Under submission ",
    "url": "https://arxiv.org/abs/2205.15117",
    "authors": [
      "Yangze Zhou",
      "Gitta Kutyniok",
      "Bruno Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.15364",
    "title": "Associative Learning Mechanism for Drug-Target Interaction Prediction",
    "abstract": " Comments: Revised and supplemented author information ",
    "url": "https://arxiv.org/abs/2205.15364",
    "authors": [
      "Zhiqin Zhu",
      "Zheng Yao",
      "Guanqiu Qi",
      "Neal Mazur",
      "Baisen Cong"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.15404",
    "title": "Gator: Customizable Channel Pruning of Neural Networks with Gating",
    "abstract": " Comments: 14 pages, 3 figures. The version that appeared in ICANN is an earlier version ",
    "url": "https://arxiv.org/abs/2205.15404",
    "authors": [
      "Eli Passov",
      "Eli David",
      "Nathan S. Netanyahu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.15638",
    "title": "Differentiable Invariant Causal Discovery",
    "abstract": " Comments: 22 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2205.15638",
    "authors": [
      "Yu Wang",
      "An Zhang",
      "Xiang Wang",
      "Xiangnan He",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2205.15688",
    "title": "Self-Supervised Learning for Building Damage Assessment from Large-scale  xBD Satellite Imagery Benchmark Datasets",
    "abstract": " Comments: 14 pages, 7 figures, DEXA 2022 ",
    "url": "https://arxiv.org/abs/2205.15688",
    "authors": [
      "Zaishuo Xia",
      "Zelin Li",
      "Yanbing Bai",
      "Jinze Yu",
      "Bruno Adriano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.15702",
    "title": "New theoretical insights in the decomposition and time-frequency  representation of nonstationary signals: the IMFogram algorithm",
    "abstract": " Title: New theoretical insights in the decomposition and time-frequency  representation of nonstationary signals: the IMFogram algorithm ",
    "url": "https://arxiv.org/abs/2205.15702",
    "authors": [
      "Antonio Cicone",
      "Wing Suet Li",
      "Haomin Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2205.15838",
    "title": "D$^2$NeRF: Self-Supervised Decoupling of Dynamic and Static Objects from  a Monocular Video",
    "abstract": " Title: D$^2$NeRF: Self-Supervised Decoupling of Dynamic and Static Objects from  a Monocular Video ",
    "url": "https://arxiv.org/abs/2205.15838",
    "authors": [
      "Tianhao Wu",
      "Fangcheng Zhong",
      "Andrea Tagliasacchi",
      "Forrester Cole",
      "Cengiz Oztireli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.15896",
    "title": "FedWalk: Communication Efficient Federated Unsupervised Node Embedding  with Differential Privacy",
    "abstract": " Comments: 10 pages, 8 figures, to be published in the Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining ",
    "url": "https://arxiv.org/abs/2205.15896",
    "authors": [
      "Qiying Pan",
      "Yifei Zhu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  }
]