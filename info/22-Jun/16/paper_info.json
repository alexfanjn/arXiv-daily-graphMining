[
  {
    "id": "arXiv:2206.07081",
    "title": "Applications of Generative Adversarial Networks in Neuroimaging and  Clinical Neuroscience",
    "abstract": "Generative adversarial networks (GANs) are one powerful type of deep learning models that have been successfully utilized in numerous fields. They belong to a broader family called generative methods, which generate new data with a probabilistic model by learning sample distribution from real examples. In the clinical context, GANs have shown enhanced capabilities in capturing spatially complex, nonlinear, and potentially subtle disease effects compared to traditional generative methods. This review appraises the existing literature on the applications of GANs in imaging studies of various neurological conditions, including Alzheimer's disease, brain tumors, brain aging, and multiple sclerosis. We provide an intuitive explanation of various GAN methods for each application and further discuss the main challenges, open questions, and promising future directions of leveraging GANs in neuroimaging. We aim to bridge the gap between advanced deep learning methods and neurology research by highlighting how GANs can be leveraged to support clinical decision making and contribute to a better understanding of the structural and functional patterns of brain diseases. ",
    "url": "https://arxiv.org/abs/2206.07081",
    "authors": [
      "Rongguang Wang",
      "Vishnu Bashyam",
      "Zhijian Yang",
      "Fanyang Yu",
      "Vasiliki Tassopoulou",
      "Lasya P. Sreepada",
      "Sai Spandana Chintapalli",
      "Dushyant Sahoo",
      "Ioanna Skampardoni",
      "Konstantina Nikita",
      "Ahmed Abdulkadir",
      "Junhao Wen",
      "Christos Davatzikos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.07089",
    "title": "A Collaboration Strategy in the Mining Pool for  Proof-of-Neural-Architecture Consensus",
    "abstract": "In most popular public accessible cryptocurrency systems, the mining pool plays a key role because mining cryptocurrency with the mining pool turns the non-profitable situation into profitable for individual miners. In many recent novel blockchain consensuses, the deep learning training procedure becomes the task for miners to prove their workload, thus the computation power of miners will not purely be spent on the hash puzzle. In this way, the hardware and energy will support the blockchain service and deep learning training simultaneously. While the incentive of miners is to earn tokens, individual miners are motivated to join mining pools to become more competitive. In this paper, we are the first to demonstrate a mining pool solution for novel consensuses based on deep learning. The mining pool manager partitions the full searching space into subspaces and all miners are scheduled to collaborate on the Neural Architecture Search (NAS) tasks in the assigned subspace. Experiments demonstrate that the performance of this type of mining pool is more competitive than an individual miner. Due to the uncertainty of miners' behaviors, the mining pool manager checks the standard deviation of the performance of high reward miners and prepares backup miners to ensure the completion of the tasks of high reward miners. ",
    "url": "https://arxiv.org/abs/2206.07089",
    "authors": [
      "Boyang Li",
      "Qing Lu",
      "Weiwen Jiang",
      "Taeho Jung",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07104",
    "title": "Most, And Least, Compact Spanning Trees of a Graph",
    "abstract": "We introduce the concept of Most, and Least, Compact Spanning Trees -- denoted respectively by $T^*(G)$ and $T^\\#(G)$ -- of a simple, connected, undirected and unweighted graph $G(V, E, W)$. For a spanning tree $T(G) \\in \\mathcal{T}(G)$ to be considered $T^*(G)$, where $\\mathcal{T}(G)$ represents the set of all the spanning trees of the graph $G$, it must have the least sum of inter-vertex pair shortest path distances from amongst the members of the set $\\mathcal{T}(G)$. Similarly, for it to be considered $T^\\#(G)$, it must have the highest sum of inter-vertex pair shortest path distances. In this work, we present an iteratively greedy rank-and-regress method that produces at least one $T^*(G)$ or $T^\\#(G)$ by eliminating one extremal edge per iteration.The rank function for performing the elimination is based on the elements of the matrix of relative forest accessibilities of a graph and the related forest distance. We provide empirical evidence in support of our methodology using some standard graph families; and discuss potentials for computational efficiencies, along with relevant trade-offs, to enable the extraction of $T^*(G)$ and $T^\\#(G)$ within reasonable time limits on standard platforms. ",
    "url": "https://arxiv.org/abs/2206.07104",
    "authors": [
      "Gyan Ranjan",
      "Nishant Saurabh",
      "Amit Ashutosh"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2206.07125",
    "title": "Self-Supervised Pretraining for Differentially Private Learning",
    "abstract": "We demonstrate self-supervised pretraining (SSP) is a scalable solution to deep learning with differential privacy (DP) regardless of the size of available public datasets in image classification. When facing the lack of public datasets, we show the features generated by SSP on only one single image enable a private classifier to obtain much better utility than the non-learned handcrafted features under the same privacy budget. When a moderate or large size public dataset is available, the features produced by SSP greatly outperform the features trained with labels on various complex private datasets under the same private budget. We also compared multiple DP-enabled training frameworks to train a private classifier on the features generated by SSP. Finally, we report a non-trivial utility 25.3\\% of a private ImageNet-1K dataset when $\\epsilon=3$. ",
    "url": "https://arxiv.org/abs/2206.07125",
    "authors": [
      "Arash Asadian",
      "Evan Weidner",
      "Lei Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.07144",
    "title": "Flatten the Curve: Efficiently Training Low-Curvature Neural Networks",
    "abstract": "The highly non-linear nature of deep neural networks causes them to be susceptible to adversarial examples and have unstable gradients which hinders interpretability. However, existing methods to solve these issues, such as adversarial training, are expensive and often sacrifice predictive accuracy. In this work, we consider curvature, which is a mathematical quantity which encodes the degree of non-linearity. Using this, we demonstrate low-curvature neural networks (LCNNs) that obtain drastically lower curvature than standard models while exhibiting similar predictive performance, which leads to improved robustness and stable gradients, with only a marginally increased training time. To achieve this, we minimize a data-independent upper bound on the curvature of a neural network, which decomposes overall curvature in terms of curvatures and slopes of its constituent layers. To efficiently minimize this bound, we introduce two novel architectural components: first, a non-linearity called centered-softplus that is a stable variant of the softplus non-linearity, and second, a Lipschitz-constrained batch normalization layer. Our experiments show that LCNNs have lower curvature, more stable gradients and increased off-the-shelf adversarial robustness when compared to their standard high-curvature counterparts, all without affecting predictive performance. Our approach is easy to use and can be readily incorporated into existing neural network models. ",
    "url": "https://arxiv.org/abs/2206.07144",
    "authors": [
      "Suraj Srinivas",
      "Kyle Matoba",
      "Himabindu Lakkaraju",
      "Francois Fleuret"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07150",
    "title": "Attacks on Perception-Based Control Systems: Modeling and Fundamental  Limits",
    "abstract": "In this work, we study performance of perception-based control systems in the presence of attacks. We focus on a wide class of stochastic nonlinear control systems, and provide methods for modeling and analysis of their resiliency to stealthy attacks on both physical and perception-based sensing. Specifically, we consider a general setup with a nonlinear affine physical plant controlled with a perception-based controller that maps both the physical sensor (e.g., IMUs) and perceptual (e.g., camera) measurements to the control input; in addition, the system is equipped with a statistical or learning-based anomaly detector (AD) to detect the presence of abnormal behaviours in the system. To enable general performance analysis, we model the attacks on perception and physical sensing in the most general form. Further, we introduce the notions of attack effectiveness and stealthiness that are independent of the employed AD; i.e., the attack remaining stealthy even from the best existing detectors. In such setting, we consider attacks with different levels of runtime knowledge about the plant and its states. We find sufficient conditions for existence of stealthy effective attacks that force the plant state into an unsafe region without being detected by any employed AD. We show that as the open-loop unstable plant dynamics diverges faster and the closed-loop system converges faster to an equilibrium point, the system will be more vulnerable to effective stealthy attacks. Specifically, we show that depending on runtime information available to the attacker, the probability of attack remaining stealthy (against any AD) can be arbitrarily close to one, if the attackers estimate of the plant state is arbitrarily close to the true plant state. ",
    "url": "https://arxiv.org/abs/2206.07150",
    "authors": [
      "Amir Khazraei",
      "Henry Pfister",
      "Miroslav Pajic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.07161",
    "title": "GraphFM: Improving Large-Scale GNN Training via Feature Momentum",
    "abstract": "Training of graph neural networks (GNNs) for large-scale node classification is challenging. A key difficulty lies in obtaining accurate hidden node representations while avoiding the neighborhood explosion problem. Here, we propose a new technique, named as feature momentum (FM), that uses a momentum step to incorporate historical embeddings when updating feature representations. We develop two specific algorithms, known as GraphFM-IB and GraphFM-OB, that consider in-batch and out-of-batch data, respectively. GraphFM-IB applies FM to in-batch sampled data, while GraphFM-OB applies FM to out-of-batch data that are 1-hop neighborhood of in-batch data. We provide a rigorous convergence analysis for GraphFM-IB and theoretical insight of GraphFM-OB for the estimation error of feature embeddings. Empirically, we observe that GraphFM-IB can effectively alleviate the neighborhood explosion problem of existing methods. In addition, GraphFM-OB achieves promising performance on multiple large-scale graph datasets. ",
    "url": "https://arxiv.org/abs/2206.07161",
    "authors": [
      "Haiyang Yu",
      "Limei Wang",
      "Bokun Wang",
      "Meng Liu",
      "Tianbao Yang",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.07162",
    "title": "Category-Agnostic 6D Pose Estimation with Conditional Neural Processes",
    "abstract": "We present a novel meta-learning approach for 6D pose estimation on unknown objects. In contrast to \"instance-level\" pose estimation methods, our algorithm learns object representation in a category-agnostic way, which endows it with strong generalization capabilities within and across object categories. Specifically, we employ a conditional neural process-based meta-learning approach to train an encoder to capture texture and geometry of an object in a latent representation, based on very few RGB-D images and ground-truth keypoints. The latent representation is then used by a simultaneously meta-trained decoder to predict the 6D pose of the object in new images. To evaluate our algorithm, experiments are conducted on our new fully-annotated synthetic datasets generated from Multiple Categories in Multiple Scenes (MCMS). Experimental results demonstrate that our model performs well on unseen objects with various shapes and appearances. ",
    "url": "https://arxiv.org/abs/2206.07162",
    "authors": [
      "Yumeng Li",
      "Ning Gao",
      "Hanna Ziesche",
      "Gerhard Neumann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.07179",
    "title": "Proximal Splitting Adversarial Attacks for Semantic Segmentation",
    "abstract": "Classification has been the focal point of research on adversarial attacks, but only a few works investigate methods suited to denser prediction tasks, such as semantic segmentation. The methods proposed in these works do not accurately solve the adversarial segmentation problem and, therefore, are overoptimistic in terms of size of the perturbations required to fool models. Here, we propose a white-box attack for these models based on a proximal splitting to produce adversarial perturbations with much smaller $\\ell_1$, $\\ell_2$, or $\\ell_\\infty$ norms. Our attack can handle large numbers of constraints within a nonconvex minimization framework via an Augmented Lagrangian approach, coupled with adaptive constraint scaling and masking strategies. We demonstrate that our attack significantly outperforms previously proposed ones, as well as classification attacks that we adapted for segmentation, providing a first comprehensive benchmark for this dense task. Our results push current limits concerning robustness evaluations in segmentation tasks. ",
    "url": "https://arxiv.org/abs/2206.07179",
    "authors": [
      "J\u00e9r\u00f4me Rony",
      "Jean-Christophe Pesquet",
      "Ismail Ben Ayed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07182",
    "title": "Automated Detection of Typed Links in Issue Trackers",
    "abstract": "Stakeholders in software projects use issue trackers like JIRA to capture and manage issues, including requirements and bugs. To ease issue navigation and structure project knowledge, stakeholders manually connect issues via links of certain types that reflect different dependencies, such as Epic-, Block-, Duplicate-, or Relate- links. Based on a large dataset of 15 JIRA repositories, we study how well state-of-the-art machine learning models can automatically detect common link types. We found that a pure BERT model trained on titles and descriptions of linked issues significantly outperforms other optimized deep learning models, achieving an encouraging average macro F1-score of 0.64 for detecting 9 popular link types across all repositories (weighted F1-score of 0.73). For the specific Subtask- and Epic- links, the model achieved top F1-scores of 0.89 and 0.97, respectively. Our model does not simply learn the textual similarity of the issues. In general, shorter issue text seems to improve the prediction accuracy with a strong negative correlation of -0.70. We found that Relate-links often get confused with the other links, which suggests that they are likely used as default links in unclear cases. We also observed significant differences across the repositories, depending on how they are used and by whom. ",
    "url": "https://arxiv.org/abs/2206.07182",
    "authors": [
      "Clara Marie L\u00fcders",
      "Tim Pietz",
      "Walid Maalej"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2206.07188",
    "title": "Defending Observation Attacks in Deep Reinforcement Learning via  Detection and Denoising",
    "abstract": "Neural network policies trained using Deep Reinforcement Learning (DRL) are well-known to be susceptible to adversarial attacks. In this paper, we consider attacks manifesting as perturbations in the observation space managed by the external environment. These attacks have been shown to downgrade policy performance significantly. We focus our attention on well-trained deterministic and stochastic neural network policies in the context of continuous control benchmarks subject to four well-studied observation space adversarial attacks. To defend against these attacks, we propose a novel defense strategy using a detect-and-denoise schema. Unlike previous adversarial training approaches that sample data in adversarial scenarios, our solution does not require sampling data in an environment under attack, thereby greatly reducing risk during training. Detailed experimental results show that our technique is comparable with state-of-the-art adversarial training approaches. ",
    "url": "https://arxiv.org/abs/2206.07188",
    "authors": [
      "Zikang Xiong",
      "Joe Eappen",
      "He Zhu",
      "Suresh Jagannathan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.07195",
    "title": "Tearing Apart NOTEARS: Controlling the Graph Prediction via Variance  Manipulation",
    "abstract": "Simulations are ubiquitous in machine learning. Especially in graph learning, simulations of Directed Acyclic Graphs (DAG) are being deployed for evaluating new algorithms. In the literature, it was recently argued that continuous-optimization approaches to structure discovery such as NOTEARS might be exploiting the sortability of the variable's variances in the available data due to their use of least square losses. Specifically, since structure discovery is a key problem in science and beyond, we want to be invariant to the scale being used for measuring our data (e.g. meter versus centimeter should not affect the causal direction inferred by the algorithm). In this work, we further strengthen this initial, negative empirical suggestion by both proving key results in the multivariate case and corroborating with further empirical evidence. In particular, we show that we can control the resulting graph with our targeted variance attacks, even in the case where we can only partially manipulate the variances of the data. ",
    "url": "https://arxiv.org/abs/2206.07195",
    "authors": [
      "Jonas Seng",
      "Matej Ze\u010devi\u0107",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07196",
    "title": "Towards a Solution to Bongard Problems: A Causal Approach",
    "abstract": "To date, Bongard Problems (BP) remain one of the few fortresses of AI history yet to be raided by the powerful models of the current era. We present a systematic analysis using modern techniques from the intersection of causality and AI/ML in a humble effort of reviving research around BPs. Specifically, we first compile the BPs into a Markov decision process, then secondly pose causal assumptions on the data generating process arguing for their applicability to BPs, and finally apply reinforcement learning techniques for solving the BPs subject to the causal assumptions. ",
    "url": "https://arxiv.org/abs/2206.07196",
    "authors": [
      "Salahedine Youssef",
      "Matej Ze\u010devi\u0107",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07197",
    "title": "Improving Solar Flare Prediction by Time Series Outlier Detection",
    "abstract": "Solar flares not only pose risks to outer space technologies and astronauts' well being, but also cause disruptions on earth to our hight-tech, interconnected infrastructure our lives highly depend on. While a number of machine-learning methods have been proposed to improve flare prediction, none of them, to the best of our knowledge, have investigated the impact of outliers on the reliability and those models' performance. In this study, we investigate the impact of outliers in a multivariate time series benchmark dataset, namely SWAN-SF, on flare prediction models, and test our hypothesis. That is, there exist outliers in SWAN-SF, removal of which enhances the performance of the prediction models on unseen datasets. We employ Isolation Forest to detect the outliers among the weaker flare instances. Several experiments are carried out using a large range of contamination rates which determine the percentage of present outliers. We asses the quality of each dataset in terms of its actual contamination using TimeSeriesSVC. In our best finding, we achieve a 279% increase in True Skill Statistic and 68% increase in Heidke Skill Score. The results show that overall a significant improvement can be achieved to flare prediction if outliers are detected and removed properly. ",
    "url": "https://arxiv.org/abs/2206.07197",
    "authors": [
      "Junzhi Wen",
      "Md Reazul Islam",
      "Azim Ahmadzadeh",
      "Rafal A. Angryk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Solar and Stellar Astrophysics (astro-ph.SR)"
    ]
  },
  {
    "id": "arXiv:2206.07203",
    "title": "Attributions Beyond Neural Networks: The Linear Program Case",
    "abstract": "Linear Programs (LPs) have been one of the building blocks in machine learning and have championed recent strides in differentiable optimizers for learning systems. While there exist solvers for even high-dimensional LPs, understanding said high-dimensional solutions poses an orthogonal and unresolved problem. We introduce an approach where we consider neural encodings for LPs that justify the application of attribution methods from explainable artificial intelligence (XAI) designed for neural learning systems. The several encoding functions we propose take into account aspects such as feasibility of the decision space, the cost attached to each input, or the distance to special points of interest. We investigate the mathematical consequences of several XAI methods on said neural LP encodings. We empirically show that the attribution methods Saliency and LIME reveal indistinguishable results up to perturbation levels, and we propose the property of Directedness as the main discriminative criterion between Saliency and LIME on one hand, and a perturbation-based Feature Permutation approach on the other hand. Directedness indicates whether an attribution method gives feature attributions with respect to an increase of that feature. We further notice the baseline selection problem beyond the classical computer vision setting for Integrated Gradients. ",
    "url": "https://arxiv.org/abs/2206.07203",
    "authors": [
      "Florian Peter Busch",
      "Matej Ze\u010devi\u0107",
      "Kristian Kersting",
      "Devendra Singh Dhami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07234",
    "title": "Brownian Noise Reduction: Maximizing Privacy Subject to Accuracy  Constraints",
    "abstract": "There is a disconnect between how researchers and practitioners handle privacy-utility tradeoffs. Researchers primarily operate from a privacy first perspective, setting strict privacy requirements and minimizing risk subject to these constraints. Practitioners often desire an accuracy first perspective, possibly satisfied with the greatest privacy they can get subject to obtaining sufficiently small error. Ligett et al. have introduced a \"noise reduction\" algorithm to address the latter perspective. The authors show that by adding correlated Laplace noise and progressively reducing it on demand, it is possible to produce a sequence of increasingly accurate estimates of a private parameter while only paying a privacy cost for the least noisy iterate released. In this work, we generalize noise reduction to the setting of Gaussian noise, introducing the Brownian mechanism. The Brownian mechanism works by first adding Gaussian noise of high variance corresponding to the final point of a simulated Brownian motion. Then, at the practitioner's discretion, noise is gradually decreased by tracing back along the Brownian path to an earlier time. Our mechanism is more naturally applicable to the common setting of bounded $\\ell_2$-sensitivity, empirically outperforms existing work on common statistical tasks, and provides customizable control of privacy loss over the entire interaction with the practitioner. We complement our Brownian mechanism with ReducedAboveThreshold, a generalization of the classical AboveThreshold algorithm that provides adaptive privacy guarantees. Overall, our results demonstrate that one can meet utility constraints while still maintaining strong levels of privacy. ",
    "url": "https://arxiv.org/abs/2206.07234",
    "authors": [
      "Justin Whitehouse",
      "Zhiwei Steven Wu",
      "Aaditya Ramdas",
      "Ryan Rogers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.07242",
    "title": "Coevolutionary Dynamics of Actions and Opinions in Social Networks",
    "abstract": "Modeling opinion formation and decision-making processes, important in their own rights, have been treated as separate problems in the study of dynamical models for social networks. Empirical studies suggest a deep intertwining between these two processes, and in this paper, we bridge the gap in the existing research by proposing a novel coevolutionary model. In the model, each individual can select an action from a binary set, and also holds an opinion on which action they prefer. Actions and opinions coevolve on a two-layer network structure. Under some reasonable assumptions on the network structure and asynchronous updating mechanics, we use rigorous analysis to establish that for all initial conditions, the actions converge in a finite number of time steps while opinions converge asymptotically. Next, we provide sufficient conditions for the emergence and the stability of polarized equilibria, whereby the population splits into two communities, each selecting and supporting one of the actions. Finally, numerical simulations are used to examine \"pluralistic ignorance\", whereby a social group incorrectly assumes the opinions of others due to the actions observed. ",
    "url": "https://arxiv.org/abs/2206.07242",
    "authors": [
      "Hassan Dehghani Aghbolagh",
      "Mengbin Ye",
      "Lorenzo Zino",
      "Ming Cao",
      "Zhiyong Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2206.07245",
    "title": "An Extractive-and-Abstractive Framework for Source Code Summarization",
    "abstract": "(Source) Code summarization aims to automatically generate summaries/comments for a given code snippet in the form of natural language. Such summaries play a key role in helping developers understand and maintain source code. Existing code summarization techniques can be categorized into extractive methods and abstractive methods. The extractive methods extract a subset of important statements and keywords from the code snippet using retrieval techniques, and generate a summary that preserves factual details in important statements and keywords. However, such a subset may miss identifier or entity naming, and consequently, the naturalness of generated summary is usually poor. The abstractive methods can generate human-written-like summaries leveraging encoder-decoder models from the neural machine translation domain. The generated summaries however often miss important factual details. To generate human-written-like summaries with preserved factual details, we propose a novel extractive-and-abstractive framework. The extractive module in the framework performs a task of extractive code summarization, which takes in the code snippet and predicts important statements containing key factual details. The abstractive module in the framework performs a task of abstractive code summarization, which takes in the entire code snippet and important statements in parallel and generates a succinct and human-written-like natural language summary. We evaluate the effectiveness of our technique, called EACS, by conducting extensive experiments on three datasets involving six programming languages. Experimental results show that EACS significantly outperforms state-of-the-art techniques in terms of all three widely used metrics, including BLEU, METEOR, and ROUGH-L. ",
    "url": "https://arxiv.org/abs/2206.07245",
    "authors": [
      "Weisong Sun",
      "Chunrong Fang",
      "Yuchen Chen",
      "Quanjun Zhang",
      "Guanhong Tao",
      "Tingxu Han",
      "Yifei Ge",
      "Yudu You",
      "Bin Luo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.07253",
    "title": "TeKo: Text-Rich Graph Neural Networks with External Knowledge",
    "abstract": "Graph Neural Networks (GNNs) have gained great popularity in tackling various analytical tasks on graph-structured data (i.e., networks). Typical GNNs and their variants follow a message-passing manner that obtains network representations by the feature propagation process along network topology, which however ignore the rich textual semantics (e.g., local word-sequence) that exist in many real-world networks. Existing methods for text-rich networks integrate textual semantics by mainly utilizing internal information such as topics or phrases/words, which often suffer from an inability to comprehensively mine the text semantics, limiting the reciprocal guidance between network structure and text semantics. To address these problems, we propose a novel text-rich graph neural network with external knowledge (TeKo), in order to take full advantage of both structural and textual information within text-rich networks. Specifically, we first present a flexible heterogeneous semantic network that incorporates high-quality entities and interactions among documents and entities. We then introduce two types of external knowledge, that is, structured triplets and unstructured entity description, to gain a deeper insight into textual semantics. We further design a reciprocal convolutional mechanism for the constructed heterogeneous semantic network, enabling network structure and textual semantics to collaboratively enhance each other and learn high-level network representations. Extensive experimental results on four public text-rich networks as well as a large-scale e-commerce searching dataset illustrate the superior performance of TeKo over state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2206.07253",
    "authors": [
      "Zhizhi Yu",
      "Di Jin",
      "Jianguo Wei",
      "Ziyang Liu",
      "Yue Shang",
      "Yun Xiao",
      "Jiawei Han",
      "Lingfei Wu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07259",
    "title": "Self-Supervised Learning of Image Scale and Orientation",
    "abstract": "We study the problem of learning to assign a characteristic pose, i.e., scale and orientation, for an image region of interest. Despite its apparent simplicity, the problem is non-trivial; it is hard to obtain a large-scale set of image regions with explicit pose annotations that a model directly learns from. To tackle the issue, we propose a self-supervised learning framework with a histogram alignment technique. It generates pairs of image patches by random rescaling/rotating and then train an estimator to predict their scale/orientation values so that their relative difference is consistent with the rescaling/rotating used. The estimator learns to predict a non-parametric histogram distribution of scale/orientation without any supervision. Experiments show that it significantly outperforms previous methods in scale/orientation estimation and also improves image matching and 6 DoF camera pose estimation by incorporating our patch poses into a matching process. ",
    "url": "https://arxiv.org/abs/2206.07259",
    "authors": [
      "Jongmin Lee",
      "Yoonwoo Jeong",
      "Minsu Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07269",
    "title": "Resource-Constrained Edge AI with Early Exit Prediction",
    "abstract": "By leveraging the data sample diversity, the early-exit network recently emerges as a prominent neural network architecture to accelerate the deep learning inference process. However, intermediate classifiers of the early exits introduce additional computation overhead, which is unfavorable for resource-constrained edge artificial intelligence (AI). In this paper, we propose an early exit prediction mechanism to reduce the on-device computation overhead in a device-edge co-inference system supported by early-exit networks. Specifically, we design a low-complexity module, namely the Exit Predictor, to guide some distinctly \"hard\" samples to bypass the computation of the early exits. Besides, considering the varying communication bandwidth, we extend the early exit prediction mechanism for latency-aware edge inference, which adapts the prediction thresholds of the Exit Predictor and the confidence thresholds of the early-exit network via a few simple regression models. Extensive experiment results demonstrate the effectiveness of the Exit Predictor in achieving a better tradeoff between accuracy and on-device computation overhead for early-exit networks. Besides, compared with the baseline methods, the proposed method for latency-aware edge inference attains higher inference accuracy under different bandwidth conditions. ",
    "url": "https://arxiv.org/abs/2206.07269",
    "authors": [
      "Rongkang Dong",
      "Yuyi Mao",
      "Jun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07272",
    "title": "Machine vision for vial positioning detection toward the safe automation  of material synthesis",
    "abstract": "Although robot-based automation in chemistry laboratories can accelerate the material development process, surveillance-free environments may lead to dangerous accidents primarily due to machine control errors. Object detection techniques can play vital roles in addressing these safety issues; however, state-of-the-art detectors, including single-shot detector (SSD) models, suffer from insufficient accuracy in environments involving complex and noisy scenes. With the aim of improving safety in a surveillance-free laboratory, we report a novel deep learning (DL)-based object detector, namely, DenseSSD. For the foremost and frequent problem of detecting vial positions, DenseSSD achieved a mean average precision (mAP) over 95% based on a complex dataset involving both empty and solution-filled vials, greatly exceeding those of conventional detectors; such high precision is critical to minimizing failure-induced accidents. Additionally, DenseSSD was observed to be highly insensitive to the environmental changes, maintaining its high precision under the variations of solution colors or testing view angles. The robustness of DenseSSD would allow the utilized equipment settings to be more flexible. This work demonstrates that DenseSSD is useful for enhancing safety in an automated material synthesis environment, and it can be extended to various applications where high detection accuracy and speed are both needed. ",
    "url": "https://arxiv.org/abs/2206.07272",
    "authors": [
      "Leslie Ching Ow Tiong",
      "Hyuk Jun Yoo",
      "Na Yeon Kim",
      "Kwan-Young Lee",
      "Sang Soo Han",
      "Donghun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2206.07278",
    "title": "Nebula Graph: An open source distributed graph database",
    "abstract": "This paper introduces the recent work of Nebula Graph, an open-source, distributed, scalable, and native graph database. We present a system design trade-off and a comprehensive overview of Nebula Graph internals, including graph data models, partitioning strategies, secondary indexes, optimizer rules, storage-side transactions, graph query languages, observability, graph processing frameworks, and visualization tool-kits. In addition, three sets of large-scale graph b ",
    "url": "https://arxiv.org/abs/2206.07278",
    "authors": [
      "Min Wu",
      "Xinglu Yi",
      "Hui Yu",
      "Yu Liu",
      "Yujue Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2206.07282",
    "title": "Human Eyes Inspired Recurrent Neural Networks are More Robust Against  Adversarial Noises",
    "abstract": "Compared to human vision, computer vision based on convolutional neural networks (CNN) are more vulnerable to adversarial noises. This difference is likely attributable to how the eyes sample visual input and how the brain processes retinal samples through its dorsal and ventral visual pathways, which are under-explored for computer vision. Inspired by the brain, we design recurrent neural networks, including an input sampler that mimics the human retina, a dorsal network that guides where to look next, and a ventral network that represents the retinal samples. Taking these modules together, the models learn to take multiple glances at an image, attend to a salient part at each glance, and accumulate the representation over time to recognize the image. We test such models for their robustness against a varying level of adversarial noises with a special focus on the effect of different input sampling strategies. Our findings suggest that retinal foveation and sampling renders a model more robust against adversarial noises, and the model may correct itself from an attack when it is given a longer time to take more glances at an image. In conclusion, robust visual recognition can benefit from the combined use of three brain-inspired mechanisms: retinal transformation, attention guided eye movement, and recurrent processing, as opposed to feedforward-only CNNs. ",
    "url": "https://arxiv.org/abs/2206.07282",
    "authors": [
      "Minkyu Choi",
      "Yizhen Zhang",
      "Kuan Han",
      "Xiaokai Wang",
      "Zhongming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07286",
    "title": "Faster Decomposition of Weighted Graphs into Cliques using Fisher's  Inequality",
    "abstract": "Mining groups of genes that consistently co-express is an important problem in biomedical research, where it is critical for applications such as drug-repositioning and designing new disease treatments. Recently, Cooley et al. modeled this problem as Exact Weighted Clique Decomposition (EWCD) in which, given an edge-weighted graph $G$ and a positive integer $k$, the goal is to decompose $G$ into at most $k$ (overlapping) weighted cliques so that an edge's weight is exactly equal to the sum of weights for cliques it participates in. They show EWCD is fixed-parameter-tractable, giving a $4^k$-kernel alongside a backtracking algorithm (together called cricca) to iteratively build a decomposition. Unfortunately, because of inherent exponential growth in the space of potential solutions, cricca is typically able to decompose graphs only when $k \\leq 11$. In this work, we establish reduction rules that exponentially decrease the size of the kernel (from $4^k$ to $k2^k$) for EWCD. In addition, we use insights about the structure of potential solutions to give new search rules that speed up the decomposition algorithm. At the core of our techniques is a result from combinatorial design theory called Fisher's inequality characterizing set systems with restricted intersections. We deploy our kernelization and decomposition algorithms (together called DeCAF) on a corpus of biologically-inspired data and obtain over two orders of magnitude speed-up over cricca. As a result, DeCAF scales to instances with $k \\geq 17$. ",
    "url": "https://arxiv.org/abs/2206.07286",
    "authors": [
      "Shweta Jain",
      "Yo Mizutani",
      "Blair Sullivan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2206.07289",
    "title": "Text-Aware End-to-end Mispronunciation Detection and Diagnosis",
    "abstract": "Mispronunciation detection and diagnosis (MDD) technology is a key component of computer-assisted pronunciation training system (CAPT). In the field of assessing the pronunciation quality of constrained speech, the given transcriptions can play the role of a teacher. Conventional methods have fully utilized the prior texts for the model construction or improving the system performance, e.g. forced-alignment and extended recognition networks. Recently, some end-to-end based methods attempt to incorporate the prior texts into model training and preliminarily show the effectiveness. However, previous studies mostly consider applying raw attention mechanism to fuse audio representations with text representations, without taking possible text-pronunciation mismatch into account. In this paper, we present a gating strategy that assigns more importance to the relevant audio features while suppressing irrelevant text information. Moreover, given the transcriptions, we design an extra contrastive loss to reduce the gap between the learning objective of phoneme recognition and MDD. We conducted experiments using two publicly available datasets (TIMIT and L2-Arctic) and our best model improved the F1 score from $57.51\\%$ to $61.75\\%$ compared to the baselines. Besides, we provide a detailed analysis to shed light on the effectiveness of gating mechanism and contrastive learning on MDD. ",
    "url": "https://arxiv.org/abs/2206.07289",
    "authors": [
      "Linkai Peng",
      "Yingming Gao",
      "Binghuai Lin",
      "Dengfeng Ke",
      "Yanlu Xie",
      "Jinsong Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.07293",
    "title": "FRCRN: Boosting Feature Representation using Frequency Recurrence for  Monaural Speech Enhancement",
    "abstract": "Convolutional recurrent networks (CRN) integrating a convolutional encoder-decoder (CED) structure and a recurrent structure have achieved promising performance for monaural speech enhancement. However, feature representation across frequency context is highly constrained due to limited receptive fields in the convolutions of CED. In this paper, we propose a convolutional recurrent encoder-decoder (CRED) structure to boost feature representation along the frequency axis. The CRED applies frequency recurrence on 3D convolutional feature maps along the frequency axis following each convolution, therefore, it is capable of catching long-range frequency correlations and enhancing feature representations of speech inputs. The proposed frequency recurrence is realized efficiently using a feedforward sequential memory network (FSMN). Besides the CRED, we insert two stacked FSMN layers between the encoder and the decoder to model further temporal dynamics. We name the proposed framework as Frequency Recurrent CRN (FRCRN). We design FRCRN to predict complex Ideal Ratio Mask (cIRM) in complex-valued domain and optimize FRCRN using both time-frequency-domain and time-domain losses. Our proposed approach achieved state-of-the-art performance on wideband benchmark datasets and achieved 2nd place for the real-time fullband track in terms of Mean Opinion Score (MOS) and Word Accuracy (WAcc) in the ICASSP 2022 Deep Noise Suppression (DNS) challenge. ",
    "url": "https://arxiv.org/abs/2206.07293",
    "authors": [
      "Shengkui Zhao",
      "Bin Ma",
      "Karn N. Watcharasupat",
      "Woon-Seng Gan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.07296",
    "title": "Enhanced Knowledge Selection for Grounded Dialogues via Document  Semantic Graphs",
    "abstract": "Providing conversation models with background knowledge has been shown to make open-domain dialogues more informative and engaging. Existing models treat knowledge selection as a sentence ranking or classification problem where each sentence is handled individually, ignoring the internal semantic connection among sentences in the background document. In this work, we propose to automatically convert the background knowledge documents into document semantic graphs and then perform knowledge selection over such graphs. Our document semantic graphs preserve sentence-level information through the use of sentence nodes and provide concept connections between sentences. We jointly apply multi-task learning for sentence-level and concept-level knowledge selection and show that it improves sentence-level selection. Our experiments show that our semantic graph-based knowledge selection improves over sentence selection baselines for both the knowledge selection task and the end-to-end response generation task on HollE and improves generalization on unseen topics in WoW. ",
    "url": "https://arxiv.org/abs/2206.07296",
    "authors": [
      "Sha Li",
      "Madhi Namazifar",
      "Di Jin",
      "Mohit Bansal",
      "Heng Ji",
      "Yang Liu",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.07298",
    "title": "S\\textsuperscript{2}-FPN: Scale-ware Strip Attention Guided Feature  Pyramid Network for Real-time Semantic Segmentation",
    "abstract": "Modern high-performance semantic segmentation methods employ a heavy backbone and dilated convolution to extract the relevant feature. Although extracting features with both contextual and semantic information is critical for the segmentation tasks, it brings a memory footprint and high computation cost for real-time applications. This paper presents a new model to achieve a trade-off between accuracy/speed for real-time road scene semantic segmentation. Specifically, we proposed a lightweight model named Scale-aware Strip Attention Guided Feature Pyramid Network (S\\textsuperscript{2}-FPN). Our network consists of three main modules: Attention Pyramid Fusion (APF) module, Scale-aware Strip Attention Module (SSAM), and Global Feature Upsample (GFU) module. APF adopts an attention mechanisms to learn discriminative multi-scale features and help close the semantic gap between different levels. APF uses the scale-aware attention to encode global context with vertical stripping operation and models the long-range dependencies, which helps relate pixels with similar semantic label. In addition, APF employs channel-wise reweighting block (CRB) to emphasize the channel features. Finally, the decoder of S\\textsuperscript{2}-FPN then adopts GFU, which is used to fuse features from APF and the encoder. Extensive experiments have been conducted on two challenging semantic segmentation benchmarks, which demonstrate that our approach achieves better accuracy/speed trade-off with different model settings. The proposed models have achieved a results of 76.2\\%mIoU/87.3FPS, 77.4\\%mIoU/67FPS, and 77.8\\%mIoU/30.5FPS on Cityscapes dataset, and 69.6\\%mIoU,71.0\\% mIoU, and 74.2\\% mIoU on Camvid dataset. The code for this work will be made available at \\url{https://github.com/mohamedac29/S2-FPN ",
    "url": "https://arxiv.org/abs/2206.07298",
    "authors": [
      "Mohammed A. M. Elhassan",
      "Chenhui Yang",
      "Chenxi Huang",
      "Tewodros Legesse Munea",
      "Xin Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.07303",
    "title": "Energetic Variational Neural Network Discretizations to Gradient Flows",
    "abstract": "We propose structure-preserving neural-network-based numerical schemes to solve both $L^2$-gradient flows and generalized diffusions. In more detail, by using neural networks as tools for spatial discretizations, we introduce a structure-preserving Eulerian algorithm to solve $L^2$-gradient flows and a structure-preserving Lagrangian algorithm to solve generalized diffusions. The Lagrangian algorithm for the generalized diffusion evolves the \"flow map\" which determines the dynamics of the generalized diffusion. This avoids computing the Wasserstein distance between two probability functions, which is non-trivial. The key ideas behind these schemes are to construct numerical discretizations based on the variational formulations of the gradient flows, i.e., the energy-dissipation laws, directly. More precisely, we construct minimizing movement schemes for these two types of gradient flow by introducing temporal discretization first, which is more efficient and convenient in neural-network-based implementations. The variational discretizations ensure the proper energy dissipation in numerical solutions and are crucial for the long-term stability of numerical computation. The neural-network-based spatial discretization enables us to solve these gradient flows in high dimensions. Various numerical experiments are presented to demonstrate the accuracy and energy stability of the proposed numerical approaches. ",
    "url": "https://arxiv.org/abs/2206.07303",
    "authors": [
      "Ziqing Hu",
      "Chun Liu",
      "Yiwei Wang",
      "Zhiliang Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2206.07311",
    "title": "Can pruning improve certified robustness of neural networks?",
    "abstract": "With the rapid development of deep learning, the sizes of neural networks become larger and larger so that the training and inference often overwhelm the hardware resources. Given the fact that neural networks are often over-parameterized, one effective way to reduce such computational overhead is neural network pruning, by removing redundant parameters from trained neural networks. It has been recently observed that pruning can not only reduce computational overhead but also can improve empirical robustness of deep neural networks (NNs), potentially owing to removing spurious correlations while preserving the predictive accuracies. This paper for the first time demonstrates that pruning can generally improve certified robustness for ReLU-based NNs under the complete verification setting. Using the popular Branch-and-Bound (BaB) framework, we find that pruning can enhance the estimated bound tightness of certified robustness verification, by alleviating linear relaxation and sub-domain split problems. We empirically verify our findings with off-the-shelf pruning methods and further present a new stability-based pruning method tailored for reducing neuron instability, that outperforms existing pruning methods in enhancing certified robustness. Our experiments show that by appropriately pruning an NN, its certified accuracy can be boosted up to 8.2% under standard training, and up to 24.5% under adversarial training on the CIFAR10 dataset. We additionally observe the existence of certified lottery tickets that can match both standard and certified robust accuracies of the original dense models across different datasets. Our findings offer a new angle to study the intriguing interaction between sparsity and robustness, i.e. interpreting the interaction of sparsity and certified robustness via neuron stability. Codes are available at: https://github.com/VITA-Group/CertifiedPruning. ",
    "url": "https://arxiv.org/abs/2206.07311",
    "authors": [
      "Zhangheng Li",
      "Tianlong Chen",
      "Linyi Li",
      "Bo Li",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07314",
    "title": "Fast and Reliable Evaluation of Adversarial Robustness with  Minimum-Margin Attack",
    "abstract": "The AutoAttack (AA) has been the most reliable method to evaluate adversarial robustness when considerable computational resources are available. However, the high computational cost (e.g., 100 times more than that of the project gradient descent attack) makes AA infeasible for practitioners with limited computational resources, and also hinders applications of AA in the adversarial training (AT). In this paper, we propose a novel method, minimum-margin (MM) attack, to fast and reliably evaluate adversarial robustness. Compared with AA, our method achieves comparable performance but only costs 3% of the computational time in extensive experiments. The reliability of our method lies in that we evaluate the quality of adversarial examples using the margin between two targets that can precisely identify the most adversarial example. The computational efficiency of our method lies in an effective Sequential TArget Ranking Selection (STARS) method, ensuring that the cost of the MM attack is independent of the number of classes. The MM attack opens a new way for evaluating adversarial robustness and provides a feasible and reliable way to generate high-quality adversarial examples in AT. ",
    "url": "https://arxiv.org/abs/2206.07314",
    "authors": [
      "Ruize Gao",
      "Jiongxiao Wang",
      "Kaiwen Zhou",
      "Feng Liu",
      "Binghui Xie",
      "Gang Niu",
      "Bo Han",
      "James Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.07321",
    "title": "Morphence-2.0: Evasion-Resilient Moving Target Defense Powered by  Out-of-Distribution Detection",
    "abstract": "Evasion attacks against machine learning models often succeed via iterative probing of a fixed target model, whereby an attack that succeeds once will succeed repeatedly. One promising approach to counter this threat is making a model a moving target against adversarial inputs. To this end, we introduce Morphence-2.0, a scalable moving target defense (MTD) powered by out-of-distribution (OOD) detection to defend against adversarial examples. By regularly moving the decision function of a model, Morphence-2.0 makes it significantly challenging for repeated or correlated attacks to succeed. Morphence-2.0 deploys a pool of models generated from a base model in a manner that introduces sufficient randomness when it responds to prediction queries. Via OOD detection, Morphence-2.0 is equipped with a scheduling approach that assigns adversarial examples to robust decision functions and benign samples to an undefended accurate models. To ensure repeated or correlated attacks fail, the deployed pool of models automatically expires after a query budget is reached and the model pool is seamlessly replaced by a new model pool generated in advance. We evaluate Morphence-2.0 on two benchmark image classification datasets (MNIST and CIFAR10) against 4 reference attacks (3 white-box and 1 black-box). Morphence-2.0 consistently outperforms prior defenses while preserving accuracy on clean data and reducing attack transferability. We also show that, when powered by OOD detection, Morphence-2.0 is able to precisely make an input-based movement of the model's decision function that leads to higher prediction accuracy on both adversarial and benign queries. ",
    "url": "https://arxiv.org/abs/2206.07321",
    "authors": [
      "Abderrahmen Amich",
      "Ata Kaboudi",
      "Birhanu Eshete"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07326",
    "title": "Recent Advances in Scene Image Representation and Classification",
    "abstract": "With the rise of deep learning algorithms nowadays, scene image representation methods on big data (e.g., SUN-397) have achieved a significant performance boost in classification. However, the performance is still limited because the scene images are mostly complex in nature having higher intra-class dissimilarity and inter-class similarity problems. To deal with such problems, there are several methods proposed in the literature with their own advantages and limitations. A detailed study of previous works is necessary to understand their pros and cons in image representation and classification. In this paper, we review the existing scene image representation methods that are being used widely for image classification. For this, we, first, devise the taxonomy using the seminal existing methods proposed in the literature to this date. Next, we compare their performance both qualitatively (e.g., quality of outputs, pros/cons, etc.) and quantitatively (e.g., accuracy). Last, we speculate the prominent research directions in scene image representation tasks. Overall, this survey provides in-depth insights and applications of recent scene image representation methods for traditional Computer Vision (CV)-based methods, Deep Learning (DL)-based methods, and Search Engine (SE)-based methods. ",
    "url": "https://arxiv.org/abs/2206.07326",
    "authors": [
      "Chiranjibi Sitaula",
      "Tej Bahadur Shahi",
      "Faezeh Marzbanrad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07328",
    "title": "A Survey : Neural Networks for AMR-to-Text",
    "abstract": "AMR-to-text is one of the key techniques in the NLP community that aims at generating sentences from the Abstract Meaning Representation (AMR) graphs. Since AMR was proposed in 2013, the study on AMR-to-Text has become increasingly prevalent as an essential branch of structured data to text because of the unique advantages of AMR as a high-level semantic description of natural language. In this paper, we provide a brief survey of AMR-to-Text. Firstly, we introduce the current scenario of this technique and point out its difficulties. Secondly, based on the methods used in previous studies, we roughly divided them into five categories according to their respective mechanisms, i.e., Rules-based, Seq-to-Seq-based, Graph-to-Seq-based, Transformer-based, and Pre-trained Language Model (PLM)-based. In particular, we detail the neural network-based method and present the latest progress of AMR-to-Text, which refers to AMR reconstruction, Decoder optimization, etc. Furthermore, we present the benchmarks and evaluation methods of AMR-to-Text. Eventually, we provide a summary of current techniques and the outlook for future research. ",
    "url": "https://arxiv.org/abs/2206.07328",
    "authors": [
      "Hongyu Hao",
      "Guangtong Li",
      "Zhiming Hu",
      "Huafeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07329",
    "title": "Application-Oriented Selection of Privacy Enhancing Technologies",
    "abstract": "To create privacy-friendly software designs, architects need comprehensive knowledge of existing privacy-enhancing technologies (PETs) and their properties. Existing works that systemize PETs, however, are outdated or focus on comparison criteria rather than providing guidance for their practical selection. In this short paper we present an enhanced classification of PETs that is more application-oriented than previous proposals. It integrates existing criteria like the privacy protection goal, and also considers practical criteria like the functional context, a technology's maturity, and its impact on various non-functional requirements. We expect that our classification simplifies the selection of PETs for experts and non-experts. ",
    "url": "https://arxiv.org/abs/2206.07329",
    "authors": [
      "Immanuel Kunz",
      "Andreas Binder"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.07331",
    "title": "ETMA: Efficient Transformer Based Multilevel Attention framework for  Multimodal Fake News Detection",
    "abstract": "In this new digital era, social media has created a severe impact on the lives of people. In recent times, fake news content on social media has become one of the major challenging problems for society. The dissemination of fabricated and false news articles includes multimodal data in the form of text and images. The previous methods have mainly focused on unimodal analysis. Moreover, for multimodal analysis, researchers fail to keep the unique characteristics corresponding to each modality. This paper aims to overcome these limitations by proposing an Efficient Transformer based Multilevel Attention (ETMA) framework for multimodal fake news detection, which comprises the following components: visual attention-based encoder, textual attention-based encoder, and joint attention-based learning. Each component utilizes the different forms of attention mechanism and uniquely deals with multimodal data to detect fraudulent content. The efficacy of the proposed network is validated by conducting several experiments on four real-world fake news datasets: Twitter, Jruvika Fake News Dataset, Pontes Fake News Dataset, and Risdal Fake News Dataset using multiple evaluation metrics. The results show that the proposed method outperforms the baseline methods on all four datasets. Further, the computation time of the model is also lower than the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2206.07331",
    "authors": [
      "Ashima Yadav",
      "Shivani Gaba",
      "Ishan Budhiraja",
      "Neeraj Kumar"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2206.07335",
    "title": "On Numerical Integration in Neural Ordinary Differential Equations",
    "abstract": "The combination of ordinary differential equations and neural networks, i.e., neural ordinary differential equations (Neural ODE), has been widely studied from various angles. However, deciphering the numerical integration in Neural ODE is still an open challenge, as many researches demonstrated that numerical integration significantly affects the performance of the model. In this paper, we propose the inverse modified differential equations (IMDE) to clarify the influence of numerical integration on training Neural ODE models. IMDE is determined by the learning task and the employed ODE solver. It is shown that training a Neural ODE model actually returns a close approximation of the IMDE, rather than the true ODE. With the help of IMDE, we deduce that (i) the discrepancy between the learned model and the true ODE is bounded by the sum of discretization error and learning loss; (ii) Neural ODE using non-symplectic numerical integration fail to learn conservation laws theoretically. Several experiments are performed to numerically verify our theoretical analysis. ",
    "url": "https://arxiv.org/abs/2206.07335",
    "authors": [
      "Aiqing Zhu",
      "Pengzhan Jin",
      "Beibei Zhu",
      "Yifa Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2206.07340",
    "title": "On the Design and Training Strategies for RNN-based Online Neural Speech  Separation Systems",
    "abstract": "While the performance of offline neural speech separation systems has been greatly advanced by the recent development of novel neural network architectures, there is typically an inevitable performance gap between the systems and their online variants. In this paper, we investigate how RNN-based offline neural speech separation systems can be changed into their online counterparts while mitigating the performance degradation. We decompose or reorganize the forward and backward RNN layers in a bidirectional RNN layer to form an online path and an offline path, which enables the model to perform both online and offline processing with a same set of model parameters. We further introduce two training strategies for improving the online model via either a pretrained offline model or a multitask training objective. Experiment results show that compared to the online models that are trained from scratch, the proposed layer decomposition and reorganization schemes and training strategies can effectively mitigate the performance gap between two RNN-based offline separation models and their online variants. ",
    "url": "https://arxiv.org/abs/2206.07340",
    "authors": [
      "Kai Li",
      "Yi Luo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.07344",
    "title": "Automatic Detection of Rice Disease in Images of Various Leaf Sizes",
    "abstract": "Fast, accurate and affordable rice disease detection method is required to assist rice farmers tackling equipment and expertise shortages problems. In this paper, we focused on the solution using computer vision technique to detect rice diseases from rice field photograph images. Dealing with images took in real-usage situation by general farmers is quite challenging due to various environmental factors, and rice leaf object size variation is one major factor caused performance gradation. To solve this problem, we presented a technique combining a CNN object detection with image tiling technique, based on automatically estimated width size of rice leaves in the images as a size reference for dividing the original input image. A model to estimate leaf width was created by small size CNN such as 18 layer ResNet architecture model. A new divided tiled sub-image set with uniformly sized object was generated and used as input for training a rice disease prediction model. Our technique was evaluated on 4,960 images of eight different types of rice leaf diseases, including blast, blight, brown spot, narrow brown spot, orange, red stripe, rice grassy stunt virus, and streak disease. The mean absolute percentage error (MAPE) for leaf width prediction task evaluated on all eight classes was 11.18% in the experiment, indicating that the leaf width prediction model performed well. The mean average precision (mAP) of the prediction performance on YOLOv4 architecture was enhanced from 87.56% to 91.14% when trained and tested with the tiled dataset. According to our study, the proposed image tiling technique improved rice disease detection efficiency. ",
    "url": "https://arxiv.org/abs/2206.07344",
    "authors": [
      "Kantip Kiratiratanapruk",
      "Pitchayagan Temniranrat",
      "Wasin Sinthupinyo",
      "Sanparith Marukatat",
      "Sujin Patarapuwadol"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07347",
    "title": "On the Use of Deep Mask Estimation Module for Neural Source Separation  Systems",
    "abstract": "Most of the recent neural source separation systems rely on a masking-based pipeline where a set of multiplicative masks are estimated from and applied to a signal representation of the input mixture. The estimation of such masks, in almost all network architectures, is done by a single layer followed by an optional nonlinear activation function. However, recent literatures have investigated the use of a deep mask estimation module and observed performance improvement compared to a shallow mask estimation module. In this paper, we analyze the role of such deeper mask estimation module by connecting it to a recently proposed unsupervised source separation method, and empirically show that the deep mask estimation module is an efficient approximation of the so-called overseparation-grouping paradigm with the conventional shallow mask estimation layers. ",
    "url": "https://arxiv.org/abs/2206.07347",
    "authors": [
      "Kai Li",
      "Xiaolin Hu",
      "Yi Luo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.07348",
    "title": "Unsupervised Capsule Networks of High-Dimension Point Clouds  classification",
    "abstract": "Three-dimensional point clouds learning is widely applied, but the point clouds are still unable to deal with classification and recognition tasks satisfactorily in the cases of irregular geometric structures and high-dimensional space. In 3D space, point clouds tend to have regular Euclidean structure because of their density. On the contrary, due to the high dimensionality, the spatial structure of high-dimensional space is more complex, and point clouds are mostly presented in non-European structure. Furthermore, among current 3D point clouds classification algorithms, Canonical Capsules algorithm based on Euclidean distance is difficult to decompose and identify non-Euclidean structures effectively. Thus, aiming at the point clouds classification task of non-Euclidean structure in 3D and high-dimensional space, this paper refers to the LLE algorithm based on geodesic distance for optimizing and proposes the unsupervised algorithm of high-dimensional point clouds capsule. In this paper, the geometric features of point clouds are considered in the extraction process, so as to transform the high-dimensional non-Euclidean structure into a lower-dimensional Euclidean structure with retaining spatial geometric features. To verify the feasibility of the unsupervised algorithm of high-dimensional point clouds capsule, experiments are conducted in Swiss Roll dataset, point clouds MNIST dataset and point clouds LFW dataset. The results show that (1) non-Euclidean structures can be can effectively identified by this model in Swiss Roll dataset; (2) a significant unsupervised learning effect is realized in point clouds MNIST dataset. In conclusion, the high-dimensional point clouds capsule unsupervised algorithm proposed in this paper is conducive to expand the application scenarios of current point clouds classification and recognition tasks. ",
    "url": "https://arxiv.org/abs/2206.07348",
    "authors": [
      "Quanfeng Xu",
      "Yi Tang",
      "Yan Yang",
      "Yumei She",
      "Zuo Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.07350",
    "title": "A Fast Heuristic for Computing Geodesic Cores in Large Networks",
    "abstract": "Motivated by the increasing interest in applications of graph geodesic convexity in machine learning and data mining, we present a heuristic for computing the geodesic convex hull of node sets in networks. It generates a set of almost maximal outerplanar spanning subgraphs for the input graph, computes the geodesic closure in each of these graphs, and regards a node as an element of the convex hull if it belongs to the closed sets for at least a user specified number of outerplanar graphs. Our heuristic algorithm runs in time linear in the number of edges of the input graph, i.e., it is faster with one order of magnitude than the standard algorithm computing the closure exactly. Its performance is evaluated empirically by approximating convexity based core-periphery decomposition of networks. Our experimental results with large real-world networks show that for most networks, the proposed heuristic was able to produce close approximations significantly faster than the standard algorithm computing the exact convex hulls. For example, while our algorithm calculated an approximate core-periphery decomposition in 5 hours or less for networks with more than 20 million edges, the standard algorithm did not terminate within 50 days. ",
    "url": "https://arxiv.org/abs/2206.07350",
    "authors": [
      "Florian Seiffarth",
      "Tam\u00e1s Horv\u00e1th",
      "Stefan Wrobel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.07352",
    "title": "Robust SAR ATR on MSTAR with Deep Learning Models trained on Full  Synthetic MOCEM data",
    "abstract": "The promising potential of Deep Learning for Automatic Target Recognition (ATR) on Synthetic Aperture Radar (SAR) images vanishes when considering the complexity of collecting training datasets measurements. Simulation can overcome this issue by producing synthetic training datasets. However, because of the limited representativeness of simulation, models trained in a classical way with synthetic images have limited generalization abilities when dealing with real measurement at test time. Previous works identified a set of equally promising deep-learning algorithms to tackle this issue. However, these approaches have been evaluated in a very favorable scenario with a synthetic training dataset that overfits the ground truth of the measured test data. In this work, we study the ATR problem outside of this ideal condition, which is unlikely to occur in real operational contexts. Our contribution is threefold. (1) Using the MOCEM simulator (developed by SCALIAN DS for the French MoD/DGA), we produce a synthetic MSTAR training dataset that differs significantly from the real measurements. (2) We experimentally demonstrate the limits of the state-of-the-art. (3) We show that domain randomization techniques and adversarial training can be combined to overcome this issue. We demonstrate that this approach is more robust than the state-of-the-art, with an accuracy of 75 %, while having a limited impact on computing performance during training. ",
    "url": "https://arxiv.org/abs/2206.07352",
    "authors": [
      "Benjamin Camus",
      "Corentin Le Barbu",
      "Eric Monteux"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.07358",
    "title": "The Complexity of Contracting Bipartite Graphs into Small Cycles",
    "abstract": "For a positive integer $\\ell \\geq 3$, the $C_\\ell$-Contractibility problem takes as input an undirected simple graph $G$ and determines whether $G$ can be transformed into a graph isomorphic to $C_\\ell$ (the induced cycle on $\\ell$ vertices) using only edge contractions. Brouwer and Veldman [JGT 1987] showed that $C_4$-Contractibility is NP-complete in general graphs. It is easy to verify that $C_3$-Contractibility is polynomial-time solvable. Dabrowski and Paulusma [IPL 2017] showed that $C_{\\ell}$-Contractibility is \\NP-complete\\ on bipartite graphs for $\\ell = 6$ and posed as open problems the status of the problem when $\\ell$ is 4 or 5. In this paper, we show that both $C_5$-Contractibility and $C_4$-Contractibility are NP-complete on bipartite graphs. ",
    "url": "https://arxiv.org/abs/2206.07358",
    "authors": [
      "R. Krithika",
      "Roohani Sharma",
      "Prafullkumar Tale"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2206.07369",
    "title": "DiffWire: Inductive Graph Rewiring via the Lov\u00e1sz Bound",
    "abstract": "Graph Neural Networks (GNNs) have been shown to achieve competitive results to tackle graph-related tasks, such as node and graph classification, link prediction and node and graph clustering in a variety of domains. Most GNNs use a message passing framework and hence are called MPNNs. Despite their promising results, MPNNs have been reported to suffer from over-smoothing, over-squashing and under-reaching. Graph rewiring and graph pooling have been proposed in the literature as solutions to address these limitations. However, most state-of-the-art graph rewiring methods fail to preserve the global topology of the graph, are not differentiable (inductive) and require the tuning of hyper-parameters. In this paper, we propose DiffWire, a novel framework for graph rewiring in MPNNs that is principled, fully differentiable and parameter-free by leveraging the Lov\\'asz bound. Our approach provides a unified theory for graph rewiring by proposing two new, complementary layers in MPNNs: first, CTLayer, a layer that learns the commute times and uses them as a relevance function for edge re-weighting; second, GAPLayer, a layer to optimize the spectral gap, depending on the nature of the network and the task at hand. We empirically validate the value of our proposed approach and each of these layers separately with benchmark datasets for graph classification. DiffWire brings together the learnability of commute times to related definitions of curvature, opening the door to the development of more expressive MPNNs. ",
    "url": "https://arxiv.org/abs/2206.07369",
    "authors": [
      "Adri\u00e1n Arnaiz-Rodr\u00edguez",
      "Ahmed Begga",
      "Francisco Escolano",
      "Nuria Oliver"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.07375",
    "title": "Knowledge4COVID-19: A Semantic-based Approach for Constructing a  COVID-19 related Knowledge Graph from Various Sources and Analysing  Treatments' Toxicities",
    "abstract": "In this paper, we present Knowledge4COVID-19, a framework that aims to showcase the power of integrating disparate sources of knowledge to discover adverse drug effects caused by drug-drug interactions among COVID-19 treatments and pre-existing condition drugs. Initially, we focus on constructing the Knowledge4COVID-19 knowledge graph (KG) from the declarative definition of mapping rules using the RDF Mapping Language. Since valuable information about drug treatments, drug-drug interactions, and side effects is present in textual descriptions in scientific databases (e.g., DrugBank) or in scientific literature (e.g., the CORD-19, the Covid-19 Open Research Dataset), the Knowledge4COVID-19 framework implements Natural Language Processing. The Knowledge4COVID-19 framework extracts relevant entities and predicates that enable the fine-grained description of COVID-19 treatments and the potential adverse events that may occur when these treatments are combined with treatments of common comorbidities, e.g., hypertension, diabetes, or asthma. Moreover, on top of the KG, several techniques for the discovery and prediction of interactions and potential adverse effects of drugs have been developed with the aim of suggesting more accurate treatments for treating the virus. We provide services to traverse the KG and visualize the effects that a group of drugs may have on a treatment outcome. Knowledge4COVID-19 was part of the Pan-European hackathon#EUvsVirus in April 2020 and is publicly available as a resource through a GitHub repository (https://github.com/SDM-TIB/Knowledge4COVID-19) and a DOI (https://zenodo.org/record/4701817#.YH336-8zbol). ",
    "url": "https://arxiv.org/abs/2206.07375",
    "authors": [
      "Ahmad Sakor",
      "Samaneh Jozashoori",
      "Emetis Niazmand",
      "Ariam Rivas",
      "Kostantinos Bougiatiotis",
      "Fotis Aisopos",
      "Enrique Iglesias",
      "Philipp D. Rohde",
      "Trupti Padiya",
      "Anastasia Krithara",
      "Georgios Paliouras",
      "Maria-Esther Vidal"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2206.07389",
    "title": "Ultra Fast Deep Lane Detection with Hybrid Anchor Driven Ordinal  Classification",
    "abstract": "Modern methods mainly regard lane detection as a problem of pixel-wise segmentation, which is struggling to address the problems of efficiency and challenging scenarios like severe occlusions and extreme lighting conditions. Inspired by human perception, the recognition of lanes under severe occlusions and extreme lighting conditions is mainly based on contextual and global information. Motivated by this observation, we propose a novel, simple, yet effective formulation aiming at ultra fast speed and the problem of challenging scenarios. Specifically, we treat the process of lane detection as an anchor-driven ordinal classification problem using global features. First, we represent lanes with sparse coordinates on a series of hybrid (row and column) anchors. With the help of the anchor-driven representation, we then reformulate the lane detection task as an ordinal classification problem to get the coordinates of lanes. Our method could significantly reduce the computational cost with the anchor-driven representation. Using the large receptive field property of the ordinal classification formulation, we could also handle challenging scenarios. Extensive experiments on four lane detection datasets show that our method could achieve state-of-the-art performance in terms of both speed and accuracy. A lightweight version could even achieve 300+ frames per second(FPS). Our code is at https://github.com/cfzd/Ultra-Fast-Lane-Detection-v2. ",
    "url": "https://arxiv.org/abs/2206.07389",
    "authors": [
      "Zequn Qin",
      "Pengyi Zhang",
      "Xi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07406",
    "title": "Hardening DNNs against Transfer Attacks during Network Compression using  Greedy Adversarial Pruning",
    "abstract": "The prevalence and success of Deep Neural Network (DNN) applications in recent years have motivated research on DNN compression, such as pruning and quantization. These techniques accelerate model inference, reduce power consumption, and reduce the size and complexity of the hardware necessary to run DNNs, all with little to no loss in accuracy. However, since DNNs are vulnerable to adversarial inputs, it is important to consider the relationship between compression and adversarial robustness. In this work, we investigate the adversarial robustness of models produced by several irregular pruning schemes and by 8-bit quantization. Additionally, while conventional pruning removes the least important parameters in a DNN, we investigate the effect of an unconventional pruning method: removing the most important model parameters based on the gradient on adversarial inputs. We call this method Greedy Adversarial Pruning (GAP) and we find that this pruning method results in models that are resistant to transfer attacks from their uncompressed counterparts. ",
    "url": "https://arxiv.org/abs/2206.07406",
    "authors": [
      "Jonah O'Brien Weiss",
      "Tiago Alves",
      "Sandip Kundu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.07431",
    "title": "Physically-admissible polarimetric data augmentation for road-scene  analysis",
    "abstract": "Polarimetric imaging, along with deep learning, has shown improved performances on different tasks including scene analysis. However, its robustness may be questioned because of the small size of the training datasets. Though the issue could be solved by data augmentation, polarization modalities are subject to physical feasibility constraints unaddressed by classical data augmentation techniques. To address this issue, we propose to use CycleGAN, an image translation technique based on deep generative models that solely relies on unpaired data, to transfer large labeled road scene datasets to the polarimetric domain. We design several auxiliary loss terms that, alongside the CycleGAN losses, deal with the physical constraints of polarimetric images. The efficiency of this solution is demonstrated on road scene object detection tasks where generated realistic polarimetric images allow to improve performances on cars and pedestrian detection up to 9%. The resulting constrained CycleGAN is publicly released, allowing anyone to generate their own polarimetric images. ",
    "url": "https://arxiv.org/abs/2206.07431",
    "authors": [
      "Cyprien Ruffino",
      "Rachel Blin",
      "Samia Ainouz",
      "Gilles Gasso",
      "Romain H\u00e9rault",
      "Fabrice Meriaudeau",
      "St\u00e9phane Canu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.07434",
    "title": "Self-Supervised Implicit Attention: Guided Attention by The Model Itself",
    "abstract": "We propose Self-Supervised Implicit Attention (SSIA), a new approach that adaptively guides deep neural network models to gain attention by exploiting the properties of the models themselves. SSIA is a novel attention mechanism that does not require any extra parameters, computation, or memory access costs during inference, which is in contrast to existing attention mechanism. In short, by considering attention weights as higher-level semantic information, we reconsidered the implementation of existing attention mechanisms and further propose generating supervisory signals from higher network layers to guide lower network layers for parameter updates. We achieved this by building a self-supervised learning task using the hierarchical features of the network itself, which only works at the training stage. To verify the effectiveness of SSIA, we performed a particular implementation (called an SSIA block) in convolutional neural network models and validated it on several image classification datasets. The experimental results show that an SSIA block can significantly improve the model performance, even outperforms many popular attention methods that require additional parameters and computation costs, such as Squeeze-and-Excitation and Convolutional Block Attention Module. Our implementation will be available on GitHub. ",
    "url": "https://arxiv.org/abs/2206.07434",
    "authors": [
      "Jinyi Wu",
      "Xun Gong",
      "Zhemin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07454",
    "title": "Collaboration Effect by Co-Authorship on Academic Citation and Social  Attention of Research",
    "abstract": "Academic citation and social attention measure different dimensions of the impact of research results. Both measures do not correlate with each other, and they are influenced by many factors. Among these factors are the field of research, the type of access, and co-authorship. In this study, the increase in the impact due to co-authorship in scientific articles disaggregated by field of research and access type, was quantified. For this, the citations and social attention accumulated until the year 2021 by a total of 244,880 research articles published in the year 2018, were analyzed. The data source was Dimensions.ai, and the units of study were research articles in Economics, History and Archaeology, and Mathematics. As the main results, a small proportion of the articles received a large part of the citations and most of the social attention. Both citations and social attention in-creased, in general, with the number of co-authors. Thus, the greater the number of co-authors, the greater the probability of being cited in academic articles and mentioned on social media. The advantage in citation and social attention due to collaboration is independent of the access type for the publication. Furthermore, although collaboration with an additional co-author is in general positive in terms of citation and social attention, these positive effects reduce as the number of co-authors increases. ",
    "url": "https://arxiv.org/abs/2206.07454",
    "authors": [
      "Pablo Dorta-Gonz\u00e1lez",
      "Mar\u00eda Isabel Dorta-Gonz\u00e1lez"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2206.07459",
    "title": "READ: Aggregating Reconstruction Error into Out-of-distribution  Detection",
    "abstract": "Detecting out-of-distribution (OOD) samples is crucial to the safe deployment of a classifier in the real world. However, deep neural networks are known to be overconfident for abnormal data. Existing works directly design score function by mining the inconsistency from classifier for in-distribution (ID) and OOD. In this paper, we further complement this inconsistency with reconstruction error, based on the assumption that an autoencoder trained on ID data can not reconstruct OOD as well as ID. We propose a novel method, READ (Reconstruction Error Aggregated Detector), to unify inconsistencies from classifier and autoencoder. Specifically, the reconstruction error of raw pixels is transformed to latent space of classifier. We show that the transformed reconstruction error bridges the semantic gap and inherits detection performance from the original. Moreover, we propose an adjustment strategy to alleviate the overconfidence problem of autoencoder according to a fine-grained characterization of OOD data. Under two scenarios of pre-training and retraining, we respectively present two variants of our method, namely READ-MD (Mahalanobis Distance) only based on pre-trained classifier and READ-ED (Euclidean Distance) which retrains the classifier. Our methods do not require access to test time OOD data for fine-tuning hyperparameters. Finally, we demonstrate the effectiveness of the proposed methods through extensive comparisons with state-of-the-art OOD detection algorithms. On a CIFAR-10 pre-trained WideResNet, our method reduces the average FPR@95TPR by up to 9.8% compared with previous state-of-the-art. ",
    "url": "https://arxiv.org/abs/2206.07459",
    "authors": [
      "Wenyu Jiang",
      "Hao Cheng",
      "Mingcai Chen",
      "Shuai Feng",
      "Yuxin Ge",
      "Chongjun Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07460",
    "title": "Coarse-to-fine Deep Video Coding with Hyperprior-guided Mode Prediction",
    "abstract": "The previous deep video compression approaches only use the single scale motion compensation strategy and rarely adopt the mode prediction technique from the traditional standards like H.264/H.265 for both motion and residual compression. In this work, we first propose a coarse-to-fine (C2F) deep video compression framework for better motion compensation, in which we perform motion estimation, compression and compensation twice in a coarse to fine manner. Our C2F framework can achieve better motion compensation results without significantly increasing bit costs. Observing hyperprior information (i.e., the mean and variance values) from the hyperprior networks contains discriminant statistical information of different patches, we also propose two efficient hyperprior-guided mode prediction methods. Specifically, using hyperprior information as the input, we propose two mode prediction networks to respectively predict the optimal block resolutions for better motion coding and decide whether to skip residual information from each block for better residual coding without introducing additional bit cost while bringing negligible extra computation cost. Comprehensive experimental results demonstrate our proposed C2F video compression framework equipped with the new hyperprior-guided mode prediction methods achieves the state-of-the-art performance on HEVC, UVG and MCL-JCV datasets. ",
    "url": "https://arxiv.org/abs/2206.07460",
    "authors": [
      "Zhihao Hu",
      "Guo Lu",
      "Jinyang Guo",
      "Shan Liu",
      "Wei Jiang",
      "Dong Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.07472",
    "title": "Collaborative Knowledge Graph Fusion by Exploiting the Open Corpus",
    "abstract": "To alleviate the challenges of building Knowledge Graphs (KG) from scratch, a more general task is to enrich a KG using triples from an open corpus, where the obtained triples contain noisy entities and relations. It is challenging to enrich a KG with newly harvested triples while maintaining the quality of the knowledge representation. This paper proposes a system to refine a KG using information harvested from an additional corpus. To this end, we formulate our task as two coupled sub-tasks, namely join event extraction (JEE) and knowledge graph fusion (KGF). We then propose a Collaborative Knowledge Graph Fusion Framework to allow our sub-tasks to mutually assist one another in an alternating manner. More concretely, the explorer carries out the JEE supervised by both the ground-truth annotation and an existing KG provided by the supervisor. The supervisor then evaluates the triples extracted by the explorer and enriches the KG with those that are highly ranked. To implement this evaluation, we further propose a Translated Relation Alignment Scoring Mechanism to align and translate the extracted triples to the prior KG. Experiments verify that this collaboration can both improve the performance of the JEE and the KGF. ",
    "url": "https://arxiv.org/abs/2206.07472",
    "authors": [
      "Yue Wang",
      "Yao Wan",
      "Lu Bai",
      "Lixin Cui",
      "Zhuo Xu",
      "Ming Li",
      "Philip S. Yu",
      "Edwin R Hancock"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.07475",
    "title": "Neural Control of Discrete Weak Formulations: Galerkin, Least-Squares  and Minimal-Residual Methods with Quasi-Optimal Weights",
    "abstract": "There is tremendous potential in using neural networks to optimize numerical methods. In this paper, we introduce and analyse a framework for the neural optimization of discrete weak formulations, suitable for finite element methods. The main idea of the framework is to include a neural-network function acting as a control variable in the weak form. Finding the neural control that (quasi-) minimizes a suitable cost (or loss) functional, then yields a numerical approximation with desirable attributes. In particular, the framework allows in a natural way the incorporation of known data of the exact solution, or the incorporation of stabilization mechanisms (e.g., to remove spurious oscillations). The main result of our analysis pertains to the well-posedness and convergence of the associated constrained-optimization problem. In particular, we prove under certain conditions, that the discrete weak forms are stable, and that quasi-minimizing neural controls exist, which converge quasi-optimally. We specialize the analysis results to Galerkin, least-squares and minimal-residual formulations, where the neural-network dependence appears in the form of suitable weights. Elementary numerical experiments support our findings and demonstrate the potential of the framework. ",
    "url": "https://arxiv.org/abs/2206.07475",
    "authors": [
      "Ignacio Brevis",
      "Ignacio Muga",
      "Kristoffer G. van der Zee"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2206.07510",
    "title": "Deep Multi-Task Networks For Occluded Pedestrian Pose Estimation",
    "abstract": "Most of the existing works on pedestrian pose estimation do not consider estimating the pose of an occluded pedestrians, as the annotations of the occluded parts are not available in relevant automotive datasets. For example, CityPersons, a well-known dataset for pedestrian detection in automotive scenes does not provide pose annotations, whereas MS-COCO, a non-automotive dataset, contains human pose estimation. In this work, we propose a multi-task framework to extract pedestrian features through detection and instance segmentation tasks performed separately on these two distributions. Thereafter, an encoder learns pose specific features using an unsupervised instance-level domain adaptation method for the pedestrian instances from both distributions. The proposed framework has improved state-of-the-art performances of pose estimation, pedestrian detection, and instance segmentation. ",
    "url": "https://arxiv.org/abs/2206.07510",
    "authors": [
      "Arindam Das",
      "Sudip Das",
      "Ganesh Sistu",
      "Jonathan Horgan",
      "Ujjwal Bhattacharya",
      "Edward Jones",
      "Martin Glavin",
      "Ciar\u00e1n Eising"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07527",
    "title": "QONNX: Representing Arbitrary-Precision Quantized Neural Networks",
    "abstract": "We present extensions to the Open Neural Network Exchange (ONNX) intermediate representation format to represent arbitrary-precision quantized neural networks. We first introduce support for low precision quantization in existing ONNX-based quantization formats by leveraging integer clipping, resulting in two new backward-compatible variants: the quantized operator format with clipping and quantize-clip-dequantize (QCDQ) format. We then introduce a novel higher-level ONNX format called quantized ONNX (QONNX) that introduces three new operators -- Quant, BipolarQuant, and Trunc -- in order to represent uniform quantization. By keeping the QONNX IR high-level and flexible, we enable targeting a wider variety of platforms. We also present utilities for working with QONNX, as well as examples of its usage in the FINN and hls4ml toolchains. Finally, we introduce the QONNX model zoo to share low-precision quantized neural networks. ",
    "url": "https://arxiv.org/abs/2206.07527",
    "authors": [
      "Alessandro Pappalardo",
      "Yaman Umuroglu",
      "Michaela Blott",
      "Jovan Mitrevski",
      "Ben Hawks",
      "Nhan Tran",
      "Vladimir Loncar",
      "Sioni Summers",
      "Hendrik Borras",
      "Jules Muhizi",
      "Matthew Trahms",
      "Shih-Chieh Hsu",
      "Javier Duarte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Programming Languages (cs.PL)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.07538",
    "title": "Body Gesture Recognition to Control a Social Robot",
    "abstract": "In this work, we propose a gesture based language to allow humans to interact with robots using their body in a natural way. We have created a new gesture detection model using neural networks and a custom dataset of humans performing a set of body gestures to train our network. Furthermore, we compare body gesture communication with other communication channels to acknowledge the importance of adding this knowledge to robots. The presented approach is extensively validated in diverse simulations and real-life experiments with non-trained volunteers. This attains remarkable results and shows that it is a valuable framework for social robotics applications, such as human robot collaboration or human-robot interaction. ",
    "url": "https://arxiv.org/abs/2206.07538",
    "authors": [
      "Javier Laplaza",
      "Joan Jaume Oliver",
      "Ram\u00f3n Romero",
      "Alberto Sanfeliu",
      "Ana\u00eds Garrell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Databases (cs.DB)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07551",
    "title": "Unknown-Aware Domain Adversarial Learning for Open-Set Domain Adaptation",
    "abstract": "Open-Set Domain Adaptation (OSDA) assumes that a target domain contains unknown classes, which are not discovered in a source domain. Existing domain adversarial learning methods are not suitable for OSDA because distribution matching with \\textit{unknown} classes leads to the negative transfer. Previous OSDA methods have focused on matching the source and the target distribution by only utilizing \\textit{known} classes. However, this \\textit{known}-only matching may fail to learn the target-\\textit{unknown} feature space. Therefore, we propose Unknown-Aware Domain Adversarial Learning (UADAL), which \\textit{aligns} the source and the targe-\\textit{known} distribution while simultaneously \\textit{segregating} the target-\\textit{unknown} distribution in the feature alignment procedure. We provide theoretical analyses on the optimized state of the proposed \\textit{unknown-aware} feature alignment, so we can guarantee both \\textit{alignment} and \\textit{segregation} theoretically. Empirically, we evaluate UADAL on the benchmark datasets, which shows that UADAL outperforms other methods with better feature alignments by reporting the state-of-the-art performances. ",
    "url": "https://arxiv.org/abs/2206.07551",
    "authors": [
      "JoonHo Jang",
      "Byeonghu Na",
      "DongHyeok Shin",
      "Mingi Ji",
      "Kyungwoo Song",
      "Il-Chul Moon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.07554",
    "title": "Hierarchical Clustering in Graph Streams: Single-Pass Algorithms and  Space Lower Bounds",
    "abstract": "The Hierarchical Clustering (HC) problem consists of building a hierarchy of clusters to represent a given dataset. Motivated by the modern large-scale applications, we study the problem in the \\streaming model, in which the memory is heavily limited and only a single or very few passes over the input are allowed. Specifically, we investigate whether a good hierarchical clustering can be obtained, or at least whether we can approximately estimate the value of the optimal hierarchy. To measure the quality of a hierarchy, we use the HC minimization objective introduced by Dasgupta. Assuming that the input is an $n$-vertex weighted graph whose edges arrive in a stream, we derive the following results on space-vs-accuracy tradeoffs: * With $O(n\\cdot \\text{polylog}\\,{n})$ space, we develop a single-pass algorithm, whose approximation ratio matches the currently best offline algorithm. * When the space is more limited, namely, $n^{1-o(1)}$, we prove that no algorithm can even estimate the value of optimum HC tree to within an $o(\\frac{\\log{n}}{\\log\\log{n}})$ factor, even when allowed $\\text{polylog}{\\,{n}}$ passes over the input. * In the most stringent setting of $\\text{polylog}\\,{n}$ space, we rule out algorithms that can even distinguish between \"highly\"-vs-\"poorly\" clusterable graphs, namely, graphs that have an $n^{1/2-o(1)}$ factor gap between their HC objective value. * Finally, we prove that any single-pass streaming algorithm that computes an optimal HC tree requires to store almost the entire input even if allowed exponential time. Our algorithmic results establish a general structural result that proves that cut sparsifiers of input graph can preserve cost of \"balanced\" HC trees to within a constant factor. Our lower bound results include a new streaming lower bound for a novel problem \"One-vs-Many-Expanders\", which can be of independent interest. ",
    "url": "https://arxiv.org/abs/2206.07554",
    "authors": [
      "Sepehr Assadi",
      "Vaggos Chatziafratis",
      "Jakub \u0141\u0105cki",
      "Vahab Mirrokni",
      "Chen Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2206.07556",
    "title": "KGEA: A Knowledge Graph Enhanced Article Quality Identification Dataset",
    "abstract": "With so many articles of varying quality being produced at every moment, it is a very urgent task to screen this data for quality articles and commit them out to social media. It is worth noting that high quality articles have many characteristics, such as relevance, text quality, straightforward, multi-sided, background, novelty and sentiment. Thus, it would be inadequate to purely use the content of an article to identify its quality. Therefore, we plan to use the external knowledge interaction to refine the performance and propose a knowledge graph enhanced article quality identification dataset (KGEA) based on Baidu Encyclopedia. We quantified the articles through 7 dimensions and use co-occurrence of the entities between the articles and the Baidu encyclopedia to construct the knowledge graph for every article. We also compared some text classification baselines and found that external knowledge can guide the articles to a more competitive classification with the graph neural networks. ",
    "url": "https://arxiv.org/abs/2206.07556",
    "authors": [
      "Chunhui Ai",
      "Derui Wang",
      "Yang Xu",
      "Wenrui Xie",
      "Ziqiang Cao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.07557",
    "title": "How to Reduce Change Detection to Semantic Segmentation",
    "abstract": "Change detection (CD) aims to identify changes that occur in an image pair taken different times. Prior methods devise specific networks from scratch to predict change masks in pixel-level, and struggle with general segmentation problems. In this paper, we propose a new paradigm that reduces CD to semantic segmentation which means tailoring an existing and powerful semantic segmentation network to solve CD. This new paradigm conveniently enjoys the mainstream semantic segmentation techniques to deal with general segmentation problems in CD. Hence we can concentrate on studying how to detect changes. We propose a novel and importance insight that different change types exist in CD and they should be learned separately. Based on it, we devise a module named MTF to extract the change information and fuse temporal features. MTF enjoys high interpretability and reveals the essential characteristic of CD. And most segmentation networks can be adapted to solve the CD problems with our MTF module. Finally, we propose C-3PO, a network to detect changes at pixel-level. C-3PO achieves state-of-the-art performance without bells and whistles. It is simple but effective and can be considered as a new baseline in this field. Our code will be available. ",
    "url": "https://arxiv.org/abs/2206.07557",
    "authors": [
      "Guo-Hua Wang",
      "Bin-Bin Gao",
      "Chengjie Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.07570",
    "title": "Calibrating Agent-based Models to Microdata with Graph Neural Networks",
    "abstract": "Calibrating agent-based models (ABMs) to data is among the most fundamental requirements to ensure the model fulfils its desired purpose. In recent years, simulation-based inference methods have emerged as powerful tools for performing this task when the model likelihood function is intractable, as is often the case for ABMs. In some real-world use cases of ABMs, both the observed data and the ABM output consist of the agents' states and their interactions over time. In such cases, there is a tension between the desire to make full use of the rich information content of such granular data on the one hand, and the need to reduce the dimensionality of the data to prevent difficulties associated with high-dimensional learning tasks on the other. A possible resolution is to construct lower-dimensional time-series through the use of summary statistics describing the macrostate of the system at each time point. However, a poor choice of summary statistics can result in an unacceptable loss of information from the original dataset, dramatically reducing the quality of the resulting calibration. In this work, we instead propose to learn parameter posteriors associated with granular microdata directly using temporal graph neural networks. We will demonstrate that such an approach offers highly compelling inductive biases for Bayesian inference using the raw ABM microstates as output. ",
    "url": "https://arxiv.org/abs/2206.07570",
    "authors": [
      "Joel Dyer",
      "Patrick Cannon",
      "J. Doyne Farmer",
      "Sebastian M. Schmon"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.07578",
    "title": "E2V-SDE: From Asynchronous Events to Fast and Continuous Video  Reconstruction via Neural Stochastic Differential Equations",
    "abstract": "Event cameras respond to brightness changes in the scene asynchronously and independently for every pixel. Due to the properties, these cameras have distinct features: high dynamic range (HDR), high temporal resolution, and low power consumption. However, the results of event cameras should be processed into an alternative representation for computer vision tasks. Also, they are usually noisy and cause poor performance in areas with few events. In recent years, numerous researchers have attempted to reconstruct videos from events. However, they do not provide good quality videos due to a lack of temporal information from irregular and discontinuous data. To overcome these difficulties, we introduce an E2V-SDE whose dynamics are governed in a latent space by Stochastic differential equations (SDE). Therefore, E2V-SDE can rapidly reconstruct images at arbitrary time steps and make realistic predictions on unseen data. In addition, we successfully adopted a variety of image composition techniques for improving image clarity and temporal consistency. By conducting extensive experiments on simulated and real-scene datasets, we verify that our model outperforms state-of-the-art approaches under various video reconstruction settings. In terms of image quality, the LPIPS score improves by up to 12% and the reconstruction speed is 87% higher than that of ET-Net. ",
    "url": "https://arxiv.org/abs/2206.07578",
    "authors": [
      "Jongwan Kim",
      "DongJin Lee",
      "Byunggook Na",
      "Seongsik Park",
      "Jeonghee Jo",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.07580",
    "title": "Evaluating object detector ensembles for improving the robustness of  artifact detection in endoscopic video streams",
    "abstract": "In this contribution we use an ensemble deep-learning method for combining the prediction of two individual one-stage detectors (i.e., YOLOv4 and Yolact) with the aim to detect artefacts in endoscopic images. This ensemble strategy enabled us to improve the robustness of the individual models without harming their real-time computation capabilities. We demonstrated the effectiveness of our approach by training and testing the two individual models and various ensemble configurations on the \"Endoscopic Artifact Detection Challenge\" dataset. Extensive experiments show the superiority, in terms of mean average precision, of the ensemble approach over the individual models and previous works in the state of the art. ",
    "url": "https://arxiv.org/abs/2206.07580",
    "authors": [
      "Pedro Esteban Chavarrias-Solano",
      "Carlos Axel Garcia-Vega",
      "Francisco Javier Lopez-Tiro",
      "Gilberto Ochoa-Ruiz",
      "Thomas Bazin",
      "Dominique Lamarque",
      "Christian Daul"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07581",
    "title": "Learn to Adapt: Robust Drift Detection in Security Domain",
    "abstract": "Deploying robust machine learning models has to account for concept drifts arising due to the dynamically changing and non-stationary nature of data. Addressing drifts is particularly imperative in the security domain due to the ever-evolving threat landscape and lack of sufficiently labeled training data at the deployment time leading to performance degradation. Recently proposed concept drift detection methods in literature tackle this problem by identifying the changes in feature/data distributions and periodically retraining the models to learn new concepts. While these types of strategies should absolutely be conducted when possible, they are not robust towards attacker-induced drifts and suffer from a delay in detecting new attacks. We aim to address these shortcomings in this work. we propose a robust drift detector that not only identifies drifted samples but also discovers new classes as they arrive in an on-line fashion. We evaluate the proposed method with two security-relevant data sets -- network intrusion data set released in 2018 and APT Command and Control dataset combined with web categorization data. Our evaluation shows that our drifting detection method is not only highly accurate but also robust towards adversarial drifts and discovers new classes from drifted samples. ",
    "url": "https://arxiv.org/abs/2206.07581",
    "authors": [
      "Aditya Kuppa",
      "Nhien-An Le-Khac"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.07585",
    "title": "NatGen: Generative pre-training by \"Naturalizing\" source code",
    "abstract": "Pre-trained Generative Language models (e.g. PLBART, CodeT5, SPT-Code) for source code yielded strong results on several tasks in the past few years, including code generation and translation. These models have adopted varying pre-training objectives to learn statistics of code construction from very large-scale corpora in a self-supervised fashion; the success of pre-trained models largely hinges on these pre-training objectives. This paper proposes a new pre-training objective, \"Naturalizing\" of source code, exploiting code's bimodal, dual-channel (formal & natural channels) nature. Unlike natural language, code's bimodal, dual-channel nature allows us to generate semantically equivalent code at scale. We introduce six classes of semantic preserving transformations to introduce un-natural forms of code, and then force our model to produce more natural original programs written by developers. Learning to generate equivalent, but more natural code, at scale, over large corpora of open-source code, without explicit manual supervision, helps the model learn to both ingest & generate code. We fine-tune our model in three generative Software Engineering tasks: code generation, code translation, and code refinement with limited human-curated labeled data and achieve state-of-the-art performance rivaling CodeT5. We show that our pre-trained model is especially competitive at zero-shot and few-shot learning, and better at learning code properties (e.g., syntax, data flow). ",
    "url": "https://arxiv.org/abs/2206.07585",
    "authors": [
      "Saikat Chakraborty",
      "Toufique Ahmed",
      "Yangruibo Ding",
      "Premkumar Devanbu",
      "Baishakhi Ray"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2206.07623",
    "title": "Dynamic State Estimation of Nonlinear Differential Algebraic Equation  Models of Power Networks",
    "abstract": "This paper investigates the joint problems of dynamic state estimation of algebraic variables (voltage and phase angle) and generator states (rotor angle and frequency) of nonlinear differential algebraic equation (NDAE) power network models, under uncertainty. Traditionally, these two problems have been decoupled due to complexity of handling NDAE models. In particular, this paper offers the first attempt to solve the aforementioned problem in a coupled approach where the algebraic and generator states estimates are simultaneously computed. The proposed estimation algorithm herein is endowed with the following properties: (i) it is fairly simple to implement and based on well-understood Lyapunov theory; (ii) considers various sources of uncertainty from generator control inputs, loads, renewables, process and measurement noise; (iii) models phasor measurement unit installations at arbitrary buses; and (iv) is computationally less intensive than the decoupled approach in the literature. ",
    "url": "https://arxiv.org/abs/2206.07623",
    "authors": [
      "Muhammad Nadeem",
      "Sebastian A. Nugroho",
      "Ahmad F. Taha"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2206.07634",
    "title": "Real3D-Aug: Point Cloud Augmentation by Placing Real Objects with  Occlusion Handling for 3D Detection and Segmentation",
    "abstract": "Object detection and semantic segmentation with the 3D lidar point cloud data require expensive annotation. We propose a data augmentation method that takes advantage of already annotated data multiple times. We propose an augmentation framework that reuses real data, automatically finds suitable placements in the scene to be augmented, and handles occlusions explicitly. Due to the usage of the real data, the scan points of newly inserted objects in augmentation sustain the physical characteristics of the lidar, such as intensity and raydrop. The pipeline proves competitive in training top-performing models for 3D object detection and semantic segmentation. The new augmentation provides a significant performance gain in rare and essential classes, notably 6.65% average precision gain for \"Hard\" pedestrian class in KITTI object detection or 2.14 mean IoU gain in the SemanticKITTI segmentation challenge over the state of the art. ",
    "url": "https://arxiv.org/abs/2206.07634",
    "authors": [
      "Petr \u0160ebek",
      "\u0160imon Pokorn\u00fd",
      "Patrik Vacek",
      "Tom\u00e1\u0161 Svoboda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.07665",
    "title": "Region-enhanced Deep Graph Convolutional Networks for Rumor Detection",
    "abstract": "Social media has been rapidly developing in the public sphere due to its ease of spreading new information, which leads to the circulation of rumors. However, detecting rumors from such a massive amount of information is becoming an increasingly arduous challenge. Previous work generally obtained valuable features from propagation information. It should be noted that most methods only target the propagation structure while ignoring the rumor transmission pattern. This limited focus severely restricts the collection of spread data. To solve this problem, the authors of the present study are motivated to explore the regionalized propagation patterns of rumors. Specifically, a novel region-enhanced deep graph convolutional network (RDGCN) that enhances the propagation features of rumors by learning regionalized propagation patterns and trains to learn the propagation patterns by unsupervised learning is proposed. In addition, a source-enhanced residual graph convolution layer (SRGCL) is designed to improve the graph neural network (GNN) oversmoothness and increase the depth limit of the rumor detection methods-based GNN. Experiments on Twitter15 and Twitter16 show that the proposed model performs better than the baseline approach on rumor detection and early rumor detection. ",
    "url": "https://arxiv.org/abs/2206.07665",
    "authors": [
      "Ge Wang",
      "Li Tan",
      "Tianbao Song",
      "Wei Wang",
      "Ziliang Shang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.07680",
    "title": "Learning Large-scale Subsurface Simulations with a Hybrid Graph Network  Simulator",
    "abstract": "Subsurface simulations use computational models to predict the flow of fluids (e.g., oil, water, gas) through porous media. These simulations are pivotal in industrial applications such as petroleum production, where fast and accurate models are needed for high-stake decision making, for example, for well placement optimization and field development planning. Classical finite difference numerical simulators require massive computational resources to model large-scale real-world reservoirs. Alternatively, streamline simulators and data-driven surrogate models are computationally more efficient by relying on approximate physics models, however they are insufficient to model complex reservoir dynamics at scale. Here we introduce Hybrid Graph Network Simulator (HGNS), which is a data-driven surrogate model for learning reservoir simulations of 3D subsurface fluid flows. To model complex reservoir dynamics at both local and global scale, HGNS consists of a subsurface graph neural network (SGNN) to model the evolution of fluid flows, and a 3D-U-Net to model the evolution of pressure. HGNS is able to scale to grids with millions of cells per time step, two orders of magnitude higher than previous surrogate models, and can accurately predict the fluid flow for tens of time steps (years into the future). Using an industry-standard subsurface flow dataset (SPE-10) with 1.1 million cells, we demonstrate that HGNS is able to reduce the inference time up to 18 times compared to standard subsurface simulators, and that it outperforms other learning-based models by reducing long-term prediction errors by up to 21%. ",
    "url": "https://arxiv.org/abs/2206.07680",
    "authors": [
      "Tailin Wu",
      "Qinchen Wang",
      "Yinan Zhang",
      "Rex Ying",
      "Kaidi Cao",
      "Rok Sosi\u010d",
      "Ridwan Jalali",
      "Hassan Hamam",
      "Marko Maucec",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2206.07685",
    "title": "Decentralized WebRCT P2P network using Kademlia",
    "abstract": "Web Real-Time Communication (WebRTC) is a new standard and industry effort that extends the web browsing model. For the first time, browsers are able to directly exchange real-time media with other browsers in a peer-to-peer fashion. Before WebRTC was introduced, it was cumbersome to build smooth chat and video applications, users often experience unstable connections, blurry videos, and unclear sounds. WebRTC's peer-to-peer communication paradigm establishes the real-time connection between browsers using the SIP(Session Initiation Protocol) Trapezoid. A wide set of protocols are bundled in WebRTC API, such as connection management, encoding/decoding negotiation, media control, selection and control, firewall and NAT element traversal, etc. However, almost all current WebRTC applications are using centralized signaling infrastructure which brings the problems of scalability, stability, and fault-tolerance. In this paper, I am presenting a decentralized architecture by introducing the Kademlia network into WebRTC to reduce the need for a centralized signaling service for WebRTC. ",
    "url": "https://arxiv.org/abs/2206.07685",
    "authors": [
      "Ryle Zhou"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2206.07692",
    "title": "A Simple Data Mixing Prior for Improving Self-Supervised Learning",
    "abstract": "Data mixing (e.g., Mixup, Cutmix, ResizeMix) is an essential component for advancing recognition models. In this paper, we focus on studying its effectiveness in the self-supervised setting. By noticing the mixed images that share the same source images are intrinsically related to each other, we hereby propose SDMP, short for $\\textbf{S}$imple $\\textbf{D}$ata $\\textbf{M}$ixing $\\textbf{P}$rior, to capture this straightforward yet essential prior, and position such mixed images as additional $\\textbf{positive pairs}$ to facilitate self-supervised representation learning. Our experiments verify that the proposed SDMP enables data mixing to help a set of self-supervised learning frameworks (e.g., MoCo) achieve better accuracy and out-of-distribution robustness. More notably, our SDMP is the first method that successfully leverages data mixing to improve (rather than hurt) the performance of Vision Transformers in the self-supervised setting. Code is publicly available at https://github.com/OliverRensu/SDMP ",
    "url": "https://arxiv.org/abs/2206.07692",
    "authors": [
      "Sucheng Ren",
      "Huiyu Wang",
      "Zhengqi Gao",
      "Shengfeng He",
      "Alan Yuille",
      "Yuyin Zhou",
      "Cihang Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07696",
    "title": "Diffusion Models for Video Prediction and Infilling",
    "abstract": "To predict and anticipate future outcomes or reason about missing information in a sequence is a key ability for agents to be able to make intelligent decisions. This requires strong temporally coherent generative capabilities. Diffusion models have shown huge success in several generative tasks lately, but have not been extensively explored in the video domain. We present Random-Mask Video Diffusion (RaMViD), which extends image diffusion models to videos using 3D convolutions, and introduces a new conditioning technique during training. By varying the mask we condition on, the model is able to perform video prediction, infilling and upsampling. Since we do not use concatenation to condition on a mask, as done in most conditionally trained diffusion models, we are able to decrease the memory footprint. We evaluated the model on two benchmark datasets for video prediction and one for video generation on which we achieved competitive results. On Kinetics-600 we achieved state-of-the-art for video prediction. ",
    "url": "https://arxiv.org/abs/2206.07696",
    "authors": [
      "Tobias H\u00f6ppe",
      "Arash Mehrjou",
      "Stefan Bauer",
      "Didrik Nielsen",
      "Andrea Dittadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.07698",
    "title": "Neural Deformable Voxel Grid for Fast Optimization of Dynamic View  Synthesis",
    "abstract": "Recently, Neural Radiance Fields (NeRF) is revolutionizing the task of novel view synthesis (NVS) for its superior performance. However, NeRF and its variants generally require a lengthy per-scene training procedure, where a multi-layer perceptron (MLP) is fitted to the captured images. To remedy the challenge, the voxel-grid representation has been proposed to significantly speed up the training. However, these existing methods can only deal with static scenes. How to develop an efficient and accurate dynamic view synthesis method remains an open problem. Extending the methods for static scenes to dynamic scenes is not straightforward as both the scene geometry and appearance change over time. In this paper, built on top of the recent advances in voxel-grid optimization, we propose a fast deformable radiance field method to handle dynamic scenes. Our method consists of two modules. The first module adopts a deformation grid to store 3D dynamic features, and a light-weight MLP for decoding the deformation that maps a 3D point in observation space to the canonical space using the interpolated features. The second module contains a density and a color grid to model the geometry and density of the scene. The occlusion is explicitly modeled to further improve the rendering quality. Experimental results show that our method achieves comparable performance to D-NeRF using only 20 minutes for training, which is more than 70x faster than D-NeRF, clearly demonstrating the efficiency of our proposed method. ",
    "url": "https://arxiv.org/abs/2206.07698",
    "authors": [
      "Xiang Guo",
      "Guanying Chen",
      "Yuchao Dai",
      "Xiaoqing Ye",
      "Jiadai Sun",
      "Xiao Tan",
      "Errui Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07705",
    "title": "LET-3D-AP: Longitudinal Error Tolerant 3D Average Precision for  Camera-Only 3D Detection",
    "abstract": "The popular object detection metric 3D Average Precision (3D AP) relies on the intersection over union between predicted bounding boxes and ground truth bounding boxes. However, depth estimation based on cameras has limited accuracy, which may cause otherwise reasonable predictions that suffer from such longitudinal localization errors to be treated as false positives and false negatives. We therefore propose variants of the popular 3D AP metric that are designed to be more permissive with respect to depth estimation errors. Specifically, our novel longitudinal error tolerant metrics, LET-3D-AP and LET-3D-APL, allow longitudinal localization errors of the predicted bounding boxes up to a given tolerance. The proposed metrics have been used in the Waymo Open Dataset 3D Camera-Only Detection Challenge. We believe that they will facilitate advances in the field of camera-only 3D detection by providing more informative performance signals. ",
    "url": "https://arxiv.org/abs/2206.07705",
    "authors": [
      "Wei-Chih Hung",
      "Henrik Kretzschmar",
      "Vincent Casser",
      "Jyh-Jing Hwang",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07706",
    "title": "Masked Frequency Modeling for Self-Supervised Visual Pre-Training",
    "abstract": "We present Masked Frequency Modeling (MFM), a unified frequency-domain-based approach for self-supervised pre-training of visual models. Instead of randomly inserting mask tokens to the input embeddings in the spatial domain, in this paper, we shift the perspective to the frequency domain. Specifically, MFM first masks out a portion of frequency components of the input image and then predicts the missing frequencies on the frequency spectrum. Our key insight is that predicting masked components in the frequency domain is more ideal to reveal underlying image patterns rather than predicting masked patches in the spatial domain, due to the heavy spatial redundancy. Our findings suggest that with the right configuration of mask-and-predict strategy, both the structural information within high-frequency components and the low-level statistics among low-frequency counterparts are useful in learning good representations. For the first time, MFM demonstrates that, for both ViT and CNN, a simple non-Siamese framework can learn meaningful representations even using none of the following: (i) extra data, (ii) extra model, (iii) mask token. Experimental results on ImageNet and several robustness benchmarks show the competitive performance and advanced robustness of MFM compared with recent masked image modeling approaches. Furthermore, we also comprehensively investigate the effectiveness of classical image restoration tasks for representation learning from a unified frequency perspective and reveal their intriguing relations with our MFM approach. Project page: https://www.mmlab-ntu.com/project/mfm/index.html. ",
    "url": "https://arxiv.org/abs/2206.07706",
    "authors": [
      "Jiahao Xie",
      "Wei Li",
      "Xiaohang Zhan",
      "Ziwei Liu",
      "Yew Soon Ong",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07707",
    "title": "Variable Bitrate Neural Fields",
    "abstract": "Neural approximations of scalar and vector fields, such as signed distance functions and radiance fields, have emerged as accurate, high-quality representations. State-of-the-art results are obtained by conditioning a neural approximation with a lookup from trainable feature grids that take on part of the learning task and allow for smaller, more efficient neural networks. Unfortunately, these feature grids usually come at the cost of significantly increased memory consumption compared to stand-alone neural network models. We present a dictionary method for compressing such feature grids, reducing their memory consumption by up to 100x and permitting a multiresolution representation which can be useful for out-of-core streaming. We formulate the dictionary optimization as a vector-quantized auto-decoder problem which lets us learn end-to-end discrete neural representations in a space where no direct supervision is available and with dynamic topology and structure. Our source code will be available at https://github.com/nv-tlabs/vqad. ",
    "url": "https://arxiv.org/abs/2206.07707",
    "authors": [
      "Towaki Takikawa",
      "Alex Evans",
      "Jonathan Tremblay",
      "Thomas M\u00fcller",
      "Morgan McGuire",
      "Alec Jacobson",
      "Sanja Fidler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2206.07710",
    "title": "PlanarRecon: Real-time 3D Plane Detection and Reconstruction from Posed  Monocular Videos",
    "abstract": "We present PlanarRecon -- a novel framework for globally coherent detection and reconstruction of 3D planes from a posed monocular video. Unlike previous works that detect planes in 2D from a single image, PlanarRecon incrementally detects planes in 3D for each video fragment, which consists of a set of key frames, from a volumetric representation of the scene using neural networks. A learning-based tracking and fusion module is designed to merge planes from previous fragments to form a coherent global plane reconstruction. Such design allows PlanarRecon to integrate observations from multiple views within each fragment and temporal information across different ones, resulting in an accurate and coherent reconstruction of the scene abstraction with low-polygonal geometry. Experiments show that the proposed approach achieves state-of-the-art performances on the ScanNet dataset while being real-time. ",
    "url": "https://arxiv.org/abs/2206.07710",
    "authors": [
      "Yiming Xie",
      "Matheus Gadelha",
      "Fengting Yang",
      "Xiaowei Zhou",
      "Huaizu Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.07113",
    "title": "Minorities in networks and algorithms",
    "abstract": "In this chapter, we provide an overview of recent advances in data-driven and theory-informed complex models of social networks and their potential in understanding societal inequalities and marginalization. We focus on inequalities arising from networks and network-based algorithms and how they affect minorities. In particular, we examine how homophily and mixing biases shape large and small social networks, influence perception of minorities, and affect collaboration patterns. We also discuss dynamical processes on and of networks and the formation of norms and health inequalities. Additionally, we argue that network modeling is paramount for unveiling the effect of ranking and social recommendation algorithms on the visibility of minorities. Finally, we highlight the key challenges and future opportunities in this emerging research topic. ",
    "url": "https://arxiv.org/abs/2206.07113",
    "authors": [
      "Fariba Karimi",
      "Marcos Oliveira",
      "Markus Strohmaier"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2206.07114",
    "title": "Inverse design of nano-photonic wavelength demultiplexer with a deep  neural network approach",
    "abstract": "In this paper, we propose a pre-trained-combined neural network (PTCN) as a comprehensive solution to the inverse design of an integrated photonic circuit. By utilizing both the initially pre-trained inverse and forward model with a joint training process, our PTCN model shows remarkable tolerance to the quantity and quality of the training data. As a proof of concept demonstration, the inverse design of a wavelength demultiplexer is used to verify the effectiveness of the PTCN model. The correlation coefficient of the prediction by the presented PTCN model remains greater than 0.974 even when the size of training data is decreased to 17%. The experimental results show a good agreement with predictions, and demonstrate a wavelength demultiplexer with an ultra-compact footprint, a high transmission efficiency with a transmission loss of -2dB, a low reflection of -10dB, and low crosstalk around -7dB simultaneously. ",
    "url": "https://arxiv.org/abs/2206.07114",
    "authors": [
      "Mengwei Yuan",
      "Gang Yang",
      "Shijie Song",
      "Luping Zhou",
      "Robert Minasian",
      "Xiaoke Yi"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07219",
    "title": "A Projection-Based K-space Transformer Network for Undersampled Radial  MRI Reconstruction with Limited Training Subjects",
    "abstract": "The recent development of deep learning combined with compressed sensing enables fast reconstruction of undersampled MR images and has achieved state-of-the-art performance for Cartesian k-space trajectories. However, non-Cartesian trajectories such as the radial trajectory need to be transformed onto a Cartesian grid in each iteration of the network training, slowing down the training process and posing inconvenience and delay during training. Multiple iterations of nonuniform Fourier transform in the networks offset the deep learning advantage of fast inference. Current approaches typically either work on image-to-image networks or grid the non-Cartesian trajectories before the network training to avoid the repeated gridding process. However, the image-to-image networks cannot ensure the k-space data consistency in the reconstructed images and the pre-processing of non-Cartesian k-space leads to gridding errors which cannot be compensated by the network training. Inspired by the Transformer network to handle long-range dependencies in sequence transduction tasks, we propose to rearrange the radial spokes to sequential data based on the chronological order of acquisition and use the Transformer to predict unacquired radial spokes from acquired ones. We propose novel data augmentation methods to generate a large amount of training data from a limited number of subjects. The network can be generated to different anatomical structures. Experimental results show superior performance of the proposed framework compared to state-of-the-art deep neural networks. ",
    "url": "https://arxiv.org/abs/2206.07219",
    "authors": [
      "Chang Gao",
      "Shu-Fu Shih",
      "J. Paul Finn",
      "Xiaodong Zhong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07280",
    "title": "ERNAS: An Evolutionary Neural Architecture Search for Magnetic Resonance  Image Reconstructions",
    "abstract": "Magnetic resonance imaging (MRI) is one of the noninvasive imaging modalities that can produce high-quality images. However, the scan procedure is relatively slow, which causes patient discomfort and motion artifacts in images. Accelerating MRI hardware is constrained by physical and physiological limitations. A popular alternative approach to accelerated MRI is to undersample the k-space data. While undersampling speeds up the scan procedure, it generates artifacts in the images, and advanced reconstruction algorithms are needed to produce artifact-free images. Recently deep learning has emerged as a promising MRI reconstruction method to address this problem. However, straightforward adoption of the existing deep learning neural network architectures in MRI reconstructions is not usually optimal in terms of efficiency and reconstruction quality. In this work, MRI reconstruction from undersampled data was carried out using an optimized neural network using a novel evolutionary neural architecture search algorithm. Brain and knee MRI datasets show that the proposed algorithm outperforms manually designed neural network-based MR reconstruction models. ",
    "url": "https://arxiv.org/abs/2206.07280",
    "authors": [
      "Samira Vafay Eslahi",
      "Jian Tao",
      "Jim Ji"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.07334",
    "title": "Detection of magnetohydrodynamic waves by using machine learning",
    "abstract": "Nonlinear wave interactions, such as shock refraction at an inclined density interface, in magnetohydrodynamic (MHD) lead to a plethora of wave patterns with myriad wave types. Identification of different types of MHD waves is an important and challenging task in such complex wave patterns. Moreover, owing to the multiplicity of solutions and their admissibility for different systems, especially for intermediate-type MHD shock waves, the identification of MHD wave types is complicated if one solely relies on the Rankine-Hugoniot jump conditions. MHD wave detection is further exacerbated by the unphysical smearing of discontinuous shock waves in numerical simulations. We present two MHD wave detection methods based on a convolutional neural network (CNN) which enables the classification of waves and identification of their locations. The first method separates the output into a regression (location prediction) and a classification problem assuming the number of waves for each training data is fixed. In the second method, the number of waves is not specified a priori and the algorithm, using only regression, predicts the waves' locations and classifies their types. The first fixed output model efficiently provides high precision and recall, the accuracy of the entire neural network achieved is up to 0.99, and the classification accuracy of some waves approaches unity. The second detection model has relatively lower performance, with more sensitivity to the setting of parameters, such as the number of grid cells N_{grid} and the thresholds of confidence score and class probability, etc. The proposed two methods demonstrate very strong potential to be applied for MHD wave detection in some complex wave structures and interactions. ",
    "url": "https://arxiv.org/abs/2206.07334",
    "authors": [
      "Fang Chen",
      "Ravi Samtaney"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)"
    ]
  },
  {
    "id": "arXiv:2206.07370",
    "title": "Lattice Convolutional Networks for Learning Ground States of Quantum  Many-Body Systems",
    "abstract": "Deep learning methods have been shown to be effective in representing ground-state wave functions of quantum many-body systems. Existing methods use convolutional neural networks (CNNs) for square lattices due to their image-like structures. For non-square lattices, existing method uses graph neural network (GNN) in which structure information is not precisely captured, thereby requiring additional hand-crafted sublattice encoding. In this work, we propose lattice convolutions in which a set of proposed operations are used to convert non-square lattices into grid-like augmented lattices on which regular convolution can be applied. Based on the proposed lattice convolutions, we design lattice convolutional networks (LCN) that use self-gating and attention mechanisms. Experimental results show that our method achieves performance on par or better than existing methods on spin 1/2 $J_1$-$J_2$ Heisenberg model over the square, honeycomb, triangular, and kagome lattices while without using hand-crafted encoding. ",
    "url": "https://arxiv.org/abs/2206.07370",
    "authors": [
      "Cong Fu",
      "Xuan Zhang",
      "Huixin Zhang",
      "Hongyi Ling",
      "Shenglong Xu",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07388",
    "title": "Subsurface Depths Structure Maps Reconstruction with Generative  Adversarial Networks",
    "abstract": "This paper described a method for reconstruction of detailed-resolution depth structure maps, usually obtained after the 3D seismic surveys, using the data from 2D seismic depth maps. The method uses two algorithms based on the generative-adversarial neural network architecture. The first algorithm StyleGAN2-ADA accumulates in the hidden space of the neural network the semantic images of mountainous terrain forms first, and then with help of transfer learning, in the ideal case - the structure geometry of stratigraphic horizons. The second algorithm, the Pixel2Style2Pixel encoder, using the semantic level of generalization of the first algorithm, learns to reconstruct the original high-resolution images from their degraded copies (super-resolution technology). There was demonstrated a methodological approach to transferring knowledge on the structural forms of stratigraphic horizon boundaries from the well-studied areas to the underexplored ones. Using the multimodal synthesis of Pixel2Style2Pixel encoder, it is proposed to create a probabilistic depth space, where each point of the project area is represented by the density of probabilistic depth distribution of equally probable reconstructed geological forms of structural images. Assessment of the reconstruction quality was carried out for two blocks. Using this method, credible detailed depth reconstructions comparable with the quality of 3D seismic maps have been obtained from 2D seismic maps. ",
    "url": "https://arxiv.org/abs/2206.07388",
    "authors": [
      "Dmitry Ivlev"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07422",
    "title": "Deep Neural Network Pruning for Nuclei Instance Segmentation in  Hematoxylin & Eosin-Stained Histological Images",
    "abstract": "Recently, pruning deep neural networks (DNNs) has received a lot of attention for improving accuracy and generalization power, reducing network size, and increasing inference speed on specialized hardwares. Although pruning was mainly tested on computer vision tasks, its application in the context of medical image analysis has hardly been explored. This work investigates the impact of well-known pruning techniques, namely layer-wise and network-wide magnitude pruning, on the nuclei instance segmentation performance in histological images. Our utilized instance segmentation model consists of two main branches: (1) a semantic segmentation branch, and (2) a deep regression branch. We investigate the impact of weight pruning on the performance of both branches separately and on the final nuclei instance segmentation result. Evaluated on two publicly available datasets, our results show that layer-wise pruning delivers slightly better performance than networkwide pruning for small compression ratios (CRs) while for large CRs, network-wide pruning yields superior performance. For semantic segmentation, deep regression and final instance segmentation, 93.75 %, 95 %, and 80 % of the model weights can be pruned by layer-wise pruning with less than 2 % reduction in the performance of respective models. ",
    "url": "https://arxiv.org/abs/2206.07422",
    "authors": [
      "Amirreza Mahbod",
      "Rahim Entezari",
      "Isabella Ellinger",
      "Olga Saukh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07481",
    "title": "A Survey of Detection Methods for Die Attachment and Wire Bonding  Defects in Integrated Circuit Manufacturing",
    "abstract": "Defect detection plays a vital role in the manufacturing process of integrated circuits (ICs). Die attachment and wire bonding are two steps of the manufacturing process that determine the quality and reliability of the power and signal transmission in an IC. This paper presents a survey or literature review of the methods used for detecting these defects based on different sensing modalities used including optical, radiological, acoustical, and infrared thermography. A discussion of the detection methods used is provided in this survey. Both conventional and deep learning approaches for detecting die attachment and wire bonding defects are considered along with challenges and future research directions. ",
    "url": "https://arxiv.org/abs/2206.07481",
    "authors": [
      "Lamia Alam",
      "Nasser Kehtarnavaz"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07515",
    "title": "A Deep Learning Network for the Classification of Intracardiac  Electrograms in Atrial Tachycardia",
    "abstract": "A key technology enabling the success of catheter ablation treatment for atrial tachycardia is activation mapping, which relies on manual local activation time (LAT) annotation of all acquired intracardiac electrogram (EGM) signals. This is a time-consuming and error-prone procedure, due to the difficulty in identifying the signal activation peaks for fractionated signals. This work presents a Deep Learning approach for the automated classification of EGM signals into three different types: normal, abnormal, and unclassified, which forms part of the LAT annotation pipeline, and contributes towards bypassing the need for manual annotations of the LAT. The Deep Learning network, the CNN-LSTM model, is a hybrid network architecture which combines convolutional neural network (CNN) layers with long short-term memory (LSTM) layers. 1452 EGM signals from a total of 9 patients undergoing clinically-indicated 3D cardiac mapping were used for the training, validation and testing of our models. From our findings, the CNN-LSTM model achieved an accuracy of 81% for the balanced dataset. For comparison, we separately developed a rule-based Decision Trees model which attained an accuracy of 67% for the same balanced dataset. Our work elucidates that analysing the EGM signals using a set of explicitly specified rules as proposed by the Decision Trees model is not suitable as EGM signals are complex. The CNN-LSTM model, on the other hand, has the ability to learn the complex, intrinsic features within the signals and identify useful features to differentiate the EGM signals. ",
    "url": "https://arxiv.org/abs/2206.07515",
    "authors": [
      "Zerui Chen",
      "Sonia Xhyn Teo",
      "Andrie Ochtman",
      "Shier Nee Saw",
      "Nicholas Cheng",
      "Eric Tien Siang Lim",
      "Murphy Lyu",
      "Hwee Kuan Lee"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07518",
    "title": "Binary Single-dimensional Convolutional Neural Network for Seizure  Prediction",
    "abstract": "Nowadays, several deep learning methods are proposed to tackle the challenge of epileptic seizure prediction. However, these methods still cannot be implemented as part of implantable or efficient wearable devices due to their large hardware and corresponding high-power consumption. They usually require complex feature extraction process, large memory for storing high precision parameters and complex arithmetic computation, which greatly increases required hardware resources. Moreover, available yield poor prediction performance, because they adopt network architecture directly from image recognition applications fails to accurately consider the characteristics of EEG signals. We propose in this paper a hardware-friendly network called Binary Single-dimensional Convolutional Neural Network (BSDCNN) intended for epileptic seizure prediction. BSDCNN utilizes 1D convolutional kernels to improve prediction performance. All parameters are binarized to reduce the required computation and storage, except the first layer. Overall area under curve, sensitivity, and false prediction rate reaches 0.915, 89.26%, 0.117/h and 0.970, 94.69%, 0.095/h on American Epilepsy Society Seizure Prediction Challenge (AES) dataset and the CHB-MIT one respectively. The proposed architecture outperforms recent works while offering 7.2 and 25.5 times reductions on the size of parameter and computation, respectively. ",
    "url": "https://arxiv.org/abs/2206.07518",
    "authors": [
      "Shiqi Zhao",
      "Jie Yang",
      "Yankun Xu",
      "Mohamad Sawan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07519",
    "title": "Smart Meter Data Anomaly Detection using Variational Recurrent  Autoencoders with Attention",
    "abstract": "In the digitization of energy systems, sensors and smart meters are increasingly being used to monitor production, operation and demand. Detection of anomalies based on smart meter data is crucial to identify potential risks and unusual events at an early stage, which can serve as a reference for timely initiation of appropriate actions and improving management. However, smart meter data from energy systems often lack labels and contain noise and various patterns without distinctively cyclical. Meanwhile, the vague definition of anomalies in different energy scenarios and highly complex temporal correlations pose a great challenge for anomaly detection. Many traditional unsupervised anomaly detection algorithms such as cluster-based or distance-based models are not robust to noise and not fully exploit the temporal dependency in a time series as well as other dependencies amongst multiple variables (sensors). This paper proposes an unsupervised anomaly detection method based on a Variational Recurrent Autoencoder with attention mechanism. with \"dirty\" data from smart meters, our method pre-detects missing values and global anomalies to shrink their contribution while training. This paper makes a quantitative comparison with the VAE-based baseline approach and four other unsupervised learning methods, demonstrating its effectiveness and superiority. This paper further validates the proposed method by a real case study of detecting the anomalies of water supply temperature from an industrial heating plant. ",
    "url": "https://arxiv.org/abs/2206.07519",
    "authors": [
      "Wenjing Dai",
      "Xiufeng Liu",
      "Alfred Heller",
      "Per Sieverts Nielsen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07571",
    "title": "Efficient decoding up to a constant fraction of the code length for  asymptotically good quantum codes",
    "abstract": "We introduce and analyse an efficient decoder for the quantum Tanner codes of that can correct adversarial errors of linear weight. Previous decoders for quantum low-density parity-check codes could only handle adversarial errors of weight $O(\\sqrt{n \\log n})$. We also work on the link between quantum Tanner codes and the Lifted Product codes of Panteleev and Kalachev, and show that our decoder can be adapted to the latter. The decoding algorithm alternates between sequential and parallel procedures and converges in linear time. ",
    "url": "https://arxiv.org/abs/2206.07571",
    "authors": [
      "Anthony Leverrier",
      "Gilles Z\u00e9mor"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2206.07594",
    "title": "Robust and Sparse Estimation of Linear Regression Coefficients with  Heavy-tailed Noises and Covariates",
    "abstract": "Robust and sparse estimation of linear regression coefficients is investigated. The situation addressed by the present paper is that covariates and noises are sampled from heavy-tailed distributions, and the covariates and noises are contaminated by malicious outliers. Our estimator can be computed efficiently. Further, our estimation error bound is sharp. ",
    "url": "https://arxiv.org/abs/2206.07594",
    "authors": [
      "Takeyuki Sasai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07595",
    "title": "BIO-CXRNET: A Robust Multimodal Stacking Machine Learning Technique for  Mortality Risk Prediction of COVID-19 Patients using Chest X-Ray Images and  Clinical Data",
    "abstract": "Fast and accurate detection of the disease can significantly help in reducing the strain on the healthcare facility of any country to reduce the mortality during any pandemic. The goal of this work is to create a multimodal system using a novel machine learning framework that uses both Chest X-ray (CXR) images and clinical data to predict severity in COVID-19 patients. In addition, the study presents a nomogram-based scoring technique for predicting the likelihood of death in high-risk patients. This study uses 25 biomarkers and CXR images in predicting the risk in 930 COVID-19 patients admitted during the first wave of COVID-19 (March-June 2020) in Italy. The proposed multimodal stacking technique produced the precision, sensitivity, and F1-score, of 89.03%, 90.44%, and 89.03%, respectively to identify low or high-risk patients. This multimodal approach improved the accuracy by 6% in comparison to the CXR image or clinical data alone. Finally, nomogram scoring system using multivariate logistic regression -- was used to stratify the mortality risk among the high-risk patients identified in the first stage. Lactate Dehydrogenase (LDH), O2 percentage, White Blood Cells (WBC) Count, Age, and C-reactive protein (CRP) were identified as useful predictor using random forest feature selection model. Five predictors parameters and a CXR image based nomogram score was developed for quantifying the probability of death and categorizing them into two risk groups: survived (<50%), and death (>=50%), respectively. The multi-modal technique was able to predict the death probability of high-risk patients with an F1 score of 92.88 %. The area under the curves for the development and validation cohorts are 0.981 and 0.939, respectively. ",
    "url": "https://arxiv.org/abs/2206.07595",
    "authors": [
      "Tawsifur Rahman",
      "Muhammad E. H. Chowdhury",
      "Amith Khandakar",
      "Zaid Bin Mahbub",
      "Md Sakib Abrar Hossain",
      "Abraham Alhatou",
      "Eynas Abdalla",
      "Sreekumar Muthiyal",
      "Khandaker Farzana Islam",
      "Saad Bin Abul Kashem",
      "Muhammad Salman Khan",
      "Susu M. Zughaier",
      "Maqsud Hossain"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07599",
    "title": "How GNNs Facilitate CNNs in Mining Geometric Information from  Large-Scale Medical Images",
    "abstract": "Gigapixel medical images provide massive data, both morphological textures and spatial information, to be mined. Due to the large data scale in histology, deep learning methods play an increasingly significant role as feature extractors. Existing solutions heavily rely on convolutional neural networks (CNNs) for global pixel-level analysis, leaving the underlying local geometric structure such as the interaction between cells in the tumor microenvironment unexplored. The topological structure in medical images, as proven to be closely related to tumor evolution, can be well characterized by graphs. To obtain a more comprehensive representation for downstream oncology tasks, we propose a fusion framework for enhancing the global image-level representation captured by CNNs with the geometry of cell-level spatial information learned by graph neural networks (GNN). The fusion layer optimizes an integration between collaborative features of global images and cell graphs. Two fusion strategies have been developed: one with MLP which is simple but turns out efficient through fine-tuning, and the other with Transformer gains a champion in fusing multiple networks. We evaluate our fusion strategies on histology datasets curated from large patient cohorts of colorectal and gastric cancers for three biomarker prediction tasks. Both two models outperform plain CNNs or GNNs, reaching a consistent AUC improvement of more than 5% on various network backbones. The experimental results yield the necessity for combining image-level morphological features with cell spatial relations in medical image analysis. Codes are available at https://github.com/yiqings/HEGnnEnhanceCnn. ",
    "url": "https://arxiv.org/abs/2206.07599",
    "authors": [
      "Yiqing Shen",
      "Bingxin Zhou",
      "Xinye Xiong",
      "Ruitian Gao",
      "Yu Guang Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07602",
    "title": "Sparse Subspace Clustering in Diverse Multiplex Network Model",
    "abstract": "The paper considers the DIverse MultiPLEx (DIMPLE) network model, introduced in Pensky and Wang (2021), where all layers of the network have the same collection of nodes and are equipped with the Stochastic Block Models. In addition, all layers can be partitioned into groups with the same community structures, although the layers in the same group may have different matrices of block connection probabilities. The DIMPLE model generalizes a multitude of papers that study multilayer networks with the same community structures in all layers, as well as the Mixture Multilayer Stochastic Block Model (MMLSBM), where the layers in the same group have identical matrices of block connection probabilities. While Pensky and Wang (2021) applied spectral clustering to the proxy of the adjacency tensor, the present paper uses Sparse Subspace Clustering (SSC) for identifying groups of layers with identical community structures. Under mild conditions, the latter leads to the strongly consistent between-layer clustering. In addition, SSC allows to handle much larger networks than methodology of Pensky and Wang (2021), and is perfectly suitable for application of parallel computing. ",
    "url": "https://arxiv.org/abs/2206.07602",
    "authors": [
      "Majid Noroozi",
      "Marianna Pensky"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.07649",
    "title": "Atrial Fibrillation Detection Using Weight-Pruned, Log-Quantised  Convolutional Neural Networks",
    "abstract": "Deep neural networks (DNN) are a promising tool in medical applications. However, the implementation of complex DNNs on battery-powered devices is challenging due to high energy costs for communication. In this work, a convolutional neural network model is developed for detecting atrial fibrillation from electrocardiogram (ECG) signals. The model demonstrates high performance despite being trained on limited, variable-length input data. Weight pruning and logarithmic quantisation are combined to introduce sparsity and reduce model size, which can be exploited for reduced data movement and lower computational complexity. The final model achieved a 91.1% model compression ratio while maintaining high model accuracy of 91.7% and less than 1% loss. ",
    "url": "https://arxiv.org/abs/2206.07649",
    "authors": [
      "Xiu Qi Chang",
      "Ann Feng Chew",
      "Benjamin Chen Ming Choong",
      "Shuhui Wang",
      "Rui Han",
      "Wang He",
      "Li Xiaolin",
      "Rajesh C. Panicker",
      "Deepu John"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07654",
    "title": "Human Activity Recognition on Time Series Accelerometer Sensor Data  using LSTM Recurrent Neural Networks",
    "abstract": "The use of sensors available through smart devices has pervaded everyday life in several applications including human activity monitoring, healthcare, and social networks. In this study, we focus on the use of smartwatch accelerometer sensors to recognize eating activity. More specifically, we collected sensor data from 10 participants while consuming pizza. Using this information, and other comparable data available for similar events such as smoking and medication-taking, and dissimilar activities of jogging, we developed a LSTM-ANN architecture that has demonstrated 90% success in identifying individual bites compared to a puff, medication-taking or jogging activities. ",
    "url": "https://arxiv.org/abs/2206.07654",
    "authors": [
      "Chrisogonas O. Odhiambo",
      "Sanjoy Saha",
      "Corby K. Martin",
      "Homayoun Valafar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07656",
    "title": "Analysis of Augmentations for Contrastive ECG Representation Learning",
    "abstract": "This paper systematically investigates the effectiveness of various augmentations for contrastive self-supervised learning of electrocardiogram (ECG) signals and identifies the best parameters. The baseline of our proposed self-supervised framework consists of two main parts: the contrastive learning and the downstream task. In the first stage, we train an encoder using a number of augmentations to extract generalizable ECG signal representations. We then freeze the encoder and finetune a few linear layers with different amounts of labelled data for downstream arrhythmia detection. We then experiment with various augmentations techniques and explore a range of parameters. Our experiments are done on PTB-XL, a large and publicly available 12-lead ECG dataset. The results show that applying augmentations in a specific range of complexities works better for self-supervised contrastive learning. For instance, when adding Gaussian noise, a sigma in the range of 0.1 to 0.2 achieves better results, while poor training occurs when the added noise is too small or too large (outside of the specified range). A similar trend is observed with other augmentations, demonstrating the importance of selecting the optimum level of difficulty for the added augmentations, as augmentations that are too simple will not result in effective training, while augmentations that are too difficult will also prevent the model from effective learning of generalized representations. Our work can influence future research on self-supervised contrastive learning on bio-signals and aid in selecting optimum parameters for different augmentations. ",
    "url": "https://arxiv.org/abs/2206.07656",
    "authors": [
      "Sahar Soltanieh",
      "Ali Etemad",
      "Javad Hashemi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07673",
    "title": "Wide Bayesian neural networks have a simple weight posterior: theory and  accelerated sampling",
    "abstract": "We introduce repriorisation, a data-dependent reparameterisation which transforms a Bayesian neural network (BNN) posterior to a distribution whose KL divergence to the BNN prior vanishes as layer widths grow. The repriorisation map acts directly on parameters, and its analytic simplicity complements the known neural network Gaussian process (NNGP) behaviour of wide BNNs in function space. Exploiting the repriorisation, we develop a Markov chain Monte Carlo (MCMC) posterior sampling algorithm which mixes faster the wider the BNN. This contrasts with the typically poor performance of MCMC in high dimensions. We observe up to 50x higher effective sample size relative to no reparametrisation for both fully-connected and residual networks. Improvements are achieved at all widths, with the margin between reparametrised and standard BNNs growing with layer width. ",
    "url": "https://arxiv.org/abs/2206.07673",
    "authors": [
      "Jiri Hron",
      "Roman Novak",
      "Jeffrey Pennington",
      "Jascha Sohl-Dickstein"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07697",
    "title": "MACE: Higher Order Equivariant Message Passing Neural Networks for Fast  and Accurate Force Fields",
    "abstract": "Creating fast and accurate force fields is a long-standing challenge in computational chemistry and materials science. Recently, several equivariant message passing neural networks (MPNNs) have been shown to outperform models built using other approaches in terms of accuracy. However, most MPNNs suffer from high computational cost and poor scalability. We propose that these limitations arise because MPNNs only pass two-body messages leading to a direct relationship between the number of layers and the expressivity of the network. In this work, we introduce MACE, a new equivariant MPNN model that uses higher body order messages. In particular, we show that using four-body messages reduces the required number of message passing iterations to just \\emph{two}, resulting in a fast and highly parallelizable model, reaching or exceeding state-of-the-art accuracy on the rMD17, 3BPA, and AcAc benchmark tasks. We also demonstrate that using higher order messages leads to an improved steepness of the learning curves. ",
    "url": "https://arxiv.org/abs/2206.07697",
    "authors": [
      "Ilyes Batatia",
      "D\u00e1vid P\u00e9ter Kov\u00e1cs",
      "Gregor N. C. Simm",
      "Christoph Ortner",
      "G\u00e1bor Cs\u00e1nyi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:1908.09042",
    "title": "SIDLE: Semantically Intelligent Distributed Leader Election Algorithm  for Wireless Sensor Networks",
    "abstract": " Comments: not agreed anymore ",
    "url": "https://arxiv.org/abs/1908.09042",
    "authors": [
      "Parsa Rajabzadeh",
      "Amin Pishevar",
      "Hamed Rahimi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:1909.10480",
    "title": "FENCE: Feasible Evasion Attacks on Neural Networks in Constrained  Environments",
    "abstract": " Comments: 35 pages ",
    "url": "https://arxiv.org/abs/1909.10480",
    "authors": [
      "Alesia Chernikova",
      "Alina Oprea"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2004.03637",
    "title": "Probabilistic Spatial Transformer Networks",
    "abstract": " Comments: UAI 2022 ",
    "url": "https://arxiv.org/abs/2004.03637",
    "authors": [
      "Pola Schw\u00f6bel",
      "Frederik Warburg",
      "Martin J\u00f8rgensen",
      "Kristoffer H. Madsen",
      "S\u00f8ren Hauberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2101.00612",
    "title": "Evolutionary Mutation-based Fuzzing as Monte Carlo Tree Search",
    "abstract": " Title: Evolutionary Mutation-based Fuzzing as Monte Carlo Tree Search ",
    "url": "https://arxiv.org/abs/2101.00612",
    "authors": [
      "Yiru Zhao",
      "Xiaoke Wang",
      "Lei Zhao",
      "Yueqiang Cheng",
      "Heng Yin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2103.02174",
    "title": "Dynamic Offloading Design in Time-Varying Mobile Edge Networks with Deep  Reinforcement Learning Approach",
    "abstract": " Title: Dynamic Offloading Design in Time-Varying Mobile Edge Networks with Deep  Reinforcement Learning Approach ",
    "url": "https://arxiv.org/abs/2103.02174",
    "authors": [
      "Liang Yu",
      "Rui Wang",
      "Minyan Shi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2103.16255",
    "title": "Towards Understanding Adversarial Robustness of Optical Flow Networks",
    "abstract": " Comments: CVPR 2022 ",
    "url": "https://arxiv.org/abs/2103.16255",
    "authors": [
      "Simon Schrodi",
      "Tonmoy Saikia",
      "Thomas Brox"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.12697",
    "title": "Can Linear Programs Have Adversarial Examples? A Causal Perspective",
    "abstract": " Comments: Main paper: 9 pages, References: 2 page, Supplement: 2 pages. Main paper: 2 figures, 3 tables, Supplement: 1 figure, 1 table ",
    "url": "https://arxiv.org/abs/2105.12697",
    "authors": [
      "Matej Ze\u010devi\u0107",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2106.04486",
    "title": "Sketch-Based Anomaly Detection in Streaming Graphs",
    "abstract": " Title: Sketch-Based Anomaly Detection in Streaming Graphs ",
    "url": "https://arxiv.org/abs/2106.04486",
    "authors": [
      "Siddharth Bhatia",
      "Mohit Wadhwa",
      "Kenji Kawaguchi",
      "Neil Shah",
      "Philip S. Yu",
      "Bryan Hooi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.11156",
    "title": "Training a neural network with exciton-polariton optical nonlinearity",
    "abstract": " Title: Training a neural network with exciton-polariton optical nonlinearity ",
    "url": "https://arxiv.org/abs/2107.11156",
    "authors": [
      "Andrzej Opala",
      "Riccardo Panico",
      "Vincenzo Ardizzone",
      "Barbara Pietka",
      "Jacek Szczytko",
      "Daniele Sanvitto",
      "Micha\u0142 Matuszewski",
      "Dario Ballarini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Quantum Gases (cond-mat.quant-gas)"
    ]
  },
  {
    "id": "arXiv:2108.08842",
    "title": "EDEN: Communication-Efficient and Robust Distributed Mean Estimation for  Federated Learning",
    "abstract": " Comments: To appear in ICML 2022 ",
    "url": "https://arxiv.org/abs/2108.08842",
    "authors": [
      "Shay Vargaftik",
      "Ran Ben Basat",
      "Amit Portnoy",
      "Gal Mendelson",
      "Yaniv Ben-Itzhak",
      "Michael Mitzenmacher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2108.09375",
    "title": "Cascade Watchdog: A Multi-tiered Adversarial Guard for Outlier Detection",
    "abstract": " Title: Cascade Watchdog: A Multi-tiered Adversarial Guard for Outlier Detection ",
    "url": "https://arxiv.org/abs/2108.09375",
    "authors": [
      "Glauco Amigo",
      "Justin M. Bui",
      "Charles Baylis",
      "Robert J. Marks"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.11145",
    "title": "Dynamic DV-QKD Networking in Fully-Meshed Software-Defined Optical  Networks",
    "abstract": " Comments: 9 pages, 5 figures, submitted to IEEE Journal of Lightwave Technology ",
    "url": "https://arxiv.org/abs/2108.11145",
    "authors": [
      "Obada Alia",
      "Rodrigo Stange Tessinari",
      "Emilio Hugues-Salas",
      "George T. Kanellos",
      "Reza Nejabati",
      "Dimitra Simeonidou"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2109.04352",
    "title": "PhysGNN: A Physics-Driven Graph Neural Network Based Model for  Predicting Soft Tissue Deformation in Image-Guided Neurosurgery",
    "abstract": " Comments: Preprint ",
    "url": "https://arxiv.org/abs/2109.04352",
    "authors": [
      "Yasmin Salehi",
      "Dennis Giannacopoulos"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.02395",
    "title": "XAI Establishes a Common Ground Between Machine Learning and Causality",
    "abstract": " Comments: Main paper: 9 pages, References: 2.5 pages, Supplement: 17 pages. Main paper: 5 figures, 1 table, Supplement: 12 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2110.02395",
    "authors": [
      "Matej Ze\u010devi\u0107",
      "Devendra Singh Dhami",
      "Constantin A. Rothkopf",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.02911",
    "title": "Shifting Capsule Networks from the Cloud to the Deep Edge",
    "abstract": " Title: Shifting Capsule Networks from the Cloud to the Deep Edge ",
    "url": "https://arxiv.org/abs/2110.02911",
    "authors": [
      "Miguel Costa",
      "Diogo Costa",
      "Tiago Gomes",
      "Sandro Pinto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.03031",
    "title": "RieszNet and ForestRiesz: Automatic Debiased Machine Learning with  Neural Nets and Random Forests",
    "abstract": " Comments: Accepted for a long presentation at the ICML. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2110.03031",
    "authors": [
      "Victor Chernozhukov",
      "Whitney K. Newey",
      "Victor Quintas-Martinez",
      "Vasilis Syrgkanis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.03054",
    "title": "On the Privacy Risks of Deploying Recurrent Neural Networks in Machine  Learning Models",
    "abstract": " Comments: Under Double-Blind Review ",
    "url": "https://arxiv.org/abs/2110.03054",
    "authors": [
      "Yunhao Yang",
      "Parham Gohari",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.03299",
    "title": "End-To-End Label Uncertainty Modeling for Speech-based Arousal  Recognition Using Bayesian Neural Networks",
    "abstract": " Comments: ACCEPTED to INTERSPEECH 2022 ",
    "url": "https://arxiv.org/abs/2110.03299",
    "authors": [
      "Navin Raj Prabhu",
      "Guillaume Carbajal",
      "Nale Lehmann-Willenbrock",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2110.06988",
    "title": "Spectral Convergence of Symmetrized Graph Laplacian on manifolds with  boundary",
    "abstract": " Comments: 6 figures ",
    "url": "https://arxiv.org/abs/2110.06988",
    "authors": [
      "J. Wilson Peoples",
      "John Harlim"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2110.10017",
    "title": "Neural Network Compatible Off-Policy Natural Actor-Critic Algorithm",
    "abstract": " Comments: This paper has been accepted for presentation at the IJCNN at IEEE WCCI 2022 and for publication in the conference proceedings published by IEEE ",
    "url": "https://arxiv.org/abs/2110.10017",
    "authors": [
      "Raghuram Bharadwaj Diddigi",
      "Prateek Jain",
      "Prabuchandran K.J.",
      "Shalabh Bhatnagar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.07964",
    "title": "Deep Network Approximation in Terms of Intrinsic Parameters",
    "abstract": " Title: Deep Network Approximation in Terms of Intrinsic Parameters ",
    "url": "https://arxiv.org/abs/2111.07964",
    "authors": [
      "Zuowei Shen",
      "Haizhao Yang",
      "Shijun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.09631",
    "title": "Neural Network Kalman filtering for 3D object tracking from linear array  ultrasound data",
    "abstract": " Comments: 13 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2111.09631",
    "authors": [
      "Arttu Arjas",
      "Erwin J. Alles",
      "Efthymios Maneas",
      "Simon Arridge",
      "Adrien Desjardins",
      "Mikko J. Sillanp\u00e4\u00e4",
      "Andreas Hauptmann"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.13336",
    "title": "MAE-DET: Revisiting Maximum Entropy Principle in Zero-Shot NAS for  Efficient Object Detection",
    "abstract": " Comments: Accepted by ICML 2022 ",
    "url": "https://arxiv.org/abs/2111.13336",
    "authors": [
      "Zhenhong Sun",
      "Ming Lin",
      "Xiuyu Sun",
      "Zhiyu Tan",
      "Hao Li",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.05307",
    "title": "Are We There Yet? Timing and Floating-Point Attacks on Differential  Privacy Systems",
    "abstract": " Comments: In Proceedings of the 43rd IEEE Symposium on Security and Privacy (IEEE S&P 2022) ",
    "url": "https://arxiv.org/abs/2112.05307",
    "authors": [
      "Jiankai Jin",
      "Eleanor McMurtry",
      "Benjamin I. P. Rubinstein",
      "Olga Ohrimenko"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.00233",
    "title": "A new criterion for $\\mathcal{M}, \\mathcal{N}$-adhesivity, with an  application to hierarchical graphs",
    "abstract": " Title: A new criterion for $\\mathcal{M}, \\mathcal{N}$-adhesivity, with an  application to hierarchical graphs ",
    "url": "https://arxiv.org/abs/2201.00233",
    "authors": [
      "Davide Castelnovo",
      "Fabio Gadducci",
      "Marino Miculan"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)",
      "Logic (math.LO)"
    ]
  },
  {
    "id": "arXiv:2201.04387",
    "title": "Maximizing Self-supervision from Thermal Image for Effective  Self-supervised Learning of Depth and Ego-motion",
    "abstract": " Comments: 8 pages, Accepted by IEEE Robotics and Automation Letters (RA-L) with IROS 2022 option ",
    "url": "https://arxiv.org/abs/2201.04387",
    "authors": [
      "Ukcheol Shin",
      "Kyunghyun Lee",
      "Byeong-Uk Lee",
      "In So Kweon"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.12078",
    "title": "You Only Cut Once: Boosting Data Augmentation with a Single Cut",
    "abstract": " Comments: ICML 2022, Code: this https URL ",
    "url": "https://arxiv.org/abs/2201.12078",
    "authors": [
      "Junlin Han",
      "Pengfei Fang",
      "Weihao Li",
      "Jie Hong",
      "Mohammad Ali Armin",
      "Ian Reid",
      "Lars Petersson",
      "Hongdong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.00211",
    "title": "GNNRank: Learning Global Rankings from Pairwise Comparisons via Directed  Graph Neural Networks",
    "abstract": " Comments: ICML 2022 spotlight; 32 pages (9 pages for main text) ",
    "url": "https://arxiv.org/abs/2202.00211",
    "authors": [
      "Yixuan He",
      "Quan Gan",
      "David Wipf",
      "Gesine Reinert",
      "Junchi Yan",
      "Mihai Cucuringu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.01627",
    "title": "Non-Vacuous Generalisation Bounds for Shallow Neural Networks",
    "abstract": " Comments: 19 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2202.01627",
    "authors": [
      "Felix Biggs",
      "Benjamin Guedj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.02514",
    "title": "Score-based Generative Modeling of Graphs via the System of Stochastic  Differential Equations",
    "abstract": " Comments: ICML 2022 ",
    "url": "https://arxiv.org/abs/2202.02514",
    "authors": [
      "Jaehyeong Jo",
      "Seul Lee",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03169",
    "title": "CITRIS: Causal Identifiability from Temporal Intervened Sequences",
    "abstract": " Comments: Accepted at the International Conference on Machine Learning (ICML), 2022 ",
    "url": "https://arxiv.org/abs/2202.03169",
    "authors": [
      "Phillip Lippe",
      "Sara Magliacane",
      "Sindy L\u00f6we",
      "Yuki M. Asano",
      "Taco Cohen",
      "Efstratios Gavves"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2202.09048",
    "title": "Task Specific Attention is one more thing you need for object detection",
    "abstract": " Title: Task Specific Attention is one more thing you need for object detection ",
    "url": "https://arxiv.org/abs/2202.09048",
    "authors": [
      "Sang Yon Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01474",
    "title": "Spatio-Temporal Gating-Adjacency GCN for Human Motion Prediction",
    "abstract": " Title: Spatio-Temporal Gating-Adjacency GCN for Human Motion Prediction ",
    "url": "https://arxiv.org/abs/2203.01474",
    "authors": [
      "Chongyang Zhong",
      "Lei Hu",
      "Zihao Zhang",
      "Yongjing Ye",
      "Shihong Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.02502",
    "title": "No More Than 6ft Apart: Robust K-Means via Radius Upper Bounds",
    "abstract": " Comments: Accepted for ICASSP 2022, 8 figures, 1 table ",
    "url": "https://arxiv.org/abs/2203.02502",
    "authors": [
      "Ahmed Imtiaz Humayun",
      "Randall Balestriero",
      "Anastasios Kyrillidis",
      "Richard Baraniuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.05625",
    "title": "PETR: Position Embedding Transformation for Multi-View 3D Object  Detection",
    "abstract": " Comments: Tech Report. Code is available at \\url{this https URL} ",
    "url": "https://arxiv.org/abs/2203.05625",
    "authors": [
      "Yingfei Liu",
      "Tiancai Wang",
      "Xiangyu Zhang",
      "Jian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.12369",
    "title": "MetricGAN+/-: Increasing Robustness of Noise Reduction on Unseen Data",
    "abstract": " Comments: 5 pages, 4 figures, Accepted to EUSIPCO 2022 ",
    "url": "https://arxiv.org/abs/2203.12369",
    "authors": [
      "George Close",
      "Thomas Hain",
      "Stefan Goetze"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.01855",
    "title": "A Survey on Graph Representation Learning Methods",
    "abstract": " Title: A Survey on Graph Representation Learning Methods ",
    "url": "https://arxiv.org/abs/2204.01855",
    "authors": [
      "Shima Khoshraftar",
      "Aijun An"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.02033",
    "title": "Learning to Reduce Information Bottleneck for Object Detection in Aerial  Images",
    "abstract": " Comments: 5 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2204.02033",
    "authors": [
      "Yuchen Shen",
      "Dong Zhang",
      "Zhihao Song",
      "Xuesong Jiang",
      "Qiaolin Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05112",
    "title": "FastMapSVM: Classifying Complex Objects Using the FastMap Algorithm and  Support-Vector Machines",
    "abstract": " Comments: 27 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2204.05112",
    "authors": [
      "Malcolm C. A. White",
      "Kushal Sharma",
      "Ang Li",
      "T. K. Satish Kumar",
      "Nori Nakata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2204.08198",
    "title": "UTNLP at SemEval-2022 Task 6: A Comparative Analysis of Sarcasm  Detection using generative-based and mutation-based data augmentation",
    "abstract": " Comments: 6 pages, 2 figures, International Workshop on Semantic Evaluation co-located with NAACL ",
    "url": "https://arxiv.org/abs/2204.08198",
    "authors": [
      "Amirhossein Abaskohi",
      "Arash Rasouli",
      "Tanin Zeraati",
      "Behnam Bahrak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.11515",
    "title": "Multimodal Dual Emotion with Fusion of Visual Sentiment for Rumor  Detection",
    "abstract": " Comments: submitted TMM ",
    "url": "https://arxiv.org/abs/2204.11515",
    "authors": [
      "Ge Wang",
      "Li Tan",
      "Ziliang Shang",
      "He Liu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.13843",
    "title": "VPNets: Volume-preserving neural networks for learning source-free  dynamics",
    "abstract": " Title: VPNets: Volume-preserving neural networks for learning source-free  dynamics ",
    "url": "https://arxiv.org/abs/2204.13843",
    "authors": [
      "Aiqing Zhu",
      "Beibei Zhu",
      "Jiawei Zhang",
      "Yifa Tang",
      "Jian Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.05871",
    "title": "Towards Robust Unsupervised Disentanglement of Sequential Data -- A Case  Study Using Music Audio",
    "abstract": " Comments: The paper is accepted to IJCAI 2022 ",
    "url": "https://arxiv.org/abs/2205.05871",
    "authors": [
      "Yin-Jyun Luo",
      "Sebastian Ewert",
      "Simon Dixon"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.08479",
    "title": "Opportunistic Routing in Quantum Networks",
    "abstract": " Comments: This version extends our INFOCOM'2022 paper by adding more analysis and simulations ",
    "url": "https://arxiv.org/abs/2205.08479",
    "authors": [
      "Ali Farahbakhsh",
      "Chen Feng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.10643",
    "title": "Self-Supervised Speech Representation Learning: A Review",
    "abstract": " Title: Self-Supervised Speech Representation Learning: A Review ",
    "url": "https://arxiv.org/abs/2205.10643",
    "authors": [
      "Abdelrahman Mohamed",
      "Hung-yi Lee",
      "Lasse Borgholt",
      "Jakob D. Havtorn",
      "Joakim Edin",
      "Christian Igel",
      "Katrin Kirchhoff",
      "Shang-Wen Li",
      "Karen Livescu",
      "Lars Maal\u00f8e",
      "Tara N. Sainath",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.12583",
    "title": "MUG: Multi-human Graph Network for 3D Mesh Reconstruction from 2D Pose",
    "abstract": " Title: MUG: Multi-human Graph Network for 3D Mesh Reconstruction from 2D Pose ",
    "url": "https://arxiv.org/abs/2205.12583",
    "authors": [
      "Chenyan Wu",
      "Yandong Li",
      "Xianfeng Tang",
      "James Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13343",
    "title": "Sliding mode control with a neural network compensation scheme for  electro-hydraulic systems",
    "abstract": " Comments: References added. This is a slightly updated version of the work presented at DINAME 2013 - XV International Symposium on Dynamic Problems of Mechanics, 2013, Arma\\c{c}\\~ao de B\\'uzios, Brazil ",
    "url": "https://arxiv.org/abs/2205.13343",
    "authors": [
      "Josiane Maria de Macedo Fernandes",
      "Marcelo Costa Tanaka",
      "Wallace Moreira Bessa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2205.14014",
    "title": "What Dense Graph Do You Need for Self-Attention?",
    "abstract": " Comments: Accepted by ICML 2022. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2205.14014",
    "authors": [
      "Yuxing Wang",
      "Chu-Tak Lee",
      "Qipeng Guo",
      "Zhangyue Yin",
      "Yunhua Zhou",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.14268",
    "title": "NeuPSL: Neural Probabilistic Soft Logic",
    "abstract": " Title: NeuPSL: Neural Probabilistic Soft Logic ",
    "url": "https://arxiv.org/abs/2205.14268",
    "authors": [
      "Connor Pryor",
      "Charles Dickens",
      "Eriq Augustine",
      "Alon Albalak",
      "William Wang",
      "Lise Getoor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.01992",
    "title": "CAINNFlow: Convolutional block Attention modules and Invertible Neural  Networks Flow for anomaly detection and localization tasks",
    "abstract": " Title: CAINNFlow: Convolutional block Attention modules and Invertible Neural  Networks Flow for anomaly detection and localization tasks ",
    "url": "https://arxiv.org/abs/2206.01992",
    "authors": [
      "Ruiqing Yan",
      "Fan Zhang",
      "Mengyuan Huang",
      "Wu Liu",
      "Dongyu Hu",
      "Jinfeng Li",
      "Qiang Liu",
      "Jingrong Jiang",
      "Qianjin Guo",
      "Linghan Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.03287",
    "title": "NeMF: Neural Motion Fields for Kinematic Animation",
    "abstract": " Comments: Our project page is available at: this https URL ",
    "url": "https://arxiv.org/abs/2206.03287",
    "authors": [
      "Chengan He",
      "Jun Saito",
      "James Zachary",
      "Holly Rushmeier",
      "Yi Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2206.03657",
    "title": "Delving into the Pre-training Paradigm of Monocular 3D Object Detection",
    "abstract": " Title: Delving into the Pre-training Paradigm of Monocular 3D Object Detection ",
    "url": "https://arxiv.org/abs/2206.03657",
    "authors": [
      "Zhuoling Li",
      "Chuanrui Zhang",
      "En Yu",
      "Haoqian Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03693",
    "title": "Autoregressive Perturbations for Data Poisoning",
    "abstract": " Comments: 22 pages, 13 figures. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2206.03693",
    "authors": [
      "Pedro Sandoval-Segura",
      "Vasu Singla",
      "Jonas Geiping",
      "Micah Goldblum",
      "Tom Goldstein",
      "David W. Jacobs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.04922",
    "title": "A Novel Chinese Dialect TTS Frontend with Non-Autoregressive Neural  Machine Translation",
    "abstract": " Comments: 5 pages,5 figures ",
    "url": "https://arxiv.org/abs/2206.04922",
    "authors": [
      "Wudi Bao",
      "Junhui Zhang",
      "Junjie Pan",
      "Xiang Yin",
      "Zejun Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.05199",
    "title": "Bayesian Estimation of Differential Privacy",
    "abstract": " Comments: 17 pages, 8 figures. Joint main authors: Santiago Zanella-B\\'eguelin, Lukas Wutschitz, and Shruti Tople ",
    "url": "https://arxiv.org/abs/2206.05199",
    "authors": [
      "Santiago Zanella-B\u00e9guelin",
      "Lukas Wutschitz",
      "Shruti Tople",
      "Ahmed Salem",
      "Victor R\u00fchle",
      "Andrew Paverd",
      "Mohammad Naseri",
      "Boris K\u00f6pf",
      "Daniel Jones"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.06445",
    "title": "Fitting Segmentation Networks on Varying Image Resolutions using  Splatting",
    "abstract": " Comments: Accepted for MIUA 2022 ",
    "url": "https://arxiv.org/abs/2206.06445",
    "authors": [
      "Mikael Brudfors",
      "Yael Balbastre",
      "John Ashburner",
      "Geraint Rees",
      "Parashkev Nachev",
      "Sebastien Ourselin",
      "M. Jorge Cardoso"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.06637",
    "title": "RF-Next: Efficient Receptive Field Search for Convolutional Neural  Networks",
    "abstract": " Comments: Accepted by TPAMI. This paper is a journal extension of our CVPR 2021 paper (arXiv:2101.00910) ",
    "url": "https://arxiv.org/abs/2206.06637",
    "authors": [
      "Shanghua Gao",
      "Zhong-Yu Li",
      "Qi Han",
      "Ming-Ming Cheng",
      "Liang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.06714",
    "title": "Interpretable Gait Recognition by Granger Causality",
    "abstract": " Comments: Preprint. Full paper accepted at the IEEE/IAPR International Conference on Pattern Recognition (ICPR), Montreal, Canada, Aug 2022. 7 pages ",
    "url": "https://arxiv.org/abs/2206.06714",
    "authors": [
      "Michal Balazia",
      "Katerina Hlavackova-Schindler",
      "Petr Sojka",
      "Claudia Plant"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.06829",
    "title": "Efficient Decoder-free Object Detection with Transformers",
    "abstract": " Title: Efficient Decoder-free Object Detection with Transformers ",
    "url": "https://arxiv.org/abs/2206.06829",
    "authors": [
      "Peixian Chen",
      "Mengdan Zhang",
      "Yunhang Shen",
      "Kekai Sheng",
      "Yuting Gao",
      "Xing Sun",
      "Ke Li",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.06885",
    "title": "Neural interval-censored Cox regression with feature selection",
    "abstract": " Title: Neural interval-censored Cox regression with feature selection ",
    "url": "https://arxiv.org/abs/2206.06885",
    "authors": [
      "Carlos Garc\u00eda Meixide",
      "Marcos Matabuena",
      "Michael R. Kosorok"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  }
]