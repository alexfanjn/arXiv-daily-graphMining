[
  {
    "id": "arXiv:2206.08369",
    "title": "Embarrassingly Parallel Independent Training of Multi-Layer Perceptrons  with Heterogeneous Architectures",
    "abstract": "The definition of a Neural Network architecture is one of the most critical and challenging tasks to perform. In this paper, we propose ParallelMLPs. ParallelMLPs is a procedure to enable the training of several independent Multilayer Perceptron Neural Networks with a different number of neurons and activation functions in parallel by exploring the principle of locality and parallelization capabilities of modern CPUs and GPUs. The core idea of this technique is to use a Modified Matrix Multiplication that replaces an ordinal matrix multiplication by two simple matrix operations that allow separate and independent paths for gradient flowing, which can be used in other scenarios. We have assessed our algorithm in simulated datasets varying the number of samples, features and batches using 10,000 different models. We achieved a training speedup from 1 to 4 orders of magnitude if compared to the sequential approach. ",
    "url": "https://arxiv.org/abs/2206.08369",
    "authors": [
      "Felipe Costa Farias",
      "Teresa Bernarda Ludermir",
      "Carmelo Jose Albanez Bastos-Filho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08407",
    "title": "Deep Multi-Task Models for Misogyny Identification and Categorization on  Arabic Social Media",
    "abstract": "The prevalence of toxic content on social media platforms, such as hate speech, offensive language, and misogyny, presents serious challenges to our interconnected society. These challenging issues have attracted widespread attention in Natural Language Processing (NLP) community. In this paper, we present the submitted systems to the first Arabic Misogyny Identification shared task. We investigate three multi-task learning models as well as their single-task counterparts. In order to encode the input text, our models rely on the pre-trained MARBERT language model. The overall obtained results show that all our submitted models have achieved the best performances (top three ranked submissions) in both misogyny identification and categorization tasks. ",
    "url": "https://arxiv.org/abs/2206.08407",
    "authors": [
      "Abdelkader El Mahdaouy",
      "Abdellah El Mekki",
      "Ahmed Oumar",
      "Hajar Mousannif",
      "Ismail Berrada"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.08415",
    "title": "CS-UM6P at SemEval-2022 Task 6: Transformer-based Models for Intended  Sarcasm Detection in English and Arabic",
    "abstract": "Sarcasm is a form of figurative language where the intended meaning of a sentence differs from its literal meaning. This poses a serious challenge to several Natural Language Processing (NLP) applications such as Sentiment Analysis, Opinion Mining, and Author Profiling. In this paper, we present our participating system to the intended sarcasm detection task in English and Arabic languages. Our system\\footnote{The source code of our system is available at \\url{https://github.com/AbdelkaderMH/iSarcasmEval}} consists of three deep learning-based models leveraging two existing pre-trained language models for Arabic and English. We have participated in all sub-tasks. Our official submissions achieve the best performance on sub-task A for Arabic language and rank second in sub-task B. For sub-task C, our system is ranked 7th and 11th on Arabic and English datasets, respectively. ",
    "url": "https://arxiv.org/abs/2206.08415",
    "authors": [
      "Abdelkader El Mahdaouy",
      "Abdellah El Mekki",
      "Kabil Essefar",
      "Abderrahman Skiredj",
      "Ismail Berrada"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.08427",
    "title": "SATBench: Benchmarking the speed-accuracy tradeoff in object recognition  by humans and dynamic neural networks",
    "abstract": "The core of everyday tasks like reading and driving is active object recognition. Attempts to model such tasks are currently stymied by the inability to incorporate time. People show a flexible tradeoff between speed and accuracy and this tradeoff is a crucial human skill. Deep neural networks have emerged as promising candidates for predicting peak human object recognition performance and neural activity. However, modeling the temporal dimension i.e., the speed-accuracy tradeoff (SAT), is essential for them to serve as useful computational models for how humans recognize objects. To this end, we here present the first large-scale (148 observers, 4 neural networks, 8 tasks) dataset of the speed-accuracy tradeoff (SAT) in recognizing ImageNet images. In each human trial, a beep, indicating the desired reaction time, sounds at a fixed delay after the image is presented, and observer's response counts only if it occurs near the time of the beep. In a series of blocks, we test many beep latencies, i.e., reaction times. We observe that human accuracy increases with reaction time and proceed to compare its characteristics with the behavior of several dynamic neural networks that are capable of inference-time adaptive computation. Using FLOPs as an analog for reaction time, we compare networks with humans on curve-fit error, category-wise correlation, and curve steepness, and conclude that cascaded dynamic neural networks are a promising model of human reaction time in object recognition tasks. ",
    "url": "https://arxiv.org/abs/2206.08427",
    "authors": [
      "Ajay Subramanian",
      "Sara Price",
      "Omkar Kumbhar",
      "Elena Sizikova",
      "Najib J. Majaj",
      "Denis G. Pelli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08428",
    "title": "EyeNeRF: A Hybrid Representation for Photorealistic Synthesis, Animation  and Relighting of Human Eyes",
    "abstract": "A unique challenge in creating high-quality animatable and relightable 3D avatars of people is modeling human eyes. The challenge of synthesizing eyes is multifold as it requires 1) appropriate representations for the various components of the eye and the periocular region for coherent viewpoint synthesis, capable of representing diffuse, refractive and highly reflective surfaces, 2) disentangling skin and eye appearance from environmental illumination such that it may be rendered under novel lighting conditions, and 3) capturing eyeball motion and the deformation of the surrounding skin to enable re-gazing. These challenges have traditionally necessitated the use of expensive and cumbersome capture setups to obtain high-quality results, and even then, modeling of the eye region holistically has remained elusive. We present a novel geometry and appearance representation that enables high-fidelity capture and photorealistic animation, view synthesis and relighting of the eye region using only a sparse set of lights and cameras. Our hybrid representation combines an explicit parametric surface model for the eyeball with implicit deformable volumetric representations for the periocular region and the interior of the eye. This novel hybrid model has been designed to address the various parts of that challenging facial area - the explicit eyeball surface allows modeling refraction and high-frequency specular reflection at the cornea, whereas the implicit representation is well suited to model lower-frequency skin reflection via spherical harmonics and can represent non-surface structures such as hair or diffuse volumetric bodies, both of which are a challenge for explicit surface models. We show that for high-resolution close-ups of the eye, our model can synthesize high-fidelity animated gaze from novel views under unseen illumination conditions. ",
    "url": "https://arxiv.org/abs/2206.08428",
    "authors": [
      "Gengyan Li",
      "Abhimitra Meka",
      "Franziska M\u00fcller",
      "Marcel C. B\u00fchler",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.08432",
    "title": "GraphScale: Scalable Bandwidth-Efficient Graph Processing on FPGAs",
    "abstract": "Recent advances in graph processing on FPGAs promise to alleviate performance bottlenecks with irregular memory access patterns. Such bottlenecks challenge performance for a growing number of important application areas like machine learning and data analytics. While FPGAs denote a promising solution through flexible memory hierarchies and massive parallelism, we argue that current graph processing accelerators either use the off-chip memory bandwidth inefficiently or do not scale well across memory channels. In this work, we propose GraphScale, a scalable graph processing framework for FPGAs. For the first time, GraphScale combines multi-channel memory with asynchronous graph processing (i.e., for fast convergence on results) and a compressed graph representation (i.e., for efficient usage of memory bandwidth and reduced memory footprint). GraphScale solves common graph problems like breadth-first search, PageRank, and weakly-connected components through modular user-defined functions, a novel two-dimensional partitioning scheme, and a high-performance two-level crossbar design. ",
    "url": "https://arxiv.org/abs/2206.08432",
    "authors": [
      "Jonas Dann",
      "Daniel Ritter",
      "Holger Fr\u00f6ning"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2206.08445",
    "title": "Enriching Abusive Language Detection with Community Context",
    "abstract": "Uses of pejorative expressions can be benign or actively empowering. When models for abuse detection misclassify these expressions as derogatory, they inadvertently censor productive conversations held by marginalized groups. One way to engage with non-dominant perspectives is to add context around conversations. Previous research has leveraged user- and thread-level features, but it often neglects the spaces within which productive conversations take place. Our paper highlights how community context can improve classification outcomes in abusive language detection. We make two main contributions to this end. First, we demonstrate that online communities cluster by the nature of their support towards victims of abuse. Second, we establish how community context improves accuracy and reduces the false positive rates of state-of-the-art abusive language classifiers. These findings suggest a promising direction for context-aware models in abusive language research. ",
    "url": "https://arxiv.org/abs/2206.08445",
    "authors": [
      "Jana Kurrek",
      "Haji Mohammad Saleem",
      "Derek Ruths"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.08446",
    "title": "Methods for Estimating and Improving Robustness of Language Models",
    "abstract": "Despite their outstanding performance, large language models (LLMs) suffer notorious flaws related to their preference for simple, surface-level textual relations over full semantic complexity of the problem. This proposal investigates a common denominator of this problem in their weak ability to generalise outside of the training domain. We survey diverse research directions providing estimations of model generalisation ability and find that incorporating some of these measures in the training objectives leads to enhanced distributional robustness of neural models. Based on these findings, we present future research directions towards enhancing the robustness of LLMs. ",
    "url": "https://arxiv.org/abs/2206.08446",
    "authors": [
      "Michal \u0160tef\u00e1nik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.08448",
    "title": "Empirical Bayesian Approaches for Robust Constraint-based Causal  Discovery under Insufficient Data",
    "abstract": "Causal discovery is to learn cause-effect relationships among variables given observational data and is important for many applications. Existing causal discovery methods assume data sufficiency, which may not be the case in many real world datasets. As a result, many existing causal discovery methods can fail under limited data. In this work, we propose Bayesian-augmented frequentist independence tests to improve the performance of constraint-based causal discovery methods under insufficient data: 1) We firstly introduce a Bayesian method to estimate mutual information (MI), based on which we propose a robust MI based independence test; 2) Secondly, we consider the Bayesian estimation of hypothesis likelihood and incorporate it into a well-defined statistical test, resulting in a robust statistical testing based independence test. We apply proposed independence tests to constraint-based causal discovery methods and evaluate the performance on benchmark datasets with insufficient samples. Experiments show significant performance improvement in terms of both accuracy and efficiency over SOTA methods. ",
    "url": "https://arxiv.org/abs/2206.08448",
    "authors": [
      "Zijun Cui",
      "Naiyu Yin",
      "Yuru Wang",
      "Qiang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2206.08452",
    "title": "GOOD: A Graph Out-of-Distribution Benchmark",
    "abstract": "Out-of-distribution (OOD) learning deals with scenarios in which training and test data follow different distributions. Although general OOD problems have been intensively studied in machine learning, graph OOD is only an emerging area of research. Currently, there lacks a systematic benchmark tailored to graph OOD method evaluation. In this work, we aim at developing an OOD benchmark, known as GOOD, for graphs specifically. We explicitly make distinctions between covariate and concept shifts and design data splits that accurately reflect different shifts. We consider both graph and node prediction tasks as there are key differences when designing shifts. Overall, GOOD contains 8 datasets with 14 domain selections. When combined with covariate, concept, and no shifts, we obtain 42 different splits. We provide performance results on 7 commonly used baseline methods with 10 random runs. This results in 294 dataset-model combinations in total. Our results show significant performance gaps between in-distribution and OOD settings. Our results also shed light on different performance trends between covariate and concept shifts by different methods. Our GOOD benchmark is a growing project and expects to expand in both quantity and variety of resources as the area develops. The GOOD benchmark can be accessed via $\\href{https://github.com/divelab/GOOD/}{\\text{https://github.com/divelab/GOOD/}}$. ",
    "url": "https://arxiv.org/abs/2206.08452",
    "authors": [
      "Shurui Gui",
      "Xiner Li",
      "Limei Wang",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.08462",
    "title": "Recursive Neural Programs: Variational Learning of Image Grammars and  Part-Whole Hierarchies",
    "abstract": "Human vision involves parsing and representing objects and scenes using structured representations based on part-whole hierarchies. Computer vision and machine learning researchers have recently sought to emulate this capability using capsule networks, reference frames and active predictive coding, but a generative model formulation has been lacking. We introduce Recursive Neural Programs (RNPs), which, to our knowledge, is the first neural generative model to address the part-whole hierarchy learning problem. RNPs model images as hierarchical trees of probabilistic sensory-motor programs that recursively reuse learned sensory-motor primitives to model an image within different reference frames, forming recursive image grammars. We express RNPs as structured variational autoencoders (sVAEs) for inference and sampling, and demonstrate parts-based parsing, sampling and one-shot transfer learning for MNIST, Omniglot and Fashion-MNIST datasets, demonstrating the model's expressive power. Our results show that RNPs provide an intuitive and explainable way of composing objects and scenes, allowing rich compositionality and intuitive interpretations of objects in terms of part-whole hierarchies. ",
    "url": "https://arxiv.org/abs/2206.08462",
    "authors": [
      "Ares Fisher",
      "Rajesh P.N. Rao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08464",
    "title": "PRANC: Pseudo RAndom Networks for Compacting deep models",
    "abstract": "Communication becomes a bottleneck in various distributed Machine Learning settings. Here, we propose a novel training framework that leads to highly efficient communication of models between agents. In short, we train our network to be a linear combination of many pseudo-randomly generated frozen models. For communication, the source agent transmits only the `seed' scalar used to generate the pseudo-random `basis' networks along with the learned linear mixture coefficients. Our method, denoted as PRANC, learns almost $100\\times$ fewer parameters than a deep model and still performs well on several datasets and architectures. PRANC enables 1) efficient communication of models between agents, 2) efficient model storage, and 3) accelerated inference by generating layer-wise weights on the fly. We test PRANC on CIFAR-10, CIFAR-100, tinyImageNet, and ImageNet-100 with various architectures like AlexNet, LeNet, ResNet18, ResNet20, and ResNet56 and demonstrate a massive reduction in the number of parameters while providing satisfactory performance on these benchmark datasets. The code is available \\href{https://github.com/UCDvision/PRANC}{https://github.com/UCDvision/PRANC} ",
    "url": "https://arxiv.org/abs/2206.08464",
    "authors": [
      "Parsa Nooralinejad",
      "Ali Abbasi",
      "Soheil Kolouri",
      "Hamed Pirsiavash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08473",
    "title": "A Robust Stacking Framework for Training Deep Graph Models with  Multifaceted Node Features",
    "abstract": "Graph Neural Networks (GNNs) with numerical node features and graph structure as inputs have demonstrated superior performance on various supervised learning tasks with graph data. However the numerical node features utilized by GNNs are commonly extracted from raw data which is of text or tabular (numeric/categorical) type in most real-world applications. The best models for such data types in most standard supervised learning settings with IID (non-graph) data are not simple neural network layers and thus are not easily incorporated into a GNN. Here we propose a robust stacking framework that fuses graph-aware propagation with arbitrary models intended for IID data, which are ensembled and stacked in multiple layers. Our layer-wise framework leverages bagging and stacking strategies to enjoy strong generalization, in a manner which effectively mitigates label leakage and overfitting. Across a variety of graph datasets with tabular/text node features, our method achieves comparable or superior performance relative to both tabular/text and graph neural network models, as well as existing state-of-the-art hybrid strategies that combine the two. ",
    "url": "https://arxiv.org/abs/2206.08473",
    "authors": [
      "Jiuhai Chen",
      "Jonas Mueller",
      "Vassilis N. Ioannidis",
      "Tom Goldstein",
      "David Wipf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08474",
    "title": "XLCoST: A Benchmark Dataset for Cross-lingual Code Intelligence",
    "abstract": "Recent advances in machine learning have significantly improved the understanding of source code data and achieved good performance on a number of downstream tasks. Open source repositories like GitHub enable this process with rich unlabeled code data. However, the lack of high quality labeled data has largely hindered the progress of several code related tasks, such as program translation, summarization, synthesis, and code search. This paper introduces XLCoST, Cross-Lingual Code SnippeT dataset, a new benchmark dataset for cross-lingual code intelligence. Our dataset contains fine-grained parallel data from 8 languages (7 commonly used programming languages and English), and supports 10 cross-lingual code tasks. To the best of our knowledge, it is the largest parallel dataset for source code both in terms of size and the number of languages. We also provide the performance of several state-of-the-art baseline models for each task. We believe this new dataset can be a valuable asset for the research community and facilitate the development and validation of new methods for cross-lingual code intelligence. ",
    "url": "https://arxiv.org/abs/2206.08474",
    "authors": [
      "Ming Zhu",
      "Aneesh Jain",
      "Karthik Suresh",
      "Roshan Ravindran",
      "Sindhu Tipirneni",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08477",
    "title": "Backdoor Attacks on Vision Transformers",
    "abstract": "Vision Transformers (ViT) have recently demonstrated exemplary performance on a variety of vision tasks and are being used as an alternative to CNNs. Their design is based on a self-attention mechanism that processes images as a sequence of patches, which is quite different compared to CNNs. Hence it is interesting to study if ViTs are vulnerable to backdoor attacks. Backdoor attacks happen when an attacker poisons a small part of the training data for malicious purposes. The model performance is good on clean test images, but the attacker can manipulate the decision of the model by showing the trigger at test time. To the best of our knowledge, we are the first to show that ViTs are vulnerable to backdoor attacks. We also find an intriguing difference between ViTs and CNNs - interpretation algorithms effectively highlight the trigger on test images for ViTs but not for CNNs. Based on this observation, we propose a test-time image blocking defense for ViTs which reduces the attack success rate by a large margin. Code is available here: https://github.com/UCDvision/backdoor_transformer.git ",
    "url": "https://arxiv.org/abs/2206.08477",
    "authors": [
      "Akshayvarun Subramanya",
      "Aniruddha Saha",
      "Soroush Abbasi Koohpayegani",
      "Ajinkya Tejankar",
      "Hamed Pirsiavash"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08496",
    "title": "Self-Supervised Contrastive Pre-Training For Time Series via  Time-Frequency Consistency",
    "abstract": "Pre-training on time series poses a unique challenge due to the potential mismatch between pre-training and target domains, such as shifts in temporal dynamics, fast-evolving trends, and long-range and short cyclic effects, which can lead to poor downstream performance. While domain adaptation methods can mitigate these shifts, most methods need examples directly from the target domain, making them suboptimal for pre-training. To address this challenge, methods need to accommodate target domains with different temporal dynamics and be capable of doing so without seeing any target examples during pre-training. Relative to other modalities, in time series, we expect that time-based and frequency-based representations of the same example are located close together in the time-frequency space. To this end, we posit that time-frequency consistency (TF-C) -- embedding a time-based neighborhood of a particular example close to its frequency-based neighborhood and back -- is desirable for pre-training. Motivated by TF-C, we define a decomposable pre-training model, where the self-supervised signal is provided by the distance between time and frequency components, each individually trained by contrastive estimation. We evaluate the new method on eight datasets, including electrodiagnostic testing, human activity recognition, mechanical fault detection, and physical status monitoring. Experiments against eight state-of-the-art methods show that TF-C outperforms baselines by 15.4% (F1 score) on average in one-to-one settings (e.g., fine-tuning an EEG-pretrained model on EMG data) and by up to 8.4% (F1 score) in challenging one-to-many settings, reflecting the breadth of scenarios that arise in real-world applications. The source code and datasets are available at https: //anonymous.4open.science/r/TFC-pretraining-6B07. ",
    "url": "https://arxiv.org/abs/2206.08496",
    "authors": [
      "Xiang Zhang",
      "Ziyuan Zhao",
      "Theodoros Tsiligkaridis",
      "Marinka Zitnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.08497",
    "title": "Unsupervised Kinematic Motion Detection for Part-segmented 3D Shape  Collections",
    "abstract": "3D models of manufactured objects are important for populating virtual worlds and for synthetic data generation for vision and robotics. To be most useful, such objects should be articulated: their parts should move when interacted with. While articulated object datasets exist, creating them is labor-intensive. Learning-based prediction of part motions can help, but all existing methods require annotated training data. In this paper, we present an unsupervised approach for discovering articulated motions in a part-segmented 3D shape collection. Our approach is based on a concept we call category closure: any valid articulation of an object's parts should keep the object in the same semantic category (e.g. a chair stays a chair). We operationalize this concept with an algorithm that optimizes a shape's part motion parameters such that it can transform into other shapes in the collection. We evaluate our approach by using it to re-discover part motions from the PartNet-Mobility dataset. For almost all shape categories, our method's predicted motion parameters have low error with respect to ground truth annotations, outperforming two supervised motion prediction methods. ",
    "url": "https://arxiv.org/abs/2206.08497",
    "authors": [
      "Xianghao Xu",
      "Yifan Ruan",
      "Srinath Sridhar",
      "Daniel Ritchie"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.08507",
    "title": "On energy-stable and high order finite element methods for the wave  equation in heterogeneous media with perfectly matched layers",
    "abstract": "This paper presents a stable finite element approximation for the acoustic wave equation on second-order form, with perfectly matched layers (PML) at the boundaries. Energy estimates are derived for varying PML damping for both the discrete and the continuous case. Moreover, a priori error estimates are derived for constant PML damping. Most of the analysis is performed in Laplace space. Numerical experiments in physical space validate the theoretical results. ",
    "url": "https://arxiv.org/abs/2206.08507",
    "authors": [
      "Gustav Ludvigsson",
      "Kenneth Duru",
      "Gunilla Kreiss"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2206.08509",
    "title": "Neural Architecture Adaptation for Object Detection by Searching Channel  Dimensions and Mapping Pre-trained Parameters",
    "abstract": "Most object detection frameworks use backbone architectures originally designed for image classification, conventionally with pre-trained parameters on ImageNet. However, image classification and object detection are essentially different tasks and there is no guarantee that the optimal backbone for classification is also optimal for object detection. Recent neural architecture search (NAS) research has demonstrated that automatically designing a backbone specifically for object detection helps improve the overall accuracy. In this paper, we introduce a neural architecture adaptation method that can optimize the given backbone for detection purposes, while still allowing the use of pre-trained parameters. We propose to adapt both the micro- and macro-architecture by searching for specific operations and the number of layers, in addition to the output channel dimensions of each block. It is important to find the optimal channel depth, as it greatly affects the feature representation capability and computation cost. We conduct experiments with our searched backbone for object detection and demonstrate that our backbone outperforms both manually designed and searched state-of-the-art backbones on the COCO dataset. ",
    "url": "https://arxiv.org/abs/2206.08509",
    "authors": [
      "Harim Jung",
      "Myeong-Seok Oh",
      "Cheoljong Yang",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.08513",
    "title": "TLETA: Deep Transfer Learning and Integrated Cellular Knowledge for  Estimated Time of Arrival Prediction",
    "abstract": "Vehicle arrival time prediction has been studied widely. With the emergence of IoT devices and deep learning techniques, estimated time of arrival (ETA) has become a critical component in intelligent transportation systems. Though many tools exist for ETA, ETA for special vehicles, such as ambulances, fire engines, etc., is still challenging due to the limited amount of traffic data for special vehicles. Existing works use one model for all types of vehicles, which can lead to low accuracy. To tackle this, as the first in the field, we propose a deep transfer learning framework TLETA for the driving time prediction. TLETA constructs cellular spatial-temporal knowledge grids for extracting driving patterns, combined with the road network structure embedding to build a deep neural network for ETA. TLETA contains transferable layers to support knowledge transfer between different categories of vehicles. Importantly, our transfer models only train the last layers to map the transferred knowledge, that reduces the training time significantly. The experimental studies show that our model predicts travel time with high accuracy and outperforms many state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2206.08513",
    "authors": [
      "Hieu Tran",
      "Son Nguyen",
      "I-Ling Yen",
      "Farokh Bastani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.08514",
    "title": "A Unified Evaluation of Textual Backdoor Learning: Frameworks and  Benchmarks",
    "abstract": "Textual backdoor attacks are a kind of practical threat to NLP systems. By injecting a backdoor in the training phase, the adversary could control model predictions via predefined triggers. As various attack and defense models have been proposed, it is of great significance to perform rigorous evaluations. However, we highlight two issues in previous backdoor learning evaluations: (1) The differences between real-world scenarios (e.g. releasing poisoned datasets or models) are neglected, and we argue that each scenario has its own constraints and concerns, thus requires specific evaluation protocols; (2) The evaluation metrics only consider whether the attacks could flip the models' predictions on poisoned samples and retain performances on benign samples, but ignore that poisoned samples should also be stealthy and semantic-preserving. To address these issues, we categorize existing works into three practical scenarios in which attackers release datasets, pre-trained models, and fine-tuned models respectively, then discuss their unique evaluation methodologies. On metrics, to completely evaluate poisoned samples, we use grammar error increase and perplexity difference for stealthiness, along with text similarity for validity. After formalizing the frameworks, we develop an open-source toolkit OpenBackdoor to foster the implementations and evaluations of textual backdoor learning. With this toolkit, we perform extensive experiments to benchmark attack and defense models under the suggested paradigm. To facilitate the underexplored defenses against poisoned datasets, we further propose CUBE, a simple yet strong clustering-based defense baseline. We hope that our frameworks and benchmarks could serve as the cornerstones for future model development and evaluations. ",
    "url": "https://arxiv.org/abs/2206.08514",
    "authors": [
      "Ganqu Cui",
      "Lifan Yuan",
      "Bingxiang He",
      "Yangyi Chen",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.08515",
    "title": "ComENet: Towards Complete and Efficient Message Passing for 3D Molecular  Graphs",
    "abstract": "Many real-world data can be modeled as 3D graphs, but learning representations that incorporates 3D information completely and efficiently is challenging. Existing methods either use partial 3D information, or suffer from excessive computational cost. To incorporate 3D information completely and efficiently, we propose a novel message passing scheme that operates within 1-hop neighborhood. Our method guarantees full completeness of 3D information on 3D graphs by achieving global and local completeness. Notably, we propose the important rotation angles to fulfill global completeness. Additionally, we show that our method is orders of magnitude faster than prior methods. We provide rigorous proof of completeness and analysis of time complexity for our methods. As molecules are in essence quantum systems, we build the \\underline{com}plete and \\underline{e}fficient graph neural network (ComENet) by combing quantum inspired basis functions and the proposed message passing scheme. Experimental results demonstrate the capability and efficiency of ComENet, especially on real-world datasets that are large in both numbers and sizes of graphs. Our code is publicly available as part of the DIG library (\\url{https://github.com/divelab/DIG}). ",
    "url": "https://arxiv.org/abs/2206.08515",
    "authors": [
      "Limei Wang",
      "Yi Liu",
      "Yuchao Lin",
      "Haoran Liu",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08523",
    "title": "A Spatio-Temporal Neural Network Forecasting Approach for Emulation of  Firefront Models",
    "abstract": "Computational simulations of wildfire spread typically employ empirical rate-of-spread calculations under various conditions (such as terrain, fuel type, weather). Small perturbations in conditions can often lead to significant changes in fire spread (such as speed and direction), necessitating a computationally expensive large set of simulations to quantify uncertainty. Model emulation seeks alternative representations of physical models using machine learning, aiming to provide more efficient and/or simplified surrogate models. We propose a dedicated spatio-temporal neural network based framework for model emulation, able to capture the complex behaviour of fire spread models. The proposed approach can approximate forecasts at fine spatial and temporal resolutions that are often challenging for neural network based approaches. Furthermore, the proposed approach is robust even with small training sets, due to novel data augmentation methods. Empirical experiments show good agreement between simulated and emulated firefronts, with an average Jaccard score of 0.76. ",
    "url": "https://arxiv.org/abs/2206.08523",
    "authors": [
      "Andrew Bolt",
      "Carolyn Huston",
      "Petra Kuhnert",
      "Joel Janek Dabrowski",
      "James Hilton",
      "Conrad Sanderson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08524",
    "title": "CDNet: Contrastive Disentangled Network for Fine-Grained Image  Categorization of Ocular B-Scan Ultrasound",
    "abstract": "Precise and rapid categorization of images in the B-scan ultrasound modality is vital for diagnosing ocular diseases. Nevertheless, distinguishing various diseases in ultrasound still challenges experienced ophthalmologists. Thus a novel contrastive disentangled network (CDNet) is developed in this work, aiming to tackle the fine-grained image categorization (FGIC) challenges of ocular abnormalities in ultrasound images, including intraocular tumor (IOT), retinal detachment (RD), posterior scleral staphyloma (PSS), and vitreous hemorrhage (VH). Three essential components of CDNet are the weakly-supervised lesion localization module (WSLL), contrastive multi-zoom (CMZ) strategy, and hyperspherical contrastive disentangled loss (HCD-Loss), respectively. These components facilitate feature disentanglement for fine-grained recognition in both the input and output aspects. The proposed CDNet is validated on our ZJU Ocular Ultrasound Dataset (ZJUOUSD), consisting of 5213 samples. Furthermore, the generalization ability of CDNet is validated on two public and widely-used chest X-ray FGIC benchmarks. Quantitative and qualitative results demonstrate the efficacy of our proposed CDNet, which achieves state-of-the-art performance in the FGIC task. Code is available at: https://github.com/ZeroOneGame/CDNet-for-OUS-FGIC . ",
    "url": "https://arxiv.org/abs/2206.08524",
    "authors": [
      "Ruilong Dan",
      "Yunxiang Li",
      "Yijie Wang",
      "Gangyong Jia",
      "Ruiquan Ge",
      "Juan Ye",
      "Qun Jin",
      "Yaqi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.08530",
    "title": "GDsmith: Detecting Bugs in Graph Database Engines",
    "abstract": "Graph database engines stand out in the era of big data for their efficiency of modeling and processing linked data. There is a strong need of testing graph database engines. However, random testing, the most practical way of automated test generation, faces the challenges of semantic validity, non-empty result, and behavior diversity to detect bugs in graph database engines. To address these challenges, in this paper, we propose GDsmith, the first black-box approach for testing graph database engines. It ensures that each randomly generated Cypher query satisfies the semantic requirements via skeleton generation and completion. GDsmith includes our technique to increase the probability of producing Cypher queries that return non-empty results by leveraging three types of structural mutation strategies. GDsmith also includes our technique to improve the behavior diversity of the generated Cypher queries by selecting property keys according to their previous frequencies when generating new queries. Our evaluation results demonstrate that GDsmith is effective and efficient for automated query generation and substantially outperforms the baseline. GDsmith successfully detects 27 previously unknown bugs on the released versions of three popular open-source graph database engines and receive positive feedback from their developers. ",
    "url": "https://arxiv.org/abs/2206.08530",
    "authors": [
      "Wei Lin",
      "Ziyue Hua",
      "Luyao Ren",
      "Zongyang Li",
      "Lu Zhang",
      "Tao Xie"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2206.08536",
    "title": "Low-latency Mini-batch GNN Inference on CPU-FPGA Heterogeneous Platform",
    "abstract": "Mini-batch inference of Graph Neural Networks (GNNs) is a key problem in many real-world applications. Recently, a GNN design principle of model depth-receptive field decoupling has been proposed to address the well-known issue of neighborhood explosion. Decoupled GNN models achieve higher accuracy than original models and demonstrate excellent scalability for mini-batch inference. We map Decoupled GNNs onto CPU-FPGA heterogeneous platforms to achieve low-latency mini-batch inference. On the FPGA platform, we design a novel GNN hardware accelerator with an adaptive datapath denoted Adaptive Computation Kernel (ACK) that can execute various computation kernels of GNNs with low-latency: (1) for dense computation kernels expressed as matrix multiplication, ACK works as a systolic array with fully localized connections, (2) for sparse computation kernels, ACK follows the scatter-gather paradigm and works as multiple parallel pipelines to support the irregular connectivity of graphs. The proposed task scheduling hides the CPU-FPGA data communication overhead to reduce the inference latency. We develop a fast design space exploration algorithm to generate a single accelerator for multiple target GNN models. We implement our accelerator on a state-of-the-art CPU-FPGA platform and evaluate the performance using three representative models (GCN, GraphSAGE, and GAT). Results show that our CPU-FPGA implementation achieves $21.4-50.8\\times$, $2.9-21.6\\times$, $4.7\\times$ latency reduction compared with state-of-the-art implementations on CPU-only, CPU-GPU and CPU-FPGA platforms. ",
    "url": "https://arxiv.org/abs/2206.08536",
    "authors": [
      "Bingyi Zhang",
      "Hanqing Zeng",
      "Viktor Prasanna"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2206.08537",
    "title": "Large-Margin Representation Learning for Texture Classification",
    "abstract": "This paper presents a novel approach combining convolutional layers (CLs) and large-margin metric learning for training supervised models on small datasets for texture classification. The core of such an approach is a loss function that computes the distances between instances of interest and support vectors. The objective is to update the weights of CLs iteratively to learn a representation with a large margin between classes. Each iteration results in a large-margin discriminant model represented by support vectors based on such a representation. The advantage of the proposed approach w.r.t. convolutional neural networks (CNNs) is two-fold. First, it allows representation learning with a small amount of data due to the reduced number of parameters compared to an equivalent CNN. Second, it has a low training cost since the backpropagation considers only support vectors. The experimental results on texture and histopathologic image datasets have shown that the proposed approach achieves competitive accuracy with lower computational cost and faster convergence when compared to equivalent CNNs. ",
    "url": "https://arxiv.org/abs/2206.08537",
    "authors": [
      "Jonathan de Matos",
      "Luiz Eduardo Soares de Oliveira",
      "Alceu de Souza Britto Junior",
      "Alessandro Lameiras Koerich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08542",
    "title": "Strategic Representation",
    "abstract": "Humans have come to rely on machines for reducing excessive information to manageable representations. But this reliance can be abused -- strategic machines might craft representations that manipulate their users. How can a user make good choices based on strategic representations? We formalize this as a learning problem, and pursue algorithms for decision-making that are robust to manipulation. In our main setting of interest, the system represents attributes of an item to the user, who then decides whether or not to consume. We model this interaction through the lens of strategic classification (Hardt et al. 2016), reversed: the user, who learns, plays first; and the system, which responds, plays second. The system must respond with representations that reveal `nothing but the truth' but need not reveal the entire truth. Thus, the user faces the problem of learning set functions under strategic subset selection, which presents distinct algorithmic and statistical challenges. Our main result is a learning algorithm that minimizes error despite strategic representations, and our theoretical analysis sheds light on the trade-off between learning effort and susceptibility to manipulation. ",
    "url": "https://arxiv.org/abs/2206.08542",
    "authors": [
      "Vineet Nair",
      "Ganesh Ghalme",
      "Inbal Talgam-Cohen",
      "Nir Rosenfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2206.08547",
    "title": "Texture Generation Using Graph Generative Adversarial Network And  Differentiable Rendering",
    "abstract": "Novel texture synthesis for existing 3D mesh models is an important step towards photo realistic asset generation for existing simulators. But existing methods inherently work in the 2D image space which is the projection of the 3D space from a given camera perspective. These methods take camera angle, 3D model information, lighting information and generate photorealistic 2D image. To generate a photorealistic image from another perspective or lighting, we need to make a computationally expensive forward pass each time we change the parameters. Also, it is hard to generate such images for a simulator that can satisfy the temporal constraints the sequences of images should be similar but only need to change the viewpoint of lighting as desired. The solution can not be directly integrated with existing tools like Blender and Unreal Engine. Manual solution is expensive and time consuming. We thus present a new system called a graph generative adversarial network (GGAN) that can generate textures which can be directly integrated into a given 3D mesh models with tools like Blender and Unreal Engine and can be simulated from any perspective and lighting condition easily. ",
    "url": "https://arxiv.org/abs/2206.08547",
    "authors": [
      "Dharma KC",
      "Clayton T. Morrison",
      "Bradley Walls"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.08556",
    "title": "Thompson Sampling for Robust Transfer in Multi-Task Bandits",
    "abstract": "We study the problem of online multi-task learning where the tasks are performed within similar but not necessarily identical multi-armed bandit environments. In particular, we study how a learner can improve its overall performance across multiple related tasks through robust transfer of knowledge. While an upper confidence bound (UCB)-based algorithm has recently been shown to achieve nearly-optimal performance guarantees in a setting where all tasks are solved concurrently, it remains unclear whether Thompson sampling (TS) algorithms, which have superior empirical performance in general, share similar theoretical properties. In this work, we present a TS-type algorithm for a more general online multi-task learning protocol, which extends the concurrent setting. We provide its frequentist analysis and prove that it is also nearly-optimal using a novel concentration inequality for multi-task data aggregation at random stopping times. Finally, we evaluate the algorithm on synthetic data and show that the TS-type algorithm enjoys superior empirical performance in comparison with the UCB-based algorithm and a baseline algorithm that performs TS for each individual task without transfer. ",
    "url": "https://arxiv.org/abs/2206.08556",
    "authors": [
      "Zhi Wang",
      "Chicheng Zhang",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.08561",
    "title": "Boosting Graph Structure Learning with Dummy Nodes",
    "abstract": "With the development of graph kernels and graph representation learning, many superior methods have been proposed to handle scalability and oversmoothing issues on graph structure learning. However, most of those strategies are designed based on practical experience rather than theoretical analysis. In this paper, we use a particular dummy node connecting to all existing vertices without affecting original vertex and edge properties. We further prove that such the dummy node can help build an efficient monomorphic edge-to-vertex transform and an epimorphic inverse to recover the original graph back. It also indicates that adding dummy nodes can preserve local and global structures for better graph representation learning. We extend graph kernels and graph neural networks with dummy nodes and conduct experiments on graph classification and subgraph isomorphism matching tasks. Empirical results demonstrate that taking graphs with dummy nodes as input significantly boosts graph structure learning, and using their edge-to-vertex graphs can also achieve similar results. We also discuss the gain of expressive power from the dummy in neural networks. ",
    "url": "https://arxiv.org/abs/2206.08561",
    "authors": [
      "Xin Liu",
      "Jiayang Cheng",
      "Yangqiu Song",
      "Xin Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08566",
    "title": "Active Data Discovery: Mining Unknown Data using Submodular Information  Measures",
    "abstract": "Active Learning is a very common yet powerful framework for iteratively and adaptively sampling subsets of the unlabeled sets with a human in the loop with the goal of achieving labeling efficiency. Most real world datasets have imbalance either in classes and slices, and correspondingly, parts of the dataset are rare. As a result, there has been a lot of work in designing active learning approaches for mining these rare data instances. Most approaches assume access to a seed set of instances which contain these rare data instances. However, in the event of more extreme rareness, it is reasonable to assume that these rare data instances (either classes or slices) may not even be present in the seed labeled set, and a critical need for the active learning paradigm is to efficiently discover these rare data instances. In this work, we provide an active data discovery framework which can mine unknown data slices and classes efficiently using the submodular conditional gain and submodular conditional mutual information functions. We provide a general algorithmic framework which works in a number of scenarios including image classification and object detection and works with both rare classes and rare slices present in the unlabeled set. We show significant accuracy and labeling efficiency gains with our approach compared to existing state-of-the-art active learning approaches for actively discovering these rare classes and slices. ",
    "url": "https://arxiv.org/abs/2206.08566",
    "authors": [
      "Suraj Kothawade",
      "Shivang Chopra",
      "Saikat Ghosh",
      "Rishabh Iyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.08568",
    "title": "Multi-Contextual Predictions with Vision Transformer for Video Anomaly  Detection",
    "abstract": "Video Anomaly Detection(VAD) has been traditionally tackled in two main methodologies: the reconstruction-based approach and the prediction-based one. As the reconstruction-based methods learn to generalize the input image, the model merely learns an identity function and strongly causes the problem called generalizing issue. On the other hand, since the prediction-based ones learn to predict a future frame given several previous frames, they are less sensitive to the generalizing issue. However, it is still uncertain if the model can learn the spatio-temporal context of a video. Our intuition is that the understanding of the spatio-temporal context of a video plays a vital role in VAD as it provides precise information on how the appearance of an event in a video clip changes. Hence, to fully exploit the context information for anomaly detection in video circumstances, we designed the transformer model with three different contextual prediction streams: masked, whole and partial. By learning to predict the missing frames of consecutive normal frames, our model can effectively learn various normality patterns in the video, which leads to a high reconstruction error at the abnormal cases that are unsuitable to the learned context. To verify the effectiveness of our approach, we assess our model on the public benchmark datasets: USCD Pedestrian 2, CUHK Avenue and ShanghaiTech and evaluate the performance with the anomaly score metric of reconstruction error. The results demonstrate that our proposed approach achieves a competitive performance compared to the existing video anomaly detection methods. ",
    "url": "https://arxiv.org/abs/2206.08568",
    "authors": [
      "Joo-Yeon Lee",
      "Woo-Jeoung Nam",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.08575",
    "title": "Query-Efficient and Scalable Black-Box Adversarial Attacks on Discrete  Sequential Data via Bayesian Optimization",
    "abstract": "We focus on the problem of adversarial attacks against models on discrete sequential data in the black-box setting where the attacker aims to craft adversarial examples with limited query access to the victim model. Existing black-box attacks, mostly based on greedy algorithms, find adversarial examples using pre-computed key positions to perturb, which severely limits the search space and might result in suboptimal solutions. To this end, we propose a query-efficient black-box attack using Bayesian optimization, which dynamically computes important positions using an automatic relevance determination (ARD) categorical kernel. We introduce block decomposition and history subsampling techniques to improve the scalability of Bayesian optimization when an input sequence becomes long. Moreover, we develop a post-optimization algorithm that finds adversarial examples with smaller perturbation size. Experiments on natural language and protein classification tasks demonstrate that our method consistently achieves higher attack success rate with significant reduction in query count and modification rate compared to the previous state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2206.08575",
    "authors": [
      "Deokjae Lee",
      "Seungyong Moon",
      "Junhyeok Lee",
      "Hyun Oh Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.08582",
    "title": "DFG-NAS: Deep and Flexible Graph Neural Architecture Search",
    "abstract": "Graph neural networks (GNNs) have been intensively applied to various graph-based applications. Despite their success, manually designing the well-behaved GNNs requires immense human expertise. And thus it is inefficient to discover the potentially optimal data-specific GNN architecture. This paper proposes DFG-NAS, a new neural architecture search (NAS) method that enables the automatic search of very deep and flexible GNN architectures. Unlike most existing methods that focus on micro-architectures, DFG-NAS highlights another level of design: the search for macro-architectures on how atomic propagation (\\textbf{\\texttt{P}}) and transformation (\\textbf{\\texttt{T}}) operations are integrated and organized into a GNN. To this end, DFG-NAS proposes a novel search space for \\textbf{\\texttt{P-T}} permutations and combinations based on message-passing dis-aggregation, defines four custom-designed macro-architecture mutations, and employs the evolutionary algorithm to conduct an efficient and effective search. Empirical studies on four node classification tasks demonstrate that DFG-NAS outperforms state-of-the-art manual designs and NAS methods of GNNs. ",
    "url": "https://arxiv.org/abs/2206.08582",
    "authors": [
      "Wentao Zhang",
      "Zheyu Lin",
      "Yu Shen",
      "Yang Li",
      "Zhi Yang",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08583",
    "title": "NAFS: A Simple yet Tough-to-beat Baseline for Graph Representation  Learning",
    "abstract": "Recently, graph neural networks (GNNs) have shown prominent performance in graph representation learning by leveraging knowledge from both graph structure and node features. However, most of them have two major limitations. First, GNNs can learn higher-order structural information by stacking more layers but can not deal with large depth due to the over-smoothing issue. Second, it is not easy to apply these methods on large graphs due to the expensive computation cost and high memory usage. In this paper, we present node-adaptive feature smoothing (NAFS), a simple non-parametric method that constructs node representations without parameter learning. NAFS first extracts the features of each node with its neighbors of different hops by feature smoothing, and then adaptively combines the smoothed features. Besides, the constructed node representation can further be enhanced by the ensemble of smoothed features extracted via different smoothing strategies. We conduct experiments on four benchmark datasets on two different application scenarios: node clustering and link prediction. Remarkably, NAFS with feature ensemble outperforms the state-of-the-art GNNs on these tasks and mitigates the aforementioned two limitations of most learning-based GNN counterparts. ",
    "url": "https://arxiv.org/abs/2206.08583",
    "authors": [
      "Wentao Zhang",
      "Zeang Sheng",
      "Mingyu Yang",
      "Yang Li",
      "Yu Shen",
      "Zhi Yang",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08610",
    "title": "Masked Autoencoders for Generic Event Boundary Detection CVPR'2022  Kinetics-GEBD Challenge",
    "abstract": "Generic Event Boundary Detection (GEBD) tasks aim at detecting generic, taxonomy-free event boundaries that segment a whole video into chunks. In this paper, we apply Masked Autoencoders to improve algorithm performance on the GEBD tasks. Our approach mainly adopted the ensemble of Masked Autoencoders fine-tuned on the GEBD task as a self-supervised learner with other base models. Moreover, we also use a semi-supervised pseudo-label method to take full advantage of the abundant unlabeled Kinetics-400 data while training. In addition, we propose a soft-label method to partially balance the positive and negative samples and alleviate the problem of ambiguous labeling in this task. Lastly, a tricky segmentation alignment policy is implemented to refine boundaries predicted by our models to more accurate locations. With our approach, we achieved 85.94% on the F1-score on the Kinetics-GEBD test set, which improved the F1-score by 2.31% compared to the winner of the 2021 Kinetics-GEBD Challenge. Our code is available at https://github.com/ContentAndMaterialPortrait/MAE-GEBD. ",
    "url": "https://arxiv.org/abs/2206.08610",
    "authors": [
      "Rui He",
      "Yuanxi Sun",
      "Youzeng Li",
      "Zuwei Huang",
      "Feng Hu",
      "Xu Cheng",
      "Jie Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.08615",
    "title": "The Role of Depth, Width, and Activation Complexity in the Number of  Linear Regions of Neural Networks",
    "abstract": "Many feedforward neural networks generate continuous and piecewise-linear (CPWL) mappings. Specifically, they partition the input domain into regions on which the mapping is an affine function. The number of these so-called linear regions offers a natural metric to characterize the expressiveness of CPWL mappings. Although the precise determination of this quantity is often out of reach, bounds have been proposed for specific architectures, including the well-known ReLU and Maxout networks. In this work, we propose a more general perspective and provide precise bounds on the maximal number of linear regions of CPWL networks based on three sources of expressiveness: depth, width, and activation complexity. Our estimates rely on the combinatorial structure of convex partitions and highlight the distinctive role of depth which, on its own, is able to exponentially increase the number of regions. We then introduce a complementary stochastic framework to estimate the average number of linear regions produced by a CPWL network architecture. Under reasonable assumptions, the expected density of linear regions along any 1D path is bounded by the product of depth, width, and a measure of activation complexity (up to a scaling factor). This yields an identical role to the three sources of expressiveness: no exponential growth with depth is observed anymore. ",
    "url": "https://arxiv.org/abs/2206.08615",
    "authors": [
      "Alexis Goujon",
      "Arian Etemadi",
      "Michael Unser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.08638",
    "title": "Minimum Noticeable Difference based Adversarial Privacy Preserving Image  Generation",
    "abstract": "Deep learning models are found to be vulnerable to adversarial examples, as wrong predictions can be caused by small perturbation in input for deep learning models. Most of the existing works of adversarial image generation try to achieve attacks for most models, while few of them make efforts on guaranteeing the perceptual quality of the adversarial examples. High quality adversarial examples matter for many applications, especially for the privacy preserving. In this work, we develop a framework based on the Minimum Noticeable Difference (MND) concept to generate adversarial privacy preserving images that have minimum perceptual difference from the clean ones but are able to attack deep learning models. To achieve this, an adversarial loss is firstly proposed to make the deep learning models attacked by the adversarial images successfully. Then, a perceptual quality-preserving loss is developed by taking the magnitude of perturbation and perturbation-caused structural and gradient changes into account, which aims to preserve high perceptual quality for adversarial image generation. To the best of our knowledge, this is the first work on exploring quality-preserving adversarial image generation based on the MND concept for privacy preserving. To evaluate its performance in terms of perceptual quality, the deep models on image classification and face recognition are tested with the proposed method and several anchor methods in this work. Extensive experimental results demonstrate that the proposed MND framework is capable of generating adversarial images with remarkably improved performance metrics (e.g., PSNR, SSIM, and MOS) than that generated with the anchor methods. ",
    "url": "https://arxiv.org/abs/2206.08638",
    "authors": [
      "Wen Sun",
      "Jian Jin",
      "Weisi Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08641",
    "title": "Improving Diversity of Multiple Trajectory Prediction based on  Map-adaptive Lane Loss",
    "abstract": "Prior arts in the field of motion predictions for autonomous driving tend to focus on finding a trajectory that is close to the ground truth trajectory. Such problem formulations and approaches, however, frequently lead to loss of diversity and biased trajectory predictions. Therefore, they are unsuitable for real-world autonomous driving where diverse and road-dependent multimodal trajectory predictions are critical for safety. To this end, this study proposes a novel loss function, \\textit{Lane Loss}, that ensures map-adaptive diversity and accommodates geometric constraints. A two-stage trajectory prediction architecture with a novel trajectory candidate proposal module, \\textit{Trajectory Prediction Attention (TPA)}, is trained with Lane Loss encourages multiple trajectories to be diversely distributed, covering feasible maneuvers in a map-aware manner. Furthermore, considering that the existing trajectory performance metrics are focusing on evaluating the accuracy based on the ground truth future trajectory, a quantitative evaluation metric is also suggested to evaluate the diversity of predicted multiple trajectories. The experiments performed on the Argoverse dataset show that the proposed method significantly improves the diversity of the predicted trajectories without sacrificing the prediction accuracy. ",
    "url": "https://arxiv.org/abs/2206.08641",
    "authors": [
      "Sanmin Kim",
      "Hyeongseok Jeon",
      "Junwon Choi",
      "Dongsuk Kum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.08656",
    "title": "tinySNN: Towards Memory- and Energy-Efficient Spiking Neural Networks",
    "abstract": "Larger Spiking Neural Network (SNN) models are typically favorable as they can offer higher accuracy. However, employing such models on the resource- and energy-constrained embedded platforms is inefficient. Towards this, we present a tinySNN framework that optimizes the memory and energy requirements of SNN processing in both the training and inference phases, while keeping the accuracy high. It is achieved by reducing the SNN operations, improving the learning quality, quantizing the SNN parameters, and selecting the appropriate SNN model. Furthermore, our tinySNN quantizes different SNN parameters (i.e., weights and neuron parameters) to maximize the compression while exploring different combinations of quantization schemes, precision levels, and rounding schemes to find the model that provides acceptable accuracy. The experimental results demonstrate that our tinySNN significantly reduces the memory footprint and the energy consumption of SNNs without accuracy loss as compared to the baseline network. Therefore, our tinySNN effectively compresses the given SNN model to achieve high accuracy in a memory- and energy-efficient manner, hence enabling the employment of SNNs for the resource- and energy-constrained embedded applications. ",
    "url": "https://arxiv.org/abs/2206.08656",
    "authors": [
      "Rachmad Vidya Wicaksana Putra",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08657",
    "title": "Bridge-Tower: Building Bridges Between Encoders in Vision-Language  Representation Learning",
    "abstract": "Vision-Language (VL) models with the Two-Tower architecture have dominated visual-language representation learning in recent years. Current VL models either use lightweight uni-modal encoders and learn to extract, align and fuse both modalities simultaneously in a cross-modal encoder, or feed the last-layer uni-modal features directly into the top cross-modal encoder, ignoring the semantic information at the different levels in the deep uni-modal encoders. Both approaches possibly restrict vision-language representation learning and limit model performance. In this paper, we introduce multiple bridge layers that build a connection between the top layers of uni-modal encoders and each layer of the cross-modal encoder. This enables comprehensive bottom-up interactions between visual and textual representations at different semantic levels, resulting in more effective cross-modal alignment and fusion. Our proposed Bridge-Tower, pre-trained with only $4$M images, achieves state-of-the-art performance on various downstream vision-language tasks. On the VQAv2 test-std set, Bridge-Tower achieves an accuracy of $78.73\\%$, outperforming the previous state-of-the-art METER model by $1.09\\%$ with the same pre-training data and almost no additional parameters and computational cost. Notably, when further scaling the model, Bridge-Tower achieves an accuracy of $81.15\\%$, surpassing models that are pre-trained on orders-of-magnitude larger datasets. Code is available at https://github.com/microsoft/BridgeTower. ",
    "url": "https://arxiv.org/abs/2206.08657",
    "authors": [
      "Xiao Xu",
      "Chenfei Wu",
      "Shachar Rosenman",
      "Vasudev Lal",
      "Nan Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08669",
    "title": "VGSwarm: A Vision-based Gene Regulation Network for UAVs Swarm Behavior  Emergence",
    "abstract": "UAVs (Unmanned Aerial Vehicles) dynamic encirclement is an emerging field with great potential. Researchers often get inspirations from biological systems, either from macro-world like fish schools or bird flocks etc, or from micro-world like gene regulatory networks. However, most swarm control algorithms rely on centralized control, global information acquisition, or communication between neighboring agents. In this work, we propose a distributed swarm control method based purely on vision without any direct communications, in which swarm agents of e.g. UAVs can generate an entrapping pattern to encircle an escaping target of UAV based purly on their installed omnidirectional vision sensors. A finite-state-machine describing the behavior model of each individual drone is also designed so that a swarm of drones can accomplish searching and entrapping of the target collectively. We verify the effectiveness and efficiency of the proposed method in various simulation and real-world experiments. ",
    "url": "https://arxiv.org/abs/2206.08669",
    "authors": [
      "Yuwei Cai",
      "Huanlin Li",
      "Zhun Fan",
      "Juncao Hong",
      "Peng Xu",
      "Hui Cheng",
      "Xiaomi Zhu",
      "Bingliang Hu",
      "Zhifeng Hao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.08673",
    "title": "A Quantitative and Qualitative Analysis of Suicide Ideation Detection  using Deep Learning",
    "abstract": "For preventing youth suicide, social media platforms have received much attention from researchers. A few researches apply machine learning, or deep learning-based text classification approaches to classify social media posts containing suicidality risk. This paper replicated competitive social media-based suicidality detection/prediction models. We evaluated the feasibility of detecting suicidal ideation using multiple datasets and different state-of-the-art deep learning models, RNN-, CNN-, and Attention-based models. Using two suicidality evaluation datasets, we evaluated 28 combinations of 7 input embeddings with 4 commonly used deep learning models and 5 pretrained language models in quantitative and qualitative ways. Our replication study confirms that deep learning works well for social media-based suicidality detection in general, but it highly depends on the dataset's quality. ",
    "url": "https://arxiv.org/abs/2206.08673",
    "authors": [
      "Siqu Long",
      "Rina Cabral",
      "Josiah Poon",
      "Soyeon Caren Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.08675",
    "title": "Understanding Robust Overfitting of Adversarial Training and Beyond",
    "abstract": "Robust overfitting widely exists in adversarial training of deep networks. The exact underlying reasons for this are still not completely understood. Here, we explore the causes of robust overfitting by comparing the data distribution of \\emph{non-overfit} (weak adversary) and \\emph{overfitted} (strong adversary) adversarial training, and observe that the distribution of the adversarial data generated by weak adversary mainly contain small-loss data. However, the adversarial data generated by strong adversary is more diversely distributed on the large-loss data and the small-loss data. Given these observations, we further designed data ablation adversarial training and identify that some small-loss data which are not worthy of the adversary strength cause robust overfitting in the strong adversary mode. To relieve this issue, we propose \\emph{minimum loss constrained adversarial training} (MLCAT): in a minibatch, we learn large-loss data as usual, and adopt additional measures to increase the loss of the small-loss data. Technically, MLCAT hinders data fitting when they become easy to learn to prevent robust overfitting; philosophically, MLCAT reflects the spirit of turning waste into treasure and making the best use of each adversarial data; algorithmically, we designed two realizations of MLCAT, and extensive experiments demonstrate that MLCAT can eliminate robust overfitting and further boost adversarial robustness. ",
    "url": "https://arxiv.org/abs/2206.08675",
    "authors": [
      "Chaojian Yu",
      "Bo Han",
      "Li Shen",
      "Jun Yu",
      "Chen Gong",
      "Mingming Gong",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.08684",
    "title": "Sparse Double Descent: Where Network Pruning Aggravates Overfitting",
    "abstract": "People usually believe that network pruning not only reduces the computational cost of deep networks, but also prevents overfitting by decreasing model capacity. However, our work surprisingly discovers that network pruning sometimes even aggravates overfitting. We report an unexpected sparse double descent phenomenon that, as we increase model sparsity via network pruning, test performance first gets worse (due to overfitting), then gets better (due to relieved overfitting), and gets worse at last (due to forgetting useful information). While recent studies focused on the deep double descent with respect to model overparameterization, they failed to recognize that sparsity may also cause double descent. In this paper, we have three main contributions. First, we report the novel sparse double descent phenomenon through extensive experiments. Second, for this phenomenon, we propose a novel learning distance interpretation that the curve of $\\ell_{2}$ learning distance of sparse models (from initialized parameters to final parameters) may correlate with the sparse double descent curve well and reflect generalization better than minima flatness. Third, in the context of sparse double descent, a winning ticket in the lottery ticket hypothesis surprisingly may not always win. ",
    "url": "https://arxiv.org/abs/2206.08684",
    "authors": [
      "Zheng He",
      "Zeke Xie",
      "Quanzhi Zhu",
      "Zengchang Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.08687",
    "title": "You Only Derive Once (YODO): Automatic Differentiation for Efficient  Sensitivity Analysis in Bayesian Networks",
    "abstract": "Sensitivity analysis measures the influence of a Bayesian network's parameters on a quantity of interest defined by the network, such as the probability of a variable taking a specific value. In particular, the so-called sensitivity value measures the quantity of interest's partial derivative with respect to the network's conditional probabilities. However, finding such values in large networks with thousands of parameters can become computationally very expensive. We propose to use automatic differentiation combined with exact inference to obtain all sensitivity values in a single pass. Our method first marginalizes the whole network once using e.g. variable elimination and then backpropagates this operation to obtain the gradient with respect to all input parameters. We demonstrate our routines by ranking all parameters by importance on a Bayesian network modeling humanitarian crises and disasters, and then show the method's efficiency by scaling it to huge networks with up to 100'000 parameters. An implementation of the methods using the popular machine learning library PyTorch is freely available. ",
    "url": "https://arxiv.org/abs/2206.08687",
    "authors": [
      "Rafael Ballester-Ripoll",
      "Manuele Leonelli"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.08702",
    "title": "Sheaf Neural Networks with Connection Laplacians",
    "abstract": "A Sheaf Neural Network (SNN) is a type of Graph Neural Network (GNN) that operates on a sheaf, an object that equips a graph with vector spaces over its nodes and edges and linear maps between these spaces. SNNs have been shown to have useful theoretical properties that help tackle issues arising from heterophily and over-smoothing. One complication intrinsic to these models is finding a good sheaf for the task to be solved. Previous works proposed two diametrically opposed approaches: manually constructing the sheaf based on domain knowledge and learning the sheaf end-to-end using gradient-based methods. However, domain knowledge is often insufficient, while learning a sheaf could lead to overfitting and significant computational overhead. In this work, we propose a novel way of computing sheaves drawing inspiration from Riemannian geometry: we leverage the manifold assumption to compute manifold-and-graph-aware orthogonal maps, which optimally align the tangent spaces of neighbouring data points. We show that this approach achieves promising results with less computational overhead when compared to previous SNN models. Overall, this work provides an interesting connection between algebraic topology and differential geometry, and we hope that it will spark future research in this direction. ",
    "url": "https://arxiv.org/abs/2206.08702",
    "authors": [
      "Federico Barbero",
      "Cristian Bodnar",
      "Haitz S\u00e1ez de Oc\u00e1riz Borde",
      "Michael Bronstein",
      "Petar Veli\u010dkovi\u0107",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Differential Geometry (math.DG)"
    ]
  },
  {
    "id": "arXiv:2206.08709",
    "title": "Statistical and Neural Methods for Cross-lingual Entity Label Mapping in  Knowledge Graphs",
    "abstract": "Knowledge bases such as Wikidata amass vast amounts of named entity information, such as multilingual labels, which can be extremely useful for various multilingual and cross-lingual applications. However, such labels are not guaranteed to match across languages from an information consistency standpoint, greatly compromising their usefulness for fields such as machine translation. In this work, we investigate the application of word and sentence alignment techniques coupled with a matching algorithm to align cross-lingual entity labels extracted from Wikidata in 10 languages. Our results indicate that mapping between Wikidata's main labels stands to be considerably improved (up to $20$ points in F1-score) by any of the employed methods. We show how methods relying on sentence embeddings outperform all others, even across different scripts. We believe the application of such techniques to measure the similarity of label pairs, coupled with a knowledge base rich in high-quality entity labels, to be an excellent asset to machine translation. ",
    "url": "https://arxiv.org/abs/2206.08709",
    "authors": [
      "Gabriel Amaral",
      "M\u0101rcis Pinnis",
      "Inguna Skadi\u0146a",
      "Odinaldo Rodrigues",
      "Elena Simperl"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08712",
    "title": "An Algorithm for the SE(3)-Transformation on Neural Implicit Maps for  Remapping Functions",
    "abstract": "Implicit representations are widely used for object reconstruction due to their efficiency and flexibility. In 2021, a novel structure named neural implicit map has been invented for incremental reconstruction. A neural implicit map alleviates the problem of inefficient memory cost of previous online 3D dense reconstruction while producing better quality. % However, the neural implicit map suffers the limitation that it does not support remapping as the frames of scans are encoded into a deep prior after generating the neural implicit map. This means, that neither this generation process is invertible, nor a deep prior is transformable. The non-remappable property makes it not possible to apply loop-closure techniques. % We present a neural implicit map based transformation algorithm to fill this gap. As our neural implicit map is transformable, our model supports remapping for this special map of latent features. % Experiments show that our remapping module is capable to well-transform neural implicit maps to new poses. Embedded into a SLAM framework, our mapping model is able to tackle the remapping of loop closures and demonstrates high-quality surface reconstruction. % Our implementation is available at github\\footnote{\\url{https://github.com/Jarrome/IMT_Mapping}} for the research community. ",
    "url": "https://arxiv.org/abs/2206.08712",
    "authors": [
      "Yijun Yuan",
      "Andreas Nuechter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.08713",
    "title": "Evaluating the Impact of Source Code Parsers on ML4SE Models",
    "abstract": "As researchers and practitioners apply Machine Learning to increasingly more software engineering problems, the approaches they use become more sophisticated. A lot of modern approaches utilize internal code structure in the form of an abstract syntax tree (AST) or its extensions: path-based representation, complex graph combining AST with additional edges. Even though the process of extracting ASTs from code can be done with different parsers, the impact of choosing a parser on the final model quality remains unstudied. Moreover, researchers often omit the exact details of extracting particular code representations. In this work, we evaluate two models, namely Code2Seq and TreeLSTM, in the method name prediction task backed by eight different parsers for the Java language. To unify the process of data preparation with different parsers, we develop SuperParser, a multi-language parser-agnostic library based on PathMiner. SuperParser facilitates the end-to-end creation of datasets suitable for training and evaluation of ML models that work with structural information from source code. Our results demonstrate that trees built by different parsers vary in their structure and content. We then analyze how this diversity affects the models' quality and show that the quality gap between the most and least suitable parsers for both models turns out to be significant. Finally, we discuss other features of the parsers that researchers and practitioners should take into account when selecting a parser along with the impact on the models' quality. The code of SuperParser is publicly available at https://doi.org/10.5281/zenodo.6366591. We also publish Java-norm, the dataset we use to evaluate the models: https://doi.org/10.5281/zenodo.6366599. ",
    "url": "https://arxiv.org/abs/2206.08713",
    "authors": [
      "Ilya Utkin",
      "Egor Spirin",
      "Egor Bogomolov",
      "Timofey Bryksin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08720",
    "title": "Fast Finite Width Neural Tangent Kernel",
    "abstract": "The Neural Tangent Kernel (NTK), defined as $\\Theta_\\theta^f(x_1, x_2) = \\left[\\partial f(\\theta, x_1)\\big/\\partial \\theta\\right] \\left[\\partial f(\\theta, x_2)\\big/\\partial \\theta\\right]^T$ where $\\left[\\partial f(\\theta, \\cdot)\\big/\\partial \\theta\\right]$ is a neural network (NN) Jacobian, has emerged as a central object of study in deep learning. In the infinite width limit, the NTK can sometimes be computed analytically and is useful for understanding training and generalization of NN architectures. At finite widths, the NTK is also used to better initialize NNs, compare the conditioning across models, perform architecture search, and do meta-learning. Unfortunately, the finite width NTK is notoriously expensive to compute, which severely limits its practical utility. We perform the first in-depth analysis of the compute and memory requirements for NTK computation in finite width networks. Leveraging the structure of neural networks, we further propose two novel algorithms that change the exponent of the compute and memory requirements of the finite width NTK, dramatically improving efficiency. Our algorithms can be applied in a black box fashion to any differentiable function, including those implementing neural networks. We open-source our implementations within the Neural Tangents package (arXiv:1912.02803) at https://github.com/google/neural-tangents. ",
    "url": "https://arxiv.org/abs/2206.08720",
    "authors": [
      "Roman Novak",
      "Jascha Sohl-Dickstein",
      "Samuel S. Schoenholz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.08726",
    "title": "Evaluation of Contrastive Learning with Various Code Representations for  Code Clone Detection",
    "abstract": "Code clones are pairs of code snippets that implement similar functionality. Clone detection is a fundamental branch of automatic source code comprehension, having many applications in refactoring recommendation, plagiarism detection, and code summarization. A particularly interesting case of clone detection is the detection of semantic clones, i.e., code snippets that have the same functionality but significantly differ in implementation. A promising approach to detecting semantic clones is contrastive learning (CL), a machine learning paradigm popular in computer vision but not yet commonly adopted for code processing. Our work aims to evaluate the most popular CL algorithms combined with three source code representations on two tasks. The first task is code clone detection, which we evaluate on the POJ-104 dataset containing implementations of 104 algorithms. The second task is plagiarism detection. To evaluate the models on this task, we introduce CodeTransformator, a tool for transforming source code. We use it to create a dataset that mimics plagiarised code based on competitive programming solutions. We trained nine models for both tasks and compared them with six existing approaches, including traditional tools and modern pre-trained neural models. The results of our evaluation show that proposed models perform diversely in each task, however the performance of the graph-based models is generally above the others. Among CL algorithms, SimCLR and SwAV lead to better results, while Moco is the most robust approach. Our code and trained models are available at https://doi.org/10.5281/zenodo.6360627, https://doi.org/10.5281/zenodo.5596345. ",
    "url": "https://arxiv.org/abs/2206.08726",
    "authors": [
      "Maksim Zubkov",
      "Egor Spirin",
      "Egor Bogomolov",
      "Timofey Bryksin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08735",
    "title": "A Co-design view of Compute in-Memory with Non-Volatile Elements for  Neural Networks",
    "abstract": "Deep Learning neural networks are pervasive, but traditional computer architectures are reaching the limits of being able to efficiently execute them for the large workloads of today. They are limited by the von Neumann bottleneck: the high cost in energy and latency incurred in moving data between memory and the compute engine. Today, special CMOS designs address this bottleneck. The next generation of computing hardware will need to eliminate or dramatically mitigate this bottleneck. We discuss how compute-in-memory can play an important part in this development. Here, a non-volatile memory based cross-bar architecture forms the heart of an engine that uses an analog process to parallelize the matrix vector multiplication operation, repeatedly used in all neural network workloads. The cross-bar architecture, at times referred to as a neuromorphic approach, can be a key hardware element in future computing machines. In the first part of this review we take a co-design view of the design constraints and the demands it places on the new materials and memory devices that anchor the cross-bar architecture. In the second part, we review what is knows about the different new non-volatile memory materials and devices suited for compute in-memory, and discuss the outlook and challenges. ",
    "url": "https://arxiv.org/abs/2206.08735",
    "authors": [
      "Wilfried Haensch",
      "Anand Raghunathan",
      "Kaushik Roy",
      "Bhaswar Chakrabart",
      "Charudatta M. Phatak",
      "Cheng Wang",
      "Supratik Guha"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.08738",
    "title": "Detecting Adversarial Examples in Batches -- a geometrical approach",
    "abstract": "Many deep learning methods have successfully solved complex tasks in computer vision and speech recognition applications. Nonetheless, the robustness of these models has been found to be vulnerable to perturbed inputs or adversarial examples, which are imperceptible to the human eye, but lead the model to erroneous output decisions. In this study, we adapt and introduce two geometric metrics, density and coverage, and evaluate their use in detecting adversarial samples in batches of unseen data. We empirically study these metrics using MNIST and two real-world biomedical datasets from MedMNIST, subjected to two different adversarial attacks. Our experiments show promising results for both metrics to detect adversarial examples. We believe that his work can lay the ground for further study on these metrics' use in deployed machine learning systems to monitor for possible attacks by adversarial examples or related pathologies such as dataset shift. ",
    "url": "https://arxiv.org/abs/2206.08738",
    "authors": [
      "Danush Kumar Venkatesh",
      "Peter Steinbach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08743",
    "title": "Learning Fair Representation via Distributional Contrastive  Disentanglement",
    "abstract": "Learning fair representation is crucial for achieving fairness or debiasing sensitive information. Most existing works rely on adversarial representation learning to inject some invariance into representation. However, adversarial learning methods are known to suffer from relatively unstable training, and this might harm the balance between fairness and predictiveness of representation. We propose a new approach, learning FAir Representation via distributional CONtrastive Variational AutoEncoder (FarconVAE), which induces the latent space to be disentangled into sensitive and nonsensitive parts. We first construct the pair of observations with different sensitive attributes but with the same labels. Then, FarconVAE enforces each non-sensitive latent to be closer, while sensitive latents to be far from each other and also far from the non-sensitive latent by contrasting their distributions. We provide a new type of contrastive loss motivated by Gaussian and Student-t kernels for distributional contrastive learning with theoretical analysis. Besides, we adopt a new swap-reconstruction loss to boost the disentanglement further. FarconVAE shows superior performance on fairness, pretrained model debiasing, and domain generalization tasks from various modalities, including tabular, image, and text. ",
    "url": "https://arxiv.org/abs/2206.08743",
    "authors": [
      "Changdae Oh",
      "Heeji Won",
      "Junhyuk So",
      "Taero Kim",
      "Yewon Kim",
      "Hosik Choi",
      "Kyungwoo Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2206.08750",
    "title": "Enriched physics-informed neural networks for in-plane crack problems:  Theory and MATLAB codes",
    "abstract": "In this paper, a method based on the physics-informed neural networks (PINNs) is presented to model in-plane crack problems in the linear elastic fracture mechanics. Instead of forming a mesh, the PINNs is meshless and can be trained on batches of randomly sampled collocation points. In order to capture the theoretical singular behavior of the near-tip stress and strain fields, the standard PINNs formulation is enriched here by including the crack-tip asymptotic functions such that the singular solutions at the crack-tip region can be modeled accurately without a high degree of nodal refinement. The learnable parameters of the enriched PINNs are trained to satisfy the governing equations of the cracked body and the corresponding boundary conditions. It was found that the incorporation of the crack-tip enrichment functions in PINNs is substantially simpler and more trouble-free than in the finite element (FEM) or boundary element (BEM) methods. The present algorithm is tested on a class of representative benchmarks with different modes of loading types. Results show that the present method allows the calculation of accurate stress intensity factors (SIFs) with far fewer degrees of freedom. A self-contained MATLAB code and data-sets accompanying this manuscript are also provided. ",
    "url": "https://arxiv.org/abs/2206.08750",
    "authors": [
      "Yan Gu",
      "Chuanzeng Zhang",
      "Peijun Zhang",
      "Mikhail V. Golub"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2206.08752",
    "title": "Federated learning with incremental clustering for heterogeneous data",
    "abstract": "Federated learning enables different parties to collaboratively build a global model under the orchestration of a server while keeping the training data on clients' devices. However, performance is affected when clients have heterogeneous data. To cope with this problem, we assume that despite data heterogeneity, there are groups of clients who have similar data distributions that can be clustered. In previous approaches, in order to cluster clients the server requires clients to send their parameters simultaneously. However, this can be problematic in a context where there is a significant number of participants that may have limited availability. To prevent such a bottleneck, we propose FLIC (Federated Learning with Incremental Clustering), in which the server exploits the updates sent by clients during federated training instead of asking them to send their parameters simultaneously. Hence no additional communications between the server and the clients are necessary other than what classical federated learning requires. We empirically demonstrate for various non-IID cases that our approach successfully splits clients into groups following the same data distributions. We also identify the limitations of FLIC by studying its capability to partition clients at the early stages of the federated learning process efficiently. We further address attacks on models as a form of data heterogeneity and empirically show that FLIC is a robust defense against poisoning attacks even when the proportion of malicious clients is higher than 50\\%. ",
    "url": "https://arxiv.org/abs/2206.08752",
    "authors": [
      "Fabiola Espinoza Castellon",
      "Aurelien Mayoue",
      "Jacques-Henri Sublemontier",
      "Cedric Gouy-Pailler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08783",
    "title": "A Human-Centric Method for Generating Causal Explanations in Natural  Language for Autonomous Vehicle Motion Planning",
    "abstract": "Inscrutable AI systems are difficult to trust, especially if they operate in safety-critical settings like autonomous driving. Therefore, there is a need to build transparent and queryable systems to increase trust levels. We propose a transparent, human-centric explanation generation method for autonomous vehicle motion planning and prediction based on an existing white-box system called IGP2. Our method integrates Bayesian networks with context-free generative rules and can give causal natural language explanations for the high-level driving behaviour of autonomous vehicles. Preliminary testing on simulated scenarios shows that our method captures the causes behind the actions of autonomous vehicles and generates intelligible explanations with varying complexity. ",
    "url": "https://arxiv.org/abs/2206.08783",
    "authors": [
      "Balint Gyevnar",
      "Massimiliano Tamborski",
      "Cheng Wang",
      "Christopher G. Lucas",
      "Shay B. Cohen",
      "Stefano V. Albrecht"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.08788",
    "title": "Is Multi-Modal Necessarily Better? Robustness Evaluation of Multi-modal  Fake News Detection",
    "abstract": "The proliferation of fake news and its serious negative social influence push fake news detection methods to become necessary tools for web managers. Meanwhile, the multi-media nature of social media makes multi-modal fake news detection popular for its ability to capture more modal features than uni-modal detection methods. However, current literature on multi-modal detection is more likely to pursue the detection accuracy but ignore the robustness of the detector. To address this problem, we propose a comprehensive robustness evaluation of multi-modal fake news detectors. In this work, we simulate the attack methods of malicious users and developers, i.e., posting fake news and injecting backdoors. Specifically, we evaluate multi-modal detectors with five adversarial and two backdoor attack methods. Experiment results imply that: (1) The detection performance of the state-of-the-art detectors degrades significantly under adversarial attacks, even worse than general detectors; (2) Most multi-modal detectors are more vulnerable when subjected to attacks on visual modality than textual modality; (3) Popular events' images will cause significant degradation to the detectors when they are subjected to backdoor attacks; (4) The performance of these detectors under multi-modal attacks is worse than under uni-modal attacks; (5) Defensive methods will improve the robustness of the multi-modal detectors. ",
    "url": "https://arxiv.org/abs/2206.08788",
    "authors": [
      "Jinyin Chen",
      "Chengyu Jia",
      "Haibin Zheng",
      "Ruoxi Chen",
      "Chenbo Fu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.08789",
    "title": "Reconstructing vehicles from orthographic drawings using deep neural  networks",
    "abstract": "This paper explores the current state-of-the-art of object reconstruction from multiple orthographic drawings using deep neural networks. It proposes two algorithms to extract multiple views from a single image. The paper proposes a system based on pixel-aligned implicit functions (PIFu) and develops an advanced sampling strategy to generate signed distance samples. It also compares this approach to depth map regression from multiple views. Additionally, the paper uses a novel dataset for vehicle reconstruction from the racing game Assetto Corsa, which features higher quality models than the commonly used ShapeNET dataset. The trained neural network generalizes well to real-world inputs and creates plausible and detailed reconstructions. ",
    "url": "https://arxiv.org/abs/2206.08789",
    "authors": [
      "Robin Klippert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08790",
    "title": "Self-supervised speech unit discovery from articulatory and acoustic  features using VQ-VAE",
    "abstract": "The human perception system is often assumed to recruit motor knowledge when processing auditory speech inputs. Using articulatory modeling and deep learning, this study examines how this articulatory information can be used for discovering speech units in a self-supervised setting. We used vector-quantized variational autoencoders (VQ-VAE) to learn discrete representations from articulatory and acoustic speech data. In line with the zero-resource paradigm, an ABX test was then used to investigate how the extracted representations encode phonetically relevant properties. Experiments were conducted on three different corpora in English and French. We found that articulatory information rather organises the latent representations in terms of place of articulation whereas the speech acoustics mainly structure the latent space in terms of manner of articulation. We show that an optimal fusion of the two modalities can lead to a joint representation of these phonetic dimensions more accurate than each modality considered individually. Since articulatory information is usually not available in a practical situation, we finally investigate the benefit it provides when inferred from the speech acoustics in a self-supervised manner. ",
    "url": "https://arxiv.org/abs/2206.08790",
    "authors": [
      "Marc-Antoine Georges",
      "Jean-Luc Schwartz",
      "Thomas Hueber"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.08800",
    "title": "Self-supervised deep visual servoing for high precision peg-in-hole  insertion",
    "abstract": "Many industrial assembly tasks involve peg-in-hole like insertions with sub-millimeter tolerances which are challenging, even in highly calibrated robot cells. Visual servoing can be employed to increase the robustness towards uncertainties in the system, however, state of the art methods either rely on accurate 3D models for synthetic renderings or manual involvement in acquisition of training data. We present a novel self-supervised visual servoing method for high precision peg-in-hole insertion, which is fully automated and does not rely on synthetic data. We demonstrate its applicability for insertion of electronic components into a printed circuit board with tight tolerances. We show that peg-in-hole insertion can be drastically sped up by preceding a robust but slow force-based insertion strategy with our proposed visual servoing method, the configuration of which is fully autonomous. ",
    "url": "https://arxiv.org/abs/2206.08800",
    "authors": [
      "Rasmus Laurvig Haugaard",
      "Anders Glent Buch",
      "Thorbj\u00f8rn Mosekj\u00e6r Iversen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.08801",
    "title": "Video Shadow Detection via Spatio-Temporal Interpolation Consistency  Training",
    "abstract": "It is challenging to annotate large-scale datasets for supervised video shadow detection methods. Using a model trained on labeled images to the video frames directly may lead to high generalization error and temporal inconsistent results. In this paper, we address these challenges by proposing a Spatio-Temporal Interpolation Consistency Training (STICT) framework to rationally feed the unlabeled video frames together with the labeled images into an image shadow detection network training. Specifically, we propose the Spatial and Temporal ICT, in which we define two new interpolation schemes, \\textit{i.e.}, the spatial interpolation and the temporal interpolation. We then derive the spatial and temporal interpolation consistency constraints accordingly for enhancing generalization in the pixel-wise classification task and for encouraging temporal consistent predictions, respectively. In addition, we design a Scale-Aware Network for multi-scale shadow knowledge learning in images, and propose a scale-consistency constraint to minimize the discrepancy among the predictions at different scales. Our proposed approach is extensively validated on the ViSha dataset and a self-annotated dataset. Experimental results show that, even without video labels, our approach is better than most state of the art supervised, semi-supervised or unsupervised image/video shadow detection methods and other methods in related tasks. Code and dataset are available at \\url{https://github.com/yihong-97/STICT}. ",
    "url": "https://arxiv.org/abs/2206.08801",
    "authors": [
      "Xiao Lu",
      "Yihong Cao",
      "Sheng Liu",
      "Chengjiang Long",
      "Zipei Chen",
      "Xuanyu Zhou",
      "Yimin Yang",
      "Chunxia Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.08809",
    "title": "Holistic Transformer: A Joint Neural Network for Trajectory Prediction  and Decision-Making of Autonomous Vehicles",
    "abstract": "Trajectory prediction and behavioral decision-making are two important tasks for autonomous vehicles that require good understanding of the environmental context; behavioral decisions are better made by referring to the outputs of trajectory predictions. However, most current solutions perform these two tasks separately. Therefore, a joint neural network that combines multiple cues is proposed and named as the holistic transformer to predict trajectories and make behavioral decisions simultaneously. To better explore the intrinsic relationships between cues, the network uses existing knowledge and adopts three kinds of attention mechanisms: the sparse multi-head type for reducing noise impact, feature selection sparse type for optimally using partial prior knowledge, and multi-head with sigmoid activation type for optimally using posteriori knowledge. Compared with other trajectory prediction models, the proposed model has better comprehensive performance and good interpretability. Perceptual noise robustness experiments demonstrate that the proposed model has good noise robustness. Thus, simultaneous trajectory prediction and behavioral decision-making combining multiple cues can reduce computational costs and enhance semantic relationships between scenes and agents. ",
    "url": "https://arxiv.org/abs/2206.08809",
    "authors": [
      "Hongyu Hu",
      "Qi Wang",
      "Zhengguang Zhang",
      "Zhengyi Li",
      "Zhenhai Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.08832",
    "title": "Prediction of Solar Radiation Based on Spatial and Temporal Embeddings  for Solar Generation Forecast",
    "abstract": "A novel method for real-time solar generation forecast using weather data, while exploiting both spatial and temporal structural dependencies is proposed. The network observed over time is projected to a lower-dimensional representation where a variety of weather measurements are used to train a structured regression model while weather forecast is used at the inference stage. Experiments were conducted at 288 locations in the San Antonio, TX area on obtained from the National Solar Radiation Database. The model predicts solar irradiance with a good accuracy (R2 0.91 for the summer, 0.85 for the winter, and 0.89 for the global model). The best accuracy was obtained by the Random Forest Regressor. Multiple experiments were conducted to characterize influence of missing data and different time horizons providing evidence that the new algorithm is robust for data missing not only completely at random but also when the mechanism is spatial, and temporal. ",
    "url": "https://arxiv.org/abs/2206.08832",
    "authors": [
      "Mohammad Alqudah",
      "Tatjana Dokic",
      "Mladen Kezunovic",
      "Zoran Obradovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08856",
    "title": "SwarmHive: Heterogeneous Swarm of Drones for Robust Autonomous Landing  on Moving Robot",
    "abstract": "The paper focuses on a heterogeneous swarm of drones to achieve a dynamic landing of formation on a moving robot. This challenging task was not yet achieved by scientists. The key technology is that instead of facilitating each agent of the swarm of drones with computer vision that considerably increases the payload and shortens the flight time, we propose to install only one camera on the leader drone. The follower drones receive the commands from the leader UAV and maintain a collision-free trajectory with the artificial potential field. The experimental results revealed a high accuracy of the swarm landing on a static mobile platform (RMSE of 4.48 cm). RMSE of swarm landing on the mobile platform moving with the maximum velocities of 1.0 m/s and 1.5 m/s equals 8.76 cm and 8.98 cm, respectively. The proposed SwarmHive technology will allow the time-saving landing of the swarm for further drone recharging. This will make it possible to achieve self-sustainable operation of a multi-agent robotic system for such scenarios as rescue operations, inspection and maintenance, autonomous warehouse inventory, cargo delivery, and etc. ",
    "url": "https://arxiv.org/abs/2206.08856",
    "authors": [
      "Ayush Gupta",
      "Ahmed Baza",
      "Ekaterina Dorzhieva",
      "Mert Alper",
      "Mariia Makarova",
      "Stepan Perminov",
      "Aleksey Fedoseev",
      "Dzmitry Tsetserukou"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.08869",
    "title": "Fast Lossless Neural Compression with Integer-Only Discrete Flows",
    "abstract": "By applying entropy codecs with learned data distributions, neural compressors have significantly outperformed traditional codecs in terms of compression ratio. However, the high inference latency of neural networks hinders the deployment of neural compressors in practical applications. In this work, we propose Integer-only Discrete Flows (IODF), an efficient neural compressor with integer-only arithmetic. Our work is built upon integer discrete flows, which consists of invertible transformations between discrete random variables. We propose efficient invertible transformations with integer-only arithmetic based on 8-bit quantization. Our invertible transformation is equipped with learnable binary gates to remove redundant filters during inference. We deploy IODF with TensorRT on GPUs, achieving 10x inference speedup compared to the fastest existing neural compressors, while retaining the high compression rates on ImageNet32 and ImageNet64. ",
    "url": "https://arxiv.org/abs/2206.08869",
    "authors": [
      "Siyu Wang",
      "Jianfei Chen",
      "Chongxuan Li",
      "Jun Zhu",
      "Bo Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2206.08871",
    "title": "How robust are pre-trained models to distribution shift?",
    "abstract": "The vulnerability of machine learning models to spurious correlations has mostly been discussed in the context of supervised learning (SL). However, there is a lack of insight on how spurious correlations affect the performance of popular self-supervised learning (SSL) and auto-encoder based models (AE). In this work, we shed light on this by evaluating the performance of these models on both real world and synthetic distribution shift datasets. Following observations that the linear head itself can be susceptible to spurious correlations, we develop a novel evaluation scheme with the linear head trained on out-of-distribution (OOD) data, to isolate the performance of the pre-trained models from a potential bias of the linear head used for evaluation. With this new methodology, we show that SSL models are consistently more robust to distribution shifts and thus better at OOD generalisation than AE and SL models. ",
    "url": "https://arxiv.org/abs/2206.08871",
    "authors": [
      "Yuge Shi",
      "Imant Daunhawer",
      "Julia E. Vogt",
      "Philip H.S. Torr",
      "Amartya Sanyal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.08882",
    "title": "Edge-Aided Sensor Data Sharing in Vehicular Communication Networks",
    "abstract": "Sensor data sharing in vehicular networks can significantly improve the range and accuracy of environmental perception for connected automated vehicles. Different concepts and schemes for dissemination and fusion of sensor data have been developed. It is common to these schemes that measurement errors of the sensors impair the perception quality and can result in road traffic accidents. Specifically, when the measurement error from the sensors (also referred as measurement noise) is unknown and time varying, the performance of the data fusion process is restricted, which represents a major challenge in the calibration of sensors. In this paper, we consider sensor data sharing and fusion in a vehicular network with both, vehicle-to-infrastructure and vehicle-to-vehicle communication. We propose a method, named Bidirectional Feedback Noise Estimation (BiFNoE), in which an edge server collects and caches sensor measurement data from vehicles. The edge estimates the noise and the targets alternately in double dynamic sliding time windows and enhances the distributed cooperative environment sensing at each vehicle with low communication costs. We evaluate the proposed algorithm and data dissemination strategy in an application scenario by simulation and show that the perception accuracy is on average improved by around 80 % with only 12 kbps uplink and 28 kbps downlink bandwidth. ",
    "url": "https://arxiv.org/abs/2206.08882",
    "authors": [
      "Rui Song",
      "Anupama Hegde",
      "Numan Senel",
      "Alois Knoll",
      "Andreas Festag"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.08883",
    "title": "CtrlFormer: Learning Transferable State Representation for Visual  Control via Transformer",
    "abstract": "Transformer has achieved great successes in learning vision and language representation, which is general across various downstream tasks. In visual control, learning transferable state representation that can transfer between different control tasks is important to reduce the training sample size. However, porting Transformer to sample-efficient visual control remains a challenging and unsolved problem. To this end, we propose a novel Control Transformer (CtrlFormer), possessing many appealing benefits that prior arts do not have. Firstly, CtrlFormer jointly learns self-attention mechanisms between visual tokens and policy tokens among different control tasks, where multitask representation can be learned and transferred without catastrophic forgetting. Secondly, we carefully design a contrastive reinforcement learning paradigm to train CtrlFormer, enabling it to achieve high sample efficiency, which is important in control problems. For example, in the DMControl benchmark, unlike recent advanced methods that failed by producing a zero score in the \"Cartpole\" task after transfer learning with 100k samples, CtrlFormer can achieve a state-of-the-art score with only 100k samples while maintaining the performance of previous tasks. The code and models are released in our project homepage. ",
    "url": "https://arxiv.org/abs/2206.08883",
    "authors": [
      "Yao Mu",
      "Shoufa Chen",
      "Mingyu Ding",
      "Jianyu Chen",
      "Runjian Chen",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08918",
    "title": "Learning a Single Neuron with Adversarial Label Noise via Gradient  Descent",
    "abstract": "We study the fundamental problem of learning a single neuron, i.e., a function of the form $\\mathbf{x}\\mapsto\\sigma(\\mathbf{w}\\cdot\\mathbf{x})$ for monotone activations $\\sigma:\\mathbb{R}\\mapsto\\mathbb{R}$, with respect to the $L_2^2$-loss in the presence of adversarial label noise. Specifically, we are given labeled examples from a distribution $D$ on $(\\mathbf{x}, y)\\in\\mathbb{R}^d \\times \\mathbb{R}$ such that there exists $\\mathbf{w}^\\ast\\in\\mathbb{R}^d$ achieving $F(\\mathbf{w}^\\ast)=\\epsilon$, where $F(\\mathbf{w})=\\mathbf{E}_{(\\mathbf{x},y)\\sim D}[(\\sigma(\\mathbf{w}\\cdot \\mathbf{x})-y)^2]$. The goal of the learner is to output a hypothesis vector $\\mathbf{w}$ such that $F(\\mathbb{w})=C\\, \\epsilon$ with high probability, where $C>1$ is a universal constant. As our main contribution, we give efficient constant-factor approximate learners for a broad class of distributions (including log-concave distributions) and activation functions. Concretely, for the class of isotropic log-concave distributions, we obtain the following important corollaries: For the logistic activation, we obtain the first polynomial-time constant factor approximation (even under the Gaussian distribution). Our algorithm has sample complexity $\\widetilde{O}(d/\\epsilon)$, which is tight within polylogarithmic factors. For the ReLU activation, we give an efficient algorithm with sample complexity $\\tilde{O}(d\\, \\polylog(1/\\epsilon))$. Prior to our work, the best known constant-factor approximate learner had sample complexity $\\tilde{\\Omega}(d/\\epsilon)$. In both of these settings, our algorithms are simple, performing gradient-descent on the (regularized) $L_2^2$-loss. The correctness of our algorithms relies on novel structural results that we establish, showing that (essentially all) stationary points of the underlying non-convex loss are approximately optimal. ",
    "url": "https://arxiv.org/abs/2206.08918",
    "authors": [
      "Ilias Diakonikolas",
      "Vasilis Kontonis",
      "Christos Tzamos",
      "Nikos Zarifis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.08401",
    "title": "Are decentralized finance really decentralized? A social network  analysis of the Aave protocol on the Ethereum blockchain",
    "abstract": "Decentralized finance (DeFi) has the potential to disrupt centralized finance by validating peer-to-peer transactions through tamper-proof smart contracts and thus significantly lower the transaction cost charged by financial intermediaries. However, the actual realization of peer-to-peer transactions and the levels and effect of decentralization are largely unknown. Our research pioneers a blockchain network study that applies social network analysis to measure the level, dynamics, and impacts of decentralization in DeFi token transactions on Ethereum blockchain. First, we find a significant core-periphery structure in the AAVE token transaction network where the cores include the two largest centralized crypto exchanges. Second, we provide evidence that multiple network features consistently characterize decentralization dynamics. Finally, we document that a more decentralized network significantly predicts a higher return and lower volatilities of the DeFi tokens. We point out that our approach is seminal for inspiring future extensions related to the facets of application scenarios, research questions, and methodologies on the mechanics of blockchain decentralization. ",
    "url": "https://arxiv.org/abs/2206.08401",
    "authors": [
      "Ziqiao Ao",
      "Gergely Horvath",
      "Luyao Zhang"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Cryptography and Security (cs.CR)",
      "Statistical Finance (q-fin.ST)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2206.08465",
    "title": "Variational Estimators of the Degree-corrected Latent Block Model for  Bipartite Networks",
    "abstract": "Biclustering on bipartite graphs is an unsupervised learning task that simultaneously clusters the two types of objects in the graph, for example, users and movies in a movie review dataset. The latent block model (LBM) has been proposed as a model-based tool for biclustering. Biclustering results by the LBM are, however, usually dominated by the row and column sums of the data matrix, i.e., degrees. We propose a degree-corrected latent block model (DC-LBM) to accommodate degree heterogeneity in row and column clusters, which greatly outperforms the classical LBM in the MovieLens dataset and simulated data. We develop an efficient variational expectation-maximization algorithm by observing that the row and column degrees maximize the objective function in the M step given any probability assignment on the cluster labels. We prove the label consistency of the variational estimator under the DC-LBM, which allows the expected graph density goes to zero as long as the average expected degrees of rows and columns go to infinity. ",
    "url": "https://arxiv.org/abs/2206.08465",
    "authors": [
      "Yunpeng Zhao",
      "Ning Hao",
      "Ji Zhu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08481",
    "title": "Orientation-guided Graph Convolutional Network for Bone Surface  Segmentation",
    "abstract": "Due to imaging artifacts and low signal-to-noise ratio in ultrasound images, automatic bone surface segmentation networks often produce fragmented predictions that can hinder the success of ultrasound-guided computer-assisted surgical procedures. Existing pixel-wise predictions often fail to capture the accurate topology of bone tissues due to a lack of supervision to enforce connectivity. In this work, we propose an orientation-guided graph convolutional network to improve connectivity while segmenting the bone surface. We also propose an additional supervision on the orientation of the bone surface to further impose connectivity. We validated our approach on 1042 vivo US scans of femur, knee, spine, and distal radius. Our approach improves over the state-of-the-art methods by 5.01% in connectivity metric. ",
    "url": "https://arxiv.org/abs/2206.08481",
    "authors": [
      "Aimon Rahman",
      "Wele Gedara Chaminda Bandara",
      "Jeya Maria Jose Valanarasu",
      "Ilker Hacihaliloglu",
      "Vishal M Patel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.08531",
    "title": "Reframed GES with a Neural Conditional Dependence Measure",
    "abstract": "In a nonparametric setting, the causal structure is often identifiable only up to Markov equivalence, and for the purpose of causal inference, it is useful to learn a graphical representation of the Markov equivalence class (MEC). In this paper, we revisit the Greedy Equivalence Search (GES) algorithm, which is widely cited as a score-based algorithm for learning the MEC of the underlying causal structure. We observe that in order to make the GES algorithm consistent in a nonparametric setting, it is not necessary to design a scoring metric that evaluates graphs. Instead, it suffices to plug in a consistent estimator of a measure of conditional dependence to guide the search. We therefore present a reframing of the GES algorithm, which is more flexible than the standard score-based version and readily lends itself to the nonparametric setting with a general measure of conditional dependence. In addition, we propose a neural conditional dependence (NCD) measure, which utilizes the expressive power of deep neural networks to characterize conditional independence in a nonparametric manner. We establish the optimality of the reframed GES algorithm under standard assumptions and the consistency of using our NCD estimator to decide conditional independence. Together these results justify the proposed approach. Experimental results demonstrate the effectiveness of our method in causal discovery, as well as the advantages of using our NCD measure over kernel-based measures. ",
    "url": "https://arxiv.org/abs/2206.08531",
    "authors": [
      "Xinwei Shen",
      "Shengyu Zhu",
      "Jiji Zhang",
      "Shoubo Hu",
      "Zhitang Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08543",
    "title": "Multi-Classification of Brain Tumor Images Using Transfer Learning Based  Deep Neural Network",
    "abstract": "In recent advancement towards computer based diagnostics system, the classification of brain tumor images is a challenging task. This paper mainly focuses on elevating the classification accuracy of brain tumor images with transfer learning based deep neural network. The classification approach is started with the image augmentation operation including rotation, zoom, hori-zontal flip, width shift, height shift, and shear to increase the diversity in image datasets. Then the general features of the input brain tumor images are extracted based on a pre-trained transfer learning method comprised of Inception-v3. Fi-nally, the deep neural network with 4 customized layers is employed for classi-fying the brain tumors in most frequent brain tumor types as meningioma, glioma, and pituitary. The proposed model acquires an effective performance with an overall accuracy of 96.25% which is much improved than some existing multi-classification methods. Whereas, the fine-tuning of hyper-parameters and inclusion of customized DNN with the Inception-v3 model results in an im-provement of the classification accuracy. ",
    "url": "https://arxiv.org/abs/2206.08543",
    "authors": [
      "Pramit Dutta",
      "Khaleda Akhter Sathi",
      "Md. Saiful Islam"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.08545",
    "title": "NU-Wave 2: A General Neural Audio Upsampling Model for Various Sampling  Rates",
    "abstract": "Conventionally, audio super-resolution models fixed the initial and the target sampling rates, which necessitate the model to be trained for each pair of sampling rates. We introduce NU-Wave 2, a diffusion model for neural audio upsampling that enables the generation of 48 kHz audio signals from inputs of various sampling rates with a single model. Based on the architecture of NU-Wave, NU-Wave 2 uses short-time Fourier convolution (STFC) to generate harmonics to resolve the main failure modes of NU-Wave, and incorporates bandwidth spectral feature transform (BSFT) to condition the bandwidths of inputs in the frequency domain. We experimentally demonstrate that NU-Wave 2 produces high-resolution audio regardless of the sampling rate of input while requiring fewer parameters than other models. The official code and the audio samples are available at https://mindslab-ai.github.io/nuwave2. ",
    "url": "https://arxiv.org/abs/2206.08545",
    "authors": [
      "Seungu Han",
      "Junhyeok Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08557",
    "title": "COVID-19 Detection using Transfer Learning with Convolutional Neural  Network",
    "abstract": "The Novel Coronavirus disease 2019 (COVID-19) is a fatal infectious disease, first recognized in December 2019 in Wuhan, Hubei, China, and has gone on an epidemic situation. Under these circumstances, it became more important to detect COVID-19 in infected people. Nowadays, the testing kits are gradually lessening in number compared to the number of infected population. Under recent prevailing conditions, the diagnosis of lung disease by analyzing chest CT (Computed Tomography) images has become an important tool for both diagnosis and prophecy of COVID-19 patients. In this study, a Transfer learning strategy (CNN) for detecting COVID-19 infection from CT images has been proposed. In the proposed model, a multilayer Convolutional neural network (CNN) with Transfer learning model Inception V3 has been designed. Similar to CNN, it uses convolution and pooling to extract features, but this transfer learning model contains weights of dataset Imagenet. Thus it can detect features very effectively which gives it an upper hand for achieving better accuracy. ",
    "url": "https://arxiv.org/abs/2206.08557",
    "authors": [
      "Pramit Dutta",
      "Tanny Roy",
      "Nafisa Anjum"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1308.1351",
    "title": "An $O^*(1.0821^n)$-Time Algorithm for Computing Maximum Independent Set  in Graphs with Bounded Degree 3",
    "abstract": " Comments: While working on an updated version, we observed a bug in one of the cases of our extensive case analysis. We are withdrawing this paper while we work to fix the bug. We will add an updated version once we manage to fix the bug ",
    "url": "https://arxiv.org/abs/1308.1351",
    "authors": [
      "Davis Issac",
      "Ragesh Jaiswal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:1810.00226",
    "title": "Toward single particle reconstruction without particle picking: Breaking  the detection limit",
    "abstract": " Comments: Older citations to this paper refer to version arXiv:1810.00226v1, parts of which now appear in: Tamir Bendory, Nicolas Boumal, William Leeb, Eitan Levin, and Amit Singer. \"Multi-target detection with application to cryo-electron microscopy.\" Inverse Problems 35, no. 10 (2019): 104003 ",
    "url": "https://arxiv.org/abs/1810.00226",
    "authors": [
      "Tamir Bendory",
      "Nicolas Boumal",
      "William Leeb",
      "Eitan Levin",
      "Amit Singer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:1910.09083",
    "title": "Spectral CUSUM for Online Network Structure Change Detection",
    "abstract": " Title: Spectral CUSUM for Online Network Structure Change Detection ",
    "url": "https://arxiv.org/abs/1910.09083",
    "authors": [
      "Minghe Zhang",
      "Liyan Xie",
      "Yao Xie"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2103.04053",
    "title": "NVUM: Non-Volatile Unbiased Memory for Robust Medical Image  Classification",
    "abstract": " Comments: MICCAI 2022 Early Accept ",
    "url": "https://arxiv.org/abs/2103.04053",
    "authors": [
      "Fengbei Liu",
      "Yuanhong Chen",
      "Yu Tian",
      "Yuyuan Liu",
      "Chong Wang",
      "Vasileios Belagiannis",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2103.16446",
    "title": "CovidTracker: A comprehensive Covid-related social media dataset for NLP  tasks",
    "abstract": " Title: CovidTracker: A comprehensive Covid-related social media dataset for NLP  tasks ",
    "url": "https://arxiv.org/abs/2103.16446",
    "authors": [
      "Richard Plant",
      "Amir Hussain"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2106.03305",
    "title": "Faster Cut-Equivalent Trees in Simple Graphs",
    "abstract": " Comments: Change license ",
    "url": "https://arxiv.org/abs/2106.03305",
    "authors": [
      "Tianyi Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2108.07664",
    "title": "On the Complexity of Two-Party Differential Privacy",
    "abstract": " Comments: Accepted to STOC 2022 ",
    "url": "https://arxiv.org/abs/2108.07664",
    "authors": [
      "Iftach Haitner",
      "Noam Mazor",
      "Jad Silbak",
      "Eliad Tsfadia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2109.01408",
    "title": "Automatic Foot Ulcer Segmentation Using an Ensemble of Convolutional  Neural Networks",
    "abstract": " Comments: Accepted for the 26th International Conference on Pattern Recognition (ICPR 2022) ",
    "url": "https://arxiv.org/abs/2109.01408",
    "authors": [
      "Amirreza Mahbod",
      "Gerald Schaefer",
      "Rupert Ecker",
      "Isabella Ellinger"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.02533",
    "title": "Neural Ensemble Search via Bayesian Sampling",
    "abstract": " Comments: Published as a conference paper at UAI 2022 ",
    "url": "https://arxiv.org/abs/2109.02533",
    "authors": [
      "Yao Shu",
      "Yizhou Chen",
      "Zhongxiang Dai",
      "Bryan Kian Hsiang Low"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.03856",
    "title": "Local Augmentation for Graph Neural Networks",
    "abstract": " Comments: Accepted by ICML'22 ",
    "url": "https://arxiv.org/abs/2109.03856",
    "authors": [
      "Songtao Liu",
      "Rex Ying",
      "Hanze Dong",
      "Lanqing Li",
      "Tingyang Xu",
      "Yu Rong",
      "Peilin Zhao",
      "Junzhou Huang",
      "Dinghao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.05075",
    "title": "On the Compression of Neural Networks Using $\\ell_0$-Norm Regularization  and Weight Pruning",
    "abstract": " Comments: 23 pages, 6 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2109.05075",
    "authors": [
      "Felipe Dennis de Resende Oliveira",
      "Eduardo Luiz Ortiz Batista",
      "Rui Seara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2109.13376",
    "title": "Counting colorings of triangle-free graphs",
    "abstract": " Comments: 16 pp ",
    "url": "https://arxiv.org/abs/2109.13376",
    "authors": [
      "Anton Bernshteyn",
      "Tyler Brazelton",
      "Ruijia Cao",
      "Akum Kang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2110.05007",
    "title": "Boosting Fast Adversarial Training with Learnable Adversarial  Initialization",
    "abstract": " Comments: Accepted by TIP ",
    "url": "https://arxiv.org/abs/2110.05007",
    "authors": [
      "Xiaojun Jia",
      "Yong Zhang",
      "Baoyuan Wu",
      "Jue Wang",
      "Xiaochun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.06256",
    "title": "Neural Network Weights Do Not Converge to Stationary Points: An  Invariant Measure Perspective",
    "abstract": " Title: Neural Network Weights Do Not Converge to Stationary Points: An  Invariant Measure Perspective ",
    "url": "https://arxiv.org/abs/2110.06256",
    "authors": [
      "Jingzhao Zhang",
      "Haochuan Li",
      "Suvrit Sra",
      "Ali Jadbabaie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.06435",
    "title": "Dropout Prediction Uncertainty Estimation Using Neuron Activation  Strength",
    "abstract": " Comments: 8 pages ",
    "url": "https://arxiv.org/abs/2110.06435",
    "authors": [
      "Haichao Yu",
      "Zhe Chen",
      "Dong Lin",
      "Gil Shamir",
      "Jie Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.13900",
    "title": "WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech  Processing",
    "abstract": " Comments: Submitted to the Journal of Selected Topics in Signal Processing (JSTSP) ",
    "url": "https://arxiv.org/abs/2110.13900",
    "authors": [
      "Sanyuan Chen",
      "Chengyi Wang",
      "Zhengyang Chen",
      "Yu Wu",
      "Shujie Liu",
      "Zhuo Chen",
      "Jinyu Li",
      "Naoyuki Kanda",
      "Takuya Yoshioka",
      "Xiong Xiao",
      "Jian Wu",
      "Long Zhou",
      "Shuo Ren",
      "Yanmin Qian",
      "Yao Qian",
      "Jian Wu",
      "Michael Zeng",
      "Xiangzhan Yu",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2111.03740",
    "title": "Toward Learning Human-aligned Cross-domain Robust Models by Countering  Misaligned Features",
    "abstract": " Comments: to appear at UAI 2022 ",
    "url": "https://arxiv.org/abs/2111.03740",
    "authors": [
      "Haohan Wang",
      "Zeyi Huang",
      "Hanlin Zhang",
      "Yong Jae Lee",
      "Eric Xing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.05457",
    "title": "Optimizing Number, Placement, and Backhaul Connectivity of Multi-UAV  Networks",
    "abstract": " Comments: To appear in IEEE Internet of Things Journal ",
    "url": "https://arxiv.org/abs/2111.05457",
    "authors": [
      "Javad Sabzehali",
      "Vijay K. Shah",
      "Qiang Fan",
      "Biplav Choudhury",
      "Lingjia Liu",
      "Jeffrey H. Reed"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2111.06310",
    "title": "Self-Normalized Importance Sampling for Neural Language Modeling",
    "abstract": " Comments: Accepted at INTERSPEECH 2022 ",
    "url": "https://arxiv.org/abs/2111.06310",
    "authors": [
      "Zijian Yang",
      "Yingbo Gao",
      "Alexander Gerstenberger",
      "Jintao Jiang",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2111.11707",
    "title": "Boosting Neural Machine Translation with Dependency-Scaled  Self-Attention Network",
    "abstract": " Title: Boosting Neural Machine Translation with Dependency-Scaled  Self-Attention Network ",
    "url": "https://arxiv.org/abs/2111.11707",
    "authors": [
      "Ru Peng",
      "Nankai Lin",
      "Yi Fang",
      "Shengyi Jiang",
      "Tianyong Hao",
      "Boyu Chen",
      "Junbo Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.07508",
    "title": "Anti-Money Laundering Alert Optimization Using Machine Learning with  Graphs",
    "abstract": " Comments: 8 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2112.07508",
    "authors": [
      "Ahmad Naser Eddin",
      "Jacopo Bono",
      "David Apar\u00edcio",
      "David Polido",
      "Jo\u00e3o Tiago Ascens\u00e3o",
      "Pedro Bizarro",
      "Pedro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.07897",
    "title": "Tight query complexity bounds for learning graph partitions",
    "abstract": " Comments: Accepted for presentation at the 35th Annual Conference of Learning Theory, 2022 ",
    "url": "https://arxiv.org/abs/2112.07897",
    "authors": [
      "Xizhi Liu",
      "Sayan Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2201.11729",
    "title": "Implicit Regularization in Hierarchical Tensor Factorization and Deep  Convolutional Neural Networks",
    "abstract": " Comments: Accepted to ICML 2022 ",
    "url": "https://arxiv.org/abs/2201.11729",
    "authors": [
      "Noam Razin",
      "Asaf Maman",
      "Nadav Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.12987",
    "title": "Interpretable and Generalizable Graph Learning via Stochastic Attention  Mechanism",
    "abstract": " Comments: Accepted to ICML 2022 ",
    "url": "https://arxiv.org/abs/2201.12987",
    "authors": [
      "Siqi Miao",
      "Miaoyuan Liu",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.00436",
    "title": "ROCK: Causal Inference Principles for Reasoning about Commonsense  Causality",
    "abstract": " Comments: To appear, ICML 2022 ",
    "url": "https://arxiv.org/abs/2202.00436",
    "authors": [
      "Jiayao Zhang",
      "Hongming Zhang",
      "Weijie J. Su",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2202.03038",
    "title": "Deep Networks on Toroids: Removing Symmetries Reveals the Structure of  Flat Regions in the Landscape Geometry",
    "abstract": " Title: Deep Networks on Toroids: Removing Symmetries Reveals the Structure of  Flat Regions in the Landscape Geometry ",
    "url": "https://arxiv.org/abs/2202.03038",
    "authors": [
      "Fabrizio Pittorino",
      "Antonio Ferraro",
      "Gabriele Perugini",
      "Christoph Feinauer",
      "Carlo Baldassi",
      "Riccardo Zecchina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)"
    ]
  },
  {
    "id": "arXiv:2202.03077",
    "title": "Adversarial Attack and Defense for Non-Parametric Two-Sample Tests",
    "abstract": " Comments: Accepted by ICML 2022 ",
    "url": "https://arxiv.org/abs/2202.03077",
    "authors": [
      "Xilie Xu",
      "Jingfeng Zhang",
      "Feng Liu",
      "Masashi Sugiyama",
      "Mohan Kankanhalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.03760",
    "title": "Modeling Structure with Undirected Neural Networks",
    "abstract": " Comments: ICML 2022 ",
    "url": "https://arxiv.org/abs/2202.03760",
    "authors": [
      "Tsvetomila Mihaylova",
      "Vlad Niculae",
      "Andr\u00e9 F. T. Martins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.04713",
    "title": "PINs: Progressive Implicit Networks for Multi-Scale Neural  Representations",
    "abstract": " Comments: ICML 2022 (spotlight) ",
    "url": "https://arxiv.org/abs/2202.04713",
    "authors": [
      "Zoe Landgraf",
      "Alexander Sorkine Hornung",
      "Ricardo Silveira Cabral"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.05628",
    "title": "Artemis: Articulated Neural Pets with Appearance and Motion synthesis",
    "abstract": " Comments: Accepted to ACM SIGGRAPH 2022 (Journal track) ",
    "url": "https://arxiv.org/abs/2202.05628",
    "authors": [
      "Haimin Luo",
      "Teng Xu",
      "Yuheng Jiang",
      "Chenglin Zhou",
      "Qiwei Qiu",
      "Yingliang Zhang",
      "Wei Yang",
      "Lan Xu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.05798",
    "title": "The Dual Form of Neural Networks Revisited: Connecting Test Time  Predictions to Training Patterns via Spotlights of Attention",
    "abstract": " Comments: Two first authors. Accepted to ICML 2022 ",
    "url": "https://arxiv.org/abs/2202.05798",
    "authors": [
      "Kazuki Irie",
      "R\u00f3bert Csord\u00e1s",
      "J\u00fcrgen Schmidhuber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07503",
    "title": "BED: A Real-Time Object Detection System for Edge Devices",
    "abstract": " Title: BED: A Real-Time Object Detection System for Edge Devices ",
    "url": "https://arxiv.org/abs/2202.07503",
    "authors": [
      "Guanchu Wang",
      "Zaid Pervaiz Bhat",
      "Zhimeng Jiang",
      "Yi-Wei Chen",
      "Daochen Zha",
      "Alfredo Costilla Reyes",
      "Afshin Niktash",
      "Gorkem Ulkar",
      "Erman Okman",
      "Xia Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01884",
    "title": "Graph Neural Networks for Multimodal Single-Cell Data Integration",
    "abstract": " Comments: Accepted by KDD 2022 Applied Data Science Track ",
    "url": "https://arxiv.org/abs/2203.01884",
    "authors": [
      "Hongzhi Wen",
      "Jiayuan Ding",
      "Wei Jin",
      "Yiqi Wang",
      "Yuying Xie",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.01912",
    "title": "Bayesian Spillover Graphs for Dynamic Networks",
    "abstract": " Title: Bayesian Spillover Graphs for Dynamic Networks ",
    "url": "https://arxiv.org/abs/2203.01912",
    "authors": [
      "Grace Deng",
      "David S. Matteson"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.04928",
    "title": "DISCO: Comprehensive and Explainable Disinformation Detection",
    "abstract": " Title: DISCO: Comprehensive and Explainable Disinformation Detection ",
    "url": "https://arxiv.org/abs/2203.04928",
    "authors": [
      "Dongqi Fu",
      "Yikun Ban",
      "Hanghang Tong",
      "Ross Maciejewski",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2203.05119",
    "title": "MetAug: Contrastive Learning via Meta Feature Augmentation",
    "abstract": " Comments: Accepted by ICML 2022 ",
    "url": "https://arxiv.org/abs/2203.05119",
    "authors": [
      "Jiangmeng Li",
      "Wenwen Qiang",
      "Changwen Zheng",
      "Bing Su",
      "Hui Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.00147",
    "title": "Semi-Weakly Supervised Object Detection by Sampling Pseudo Ground-Truth  Boxes",
    "abstract": " Comments: Accepted at IJCNN 2022 ",
    "url": "https://arxiv.org/abs/2204.00147",
    "authors": [
      "Akhil Meethal",
      "Marco Pedersoli",
      "Zhongwen Zhu",
      "Francisco Perdigon Romero",
      "Eric Granger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05490",
    "title": "Modelling Evolutionary and Stationary User Preferences for Temporal Sets  Prediction",
    "abstract": " Comments: This paper is still in progress ",
    "url": "https://arxiv.org/abs/2204.05490",
    "authors": [
      "Le Yu",
      "Zihang Liu",
      "Tongyu Zhu",
      "Leilei Sun",
      "Bowen Du",
      "Weifeng Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.06507",
    "title": "Out-of-Distribution Detection with Deep Nearest Neighbors",
    "abstract": " Comments: 15 pages, 4 figures, accepted in ICML 2022 ",
    "url": "https://arxiv.org/abs/2204.06507",
    "authors": [
      "Yiyou Sun",
      "Yifei Ming",
      "Xiaojin Zhu",
      "Yixuan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.07566",
    "title": "Improving Frame-Online Neural Speech Enhancement with Overlapped-Frame  Prediction",
    "abstract": " Comments: in IEEE Signal Processing Letters ",
    "url": "https://arxiv.org/abs/2204.07566",
    "authors": [
      "Zhong-Qiu Wang",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.10495",
    "title": "Adversarial Estimators",
    "abstract": " Title: Adversarial Estimators ",
    "url": "https://arxiv.org/abs/2204.10495",
    "authors": [
      "Jonas Metzger"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.00165",
    "title": "NeuralEF: Deconstructing Kernels by Deep Neural Networks",
    "abstract": " Comments: International Conference on Machine Learning (ICML), 2022 ",
    "url": "https://arxiv.org/abs/2205.00165",
    "authors": [
      "Zhijie Deng",
      "Jiaxin Shi",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.06672",
    "title": "Local Attention Graph-based Transformer for Multi-target Genetic  Alteration Prediction",
    "abstract": " Title: Local Attention Graph-based Transformer for Multi-target Genetic  Alteration Prediction ",
    "url": "https://arxiv.org/abs/2205.06672",
    "authors": [
      "Daniel Reisenb\u00fcchler",
      "Sophia J. Wagner",
      "Melanie Boxberg",
      "Tingying Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11172",
    "title": "How Powerful are Spectral Graph Neural Networks",
    "abstract": " Comments: To be published in ICML2022 ",
    "url": "https://arxiv.org/abs/2205.11172",
    "authors": [
      "Xiyuan Wang",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13344",
    "title": "A neural network based controller for underwater robotic vehicles",
    "abstract": " Comments: References added. This is a slightly updated version of the work presented at the COBEM 2011 - 21st Congress of Mechanical Engineering, 2011, Natal Brazil ",
    "url": "https://arxiv.org/abs/2205.13344",
    "authors": [
      "Josiane Maria Macedo Fernandes",
      "Marcelo Costa Tanaka",
      "Raimundo Carlos Silv\u00e9rio Freire J\u00fanior",
      "Wallace Moreira Bessa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.14120",
    "title": "Neural Basis Models for Interpretability",
    "abstract": " Comments: 17 pages including appendix. v2 includes link to source code available at this https URL v3 includes updates to baseline results ",
    "url": "https://arxiv.org/abs/2205.14120",
    "authors": [
      "Filip Radenovic",
      "Abhimanyu Dubey",
      "Dhruv Mahajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00843",
    "title": "DepthShrinker: A New Compression Paradigm Towards Boosting Real-Hardware  Efficiency of Compact Neural Networks",
    "abstract": " Comments: Accepted at ICML 2022 ",
    "url": "https://arxiv.org/abs/2206.00843",
    "authors": [
      "Yonggan Fu",
      "Haichuan Yang",
      "Jiayi Yuan",
      "Meng Li",
      "Cheng Wan",
      "Raghuraman Krishnamoorthi",
      "Vikas Chandra",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.01266",
    "title": "Exponential Separations in Symmetric Neural Networks",
    "abstract": " Title: Exponential Separations in Symmetric Neural Networks ",
    "url": "https://arxiv.org/abs/2206.01266",
    "authors": [
      "Aaron Zweig",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.05330",
    "title": "The Gender Gap in Scholarly Self-Promotion on Social Media",
    "abstract": " Title: The Gender Gap in Scholarly Self-Promotion on Social Media ",
    "url": "https://arxiv.org/abs/2206.05330",
    "authors": [
      "Hao Peng",
      "Misha Teplitskiy",
      "Daniel M. Romero",
      "Em\u0151ke-\u00c1gnes Horv\u00e1t"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.06829",
    "title": "Efficient Decoder-free Object Detection with Transformers",
    "abstract": " Comments: Update metadata, 10 pages ",
    "url": "https://arxiv.org/abs/2206.06829",
    "authors": [
      "Peixian Chen",
      "Mengdan Zhang",
      "Yunhang Shen",
      "Kekai Sheng",
      "Yuting Gao",
      "Xing Sun",
      "Ke Li",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07311",
    "title": "Can pruning improve certified robustness of neural networks?",
    "abstract": " Title: Can pruning improve certified robustness of neural networks? ",
    "url": "https://arxiv.org/abs/2206.07311",
    "authors": [
      "Zhangheng Li",
      "Tianlong Chen",
      "Linyi Li",
      "Bo Li",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07527",
    "title": "QONNX: Representing Arbitrary-Precision Quantized Neural Networks",
    "abstract": " Comments: 9 pages, 5 figures, Contribution to 4th Workshop on Accelerated Machine Learning (AccML) at HiPEAC 2022 Conference ",
    "url": "https://arxiv.org/abs/2206.07527",
    "authors": [
      "Alessandro Pappalardo",
      "Yaman Umuroglu",
      "Michaela Blott",
      "Jovan Mitrevski",
      "Ben Hawks",
      "Nhan Tran",
      "Vladimir Loncar",
      "Sioni Summers",
      "Hendrik Borras",
      "Jules Muhizi",
      "Matthew Trahms",
      "Shih-Chieh Hsu",
      "Scott Hauck",
      "Javier Duarte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Programming Languages (cs.PL)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.07990",
    "title": "Patch-level Representation Learning for Self-supervised Vision  Transformers",
    "abstract": " Comments: Accepted to CVPR 2022. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2206.07990",
    "authors": [
      "Sukmin Yun",
      "Hankook Lee",
      "Jaehyung Kim",
      "Jinwoo Shin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  }
]