[
  {
    "id": "arXiv:2206.02782",
    "title": "Towards Job-Transition-Tag Graph for a Better Job Title Representation  Learning",
    "abstract": "Works on learning job title representation are mainly based on \\textit{Job-Transition Graph}, built from the working history of talents. However, since these records are usually messy, this graph is very sparse, which affects the quality of the learned representation and hinders further analysis. To address this specific issue, we propose to enrich the graph with additional nodes that improve the quality of job title representation. Specifically, we construct \\textit{Job-Transition-Tag Graph}, a heterogeneous graph containing two types of nodes, i.e., job titles and tags (i.e., words related to job responsibilities or functionalities). Along this line, we reformulate job title representation learning as the task of learning node embedding on the \\textit{Job-Transition-Tag Graph}. Experiments on two datasets show the interest of our approach. ",
    "url": "https://arxiv.org/abs/2206.02782",
    "authors": [
      "Jun Zhu",
      "C\u00e9line Hudelot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.02796",
    "title": "Interpolation-based Correlation Reduction Network for Semi-Supervised  Graph Learning",
    "abstract": "Graph Neural Networks (GNNs) have achieved promising performance in semi-supervised node classification in recent years. However, the problem of insufficient supervision, together with representation collapse, largely limits the performance of the GNNs in this field. To alleviate the collapse of node representations in semi-supervised scenario, we propose a novel graph contrastive learning method, termed Interpolation-based Correlation Reduction Network (ICRN). In our method, we improve the discriminative capability of the latent feature by enlarging the margin of decision boundaries and improving the cross-view consistency of the latent representation. Specifically, we first adopt an interpolation-based strategy to conduct data augmentation in the latent space and then force the prediction model to change linearly between samples. Second, we enable the learned network to tell apart samples across two interpolation-perturbed views through forcing the correlation matrix across views to approximate an identity matrix. By combining the two settings, we extract rich supervision information from both the abundant unlabeled nodes and the rare yet valuable labeled nodes for discriminative representation learning. Extensive experimental results on six datasets demonstrate the effectiveness and the generality of ICRN compared to the existing state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2206.02796",
    "authors": [
      "Xihong Yang",
      "Yue Liu",
      "Sihang Zhou",
      "Xinwang Liu",
      "En Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.02829",
    "title": "RORL: Robust Offline Reinforcement Learning via Conservative Smoothing",
    "abstract": "Offline reinforcement learning (RL) provides a promising direction to exploit the massive amount of offline data for complex decision-making tasks. Due to the distribution shift issue, current offline RL algorithms are generally designed to be conservative for value estimation and action selection. However, such conservatism impairs the robustness of learned policies, leading to a significant change even for a small perturbation on observations. To trade off robustness and conservatism, we propose Robust Offline Reinforcement Learning (RORL) with a novel conservative smoothing technique. In RORL, we explicitly introduce regularization on the policy and the value function for states near the dataset and additional conservative value estimation on these OOD states. Theoretically, we show RORL enjoys a tighter suboptimality bound than recent theoretical results in linear MDPs. We demonstrate that RORL can achieve the state-of-the-art performance on the general offline RL benchmark and is considerably robust to adversarial observation perturbation. ",
    "url": "https://arxiv.org/abs/2206.02829",
    "authors": [
      "Rui Yang",
      "Chenjia Bai",
      "Xiaoteng Ma",
      "Zhaoran Wang",
      "Chongjie Zhang",
      "Lei Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.02834",
    "title": "Collaborative Linear Bandits with Adversarial Agents: Near-Optimal  Regret Bounds",
    "abstract": "We consider a linear stochastic bandit problem involving $M$ agents that can collaborate via a central server to minimize regret. A fraction $\\alpha$ of these agents are adversarial and can act arbitrarily, leading to the following tension: while collaboration can potentially reduce regret, it can also disrupt the process of learning due to adversaries. In this work, we provide a fundamental understanding of this tension by designing new algorithms that balance the exploration-exploitation trade-off via carefully constructed robust confidence intervals. We also complement our algorithms with tight analyses. First, we develop a robust collaborative phased elimination algorithm that achieves $\\tilde{O}\\left(\\alpha+ 1/\\sqrt{M}\\right) \\sqrt{dT}$ regret for each good agent; here, $d$ is the model-dimension and $T$ is the horizon. For small $\\alpha$, our result thus reveals a clear benefit of collaboration despite adversaries. Using an information-theoretic argument, we then prove a matching lower bound, thereby providing the first set of tight, near-optimal regret bounds for collaborative linear bandits with adversaries. Furthermore, by leveraging recent advances in high-dimensional robust statistics, we significantly extend our algorithmic ideas and results to (i) the generalized linear bandit model that allows for non-linear observation maps; and (ii) the contextual bandit setting that allows for time-varying feature vectors. ",
    "url": "https://arxiv.org/abs/2206.02834",
    "authors": [
      "Aritra Mitra",
      "Arman Adibi",
      "George J. Pappas",
      "Hamed Hassani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.02846",
    "title": "A Deeper Dive Into What Deep Spatiotemporal Networks Encode: Quantifying  Static vs. Dynamic Information",
    "abstract": "Deep spatiotemporal models are used in a variety of computer vision tasks, such as action recognition and video object segmentation. Currently, there is a limited understanding of what information is captured by these models in their intermediate representations. For example, while it has been observed that action recognition algorithms are heavily influenced by visual appearance in single static frames, there is no quantitative methodology for evaluating such static bias in the latent representation compared to bias toward dynamic information (e.g. motion). We tackle this challenge by proposing a novel approach for quantifying the static and dynamic biases of any spatiotemporal model. To show the efficacy of our approach, we analyse two widely studied tasks, action recognition and video object segmentation. Our key findings are threefold: (i) Most examined spatiotemporal models are biased toward static information; although, certain two-stream architectures with cross-connections show a better balance between the static and dynamic information captured. (ii) Some datasets that are commonly assumed to be biased toward dynamics are actually biased toward static information. (iii) Individual units (channels) in an architecture can be biased toward static, dynamic or a combination of the two. ",
    "url": "https://arxiv.org/abs/2206.02846",
    "authors": [
      "Matthew Kowal",
      "Mennatullah Siam",
      "Md Amirul Islam",
      "Neil D. B. Bruce",
      "Richard P. Wildes",
      "Konstantinos G. Derpanis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.02849",
    "title": "A Bird's-Eye Tutorial of Graph Attention Architectures",
    "abstract": "Graph Neural Networks (GNNs) have shown tremendous strides in performance for graph-structured problems especially in the domains of natural language processing, computer vision and recommender systems. Inspired by the success of the transformer architecture, there has been an ever-growing body of work on attention variants of GNNs attempting to advance the state of the art in many of these problems. Incorporating \"attention\" into graph mining has been viewed as a way to overcome the noisiness, heterogenity and complexity associated with graph-structured data as well as to encode soft-inductive bias. It is hence crucial and advantageous to study these variants from a bird's-eye view to assess their strengths and weaknesses. We provide a systematic and focused tutorial centered around attention based GNNs in a hope to benefit researchers dealing with graph-structured problems. Our tutorial looks at GNN variants from the point of view of the attention function and iteratively builds the reader's understanding of different graph attention variants. ",
    "url": "https://arxiv.org/abs/2206.02849",
    "authors": [
      "Kaustubh D. Dhole",
      "Carl Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.02856",
    "title": "Physics and semantic informed multi-sensor calibration via optimization  theory and self-supervised learning",
    "abstract": "Achieving safe and reliable autonomous driving relies greatly on the ability to achieve an accurate and robust perception system; however, this cannot be fully realized without precisely calibrated sensors. Environmental and operational conditions as well as improper maintenance can produce calibration errors inhibiting sensor fusion and, consequently, degrading the perception performance. Traditionally, sensor calibration is performed in a controlled environment with one or more known targets. Such a procedure can only be carried out in between drives and requires manual operation; a tedious task if needed to be conducted on a regular basis. This sparked a recent interest in online targetless methods, capable of yielding a set of geometric transformations based on perceived environmental features, however, the required redundancy in sensing modalities makes this task even more challenging, as the features captured by each modality and their distinctiveness may vary. We present a holistic approach to performing joint calibration of a camera-lidar-radar trio. Leveraging prior knowledge and physical properties of these sensing modalities together with semantic information, we propose two targetless calibration methods within a cost minimization framework once via direct online optimization, and second via self-supervised learning (SSL). ",
    "url": "https://arxiv.org/abs/2206.02856",
    "authors": [
      "Shmuel Y. Hayoun",
      "Meir Halachmi",
      "Doron Serebro",
      "Kfir Twizer",
      "Elinor Medezinski",
      "Liron Korkidi",
      "Moshik Cohen",
      "Itai Orr"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.02862",
    "title": "Low Complexity Beam Searching Using Trajectory Information in Mobile  Millimeter-wave Networks",
    "abstract": "Millimeter-wave and terahertz systems rely on beamforming/combining codebooks for finding the best beam directions during the initial access procedure. Existing approaches suffer from large codebook sizes and high beam searching overhead in the presence of mobile devices. To alleviate this problem, we suggest utilizing the similarity of the channel in adjacent locations to divide the UE trajectory into a set of separate regions and maintain a set of candidate paths for each region in a database. In this paper, we show the tradeoff between the number of regions and the signalling overhead, i.e., higher number of regions corresponds to higher signal-to-noise ratio (SNR) but also higher signalling overhead for the database. We then propose an optimization framework to find the minimum number of regions based on the trajectory of a mobile device. Using realistic ray tracing datasets, we demonstrate that the proposed method reduces the beam searching complexity and latency while providing high SNR. ",
    "url": "https://arxiv.org/abs/2206.02862",
    "authors": [
      "Sara Khosravi",
      "Hossein S. Ghadikolaei",
      "Jens Zander",
      "Marina Petrova"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.02876",
    "title": "SpikiLi: A Spiking Simulation of LiDAR based Real-time Object Detection  for Autonomous Driving",
    "abstract": "Spiking Neural Networks are a recent and new neural network design approach that promises tremendous improvements in power efficiency, computation efficiency, and processing latency. They do so by using asynchronous spike-based data flow, event-based signal generation, processing, and modifying the neuron model to resemble biological neurons closely. While some initial works have shown significant initial evidence of applicability to common deep learning tasks, their applications in complex real-world tasks has been relatively low. In this work, we first illustrate the applicability of spiking neural networks to a complex deep learning task namely Lidar based 3D object detection for automated driving. Secondly, we make a step-by-step demonstration of simulating spiking behavior using a pre-trained convolutional neural network. We closely model essential aspects of spiking neural networks in simulation and achieve equivalent run-time and accuracy on a GPU. When the model is realized on a neuromorphic hardware, we expect to have significantly improved power efficiency. ",
    "url": "https://arxiv.org/abs/2206.02876",
    "authors": [
      "Sambit Mohapatra",
      "Thomas Mesquida",
      "Mona Hodaei",
      "Senthil Yogamani",
      "Heinrich Gotzig",
      "Patrick Mader"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.02886",
    "title": "Graph Rationalization with Environment-based Augmentations",
    "abstract": "Rationale is defined as a subset of input features that best explains or supports the prediction by machine learning models. Rationale identification has improved the generalizability and interpretability of neural networks on vision and language data. In graph applications such as molecule and polymer property prediction, identifying representative subgraph structures named as graph rationales plays an essential role in the performance of graph neural networks. Existing graph pooling and/or distribution intervention methods suffer from lack of examples to learn to identify optimal graph rationales. In this work, we introduce a new augmentation operation called environment replacement that automatically creates virtual data examples to improve rationale identification. We propose an efficient framework that performs rationale-environment separation and representation learning on the real and augmented examples in latent spaces to avoid the high complexity of explicit graph decoding and encoding. Comparing against recent techniques, experiments on seven molecular and four polymer real datasets demonstrate the effectiveness and efficiency of the proposed augmentation-based graph rationalization framework. ",
    "url": "https://arxiv.org/abs/2206.02886",
    "authors": [
      "Gang Liu",
      "Tong Zhao",
      "Jiaxin Xu",
      "Tengfei Luo",
      "Meng Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.02887",
    "title": "Sample Complexity of Nonparametric Off-Policy Evaluation on  Low-Dimensional Manifolds using Deep Networks",
    "abstract": "We consider the off-policy evaluation problem of reinforcement learning using deep neural networks. We analyze the deep fitted Q-evaluation method for estimating the expected cumulative reward of a target policy, when the data are generated from an unknown behavior policy. We show that, by choosing network size appropriately, one can leverage the low-dimensional manifold structure in the Markov decision process and obtain a sample-efficient estimator without suffering from the curse of high representation dimensionality. Specifically, we establish a sharp error bound for the fitted Q-evaluation that depends on the intrinsic low dimension, the smoothness of the state-action space, and a function class-restricted $\\chi^2$-divergence. It is noteworthy that the restricted $\\chi^2$-divergence measures the behavior and target policies' {\\it mismatch in the function space}, which can be small even if the two policies are not close to each other in their tabular forms. Numerical experiments are provided to support our theoretical analysis. ",
    "url": "https://arxiv.org/abs/2206.02887",
    "authors": [
      "Xiang Ji",
      "Minshuo Chen",
      "Mengdi Wang",
      "Tuo Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.02915",
    "title": "8-bit Numerical Formats for Deep Neural Networks",
    "abstract": "Given the current trend of increasing size and complexity of machine learning architectures, it has become of critical importance to identify new approaches to improve the computational efficiency of model training. In this context, we address the advantages of floating-point over fixed-point representation, and present an in-depth study on the use of 8-bit floating-point number formats for activations, weights, and gradients for both training and inference. We explore the effect of different bit-widths for exponents and significands and different exponent biases. The experimental results demonstrate that a suitable choice of these low-precision formats enables faster training and reduced power consumption without any degradation in accuracy for a range of deep learning models for image classification and language processing. ",
    "url": "https://arxiv.org/abs/2206.02915",
    "authors": [
      "Badreddine Noune",
      "Philip Jones",
      "Daniel Justus",
      "Dominic Masters",
      "Carlo Luschi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.02916",
    "title": "Remember the Past: Distilling Datasets into Addressable Memories for  Neural Networks",
    "abstract": "We propose an algorithm that compresses the critical information of a large dataset into compact addressable memories. These memories can then be recalled to quickly re-train a neural network and recover the performance (instead of storing and re-training on the full original dataset). Building upon the dataset distillation framework, we make a key observation that a shared common representation allows for more efficient and effective distillation. Concretely, we learn a set of bases (aka \"memories\") which are shared between classes and combined through learned flexible addressing functions to generate a diverse set of training examples. This leads to several benefits: 1) the size of compressed data does not necessarily grow linearly with the number of classes; 2) an overall higher compression rate with more effective distillation is achieved; and 3) more generalized queries are allowed beyond recalling the original classes. We demonstrate state-of-the-art results on the dataset distillation task across five benchmarks, including up to 16.5% and 9.7% in retained accuracy improvement when distilling CIFAR10 and CIFAR100 respectively. We then leverage our framework to perform continual learning, achieving state-of-the-art results on four benchmarks, with 23.2% accuracy improvement on MANY. ",
    "url": "https://arxiv.org/abs/2206.02916",
    "authors": [
      "Zhiwei Deng",
      "Olga Russakovsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.02921",
    "title": "Schema-Guided Event Graph Completion",
    "abstract": "We tackle a new task, event graph completion, which aims to predict missing event nodes for event graphs. Existing link prediction or graph completion methods have difficulty dealing with event graphs because they are usually designed for a single large graph such as a social network or a knowledge graph, rather than multiple small dynamic event graphs. Moreover, they can only predict missing edges rather than missing nodes. In this work, we propose to utilize event schema, a template that describes the stereotypical structure of event graphs, to address the above issues. Our schema-guided event graph completion approach first maps an instance event graph to a subgraph of the schema graph by a heuristic subgraph matching algorithm. Then it predicts whether a candidate event node in the schema graph should be added to the instantiated schema subgraph by characterizing two types of local topology of the schema graph: neighbors of the candidate node and the subgraph, and paths that connect the candidate node and the subgraph. These two modules are later combined together for the final prediction. We also propose a self-supervised strategy to construct training samples, as well as an inference algorithm that is specifically designed to complete event graphs. Extensive experimental results on four datasets demonstrate that our proposed method achieves state-of-the-art performance, with 4.3% to 19.4% absolute F1 gains over the best baseline method on the four datasets. ",
    "url": "https://arxiv.org/abs/2206.02921",
    "authors": [
      "Hongwei Wang",
      "Zixuan Zhang",
      "Sha Li",
      "Jiawei Han",
      "Yizhou Sun",
      "Hanghang Tong",
      "Joseph P. Olive",
      "Heng Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.02928",
    "title": "Neuro-Symbolic Causal Language Planning with Commonsense Prompting",
    "abstract": "Language planning aims to implement complex high-level goals by decomposition into sequential simpler low-level steps. Such procedural reasoning ability is essential for applications such as household robots and virtual assistants. Although language planning is a basic skill set for humans in daily life, it remains a challenge for large language models (LLMs) that lack deep-level commonsense knowledge in the real world. Previous methods require either manual exemplars or annotated programs to acquire such ability from LLMs. In contrast, this paper proposes Neuro-Symbolic Causal Language Planner (CLAP) that elicits procedural knowledge from the LLMs with commonsense-infused prompting. Pre-trained knowledge in LLMs is essentially an unobserved confounder that causes spurious correlations between tasks and action plans. Through the lens of a Structural Causal Model (SCM), we propose an effective strategy in CLAP to construct prompts as a causal intervention toward our SCM. Using graph sampling techniques and symbolic program executors, our strategy formalizes the structured causal prompts from commonsense knowledge bases. CLAP obtains state-of-the-art performance on WikiHow and RobotHow, achieving a relative improvement of 5.28% in human evaluations under the counterfactual setting. This indicates the superiority of CLAP in causal language planning semantically and sequentially. ",
    "url": "https://arxiv.org/abs/2206.02928",
    "authors": [
      "Yujie Lu",
      "Weixi Feng",
      "Wanrong Zhu",
      "Wenda Xu",
      "Xin Eric Wang",
      "Miguel Eckstein",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.02950",
    "title": "A Continuum Approach for Collaborative Task Processing in UAV MEC  Networks",
    "abstract": "Unmanned aerial vehicles (UAVs) are becoming a viable platform for sensing and estimation in a wide variety of applications including disaster response, search and rescue, and security monitoring. These sensing UAVs have limited battery and computational capabilities, and thus must offload their data so it can be processed to provide actionable intelligence. We consider a compute platform consisting of a limited number of highly-resourced UAVs that act as mobile edge computing (MEC) servers to process the workload on premises. We propose a novel distributed solution to the collaborative processing problem that adaptively positions the MEC UAVs in response to the changing workload that arises both from the sensing UAVs' mobility and the task generation. Our solution consists of two key building blocks: (1) an efficient workload estimation process by which the UAVs estimate the task field - a continuous approximation of the number of tasks to be processed at each location in the airspace, and (2) a distributed optimization method by which the UAVs partition the task field so as to maximize the system throughput. We evaluate our proposed solution using realistic models of surveillance UAV mobility and show that our method achieves up to 28% improvement in throughput over a non-adaptive baseline approach. ",
    "url": "https://arxiv.org/abs/2206.02950",
    "authors": [
      "Lorson Blair",
      "Carlos A. Varela",
      "Stacy Patterson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2206.02956",
    "title": "Robust Time Series Dissimilarity Measure for Outlier Detection and  Periodicity Detection",
    "abstract": "Dynamic time warping (DTW) is an effective dissimilarity measure in many time series applications. Despite its popularity, it is prone to noises and outliers, which leads to singularity problem and bias in the measurement. The time complexity of DTW is quadratic to the length of time series, making it inapplicable in real-time applications. In this paper, we propose a novel time series dissimilarity measure named RobustDTW to reduce the effects of noises and outliers. Specifically, the RobustDTW estimates the trend and optimizes the time warp in an alternating manner by utilizing our designed temporal graph trend filtering. To improve efficiency, we propose a multi-level framework that estimates the trend and the warp function at a lower resolution, and then repeatedly refines them at a higher resolution. Based on the proposed RobustDTW, we further extend it to periodicity detection and outlier time series detection. Experiments on real-world datasets demonstrate the superior performance of RobustDTW compared to DTW variants in both outlier time series detection and periodicity detection. ",
    "url": "https://arxiv.org/abs/2206.02956",
    "authors": [
      "Xiaomin Song",
      "Qingsong Wen",
      "Yan Li",
      "Liang Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2206.02957",
    "title": "GRETEL: A unified framework for Graph Counterfactual Explanation  Evaluation",
    "abstract": "Machine Learning (ML) systems are a building part of the modern tools which impact our daily life in several application domains. Due to their black-box nature, those systems are hardly adopted in application domains (e.g. health, finance) where understanding the decision process is of paramount importance. Explanation methods were developed to explain how the ML model has taken a specific decision for a given case/instance. Graph Counterfactual Explanations (GCE) is one of the explanation techniques adopted in the Graph Learning domain. The existing works of Graph Counterfactual Explanations diverge mostly in the problem definition, application domain, test data, and evaluation metrics, and most existing works do not compare exhaustively against other counterfactual explanation techniques present in the literature. We present GRETEL, a unified framework to develop and test GCE methods in several settings. GRETEL is a highly extensible evaluation framework which promotes the Open Science and the evaluations reproducibility by providing a set of well-defined mechanisms to integrate and manage easily: both real and synthetic datasets, ML models, state-of-the-art explanation techniques, and evaluation measures. To present GRETEL, we show the experiments conducted to integrate and test several synthetic and real datasets with several existing explanation techniques and base ML models. ",
    "url": "https://arxiv.org/abs/2206.02957",
    "authors": [
      "Mario Alfonso Prado-Romero",
      "Giovanni Stilo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.02963",
    "title": "Improving Knowledge Graph Embedding via Iterative Self-Semantic  Knowledge Distillation",
    "abstract": "Knowledge graph embedding (KGE) has been intensively investigated for link prediction by projecting entities and relations into continuous vector spaces. Current popular high-dimensional KGE methods obtain quite slight performance gains while require enormous computation and memory costs. In contrast to high-dimensional KGE models, training low-dimensional models is more efficient and worthwhile for better deployments to practical intelligent systems. However, the model expressiveness of semantic information in knowledge graphs (KGs) is highly limited in the low dimension parameter space. In this paper, we propose iterative self-semantic knowledge distillation strategy to improve the KGE model expressiveness in the low dimension space. KGE model combined with our proposed strategy plays the teacher and student roles alternatively during the whole training process. Specifically, at a certain iteration, the model is regarded as a teacher to provide semantic information for the student. At next iteration, the model is regard as a student to incorporate the semantic information transferred from the teacher. We also design a novel semantic extraction block to extract iteration-based semantic information for the training model self-distillation. Iteratively incorporating and accumulating iteration-based semantic information enables the low-dimensional model to be more expressive for better link prediction in KGs. There is only one model during the whole training, which alleviates the increase of computational expensiveness and memory requirements. Furthermore, the proposed strategy is model-agnostic and can be seamlessly combined with other KGE models. Consistent and significant performance gains in experimental evaluations on four standard datasets demonstrate the effectiveness of the proposed self-distillation strategy. ",
    "url": "https://arxiv.org/abs/2206.02963",
    "authors": [
      "Zhehui Zhou",
      "Defang Chen",
      "Can Wang",
      "Yan Feng",
      "Chun Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.02971",
    "title": "Human Trafficking in Mexico: Data sources, Network Analysis and the  Limits of Dismantling Strategies",
    "abstract": "Human trafficking is a heartless crime that represents the second most profitable crime in the world. Mexico's geographical position makes it a country with high levels of human trafficking. Using the snowball sampling method, the major contribution of this paper is the abstraction of the human trafficking network on the southern border of Mexico. Based on a social network analysis, it is identified that the criminal network is moderately centralized (44.32%) and with medium density (0.401). Therefore, the network has minimal cohesiveness and members may find it difficult to share information, money, or products among themselves. To evaluate different dismantling strategies to tackle the criminal organization, three algorithms are evaluated. We found that the first actors to be removed are neither the most connected nor the most peripheral, but the actors who are moderately connected to people of their kind should be removed. In summary, this paper provides a significant step forward to understand quantitatively human trafficking networks and evaluate the limits of dismantling strategies. ",
    "url": "https://arxiv.org/abs/2206.02971",
    "authors": [
      "Sof\u00eda de la Mora Tostado",
      "Mayra N\u00fa\u00f1ez-L\u00f3pez",
      "Esteban A. Hern\u00e1ndez-Vargas"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2206.02976",
    "title": "Recall Distortion in Neural Network Pruning and the Undecayed Pruning  Algorithm",
    "abstract": "Pruning techniques have been successfully used in neural networks to trade accuracy for sparsity. However, the impact of network pruning is not uniform: prior work has shown that the recall for underrepresented classes in a dataset may be more negatively affected. In this work, we study such relative distortions in recall by hypothesizing an intensification effect that is inherent to the model. Namely, that pruning makes recall relatively worse for a class with recall below accuracy and, conversely, that it makes recall relatively better for a class with recall above accuracy. In addition, we propose a new pruning algorithm aimed at attenuating such effect. Through statistical analysis, we have observed that intensification is less severe with our algorithm but nevertheless more pronounced with relatively more difficult tasks, less complex models, and higher pruning ratios. More surprisingly, we conversely observe a de-intensification effect with lower pruning ratios. ",
    "url": "https://arxiv.org/abs/2206.02976",
    "authors": [
      "Aidan Good",
      "Jiaqi Lin",
      "Hannah Sieg",
      "Mikey Ferguson",
      "Xin Yu",
      "Shandian Zhe",
      "Jerzy Wieczorek",
      "Thiago Serra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.02977",
    "title": "DETR++: Taming Your Multi-Scale Detection Transformer",
    "abstract": "Convolutional Neural Networks (CNN) have dominated the field of detection ever since the success of AlexNet in ImageNet classification [12]. With the sweeping reform of Transformers [27] in natural language processing, Carion et al. [2] introduce the Transformer-based detection method, i.e., DETR. However, due to the quadratic complexity in the self-attention mechanism in the Transformer, DETR is never able to incorporate multi-scale features as performed in existing CNN-based detectors, leading to inferior results in small object detection. To mitigate this issue and further improve performance of DETR, in this work, we investigate different methods to incorporate multi-scale features and find that a Bi-directional Feature Pyramid (BiFPN) works best with DETR in further raising the detection precision. With this discovery, we propose DETR++, a new architecture that improves detection results by 1.9% AP on MS COCO 2017, 11.5% AP on RICO icon detection, and 9.1% AP on RICO layout extraction over existing baselines. ",
    "url": "https://arxiv.org/abs/2206.02977",
    "authors": [
      "Chi Zhang",
      "Lijuan Liu",
      "Xiaoxue Zang",
      "Frederick Liu",
      "Hao Zhang",
      "Xinying Song",
      "Jindong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.02982",
    "title": "DynaMaR: Dynamic Prompt with Mask Token Representation",
    "abstract": "Recent research has shown that large language models pretrained using unsupervised approaches can achieve significant performance improvement on many downstream tasks. Typically when adapting these language models to downstream tasks, like a classification or regression task, we employ a fine-tuning paradigm in which the sentence representation from the language model is input to a task-specific head; the model is then fine-tuned end-to-end. However, with the emergence of models like GPT-3, prompt-based fine-tuning has been proven to be a successful approach for few-shot tasks. Inspired by this work, we study discrete prompt technologies in practice. There are two issues that arise with the standard prompt approach. First, it can overfit on the prompt template. Second, it requires manual effort to formulate the downstream task as a language model problem. In this paper, we propose an improvement to prompt-based fine-tuning that addresses these two issues. We refer to our approach as DynaMaR -- Dynamic Prompt with Mask Token Representation. Results show that DynaMaR can achieve an average improvement of 10% in few-shot settings and improvement of 3.7% in data-rich settings over the standard fine-tuning approach on four e-commerce applications. ",
    "url": "https://arxiv.org/abs/2206.02982",
    "authors": [
      "Xiaodi Sun",
      "Sunny Rajagopalan",
      "Priyanka Nigam",
      "Weiyi Lu",
      "Yi Xu",
      "Belinda Zeng",
      "Trishul Chilimbi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.02985",
    "title": "Structured Context Transformer for Generic Event Boundary Detection",
    "abstract": "Generic Event Boundary Detection (GEBD) aims to detect moments where humans naturally perceive as event boundaries. In this paper, we present Structured Context Transformer (or SC-Transformer) to solve the GEBD task, which can be trained in an end-to-end fashion. Specifically, we use the backbone convolutional neural network (CNN) to extract the features of each video frame. To capture temporal context information of each frame, we design the structure context transformer (SC-Transformer) by re-partitioning input frame sequence. Note that, the overall computation complexity of SC-Transformer is linear to the video length. After that, the group similarities are computed to capture the differences between frames. Then, a lightweight fully convolutional network is used to determine the event boundaries based on the grouped similarity maps. To remedy the ambiguities of boundary annotations, the Gaussian kernel is adopted to preprocess the ground-truth event boundaries to further boost the accuracy. Extensive experiments conducted on the challenging Kinetics-GEBD and TAPOS datasets demonstrate the effectiveness of the proposed method compared to the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2206.02985",
    "authors": [
      "Congcong Li",
      "Xinyao Wang",
      "Dexiang Hong",
      "Yufei Wang",
      "Libo Zhang",
      "Tiejian Luo",
      "Longyin Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.02993",
    "title": "False Consensus, Information Theory, and Prediction Markets",
    "abstract": "Our main result shows that when agents' private information about an event are independent conditioning on the event's outcome, then, after an initial announcement, whenever agents have similar beliefs about the outcome, their information is aggregated. That is, there is no false consensus. Our main result has a short proof based on a natural information theoretic framework. A key ingredient of the framework is the equivalence between the sign of the ``interaction information'' and a super/sub-additive property of the value of people's information. This provides an intuitive interpretation and an interesting application of the interaction information, which measures the amount of information shared by three random variables. We illustrate the power of this information theoretic framework by reproving two additional results within it: 1) that agents quickly agree when while announcing beliefs in round robin fashion [Aaronson 2005]; and 2) results from [Chen et al 2010] on when prediction market agents should release information to maximize their payment. We also interpret the information theoretic framework and the above results in prediction markets by proving that the expected reward of revealing information is the conditional mutual information of the information revealed. ",
    "url": "https://arxiv.org/abs/2206.02993",
    "authors": [
      "Yuqing Kong",
      "Grant Schoenebeck"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ]
  },
  {
    "id": "arXiv:2206.02997",
    "title": "TadML: A fast temporal action detection with Mechanics-MLP",
    "abstract": "Temporal Action Detection(TAD) is a crucial but challenging task in video understanding.It is aimed at detecting both the type and start-end frame for each action instance in a long, untrimmed video.Most current models adopt both RGB and Optical-Flow streams for the TAD task. Thus, original RGB frames must be converted manually into Optical-Flow frames with additional computation and time cost, which is an obstacle to achieve real-time processing. At present, many models adopt two-stage strategies, which would slow the inference speed down and complicatedly tuning on proposals generating.By comparison, we propose a one-stage anchor-free temporal localization method with RGB stream only, in which a novel Newtonian \\emph{Mechanics-MLP} architecture is established. It has comparable accuracy with all existing state-of-the-art models, while surpasses the inference speed of these methods by a large margin. The typical inference speed in this paper is astounding 4.44 video per second on THUMOS14. In applications, because there is no need to convert optical flow, the inference speed will be faster.It also proves that \\emph{MLP} has great potential in downstream tasks such as TAD. The source code is available at \\url{https://github.com/BonedDeng/TadML} ",
    "url": "https://arxiv.org/abs/2206.02997",
    "authors": [
      "Bowen Deng",
      "Dongchang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03008",
    "title": "Histogram Estimation under User-level Privacy with Heterogeneous Data",
    "abstract": "We study the problem of histogram estimation under user-level differential privacy, where the goal is to preserve the privacy of all entries of any single user. While there is abundant literature on this classical problem under the item-level privacy setup where each user contributes only one data point, little has been known for the user-level counterpart. We consider the heterogeneous scenario where both the quantity and distribution of data can be different for each user. We propose an algorithm based on a clipping strategy that almost achieves a two-approximation with respect to the best clipping threshold in hindsight. This result holds without any distribution assumptions on the data. We also prove that the clipping bias can be significantly reduced when the counts are from non-i.i.d. Poisson distributions and show empirically that our debiasing method provides improvements even without such constraints. Experiments on both real and synthetic datasets verify our theoretical findings and demonstrate the effectiveness of our algorithms. ",
    "url": "https://arxiv.org/abs/2206.03008",
    "authors": [
      "Yuhan Liu",
      "Ananda Theertha Suresh",
      "Wennan Zhu",
      "Peter Kairouz",
      "Marco Gruteser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.03012",
    "title": "TriBYOL: Triplet BYOL for Self-Supervised Representation Learning",
    "abstract": "This paper proposes a novel self-supervised learning method for learning better representations with small batch sizes. Many self-supervised learning methods based on certain forms of the siamese network have emerged and received significant attention. However, these methods need to use large batch sizes to learn good representations and require heavy computational resources. We present a new triplet network combined with a triple-view loss to improve the performance of self-supervised representation learning with small batch sizes. Experimental results show that our method can drastically outperform state-of-the-art self-supervised learning methods on several datasets in small-batch cases. Our method provides a feasible solution for self-supervised learning with real-world high-resolution images that uses small batch sizes. ",
    "url": "https://arxiv.org/abs/2206.03012",
    "authors": [
      "Guang Li",
      "Ren Togo",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.03014",
    "title": "The Devil is in the Labels: Noisy Label Correction for Robust Scene  Graph Generation",
    "abstract": "Unbiased SGG has achieved significant progress over recent years. However, almost all existing SGG models have overlooked the ground-truth annotation qualities of prevailing SGG datasets, i.e., they always assume: 1) all the manually annotated positive samples are equally correct; 2) all the un-annotated negative samples are absolutely background. In this paper, we argue that both assumptions are inapplicable to SGG: there are numerous \"noisy\" groundtruth predicate labels that break these two assumptions, and these noisy samples actually harm the training of unbiased SGG models. To this end, we propose a novel model-agnostic NoIsy label CorrEction strategy for SGG: NICE. NICE can not only detect noisy samples but also reassign more high-quality predicate labels to them. After the NICE training, we can obtain a cleaner version of SGG dataset for model training. Specifically, NICE consists of three components: negative Noisy Sample Detection (Neg-NSD), positive NSD (Pos-NSD), and Noisy Sample Correction (NSC). Firstly, in Neg-NSD, we formulate this task as an out-of-distribution detection problem, and assign pseudo labels to all detected noisy negative samples. Then, in Pos-NSD, we use a clustering-based algorithm to divide all positive samples into multiple sets, and treat the samples in the noisiest set as noisy positive samples. Lastly, in NSC, we use a simple but effective weighted KNN to reassign new predicate labels to noisy positive samples. Extensive results on different backbones and tasks have attested to the effectiveness and generalization abilities of each component of NICE. ",
    "url": "https://arxiv.org/abs/2206.03014",
    "authors": [
      "Lin Li",
      "Long Chen",
      "Yifeng Huang",
      "Zhimeng Zhang",
      "Songyang Zhang",
      "Jun Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03017",
    "title": "Development of Automatic Endotracheal Tube and Carina Detection on  Portable Supine Chest Radiographs using Artificial Intelligence",
    "abstract": "The image quality of portable supine chest radiographs is inherently poor due to low contrast and high noise. The endotracheal intubation detection requires the locations of the endotracheal tube (ETT) tip and carina. The goal is to find the distance between the ETT tip and the carina in chest radiography. To overcome such a problem, we propose a feature extraction method with Mask R-CNN. The Mask R-CNN predicts a tube and a tracheal bifurcation in an image. Then, the feature extraction method is used to find the feature point of the ETT tip and that of the carina. Therefore, the ETT-carina distance can be obtained. In our experiments, our results can exceed 96\\% in terms of recall and precision. Moreover, the object error is less than $4.7751\\pm 5.3420$ mm, and the ETT-carina distance errors are less than $5.5432\\pm 6.3100$ mm. The external validation shows that the proposed method is a high-robustness system. According to the Pearson correlation coefficient, we have a strong correlation between the board-certified intensivists and our result in terms of ETT-carina distance. ",
    "url": "https://arxiv.org/abs/2206.03017",
    "authors": [
      "Chi-Yeh Chen",
      "Min-Hsin Huang",
      "Yung-Nien Sun",
      "Chao-Han Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.03020",
    "title": "Adaptive Weighted Nonnegative Matrix Factorization for Robust Feature  Representation",
    "abstract": "Nonnegative matrix factorization (NMF) has been widely used to dimensionality reduction in machine learning. However, the traditional NMF does not properly handle outliers, so that it is sensitive to noise. In order to improve the robustness of NMF, this paper proposes an adaptive weighted NMF, which introduces weights to emphasize the different importance of each data point, thus the algorithmic sensitivity to noisy data is decreased. It is very different from the existing robust NMFs that use a slow growth similarity measure. Specifically, two strategies are proposed to achieve this: fuzzier weighted technique and entropy weighted regularized technique, and both of them lead to an iterative solution with a simple form. Experimental results showed that new methods have more robust feature representation on several real datasets with noise than exsiting methods. ",
    "url": "https://arxiv.org/abs/2206.03020",
    "authors": [
      "Tingting Shen",
      "Junhang Li",
      "Can Tong",
      "Qiang He",
      "Chen Li",
      "Yudong Yao",
      "Yueyang Teng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03025",
    "title": "OCHADAI at SemEval-2022 Task 2: Adversarial Training for Multilingual  Idiomaticity Detection",
    "abstract": "We propose a multilingual adversarial training model for determining whether a sentence contains an idiomatic expression. Given that a key challenge with this task is the limited size of annotated data, our model relies on pre-trained contextual representations from different multi-lingual state-of-the-art transformer-based language models (i.e., multilingual BERT and XLM-RoBERTa), and on adversarial training, a training method for further enhancing model generalization and robustness. Without relying on any human-crafted features, knowledge bases, or additional datasets other than the target datasets, our model achieved competitive results and ranked 6th place in SubTask A (zero-shot) setting and 15th place in SubTask A (one-shot) setting. ",
    "url": "https://arxiv.org/abs/2206.03025",
    "authors": [
      "Lis Kanashiro Pereira",
      "Ichiro Kobayashi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.03044",
    "title": "CAISAR: A platform for Characterizing Artificial Intelligence Safety and  Robustness",
    "abstract": "We present CAISAR, an open-source platform under active development for the characterization of AI systems' robustness and safety. CAISAR provides a unified entry point for defining verification problems by using WhyML, the mature and expressive language of the Why3 verification platform. Moreover, CAISAR orchestrates and composes state-of-the-art machine learning verification tools which, individually, are not able to efficiently handle all problems but, collectively, can cover a growing number of properties. Our aim is to assist, on the one hand, the V\\&V process by reducing the burden of choosing the methodology tailored to a given verification problem, and on the other hand the tools developers by factorizing useful features-visualization, report generation, property description-in one platform. CAISAR will soon be available at https://git.frama-c.com/pub/caisar. ",
    "url": "https://arxiv.org/abs/2206.03044",
    "authors": [
      "Michele Alberti",
      "Fran\u00e7ois Bobot",
      "Zakaria Chihani",
      "Julien Girard-Satabin",
      "Augustin Lemesle"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2206.03047",
    "title": "Fibonacci-like sequences for variants of the tower of Hanoi, and  corresponding graphs and gray codes",
    "abstract": "We modify the rules of the classical Tower of Hanoi puzzle in a quite natural way to get the Fibonacci sequence involved in the optimal algorithm of resolution, and show some nice properties of such a variant. In particular, we deduce from this Tower of Hanoi-Fibonacci a Gray-like code on the set of binary words without the factor 11, which has some properties intersting for itself and from which an iterative algorithm for the Tower of Hanoi-Fibonacci is obtained. Such an algorithm involves the Fibonacci substitution. Eventually, we briefly extend the study to some natural generalizations. ",
    "url": "https://arxiv.org/abs/2206.03047",
    "authors": [
      "Beno\u00eet Rittaud"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Number Theory (math.NT)"
    ]
  },
  {
    "id": "arXiv:2206.03061",
    "title": "Spatial Parsing and Dynamic Temporal Pooling networks for Human-Object  Interaction detection",
    "abstract": "The key of Human-Object Interaction(HOI) recognition is to infer the relationship between human and objects. Recently, the image's Human-Object Interaction(HOI) detection has made significant progress. However, there is still room for improvement in video HOI detection performance. Existing one-stage methods use well-designed end-to-end networks to detect a video segment and directly predict an interaction. It makes the model learning and further optimization of the network more complex. This paper introduces the Spatial Parsing and Dynamic Temporal Pooling (SPDTP) network, which takes the entire video as a spatio-temporal graph with human and object nodes as input. Unlike existing methods, our proposed network predicts the difference between interactive and non-interactive pairs through explicit spatial parsing, and then performs interaction recognition. Moreover, we propose a learnable and differentiable Dynamic Temporal Module(DTM) to emphasize the keyframes of the video and suppress the redundant frame. Furthermore, the experimental results show that SPDTP can pay more attention to active human-object pairs and valid keyframes. Overall, we achieve state-of-the-art performance on CAD-120 dataset and Something-Else dataset. ",
    "url": "https://arxiv.org/abs/2206.03061",
    "authors": [
      "Hongsheng Li",
      "Guangming Zhu",
      "Wu Zhen",
      "Lan Ni",
      "Peiyi Shen",
      "Liang Zhang",
      "Ning Wang",
      "Cong Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03084",
    "title": "Content Privacy Enforcement Models in Decentralized Online Social  Networks: State of Play, Solutions, Limitations, and Future Directions",
    "abstract": "In recent years, Decentralized Online Social Networks (DOSNs) have been attracting the attention of many users because they reduce the risk of censorship, surveillance, and information leakage from the service provider. In contrast to the most popular Online Social Networks, which are based on centralized architectures (e.g., Facebook, Twitter, or Instagram), DOSNs are not based on a single service provider acting as a central authority. Indeed, the contents that are published on DOSNs are stored on the devices made available by their users, which cooperate to execute the tasks needed to provide the service. To continuously guarantee their availability, the contents published by a user could be stored on the devices of other users, simply because they are online when required. Consequently, such contents must be properly protected by the DOSN infrastructure, in order to ensure that they can be really accessed only by users who have the permission of the publishers. As a consequence, DOSNs require efficient solutions for protecting the privacy of the contents published by each user with respect to the other users of the social network. In this paper, we investigate and compare the principal content privacy enforcement models adopted by current DOSNs evaluating their suitability to support different types of privacy policies based on user groups. Such evaluation is carried out by implementing several models and comparing their performance for the typical operations performed on groups, i.e., content publish, user join and leave. Further, we also highlight the limitations of current approaches and show future research directions. This contribution, other than being interesting on its own, provides a blueprint for researchers and practitioners interested in implementing DOSNs, and also highlights a few open research directions. ",
    "url": "https://arxiv.org/abs/2206.03084",
    "authors": [
      "Andrea De Salve",
      "Paolo Mori",
      "Laura Ricci",
      "Roberto Di Pietro"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.03085",
    "title": "A Route Network Planning Method for Urban Air Delivery",
    "abstract": "High-tech giants and start-ups are investing in drone technologies to provide urban air delivery service, which is expected to solve the last-mile problem and mitigate road traffic congestion. However, air delivery service will not scale up without proper traffic management for drones in dense urban environment. Currently, a range of Concepts of Operations (ConOps) for unmanned aircraft system traffic management (UTM) are being proposed and evaluated by researchers, operators, and regulators. Among these, the tube-based (or corridor-based) ConOps has emerged in operations in some regions of the world for drone deliveries and is expected to continue serving certain scenarios that with dense and complex airspace and requires centralized control in the future. Towards the tube-based ConOps, we develop a route network planning method to design routes (tubes) in a complex urban environment in this paper. In this method, we propose a priority structure to decouple the network planning problem, which is NP-hard, into single-path planning problems. We also introduce a novel space cost function to enable the design of dense and aligned routes in a network. The proposed method is tested on various scenarios and compared with other state-of-the-art methods. Results show that our method can generate near-optimal route networks with significant computational time-savings. ",
    "url": "https://arxiv.org/abs/2206.03085",
    "authors": [
      "Xinyu He",
      "Fang He",
      "Lishuai Li",
      "Lei Zhang",
      "Gang Xiao"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2206.03087",
    "title": "Critical Regularizations for Neural Surface Reconstruction in the Wild",
    "abstract": "Neural implicit functions have recently shown promising results on surface reconstructions from multiple views. However, current methods still suffer from excessive time complexity and poor robustness when reconstructing unbounded or complex scenes. In this paper, we present RegSDF, which shows that proper point cloud supervisions and geometry regularizations are sufficient to produce high-quality and robust reconstruction results. Specifically, RegSDF takes an additional oriented point cloud as input, and optimizes a signed distance field and a surface light field within a differentiable rendering framework. We also introduce the two critical regularizations for this optimization. The first one is the Hessian regularization that smoothly diffuses the signed distance values to the entire distance field given noisy and incomplete input. And the second one is the minimal surface regularization that compactly interpolates and extrapolates the missing geometry. Extensive experiments are conducted on DTU, BlendedMVS, and Tanks and Temples datasets. Compared with recent neural surface reconstruction approaches, RegSDF is able to reconstruct surfaces with fine details even for open scenes with complex topologies and unstructured camera trajectories. ",
    "url": "https://arxiv.org/abs/2206.03087",
    "authors": [
      "Jingyang Zhang",
      "Yao Yao",
      "Shiwei Li",
      "Tian Fang",
      "David McKinnon",
      "Yanghai Tsin",
      "Long Quan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03105",
    "title": "Dual Swin-Transformer based Mutual Interactive Network for RGB-D Salient  Object Detection",
    "abstract": "Salient Object Detection is the task of predicting the human attended region in a given scene. Fusing depth information has been proven effective in this task. The main challenge of this problem is how to aggregate the complementary information from RGB modality and depth modality. However, conventional deep models heavily rely on CNN feature extractors, and the long-range contextual dependencies are usually ignored. In this work, we propose Dual Swin-Transformer based Mutual Interactive Network. We adopt Swin-Transformer as the feature extractor for both RGB and depth modality to model the long-range dependencies in visual inputs. Before fusing the two branches of features into one, attention-based modules are applied to enhance features from each modality. We design a self-attention-based cross-modality interaction module and a gated modality attention module to leverage the complementary information between the two modalities. For the saliency decoding, we create different stages enhanced with dense connections and keep a decoding memory while the multi-level encoding features are considered simultaneously. Considering the inaccurate depth map issue, we collect the RGB features of early stages into a skip convolution module to give more guidance from RGB modality to the final saliency prediction. In addition, we add edge supervision to regularize the feature learning process. Comprehensive experiments on five standard RGB-D SOD benchmark datasets over four evaluation metrics demonstrate the superiority of the proposed DTMINet method. ",
    "url": "https://arxiv.org/abs/2206.03105",
    "authors": [
      "Chao Zeng",
      "Sam Kwong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03111",
    "title": "MIRNF: Medical Image Registration via Neural Fields",
    "abstract": "Image registration is widely used in medical image analysis to provide spatial correspondences between two images. Recently learning-based methods utilizing convolutional neural networks (CNNs) have been proposed for solving image registration problems. The learning-based methods tend to be much faster than traditional optimization-based methods, but the accuracy improvements gained from the complex CNN-based methods are modest. Here we introduce a new deep-neural net-based image registration framework, named \\textbf{MIRNF}, which represents the correspondence mapping with a continuous function implemented via Neural Fields. MIRNF outputs either a deformation vector or velocity vector given a 3D coordinate as input. To ensure the mapping is diffeomorphic, the velocity vector output from MIRNF is integrated using the Neural ODE solver to derive the correspondences between two images. Furthermore, we propose a hybrid coordinate sampler along with a cascaded architecture to achieve the high-similarity mapping performance and low-distortion deformation fields. We conduct experiments on two 3D MR brain scan datasets, showing that our proposed framework provides state-of-art registration performance while maintaining comparable optimization time. ",
    "url": "https://arxiv.org/abs/2206.03111",
    "authors": [
      "Shanlin Sun",
      "Kun Han",
      "Deying Kong",
      "Chenyu You",
      "Xiaohui Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03113",
    "title": "Wavelet Prior Attention Learning in Axial Inpainting Network",
    "abstract": "Image inpainting is the task of filling masked or unknown regions of an image with visually realistic contents, which has been remarkably improved by Deep Neural Networks (DNNs) recently. Essentially, as an inverse problem, the inpainting has the underlying challenges of reconstructing semantically coherent results without texture artifacts. Many previous efforts have been made via exploiting attention mechanisms and prior knowledge, such as edges and semantic segmentation. However, these works are still limited in practice by an avalanche of learnable prior parameters and prohibitive computational burden. To this end, we propose a novel model -- Wavelet prior attention learning in Axial Inpainting Network (WAIN), whose generator contains the encoder, decoder, as well as two key components of Wavelet image Prior Attention (WPA) and stacked multi-layer Axial-Transformers (ATs). Particularly, the WPA guides the high-level feature aggregation in the multi-scale frequency domain, alleviating the textual artifacts. Stacked ATs employ unmasked clues to help model reasonable features along with low-level features of horizontal and vertical axes, improving the semantic coherence. Extensive quantitative and qualitative experiments on Celeba-HQ and Places2 datasets are conducted to validate that our WAIN can achieve state-of-the-art performance over the competitors. The codes and models will be released. ",
    "url": "https://arxiv.org/abs/2206.03113",
    "authors": [
      "Chenjie Cao",
      "Chengrong Wang",
      "Yuntao Zhang",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03127",
    "title": "Data-driven evolutionary algorithm for oil reservoir well-placement and  control optimization",
    "abstract": "Optimal well placement and well injection-production are crucial for the reservoir development to maximize the financial profits during the project lifetime. Meta-heuristic algorithms have showed good performance in solving complex, nonlinear and non-continuous optimization problems. However, a large number of numerical simulation runs are involved during the optimization process. In this work, a novel and efficient data-driven evolutionary algorithm, called generalized data-driven differential evolutionary algorithm (GDDE), is proposed to reduce the number of simulation runs on well-placement and control optimization problems. Probabilistic neural network (PNN) is adopted as the classifier to select informative and promising candidates, and the most uncertain candidate based on Euclidean distance is prescreened and evaluated with a numerical simulator. Subsequently, local surrogate model is built by radial basis function (RBF) and the optimum of the surrogate, found by optimizer, is evaluated by the numerical simulator to accelerate the convergence. It is worth noting that the shape factors of RBF model and PNN are optimized via solving hyper-parameter sub-expensive optimization problem. The results show the optimization algorithm proposed in this study is very promising for a well-placement optimization problem of two-dimensional reservoir and joint optimization of Egg model. ",
    "url": "https://arxiv.org/abs/2206.03127",
    "authors": [
      "Guodong Chen",
      "Xin Luo",
      "Jimmy Jiu Jiao",
      "Xiaoming Xue"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.03128",
    "title": "Spatial-Temporal Adaptive Graph Convolution with Attention Network for  Traffic Forecasting",
    "abstract": "Traffic forecasting is one canonical example of spatial-temporal learning task in Intelligent Traffic System. Existing approaches capture spatial dependency with a pre-determined matrix in graph convolution neural operators. However, the explicit graph structure losses some hidden representations of relationships among nodes. Furthermore, traditional graph convolution neural operators cannot aggregate long-range nodes on the graph. To overcome these limits, we propose a novel network, Spatial-Temporal Adaptive graph convolution with Attention Network (STAAN) for traffic forecasting. Firstly, we adopt an adaptive dependency matrix instead of using a pre-defined matrix during GCN processing to infer the inter-dependencies among nodes. Secondly, we integrate PW-attention based on graph attention network which is designed for global dependency, and GCN as spatial block. What's more, a stacked dilated 1D convolution, with efficiency in long-term prediction, is adopted in our temporal block for capturing the different time series. We evaluate our STAAN on two real-world datasets, and experiments validate that our model outperforms state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2206.03128",
    "authors": [
      "Chen Weikang",
      "Li Yawen",
      "Xue Zhe",
      "Li Ang",
      "Wu Guobin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2206.03151",
    "title": "Shuffled Check-in: Privacy Amplification towards Practical Distributed  Learning",
    "abstract": "Recent studies of distributed computation with formal privacy guarantees, such as differentially private (DP) federated learning, leverage random sampling of clients in each round (privacy amplification by subsampling) to achieve satisfactory levels of privacy. Achieving this however requires strong assumptions which may not hold in practice, including precise and uniform subsampling of clients, and a highly trusted aggregator to process clients' data. In this paper, we explore a more practical protocol, shuffled check-in, to resolve the aforementioned issues. The protocol relies on client making independent and random decision to participate in the computation, freeing the requirement of server-initiated subsampling, and enabling robust modelling of client dropouts. Moreover, a weaker trust model known as the shuffle model is employed instead of using a trusted aggregator. To this end, we introduce new tools to characterize the R\\'enyi differential privacy (RDP) of shuffled check-in. We show that our new techniques improve at least three times in privacy guarantee over those using approximate DP's strong composition at various parameter regimes. Furthermore, we provide a numerical approach to track the privacy of generic shuffled check-in mechanism including distributed stochastic gradient descent (SGD) with Gaussian mechanism. To the best of our knowledge, this is also the first evaluation of Gaussian mechanism within the local/shuffle model under the distributed setting in the literature, which can be of independent interest. ",
    "url": "https://arxiv.org/abs/2206.03151",
    "authors": [
      "Seng Pei Liew",
      "Satoshi Hasegawa",
      "Tsubasa Takahashi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.03159",
    "title": "The Structure of Interdisciplinary Science: Uncovering and Explaining  Roles in Citation Graphs",
    "abstract": "Role discovery is the task of dividing the set of nodes on a graph into classes of structurally similar roles. Modern strategies for role discovery typically rely on graph embedding techniques, which are capable of recognising complex local structures. However, when working with large, real-world networks, it is difficult to interpret or validate a set of roles identified according to these methods. In this work, motivated by advancements in the field of explainable artificial intelligence (XAI), we propose a new framework for interpreting role assignments on large graphs using small subgraph structures known as graphlets. We demonstrate our methods on a large, multidisciplinary citation network, where we successfully identify a number of important citation patterns which reflect interdisciplinary research ",
    "url": "https://arxiv.org/abs/2206.03159",
    "authors": [
      "Eoghan Cunningham",
      "Derek Greene"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.03171",
    "title": "Look Back When Surprised: Stabilizing Reverse Experience Replay for  Neural Approximation",
    "abstract": "Experience replay methods, which are an essential part of reinforcement learning(RL) algorithms, are designed to mitigate spurious correlations and biases while learning from temporally dependent data. Roughly speaking, these methods allow us to draw batched data from a large buffer such that these temporal correlations do not hinder the performance of descent algorithms. In this experimental work, we consider the recently developed and theoretically rigorous reverse experience replay (RER), which has been shown to remove such spurious biases in simplified theoretical settings. We combine RER with optimistic experience replay (OER) to obtain RER++, which is stable under neural function approximation. We show via experiments that this has a better performance than techniques like prioritized experience replay (PER) on various tasks, with a significantly smaller computational complexity. It is well known in the RL literature that choosing examples greedily with the largest TD error (as in OER) or forming mini-batches with consecutive data points (as in RER) leads to poor performance. However, our method, which combines these techniques, works very well. ",
    "url": "https://arxiv.org/abs/2206.03171",
    "authors": [
      "Ramnath Kumar",
      "Dheeraj Nagaraj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03179",
    "title": "TSFEDL: A Python Library for Time Series Spatio-Temporal Feature  Extraction and Prediction using Deep Learning (with Appendices on Detailed  Network Architectures and Experimental Cases of Study)",
    "abstract": "The combination of convolutional and recurrent neural networks is a promising framework that allows the extraction of high-quality spatio-temporal features together with its temporal dependencies, which is key for time series prediction problems such as forecasting, classification or anomaly detection, amongst others. In this paper, the TSFEDL library is introduced. It compiles 20 state-of-the-art methods for both time series feature extraction and prediction, employing convolutional and recurrent deep neural networks for its use in several data mining tasks. The library is built upon a set of Tensorflow+Keras and PyTorch modules under the AGPLv3 license. The performance validation of the architectures included in this proposal confirms the usefulness of this Python package. ",
    "url": "https://arxiv.org/abs/2206.03179",
    "authors": [
      "Ignacio Aguilera-Martos",
      "\u00c1ngel M. Garc\u00eda-Vico",
      "Juli\u00e1n Luengo",
      "Sergio Damas",
      "Francisco J. Melero",
      "Jos\u00e9 Javier Valle-Alonso",
      "Francisco Herrera"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.03181",
    "title": "Detecting Global Community Structure in a COVID-19 Activity Correlation  Network",
    "abstract": "The global pandemic of COVID-19 over the last 2.5 years have produced an enormous amount of epidemic/public health datasets, which may also be useful for studying the underlying structure of our globally connected world. Here we used the Johns Hopkins University COVID-19 dataset to construct a correlation network of countries/regions and studied its global community structure. Specifically, we selected countries/regions that had at least 100,000 cumulative positive cases from the dataset and generated a 7-day moving average time series of new positive cases reported for each country/region. We then calculated a time series of daily change exponents by taking the day-to-day difference in log of the number of new positive cases. We constructed a correlation network by connecting countries/regions that had positive correlations in their daily change exponent time series using their Pearson correlation coefficient as the edge weight. Applying the modularity maximization method revealed that there were three major communities: (1) Mainly Europe + North America + Southeast Asia that showed similar six-peak patterns during the pandemic, (2) mainly Near/Middle East + Central/South Asia + Central/South America that loosely followed Community 1 but had a notable increase of activities because of the Delta variant and was later impacted significantly by the Omicron variant, and (3) mainly Africa + Central/East Canada + Australia that did not have much activities until a huge spike was caused by the Omicron variant. These three communities were robustly detected under varied settings. Constructing a 3D \"phase space\" by using the median curves in those three communities for x-y-z coordinates generated an effective summary trajectory of how the global pandemic progressed. ",
    "url": "https://arxiv.org/abs/2206.03181",
    "authors": [
      "Hiroki Sayama"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2206.03190",
    "title": "TRAVEL: Traversable Ground and Above-Ground Object Segmentation Using  Graph Representation of 3D LiDAR Scans",
    "abstract": "Perception of traversable regions and objects of interest from a 3D point cloud is one of the critical tasks in autonomous navigation. A ground vehicle needs to look for traversable terrains that are explorable by wheels. Then, to make safe navigation decisions, the segmentation of objects positioned on those terrains has to be followed up. However, over-segmentation and under-segmentation can negatively influence such navigation decisions. To that end, we propose TRAVEL, which performs traversable ground detection and object clustering simultaneously using the graph representation of a 3D point cloud. To segment the traversable ground, a point cloud is encoded into a graph structure, tri-grid field, which treats each tri-grid as a node. Then, the traversable regions are searched and redefined by examining local convexity and concavity of edges that connect nodes. On the other hand, our above-ground object segmentation employs a graph structure by representing a group of horizontally neighboring 3D points in a spherical-projection space as a node and vertical/horizontal relationship between nodes as an edge. Fully leveraging the node-edge structure, the above-ground segmentation ensures real-time operation and mitigates over-segmentation. Through experiments using simulations, urban scenes, and our own datasets, we have demonstrated that our proposed traversable ground segmentation algorithm outperforms other state-of-the-art methods in terms of the conventional metrics and that our newly proposed evaluation metrics are meaningful for assessing the above-ground segmentation. We will make the code and our own dataset available to public at https://github.com/url-kaist/TRAVEL. ",
    "url": "https://arxiv.org/abs/2206.03190",
    "authors": [
      "Minho Oh",
      "Euigon Jung",
      "Hyungtae Lim",
      "Wonho Song",
      "Sumin Hu",
      "Eungchang Mason Lee",
      "Junghee Park",
      "Jaekyung Kim",
      "Jangwoo Lee",
      "Hyun Myung"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.03200",
    "title": "FairVFL: A Fair Vertical Federated Learning Framework with Contrastive  Adversarial Learning",
    "abstract": "Vertical federated learning (VFL) is a privacy-preserving machine learning paradigm that can learn models from features distributed on different platforms in a privacy-preserving way. Since in real-world applications the data may contain bias on fairness-sensitive features (e.g., gender), VFL models may inherit bias from training data and become unfair for some user groups. However, existing fair ML methods usually rely on the centralized storage of fairness-sensitive features to achieve model fairness, which are usually inapplicable in federated scenarios. In this paper, we propose a fair vertical federated learning framework (FairVFL), which can improve the fairness of VFL models. The core idea of FairVFL is to learn unified and fair representations of samples based on the decentralized feature fields in a privacy-preserving way. Specifically, each platform with fairness-insensitive features first learns local data representations from local features. Then, these local representations are uploaded to a server and aggregated into a unified representation for the target task. In order to learn fair unified representations, we send them to each platform storing fairness-sensitive features and apply adversarial learning to remove bias from the unified representations inherited from the biased data. Moreover, for protecting user privacy, we further propose a contrastive adversarial learning method to remove privacy information from the unified representations in server before sending them to the platforms keeping fairness-sensitive features. Experiments on two real-world datasets validate that our method can effectively improve model fairness with user privacy well-protected. ",
    "url": "https://arxiv.org/abs/2206.03200",
    "authors": [
      "Tao Qi",
      "Fangzhao Wu",
      "Chuhan Wu",
      "Lingjuan Lyu",
      "Tong Xu",
      "Zhongliang Yang",
      "Yongfeng Huang",
      "Xing Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03210",
    "title": "Deep Neural Patchworks: Coping with Large Segmentation Tasks",
    "abstract": "Convolutional neural networks are the way to solve arbitrary image segmentation tasks. However, when images are large, memory demands often exceed the available resources, in particular on a common GPU. Especially in biomedical imaging, where 3D images are common, the problems are apparent. A typical approach to solve this limitation is to break the task into smaller subtasks by dividing images into smaller image patches. Another approach, if applicable, is to look at the 2D image sections separately, and to solve the problem in 2D. Often, the loss of global context makes such approaches less effective; important global information might not be present in the current image patch, or the selected 2D image section. Here, we propose Deep Neural Patchworks (DNP), a segmentation framework that is based on hierarchical and nested stacking of patch-based networks that solves the dilemma between global context and memory limitations. ",
    "url": "https://arxiv.org/abs/2206.03210",
    "authors": [
      "Marco Reisert",
      "Maximilian Russe",
      "Samer Elsheikh",
      "Elias Kellner",
      "Henrik Skibbe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03211",
    "title": "Variational Meta Reinforcement Learning for Social Robotics",
    "abstract": "With the increasing presence of robots in our every-day environments, improving their social skills is of utmost importance. Nonetheless, social robotics still faces many challenges. One bottleneck is that robotic behaviors need to be often adapted as social norms depend strongly on the environment. For example, a robot should navigate more carefully around patients in a hospital compared to workers in an office. In this work, we investigate meta-reinforcement learning (meta-RL) as a potential solution. Here, robot behaviors are learned via reinforcement learning where a reward function needs to be chosen so that the robot learns an appropriate behavior for a given environment. We propose to use a variational meta-RL procedure that quickly adapts the robots' behavior to new reward functions. As a result, given a new environment different reward functions can be quickly evaluated and an appropriate one selected. The procedure learns a vectorized representation for reward functions and a meta-policy that can be conditioned on such a representation. Given observations from a new reward function, the procedure identifies its representation and conditions the meta-policy to it. While investigating the procedures' capabilities, we realized that it suffers from posterior collapse where only a subset of the dimensions in the representation encode useful information resulting in a reduced performance. Our second contribution, a radial basis function (RBF) layer, partially mitigates this negative effect. The RBF layer lifts the representation to a higher dimensional space, which is more easily exploitable for the meta-policy. We demonstrate the interest of the RBF layer and the usage of meta-RL for social robotics on four robotic simulation tasks. ",
    "url": "https://arxiv.org/abs/2206.03211",
    "authors": [
      "Anand Ballou",
      "Chris Reinke",
      "Xavier Alameda-Pineda"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.03222",
    "title": "Improved Cardiac Arrhythmia Prediction Based on Heart Rate Variability  Analysis",
    "abstract": "Many types of ventricular and atrial cardiac arrhythmias have been discovered in clinical practice in the past 100 years, and these arrhythmias are a major contributor to sudden cardiac death. Ventricular tachycardia, ventricular fibrillation, and paroxysmal atrial fibrillation are the most commonly-occurring and dangerous arrhythmias, therefore early detection is crucial to prevent any further complications and reduce fatalities. Implantable devices such as pacemakers are commonly used in patients at high risk of sudden cardiac death. While great advances have been made in medical technology, there remain significant challenges in effective management of common arrhythmias. This thesis proposes novel arrhythmia detection and prediction methods to differentiate cardiac arrhythmias from non-life-threatening cardiac events, to increase the likelihood of detecting events that may lead to mortality, as well as reduce the incidence of unnecessary therapeutic intervention. The methods are based on detailed analysis of Heart Rate Variability (HRV) information. The results of the work show good performance of the proposed methods and support the potential for their deployment in resource-constrained devices for ventricular and atrial arrhythmia prediction, such as implantable pacemakers and defibrillators. ",
    "url": "https://arxiv.org/abs/2206.03222",
    "authors": [
      "Ashkan Parsi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.03239",
    "title": "Analyzing the impact of feature selection on the accuracy of heart  disease prediction",
    "abstract": "Heart Disease has become one of the most serious diseases that has a significant impact on human life. It has emerged as one of the leading causes of mortality among the people across the globe during the last decade. In order to prevent patients from further damage, an accurate diagnosis of heart disease on time is an essential factor. Recently we have seen the usage of non-invasive medical procedures, such as artificial intelligence-based techniques in the field of medical. Specially machine learning employs several algorithms and techniques that are widely used and are highly useful in accurately diagnosing the heart disease with less amount of time. However, the prediction of heart disease is not an easy task. The increasing size of medical datasets has made it a complicated task for practitioners to understand the complex feature relations and make disease predictions. Accordingly, the aim of this research is to identify the most important risk-factors from a highly dimensional dataset which helps in the accurate classification of heart disease with less complications. For a broader analysis, we have used two heart disease datasets with various medical features. The classification results of the benchmarked models proved that there is a high impact of relevant features on the classification accuracy. Even with a reduced number of features, the performance of the classification models improved significantly with a reduced training time as compared with models trained on full feature set. ",
    "url": "https://arxiv.org/abs/2206.03239",
    "authors": [
      "Muhammad Salman Pathan",
      "Avishek Nag",
      "Muhammad Mohisn Pathan",
      "Soumyabrata Dev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.03265",
    "title": "Marvolo: Programmatic Data Augmentation for Practical ML-Driven Malware  Detection",
    "abstract": "Data augmentation has been rare in the cyber security domain due to technical difficulties in altering data in a manner that is semantically consistent with the original data. This shortfall is particularly onerous given the unique difficulty of acquiring benign and malicious training data that runs into copyright restrictions, and that institutions like banks and governments receive targeted malware that will never exist in large quantities. We present MARVOLO, a binary mutator that programmatically grows malware (and benign) datasets in a manner that boosts the accuracy of ML-driven malware detectors. MARVOLO employs semantics-preserving code transformations that mimic the alterations that malware authors and defensive benign developers routinely make in practice , allowing us to generate meaningful augmented data. Crucially, semantics-preserving transformations also enable MARVOLO to safely propagate labels from original to newly-generated data samples without mandating expensive reverse engineering of binaries. Further, MARVOLO embeds several key optimizations that keep costs low for practitioners by maximizing the density of diverse data samples generated within a given time (or resource) budget. Experiments using wide-ranging commercial malware datasets and a recent ML-driven malware detector show that MARVOLO boosts accuracies by up to 5%, while operating on only a small fraction (15%) of the potential input binaries. ",
    "url": "https://arxiv.org/abs/2206.03265",
    "authors": [
      "Michael D. Wong",
      "Edward Raff",
      "James Holt",
      "Ravi Netravali"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03274",
    "title": "Minimizing Energy Consumption for End-to-End Slicing in 5G Wireless  Networks and Beyond",
    "abstract": "End-to-End (E2E) network slicing enables wireless networks to provide diverse services on a common infrastructure. Each E2E slice, including resources of radio access network (RAN) and core network, is rented to mobile virtual network operators (MVNOs) to provide a specific service to end-users. RAN slicing, which is realized through wireless network virtualization, involves sharing the frequency spectrum and base station antennas in RAN. Similarly, in core slicing, which is achieved by network function virtualization, data center resources such as commodity servers and physical links are shared between users of different MVNOs. In this paper, we study E2E slicing with the aim of minimizing the total energy consumption. The stated optimization problem is non-convex that is solved by a sub-optimal algorithm proposed here. The simulation results show that our proposed joint power control, server and link allocation (JPSLA) algorithm achieves 30% improvement compared to the disjoint scheme, where RAN and core are sliced separately. ",
    "url": "https://arxiv.org/abs/2206.03274",
    "authors": [
      "Shiva Kazemi Taskou",
      "Mehdi Rasti",
      "Pedro H. J. Nardelli"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2206.03281",
    "title": "Unsupervised Context Aware Sentence Representation Pretraining for  Multi-lingual Dense Retrieval",
    "abstract": "Recent research demonstrates the effectiveness of using pretrained language models (PLM) to improve dense retrieval and multilingual dense retrieval. In this work, we present a simple but effective monolingual pretraining task called contrastive context prediction~(CCP) to learn sentence representation by modeling sentence level contextual relation. By pushing the embedding of sentences in a local context closer and pushing random negative samples away, different languages could form isomorphic structure, then sentence pairs in two different languages will be automatically aligned. Our experiments show that model collapse and information leakage are very easy to happen during contrastive training of language model, but language-specific memory bank and asymmetric batch normalization operation play an essential role in preventing collapsing and information leakage, respectively. Besides, a post-processing for sentence embedding is also very effective to achieve better retrieval performance. On the multilingual sentence retrieval task Tatoeba, our model achieves new SOTA results among methods without using bilingual data. Our model also shows larger gain on Tatoeba when transferring between non-English pairs. On two multi-lingual query-passage retrieval tasks, XOR Retrieve and Mr.TYDI, our model even achieves two SOTA results in both zero-shot and supervised setting among all pretraining models using bilingual data. ",
    "url": "https://arxiv.org/abs/2206.03281",
    "authors": [
      "Ning Wu",
      "Yaobo Liang",
      "Houxing Ren",
      "Linjun Shou",
      "Nan Duan",
      "Ming Gong",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.03287",
    "title": "NeMF: Neural Motion Fields for Kinematic Animation",
    "abstract": "We present an implicit neural representation to learn the spatio-temporal space of kinematic motions. Unlike previous work that represents motion as discrete sequential samples, we propose to express the vast motion space as a continuous function over time, hence the name Neural Motion Fields (NeMF). Specifically, we use a neural network to learn this function for miscellaneous sets of motions, which is designed to be a generative model conditioned on a temporal coordinate $t$ and a random vector $z$ for controlling the style. The model is then trained as a Variational Autoencoder (VAE) with motion encoders to sample the latent space. We train our model with diverse human motion dataset and quadruped dataset to prove its versatility, and finally deploy it as a generic motion prior to solve task-agnostic problems and show its superiority in different motion generation and editing applications, such as motion interpolation, in-betweening, and re-navigating. ",
    "url": "https://arxiv.org/abs/2206.03287",
    "authors": [
      "Chengan He",
      "Jun Saito",
      "James Zachary",
      "Holly Rushmeier",
      "Yi Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2206.03291",
    "title": "GAAF: Searching Activation Functions for Binary Neural Networks through  Genetic Algorithm",
    "abstract": "Binary neural networks (BNNs) show promising utilization in cost and power-restricted domains such as edge devices and mobile systems. This is due to its significantly less computation and storage demand, but at the cost of degraded performance. To close the accuracy gap, in this paper we propose to add a complementary activation function (AF) ahead of the sign based binarization, and rely on the genetic algorithm (GA) to automatically search for the ideal AFs. These AFs can help extract extra information from the input data in the forward pass, while allowing improved gradient approximation in the backward pass. Fifteen novel AFs are identified through our GA-based search, while most of them show improved performance (up to 2.54% on ImageNet) when testing on different datasets and network models. Our method offers a novel approach for designing general and application-specific BNN architecture. Our code is available at this http URL ",
    "url": "https://arxiv.org/abs/2206.03291",
    "authors": [
      "Yanfei Li",
      "Tong Geng",
      "Samuel Stein",
      "Ang Li",
      "Huimin Yu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03299",
    "title": "Generalization Error Bounds for Deep Neural Networks Trained by SGD",
    "abstract": "Generalization error bounds for deep neural networks trained by stochastic gradient descent (SGD) are derived by combining a dynamical control of an appropriate parameter norm and the Rademacher complexity estimate based on parameter norms. The bounds explicitly depend on the loss along the training trajectory, and work for a wide range of network architectures including multilayer perceptron (MLP) and convolutional neural networks (CNN). Compared with other algorithm-depending generalization estimates such as uniform stability-based bounds, our bounds do not require $L$-smoothness of the nonconvex loss function, and apply directly to SGD instead of Stochastic Langevin gradient descent (SGLD). Numerical results show that our bounds are non-vacuous and robust with the change of optimizer and network hyperparameters. ",
    "url": "https://arxiv.org/abs/2206.03299",
    "authors": [
      "Mingze Wang",
      "Chao Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.03304",
    "title": "On the balance between the training time and interpretability of neural  ODE for time series modelling",
    "abstract": "Most machine learning methods are used as a black box for modelling. We may try to extract some knowledge from physics-based training methods, such as neural ODE (ordinary differential equation). Neural ODE has advantages like a possibly higher class of represented functions, the extended interpretability compared to black-box machine learning models, ability to describe both trend and local behaviour. Such advantages are especially critical for time series with complicated trends. However, the known drawback is the high training time compared to the autoregressive models and long-short term memory (LSTM) networks widely used for data-driven time series modelling. Therefore, we should be able to balance interpretability and training time to apply neural ODE in practice. The paper shows that modern neural ODE cannot be reduced to simpler models for time-series modelling applications. The complexity of neural ODE is compared to or exceeds the conventional time-series modelling tools. The only interpretation that could be extracted is the eigenspace of the operator, which is an ill-posed problem for a large system. Spectra could be extracted using different classical analysis methods that do not have the drawback of extended time. Consequently, we reduce the neural ODE to a simpler linear form and propose a new view on time-series modelling using combined neural networks and an ODE system approach. ",
    "url": "https://arxiv.org/abs/2206.03304",
    "authors": [
      "Yakov Golovanev",
      "Alexander Hvatov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Classical Analysis and ODEs (math.CA)"
    ]
  },
  {
    "id": "arXiv:2206.03315",
    "title": "Neural Network Decoders for Permutation Codes Correcting Different  Errors",
    "abstract": "Permutation codes were extensively studied in order to correct different types of errors for the applications on power line communication and rank modulation for flash memory. In this paper, we introduce the neural network decoders for permutation codes to correct these errors with one-shot decoding, which treat the decoding as $n$ classification tasks for non-binary symbols for a code of length $n$. These are actually the first general decoders introduced to deal with any error type for these two applications. The performance of the decoders is evaluated by simulations with different error models. ",
    "url": "https://arxiv.org/abs/2206.03315",
    "authors": [
      "Yeow Meng Chee",
      "Hui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03317",
    "title": "Subject Membership Inference Attacks in Federated Learning",
    "abstract": "Privacy in Federated Learning (FL) is studied at two different granularities: item-level, which protects individual data points, and user-level, which protects each user (participant) in the federation. Nearly all of the private FL literature is dedicated to studying privacy attacks and defenses at these two granularities. Recently, subject-level privacy has emerged as an alternative privacy granularity to protect the privacy of individuals (data subjects) whose data is spread across multiple (organizational) users in cross-silo FL settings. An adversary might be interested in recovering private information about these individuals (a.k.a. \\emph{data subjects}) by attacking the trained model. A systematic study of these patterns requires complete control over the federation, which is impossible with real-world datasets. We design a simulator for generating various synthetic federation configurations, enabling us to study how properties of the data, model design and training, and the federation itself impact subject privacy risk. We propose three attacks for \\emph{subject membership inference} and examine the interplay between all factors within a federation that affect the attacks' efficacy. We also investigate the effectiveness of Differential Privacy in mitigating this threat. Our takeaways generalize to real-world datasets like FEMNIST, giving credence to our findings. ",
    "url": "https://arxiv.org/abs/2206.03317",
    "authors": [
      "Anshuman Suri",
      "Pallika Kanani",
      "Virendra J. Marathe",
      "Daniel W. Peterson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.03321",
    "title": "Early Abnormal Detection of Sewage Pipe Network: Bagging of Various  Abnormal Detection Algorithms",
    "abstract": "Abnormalities of the sewage pipe network will affect the normal operation of the whole city. Therefore, it is important to detect the abnormalities early. This paper propose an early abnormal-detection method. The abnormalities are detected by using the conventional algorithms, such as isolation forest algorithm, two innovations are given: (1) The current and historical data measured by the sensors placed in the sewage pipe network (such as ultrasonic Doppler flowmeter) are taken as the overall dataset, and then the general dataset is detected by using the conventional anomaly detection method to diagnose the anomaly of the data. The anomaly refers to the sample different from the others samples in the whole dataset. Because the definition of anomaly is not through the algorithm, but the whole dataset, the construction of the whole dataset is the key to propose the early abnormal-detection algorithms. (2) A bagging strategy for a variety of conventional anomaly detection algorithms is proposed to achieve the early detection of anomalies with the high precision and recall. The results show that this method can achieve the early anomaly detection with the highest precision of 98.21%, the recall rate 63.58% and F1-score of 0.774. ",
    "url": "https://arxiv.org/abs/2206.03321",
    "authors": [
      "Zhen-Yu Zhang",
      "Guo-Xiang Shao",
      "Chun-Ming Qiu",
      "Yue-Jie Hou",
      "En-Ming Zhao",
      "Chi-Chun Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03325",
    "title": "Searching Similarity Measure for Binarized Neural Networks",
    "abstract": "Being a promising model to be deployed in resource-limited devices, Binarized Neural Networks (BNNs) have drawn extensive attention from both academic and industry. However, comparing to the full-precision deep neural networks (DNNs), BNNs suffer from non-trivial accuracy degradation, limiting its applicability in various domains. This is partially because existing network components, such as the similarity measure, are specially designed for DNNs, and might be sub-optimal for BNNs. In this work, we focus on the key component of BNNs -- the similarity measure, which quantifies the distance between input feature maps and filters, and propose an automatic searching method, based on genetic algorithm, for BNN-tailored similarity measure. Evaluation results on Cifar10 and Cifar100 using ResNet, NIN and VGG show that most of the identified similarty measure can achieve considerable accuracy improvement (up to 3.39%) over the commonly-used cross-correlation approach. ",
    "url": "https://arxiv.org/abs/2206.03325",
    "authors": [
      "Yanfei Li",
      "Ang Li",
      "Huimin Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03331",
    "title": "Improving the Diagnosis of Psychiatric Disorders with Self-Supervised  Graph State Space Models",
    "abstract": "Single subject prediction of brain disorders from neuroimaging data has gained increasing attention in recent years. Yet, for some heterogeneous disorders such as major depression disorder (MDD) and autism spectrum disorder (ASD), the performance of prediction models on large-scale multi-site datasets remains poor. We present a two-stage framework to improve the diagnosis of heterogeneous psychiatric disorders from resting-state functional magnetic resonance imaging (rs-fMRI). First, we propose a self-supervised mask prediction task on data from healthy individuals that can exploit differences between healthy controls and patients in clinical datasets. Next, we train a supervised classifier on the learned discriminative representations. To model rs-fMRI data, we develop Graph-S4; an extension to the recently proposed state-space model S4 to graph settings where the underlying graph structure is not known in advance. We show that combining the framework and Graph-S4 can significantly improve the diagnostic performance of neuroimaging-based single subject prediction models of MDD and ASD on three open-source multi-center rs-fMRI clinical datasets. ",
    "url": "https://arxiv.org/abs/2206.03331",
    "authors": [
      "Ahmed El Gazzar",
      "Rajat Mani Thomas",
      "Guido Van Wingen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03334",
    "title": "Correlations of network trajectories",
    "abstract": "Temporal networks model how the interaction between elements in a complex system evolve over time. Just like complex systems display collective dynamics, here we interpret temporal networks as trajectories performing a collective motion in graph space, following a latent graph dynamical system. Under this paradigm, we propose a way to measure how the network pulsates and collectively fluctuates over time and space. To this aim, we extend the notion of linear correlations function to the case of sequences of network snapshots, i.e. a network trajectory. We construct stochastic and deterministic graph dynamical systems and show that the emergent collective correlations are well captured by simple measures, and illustrate how these patterns are revealed in empirical networks arising in different domains. ",
    "url": "https://arxiv.org/abs/2206.03334",
    "authors": [
      "Lucas Lacasa",
      "Jorge P. Rodriguez",
      "Victor M. Eguiluz"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2206.03348",
    "title": "Specification-Guided Learning of Nash Equilibria with High Social  Welfare",
    "abstract": "Reinforcement learning has been shown to be an effective strategy for automatically training policies for challenging control problems. Focusing on non-cooperative multi-agent systems, we propose a novel reinforcement learning framework for training joint policies that form a Nash equilibrium. In our approach, rather than providing low-level reward functions, the user provides high-level specifications that encode the objective of each agent. Then, guided by the structure of the specifications, our algorithm searches over policies to identify one that provably forms an $\\epsilon$-Nash equilibrium (with high probability). Importantly, it prioritizes policies in a way that maximizes social welfare across all agents. Our empirical evaluation demonstrates that our algorithm computes equilibrium policies with high social welfare, whereas state-of-the-art baselines either fail to compute Nash equilibria or compute ones with comparatively lower social welfare. ",
    "url": "https://arxiv.org/abs/2206.03348",
    "authors": [
      "Kishor Jothimurugan",
      "Suguman Bansal",
      "Osbert Bastani",
      "Rajeev Alur"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03351",
    "title": "AS2T: Arbitrary Source-To-Target Adversarial Attack on Speaker  Recognition Systems",
    "abstract": "Recent work has illuminated the vulnerability of speaker recognition systems (SRSs) against adversarial attacks, raising significant security concerns in deploying SRSs. However, they considered only a few settings (e.g., some combinations of source and target speakers), leaving many interesting and important settings in real-world attack scenarios alone. In this work, we present AS2T, the first attack in this domain which covers all the settings, thus allows the adversary to craft adversarial voices using arbitrary source and target speakers for any of three main recognition tasks. Since none of the existing loss functions can be applied to all the settings, we explore many candidate loss functions for each setting including the existing and newly designed ones. We thoroughly evaluate their efficacy and find that some existing loss functions are suboptimal. Then, to improve the robustness of AS2T towards practical over-the-air attack, we study the possible distortions occurred in over-the-air transmission, utilize different transformation functions with different parameters to model those distortions, and incorporate them into the generation of adversarial voices. Our simulated over-the-air evaluation validates the effectiveness of our solution in producing robust adversarial voices which remain effective under various hardware devices and various acoustic environments with different reverberation, ambient noises, and noise levels. Finally, we leverage AS2T to perform thus far the largest-scale evaluation to understand transferability among 14 diverse SRSs. The transferability analysis provides many interesting and useful insights which challenge several findings and conclusion drawn in previous works in the image domain. Our study also sheds light on future directions of adversarial attacks in the speaker recognition domain. ",
    "url": "https://arxiv.org/abs/2206.03351",
    "authors": [
      "Guangke Chen",
      "Zhe Zhao",
      "Fu Song",
      "Sen Chen",
      "Lingling Fan",
      "Yang Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.03360",
    "title": "Towards Explainable Social Agent Authoring tools: A case study on  FAtiMA-Toolkit",
    "abstract": "The deployment of Socially Intelligent Agents (SIAs) in learning environments has proven to have several advantages in different areas of application. Social Agent Authoring Tools allow scenario designers to create tailored experiences with high control over SIAs behaviour, however, on the flip side, this comes at a cost as the complexity of the scenarios and its authoring can become overbearing. In this paper we introduce the concept of Explainable Social Agent Authoring Tools with the goal of analysing if authoring tools for social agents are understandable and interpretable. To this end we examine whether an authoring tool, FAtiMA-Toolkit, is understandable and its authoring steps interpretable, from the point-of-view of the author. We conducted two user studies to quantitatively assess the Interpretability, Comprehensibility and Transparency of FAtiMA-Toolkit from the perspective of a scenario designer. One of the key findings is the fact that FAtiMA-Toolkit's conceptual model is, in general, understandable, however the emotional-based concepts were not as easily understood and used by the authors. Although there are some positive aspects regarding the explainability of FAtiMA-Toolkit, there is still progress to be made to achieve a fully explainable social agent authoring tool. We provide a set of key concepts and possible solutions that can guide developers to build such tools. ",
    "url": "https://arxiv.org/abs/2206.03360",
    "authors": [
      "Manuel Guimar\u00e3es",
      "Joana Campos",
      "Pedro A. Santos",
      "Jo\u00e3o Dias",
      "Rui Prada"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.03362",
    "title": "Building Robust Ensembles via Margin Boosting",
    "abstract": "In the context of adversarial robustness, a single model does not usually have enough power to defend against all possible adversarial attacks, and as a result, has sub-optimal robustness. Consequently, an emerging line of work has focused on learning an ensemble of neural networks to defend against adversarial attacks. In this work, we take a principled approach towards building robust ensembles. We view this problem from the perspective of margin-boosting and develop an algorithm for learning an ensemble with maximum margin. Through extensive empirical evaluation on benchmark datasets, we show that our algorithm not only outperforms existing ensembling techniques, but also large models trained in an end-to-end fashion. An important byproduct of our work is a margin-maximizing cross-entropy (MCE) loss, which is a better alternative to the standard cross-entropy (CE) loss. Empirically, we show that replacing the CE loss in state-of-the-art adversarial training techniques with our MCE loss leads to significant performance improvement. ",
    "url": "https://arxiv.org/abs/2206.03362",
    "authors": [
      "Dinghuai Zhang",
      "Hongyang Zhang",
      "Aaron Courville",
      "Yoshua Bengio",
      "Pradeep Ravikumar",
      "Arun Sai Suggala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.03391",
    "title": "Data Stealing Attack on Medical Images: Is it Safe to Export Networks  from Data Lakes?",
    "abstract": "In privacy-preserving machine learning, it is common that the owner of the learned model does not have any physical access to the data. Instead, only a secured remote access to a data lake is granted to the model owner without any ability to retrieve data from the data lake. Yet, the model owner may want to export the trained model periodically from the remote repository and a question arises whether this may cause is a risk of data leakage. In this paper, we introduce the concept of data stealing attack during the export of neural networks. It consists in hiding some information in the exported network that allows the reconstruction outside the data lake of images initially stored in that data lake. More precisely, we show that it is possible to train a network that can perform lossy image compression and at the same time solve some utility tasks such as image segmentation. The attack then proceeds by exporting the compression decoder network together with some image codes that leads to the image reconstruction outside the data lake. We explore the feasibility of such attacks on databases of CT and MR images, showing that it is possible to obtain perceptually meaningful reconstructions of the target dataset, and that the stolen dataset can be used in turns to solve a broad range of tasks. Comprehensive experiments and analyses show that data stealing attacks should be considered as a threat for sensitive imaging data sources. ",
    "url": "https://arxiv.org/abs/2206.03391",
    "authors": [
      "Huiyu Li",
      "Nicholas Ayache",
      "Herv\u00e9 Delingette"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03393",
    "title": "Towards Understanding and Mitigating Audio Adversarial Examples for  Speaker Recognition",
    "abstract": "Speaker recognition systems (SRSs) have recently been shown to be vulnerable to adversarial attacks, raising significant security concerns. In this work, we systematically investigate transformation and adversarial training based defenses for securing SRSs. According to the characteristic of SRSs, we present 22 diverse transformations and thoroughly evaluate them using 7 recent promising adversarial attacks (4 white-box and 3 black-box) on speaker recognition. With careful regard for best practices in defense evaluations, we analyze the strength of transformations to withstand adaptive attacks. We also evaluate and understand their effectiveness against adaptive attacks when combined with adversarial training. Our study provides lots of useful insights and findings, many of them are new or inconsistent with the conclusions in the image and speech recognition domains, e.g., variable and constant bit rate speech compressions have different performance, and some non-differentiable transformations remain effective against current promising evasion techniques which often work well in the image domain. We demonstrate that the proposed novel feature-level transformation combined with adversarial training is rather effective compared to the sole adversarial training in a complete white-box setting, e.g., increasing the accuracy by 13.62% and attack cost by two orders of magnitude, while other transformations do not necessarily improve the overall defense capability. This work sheds further light on the research directions in this field. We also release our evaluation platform SPEAKERGUARD to foster further research. ",
    "url": "https://arxiv.org/abs/2206.03393",
    "authors": [
      "Guangke Chen",
      "Zhe Zhao",
      "Fu Song",
      "Sen Chen",
      "Lingling Fan",
      "Feng Wang",
      "Jiashui Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.03396",
    "title": "Group privacy for personalized federated learning",
    "abstract": "Federated learning is a type of collaborative machine learning, where participating clients process their data locally, sharing only updates to the collaborative model. This enables to build privacy-aware distributed machine learning models, among others. The goal is the optimization of a statistical model's parameters by minimizing a cost function of a collection of datasets which are stored locally by a set of clients. This process exposes the clients to two issues: leakage of private information and lack of personalization of the model. On the other hand, with the recent advancements in techniques to analyze data, there is a surge of concern for the privacy violation of the participating clients. To mitigate this, differential privacy and its variants serve as a standard for providing formal privacy guarantees. Often the clients represent very heterogeneous communities and hold data which are very diverse. Therefore, aligned with the recent focus of the FL community to build a framework of personalized models for the users representing their diversity, it is also of utmost importance to protect against potential threats against the sensitive and personal information of the clients. $d$-privacy, which is a generalization of geo-indistinguishability, the lately popularized paradigm of location privacy, uses a metric-based obfuscation technique that preserves the spatial distribution of the original data. To address the issue of protecting the privacy of the clients and allowing for personalized model training to enhance the fairness and utility of the system, we propose a method to provide group privacy guarantees exploiting some key properties of $d$-privacy which enables personalized models under the framework of FL. We provide with theoretical justifications to the applicability and experimental validation on real-world datasets to illustrate the working of the proposed method. ",
    "url": "https://arxiv.org/abs/2206.03396",
    "authors": [
      "Filippo Galli",
      "Sayan Biswas",
      "Kangsoo Jung",
      "Catuscia Palamidessi",
      "Tommaso Cucinotta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.03410",
    "title": "Fast and Robust Non-Rigid Registration Using Accelerated  Majorization-Minimization",
    "abstract": "Non-rigid registration, which deforms a source shape in a non-rigid way to align with a target shape, is a classical problem in computer vision. Such problems can be challenging because of imperfect data (noise, outliers and partial overlap) and high degrees of freedom. Existing methods typically adopt the $\\ell_{p}$ type robust norm to measure the alignment error and regularize the smoothness of deformation, and use a proximal algorithm to solve the resulting non-smooth optimization problem. However, the slow convergence of such algorithms limits their wide applications. In this paper, we propose a formulation for robust non-rigid registration based on a globally smooth robust norm for alignment and regularization, which can effectively handle outliers and partial overlaps. The problem is solved using the majorization-minimization algorithm, which reduces each iteration to a convex quadratic problem with a closed-form solution. We further apply Anderson acceleration to speed up the convergence of the solver, enabling the solver to run efficiently on devices with limited compute capability. Extensive experiments demonstrate the effectiveness of our method for non-rigid alignment between two shapes with outliers and partial overlaps, with quantitative evaluation showing that it outperforms state-of-the-art methods in terms of registration accuracy and computational speed. The source code is available at https://github.com/yaoyx689/AMM_NRR. ",
    "url": "https://arxiv.org/abs/2206.03410",
    "authors": [
      "Yuxin Yao",
      "Bailin Deng",
      "Weiwei Xu",
      "Juyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2206.03419",
    "title": "A Secure and Trusted Mechanism for Industrial IoT Network using  Blockchain",
    "abstract": "Industrial Internet-of-Things (IIoT) is a powerful IoT application which remodels the growth of industries by ensuring transparent communication among various entities such as hubs, manufacturing places and packaging units. Introducing data science techniques within the IIoT improves the ability to analyze the collected data in a more efficient manner, which current IIoT architectures lack due to their distributed nature. From a security perspective, network anomalies/attackers pose high security risk in IIoT. In this paper, we have addressed this problem, where a coordinator IoT device is elected to compute the trust of IoT devices to prevent the malicious devices to be part of network. Further, the transparency of the data is ensured by integrating a blockchain-based data model. The performance of the proposed framework is validated extensively and rigorously via MATLAB against various security metrics such as attack strength, message alteration, and probability of false authentication. The simulation results suggest that the proposed solution increases IIoT network security by efficiently detecting malicious attacks in the network. ",
    "url": "https://arxiv.org/abs/2206.03419",
    "authors": [
      "Geetanjali Rathee",
      "Farhan Ahmad",
      "Naveen Jaglan",
      "Charalambos Konstantinou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.03420",
    "title": "FedRel: An Adaptive Federated Relevance Framework for Spatial Temporal  Graph Learning",
    "abstract": "Spatial-temporal data contains rich information and has been widely studied in recent years due to the rapid development of relevant applications in many fields. For instance, medical institutions often use electrodes attached to different parts of a patient to analyse the electorencephal data rich with spatial and temporal features for health assessment and disease diagnosis. Existing research has mainly used deep learning techniques such as convolutional neural network (CNN) or recurrent neural network (RNN) to extract hidden spatial-temporal features. Yet, it is challenging to incorporate both inter-dependencies spatial information and dynamic temporal changes simultaneously. In reality, for a model that leverages these spatial-temporal features to fulfil complex prediction tasks, it often requires a colossal amount of training data in order to obtain satisfactory model performance. Considering the above-mentioned challenges, we propose an adaptive federated relevance framework, namely FedRel, for spatial-temporal graph learning in this paper. After transforming the raw spatial-temporal data into high quality features, the core Dynamic Inter-Intra Graph (DIIG) module in the framework is able to use these features to generate the spatial-temporal graphs capable of capturing the hidden topological and long-term temporal correlation information in these graphs. To improve the model generalization ability and performance while preserving the local data privacy, we also design a relevance-driven federated learning module in our framework to leverage diverse data distributions from different participants with attentive aggregations of their models. ",
    "url": "https://arxiv.org/abs/2206.03420",
    "authors": [
      "Tiehua Zhang",
      "Yuze Liu",
      "Zhishu Shen",
      "Rui Xu",
      "Xin Chen",
      "Xiaowei Huang",
      "Xi Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.03426",
    "title": "Improving Fairness in Graph Neural Networks via Mitigating Sensitive  Attribute Leakage",
    "abstract": "Graph Neural Networks (GNNs) have shown great power in learning node representations on graphs. However, they may inherit historical prejudices from training data, leading to discriminatory bias in predictions. Although some work has developed fair GNNs, most of them directly borrow fair representation learning techniques from non-graph domains without considering the potential problem of sensitive attribute leakage caused by feature propagation in GNNs. However, we empirically observe that feature propagation could vary the correlation of previously innocuous non-sensitive features to the sensitive ones. This can be viewed as a leakage of sensitive information which could further exacerbate discrimination in predictions. Thus, we design two feature masking strategies according to feature correlations to highlight the importance of considering feature propagation and correlation variation in alleviating discrimination. Motivated by our analysis, we propose Fair View Graph Neural Network (FairVGNN) to generate fair views of features by automatically identifying and masking sensitive-correlated features considering correlation variation after feature propagation. Given the learned fair views, we adaptively clamp weights of the encoder to avoid using sensitive-related features. Experiments on real-world datasets demonstrate that FairVGNN enjoys a better trade-off between model utility and fairness. Our code is publicly available at \\href{https://github.com/YuWVandy/FairVGNN}{\\textcolor{blue}{https://github.com/YuWVandy/FairVGNN}}. ",
    "url": "https://arxiv.org/abs/2206.03426",
    "authors": [
      "Yu Wang",
      "Yuying Zhao",
      "Yushun Dong",
      "Huiyuan Chen",
      "Jundong Li",
      "Tyler Derr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03431",
    "title": "Self-supervised Domain Adaptation in Crowd Counting",
    "abstract": "Self-training crowd counting has not been attentively explored though it is one of the important challenges in computer vision. In practice, the fully supervised methods usually require an intensive resource of manual annotation. In order to address this challenge, this work introduces a new approach to utilize existing datasets with ground truth to produce more robust predictions on unlabeled datasets, named domain adaptation, in crowd counting. While the network is trained with labeled data, samples without labels from the target domain are also added to the training process. In this process, the entropy map is computed and minimized in addition to the adversarial training process designed in parallel. Experiments on Shanghaitech, UCF_CC_50, and UCF-QNRF datasets prove a more generalized improvement of our method over the other state-of-the-arts in the cross-domain setting. ",
    "url": "https://arxiv.org/abs/2206.03431",
    "authors": [
      "Pha Nguyen",
      "Thanh-Dat Truong",
      "Miaoqing Huang",
      "Yi Liang",
      "Ngan Le",
      "Khoa Luu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03441",
    "title": "Robust Sparse Mean Estimation via Sum of Squares",
    "abstract": "We study the problem of high-dimensional sparse mean estimation in the presence of an $\\epsilon$-fraction of adversarial outliers. Prior work obtained sample and computationally efficient algorithms for this task for identity-covariance subgaussian distributions. In this work, we develop the first efficient algorithms for robust sparse mean estimation without a priori knowledge of the covariance. For distributions on $\\mathbb R^d$ with \"certifiably bounded\" $t$-th moments and sufficiently light tails, our algorithm achieves error of $O(\\epsilon^{1-1/t})$ with sample complexity $m = (k\\log(d))^{O(t)}/\\epsilon^{2-2/t}$. For the special case of the Gaussian distribution, our algorithm achieves near-optimal error of $\\tilde O(\\epsilon)$ with sample complexity $m = O(k^4 \\mathrm{polylog}(d))/\\epsilon^2$. Our algorithms follow the Sum-of-Squares based, proofs to algorithms approach. We complement our upper bounds with Statistical Query and low-degree polynomial testing lower bounds, providing evidence that the sample-time-error tradeoffs achieved by our algorithms are qualitatively the best possible. ",
    "url": "https://arxiv.org/abs/2206.03441",
    "authors": [
      "Ilias Diakonikolas",
      "Daniel M. Kane",
      "Sushrut Karmalkar",
      "Ankit Pensia",
      "Thanasis Pittas"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.03452",
    "title": "Can CNNs Be More Robust Than Transformers?",
    "abstract": "The recent success of Vision Transformers is shaking the long dominance of Convolutional Neural Networks (CNNs) in image recognition for a decade. Specifically, in terms of robustness on out-of-distribution samples, recent research finds that Transformers are inherently more robust than CNNs, regardless of different training setups. Moreover, it is believed that such superiority of Transformers should largely be credited to their self-attention-like architectures per se. In this paper, we question that belief by closely examining the design of Transformers. Our findings lead to three highly effective architecture designs for boosting robustness, yet simple enough to be implemented in several lines of code, namely a) patchifying input images, b) enlarging kernel size, and c) reducing activation layers and normalization layers. Bringing these components together, we are able to build pure CNN architectures without any attention-like operations that is as robust as, or even more robust than, Transformers. We hope this work can help the community better understand the design of robust neural architectures. The code is publicly available at https://github.com/UCSC-VLAA/RobustCNN. ",
    "url": "https://arxiv.org/abs/2206.03452",
    "authors": [
      "Zeyu Wang",
      "Yutong Bai",
      "Yuyin Zhou",
      "Cihang Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03461",
    "title": "Fast Unsupervised Brain Anomaly Detection and Segmentation with  Diffusion Models",
    "abstract": "Deep generative models have emerged as promising tools for detecting arbitrary anomalies in data, dispensing with the necessity for manual labelling. Recently, autoregressive transformers have achieved state-of-the-art performance for anomaly detection in medical imaging. Nonetheless, these models still have some intrinsic weaknesses, such as requiring images to be modelled as 1D sequences, the accumulation of errors during the sampling process, and the significant inference times associated with transformers. Denoising diffusion probabilistic models are a class of non-autoregressive generative models recently shown to produce excellent samples in computer vision (surpassing Generative Adversarial Networks), and to achieve log-likelihoods that are competitive with transformers while having fast inference times. Diffusion models can be applied to the latent representations learnt by autoencoders, making them easily scalable and great candidates for application to high dimensional data, such as medical images. Here, we propose a method based on diffusion models to detect and segment anomalies in brain imaging. By training the models on healthy data and then exploring its diffusion and reverse steps across its Markov chain, we can identify anomalous areas in the latent space and hence identify anomalies in the pixel space. Our diffusion models achieve competitive performance compared with autoregressive approaches across a series of experiments with 2D CT and MRI data involving synthetic and real pathological lesions with much reduced inference times, making their usage clinically viable. ",
    "url": "https://arxiv.org/abs/2206.03461",
    "authors": [
      "Walter H. L. Pinaya",
      "Mark S. Graham",
      "Robert Gray",
      "Pedro F Da Costa",
      "Petru-Daniel Tudosiu",
      "Paul Wright",
      "Yee H. Mah",
      "Andrew D. MacKinnon",
      "James T. Teo",
      "Rolf Jager",
      "David Werring",
      "Geraint Rees",
      "Parashkev Nachev",
      "Sebastien Ourselin",
      "M. Jorge Cardoso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2206.03466",
    "title": "Adversarial Reprogramming Revisited",
    "abstract": "Adversarial reprogramming, introduced by Elsayed, Goodfellow, and Sohl-Dickstein, seeks to repurpose a neural network to perform a different task, by manipulating its input without modifying its weights. We prove that two-layer ReLU neural networks with random weights can be adversarially reprogrammed to achieve arbitrarily high accuracy on Bernoulli data models over hypercube vertices, provided the network width is no greater than its input dimension. We also substantially strengthen a recent result of Phuong and Lampert on directional convergence of gradient flow, and obtain as a corollary that training two-layer ReLU neural networks on orthogonally separable datasets can cause their adversarial reprogramming to fail. We support these theoretical results by experiments that demonstrate that, as long as batch normalisation layers are suitably initialised, even untrained networks with random weights are susceptible to adversarial reprogramming. This is in contrast to observations in several recent works that suggested that adversarial reprogramming is not possible for untrained networks to any degree of reliability. ",
    "url": "https://arxiv.org/abs/2206.03466",
    "authors": [
      "Matthias Englert",
      "Ranko Lazic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03467",
    "title": "Discrete State-Action Abstraction via the Successor Representation",
    "abstract": "When reinforcement learning is applied with sparse rewards, agents must spend a prohibitively long time exploring the unknown environment without any learning signal. Abstraction is one approach that provides the agent with an intrinsic reward for transitioning in a latent space. Prior work focuses on dense continuous latent spaces, or requires the user to manually provide the representation. Our approach is the first for automatically learning a discrete abstraction of the underlying environment. Moreover, our method works on arbitrary input spaces, using an end-to-end trainable regularized successor representation model. For transitions between abstract states, we train a set of temporally extended actions in the form of options, i.e., an action abstraction. Our proposed algorithm, Discrete State-Action Abstraction (DSAA), iteratively swaps between training these options and using them to efficiently explore more of the environment to improve the state abstraction. As a result, our model is not only useful for transfer learning but also in the online learning setting. We empirically show that our agent is able to explore the environment and solve provided tasks more efficiently than baseline reinforcement learning algorithms. Our code is publicly available at \\url{https://github.com/amnonattali/dsaa}. ",
    "url": "https://arxiv.org/abs/2206.03467",
    "authors": [
      "Amnon Attali",
      "Pedro Cisneros-Velarde",
      "Marco Morales",
      "Nancy M. Amato"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.03469",
    "title": "FDGNN: Fully Dynamic Graph Neural Network",
    "abstract": "Dynamic Graph Neural Networks recently became more and more important as graphs from many scientific fields, ranging from mathematics, biology, social sciences, and physics to computer science, are dynamic by nature. While temporal changes (dynamics) play an essential role in many real-world applications, most of the models in the literature on Graph Neural Networks (GNN) process static graphs. The few GNN models on dynamic graphs only consider exceptional cases of dynamics, e.g., node attribute-dynamic graphs or structure-dynamic graphs limited to additions or changes to the graph's edges, etc. Therefore, we present a novel Fully Dynamic Graph Neural Network (FDGNN) that can handle fully-dynamic graphs in continuous time. The proposed method provides a node and an edge embedding that includes their activity to address added and deleted nodes or edges, and possible attributes. Furthermore, the embeddings specify Temporal Point Processes for each event to encode the distributions of the structure- and attribute-related incoming graph events. In addition, our model can be updated efficiently by considering single events for local retraining. ",
    "url": "https://arxiv.org/abs/2206.03469",
    "authors": [
      "Alice Moallemy-Oureh",
      "Silvia Beddar-Wiesing",
      "R\u00fcdiger Nather",
      "Josephine M. Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03482",
    "title": "Parametric Chordal Sparsity for SDP-based Neural Network Verification",
    "abstract": "Many future technologies rely on neural networks, but verifying the correctness of their behavior remains a major challenge. It is known that neural networks can be fragile in the presence of even small input perturbations, yielding unpredictable outputs. The verification of neural networks is therefore vital to their adoption, and a number of approaches have been proposed in recent years. In this paper we focus on semidefinite programming (SDP) based techniques for neural network verification, which are particularly attractive because they can encode expressive behaviors while ensuring a polynomial time decision. Our starting point is the DeepSDP framework proposed by Fazlyab et al, which uses quadratic constraints to abstract the verification problem into a large-scale SDP. When the size of the neural network grows, however, solving this SDP quickly becomes intractable. Our key observation is that by leveraging chordal sparsity and specific parametrizations of DeepSDP, we can decompose the primary computational bottleneck of DeepSDP -- a large linear matrix inequality (LMI) -- into an equivalent collection of smaller LMIs. Our parametrization admits a tunable parameter, allowing us to trade-off efficiency and accuracy in the verification procedure. We call our formulation Chordal-DeepSDP, and provide experimental evaluation to show that it can: (1) effectively increase accuracy with the tunable parameter and (2) outperform DeepSDP on deeper networks. ",
    "url": "https://arxiv.org/abs/2206.03482",
    "authors": [
      "Anton Xue",
      "Lars Lindemann",
      "Rajeev Alur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2206.03484",
    "title": "Detection Hub: Unifying Object Detection Datasets via Query Adaptation  on Language Embedding",
    "abstract": "Leveraging large-scale data can introduce performance gains on many computer vision tasks. Unfortunately, this does not happen in object detection when training a single model under multiple datasets together. We observe two main obstacles: taxonomy difference and bounding box annotation inconsistency, which introduces domain gaps in different datasets that prevents us from joint training. In this paper, we show that these two challenges can be effectively addressed by simply adapting object queries on language embedding of categories per dataset. We design a detection hub to dynamically adapt queries on category embedding based on the different distributions of datasets. Unlike previous methods attempted to learn a joint embedding for all datasets, our adaptation method can utilize the language embedding as semantic centers for common categories, while learning the semantic bias towards specific categories belonging to different datasets to handle annotation differences and make up the domain gaps. These novel improvements enable us to end-to-end train a single detector on multiple datasets simultaneously to fully take their advantages. Further experiments on joint training on multiple datasets demonstrate the significant performance gains over separate individual fine-tuned detectors. ",
    "url": "https://arxiv.org/abs/2206.03484",
    "authors": [
      "Lingchen Meng",
      "Xiyang Dai",
      "Yinpeng Chen",
      "Pengchuan Zhang",
      "Dongdong Chen",
      "Mengchen Liu",
      "Jianfeng Wang",
      "Zuxuan Wu",
      "Lu Yuan",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.03428",
    "title": "Detecting Vocal Fatigue with Neural Embeddings",
    "abstract": "Vocal fatigue refers to the feeling of tiredness and weakness of voice due to extended utilization. This paper investigates the effectiveness of neural embeddings for the detection of vocal fatigue. We compare x-vectors, ECAPA-TDNN, and wav2vec 2.0 embeddings on a corpus of academic spoken English. Low-dimensional mappings of the data reveal that neural embeddings capture information about the change in vocal characteristics of a speaker during prolonged voice usage. We show that vocal fatigue can be reliably predicted using all three kinds of neural embeddings after only 50 minutes of continuous speaking when temporal smoothing and normalization are applied to the extracted embeddings. We employ support vector machines for classification and achieve accuracy scores of 81% using x-vectors, 85% using ECAPA-TDNN embeddings, and 82% using wav2vec 2.0 embeddings as input features. We obtain an accuracy score of 76%, when the trained system is applied to a different speaker and recording environment without any adaptation. ",
    "url": "https://arxiv.org/abs/2204.03428",
    "authors": [
      "Sebastian P. Bayerl",
      "Dominik Wagner",
      "Ilja Baumann",
      "Korbinian Riedhammer",
      "Tobias Bocklet"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2206.02789",
    "title": "Efficient and Accurate Physics-aware Multiplex Graph Neural Networks for  3D Small Molecules and Macromolecule Complexes",
    "abstract": "Recent advances in applying Graph Neural Networks (GNNs) to molecular science have showcased the power of learning three-dimensional (3D) structure representations with GNNs. However, most existing GNNs suffer from the limitations of insufficient modeling of diverse interactions, computational expensive operations, and ignorance of vectorial values. Here, we tackle these limitations by proposing a novel GNN model, Physics-aware Multiplex Graph Neural Network (PaxNet), to efficiently and accurately learn the representations of 3D molecules for both small organic compounds and macromolecule complexes. PaxNet separates the modeling of local and non-local interactions inspired by molecular mechanics, and reduces the expensive angle-related computations. Besides scalar properties, PaxNet can also predict vectorial properties by learning an associated vector for each atom. To evaluate the performance of PaxNet, we compare it with state-of-the-art baselines in two tasks. On small molecule dataset for predicting quantum chemical properties, PaxNet reduces the prediction error by 15% and uses 73% less memory than the best baseline. On macromolecule dataset for predicting protein-ligand binding affinities, PaxNet outperforms the best baseline while reducing the memory consumption by 33% and the inference time by 85%. Thus, PaxNet provides a universal, robust and accurate method for large-scale machine learning of molecules. ",
    "url": "https://arxiv.org/abs/2206.02789",
    "authors": [
      "Shuo Zhang",
      "Yang Liu",
      "Lei Xie"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.02806",
    "title": "Quantum Neural Network Classifiers: A Tutorial",
    "abstract": "Machine learning has achieved dramatic success over the past decade, with applications ranging from face recognition to natural language processing. Meanwhile, rapid progress has been made in the field of quantum computation including developing both powerful quantum algorithms and advanced quantum devices. The interplay between machine learning and quantum physics holds the intriguing potential for bringing practical applications to the modern society. Here, we focus on quantum neural networks in the form of parameterized quantum circuits. We will mainly discuss different structures and encoding strategies of quantum neural networks for supervised learning tasks, and benchmark their performance utilizing Yao.jl, a quantum simulation package written in Julia Language. The codes are efficient, aiming to provide convenience for beginners in scientific works such as developing powerful variational quantum learning models and assisting the corresponding experimental demonstrations. ",
    "url": "https://arxiv.org/abs/2206.02806",
    "authors": [
      "Weikang Li",
      "Zhide Lu",
      "Dong-Ling Deng"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.02838",
    "title": "Invertible Sharpening Network for MRI Reconstruction Enhancement",
    "abstract": "High-quality MRI reconstruction plays a critical role in clinical applications. Deep learning-based methods have achieved promising results on MRI reconstruction. However, most state-of-the-art methods were designed to optimize the evaluation metrics commonly used for natural images, such as PSNR and SSIM, whereas the visual quality is not primarily pursued. Compared to the fully-sampled images, the reconstructed images are often blurry, where high-frequency features might not be sharp enough for confident clinical diagnosis. To this end, we propose an invertible sharpening network (InvSharpNet) to improve the visual quality of MRI reconstructions. During training, unlike the traditional methods that learn to map the input data to the ground truth, InvSharpNet adapts a backward training strategy that learns a blurring transform from the ground truth (fully-sampled image) to the input data (blurry reconstruction). During inference, the learned blurring transform can be inverted to a sharpening transform leveraging the network's invertibility. The experiments on various MRI datasets demonstrate that InvSharpNet can improve reconstruction sharpness with few artifacts. The results were also evaluated by radiologists, indicating better visual quality and diagnostic confidence of our proposed method. ",
    "url": "https://arxiv.org/abs/2206.02838",
    "authors": [
      "Siyuan Dong",
      "Eric Z. Chen",
      "Lin Zhao",
      "Xiao Chen",
      "Yikang Liu",
      "Terrence Chen",
      "Shanhui Sun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.02909",
    "title": "Self-supervised Learning for Human Activity Recognition Using 700,000  Person-days of Wearable Data",
    "abstract": "Advances in deep learning for human activity recognition have been relatively limited due to the lack of large labelled datasets. In this study, we leverage self-supervised learning techniques on the UK-Biobank activity tracker dataset--the largest of its kind to date--containing more than 700,000 person-days of unlabelled wearable sensor data. Our resulting activity recognition model consistently outperformed strong baselines across seven benchmark datasets, with an F1 relative improvement of 2.5%-100% (median 18.4%), the largest improvements occurring in the smaller datasets. In contrast to previous studies, our results generalise across external datasets, devices, and environments. Our open-source model will help researchers and developers to build customisable and generalisable activity classifiers with high performance. ",
    "url": "https://arxiv.org/abs/2206.02909",
    "authors": [
      "Hang Yuan",
      "Shing Chan",
      "Andrew P. Creagh",
      "Catherine Tong",
      "David A. Clifton",
      "Aiden Doherty"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.02927",
    "title": "Spectral Bias Outside the Training Set for Deep Networks in the Kernel  Regime",
    "abstract": "We provide quantitative bounds measuring the $L^2$ difference in function space between the trajectory of a finite-width network trained on finitely many samples from the idealized kernel dynamics of infinite width and infinite data. An implication of the bounds is that the network is biased to learn the top eigenfunctions of the Neural Tangent Kernel not just on the training set but over the entire input space. This bias depends on the model architecture and input distribution alone and thus does not depend on the target function which does not need to be in the RKHS of the kernel. The result is valid for deep architectures with fully connected, convolutional, and residual layers. Furthermore the width does not need to grow polynomially with the number of samples in order to obtain high probability bounds up to a stopping time. The proof exploits the low-effective-rank property of the Fisher Information Matrix at initialization, which implies a low effective dimension of the model (far smaller than the number of parameters). We conclude that local capacity control from the low effective rank of the Fisher Information Matrix is still underexplored theoretically. ",
    "url": "https://arxiv.org/abs/2206.02927",
    "authors": [
      "Benjamin Bowman",
      "Guido Montufar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.02959",
    "title": "HMRNet: High and Multi-Resolution Network with Bidirectional Feature  Calibration for Brain Structure Segmentation in Radiotherapy",
    "abstract": "Accurate segmentation of Anatomical brain Barriers to Cancer spread (ABCs) plays an important role for automatic delineation of Clinical Target Volume (CTV) of brain tumors in radiotherapy. Despite that variants of U-Net are state-of-the-art segmentation models, they have limited performance when dealing with ABCs structures with various shapes and sizes, especially thin structures (e.g., the falx cerebri) that span only few slices. To deal with this problem, we propose a High and Multi-Resolution Network (HMRNet) that consists of a multi-scale feature learning branch and a high-resolution branch, which can maintain the high-resolution contextual information and extract more robust representations of anatomical structures with various scales. We further design a Bidirectional Feature Calibration (BFC) block to enable the two branches to generate spatial attention maps for mutual feature calibration. Considering the different sizes and positions of ABCs structures, our network was applied after a rough localization of each structure to obtain fine segmentation results. Experiments on the MICCAI 2020 ABCs challenge dataset showed that: 1) Our proposed two-stage segmentation strategy largely outperformed methods segmenting all the structures in just one stage; 2) The proposed HMRNet with two branches can maintain high-resolution representations and is effective to improve the performance on thin structures; 3) The proposed BFC block outperformed existing attention methods using monodirectional feature calibration. Our method won the second place of ABCs 2020 challenge and has a potential for more accurate and reasonable delineation of CTV of brain tumors. ",
    "url": "https://arxiv.org/abs/2206.02959",
    "authors": [
      "Hao Fu",
      "Guotai Wang",
      "Wenhui Lei",
      "Wei Xu",
      "Qianfei Zhao",
      "Shichuan Zhang",
      "Kang Li",
      "Shaoting Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.02962",
    "title": "Confounder Analysis in Measuring Representation in Product Funnels",
    "abstract": "This paper discusses an application of Shapley values in the causal inference field, specifically on how to select the top confounder variables for coarsened exact matching method in a scalable way. We use a dataset from an observational experiment involving LinkedIn members as a use case to test its applicability, and show that Shapley values are highly informational and can be leveraged for its robust importance-ranking capability. ",
    "url": "https://arxiv.org/abs/2206.02962",
    "authors": [
      "Jilei Yang",
      "Wentao Su"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.02972",
    "title": "Decomposed Linear Dynamical Systems (dLDS) for learning the latent  components of neural dynamics",
    "abstract": "Learning interpretable representations of neural dynamics at a population level is a crucial first step to understanding how neural activity relates to perception and behavior. Models of neural dynamics often focus on either low-dimensional projections of neural activity, or on learning dynamical systems that explicitly relate to the neural state over time. We discuss how these two approaches are interrelated by considering dynamical systems as representative of flows on a low-dimensional manifold. Building on this concept, we propose a new decomposed dynamical system model that represents complex non-stationary and nonlinear dynamics of time-series data as a sparse combination of simpler, more interpretable components. The decomposed nature of the dynamics generalizes over previous switched approaches and enables modeling of overlapping and non-stationary drifts in the dynamics. We further present a dictionary learning-driven approach to model fitting, where we leverage recent results in tracking sparse vectors over time. We demonstrate that our model can learn efficient representations and smooth transitions between dynamical modes in both continuous-time and discrete-time examples. We show results on low-dimensional linear and nonlinear attractors to demonstrate that our decomposed dynamical systems model can well approximate nonlinear dynamics. Additionally, we apply our model to C. elegans data, illustrating a diversity of dynamics that is obscured when classified into discrete states. ",
    "url": "https://arxiv.org/abs/2206.02972",
    "authors": [
      "Noga Mudrik",
      "Yenho Chen",
      "Eva Yezerets",
      "Christopher J. Rozell",
      "Adam S. Charles"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2206.03009",
    "title": "Self-Knowledge Distillation based Self-Supervised Learning for Covid-19  Detection from Chest X-Ray Images",
    "abstract": "The global outbreak of the Coronavirus 2019 (COVID-19) has overloaded worldwide healthcare systems. Computer-aided diagnosis for COVID-19 fast detection and patient triage is becoming critical. This paper proposes a novel self-knowledge distillation based self-supervised learning method for COVID-19 detection from chest X-ray images. Our method can use self-knowledge of images based on similarities of their visual features for self-supervised learning. Experimental results show that our method achieved an HM score of 0.988, an AUC of 0.999, and an accuracy of 0.957 on the largest open COVID-19 chest X-ray dataset. ",
    "url": "https://arxiv.org/abs/2206.03009",
    "authors": [
      "Guang Li",
      "Ren Togo",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03049",
    "title": "Siamese Encoder-based Spatial-Temporal Mixer for Growth Trend Prediction  of Lung Nodules on CT Scans",
    "abstract": "In the management of lung nodules, we are desirable to predict nodule evolution in terms of its diameter variation on Computed Tomography (CT) scans and then provide a follow-up recommendation according to the predicted result of the growing trend of the nodule. In order to improve the performance of growth trend prediction for lung nodules, it is vital to compare the changes of the same nodule in consecutive CT scans. Motivated by this, we screened out 4,666 subjects with more than two consecutive CT scans from the National Lung Screening Trial (NLST) dataset to organize a temporal dataset called NLSTt. In specific, we first detect and pair regions of interest (ROIs) covering the same nodule based on registered CT scans. After that, we predict the texture category and diameter size of the nodules through models. Last, we annotate the evolution class of each nodule according to its changes in diameter. Based on the built NLSTt dataset, we propose a siamese encoder to simultaneously exploit the discriminative features of 3D ROIs detected from consecutive CT scans. Then we novelly design a spatial-temporal mixer (STM) to leverage the interval changes of the same nodule in sequential 3D ROIs and capture spatial dependencies of nodule regions and the current 3D ROI. According to the clinical diagnosis routine, we employ hierarchical loss to pay more attention to growing nodules. The extensive experiments on our organized dataset demonstrate the advantage of our proposed method. We also conduct experiments on an in-house dataset to evaluate the clinical utility of our method by comparing it against skilled clinicians. ",
    "url": "https://arxiv.org/abs/2206.03049",
    "authors": [
      "Jiansheng Fang",
      "Jingwen Wang",
      "Anwei Li",
      "Yuguang Yan",
      "Yonghe Hou",
      "Chao Song",
      "Hongbo Liu",
      "Jiang Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03066",
    "title": "Recent Advances for Quantum Neural Networks in Generative Learning",
    "abstract": "Quantum computers are next-generation devices that hold promise to perform calculations beyond the reach of classical computers. A leading method towards achieving this goal is through quantum machine learning, especially quantum generative learning. Due to the intrinsic probabilistic nature of quantum mechanics, it is reasonable to postulate that quantum generative learning models (QGLMs) may surpass their classical counterparts. As such, QGLMs are receiving growing attention from the quantum physics and computer science communities, where various QGLMs that can be efficiently implemented on near-term quantum machines with potential computational advantages are proposed. In this paper, we review the current progress of QGLMs from the perspective of machine learning. Particularly, we interpret these QGLMs, covering quantum circuit born machines, quantum generative adversarial networks, quantum Boltzmann machines, and quantum autoencoders, as the quantum extension of classical generative learning models. In this context, we explore their intrinsic relation and their fundamental differences. We further summarize the potential applications of QGLMs in both conventional machine learning tasks and quantum physics. Last, we discuss the challenges and further research directions for QGLMs. ",
    "url": "https://arxiv.org/abs/2206.03066",
    "authors": [
      "Jinkai Tian",
      "Xiaoyu Sun",
      "Yuxuan Du",
      "Shanshan Zhao",
      "Qing Liu",
      "Kaining Zhang",
      "Wei Yi",
      "Wanrong Huang",
      "Chaoyue Wang",
      "Xingyao Wu",
      "Min-Hsiu Hsieh",
      "Tongliang Liu",
      "Wenjing Yang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03247",
    "title": "Towards better Interpretable and Generalizable AD detection using  Collective Artificial Intelligence",
    "abstract": "Accurate diagnosis and prognosis of Alzheimer's disease are crucial for developing new therapies and reducing the associated costs. Recently, with the advances of convolutional neural networks, deep learning methods have been proposed to automate these two tasks using structural MRI. However, these methods often suffer from a lack of interpretability and generalization and have limited prognosis performance. In this paper, we propose a novel deep framework designed to overcome these limitations. Our pipeline consists of two stages. In the first stage, 125 3D U-Nets are used to estimate voxelwise grade scores over the whole brain. The resulting 3D maps are then fused to construct an interpretable 3D grading map indicating the disease severity at the structure level. As a consequence, clinicians can use this map to detect the brain structures affected by the disease. In the second stage, the grading map and subject's age are used to perform classification with a graph convolutional neural network. Experimental results based on 2106 subjects demonstrated competitive performance of our deep framework compared to state-of-the-art methods on different datasets for both AD diagnosis and prognosis. Moreover, we found that using a large number of U-Nets processing different overlapping brain areas improved the generalization capacity of the proposed methods. ",
    "url": "https://arxiv.org/abs/2206.03247",
    "authors": [
      "Huy-Dung Nguyen",
      "Micha\u00ebl Cl\u00e9ment",
      "Boris Mansencal",
      "Pierrick Coup\u00e9"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03314",
    "title": "Integrating Random Effects in Deep Neural Networks",
    "abstract": "Modern approaches to supervised learning like deep neural networks (DNNs) typically implicitly assume that observed responses are statistically independent. In contrast, correlated data are prevalent in real-life large-scale applications, with typical sources of correlation including spatial, temporal and clustering structures. These correlations are either ignored by DNNs, or ad-hoc solutions are developed for specific use cases. We propose to use the mixed models framework to handle correlated data in DNNs. By treating the effects underlying the correlation structure as random effects, mixed models are able to avoid overfitted parameter estimates and ultimately yield better predictive performance. The key to combining mixed models and DNNs is using the Gaussian negative log-likelihood (NLL) as a natural loss function that is minimized with DNN machinery including stochastic gradient descent (SGD). Since NLL does not decompose like standard DNN loss functions, the use of SGD with NLL presents some theoretical and implementation challenges, which we address. Our approach which we call LMMNN is demonstrated to improve performance over natural competitors in various correlation scenarios on diverse simulated and real datasets. Our focus is on a regression setting and tabular datasets, but we also show some results for classification. Our code is available at https://github.com/gsimchoni/lmmnn. ",
    "url": "https://arxiv.org/abs/2206.03314",
    "authors": [
      "Giora Simchoni",
      "Saharon Rosset"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03353",
    "title": "Adaptive Regularization for Adversarial Training",
    "abstract": "Adversarial training, which is to enhance robustness against adversarial attacks, has received much attention because it is easy to generate human-imperceptible perturbations of data to deceive a given deep neural network. In this paper, we propose a new adversarial training algorithm that is theoretically well motivated and empirically superior to other existing algorithms. A novel feature of the proposed algorithm is to use a data-adaptive regularization for robustifying a prediction model. We apply more regularization to data which are more vulnerable to adversarial attacks and vice versa. Even though the idea of data-adaptive regularization is not new, our data-adaptive regularization has a firm theoretical base of reducing an upper bound of the robust risk. Numerical experiments illustrate that our proposed algorithm improves the generalization (accuracy on clean samples) and robustness (accuracy on adversarial attacks) simultaneously to achieve the state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2206.03353",
    "authors": [
      "Dongyoon Yang",
      "Insung Kong",
      "Yongdai Kim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03359",
    "title": "An efficient semi-supervised quality control system trained using  physics-based MRI-artefact generators and adversarial training",
    "abstract": "Large medical imaging data sets are becoming increasingly available. A common challenge in these data sets is to ensure that each sample meets minimum quality requirements devoid of significant artefacts. Despite a wide range of existing automatic methods having been developed to identify imperfections and artefacts in medical imaging, they mostly rely on data-hungry methods. In particular, the lack of sufficient scans with artefacts available for training has created a barrier in designing and deploying machine learning in clinical research. To tackle this problem, we propose a novel framework having four main components: (1) a set of artefact generators inspired by magnetic resonance physics to corrupt brain MRI scans and augment a training dataset, (2) a set of abstract and engineered features to represent images compactly, (3) a feature selection process that depends on the class of artefact to improve classification performance, and (4) a set of Support Vector Machine (SVM) classifiers trained to identify artefacts. Our novel contributions are threefold: first, we use the novel physics-based artefact generators to generate synthetic brain MRI scans with controlled artefacts as a data augmentation technique. This will avoid the labour-intensive collection and labelling process of scans with rare artefacts. Second, we propose a large pool of abstract and engineered image features developed to identify 9 different artefacts for structural MRI. Finally, we use an artefact-based feature selection block that, for each class of artefacts, finds the set of features that provide the best classification performance. We performed validation experiments on a large data set of scans with artificially-generated artefacts, and in a multiple sclerosis clinical trial where real artefacts were identified by experts, showing that the proposed pipeline outperforms traditional methods. ",
    "url": "https://arxiv.org/abs/2206.03359",
    "authors": [
      "Daniele Ravi",
      "Frederik Barkhof",
      "Daniel C. Alexander",
      "Geoffrey JM Parker",
      "Arman Eshaghi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03364",
    "title": "KPGT: Knowledge-Guided Pre-training of Graph Transformer for Molecular  Property Prediction",
    "abstract": "Designing accurate deep learning models for molecular property prediction plays an increasingly essential role in drug and material discovery. Recently, due to the scarcity of labeled molecules, self-supervised learning methods for learning generalizable and transferable representations of molecular graphs have attracted lots of attention. In this paper, we argue that there exist two major issues hindering current self-supervised learning methods from obtaining desired performance on molecular property prediction, that is, the ill-defined pre-training tasks and the limited model capacity. To this end, we introduce Knowledge-guided Pre-training of Graph Transformer (KPGT), a novel self-supervised learning framework for molecular graph representation learning, to alleviate the aforementioned issues and improve the performance on the downstream molecular property prediction tasks. More specifically, we first introduce a high-capacity model, named Line Graph Transformer (LiGhT), which emphasizes the importance of chemical bonds and is mainly designed to model the structural information of molecular graphs. Then, a knowledge-guided pre-training strategy is proposed to exploit the additional knowledge of molecules to guide the model to capture the abundant structural and semantic information from large-scale unlabeled molecular graphs. Extensive computational tests demonstrated that KPGT can offer superior performance over current state-of-the-art methods on several molecular property prediction tasks. ",
    "url": "https://arxiv.org/abs/2206.03364",
    "authors": [
      "Han Li",
      "Dan Zhao",
      "Jianyang Zeng"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2206.03400",
    "title": "The Influence of Dataset Partitioning on Dysfluency Detection Systems",
    "abstract": "This paper empirically investigates the influence of different data splits and splitting strategies on the performance of dysfluency detection systems. For this, we perform experiments using wav2vec 2.0 models with a classification head as well as support vector machines (SVM) in conjunction with the features extracted from the wav2vec 2.0 model to detect dysfluencies. We train and evaluate the systems with different non-speaker-exclusive and speaker-exclusive splits of the Stuttering Events in Podcasts (SEP-28k) dataset to shed some light on the variability of results w.r.t. to the partition method used. Furthermore, we show that the SEP-28k dataset is dominated by only a few speakers, making it difficult to evaluate. To remedy this problem, we created SEP-28k-Extended (SEP-28k-E), containing semi-automatically generated speaker and gender information for the SEP-28k corpus, and suggest different data splits, each useful for evaluating other aspects of methods for dysfluency detection. ",
    "url": "https://arxiv.org/abs/2206.03400",
    "authors": [
      "Sebastian P. Bayerl",
      "Dominik Wagner",
      "Elmar N\u00f6th",
      "Tobias Bocklet",
      "Korbinian Riedhammer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2206.03422",
    "title": "Vertex-critical $(P_3+\\ell P_1)$-free and vertex-critical (gem,  co-gem)-free graphs",
    "abstract": "A graph $G$ is $k$-vertex-critical if $\\chi(G)=k$ but $\\chi(G-v)<k$ for all $v\\in V(G)$ where $\\chi(G)$ denotes the chromatic number of $G$. We show that there are only finitely many $k$-critical $(P_3+\\ell P_1)$-free graphs for all $k$ and all $\\ell$. Together with previous results, the only graphs $H$ for which it is unknown if there are an infinite number of $k$-vertex-critical $H$-free graphs is $H=(P_4+\\ell P_1)$ for all $\\ell\\ge 1$. We consider a restriction on the smallest open case, and show that there are only finitely many $k$-vertex-critical (gem, co-gem)-free graphs for all $k$, where gem$=\\overline{P_4+P_1}$. To do this, we show the stronger result that every vertex-critical (gem, co-gem)-free graph is either complete or a clique expansion of $C_5$. This characterization allows us to give the complete list of all $k$-vertex-critical (gem, co-gem)-free graphs for all $k\\le 16$ ",
    "url": "https://arxiv.org/abs/2206.03422",
    "authors": [
      "Tala Abuadas",
      "Ben Cameron",
      "Ch\u00ednh T. Ho\u00e0ng",
      "Joe Sawada"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:1911.03855",
    "title": "Correcting Sociodemographic Selection Biases for Population Prediction  from Social Media",
    "abstract": " Comments: Published at the 16th International AAAI Conference on Web and Social Media (ICWSM) 2022 ",
    "url": "https://arxiv.org/abs/1911.03855",
    "authors": [
      "Salvatore Giorgi",
      "Veronica Lynn",
      "Keshav Gupta",
      "Farhan Ahmed",
      "Sandra Matz",
      "Lyle Ungar",
      "H. Andrew Schwartz"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2001.02892",
    "title": "A Generalized Probabilistic Learning Approach for Multi-Fidelity  Uncertainty Propagation in Complex Physical Simulations",
    "abstract": " Comments: 35 pages, 16 figures ",
    "url": "https://arxiv.org/abs/2001.02892",
    "authors": [
      "Jonas Nitzler",
      "Jonas Biehler",
      "Niklas Fehn",
      "Phaedon-Stelios Koutsourelakis",
      "Wolfgang A. Wall"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2002.06838",
    "title": "Stratified Rule-Aware Network for Abstract Visual Reasoning",
    "abstract": " Comments: AAAI 2021 paper. Code: this https URL ",
    "url": "https://arxiv.org/abs/2002.06838",
    "authors": [
      "Sheng Hu",
      "Yuqing Ma",
      "Xianglong Liu",
      "Yanlu Wei",
      "Shihao Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2101.07077",
    "title": "Yet Another Representation of Binary Decision Trees: A Mathematical  Demonstration",
    "abstract": " Title: Yet Another Representation of Binary Decision Trees: A Mathematical  Demonstration ",
    "url": "https://arxiv.org/abs/2101.07077",
    "authors": [
      "Jinxiong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2102.01460",
    "title": "Learning to Segment Human Body Parts with Synthetically Trained Deep  Convolutional Networks",
    "abstract": " Comments: This paper has been published in: Proceedings of the 16th International Conference on Intelligent Autonomous Systems (IAS 2021) ",
    "url": "https://arxiv.org/abs/2102.01460",
    "authors": [
      "Alessandro Saviolo",
      "Matteo Bonotto",
      "Daniele Evangelista",
      "Marco Imperoli",
      "Jacopo Lazzaro",
      "Emanuele Menegatti",
      "Alberto Pretto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.01369",
    "title": "Private Computation of Polynomials over Networks",
    "abstract": " Comments: 12 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2104.01369",
    "authors": [
      "Teimour Hosseinalizadeh",
      "Fatih Turkmen",
      "Nima Monshizadeh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2104.05031",
    "title": "Deformable Capsules for Object Detection",
    "abstract": " Title: Deformable Capsules for Object Detection ",
    "url": "https://arxiv.org/abs/2104.05031",
    "authors": [
      "Rodney Lalonde",
      "Naji Khosravan",
      "Ulas Bagci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.15927",
    "title": "A Robust Classification-autoencoder to Defend Outliers and Adversaries",
    "abstract": " Title: A Robust Classification-autoencoder to Defend Outliers and Adversaries ",
    "url": "https://arxiv.org/abs/2106.15927",
    "authors": [
      "Lijia Yu",
      "Xiao-Shan Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.05455",
    "title": "A Local Diagnosis Algorithm for Hypercube-like Networks under the BGM  Diagnosis Model",
    "abstract": " Title: A Local Diagnosis Algorithm for Hypercube-like Networks under the BGM  Diagnosis Model ",
    "url": "https://arxiv.org/abs/2107.05455",
    "authors": [
      "Cheng-Kuan Lin",
      "Tzu-Liang Kung",
      "Chun-Nan Hung",
      "Yuan-Hsiang Teng"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2107.09370",
    "title": "An Embedding of ReLU Networks and an Analysis of their Identifiability",
    "abstract": " Comments: Constructive Approximation camera-ready ",
    "url": "https://arxiv.org/abs/2107.09370",
    "authors": [
      "Pierre Stock",
      "R\u00e9mi Gribonval"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.01494",
    "title": "Computing Graph Descriptors on Edge Streams",
    "abstract": " Comments: Extension of work accepted to PAKDD 2020 ",
    "url": "https://arxiv.org/abs/2109.01494",
    "authors": [
      "Zohair Raza Hassan",
      "Sarwan Ali",
      "Imdadullah Khan",
      "Mudassir Shabbir",
      "Waseem Abbas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2109.07711",
    "title": "DeepMTS: Deep Multi-task Learning for Survival Prediction in Patients  with Advanced Nasopharyngeal Carcinoma using Pretreatment PET/CT",
    "abstract": " Comments: Accepted at IEEE Journal of Biomedical and Health Informatics (JBHI) ",
    "url": "https://arxiv.org/abs/2109.07711",
    "authors": [
      "Mingyuan Meng",
      "Bingxin Gu",
      "Lei Bi",
      "Shaoli Song",
      "David Dagan Feng",
      "Jinman Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.02329",
    "title": "Task-aware Privacy Preservation for Multi-dimensional Data",
    "abstract": " Comments: Accepted by 39th International Conference on Machine Learning (ICML 2022) ",
    "url": "https://arxiv.org/abs/2110.02329",
    "authors": [
      "Jiangnan Cheng",
      "Ao Tang",
      "Sandeep Chinchali"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.13492",
    "title": "TUNet: A Block-online Bandwidth Extension Model based on Transformers  and Self-supervised Pretraining",
    "abstract": " Comments: Published as a conference paper at ICASSP 2022, 5 pages, 4 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2110.13492",
    "authors": [
      "Viet-Anh Nguyen",
      "Anh H. T. Nguyen",
      "Andy W. H. Khong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2111.13336",
    "title": "MAE-DET: Revisiting Maximum Entropy Principle in Zero-Shot NAS for  Efficient Object Detection",
    "abstract": " Comments: Accepted by ICML 2022 ",
    "url": "https://arxiv.org/abs/2111.13336",
    "authors": [
      "Zhenhong Sun",
      "Ming Lin",
      "Xiuyu Sun",
      "Zhiyu Tan",
      "Hao Li",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.01473",
    "title": "Neural Point Light Fields",
    "abstract": " Comments: 9 pages, replacement changed font of equations ",
    "url": "https://arxiv.org/abs/2112.01473",
    "authors": [
      "Julian Ost",
      "Issam Laradji",
      "Alejandro Newell",
      "Yuval Bahat",
      "Felix Heide"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2201.05125",
    "title": "GradMax: Growing Neural Networks using Gradient Information",
    "abstract": " Comments: ICLR 2022 ",
    "url": "https://arxiv.org/abs/2201.05125",
    "authors": [
      "Utku Evci",
      "Bart van Merri\u00ebnboer",
      "Thomas Unterthiner",
      "Max Vladymyrov",
      "Fabian Pedregosa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.05624",
    "title": "Scientific Machine Learning through Physics-Informed Neural Networks:  Where we are and What's next",
    "abstract": " Title: Scientific Machine Learning through Physics-Informed Neural Networks:  Where we are and What's next ",
    "url": "https://arxiv.org/abs/2201.05624",
    "authors": [
      "Salvatore Cuomo",
      "Vincenzo Schiano di Cola",
      "Fabio Giampaolo",
      "Gianluigi Rozza",
      "Maziar Raissi",
      "Francesco Piccialli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2201.12179",
    "title": "Plug & Play Attacks: Towards Robust and Flexible Model Inversion Attacks",
    "abstract": " Comments: Accepted by ICML 2022 as Oral ",
    "url": "https://arxiv.org/abs/2201.12179",
    "authors": [
      "Lukas Struppek",
      "Dominik Hintersdorf",
      "Antonio De Almeida Correia",
      "Antonia Adler",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.12843",
    "title": "On Recoverability of Graph Neural Network Representations",
    "abstract": " Title: On Recoverability of Graph Neural Network Representations ",
    "url": "https://arxiv.org/abs/2201.12843",
    "authors": [
      "Maxim Fishman",
      "Chaim Baskin",
      "Evgenii Zheltonozhskii",
      "Almog David",
      "Ron Banner",
      "Avi Mendelson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.00529",
    "title": "Molecular Representation Learning via Heterogeneous Motif Graph Neural  Networks",
    "abstract": " Comments: International Conference on Machine Learning (2022) ",
    "url": "https://arxiv.org/abs/2202.00529",
    "authors": [
      "Zhaoning Yu",
      "Hongyang Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.12448",
    "title": "Deep neural networks for fine-grained surveillance of overdose mortality",
    "abstract": " Comments: Accepted to appear in the American Journal of Epidemiology ",
    "url": "https://arxiv.org/abs/2202.12448",
    "authors": [
      "Patrick J. Ward",
      "April M. Young",
      "Svetla Slavova",
      "Madison Liford",
      "Lara Daniels",
      "Ripley Lucas",
      "Ramakanth Kavuluru"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.01601",
    "title": "Syntax-Aware Network for Handwritten Mathematical Expression Recognition",
    "abstract": " Comments: CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.01601",
    "authors": [
      "Ye Yuan",
      "Xiao Liu",
      "Wondimu Dikubab",
      "Hui Liu",
      "Zhilong Ji",
      "Zhongqin Wu",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07941",
    "title": "Reachability In Simple Neural Networks",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2108.13179 ",
    "url": "https://arxiv.org/abs/2203.07941",
    "authors": [
      "Marco S\u00e4lzer",
      "Martin Lange"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09308",
    "title": "Few-Shot Learning on Graphs",
    "abstract": " Title: Few-Shot Learning on Graphs ",
    "url": "https://arxiv.org/abs/2203.09308",
    "authors": [
      "Chuxu Zhang",
      "Kaize Ding",
      "Jundong Li",
      "Xiangliang Zhang",
      "Yanfang Ye",
      "Nitesh V. Chawla",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04853",
    "title": "Neural Lagrangian Schr\u00f6dinger Bridge",
    "abstract": " Title: Neural Lagrangian Schr\u00f6dinger Bridge ",
    "url": "https://arxiv.org/abs/2204.04853",
    "authors": [
      "Takeshi Koshizuka",
      "Issei Sato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2204.06828",
    "title": "Deep Vehicle Detection in Satellite Video",
    "abstract": " Title: Deep Vehicle Detection in Satellite Video ",
    "url": "https://arxiv.org/abs/2204.06828",
    "authors": [
      "Roman Pflugfelder",
      "Axel Weissenfeld",
      "Julian Wagner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01306",
    "title": "CANShield: Signal-based Intrusion Detection for Controller Area Networks",
    "abstract": " Comments: 15 pages, 6 figures, A version of this paper is accepted by escar USA 2022 ",
    "url": "https://arxiv.org/abs/2205.01306",
    "authors": [
      "Md Hasan Shahriar",
      "Yang Xiao",
      "Pablo Moriano",
      "Wenjing Lou",
      "Y. Thomas Hou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01703",
    "title": "Improving In-Context Few-Shot Learning via Self-Supervised Training",
    "abstract": " Comments: NAACL 2022 ",
    "url": "https://arxiv.org/abs/2205.01703",
    "authors": [
      "Mingda Chen",
      "Jingfei Du",
      "Ramakanth Pasunuru",
      "Todor Mihaylov",
      "Srini Iyer",
      "Veselin Stoyanov",
      "Zornitsa Kozareva"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.07556",
    "title": "An Effective Transformer-based Solution for RSNA Intracranial Hemorrhage  Detection Competition",
    "abstract": " Title: An Effective Transformer-based Solution for RSNA Intracranial Hemorrhage  Detection Competition ",
    "url": "https://arxiv.org/abs/2205.07556",
    "authors": [
      "Fangxin Shang",
      "Siqi Wang",
      "Xiaorong Wang",
      "Yehui Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.07865",
    "title": "Simple Contrastive Graph Clustering",
    "abstract": " Comments: There is an error in the introduction of the loss-pass denoiseing operation. We mistakenly describe the hyper-parameter k in section 3.3 ",
    "url": "https://arxiv.org/abs/2205.07865",
    "authors": [
      "Yue Liu",
      "Xihong Yang",
      "Sihang Zhou",
      "Xinwang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.09026",
    "title": "VLC Physical Layer Security through RIS-aided Jamming Receiver for 6G  Wireless Networks",
    "abstract": " Title: VLC Physical Layer Security through RIS-aided Jamming Receiver for 6G  Wireless Networks ",
    "url": "https://arxiv.org/abs/2205.09026",
    "authors": [
      "Simone Soderi",
      "Alessandro Brighente",
      "Federico Turrin",
      "Mauro Conti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.09382",
    "title": "BabyNet: Residual Transformer Module for Birth Weight Prediction on  Fetal Ultrasound Video",
    "abstract": " Comments: Early accepted for 25th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) 2022, Singapore ",
    "url": "https://arxiv.org/abs/2205.09382",
    "authors": [
      "Szymon P\u0142otka",
      "Michal K. Grzeszczyk",
      "Robert Brawura-Biskupski-Samaha",
      "Pawe\u0142 Gutaj",
      "Micha\u0142 Lipa",
      "Tomasz Trzci\u0144ski",
      "Arkadiusz Sitek"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09786",
    "title": "Subset Node Anomaly Tracking over Large Dynamic Graphs",
    "abstract": " Comments: 9 pages + 2 pages supplement, accepted to 2022 ACM SIGKDD Research Track ",
    "url": "https://arxiv.org/abs/2205.09786",
    "authors": [
      "Xingzhi Guo",
      "Baojian Zhou",
      "Steven Skiena"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.10278",
    "title": "A framework for self-supervised MR image reconstruction using  sub-sampling via Noisier2Noise",
    "abstract": " Comments: Submitted to IEEE Computational Imaging ",
    "url": "https://arxiv.org/abs/2205.10278",
    "authors": [
      "Charles Millard",
      "Mark Chiew"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11283",
    "title": "SelfReformer: Self-Refined Network with Transformer for Salient Object  Detection",
    "abstract": " Title: SelfReformer: Self-Refined Network with Transformer for Salient Object  Detection ",
    "url": "https://arxiv.org/abs/2205.11283",
    "authors": [
      "Yi Ke Yun",
      "Weisi Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14837",
    "title": "Enhancing Sequential Recommendation with Graph Contrastive Learning",
    "abstract": " Comments: 8 pages, 3 figures, Accepted by IJCAI 2022 ",
    "url": "https://arxiv.org/abs/2205.14837",
    "authors": [
      "Yixin Zhang",
      "Yong Liu",
      "Yonghui Xu",
      "Hao Xiong",
      "Chenyi Lei",
      "Wei He",
      "Lizhen Cui",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.14839",
    "title": "Adversarial Bandits Robust to $S$-Switch Regret",
    "abstract": " Title: Adversarial Bandits Robust to $S$-Switch Regret ",
    "url": "https://arxiv.org/abs/2205.14839",
    "authors": [
      "Jung-hun Kim",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.15173",
    "title": "Self-Supervised Pre-training of Vision Transformers for Dense Prediction  Tasks",
    "abstract": " Title: Self-Supervised Pre-training of Vision Transformers for Dense Prediction  Tasks ",
    "url": "https://arxiv.org/abs/2205.15173",
    "authors": [
      "Jaonary Rabarisoa",
      "Valentin Belissen",
      "Florian Chabot",
      "Quoc-Cuong Pham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00807",
    "title": "Applied Federated Learning: Architectural Design for Robust and  Efficient Learning in Privacy Aware Settings",
    "abstract": " Title: Applied Federated Learning: Architectural Design for Robust and  Efficient Learning in Privacy Aware Settings ",
    "url": "https://arxiv.org/abs/2206.00807",
    "authors": [
      "Branislav Stojkovic",
      "Jonathan Woodbridge",
      "Zhihan Fang",
      "Jerry Cai",
      "Andrey Petrov",
      "Sathya Iyer",
      "Daoyu Huang",
      "Patrick Yau",
      "Arvind Sastha Kumar",
      "Hitesh Jawa",
      "Anamita Guha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00934",
    "title": "Deep neural networks can stably solve high-dimensional, noisy,  non-linear inverse problems",
    "abstract": " Title: Deep neural networks can stably solve high-dimensional, noisy,  non-linear inverse problems ",
    "url": "https://arxiv.org/abs/2206.00934",
    "authors": [
      "Andr\u00e9s Felipe Lerma Pineda",
      "Philipp Christian Petersen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.01008",
    "title": "Approximate Network Motif Mining Via Graph Learning",
    "abstract": " Title: Approximate Network Motif Mining Via Graph Learning ",
    "url": "https://arxiv.org/abs/2206.01008",
    "authors": [
      "Carlos Oliver",
      "Dexiong Chen",
      "Vincent Mallet",
      "Pericles Philippopoulos",
      "Karsten Borgwardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.01696",
    "title": "Deep Learning Prediction of Severe Health Risks for Pediatric COVID-19  Patients with a Large Feature Set in 2021 BARDA Data Challenge",
    "abstract": " Comments: Acknowledgment updated, minor typos fixed ",
    "url": "https://arxiv.org/abs/2206.01696",
    "authors": [
      "Sajid Mahmud",
      "Elham Soltanikazemi",
      "Frimpong Boadu",
      "Ashwin Dhakal",
      "Jianlin Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.01910",
    "title": "The Spike Gating Flow: A Hierarchical Structure Based Spiking Neural  Network for Online Gesture Recognition",
    "abstract": " Title: The Spike Gating Flow: A Hierarchical Structure Based Spiking Neural  Network for Online Gesture Recognition ",
    "url": "https://arxiv.org/abs/2206.01910",
    "authors": [
      "Zihao Zhao",
      "Yanhong Wang",
      "Qiaosha Zou",
      "Tie Xu",
      "Fangbo Tao",
      "Jiansong Zhang",
      "Xiaoan Wang",
      "C.-J. Richard Shi",
      "Junwen Luo",
      "Yuan Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.01992",
    "title": "CAINNFlow: Convolutional block Attention modules and Invertible Neural  Networks Flow for anomaly detection and localization tasks",
    "abstract": " Title: CAINNFlow: Convolutional block Attention modules and Invertible Neural  Networks Flow for anomaly detection and localization tasks ",
    "url": "https://arxiv.org/abs/2206.01992",
    "authors": [
      "Ruiqing Yan",
      "Fan Zhang",
      "Mengyuan Huang",
      "Wu Liu",
      "Dongyu Hu",
      "Jinfeng Li",
      "Qiang Liu",
      "Jingrong Jiang",
      "Qianjin Guo",
      "Linghan Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.02617",
    "title": "Per-Instance Privacy Accounting for Differentially Private Stochastic  Gradient Descent",
    "abstract": " Title: Per-Instance Privacy Accounting for Differentially Private Stochastic  Gradient Descent ",
    "url": "https://arxiv.org/abs/2206.02617",
    "authors": [
      "Da Yu",
      "Gautam Kamath",
      "Janardhan Kulkarni",
      "Tie-Yan Liu",
      "Jian Yin",
      "Huishuai Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.02670",
    "title": "Robust Adversarial Attacks Detection based on Explainable Deep  Reinforcement Learning For UAV Guidance and Planning",
    "abstract": " Comments: 13 pages, 20 figures ",
    "url": "https://arxiv.org/abs/2206.02670",
    "authors": [
      "Thomas Hickling",
      "Nabil Aouf",
      "Phillippa Spencer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Robotics (cs.RO)"
    ]
  }
]