[
  {
    "id": "arXiv:2206.08950",
    "title": "Photoelectric Factor Prediction Using Automated Learning and Uncertainty  Quantification",
    "abstract": "The photoelectric factor (PEF) is an important well logging tool to distinguish between different types of reservoir rocks because PEF measurement is sensitive to elements with high atomic number. Furthermore, the ratio of rock minerals could be determined by combining PEF log with other well logs. However, PEF log could be missing in some cases such as in old well logs and wells drilled with barite-based mud. Therefore, developing models for estimating missing PEF log is essential in those circumstances. In this work, we developed various machine learning models to predict PEF values using the following well logs as inputs: bulk density (RHOB), neutron porosity (NPHI), gamma ray (GR), compressional and shear velocity. The predictions of PEF values using adaptive-network-fuzzy inference system (ANFIS) and artificial neural network (ANN) models have errors of about 16% and 14% average absolute percentage error (AAPE) in the testing dataset, respectively. Thus, a different approach was proposed that is based on the concept of automated machine learning. It works by automatically searching for the optimal model type and optimizes its hyperparameters for the dataset under investigation. This approach selected a Gaussian process regression (GPR) model for accurate estimation of PEF values. The developed GPR model decreases the AAPE of the predicted PEF values in the testing dataset to about 10% AAPE. This error could be further decreased to about 2% by modeling the potential noise in the measurements using the GPR model. ",
    "url": "https://arxiv.org/abs/2206.08950",
    "authors": [
      "Khalid L. Alsamadony",
      "Ahmed Farid Ibrahim",
      "Salaheldin Elkatatny",
      "Abdulazeez Abdulraheem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2206.08952",
    "title": "The Impact of Variable Ordering on Bayesian Network Structure Learning",
    "abstract": "Causal Bayesian Networks provide an important tool for reasoning under uncertainty with potential application to many complex causal systems. Structure learning algorithms that can tell us something about the causal structure of these systems are becoming increasingly important. In the literature, the validity of these algorithms is often tested for sensitivity over varying sample sizes, hyper-parameters, and occasionally objective functions. In this paper, we show that the order in which the variables are read from data can have much greater impact on the accuracy of the algorithm than these factors. Because the variable ordering is arbitrary, any significant effect it has on learnt graph accuracy is concerning, and this raises questions about the validity of the results produced by algorithms that are sensitive to, but have not been assessed against, different variable orderings. ",
    "url": "https://arxiv.org/abs/2206.08952",
    "authors": [
      "Neville K Kitson",
      "Anthony C Constantinou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08954",
    "title": "Intra-Instance VICReg: Bag of Self-Supervised Image Patch Embedding",
    "abstract": "Recently, self-supervised learning (SSL) has achieved tremendous empirical advancements in learning image representation. However, our understanding and knowledge of the representation are still limited. This work shows that the success of the SOTA siamese-network-based SSL approaches is primarily based on learning a representation of image patches. Particularly, we show that when we learn a representation only for fixed-scale image patches and aggregate different patch representations linearly for an image (instance), it can achieve on par or even better results than the baseline methods on several benchmarks. Further, we show that the patch representation aggregation can also improve various SOTA baseline methods by a large margin. We also establish a formal connection between the SSL objective and the image patches co-occurrence statistics modeling, which supplements the prevailing invariance perspective. By visualizing the nearest neighbors of different image patches in the embedding space and projection space, we show that while the projection has more invariance, the embedding space tends to preserve more equivariance and locality. Finally, we propose a hypothesis for the future direction based on the discovery of this work. ",
    "url": "https://arxiv.org/abs/2206.08954",
    "authors": [
      "Yubei Chen",
      "Adrien Bardes",
      "Zengyi Li",
      "Yann LeCun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08980",
    "title": "Explainable Global Error Weighted on Feature Importance: The xGEWFI  metric to evaluate the error of data imputation and data augmentation",
    "abstract": "Evaluating the performance of an algorithm is crucial. Evaluating the performance of data imputation and data augmentation can be similar since both generated data can be compared with an original distribution. Although, the typical evaluation metrics have the same flaw: They calculate the feature's error and the global error on the generated data without weighting the error with the feature importance. The result can be good if all of the feature's importance is similar. However, in most cases, the importance of the features is imbalanced, and it can induce an important bias on the features and global errors. This paper proposes a novel metric named \"Explainable Global Error Weighted on Feature Importance\"(xGEWFI). This new metric is tested in a whole preprocessing method that 1. detects the outliers and replaces them with a null value. 2. imputes the data missing, and 3. augments the data. At the end of the process, the xGEWFI error is calculated. The distribution error between the original and generated data is calculated using a Kolmogorov-Smirnov test (KS test) for each feature. Those results are multiplied by the importance of the respective features, calculated using a Random Forest (RF) algorithm. The metric result is expressed in an explainable format, aiming for an ethical AI. ",
    "url": "https://arxiv.org/abs/2206.08980",
    "authors": [
      "Jean-S\u00e9bastien Dessureault",
      "Daniel Massicotte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08996",
    "title": "Towards Consensus: Reducing Polarization by Perturbing Social Networks",
    "abstract": "This paper studies how a centralized planner can modify the structure of a social or information network to reduce polarization. First, polarization is found to be highly dependent on degree and structural properties of the network. We then formulate the planner's problem under full information, and motivate disagreement-seeking and coordinate descent heuristics. A novel setting for the planner in which the population's innate opinions are adversarially chosen is introduced, and shown to be equivalent to maximization of the Laplacian's spectral gap. We prove bounds for the effectiveness of a strategy that adds edges between vertices on opposite sides of the cut induced by the spectral gap's eigenvector. Finally, these strategies are evaluated on six real-world and synthetic networks. In several networks, we find that polarization can be significantly reduced through the addition of a small number of edges. ",
    "url": "https://arxiv.org/abs/2206.08996",
    "authors": [
      "Miklos Z. Racz",
      "Daniel E. Rigobon"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2206.09011",
    "title": "Evolutionary Random Graph for Bitcoin Overlay and Blockchain Mining  Networks",
    "abstract": "The world economy is experiencing the novel adoption of distributed currencies that are free from the control of central banks. Distributed currencies suffer from extreme volatility, and this can lead to catastrophic implications during future economic crisis. Understanding the dynamics of this new type of currencies is vital for empowering supervisory bodies from current reactive and manual incident responders to more proactive and well-informed planners. Bitcoin, the first and dominant distributed cryptocurrency, is still notoriously vague, especially for a financial instrument with market value exceeding 1 trillion. Modeling of bitcoin overlay network poses a number of important theoretical and methodological challenges. Current measuring approaches, for example, fail to identify the real network size of bitcoin miners. This drastically undermines the ability to predict forks, the suitable mining difficulty and most importantly the resilience of the network supporting bitcoin. In this work, we developed Evolutionary Random Graph, a theoretical model that describes the network of bitcoin miners. The correctness of this model has been validated using simulated and measure real bitcoin data. We then predicted forking, optimal mining difficulty, network size and consequently the network's inability to stand a drastic drop in bitcoin price using the current mining configuration. ",
    "url": "https://arxiv.org/abs/2206.09011",
    "authors": [
      "Jacques Bou Abdo",
      "Shuvalaxmi Dass",
      "Basheer Qolomany",
      "Liaquat Hossain"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.09027",
    "title": "Landscape Learning for Neural Network Inversion",
    "abstract": "Many machine learning methods operate by inverting a neural network at inference time, which has become a popular technique for solving inverse problems in computer vision, robotics, and graphics. However, these methods often involve gradient descent through a highly non-convex loss landscape, causing the optimization process to be unstable and slow. We introduce a method that learns a loss landscape where gradient descent is efficient, bringing massive improvement and acceleration to the inversion process. We demonstrate this advantage on a number of methods for both generative and discriminative tasks, including GAN inversion, adversarial defense, and 3D human pose reconstruction. ",
    "url": "https://arxiv.org/abs/2206.09027",
    "authors": [
      "Ruoshi Liu",
      "Chengzhi Mao",
      "Purva Tendulkar",
      "Hao Wang",
      "Carl Vondrick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09029",
    "title": "Binary Early-Exit Network for Adaptive Inference on Low-Resource Devices",
    "abstract": "Deep neural networks have significantly improved performance on a range of tasks with the increasing demand for computational resources, leaving deployment on low-resource devices (with limited memory and battery power) infeasible. Binary neural networks (BNNs) tackle the issue to an extent with extreme compression and speed-up gains compared to real-valued models. We propose a simple but effective method to accelerate inference through unifying BNNs with an early-exiting strategy. Our approach allows simple instances to exit early based on a decision threshold and utilizes output layers added to different intermediate layers to avoid executing the entire binary model. We extensively evaluate our method on three audio classification tasks and across four BNNs architectures. Our method demonstrates favorable quality-efficiency trade-offs while being controllable with an entropy-based threshold specified by the system user. It also results in better speed-ups (latency less than 6ms) with a single model based on existing BNN architectures without retraining for different efficiency levels. It also provides a straightforward way to estimate sample difficulty and better understanding of uncertainty around certain classes within the dataset. ",
    "url": "https://arxiv.org/abs/2206.09029",
    "authors": [
      "Aaqib Saeed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09030",
    "title": "Responsibility-associated Multi-agent Collision Avoidance with Social  Preferences",
    "abstract": "This paper introduces a novel social preference-aware decentralized safe control framework to address the responsibility allocation problem in multi-agent collision avoidance. Considering that agents do not necessarily cooperate in symmetric ways, this paper focuses on semi-cooperative behavior among heterogeneous agents with varying cooperation levels. Drawing upon the idea of Social Value Orientation (SVO) for quantifying the individual selfishness, we propose a novel concept of Responsibility-associated Social Value Orientation (R-SVO) to express the intended relative social implications between pairwise agents. This is used to redefine each agent's social preferences or personalities in terms of corresponding responsibility shares in contributing to the coordination scenario, such as semi-cooperative collision avoidance where all agents interact in an asymmetric way. By incorporating such relative social implications through proposed Local Pairwise Responsibility Weights, we develop a Responsibility-associated Control Barrier Function-based safe control framework for individual agents, and multi-agent collision avoidance is achieved with formally provable safety guarantees. Simulations are provided to demonstrate the effectiveness and efficiency of the proposed framework in several multi-agent navigation tasks, such as a position-swapping game, a self-driving car highway ramp merging scenario, and a circular position swapping game. ",
    "url": "https://arxiv.org/abs/2206.09030",
    "authors": [
      "Yiwei Lyu",
      "Wenhao Luo",
      "John M. Dolan"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.09055",
    "title": "Augmented Imagefication: A Data-driven Fault Detection Method for  Aircraft Air Data Sensors",
    "abstract": "In this paper, a novel data-driven approach named Augmented Imagefication for Fault detection (FD) of aircraft air data sensors (ADS) is proposed. Exemplifying the FD problem of aircraft air data sensors, an online FD scheme on edge device based on deep neural network (DNN) is developed. First, the aircraft inertial reference unit measurements is adopted as equivalent inputs, which is scalable to different aircraft/flight cases. Data associated with 6 different aircraft/flight conditions are collected to provide diversity (scalability) in the training/testing database. Then Augmented Imagefication is proposed for the DNN-based prediction of flying conditions. The raw data are reshaped as a grayscale image for convolutional operation, and the necessity of augmentation is analyzed and pointed out. Different kinds of augmented method, i.e. Flip, Repeat, Tile and their combinations are discussed, the result shows that the All Repeat operation in both axes of image matrix leads to the best performance of DNN. The interpretability of DNN is studied based on Grad-CAM, which provide a better understanding and further solidifies the robustness of DNN. Next the DNN model, VGG-16 with augmented imagefication data is optimized for mobile hardware deployment. After pruning of DNN, a lightweight model (98.79% smaller than original VGG-16) with high accuracy (slightly up by 0.27%) and fast speed (time delay is reduced by 87.54%) is obtained. And the hyperparameters optimization of DNN based on TPE is implemented and the best combination of hyperparameters is determined (learning rate 0.001, iterative epochs 600, and batch size 100 yields the highest accuracy at 0.987). Finally, a online FD deployment based on edge device, Jetson Nano, is developed and the real time monitoring of aircraft is achieved. We believe that this method is instructive for addressing the FD problems in other similar fields. ",
    "url": "https://arxiv.org/abs/2206.09055",
    "authors": [
      "Hang Zhao",
      "Jinyi Ma",
      "Zhongzhi Li",
      "Yiqun Dong",
      "Jianliang Ai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.09082",
    "title": "Context-aware Proposal Network for Temporal Action Detection",
    "abstract": "This technical report presents our first place winning solution for temporal action detection task in CVPR-2022 AcitivityNet Challenge. The task aims to localize temporal boundaries of action instances with specific classes in long untrimmed videos. Recent mainstream attempts are based on dense boundary matchings and enumerate all possible combinations to produce proposals. We argue that the generated proposals contain rich contextual information, which may benefits detection confidence prediction. To this end, our method mainly consists of the following three steps: 1) action classification and feature extraction by Slowfast, CSN, TimeSformer, TSP, I3D-flow, VGGish-audio, TPN and ViViT; 2) proposal generation. Our proposed Context-aware Proposal Network (CPN) builds on top of BMN, GTAD and PRN to aggregate contextual information by randomly masking some proposal features. 3) action detection. The final detection prediction is calculated by assigning the proposals with corresponding video-level classifcation results. Finally, we ensemble the results under different feature combination settings and achieve 45.8% performance on the test set, which improves the champion result in CVPR-2021 ActivityNet Challenge by 1.1% in terms of average mAP. ",
    "url": "https://arxiv.org/abs/2206.09082",
    "authors": [
      "Xiang Wang",
      "Huaxin Zhang",
      "Shiwei Zhang",
      "Changxin Gao",
      "Yuanjie Shao",
      "Nong Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09097",
    "title": "Fully Privacy-Preserving Federated Representation Learning via Secure  Embedding Aggregation",
    "abstract": "We consider a federated representation learning framework, where with the assistance of a central server, a group of $N$ distributed clients train collaboratively over their private data, for the representations (or embeddings) of a set of entities (e.g., users in a social network). Under this framework, for the key step of aggregating local embeddings trained at the clients in a private manner, we develop a secure embedding aggregation protocol named SecEA, which provides information-theoretical privacy guarantees for the set of entities and the corresponding embeddings at each client $simultaneously$, against a curious server and up to $T < N/2$ colluding clients. As the first step of SecEA, the federated learning system performs a private entity union, for each client to learn all the entities in the system without knowing which entities belong to which clients. In each aggregation round, the local embeddings are secretly shared among the clients using Lagrange interpolation, and then each client constructs coded queries to retrieve the aggregated embeddings for the intended entities. We perform comprehensive experiments on various representation learning tasks to evaluate the utility and efficiency of SecEA, and empirically demonstrate that compared with embedding aggregation protocols without (or with weaker) privacy guarantees, SecEA incurs negligible performance loss (within 5%); and the additional computation latency of SecEA diminishes for training deeper models on larger datasets. ",
    "url": "https://arxiv.org/abs/2206.09097",
    "authors": [
      "Jiaxiang Tang",
      "Jinbao Zhu",
      "Songze Li",
      "Kai Zhang",
      "Lichao Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2206.09098",
    "title": "Existence and Minimax Theorems for Adversarial Surrogate Risks in Binary  Classification",
    "abstract": "Adversarial training is one of the most popular methods for training methods robust to adversarial attacks, however, it is not well-understood from a theoretical perspective. We prove and existence, regularity, and minimax theorems for adversarial surrogate risks. Our results explain some empirical observations on adversarial robustness from prior work and suggest new directions in algorithm development. Furthermore, our results extend previously known existence and minimax theorems for the adversarial classification risk to surrogate risks. ",
    "url": "https://arxiv.org/abs/2206.09098",
    "authors": [
      "Natalie S. Frank"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2206.09099",
    "title": "The Consistency of Adversarial Training for Binary Classification",
    "abstract": "Robustness to adversarial perturbations is of paramount concern in modern machine learning. One of the state-of-the-art methods for training robust classifiers is adversarial training, which involves minimizing a supremum-based surrogate risk. The statistical consistency of surrogate risks is well understood in the context of standard machine learning, but not in the adversarial setting. In this paper, we characterize which supremum-based surrogates are consistent for distributions absolutely continuous with respect to Lebesgue measure in binary classification. Furthermore, we obtain quantitative bounds relating adversarial surrogate risks to the adversarial classification risk. Lastly, we discuss implications for the $\\cH$-consistency of adversarial training. ",
    "url": "https://arxiv.org/abs/2206.09099",
    "authors": [
      "Natalie S. Frank",
      "Jonathan Niles-Weed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2206.09111",
    "title": "VReBERT: A Simple and Flexible Transformer for Visual Relationship  Detection",
    "abstract": "Visual Relationship Detection (VRD) impels a computer vision model to 'see' beyond an individual object instance and 'understand' how different objects in a scene are related. The traditional way of VRD is first to detect objects in an image and then separately predict the relationship between the detected object instances. Such a disjoint approach is prone to predict redundant relationship tags (i.e., predicate) between the same object pair with similar semantic meaning, or incorrect ones that have a similar meaning to the ground truth but are semantically incorrect. To remedy this, we propose to jointly train a VRD model with visual object features and semantic relationship features. To this end, we propose VReBERT, a BERT-like transformer model for Visual Relationship Detection with a multi-stage training strategy to jointly process visual and semantic features. We show that our simple BERT-like model is able to outperform the state-of-the-art VRD models in predicate prediction. Furthermore, we show that by using the pre-trained VReBERT model, our model pushes the state-of-the-art zero-shot predicate prediction by a significant margin (+8.49 R@50 and +8.99 R@100). ",
    "url": "https://arxiv.org/abs/2206.09111",
    "authors": [
      "Yu Cui",
      "Moshiur Farazi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.09112",
    "title": "Decoupled Dynamic Spatial-Temporal Graph Neural Network for Traffic  Forecasting",
    "abstract": "We all depend on mobility, and vehicular transportation affects the daily lives of most of us. Thus, the ability to forecast the state of traffic in a road network is an important functionality and a challenging task. Traffic data is often obtained from sensors deployed in a road network. Recent proposals on spatial-temporal graph neural networks have achieved great progress at modeling complex spatial-temporal correlations in traffic data, by modeling traffic data as a diffusion process. However, intuitively, traffic data encompasses two different kinds of hidden time series signals, namely the diffusion signals and inherent signals. Unfortunately, nearly all previous works coarsely consider traffic signals entirely as the outcome of the diffusion, while neglecting the inherent signals, which impacts model performance negatively. To improve modeling performance, we propose a novel Decoupled Spatial-Temporal Framework (DSTF) that separates the diffusion and inherent traffic information in a data-driven manner, which encompasses a unique estimation gate and a residual decomposition mechanism. The separated signals can be handled subsequently by the diffusion and inherent modules separately. Further, we propose an instantiation of DSTF, Decoupled Dynamic Spatial-Temporal Graph Neural Network (D2STGNN), that captures spatial-temporal correlations and also features a dynamic graph learning module that targets the learning of the dynamic characteristics of traffic networks. Extensive experiments with four real-world traffic datasets demonstrate that the framework is capable of advancing the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2206.09112",
    "authors": [
      "Zezhi Shao",
      "Zhao Zhang",
      "Wei Wei",
      "Fei Wang",
      "Yongjun Xu",
      "Xin Cao",
      "Christian S. Jensen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09113",
    "title": "Pre-training Enhanced Spatial-temporal Graph Neural Network for  Multivariate Time Series Forecasting",
    "abstract": "Multivariate Time Series (MTS) forecasting plays a vital role in a wide range of applications. Recently, Spatial-Temporal Graph Neural Networks (STGNNs) have become increasingly popular MTS forecasting methods. STGNNs jointly model the spatial and temporal patterns of MTS through graph neural networks and sequential models, significantly improving the prediction accuracy. But limited by model complexity, most STGNNs only consider short-term historical MTS data, such as data over the past one hour. However, the patterns of time series and the dependencies between them (i.e., the temporal and spatial patterns) need to be analyzed based on long-term historical MTS data. To address this issue, we propose a novel framework, in which STGNN is Enhanced by a scalable time series Pre-training model (STEP). Specifically, we design a pre-training model to efficiently learn temporal patterns from very long-term history time series (e.g., the past two weeks) and generate segment-level representations. These representations provide contextual information for short-term time series input to STGNNs and facilitate modeling dependencies between time series. Experiments on three public real-world datasets demonstrate that our framework is capable of significantly enhancing downstream STGNNs, and our pre-training model aptly captures temporal patterns. ",
    "url": "https://arxiv.org/abs/2206.09113",
    "authors": [
      "Zezhi Shao",
      "Zhao Zhang",
      "Fei Wang",
      "Yongjun Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09116",
    "title": "Person-job fit estimation from candidate profile and related recruitment  history with co-attention neural networks",
    "abstract": "Existing online recruitment platforms depend on automatic ways of conducting the person-job fit, whose goal is matching appropriate job seekers with job positions. Intuitively, the previous successful recruitment records contain important information, which should be helpful for the current person-job fit. Existing studies on person-job fit, however, mainly focus on calculating the similarity between the candidate resumes and the job postings on the basis of their contents, without taking the recruiters' experience (i.e., historical successful recruitment records) into consideration. In this paper, we propose a novel neural network approach for person-job fit, which estimates person-job fit from candidate profile and related recruitment history with co-attention neural networks (named PJFCANN). Specifically, given a target resume-job post pair, PJFCANN generates local semantic representations through co-attention neural networks and global experience representations via graph neural networks. The final matching degree is calculated by combining these two representations. In this way, the historical successful recruitment records are introduced to enrich the features of resumes and job postings and strengthen the current matching process. Extensive experiments conducted on a large-scale recruitment dataset verify the effectiveness of PJFCANN compared with several state-of-the-art baselines. The codes are released at: https://github.com/CCIIPLab/PJFCANN. ",
    "url": "https://arxiv.org/abs/2206.09116",
    "authors": [
      "Ziyang Wang",
      "Wei Wei",
      "Chenwei Xu",
      "Jun Xu",
      "Xian-Ling Mao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.09117",
    "title": "NISPA: Neuro-Inspired Stability-Plasticity Adaptation for Continual  Learning in Sparse Networks",
    "abstract": "The goal of continual learning (CL) is to learn different tasks over time. The main desiderata associated with CL are to maintain performance on older tasks, leverage the latter to improve learning of future tasks, and to introduce minimal overhead in the training process (for instance, to not require a growing model or retraining). We propose the Neuro-Inspired Stability-Plasticity Adaptation (NISPA) architecture that addresses these desiderata through a sparse neural network with fixed density. NISPA forms stable paths to preserve learned knowledge from older tasks. Also, NISPA uses connection rewiring to create new plastic paths that reuse existing knowledge on novel tasks. Our extensive evaluation on EMNIST, FashionMNIST, CIFAR10, and CIFAR100 datasets shows that NISPA significantly outperforms representative state-of-the-art continual learning baselines, and it uses up to ten times fewer learnable parameters compared to baselines. We also make the case that sparsity is an essential ingredient for continual learning. The NISPA code is available at https://github.com/BurakGurbuz97/NISPA. ",
    "url": "https://arxiv.org/abs/2206.09117",
    "authors": [
      "Mustafa Burak Gurbuz",
      "Constantine Dovrolis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09122",
    "title": "Measuring Lower Bounds of Local Differential Privacy via Adversary  Instantiations in Federated Learning",
    "abstract": "Local differential privacy (LDP) gives a strong privacy guarantee to be used in a distributed setting like federated learning (FL). LDP mechanisms in FL protect a client's gradient by randomizing it on the client; however, how can we interpret the privacy level given by the randomization? Moreover, what types of attacks can we mitigate in practice? To answer these questions, we introduce an empirical privacy test by measuring the lower bounds of LDP. The privacy test estimates how an adversary predicts if a reported randomized gradient was crafted from a raw gradient $g_1$ or $g_2$. We then instantiate six adversaries in FL under LDP to measure empirical LDP at various attack surfaces, including a worst-case attack that reaches the theoretical upper bound of LDP. The empirical privacy test with the adversary instantiations enables us to interpret LDP more intuitively and discuss relaxation of the privacy parameter until a particular instantiated attack surfaces. We also demonstrate numerical observations of the measured privacy in these adversarial settings, and the worst-case attack is not realistic in FL. In the end, we also discuss the possible relaxation of privacy levels in FL under LDP. ",
    "url": "https://arxiv.org/abs/2206.09122",
    "authors": [
      "Marin Matsumoto",
      "Tsubasa Takahashi",
      "Seng Pei Liew",
      "Masato Oguchi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.09140",
    "title": "Certified Graph Unlearning",
    "abstract": "Graph-structured data is ubiquitous in practice and often processed using graph neural networks (GNNs). With the adoption of recent laws ensuring the ``right to be forgotten'', the problem of graph data removal has become of significant importance. To address the problem, we introduce the first known framework for \\emph{certified graph unlearning} of GNNs. In contrast to standard machine unlearning, new analytical and heuristic unlearning challenges arise when dealing with complex graph data. First, three different types of unlearning requests need to be considered, including node feature, edge and node unlearning. Second, to establish provable performance guarantees, one needs to address challenges associated with feature mixing during propagation. The underlying analysis is illustrated on the example of simple graph convolutions (SGC) and their generalized PageRank (GPR) extensions, thereby laying the theoretical foundation for certified unlearning of GNNs. Our empirical studies on six benchmark datasets demonstrate excellent performance-complexity trade-offs when compared to complete retraining methods and approaches that do not leverage graph information. For example, when unlearning $20\\%$ of the nodes on the Cora dataset, our approach suffers only a $0.1\\%$ loss in test accuracy while offering a $4$-fold speed-up compared to complete retraining. Our scheme also outperforms unlearning methods that do not leverage graph information with a $12\\%$ increase in test accuracy for a comparable time complexity. ",
    "url": "https://arxiv.org/abs/2206.09140",
    "authors": [
      "Eli Chien",
      "Chao Pan",
      "Olgica Milenkovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09149",
    "title": "Piecewise Linear Neural Networks and Deep Learning",
    "abstract": "As a powerful modelling method, PieceWise Linear Neural Networks (PWLNNs) have proven successful in various fields, most recently in deep learning. To apply PWLNN methods, both the representation and the learning have long been studied. In 1977, the canonical representation pioneered the works of shallow PWLNNs learned by incremental designs, but the applications to large-scale data were prohibited. In 2010, the Rectified Linear Unit (ReLU) advocated the prevalence of PWLNNs in deep learning. Ever since, PWLNNs have been successfully applied to extensive tasks and achieved advantageous performances. In this Primer, we systematically introduce the methodology of PWLNNs by grouping the works into shallow and deep networks. Firstly, different PWLNN representation models are constructed with elaborated examples. With PWLNNs, the evolution of learning algorithms for data is presented and fundamental theoretical analysis follows up for in-depth understandings. Then, representative applications are introduced together with discussions and outlooks. ",
    "url": "https://arxiv.org/abs/2206.09149",
    "authors": [
      "Qinghua Tao",
      "Li Li",
      "Xiaolin Huang",
      "Xiangming Xi",
      "Shuning Wang",
      "Johan A.K. Suykens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09153",
    "title": "Markov Chain Approaches to Payoff Optimization in the Self-Organizing  Network Coloring Game",
    "abstract": "The model of Network Coloring Game (NCG) is used to simulate conflict resolving and consensus reaching procedures in social science. In this work, we adopted some Markov Chain Techniques into the investigation of NCG. Firstly, with no less than $\\Delta + 2$ colors provided, we proposed and proved that the conflict resolving time has its expectation to be $O(\\log n)$ and the variance $O((\\log n)^2)$, thus is $O_p(\\log n)$, where $n$ is the number of vertices and $\\Delta$ is the maximum degree of the network. This was done by introducing an absorbing Markov Chain into NCG. Secondly, we developed an algorithms to reduce the network in post-conflict-resolution adjustments when a Borda rule is applied among players. Markov Chain Monte Carlo methods were employed to estimate both local and global optimal payoffs. Supporting experimental results were given to illustrate the corresponding procedures. ",
    "url": "https://arxiv.org/abs/2206.09153",
    "authors": [
      "Zeyi Chen"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computer Science and Game Theory (cs.GT)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.09161",
    "title": "A Marriage between Adversarial Team Games and 2-player Games: Enabling  Abstractions, No-regret Learning, and Subgame Solving",
    "abstract": "\\emph{Ex ante} correlation is becoming the mainstream approach for \\emph{sequential adversarial team games}, where a team of players faces another team in a zero-sum game. It is known that team members' asymmetric information makes both equilibrium computation \\textsf{APX}-hard and team's strategies not directly representable on the game tree. This latter issue prevents the adoption of successful tools for huge 2-player zero-sum games such as, \\emph{e.g.}, abstractions, no-regret learning, and subgame solving. This work shows that we can recover from this weakness by bridging the gap between sequential adversarial team games and 2-player games. In particular, we propose a new, suitable game representation that we call \\emph{team-public-information}, in which a team is represented as a single coordinator who only knows information common to the whole team and prescribes to each member an action for any possible private state. The resulting representation is highly \\emph{explainable}, being a 2-player tree in which the team's strategies are behavioral with a direct interpretation and more expressive than the original extensive form when designing abstractions. Furthermore, we prove payoff equivalence of our representation, and we provide techniques that, starting directly from the extensive form, generate dramatically more compact representations without information loss. Finally, we experimentally evaluate our techniques when applied to a standard testbed, comparing their performance with the current state of the art. ",
    "url": "https://arxiv.org/abs/2206.09161",
    "authors": [
      "Luca Carminati",
      "Federico Cacciamani",
      "Marco Ciccone",
      "Nicola Gatti"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2206.09166",
    "title": "NAS-Bench-Graph: Benchmarking Graph Neural Architecture Search",
    "abstract": "Graph neural architecture search (GraphNAS) has recently aroused considerable attention in both academia and industry. However, two key challenges seriously hinder the further research of GraphNAS. First, since there is no consensus for the experimental setting, the empirical results in different research papers are often not comparable and even not reproducible, leading to unfair comparisons. Secondly, GraphNAS often needs extensive computations, which makes it highly inefficient and inaccessible to researchers without access to large-scale computation. To solve these challenges, we propose NAS-Bench-Graph, a tailored benchmark that supports unified, reproducible, and efficient evaluations for GraphNAS. Specifically, we construct a unified, expressive yet compact search space, covering 26,206 unique graph neural network (GNN) architectures and propose a principled evaluation protocol. To avoid unnecessary repetitive training, we have trained and evaluated all of these architectures on nine representative graph datasets, recording detailed metrics including train, validation, and test performance in each epoch, the latency, the number of parameters, etc. Based on our proposed benchmark, the performance of GNN architectures can be directly obtained by a look-up table without any further computation, which enables fair, fully reproducible, and efficient comparisons. To demonstrate its usage, we make in-depth analyses of our proposed NAS-Bench-Graph, revealing several interesting findings for GraphNAS. We also showcase how the benchmark can be easily compatible with GraphNAS open libraries such as AutoGL and NNI. To the best of our knowledge, our work is the first benchmark for graph neural architecture search. ",
    "url": "https://arxiv.org/abs/2206.09166",
    "authors": [
      "Yijian Qin",
      "Ziwei Zhang",
      "Xin Wang",
      "Zeyang Zhang",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09182",
    "title": "Coin Flipping Neural Networks",
    "abstract": "We show that neural networks with access to randomness can outperform deterministic networks by using amplification. We call such networks Coin-Flipping Neural Networks, or CFNNs. We show that a CFNN can approximate the indicator of a $d$-dimensional ball to arbitrary accuracy with only 2 layers and $\\mathcal{O}(1)$ neurons, where a 2-layer deterministic network was shown to require $\\Omega(e^d)$ neurons, an exponential improvement (arXiv:1610.09887 [cs.LG]). We prove a highly non-trivial result, that for almost any classification problem, there exists a trivially simple network that solves it given a sufficiently powerful generator for the network's weights. Combining these results we conjecture that for most classification problems, there is a CFNN which solves them with higher accuracy or fewer neurons than any deterministic network. Finally, we verify our proofs experimentally using novel CFNN architectures on CIFAR10 and CIFAR100, reaching an improvement of 9.25\\% from the baseline. ",
    "url": "https://arxiv.org/abs/2206.09182",
    "authors": [
      "Yuval Sieradzki",
      "Nitzan Hodos",
      "Gal Yehuda",
      "Assaf Schuster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09184",
    "title": "PHN: Parallel heterogeneous network with soft gating for CTR prediction",
    "abstract": "The Click-though Rate (CTR) prediction task is a basic task in recommendation system. Most of the previous researches of CTR models built based on Wide \\& deep structure and gradually evolved into parallel structures with different modules. However, the simple accumulation of parallel structures can lead to higher structural complexity and longer training time. Based on the Sigmoid activation function of output layer, the linear addition activation value of parallel structures in the training process is easy to make the samples fall into the weak gradient interval, resulting in the phenomenon of weak gradient, and reducing the effectiveness of training. To this end, this paper proposes a Parallel Heterogeneous Network (PHN) model, which constructs a network with parallel structure through three different interaction analysis methods, and uses Soft Selection Gating (SSG) to feature heterogeneous data with different structure. Finally, residual link with trainable parameters are used in the network to mitigate the influence of weak gradient phenomenon. Furthermore, we demonstrate the effectiveness of PHN in a large number of comparative experiments, and visualize the performance of the model in training process and structure. ",
    "url": "https://arxiv.org/abs/2206.09184",
    "authors": [
      "Ri Su",
      "Alphonse Houssou Hounye",
      "Cong Cao",
      "Muzhou Hou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2206.09186",
    "title": "Causal Inference with Treatment Measurement Error: A Nonparametric  Instrumental Variable Approach",
    "abstract": "We propose a kernel-based nonparametric estimator for the causal effect when the cause is corrupted by error. We do so by generalizing estimation in the instrumental variable setting. Despite significant work on regression with measurement error, additionally handling unobserved confounding in the continuous setting is non-trivial: we have seen little prior work. As a by-product of our investigation, we clarify a connection between mean embeddings and characteristic functions, and how learning one simultaneously allows one to learn the other. This opens the way for kernel method research to leverage existing results in characteristic function estimation. Finally, we empirically show that our proposed method, MEKIV, improves over baselines and is robust under changes in the strength of measurement error and to the type of error distributions. ",
    "url": "https://arxiv.org/abs/2206.09186",
    "authors": [
      "Yuchen Zhu",
      "Limor Gultchin",
      "Arthur Gretton",
      "Matt Kusner",
      "Ricardo Silva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2206.09214",
    "title": "An Invertible Graph Diffusion Neural Network for Source Localization",
    "abstract": "Localizing the source of graph diffusion phenomena, such as misinformation propagation, is an important yet extremely challenging task. Existing source localization models typically are heavily dependent on the hand-crafted rules. Unfortunately, a large portion of the graph diffusion process for many applications is still unknown to human beings so it is important to have expressive models for learning such underlying rules automatically. This paper aims to establish a generic framework of invertible graph diffusion models for source localization on graphs, namely Invertible Validity-aware Graph Diffusion (IVGD), to handle major challenges including 1) Difficulty to leverage knowledge in graph diffusion models for modeling their inverse processes in an end-to-end fashion, 2) Difficulty to ensure the validity of the inferred sources, and 3) Efficiency and scalability in source inference. Specifically, first, to inversely infer sources of graph diffusion, we propose a graph residual scenario to make existing graph diffusion models invertible with theoretical guarantees; second, we develop a novel error compensation mechanism that learns to offset the errors of the inferred sources. Finally, to ensure the validity of the inferred sources, a new set of validity-aware layers have been devised to project inferred sources to feasible regions by flexibly encoding constraints with unrolled optimization techniques. A linearization technique is proposed to strengthen the efficiency of our proposed layers. The convergence of the proposed IVGD is proven theoretically. Extensive experiments on nine real-world datasets demonstrate that our proposed IVGD outperforms state-of-the-art comparison methods significantly. We have released our code at https://github.com/xianggebenben/IVGD. ",
    "url": "https://arxiv.org/abs/2206.09214",
    "authors": [
      "Junxiang Wang",
      "Junji Jiang",
      "Liang Zhao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09215",
    "title": "Mind the Gap: Norm-Aware Adaptive Robust Loss for Multivariate  Least-Squares Problems",
    "abstract": "Measurement outliers are unavoidable when solving real-world robot state estimation problems. A large family of robust loss functions (RLFs) exists to mitigate the effects of outliers, including newly developed adaptive methods that do not require parameter tuning. All of these methods assume that residuals follow a zero-mean Gaussian-like distribution. However, in multivariate problems the residual is often defined as a norm, and norms follow a Chi-like distribution with a non-zero mode value. This produces a ''mode gap'' that impacts the convergence rate and accuracy of existing RLFs. The proposed approach, ''Adaptive MB,'' accounts for this gap by first estimating the mode of the residuals using an adaptive Chi-like distribution. Applying an existing adaptive weighting scheme only to residuals greater than the mode leads to more robust performance and faster convergence times in two fundamental state estimation problems, point cloud alignment and pose averaging. ",
    "url": "https://arxiv.org/abs/2206.09215",
    "authors": [
      "Thomas Hitchcox",
      "James Richard Forbes"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.09221",
    "title": "3D Face Parsing via Surface Parameterization and 2D Semantic  Segmentation Network",
    "abstract": "Face parsing assigns pixel-wise semantic labels as the face representation for computers, which is the fundamental part of many advanced face technologies. Compared with 2D face parsing, 3D face parsing shows more potential to achieve better performance and further application, but it is still challenging due to 3D mesh data computation. Recent works introduced different methods for 3D surface segmentation, while the performance is still limited. In this paper, we propose a method based on the \"3D-2D-3D\" strategy to accomplish 3D face parsing. The topological disk-like 2D face image containing spatial and textural information is transformed from the sampled 3D face data through the face parameterization algorithm, and a specific 2D network called CPFNet is proposed to achieve the semantic segmentation of the 2D parameterized face data with multi-scale technologies and feature aggregation. The 2D semantic result is then inversely re-mapped to 3D face data, which finally achieves the 3D face parsing. Experimental results show that both CPFNet and the \"3D-2D-3D\" strategy accomplish high-quality 3D face parsing and outperform state-of-the-art 2D networks as well as 3D methods in both qualitative and quantitative comparisons. ",
    "url": "https://arxiv.org/abs/2206.09221",
    "authors": [
      "Wenyuan Sun",
      "Ping Zhou",
      "Yangang Wang",
      "Zongpu Yu",
      "Jing Jin",
      "Guangquan Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09229",
    "title": "Digital Surveillance Networks of 2014 Ebola Epidemics and Lessons for  COVID-19",
    "abstract": "2014 Ebola outbreaks can offer lessons for the COVOID-19 and the ongoing variant surveillance and the use of multi method approach to detect public health preparedness. We are increasingly seeing a delay and disconnect of the transmission of locally situated information to the hierarchical system for making the overall preparedness and response more proactive than reactive for dealing with emergencies such as 2014 Ebola. For our COVID-19, it is timely to consider whether digital surveillance networks and support systems can be used to bring the formal and community based ad hoc networks required for facilitating the transmission of both strong (i.e., infections, confirmed cases, deaths in hospital or clinic settings) and weak alters from the community. This will allow timely detection of symptoms of isolated suspected cases for making the overall surveillance and intervention strategy far more effective. The use of digital surveillance networks can further contribute to the development of global awareness of complex emergencies such as Ebola for constructing information infrastructure required to develop, monitor and analysis of community based global emergency surveillance in developed and developing countries. In this study, a systematic analysis of the spread during the months of March to October 2014 was performed using data from the Program for Monitoring Emerging Diseases (ProMED) and the Factiva database. Using digital surveillance networks, we aim to draw network connections of individuals/groups from a localized to a globalized transmission of Ebola using reported suspected/probable/confirmed cases at different locations around the world. We argue that public health preparedness and response can be strengthened by understanding the social network connections between responders (such as local health authorities) and spreaders (infected individuals and groups). ",
    "url": "https://arxiv.org/abs/2206.09229",
    "authors": [
      "Liaquat Hossain",
      "Fiona Kong",
      "Derek Kham"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2206.09238",
    "title": "On the Role of Generalization in Transferability of Adversarial Examples",
    "abstract": "Black-box adversarial attacks designing adversarial examples for unseen neural networks (NNs) have received great attention over the past years. While several successful black-box attack schemes have been proposed in the literature, the underlying factors driving the transferability of black-box adversarial examples still lack a thorough understanding. In this paper, we aim to demonstrate the role of the generalization properties of the substitute classifier used for generating adversarial examples in the transferability of the attack scheme to unobserved NN classifiers. To do this, we apply the max-min adversarial example game framework and show the importance of the generalization properties of the substitute NN in the success of the black-box attack scheme in application to different NN classifiers. We prove theoretical generalization bounds on the difference between the attack transferability rates on training and test samples. Our bounds suggest that a substitute NN with better generalization behavior could result in more transferable adversarial examples. In addition, we show that standard operator norm-based regularization methods could improve the transferability of the designed adversarial examples. We support our theoretical results by performing several numerical experiments showing the role of the substitute network's generalization in generating transferable adversarial examples. Our empirical results indicate the power of Lipschitz regularization methods in improving the transferability of adversarial examples. ",
    "url": "https://arxiv.org/abs/2206.09238",
    "authors": [
      "Yilin Wang",
      "Farzan Farnia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.09247",
    "title": "Reduced Robust Random Cut Forest for Out-Of-Distribution detection in  machine learning models",
    "abstract": "Most machine learning-based regressors extract information from data collected via past observations of limited length to make predictions in the future. Consequently, when input to these trained models is data with significantly different statistical properties from data used for training, there is no guarantee of accurate prediction. Consequently, using these models on out-of-distribution input data may result in a completely different predicted outcome from the desired one, which is not only erroneous but can also be hazardous in some cases. Successful deployment of these machine learning models in any system requires a detection system, which should be able to distinguish between out-of-distribution and in-distribution data (i.e. similar to training data). In this paper, we introduce a novel approach for this detection process using a Reduced Robust Random Cut Forest (RRRCF) data structure, which can be used on both small and large data sets. Similar to the Robust Random Cut Forest (RRCF), RRRCF is a structured, but a reduced representation of the training data sub-space in form of cut trees. Empirical results of this method on both low and high-dimensional data showed that inference about data being in/out of training distribution can be made efficiently and the model is easy to train with no difficult hyper-parameter tuning. The paper discusses two different use-cases for testing and validating results. ",
    "url": "https://arxiv.org/abs/2206.09247",
    "authors": [
      "Harsh Vardhan",
      "Janos Sztipanovits"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.09249",
    "title": "RuArg-2022: Argument Mining Evaluation",
    "abstract": "Argumentation analysis is a field of computational linguistics that studies methods for extracting arguments from texts and the relationships between them, as well as building argumentation structure of texts. This paper is a report of the organizers on the first competition of argumentation analysis systems dealing with Russian language texts within the framework of the Dialogue conference. During the competition, the participants were offered two tasks: stance detection and argument classification. A corpus containing 9,550 sentences (comments on social media posts) on three topics related to the COVID-19 pandemic (vaccination, quarantine, and wearing masks) was prepared, annotated, and used for training and testing. The system that won the first place in both tasks used the NLI (Natural Language Inference) variant of the BERT architecture, automatic translation into English to apply a specialized BERT model, retrained on Twitter posts discussing COVID-19, as well as additional masking of target entities. This system showed the following results: for the stance detection task an F1-score of 0.6968, for the argument classification task an F1-score of 0.7404. We hope that the prepared dataset and baselines will help to foster further research on argument mining for the Russian language. ",
    "url": "https://arxiv.org/abs/2206.09249",
    "authors": [
      "Evgeny Kotelnikov",
      "Natalia Loukachevitch",
      "Irina Nikishina",
      "Alexander Panchenko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.09259",
    "title": "Can Language Models Capture Graph Semantics? From Graphs to Language  Model and Vice-Versa",
    "abstract": "Knowledge Graphs are a great resource to capture semantic knowledge in terms of entities and relationships between the entities. However, current deep learning models takes as input distributed representations or vectors. Thus, the graph is compressed in a vectorized representation. We conduct a study to examine if the deep learning model can compress a graph and then output the same graph with most of the semantics intact. Our experiments show that Transformer models are not able to express the full semantics of the input knowledge graph. We find that this is due to the disparity between the directed, relationship and type based information contained in a Knowledge Graph and the fully connected token-token undirected graphical interpretation of the Transformer Attention matrix. ",
    "url": "https://arxiv.org/abs/2206.09259",
    "authors": [
      "Tarun Garg",
      "Kaushik Roy",
      "Amit Sheth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.09276",
    "title": "Neural Shape-from-Shading for Survey-Scale Self-Consistent Bathymetry  from Sidescan",
    "abstract": "Sidescan sonar is a small and cost-effective sensing solution that can be easily mounted on most vessels. Historically, it has been used to produce high-definition images that experts may use to identify targets on the seafloor or in the water column. While solutions have been proposed to produce bathymetry solely from sidescan, or in conjunction with multibeam, they have had limited impact. This is partly a result of mostly being limited to single sidescan lines. In this paper, we propose a modern, salable solution to create high quality survey-scale bathymetry from many sidescan lines. By incorporating multiple observations of the same place, results can be improved as the estimates reinforce each other. Our method is based on sinusoidal representation networks, a recent advance in neural representation learning. We demonstrate the scalability of the approach by producing bathymetry from a large sidescan survey. The resulting quality is demonstrated by comparing to data collected with a high-precision multibeam sensor. ",
    "url": "https://arxiv.org/abs/2206.09276",
    "authors": [
      "Nils Bore",
      "John Folkesson"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.09280",
    "title": "AutoGML: Fast Automatic Model Selection for Graph Machine Learning",
    "abstract": "Given a graph learning task, such as link prediction, on a new graph dataset, how can we automatically select the best method as well as its hyperparameters (collectively called a model)? Model selection for graph learning has been largely ad hoc. A typical approach has been to apply popular methods to new datasets, but this is often suboptimal. On the other hand, systematically comparing models on the new graph quickly becomes too costly, or even impractical. In this work, we develop the first meta-learning approach for automatic graph machine learning, called AutoGML, which capitalizes on the prior performances of a large body of existing methods on benchmark graph datasets, and carries over this prior experience to automatically select an effective model to use for the new graph, without any model training or evaluations. To capture the similarity across graphs from different domains, we introduce specialized meta-graph features that quantify the structural characteristics of a graph. Then we design a meta-graph that represents the relations among models and graphs, and develop a graph meta-learner operating on the meta-graph, which estimates the relevance of each model to different graphs. Through extensive experiments, we show that using AutoGML to select a method for the new graph significantly outperforms consistently applying popular methods as well as several existing meta-learners, while being extremely fast at test time. ",
    "url": "https://arxiv.org/abs/2206.09280",
    "authors": [
      "Namyong Park",
      "Ryan Rossi",
      "Nesreen Ahmed",
      "Christos Faloutsos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.09299",
    "title": "Enforcing Continuous Physical Symmetries in Deep Learning Network for  Solving Partial Differential Equations",
    "abstract": "As a typical {application} of deep learning, physics-informed neural network (PINN) {has been} successfully used to find numerical solutions of partial differential equations (PDEs), but how to improve the limited accuracy is still a great challenge for PINN. In this work, we introduce a new method, symmetry-enhanced physics informed neural network (SPINN) where the invariant surface conditions induced by the Lie symmetries of PDEs are embedded into the loss function of PINN, for improving the accuracy of PINN. We test the effectiveness of SPINN via two groups of ten independent numerical experiments for the heat equation, Korteweg-de Vries (KdV) equation and potential Burgers {equations} respectively, which shows that SPINN performs better than PINN with fewer training points and simpler architecture of neural network. Furthermore, we discuss the computational overhead of SPINN in terms of the relative computational cost to PINN and show that the training time of SPINN has no obvious increases, even less than PINN for some cases. ",
    "url": "https://arxiv.org/abs/2206.09299",
    "authors": [
      "Zhi-Yong Zhang",
      "Hui Zhang",
      "Li-Sheng Zhang",
      "Lei-Lei Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09305",
    "title": "Adversarial Scrutiny of Evidentiary Statistical Software",
    "abstract": "The U.S. criminal legal system increasingly relies on software output to convict and incarcerate people. In a large number of cases each year, the government makes these consequential decisions based on evidence from statistical software -- such as probabilistic genotyping, environmental audio detection, and toolmark analysis tools -- that defense counsel cannot fully cross-examine or scrutinize. This undermines the commitments of the adversarial criminal legal system, which relies on the defense's ability to probe and test the prosecution's case to safeguard individual rights. Responding to this need to adversarially scrutinize output from such software, we propose robust adversarial testing as an audit framework to examine the validity of evidentiary statistical software. We define and operationalize this notion of robust adversarial testing for defense use by drawing on a large body of recent work in robust machine learning and algorithmic fairness. We demonstrate how this framework both standardizes the process for scrutinizing such tools and empowers defense lawyers to examine their validity for instances most relevant to the case at hand. We further discuss existing structural and institutional challenges within the U.S. criminal legal system that may create barriers for implementing this and other such audit frameworks and close with a discussion on policy changes that could help address these concerns. ",
    "url": "https://arxiv.org/abs/2206.09305",
    "authors": [
      "Rediet Abebe",
      "Moritz Hardt",
      "Angela Jin",
      "John Miller",
      "Ludwig Schmidt",
      "Rebecca Wexler"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09314",
    "title": "Robust Imitation Learning against Variations in Environment Dynamics",
    "abstract": "In this paper, we propose a robust imitation learning (IL) framework that improves the robustness of IL when environment dynamics are perturbed. The existing IL framework trained in a single environment can catastrophically fail with perturbations in environment dynamics because it does not capture the situation that underlying environment dynamics can be changed. Our framework effectively deals with environments with varying dynamics by imitating multiple experts in sampled environment dynamics to enhance the robustness in general variations in environment dynamics. In order to robustly imitate the multiple sample experts, we minimize the risk with respect to the Jensen-Shannon divergence between the agent's policy and each of the sample experts. Numerical results show that our algorithm significantly improves robustness against dynamics perturbations compared to conventional IL baselines. ",
    "url": "https://arxiv.org/abs/2206.09314",
    "authors": [
      "Jongseong Chae",
      "Seungyul Han",
      "Whiyoung Jung",
      "Myungsik Cho",
      "Sungho Choi",
      "Youngchul Sung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.09319",
    "title": "TrafficFlowGAN: Physics-informed Flow based Generative Adversarial  Network for Uncertainty Quantification",
    "abstract": "This paper proposes the TrafficFlowGAN, a physics-informed flow based generative adversarial network (GAN), for uncertainty quantification (UQ) of dynamical systems. TrafficFlowGAN adopts a normalizing flow model as the generator to explicitly estimate the data likelihood. This flow model is trained to maximize the data likelihood and to generate synthetic data that can fool a convolutional discriminator. We further regularize this training process using prior physics information, so-called physics-informed deep learning (PIDL). To the best of our knowledge, we are the first to propose an integration of flow, GAN and PIDL for the UQ problems. We take the traffic state estimation (TSE), which aims to estimate the traffic variables (e.g. traffic density and velocity) using partially observed data, as an example to demonstrate the performance of our proposed model. We conduct numerical experiments where the proposed model is applied to learn the solutions of stochastic differential equations. The results demonstrate the robustness and accuracy of the proposed model, together with the ability to learn a machine learning surrogate model. We also test it on a real-world dataset, the Next Generation SIMulation (NGSIM), to show that the proposed TrafficFlowGAN can outperform the baselines, including the pure flow model, the physics-informed flow model, and the flow based GAN model. ",
    "url": "https://arxiv.org/abs/2206.09319",
    "authors": [
      "Zhaobin Mo",
      "Yongjie Fu",
      "Daran Xu",
      "Xuan Di"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09321",
    "title": "Mitigating Learning Complexity in Physics and Equality Constrained  Artificial Neural Networks",
    "abstract": "Physics-informed neural networks (PINNs) have been proposed to learn the solution of partial differential equations (PDE). In PINNs, the residual form of the PDE of interest and its boundary conditions are lumped into a composite objective function as soft penalties. Here, we show that this specific way of formulating the objective function is the source of severe limitations in the PINN approach when applied to different kinds of PDEs. To address these limitations, we propose a versatile framework based on a constrained optimization problem formulation, where we use the augmented Lagrangian method (ALM) to constrain the solution of a PDE with its boundary conditions and any high-fidelity data that may be available. Our approach is adept at forward and inverse problems with multi-fidelity data fusion. We demonstrate the efficacy and versatility of our physics- and equality-constrained deep-learning framework by applying it to several forward and inverse problems involving multi-dimensional PDEs.Our framework achieves orders of magnitude improvements in accuracy levels in comparison with state-of-the-art physics-informed neural networks. ",
    "url": "https://arxiv.org/abs/2206.09321",
    "authors": [
      "Shamsulhaq Basir",
      "Inanc Senocak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2206.09325",
    "title": "EATFormer: Improving Vision Transformer Inspired by Evolutionary  Algorithm",
    "abstract": "Motivated by biological evolution, this paper explains the rationality of Vision Transformer by analogy with the proven practical Evolutionary Algorithm (EA) and derives that both have consistent mathematical formulation. Then inspired by effective EA variants, we propose a novel pyramid EATFormer backbone that only contains the proposed \\emph{EA-based Transformer} (EAT) block, which consists of three residual parts, \\ie, \\emph{Multi-Scale Region Aggregation} (MSRA), \\emph{Global and Local Interaction} (GLI), and \\emph{Feed-Forward Network} (FFN) modules, to model multi-scale, interactive, and individual information separately. Moreover, we design a \\emph{Task-Related Head} (TRH) docked with transformer backbone to complete final information fusion more flexibly and \\emph{improve} a \\emph{Modulated Deformable MSA} (MD-MSA) to dynamically model irregular locations. Massive quantitative and quantitative experiments on image classification, downstream tasks, and explanatory experiments demonstrate the effectiveness and superiority of our approach over State-Of-The-Art (SOTA) methods. \\Eg, our Mobile (1.8M), Tiny (6.1M), Small (24.3M), and Base (49.0M) models achieve 69.4, 78.4, 83.1, and 83.9 Top-1 only trained on ImageNet-1K with naive training recipe; EATFormer-Tiny/Small/Base armed Mask-R-CNN obtain 45.4/47.4/49.0 box AP and 41.4/42.9/44.2 mask AP on COCO detection, surpassing contemporary MPViT-T, Swin-T, and Swin-S by 0.6/1.4/0.5 box AP and 0.4/1.3/0.9 mask AP separately with less FLOPs; Our EATFormer-Small/Base achieve 47.3/49.3 mIoU on ADE20K by Upernet that exceeds Swin-T/S by 2.8/1.7. Code will be available at \\url{https://https://github.com/zhangzjn/EATFormer}. ",
    "url": "https://arxiv.org/abs/2206.09325",
    "authors": [
      "Jiangning Zhang",
      "Xiangtai Li",
      "Yabiao Wang",
      "Chengjie Wang",
      "Yibo Yang",
      "Yong Liu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2206.09345",
    "title": "Finding Diverse and Predictable Subgraphs for Graph Domain  Generalization",
    "abstract": "This paper focuses on out-of-distribution generalization on graphs where performance drops due to the unseen distribution shift. Previous graph domain generalization works always resort to learning an invariant predictor among different source domains. However, they assume sufficient source domains are available during training, posing huge challenges for realistic applications. By contrast, we propose a new graph domain generalization framework, dubbed as DPS, by constructing multiple populations from the source domains. Specifically, DPS aims to discover multiple \\textbf{D}iverse and \\textbf{P}redictable \\textbf{S}ubgraphs with a set of generators, namely, subgraphs are different from each other but all the them share the same semantics with the input graph. These generated source domains are exploited to learn an \\textit{equi-predictive} graph neural network (GNN) across domains, which is expected to generalize well to unseen target domains. Generally, DPS is model-agnostic that can be incorporated with various GNN backbones. Extensive experiments on both node-level and graph-level benchmarks shows that the proposed DPS achieves impressive performance for various graph domain generalization tasks. ",
    "url": "https://arxiv.org/abs/2206.09345",
    "authors": [
      "Junchi Yu",
      "Jian Liang",
      "Ran He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.09349",
    "title": "Quantifying Uncertainty In Traffic State Estimation Using Generative  Adversarial Networks",
    "abstract": "This paper aims to quantify uncertainty in traffic state estimation (TSE) using the generative adversarial network based physics-informed deep learning (PIDL). The uncertainty of the focus arises from fundamental diagrams, in other words, the mapping from traffic density to velocity. To quantify uncertainty for the TSE problem is to characterize the robustness of predicted traffic states. Since its inception, generative adversarial networks (GAN) have become a popular probabilistic machine learning framework. In this paper, we will inform the GAN based predictions using stochastic traffic flow models and develop a GAN based PIDL framework for TSE, named ``PhysGAN-TSE\". By conducting experiments on a real-world dataset, the Next Generation SIMulation (NGSIM) dataset, this method is shown to be more robust for uncertainty quantification than the pure GAN model or pure traffic flow models. Two physics models, the Lighthill-Whitham-Richards (LWR) and the Aw-Rascle-Zhang (ARZ) models, are compared as the physics components for the PhysGAN, and results show that the ARZ-based PhysGAN achieves a better performance than the LWR-based one. ",
    "url": "https://arxiv.org/abs/2206.09349",
    "authors": [
      "Zhaobin Mo",
      "Yongjie Fu",
      "Xuan Di"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09359",
    "title": "Productive Reproducible Workflows for DNNs: A Case Study for Industrial  Defect Detection",
    "abstract": "As Deep Neural Networks (DNNs) have become an increasingly ubiquitous workload, the range of libraries and tooling available to aid in their development and deployment has grown significantly. Scalable, production quality tools are freely available under permissive licenses, and are accessible enough to enable even small teams to be very productive. However within the research community, awareness and usage of said tools is not necessarily widespread, and researchers may be missing out on potential productivity gains from exploiting the latest tools and workflows. This paper presents a case study where we discuss our recent experience producing an end-to-end artificial intelligence application for industrial defect detection. We detail the high level deep learning libraries, containerized workflows, continuous integration/deployment pipelines, and open source code templates we leveraged to produce a competitive result, matching the performance of other ranked solutions to our three target datasets. We highlight the value that exploiting such systems can bring, even for research, and detail our solution and present our best results in terms of accuracy and inference time on a server class GPU, as well as inference times on a server class CPU, and a Raspberry Pi 4. ",
    "url": "https://arxiv.org/abs/2206.09359",
    "authors": [
      "Perry Gibson",
      "Jos\u00e9 Cano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Performance (cs.PF)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2206.09365",
    "title": "Semi-supervised Change Detection of Small Water Bodies Using RGB and  Multispectral Images in Peruvian Rainforests",
    "abstract": "Artisanal and Small-scale Gold Mining (ASGM) is an important source of income for many households, but it can have large social and environmental effects, especially in rainforests of developing countries. The Sentinel-2 satellites collect multispectral images that can be used for the purpose of detecting changes in water extent and quality which indicates the locations of mining sites. This work focuses on the recognition of ASGM activities in Peruvian Amazon rainforests. We tested several semi-supervised classifiers based on Support Vector Machines (SVMs) to detect the changes of water bodies from 2019 to 2021 in the Madre de Dios region, which is one of the global hotspots of ASGM activities. Experiments show that SVM-based models can achieve reasonable performance for both RGB (using Cohen's $\\kappa$ 0.49) and 6-channel images (using Cohen's $\\kappa$ 0.71) with very limited annotations. The efficacy of incorporating Lab color space for change detection is analyzed as well. ",
    "url": "https://arxiv.org/abs/2206.09365",
    "authors": [
      "Kangning Cui",
      "Seda Camalan",
      "Ruoning Li",
      "Victor P. Pauca",
      "Sarra Alqahtani",
      "Robert J. Plemmons",
      "Miles Silman",
      "Evan N. Dethier",
      "David Lutz",
      "Raymond H. Chan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2206.09372",
    "title": "mvHOTA: A multi-view higher order tracking accuracy metric to measure  spatial and temporal associations in multi-point detection",
    "abstract": "Multi-object tracking (MOT) is a challenging task that involves detecting objects in the scene and tracking them across a sequence of frames. Evaluating this task is difficult due to temporal occlusions, and varying trajectories across a sequence of images. The main evaluation metric to benchmark MOT methods on datasets such as KITTI has recently become the higher order tracking accuracy (HOTA) metric, which is capable of providing a better description of the performance over metrics such as MOTA, DetA, and IDF1. Point detection and tracking is a closely related task, which could be regarded as a special case of object detection. However, there are differences in evaluating the detection task itself (point distances vs. bounding box overlap). When including the temporal dimension and multi-view scenarios, the evaluation task becomes even more complex. In this work, we propose a multi-view higher order tracking metric (mvHOTA) to determine the accuracy of multi-point (multi-instance and multi-class) detection, while taking into account temporal and spatial associations. mvHOTA can be interpreted as the geometric mean of the detection, association, and correspondence accuracies, thereby providing equal weighting to each of the factors. We demonstrate a use-case through a publicly available endoscopic point detection dataset from a previously organised medical challenge. Furthermore, we compare with other adjusted MOT metrics for this use-case, discuss the properties of mvHOTA, and show how the proposed correspondence accuracy and the Occlusion index facilitate analysis of methods with respect to handling of occlusions. The code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2206.09372",
    "authors": [
      "Lalith Sharan",
      "Halvar Kelm",
      "Gabriele Romano",
      "Matthias Karck",
      "Raffaele De Simone",
      "Sandy Engelhardt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.09374",
    "title": "A robust and conservative dynamical low-rank algorithm",
    "abstract": "Dynamical low-rank approximation, as has been demonstrated recently, can be extremely efficient in solving kinetic equations. However, a major deficiency is that they do not preserve the structure of the underlying physical problem. For example, the classic dynamical low-rank methods violate mass, momentum, and energy conservation. In [L. Einkemmer, I. Joseph, J. Comput. Phys. 443:110495, 2021] a conservative dynamical low-rank approach has been proposed. However, directly integrating the resulting equations of motion, similar to the classic dynamical low-rank approach, results in an ill-posed scheme. In this work we propose a robust, i.e.~well-posed, integrator for the conservative dynamical low-rank approach that conserves mass and momentum (up to machine precision) and significantly improves energy conservation. We also report improved qualitative results for some problems and show how the approach can be combined with a rank adaptive scheme. ",
    "url": "https://arxiv.org/abs/2206.09374",
    "authors": [
      "Lukas Einkemmer",
      "Alexander Ostermann",
      "Carmen Scalone"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2206.09379",
    "title": "0/1 Deep Neural Networks via Block Coordinate Descent",
    "abstract": "The step function is one of the simplest and most natural activation functions for deep neural networks (DNNs). As it counts 1 for positive variables and 0 for others, its intrinsic characteristics (e.g., discontinuity and no viable information of subgradients) impede its development for several decades. Even if there is an impressive body of work on designing DNNs with continuous activation functions that can be deemed as surrogates of the step function, it is still in the possession of some advantageous properties, such as complete robustness to outliers and being capable of attaining the best learning-theoretic guarantee of predictive accuracy. Hence, in this paper, we aim to train DNNs with the step function used as an activation function (dubbed as 0/1 DNNs). We first reformulate 0/1 DNNs as an unconstrained optimization problem and then solve it by a block coordinate descend (BCD) method. Moreover, we acquire closed-form solutions for sub-problems of BCD as well as its convergence properties. Furthermore, we also integrate $\\ell_{2,0}$-regularization into 0/1 DNN to accelerate the training process and compress the network scale. As a result, the proposed algorithm has a high performance on classifying MNIST and Fashion-MNIST datasets. ",
    "url": "https://arxiv.org/abs/2206.09379",
    "authors": [
      "Hui Zhang",
      "Shenglong Zhou",
      "Geoffrey Ye Li",
      "Naihua Xiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09380",
    "title": "Supervision Adaptation Balances In-Distribution Generalization and  Out-of-Distribution Detection",
    "abstract": "When there is a discrepancy between in-distribution (ID) samples and out-of-distribution (OOD) samples, deep neural networks trained on ID samples suffer from high-confidence prediction on OOD samples. This is primarily caused by unavailable OOD samples to constrain the networks in the training process. To improve the OOD sensitivity of deep networks, several state-of-the-art methods introduce samples from other real-world datasets as OOD samples to the training process and assign manually-determined labels to these OOD samples. However, they sacrifice the classification accuracy because the unreliable labeling of OOD samples would disrupt ID classification. To balance ID generalization and OOD detection, a major challenge to tackle is to make OOD samples compatible with ID ones, which is addressed by our proposed \\textit{supervision adaptation} method in this paper to define adaptive supervision information for OOD samples. First, by measuring the dependency between ID samples and their labels through mutual information, we reveal the form of the supervision information in terms of the negative probabilities of all classes. Second, after exploring the data correlations between ID and OOD samples by solving multiple binary regression problems, we estimate the supervision information to make ID classes more separable. We perform experiments on four advanced network architectures with two ID datasets and eleven OOD datasets to demonstrate the balancing effect of our supervision adaptation method in achieving both the ID classification ability and the OOD detection capacity. ",
    "url": "https://arxiv.org/abs/2206.09380",
    "authors": [
      "Zhilin Zhao",
      "Longbing Cao",
      "Kun-Yu Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09385",
    "title": "Out-of-distribution Detection by Cross-class Vicinity Distribution of  In-distribution Data",
    "abstract": "Deep neural networks only learn to map in-distribution inputs to their corresponding ground truth labels in the training phase without differentiating out-of-distribution samples from in-distribution ones. This results from the assumption that all samples are independent and identically distributed without distributional distinction. Therefore, a pretrained network learned from the in-distribution samples treats out-of-distribution samples as in-distribution and makes high-confidence predictions on them in the test phase. To address this issue, we draw out-of-distribution samples from the vicinity distribution of training in-distribution samples for learning to reject the prediction on out-of-distribution inputs. A \\textit{Cross-class Vicinity Distribution} is introduced by assuming that an out-of-distribution sample generated by mixing multiple in-distribution samples does not share the same classes of its constituents. We thus improve the discriminability of a pretrained network by finetuning it with out-of-distribution samples drawn from the cross-class vicinity distribution, where each out-of-distribution input corresponds to a complementary label. Experiments on various in-/out-of-distribution datasets show that the proposed method significantly outperforms existing methods in improving the capacity of discriminating between in- and out-of-distribution samples. ",
    "url": "https://arxiv.org/abs/2206.09385",
    "authors": [
      "Zhilin Zhao",
      "Longbing Cao",
      "Kun-Yu Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09386",
    "title": "Scalable Neural Data Server: A Data Recommender for Transfer Learning",
    "abstract": "Absence of large-scale labeled data in the practitioner's target domain can be a bottleneck to applying machine learning algorithms in practice. Transfer learning is a popular strategy for leveraging additional data to improve the downstream performance, but finding the most relevant data to transfer from can be challenging. Neural Data Server (NDS), a search engine that recommends relevant data for a given downstream task, has been previously proposed to address this problem. NDS uses a mixture of experts trained on data sources to estimate similarity between each source and the downstream task. Thus, the computational cost to each user grows with the number of sources. To address these issues, we propose Scalable Neural Data Server (SNDS), a large-scale search engine that can theoretically index thousands of datasets to serve relevant ML data to end users. SNDS trains the mixture of experts on intermediary datasets during initialization, and represents both data sources and downstream tasks by their proximity to the intermediary datasets. As such, computational cost incurred by SNDS users remains fixed as new datasets are added to the server. We validate SNDS on a plethora of real world tasks and find that data recommended by SNDS improves downstream task performance over baselines. We also demonstrate the scalability of SNDS by showing its ability to select relevant data for transfer outside of the natural image setting. ",
    "url": "https://arxiv.org/abs/2206.09386",
    "authors": [
      "Tianshi Cao",
      "Sasha Doubov",
      "David Acuna",
      "Sanja Fidler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09387",
    "title": "Label and Distribution-discriminative Dual Representation Learning for  Out-of-Distribution Detection",
    "abstract": "To classify in-distribution samples, deep neural networks learn label-discriminative representations, which, however, are not necessarily distribution-discriminative according to the information bottleneck. Therefore, trained networks could assign unexpected high-confidence predictions to out-of-distribution samples drawn from distributions differing from that of in-distribution samples. Specifically, networks extract the strongly label-related information from in-distribution samples to learn the label-discriminative representations but discard the weakly label-related information. Accordingly, networks treat out-of-distribution samples with minimum label-sensitive information as in-distribution samples. According to the different informativeness properties of in- and out-of-distribution samples, a Dual Representation Learning (DRL) method learns distribution-discriminative representations that are weakly related to the labeling of in-distribution samples and combines label- and distribution-discriminative representations to detect out-of-distribution samples. For a label-discriminative representation, DRL constructs the complementary distribution-discriminative representation by an implicit constraint, i.e., integrating diverse intermediate representations where an intermediate representation less similar to the label-discriminative representation owns a higher weight. Experiments show that DRL outperforms the state-of-the-art methods for out-of-distribution detection. ",
    "url": "https://arxiv.org/abs/2206.09387",
    "authors": [
      "Zhilin Zhao",
      "Longbing Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09388",
    "title": "Privacy-Preserving Analytics on Decentralized Social Graphs: The Case of  Eigendecomposition",
    "abstract": "Analytics over social graphs allows to extract valuable knowledge and insights for many fields like community detection, fraud detection, and interest mining. In practice, decentralized social graphs frequently arise, where the social graph is not available to a single entity and is decentralized among a large number of users, each holding only a limited local view about the whole graph. Collecting the local views for analytics of decentralized social graphs raises critical privacy concerns, as they encode private information about the social interactions among individuals. In this paper, we design, implement, and evaluate PrivGED, a new system aimed at privacy-preserving analytics over decentralized social graphs. PrivGED focuses on the support for eigendecomposition, one popular and fundamental graph analytics task producing eigenvalues/eigenvectors over the adjacency matrix of a social graph and benefits various practical applications. PrivGED is built from a delicate synergy of insights on graph analytics, lightweight cryptography, and differential privacy, allowing users to securely contribute their local views on a decentralized social graph for a cloud-based eigendecomposition analytics service while gaining strong privacy protection. Extensive experiments over real-world social graph datasets demonstrate that PrivGED achieves accuracy comparable to the plaintext domain, with practically affordable performance superior to prior art. ",
    "url": "https://arxiv.org/abs/2206.09388",
    "authors": [
      "Songlei Wang",
      "Yifeng Zheng",
      "Xiaohua Jia",
      "Xun Yi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.09391",
    "title": "Towards Adversarial Attack on Vision-Language Pre-training Models",
    "abstract": "While vision-language pre-training model (VLP) has shown revolutionary improvements on various vision-language (V+L) tasks, the studies regarding its adversarial robustness remain largely unexplored. This paper studied the adversarial attack on popular VLP models and V+L tasks. First, we analyzed the performance of adversarial attacks under different settings. By examining the influence of different perturbed objects and attack targets, we concluded some key observations as guidance on both designing strong multimodal adversarial attack and constructing robust VLP models. Second, we proposed a novel multimodal attack method on the VLP models called Collaborative Multimodal Adversarial Attack (Co-Attack), which collectively carries out the attacks on the image modality and the text modality. Experimental results demonstrated that the proposed method achieves improved attack performances on different V+L downstream tasks and VLP models. The analysis observations and novel attack method hopefully provide new understanding into the adversarial robustness of VLP models, so as to contribute their safe and reliable deployment in more real-world scenarios. ",
    "url": "https://arxiv.org/abs/2206.09391",
    "authors": [
      "Jiaming Zhang",
      "Qi Yi",
      "Jitao Sang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2206.09406",
    "title": "Coded Caching via Federated Deep Reinforcement Learning in Fog Radio  Access Networks",
    "abstract": "In this paper, the placement strategy design of coded caching in fog-radio access networks (F-RANs) is investigated. By considering time-variant content popularity, federated deep reinforcement learning is exploited to learn the placement strategy for our coded caching scheme. Initially, the placement problem is modeled as a Markov decision process (MDP) to capture the popularity variations and minimize the long-term content access delay. The reformulated sequential decision problem is solved by dueling double deep Q-learning (dueling DDQL). Then, federated learning is applied to learn the relatively low-dimensional local decision models and aggregate the global decision model, which alleviates over-consumption of bandwidth resources and avoids direct learning of a complex coded caching decision model with high-dimensional state space. Simulation results show that our proposed scheme outperforms the benchmarks in reducing the content access delay, keeping the performance stable, and trading off between the local caching gain and the global multicasting gain. ",
    "url": "https://arxiv.org/abs/2206.09406",
    "authors": [
      "Yingqi Chen",
      "Yanxiang Jiang",
      "Fu-Chun Zheng",
      "Mehdi Bennis",
      "Xiaohu You"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2206.09410",
    "title": "JPEG Compression-Resistant Low-Mid Adversarial Perturbation against  Unauthorized Face Recognition System",
    "abstract": "It has been observed that the unauthorized use of face recognition system raises privacy problems. Using adversarial perturbations provides one possible solution to address this issue. A critical issue to exploit adversarial perturbation against unauthorized face recognition system is that: The images uploaded to the web need to be processed by JPEG compression, which weakens the effectiveness of adversarial perturbation. Existing JPEG compression-resistant methods fails to achieve a balance among compression resistance, transferability, and attack effectiveness. To this end, we propose a more natural solution called low frequency adversarial perturbation (LFAP). Instead of restricting the adversarial perturbations, we turn to regularize the source model to employing more low-frequency features by adversarial training. Moreover, to better influence model in different frequency components, we proposed the refined low-mid frequency adversarial perturbation (LMFAP) considering the mid frequency components as the productive complement. We designed a variety of settings in this study to simulate the real-world application scenario, including cross backbones, supervisory heads, training datasets and testing datasets. Quantitative and qualitative experimental results validate the effectivenss of proposed solutions. ",
    "url": "https://arxiv.org/abs/2206.09410",
    "authors": [
      "Jiaming Zhang",
      "Qi Yi",
      "Jitao Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.09422",
    "title": "Phantom Artifacts & Code Review Coverage in Dependency Updates",
    "abstract": "The goal of this study is to aid developers in securely accepting dependency updates by measuring if the code changes in an update have passed through a code review process. We implement DepDive, an update audit tool for packages in Crates.io, npm, PyPI, and RubyGems registry. DepDive first (i) identifies the files and the code changes in an update that cannot be traced back to the package's source repository, i.e., phantom artifacts; and then (ii) measures what portion of changes in the update, excluding the phantom artifacts, has passed through a code review process, i.e., code review coverage. Using DepDive, we present an empirical study across the latest ten updates of the most downloaded 1000 packages in each of the four registries. Our study unveils interesting insights while also providing an evaluation of our proposed approach. We find that phantom artifacts are not uncommon in the updates (20.1\\% of the analyzed updates had at least one phantom file). The phantoms can appear either due to legitimate reasons, such as in the case of programmatically generated files, or from accidental inclusion, such as in the case of files that are ignored in the repository. However, without provenance tracking, we cannot audit if the changes in these phantom artifacts were code-reviewed or not. Regarding code review coverage (\\textit{CRC)}, we find the updates are typically only partially code-reviewed (52.5\\% of the time). Further, only 9.0\\% of the packages had all their updates in our data set fully code-reviewed, indicating that even the most used packages can introduce non-reviewed code in the software supply chain. We also observe that updates either tend to have very high \\textit{CRC} or very low \\textit{CRC}, suggesting that packages at the opposite end of the spectrum may require a separate set of treatments. ",
    "url": "https://arxiv.org/abs/2206.09422",
    "authors": [
      "Nasif Imtiaz",
      "Laurie Williams"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2206.09426",
    "title": "ADBench: Anomaly Detection Benchmark",
    "abstract": "Given a long list of anomaly detection algorithms developed in the last few decades, how do they perform with regard to (i) varying levels of supervision, (ii) different types of anomalies, and (iii) noisy and corrupted data? In this work, we answer these key questions by conducting (to our best knowledge) the most comprehensive anomaly detection benchmark with 30 algorithms on 55 benchmark datasets, named ADBench. Our extensive experiments (93,654 in total) identify meaningful insights into the role of supervision and anomaly types, and unlock future directions for researchers in algorithm selection and design. With ADBench, researchers can easily conduct comprehensive and fair evaluations for newly proposed methods on the datasets (including our contributed ones from natural language and computer vision domains) against the existing baselines. To foster accessibility and reproducibility, we fully open-source ADBench and the corresponding results. ",
    "url": "https://arxiv.org/abs/2206.09426",
    "authors": [
      "Songqiao Han",
      "Xiyang Hu",
      "Hailiang Huang",
      "Mingqi Jiang",
      "Yue Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.09449",
    "title": "SNN2ANN: A Fast and Memory-Efficient Training Framework for Spiking  Neural Networks",
    "abstract": "Spiking neural networks are efficient computation models for low-power environments. Spike-based BP algorithms and ANN-to-SNN (ANN2SNN) conversions are successful techniques for SNN training. Nevertheless, the spike-base BP training is slow and requires large memory costs. Though ANN2NN provides a low-cost way to train SNNs, it requires many inference steps to mimic the well-trained ANN for good performance. In this paper, we propose a SNN-to-ANN (SNN2ANN) framework to train the SNN in a fast and memory-efficient way. The SNN2ANN consists of 2 components: a) a weight sharing architecture between ANN and SNN and b) spiking mapping units. Firstly, the architecture trains the weight-sharing parameters on the ANN branch, resulting in fast training and low memory costs for SNN. Secondly, the spiking mapping units ensure that the activation values of the ANN are the spiking features. As a result, the classification error of the SNN can be optimized by training the ANN branch. Besides, we design an adaptive threshold adjustment (ATA) algorithm to address the noisy spike problem. Experiment results show that our SNN2ANN-based models perform well on the benchmark datasets (CIFAR10, CIFAR100, and Tiny-ImageNet). Moreover, the SNN2ANN can achieve comparable accuracy under 0.625x time steps, 0.377x training time, 0.27x GPU memory costs, and 0.33x spike activities of the Spike-based BP model. ",
    "url": "https://arxiv.org/abs/2206.09449",
    "authors": [
      "Jianxiong Tang",
      "Jianhuang Lai",
      "Xiaohua Xie",
      "Lingxiao Yang",
      "Wei-Shi Zheng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09450",
    "title": "Data Augmentation vs. Equivariant Networks: A Theory of Generalization  on Dynamics Forecasting",
    "abstract": "Exploiting symmetry in dynamical systems is a powerful way to improve the generalization of deep learning. The model learns to be invariant to transformation and hence is more robust to distribution shift. Data augmentation and equivariant networks are two major approaches to injecting symmetry into learning. However, their exact role in improving generalization is not well understood. In this work, we derive the generalization bounds for data augmentation and equivariant networks, characterizing their effect on learning in a unified framework. Unlike most prior theories for the i.i.d. setting, we focus on non-stationary dynamics forecasting with complex temporal dependencies. ",
    "url": "https://arxiv.org/abs/2206.09450",
    "authors": [
      "Rui Wang",
      "Robin Walters",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09458",
    "title": "A Universal Adversarial Policy for Text Classifiers",
    "abstract": "Discovering the existence of universal adversarial perturbations had large theoretical and practical impacts on the field of adversarial learning. In the text domain, most universal studies focused on adversarial prefixes which are added to all texts. However, unlike the vision domain, adding the same perturbation to different inputs results in noticeably unnatural inputs. Therefore, we introduce a new universal adversarial setup - a universal adversarial policy, which has many advantages of other universal attacks but also results in valid texts - thus making it relevant in practice. We achieve this by learning a single search policy over a predefined set of semantics preserving text alterations, on many texts. This formulation is universal in that the policy is successful in finding adversarial examples on new texts efficiently. Our approach uses text perturbations which were extensively shown to produce natural attacks in the non-universal setup (specific synonym replacements). We suggest a strong baseline approach for this formulation which uses reinforcement learning. It's ability to generalise (from as few as 500 training texts) shows that universal adversarial patterns exist in the text domain as well. ",
    "url": "https://arxiv.org/abs/2206.09458",
    "authors": [
      "Gallil Maimon",
      "Lior Rokach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.09474",
    "title": "3D Object Detection for Autonomous Driving: A Review and New Outlooks",
    "abstract": "Autonomous driving, in recent years, has been receiving increasing attention for its potential to relieve drivers' burdens and improve the safety of driving. In modern autonomous driving pipelines, the perception system is an indispensable component, aiming to accurately estimate the status of surrounding environments and provide reliable observations for prediction and planning. 3D object detection, which intelligently predicts the locations, sizes, and categories of the critical 3D objects near an autonomous vehicle, is an important part of a perception system. This paper reviews the advances in 3D object detection for autonomous driving. First, we introduce the background of 3D object detection and discuss the challenges in this task. Second, we conduct a comprehensive survey of the progress in 3D object detection from the aspects of models and sensory inputs, including LiDAR-based, camera-based, and multi-modal detection approaches. We also provide an in-depth analysis of the potentials and challenges in each category of methods. Additionally, we systematically investigate the applications of 3D object detection in driving systems. Finally, we conduct a performance analysis of the 3D object detection approaches, and we further summarize the research trends over the years and prospect the future directions of this area. ",
    "url": "https://arxiv.org/abs/2206.09474",
    "authors": [
      "Jiageng Mao",
      "Shaoshuai Shi",
      "Xiaogang Wang",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.09477",
    "title": "Geometric Matrix Completion via Sylvester Multi-Graph Neural Network",
    "abstract": "Despite the success of the Sylvester equation empowered methods on various graph mining applications, such as semi-supervised label learning and network alignment, there also exists several limitations. The Sylvester equation's inability of modeling non-linear relations and the inflexibility of tuning towards different tasks restrict its performance. In this paper, we propose an end-to-end neural framework, SYMGNN, which consists of a multi-network neural aggregation module and a prior multi-network association incorporation learning module. The proposed framework inherits the key ideas of the Sylvester equation, and meanwhile generalizes it to overcome aforementioned limitations. Empirical evaluations on real-world datasets show that the instantiations of SYMGNN overall outperform the baselines in geometric matrix completion task, and its low-rank instantiation could further reduce the memory consumption by 16.98\\% on average. ",
    "url": "https://arxiv.org/abs/2206.09477",
    "authors": [
      "Boxin Du",
      "Changhe Yuan",
      "Fei Wang",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09483",
    "title": "An Analysis of the Admissibility of the Objective Functions Applied in  Evolutionary Multi-objective Clustering",
    "abstract": "A variety of clustering criteria has been applied as an objective function in Evolutionary Multi-Objective Clustering approaches (EMOCs). However, most EMOCs do not provide detailed analysis regarding the choice and usage of the objective functions. Aiming to support a better choice and definition of the objectives in the EMOCs, this paper proposes an analysis of the admissibility of the clustering criteria in evolutionary optimization by examining the search direction and its potential in finding optimal results. As a result, we demonstrate how the admissibility of the objective functions can influence the optimization. Furthermore, we provide insights regarding the combinations and usage of the clustering criteria in the EMOCs. ",
    "url": "https://arxiv.org/abs/2206.09483",
    "authors": [
      "Cristina Y. Morimoto",
      "Aurora Pozo",
      "Marc\u00edlio C. P. de Souto"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09500",
    "title": "Unbiased Teacher v2: Semi-supervised Object Detection for Anchor-free  and Anchor-based Detectors",
    "abstract": "With the recent development of Semi-Supervised Object Detection (SS-OD) techniques, object detectors can be improved by using a limited amount of labeled data and abundant unlabeled data. However, there are still two challenges that are not addressed: (1) there is no prior SS-OD work on anchor-free detectors, and (2) prior works are ineffective when pseudo-labeling bounding box regression. In this paper, we present Unbiased Teacher v2, which shows the generalization of SS-OD method to anchor-free detectors and also introduces Listen2Student mechanism for the unsupervised regression loss. Specifically, we first present a study examining the effectiveness of existing SS-OD methods on anchor-free detectors and find that they achieve much lower performance improvements under the semi-supervised setting. We also observe that box selection with centerness and the localization-based labeling used in anchor-free detectors cannot work well under the semi-supervised setting. On the other hand, our Listen2Student mechanism explicitly prevents misleading pseudo-labels in the training of bounding box regression; we specifically develop a novel pseudo-labeling selection mechanism based on the Teacher and Student's relative uncertainties. This idea contributes to favorable improvement in the regression branch in the semi-supervised setting. Our method, which works for both anchor-free and anchor-based methods, consistently performs favorably against the state-of-the-art methods in VOC, COCO-standard, and COCO-additional. ",
    "url": "https://arxiv.org/abs/2206.09500",
    "authors": [
      "Yen-Cheng Liu",
      "Chih-Yao Ma",
      "Zsolt Kira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09506",
    "title": "Log-GPIS-MOP: A Unified Representation for Mapping, Odometry and  Planning",
    "abstract": "Whereas dedicated scene representations are required for each different tasks in conventional robotic systems, this paper demonstrates that a unified representation can be used directly for multiple key tasks. We propose the Log-Gaussian Process Implicit Surface for Mapping, Odometry and Planning (Log-GPIS-MOP): a probabilistic framework for surface reconstruction, localisation and navigation based on a unified representation. Our framework applies a logarithmic transformation to a Gaussian Process Implicit Surface (GPIS) formulation to recover a global representation that accurately captures the Euclidean distance field with gradients and, at the same time, the implicit surface. By directly estimate the distance field and its gradient through Log-GPIS inference, the proposed incremental odometry technique computes the optimal alignment of an incoming frame, and fuses it globally to produce a map. Concurrently, an optimisation-based planner computes a safe collision-free path using the same Log-GPIS surface representation. We validate the proposed framework on simulated and real datasets in 2D and 3D and benchmark against the state-of-the-art approaches. Our experiments show that Log-GPIS-MOP produces competitive results in sequential odometry, surface mapping and obstacle avoidance. ",
    "url": "https://arxiv.org/abs/2206.09506",
    "authors": [
      "Lan Wu",
      "Ki Myung Brian Lee",
      "Teresa Vidal-Calleja"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.09509",
    "title": "Hybrid Facial Expression Recognition (FER2013) Model for Real-Time  Emotion Classification and Prediction",
    "abstract": "Facial Expression Recognition is a vital research topic in most fields ranging from artificial intelligence and gaming to Human-Computer Interaction (HCI) and Psychology. This paper proposes a hybrid model for Facial Expression recognition, which comprises a Deep Convolutional Neural Network (DCNN) and Haar Cascade deep learning architectures. The objective is to classify real-time and digital facial images into one of the seven facial emotion categories considered. The DCNN employed in this research has more convolutional layers, ReLU Activation functions, and multiple kernels to enhance filtering depth and facial feature extraction. In addition, a haar cascade model was also mutually used to detect facial features in real-time images and video frames. Grayscale images from the Kaggle repository (FER-2013) and then exploited Graphics Processing Unit (GPU) computation to expedite the training and validation process. Pre-processing and data augmentation techniques are applied to improve training efficiency and classification performance. The experimental results show a significantly improved classification performance compared to state-of-the-art (SoTA) experiments and research. Also, compared to other conventional models, this paper validates that the proposed architecture is superior in classification performance with an improvement of up to 6%, totaling up to 70% accuracy, and with less execution time of 2098.8s. ",
    "url": "https://arxiv.org/abs/2206.09509",
    "authors": [
      "Ozioma Collins Oguine",
      "Kaleab Alamayehu Kinfu",
      "Kanyifeechukwu Jane Oguine",
      "Hashim Ibrahim Bisallah",
      "Daniel Ofuani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.09519",
    "title": "Walking to Hide: Privacy Amplification via Random Message Exchanges in  Network",
    "abstract": "The *shuffle model* is a powerful tool to amplify the privacy guarantees of the *local model* of differential privacy. In contrast to the fully decentralized manner of guaranteeing privacy in the local model, the shuffle model requires a central, trusted shuffler. To avoid this central shuffler, recent work of Liew et al. (2022) proposes shuffling locally randomized data in a decentralized manner, via random walks on the communication network constituted by the clients. The privacy amplification bound it thus provides depends on the topology of the underlying communication network, even for infinitely long random walks. It does not match the state-of-the-art privacy amplification bound for the shuffle model (Feldman et al., 2021). In this work, we prove that the output of~$n$ clients' data, each perturbed by an ${\\epsilon}_0$-local randomizer, and shuffled by random walks with a logarithmic number of steps, is $( {O} ( (1 - e^{-\\epsilon_0} ) \\sqrt{ ( e^{\\epsilon_0} / n ) \\ln (1 / \\delta ) } ), O(\\delta) )$-differentially private. Importantly, this bound is independent of the topology of the communication network, and asymptotically closes the gap between the privacy amplification bounds for the network shuffle model (Liew et al., 2022) and the shuffle model (Feldman et al., 2021). Our proof is based on a reduction to the shuffle model, and an analysis of the distribution of random walks of finite length. Building on this, we further show that if each client is sampled independently with probability~$p$, the privacy guarantee of the network shuffle model can be further improved to $( {O} ( (1 - e^{-\\epsilon_0} ) \\sqrt{p ( e^{\\epsilon_0} / n ) \\ln (1 / \\delta ) } ) , O(\\delta) )$. Importantly, the subsampling is also performed in a fully decentralized manner that does not require a trusted central entity; compared with related bounds in prior work, our bound is stronger. ",
    "url": "https://arxiv.org/abs/2206.09519",
    "authors": [
      "Hao Wu",
      "Olga Ohrimenko",
      "Anthony Wirth"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.09526",
    "title": "Robust One Round Federated Learning with Predictive Space Bayesian  Inference",
    "abstract": "Making predictions robust is an important challenge. A separate challenge in federated learning (FL) is to reduce the number of communication rounds, particularly since doing so reduces performance in heterogeneous data settings. To tackle both issues, we take a Bayesian perspective on the problem of learning a global model. We show how the global predictive posterior can be approximated using client predictive posteriors. This is unlike other works which aggregate the local model space posteriors into the global model space posterior, and are susceptible to high approximation errors due to the posterior's high dimensional multimodal nature. In contrast, our method performs the aggregation on the predictive posteriors, which are typically easier to approximate owing to the low-dimensionality of the output space. We present an algorithm based on this idea, which performs MCMC sampling at each client to obtain an estimate of the local posterior, and then aggregates these in one round to obtain a global ensemble model. Through empirical evaluation on several classification and regression tasks, we show that despite using one round of communication, the method is competitive with other FL techniques, and outperforms them on heterogeneous settings. The code is publicly available at https://github.com/hasanmohsin/FedPredSpace_1Round. ",
    "url": "https://arxiv.org/abs/2206.09526",
    "authors": [
      "Mohsin Hasan",
      "Zehao Zhang",
      "Kaiyang Guo",
      "Mahdi Karami",
      "Guojun Zhang",
      "Xi Chen",
      "Pascal Poupart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.09527",
    "title": "Simultaneous approximation of a smooth function and its derivatives by  deep neural networks with piecewise-polynomial activations",
    "abstract": "This paper investigates the approximation properties of deep neural networks with piecewise-polynomial activation functions. We derive the required depth, width, and sparsity of a deep neural network to approximate any H\\\"{o}lder smooth function up to a given approximation error in H\\\"{o}lder norms in such a way that all weights of this neural network are bounded by $1$. The latter feature is essential to control generalization errors in many statistical and machine learning applications. ",
    "url": "https://arxiv.org/abs/2206.09527",
    "authors": [
      "Denis Belomestny",
      "Alexey Naumov",
      "Nikita Puchkin",
      "Sergey Samsonov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2206.09529",
    "title": "Temporal Link Prediction via Adjusted Sigmoid Function and 2-Simplex  Sructure",
    "abstract": "Temporal network link prediction is an important task in the field of network science, and has a wide range of applications in practical scenarios. Revealing the evolutionary mechanism of the network is essential for link prediction, and how to effectively utilize the historical information for temporal links and efficiently extract the high-order patterns of network structure remains a vital challenge. To address these issues, in this paper, we propose a novel temporal link prediction model with adjusted sigmoid function and 2-simplex structure (TLPSS). The adjusted sigmoid decay mode takes the active, decay and stable states of edges into account, which properly fits the life cycle of information. Moreover, the latent matrix sequence is introduced, which is composed of simplex high-order structure, to enhance the performance of link prediction method since it is highly feasible in sparse network. Combining the life cycle of information and simplex high-order structure, the overall performance of TLPSS is achieved by satisfying the consistency of temporal and structural information in dynamic networks. Experimental results on six real-world datasets demonstrate the effectiveness of TLPSS, and our proposed model improves the performance of link prediction by an average of 15% compared to other baseline methods. ",
    "url": "https://arxiv.org/abs/2206.09529",
    "authors": [
      "Ruizhi Zhang",
      "Qiaozi Wang",
      "Qiming Yang",
      "Wei Wei"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.09535",
    "title": "Extracting Fast and Slow: User-Action Embedding with Inter-temporal  Information",
    "abstract": "With the recent development of technology, data on detailed human temporal behaviors has become available. Many methods have been proposed to mine those human dynamic behavior data and revealed valuable insights for research and businesses. However, most methods analyze only sequence of actions and do not study the inter-temporal information such as the time intervals between actions in a holistic manner. While actions and action time intervals are interdependent, it is challenging to integrate them because they have different natures: time and action. To overcome this challenge, we propose a unified method that analyzes user actions with intertemporal information (time interval). We simultaneously embed the user's action sequence and its time intervals to obtain a low-dimensional representation of the action along with intertemporal information. The paper demonstrates that the proposed method enables us to characterize user actions in terms of temporal context, using three real-world data sets. This paper demonstrates that explicit modeling of action sequences and inter-temporal user behavior information enable successful interpretable analysis. ",
    "url": "https://arxiv.org/abs/2206.09535",
    "authors": [
      "Akira Matsui",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.09549",
    "title": "Cooperative Edge Caching via Multi Agent Reinforcement Learning in Fog  Radio Access Networks",
    "abstract": "In this paper, the cooperative edge caching problem in fog radio access networks (F-RANs) is investigated. To minimize the content transmission delay, we formulate the cooperative caching optimization problem to find the globally optimal caching strategy.By considering the non-deterministic polynomial hard (NP-hard) property of this problem, a Multi Agent Reinforcement Learning (MARL)-based cooperative caching scheme is proposed.Our proposed scheme applies double deep Q-network (DDQN) in every fog access point (F-AP), and introduces the communication process in multi-agent system. Every F-AP records the historical caching strategies of its associated F-APs as the observations of communication procedure.By exchanging the observations, F-APs can leverage the cooperation and make the globally optimal caching strategy.Simulation results show that the proposed MARL-based cooperative caching scheme has remarkable performance compared with the benchmark schemes in minimizing the content transmission delay. ",
    "url": "https://arxiv.org/abs/2206.09549",
    "authors": [
      "Qi Chang",
      "Yanxiang Jiang",
      "Fu-Chun Zheng",
      "Mehdi Bennis",
      "Xiaohu You"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2206.09552",
    "title": "Dynamic Message Propagation Network for RGB-D Salient Object Detection",
    "abstract": "This paper presents a novel deep neural network framework for RGB-D salient object detection by controlling the message passing between the RGB images and depth maps on the feature level and exploring the long-range semantic contexts and geometric information on both RGB and depth features to infer salient objects. To achieve this, we formulate a dynamic message propagation (DMP) module with the graph neural networks and deformable convolutions to dynamically learn the context information and to automatically predict filter weights and affinity matrices for message propagation control. We further embed this module into a Siamese-based network to process the RGB image and depth map respectively and design a multi-level feature fusion (MFF) module to explore the cross-level information between the refined RGB and depth features. Compared with 17 state-of-the-art methods on six benchmark datasets for RGB-D salient object detection, experimental results show that our method outperforms all the others, both quantitatively and visually. ",
    "url": "https://arxiv.org/abs/2206.09552",
    "authors": [
      "Baian Chen",
      "Zhilei Chen",
      "Xiaowei Hu",
      "Jun Xu",
      "Haoran Xie",
      "Mingqiang Wei",
      "Jing Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09564",
    "title": "A Novel Long-term Iterative Mining Scheme for Video Salient Object  Detection",
    "abstract": "The existing state-of-the-art (SOTA) video salient object detection (VSOD) models have widely followed short-term methodology, which dynamically determines the balance between spatial and temporal saliency fusion by solely considering the current consecutive limited frames. However, the short-term methodology has one critical limitation, which conflicts with the real mechanism of our visual system -- a typical long-term methodology. As a result, failure cases keep showing up in the results of the current SOTA models, and the short-term methodology becomes the major technical bottleneck. To solve this problem, this paper proposes a novel VSOD approach, which performs VSOD in a complete long-term way. Our approach converts the sequential VSOD, a sequential task, to a data mining problem, i.e., decomposing the input video sequence to object proposals in advance and then mining salient object proposals as much as possible in an easy-to-hard way. Since all object proposals are simultaneously available, the proposed approach is a complete long-term approach, which can alleviate some difficulties rooted in conventional short-term approaches. In addition, we devised an online updating scheme that can grasp the most representative and trustworthy pattern profile of the salient objects, outputting framewise saliency maps with rich details and smoothing both spatially and temporally. The proposed approach outperforms almost all SOTA models on five widely used benchmark datasets. ",
    "url": "https://arxiv.org/abs/2206.09564",
    "authors": [
      "Chenglizhao Chen",
      "Hengsen Wang",
      "Yuming Fang",
      "Chong Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09567",
    "title": "Two-Dimensional Weisfeiler-Lehman Graph Neural Networks for Link  Prediction",
    "abstract": "Link prediction is one important application of graph neural networks (GNNs). Most existing GNNs for link prediction are based on one-dimensional Weisfeiler-Lehman (1-WL) test. 1-WL-GNNs first compute node representations by iteratively passing neighboring node features to the center, and then obtain link representations by aggregating the pairwise node representations. As pointed out by previous works, this two-step procedure results in low discriminating power, as 1-WL-GNNs by nature learn node-level representations instead of link-level. In this paper, we study a completely different approach which can directly obtain node pair (link) representations based on \\textit{two-dimensional Weisfeiler-Lehman (2-WL) tests}. 2-WL tests directly use links (2-tuples) as message passing units instead of nodes, and thus can directly obtain link representations. We theoretically analyze the expressive power of 2-WL tests to discriminate non-isomorphic links, and prove their superior link discriminating power than 1-WL. Based on different 2-WL variants, we propose a series of novel 2-WL-GNN models for link prediction. Experiments on a wide range of real-world datasets demonstrate their competitive performance to state-of-the-art baselines and superiority over plain 1-WL-GNNs. ",
    "url": "https://arxiv.org/abs/2206.09567",
    "authors": [
      "Yang Hu",
      "Xiyuan Wang",
      "Zhouchen Lin",
      "Pan Li",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09569",
    "title": "Shuffle Gaussian Mechanism for Differential Privacy",
    "abstract": "We study Gaussian mechanism in the shuffle model of differential privacy (DP). Particularly, we characterize the mechanism's R\\'enyi differential privacy (RDP), showing that it is of the form: $$ \\epsilon(\\lambda) \\leq \\frac{1}{\\lambda-1}\\log\\left(\\frac{e^{-\\lambda/2\\sigma^2}}{n^\\lambda}\\sum_{\\substack{k_1+\\dotsc+k_n=\\lambda;\\\\k_1,\\dotsc,k_n\\geq 0}}\\binom{\\lambda!}{k_1,\\dotsc,k_n}e^{\\sum_{i=1}^nk_i^2/2\\sigma^2}\\right) $$ We further prove that the RDP is strictly upper-bounded by the Gaussian RDP without shuffling. The shuffle Gaussian RDP is advantageous in composing multiple DP mechanisms, where we demonstrate its improvement over the state-of-the-art approximate DP composition theorems in privacy guarantees of the shuffle model. Moreover, we extend our study to the subsampled shuffle mechanism and the recently proposed shuffled check-in mechanism, which are protocols geared towards distributed/federated learning. Finally, an empirical study of these mechanisms is given to demonstrate the efficacy of employing shuffle Gaussian mechanism under the distributed learning framework to guarantee rigorous user privacy. ",
    "url": "https://arxiv.org/abs/2206.09569",
    "authors": [
      "Seng Pei Liew",
      "Tsubasa Takahashi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.09575",
    "title": "C-SENN: Contrastive Self-Explaining Neural Network",
    "abstract": "In this study, we use a self-explaining neural network (SENN), which learns unsupervised concepts, to acquire concepts that are easy for people to understand automatically. In concept learning, the hidden layer retains verbalizable features relevant to the output, which is crucial when adapting to real-world environments where explanations are required. However, it is known that the interpretability of concepts output by SENN is reduced in general settings, such as autonomous driving scenarios. Thus, this study combines contrastive learning with concept learning to improve the readability of concepts and the accuracy of tasks. We call this model Contrastive Self-Explaining Neural Network (C-SENN). ",
    "url": "https://arxiv.org/abs/2206.09575",
    "authors": [
      "Yoshihide Sawada",
      "Keigo Nakamura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09592",
    "title": "DALL-E for Detection: Language-driven Context Image Synthesis for Object  Detection",
    "abstract": "Object cut-and-paste has become a promising approach to efficiently generate large sets of labeled training data. It involves compositing foreground object masks onto background images. The background images, when congruent with the objects, provide helpful context information for training object recognition models. While the approach can easily generate large labeled data, finding congruent context images for downstream tasks has remained an elusive problem. In this work, we propose a new paradigm for automatic context image generation at scale. At the core of our approach lies utilizing an interplay between language description of context and language-driven image generation. Language description of a context is provided by applying an image captioning method on a small set of images representing the context. These language descriptions are then used to generate diverse sets of context images using the language-based DALL-E image generation framework. These are then composited with objects to provide an augmented training set for a classifier. We demonstrate the advantages of our approach over the prior context image generation approaches on four object detection datasets. Furthermore, we also highlight the compositional nature of our data generation approach on out-of-distribution and zero-shot data generation scenarios. ",
    "url": "https://arxiv.org/abs/2206.09592",
    "authors": [
      "Yunhao Ge",
      "Jiashu Xu",
      "Brian Nlong Zhao",
      "Laurent Itti",
      "Vibhav Vineet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09599",
    "title": "Examining the Robustness of Spiking Neural Networks on Non-ideal  Memristive Crossbars",
    "abstract": "Spiking Neural Networks (SNNs) have recently emerged as the low-power alternative to Artificial Neural Networks (ANNs) owing to their asynchronous, sparse, and binary information processing. To improve the energy-efficiency and throughput, SNNs can be implemented on memristive crossbars where Multiply-and-Accumulate (MAC) operations are realized in the analog domain using emerging Non-Volatile-Memory (NVM) devices. Despite the compatibility of SNNs with memristive crossbars, there is little attention to study on the effect of intrinsic crossbar non-idealities and stochasticity on the performance of SNNs. In this paper, we conduct a comprehensive analysis of the robustness of SNNs on non-ideal crossbars. We examine SNNs trained via learning algorithms such as, surrogate gradient and ANN-SNN conversion. Our results show that repetitive crossbar computations across multiple time-steps induce error accumulation, resulting in a huge performance drop during SNN inference. We further show that SNNs trained with a smaller number of time-steps achieve better accuracy when deployed on memristive crossbars. ",
    "url": "https://arxiv.org/abs/2206.09599",
    "authors": [
      "Abhiroop Bhattacharjee",
      "Youngeun Kim",
      "Abhishek Moitra",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.09604",
    "title": "Distortion-Aware Network Pruning and Feature Reuse for Real-time Video  Segmentation",
    "abstract": "Real-time video segmentation is a crucial task for many real-world applications such as autonomous driving and robot control. Since state-of-the-art semantic segmentation models are often too heavy for real-time applications despite their impressive performance, researchers have proposed lightweight architectures with speed-accuracy trade-offs, achieving real-time speed at the expense of reduced accuracy. In this paper, we propose a novel framework to speed up any architecture with skip-connections for real-time vision tasks by exploiting the temporal locality in videos. Specifically, at the arrival of each frame, we transform the features from the previous frame to reuse them at specific spatial bins. We then perform partial computation of the backbone network on the regions of the current frame that captures temporal differences between the current and previous frame. This is done by dynamically dropping out residual blocks using a gating mechanism which decides which blocks to drop based on inter-frame distortion. We validate our Spatial-Temporal Mask Generator (STMG) on video semantic segmentation benchmarks with multiple backbone networks, and show that our method largely speeds up inference with minimal loss of accuracy. ",
    "url": "https://arxiv.org/abs/2206.09604",
    "authors": [
      "Hyunsu Rhee",
      "Dongchan Min",
      "Sunil Hwang",
      "Bruno Andreis",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.09607",
    "title": "NLOS Ranging Mitigation with Neural Network Model for UWB Localization",
    "abstract": "Localization of robots is vital for navigation and path planning, such as in cases where a map of the environment is needed. Ultra-Wideband (UWB) for indoor location systems has been gaining popularity over the years with the introduction of low-cost UWB modules providing centimetre-level accuracy. However, in the presence of obstacles in the environment, Non-Line-Of-Sight (NLOS) measurements from the UWB will produce inaccurate results. As low-cost UWB devices do not provide channel information, we propose an approach to decide if a measurement is within Line-Of-Sight (LOS) or not by using some signal strength information provided by low-cost UWB modules through a Neural Network (NN) model. The result of this model is the probability of a ranging measurement being LOS which was used for localization through the Weighted-Least-Square (WLS) method. Our approach improves localization accuracy by 16.93% on the lobby testing data and 27.97% on the corridor testing data using the NN model trained with all extracted inputs from the office training data. ",
    "url": "https://arxiv.org/abs/2206.09607",
    "authors": [
      "Muhammad Shalihan",
      "Ran Liu",
      "Chau Yuen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.09619",
    "title": "Analyzing B\u00fcchi Automata with Graph Neural Networks",
    "abstract": "B\\\"uchi Automata on infinite words present many interesting problems and are used frequently in program verification and model checking. A lot of these problems on B\\\"uchi automata are computationally hard, raising the question if a learning-based data-driven analysis might be more efficient than using traditional algorithms. Since B\\\"uchi automata can be represented by graphs, graph neural networks are a natural choice for such a learning-based analysis. In this paper, we demonstrate how graph neural networks can be used to reliably predict basic properties of B\\\"uchi automata when trained on automatically generated random automata datasets. ",
    "url": "https://arxiv.org/abs/2206.09619",
    "authors": [
      "Christophe Stammet",
      "Prisca Dotti",
      "Ulrich Ultes-Nitsche",
      "Andreas Fischer"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09620",
    "title": "Asymptotic Nash Equilibrium for the $M$-ary Sequential Adversarial  Hypothesis Testing Game",
    "abstract": "In this paper, we consider a novel $M$-ary sequential hypothesis testing problem in which an adversary is present and perturbs the distributions of the samples before the decision maker observes them. This problem is formulated as a sequential adversarial hypothesis testing game played between the decision maker and the adversary. This game is a zero-sum and strategic one. We assume the adversary is active under \\emph{all} hypotheses and knows the underlying distribution of observed samples. We adopt this framework as it is the worst-case scenario from the perspective of the decision maker. The goal of the decision maker is to minimize the expectation of the stopping time to ensure that the test is as efficient as possible; the adversary's goal is, instead, to maximize the stopping time. We derive a pair of strategies under which the asymptotic Nash equilibrium of the game is attained. We also consider the case in which the adversary is not aware of the underlying hypothesis and hence is constrained to apply the same strategy regardless of which hypothesis is in effect. Numerical results corroborate our theoretical findings. ",
    "url": "https://arxiv.org/abs/2206.09620",
    "authors": [
      "Jiachun Pan",
      "Yonglong Li",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.09623",
    "title": "MDS Codes Based Group Coded Caching in Fog Radio Access Networks",
    "abstract": "In this paper, we investigate maximum distance separable (MDS) codes based group coded caching in fog radio access networks (F-RANs). The goal is to minimize the average fronthaul rate under nonuniform file popularity. Firstly, an MDS codes and file grouping based coded placement scheme is proposed to provide coded packets and allocate more cache to the most popular files simultaneously. Next, a fog access point (F-AP) grouping based coded delivery scheme is proposed to meet the requests for files from different groups. Furthermore, a closed-form expression of the average fronthaul rate is derived. Finally, the parameters related to the proposed coded caching scheme are optimized to fully utilize the gains brought by MDS codes and file grouping. Simulation results show that our proposed scheme obtains significant performance improvement over several existing caching schemes in terms of fronthaul rate reduction. ",
    "url": "https://arxiv.org/abs/2206.09623",
    "authors": [
      "Qianli Tan",
      "Yanxiang Jiang",
      "Fu-Chun Zheng",
      "Mehdi Bennis",
      "Xiaohu You"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2206.09628",
    "title": "Diversified Adversarial Attacks based on Conjugate Gradient Method",
    "abstract": "Deep learning models are vulnerable to adversarial examples, and adversarial attacks used to generate such examples have attracted considerable research interest. Although existing methods based on the steepest descent have achieved high attack success rates, ill-conditioned problems occasionally reduce their performance. To address this limitation, we utilize the conjugate gradient (CG) method, which is effective for this type of problem, and propose a novel attack algorithm inspired by the CG method, named the Auto Conjugate Gradient (ACG) attack. The results of large-scale evaluation experiments conducted on the latest robust models show that, for most models, ACG was able to find more adversarial examples with fewer iterations than the existing SOTA algorithm Auto-PGD (APGD). We investigated the difference in search performance between ACG and APGD in terms of diversification and intensification, and define a measure called Diversity Index (DI) to quantify the degree of diversity. From the analysis of the diversity using this index, we show that the more diverse search of the proposed method remarkably improves its attack success rate. ",
    "url": "https://arxiv.org/abs/2206.09628",
    "authors": [
      "Keiichiro Yamamura",
      "Haruki Sato",
      "Nariaki Tateiwa",
      "Nozomi Hata",
      "Toru Mitsutake",
      "Issa Oe",
      "Hiroki Ishikura",
      "Katsuki Fujisawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09642",
    "title": "Beyond IID: data-driven decision-making in heterogeneous environments",
    "abstract": "In this work, we study data-driven decision-making and depart from the classical identically and independently distributed (i.i.d.) assumption. We present a new framework in which historical samples are generated from unknown and different distributions, which we dub heterogeneous environments. These distributions are assumed to lie in a heterogeneity ball with known radius and centered around the (also) unknown future (out-of-sample) distribution on which the performance of a decision will be evaluated. We quantify the asymptotic worst-case regret that is achievable by central data-driven policies such as Sample Average Approximation, but also by rate-optimal ones, as a function of the radius of the heterogeneity ball. Our work shows that the type of achievable performance varies considerably across different combinations of problem classes and notions of heterogeneity. We demonstrate the versatility of our framework by comparing achievable guarantees for the heterogeneous version of widely studied data-driven problems such as pricing, ski-rental, and newsvendor. En route, we establish a new connection between data-driven decision-making and distributionally robust optimization. ",
    "url": "https://arxiv.org/abs/2206.09642",
    "authors": [
      "Omar Besbes",
      "Will Ma",
      "Omar Mouchtaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.09654",
    "title": "Performance Prediction in Major League Baseball by Long Short-Term  Memory Networks",
    "abstract": "Player performance prediction is a serious problem in every sport since it brings valuable future information for managers to make important decisions. In baseball industries, there already existed variable prediction systems and many types of researches that attempt to provide accurate predictions and help domain users. However, it is a lack of studies about the predicting method or systems based on deep learning. Deep learning models had proven to be the greatest solutions in different fields nowadays, so we believe they could be tried and applied to the prediction problem in baseball. Hence, the predicting abilities of deep learning models are set to be our research problem in this paper. As a beginning, we select numbers of home runs as the target because it is one of the most critical indexes to understand the power and the talent of baseball hitters. Moreover, we use the sequential model Long Short-Term Memory as our main method to solve the home run prediction problem in Major League Baseball. We compare models' ability with several machine learning models and a widely used baseball projection system, sZymborski Projection System. Our results show that Long Short-Term Memory has better performance than others and has the ability to make more exact predictions. We conclude that Long Short-Term Memory is a feasible way for performance prediction problems in baseball and could bring valuable information to fit users' needs. ",
    "url": "https://arxiv.org/abs/2206.09654",
    "authors": [
      "Hsuan-Cheng Sun",
      "Tse-Yu Lin",
      "Yen-Lung Tsai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.09664",
    "title": "What Can be Seen is What You Get: Structure Aware Point Cloud  Augmentation",
    "abstract": "To train a well performing neural network for semantic segmentation, it is crucial to have a large dataset with available ground truth for the network to generalize on unseen data. In this paper we present novel point cloud augmentation methods to artificially diversify a dataset. Our sensor-centric methods keep the data structure consistent with the lidar sensor capabilities. Due to these new methods, we are able to enrich low-value data with high-value instances, as well as create entirely new scenes. We validate our methods on multiple neural networks with the public SemanticKITTI dataset and demonstrate that all networks improve compared to their respective baseline. In addition, we show that our methods enable the use of very small datasets, saving annotation time, training time and the associated costs. ",
    "url": "https://arxiv.org/abs/2206.09664",
    "authors": [
      "Frederik Hasecke",
      "Martin Alsfasser",
      "Anton Kummert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09672",
    "title": "Adaptive Domain Interest Network for Multi-domain Recommendation",
    "abstract": "Industrial recommender systems usually hold data from multiple business scenarios and are expected to provide recommendation services for these scenarios simultaneously. In the retrieval step, the topK high-quality items selected from a large number of corpus usually need to be various for multiple scenarios. Take Alibaba display advertising system for example, not only because the behavior patterns of Taobao users are diverse, but also differentiated scenarios' bid prices assigned by advertisers vary significantly. Traditional methods either train models for each scenario separately, ignoring the cross-domain overlapping of user groups and items, or simply mix all samples and maintain a shared model which makes it difficult to capture significant diversities between scenarios. In this paper, we present Adaptive Domain Interest network that adaptively handles the commonalities and diversities across scenarios, making full use of multi-scenarios data during training. Then the proposed method is able to improve the performance of each business domain by giving various topK candidates for different scenarios during online inference. Specifically, our proposed ADI models the commonalities and diversities for different domains by shared networks and domain-specific networks, respectively. In addition, we apply the domain-specific batch normalization and design the domain interest adaptation layer for feature-level domain adaptation. A self training strategy is also incorporated to capture label-level connections across domains.ADI has been deployed in the display advertising system of Alibaba, and obtains 1.8% improvement on advertising revenue. ",
    "url": "https://arxiv.org/abs/2206.09672",
    "authors": [
      "Yuchen Jiang",
      "Qi Li",
      "Han Zhu",
      "Jinbei Yu",
      "Jin Li",
      "Ziru Xu",
      "Huihui Dong",
      "Bo Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.09677",
    "title": "GraphFramEx: Towards Systematic Evaluation of Explainability Methods for  Graph Neural Networks",
    "abstract": "As one of the most popular machine learning models today, graph neural networks (GNNs) have attracted intense interest recently, and so does their explainability. Users are increasingly interested in a better understanding of GNN models and their outcomes. Unfortunately, today's evaluation frameworks for GNN explainability often rely on synthetic datasets, leading to conclusions of limited scope due to a lack of complexity in the problem instances. As GNN models are deployed to more mission-critical applications, we are in dire need for a common evaluation protocol of explainability methods of GNNs. In this paper, we propose, to our best knowledge, the first systematic evaluation framework for GNN explainability, considering explainability on three different \"user needs:\" explanation focus, mask nature, and mask transformation. We propose a unique metric that combines the fidelity measures and classify explanations based on their quality of being sufficient or necessary. We scope ourselves to node classification tasks and compare the most representative techniques in the field of input-level explainability for GNNs. For the widely used synthetic benchmarks, surprisingly shallow techniques such as personalized PageRank have the best performance for a minimum computation time. But when the graph structure is more complex and nodes have meaningful features, gradient-based methods, in particular Saliency, are the best according to our evaluation criteria. However, none dominates the others on all evaluation dimensions and there is always a trade-off. We further apply our evaluation protocol in a case study on eBay graphs to reflect the production environment. ",
    "url": "https://arxiv.org/abs/2206.09677",
    "authors": [
      "Kenza Amara",
      "Rex Ying",
      "Zitao Zhang",
      "Zhihao Han",
      "Yinan Shan",
      "Ulrik Brandes",
      "Sebastian Schemm",
      "Ce Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.09683",
    "title": "Distribution Regularized Self-Supervised Learning for Domain Adaptation  of Semantic Segmentation",
    "abstract": "This paper proposes a novel pixel-level distribution regularization scheme (DRSL) for self-supervised domain adaptation of semantic segmentation. In a typical setting, the classification loss forces the semantic segmentation model to greedily learn the representations that capture inter-class variations in order to determine the decision (class) boundary. Due to the domain shift, this decision boundary is unaligned in the target domain, resulting in noisy pseudo labels adversely affecting self-supervised domain adaptation. To overcome this limitation, along with capturing inter-class variation, we capture pixel-level intra-class variations through class-aware multi-modal distribution learning (MMDL). Thus, the information necessary for capturing the intra-class variations is explicitly disentangled from the information necessary for inter-class discrimination. Features captured thus are much more informative, resulting in pseudo-labels with low noise. This disentanglement allows us to perform separate alignments in discriminative space and multi-modal distribution space, using cross-entropy based self-learning for the former. For later, we propose a novel stochastic mode alignment method, by explicitly decreasing the distance between the target and source pixels that map to the same mode. The distance metric learning loss, computed over pseudo-labels and backpropagated from multi-modal modeling head, acts as the regularizer over the base network shared with the segmentation head. The results from comprehensive experiments on synthetic to real domain adaptation setups, i.e., GTA-V/SYNTHIA to Cityscapes, show that DRSL outperforms many existing approaches (a minimum margin of 2.3% and 2.5% in mIoU for SYNTHIA to Cityscapes). ",
    "url": "https://arxiv.org/abs/2206.09683",
    "authors": [
      "Javed Iqbal",
      "Hamza Rawal",
      "Rehan Hafiz",
      "Yu-Tseh Chi",
      "Mohsen Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09735",
    "title": "A Safe Control Architecture Based on Robust Model Predictive Control for  Autonomous Driving",
    "abstract": "This paper proposes a Robust Safe Control Architecture (RSCA) for safe-decision making. The system to be controlled is a vehicle in the presence of bounded disturbances. The RSCA consists of two parts: a Supervisor MPC and a Controller MPC. Both the Supervisor and the Controller are tube MPCs (TMPCs). The Supervisor MPC provides a safety certificate for an operating controller and a backup control input in every step. After an unsafe action by the operating controller is predicted, the Controller MPC takes over the system. In this paper, a method for the computation of a terminal set is proposed, which is robust against changes in road curvature and forces the vehicle to reach a safe reference. Moreover, two important proofs are provided in this paper. First, it is shown that the backup control input is safe to be applied to the system to lead the vehicle to a safe state. Next, the recursive feasibility of the RSCA is proven. By simulating some obstacle avoidance scenarios, the effectiveness of the proposed RSCA is confirmed. ",
    "url": "https://arxiv.org/abs/2206.09735",
    "authors": [
      "Maryam Nezami",
      "Ngoc Thinh Nguyen",
      "Georg M\u00e4nnel",
      "Hossam Seddik Abbas",
      "Georg Schildbach"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.09736",
    "title": "Geo-NI: Geometry-aware Neural Interpolation for Light Field Rendering",
    "abstract": "In this paper, we present a Geometry-aware Neural Interpolation (Geo-NI) framework for light field rendering. Previous learning-based approaches either rely on the capability of neural networks to perform direct interpolation, which we dubbed Neural Interpolation (NI), or explore scene geometry for novel view synthesis, also known as Depth Image-Based Rendering (DIBR). Instead, we incorporate the ideas behind these two kinds of approaches by launching the NI with a novel DIBR pipeline. Specifically, the proposed Geo-NI first performs NI using input light field sheared by a set of depth hypotheses. Then the DIBR is implemented by assigning the sheared light fields with a novel reconstruction cost volume according to the reconstruction quality under different depth hypotheses. The reconstruction cost is interpreted as a blending weight to render the final output light field by blending the reconstructed light fields along the dimension of depth hypothesis. By combining the superiorities of NI and DIBR, the proposed Geo-NI is able to render views with large disparity with the help of scene geometry while also reconstruct non-Lambertian effect when depth is prone to be ambiguous. Extensive experiments on various datasets demonstrate the superior performance of the proposed geometry-aware light field rendering framework. ",
    "url": "https://arxiv.org/abs/2206.09736",
    "authors": [
      "Gaochang Wu",
      "Yuemei Zhou",
      "Yebin Liu",
      "Lu Fang",
      "Tianyou Chai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.09752",
    "title": "A Comparative Study on Application of Class-Imbalance Learning for  Severity Prediction of Adverse Events Following Immunization",
    "abstract": "In collaboration with the Liaoning CDC, China, we propose a prediction system to predict the subsequent hospitalization of children with adverse reactions based on data on adverse events following immunization. We extracted multiple features from the data, and selected \"hospitalization or not\" as the target for classification. Since the data are imbalanced, we used various class-imbalance learning methods for training and improved the RUSBoost algorithm. Experimental results show that the improved RUSBoost has the highest Area Under the ROC Curve on the target among these algorithms. Additionally, we compared these class-imbalance learning methods with some common machine learning algorithms. We combined the improved RUSBoost with dynamic web resource development techniques to build an evaluation system with information entry and vaccination response prediction capabilities for relevant medical practitioners. ",
    "url": "https://arxiv.org/abs/2206.09752",
    "authors": [
      "Ning Chen",
      "Zhengke Sun",
      "Tong Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09753",
    "title": "Visualizing and Understanding Self-Supervised Vision Learning",
    "abstract": "Self-Supervised vision learning has revolutionized deep learning, becoming the next big challenge in the domain and rapidly closing the gap with supervised methods on large computer vision benchmarks. With current models and training data exponentially growing, explaining and understanding these models becomes pivotal. We study the problem of explainable artificial intelligence in the domain of self-supervised learning for vision tasks, and present methods to understand networks trained with self-supervision and their inner workings. Given the huge diversity of self-supervised vision pretext tasks, we narrow our focus on understanding paradigms which learn from two views of the same image, and mainly aim to understand the pretext task. Our work focuses on explaining similarity learning, and is easily extendable to all other pretext tasks. We study two popular self-supervised vision models: SimCLR and Barlow Twins. We develop a total of six methods for visualizing and understanding these models: Perturbation-based methods (conditional occlusion, context-agnostic conditional occlusion and pairwise occlusion), Interaction-CAM, Feature Visualization, Model Difference Visualization, Averaged Transforms and Pixel Invaraince. Finally, we evaluate these explanations by translating well-known evaluation metrics tailored towards supervised image classification systems involving a single image, into the domain of self-supervised learning where two images are involved. Code is at: https://github.com/fawazsammani/xai-ssl ",
    "url": "https://arxiv.org/abs/2206.09753",
    "authors": [
      "Fawaz Sammani",
      "Boris Joukovsky",
      "Nikos Deligiannis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09756",
    "title": "Time Gated Convolutional Neural Networks for Crop Classification",
    "abstract": "This paper presented a state-of-the-art framework, Time Gated Convolutional Neural Network (TGCNN) that takes advantage of temporal information and gating mechanisms for the crop classification problem. Besides, several vegetation indices were constructed to expand dimensions of input data to take advantage of spectral information. Both spatial (channel-wise) and temporal (step-wise) correlation are considered in TGCNN. Specifically, our preliminary analysis indicates that step-wise information is of greater importance in this data set. Lastly, the gating mechanism helps capture high-order relationship. Our TGCNN solution achieves $0.973$ F1 score, $0.977$ AUC ROC and $0.948$ IoU, respectively. In addition, it outperforms three other benchmarks in different local tasks (Kenya, Brazil and Togo). Overall, our experiments demonstrate that TGCNN is advantageous in this earth observation time series classification task. ",
    "url": "https://arxiv.org/abs/2206.09756",
    "authors": [
      "Longlong Weng",
      "Yashu Kang",
      "Kezhao Jiang",
      "Chunlei Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.09777",
    "title": "Actively learning to learn causal relationships",
    "abstract": "How do people actively learn to learn? That is, how and when do people choose actions that facilitate long-term learning and choosing future actions that are more informative? We explore these questions in the domain of active causal learning. We propose a hierarchical Bayesian model that goes beyond past models by predicting that people pursue information not only about the causal relationship at hand but also about causal overhypotheses$\\unicode{x2014}$abstract beliefs about causal relationships that span multiple situations and constrain how we learn the specifics in each situation. In two active \"blicket detector\" experiments with 14 between-subjects manipulations, our model was supported by both qualitative trends in participant behavior and an individual-differences-based model comparison. Our results suggest when there are abstract similarities across active causal learning problems, people readily learn and transfer overhypotheses about these similarities. Moreover, people exploit these overhypotheses to facilitate long-term active learning. ",
    "url": "https://arxiv.org/abs/2206.09777",
    "authors": [
      "Chentian Jiang",
      "Christopher G. Lucas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09796",
    "title": "Knowledge Distillation for Oriented Object Detection on Aerial Images",
    "abstract": "Deep convolutional neural network with increased number of parameters has achieved improved precision in task of object detection on natural images, where objects of interests are annotated with horizontal boundary boxes. On aerial images captured from the bird-view perspective, these improvements on model architecture and deeper convolutional layers can also boost the performance on oriented object detection task. However, it is hard to directly apply those state-of-the-art object detectors on the devices with limited computation resources, which necessitates lightweight models through model compression. In order to address this issue, we present a model compression method for rotated object detection on aerial images by knowledge distillation, namely KD-RNet. With a well-trained teacher oriented object detector with a large number of parameters, the obtained object category and location information are both transferred to a compact student network in KD-RNet by collaborative training strategy. Transferring the category information is achieved by knowledge distillation on predicted probability distribution, and a soft regression loss is adopted for handling displacement in location information transfer. The experimental result on a large-scale aerial object detection dataset (DOTA) demonstrates that the proposed KD-RNet model can achieve improved mean-average precision (mAP) with reduced number of parameters, at the same time, KD-RNet boost the performance on providing high quality detections with higher overlap with groundtruth annotations. ",
    "url": "https://arxiv.org/abs/2206.09796",
    "authors": [
      "Yicheng Xiao",
      "Junpeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09798",
    "title": "Actively Learning Deep Neural Networks with Uncertainty Sampling Based  on Sum-Product Networks",
    "abstract": "Active learning is popular approach for reducing the amount of data in training deep neural network model. Its success hinges on the choice of an effective acquisition function, which ranks not yet labeled data points according to their expected informativeness. In uncertainty sampling, the uncertainty that the current model has about a point's class label is the main criterion for this type of ranking. This paper proposes a new approach to uncertainty sampling in training a Convolutional Neural Network (CNN). The main idea is to use feature representation extracted extracted by the CNN as data for training a Sum-Product Network (SPN). Since SPNs are typically used for estimating the distribution of a dataset, they are well suited to the task of estimating class probabilities that can be used directly by standard acquisition functions such as max entropy and variational ratio. Moreover, we enhance these acquisition functions by weights calculated with the help of the SPN model; these weights make the acquisition function more sensitive to the diversity of conceivable class labels for data points. The effectiveness of our method is demonstrated in an experimental study on the MNIST, Fashion-MNIST and CIFAR-10 datasets, where we compare it to the state-of-the-art methods MC Dropout and Bayesian Batch. ",
    "url": "https://arxiv.org/abs/2206.09798",
    "authors": [
      "Mohamadsadegh Khosravani",
      "Sandra Zilles"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2206.09806",
    "title": "Self-Supervised Consistent Quantization for Fully Unsupervised Image  Retrieval",
    "abstract": "Unsupervised image retrieval aims to learn an efficient retrieval system without expensive data annotations, but most existing methods rely heavily on handcrafted feature descriptors or pre-trained feature extractors. To minimize human supervision, recent advance proposes deep fully unsupervised image retrieval aiming at training a deep model from scratch to jointly optimize visual features and quantization codes. However, existing approach mainly focuses on instance contrastive learning without considering underlying semantic structure information, resulting in sub-optimal performance. In this work, we propose a novel self-supervised consistent quantization approach to deep fully unsupervised image retrieval, which consists of part consistent quantization and global consistent quantization. In part consistent quantization, we devise part neighbor semantic consistency learning with codeword diversity regularization. This allows to discover underlying neighbor structure information of sub-quantized representations as self-supervision. In global consistent quantization, we employ contrastive learning for both embedding and quantized representations and fuses these representations for consistent contrastive regularization between instances. This can make up for the loss of useful representation information during quantization and regularize consistency between instances. With a unified learning objective of part and global consistent quantization, our approach exploits richer self-supervision cues to facilitate model learning. Extensive experiments on three benchmark datasets show the superiority of our approach over the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2206.09806",
    "authors": [
      "Guile Wu",
      "Chao Zhang",
      "Stephan Liwicki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09811",
    "title": "Shapley-NAS: Discovering Operation Contribution for Neural Architecture  Search",
    "abstract": "In this paper, we propose a Shapley value based method to evaluate operation contribution (Shapley-NAS) for neural architecture search. Differentiable architecture search (DARTS) acquires the optimal architectures by optimizing the architecture parameters with gradient descent, which significantly reduces the search cost. However, the magnitude of architecture parameters updated by gradient descent fails to reveal the actual operation importance to the task performance and therefore harms the effectiveness of obtained architectures. By contrast, we propose to evaluate the direct influence of operations on validation accuracy. To deal with the complex relationships between supernet components, we leverage Shapley value to quantify their marginal contributions by considering all possible combinations. Specifically, we iteratively optimize the supernet weights and update the architecture parameters by evaluating operation contributions via Shapley value, so that the optimal architectures are derived by selecting the operations that contribute significantly to the tasks. Since the exact computation of Shapley value is NP-hard, the Monte-Carlo sampling based algorithm with early truncation is employed for efficient approximation, and the momentum update mechanism is adopted to alleviate fluctuation of the sampling process. Extensive experiments on various datasets and various search spaces show that our Shapley-NAS outperforms the state-of-the-art methods by a considerable margin with light search cost. The code is available at https://github.com/Euphoria16/Shapley-NAS.git ",
    "url": "https://arxiv.org/abs/2206.09811",
    "authors": [
      "Han Xiao",
      "Ziwei Wang",
      "Zheng Zhu",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09868",
    "title": "Understanding Robust Learning through the Lens of Representation  Similarities",
    "abstract": "Representation learning, i.e. the generation of representations useful for downstream applications, is a task of fundamental importance that underlies much of the success of deep neural networks (DNNs). Recently, robustness to adversarial examples has emerged as a desirable property for DNNs, spurring the development of robust training methods that account for adversarial examples. In this paper, we aim to understand how the properties of representations learned by robust training differ from those obtained from standard, non-robust training. This is critical to diagnosing numerous salient pitfalls in robust networks, such as, degradation of performance on benign inputs, poor generalization of robustness, and increase in over-fitting. We utilize a powerful set of tools known as representation similarity metrics, across three vision datasets, to obtain layer-wise comparisons between robust and non-robust DNNs with different architectures, training procedures and adversarial constraints. Our experiments highlight hitherto unseen properties of robust representations that we posit underlie the behavioral differences of robust networks. We discover a lack of specialization in robust networks' representations along with a disappearance of `block structure'. We also find overfitting during robust training largely impacts deeper layers. These, along with other findings, suggest ways forward for the design and training of better robust networks. ",
    "url": "https://arxiv.org/abs/2206.09868",
    "authors": [
      "Christian Cianfarani",
      "Arjun Nitin Bhagoji",
      "Vikash Sehwag",
      "Ben Zhao",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09870",
    "title": "Privacy-aware Secure Region-based Handover for Small Cell Networks in  5G-enabled Mobile Communication",
    "abstract": "The 5G mobile communication network provides seamless communications between users and service providers and promises to achieve several stringent requirements, such as seamless mobility and massive connectivity. Although 5G can offer numerous benefits, security and privacy issues still need to be addressed. For example, the inclusion of small cell networks (SCN) into 5G brings the network closer to the connected users, providing a better quality of services (QoS), resulting in a significant increase in the number of Handover procedures (HO), which will affect the security, latency and efficiency of the network. It is then crucial to design a scheme that supports seamless handovers through secure authentication to avoid the consequences of SCN. To address this issue, this article proposes a secure region-based handover scheme with user anonymity and an efficient revocation mechanism that supports seamless connectivity for SCNs in 5G. In this context, we introduce three privacy-preserving authentication protocols, i.e., initial authentication protocol, intra-region handover protocol and inter-region handover protocol, for dealing with three communication scenarios. To the best of our knowledge, this is the first paper to consider the privacy and security in both the intra-region and inter-region handover scenarios in 5G communication. Detailed security and performance analysis of our proposed scheme is presented to show that it is resilient against many security threats, is cost-effective in computation and provides an efficient solution for the 5G enabled mobile communication. ",
    "url": "https://arxiv.org/abs/2206.09870",
    "authors": [
      "Rabiah Alnashwan",
      "Prosanta Gope",
      "Benjamin Dowling"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.09885",
    "title": "KOLOMVERSE: KRISO open large-scale image dataset for object detection in  the maritime universe",
    "abstract": "Over the years, datasets have been developed for various object detection tasks. Object detection in the maritime domain is essential for the safety and navigation of ships. However, there is still a lack of publicly available large-scale datasets in the maritime domain. To overcome this challenge, we present KOLOMVERSE, an open large-scale image dataset for object detection in the maritime domain by KRISO (Korea Research Institute of Ships and Ocean Engineering). We collected 5,845 hours of video data captured from 21 territorial waters of South Korea. Through an elaborate data quality assessment process, we gathered around 2,151,470 4K resolution images from the video data. This dataset considers various environments: weather, time, illumination, occlusion, viewpoint, background, wind speed, and visibility. The KOLOMVERSE consists of five classes (ship, buoy, fishnet buoy, lighthouse and wind farm) for maritime object detection. The dataset has images of 3840$\\times$2160 pixels and to our knowledge, it is by far the largest publicly available dataset for object detection in the maritime domain. We performed object detection experiments and evaluated our dataset on several pre-trained state-of-the-art architectures to show the effectiveness and usefulness of our dataset. The dataset is available at: \\url{https://github.com/MaritimeDataset/KOLOMVERSE}. ",
    "url": "https://arxiv.org/abs/2206.09885",
    "authors": [
      "Abhilasha Nanda",
      "Sung Won Cho",
      "Hyeopwoo Lee",
      "Jin Hyoung Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09907",
    "title": "ORFD: A Dataset and Benchmark for Off-Road Freespace Detection",
    "abstract": "Freespace detection is an essential component of autonomous driving technology and plays an important role in trajectory planning. In the last decade, deep learning-based free space detection methods have been proved feasible. However, these efforts were focused on urban road environments and few deep learning-based methods were specifically designed for off-road free space detection due to the lack of off-road benchmarks. In this paper, we present the ORFD dataset, which, to our knowledge, is the first off-road free space detection dataset. The dataset was collected in different scenes (woodland, farmland, grassland, and countryside), different weather conditions (sunny, rainy, foggy, and snowy), and different light conditions (bright light, daylight, twilight, darkness), which totally contains 12,198 LiDAR point cloud and RGB image pairs with the traversable area, non-traversable area and unreachable area annotated in detail. We propose a novel network named OFF-Net, which unifies Transformer architecture to aggregate local and global information, to meet the requirement of large receptive fields for free space detection tasks. We also propose the cross-attention to dynamically fuse LiDAR and RGB image information for accurate off-road free space detection. Dataset and code are publicly available athttps://github.com/chaytonmin/OFF-Net. ",
    "url": "https://arxiv.org/abs/2206.09907",
    "authors": [
      "Chen Min",
      "Weizhong Jiang",
      "Dawei Zhao",
      "Jiaolong Xu",
      "Liang Xiao",
      "Yiming Nie",
      "Bin Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09912",
    "title": "A Dense Representation Framework for Lexical and Semantic Matching",
    "abstract": "Lexical and semantic matching capture different successful approaches to text retrieval and the fusion of their results has proven to be more effective and robust than either alone. Prior work performs hybrid retrieval by conducting lexical and semantic text matching using different systems (e.g., Lucene and Faiss, respectively) and then fusing their model outputs. In contrast, our work integrates lexical representations with dense semantic representations by densifying high-dimensional lexical representations into what we call low-dimensional dense lexical representations (DLRs). Our experiments show that DLRs can effectively approximate the original lexical representations, preserving effectiveness while improving query latency. Furthermore, we can combine dense lexical and semantic representations to generate dense hybrid representations (DHRs) that are more flexible and yield faster retrieval compared to existing hybrid techniques. Finally, we explore {\\it jointly} training lexical and semantic representations in a single model and empirically show that the resulting DHRs are able to combine the advantages of each individual component. Our best DHR model is competitive with state-of-the-art single-vector and multi-vector dense retrievers in both in-domain and zero-shot evaluation settings. Furthermore, our model is both faster and requires smaller indexes, making our dense representation framework an attractive approach to text retrieval. Our code is available at https://github.com/castorini/dhr. ",
    "url": "https://arxiv.org/abs/2206.09912",
    "authors": [
      "Sheng-Chieh Lin",
      "Jimmy Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.09917",
    "title": "Multilingual HateCheck: Functional Tests for Multilingual Hate Speech  Detection Models",
    "abstract": "Hate speech detection models are typically evaluated on held-out test sets. However, this risks painting an incomplete and potentially misleading picture of model performance because of increasingly well-documented systematic gaps and biases in hate speech datasets. To enable more targeted diagnostic insights, recent research has thus introduced functional tests for hate speech detection models. However, these tests currently only exist for English-language content, which means that they cannot support the development of more effective models in other languages spoken by billions across the world. To help address this issue, we introduce Multilingual HateCheck (MHC), a suite of functional tests for multilingual hate speech detection models. MHC covers 34 functionalities across ten languages, which is more languages than any other hate speech dataset. To illustrate MHC's utility, we train and test a high-performing multilingual hate speech detection model, and reveal critical model weaknesses for monolingual and cross-lingual applications. ",
    "url": "https://arxiv.org/abs/2206.09917",
    "authors": [
      "Paul R\u00f6ttger",
      "Haitham Seelawi",
      "Debora Nozza",
      "Zeerak Talat",
      "Bertie Vidgen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.09951",
    "title": "Seizure Detection and Prediction by Parallel Memristive Convolutional  Neural Networks",
    "abstract": "During the past two decades, epileptic seizure detection and prediction algorithms have evolved rapidly. However, despite significant performance improvements, their hardware implementation using conventional technologies, such as Complementary Metal-Oxide-Semiconductor (CMOS), in power and area-constrained settings remains a challenging task; especially when many recording channels are used. In this paper, we propose a novel low-latency parallel Convolutional Neural Network (CNN) architecture that has between 2-2,800x fewer network parameters compared to SOTA CNN architectures and achieves 5-fold cross validation accuracy of 99.84% for epileptic seizure detection, and 99.01% and 97.54% for epileptic seizure prediction, when evaluated using the University of Bonn Electroencephalogram (EEG), CHB-MIT and SWEC-ETHZ seizure datasets, respectively. We subsequently implement our network onto analog crossbar arrays comprising Resistive Random-Access Memory (RRAM) devices, and provide a comprehensive benchmark by simulating, laying out, and determining hardware requirements of the CNN component of our system. To the best of our knowledge, we are the first to parallelize the execution of convolution layer kernels on separate analog crossbars to enable 2 orders of magnitude reduction in latency compared to SOTA hybrid Memristive-CMOS DL accelerators. Furthermore, we investigate the effects of non-idealities on our system and investigate Quantization Aware Training (QAT) to mitigate the performance degradation due to low ADC/DAC resolution. Finally, we propose a stuck weight offsetting methodology to mitigate performance degradation due to stuck RON/ROFF memristor weights, recovering up to 32% accuracy, without requiring retraining. The CNN component of our platform is estimated to consume approximately 2.791W of power while occupying an area of 31.255mm$^2$ in a 22nm FDSOI CMOS process. ",
    "url": "https://arxiv.org/abs/2206.09951",
    "authors": [
      "Chenqi Li",
      "Corey Lammie",
      "Xuening Dong",
      "Amirali Amirsoleimani",
      "Mostafa Rahimi Azghadi",
      "Roman Genov"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2206.09960",
    "title": "A Fast Algorithm for Ranking Users by their Influence in Online Social  Platforms",
    "abstract": "Measuring the influence of users in social networks is key for numerous applications. A recently proposed influence metric, coined as $\\psi$-score, allows to go beyond traditional centrality metrics, which only assess structural graph importance, by further incorporating the rich information provided by the posting and re-posting activity of users. The $\\psi$-score is shown in fact to generalize PageRank for non-homogeneous node activity. Despite its significance, it scales poorly to large datasets; for a network of $N$ users it requires to solve $N$ linear systems of equations of size $N$. To address this problem, this work introduces a novel scalable algorithm for the fast approximation of $\\psi$-score, named Power-$\\psi$. The proposed algorithm is based on a novel equation indicating that it suffices to solve one system of equations of size $N$ to compute the $\\psi$-score. Then, our algorithm exploits the fact that such system can be recursively and distributedly approximated to any desired error. This permits the $\\psi$-score, summarizing both structural and behavioral information for the nodes, to run as fast as PageRank. We validate the effectiveness of the proposed algorithm on several real-world datasets. ",
    "url": "https://arxiv.org/abs/2206.09960",
    "authors": [
      "Nouamane Arhachoui",
      "Esteban Bautista",
      "Maximilien Danisch",
      "Anastasios Giovanidis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.09961",
    "title": "Critical Investigation of Failure Modes in Physics-informed Neural  Networks",
    "abstract": "Several recent works in scientific machine learning have revived interest in the application of neural networks to partial differential equations (PDEs). A popular approach is to aggregate the residual form of the governing PDE and its boundary conditions as soft penalties into a composite objective/loss function for training neural networks, which is commonly referred to as physics-informed neural networks (PINNs). In the present study, we visualize the loss landscapes and distributions of learned parameters and explain the ways this particular formulation of the objective function may hinder or even prevent convergence when dealing with challenging target solutions. We construct a purely data-driven loss function composed of both the boundary loss and the domain loss. Using this data-driven loss function and, separately, a physics-informed loss function, we then train two neural network models with the same architecture. We show that incomparable scales between boundary and domain loss terms are the culprit behind the poor performance. Additionally, we assess the performance of both approaches on two elliptic problems with increasingly complex target solutions. Based on our analysis of their loss landscapes and learned parameter distributions, we observe that a physics-informed neural network with a composite objective function formulation produces highly non-convex loss surfaces that are difficult to optimize and are more prone to the problem of vanishing gradients. ",
    "url": "https://arxiv.org/abs/2206.09961",
    "authors": [
      "Shamsulhaq Basir",
      "Inanc Senocak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2206.09978",
    "title": "German AI Start-Ups and AI Ethics: Using A Social Practice Lens for  Assessing and Implementing Socio-Technical Innovation",
    "abstract": "Within the current AI ethics discourse, there is a gap in empirical research on understanding how AI practitioners understand ethics and socially organize to operationalize ethical concerns, particularly in the context of AI start-ups. This gap intensifies the risk of a disconnect between scholarly research, innovation, and application. This risk materializes acutely as mounting pressures to identify and mitigate the potential harms of AI systems have created an urgent need to assess and implement socio-technical innovation for fairness, accountability, and transparency. Building on social practice theory, we address this need via a framework that allows AI researchers, practitioners, and regulators to systematically analyze existing cultural understandings, histories, and social practices of ethical AI to define appropriate strategies for effectively implementing socio-technical innovations. Our contributions are threefold: 1) we introduce a practice-based approach for understanding ethical AI; 2) we present empirical findings from our study on the operationalization of ethics in German AI start-ups to underline that AI ethics and social practices must be understood in their specific cultural and historical contexts; and 3) based on our empirical findings, we suggest that ethical AI practices can be broken down into principles, needs, narratives, materializations, and cultural genealogies to form a useful backdrop for considering socio-technical innovations. ",
    "url": "https://arxiv.org/abs/2206.09978",
    "authors": [
      "Mona Sloane",
      "Janina Zakrzewski"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2206.09979",
    "title": "Mitigating Data Heterogeneity in Federated Learning with Data  Augmentation",
    "abstract": "Federated Learning (FL) is a prominent framework that enables training a centralized model while securing user privacy by fusing local, decentralized models. In this setting, one major obstacle is data heterogeneity, i.e., each client having non-identically and independently distributed (non-IID) data. This is analogous to the context of Domain Generalization (DG), where each client can be treated as a different domain. However, while many approaches in DG tackle data heterogeneity from the algorithmic perspective, recent evidence suggests that data augmentation can induce equal or greater performance. Motivated by this connection, we present federated versions of popular DG algorithms, and show that by applying appropriate data augmentation, we can mitigate data heterogeneity in the federated setting, and obtain higher accuracy on unseen clients. Equipped with data augmentation, we can achieve state-of-the-art performance using even the most basic Federated Averaging algorithm, with much sparser communication. ",
    "url": "https://arxiv.org/abs/2206.09979",
    "authors": [
      "Artur Back de Luca",
      "Guojun Zhang",
      "Xi Chen",
      "Yaoliang Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09983",
    "title": "Mnemonic: A Parallel Subgraph Matching System for Streaming Graphs",
    "abstract": "Finding patterns in large highly connected datasets is critical for value discovery in business development and scientific research. This work focuses on the problem of subgraph matching on streaming graphs, which provides utility in a myriad of real-world applications ranging from social network analysis to cybersecurity. Each application poses a different set of control parameters, including the restrictions for a match, type of data stream, and search granularity. The problem-driven design of existing subgraph matching systems makes them challenging to apply for different problem domains. This paper presents Mnemonic, a programmable system that provides a high-level API and democratizes the development of a wide variety of subgraph matching solutions. Importantly, Mnemonic also delivers key data management capabilities and optimizations to support real-time processing on long-running, high-velocity multi-relational graph streams. The experiments demonstrate the versatility of Mnemonic, as it outperforms several state-of-the-art systems by up to two orders of magnitude. ",
    "url": "https://arxiv.org/abs/2206.09983",
    "authors": [
      "Bibek Bhattarai",
      "Howie Huang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2206.10009",
    "title": "Event-Case Correlation for Process Mining using Probabilistic  Optimization",
    "abstract": "Process mining supports the analysis of the actual behavior and performance of business processes using event logs. % such as, e.g., sales transactions recorded by an ERP system. An essential requirement is that every event in the log must be associated with a unique case identifier (e.g., the order ID of an order-to-cash process). In reality, however, this case identifier may not always be present, especially when logs are acquired from different systems or extracted from non-process-aware information systems. In such settings, the event log needs to be pre-processed by grouping events into cases -- an operation known as event correlation. Existing techniques for correlating events have worked with assumptions to make the problem tractable: some assume the generative processes to be acyclic, while others require heuristic information or user input. Moreover, %these techniques' primary assumption is that they abstract the log to activities and timestamps, and miss the opportunity to use data attributes. % In this paper, we lift these assumptions and propose a new technique called EC-SA-Data based on probabilistic optimization. The technique takes as inputs a sequence of timestamped events (the log without case IDs), a process model describing the underlying business process, and constraints over the event attributes. Our approach returns an event log in which every event is associated with a case identifier. The technique allows users to incorporate rules on process knowledge and data constraints flexibly. The approach minimizes the misalignment between the generated log and the input process model, maximizes the support of the given data constraints over the correlated log, and the variance between activity durations across cases. Our experiments with various real-life datasets show the advantages of our approach over the state of the art. ",
    "url": "https://arxiv.org/abs/2206.10009",
    "authors": [
      "Dina Bayomie",
      "Claudio Di Ciccio",
      "Jan Mendling"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2206.10027",
    "title": "DNA: Proximal Policy Optimization with a Dual Network Architecture",
    "abstract": "This paper explores the problem of simultaneously learning a value function and policy in deep actor-critic reinforcement learning models. We find that the common practice of learning these functions jointly is sub-optimal, due to an order-of-magnitude difference in noise levels between these two tasks. Instead, we show that learning these tasks independently, but with a constrained distillation phase, significantly improves performance. Furthermore, we find that the policy gradient noise levels can be decreased by using a lower \\textit{variance} return estimate. Whereas, the value learning noise level decreases with a lower \\textit{bias} estimate. Together these insights inform an extension to Proximal Policy Optimization we call \\textit{Dual Network Architecture} (DNA), which significantly outperforms its predecessor. DNA also exceeds the performance of the popular Rainbow DQN algorithm on four of the five environments tested, even under more difficult stochastic control settings. ",
    "url": "https://arxiv.org/abs/2206.10027",
    "authors": [
      "Mathew Aitchison",
      "Penny Sweetser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.10033",
    "title": "Test Time Transform Prediction for Open Set Histopathological Image  Recognition",
    "abstract": "Tissue typology annotation in Whole Slide histological images is a complex and tedious, yet necessary task for the development of computational pathology models. We propose to address this problem by applying Open Set Recognition techniques to the task of jointly classifying tissue that belongs to a set of annotated classes, e.g. clinically relevant tissue categories, while rejecting in test time Open Set samples, i.e. images that belong to categories not present in the training set. To this end, we introduce a new approach for Open Set histopathological image recognition based on training a model to accurately identify image categories and simultaneously predict which data augmentation transform has been applied. In test time, we measure model confidence in predicting this transform, which we expect to be lower for images in the Open Set. We carry out comprehensive experiments in the context of colorectal cancer assessment from histological images, which provide evidence on the strengths of our approach to automatically identify samples from unknown categories. Code is released at https://github.com/agaldran/t3po . ",
    "url": "https://arxiv.org/abs/2206.10033",
    "authors": [
      "Adrian Galdran. Katherine J. Hewitt",
      "Narmin L. Ghaffari",
      "Jakob N. Kather",
      "Gustavo Carneiro",
      "Miguel A. Gonz\u00e1lez Ballester"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.10041",
    "title": "MPA: MultiPath++ Based Architecture for Motion Prediction",
    "abstract": "Autonomous driving technology is developing rapidly and nowadays first autonomous rides are being provided in city areas. This requires the highest standards for the safety and reliability of the technology. Motion prediction part of the general self-driving pipeline plays a crucial role in providing these qualities. In this work we present one of the solutions for Waymo Motion Prediction Challenge 2022 based on MultiPath++ ranked the 3rd as of May, 26 2022. Our source code is publicly available on GitHub. ",
    "url": "https://arxiv.org/abs/2206.10041",
    "authors": [
      "Stepan Konev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.10057",
    "title": "Robust Deep Reinforcement Learning through Bootstrapped Opportunistic  Curriculum",
    "abstract": "Despite considerable advances in deep reinforcement learning, it has been shown to be highly vulnerable to adversarial perturbations to state observations. Recent efforts that have attempted to improve adversarial robustness of reinforcement learning can nevertheless tolerate only very small perturbations, and remain fragile as perturbation size increases. We propose Bootstrapped Opportunistic Adversarial Curriculum Learning (BCL), a novel flexible adversarial curriculum learning framework for robust reinforcement learning. Our framework combines two ideas: conservatively bootstrapping each curriculum phase with highest quality solutions obtained from multiple runs of the previous phase, and opportunistically skipping forward in the curriculum. In our experiments we show that the proposed BCL framework enables dramatic improvements in robustness of learned policies to adversarial perturbations. The greatest improvement is for Pong, where our framework yields robustness to perturbations of up to 25/255; in contrast, the best existing approach can only tolerate adversarial noise up to 5/255. Our code is available at: https://github.com/jlwu002/BCL. ",
    "url": "https://arxiv.org/abs/2206.10057",
    "authors": [
      "Junlin Wu",
      "Yevgeniy Vorobeychik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.10059",
    "title": "Bypass Network for Semantics Driven Image Paragraph Captioning",
    "abstract": "Image paragraph captioning aims to describe a given image with a sequence of coherent sentences. Most existing methods model the coherence through the topic transition that dynamically infers a topic vector from preceding sentences. However, these methods still suffer from immediate or delayed repetitions in generated paragraphs because (i) the entanglement of syntax and semantics distracts the topic vector from attending pertinent visual regions; (ii) there are few constraints or rewards for learning long-range transitions. In this paper, we propose a bypass network that separately models semantics and linguistic syntax of preceding sentences. Specifically, the proposed model consists of two main modules, i.e. a topic transition module and a sentence generation module. The former takes previous semantic vectors as queries and applies attention mechanism on regional features to acquire the next topic vector, which reduces immediate repetition by eliminating linguistics. The latter decodes the topic vector and the preceding syntax state to produce the following sentence. To further reduce delayed repetition in generated paragraphs, we devise a replacement-based reward for the REINFORCE training. Comprehensive experiments on the widely used benchmark demonstrate the superiority of the proposed model over the state of the art for coherence while maintaining high accuracy. ",
    "url": "https://arxiv.org/abs/2206.10059",
    "authors": [
      "Qi Zheng",
      "Chaoyue Wang",
      "Dadong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.10071",
    "title": "Benchmarking Node Outlier Detection on Graphs",
    "abstract": "Graph outlier detection is an emerging but crucial machine learning task with numerous applications. Despite the proliferation of algorithms developed in recent years, the lack of a standard and unified setting for performance evaluation limits their advancement and usage in real-world applications. To tap the gap, we present, (to our best knowledge) the first comprehensive unsupervised node outlier detection benchmark for graphs called UNOD, with the following highlights: (1) evaluating fourteen methods with backbone spanning from classical matrix factorization to the latest graph neural networks; (2) benchmarking the method performance with different types of injected outliers and organic outliers on real-world datasets; (3) comparing the efficiency and scalability of the algorithms by runtime and GPU memory usage on synthetic graphs at different scales. Based on the analyses of extensive experimental results, we discuss the pros and cons of current UNOD methods, and point out multiple crucial and promising future research directions. ",
    "url": "https://arxiv.org/abs/2206.10071",
    "authors": [
      "Kay Liu",
      "Yingtong Dou",
      "Yue Zhao",
      "Xueying Ding",
      "Xiyang Hu",
      "Ruitong Zhang",
      "Kaize Ding",
      "Canyu Chen",
      "Hao Peng",
      "Kai Shu",
      "Lichao Sun",
      "Jundong Li",
      "George H. Chen",
      "Zhihao Jia",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.10080",
    "title": "One-stage Action Detection Transformer",
    "abstract": "In this work, we introduce our solution to the EPIC-KITCHENS-100 2022 Action Detection challenge. One-stage Action Detection Transformer (OADT) is proposed to model the temporal connection of video segments. With the help of OADT, both the category and time boundary can be recognized simultaneously. After ensembling multiple OADT models trained from different features, our model can reach 21.28\\% action mAP and ranks the 1st on the test-set of the Action detection challenge. ",
    "url": "https://arxiv.org/abs/2206.10080",
    "authors": [
      "Lijun Li",
      "Li'an Zhuo",
      "Bang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.10087",
    "title": "Bio-inspired Neural Network-based Optimal Path Planning for UUVs under  the Effect of Ocean Currents",
    "abstract": "To eliminate the effect of ocean currents when addressing the optimal path in the underwater environment, an intelligent algorithm designed for the unmanned underwater vehicle (UUV) is proposed in this paper. The algorithm consists of two parts: a neural network-based algorithm that deducts the shortest path and avoids all possible collisions; and an adjusting component that balances off the deviation brought by the effect of ocean currents. The optimization results of the proposed algorithm are presented in detail, and compared with the path planning algorithm that does not consider the effect of currents. Results of the comparison prove the effectiveness of the path planning method when encountering currents of different directions and velocities. ",
    "url": "https://arxiv.org/abs/2206.10087",
    "authors": [
      "Danjie Zhu",
      "Simon X. Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.10088",
    "title": "Renormalized Sparse Neural Network Pruning",
    "abstract": "Large neural networks are heavily over-parameterized. This is done because it improves training to optimality. However once the network is trained, this means many parameters can be zeroed, or pruned, leaving an equivalent sparse neural network. We propose renormalizing sparse neural networks in order to improve accuracy. We prove that our method's error converges to 0 as network parameters cluster or concentrate. We prove that without renormalizing, the error does not converge to zero in general. We experiment with our method on real world datasets MNIST, Fashion MNIST, and CIFAR-10 and confirm a large improvement in accuracy with renormalization versus standard pruning. ",
    "url": "https://arxiv.org/abs/2206.10088",
    "authors": [
      "Michael G. Rawson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.10090",
    "title": "KTN: Knowledge Transfer Network for Learning Multi-person 2D-3D  Correspondences",
    "abstract": "Human densepose estimation, aiming at establishing dense correspondences between 2D pixels of human body and 3D human body template, is a key technique in enabling machines to have an understanding of people in images. It still poses several challenges due to practical scenarios where real-world scenes are complex and only partial annotations are available, leading to incompelete or false estimations. In this work, we present a novel framework to detect the densepose of multiple people in an image. The proposed method, which we refer to Knowledge Transfer Network (KTN), tackles two main problems: 1) how to refine image representation for alleviating incomplete estimations, and 2) how to reduce false estimation caused by the low-quality training labels (i.e., limited annotations and class-imbalance labels). Unlike existing works directly propagating the pyramidal features of regions for densepose estimation, the KTN uses a refinement of pyramidal representation, where it simultaneously maintains feature resolution and suppresses background pixels, and this strategy results in a substantial increase in accuracy. Moreover, the KTN enhances the ability of 3D based body parsing with external knowledges, where it casts 2D based body parsers trained from sufficient annotations as a 3D based body parser through a structural body knowledge graph. In this way, it significantly reduces the adverse effects caused by the low-quality annotations. The effectiveness of KTN is demonstrated by its superior performance to the state-of-the-art methods on DensePose-COCO dataset. Extensive ablation studies and experimental results on representative tasks (e.g., human body segmentation, human part segmentation and keypoints detection) and two popular densepose estimation pipelines (i.e., RCNN and fully-convolutional frameworks), further indicate the generalizability of the proposed method. ",
    "url": "https://arxiv.org/abs/2206.10090",
    "authors": [
      "Xuanhan Wang",
      "Lianli Gao",
      "Yixuan Zhou",
      "Jingkuan Song",
      "Meng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.10092",
    "title": "BEVDepth: Acquisition of Reliable Depth for Multi-view 3D Object  Detection",
    "abstract": "In this research, we propose a new 3D object detector with a trustworthy depth estimation, dubbed BEVDepth, for camera-based Bird's-Eye-View (BEV) 3D object detection. By a thorough analysis of recent approaches, we discover that the depth estimation is implicitly learned without camera information, making it the de-facto fake-depth for creating the following pseudo point cloud. BEVDepth gets explicit depth supervision utilizing encoded intrinsic and extrinsic parameters. A depth correction sub-network is further introduced to counteract projecting-induced disturbances in depth ground truth. To reduce the speed bottleneck while projecting features from image-view into BEV using estimated depth, a quick view-transform operation is also proposed. Besides, our BEVDepth can be easily extended with input from multi-frame. Without any bells and whistles, BEVDepth achieves the new state-of-the-art 60.0% NDS on the challenging nuScenes test set while maintaining high efficiency. For the first time, the performance gap between the camera and LiDAR is largely reduced within 10% NDS. ",
    "url": "https://arxiv.org/abs/2206.10092",
    "authors": [
      "Yinhao Li",
      "Zheng Ge",
      "Guanyi Yu",
      "Jinrong Yang",
      "Zengran Wang",
      "Yukang Shi",
      "Jianjian Sun",
      "Zeming Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.10095",
    "title": "Pyramid Region-based Slot Attention Network for Temporal Action Proposal  Generation",
    "abstract": "It has been found that temporal action proposal generation, which aims to discover the temporal action instances within the range of the start and end frames in the untrimmed videos, can largely benefit from proper temporal and semantic context exploitation. The latest efforts were dedicated to considering the temporal context and similarity-based semantic contexts through self-attention modules. However, they still suffer from cluttered background information and limited contextual feature learning. In this paper, we propose a novel Pyramid Region-based Slot Attention (PRSlot) module to address these issues. Instead of using the similarity computation, our PRSlot module directly learns the local relations in an encoder-decoder manner and generates the representation of a local region enhanced based on the attention over input features called \\textit{slot}. Specifically, upon the input snippet-level features, PRSlot module takes the target snippet as \\textit{query}, its surrounding region as \\textit{key} and then generates slot representations for each \\textit{query-key} slot by aggregating the local snippet context with a parallel pyramid strategy. Based on PRSlot modules, we present a novel Pyramid Region-based Slot Attention Network termed PRSA-Net to learn a unified visual representation with rich temporal and semantic context for better proposal generation. Extensive experiments are conducted on two widely adopted THUMOS14 and ActivityNet-1.3 benchmarks. Our PRSA-Net outperforms other state-of-the-art methods. In particular, we improve the AR@100 from the previous best 50.67% to 56.12% for proposal generation and raise the mAP under 0.5 tIoU from 51.9\\% to 58.7\\% for action detection on THUMOS14. \\textit{Code is available at} \\url{https://github.com/handhand123/PRSA-Net} ",
    "url": "https://arxiv.org/abs/2206.10095",
    "authors": [
      "Shuaicheng Li",
      "Feng Zhang",
      "Rui-Wei Zhao",
      "Rui Feng",
      "Kunlin Yang",
      "Lingbo Liu",
      "Jun Hou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.10098",
    "title": "Reconstruct from Top View: A 3D Lane Detection Approach based on  Geometry Structure Prior",
    "abstract": "In this paper, we propose an advanced approach in targeting the problem of monocular 3D lane detection by leveraging geometry structure underneath the process of 2D to 3D lane reconstruction. Inspired by previous methods, we first analyze the geometry heuristic between the 3D lane and its 2D representation on the ground and propose to impose explicit supervision based on the structure prior, which makes it achievable to build inter-lane and intra-lane relationships to facilitate the reconstruction of 3D lanes from local to global. Second, to reduce the structure loss in 2D lane representation, we directly extract top view lane information from front view images, which tremendously eases the confusion of distant lane features in previous methods. Furthermore, we propose a novel task-specific data augmentation method by synthesizing new training data for both segmentation and reconstruction tasks in our pipeline, to counter the imbalanced data distribution of camera pose and ground slope to improve generalization on unseen data. Our work marks the first attempt to employ the geometry prior information into DNN-based 3D lane detection and makes it achievable for detecting lanes in an extra-long distance, doubling the original detection range. The proposed method can be smoothly adopted by other frameworks without extra costs. Experimental results show that our work outperforms state-of-the-art approaches by 3.8% F-Score on Apollo 3D synthetic dataset at real-time speed of 82 FPS without introducing extra parameters. ",
    "url": "https://arxiv.org/abs/2206.10098",
    "authors": [
      "Chenguang Li",
      "Jia Shi",
      "Ya Wang",
      "Guangliang Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.10118",
    "title": "HOPE: Hierarchical Spatial-temporal Network for Occupancy Flow  Prediction",
    "abstract": "In this report, we introduce our solution to the Occupancy and Flow Prediction challenge in the Waymo Open Dataset Challenges at CVPR 2022, which ranks 1st on the leaderboard. We have developed a novel hierarchical spatial-temporal network featured with spatial-temporal encoders, a multi-scale aggregator enriched with latent variables, and a recursive hierarchical 3D decoder. We use multiple losses including focal loss and modified flow trace loss to efficiently guide the training process. Our method achieves a Flow-Grounded Occupancy AUC of 0.8389 and outperforms all the other teams on the leaderboard. ",
    "url": "https://arxiv.org/abs/2206.10118",
    "authors": [
      "Yihan Hu",
      "Wenxin Shao",
      "Bo Jiang",
      "Jiajie Chen",
      "Siqi Chai",
      "Zhening Yang",
      "Jingyu Qian",
      "Helong Zhou",
      "Qiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.10119",
    "title": "Optimization simulation of reflow welding based on prediction of  regional center temperature field",
    "abstract": "Before reflow soldering of integrated electronic products, the numerical simulation of temperature control curve of reflow furnace is crucial for selecting proper parameters and improving the overall efficiency of reflow soldering process and product quality. According to the heat conduction law and the specific heat capacity formula, the first-order ordinary differential equation of the central temperature curve of the welding area with respect to the temperature distribution function in the furnace on the conveyor belt displacement is obtained. For the gap with small temperature difference, the sigmoid function is used to obtain a smooth interval temperature transition curve; For the gap with large temperature difference, the linear combination of exponential function and primary function is used to approach the actual concave function, so as to obtain the complete temperature distribution function in the furnace. The welding parameters are obtained by solving the ordinary differential equation, and a set of optimal process parameters consistent with the process boundary are obtained by calculating the mean square error between the predicted temperature field and the real temperature distribution. At the same time, a set of reflow optimization strategies are designed for speed interval prediction strategy, minimum parameter interval prediction strategy, and the most symmetrical parameter interval prediction of solder paste melting reflow area. The simulation results show that the temperature field prediction results obtained by this method are highly consistent with the actual sensor data, and have strong correlation. This method can help to select appropriate process parameters, optimize the production process, reduce equipment commissioning practice and optimize the solder joint quality of production products. ",
    "url": "https://arxiv.org/abs/2206.10119",
    "authors": [
      "Yuan Sui",
      "Fan-yang Bu",
      "Zi-long Shao",
      "Wei Yan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.10125",
    "title": "Supervision-Guided Codebooks for Masked Prediction in Speech  Pre-training",
    "abstract": "Recently, masked prediction pre-training has seen remarkable progress in self-supervised learning (SSL) for speech recognition. It usually requires a codebook obtained in an unsupervised way, making it less accurate and difficult to interpret. We propose two supervision-guided codebook generation approaches to improve automatic speech recognition (ASR) performance and also the pre-training efficiency, either through decoding with a hybrid ASR system to generate phoneme-level alignments (named PBERT), or performing clustering on the supervised speech features extracted from an end-to-end CTC model (named CTC clustering). Both the hybrid and CTC models are trained on the same small amount of labeled speech as used in fine-tuning. Experiments demonstrate significant superiority of our methods to various SSL and self-training baselines, with up to 17.0% relative WER reduction. Our pre-trained models also show good transferability in a non-ASR speech task. ",
    "url": "https://arxiv.org/abs/2206.10125",
    "authors": [
      "Chengyi Wang",
      "Yiming Wang",
      "Yu Wu",
      "Sanyuan Chen",
      "Jinyu Li",
      "Shujie Liu",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.10131",
    "title": "An Integrated Representation & Compression Scheme Based on Convolutional  Autoencoders with 4D DCT Perceptual Encoding for High Dynamic Range Light  Fields",
    "abstract": "The emerging and existing light field displays are highly capable of realistic presentation of 3D scenes on auto-stereoscopic glasses-free platforms. The light field size is a major drawback while utilising 3D displays and streaming purposes. When a light field is of high dynamic range, the size increases drastically. In this paper, we propose a novel compression algorithm for a high dynamic range light field which yields a perceptually lossless compression. The algorithm exploits the inter and intra view correlations of the HDR light field by interpreting it to be a four-dimension volume. The HDR light field compression is based on a novel 4DDCT-UCS (4D-DCT Uniform Colour Space) algorithm. Additional encoding of 4DDCT-UCS acquired images by HEVC eliminates intra-frame, inter-frame and intrinsic redundancies in HDR light field data. Comparison with state-of-the-art coders like JPEG-XL and HDR video coding algorithm exhibits superior compression performance of the proposed scheme for real-world light fields. ",
    "url": "https://arxiv.org/abs/2206.10131",
    "authors": [
      "Sally Khaidem",
      "Mansi Sharma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.10137",
    "title": "Few-Max: Few-Shot Domain Adaptation for Unsupervised Contrastive  Representation Learning",
    "abstract": "Contrastive self-supervised learning methods learn to map data points such as images into non-parametric representation space without requiring labels. While highly successful, current methods require a large amount of data in the training phase. In situations where the target training set is limited in size, generalization is known to be poor. Pretraining on a large source data set and fine-tuning on the target samples is prone to overfitting in the few-shot regime, where only a small number of target samples are available. Motivated by this, we propose a domain adaption method for self-supervised contrastive learning, termed Few-Max, to address the issue of adaptation to a target distribution under few-shot learning. To quantify the representation quality, we evaluate Few-Max on a range of source and target datasets, including ImageNet, VisDA, and fastMRI, on which Few-Max consistently outperforms other approaches. ",
    "url": "https://arxiv.org/abs/2206.10137",
    "authors": [
      "Ali Lotfi Rezaabad",
      "Sidharth Kumar",
      "Sriram Vishwanath",
      "Jonathan I. Tamir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.10140",
    "title": "Comprehensive Analysis of Negative Sampling in Knowledge Graph  Representation Learning",
    "abstract": "Negative sampling (NS) loss plays an important role in learning knowledge graph embedding (KGE) to handle a huge number of entities. However, the performance of KGE degrades without hyperparameters such as the margin term and number of negative samples in NS loss being appropriately selected. Currently, empirical hyperparameter tuning addresses this problem at the cost of computational time. To solve this problem, we theoretically analyzed NS loss to assist hyperparameter tuning and understand the better use of the NS loss in KGE learning. Our theoretical analysis showed that scoring methods with restricted value ranges, such as TransE and RotatE, require appropriate adjustment of the margin term or the number of negative samples different from those without restricted value ranges, such as RESCAL, ComplEx, and DistMult. We also propose subsampling methods specialized for the NS loss in KGE studied from a theoretical aspect. Our empirical analysis on the FB15k-237, WN18RR, and YAGO3-10 datasets showed that the results of actually trained models agree with our theoretical findings. ",
    "url": "https://arxiv.org/abs/2206.10140",
    "authors": [
      "Hidetaka Kamigaito",
      "Katsuhiko Hayashi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.10142",
    "title": "Propagation with Adaptive Mask then Training for Node Classification on  Attributed Networks",
    "abstract": "Node classification on attributed networks is a semi-supervised task that is crucial for network analysis. By decoupling two critical operations in Graph Convolutional Networks (GCNs), namely feature transformation and neighborhood aggregation, some recent works of decoupled GCNs could support the information to propagate deeper and achieve advanced performance. However, they follow the traditional structure-aware propagation strategy of GCNs, making it hard to capture the attribute correlation of nodes and sensitive to the structure noise described by edges whose two endpoints belong to different categories. To address these issues, we propose a new method called the itshape Propagation with Adaptive Mask then Training (PAMT). The key idea is to integrate the attribute similarity mask into the structure-aware propagation process. In this way, PAMT could preserve the attribute correlation of adjacent nodes during the propagation and effectively reduce the influence of structure noise. Moreover, we develop an iterative refinement mechanism to update the similarity mask during the training process for improving the training performance. Extensive experiments on four real-world datasets demonstrate the superior performance and robustness of PAMT. ",
    "url": "https://arxiv.org/abs/2206.10142",
    "authors": [
      "Jinsong Chen",
      "Boyu Li",
      "Qiuting He",
      "Kun He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.10148",
    "title": "Resource Allocation and Computation Offloading in a Millimeter-Wave  Train-Ground Network",
    "abstract": "In this paper, we consider an mmWave-based trainground communication system in the high-speed railway (HSR) scenario, where the computation tasks of users can be partially offloaded to the rail-side base station (BS) or the mobile relays (MRs) deployed on the roof of the train. The MRs operate in the full-duplex (FD) mode to achieve high spectrum utilization. We formulate the problem of minimizing the average task execution latency of all users, under local device and MRs energy consumption constraints. We propose a joint resource allocation and computation offloading scheme (JRACO) to solve the problem. It consists of a resource allocation and computation offloading (RACO) algorithm and an MR Energy constraint algorithm. RACO utilizes the matching game theory to iterate between two subproblems, i.e., data segmentation and user association and sub-channel allocation. With the RACO results, the MR energy constraint algorithm ensures that the MR energy consumption constraint is satisfied. Extensive simulations validate that JRACO can effectively reduce the average latency and increase the number of served users compared with three baseline schemes. ",
    "url": "https://arxiv.org/abs/2206.10148",
    "authors": [
      "Linqian Li",
      "Yong Niu",
      "Shiwen Mao",
      "Bo Ai",
      "Zhangdui Zhong",
      "Ning Wang",
      "Yali Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2206.10155",
    "title": "Review Neural Networks about Image Transformation Based on IGC Learning  Framework with Annotated Information",
    "abstract": "Image transformation, a class of vision and graphics problems whose goal is to learn the mapping between an input image and an output image, develops rapidly in the context of deep neural networks. In Computer Vision (CV), many problems can be regarded as the image transformation task, e.g., semantic segmentation and style transfer. These works have different topics and motivations, making the image transformation task flourishing. Some surveys only review the research on style transfer or image-to-image translation, all of which are just a branch of image transformation. However, none of the surveys summarize those works together in a unified framework to our best knowledge. This paper proposes a novel learning framework including Independent learning, Guided learning, and Cooperative learning, called the IGC learning framework. The image transformation we discuss mainly involves the general image-to-image translation and style transfer about deep neural networks. From the perspective of this framework, we review those subtasks and give a unified interpretation of various scenarios. We categorize related subtasks about the image transformation according to similar development trends. Furthermore, experiments have been performed to verify the effectiveness of IGC learning. Finally, new research directions and open problems are discussed for future research. ",
    "url": "https://arxiv.org/abs/2206.10155",
    "authors": [
      "Yuanjie Yan",
      "Suorong Yang",
      "Yan Wang",
      "Jian Zhao",
      "Furao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.10157",
    "title": "Probing Visual-Audio Representation for Video Highlight Detection via  Hard-Pairs Guided Contrastive Learning",
    "abstract": "Video highlight detection is a crucial yet challenging problem that aims to identify the interesting moments in untrimmed videos. The key to this task lies in effective video representations that jointly pursue two goals, \\textit{i.e.}, cross-modal representation learning and fine-grained feature discrimination. In this paper, these two challenges are tackled by not only enriching intra-modality and cross-modality relations for representation modeling but also shaping the features in a discriminative manner. Our proposed method mainly leverages the intra-modality encoding and cross-modality co-occurrence encoding for fully representation modeling. Specifically, intra-modality encoding augments the modality-wise features and dampens irrelevant modality via within-modality relation learning in both audio and visual signals. Meanwhile, cross-modality co-occurrence encoding focuses on the co-occurrence inter-modality relations and selectively captures effective information among multi-modality. The multi-modal representation is further enhanced by the global information abstracted from the local context. In addition, we enlarge the discriminative power of feature embedding with a hard-pairs guided contrastive learning (HPCL) scheme. A hard-pairs sampling strategy is further employed to mine the hard samples for improving feature discrimination in HPCL. Extensive experiments conducted on two benchmarks demonstrate the effectiveness and superiority of our proposed methods compared to other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2206.10157",
    "authors": [
      "Shuaicheng Li",
      "Feng Zhang",
      "Kunlin Yang",
      "Lingbo Liu",
      "Shinan Liu",
      "Jun Hou",
      "Shuai Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.10158",
    "title": "Certifiably Robust Policy Learning against Adversarial Communication in  Multi-agent Systems",
    "abstract": "Communication is important in many multi-agent reinforcement learning (MARL) problems for agents to share information and make good decisions. However, when deploying trained communicative agents in a real-world application where noise and potential attackers exist, the safety of communication-based policies becomes a severe issue that is underexplored. Specifically, if communication messages are manipulated by malicious attackers, agents relying on untrustworthy communication may take unsafe actions that lead to catastrophic consequences. Therefore, it is crucial to ensure that agents will not be misled by corrupted communication, while still benefiting from benign communication. In this work, we consider an environment with $N$ agents, where the attacker may arbitrarily change the communication from any $C<\\frac{N-1}{2}$ agents to a victim agent. For this strong threat model, we propose a certifiable defense by constructing a message-ensemble policy that aggregates multiple randomly ablated message sets. Theoretical analysis shows that this message-ensemble policy can utilize benign communication while being certifiably robust to adversarial communication, regardless of the attacking algorithm. Experiments in multiple environments verify that our defense significantly improves the robustness of trained policies against various types of attacks. ",
    "url": "https://arxiv.org/abs/2206.10158",
    "authors": [
      "Yanchao Sun",
      "Ruijie Zheng",
      "Parisa Hassanzadeh",
      "Yongyuan Liang",
      "Soheil Feizi",
      "Sumitra Ganesh",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2206.10162",
    "title": "Complex Network Analysis of a Graphic Novel: The Case of the Bande  Dessin{\u00e9}e Thorgal",
    "abstract": "The task of extracting and analyzing character networks from works of fiction, such as novels and movies, has been the object of a number of recent publications. However, only a very few of them focus on graphic novels, and even fewer on European graphic novels. In this article, we focus on Thorgal, a bande dessin{\\'e}e, i.e. a comic of the French-Belgian tradition. We manually annotate all the volumes of this series, in order to constitute a corpus allowing us to extract its character network. We perform a descriptive analysis of the network structure and compare it to real-world and fictional social networks. We also study the effect of character filtering over the network structure. Finally, we leverage complex network analysis tools to answer two research questions from the literature, related to the similarity between Thorgal and the Saga of Icelanders; and to the position of women in the series. Our data and source code are both publicly available online. ",
    "url": "https://arxiv.org/abs/2206.10162",
    "authors": [
      "Vincent Labatut"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2206.10175",
    "title": "A Multi-grained based Attention Network for Semi-supervised Sound Event  Detection",
    "abstract": "Sound event detection (SED) is an interesting but challenging task due to the scarcity of data and diverse sound events in real life. This paper presents a multi-grained based attention network (MGA-Net) for semi-supervised sound event detection. To obtain the feature representations related to sound events, a residual hybrid convolution (RH-Conv) block is designed to boost the vanilla convolution's ability to extract the time-frequency features. Moreover, a multi-grained attention (MGA) module is designed to learn temporal resolution features from coarse-level to fine-level. With the MGA module,the network could capture the characteristics of target events with short- or long-duration, resulting in more accurately determining the onset and offset of sound events. Furthermore, to effectively boost the performance of the Mean Teacher (MT) method, a spatial shift (SS) module as a data perturbation mechanism is introduced to increase the diversity of data. Experimental results show that the MGA-Net outperforms the published state-of-the-art competitors, achieving 53.27% and 56.96% event-based macro F1 (EB-F1) score, 0.709 and 0.739 polyphonic sound detection score (PSDS) on the validation and public set respectively. ",
    "url": "https://arxiv.org/abs/2206.10175",
    "authors": [
      "Ying Hu",
      "Xiujuan Zhu",
      "Yunlong Li",
      "Hao Huang",
      "Liang He"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.10177",
    "title": "TCJA-SNN: Temporal-Channel Joint Attention for Spiking Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs) is a practical approach toward more data-efficient deep learning by simulating neurons leverage on temporal information. In this paper, we propose the Temporal-Channel Joint Attention (TCJA) architectural unit, an efficient SNN technique that depends on attention mechanisms, by effectively enforcing the relevance of spike sequence along both spatial and temporal dimensions. Our essential technical contribution lies on: 1) compressing the spike stream into an average matrix by employing the squeeze operation, then using two local attention mechanisms with an efficient 1-D convolution to establish temporal-wise and channel-wise relations for feature extraction in a flexible fashion. 2) utilizing the Cross Convolutional Fusion (CCF) layer for modeling inter-dependencies between temporal and channel scope, which breaks the independence of the two dimensions and realizes the interaction between features. By virtue of jointly exploring and recalibrating data stream, our method outperforms the state-of-the-art (SOTA) by up to 15.7% in terms of top-1 classification accuracy on all tested mainstream static and neuromorphic datasets, including Fashion-MNIST, CIFAR10-DVS, N-Caltech 101, and DVS128 Gesture. ",
    "url": "https://arxiv.org/abs/2206.10177",
    "authors": [
      "Rui-Jie Zhu",
      "Qihang Zhao",
      "Tianjing Zhang",
      "Haoyu Deng",
      "Yule Duan",
      "Malu Zhang",
      "Liang-Jian Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.10186",
    "title": "Improving Localization for Semi-Supervised Object Detection",
    "abstract": "Nowadays, Semi-Supervised Object Detection (SSOD) is a hot topic, since, while it is rather easy to collect images for creating a new dataset, labeling them is still an expensive and time-consuming task. One of the successful methods to take advantage of raw images on a Semi-Supervised Learning (SSL) setting is the Mean Teacher technique, where the operations of pseudo-labeling by the Teacher and the Knowledge Transfer from the Student to the Teacher take place simultaneously. However, the pseudo-labeling by thresholding is not the best solution since the confidence value is not strictly related to the prediction uncertainty, not permitting to safely filter predictions. In this paper, we introduce an additional classification task for bounding box localization to improve the filtering of the predicted bounding boxes and obtain higher quality on Student training. Furthermore, we empirically prove that bounding box regression on the unsupervised part can equally contribute to the training as much as category classification. Our experiments show that our IL-net (Improving Localization net) increases SSOD performance by 1.14% AP on COCO dataset in limited-annotation regime. The code is available at https://github.com/IMPLabUniPr/unbiased-teacher/tree/ilnet ",
    "url": "https://arxiv.org/abs/2206.10186",
    "authors": [
      "Leonardo Rossi",
      "Akbar Karimi",
      "Andrea Prati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.10188",
    "title": "Analysis of Self-Supervised Learning and Dimensionality Reduction  Methods in Clustering-Based Active Learning for Speech Emotion Recognition",
    "abstract": "When domain experts are needed to perform data annotation for complex machine-learning tasks, reducing annotation effort is crucial in order to cut down time and expenses. For cases when there are no annotations available, one approach is to utilize the structure of the feature space for clustering-based active learning (AL) methods. However, these methods are heavily dependent on how the samples are organized in the feature space and what distance metric is used. Unsupervised methods such as contrastive predictive coding (CPC) can potentially be used to learn organized feature spaces, but these methods typically create high-dimensional features which might be challenging for estimating data density. In this paper, we combine CPC and multiple dimensionality reduction methods in search of functioning practices for clustering-based AL. Our experiments for simulating speech emotion recognition system deployment show that both the local and global topology of the feature space can be successfully used for AL, and that CPC can be used to improve clustering-based AL performance over traditional signal features. Additionally, we observe that compressing data dimensionality does not harm AL performance substantially, and that 2-D feature representations achieved similar AL performance as higher-dimensional representations when the number of annotations is not very low. ",
    "url": "https://arxiv.org/abs/2206.10188",
    "authors": [
      "Einari Vaaras",
      "Manu Airaksinen",
      "Okko R\u00e4s\u00e4nen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.10189",
    "title": "A General Theory for Federated Optimization with Asynchronous and  Heterogeneous Clients Updates",
    "abstract": "We propose a novel framework to study asynchronous federated learning optimization with delays in gradient updates. Our theoretical framework extends the standard FedAvg aggregation scheme by introducing stochastic aggregation weights to represent the variability of the clients update time, due for example to heterogeneous hardware capabilities. Our formalism applies to the general federated setting where clients have heterogeneous datasets and perform at least one step of stochastic gradient descent (SGD). We demonstrate convergence for such a scheme and provide sufficient conditions for the related minimum to be the optimum of the federated problem. We show that our general framework applies to existing optimization schemes including centralized learning, FedAvg, asynchronous FedAvg, and FedBuff. The theory here provided allows drawing meaningful guidelines for designing a federated learning experiment in heterogeneous conditions. In particular, we develop in this work FedFix, a novel extension of FedAvg enabling efficient asynchronous federated training while preserving the convergence stability of synchronous aggregation. We empirically demonstrate our theory on a series of experiments showing that asynchronous FedAvg leads to fast convergence at the expense of stability, and we finally demonstrate the improvements of FedFix over synchronous and asynchronous FedAvg. ",
    "url": "https://arxiv.org/abs/2206.10189",
    "authors": [
      "Yann Fraboni",
      "Richard Vidal",
      "Laetitia Kameni",
      "Marco Lorenzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.10192",
    "title": "LDD: A Dataset for Grape Diseases Object Detection and Instance  Segmentation",
    "abstract": "The Instance Segmentation task, an extension of the well-known Object Detection task, is of great help in many areas, such as precision agriculture: being able to automatically identify plant organs and the possible diseases associated with them, allows to effectively scale and automate crop monitoring and its diseases control. To address the problem related to early disease detection and diagnosis on vines plants, a new dataset has been created with the goal of advancing the state-of-the-art of diseases recognition via instance segmentation approaches. This was achieved by gathering images of leaves and clusters of grapes affected by diseases in their natural context. The dataset contains photos of 10 object types which include leaves and grapes with and without symptoms of the eight more common grape diseases, with a total of 17,706 labeled instances in 1,092 images. Multiple statistical measures are proposed in order to offer a complete view on the characteristics of the dataset. Preliminary results for the object detection and instance segmentation tasks reached by the models Mask R-CNN and R^3-CNN are provided as baseline, demonstrating that the procedure is able to reach promising results about the objective of automatic diseases' symptoms recognition. ",
    "url": "https://arxiv.org/abs/2206.10192",
    "authors": [
      "Leonardo Rossi",
      "Marco Valenti",
      "Sara Elisabetta Legler",
      "Andrea Prati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.10200",
    "title": "Enabling Capsule Networks at the Edge through Approximate Softmax and  Squash Operations",
    "abstract": "Complex Deep Neural Networks such as Capsule Networks (CapsNets) exhibit high learning capabilities at the cost of compute-intensive operations. To enable their deployment on edge devices, we propose to leverage approximate computing for designing approximate variants of the complex operations like softmax and squash. In our experiments, we evaluate tradeoffs between area, power consumption, and critical path delay of the designs implemented with the ASIC design flow, and the accuracy of the quantized CapsNets, compared to the exact functions. ",
    "url": "https://arxiv.org/abs/2206.10200",
    "authors": [
      "Alberto Marchisio",
      "Beatrice Bussolino",
      "Edoardo Salvati",
      "Maurizio Martina",
      "Guido Masera",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.10213",
    "title": "Rethinking Unsupervised Neural Superpixel Segmentation",
    "abstract": "Recently, the concept of unsupervised learning for superpixel segmentation via CNNs has been studied. Essentially, such methods generate superpixels by convolutional neural network (CNN) employed on a single image, and such CNNs are trained without any labels or further information. Thus, such approach relies on the incorporation of priors, typically by designing an objective function that guides the solution towards a meaningful superpixel segmentation. In this paper we propose three key elements to improve the efficacy of such networks: (i) the similarity of the \\emph{soft} superpixelated image compared to the input image, (ii) the enhancement and consideration of object edges and boundaries and (iii) a modified architecture based on atrous convolution, which allow for a wider field of view, functioning as a multi-scale component in our network. By experimenting with the BSDS500 dataset, we find evidence to the significance of our proposal, both qualitatively and quantitatively. ",
    "url": "https://arxiv.org/abs/2206.10213",
    "authors": [
      "Moshe Eliasof",
      "Nir Ben Zikri",
      "Eran Treister"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.10226",
    "title": "Fluctuation-driven initialization for spiking neural network training",
    "abstract": "Spiking neural networks (SNNs) underlie low-power, fault-tolerant information processing in the brain and could constitute a power-efficient alternative to conventional deep neural networks when implemented on suitable neuromorphic hardware accelerators. However, instantiating SNNs that solve complex computational tasks in-silico remains a significant challenge. Surrogate gradient (SG) techniques have emerged as a standard solution for training SNNs end-to-end. Still, their success depends on synaptic weight initialization, similar to conventional artificial neural networks (ANNs). Yet, unlike in the case of ANNs, it remains elusive what constitutes a good initial state for an SNN. Here, we develop a general initialization strategy for SNNs inspired by the fluctuation-driven regime commonly observed in the brain. Specifically, we derive practical solutions for data-dependent weight initialization that ensure fluctuation-driven firing in the widely used leaky integrate-and-fire (LIF) neurons. We empirically show that SNNs initialized following our strategy exhibit superior learning performance when trained with SGs. These findings generalize across several datasets and SNN architectures, including fully connected, deep convolutional, recurrent, and more biologically plausible SNNs obeying Dale's law. Thus fluctuation-driven initialization provides a practical, versatile, and easy-to-implement strategy for improving SNN training performance on diverse tasks in neuromorphic engineering and computational neuroscience. ",
    "url": "https://arxiv.org/abs/2206.10226",
    "authors": [
      "Julian Rossbroich",
      "Julia Gygax",
      "Friedemann Zenke"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2206.10227",
    "title": "TAPHSIR: Towards AnaPHoric Ambiguity Detection and ReSolution In  Requirements",
    "abstract": "We introduce TAPHSIR, a tool for anaphoric ambiguity detection and anaphora resolution in requirements. TAPHSIR facilities reviewing the use of pronouns in a requirements specification and revising those pronouns that can lead to misunderstandings during the development process. To this end, TAPHSIR detects the requirements which have potential anaphoric ambiguity and further attempts interpreting anaphora occurrences automatically. TAPHSIR employs a hybrid solution composed of an ambiguity detection solution based on machine learning and an anaphora resolution solution based on a variant of the BERT language model. Given a requirements specification, TAPHSIR decides for each pronoun occurrence in the specification whether the pronoun is ambiguous or unambiguous, and further provides an automatic interpretation for the pronoun. The output generated by TAPHSIR can be easily reviewed and validated by requirements engineers. TAPHSIR is publicly available on Zenodo (DOI: 10.5281/zenodo.5902117). ",
    "url": "https://arxiv.org/abs/2206.10227",
    "authors": [
      "Saad Ezzini",
      "Sallam Abualhaija",
      "Chetan Arora",
      "Mehrdad Sabetzadeh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.10235",
    "title": "Riemannian data-dependent randomized smoothing for neural networks  certification",
    "abstract": "Certification of neural networks is an important and challenging problem that has been attracting the attention of the machine learning community since few years. In this paper, we focus on randomized smoothing (RS) which is considered as the state-of-the-art method to obtain certifiably robust neural networks. In particular, a new data-dependent RS technique called ANCER introduced recently can be used to certify ellipses with orthogonal axis near each input data of the neural network. In this work, we remark that ANCER is not invariant under rotation of input data and propose a new rotationally-invariant formulation of it which can certify ellipses without constraints on their axis. Our approach called Riemannian Data Dependant Randomized Smoothing (RDDRS) relies on information geometry techniques on the manifold of covariance matrices and can certify bigger regions than ANCER based on our experiments on the MNIST dataset. ",
    "url": "https://arxiv.org/abs/2206.10235",
    "authors": [
      "Pol Labarbarie",
      "Hatem Hajri",
      "Marc Arnaudon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.10261",
    "title": "Interpretable Deep Causal Learning for Moderation Effects",
    "abstract": "In this extended abstract paper, we address the problem of interpretability and targeted regularization in causal machine learning models. In particular, we focus on the problem of estimating individual causal/treatment effects under observed confounders, which can be controlled for and moderate the effect of the treatment on the outcome of interest. Black-box ML models adjusted for the causal setting perform generally well in this task, but they lack interpretable output identifying the main drivers of treatment heterogeneity and their functional relationship. We propose a novel deep counterfactual learning architecture for estimating individual treatment effects that can simultaneously: i) convey targeted regularization on, and produce quantify uncertainty around the quantity of interest (i.e., the Conditional Average Treatment Effect); ii) disentangle baseline prognostic and moderating effects of the covariates and output interpretable score functions describing their relationship with the outcome. Finally, we demonstrate the use of the method via a simple simulated experiment. ",
    "url": "https://arxiv.org/abs/2206.10261",
    "authors": [
      "Alberto Caron",
      "Gianluca Baio",
      "Ioanna Manolopoulou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.10263",
    "title": "Object Structural Points Representation for Graph-based Semantic  Monocular Localization and Mapping",
    "abstract": "Efficient object level representation for monocular semantic simultaneous localization and mapping (SLAM) still lacks a widely accepted solution. In this paper, we propose the use of an efficient representation, based on structural points, for the geometry of objects to be used as landmarks in a monocular semantic SLAM system based on the pose-graph formulation. In particular, an inverse depth parametrization is proposed for the landmark nodes in the pose-graph to store object position, orientation and size/scale. The proposed formulation is general and it can be applied to different geometries; in this paper we focus on indoor environments where human-made artifacts commonly share a planar rectangular shape, e.g., windows, doors, cabinets, etc. The approach can be easily extended to urban scenarios where similar shapes exists as well. Experiments in simulation show good performance, particularly in object geometry reconstruction. ",
    "url": "https://arxiv.org/abs/2206.10263",
    "authors": [
      "Davide Tateo",
      "Davide Antonio Cucci",
      "Matteo Matteucci",
      "Andrea Bonarini"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.10265",
    "title": "KnowDA: All-in-One Knowledge Mixture Model for Data Augmentation in  Few-Shot NLP",
    "abstract": "This paper focuses on text data augmentation for few-shot NLP tasks. The existing data augmentation algorithms either leverage task-independent heuristic rules (e.g., Synonym Replacement) or fine-tune general-purpose pre-trained language models (e.g., GPT2) using a small training set to produce new synthetic data. Consequently, these methods have trivial task-specific knowledge and are limited to yielding low-quality synthetic data for weak baselines in simple tasks. To combat this issue, we propose the Knowledge Mixture Data Augmentation Model (KnowDA): an encoder-decoder LM pretrained on a mixture of diverse NLP tasks using Knowledge Mixture Training (KoMT). KoMT is a training procedure that reformulates input examples from various heterogeneous NLP tasks into a unified text-to-text format and employs denoising objectives in different granularity to learn to generate partial or complete samples. With the aid of KoMT, KnowDA could combine required task-specific knowledge implicitly from the learned mixture of tasks and quickly grasp the inherent synthesis law of the target task through a few given instances. To the best of our knowledge, we are the first attempt to scale the number of tasks to 100+ in multi-task co-training for data augmentation. Extensive experiments show that i) KnowDA successfully improves the performance of Albert and Deberta by a large margin on the FewGLUE benchmark, outperforming previous state-of-the-art data augmentation baselines; ii) KnowDA could also improve the model performance on the few-shot NER tasks, a held-out task type not included in KoMT. ",
    "url": "https://arxiv.org/abs/2206.10265",
    "authors": [
      "Yufei Wang",
      "Jiayi Zheng",
      "Can Xu",
      "Xiubo Geng",
      "Tao Shen",
      "Chongyang Tao",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.10272",
    "title": "Identification of Attack Paths Using Kill Chain and Attack Graphs",
    "abstract": "The ever-evolving capabilities of cyber attackers force security administrators to focus on the early identification of emerging threats. Targeted cyber attacks usually consist of several phases, from initial reconnaissance of the network environment to final impact on objectives. This paper investigates the identification of multi-step cyber threat scenarios using kill chain and attack graphs. Kill chain and attack graphs are threat modeling concepts that enable determining weak security defense points. We propose a novel kill chain attack graph that merges kill chain and attack graphs together. This approach determines possible chains of attacker's actions and their materialization within the protected network. The graph generation uses a categorization of threats according to violated security properties. The graph allows determining the kill chain phase the administrator should focus on and applicable countermeasures to mitigate possible cyber threats. We implemented the proposed approach for a predefined range of cyber threats, especially vulnerability exploitation and network threats. The approach was validated on a real-world use case. Publicly available implementation contains a proof-of-concept kill chain attack graph generator. ",
    "url": "https://arxiv.org/abs/2206.10272",
    "authors": [
      "Luk\u00e1\u0161 Sadlek",
      "Pavel \u010celeda",
      "Daniel Tovar\u0148\u00e1k"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.10289",
    "title": "Imitation Learning for Nonprehensile Manipulation through  Self-Supervised Learning Considering Motion Speed",
    "abstract": "Robots are expected to replace menial tasks such as housework. Some of these tasks include nonprehensile manipulation performed without grasping objects. Nonprehensile manipulation is very difficult because it requires considering the dynamics of environments and objects. Therefore imitating complex behaviors requires a large number of human demonstrations. In this study, a self-supervised learning that considers dynamics to achieve variable speed for nonprehensile manipulation is proposed. The proposed method collects and fine-tunes only successful action data obtained during autonomous operations. By fine-tuning the successful data, the robot learns the dynamics among itself, its environment, and objects. We experimented with the task of scooping and transporting pancakes using the neural network model trained on 24 human-collected training data. The proposed method significantly improved the success rate from 40.2% to 85.7%, and succeeded the task more than 75% for other objects. ",
    "url": "https://arxiv.org/abs/2206.10289",
    "authors": [
      "Yuki Saigusa",
      "Sho Sakaino",
      "Toshiaki Tsuji"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.10292",
    "title": "Artificial Neural Network evaluation of Poincar\u00e9 constant for Voronoi  polygons",
    "abstract": "We propose a method, based on Artificial Neural Networks, that learns the dependence of the constant in the Poincar\\'e inequality on polygonal elements of Voronoi meshes, on some geometrical metrics of the element. The cost of this kind of algorithms mainly resides in the data preprocessing and learning phases, that can be performed offline once and for all, constructing an efficient method for computing the constant, which is needed in the design of a posteriori error estimates in numerical mesh-based schemes for the solution of Partial Differential Equations. ",
    "url": "https://arxiv.org/abs/2206.10292",
    "authors": [
      "Beatrice Crippa",
      "Silvia Bertoluzza",
      "Micol Pennacchio"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2206.10298",
    "title": "ViralBERT: A User Focused BERT-Based Approach to Virality Prediction",
    "abstract": "Recently, Twitter has become the social network of choice for sharing and spreading information to a multitude of users through posts called 'tweets'. Users can easily re-share these posts to other users through 'retweets', which allow information to cascade to many more users, increasing its outreach. Clearly, being able to know the extent to which a post can be retweeted has great value in advertising, influencing and other such campaigns. In this paper we propose ViralBERT, which can be used to predict the virality of tweets using content- and user-based features. We employ a method of concatenating numerical features such as hashtags and follower numbers to tweet text, and utilise two BERT modules: one for semantic representation of the combined text and numerical features, and another module purely for sentiment analysis of text, as both the information within text and it's ability to elicit an emotional response play a part in retweet proneness. We collect a dataset of 330k tweets to train ViralBERT and validate the efficacy of our model using baselines from current studies in this field. Our experiments show that our approach outperforms these baselines, with a 13% increase in both F1 Score and Accuracy compared to the best performing baseline method. We then undergo an ablation study to investigate the importance of chosen features, finding that text sentiment and follower counts, and to a lesser extent mentions and following counts, are the strongest features for the model, and that hashtag counts are detrimental to the model. ",
    "url": "https://arxiv.org/abs/2206.10298",
    "authors": [
      "Rikaz Rameez",
      "Hossein A. Rahmani",
      "Emine Yilmaz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.10303",
    "title": "Prediction of Maneuvering Status for Aerial Vehicles using Supervised  Learning Methods",
    "abstract": "Aerial Vehicles follow a guided approach based on Latitude, Longitude and Altitude. This information can be used for calculating the status of maneuvering for the aerial vehicles along the line of trajectory. This is a binary classification problem and Machine Learning can be leveraged for solving such problem. In this paper we present a methodology for deriving maneuvering status and its prediction using Linear, Distance Metric, Discriminant Analysis and Boosting Ensemble supervised learning methods. We provide various metrics along the line in the results section that give condensed comparison of the appropriate algorithm for prediction of the maneuvering status. ",
    "url": "https://arxiv.org/abs/2206.10303",
    "authors": [
      "Abhishek Gupta",
      "Sarvesh Thustu",
      "Riti Thakor",
      "Saniya Patil",
      "Raunak Joshi",
      "Ronald Melvin Laban"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.10305",
    "title": "Scale-Variant Robust Kernel Optimization for Non-linear Least Squares  Problems",
    "abstract": "In this letter, we present an algorithm for iterative nonlinear least-squares which increases the adaptive nature of previous methods in the literature. Our method uses two parameters to learn the best fitting distribution of the measurement residuals and performs Iterative Re-weighted Least Squares (IRLS) based on these two parameters. This adaptive nature of the weights is shown to be helpful in situations where the noise level varies in the measurements and is shown to increase robustness to outliers. We test our algorithm first on the point cloud registration problem with synthetic data sets, where the true transformation is known. Next, we also evaluate the approach with an open-source LiDAR-inertial SLAM package to demonstrate that the proposed approach is more effective than constant parameters for the application of incremental LiDAR-inertial odometry. This increased adaptivity can help in a wide range of estimation problems in robotics by better modeling the measurement errors. ",
    "url": "https://arxiv.org/abs/2206.10305",
    "authors": [
      "Shounak Das",
      "Jason Gross"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.10318",
    "title": "FabKG: A Knowledge graph of Manufacturing Science domain utilizing  structured and unconventional unstructured knowledge source",
    "abstract": "As the demands for large-scale information processing have grown, knowledge graph-based approaches have gained prominence for representing general and domain knowledge. The development of such general representations is essential, particularly in domains such as manufacturing which intelligent processes and adaptive education can enhance. Despite the continuous accumulation of text in these domains, the lack of structured data has created information extraction and knowledge transfer barriers. In this paper, we report on work towards developing robust knowledge graphs based upon entity and relation data for both commercial and educational uses. To create the FabKG (Manufacturing knowledge graph), we have utilized textbook index words, research paper keywords, FabNER (manufacturing NER), to extract a sub knowledge base contained within Wikidata. Moreover, we propose a novel crowdsourcing method for KG creation by leveraging student notes, which contain invaluable information but are not captured as meaningful information, excluding their use in personal preparation for learning and written exams. We have created a knowledge graph containing 65000+ triples using all data sources. We have also shown the use case of domain-specific question answering and expression/formula-based question answering for educational purposes. ",
    "url": "https://arxiv.org/abs/2206.10318",
    "authors": [
      "Aman Kumar",
      "Akshay G Bharadwaj",
      "Binil Starly",
      "Collin Lynch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2206.10324",
    "title": "Online progressive instance-balanced sampling for weakly supervised  object detection",
    "abstract": "Based on multiple instance detection networks (MIDN), plenty of works have contributed tremendous efforts to weakly supervised object detection (WSOD). However, most methods neglect the fact that the overwhelming negative instances exist in each image during the training phase, which would mislead the training and make the network fall into local minima. To tackle this problem, an online progressive instance-balanced sampling (OPIS) algorithm based on hard sampling and soft sampling is proposed in this paper. The algorithm includes two modules: a progressive instance balance (PIB) module and a progressive instance reweighting (PIR) module. The PIB module combining random sampling and IoU-balanced sampling progressively mines hard negative instances while balancing positive instances and negative instances. The PIR module further utilizes classifier scores and IoUs of adjacent refinements to reweight the weights of positive instances for making the network focus on positive instances. Extensive experimental results on the PASCAL VOC 2007 and 2012 datasets demonstrate the proposed method can significantly improve the baseline, which is also comparable to many existing state-of-the-art results. In addition, compared to the baseline, the proposed method requires no extra network parameters and the supplementary training overheads are small, which could be easily integrated into other methods based on the instance classifier refinement paradigm. ",
    "url": "https://arxiv.org/abs/2206.10324",
    "authors": [
      "M. Chen",
      "Y. Tian",
      "Z. Li",
      "E. Li",
      "Z. Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.10334",
    "title": "Defending Adversarial Examples by Negative Correlation Ensemble",
    "abstract": "The security issues in DNNs, such as adversarial examples, have attracted much attention. Adversarial examples refer to the examples which are capable to induce the DNNs return completely predictions by introducing carefully designed perturbations. Obviously, adversarial examples bring great security risks to the development of deep learning. Recently, Some defense approaches against adversarial examples have been proposed, however, in our opinion, the performance of these approaches are still limited. In this paper, we propose a new ensemble defense approach named the Negative Correlation Ensemble (NCEn), which achieves compelling results by introducing gradient directions and gradient magnitudes of each member in the ensemble negatively correlated and at the same time, reducing the transferability of adversarial examples among them. Extensive experiments have been conducted, and the results demonstrate that NCEn can improve the adversarial robustness of ensembles effectively. ",
    "url": "https://arxiv.org/abs/2206.10334",
    "authors": [
      "Wenjian Luo",
      "Hongwei Zhang",
      "Linghao Kong",
      "Zhijian Chen",
      "Ke Tang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.10338",
    "title": "Comparative Analysis of Dynamic Data Race Detection Techniques",
    "abstract": "The consequences of data races can be potentially very problematic [1], and it is important to determine what tools and methods are best at detecting them. The following conditions must be met for a data race to occur: two or more threads in a single process access the same memory location concurrently, at least one of the accesses is for writing, and the threads are not using any exclusive locks to control their accesses to that memory. This paper reveals the techniques and implementations of the two main methods for dynamic data race detection techniques; the happens-before and lockset methods, and produces an analysis for several tools that employ either ({\\S}4, {\\S}5) or of both these methods ({\\S}7.1) for detecting data races. This paper also reveals the extent to which dynamic data race detection (also called dynamic analysis) can identify harmful data races, how it can be implemented, and how it compares to other forms of data detection in terms of performance and accuracy. ",
    "url": "https://arxiv.org/abs/2206.10338",
    "authors": [
      "Danial Entezari"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2206.10375",
    "title": "MEStereo-Du2CNN: A Novel Dual Channel CNN for Learning Robust Depth  Estimates from Multi-exposure Stereo Images for HDR 3D Applications",
    "abstract": "Display technologies have evolved over the years. It is critical to develop practical HDR capturing, processing, and display solutions to bring 3D technologies to the next level. Depth estimation of multi-exposure stereo image sequences is an essential task in the development of cost-effective 3D HDR video content. In this paper, we develop a novel deep architecture for multi-exposure stereo depth estimation. The proposed architecture has two novel components. First, the stereo matching technique used in traditional stereo depth estimation is revamped. For the stereo depth estimation component of our architecture, a mono-to-stereo transfer learning approach is deployed. The proposed formulation circumvents the cost volume construction requirement, which is replaced by a ResNet based dual-encoder single-decoder CNN with different weights for feature fusion. EfficientNet based blocks are used to learn the disparity. Secondly, we combine disparity maps obtained from the stereo images at different exposure levels using a robust disparity feature fusion approach. The disparity maps obtained at different exposures are merged using weight maps calculated for different quality measures. The final predicted disparity map obtained is more robust and retains best features that preserve the depth discontinuities. The proposed CNN offers flexibility to train using standard dynamic range stereo data or with multi-exposure low dynamic range stereo sequences. In terms of performance, the proposed model surpasses state-of-the-art monocular and stereo depth estimation methods, both quantitatively and qualitatively, on challenging Scene flow and differently exposed Middlebury stereo datasets. The architecture performs exceedingly well on complex natural scenes, demonstrating its usefulness for diverse 3D HDR applications. ",
    "url": "https://arxiv.org/abs/2206.10375",
    "authors": [
      "Rohit Choudhary",
      "Mansi Sharma",
      "Uma T V",
      "Rithvik Anil"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.10379",
    "title": "Can process mining help in anomaly-based intrusion detection?",
    "abstract": "In this paper, we consider the naive applications of process mining in network traffic comprehension, traffic anomaly detection, and intrusion detection. We standardise the procedure of transforming packet data into an event log. We mine multiple process models and analyse the process models mined with the inductive miner using ProM and the fuzzy miner using Disco. We compare the two types of process models extracted from event logs of differing sizes. We contrast the process models with the RFC TCP state transition diagram and the diagram by Bishop et al. We analyse the issues and challenges associated with process mining in intrusion detection and explain why naive process mining with network data is ineffective. ",
    "url": "https://arxiv.org/abs/2206.10379",
    "authors": [
      "Yinzheng Zhong",
      "Alexei Lisitsa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.10397",
    "title": "Neural Moving Horizon Estimation for Robust Flight Control",
    "abstract": "Estimating and reacting to external disturbances is crucial for robust flight control of quadrotors. Existing estimators typically require significant tuning for a specific flight scenario or training with extensive real-world data to achieve satisfactory performance. In this paper, we propose a neural moving horizon estimator (NeuroMHE) that can automatically tune the MHE parameters modeled by a neural network and adapt to different flight scenarios. We achieve this by deriving the analytical gradient of the MHE estimates with respect to the tunable parameters, enabling a seamless embedding of MHE as a layer into the neural network for highly effective learning. Most interestingly, we show that the gradient can be solved efficiently from a Kalman filter in a recursive form. Moreover, we develop a model-based policy gradient algorithm to train NeuroMHE directly from the trajectory tracking error without the need for the ground-truth disturbance. The effectiveness of NeuroMHE is verified extensively via both simulations and physical experiments on a quadrotor in various challenging flights. Notably, NeuroMHE outperforms the state-of-the-art estimator with force estimation error reductions of up to 49.4% by using only a 2.5% amount of parameters. The proposed method is general and can be applied to robust adaptive control for other robotic systems. ",
    "url": "https://arxiv.org/abs/2206.10397",
    "authors": [
      "Bingheng Wang",
      "Zhengtian Ma",
      "Shupeng Lai",
      "Lin Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.10400",
    "title": "Using EBGAN for Anomaly Intrusion Detection",
    "abstract": "As an active network security protection scheme, intrusion detection system (IDS) undertakes the important responsibility of detecting network attacks in the form of malicious network traffic. Intrusion detection technology is an important part of IDS. At present, many scholars have carried out extensive research on intrusion detection technology. However, developing an efficient intrusion detection method for massive network traffic data is still difficult. Since Generative Adversarial Networks (GANs) have powerful modeling capabilities for complex high-dimensional data, they provide new ideas for addressing this problem. In this paper, we put forward an EBGAN-based intrusion detection method, IDS-EBGAN, that classifies network records as normal traffic or malicious traffic. The generator in IDS-EBGAN is responsible for converting the original malicious network traffic in the training set into adversarial malicious examples. This is because we want to use adversarial learning to improve the ability of discriminator to detect malicious traffic. At the same time, the discriminator adopts Autoencoder model. During testing, IDS-EBGAN uses reconstruction error of discriminator to classify traffic records. ",
    "url": "https://arxiv.org/abs/2206.10400",
    "authors": [
      "Yi Cui",
      "Wenfeng Shen",
      "Jian Zhang",
      "Weijia Lu",
      "Chuang Liu",
      "Lin Sun",
      "Si Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.10411",
    "title": "Audio-video fusion strategies for active speaker detection in meetings",
    "abstract": "Meetings are a common activity in professional contexts, and it remains challenging to endow vocal assistants with advanced functionalities to facilitate meeting management. In this context, a task like active speaker detection can provide useful insights to model interaction between meeting participants. Motivated by our application context related to advanced meeting assistant, we want to combine audio and visual information to achieve the best possible performance. In this paper, we propose two different types of fusion for the detection of the active speaker, combining two visual modalities and an audio modality through neural networks. For comparison purpose, classical unsupervised approaches for audio feature extraction are also used. We expect visual data centered on the face of each participant to be very appropriate for detecting voice activity, based on the detection of lip and facial gestures. Thus, our baseline system uses visual data and we chose a 3D Convolutional Neural Network architecture, which is effective for simultaneously encoding appearance and movement. To improve this system, we supplemented the visual information by processing the audio stream with a CNN or an unsupervised speaker diarization system. We have further improved this system by adding visual modality information using motion through optical flow. We evaluated our proposal with a public and state-of-the-art benchmark: the AMI corpus. We analysed the contribution of each system to the merger carried out in order to determine if a given participant is currently speaking. We also discussed the results we obtained. Besides, we have shown that, for our application context, adding motion information greatly improves performance. Finally, we have shown that attention-based fusion improves performance while reducing the standard deviation. ",
    "url": "https://arxiv.org/abs/2206.10411",
    "authors": [
      "Lionel Pibre",
      "Francisco Madrigal",
      "Cyrille Equoy",
      "Fr\u00e9d\u00e9ric Lerasle",
      "Thomas Pellegrini",
      "Julien Pinquier",
      "Isabelle Ferran\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.10421",
    "title": "Rethinking Audio-visual Synchronization for Active Speaker Detection",
    "abstract": "Active speaker detection (ASD) systems are important modules for analyzing multi-talker conversations. They aim to detect which speakers or none are talking in a visual scene at any given time. Existing research on ASD does not agree on the definition of active speakers. We clarify the definition in this work and require synchronization between the audio and visual speaking activities. This clarification of definition is motivated by our extensive experiments, through which we discover that existing ASD methods fail in modeling the audio-visual synchronization and often classify unsynchronized videos as active speaking. To address this problem, we propose a cross-modal contrastive learning strategy and apply positional encoding in attention modules for supervised ASD models to leverage the synchronization cue. Experimental results suggest that our model can successfully detect unsynchronized speaking as not speaking, addressing the limitation of current models. ",
    "url": "https://arxiv.org/abs/2206.10421",
    "authors": [
      "Abudukelimu Wuerkaixi",
      "You Zhang",
      "Zhiyao Duan",
      "Changshui Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.10429",
    "title": "Plug and Play Counterfactual Text Generation for Model Robustness",
    "abstract": "Generating counterfactual test-cases is an important backbone for testing NLP models and making them as robust and reliable as traditional software. In generating the test-cases, a desired property is the ability to control the test-case generation in a flexible manner to test for a large variety of failure cases and to explain and repair them in a targeted manner. In this direction, significant progress has been made in the prior works by manually writing rules for generating controlled counterfactuals. However, this approach requires heavy manual supervision and lacks the flexibility to easily introduce new controls. Motivated by the impressive flexibility of the plug-and-play approach of PPLM, we propose bringing the framework of plug-and-play to counterfactual test case generation task. We introduce CASPer, a plug-and-play counterfactual generation framework to generate test cases that satisfy goal attributes on demand. Our plug-and-play model can steer the test case generation process given any attribute model without requiring attribute-specific training of the model. In experiments, we show that CASPer effectively generates counterfactual text that follow the steering provided by an attribute model while also being fluent, diverse and preserving the original content. We also show that the generated counterfactuals from CASPer can be used for augmenting the training data and thereby fixing and making the test model more robust. ",
    "url": "https://arxiv.org/abs/2206.10429",
    "authors": [
      "Nishtha Madaan",
      "Srikanta Bedathur",
      "Diptikalyan Saha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.10442",
    "title": "Robust Task Representations for Offline Meta-Reinforcement Learning via  Contrastive Learning",
    "abstract": "We study offline meta-reinforcement learning, a practical reinforcement learning paradigm that learns from offline data to adapt to new tasks. The distribution of offline data is determined jointly by the behavior policy and the task. Existing offline meta-reinforcement learning algorithms cannot distinguish these factors, making task representations unstable to the change of behavior policies. To address this problem, we propose a contrastive learning framework for task representations that are robust to the distribution mismatch of behavior policies in training and test. We design a bi-level encoder structure, use mutual information maximization to formalize task representation learning, derive a contrastive learning objective, and introduce several approaches to approximate the true distribution of negative pairs. Experiments on a variety of offline meta-reinforcement learning benchmarks demonstrate the advantages of our method over prior methods, especially on the generalization to out-of-distribution behavior policies. The code is available at https://github.com/PKU-AI-Edge/CORRO. ",
    "url": "https://arxiv.org/abs/2206.10442",
    "authors": [
      "Haoqi Yuan",
      "Zongqing Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.10451",
    "title": "Winning the Lottery Ahead of Time: Efficient Early Network Pruning",
    "abstract": "Pruning, the task of sparsifying deep neural networks, received increasing attention recently. Although state-of-the-art pruning methods extract highly sparse models, they neglect two main challenges: (1) the process of finding these sparse models is often very expensive; (2) unstructured pruning does not provide benefits in terms of GPU memory, training time, or carbon emissions. We propose Early Compression via Gradient Flow Preservation (EarlyCroP), which efficiently extracts state-of-the-art sparse models before or early in training addressing challenge (1), and can be applied in a structured manner addressing challenge (2). This enables us to train sparse networks on commodity GPUs whose dense versions would be too large, thereby saving costs and reducing hardware requirements. We empirically show that EarlyCroP outperforms a rich set of baselines for many tasks (incl. classification, regression) and domains (incl. computer vision, natural language processing, and reinforcment learning). EarlyCroP leads to accuracy comparable to dense training while outperforming pruning baselines. ",
    "url": "https://arxiv.org/abs/2206.10451",
    "authors": [
      "John Rachwan",
      "Daniel Z\u00fcgner",
      "Bertrand Charpentier",
      "Simon Geisler",
      "Morgane Ayle",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.10457",
    "title": "Domain Adaptive 3D Pose Augmentation for In-the-wild Human Mesh Recovery",
    "abstract": "The ability to perceive 3D human bodies from a single image has a multitude of applications ranging from entertainment and robotics to neuroscience and healthcare. A fundamental challenge in human mesh recovery is in collecting the ground truth 3D mesh targets required for training, which requires burdensome motion capturing systems and is often limited to indoor laboratories. As a result, while progress is made on benchmark datasets collected in these restrictive settings, models fail to generalize to real-world ``in-the-wild'' scenarios due to distribution shifts. We propose Domain Adaptive 3D Pose Augmentation (DAPA), a data augmentation method that enhances the model's generalization ability in in-the-wild scenarios. DAPA combines the strength of methods based on synthetic datasets by getting direct supervision from the synthesized meshes, and domain adaptation methods by using ground truth 2D keypoints from the target dataset. We show quantitatively that finetuning with DAPA effectively improves results on benchmarks 3DPW and AGORA. We further demonstrate the utility of DAPA on a challenging dataset curated from videos of real-world parent-child interaction. ",
    "url": "https://arxiv.org/abs/2206.10457",
    "authors": [
      "Zhenzhen Weng",
      "Kuan-Chieh Wang",
      "Angjoo Kanazawa",
      "Serena Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.10464",
    "title": "Hybridization of evolutionary algorithm and deep reinforcement learning  for multi-objective orienteering optimization",
    "abstract": "Multi-objective orienteering problems (MO-OPs) are classical multi-objective routing problems and have received a lot of attention in the past decades. This study seeks to solve MO-OPs through a problem-decomposition framework, that is, a MO-OP is decomposed into a multi-objective knapsack problem (MOKP) and a travelling salesman problem (TSP). The MOKP and TSP are then solved by a multi-objective evolutionary algorithm (MOEA) and a deep reinforcement learning (DRL) method, respectively. While the MOEA module is for selecting cities, the DRL module is for planning a Hamiltonian path for these cities. An iterative use of these two modules drives the population towards the Pareto front of MO-OPs. The effectiveness of the proposed method is compared against NSGA-II and NSGA-III on various types of MO-OP instances. Experimental results show that our method exhibits the best performance on almost all the test instances, and has shown strong generalization ability. ",
    "url": "https://arxiv.org/abs/2206.10464",
    "authors": [
      "Wei Liu",
      "Rui Wang",
      "Tao Zhang",
      "Kaiwen Li",
      "Wenhua Li",
      "Hisao Ishibuchi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.10469",
    "title": "The Privacy Onion Effect: Memorization is Relative",
    "abstract": "Machine learning models trained on private datasets have been shown to leak their private data. While recent work has found that the average data point is rarely leaked, the outlier samples are frequently subject to memorization and, consequently, privacy leakage. We demonstrate and analyse an Onion Effect of memorization: removing the \"layer\" of outlier points that are most vulnerable to a privacy attack exposes a new layer of previously-safe points to the same attack. We perform several experiments to study this effect, and understand why it occurs. The existence of this effect has various consequences. For example, it suggests that proposals to defend against memorization without training with rigorous privacy guarantees are unlikely to be effective. Further, it suggests that privacy-enhancing technologies such as machine unlearning could actually harm the privacy of other users. ",
    "url": "https://arxiv.org/abs/2206.10469",
    "authors": [
      "Nicholas Carlini",
      "Matthew Jagielski",
      "Nicolas Papernot",
      "Andreas Terzis",
      "Florian Tramer",
      "Chiyuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.10472",
    "title": "NorBERT: NetwOrk Representations through BERT for Network Analysis and  Management",
    "abstract": "Deep neural network models have been very successfully applied to Natural Language Processing (NLP) and Image based tasks. Their application to network analysis and management tasks is just recently being pursued. Our interest is in producing deep models that can be effectively generalized to perform well on multiple network tasks in different environments. A major challenge is that traditional deep models often rely on categorical features, but cannot handle unseen categorical values. One method for dealing with such problems is to learn contextual embeddings for categorical variables used by deep networks to improve their performance. In this paper, we adapt the NLP pre-training technique and associated deep model BERT to learn semantically meaningful numerical representations (embeddings) for Fully Qualified Domain Names (FQDNs) used in communication networks. We show through a series of experiments that such an approach can be used to generate models that maintain their effectiveness when applied to environments other than the one in which they were trained. ",
    "url": "https://arxiv.org/abs/2206.10472",
    "authors": [
      "Franck Le",
      "Davis Wertheimer",
      "Seraphin Calo",
      "Erich Nahum"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2206.10491",
    "title": "Bi-Calibration Networks for Weakly-Supervised Video Representation  Learning",
    "abstract": "The leverage of large volumes of web videos paired with the searched queries or surrounding texts (e.g., title) offers an economic and extensible alternative to supervised video representation learning. Nevertheless, modeling such weakly visual-textual connection is not trivial due to query polysemy (i.e., many possible meanings for a query) and text isomorphism (i.e., same syntactic structure of different text). In this paper, we introduce a new design of mutual calibration between query and text to boost weakly-supervised video representation learning. Specifically, we present Bi-Calibration Networks (BCN) that novelly couples two calibrations to learn the amendment from text to query and vice versa. Technically, BCN executes clustering on all the titles of the videos searched by an identical query and takes the centroid of each cluster as a text prototype. The query vocabulary is built directly on query words. The video-to-text/video-to-query projections over text prototypes/query vocabulary then start the text-to-query or query-to-text calibration to estimate the amendment to query or text. We also devise a selection scheme to balance the two corrections. Two large-scale web video datasets paired with query and title for each video are newly collected for weakly-supervised video representation learning, which are named as YOVO-3M and YOVO-10M, respectively. The video features of BCN learnt on 3M web videos obtain superior results under linear model protocol on downstream tasks. More remarkably, BCN trained on the larger set of 10M web videos with further fine-tuning leads to 1.6%, and 1.8% gains in top-1 accuracy on Kinetics-400, and Something-Something V2 datasets over the state-of-the-art TDN, and ACTION-Net methods with ImageNet pre-training. Source code and datasets are available at \\url{https://github.com/FuchenUSTC/BCN}. ",
    "url": "https://arxiv.org/abs/2206.10491",
    "authors": [
      "Fuchen Long",
      "Ting Yao",
      "Zhaofan Qiu",
      "Xinmei Tian",
      "Jiebo Luo",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2206.10525",
    "title": "Three-way optimization of privacy and utility of location data",
    "abstract": "With the recent bloom of data and the drive towards an information-based society, the urge of and the advancements in data analytics is surging like never before. And with this, the risks of privacy violation of various kinds are also increasing manifold. Most of the methods to mitigate the privacy risks for location data resort to adding some noise to the location, like the planar Laplace used to achieve geo-indistinguishability. However, the noise should be calibrated carefully, taking into account the implications for utility, because it is far from ideal for the service providers to completely lose the utility of the collected data succumbing to the privacy requirements of the users. Similarly, the quality of service for the users should be optimized with their personalized needs of privacy protection used to shield their sensitive information. In this paper, we address this age-old battle between privacy and utility from three ends: privacy of the users' data, the quality of service (QoS) received by them in exchange for sharing their privatized data, and the statistical utility of the privatized data for the service providers who wish to perform various kinds of analysis and research on the data collected from the users. We propose a method to produce a geo-indistinguishable location-privacy mechanism that advances to optimize simultaneously between the level of privacy attained, the QoS, and the statistical utility achieved by the obfuscated data. We illustrate the soundness of this three-way privacy-utility optimization mechanism both analytically and with experiments. Apart from the novelty of the proposed method, this work is aimed to engender an analytical perspective to bridge between geo-indistinguishable location-privacy, QoS, and statistical utilities used in standard data analytics, from an information theoretical, probabilistic, and statistical perspective. ",
    "url": "https://arxiv.org/abs/2206.10525",
    "authors": [
      "Sayan Biswas",
      "Catuscia Palamidessi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2206.10531",
    "title": "Neural Transformers for Intraductal Papillary Mucosal Neoplasms (IPMN)  Classification in MRI images",
    "abstract": "Early detection of precancerous cysts or neoplasms, i.e., Intraductal Papillary Mucosal Neoplasms (IPMN), in pancreas is a challenging and complex task, and it may lead to a more favourable outcome. Once detected, grading IPMNs accurately is also necessary, since low-risk IPMNs can be under surveillance program, while high-risk IPMNs have to be surgically resected before they turn into cancer. Current standards (Fukuoka and others) for IPMN classification show significant intra- and inter-operator variability, beside being error-prone, making a proper diagnosis unreliable. The established progress in artificial intelligence, through the deep learning paradigm, may provide a key tool for an effective support to medical decision for pancreatic cancer. In this work, we follow this trend, by proposing a novel AI-based IPMN classifier that leverages the recent success of transformer networks in generalizing across a wide variety of tasks, including vision ones. We specifically show that our transformer-based model exploits pre-training better than standard convolutional neural networks, thus supporting the sought architectural universalism of transformers in vision, including the medical image domain and it allows for a better interpretation of the obtained results. ",
    "url": "https://arxiv.org/abs/2206.10531",
    "authors": [
      "Federica Proietto Salanitri",
      "Giovanni Bellitto",
      "Simone Palazzo",
      "Ismail Irmakci",
      "Michael B. Wallace",
      "Candice W. Bolan",
      "Megan Engels",
      "Sanne Hoogenboom",
      "Marco Aldinucci",
      "Ulas Bagci",
      "Daniela Giordano",
      "Concetto Spampinato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.10536",
    "title": "HealNet -- Self-Supervised Acute Wound Heal-Stage Classification",
    "abstract": "Identifying, tracking, and predicting wound heal-stage progression is a fundamental task towards proper diagnosis, effective treatment, facilitating healing, and reducing pain. Traditionally, a medical expert might observe a wound to determine the current healing state and recommend treatment. However, sourcing experts who can produce such a diagnosis solely from visual indicators can be time-consuming and expensive. In addition, lesions may take several weeks to undergo the healing process, demanding resources to monitor and diagnose continually. Automating this task can be challenging; datasets that follow wound progression from onset to maturation are small, rare, and often collected without computer vision in mind. To tackle these challenges, we introduce a self-supervised learning scheme composed of (a) learning embeddings of wound's temporal dynamics, (b) clustering for automatic stage discovery, and (c) fine-tuned classification. The proposed self-supervised and flexible learning framework is biologically inspired and trained on a small dataset with zero human labeling. The HealNet framework achieved high pre-text and downstream classification accuracy; when evaluated on held-out test data, HealNet achieved 94.2% pre-text accuracy and 93.8% heal-stage classification accuracy. ",
    "url": "https://arxiv.org/abs/2206.10536",
    "authors": [
      "H\u00e9ctor Carri\u00f3n",
      "Mohammad Jafari",
      "Hsin-Ya Yang",
      "Roslyn Rivkah",
      "Marco Rolandi",
      "Marcella Gomez",
      "Narges Norouzi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.10550",
    "title": "(Certified!!) Adversarial Robustness for Free!",
    "abstract": "In this paper we show how to achieve state-of-the-art certified adversarial robustness to 2-norm bounded perturbations by relying exclusively on off-the-shelf pretrained models. To do so, we instantiate the denoised smoothing approach of Salman et al. by combining a pretrained denoising diffusion probabilistic model and a standard high-accuracy classifier. This allows us to certify 71% accuracy on ImageNet under adversarial perturbations constrained to be within a 2-norm of 0.5, an improvement of 14 percentage points over the prior certified SoTA using any approach, or an improvement of 30 percentage points over denoised smoothing. We obtain these results using only pretrained diffusion models and image classifiers, without requiring any fine tuning or retraining of model parameters. ",
    "url": "https://arxiv.org/abs/2206.10550",
    "authors": [
      "Nicholas Carlini",
      "Florian Tramer",
      "Krishnamurthy",
      "Dvijotham",
      "J. Zico Kolter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.10557",
    "title": "A Study of Weisfeiler-Leman Colorings on Planar Graphs",
    "abstract": "The Weisfeiler-Leman (WL) algorithm is a combinatorial procedure that computes colorings on graphs, which can often be used to detect their (non-)isomorphism. Particularly the 1- and 2-dimensional versions 1-WL and 2-WL have received much attention, due to their numerous links to other areas of computer science. Knowing the expressive power of a certain dimension of the algorithm usually amounts to understanding the computed colorings. An increase in the dimension leads to finer computed colorings and, thus, more graphs can be distinguished. For example, on the class of planar graphs, 3-WL solves the isomorphism problem. However, the expressive power of 2-WL on the class is poorly understood (and, in particular, it may even well be that it decides isomorphism). In this paper, we investigate the colorings computed by 2-WL on planar graphs. Towards this end, we analyze the graphs induced by edge color classes in the graph. Based on the obtained classification, we show that for every 3-connected planar graph, it holds that: a) after coloring all pairs with their 2-WL color, the graph has fixing number 1 with respect to 1-WL, or b) there is a 2-WL-definable matching that can be used to transform the graph into a smaller one, or c) 2-WL detects a connected subgraph that is essentially the graph of a Platonic or Archimedean solid, a prism, a cycle, or a bipartite graph K_{2,\\ell}. In particular, the graphs from case (a) are identified by 2-WL. ",
    "url": "https://arxiv.org/abs/2206.10557",
    "authors": [
      "Sandra Kiefer",
      "Daniel Neuen"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2206.10579",
    "title": "Gradient-Enhanced Physics-Informed Neural Networks for Power Systems  Operational Support",
    "abstract": "The application of deep learning methods to speed up the resolution of challenging power flow problems has recently shown very encouraging results. However, power system dynamics are not snap-shot, steady-state operations. These dynamics must be considered to ensure that the optimal solutions provided by these models adhere to practical dynamical constraints, avoiding frequency fluctuations and grid instabilities. Unfortunately, dynamic system models based on ordinary or partial differential equations are frequently unsuitable for direct application in control or state estimates due to their high computational costs. To address these challenges, this paper introduces a machine learning method to approximate the behavior of power systems dynamics in near real time. The proposed framework is based on gradient-enhanced physics-informed neural networks (gPINNs) and encodes the underlying physical laws governing power systems. A key characteristic of the proposed gPINN is its ability to train without the need of generating expensive training data. The paper illustrates the potential of the proposed approach in both forward and inverse problems in a single-machine infinite bus system for predicting rotor angles and frequency, and uncertain parameters such as inertia and damping to showcase its potential for a range of power systems applications. ",
    "url": "https://arxiv.org/abs/2206.10579",
    "authors": [
      "Mostafa Mohammadian",
      "Kyri Baker",
      "Ferdinando Fioretto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.10581",
    "title": "Nimble GNN Embedding with Tensor-Train Decomposition",
    "abstract": "This paper describes a new method for representing embedding tables of graph neural networks (GNNs) more compactly via tensor-train (TT) decomposition. We consider the scenario where (a) the graph data that lack node features, thereby requiring the learning of embeddings during training; and (b) we wish to exploit GPU platforms, where smaller tables are needed to reduce host-to-GPU communication even for large-memory GPUs. The use of TT enables a compact parameterization of the embedding, rendering it small enough to fit entirely on modern GPUs even for massive graphs. When combined with judicious schemes for initialization and hierarchical graph partitioning, this approach can reduce the size of node embedding vectors by 1,659 times to 81,362 times on large publicly available benchmark datasets, achieving comparable or better accuracy and significant speedups on multi-GPU systems. In some cases, our model without explicit node features on input can even match the accuracy of models that use node features. ",
    "url": "https://arxiv.org/abs/2206.10581",
    "authors": [
      "Chunxing Yin",
      "Da Zheng",
      "Israt Nisa",
      "Christos Faloutos",
      "George Karypis",
      "Richard Vuduc"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.10587",
    "title": "Guiding Visual Attention in Deep Convolutional Neural Networks Based on  Human Eye Movements",
    "abstract": "Deep Convolutional Neural Networks (DCNNs) were originally inspired by principles of biological vision, have evolved into best current computational models of object recognition, and consequently indicate strong architectural and functional parallelism with the ventral visual pathway throughout comparisons with neuroimaging and neural time series data. As recent advances in deep learning seem to decrease this similarity, computational neuroscience is challenged to reverse-engineer the biological plausibility to obtain useful models. While previous studies have shown that biologically inspired architectures are able to amplify the human-likeness of the models, in this study, we investigate a purely data-driven approach. We use human eye tracking data to directly modify training examples and thereby guide the models' visual attention during object recognition in natural images either towards or away from the focus of human fixations. We compare and validate different manipulation types (i.e., standard, human-like, and non-human-like attention) through GradCAM saliency maps against human participant eye tracking data. Our results demonstrate that the proposed guided focus manipulation works as intended in the negative direction and non-human-like models focus on significantly dissimilar image parts compared to humans. The observed effects were highly category-specific, enhanced by animacy and face presence, developed only after feedforward processing was completed, and indicated a strong influence on face detection. With this approach, however, no significantly increased human-likeness was found. Possible applications of overt visual attention in DCNNs and further implications for theories of face detection are discussed. ",
    "url": "https://arxiv.org/abs/2206.10587",
    "authors": [
      "Leonard E. van Dyck",
      "Sebastian J. Denzler",
      "Walter R. Gruber"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.10588",
    "title": "Robust SDE-Based Variational Formulations for Solving Linear PDEs via  Deep Learning",
    "abstract": "The combination of Monte Carlo methods and deep learning has recently led to efficient algorithms for solving partial differential equations (PDEs) in high dimensions. Related learning problems are often stated as variational formulations based on associated stochastic differential equations (SDEs), which allow the minimization of corresponding losses using gradient-based optimization methods. In respective numerical implementations it is therefore crucial to rely on adequate gradient estimators that exhibit low variance in order to reach convergence accurately and swiftly. In this article, we rigorously investigate corresponding numerical aspects that appear in the context of linear Kolmogorov PDEs. In particular, we systematically compare existing deep learning approaches and provide theoretical explanations for their performances. Subsequently, we suggest novel methods that can be shown to be more robust both theoretically and numerically, leading to substantial performance improvements. ",
    "url": "https://arxiv.org/abs/2206.10588",
    "authors": [
      "Lorenz Richter",
      "Julius Berner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.07811",
    "title": "Safety Guarantees for Neural Network Dynamic Systems via Stochastic  Barrier Functions",
    "abstract": "Neural Networks (NNs) have been successfully employed to represent the state evolution of complex dynamical systems. Such models, referred to as NN dynamic models (NNDMs), use iterative noisy predictions of NN to estimate a distribution of system trajectories over time. Despite their accuracy, safety analysis of NNDMs is known to be a challenging problem and remains largely unexplored. To address this issue, in this paper, we introduce a method of providing safety guarantees for NNDMs. Our approach is based on stochastic barrier functions, whose relation with safety are analogous to that of Lyapunov functions with stability. We first show a method of synthesizing stochastic barrier functions for NNDMs via a convex optimization problem, which in turn provides a lower bound on the system's safety probability. A key step in our method is the employment of the recent convex approximation results for NNs to find piece-wise linear bounds, which allow the formulation of the barrier function synthesis problem as a sum-of-squares optimization program. If the obtained safety probability is above the desired threshold, the system is certified. Otherwise, we introduce a method of generating controls for the system that robustly maximizes the safety probability in a minimally-invasive manner. We exploit the convexity property of the barrier function to formulate the optimal control synthesis problem as a linear program. Experimental results illustrate the efficacy of the method. Namely, they show that the method can scale to multi-dimensional NNDMs with multiple layers and hundreds of neurons per layer, and that the controller can significantly improve the safety probability. ",
    "url": "https://arxiv.org/abs/2206.07811",
    "authors": [
      "Rayan Mazouz",
      "Karan Muvvala",
      "Akash Ratheesh",
      "Luca Laurenti",
      "Morteza Lahijanian"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.08936",
    "title": "Simultaneous Bone and Shadow Segmentation Network using Task  Correspondence Consistency",
    "abstract": "Segmenting both bone surface and the corresponding acoustic shadow are fundamental tasks in ultrasound (US) guided orthopedic procedures. However, these tasks are challenging due to minimal and blurred bone surface response in US images, cross-machine discrepancy, imaging artifacts, and low signal-to-noise ratio. Notably, bone shadows are caused by a significant acoustic impedance mismatch between the soft tissue and bone surfaces. To leverage this mutual information between these highly related tasks, we propose a single end-to-end network with a shared transformer-based encoder and task independent decoders for simultaneous bone and shadow segmentation. To share complementary features, we propose a cross task feature transfer block which learns to transfer meaningful features from decoder of shadow segmentation to that of bone segmentation and vice-versa. We also introduce a correspondence consistency loss which makes sure that network utilizes the inter-dependency between the bone surface and its corresponding shadow to refine the segmentation. Validation against expert annotations shows that the method outperforms the previous state-of-the-art for both bone surface and shadow segmentation. ",
    "url": "https://arxiv.org/abs/2206.08936",
    "authors": [
      "Aimon Rahman",
      "Jeya Maria Jose Valanarasu",
      "Ilker Hacihaliloglu",
      "Vishal M Patel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.08953",
    "title": "Bayesian neural networks for the probabilistic forecasting of wind  direction and speed using ocean data",
    "abstract": "Neural networks are increasingly being used in a variety of settings to predict wind direction and speed, two of the most important factors for estimating the potential power output of a wind farm. However, these predictions are arguably of limited value because classical neural networks lack the ability to express uncertainty. Here we instead consider the use of Bayesian Neural Networks (BNNs), for which the weights, biases and outputs are distributions rather than deterministic point values. This allows for the evaluation of both epistemic and aleatoric uncertainty and leads to well-calibrated uncertainty predictions of both wind speed and power. Here we consider the application of BNNs to the problem of offshore wind resource prediction for renewable energy applications. For our dataset, we use observations recorded at the FINO1 research platform in the North Sea and our predictors are ocean data such as water temperature and current direction. The probabilistic forecast predicted by the BNN adds considerable value to the results and, in particular, informs the user of the network's ability to make predictions of out-of-sample datapoints. We use this property of BNNs to conclude that the accuracy and uncertainty of the wind speed and direction predictions made by our network are unaffected by the construction of the nearby Alpha Ventus wind farm. Hence, at this site, networks trained on pre-farm ocean data can be used to accurately predict wind field information from ocean data after the wind farm has been constructed. ",
    "url": "https://arxiv.org/abs/2206.08953",
    "authors": [
      "Mariana C A Clare",
      "Matthew D Piggott"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08994",
    "title": "Robust Group Synchronization via Quadratic Programming",
    "abstract": "We propose a novel quadratic programming formulation for estimating the corruption levels in group synchronization, and use these estimates to solve this problem. Our objective function exploits the cycle consistency of the group and we thus refer to our method as detection and estimation of structural consistency (DESC). This general framework can be extended to other algebraic and geometric structures. Our formulation has the following advantages: it can tolerate corruption as high as the information-theoretic bound, it does not require a good initialization for the estimates of group elements, it has a simple interpretation, and under some mild conditions the global minimum of our objective function exactly recovers the corruption levels. We demonstrate the competitive accuracy of our approach on both synthetic and real data experiments of rotation averaging. ",
    "url": "https://arxiv.org/abs/2206.08994",
    "authors": [
      "Yunpeng Shi",
      "Cole Wyeth",
      "Gilad Lerman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2206.09041",
    "title": "Accelerating Machine Learning Training Time for Limit Order Book  Prediction",
    "abstract": "Financial firms are interested in simulation to discover whether a given algorithm involving financial machine learning will operate profitably. While many versions of this type of algorithm have been published recently by researchers, the focus herein is on a particular machine learning training project due to the explainable nature and the availability of high frequency market data. For this task, hardware acceleration is expected to speed up the time required for the financial machine learning researcher to obtain the results. As the majority of the time can be spent in classifier training, there is interest in faster training steps. A published Limit Order Book algorithm for predicting stock market direction is our subject, and the machine learning training process can be time-intensive especially when considering the iterative nature of model development. To remedy this, we deploy Graphical Processing Units (GPUs) produced by NVIDIA available in the data center where the computer architecture is geared to parallel high-speed arithmetic operations. In the studied configuration, this leads to significantly faster training time allowing more efficient and extensive model development. ",
    "url": "https://arxiv.org/abs/2206.09041",
    "authors": [
      "Mark Joseph Bennett"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09042",
    "title": "Riemannian CUR Decompositions for Robust Principal Component Analysis",
    "abstract": "Robust Principal Component Analysis (PCA) has received massive attention in recent years. It aims to recover a low-rank matrix and a sparse matrix from their sum. This paper proposes a novel nonconvex Robust PCA algorithm, coined Riemannian CUR (RieCUR), which utilizes the ideas of Riemannian optimization and robust CUR decompositions. This algorithm has the same computational complexity as Iterated Robust CUR, which is currently state-of-the-art, but is more robust to outliers. RieCUR is also able to tolerate a significant amount of outliers, and is comparable to Accelerated Alternating Projections, which has high outlier tolerance but worse computational complexity than the proposed method. Thus, the proposed algorithm achieves state-of-the-art performance on Robust PCA both in terms of computational complexity and outlier tolerance. ",
    "url": "https://arxiv.org/abs/2206.09042",
    "authors": [
      "Keaton Hamm",
      "Mohamed Meskini",
      "HanQin Cai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2206.09065",
    "title": "Free-form Lesion Synthesis Using a Partial Convolution Generative  Adversarial Network for Enhanced Deep Learning Liver Tumor Segmentation",
    "abstract": "Automatic deep learning segmentation models has been shown to improve both the segmentation efficiency and the accuracy. However, training a robust segmentation model requires considerably large labeled training samples, which may be impractical. This study aimed to develop a deep learning framework for generating synthetic lesions that can be used to enhance network training. The lesion synthesis network is a modified generative adversarial network (GAN). Specifically, we innovated a partial convolution strategy to construct an Unet-like generator. The discriminator is designed using Wasserstein GAN with gradient penalty and spectral normalization. A mask generation method based on principal component analysis was developed to model various lesion shapes. The generated masks are then converted into liver lesions through a lesion synthesis network. The lesion synthesis framework was evaluated for lesion textures, and the synthetic lesions were used to train a lesion segmentation network to further validate the effectiveness of this framework. All the networks are trained and tested on the public dataset from LITS. The synthetic lesions generated by the proposed approach have very similar histogram distributions compared to the real lesions for the two employed texture parameters, GLCM-energy and GLCM-correlation. The Kullback-Leibler divergence of GLCM-energy and GLCM-correlation were 0.01 and 0.10, respectively. Including the synthetic lesions in the tumor segmentation network improved the segmentation dice performance of U-Net significantly from 67.3% to 71.4% (p<0.05). Meanwhile, the volume precision and sensitivity improve from 74.6% to 76.0% (p=0.23) and 66.1% to 70.9% (p<0.01), respectively. The synthetic data significantly improves the segmentation performance. ",
    "url": "https://arxiv.org/abs/2206.09065",
    "authors": [
      "Yingao Liu",
      "Fei Yang",
      "Yidong Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09103",
    "title": "Identifying Source Speakers for Voice Conversion based Spoofing Attacks  on Speaker Verification Systems",
    "abstract": "An automatic speaker verification system aims to verify the speaker identity of a speech signal. However, a voice conversion system manipulates the original person's speech signal to make it sound like the target speaker's voice and deceive the speaker verification system. Most countermeasures for voice conversion-based spoofing attacks are designed to discriminate bona fide speech from spoofed speech for speaker verification systems. In this paper, we investigate the problem of source speaker identification -- inferring the identity of the source speaker given the voice converted speech. To perform source speaker identification, we simply add voice-converted speech data with the label of source speaker identity to the genuine speech dataset during speaker embedding network training. Experimental results show the feasibility of source speaker identification when training and testing with converted speeches from the same voice conversion model(s). When testing on converted speeches from an unseen voice conversion algorithm, the performance of source speaker identification improves when more voice conversion models are used during training. ",
    "url": "https://arxiv.org/abs/2206.09103",
    "authors": [
      "Danwei Cai",
      "Zexin Cai",
      "Ming Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.09109",
    "title": "Fast and Provable Tensor Robust Principal Component Analysis via Scaled  Gradient Descent",
    "abstract": "An increasing number of data science and machine learning problems rely on computation with tensors, which better capture the multi-way relationships and interactions of data than matrices. When tapping into this critical advantage, a key challenge is to develop computationally efficient and provably correct algorithms for extracting useful information from tensor data that are simultaneously robust to corruptions and ill-conditioning. This paper tackles tensor robust principal component analysis (RPCA), which aims to recover a low-rank tensor from its observations contaminated by sparse corruptions, under the Tucker decomposition. To minimize the computation and memory footprints, we propose to directly recover the low-dimensional tensor factors -- starting from a tailored spectral initialization -- via scaled gradient descent (ScaledGD), coupled with an iteration-varying thresholding operation to adaptively remove the impact of corruptions. Theoretically, we establish that the proposed algorithm converges linearly to the true low-rank tensor at a constant rate that is independent with its condition number, as long as the level of corruptions is not too large. Empirically, we demonstrate that the proposed algorithm achieves better and more scalable performance than state-of-the-art matrix and tensor RPCA algorithms through synthetic experiments and real-world applications. ",
    "url": "https://arxiv.org/abs/2206.09109",
    "authors": [
      "Harry Dong",
      "Tian Tong",
      "Cong Ma",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2206.09120",
    "title": "Pursuit of a Discriminative Representation for Multiple Subspaces via  Sequential Games",
    "abstract": "We consider the problem of learning discriminative representations for data in a high-dimensional space with distribution supported on or around multiple low-dimensional linear subspaces. That is, we wish to compute a linear injective map of the data such that the features lie on multiple orthogonal subspaces. Instead of treating this learning problem using multiple PCAs, we cast it as a sequential game using the closed-loop transcription (CTRL) framework recently proposed for learning discriminative and generative representations for general low-dimensional submanifolds. We prove that the equilibrium solutions to the game indeed give correct representations. Our approach unifies classical methods of learning subspaces with modern deep learning practice, by showing that subspace learning problems may be provably solved using the modern toolkit of representation learning. In addition, our work provides the first theoretical justification for the CTRL framework, in the important case of linear subspaces. We support our theoretical findings with compelling empirical evidence. We also generalize the sequential game formulation to more general representation learning problems. Our code, including methods for easy reproduction of experimental results, is publically available on GitHub. ",
    "url": "https://arxiv.org/abs/2206.09120",
    "authors": [
      "Druv Pai",
      "Michael Psenka",
      "Chih-Yuan Chiu",
      "Manxi Wu",
      "Edgar Dobriban",
      "Yi Ma"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09128",
    "title": "A Combined PCA-MLP Network for Early Breast Cancer Detection",
    "abstract": "Breast cancer is the second most responsible for all cancer types and has been the cause of numerous deaths over the years, especially among women. Any improvisation of the existing diagnosis system for the detection of cancer can contribute to minimizing the death ratio. Moreover, cancer detection at an early stage has recently been a prime research area in the scientific community to enhance the survival rate. Proper choice of machine learning tools can ensure early-stage prognosis with high accuracy. In this paper, we have studied different machine learning algorithms to detect whether a patient is likely to face breast cancer or not. Due to the implicit behavior of early-stage features, we have implemented a multilayer perception model with the integration of PCA and suggested it to be more viable than other detection algorithms. Our 4 layers MLP-PCA network has obtained the best accuracy of 100% with a mean of 90.48% accuracy on the BCCD dataset. ",
    "url": "https://arxiv.org/abs/2206.09128",
    "authors": [
      "Md. Wahiduzzaman Khan Arnob",
      "Arunima Dey Pooja",
      "Md. Saif Hassan Onim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09193",
    "title": "Multi-Modality Image Super-Resolution using Generative Adversarial  Networks",
    "abstract": "Over the past few years deep learning-based techniques such as Generative Adversarial Networks (GANs) have significantly improved solutions to image super-resolution and image-to-image translation problems. In this paper, we propose a solution to the joint problem of image super-resolution and multi-modality image-to-image translation. The problem can be stated as the recovery of a high-resolution image in a modality, given a low-resolution observation of the same image in an alternative modality. Our paper offers two models to address this problem and will be evaluated on the recovery of high-resolution day images given low-resolution night images of the same scene. Promising qualitative and quantitative results will be presented for each model. ",
    "url": "https://arxiv.org/abs/2206.09193",
    "authors": [
      "Aref Abedjooy",
      "Mehran Ebrahimi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09210",
    "title": "Multi-Modality Image Inpainting using Generative Adversarial Networks",
    "abstract": "Deep learning techniques, especially Generative Adversarial Networks (GANs) have significantly improved image inpainting and image-to-image translation tasks over the past few years. To the best of our knowledge, the problem of combining the image inpainting task with the multi-modality image-to-image translation remains intact. In this paper, we propose a model to address this problem. The model will be evaluated on combined night-to-day image translation and inpainting, along with promising qualitative and quantitative results. ",
    "url": "https://arxiv.org/abs/2206.09210",
    "authors": [
      "Aref Abedjooy",
      "Mehran Ebrahimi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09241",
    "title": "An Empirical Study of Quantum Dynamics as a Ground State Problem with  Neural Quantum States",
    "abstract": "Neural quantum states are variational wave functions parameterised by artificial neural networks, a mathematical model studied for decades in the machine learning community. In the context of many-body physics, methods such as variational Monte Carlo with neural quantum states as variational wave functions are successful in approximating, with great accuracy, the ground-state of a quantum Hamiltonian. However, all the difficulties of proposing neural network architectures, along with exploring their expressivity and trainability, permeate their application as neural quantum states. In this paper, we consider the Feynman-Kitaev Hamiltonian for the transverse field Ising model, whose ground state encodes the time evolution of a spin chain at discrete time steps. We show how this ground state problem specifically challenges the neural quantum state trainability as the time steps increase because the true ground state becomes more entangled, and the probability distribution starts to spread across the Hilbert space. Our results indicate that the considered neural quantum states are capable of accurately approximating the true ground state of the system, i.e., they are expressive enough. However, extensive hyper-parameter tuning experiments point towards the empirical fact that it is poor trainability--in the variational Monte Carlo setup--that prevents a faithful approximation of the true ground state. ",
    "url": "https://arxiv.org/abs/2206.09241",
    "authors": [
      "Vladimir Vargas-Calder\u00f3n",
      "Herbert Vinck-Posada",
      "Fabio A. Gonz\u00e1lez"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09326",
    "title": "Toward Agile and Robust Supply Chains: A Lesson from Stochastic Job-Shop  Scheduling",
    "abstract": "Motivated by the presence of uncertainties as well as combinatorial complexity within the links of supply chains, this paper addresses the outstanding and timely challenge illustrated through a case study of stochastic job-shop scheduling problems arising within low-volume high-variety manufacturing. These problems have been classically formulated as integer linear programs (ILPs), which are known to be NP-hard, and are computationally intractable. Yet, optimal or near-optimal solutions must be obtained within strict computational time requirements. While the deterministic cases have been efficiently solved by state-of-the-art methods such as branch-and-cut (B&C), uncertainties may compromise the entire schedule thereby potentially affecting the entire supply chain downstream, thus, uncertainties must be explicitly captured to ensure the feasibility of operations. The stochastic nature of the resulting problem adds a layer of computational difficulty on top of an already intractable problem, as evidenced by the presented case studies with some cases taking hours without being able to find a \"near-optimal\" schedule. To efficiently solve the stochastic JSS problem, a recent Surrogate \"Level-Based\" Lagrangian Relaxation is used to reduce computational effort while efficiently exploiting geometric convergence potential inherent to Polyak's step-sizing formula thereby leading to fast convergence. Computational results demonstrate that the new method is more than two orders of magnitude faster compared to B&C. Moreover, insights based on a small intuitive example are provided through simulations demonstrating an advantage of scholastic scheduling. ",
    "url": "https://arxiv.org/abs/2206.09326",
    "authors": [
      "Mikhail A. Bragin",
      "Matthew E. Wilhelm",
      "Matthew D. Stuber"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.09381",
    "title": "Graph Neural Network Aided MU-MIMO Detectors",
    "abstract": "Multi-user multiple-input multiple-output (MU-MIMO) systems can be used to meet high throughput requirements of 5G and beyond networks. A base station serves many users in an uplink MU-MIMO system, leading to a substantial multi-user interference (MUI). Designing a high-performance detector for dealing with a strong MUI is challenging. This paper analyses the performance degradation caused by the posterior distribution approximation used in the state-of-the-art message passing (MP) detectors in the presence of high MUI. We develop a graph neural network based framework to fine-tune the MP detectors' cavity distributions and thus improve the posterior distribution approximation in the MP detectors. We then propose two novel neural network based detectors which rely on the expectation propagation (EP) and Bayesian parallel interference cancellation (BPIC), referred to as the GEPNet and GPICNet detectors, respectively. The GEPNet detector maximizes detection performance, while GPICNet detector balances the performance and complexity. We provide proof of the permutation equivariance property, allowing the detectors to be trained only once, even in the systems with dynamic changes of the number of users. The simulation results show that the proposed GEPNet detector performance approaches maximum likelihood performance in various configurations and GPICNet detector doubles the multiplexing gain of BPIC detector. ",
    "url": "https://arxiv.org/abs/2206.09381",
    "authors": [
      "Alva Kosasih",
      "Vincent Onasis",
      "Vera Miloslavskaya",
      "Wibowo Hardjawana",
      "Victor Andrean",
      "Branka Vucetic"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.09396",
    "title": "Transfer Learning for Robust Low-Resource Children's Speech ASR with  Transformers and Source-Filter Warping",
    "abstract": "Automatic Speech Recognition (ASR) systems are known to exhibit difficulties when transcribing children's speech. This can mainly be attributed to the absence of large children's speech corpora to train robust ASR models and the resulting domain mismatch when decoding children's speech with systems trained on adult data. In this paper, we propose multiple enhancements to alleviate these issues. First, we propose a data augmentation technique based on the source-filter model of speech to close the domain gap between adult and children's speech. This enables us to leverage the data availability of adult speech corpora by making these samples perceptually similar to children's speech. Second, using this augmentation strategy, we apply transfer learning on a Transformer model pre-trained on adult data. This model follows the recently introduced XLS-R architecture, a wav2vec 2.0 model pre-trained on several cross-lingual adult speech corpora to learn general and robust acoustic frame-level representations. Adopting this model for the ASR task using adult data augmented with the proposed source-filter warping strategy and a limited amount of in-domain children's speech significantly outperforms previous state-of-the-art results on the PF-STAR British English Children's Speech corpus with a 4.86% WER on the official test set. ",
    "url": "https://arxiv.org/abs/2206.09396",
    "authors": [
      "Jenthe Thienpondt",
      "Kris Demuynck"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2206.09490",
    "title": "A Bounded-Confidence Model of Opinion Dynamics with Heterogeneous  Node-Activity Levels",
    "abstract": "Agent-based models of opinion dynamics examine the spread of opinions between entities and allow one to study phenomena such as consensus, polarization, and fragmentation. One examines them on social networks to investigate the effects of network structure on these phenomena. In social networks, some individuals share their ideas and opinions more frequently than others. These disparities can arise from heterogeneous sociabilities, heterogeneous activity levels, different prevalences to share opinions when engaging in a social-media platform, or something else. To examine the impact of such heterogeneities on opinion dynamics, we generalize the Deffuant--Weisbuch (DW) bounded-confidence model (BCM) of opinion dynamics by incorporating node weights. The node weights allow us to model agents with different probabilities of interacting. Using numerical simulations, we systematically investigate (using a variety of network structures and node-weight distributions) the effects of node weights, which we assign uniformly at random to the nodes. We demonstrate that introducing heterogeneous node weights results in longer convergence times and more opinion fragmentation than in a baseline DW model. One can use the node weights of our BCM to capture a variety of sociological scenarios in which agents have heterogeneous probabilities of interacting with other agents. ",
    "url": "https://arxiv.org/abs/2206.09490",
    "authors": [
      "Grace J. Li",
      "Mason A. Porter"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.09513",
    "title": "$C^*$-algebra Net: A New Approach Generalizing Neural Network Parameters  to $C^*$-algebra",
    "abstract": "We propose a new framework that generalizes the parameters of neural network models to $C^*$-algebra-valued ones. $C^*$-algebra is a generalization of the space of complex numbers. A typical example is the space of continuous functions on a compact space. This generalization enables us to combine multiple models continuously and use tools for functions such as regression and integration. Consequently, we can learn features of data efficiently and adapt the models to problems continuously. We apply our framework to practical problems such as density estimation and few-shot learning and show that our framework enables us to learn features of data even with a limited number of samples. Our new framework highlights the potential possibility of applying the theory of $C^*$-algebra to general neural network models. ",
    "url": "https://arxiv.org/abs/2206.09513",
    "authors": [
      "Yuka Hashimoto",
      "Zhao Wang",
      "Tomoko Matsu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09522",
    "title": "Multiple Testing Framework for Out-of-Distribution Detection",
    "abstract": "We study the problem of Out-of-Distribution (OOD) detection, that is, detecting whether a learning algorithm's output can be trusted at inference time. While a number of tests for OOD detection have been proposed in prior work, a formal framework for studying this problem is lacking. We propose a definition for the notion of OOD that includes both the input distribution and the learning algorithm, which provides insights for the construction of powerful tests for OOD detection. We propose a multiple hypothesis testing inspired procedure to systematically combine any number of different statistics from the learning algorithm using conformal p-values. We further provide strong guarantees on the probability of incorrectly classifying an in-distribution sample as OOD. In our experiments, we find that threshold-based tests proposed in prior work perform well in specific settings, but not uniformly well across different types of OOD instances. In contrast, our proposed method that combines multiple statistics performs uniformly well across different datasets and neural networks. ",
    "url": "https://arxiv.org/abs/2206.09522",
    "authors": [
      "Akshayaa Magesh",
      "Venugopal V. Veeravalli",
      "Anirban Roy",
      "Susmit Jha"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09543",
    "title": "Meta-learning for Out-of-Distribution Detection via Density Estimation  in Latent Space",
    "abstract": "Many neural network-based out-of-distribution (OoD) detection methods have been proposed. However, they require many training data for each target task. We propose a simple yet effective meta-learning method to detect OoD with small in-distribution data in a target task. With the proposed method, the OoD detection is performed by density estimation in a latent space. A neural network shared among all tasks is used to flexibly map instances in the original space to the latent space. The neural network is meta-learned such that the expected OoD detection performance is improved by using various tasks that are different from the target tasks. This meta-learning procedure enables us to obtain appropriate representations in the latent space for OoD detection. For density estimation, we use a Gaussian mixture model (GMM) with full covariance for each class. We can adapt the GMM parameters to in-distribution data in each task in a closed form by maximizing the likelihood. Since the closed form solution is differentiable, we can meta-learn the neural network efficiently with a stochastic gradient descent method by incorporating the solution into the meta-learning objective function. In experiments using six datasets, we demonstrate that the proposed method achieves better performance than existing meta-learning and OoD detection methods. ",
    "url": "https://arxiv.org/abs/2206.09543",
    "authors": [
      "Tomoharu Iwata",
      "Atsutoshi Kumagai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09662",
    "title": "On approximating the rank of graph divisors",
    "abstract": "Baker and Norine initiated the study of graph divisors as a graph-theoretic analogue of the Riemann-Roch theory for Riemann surfaces. One of the key concepts of graph divisor theory is the {\\it rank} of a divisor on a graph. The importance of the rank is well illustrated by Baker's {\\it Specialization lemma}, stating that the dimension of a linear system can only go up under specialization from curves to graphs, leading to a fruitful interaction between divisors on graphs and curves. Due to its decisive role, determining the rank is a central problem in graph divisor theory. Kiss and T\\'othm\\'eresz reformulated the problem using chip-firing games, and showed that computing the rank of a divisor on a graph is NP-hard via reduction from the Minimum Feedback Arc Set problem. In this paper, we strengthen their result by establishing a connection between chip-firing games and the Minimum Target Set Selection problem. As a corollary, we show that the rank is difficult to approximate to within a factor of $O(2^{\\log^{1-\\varepsilon}n})$ for any $\\varepsilon > 0$ unless $P=NP$. Furthermore, assuming the Planted Dense Subgraph Conjecture, the rank is difficult to approximate to within a factor of $O(n^{1/4-\\varepsilon})$ for any $\\varepsilon>0$. ",
    "url": "https://arxiv.org/abs/2206.09662",
    "authors": [
      "Krist\u00f3f B\u00e9rczi",
      "Hung P. Hoang",
      "Lilla T\u00f3thm\u00e9r\u00e9sz"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2206.09818",
    "title": "SMT-DTA: Improving Drug-Target Affinity Prediction with Semi-supervised  Multi-task Training",
    "abstract": "Drug-Target Affinity (DTA) prediction is an essential task for drug discovery and pharmaceutical research. Accurate predictions of DTA can greatly benefit the design of new drug. As wet experiments are costly and time consuming, the supervised data for DTA prediction is extremely limited. This seriously hinders the application of deep learning based methods, which require a large scale of supervised data. To address this challenge and improve the DTA prediction accuracy, we propose a framework with several simple yet effective strategies in this work: (1) a multi-task training strategy, which takes the DTA prediction and the masked language modeling (MLM) task on the paired drug-target dataset; (2) a semi-supervised training method to empower the drug and target representation learning by leveraging large-scale unpaired molecules and proteins in training, which differs from previous pre-training and fine-tuning methods that only utilize molecules or proteins in pre-training; and (3) a cross-attention module to enhance the interaction between drug and target representation. Extensive experiments are conducted on three real-world benchmark datasets: BindingDB, DAVIS and KIBA. The results show that our framework significantly outperforms existing methods and achieves state-of-the-art performances, e.g., $0.712$ RMSE on BindingDB IC$_{50}$ measurement with more than $5\\%$ improvement than previous best work. In addition, case studies on specific drug-target binding activities, drug feature visualizations, and real-world applications demonstrate the great potential of our work. The code and data are released at https://github.com/QizhiPei/SMT-DTA ",
    "url": "https://arxiv.org/abs/2206.09818",
    "authors": [
      "Qizhi Pei",
      "Lijun Wu",
      "Jinhua Zhu",
      "Yingce Xia",
      "Shufang Xia",
      "Tao Qin",
      "Haiguang Liu",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09823",
    "title": "Multi-criteria optimization and automated network restructuring to  mitigate construction projects delays on-the-run",
    "abstract": "Construction project management requires dynamic mitigation control ensuring the project's timely completion by a best fit for common purpose strategy for all stakeholders. Current mitigation approaches are usually performed by an iterative Monte Carlo (MC) analysis focussing on lowest-cost strategies which do not include (1) the project manager's goal-oriented behaviour, (2) automated network restructuring potential, and (3) multi-dimensional optimization criteria for best fitting mitigation strategies-criteria. Therefore, the development statement within this paper is to design a method and implementation tool that properly dissolves all the aforementioned shortcomings ensuring the project's completion date by finding the most effective and efficient mitigation strategy. To fulfill the purpose of this paper, the Mitigation Controller (MitC) has been developed using an integrative approach of non-linear optimization techniques, probabilistic Monte Carlo simulation, and preference function modeling. Compared to the conventional way of mitigating project delays. The developed MitC allows mitigating potential delays with the least negative consequences on several project criteria, such as cost, environmental impact, etc. The application of the model to the demonstrative case study shows the ability of the model to significantly increase the probability of completing the project in the given target duration. Embedding the multi-criteria evaluation in the optimization model ensures that other interests are also represented in finding the optimal strategy for project delays. ",
    "url": "https://arxiv.org/abs/2206.09823",
    "authors": [
      "Nina Prins",
      "Omar Kammouh",
      "A.R.M. Wolfert"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.09872",
    "title": "A Neural Network Based Method with Transfer Learning for Genetic Data  Analysis",
    "abstract": "Transfer learning has emerged as a powerful technique in many application problems, such as computer vision and natural language processing. However, this technique is largely ignored in application to genetic data analysis. In this paper, we combine transfer learning technique with a neural network based method(expectile neural networks). With transfer learning, instead of starting the learning process from scratch, we start from one task that have been learned when solving a different task. We leverage previous learnings and avoid starting from scratch to improve the model performance by passing information gained in different but related task. To demonstrate the performance, we run two real data sets. By using transfer learning algorithm, the performance of expectile neural networks is improved compared to expectile neural network without using transfer learning technique. ",
    "url": "https://arxiv.org/abs/2206.09872",
    "authors": [
      "Jinghang Lin",
      "Shan Zhang",
      "Qing Lu"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ]
  },
  {
    "id": "arXiv:2206.09901",
    "title": "Only Tails Matter: Average-Case Universality and Robustness in the  Convex Regime",
    "abstract": "The recently developed average-case analysis of optimization methods allows a more fine-grained and representative convergence analysis than usual worst-case results. In exchange, this analysis requires a more precise hypothesis over the data generating process, namely assuming knowledge of the expected spectral distribution (ESD) of the random matrix associated with the problem. This work shows that the concentration of eigenvalues near the edges of the ESD determines a problem's asymptotic average complexity. This a priori information on this concentration is a more grounded assumption than complete knowledge of the ESD. This approximate concentration is effectively a middle ground between the coarseness of the worst-case scenario convergence and the restrictive previous average-case analysis. We also introduce the Generalized Chebyshev method, asymptotically optimal under a hypothesis on this concentration and globally optimal when the ESD follows a Beta distribution. We compare its performance to classical optimization algorithms, such as gradient descent or Nesterov's scheme, and we show that, in the average-case context, Nesterov's method is universally nearly optimal asymptotically. ",
    "url": "https://arxiv.org/abs/2206.09901",
    "authors": [
      "Leonardo Cunha",
      "Gauthier Gidel",
      "Fabien Pedregosa",
      "Damien Scieurand Courtney Paquette"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09992",
    "title": "Hyperparameter Importance of Quantum Neural Networks Across Small  Datasets",
    "abstract": "As restricted quantum computers are slowly becoming a reality, the search for meaningful first applications intensifies. In this domain, one of the more investigated approaches is the use of a special type of quantum circuit - a so-called quantum neural network -- to serve as a basis for a machine learning model. Roughly speaking, as the name suggests, a quantum neural network can play a similar role to a neural network. However, specifically for applications in machine learning contexts, very little is known about suitable circuit architectures, or model hyperparameters one should use to achieve good learning performance. In this work, we apply the functional ANOVA framework to quantum neural networks to analyze which of the hyperparameters were most influential for their predictive performance. We analyze one of the most typically used quantum neural network architectures. We then apply this to $7$ open-source datasets from the OpenML-CC18 classification benchmark whose number of features is small enough to fit on quantum hardware with less than $20$ qubits. Three main levels of importance were detected from the ranking of hyperparameters obtained with functional ANOVA. Our experiment both confirmed expected patterns and revealed new insights. For instance, setting well the learning rate is deemed the most critical hyperparameter in terms of marginal contribution on all datasets, whereas the particular choice of entangling gates used is considered the least important except on one dataset. This work introduces new methodologies to study quantum machine learning models and provides new insights toward quantum model selection. ",
    "url": "https://arxiv.org/abs/2206.09992",
    "authors": [
      "Charles Moussa",
      "Jan N. van Rijn",
      "Thomas B\u00e4ck",
      "Vedran Dunjko"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.10010",
    "title": "Extremal graph realizations and graph Laplacian eigenvalues",
    "abstract": "For a regular polyhedron (or polygon) centered at the origin, the coordinates of the vertices are eigenvectors of the graph Laplacian for the skeleton of that polyhedron (or polygon) associated with the first (non-trivial) eigenvalue. In this paper, we generalize this relationship. For a given graph, we study the eigenvalue optimization problem of maximizing the first (non-trivial) eigenvalue of the graph Laplacian over non-negative edge weights. We show that the spectral realization of the graph using the eigenvectors corresponding to the solution of this problem, under certain assumptions, is a centered, unit-distance graph realization that has maximal total variance. This result gives a new method for generating unit-distance graph realizations and is based on convex duality. A drawback of this method is that the dimension of the realization is given by the multiplicity of the extremal eigenvalue, which is typically unknown prior to solving the eigenvalue optimization problem. Our results are illustrated with a number of examples. ",
    "url": "https://arxiv.org/abs/2206.10010",
    "authors": [
      "Braxton Osting"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2206.10074",
    "title": "Statistical network isomorphism",
    "abstract": "Graph isomorphism is a problem for which there is no known polynomial-time solution. Nevertheless, assessing (dis)similarity between two or more networks is a key task in many areas, such as image recognition, biology, chemistry, computer and social networks. Moreover, questions of similarity are typically more general and their answers more widely applicable than the more restrictive isomorphism question. In this article, we offer a statistical answer to the following questions: a) {\\it ``Are networks $G_1$ and $G_2$ similar?''}, b) {\\it ``How different are the networks $G_1$ and $G_2$?''} and c) {\\it ``Is $G_3$ more similar to $G_1$ or $G_2$?''}. Our comparisons begin with the transformation of each graph into an all-pairs distance matrix. Our node-node distance, Jaccard distance, has been shown to offer a good reflection of the graph's connectivity structure. We then model these distances as probability distributions. Finally, we use well-established statistical tools to gauge the (dis)similarities in terms of probability distribution (dis)similarity. This comparison procedure aims to detect (dis)similarities in connectivity structure, not in easily observable graph characteristics, such as degrees, edge counts or density. We validate our hypothesis that graphs can be meaningfully summarized and compared via their node-node distance distributions, using several synthetic and real-world graphs. Empirical results demonstrate its validity and the accuracy of our comparison technique. ",
    "url": "https://arxiv.org/abs/2206.10074",
    "authors": [
      "Pierre Miasnikof. Alexander Y. Shestopaloff",
      "Cristi\u00e1n Bravo",
      "Yuri Lawryshyn"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Discrete Mathematics (cs.DM)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.10143",
    "title": "A Contrastive Approach to Online Change Point Detection",
    "abstract": "We suggest a novel procedure for online change point detection. Our approach expands an idea of maximizing a discrepancy measure between points from pre-change and post-change distributions. This leads to a flexible procedure suitable for both parametric and nonparametric scenarios. We prove non-asymptotic bounds on the average running length of the procedure and its expected detection delay. The efficiency of the algorithm is illustrated with numerical experiments on synthetic and real-world data sets. ",
    "url": "https://arxiv.org/abs/2206.10143",
    "authors": [
      "Nikita Puchkin",
      "Valeriia Shcherbakova"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2206.10152",
    "title": "Diffractive Interconnects: All-Optical Permutation Operation Using  Diffractive Networks",
    "abstract": "Permutation matrices form an important computational building block frequently used in various fields including e.g., communications, information security and data processing. Optical implementation of permutation operators with relatively large number of input-output interconnections based on power-efficient, fast, and compact platforms is highly desirable. Here, we present diffractive optical networks engineered through deep learning to all-optically perform permutation operations that can scale to hundreds of thousands of interconnections between an input and an output field-of-view using passive transmissive layers that are individually structured at the wavelength scale. Our findings indicate that the capacity of the diffractive optical network in approximating a given permutation operation increases proportional to the number of diffractive layers and trainable transmission elements in the system. Such deeper diffractive network designs can pose practical challenges in terms of physical alignment and output diffraction efficiency of the system. We addressed these challenges by designing misalignment tolerant diffractive designs that can all-optically perform arbitrarily-selected permutation operations, and experimentally demonstrated, for the first time, a diffractive permutation network that operates at THz part of the spectrum. Diffractive permutation networks might find various applications in e.g., security, image encryption and data processing, along with telecommunications; especially with the carrier frequencies in wireless communications approaching THz-bands, the presented diffractive permutation networks can potentially serve as channel routing and interconnection panels in wireless networks. ",
    "url": "https://arxiv.org/abs/2206.10152",
    "authors": [
      "Deniz Mengu",
      "Yifan Zhao",
      "Anika Tabassum",
      "Mona Jarrahi",
      "Aydogan Ozcan"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.10348",
    "title": "Supervised learning of random quantum circuits via scalable neural  networks",
    "abstract": "Predicting the output of quantum circuits is a hard computational task that plays a pivotal role in the development of universal quantum computers. Here we investigate the supervised learning of output expectation values of random quantum circuits. Deep convolutional neural networks (CNNs) are trained to predict single-qubit and two-qubit expectation values using databases of classically simulated circuits. These circuits are represented via an appropriately designed one-hot encoding of the constituent gates. The prediction accuracy for previously unseen circuits is analyzed, also making comparisons with small-scale quantum computers available from the free IBM Quantum program. The CNNs often outperform the quantum devices, depending on the circuit depth, on the network depth, and on the training set size. Notably, our CNNs are designed to be scalable. This allows us exploiting transfer learning and performing extrapolations to circuits larger than those included in the training set. These CNNs also demonstrate remarkable resilience against noise, namely, they remain accurate even when trained on (simulated) expectation values averaged over very few measurements. ",
    "url": "https://arxiv.org/abs/2206.10348",
    "authors": [
      "S. Cantori",
      "D. Vitali",
      "S. Pilati"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1710.05359",
    "title": "Information-Theoretic Representation Learning for Positive-Unlabeled  Classification",
    "abstract": " Title: Information-Theoretic Representation Learning for Positive-Unlabeled  Classification ",
    "url": "https://arxiv.org/abs/1710.05359",
    "authors": [
      "Tomoya Sakai",
      "Gang Niu",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1902.02804",
    "title": "SiamVGG: Visual Tracking using Deeper Siamese Networks",
    "abstract": " Title: SiamVGG: Visual Tracking using Deeper Siamese Networks ",
    "url": "https://arxiv.org/abs/1902.02804",
    "authors": [
      "Yuhong Li",
      "Xiaofan Zhang",
      "Deming Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1902.08813",
    "title": "A Degeneracy Framework for Scalable Graph Autoencoders",
    "abstract": " Comments: International Joint Conference on Artificial Intelligence (IJCAI 2019) ",
    "url": "https://arxiv.org/abs/1902.08813",
    "authors": [
      "Guillaume Salha",
      "Romain Hennequin",
      "Viet Anh Tran",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1908.05672",
    "title": "Towards Making the Most of BERT in Neural Machine Translation",
    "abstract": " Comments: 10pages. the same as AAAI 2020 version, reformated with additional link to github repository ",
    "url": "https://arxiv.org/abs/1908.05672",
    "authors": [
      "Jiacheng Yang",
      "Mingxuan Wang",
      "Hao Zhou",
      "Chengqi Zhao",
      "Yong Yu",
      "Weinan Zhang",
      "Lei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1911.11800",
    "title": "TimeCaps: Capturing Time Series Data With Capsule Networks",
    "abstract": " Title: TimeCaps: Capturing Time Series Data With Capsule Networks ",
    "url": "https://arxiv.org/abs/1911.11800",
    "authors": [
      "Hirunima Jayasekara",
      "Vinoj Jayasundara",
      "Mohamed Athif",
      "Jathushan Rajasegaran",
      "Sandaru Jayasekara",
      "Suranga Seneviratne",
      "Ranga Rodrigo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2002.11309",
    "title": "Neural Parametric Fokker-Planck Equations",
    "abstract": " Title: Neural Parametric Fokker-Planck Equations ",
    "url": "https://arxiv.org/abs/2002.11309",
    "authors": [
      "Shu Liu",
      "Wuchen Li",
      "Hongyuan Zha",
      "Haomin Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2003.12197",
    "title": "HERS: Homomorphically Encrypted Representation Search",
    "abstract": " Comments: Published in the Trustworthy Biometrics Special Issue of IEEE Transactions on Biometrics, Behavior, and Identity Science 2021 ",
    "url": "https://arxiv.org/abs/2003.12197",
    "authors": [
      "Joshua J. Engelsma",
      "Anil K. Jain",
      "Vishnu Naresh Boddeti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2005.03986",
    "title": "Exploiting $\\mathbf{c}$-Closure in Kernelization Algorithms for Graph  Problems",
    "abstract": " Title: Exploiting $\\mathbf{c}$-Closure in Kernelization Algorithms for Graph  Problems ",
    "url": "https://arxiv.org/abs/2005.03986",
    "authors": [
      "Tomohiro Koana",
      "Christian Komusiewicz",
      "Frank Sommer"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2005.11949",
    "title": "Approximation in shift-invariant spaces with deep ReLU neural networks",
    "abstract": " Title: Approximation in shift-invariant spaces with deep ReLU neural networks ",
    "url": "https://arxiv.org/abs/2005.11949",
    "authors": [
      "Yunfei Yang",
      "Zhen Li",
      "Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2006.14591",
    "title": "Bidirectional compression in heterogeneous settings for distributed or  federated learning with partial participation: tight convergence guarantees",
    "abstract": " Comments: 54 pages, 4 theorems, 1 algorithm, code source on GitHub ",
    "url": "https://arxiv.org/abs/2006.14591",
    "authors": [
      "Constantin Philippenko",
      "Aymeric Dieuleveut"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2009.03825",
    "title": "Optimal training of integer-valued neural networks with mixed integer  programming",
    "abstract": " Comments: To appear in PLOS ONE (2022) ",
    "url": "https://arxiv.org/abs/2009.03825",
    "authors": [
      "T\u00f3mas Thorbjarnarson",
      "Neil Yorke-Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2011.05074",
    "title": "Efficient and Transferable Adversarial Examples from Bayesian Neural  Networks",
    "abstract": " Comments: Accepted at UAI 2022 ",
    "url": "https://arxiv.org/abs/2011.05074",
    "authors": [
      "Martin Gubri",
      "Maxime Cordy",
      "Mike Papadakis",
      "Yves Le Traon",
      "Koushik Sen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2102.03497",
    "title": "Weight Rescaling: Effective and Robust Regularization for Deep Neural  Networks with Batch Normalization",
    "abstract": " Comments: Preprint ",
    "url": "https://arxiv.org/abs/2102.03497",
    "authors": [
      "Ziquan Liu",
      "Yufei Cui",
      "Jia Wan",
      "Yu Mao",
      "Antoni B. Chan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2102.08275",
    "title": "Evaluating Node Embeddings of Complex Networks",
    "abstract": " Comments: 29 pages, 19 figures ",
    "url": "https://arxiv.org/abs/2102.08275",
    "authors": [
      "Arash Dehghan-Kooshkghazi",
      "Bogumi\u0142 Kami\u0144ski",
      "\u0141ukasz Krai\u0144ski",
      "Pawe\u0142 Pra\u0142at",
      "Fran\u00e7ois Th\u00e9berge"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2103.00369",
    "title": "Towards Continual, Online, Self-Supervised Depth",
    "abstract": " Title: Towards Continual, Online, Self-Supervised Depth ",
    "url": "https://arxiv.org/abs/2103.00369",
    "authors": [
      "Muhammad Umar Karim Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2103.05109",
    "title": "Highly Efficient Representation and Active Learning Framework and Its  Application to Imbalanced Medical Image Classification",
    "abstract": " Comments: Published in NeurIPs Data-Centric AI workshop ",
    "url": "https://arxiv.org/abs/2103.05109",
    "authors": [
      "Heng Hao",
      "Hankyu Moon",
      "Sima Didari",
      "Jae Oh Woo",
      "Patrick Bangert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2103.11676",
    "title": "Continuous mean distance of a weighted graph",
    "abstract": " Title: Continuous mean distance of a weighted graph ",
    "url": "https://arxiv.org/abs/2103.11676",
    "authors": [
      "Delia Garijo",
      "Alberto M\u00e1rquez",
      "Rodrigo I. Silveira"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2104.01841",
    "title": "Spined categories: generalizing tree-width beyond graphs",
    "abstract": " Comments: 28 pages ",
    "url": "https://arxiv.org/abs/2104.01841",
    "authors": [
      "Benjamin Merlin Bumpus",
      "Zoltan A. Kocsis"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Category Theory (math.CT)"
    ]
  },
  {
    "id": "arXiv:2104.14215",
    "title": "Unleashing the Power of Paying Multiplexing Only Once in Stochastic  Network Calculus",
    "abstract": " Comments: Accepted at ACM SIGMETRICS 2022 ",
    "url": "https://arxiv.org/abs/2104.14215",
    "authors": [
      "Anne Bouillard",
      "Paul Nikolaus",
      "Jens Schmitt"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2105.00026",
    "title": "Data Augmentation in High Dimensional Low Sample Size Setting Using a  Geometry-Based Variational Autoencoder",
    "abstract": " Comments: accepted to IEEE transactions on pattern analysis and machine intelligence (TPAMI) ",
    "url": "https://arxiv.org/abs/2105.00026",
    "authors": [
      "Cl\u00e9ment Chadebec",
      "Elina Thibeau-Sutre",
      "Ninon Burgos",
      "St\u00e9phanie Allassonni\u00e8re"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.05432",
    "title": "Discrete-time Contraction-based Control of Nonlinear Systems with  Parametric Uncertainties using Neural Networks",
    "abstract": " Comments: This work has been submitted to Computers & Chemical Engineering for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2105.05432",
    "authors": [
      "Lai Wei",
      "Ryan McCloy",
      "Jie Bao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2105.13001",
    "title": "Estimating Instance-dependent Bayes-label Transition Matrix using a Deep  Neural Network",
    "abstract": " Comments: ICML 22 camera ready ",
    "url": "https://arxiv.org/abs/2105.13001",
    "authors": [
      "Shuo Yang",
      "Erkun Yang",
      "Bo Han",
      "Yang Liu",
      "Min Xu",
      "Gang Niu",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.05481",
    "title": "Tree-Structured Data Clustering-Driven Neural Network for Intra  Prediction in Video Coding",
    "abstract": " Title: Tree-Structured Data Clustering-Driven Neural Network for Intra  Prediction in Video Coding ",
    "url": "https://arxiv.org/abs/2106.05481",
    "authors": [
      "Hengyu Man",
      "Xiaopeng Fan",
      "Ruiqin Xiong",
      "Debin Zhao"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2106.08261",
    "title": "Physion: Evaluating Physical Prediction from Vision in Humans and  Machines",
    "abstract": " Comments: 28 pages ",
    "url": "https://arxiv.org/abs/2106.08261",
    "authors": [
      "Daniel M. Bear",
      "Elias Wang",
      "Damian Mrowca",
      "Felix J. Binder",
      "Hsiao-Yu Fish Tung",
      "R.T. Pramod",
      "Cameron Holdaway",
      "Sirui Tao",
      "Kevin Smith",
      "Fan-Yun Sun",
      "Li Fei-Fei",
      "Nancy Kanwisher",
      "Joshua B. Tenenbaum",
      "Daniel L.K. Yamins",
      "Judith E. Fan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.08913",
    "title": "Technical Report: Hardening Code Obfuscation Against Automated Attacks",
    "abstract": " Title: Technical Report: Hardening Code Obfuscation Against Automated Attacks ",
    "url": "https://arxiv.org/abs/2106.08913",
    "authors": [
      "Moritz Schloegel",
      "Tim Blazytko",
      "Moritz Contag",
      "Cornelius Aschermann",
      "Julius Basler",
      "Thorsten Holz",
      "Ali Abbasi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2106.14956",
    "title": "Robust Distributed Optimization With Randomly Corrupted Gradients",
    "abstract": " Comments: 21 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2106.14956",
    "authors": [
      "Berkay Turan",
      "Cesar A. Uribe",
      "Hoi-To Wai",
      "Mahnoosh Alizadeh"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2108.03429",
    "title": "Enhancing MR Image Segmentation with Realistic Adversarial Data  Augmentation",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2108.03429",
    "authors": [
      "Chen Chen",
      "Chen Qin",
      "Cheng Ouyang",
      "Zeju Li",
      "Shuo Wang",
      "Huaqi Qiu",
      "Liang Chen",
      "Giacomo Tarroni",
      "Wenjia Bai",
      "Daniel Rueckert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2108.05030",
    "title": "DQ-GAT: Towards Safe and Efficient Autonomous Driving with Deep  Q-Learning and Graph Attention Networks",
    "abstract": " Comments: Accepted to IEEE Transactions on Intelligent Transportation Systems (T-ITS), 2022 ",
    "url": "https://arxiv.org/abs/2108.05030",
    "authors": [
      "Peide Cai",
      "Hengli Wang",
      "Yuxiang Sun",
      "Ming Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2108.07108",
    "title": "How Deep the Theory of Quantum Communications Goes: Superadditivity,  Superactivation and Causal Activation",
    "abstract": " Title: How Deep the Theory of Quantum Communications Goes: Superadditivity,  Superactivation and Causal Activation ",
    "url": "https://arxiv.org/abs/2108.07108",
    "authors": [
      "Seid Koudia",
      "Angela Sara Cacciapuoti",
      "Kyrylo Simonov",
      "Marcello Caleffi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2108.08930",
    "title": "Cross-Silo Federated Learning for Multi-Tier Networks with Vertical and  Horizontal Data Partitioning",
    "abstract": " Comments: Accepted in ACM Transactions on Intelligent Systems and Technology (ACM TIST), 2022. Updated paper organization, algorithm description, figures, numerical experiments. This is the final camera ready version ",
    "url": "https://arxiv.org/abs/2108.08930",
    "authors": [
      "Anirban Das",
      "Timothy Castiglia",
      "Shiqiang Wang",
      "Stacy Patterson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2109.04516",
    "title": "Robust Impedance Control for Dexterous Interaction Using Fractal  Impedance Controller with IK-Optimisation",
    "abstract": " Title: Robust Impedance Control for Dexterous Interaction Using Fractal  Impedance Controller with IK-Optimisation ",
    "url": "https://arxiv.org/abs/2109.04516",
    "authors": [
      "Carlo Tiseo",
      "Quentin Rouxel",
      "Zhibin Li",
      "Michael Mistry"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2109.10061",
    "title": "Graph Neural Networks for Graph Drawing",
    "abstract": " Comments: Accepted for publication in Transaction of Neural Networks and Learning Systems (TNNLS), Special Issue on Deep Neural Networks for Graphs: Theory, Models, Algorithms and Applications ",
    "url": "https://arxiv.org/abs/2109.10061",
    "authors": [
      "Matteo Tiezzi",
      "Gabriele Ciravegna",
      "Marco Gori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.12073",
    "title": "A Graph Policy Network Approach for Volt-Var Control in Power  Distribution Systems",
    "abstract": " Comments: Presented at NeurIPS 2021 Deep RL Workshop ",
    "url": "https://arxiv.org/abs/2109.12073",
    "authors": [
      "Xian Yeow Lee",
      "Soumik Sarkar",
      "Yubo Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2110.03611",
    "title": "Adversarial Retriever-Ranker for dense text retrieval",
    "abstract": " Comments: ICLR 2022 ",
    "url": "https://arxiv.org/abs/2110.03611",
    "authors": [
      "Hang Zhang",
      "Yeyun Gong",
      "Yelong Shen",
      "Jiancheng Lv",
      "Nan Duan",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2110.05721",
    "title": "Action-Sufficient State Representation Learning for Control with  Structural Constraints",
    "abstract": " Title: Action-Sufficient State Representation Learning for Control with  Structural Constraints ",
    "url": "https://arxiv.org/abs/2110.05721",
    "authors": [
      "Biwei Huang",
      "Chaochao Lu",
      "Liu Leqi",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
      "Clark Glymour",
      "Bernhard Sch\u00f6lkopf",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.06765",
    "title": "libdlr: Efficient imaginary time calculations using the discrete Lehmann  representation",
    "abstract": " Title: libdlr: Efficient imaginary time calculations using the discrete Lehmann  representation ",
    "url": "https://arxiv.org/abs/2110.06765",
    "authors": [
      "Jason Kaye",
      "Kun Chen",
      "Hugo U. R. Strand"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Mathematical Software (cs.MS)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2110.09893",
    "title": "Visualizing Collective Idea Generation and Innovation Processes in  Social Networks",
    "abstract": " Comments: in press ",
    "url": "https://arxiv.org/abs/2110.09893",
    "authors": [
      "Yiding Cao",
      "Yingjun Dong",
      "Minjun Kim",
      "Neil G. MacLaren",
      "Sriniwas Pandey",
      "Shelley D. Dionne",
      "Francis J. Yammarino",
      "Hiroki Sayama"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2110.14007",
    "title": "TOD: GPU-accelerated Outlier Detection via Tensor Operations",
    "abstract": " Comments: Code available at this https URL ",
    "url": "https://arxiv.org/abs/2110.14007",
    "authors": [
      "Yue Zhao",
      "George H. Chen",
      "Zhihao Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2110.14626",
    "title": "Scalable Bayesian Network Structure Learning with Splines",
    "abstract": " Title: Scalable Bayesian Network Structure Learning with Splines ",
    "url": "https://arxiv.org/abs/2110.14626",
    "authors": [
      "Charupriya Sharma",
      "Peter van Beek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.15278",
    "title": "Self-supervised EEG Representation Learning for Automatic Sleep Staging",
    "abstract": " Comments: Preprocessing and Code in Github: this https URL, additional loss analysis can be found: this https URL ",
    "url": "https://arxiv.org/abs/2110.15278",
    "authors": [
      "Chaoqi Yang",
      "Danica Xiao",
      "M. Brandon Westover",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.01356",
    "title": "DeepParticle: learning invariant measure by a deep neural network  minimizing Wasserstein distance on data generated from an interacting  particle method",
    "abstract": " Title: DeepParticle: learning invariant measure by a deep neural network  minimizing Wasserstein distance on data generated from an interacting  particle method ",
    "url": "https://arxiv.org/abs/2111.01356",
    "authors": [
      "Zhongjian Wang",
      "Jack Xin",
      "Zhiwen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2111.02541",
    "title": "Asymptotic-Preserving Neural Networks for Multiscale Time-Dependent  Linear Transport Equations",
    "abstract": " Title: Asymptotic-Preserving Neural Networks for Multiscale Time-Dependent  Linear Transport Equations ",
    "url": "https://arxiv.org/abs/2111.02541",
    "authors": [
      "Shi Jin",
      "Zheng Ma",
      "Keke Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2111.12958",
    "title": "Self-Distilled Self-Supervised Representation Learning",
    "abstract": " Comments: 15 pages ",
    "url": "https://arxiv.org/abs/2111.12958",
    "authors": [
      "Jiho Jang",
      "Seonhoon Kim",
      "Kiyoon Yoo",
      "Jangho Kim",
      "Nojun Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.00248",
    "title": "Simulation platform for pattern recognition based on reservoir computing  with memristor networks",
    "abstract": " Comments: 14 pages, 7 figures, 5 supplementary figures ",
    "url": "https://arxiv.org/abs/2112.00248",
    "authors": [
      "Gouhei Tanaka",
      "Ryosho Nakane"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2112.03432",
    "title": "First-Order Regret in Reinforcement Learning with Linear Function  Approximation: A Robust Estimation Approach",
    "abstract": " Title: First-Order Regret in Reinforcement Learning with Linear Function  Approximation: A Robust Estimation Approach ",
    "url": "https://arxiv.org/abs/2112.03432",
    "authors": [
      "Andrew Wagenmaker",
      "Yifang Chen",
      "Max Simchowitz",
      "Simon S. Du",
      "Kevin Jamieson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.03547",
    "title": "Self-Organized Polynomial-Time Coordination Graphs",
    "abstract": " Title: Self-Organized Polynomial-Time Coordination Graphs ",
    "url": "https://arxiv.org/abs/2112.03547",
    "authors": [
      "Qianlan Yang",
      "Weijun Dong",
      "Zhizhou Ren",
      "Jianhao Wang",
      "Tonghan Wang",
      "Chongjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2112.05477",
    "title": "Modelling DDoS Attacks in IoT Networks using Machine Learning",
    "abstract": " Comments: 20 pages, 13 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2112.05477",
    "authors": [
      "Pheeha Machaka",
      "Olasupo Ajayi",
      "Hloniphani Maluleke",
      "Ferdinand Kahenga",
      "Antoine Bagula",
      "Kyandoghere Kyamakya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.05640",
    "title": "Fast and scalable neuroevolution deep learning architecture search for  multivariate anomaly detection",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2108.03585 ",
    "url": "https://arxiv.org/abs/2112.05640",
    "authors": [
      "M.Pietro\u0144",
      "D.\u017burek",
      "K.Faber"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.07160",
    "title": "A New Perspective on the Effects of Spectrum in Graph Neural Networks",
    "abstract": " Title: A New Perspective on the Effects of Spectrum in Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2112.07160",
    "authors": [
      "Mingqi Yang",
      "Yanming Shen",
      "Rui Li",
      "Heng Qi",
      "Qiang Zhang",
      "Baocai Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.12591",
    "title": "Black-Box Testing of Deep Neural Networks through Test Case Diversity",
    "abstract": " Title: Black-Box Testing of Deep Neural Networks through Test Case Diversity ",
    "url": "https://arxiv.org/abs/2112.12591",
    "authors": [
      "Zohreh Aghababaeyan",
      "Manel Abdellatif",
      "Lionel Briand",
      "Ramesh S",
      "Mojtaba Bagherzadeh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.14232",
    "title": "Constrained Gradient Descent: A Powerful and Principled Evasion Attack  Against Neural Networks",
    "abstract": " Title: Constrained Gradient Descent: A Powerful and Principled Evasion Attack  Against Neural Networks ",
    "url": "https://arxiv.org/abs/2112.14232",
    "authors": [
      "Weiran Lin",
      "Keane Lucas",
      "Lujo Bauer",
      "Michael K. Reiter",
      "Mahmood Sharif"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.00299",
    "title": "Improving Out-of-Distribution Robustness via Selective Augmentation",
    "abstract": " Comments: Accepted by ICML 2022 ",
    "url": "https://arxiv.org/abs/2201.00299",
    "authors": [
      "Huaxiu Yao",
      "Yu Wang",
      "Sai Li",
      "Linjun Zhang",
      "Weixin Liang",
      "James Zou",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.06444",
    "title": "Black-box error diagnosis in deep neural networks for computer vision: a  survey of tools",
    "abstract": " Comments: Submitted to Springer Neural Computing and Applications ",
    "url": "https://arxiv.org/abs/2201.06444",
    "authors": [
      "Piero Fraternali",
      "Federico Milani",
      "Rocio Nahime Torres",
      "Niccol\u00f2 Zangrando"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2201.09815",
    "title": "Analytic Mutual Information in Bayesian Neural Networks",
    "abstract": " Title: Analytic Mutual Information in Bayesian Neural Networks ",
    "url": "https://arxiv.org/abs/2201.09815",
    "authors": [
      "Jae Oh Woo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11729",
    "title": "Implicit Regularization in Hierarchical Tensor Factorization and Deep  Convolutional Neural Networks",
    "abstract": " Comments: Accepted to ICML 2022 ",
    "url": "https://arxiv.org/abs/2201.11729",
    "authors": [
      "Noam Razin",
      "Asaf Maman",
      "Nadav Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.12091",
    "title": "Linear Adversarial Concept Erasure",
    "abstract": " Comments: Accepted in ICML 2022 ",
    "url": "https://arxiv.org/abs/2201.12091",
    "authors": [
      "Shauli Ravfogel",
      "Michael Twiton",
      "Yoav Goldberg",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2201.12498",
    "title": "Investigating Why Contrastive Learning Benefits Robustness Against Label  Noise",
    "abstract": " Title: Investigating Why Contrastive Learning Benefits Robustness Against Label  Noise ",
    "url": "https://arxiv.org/abs/2201.12498",
    "authors": [
      "Yihao Xue",
      "Kyle Whitecross",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.13360",
    "title": "Hydra: A Real-time Spatial Perception System for 3D Scene Graph  Construction and Optimization",
    "abstract": " Comments: 13 pages, 10 figures, published in Robotics Science and Systems (RSS) 2022 proceedings ",
    "url": "https://arxiv.org/abs/2201.13360",
    "authors": [
      "Nathan Hughes",
      "Yun Chang",
      "Luca Carlone"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.00961",
    "title": "Modularity-Aware Graph Autoencoders for Joint Community Detection and  Link Prediction",
    "abstract": " Comments: Accepted for publication in Elsevier's Neural Networks journal in 2022 ",
    "url": "https://arxiv.org/abs/2202.00961",
    "authors": [
      "Guillaume Salha-Galvan",
      "Johannes F. Lutzeyer",
      "George Dasoulas",
      "Romain Hennequin",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.01144",
    "title": "An Adiabatic Capacitive Artificial Neuron with RRAM-based Threshold  Detection for Energy-Efficient Neuromorphic Computing",
    "abstract": " Comments: This work has been accepted to the IEEE TCAS-I ",
    "url": "https://arxiv.org/abs/2202.01144",
    "authors": [
      "Sachin Maheshwari",
      "Alexander Serb",
      "Christos Papavassiliou",
      "Themistoklis Prodromakis"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2202.01181",
    "title": "Make Some Noise: Reliable and Efficient Single-Step Adversarial Training",
    "abstract": " Title: Make Some Noise: Reliable and Efficient Single-Step Adversarial Training ",
    "url": "https://arxiv.org/abs/2202.01181",
    "authors": [
      "Pau de Jorge",
      "Adel Bibi",
      "Riccardo Volpi",
      "Amartya Sanyal",
      "Philip H. S. Torr",
      "Gr\u00e9gory Rogez",
      "Puneet K. Dokania"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.01503",
    "title": "Global sensitivity analysis based on Gaussian-process metamodelling for  complex biomechanical problems",
    "abstract": " Title: Global sensitivity analysis based on Gaussian-process metamodelling for  complex biomechanical problems ",
    "url": "https://arxiv.org/abs/2202.01503",
    "authors": [
      "Barbara Wirthl",
      "Sebastian Brandstaeter",
      "Jonas Nitzler",
      "Bernhard A. Schrefler",
      "Wolfgang A. Wall"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2202.02195",
    "title": "Deep End-to-end Causal Inference",
    "abstract": " Title: Deep End-to-end Causal Inference ",
    "url": "https://arxiv.org/abs/2202.02195",
    "authors": [
      "Tomas Geffner",
      "Javier Antoran",
      "Adam Foster",
      "Wenbo Gong",
      "Chao Ma",
      "Emre Kiciman",
      "Amit Sharma",
      "Angus Lamb",
      "Martin Kukla",
      "Nick Pawlowski",
      "Miltiadis Allamanis",
      "Cheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03740",
    "title": "Consistency-Regularized Region-Growing Network for Semantic Segmentation  of Urban Scenes with Point-Level Annotations",
    "abstract": " Title: Consistency-Regularized Region-Growing Network for Semantic Segmentation  of Urban Scenes with Point-Level Annotations ",
    "url": "https://arxiv.org/abs/2202.03740",
    "authors": [
      "Yonghao Xu",
      "Pedram Ghamisi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.05244",
    "title": "REvolveR: Continuous Evolutionary Models for Robot-to-robot Policy  Transfer",
    "abstract": " Comments: ICML 2022 (Long Oral) ",
    "url": "https://arxiv.org/abs/2202.05244",
    "authors": [
      "Xingyu Liu",
      "Deepak Pathak",
      "Kris M. Kitani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.05441",
    "title": "Invariance Principle Meets Out-of-Distribution Generalization on Graphs",
    "abstract": " Comments: A preprint version ",
    "url": "https://arxiv.org/abs/2202.05441",
    "authors": [
      "Yongqiang Chen",
      "Yonggang Zhang",
      "Yatao Bian",
      "Han Yang",
      "Kaili Ma",
      "Binghui Xie",
      "Tongliang Liu",
      "Bo Han",
      "James Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06618",
    "title": "A Differential Entropy Estimator for Training Neural Networks",
    "abstract": " Comments: to be presented at ICML2022 in Baltimore, MD ",
    "url": "https://arxiv.org/abs/2202.06618",
    "authors": [
      "Georg Pichler",
      "Pierre Colombo",
      "Malik Boudiaf",
      "G\u00fcnther Koliander",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.07919",
    "title": "HousE: Knowledge Graph Embedding with Householder Parameterization",
    "abstract": " Comments: Accepted by ICML 2022 ",
    "url": "https://arxiv.org/abs/2202.07919",
    "authors": [
      "Rui Li",
      "Jianan Zhao",
      "Chaozhuo Li",
      "Di He",
      "Yiqi Wang",
      "Yuming Liu",
      "Hao Sun",
      "Senzhang Wang",
      "Weiwei Deng",
      "Yanming Shen",
      "Xing Xie",
      "Qi Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.08833",
    "title": "What Functions Can Graph Neural Networks Generate?",
    "abstract": " Comments: 37 pages ",
    "url": "https://arxiv.org/abs/2202.08833",
    "authors": [
      "Mohammad Fereydounian",
      "Hamed Hassani",
      "Amin Karbasi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.12636",
    "title": "Learning Multi-Task Gaussian Process Over Heterogeneous Input Domains",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2202.12636",
    "authors": [
      "Haitao Liu",
      "Kai Wu",
      "Yew-Soon Ong",
      "Chao Bian",
      "Xiaomo Jiang",
      "Xiaofang Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.12785",
    "title": "Confidence Calibration for Object Detection and Segmentation",
    "abstract": " Comments: Book chapter in: Tim Fingerscheidt, Hanno Gottschalk, Sebastian Houben (eds.): \"Deep Neural Networks and Data for Automated Driving\", pp. 225--250, Springer Nature, Switzerland, 2022 ",
    "url": "https://arxiv.org/abs/2202.12785",
    "authors": [
      "Fabian K\u00fcppers",
      "Anselm Haselhoff",
      "Jan Kronenberger",
      "Jonas Schneider"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.00199",
    "title": "Equivariant and Stable Positional Encoding for More Powerful Graph  Neural Networks",
    "abstract": " Comments: ICLR 2022; The revised version updates some notation mistakes and discusses on the stability of PE in different settings; code available at this https URL ",
    "url": "https://arxiv.org/abs/2203.00199",
    "authors": [
      "Haorui Wang",
      "Haoteng Yin",
      "Muhan Zhang",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.01137",
    "title": "Self-Supervised Scene Flow Estimation with 4-D Automotive Radar",
    "abstract": " Comments: Copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works ",
    "url": "https://arxiv.org/abs/2203.01137",
    "authors": [
      "Fangqiang Ding",
      "Zhijun Pan",
      "Yimin Deng",
      "Jianning Deng",
      "Chris Xiaoxuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.01762",
    "title": "NeuroFluid: Fluid Dynamics Grounding with Particle-Driven Neural  Radiance Fields",
    "abstract": " Comments: ICML 2022, the project page: this https URL ",
    "url": "https://arxiv.org/abs/2203.01762",
    "authors": [
      "Shanyan Guan",
      "Huayu Deng",
      "Yunbo Wang",
      "Xiaokang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2203.03673",
    "title": "AgraSSt: Approximate Graph Stein Statistics for Interpretable Assessment  of Implicit Graph Generators",
    "abstract": " Title: AgraSSt: Approximate Graph Stein Statistics for Interpretable Assessment  of Implicit Graph Generators ",
    "url": "https://arxiv.org/abs/2203.03673",
    "authors": [
      "Wenkai Xu",
      "Gesine Reinert"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.03677",
    "title": "Object-centric and memory-guided normality reconstruction for video  anomaly detection",
    "abstract": " Comments: Accepted at ICIP 2022 ",
    "url": "https://arxiv.org/abs/2203.03677",
    "authors": [
      "Khalil Bergaoui",
      "Yassine Naji",
      "Aleksandr Setkov",
      "Ang\u00e9lique Loesch",
      "Mich\u00e8le Gouiff\u00e8s",
      "Romaric Audigier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.04466",
    "title": "The Combinatorial Brain Surgeon: Pruning Weights That Cancel One Another  in Neural Networks",
    "abstract": " Title: The Combinatorial Brain Surgeon: Pruning Weights That Cancel One Another  in Neural Networks ",
    "url": "https://arxiv.org/abs/2203.04466",
    "authors": [
      "Xin Yu",
      "Thiago Serra",
      "Srikumar Ramalingam",
      "Shandian Zhe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09550",
    "title": "Multi-similarity based Hyperrelation Network for few-shot segmentation",
    "abstract": " Title: Multi-similarity based Hyperrelation Network for few-shot segmentation ",
    "url": "https://arxiv.org/abs/2203.09550",
    "authors": [
      "Xiangwen Shi",
      "Zhe Cui",
      "Shaobing Zhang",
      "Miao Cheng",
      "Lian He",
      "Xianghong Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09672",
    "title": "Deep Multi-Modal Structural Equations For Causal Effect Estimation With  Unstructured Proxies",
    "abstract": " Title: Deep Multi-Modal Structural Equations For Causal Effect Estimation With  Unstructured Proxies ",
    "url": "https://arxiv.org/abs/2203.09672",
    "authors": [
      "Shachi Deshpande",
      "Kaiwen Wang",
      "Dhruv Sreenivas",
      "Zheng Li",
      "Volodymyr Kuleshov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13913",
    "title": "SpeqNets: Sparsity-aware Permutation-equivariant Graph Networks",
    "abstract": " Comments: ICML 2022 ",
    "url": "https://arxiv.org/abs/2203.13913",
    "authors": [
      "Christopher Morris",
      "Gaurav Rattan",
      "Sandra Kiefer",
      "Siamak Ravanbakhsh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.14565",
    "title": "Style-Guided Domain Adaptation for Face Presentation Attack Detection",
    "abstract": " Comments: With the agreement of all authors, we would like to withdraw the manuscript. For lack of some experiments, a part of important claims cannot stand solidly. We need to further carry out experiments, and reconsider the rationality of these claims ",
    "url": "https://arxiv.org/abs/2203.14565",
    "authors": [
      "Young-Eun Kim",
      "Woo-Jeoung Nam",
      "Kyungseo Min",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15610",
    "title": "LightHuBERT: Lightweight and Configurable Speech Representation Learning  with Once-for-All Hidden-Unit BERT",
    "abstract": " Comments: 5 pages, 2 figures, accepted to Insterspeech 2022 ",
    "url": "https://arxiv.org/abs/2203.15610",
    "authors": [
      "Rui Wang",
      "Qibing Bai",
      "Junyi Ao",
      "Long Zhou",
      "Zhixiang Xiong",
      "Zhihua Wei",
      "Yu Zhang",
      "Tom Ko",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2203.16040",
    "title": "Disentangling the Impacts of Language and Channel Variability on Speech  Separation Networks",
    "abstract": " Comments: Published in Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2203.16040",
    "authors": [
      "Fan-Lin Wang",
      "Hung-Shin Lee",
      "Yu Tsao",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.16462",
    "title": "Convergence of gradient descent for deep neural networks",
    "abstract": " Comments: 30 pages, 1 figure. In this revision, I have tried to explain better the main difference between this paper and prior works, which may not have been clear to some readers ",
    "url": "https://arxiv.org/abs/2203.16462",
    "authors": [
      "Sourav Chatterjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.00465",
    "title": "Deep Neural Convolutive Matrix Factorization for Articulatory  Representation Decomposition",
    "abstract": " Comments: Accepted to 2022 Interspeech. Code is publicly available at this https URL ",
    "url": "https://arxiv.org/abs/2204.00465",
    "authors": [
      "Jiachen Lian",
      "Alan W Black",
      "Louis Goldstein",
      "Gopala Krishna Anumanchipalli"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2204.01613",
    "title": "SPECTRE: Spectral Conditioning Helps to Overcome the Expressivity Limits  of One-shot Graph Generators",
    "abstract": " Comments: The 39th International Conference on Machine Learning (ICML 2022), 21 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2204.01613",
    "authors": [
      "Karolis Martinkus",
      "Andreas Loukas",
      "Nathana\u00ebl Perraudin",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.02602",
    "title": "Distributed Transition Systems with Tags for Privacy Analysis",
    "abstract": " Title: Distributed Transition Systems with Tags for Privacy Analysis ",
    "url": "https://arxiv.org/abs/2204.02602",
    "authors": [
      "Siva Anantharaman",
      "Sabine Frittella",
      "Benjamin Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2204.06760",
    "title": "HCFL: A High Compression Approach for Communication-Efficient Federated  Learning in Very Large Scale IoT Networks",
    "abstract": " Comments: 14 pages, 12 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2204.06760",
    "authors": [
      "Minh-Duong Nguyen",
      "Sang-Min Lee",
      "Quoc-Viet Pham",
      "Dinh Thai Hoang",
      "Diep N. Nguyen",
      "Won-Joo Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2204.08504",
    "title": "CGC: Contrastive Graph Clustering for Community Detection and Tracking",
    "abstract": " Comments: TheWebConf 2022 Research Track ",
    "url": "https://arxiv.org/abs/2204.08504",
    "authors": [
      "Namyong Park",
      "Ryan Rossi",
      "Eunyee Koh",
      "Iftikhar Ahamath Burhanuddin",
      "Sungchul Kim",
      "Fan Du",
      "Nesreen Ahmed",
      "Christos Faloutsos"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.13101",
    "title": "Self-Supervised Learning of Object Parts for Semantic Segmentation",
    "abstract": " Comments: Accepted at CVPR 2022 ",
    "url": "https://arxiv.org/abs/2204.13101",
    "authors": [
      "Adrian Ziegler",
      "Yuki M. Asano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01945",
    "title": "Optimal Network Charge for Peer-to-Peer Energy Trading: A Grid  Perspective",
    "abstract": " Comments: 12 pages, 16 figures ",
    "url": "https://arxiv.org/abs/2205.01945",
    "authors": [
      "Yu Yang",
      "Yue Chen",
      "Guoqiang Hu",
      "Costas J. Spanos"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2205.03296",
    "title": "Disentangled Learning of Stance and Aspect Topics for Vaccine Attitude  Detection in Social Media",
    "abstract": " Title: Disentangled Learning of Stance and Aspect Topics for Vaccine Attitude  Detection in Social Media ",
    "url": "https://arxiv.org/abs/2205.03296",
    "authors": [
      "Lixing Zhu",
      "Zheng Fang",
      "Gabriele Pergola",
      "Rob Procter",
      "Yulan He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.04309",
    "title": "Characterizing Positionality in Games of Infinite Duration over Infinite  Graphs",
    "abstract": " Comments: 43 pages, 20 figures ",
    "url": "https://arxiv.org/abs/2205.04309",
    "authors": [
      "Pierre Ohlmann"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2205.08601",
    "title": "Universal characteristics of deep neural network loss surfaces from  random matrix theory",
    "abstract": " Comments: 42 pages ",
    "url": "https://arxiv.org/abs/2205.08601",
    "authors": [
      "Nicholas P Baskerville",
      "Jonathan P Keating",
      "Francesco Mezzadri",
      "Joseph Najnudel",
      "Diego Granziol"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10798",
    "title": "PAC-Wrap: Semi-Supervised PAC Anomaly Detection",
    "abstract": " Comments: Accepted by SIGKDD 2022 ",
    "url": "https://arxiv.org/abs/2205.10798",
    "authors": [
      "Shuo Li",
      "Xiayan Ji",
      "Edgar Dobriban",
      "Oleg Sokolsky",
      "Insup Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.12711",
    "title": "Service Discovery in Social Internet of Things using Graph Neural  Networks",
    "abstract": " Comments: Accepted for publications in the 65 IEEE International Midwest Symposium on Circuits and Systems (MWSCAS'22) 7 figures, 1 table, 5 pages ",
    "url": "https://arxiv.org/abs/2205.12711",
    "authors": [
      "Aymen Hamrouni",
      "Hakim Ghazzai",
      "Yehia Massoud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.13076",
    "title": "Entropy Maximization with Depth: A Variational Principle for Random  Neural Networks",
    "abstract": " Title: Entropy Maximization with Depth: A Variational Principle for Random  Neural Networks ",
    "url": "https://arxiv.org/abs/2205.13076",
    "authors": [
      "Amir Joudaki",
      "Hadi Daneshmand",
      "Francis Bach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2205.14576",
    "title": "Problem-Space Evasion Attacks in the Android OS: a Survey",
    "abstract": " Title: Problem-Space Evasion Attacks in the Android OS: a Survey ",
    "url": "https://arxiv.org/abs/2205.14576",
    "authors": [
      "Harel Berger",
      "Chen Hajaj",
      "Amit Dvir"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.15322",
    "title": "Superposing Many Tickets into One: A Performance Booster for Sparse  Neural Network Training",
    "abstract": " Comments: 17 pages, 5 figures, accepted by the 38th Conference on Uncertainty in Artificial Intelligence (UAI) ",
    "url": "https://arxiv.org/abs/2205.15322",
    "authors": [
      "Lu Yin",
      "Vlado Menkovski",
      "Meng Fang",
      "Tianjin Huang",
      "Yulong Pei",
      "Mykola Pechenizkiy",
      "Decebal Constantin Mocanu",
      "Shiwei Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.00790",
    "title": "Efficient Self-supervised Vision Pretraining with Local Masked  Reconstruction",
    "abstract": " Comments: Add code ",
    "url": "https://arxiv.org/abs/2206.00790",
    "authors": [
      "Jun Chen",
      "Ming Hu",
      "Boyang Li",
      "Mohamed Elhoseiny"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00934",
    "title": "Deep neural networks can stably solve high-dimensional, noisy,  non-linear inverse problems",
    "abstract": " Title: Deep neural networks can stably solve high-dimensional, noisy,  non-linear inverse problems ",
    "url": "https://arxiv.org/abs/2206.00934",
    "authors": [
      "Andr\u00e9s Felipe Lerma Pineda",
      "Philipp Christian Petersen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.01737",
    "title": "MaxStyle: Adversarial Style Composition for Robust Medical Image  Segmentation",
    "abstract": " Comments: Early accepted by MICCAI 2022 (Camera-ready version) ",
    "url": "https://arxiv.org/abs/2206.01737",
    "authors": [
      "Chen Chen",
      "Zeju Li",
      "Cheng Ouyang",
      "Matt Sinclair",
      "Wenjia Bai",
      "Daniel Rueckert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2206.03044",
    "title": "CAISAR: A platform for Characterizing Artificial Intelligence Safety and  Robustness",
    "abstract": " Title: CAISAR: A platform for Characterizing Artificial Intelligence Safety and  Robustness ",
    "url": "https://arxiv.org/abs/2206.03044",
    "authors": [
      "Julien Girard-Satabin",
      "Michele Alberti",
      "Fran\u00e7ois Bobot",
      "Zakaria Chihani",
      "Augustin Lemesle"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2206.03181",
    "title": "Detecting Global Community Structure in a COVID-19 Activity Correlation  Network",
    "abstract": " Comments: 11 pages, 4 figures, 1 table ",
    "url": "https://arxiv.org/abs/2206.03181",
    "authors": [
      "Hiroki Sayama"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2206.05483",
    "title": "Bilateral Dependency Optimization: Defending Against Model-inversion  Attacks",
    "abstract": " Comments: Accepted to KDD 2022 (Research Track) ",
    "url": "https://arxiv.org/abs/2206.05483",
    "authors": [
      "Xiong Peng",
      "Feng Liu",
      "Jingfen Zhang",
      "Long Lan",
      "Junjie Ye",
      "Tongliang Liu",
      "Bo Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.05687",
    "title": "DRNet: Decomposition and Reconstruction Network for Remote Physiological  Measurement",
    "abstract": " Title: DRNet: Decomposition and Reconstruction Network for Remote Physiological  Measurement ",
    "url": "https://arxiv.org/abs/2206.05687",
    "authors": [
      "Yuhang Dong",
      "Gongping Yang",
      "Yilong Yin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.06274",
    "title": "Lalaine: Measuring and Characterizing Non-Compliance of Apple Privacy  Labels at Scale",
    "abstract": " Title: Lalaine: Measuring and Characterizing Non-Compliance of Apple Privacy  Labels at Scale ",
    "url": "https://arxiv.org/abs/2206.06274",
    "authors": [
      "Yue Xiao",
      "Zhengyi Li",
      "Yue Qin",
      "Xiaolong Bai",
      "Jiale Guan",
      "Xiaojing Liao",
      "Luyi Xing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.06561",
    "title": "FreeKD: Free-direction Knowledge Distillation for Graph Neural Networks",
    "abstract": " Comments: Accepted to KDD 2022 ",
    "url": "https://arxiv.org/abs/2206.06561",
    "authors": [
      "Kaituo Feng",
      "Changsheng Li",
      "Ye Yuan",
      "Guoren Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.06584",
    "title": "Probabilistic Conformal Prediction Using Conditional Random Samples",
    "abstract": " Title: Probabilistic Conformal Prediction Using Conditional Random Samples ",
    "url": "https://arxiv.org/abs/2206.06584",
    "authors": [
      "Zhendong Wang",
      "Ruijiang Gao",
      "Mingzhang Yin",
      "Mingyuan Zhou",
      "David M. Blei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2206.06665",
    "title": "Online Easy Example Mining for Weakly-supervised Gland Segmentation from  Histology Images",
    "abstract": " Comments: MICCAI 2022 Accepeted ",
    "url": "https://arxiv.org/abs/2206.06665",
    "authors": [
      "Yi Li",
      "Yiduo Yu",
      "Yiwen Zou",
      "Tianqi Xiang",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.06677",
    "title": "Abstraction-Based Segmental Simulation of Chemical Reaction Networks",
    "abstract": " Comments: Accepted to Computational Methods in Systems Biology 2022 ",
    "url": "https://arxiv.org/abs/2206.06677",
    "authors": [
      "Martin Helfrich",
      "Milan \u010ce\u0161ka",
      "Jan K\u0159et\u00ednsk\u00fd",
      "\u0160tefan Marti\u010dek"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2206.06680",
    "title": "Exploring speaker enrolment for few-shot personalisation in emotional  vocalisation prediction",
    "abstract": " Comments: Proceedings of the ICML Expressive Vocalizations Workshop and Competition held in conjunction with the $\\mathit{39}^{th}$ International Conference on Machine Learning, Copyright 2022 by the author(s) ",
    "url": "https://arxiv.org/abs/2206.06680",
    "authors": [
      "Andreas Triantafyllopoulos",
      "Meishu Song",
      "Zijiang Yang",
      "Xin Jing",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.06811",
    "title": "Adversarial Audio Synthesis with Complex-valued Polynomial Networks",
    "abstract": " Comments: Accepted as oral presentation in Workshop on Machine Learning for Audio Synthesis at ICML 2022 ",
    "url": "https://arxiv.org/abs/2206.06811",
    "authors": [
      "Yongtao Wu",
      "Grigorios G Chrysos",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.06986",
    "title": "Exploring Representation of Horn Clauses using GNNs (technique report)",
    "abstract": " Title: Exploring Representation of Horn Clauses using GNNs (technique report) ",
    "url": "https://arxiv.org/abs/2206.06986",
    "authors": [
      "Chencheng Liang",
      "Philipp R\u00fcmmer",
      "Marc Brockschmidt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07104",
    "title": "Most, And Least, Compact Spanning Trees of a Graph",
    "abstract": " Title: Most, And Least, Compact Spanning Trees of a Graph ",
    "url": "https://arxiv.org/abs/2206.07104",
    "authors": [
      "Gyan Ranjan",
      "Nishant Saurabh",
      "Amit Ashutosh"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2206.07161",
    "title": "GraphFM: Improving Large-Scale GNN Training via Feature Momentum",
    "abstract": " Comments: ICML 2022 ",
    "url": "https://arxiv.org/abs/2206.07161",
    "authors": [
      "Haiyang Yu",
      "Limei Wang",
      "Bokun Wang",
      "Meng Liu",
      "Tianbao Yang",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.07269",
    "title": "Resource-Constrained Edge AI with Early Exit Prediction",
    "abstract": " Comments: 26 pages, 16 figures, 6 tables. This paper is accepted by Journal of Communications and Information Networks ",
    "url": "https://arxiv.org/abs/2206.07269",
    "authors": [
      "Rongkang Dong",
      "Yuyi Mao",
      "Jun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07940",
    "title": "PROFHIT: Probabilistic Robust Forecasting for Hierarchical Time-series",
    "abstract": " Comments: 15 pages ",
    "url": "https://arxiv.org/abs/2206.07940",
    "authors": [
      "Harshavardhan Kamarthi",
      "Lingkai Kong",
      "Alexander Rodr\u00edguez",
      "Chao Zhang",
      "B. Aditya Prakash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.08065",
    "title": "Neural tangent kernel analysis of shallow $\u03b1$-Stable ReLU neural  networks",
    "abstract": " Comments: 33 pages ",
    "url": "https://arxiv.org/abs/2206.08065",
    "authors": [
      "Stefano Favaro",
      "Sandra Fortini",
      "Stefano Peluchetti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.08362",
    "title": "Unified Fourier-based Kernel and Nonlinearity Design for Equivariant  Networks on Homogeneous Spaces",
    "abstract": " Comments: Accepted at ICML2022 Thirty-ninth International Conference on Machine Learning ",
    "url": "https://arxiv.org/abs/2206.08362",
    "authors": [
      "Yinshuang Xu",
      "Jiahui Lei",
      "Edgar Dobriban",
      "Kostas Daniilidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.08462",
    "title": "Recursive Neural Programs: Variational Learning of Image Grammars and  Part-Whole Hierarchies",
    "abstract": " Comments: 9 pages, 6 figures. fixed LaTeX typo for figure reference ",
    "url": "https://arxiv.org/abs/2206.08462",
    "authors": [
      "Ares Fisher",
      "Rajesh P.N. Rao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  }
]