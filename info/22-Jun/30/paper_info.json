[
  {
    "id": "arXiv:2206.14200",
    "title": "ECG Heartbeat classification using deep transfer learning with  Convolutional Neural Network and STFT technique",
    "abstract": "Electrocardiogram (ECG) is a simple non-invasive measure to identify heart-related issues such as irregular heartbeats known as arrhythmias. While artificial intelligence and machine learning is being utilized in a wide range of healthcare related applications and datasets, many arrhythmia classifiers using deep learning methods have been proposed in recent years. However, sizes of the available datasets from which to build and assess machine learning models is often very small and the lack of well-annotated public ECG datasets is evident. In this paper, we propose a deep transfer learning framework that is aimed to perform classification on a small size training dataset. The proposed method is to fine-tune a general-purpose image classifier ResNet-18 with MIT-BIH arrhythmia dataset in accordance with the AAMI EC57 standard. This paper further investigates many existing deep learning models that have failed to avoid data leakage against AAMI recommendations. We compare how different data split methods impact the model performance. This comparison study implies that future work in arrhythmia classification should follow the AAMI EC57 standard when using any including MIT-BIH arrhythmia dataset. ",
    "url": "https://arxiv.org/abs/2206.14200",
    "authors": [
      "Minh Cao",
      "Tianqi Zhao",
      "Yanxun Li",
      "Wenhao Zhang",
      "Peyman Benharash",
      "Ramin Ramezani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14202",
    "title": "Building Matters: Spatial Variability in Machine Learning Based Thermal  Comfort Prediction in Winters",
    "abstract": "Thermal comfort in indoor environments has an enormous impact on the health, well-being, and performance of occupants. Given the focus on energy efficiency and Internet-of-Things enabled smart buildings, machine learning (ML) is being increasingly used for data-driven thermal comfort (TC) prediction. Generally, ML-based solutions are proposed for air-conditioned or HVAC ventilated buildings and the models are primarily designed for adults. On the other hand, naturally ventilated (NV) buildings are the norm in most countries. They are also ideal for energy conservation and long-term sustainability goals. However, the indoor environment of NV buildings lacks thermal regulation and varies significantly across spatial contexts. These factors make TC prediction extremely challenging. Thus, determining the impact of the building environment on the performance of TC models is important. Further, the generalization capability of TC prediction models across different NV indoor spaces needs to be studied. This work addresses these problems. Data is gathered through month-long field experiments conducted in 5 naturally ventilated school buildings, involving 512 primary school students. The impact of spatial variability on student comfort is demonstrated through variation in prediction accuracy (by as much as 71%). The influence of building environment on TC prediction is also demonstrated through variation in feature importance. Further, a comparative analysis of spatial variability in model performance is done for children (our dataset) and adults (ASHRAE-II database). Finally, the generalization capability of thermal comfort models in NV classrooms is assessed and major challenges are highlighted. ",
    "url": "https://arxiv.org/abs/2206.14202",
    "authors": [
      "Betty Lala",
      "Srikant Manas Kala",
      "Anmol Rastogi",
      "Kunal Dahiya",
      "Hirozumi Yamaguchi",
      "Aya Hagishima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14245",
    "title": "SImProv: Scalable Image Provenance Framework for Robust Content  Attribution",
    "abstract": "We present SImProv - a scalable image provenance framework to match a query image back to a trusted database of originals and identify possible manipulations on the query. SImProv consists of three stages: a scalable search stage for retrieving top-k most similar images; a re-ranking and near-duplicated detection stage for identifying the original among the candidates; and finally a manipulation detection and visualization stage for localizing regions within the query that may have been manipulated to differ from the original. SImProv is robust to benign image transformations that commonly occur during online redistribution, such as artifacts due to noise and recompression degradation, as well as out-of-place transformations due to image padding, warping, and changes in size and shape. Robustness towards out-of-place transformations is achieved via the end-to-end training of a differentiable warping module within the comparator architecture. We demonstrate effective retrieval and manipulation detection over a dataset of 100 million images. ",
    "url": "https://arxiv.org/abs/2206.14245",
    "authors": [
      "Alexander Black",
      "Tu Bui",
      "Simon Jenni",
      "Zhifei Zhang",
      "Viswanathan Swaminanthan",
      "John Collomosse"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14254",
    "title": "No imputation without representation",
    "abstract": "By filling in missing values in datasets, imputation allows these datasets to be used with algorithms that cannot handle missing values by themselves. However, missing values may in principle contribute useful information that is lost through imputation. The missing-indicator approach can be used in combination with imputation to instead represent this information as a part of the dataset. There are several theoretical considerations why missing-indicators may or may not be beneficial, but there has not been any large-scale practical experiment on real-life datasets to test this question for machine learning predictions. We perform this experiment for three imputation strategies and a range of different classification algorithms, on the basis of twenty real-life datasets. We find that on these datasets, missing-indicators generally increase classification performance. In addition, we find no evidence for most algorithms that nearest neighbour and iterative imputation lead to better performance than simple mean/mode imputation. Therefore, we recommend the use of missing-indicators with mean/mode imputation as a safe default, with the caveat that for decision trees, pruning is necessary to prevent overfitting. In a follow-up experiment, we determine attribute-specific missingness thresholds for each classifier above which missing-indicators are more likely than not to increase classification performance, and observe that these thresholds are much lower for categorical than for numerical attributes. Finally, we argue that mean imputation of numerical attributes may preserve some of the information from missing values, and we show that in the absence of missing-indicators, it can similarly be useful to apply mean imputation to one-hot encoded categorical attributes instead of mode imputation. ",
    "url": "https://arxiv.org/abs/2206.14254",
    "authors": [
      "Oliver Urs Lenz",
      "Daniel Peralta",
      "Chris Cornelis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.14265",
    "title": "Online Anomaly Detection Based On Reservoir Sampling and LOF for IoT  devices",
    "abstract": "The growing number of IoT devices and their use to monitor the operation of machines and equipment increases interest in anomaly detection algorithms running on devices. However, the difficulty is the limitations of the available computational and memory resources on the devices. In the case of microcontrollers (MCUs), these are single megabytes of program and several hundred kilobytes of working memory. Consequently, algorithms must be appropriately matched to the capabilities of the devices. In the paper, we analyse the processing pipeline for anomaly detection and implementation of the Local Outliner Factor (LOF) algorithm on a MCU. We also show that it is possible to train such an algorithm directly on the device, which gives great potential to use the solution in real devices. ",
    "url": "https://arxiv.org/abs/2206.14265",
    "authors": [
      "Tomasz Szydlo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14268",
    "title": "BertNet: Harvesting Knowledge Graphs from Pretrained Language Models",
    "abstract": "Symbolic knowledge graphs (KGs) have been constructed either by expensive human crowdsourcing or with domain-specific complex information extraction pipelines. The emerging large pretrained language models (LMs), such as Bert, have shown to implicitly encode massive knowledge which can be queried with properly designed prompts. However, compared to the explicit KGs, the implict knowledge in the black-box LMs is often difficult to access or edit and lacks explainability. In this work, we aim at harvesting symbolic KGs from the LMs, a new framework for automatic KG construction empowered by the neural LMs' flexibility and scalability. Compared to prior works that often rely on large human annotated data or existing massive KGs, our approach requires only the minimal definition of relations as inputs, and hence is suitable for extracting knowledge of rich new relations not available before.The approach automatically generates diverse prompts, and performs efficient knowledge search within a given LM for consistent and extensive outputs. The harvested knowledge with our approach is substantially more accurate than with previous methods, as shown in both automatic and human evaluation. As a result, we derive from diverse LMs a family of new KGs (e.g., BertNet and RoBERTaNet) that contain a richer set of commonsense relations, including complex ones (e.g., \"A is capable of but not good at B\"), than the human-annotated KGs (e.g., ConceptNet). Besides, the resulting KGs also serve as a vehicle to interpret the respective source LMs, leading to new insights into the varying knowledge capability of different LMs. ",
    "url": "https://arxiv.org/abs/2206.14268",
    "authors": [
      "Shibo Hao",
      "Bowen Tan",
      "Kaiwen Tang",
      "Hengzhe Zhang",
      "Eric P Xing",
      "Zhiting Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.14272",
    "title": "Collecting high-quality adversarial data for machine reading  comprehension tasks with humans and models in the loop",
    "abstract": "We present our experience as annotators in the creation of high-quality, adversarial machine-reading-comprehension data for extractive QA for Task 1 of the First Workshop on Dynamic Adversarial Data Collection (DADC). DADC is an emergent data collection paradigm with both models and humans in the loop. We set up a quasi-experimental annotation design and perform quantitative analyses across groups with different numbers of annotators focusing on successful adversarial attacks, cost analysis, and annotator confidence correlation. We further perform a qualitative analysis of our perceived difficulty of the task given the different topics of the passages in our dataset and conclude with recommendations and suggestions that might be of value to people working on future DADC tasks and related annotation interfaces. ",
    "url": "https://arxiv.org/abs/2206.14272",
    "authors": [
      "Damian Y. Romero Diaz",
      "Magdalena Anio\u0142",
      "John Culnan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14282",
    "title": "Neural Integro-Differential Equations",
    "abstract": "Modeling continuous dynamical systems from discretely sampled observations is a fundamental problem in data science. Often, such dynamics are the result of non-local processes that present an integral over time. As such, these systems are modeled with Integro-Differential Equations (IDEs); generalizations of differential equations that comprise both an integral and a differential component. For example, brain dynamics are not accurately modeled by differential equations since their behavior is non-Markovian, i.e. dynamics are in part dictated by history. Here, we introduce the Neural IDE (NIDE), a framework that models ordinary and integral components of IDEs using neural networks. We test NIDE on several toy and brain activity datasets and demonstrate that NIDE outperforms other models, including Neural ODE. These tasks include time extrapolation as well as predicting dynamics from unseen initial conditions, which we test on whole-cortex activity recordings in freely behaving mice. Further, we show that NIDE can decompose dynamics into its Markovian and non-Markovian constituents, via the learned integral operator, which we test on fMRI brain activity recordings of people on ketamine. Finally, the integrand of the integral operator provides a latent space that gives insight into the underlying dynamics, which we demonstrate on wide-field brain imaging recordings. Altogether, NIDE is a novel approach that enables modeling of complex non-local dynamics with neural networks. ",
    "url": "https://arxiv.org/abs/2206.14282",
    "authors": [
      "Emanuele Zappala",
      "Antonio Henrique de Oliveira Fonseca",
      "Andrew Henry Moberly",
      "Michael James Higley",
      "Chadi Abdallah",
      "Jessica Cardin",
      "David van Dijk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14288",
    "title": "Learning Time Delay Systems with Neural Ordinary Differential Equations",
    "abstract": "A novel way of using neural networks to learn the dynamics of time delay systems from sequential data is proposed. A neural network with trainable delays is used to approximate the right hand side of a delay differential equation. We relate the delay differential equation to an ordinary differential equation by discretizing the time history and train the corresponding neural ordinary differential equation (NODE) to learn the dynamics. An example on learning the dynamics of the Mackey-Glass equation using data from chaotic behavior is given. After learning both the nonlinearity and the time delay, we demonstrate that the bifurcation diagram of the neural network matches that of the original system. ",
    "url": "https://arxiv.org/abs/2206.14288",
    "authors": [
      "Xunbi A. Ji",
      "Gabor Orosz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2206.14298",
    "title": "Left Heavy Tails and the Effectiveness of the Policy and Value Networks  in DNN-based best-first search for Sokoban Planning",
    "abstract": "Despite the success of practical solvers in various NP-complete domains such as SAT and CSP as well as using deep reinforcement learning to tackle two-player games such as Go, certain classes of PSPACE-hard planning problems have remained out of reach. Even carefully designed domain-specialized solvers can fail quickly due to the exponential search space on hard instances. Recent works that combine traditional search methods, such as best-first search and Monte Carlo tree search, with Deep Neural Networks' (DNN) heuristics have shown promising progress and can solve a significant number of hard planning instances beyond specialized solvers. To better understand why these approaches work, we studied the interplay of the policy and value networks of DNN-based best-first search on Sokoban and show the surprising effectiveness of the policy network, further enhanced by the value network, as a guiding heuristic for the search. To further understand the phenomena, we studied the cost distribution of the search algorithms and found that Sokoban instances can have heavy-tailed runtime distributions, with tails both on the left and right-hand sides. In particular, for the first time, we show the existence of \\textit{left heavy tails} and propose an abstract tree model that can empirically explain the appearance of these tails. The experiments show the critical role of the policy network as a powerful heuristic guiding the search, which can lead to left heavy tails with polynomial scaling by avoiding exploring exponentially sized subtrees. Our results also demonstrate the importance of random restarts, as are widely used in traditional combinatorial solvers, for DNN-based search methods to avoid left and right heavy tails. ",
    "url": "https://arxiv.org/abs/2206.14298",
    "authors": [
      "Dieqiao Feng",
      "Carla Gomes",
      "Bart Selman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.14314",
    "title": "Generative Neural Articulated Radiance Fields",
    "abstract": "Unsupervised learning of 3D-aware generative adversarial networks (GANs) using only collections of single-view 2D photographs has very recently made much progress. These 3D GANs, however, have not been demonstrated for human bodies and the generated radiance fields of existing frameworks are not directly editable, limiting their applicability in downstream tasks. We propose a solution to these challenges by developing a 3D GAN framework that learns to generate radiance fields of human bodies or faces in a canonical pose and warp them using an explicit deformation field into a desired body pose or facial expression. Using our framework, we demonstrate the first high-quality radiance field generation results for human bodies. Moreover, we show that our deformation-aware training procedure significantly improves the quality of generated bodies or faces when editing their poses or facial expressions compared to a 3D GAN that is not trained with explicit deformations. ",
    "url": "https://arxiv.org/abs/2206.14314",
    "authors": [
      "Alexander W. Bergman",
      "Petr Kellnhofer",
      "Yifan Wang",
      "Eric R. Chan",
      "David B. Lindell",
      "Gordon Wetzstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2206.14337",
    "title": "Deformable Graph Transformer",
    "abstract": "Transformer-based models have been widely used and achieved state-of-the-art performance in various domains such as natural language processing and computer vision. Recent works show that Transformers can also be generalized to graph-structured data. However, the success is limited to small-scale graphs due to technical challenges such as the quadratic complexity in regards to the number of nodes and non-local aggregation that often leads to inferior generalization performance to conventional graph neural networks. In this paper, to address these issues, we propose Deformable Graph Transformer (DGT) that performs sparse attention with dynamically sampled key and value pairs. Specifically, our framework first constructs multiple node sequences with various criteria to consider both structural and semantic proximity. Then, the sparse attention is applied to the node sequences for learning node representations with a reduced computational cost. We also design simple and effective positional encodings to capture structural similarity and distance between nodes. Experiments demonstrate that our novel graph Transformer consistently outperforms existing Transformer-based models and shows competitive performance compared to state-of-the-art models on 8 graph benchmark datasets including large-scale graphs. ",
    "url": "https://arxiv.org/abs/2206.14337",
    "authors": [
      "Jinyoung Park",
      "Seongjun Yun",
      "Hyeonjin Park",
      "Jaewoo Kang",
      "Jisu Jeong",
      "Kyung-Min Kim",
      "Jung-woo Ha",
      "Hyunwoo J. Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14341",
    "title": "CoAP-DoS: An IoT Network Intrusion Dataset",
    "abstract": "The need for secure Internet of Things (IoT) devices is growing as IoT devices are becoming more integrated into vital networks. Many systems rely on these devices to remain available and provide reliable service. Denial of service attacks against IoT devices are a real threat due to the fact these low power devices are very susceptible to denial-of-service attacks. Machine learning enabled network intrusion detection systems are effective at identifying new threats, but they require a large amount of data to work well. There are many network traffic data sets but very few that focus on IoT network traffic. Within the IoT network data sets there is a lack of CoAP denial of service data. We propose a novel data set covering this gap. We develop a new data set by collecting network traffic from real CoAP denial of service attacks and compare the data on multiple different machine learning classifiers. We show that the data set is effective on many classifiers. ",
    "url": "https://arxiv.org/abs/2206.14341",
    "authors": [
      "Jared Mathews",
      "Prosenjit Chatterjee",
      "Shankar Banik"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2206.14342",
    "title": "Intrinsic Anomaly Detection for Multi-Variate Time Series",
    "abstract": "We introduce a novel, practically relevant variation of the anomaly detection problem in multi-variate time series: intrinsic anomaly detection. It appears in diverse practical scenarios ranging from DevOps to IoT, where we want to recognize failures of a system that operates under the influence of a surrounding environment. Intrinsic anomalies are changes in the functional dependency structure between time series that represent an environment and time series that represent the internal state of a system that is placed in said environment. We formalize this problem, provide under-studied public and new purpose-built data sets for it, and present methods that handle intrinsic anomaly detection. These address the short-coming of existing anomaly detection methods that cannot differentiate between expected changes in the system's state and unexpected ones, i.e., changes in the system that deviate from the environment's influence. Our most promising approach is fully unsupervised and combines adversarial learning and time series representation learning, thereby addressing problems such as label sparsity and subjectivity, while allowing to navigate and improve notoriously problematic anomaly detection data sets. ",
    "url": "https://arxiv.org/abs/2206.14342",
    "authors": [
      "Stephan Rabanser",
      "Tim Januschowski",
      "Kashif Rasul",
      "Oliver Borchert",
      "Richard Kurle",
      "Jan Gasthaus",
      "Michael Bohlke-Schneider",
      "Nicolas Papernot",
      "Valentin Flunkert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.14346",
    "title": "A Deep Learning Approach to Create DNS Amplification Attacks",
    "abstract": "In recent years, deep learning has shown itself to be an incredibly valuable tool in cybersecurity as it helps network intrusion detection systems to classify attacks and detect new ones. Adversarial learning is the process of utilizing machine learning to generate a perturbed set of inputs to then feed to the neural network to misclassify it. Much of the current work in the field of adversarial learning has been conducted in image processing and natural language processing with a wide variety of algorithms. Two algorithms of interest are the Elastic-Net Attack on Deep Neural Networks and TextAttack. In our experiment the EAD and TextAttack algorithms are applied to a Domain Name System amplification classifier. The algorithms are used to generate malicious Distributed Denial of Service adversarial examples to then feed as inputs to the network intrusion detection systems neural network to classify as valid traffic. We show in this work that both image processing and natural language processing adversarial learning algorithms can be applied against a network intrusion detection neural network. ",
    "url": "https://arxiv.org/abs/2206.14346",
    "authors": [
      "Jared Mathews",
      "Prosenjit Chatterjee",
      "Shankar Banik",
      "Cory Nance"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.14350",
    "title": "Convolutional Neural Network Based Partial Face Detection",
    "abstract": "Due to the massive explanation of artificial intelligence, machine learning technology is being used in various areas of our day-to-day life. In the world, there are a lot of scenarios where a simple crime can be prevented before it may even happen or find the person responsible for it. A face is one distinctive feature that we have and can differentiate easily among many other species. But not just different species, it also plays a significant role in determining someone from the same species as us, humans. Regarding this critical feature, a single problem occurs most often nowadays. When the camera is pointed, it cannot detect a person's face, and it becomes a poor image. On the other hand, where there was a robbery and a security camera installed, the robber's identity is almost indistinguishable due to the low-quality camera. But just making an excellent algorithm to work and detecting a face reduces the cost of hardware, and it doesn't cost that much to focus on that area. Facial recognition, widget control, and such can be done by detecting the face correctly. This study aims to create and enhance a machine learning model that correctly recognizes faces. Total 627 Data have been collected from different Bangladeshi people's faces on four angels. In this work, CNN, Harr Cascade, Cascaded CNN, Deep CNN & MTCNN are these five machine learning approaches implemented to get the best accuracy of our dataset. After creating and running the model, Multi-Task Convolutional Neural Network (MTCNN) achieved 96.2% best model accuracy with training data rather than other machine learning models. ",
    "url": "https://arxiv.org/abs/2206.14350",
    "authors": [
      "Md. Towfiqul Islam",
      "Tanzim Ahmed",
      "A.B.M. Raihanur Rashid",
      "Taminul Islam",
      "Md. Sadekur Rahman",
      "Md. Tarek Habib"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14354",
    "title": "Hardness and Algorithms for Robust and Sparse Optimization",
    "abstract": "We explore algorithms and limitations for sparse optimization problems such as sparse linear regression and robust linear regression. The goal of the sparse linear regression problem is to identify a small number of key features, while the goal of the robust linear regression problem is to identify a small number of erroneous measurements. Specifically, the sparse linear regression problem seeks a $k$-sparse vector $x\\in\\mathbb{R}^d$ to minimize $\\|Ax-b\\|_2$, given an input matrix $A\\in\\mathbb{R}^{n\\times d}$ and a target vector $b\\in\\mathbb{R}^n$, while the robust linear regression problem seeks a set $S$ that ignores at most $k$ rows and a vector $x$ to minimize $\\|(Ax-b)_S\\|_2$. We first show bicriteria, NP-hardness of approximation for robust regression building on the work of [OWZ15] which implies a similar result for sparse regression. We further show fine-grained hardness of robust regression through a reduction from the minimum-weight $k$-clique conjecture. On the positive side, we give an algorithm for robust regression that achieves arbitrarily accurate additive error and uses runtime that closely matches the lower bound from the fine-grained hardness result, as well as an algorithm for sparse regression with similar runtime. Both our upper and lower bounds rely on a general reduction from robust linear regression to sparse regression that we introduce. Our algorithms, inspired by the 3SUM problem, use approximate nearest neighbor data structures and may be of independent interest for solving sparse optimization problems. For instance, we demonstrate that our techniques can also be used for the well-studied sparse PCA problem. ",
    "url": "https://arxiv.org/abs/2206.14354",
    "authors": [
      "Eric Price",
      "Sandeep Silwal",
      "Samson Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2206.14355",
    "title": "EBMs vs. CL: Exploring Self-Supervised Visual Pretraining for Visual  Question Answering",
    "abstract": "The availability of clean and diverse labeled data is a major roadblock for training models on complex tasks such as visual question answering (VQA). The extensive work on large vision-and-language models has shown that self-supervised learning is effective for pretraining multimodal interactions. In this technical report, we focus on visual representations. We review and evaluate self-supervised methods to leverage unlabeled images and pretrain a model, which we then fine-tune on a custom VQA task that allows controlled evaluation and diagnosis. We compare energy-based models (EBMs) with contrastive learning (CL). While EBMs are growing in popularity, they lack an evaluation on downstream tasks. We find that both EBMs and CL can learn representations from unlabeled images that enable training a VQA model on very little annotated data. In a simple setting similar to CLEVR, we find that CL representations also improve systematic generalization, and even match the performance of representations from a larger, supervised, ImageNet-pretrained model. However, we find EBMs to be difficult to train because of instabilities and high variability in their results. Although EBMs prove useful for OOD detection, other results on supervised energy-based training and uncertainty calibration are largely negative. Overall, CL currently seems a preferable option over EBMs. ",
    "url": "https://arxiv.org/abs/2206.14355",
    "authors": [
      "Violetta Shevchenko",
      "Ehsan Abbasnejad",
      "Anthony Dick",
      "Anton van den Hengel",
      "Damien Teney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14362",
    "title": "On Lower Bounds of Error Probability for Invariant Causal Prediction",
    "abstract": "It is common practice to collect observations of feature and response pairs from different environments. A natural question is how to identify features that have consistent prediction power across environments. The invariant causal prediction framework proposes to approach this problem through invariance, assuming a linear model that is invariant under different environments. In this work, we make an attempt to shed light on this framework by connecting it to the Gaussian multiple access channel problem. Specifically, we incorporate optimal code constructions and decoding methods to provide lower bounds of error probability. We illustrate our findings by various simulation settings. ",
    "url": "https://arxiv.org/abs/2206.14362",
    "authors": [
      "Austin Goddard",
      "Yu Xiang",
      "Ilya Soloveychik"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2206.14363",
    "title": "AAE: An Active Auto-Estimator for Improving Graph Storage",
    "abstract": "Nowadays, graph becomes an increasingly popular model in many real applications. The efficiency of graph storage is crucial for these applications. Generally speaking, the tune tasks of graph storage rely on the database administrators (DBAs) to find the best graph storage. However, DBAs make the tune decisions by mainly relying on their experiences and intuition. Due to the limitations of DBAs's experiences, the tunes may have an uncertain performance and conduct worse efficiency. In this paper, we observe that an estimator of graph workload has the potential to guarantee the performance of tune operations. Unfortunately, because of the complex characteristics of graph evaluation task, there exists no mature estimator for graph workload. We formulate the evaluation task of graph workload as a classification task and carefully design the feature engineering process, including graph data features, graph workload features and graph storage features. Considering the complex features of graph and the huge time consumption in graph workload execution, it is difficult for the graph workload estimator to obtain enough training set. So, we propose an active auto-estimator (AAE) for the graph workload evaluation by combining the active learning and deep learning. AAE could achieve good evaluation efficiency with limited training set. We test the time efficiency and evaluation accuracy of AAE with two open source graph data, LDBC and Freebase. Experimental results show that our estimator could efficiently complete the graph workload evaluation in milliseconds. ",
    "url": "https://arxiv.org/abs/2206.14363",
    "authors": [
      "Yu Yan",
      "Man Yang",
      "Hongzhi Wang",
      "Yuzhuo Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2206.14369",
    "title": "Robust Online Voltage Control with an Unknown Grid Topology",
    "abstract": "Voltage control generally requires accurate information about the grid's topology in order to guarantee network stability. However, accurate topology identification is a challenging problem for existing methods, especially as the grid is subject to increasingly frequent reconfiguration due to the adoption of renewable energy. Further, running existing control mechanisms with incorrect network information may lead to unstable control. In this work, we combine a nested convex body chasing algorithm with a robust predictive controller to achieve provably finite-time convergence to safe voltage limits in the online setting where the network topology is initially unknown. Specifically, the online controller does not know the true network topology and line parameters, but instead must learn them over time by narrowing down the set of network topologies and line parameters that are consistent with its observations and adjusting reactive power generation accordingly to keep voltages within desired safety limits. We demonstrate the effectiveness of the approach using a case study, which shows that in practical settings the controller is indeed able to narrow the set of consistent topologies quickly enough to make control decisions that ensure stability. ",
    "url": "https://arxiv.org/abs/2206.14369",
    "authors": [
      "Christopher Yeh",
      "Jing Yu",
      "Yuanyuan Shi",
      "Adam Wierman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2206.14384",
    "title": "Framing Algorithmic Recourse for Anomaly Detection",
    "abstract": "The problem of algorithmic recourse has been explored for supervised machine learning models, to provide more interpretable, transparent and robust outcomes from decision support systems. An unexplored area is that of algorithmic recourse for anomaly detection, specifically for tabular data with only discrete feature values. Here the problem is to present a set of counterfactuals that are deemed normal by the underlying anomaly detection model so that applications can utilize this information for explanation purposes or to recommend countermeasures. We present an approach -- Context preserving Algorithmic Recourse for Anomalies in Tabular data (CARAT), that is effective, scalable, and agnostic to the underlying anomaly detection model. CARAT uses a transformer based encoder-decoder model to explain an anomaly by finding features with low likelihood. Subsequently semantically coherent counterfactuals are generated by modifying the highlighted features, using the overall context of features in the anomalous instance(s). Extensive experiments help demonstrate the efficacy of CARAT. ",
    "url": "https://arxiv.org/abs/2206.14384",
    "authors": [
      "Debanjan Datta",
      "Feng Chen",
      "Naren Ramakrishnan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2206.14388",
    "title": "Chinese Word Sense Embedding with SememeWSD and Synonym Set",
    "abstract": "Word embedding is a fundamental natural language processing task which can learn feature of words. However, most word embedding methods assign only one vector to a word, even if polysemous words have multi-senses. To address this limitation, we propose SememeWSD Synonym (SWSDS) model to assign a different vector to every sense of polysemous words with the help of word sense disambiguation (WSD) and synonym set in OpenHowNet. We use the SememeWSD model, an unsupervised word sense disambiguation model based on OpenHowNet, to do word sense disambiguation and annotate the polysemous word with sense id. Then, we obtain top 10 synonyms of the word sense from OpenHowNet and calculate the average vector of synonyms as the vector of the word sense. In experiments, We evaluate the SWSDS model on semantic similarity calculation with Gensim's wmdistance method. It achieves improvement of accuracy. We also examine the SememeWSD model on different BERT models to find the more effective model. ",
    "url": "https://arxiv.org/abs/2206.14388",
    "authors": [
      "Yangxi Zhou",
      "Junping Du",
      "Zhe Xue",
      "Ang Li",
      "Zeli Guan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.14390",
    "title": "Diet Code is Healthy: Simplifying Programs for Pre-Trained Models of  Code",
    "abstract": "Pre-trained code representation models such as CodeBERT have demonstrated superior performance in a variety of software engineering tasks, yet they are often heavy in complexity, quadratically with the length of the input sequence. Our empirical analysis of CodeBERT's attention reveals that CodeBERT pays more attention to certain types of tokens and statements such as keywords and data-relevant statements. Based on these findings, we propose DietCodeBERT, which aims at lightweight leverage of large pre-trained models for source code. DietCodeBERT simplifies the input program of CodeBERT with three strategies, namely, word dropout, frequency filtering, and an attention-based strategy which selects statements and tokens that receive the most attention weights during pre-training. Hence, it gives a substantial reduction in the computational cost without hampering the model performance. Experimental results on two downstream tasks show that DietCodeBERT provides comparable results to CodeBERT with 40% less computational cost in fine-tuning and testing. ",
    "url": "https://arxiv.org/abs/2206.14390",
    "authors": [
      "Zhaowei Zhang",
      "Hongyu Zhang",
      "Beijun Shen",
      "Xiaodong Gu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2206.14418",
    "title": "Optimization-Induced Graph Implicit Nonlinear Diffusion",
    "abstract": "Due to the over-smoothing issue, most existing graph neural networks can only capture limited dependencies with their inherently finite aggregation layers. To overcome this limitation, we propose a new kind of graph convolution, called Graph Implicit Nonlinear Diffusion (GIND), which implicitly has access to infinite hops of neighbors while adaptively aggregating features with nonlinear diffusion to prevent over-smoothing. Notably, we show that the learned representation can be formalized as the minimizer of an explicit convex optimization objective. With this property, we can theoretically characterize the equilibrium of our GIND from an optimization perspective. More interestingly, we can induce new structural variants by modifying the corresponding optimization objective. To be specific, we can embed prior properties to the equilibrium, as well as introducing skip connections to promote training stability. Extensive experiments show that GIND is good at capturing long-range dependencies, and performs well on both homophilic and heterophilic graphs with nonlinear diffusion. Moreover, we show that the optimization-induced variants of our models can boost the performance and improve training stability and efficiency as well. As a result, our GIND obtains significant improvements on both node-level and graph-level tasks. ",
    "url": "https://arxiv.org/abs/2206.14418",
    "authors": [
      "Qi Chen",
      "Yifei Wang",
      "Yisen Wang",
      "Jiansheng Yang",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14442",
    "title": "Conditioned Human Trajectory Prediction using Iterative Attention Blocks",
    "abstract": "Human motion prediction is key to understand social environments, with direct applications in robotics, surveillance, etc. We present a simple yet effective pedestrian trajectory prediction model aimed at pedestrians positions prediction in urban-like environments conditioned by the environment: map and surround agents. Our model is a neural-based architecture that can run several layers of attention blocks and transformers in an iterative sequential fashion, allowing to capture the important features in the environment that improve prediction. We show that without explicit introduction of social masks, dynamical models, social pooling layers, or complicated graph-like structures, it is possible to produce on par results with SoTA models, which makes our approach easily extendable and configurable, depending on the data available. We report results performing similarly with SoTA models on publicly available and extensible-used datasets with unimodal prediction metrics ADE and FDE. ",
    "url": "https://arxiv.org/abs/2206.14442",
    "authors": [
      "Aleksey Postnikov",
      "Aleksander Gamayunov",
      "Gonzalo Ferrer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.14451",
    "title": "SRCN3D: Sparse R-CNN 3D Surround-View Camera Object Detection and  Tracking for Autonomous Driving",
    "abstract": "Detection And Tracking of Moving Objects (DATMO) is an essential component in environmental perception for autonomous driving. While 3D detectors using surround-view cameras are just flourishing, there is a growing tendency of using different transformer-based methods to learn queries in 3D space from 2D feature maps of perspective view. This paper proposes Sparse R-CNN 3D (SRCN3D), a novel two-stage fully-convolutional mapping pipeline for surround-view camera detection and tracking. SRCN3D adopts a cascade structure with twin-track update of both fixed number of proposal boxes and proposal latent features. Proposal boxes are projected to perspective view so as to aggregate Region of Interest (RoI) local features. Based on that, proposal features are refined via a dynamic instance interactive head, which then generates classification and the offsets applied to original bounding boxes. Compared to prior arts, our sparse feature sampling module only utilizes local 2D features for adjustment of each corresponding 3D proposal box, leading to a complete sparse paradigm. The proposal features and appearance features are both taken in data association process in a multi-hypotheses 3D multi-object tracking approach. Extensive experiments on nuScenes dataset demonstrate the effectiveness of our proposed SRCN3D detector and tracker. Code is available at https://github.com/synsin0/SRCN3D. ",
    "url": "https://arxiv.org/abs/2206.14451",
    "authors": [
      "Yining Shi",
      "Jingyan Shen",
      "Yifan Sun",
      "Yunlong Wang",
      "Jiaxin Li",
      "Shiqi Sun",
      "Kun Jiang",
      "Diange Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14475",
    "title": "Siamese Contrastive Embedding Network for Compositional Zero-Shot  Learning",
    "abstract": "Compositional Zero-Shot Learning (CZSL) aims to recognize unseen compositions formed from seen state and object during training. Since the same state may be various in the visual appearance while entangled with different objects, CZSL is still a challenging task. Some methods recognize state and object with two trained classifiers, ignoring the impact of the interaction between object and state; the other methods try to learn the joint representation of the state-object compositions, leading to the domain gap between seen and unseen composition sets. In this paper, we propose a novel Siamese Contrastive Embedding Network (SCEN) (Code: https://github.com/XDUxyLi/SCEN-master) for unseen composition recognition. Considering the entanglement between state and object, we embed the visual feature into a Siamese Contrastive Space to capture prototypes of them separately, alleviating the interaction between state and object. In addition, we design a State Transition Module (STM) to increase the diversity of training compositions, improving the robustness of the recognition model. Extensive experiments indicate that our method significantly outperforms the state-of-the-art approaches on three challenging benchmark datasets, including the recent proposed C-QGA dataset. ",
    "url": "https://arxiv.org/abs/2206.14475",
    "authors": [
      "Xiangyu Li",
      "Xu Yang",
      "Kun Wei",
      "Cheng Deng",
      "Muli Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14477",
    "title": "Adversarial Ensemble Training by Jointly Learning Label Dependencies and  Member Models",
    "abstract": "Training an ensemble of different sub-models has empirically proven to be an effective strategy to improve deep neural networks' adversarial robustness. Current ensemble training methods for image recognition usually encode the image labels by one-hot vectors, which neglect dependency relationships between the labels. Here we propose a novel adversarial training approach that learns the conditional dependencies between labels and the model ensemble jointly. We test our approach on widely used datasets MNIST, FasionMNIST and CIFAR-10. Results show that our approach is more robust against black-box attacks compared with state-of-the-art methods. Our code is available at https://github.com/ZJLAB-AMMI/LSD. ",
    "url": "https://arxiv.org/abs/2206.14477",
    "authors": [
      "Lele Wang",
      "Bin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.14480",
    "title": "Representation and Synthesis of C++ Programs for Generalized Planning",
    "abstract": "The paper introduces a novel representation for Generalized Planning (GP) problems, and their solutions, as C++ programs. Our C++ representation allows to formally proving the termination of generalized plans, and to specifying their asymptotic complexity w.r.t. the number of world objects. Characterizing the complexity of C++ generalized plans enables the application of a combinatorial search that enumerates the space of possible GP solutions in order of complexity. Experimental results show that our implementation of this approach, which we call BFGP++, outperforms the previous GP as heuristic search approach for the computation of generalized plans represented as compiler-styled programs. Last but not least, the execution of a C++ program on a classical planning instance is a deterministic grounding-free and search-free process, so our C++ representation allows us to automatically validate the computed solutions on large test instances of thousands of objects, where off-the-shelf classical planners get stuck either in the pre-processing or in the search. ",
    "url": "https://arxiv.org/abs/2206.14480",
    "authors": [
      "Javier Segovia-Aguas",
      "Yolanda E-Mart\u00edn",
      "Sergio Jim\u00e9nez"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.14483",
    "title": "Data augmentation for learning predictive models on EEG: a systematic  comparison",
    "abstract": "The use of deep learning for electroencephalography (EEG) classification tasks has been rapidly growing in the last years, yet its application has been limited by the relatively small size of EEG datasets. Data augmentation, which consists in artificially increasing the size of the dataset during training, has been a key ingredient to obtain state-of-the-art performances across applications such as computer vision or speech. While a few augmentation transformations for EEG data have been proposed in the literature, their positive impact on performance across tasks remains elusive. In this work, we propose a unified and exhaustive analysis of the main existing EEG augmentations, which are compared in a common experimental setting. Our results highlight the best data augmentations to consider for sleep stage classification and motor imagery brain computer interfaces, showing predictive power improvements greater than 10% in some cases. ",
    "url": "https://arxiv.org/abs/2206.14483",
    "authors": [
      "C\u00e9dric Rommel",
      "Joseph Paillard",
      "Thomas Moreau",
      "Alexandre Gramfort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.14486",
    "title": "Beyond neural scaling laws: beating power law scaling via data pruning",
    "abstract": "Widely observed neural scaling laws, in which error falls off as a power of the training set size, model size, or both, have driven substantial performance improvements in deep learning. However, these improvements through scaling alone require considerable costs in compute and energy. Here we focus on the scaling of error with dataset size and show how both in theory and practice we can break beyond power law scaling and reduce it to exponential scaling instead if we have access to a high-quality data pruning metric that ranks the order in which training examples should be discarded to achieve any pruned dataset size. We then test this new exponential scaling prediction with pruned dataset size empirically, and indeed observe better than power law scaling performance on ResNets trained on CIFAR-10, SVHN, and ImageNet. Given the importance of finding high-quality pruning metrics, we perform the first large-scale benchmarking study of ten different data pruning metrics on ImageNet. We find most existing high performing metrics scale poorly to ImageNet, while the best are computationally intensive and require labels for every image. We therefore developed a new simple, cheap and scalable self-supervised pruning metric that demonstrates comparable performance to the best supervised metrics. Overall, our work suggests that the discovery of good data-pruning metrics may provide a viable path forward to substantially improved neural scaling laws, thereby reducing the resource costs of modern deep learning. ",
    "url": "https://arxiv.org/abs/2206.14486",
    "authors": [
      "Ben Sorscher",
      "Robert Geirhos",
      "Shashank Shekhar",
      "Surya Ganguli",
      "Ari S. Morcos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.14496",
    "title": "Auto-Encoder-Extreme Learning Machine Model for Boiler NOx Emission  Concentration Prediction",
    "abstract": "An automatic encoder (AE) extreme learning machine (ELM)-AE-ELM model is proposed to predict the NOx emission concentration based on the combination of mutual information algorithm (MI), AE, and ELM. First, the importance of practical variables is computed by the MI algorithm, and the mechanism is analyzed to determine the variables related to the NOx emission concentration. Then, the time delay correlations between the selected variables and NOx emission concentration are further analyzed to reconstruct the modeling data. Subsequently, the AE is applied to extract hidden features within the input variables. Finally, an ELM algorithm establishes the relationship between the NOx emission concentration and deep features. The experimental results on practical data indicate that the proposed model shows promising performance compared to state-of-art models. ",
    "url": "https://arxiv.org/abs/2206.14496",
    "authors": [
      "Zhenhao Tang",
      "Shikui Wang",
      "Xiangying Chai",
      "Shengxian Cao",
      "Tinghui Ouyang",
      "Yang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.14502",
    "title": "RegMixup: Mixup as a Regularizer Can Surprisingly Improve Accuracy and  Out Distribution Robustness",
    "abstract": "We show that the effectiveness of the well celebrated Mixup [Zhang et al., 2018] can be further improved if instead of using it as the sole learning objective, it is utilized as an additional regularizer to the standard cross-entropy loss. This simple change not only provides much improved accuracy but also significantly improves the quality of the predictive uncertainty estimation of Mixup in most cases under various forms of covariate shifts and out-of-distribution detection experiments. In fact, we observe that Mixup yields much degraded performance on detecting out-of-distribution samples possibly, as we show empirically, because of its tendency to learn models that exhibit high-entropy throughout; making it difficult to differentiate in-distribution samples from out-distribution ones. To show the efficacy of our approach (RegMixup), we provide thorough analyses and experiments on vision datasets (ImageNet & CIFAR-10/100) and compare it with a suite of recent approaches for reliable uncertainty estimation. ",
    "url": "https://arxiv.org/abs/2206.14502",
    "authors": [
      "Francesco Pinto",
      "Harry Yang",
      "Ser-Nam Lim",
      "Philip H.S. Torr",
      "Puneet K. Dokania"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14523",
    "title": "Supervised Deep Hashing for High-dimensional and Heterogeneous  Case-based Reasoning",
    "abstract": "Case-based Reasoning (CBR) on high-dimensional and heterogeneous data is a trending yet challenging and computationally expensive task in the real world. A promising approach is to obtain low-dimensional hash codes representing cases and perform a similarity retrieval of cases in Hamming space. However, previous methods based on data-independent hashing rely on random projections or manual construction, inapplicable to address specific data issues (e.g., high-dimensionality and heterogeneity) due to their insensitivity to data characteristics. To address these issues, this work introduces a novel deep hashing network to learn similarity-preserving compact hash codes for efficient case retrieval and proposes a deep-hashing-enabled CBR model HeCBR. Specifically, we introduce position embedding to represent heterogeneous features and utilize a multilinear interaction layer to obtain case embeddings, which effectively filtrates zero-valued features to tackle high-dimensionality and sparsity and captures inter-feature couplings. Then, we feed the case embeddings into fully-connected layers, and subsequently a hash layer generates hash codes with a quantization regularizer to control the quantization loss during relaxation. To cater to incremental learning of CBR, we further propose an adaptive learning strategy to update the hash function. Extensive experiments on public datasets show that HeCBR greatly reduces storage and significantly accelerates case retrieval. HeCBR achieves desirable performance compared with the state-of-the-art CBR methods and performs significantly better than hashing-based CBR methods in classification. ",
    "url": "https://arxiv.org/abs/2206.14523",
    "authors": [
      "Qi Zhang",
      "Liang Hu",
      "Chongyang Shi",
      "Ke Liu",
      "Longbing Cao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.14539",
    "title": "Current Challenges of Cyber Threat and Vulnerability Identification  Using Public Enumerations",
    "abstract": "Identification of cyber threats is one of the essential tasks for security teams. Currently, cyber threats can be identified using knowledge organized into various formats, enumerations, and knowledge bases. This paper studies the current challenges of identifying vulnerabilities and threats in cyberspace using enumerations and data about assets. Although enumerations are used in practice, we point out several issues that still decrease the quality of vulnerability and threat identification. Since vulnerability identification methods are based on network monitoring and agents, the issues are related to the asset discovery, the precision of vulnerability discovery, and the amount of data. On the other hand, threat identification utilizes graph-based, nature-language, machine-learning, and ontological approaches. The current trend is to propose methods that utilize tactics, techniques, and procedures instead of low-level indicators of compromise to make cyber threat identification more mature. Cooperation between standards from threat, vulnerability, and asset management is also an unresolved issue confirmed by analyzing relationships between public enumerations and knowledge bases. Last, we studied the usability of techniques from the MITRE ATT&CK knowledge base for threat modeling using network monitoring to capture data. Although network traffic is not the most used data source, it allows the modeling of almost all tactics from the MITRE ATT&CK. ",
    "url": "https://arxiv.org/abs/2206.14539",
    "authors": [
      "Luk\u00e1\u0161 Sadlek",
      "Pavel \u010celeda",
      "Daniel Tovar\u0148\u00e1k"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.14547",
    "title": "A Novel Attack to the Permuted Kernel Problem",
    "abstract": "The Permuted Kernel Problem (PKP) asks to find a permutation of a given vector belonging to the kernel of a given matrix. The PKP is at the basis of PKP-DSS, a post-quantum signature scheme deriving from the identification scheme proposed by Shamir in 1989. The most efficient solver for PKP is due to a recent paper by Koussa et al. In this paper we propose an improvement of such an algorithm, which we achieve by considering an additional collision search step applied on kernel equations involving a small number of coordinates. We study the conditions for such equations to exist from a coding theory perspective, and we describe how to efficiently find them with methods borrowed from coding theory, such as information set decoding. We assess the complexity of the resulting algorithm and show that it outperforms previous approaches in several cases. We also show that, taking the new solver into account, the security level of some instances of PKP-DSS turns out to be slightly overestimated. ",
    "url": "https://arxiv.org/abs/2206.14547",
    "authors": [
      "Paolo Santini",
      "Marco Baldi",
      "Franco Chiaraluce"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.14562",
    "title": "Observer-Based Coordinated Tracking Control for Nonlinear Multi-Agent  Systems with Intermittent Communication under Heterogeneous Coupling  Framework",
    "abstract": "In this article, the observer-based coordinated tracking control problem for a class of nonlinear multi-agent systems(MASs) with intermittent communication and information constraints is studied under dynamic switching topology. First, a state observer is designed to estimate the unmeasurable actual state information in the system. Second, adjustable heterogeneous coupling weighting parameters are introduced in the dynamic switching topology, and the distributed coordinated tracking control protocol under heterogeneous coupling framework is proposed. Then, a new Lemma is constructed to realize the cooperative design of observer gain, state feedback gain and heterogeneous coupling gain matrices. Furthermore, the stability of the system is further proved, and the range of communication rate is obtained. On this basis, the intermittent communication mode is extended to three time interval cases, namely normal communication, leader-follower communication interruption and all agents communication interruption, and then the distributed coordinated tracking control method is improved to solve this problem. Finally, simulation experiments are conducted with nonlinear MASs to verify the correctness of methods. ",
    "url": "https://arxiv.org/abs/2206.14562",
    "authors": [
      "Yuhang Zhang",
      "Yulian Jiang",
      "Shenquan Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2206.14567",
    "title": "Contributions to Context-Aware Smart Healthcare: A Security and Privacy  Perspective",
    "abstract": "The management of health data, from their gathering to their analysis, arises a number of challenging issues due to their highly confidential nature. In particular, this dissertation contributes to several security and privacy challenges within the smart health paradigm. More concretely, we firstly develop some contributions to context-aware environments enabling smart health scenarios. We present an extensive analysis on the security aspects of the underlying sensors and networks deployed in such environments, a novel user-centred privacy framework for analysing ubiquitous computing systems, and a complete analysis on the security and privacy challenges that need to be faced to implement cognitive cities properly. Second, we contribute to process mining, a popular analytical field that helps analyse business processes within organisations. Despite its popularity within the healthcare industry, we address two major issues: the high complexity of healthcare processes and the scarce research on privacy aspects. Regarding the first issue, we present a novel process discovery algorithm with a built-in heuristic that simplifies complex processes and, regarding the second, we propose two novel privacy-preserving process mining methods, which achieve a remarkable trade-off between accuracy and privacy. Last but not least, we present some smart health applications, namely a context-aware recommender system for routes, a platform supporting early mobilization programmes in hospital settings, and a health-oriented geographic information system. The results of this dissertation are intended to help the research community to enhance the security of the intelligent environments of the future as well as the privacy of the citizens regarding their personal and health data. ",
    "url": "https://arxiv.org/abs/2206.14567",
    "authors": [
      "Edgar Batista"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2206.14571",
    "title": "Should Social Robots in Retail Manipulate Customers?",
    "abstract": "Against the backdrop of structural changes in the retail trade, social robots have found their way into retail stores and shopping malls in order to attract, welcome, and greet customers; to inform them, advise them, and persuade them to make a purchase. Salespeople often have a broad knowledge of their product and rely on offering competent and honest advice, whether it be on shoes, clothing, or kitchen appliances. However, some frequently use sales tricks to secure purchases. The question arises of how consulting and sales robots should \"behave\". Should they behave like human advisors and salespeople, i.e., occasionally manipulate customers? Or should they be more honest and reliable than us? This article tries to answer these questions. After explaining the basics, it evaluates a study in this context and gives recommendations for companies that want to use consulting and sales robots. Ultimately, fair, honest, and trustworthy robots in retail are a win-win situation for all concerned. ",
    "url": "https://arxiv.org/abs/2206.14571",
    "authors": [
      "Oliver Bendel",
      "Liliana Margarida Dos Santos Alves"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2206.14574",
    "title": "Knowledge Graph Fusion for Language Model Fine-tuning",
    "abstract": "Language Models such as BERT have grown in popularity due to their ability to be pre-trained and perform robustly on a wide range of Natural Language Processing tasks. Often seen as an evolution over traditional word embedding techniques, they can produce semantic representations of text, useful for tasks such as semantic similarity. However, state-of-the-art models often have high computational requirements and lack global context or domain knowledge which is required for complete language understanding. To address these limitations, we investigate the benefits of knowledge incorporation into the fine-tuning stages of BERT. An existing K-BERT model, which enriches sentences with triplets from a Knowledge Graph, is adapted for the English language and extended to inject contextually relevant information into sentences. As a side-effect, changes made to K-BERT for accommodating the English language also extend to other word-based languages. Experiments conducted indicate that injected knowledge introduces noise. We see statistically significant improvements for knowledge-driven tasks when this noise is minimised. We show evidence that, given the appropriate task, modest injection with relevant, high-quality knowledge is most performant. ",
    "url": "https://arxiv.org/abs/2206.14574",
    "authors": [
      "Nimesh Bhana",
      "Terence L. van Zyl"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14575",
    "title": "Why Robust Natural Language Understanding is a Challenge",
    "abstract": "With the proliferation of Deep Machine Learning into real-life applications, a particular property of this technology has been brought to attention: Neural Networks notoriously present low robustness and can be highly sensitive to small input perturbations. Recently, many methods for verifying networks' general properties of robustness have been proposed, but they are mostly applied in Computer Vision. In this paper we propose a Verification method for Natural Language Understanding classification based on larger regions of interest, and we discuss the challenges of such task. We observe that, although the data is almost linearly separable, the verifier does not output positive results and we explain the problems and implications. ",
    "url": "https://arxiv.org/abs/2206.14575",
    "authors": [
      "Marco Casadio",
      "Ekaterina Komendantskaya",
      "Verena Rieser",
      "Matthew L. Daggitt",
      "Daniel Kienitz",
      "Luca Arnaboldi",
      "Wen Kokke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.14597",
    "title": "Generative Anomaly Detection for Time Series Datasets",
    "abstract": "Traffic congestion anomaly detection is of paramount importance in intelligent traffic systems. The goals of transportation agencies are two-fold: to monitor the general traffic conditions in the area of interest and to locate road segments under abnormal congestion states. Modeling congestion patterns can achieve these goals for citywide roadways, which amounts to learning the distribution of multivariate time series (MTS). However, existing works are either not scalable or unable to capture the spatial-temporal information in MTS simultaneously. To this end, we propose a principled and comprehensive framework consisting of a data-driven generative approach that can perform tractable density estimation for detecting traffic anomalies. Our approach first clusters segments in the feature space and then uses conditional normalizing flow to identify anomalous temporal snapshots at the cluster level in an unsupervised setting. Then, we identify anomalies at the segment level by using a kernel density estimator on the anomalous cluster. Extensive experiments on synthetic datasets show that our approach significantly outperforms several state-of-the-art congestion anomaly detection and diagnosis methods in terms of Recall and F1-Score. We also use the generative model to sample labeled data, which can train classifiers in a supervised setting, alleviating the lack of labeled data for anomaly detection in sparse settings. ",
    "url": "https://arxiv.org/abs/2206.14597",
    "authors": [
      "Zhuangwei Kang",
      "Ayan Mukhopadhyay",
      "Aniruddha Gokhale",
      "Shijie Wen",
      "Abhishek Dubey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.14604",
    "title": "Mining Seasonal Temporal Patterns in Big Time Series",
    "abstract": "Very large time series are increasingly available from an ever wider range of IoT-enabled sensors, from which significant insights can be obtained through mining temporal patterns from them. A useful type of patterns found in many real-world applications exhibits periodic occurrences, and is thus called seasonal temporal pattern (STP). Compared to regular patterns, mining seasonal temporal patterns is more challenging since traditional measures such as support and confidence do not capture the seasonality characteristics. Further, the anti-monotonicity property does not hold for STPs, and thus, resulting in an exponential search space. This paper presents our Frequent Seasonal Temporal Pattern Mining from Time Series (FreqSTPfTS) solution providing: (1) The first solution for seasonal temporal pattern mining (STPM) from time series that can mine STP at different data granularities. (2) The STPM algorithm that uses efficient data structures and two pruning techniques to reduce the search space and speed up the mining process. (3) An approximate version of STPM that uses mutual information, a measure of data correlation, to prune unpromising time series from the search space. (4) An extensive experimental evaluation showing that STPM outperforms the baseline in runtime and memory consumption, and can scale to big datasets. The approximate STPM is up to an order of magnitude faster and less memory consuming than the baseline, while maintaining high accuracy. ",
    "url": "https://arxiv.org/abs/2206.14604",
    "authors": [
      "Van Long Ho",
      "Nguyen Ho",
      "Torben Bach Pedersen"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2206.14615",
    "title": "Quantification of Deep Neural Network Prediction Uncertainties for VVUQ  of Machine Learning Models",
    "abstract": "Recent performance breakthroughs in Artificial intelligence (AI) and Machine learning (ML), especially advances in Deep learning (DL), the availability of powerful, easy-to-use ML libraries (e.g., scikit-learn, TensorFlow, PyTorch.), and increasing computational power have led to unprecedented interest in AI/ML among nuclear engineers. For physics-based computational models, Verification, Validation and Uncertainty Quantification (VVUQ) have been very widely investigated and a lot of methodologies have been developed. However, VVUQ of ML models has been relatively less studied, especially in nuclear engineering. In this work, we focus on UQ of ML models as a preliminary step of ML VVUQ, more specifically, Deep Neural Networks (DNNs) because they are the most widely used supervised ML algorithm for both regression and classification tasks. This work aims at quantifying the prediction, or approximation uncertainties of DNNs when they are used as surrogate models for expensive physical models. Three techniques for UQ of DNNs are compared, namely Monte Carlo Dropout (MCD), Deep Ensembles (DE) and Bayesian Neural Networks (BNNs). Two nuclear engineering examples are used to benchmark these methods, (1) time-dependent fission gas release data using the Bison code, and (2) void fraction simulation based on the BFBT benchmark using the TRACE code. It was found that the three methods typically require different DNN architectures and hyperparameters to optimize their performance. The UQ results also depend on the amount of training data available and the nature of the data. Overall, all these three methods can provide reasonable estimations of the approximation uncertainties. The uncertainties are generally smaller when the mean predictions are close to the test data, while the BNN methods usually produce larger uncertainties than MCD and DE. ",
    "url": "https://arxiv.org/abs/2206.14615",
    "authors": [
      "Mahmoud Yaseen",
      "Xu Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14621",
    "title": "Extracting Weighted Finite Automata from Recurrent Neural Networks for  Natural Languages",
    "abstract": "Recurrent Neural Networks (RNNs) have achieved tremendous success in sequential data processing. However, it is quite challenging to interpret and verify RNNs' behaviors directly. To this end, many efforts have been made to extract finite automata from RNNs. Existing approaches such as exact learning are effective in extracting finite-state models to characterize the state dynamics of RNNs for formal languages, but are limited in the scalability to process natural languages. Compositional approaches that are scablable to natural languages fall short in extraction precision. In this paper, we identify the transition sparsity problem that heavily impacts the extraction precision. To address this problem, we propose a transition rule extraction approach, which is scalable to natural language processing models and effective in improving extraction precision. Specifically, we propose an empirical method to complement the missing rules in the transition diagram. In addition, we further adjust the transition matrices to enhance the context-aware ability of the extracted weighted finite automaton (WFA). Finally, we propose two data augmentation tactics to track more dynamic behaviors of the target RNN. Experiments on two popular natural language datasets show that our method can extract WFA from RNN for natural language processing with better precision than existing approaches. ",
    "url": "https://arxiv.org/abs/2206.14621",
    "authors": [
      "Zeming Wei",
      "Xiyue Zhang",
      "Meng Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14625",
    "title": "From Kernel Methods to Neural Networks: A Unifying Variational  Formulation",
    "abstract": "The minimization of a data-fidelity term and an additive regularization functional gives rise to a powerful framework for supervised learning. In this paper, we present a unifying regularization functional that depends on an operator and on a generic Radon-domain norm. We establish the existence of a minimizer and give the parametric form of the solution(s) under very mild assumptions. When the norm is Hilbertian, the proposed formulation yields a solution that involves radial-basis functions and is compatible with the classical methods of machine learning. By contrast, for the total-variation norm, the solution takes the form of a two-layer neural network with an activation function that is determined by the regularization operator. In particular, we retrieve the popular ReLU networks by letting the operator be the Laplacian. We also characterize the solution for the intermediate regularization norms $\\|\\cdot\\|=\\|\\cdot\\|_{L_p}$ with $p\\in(1,2]$. Our framework offers guarantees of universal approximation for a broad family of regularization operators or, equivalently, for a wide variety of shallow neural networks, including the cases (such as ReLU) where the activation function is increasing polynomially. It also explains the favorable role of bias and skip connections in neural architectures. ",
    "url": "https://arxiv.org/abs/2206.14625",
    "authors": [
      "Michael Unser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2206.14647",
    "title": "Meta-Wrapper: Differentiable Wrapping Operator for User Interest  Selection in CTR Prediction",
    "abstract": "Click-through rate (CTR) prediction, whose goal is to predict the probability of the user to click on an item, has become increasingly significant in the recommender systems. Recently, some deep learning models with the ability to automatically extract the user interest from his/her behaviors have achieved great success. In these work, the attention mechanism is used to select the user interested items in historical behaviors, improving the performance of the CTR predictor. Normally, these attentive modules can be jointly trained with the base predictor by using gradient descents. In this paper, we regard user interest modeling as a feature selection problem, which we call user interest selection. For such a problem, we propose a novel approach under the framework of the wrapper method, which is named Meta-Wrapper. More specifically, we use a differentiable module as our wrapping operator and then recast its learning problem as a continuous bilevel optimization. Moreover, we use a meta-learning algorithm to solve the optimization and theoretically prove its convergence. Meanwhile, we also provide theoretical analysis to show that our proposed method 1) efficiencies the wrapper-based feature selection, and 2) achieves better resistance to overfitting. Finally, extensive experiments on three public datasets manifest the superiority of our method in boosting the performance of CTR prediction. ",
    "url": "https://arxiv.org/abs/2206.14647",
    "authors": [
      "Tianwei Cao",
      "Qianqian Xu",
      "Zhiyong Yang",
      "Qingming Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.14648",
    "title": "Two-Stage Neural Contextual Bandits for Personalised News Recommendation",
    "abstract": "We consider the problem of personalised news recommendation where each user consumes news in a sequential fashion. Existing personalised news recommendation methods focus on exploiting user interests and ignores exploration in recommendation, which leads to biased feedback loops and hurt recommendation quality in the long term. We build on contextual bandits recommendation strategies which naturally address the exploitation-exploration trade-off. The main challenges are the computational efficiency for exploring the large-scale item space and utilising the deep representations with uncertainty. We propose a two-stage hierarchical topic-news deep contextual bandits framework to efficiently learn user preferences when there are many news items. We use deep learning representations for users and news, and generalise the neural upper confidence bound (UCB) policies to generalised additive UCB and bilinear UCB. Empirical results on a large-scale news recommendation dataset show that our proposed policies are efficient and outperform the baseline bandit policies. ",
    "url": "https://arxiv.org/abs/2206.14648",
    "authors": [
      "Mengyan Zhang",
      "Thanh Nguyen-Tang",
      "Fangzhao Wu",
      "Zhenyu He",
      "Xing Xie",
      "Cheng Soon Ong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14651",
    "title": "BoT-SORT: Robust Associations Multi-Pedestrian Tracking",
    "abstract": "The goal of multi-object tracking (MOT) is detecting and tracking all the objects in a scene, while keeping a unique identifier for each object. In this paper, we present a new robust state-of-the-art tracker, which can combine the advantages of motion and appearance information, along with camera-motion compensation, and a more accurate Kalman filter state vector. Our new trackers BoT-SORT, and BoT-SORT-ReID rank first in the datasets of MOTChallenge [29, 11] on both MOT17 and MOT20 test sets, in terms of all the main MOT metrics: MOTA, IDF1, and HOTA. For MOT17: 80.5 MOTA, 80.2 IDF1, and 65.0 HOTA are achieved. The source code and the pre-trained models are available at https://github.com/NirAharon/BOT-SORT ",
    "url": "https://arxiv.org/abs/2206.14651",
    "authors": [
      "Nir Aharon",
      "Roy Orfaig",
      "Ben-Zion Bobrovsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14683",
    "title": "Computer-aided diagnosis and prediction in brain disorders",
    "abstract": "Computer-aided methods have shown added value for diagnosing and predicting brain disorders and can thus support decision making in clinical care and treatment planning. This chapter will provide insight into the type of methods, their working, their input data - such as cognitive tests, imaging and genetic data - and the types of output they provide. We will focus on specific use cases for diagnosis, i.e. estimating the current 'condition' of the patient, such as early detection and diagnosis of dementia, differential diagnosis of brain tumours, and decision making in stroke. Regarding prediction, i.e. estimation of the future 'condition' of the patient, we will zoom in on use cases such as predicting the disease course in multiple sclerosis and predicting patient outcomes after treatment in brain cancer. Furthermore, based on these use cases, we will assess the current state-of-the-art methodology and highlight current efforts on benchmarking of these methods and the importance of open science therein. Finally, we assess the current clinical impact of computer-aided methods and discuss the required next steps to increase clinical impact. ",
    "url": "https://arxiv.org/abs/2206.14683",
    "authors": [
      "Vikram Venkatraghavan",
      "Sebastian R. van der Voort",
      "Daniel Bos",
      "Marion Smits",
      "Frederik Barkhof",
      "Wiro J. Niessen",
      "Stefan Klein",
      "Esther E. Bron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2206.14684",
    "title": "Smoothed Analysis of Social Choice Revisited",
    "abstract": "A canonical problem in voting theory is: which voting rule should we use to aggregate voters' preferences into a collective decision over alternatives? When applying the axiomatic approach to evaluate and compare voting rules, we are faced with prohibitive impossibilities. However, these impossibilities occur under the assumption that voters' preferences (collectively called a profile) will be worst-case with respect to the desired criterion. In this paper, we study the axiomatic approach slightly \\emph{beyond} the worst-case: we present and apply a \"smoothed\" model of the voting setting, which assumes that while inputs (profiles) may be worst-case, all inputs will be perturbed by a small amount of noise. In defining and analyzing our noise model, we do not aim to substantially technically innovate on Lirong Xia's recently-proposed smoothed model of social choice; rather, we offer an alternative model and approach to analyzing it that aims to strike a different balance of simplicity and technical generality, and to correspond closely to Spielman and Teng's (2004) original work on smoothed analysis. Within our model, we then give simple proofs of smoothed-satisfaction or smoothed-violation of several axioms and paradoxes, including most of those studied by Xia as well as some previously unstudied. Novel results include smoothed analysis of Arrow's theorem and analyses of the axioms Consistency and Independence of Irrelevant Alternatives. In independent work from a recent paper by Xia (2022), we also show the smoothed-satisfaction of coalition-based notions of Strategy-Proofness, Monotonocity, and Participation. A final, central component of our contributions are the high-level insights and future directions we identify based on this work, which we describe in detail to maximally facilitate additional research in this area. ",
    "url": "https://arxiv.org/abs/2206.14684",
    "authors": [
      "Bailey Flanigan",
      "Daniel Halpern",
      "Alexandros Psomas"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2206.14687",
    "title": "Multi-scale Physical Representations for Approximating PDE Solutions  with Graph Neural Operators",
    "abstract": "Representing physical signals at different scales is among the most challenging problems in engineering. Several multi-scale modeling tools have been developed to describe physical systems governed by \\emph{Partial Differential Equations} (PDEs). These tools are at the crossroad of principled physical models and numerical schema. Recently, data-driven models have been introduced to speed-up the approximation of PDE solutions compared to numerical solvers. Among these recent data-driven methods, neural integral operators are a class that learn a mapping between function spaces. These functions are discretized on graphs (meshes) which are appropriate for modeling interactions in physical phenomena. In this work, we study three multi-resolution schema with integral kernel operators that can be approximated with \\emph{Message Passing Graph Neural Networks} (MPGNNs). To validate our study, we make extensive MPGNNs experiments with well-chosen metrics considering steady and unsteady PDEs. ",
    "url": "https://arxiv.org/abs/2206.14687",
    "authors": [
      "L\u00e9on Migus",
      "Yuan Yin",
      "Jocelyn Ahmed Mazari",
      "Patrick Gallinari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14707",
    "title": "An Embedding Framework for the Design and Analysis of Consistent  Polyhedral Surrogates",
    "abstract": "We formalize and study the natural approach of designing convex surrogate loss functions via embeddings, for problems such as classification, ranking, or structured prediction. In this approach, one embeds each of the finitely many predictions (e.g. rankings) as a point in $R^d$, assigns the original loss values to these points, and \"convexifies\" the loss in some way to obtain a surrogate. We establish a strong connection between this approach and polyhedral (piecewise-linear convex) surrogate losses: every discrete loss is embedded by some polyhedral loss, and every polyhedral loss embeds some discrete loss. Moreover, an embedding gives rise to a consistent link function as well as linear surrogate regret bounds. Our results are constructive, as we illustrate with several examples. In particular, our framework gives succinct proofs of consistency or inconsistency for various polyhedral surrogates in the literature, and for inconsistent surrogates, it further reveals the discrete losses for which these surrogates are consistent. We go on to show additional structure of embeddings, such as the equivalence of embedding and matching Bayes risks, and the equivalence of various notions of non-redudancy. Using these results, we establish that indirect elicitation, a necessary condition for consistency, is also sufficient when working with polyhedral surrogates. ",
    "url": "https://arxiv.org/abs/2206.14707",
    "authors": [
      "Jessie Finocchiaro",
      "Rafael M. Frongillo",
      "Bo Waggoner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2206.14723",
    "title": "DrumGAN VST: A Plugin for Drum Sound Analysis/Synthesis With  Autoencoding Generative Adversarial Networks",
    "abstract": "In contemporary popular music production, drum sound design is commonly performed by cumbersome browsing and processing of pre-recorded samples in sound libraries. One can also use specialized synthesis hardware, typically controlled through low-level, musically meaningless parameters. Today, the field of Deep Learning offers methods to control the synthesis process via learned high-level features and allows generating a wide variety of sounds. In this paper, we present DrumGAN VST, a plugin for synthesizing drum sounds using a Generative Adversarial Network. DrumGAN VST operates on 44.1 kHz sample-rate audio, offers independent and continuous instrument class controls, and features an encoding neural network that maps sounds into the GAN's latent space, enabling resynthesis and manipulation of pre-existing drum sounds. We provide numerous sound examples and a demo of the proposed VST plugin. ",
    "url": "https://arxiv.org/abs/2206.14723",
    "authors": [
      "Javier Nistal",
      "Cyran Aouameur",
      "Ithan Velarde",
      "Stefan Lattner"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.14724",
    "title": "Private Graph Extraction via Feature Explanations",
    "abstract": "Privacy and interpretability are two of the important ingredients for achieving trustworthy machine learning. We study the interplay of these two aspects in graph machine learning through graph reconstruction attacks. The goal of the adversary here is to reconstruct the graph structure of the training data given access to model explanations. Based on the different kinds of auxiliary information available to the adversary, we propose several graph reconstruction attacks. We show that additional knowledge of post-hoc feature explanations substantially increases the success rate of these attacks. Further, we investigate in detail the differences between attack performance with respect to three different classes of explanation methods for graph neural networks: gradient-based, perturbation-based, and surrogate model-based methods. While gradient-based explanations reveal the most in terms of the graph structure, we find that these explanations do not always score high in utility. For the other two classes of explanations, privacy leakage increases with an increase in explanation utility. Finally, we propose a defense based on a randomized response mechanism for releasing the explanations which substantially reduces the attack success rate. Our anonymized code is available. ",
    "url": "https://arxiv.org/abs/2206.14724",
    "authors": [
      "Iyiola E. Olatunji",
      "Mandeep Rathee",
      "Thorben Funke",
      "Megha Khosla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.14729",
    "title": "longhorns at DADC 2022: How many linguists does it take to fool a  Question Answering model? A systematic approach to adversarial attacks",
    "abstract": "Developing methods to adversarially challenge NLP systems is a promising avenue for improving both model performance and interpretability. Here, we describe the approach of the team \"longhorns\" on Task 1 of the The First Workshop on Dynamic Adversarial Data Collection (DADC), which asked teams to manually fool a model on an Extractive Question Answering task. Our team finished first, with a model error rate of 62%. We advocate for a systematic, linguistically informed approach to formulating adversarial questions, and we describe the results of our pilot experiments, as well as our official submission. ",
    "url": "https://arxiv.org/abs/2206.14729",
    "authors": [
      "Venelin Kovatchev",
      "Trina Chatterjee",
      "Venkata S Govindarajan",
      "Jifan Chen",
      "Eunsol Choi",
      "Gabriella Chronis",
      "Anubrata Das",
      "Katrin Erk",
      "Matthew Lease",
      "Junyi Jessy Li",
      "Yating Wu",
      "Kyle Mahowald"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2206.14735",
    "title": "GO-Surf: Neural Feature Grid Optimization for Fast, High-Fidelity RGB-D  Surface Reconstruction",
    "abstract": "We present GO-Surf, a direct feature grid optimization method for accurate and fast surface reconstruction from RGB-D sequences. We model the underlying scene with a learned hierarchical feature voxel grid that encapsulates multi-level geometric and appearance local information. Feature vectors are directly optimized such that after being tri-linearly interpolated, decoded by two shallow MLPs into signed distance and radiance values, and rendered via surface volume rendering, the discrepancy between synthesized and observed RGB/depth values is minimized. Our supervision signals -- RGB, depth and approximate SDF -- can be obtained directly from input images without any need for fusion or post-processing. We formulate a novel SDF gradient regularization term that encourages surface smoothness and hole filling while maintaining high frequency details. GO-Surf can optimize sequences of $1$-$2$K frames in $15$-$45$ minutes, a speedup of $\\times60$ over NeuralRGB-D, the most related approach based on an MLP representation, while maintaining on par performance on standard benchmarks. Project page: https://jingwenwang95.github.io/go_surf/ ",
    "url": "https://arxiv.org/abs/2206.14735",
    "authors": [
      "Jingwen Wang",
      "Tymoteusz Bleja",
      "Lourdes Agapito"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14741",
    "title": "Modeling Teams Performance Using Deep Representational Learning on  Graphs",
    "abstract": "The large majority of human activities require collaborations within and across formal or informal teams. Our understanding of how the collaborative efforts spent by teams relate to their performance is still a matter of debate. Teamwork results in a highly interconnected ecosystem of potentially overlapping components where tasks are performed in interaction with team members and across other teams. To tackle this problem, we propose a graph neural network model designed to predict a team's performance while identifying the drivers that determine such an outcome. In particular, the model is based on three architectural channels: topological, centrality, and contextual which capture different factors potentially shaping teams' success. We endow the model with two attention mechanisms to boost model performance and allow interpretability. A first mechanism allows pinpointing key members inside the team. A second mechanism allows us to quantify the contributions of the three driver effects in determining the outcome performance. We test model performance on a wide range of domains outperforming most of the classical and neural baselines considered. Moreover, we include synthetic datasets specifically designed to validate how the model disentangles the intended properties on which our model vastly outperforms baselines. ",
    "url": "https://arxiv.org/abs/2206.14741",
    "authors": [
      "Francesco Carli",
      "Pietro Foini",
      "Nicol\u00f2 Gozzi",
      "Nicola Perra",
      "Rossano Schifanella"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14743",
    "title": "Key Factors of Wireless Real-Time Networks -- From Dependability to  Timeliness",
    "abstract": "Offering support for real-time communications on top of a wireless network infrastructure is both a hot topic and still an open challenge. Wireless networks are not on the same level of safety, dependability, and timeliness observed in the wired realm, but they are evolving towards it. Instead of focusing on the results that need to be delivered, the key factors of wireless real-time networks are on the foundation of the network operation, defining their capability of being dependable, safe, and timely on their roots. IEEE 802.15.4 and ISA100.11a are part of this context, which we show how to be strengthened. From dealing with network inaccessibility to touching the needs of reliable communication protocols to ensure the safe and sound exchange of information, this white paper describes how we can go from dependability to timeliness. This is achieved by visiting the roots of the network operation for securing the provided communication service as a dependable, safe, and timely asset for industrial automation. Keywords: Dependability, Safety, Timeliness, Resilience, Real-Time Wireless Networks, Industrial Automation. ",
    "url": "https://arxiv.org/abs/2206.14743",
    "authors": [
      "Jeferson L. R. Souza",
      "Frank Siqueira"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.14764",
    "title": "Potential Technical Debt and Its Resolution in Code Reviews: An  Exploratory Study of the OpenStack and Qt Communities",
    "abstract": "Technical Debt (TD) refers to the situation where developers make trade-offs to achieve short-term goals at the expense of long-term code quality, which can have a negative impact on the quality of software systems. In the context of code review, such sub-optimal implementations have chances to be timely resolved during the review process before the code is merged. Therefore, we could consider them as Potential Technical Debt (PTD) since PTD will evolve into TD when it is injected into software systems without being resolved. To date, little is known about the extent to which PTD is identified in code reviews. To this end, we conducted an exploratory study in an attempt to understand the nature of PTD in code reviews and track down the resolution of PTD after being identified. We randomly collected 2,030 review comments from the Nova project of OpenStack and the Qt Base project of Qt. We then manually checked these review comments, and obtained 163 PTD-related review comments for further analysis. Our results show that: (1) PTD can be identified in code reviews but is not prevalent. (2) Design, defect, documentation, requirement, test, and code PTD are identified in code reviews, in which code and documentation PTD are the dominant. (3) 81.0% of the PTD identified in code reviews has been resolved by developers, and 78.0% of the resolved TD was resolved by developers within a week. (4) Code refactoring is the main practice used by developers to resolve the PTD identified in code reviews. Our findings indicate that: (1) review-based detection of PTD is seen as one of the trustworthy mechanisms in development, and (2) there is still a significant proportion of PTD (19.0%) remaining unresolved when injected into the software systems. Practitioners and researchers should establish effective strategies to manage and resolve PTD in development. ",
    "url": "https://arxiv.org/abs/2206.14764",
    "authors": [
      "Liming Fu",
      "Peng Liang",
      "Zeeshan Rasheed",
      "Zengyang Li",
      "Amjed Tahir",
      "Xiaofeng Han"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2206.14767",
    "title": "Verified Causal Broadcast with Liquid Haskell",
    "abstract": "Protocols to ensure that messages are delivered in causal order are a ubiquitous building block of distributed systems. For instance, key-value stores can use causally ordered message delivery to ensure causal consistency -- a sweet spot in the availability/consistency trade-off space -- and replicated data structures rely on the existence of an underlying causally-ordered messaging layer to ensure that geo-distributed replicas eventually converge to the same state. A causal delivery protocol ensures that when a message is delivered to a process, any causally preceding messages sent to the same process have already been delivered to it. While causal message delivery protocols are widely used in distributed systems, verification of the correctness of those protocols is less common, much less machine-checked proofs about executable implementations. We implemented a standard causal broadcast protocol in Haskell and used the Liquid Haskell solver-aided verification system to express and mechanically prove that messages will never be delivered to a process in an order that violates causality. To do so, we express a process-local causal delivery property using refinement types, and we prove that it holds of our implementation using Liquid Haskell's theorem-proving facilities, resulting in the first machine-checked proof of correctness of an executable causal broadcast implementation. We then put our verified causal broadcast implementation to work as the foundation of a distributed key-value store implemented in Haskell. ",
    "url": "https://arxiv.org/abs/2206.14767",
    "authors": [
      "Patrick Redmond",
      "Gan Shen",
      "Niki Vazou",
      "Lindsey Kuper"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2206.14772",
    "title": "IBP Regularization for Verified Adversarial Robustness via  Branch-and-Bound",
    "abstract": "Recent works have tried to increase the verifiability of adversarially trained networks by running the attacks over domains larger than the original perturbations and adding various regularization terms to the objective. However, these algorithms either underperform or require complex and expensive stage-wise training procedures, hindering their practical applicability. We present IBP-R, a novel verified training algorithm that is both simple and effective. IBP-R induces network verifiability by coupling adversarial attacks on enlarged domains with a regularization term, based on inexpensive interval bound propagation, that minimizes the gap between the non-convex verification problem and its approximations. By leveraging recent branch-and-bound frameworks, we show that IBP-R obtains state-of-the-art verified robustness-accuracy trade-offs for small perturbations on CIFAR-10 while training significantly faster than relevant previous work. Additionally, we present UPB, a novel branching strategy that, relying on a simple heuristic based on $\\beta$-CROWN, reduces the cost of state-of-the-art branching algorithms while yielding splits of comparable quality. ",
    "url": "https://arxiv.org/abs/2206.14772",
    "authors": [
      "Alessandro De Palma",
      "Rudy Bunel",
      "Krishnamurthy Dvijotham",
      "M. Pawan Kumar",
      "Robert Stanforth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.14774",
    "title": "TweetNLP: Cutting-Edge Natural Language Processing for Social Media",
    "abstract": "In this paper we present TweetNLP, an integrated platform for Natural Language Processing (NLP) in social media. TweetNLP supports a diverse set of NLP tasks, including generic focus areas such as sentiment analysis and named entity recognition, as well as social media-specific tasks such as emoji prediction and offensive language identification. Task-specific systems are powered by reasonably-sized Transformer-based language models specialized on social media text (in particular, Twitter) which can be run without the need for dedicated hardware or cloud services. The main contributions of TweetNLP are: (1) an integrated Python library for a modern toolkit supporting social media analysis using our various task-specific models adapted to the social domain; (2) an interactive online demo for codeless experimentation using our models; and (3) a tutorial covering a wide variety of typical social media applications. ",
    "url": "https://arxiv.org/abs/2206.14774",
    "authors": [
      "Jose Camacho-Collados",
      "Kiamehr Rezaee",
      "Talayeh Riahi",
      "Asahi Ushio",
      "Daniel Loureiro",
      "Dimosthenis Antypas",
      "Joanne Boisson",
      "Luis Espinosa-Anke",
      "Fangyu Liu",
      "Eugenio Mart\u00ednez-C\u00e1mara",
      "Gonzalo Medina",
      "Thomas Buhrmann",
      "Leonardo Neves",
      "Francesco Barbieri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.14796",
    "title": "On the Robustness of Dialogue History Representation in Conversational  Question Answering: A Comprehensive Study and a New Prompt-based Method",
    "abstract": "Most works on modeling the conversation history in Conversational Question Answering (CQA) report a single main result on a common CQA benchmark. While existing models show impressive results on CQA leaderboards, it remains unclear whether they are robust to shifts in setting (sometimes to more realistic ones), training data size (e.g. from large to small sets) and domain. In this work, we design and conduct the first large-scale robustness study of history modeling approaches for CQA. We find that high benchmark scores do not necessarily translate to strong robustness, and that various methods can perform extremely differently under different settings. Equipped with the insights from our study, we design a novel prompt-based history modeling approach, and demonstrate its strong robustness across various settings. Our approach is inspired by existing methods that highlight historic answers in the passage. However, instead of highlighting by modifying the passage token embeddings, we add textual prompts directly in the passage text. Our approach is simple, easy-to-plug into practically any model, and highly effective, thus we recommend it as a starting point for future model developers. We also hope that our study and insights will raise awareness to the importance of robustness-focused evaluation, in addition to obtaining high leaderboard scores, leading to better CQA systems. ",
    "url": "https://arxiv.org/abs/2206.14796",
    "authors": [
      "Zorik Gekhman",
      "Nadav Oved",
      "Orgad Keller",
      "Idan Szpektor",
      "Roi Reichart"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14801",
    "title": "Meta-Learning over Time for Destination Prediction Tasks",
    "abstract": "A need to understand and predict vehicles' behavior underlies both public and private goals in the transportation domain, including urban planning and management, ride-sharing services, and intelligent transportation systems. Individuals' preferences and intended destinations vary throughout the day, week, and year: for example, bars are most popular in the evenings, and beaches are most popular in the summer. Despite this principle, we note that recent studies on a popular benchmark dataset from Porto, Portugal have found, at best, only marginal improvements in predictive performance from incorporating temporal information. We propose an approach based on hypernetworks, a variant of meta-learning (\"learning to learn\") in which a neural network learns to change its own weights in response to an input. In our case, the weights responsible for destination prediction vary with the metadata, in particular the time, of the input trajectory. The time-conditioned weights notably improve the model's error relative to ablation studies and comparable prior work, and we confirm our hypothesis that knowledge of time should improve prediction of a vehicle's intended destination. ",
    "url": "https://arxiv.org/abs/2206.14801",
    "authors": [
      "Mark Tenzer",
      "Zeeshan Rasheed",
      "Khurram Shafique",
      "Nuno Vasconcelos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14284",
    "title": "Optimal Estimation of Generic Dynamics by Path-Dependent Neural Jump  ODEs",
    "abstract": "This paper studies the problem of forecasting general stochastic processes using an extension of the Neural Jump ODE (NJ-ODE) framework. While NJ-ODE was the first framework to establish convergence guarantees for the prediction of irregularly observed time-series, these results were limited to data stemming from It\\^o-diffusions with complete observations, in particular Markov processes where all coordinates are observed simultaneously. In this work, we generalise these results to generic, possibly non-Markovian or discontinuous, stochastic processes with incomplete observations, by utilising the reconstruction properties of the signature transform. These theoretical results are supported by empirical studies, where it is shown that the path-dependent NJ-ODE outperforms the original NJ-ODE framework in the case of non-Markovian data. ",
    "url": "https://arxiv.org/abs/2206.14284",
    "authors": [
      "Florian Krach",
      "Marc N\u00fcbel",
      "Josef Teichmann"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2206.14357",
    "title": "Comparing Conventional Pitch Detection Algorithms with a Neural Network  Approach",
    "abstract": "Despite much research, traditional methods to pitch prediction are still not perfect. With the emergence of neural networks (NNs), researchers hope to create a NN-based pitch predictor that outperforms traditional methods. Three pitch detection algorithms (PDAs), pYIN, YAAPT, and CREPE are compared in this paper. pYIN and YAAPT are conventional approaches considering time domain and frequency domain processing. CREPE utilizes a data-trained deep convolutional neural network to estimate pitch. It involves 6 densely connected convolutional hidden layers and determines pitch probabilities for a given input signal. The performance of CREPE representing neural network pitch predictors is compared to more classical approaches represented by pYIN and YAAPT. The figure of merit (FOM) will include the amount of unvoiced-to-voiced errors, voiced-to-voiced errors, gross pitch errors, and fine pitch errors. ",
    "url": "https://arxiv.org/abs/2206.14357",
    "authors": [
      "Anja Kroon"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.14420",
    "title": "Robust optimization for quantum reinforcement learning control using  partial observations",
    "abstract": "The current quantum reinforcement learning control models often assume that the quantum states are known a priori for control optimization. However, full observation of quantum state is experimentally infeasible due to the exponential scaling of the number of required quantum measurements on the number of qubits. In this paper, we investigate a robust reinforcement learning method using partial observations to overcome this difficulty. This control scheme is compatible with near-term quantum devices, where the noise is prevalent and predetermining the dynamics of quantum state is practically impossible. We show that this simplified control scheme can achieve similar or even better performance when compared to the conventional methods relying on full observation. We demonstrate the effectiveness of this scheme on examples of quantum state control and quantum approximate optimization algorithm. It has been shown that high-fidelity state control can be achieved even if the noise amplitude is at the same level as the control amplitude. Besides, an acceptable level of optimization accuracy can be achieved for QAOA with noisy control Hamiltonian. This robust control optimization model can be trained to compensate the uncertainties in practical quantum computing. ",
    "url": "https://arxiv.org/abs/2206.14420",
    "authors": [
      "Chen Jiang",
      "Yu Pan",
      "Zheng-Guang Wu",
      "Qing Gao",
      "Daoyi Dong"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.14430",
    "title": "Social Media and Democracy",
    "abstract": "We study the ability of a social media platform with a political agenda to influence voting outcomes. Our benchmark is Condorcet's jury theorem, which states that the likelihood of a correct decision under majority voting increases with the number of voters. We show how information manipulation by a social media platform can overturn the jury theorem, thereby undermining democracy. We also show that sometimes the platform can do so only by providing information that is biased in the opposite direction of its preferred outcome. Finally, we compare manipulation of voting outcomes through social media to manipulation through traditional media. ",
    "url": "https://arxiv.org/abs/2206.14430",
    "authors": [
      "Ronen Gradwohl",
      "Yuval Heller",
      "Arye Hillman"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2206.14618",
    "title": "On the Prediction Network Architecture in RNN-T for ASR",
    "abstract": "RNN-T models have gained popularity in the literature and in commercial systems because of their competitiveness and capability of operating in online streaming mode. In this work, we conduct an extensive study comparing several prediction network architectures for both monotonic and original RNN-T models. We compare 4 types of prediction networks based on a common state-of-the-art Conformer encoder and report results obtained on Librispeech and an internal medical conversation data set. Our study covers both offline batch-mode and online streaming scenarios. In contrast to some previous works, our results show that Transformer does not always outperform LSTM when used as prediction network along with Conformer encoder. Inspired by our scoreboard, we propose a new simple prediction network architecture, N-Concat, that outperforms the others in our on-line streaming benchmark. Transformer and n-gram reduced architectures perform very similarly yet with some important distinct behaviour in terms of previous context. Overall we obtained up to 4.1 % relative WER improvement compared to our LSTM baseline, while reducing prediction network parameters by nearly an order of magnitude (8.4 times). ",
    "url": "https://arxiv.org/abs/2206.14618",
    "authors": [
      "Dario Albesano",
      "Jes\u00fas Andr\u00e9s-Ferrer",
      "Nicola Ferri",
      "Puming Zhan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.14738",
    "title": "Finding $k$-community structures in special graph classes",
    "abstract": "For a fixed integer $k\\ge 2$, a $k$-community structure in an undirected graph is a partition of its vertex set into $k$ sets (called communities), each of size at least two, such that every vertex of the graph has proportionally at least as many neighbours in its own community as in any other community. In this paper, we present a necessary and sufficient condition for a forest $F$ to admit a $k$-community structure, for any integer $k\\ge 2$. Furthermore, if such a $k$-community exists, it can be found in polynomial time. This generalises a result of Bazgan et al. (2018), who showed that all trees of size at least four, except stars, admit a $2$-community that can be found in polynomial time. We also show that, if communities are allowed to have size one, then every forest with at least $k\\geq 2$ vertices admits a $k$-community structure that can be found in polynomial time. We then consider threshold graphs and show that every such connected graph admits a $2$-community structure if and only if it is not isomorphic to a star; also, if such a $2$-community structure exists, it can be found in polynomial time. Finally, we introduce a new infinite family of connected graphs that do not admit any $2$-community structure (even if communities are allowed to have size one). Such a family was presented in Bazgan et al. (2020), but its graphs all contained an even number of vertices. The graphs in our new family may contain an even or an odd number of vertices. ",
    "url": "https://arxiv.org/abs/2206.14738",
    "authors": [
      "Narmina Baghirova",
      "Cl\u00e9ment Dallard",
      "Bernard Ries",
      "David Schindl"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2206.14794",
    "title": "LinearAlifold: Linear-Time Consensus Structure Prediction for RNA  Alignments",
    "abstract": "Predicting the consensus structure of a set of aligned RNA homologs is a convenient method to find conserved structures in an RNA genome, which has applications in SARS-CoV-2 diagnostics and therapeutics. However, the state-of-the-art algorithm for this task, RNAalifold, is prohibitively slow for long sequences, due to a cubic scaling with the sequence length, and even slower when analyzing many such sequences, due to a superlinear scaling with the number of homologs, taking 4 days on 200 SARS-CoV variants. We present LinearAlifold, an efficient algorithm for folding aligned RNA homologs that scales linearly with both the sequence length and the number of sequences, based on our recent work LinearFold that folds a single RNA in linear time. Our work is orders of magnitude faster than RNAalifold (e.g., 0.5 hours on the above 200 sequences or 316 times speedup) and achieves comparable accuracies compared to a database of known structures. More interestingly, LinearAlifold's prediction on SARS-CoV-2 correlates well with experimentally determined structures, outperforming RNAalifold. Finally, LinearAlifold supports three modes: minimum free energy (MFE), partition function, and stochastic sampling, each of which takes under an hour for hundreds of SARS-CoV variants, while only the MFE mode of RNAalifold works for them, taking days or weeks. ",
    "url": "https://arxiv.org/abs/2206.14794",
    "authors": [
      "Liang Zhang",
      "Sizhen Li",
      "He Zhang",
      "David H. Mathews",
      "Liang Huang"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Data Structures and Algorithms (cs.DS)",
      "Biological Physics (physics.bio-ph)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2206.14798",
    "title": "Generalized Permutants and Graph GENEOs",
    "abstract": "In this paper we establish a bridge between Topological Data Analysis and Geometric Deep Learning, adapting the topological theory of group equivariant non-expansive operators (GENEOs) to act on the space of all graphs weighted on vertices or edges. This is done by showing how the general concept of GENEO can be used to transform graphs and to give information about their structure. This requires the introduction of the new concepts of generalized permutant and generalized permutant measure and the mathematical proof that these concepts allow us to build GENEOs between graphs. An experimental section concludes the paper, illustrating the possible use of our operators to extract information from graphs. This paper is part of a line of research devoted to developing a compositional and geometric theory of GENEOs for Geometric Deep Learning. ",
    "url": "https://arxiv.org/abs/2206.14798",
    "authors": [
      "Faraz Ahmad",
      "Massimo Ferri",
      "Patrizio Frosini"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1711.02123",
    "title": "Consistency of Maximum Likelihood for Continuous-Space Network Models I",
    "abstract": " Comments: 17 pages ",
    "url": "https://arxiv.org/abs/1711.02123",
    "authors": [
      "Cosma Rohilla Shalizi",
      "Dena Marie Asta"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2005.01699",
    "title": "Depth-2 Neural Networks Under a Data-Poisoning Attack",
    "abstract": " Comments: 32 page, 7 figures ",
    "url": "https://arxiv.org/abs/2005.01699",
    "authors": [
      "Sayar Karmakar",
      "Anirbit Mukherjee",
      "Theodore Papamarkou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2008.01681",
    "title": "SoloGAN: Multi-domain Multimodal Unpaired Image-to-Image Translation via  a Single Generative Adversarial Network",
    "abstract": " Comments: pages 14, 15 figures ",
    "url": "https://arxiv.org/abs/2008.01681",
    "authors": [
      "Shihua Huang",
      "Cheng He",
      "Ran Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.03775",
    "title": "Geometry-based Distance Decomposition for Monocular 3D Object Detection",
    "abstract": " Comments: Accepted to ICCV 2021. Code: this https URL ",
    "url": "https://arxiv.org/abs/2104.03775",
    "authors": [
      "Xuepeng Shi",
      "Qi Ye",
      "Xiaozhi Chen",
      "Chuangrong Chen",
      "Zhixiang Chen",
      "Tae-Kyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.03726",
    "title": "Mental Models of Adversarial Machine Learning",
    "abstract": " Comments: accepted at SOUPS 2022 ",
    "url": "https://arxiv.org/abs/2105.03726",
    "authors": [
      "Lukas Bieringer",
      "Kathrin Grosse",
      "Michael Backes",
      "Battista Biggio",
      "Katharina Krombholz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.00967",
    "title": "Multiresolution Equivariant Graph Variational Autoencoder",
    "abstract": " Title: Multiresolution Equivariant Graph Variational Autoencoder ",
    "url": "https://arxiv.org/abs/2106.00967",
    "authors": [
      "Truong Son Hy",
      "Risi Kondor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2107.14229",
    "title": "Physics-informed Guided Disentanglement in Generative Networks",
    "abstract": " Comments: Journal submission ",
    "url": "https://arxiv.org/abs/2107.14229",
    "authors": [
      "Fabio Pizzati",
      "Pietro Cerri",
      "Raoul de Charette"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2108.02501",
    "title": "Locally Interpretable One-Class Anomaly Detection for Credit Card Fraud  Detection",
    "abstract": " Comments: 6 pages, 5 figures, 2 tables. Accepted to the 26th International Conference on Technologies and Applications of Artificial Intelligence (TAAI 2021). Best Paper Award ",
    "url": "https://arxiv.org/abs/2108.02501",
    "authors": [
      "Tungyu Wu",
      "Youting Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2108.06009",
    "title": "Non-imaging real-time detection and tracking of fast-moving objects  using a single-pixel detector",
    "abstract": " Title: Non-imaging real-time detection and tracking of fast-moving objects  using a single-pixel detector ",
    "url": "https://arxiv.org/abs/2108.06009",
    "authors": [
      "Fengming Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.07413",
    "title": "Cross-Image Region Mining with Region Prototypical Network for Weakly  Supervised Segmentation",
    "abstract": " Title: Cross-Image Region Mining with Region Prototypical Network for Weakly  Supervised Segmentation ",
    "url": "https://arxiv.org/abs/2108.07413",
    "authors": [
      "Weide Liu",
      "Xiangfei Kong",
      "Tzu-Yi Hung",
      "Guosheng Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.09444",
    "title": "When Do Extended Physics-Informed Neural Networks (XPINNs) Improve  Generalization?",
    "abstract": " Comments: Accepted to be published in SIAM Journal on Scientific Computing (SISC) ",
    "url": "https://arxiv.org/abs/2109.09444",
    "authors": [
      "Zheyuan Hu",
      "Ameya D. Jagtap",
      "George Em Karniadakis",
      "Kenji Kawaguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2109.10903",
    "title": "In-network Computation for Large-scale Federated Learning over Wireless  Edge Networks",
    "abstract": " Comments: This work is partly presented in arXiv:2109.10489 ",
    "url": "https://arxiv.org/abs/2109.10903",
    "authors": [
      "Thinh Quang Dinh",
      "Diep N. Nguyen",
      "Dinh Thai Hoang",
      "Pham Tran Vu",
      "Eryk Dutkiewicz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2110.01889",
    "title": "Deep Neural Networks and Tabular Data: A Survey",
    "abstract": " Title: Deep Neural Networks and Tabular Data: A Survey ",
    "url": "https://arxiv.org/abs/2110.01889",
    "authors": [
      "Vadim Borisov",
      "Tobias Leemann",
      "Kathrin Se\u00dfler",
      "Johannes Haug",
      "Martin Pawelczyk",
      "Gjergji Kasneci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.02642",
    "title": "Anomaly Transformer: Time Series Anomaly Detection with Association  Discrepancy",
    "abstract": " Title: Anomaly Transformer: Time Series Anomaly Detection with Association  Discrepancy ",
    "url": "https://arxiv.org/abs/2110.02642",
    "authors": [
      "Jiehui Xu",
      "Haixu Wu",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.03593",
    "title": "TranSalNet: Towards perceptually relevant visual saliency prediction",
    "abstract": " Comments: Source code: this https URL ",
    "url": "https://arxiv.org/abs/2110.03593",
    "authors": [
      "Jianxun Lou",
      "Hanhe Lin",
      "David Marshall",
      "Dietmar Saupe",
      "Hantao Liu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.05330",
    "title": "Edge-wise funnel output synchronization of heterogeneous agents with  relative degree one",
    "abstract": " Comments: 14 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2110.05330",
    "authors": [
      "Jin Gyu Lee",
      "Thomas Berger",
      "Stephan Trenn",
      "Hyungbo Shim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2110.08232",
    "title": "Fire Together Wire Together: A Dynamic Pruning Approach with  Self-Supervised Mask Prediction",
    "abstract": " Title: Fire Together Wire Together: A Dynamic Pruning Approach with  Self-Supervised Mask Prediction ",
    "url": "https://arxiv.org/abs/2110.08232",
    "authors": [
      "Sara Elkerdawy",
      "Mostafa Elhoushi",
      "Hong Zhang",
      "Nilanjan Ray"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.08634",
    "title": "Towards Robust Waveform-Based Acoustic Models",
    "abstract": " Title: Towards Robust Waveform-Based Acoustic Models ",
    "url": "https://arxiv.org/abs/2110.08634",
    "authors": [
      "Dino Oglic",
      "Zoran Cvetkovic",
      "Peter Sollich",
      "Steve Renals",
      "Bin Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.08191",
    "title": "CoCA-MDD: A Coupled Cross-Attention based Framework for Streaming  Mispronunciation Detection and Diagnosis",
    "abstract": " Comments: 5 pages, 4 figures, Accepted by INTERSPEECH 2022 ",
    "url": "https://arxiv.org/abs/2111.08191",
    "authors": [
      "Nianzu Zheng",
      "Liqun Deng",
      "Wenyong Huang",
      "Yu Ting Yeung",
      "Baohua Xu",
      "Yuanyuan Guo",
      "Yasheng Wang",
      "Xiao Chen",
      "Xin Jiang",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2111.10196",
    "title": "Towards Traffic Scene Description: The Semantic Scene Graph",
    "abstract": " Title: Towards Traffic Scene Description: The Semantic Scene Graph ",
    "url": "https://arxiv.org/abs/2111.10196",
    "authors": [
      "Maximilian Zipfl",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.12370",
    "title": "Uniform Convergence Rates for Lipschitz Learning on Graphs",
    "abstract": " Title: Uniform Convergence Rates for Lipschitz Learning on Graphs ",
    "url": "https://arxiv.org/abs/2111.12370",
    "authors": [
      "Leon Bungert",
      "Jeff Calder",
      "Tim Roith"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2111.12490",
    "title": "Matching Learned Causal Effects of Neural Networks with Domain Priors",
    "abstract": " Comments: Accepted at International Conference on Machine Learning (ICML'22) ",
    "url": "https://arxiv.org/abs/2111.12490",
    "authors": [
      "Sai Srinivas Kancheti",
      "Abbavaram Gowtham Reddy",
      "Vineeth N Balasubramanian",
      "Amit Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.05640",
    "title": "Fast and scalable neuroevolution deep learning architecture search for  multivariate anomaly detection",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2108.03585 ",
    "url": "https://arxiv.org/abs/2112.05640",
    "authors": [
      "M.Pietro\u0144",
      "D.\u017burek",
      "K.Faber",
      "R.Corizzo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.00058",
    "title": "Representation Topology Divergence: A Method for Comparing Neural  Network Representations",
    "abstract": " Title: Representation Topology Divergence: A Method for Comparing Neural  Network Representations ",
    "url": "https://arxiv.org/abs/2201.00058",
    "authors": [
      "Serguei Barannikov",
      "Ilya Trofimov",
      "Nikita Balabin",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11726",
    "title": "Search Trajectories Networks of Multiobjective Evolutionary Algorithms",
    "abstract": " Title: Search Trajectories Networks of Multiobjective Evolutionary Algorithms ",
    "url": "https://arxiv.org/abs/2201.11726",
    "authors": [
      "Yuri Lavinas",
      "Claus Aranha",
      "Gabriela Ochoa"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02448",
    "title": "Linear Model Against Malicious Adversaries with Local Differential  Privacy",
    "abstract": " Title: Linear Model Against Malicious Adversaries with Local Differential  Privacy ",
    "url": "https://arxiv.org/abs/2202.02448",
    "authors": [
      "Guanhong Miao",
      "A. Adam Ding",
      "Samuel S. Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.03609",
    "title": "Backdoor Detection in Reinforcement Learning",
    "abstract": " Title: Backdoor Detection in Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2202.03609",
    "authors": [
      "Junfeng Guo",
      "Ang Li",
      "Cong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.08603",
    "title": "Cross-Silo Heterogeneous Model Federated Multitask Learning",
    "abstract": " Title: Cross-Silo Heterogeneous Model Federated Multitask Learning ",
    "url": "https://arxiv.org/abs/2202.08603",
    "authors": [
      "Xingjian Cao",
      "Zonghang Li",
      "Hongfang Yu",
      "Gang Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.13903",
    "title": "Bayesian Structure Learning with Generative Flow Networks",
    "abstract": " Title: Bayesian Structure Learning with Generative Flow Networks ",
    "url": "https://arxiv.org/abs/2202.13903",
    "authors": [
      "Tristan Deleu",
      "Ant\u00f3nio G\u00f3is",
      "Chris Emezue",
      "Mansi Rankawat",
      "Simon Lacoste-Julien",
      "Stefan Bauer",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.15405",
    "title": "Automatic Detection of Speech Sound Disorder in Child Speech Using  Posterior-based Speaker Representations",
    "abstract": " Comments: Accepted to Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2203.15405",
    "authors": [
      "Si-Ioi Ng",
      "Cymie Wing-Yee Ng",
      "Jiarui Wang",
      "Tan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2203.15431",
    "title": "Investigating Self-supervised Pretraining Frameworks for Pathological  Speech Recognition",
    "abstract": " Comments: Accepted to INTERSPEECH 2022 ",
    "url": "https://arxiv.org/abs/2203.15431",
    "authors": [
      "Lester Phillip Violeta",
      "Wen-Chin Huang",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.15683",
    "title": "DRSpeech: Degradation-Robust Text-to-Speech Synthesis with Frame-Level  and Utterance-Level Acoustic Representation Learning",
    "abstract": " Comments: Accepted to INTERSPEECH 2022 ",
    "url": "https://arxiv.org/abs/2203.15683",
    "authors": [
      "Takaaki Saeki",
      "Kentaro Tachibana",
      "Ryuichi Yamamoto"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.13742",
    "title": "Twin-width and Limits of Tractability of FO Model Checking on Geometric  Graphs",
    "abstract": " Comments: technical corrections ",
    "url": "https://arxiv.org/abs/2204.13742",
    "authors": [
      "Petr Hlin\u011bn\u00fd",
      "Filip Pokr\u00fdvka"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2205.03238",
    "title": "Ultra-sensitive Flexible Sponge-Sensor Array for Muscle Activities  Detection and Human Limb Motion Recognition",
    "abstract": " Comments: 17 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2205.03238",
    "authors": [
      "Jiao Suo",
      "Yifan Liu",
      "Clio Cheng",
      "Keer Wang",
      "Meng Chen",
      "Ho-yin Chan",
      "Roy Vellaisamy",
      "Ning Xi",
      "Vivian W. Q. Lou",
      "Wen Jung Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.07890",
    "title": "On the Difficulty of Defending Self-Supervised Learning against Model  Extraction",
    "abstract": " Comments: Accepted at ICML 2022 ",
    "url": "https://arxiv.org/abs/2205.07890",
    "authors": [
      "Adam Dziedzic",
      "Nikita Dhawan",
      "Muhammad Ahmad Kaleem",
      "Jonas Guan",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.09974",
    "title": "Diagnosis and Prognosis of COVID-19 Disease Using Routine Blood Values  and LogNNet Neural Network",
    "abstract": " Comments: 28 pages, 10 figures, 12 Tables ",
    "url": "https://arxiv.org/abs/2205.09974",
    "authors": [
      "Mehmet Tahir Huyut",
      "Andrei Velichko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Medical Physics (physics.med-ph)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2205.14831",
    "title": "Temporal Multiresolution Graph Neural Networks For Epidemic Prediction",
    "abstract": " Title: Temporal Multiresolution Graph Neural Networks For Epidemic Prediction ",
    "url": "https://arxiv.org/abs/2205.14831",
    "authors": [
      "Truong Son Hy",
      "Viet Bach Nguyen",
      "Long Tran-Thanh",
      "Risi Kondor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2205.14969",
    "title": "Guided Diffusion Model for Adversarial Purification",
    "abstract": " Title: Guided Diffusion Model for Adversarial Purification ",
    "url": "https://arxiv.org/abs/2205.14969",
    "authors": [
      "Jinyi Wang",
      "Zhaoyang Lyu",
      "Dahua Lin",
      "Bo Dai",
      "Hongfei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.15466",
    "title": "Data Banzhaf: A Data Valuation Framework with Maximal Robustness to  Learning Stochasticity",
    "abstract": " Title: Data Banzhaf: A Data Valuation Framework with Maximal Robustness to  Learning Stochasticity ",
    "url": "https://arxiv.org/abs/2205.15466",
    "authors": [
      "Tianhao Wang",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.15688",
    "title": "Self-Supervised Learning for Building Damage Assessment from Large-scale  xBD Satellite Imagery Benchmark Datasets",
    "abstract": " Comments: 14 pages, 7 figures, DEXA 2022 ",
    "url": "https://arxiv.org/abs/2205.15688",
    "authors": [
      "Zaishuo Xia",
      "Zelin Li",
      "Yanbing Bai",
      "Jinze Yu",
      "Bruno Adriano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.02477",
    "title": "Optimal Stopping Theory for a Distributionally Robust Seller",
    "abstract": " Comments: Revised version that accounts for overlap with earlier work (not by the authors) ",
    "url": "https://arxiv.org/abs/2206.02477",
    "authors": [
      "Pieter Kleer",
      "Johan van Leeuwaarden"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2206.03935",
    "title": "Dual-Distribution Discrepancy for Anomaly Detection in Chest X-Rays",
    "abstract": " Comments: Early Accepted to MICCAI 2022 ",
    "url": "https://arxiv.org/abs/2206.03935",
    "authors": [
      "Yu Cai",
      "Hao Chen",
      "Xin Yang",
      "Yu Zhou",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.04310",
    "title": "GSmooth: Certified Robustness against Semantic Transformations via  Generalized Randomized Smoothing",
    "abstract": " Title: GSmooth: Certified Robustness against Semantic Transformations via  Generalized Randomized Smoothing ",
    "url": "https://arxiv.org/abs/2206.04310",
    "authors": [
      "Zhongkai Hao",
      "Chengyang Ying",
      "Yinpeng Dong",
      "Hang Su",
      "Jun Zhu",
      "Jian Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.06281",
    "title": "Cumulative culture spontaneously emerges in artificial navigators who  are social and memory-guided",
    "abstract": " Title: Cumulative culture spontaneously emerges in artificial navigators who  are social and memory-guided ",
    "url": "https://arxiv.org/abs/2206.06281",
    "authors": [
      "Edwin S. Dalmaijer"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.10397",
    "title": "Neural Moving Horizon Estimation for Robust Flight Control",
    "abstract": " Title: Neural Moving Horizon Estimation for Robust Flight Control ",
    "url": "https://arxiv.org/abs/2206.10397",
    "authors": [
      "Bingheng Wang",
      "Zhengtian Ma",
      "Shupeng Lai",
      "Lin Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.10910",
    "title": "SpA-Former: Transformer image shadow detection and removal via spatial  attention",
    "abstract": " Title: SpA-Former: Transformer image shadow detection and removal via spatial  attention ",
    "url": "https://arxiv.org/abs/2206.10910",
    "authors": [
      "Xiao Feng Zhang",
      "Chao Chen Gu",
      "Shan Ying Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.12832",
    "title": "Prediction Errors for Penalized Regressions based on Generalized  Approximate Message Passing",
    "abstract": " Comments: 69 pages, 13 figures, review paper for Journal of Physics A ",
    "url": "https://arxiv.org/abs/2206.12832",
    "authors": [
      "Ayaka Sakata"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  }
]