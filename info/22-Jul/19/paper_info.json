[
  {
    "id": "arXiv:2207.07650",
    "title": "Contrastive Brain Network Learning via Hierarchical Signed Graph Pooling  Model",
    "abstract": "Recently brain networks have been widely adopted to study brain dynamics, brain development and brain diseases. Graph representation learning techniques on brain functional networks can facilitate the discovery of novel biomarkers for clinical phenotypes and neurodegenerative diseases. However, current graph learning techniques have several issues on brain network mining. Firstly, most current graph learning models are designed for unsigned graph, which hinders the analysis of many signed network data (e.g., brain functional networks). Meanwhile, the insufficiency of brain network data limits the model performance on clinical phenotypes predictions. Moreover, few of current graph learning model is interpretable, which may not be capable to provide biological insights for model outcomes. Here, we propose an interpretable hierarchical signed graph representation learning model to extract graph-level representations from brain functional networks, which can be used for different prediction tasks. In order to further improve the model performance, we also propose a new strategy to augment functional brain network data for contrastive learning. We evaluate this framework on different classification and regression tasks using the data from HCP and OASIS. Our results from extensive experiments demonstrate the superiority of the proposed model compared to several state-of-the-art techniques. Additionally, we use graph saliency maps, derived from these prediction tasks, to demonstrate detection and interpretation of phenotypic biomarkers. ",
    "url": "https://arxiv.org/abs/2207.07650",
    "authors": [
      "Haoteng Tang",
      "Guixiang Ma",
      "Lei Guo",
      "Xiyao Fu",
      "Heng Huang",
      "Liang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2207.07656",
    "title": "FLOWGEN: Fast and slow graph generation",
    "abstract": "We present FLOWGEN, a graph-generation model inspired by the dual-process theory of mind that generates large graphs incrementally. Depending on the difficulty of completing the graph at the current step, graph generation is routed to either a fast~(weaker) or a slow~(stronger) model. fast and slow models have identical architectures, but vary in the number of parameters and consequently the strength. Experiments on real-world graphs show that ours can successfully generate graphs similar to those generated by a single large model in a fraction of time. ",
    "url": "https://arxiv.org/abs/2207.07656",
    "authors": [
      "Aman Madaan",
      "Yiming Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.07683",
    "title": "First Order Logic and Twin-Width in Tournaments and Dense Oriented  Graphs",
    "abstract": "We characterise the classes of tournaments with tractable first-order model checking. For every hereditary class of tournaments $\\mathcal T$, first-order model checking either is fixed parameter tractable, or is AW$[*]$-hard. This dichotomy coincides with the fact that $\\mathcal T$ has either bounded or unbounded twin-width, and that the growth of $\\mathcal T$ is either at most exponential or at least factorial. From the model-theoretic point of view, we show that NIP classes of tournaments coincide with bounded twin-width. Twin-width is also characterised by three infinite families of obstructions: $\\mathcal T$ has bounded twin-width if and only if it excludes one tournament from each family. This generalises results of Bonnet et al. on ordered graphs. The key for these results is a polynomial time algorithm which takes as input a tournament $T$ and compute a linear order $<$ on $V(T)$ such that the twin-width of the birelation $(T,<)$ is at most some function of the twin-width of $T$. Since approximating twin-width can be done in polynomial time for an ordered structure $(T,<)$, this provides a polytime approximation of twin-width for tournaments. Our results extend to oriented graphs with stable sets of bounded size, which may also be augmented by arbitrary binary relations. ",
    "url": "https://arxiv.org/abs/2207.07683",
    "authors": [
      "Colin Geniet",
      "St\u00e9phan Thomass\u00e9"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2207.07684",
    "title": "Node Graph Optimization Using Differentiable Proxies",
    "abstract": "Graph-based procedural materials are ubiquitous in content production industries. Procedural models allow the creation of photorealistic materials with parametric control for flexible editing of appearance. However, designing a specific material is a time-consuming process in terms of building a model and fine-tuning parameters. Previous work [Hu et al. 2022; Shi et al. 2020] introduced material graph optimization frameworks for matching target material samples. However, these previous methods were limited to optimizing differentiable functions in the graphs. In this paper, we propose a fully differentiable framework which enables end-to-end gradient based optimization of material graphs, even if some functions of the graph are non-differentiable. We leverage the Differentiable Proxy, a differentiable approximator of a non-differentiable black-box function. We use our framework to match structure and appearance of an output material to a target material, through a multi-stage differentiable optimization. Differentiable Proxies offer a more general optimization solution to material appearance matching than previous work. ",
    "url": "https://arxiv.org/abs/2207.07684",
    "authors": [
      "Yiwei Hu",
      "Paul Guerrero",
      "Milo\u0161 Ha\u0161an",
      "Holly Rushmeier",
      "Valentin Deschaintre"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2207.07696",
    "title": "Algorithmic Determination of the Combinatorial Structure of the Linear  Regions of ReLU Neural Networks",
    "abstract": "We algorithmically determine the regions and facets of all dimensions of the canonical polyhedral complex, the universal object into which a ReLU network decomposes its input space. We show that the locations of the vertices of the canonical polyhedral complex along with their signs with respect to layer maps determine the full facet structure across all dimensions. We present an algorithm which calculates this full combinatorial structure, making use of our theorems that the dual complex to the canonical polyhedral complex is cubical and it possesses a multiplication compatible with its facet structure. The resulting algorithm is numerically stable, polynomial time in the number of intermediate neurons, and obtains accurate information across all dimensions. This permits us to obtain, for example, the true topology of the decision boundaries of networks with low-dimensional inputs. We run empirics on such networks at initialization, finding that width alone does not increase observed topology, but width in the presence of depth does. Source code for our algorithms is accessible online at https://github.com/mmasden/canonicalpoly. ",
    "url": "https://arxiv.org/abs/2207.07696",
    "authors": [
      "Marissa Masden"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2207.07697",
    "title": "POET: Training Neural Networks on Tiny Devices with Integrated  Rematerialization and Paging",
    "abstract": "Fine-tuning models on edge devices like mobile phones would enable privacy-preserving personalization over sensitive data. However, edge training has historically been limited to relatively small models with simple architectures because training is both memory and energy intensive. We present POET, an algorithm to enable training large neural networks on memory-scarce battery-operated edge devices. POET jointly optimizes the integrated search search spaces of rematerialization and paging, two algorithms to reduce the memory consumption of backpropagation. Given a memory budget and a run-time constraint, we formulate a mixed-integer linear program (MILP) for energy-optimal training. Our approach enables training significantly larger models on embedded devices while reducing energy consumption while not modifying mathematical correctness of backpropagation. We demonstrate that it is possible to fine-tune both ResNet-18 and BERT within the memory constraints of a Cortex-M class embedded device while outperforming current edge training methods in energy efficiency. POET is an open-source project available at https://github.com/ShishirPatil/poet ",
    "url": "https://arxiv.org/abs/2207.07697",
    "authors": [
      "Shishir G. Patil",
      "Paras Jain",
      "Prabal Dutta",
      "Ion Stoica",
      "Joseph E. Gonzalez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.07703",
    "title": "Distributed Backlog-Aware D2D Communication for Heterogeneous IIoT  Applications",
    "abstract": "Delay and Age-of-Information (AoI) are two crucial performance metrics for emerging time-sensitive applications in Industrial Internet of Things (IIoT). In order to achieve optimal performance, studying the inherent interplay between these two parameters in non-trivial task. In this work, we consider a Device-to-Device (D2D)-based heterogeneous IIoT network that supports two types of traffic flows, namely AoI-orientated. First, we introduce a distributed backlog-aware random access protocol that allows the AoI-orientated nodes to opportunistically access the channel based on the queue occupancy of the delay-oriented node. Then, we develop an analytical framework to evaluate the average delay and the average AoI, and formulate an optimization problem to minimize the AoI under a given delay constraint. Finally, we provide numerical results to demonstrate the impact of different network parameters on the performance in terms of the average delay and the average AoI. We also give the numerical solutions of the optimal parameters that minimize the AoI subject to a delay constraint. ",
    "url": "https://arxiv.org/abs/2207.07703",
    "authors": [
      "Hossam Farag",
      "Cedomir Stefanovic",
      "Mikael Gidlund"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.07704",
    "title": "Maximizing Fair Content Spread via Edge Suggestion in Social Networks",
    "abstract": "Content spread inequity is a potential unfairness issue in online social networks, disparately impacting minority groups. In this paper, we view friendship suggestion, a common feature in social network platforms, as an opportunity to achieve an equitable spread of content. In particular, we propose to suggest a subset of potential edges (currently not existing in the network but likely to be accepted) that maximizes content spread while achieving fairness. Instead of re-engineering the existing systems, our proposal builds a fairness wrapper on top of the existing friendship suggestion components. We prove the problem is NP-hard and inapproximable in polynomial time unless P = NP. Therefore, allowing relaxation of the fairness constraint, we propose an algorithm based on LP-relaxation and randomized rounding with fixed approximation ratios on fairness and content spread. We provide multiple optimizations, further improving the performance of our algorithm in practice. Besides, we propose a scalable algorithm that dynamically adds subsets of nodes, chosen via iterative sampling, and solves smaller problems corresponding to these nodes. Besides theoretical analysis, we conduct comprehensive experiments on real and synthetic data sets. Across different settings, our algorithms found solutions with nearzero unfairness while significantly increasing the content spread. Our scalable algorithm could process a graph with half a million nodes on a single machine, reducing the unfairness to around 0.0004 while lifting content spread by 43%. ",
    "url": "https://arxiv.org/abs/2207.07704",
    "authors": [
      "Ian P. Swift",
      "Sana Ebrahmi",
      "Azade Nova",
      "Abolfazl Asudeh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.07706",
    "title": "Probing Semantic Grounding in Language Models of Code with  Representational Similarity Analysis",
    "abstract": "Representational Similarity Analysis is a method from cognitive neuroscience, which helps in comparing representations from two different sources of data. In this paper, we propose using Representational Similarity Analysis to probe the semantic grounding in language models of code. We probe representations from the CodeBERT model for semantic grounding by using the data from the IBM CodeNet dataset. Through our experiments, we show that current pre-training methods do not induce semantic grounding in language models of code, and instead focus on optimizing form-based patterns. We also show that even a little amount of fine-tuning on semantically relevant tasks increases the semantic grounding in CodeBERT significantly. Our ablations with the input modality to the CodeBERT model show that using bimodal inputs (code and natural language) over unimodal inputs (only code) gives better semantic grounding and sample efficiency during semantic fine-tuning. Finally, our experiments with semantic perturbations in code reveal that CodeBERT is able to robustly distinguish between semantically correct and incorrect code. ",
    "url": "https://arxiv.org/abs/2207.07706",
    "authors": [
      "Shounak Naik",
      "Rajaswa Patil",
      "Swati Agarwal",
      "Veeky Baths"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2207.07708",
    "title": "Approximating Highly Inapproximable Problems on Graphs of Bounded  Twin-Width",
    "abstract": "For any $\\varepsilon > 0$, we give a polynomial-time $n^\\varepsilon$-approximation algorithm for Max Independent Set in graphs of bounded twin-width given with an $O(1)$-sequence. This result is derived from the following time-approximation trade-off: We establish an $O(1)^{2^q-1}$-approximation algorithm running in time $\\exp(O_q(n^{2^{-q}}))$, for every integer $q \\geqslant 0$. Guided by the same framework, we obtain similar approximation algorithms for Min Coloring and Max Induced Matching. In general graphs, all these problems are known to be highly inapproximable: for any $\\varepsilon > 0$, a polynomial-time $n^{1-\\varepsilon}$-approximation for any of them would imply that P$=$NP [Hastad, FOCS '96; Zuckerman, ToC '07; Chalermsook et al., SODA '13]. We generalize the algorithms for Max Independent Set and Max Induced Matching to the independent (induced) packing of any fixed connected graph $H$. In contrast, we show that such approximation guarantees on graphs of bounded twin-width given with an $O(1)$-sequence are very unlikely for Min Independent Dominating Set, and somewhat unlikely for Longest Path and Longest Induced Path. Regarding the existence of better approximation algorithms, there is a (very) light evidence that the obtained approximation factor of $n^\\varepsilon$ for Max Independent Set may be best possible. This is the first in-depth study of the approximability of problems in graphs of bounded twin-width. Prior to this paper, essentially the only such result was a~polynomial-time $O(1)$-approximation algorithm for Min Dominating Set [Bonnet et al., ICALP '21]. ",
    "url": "https://arxiv.org/abs/2207.07708",
    "authors": [
      "Pierre Berg\u00e9",
      "\u00c9douard Bonnet",
      "Hugues D\u00e9pr\u00e9s",
      "R\u00e9mi Watrigant"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2207.07719",
    "title": "Temporal Forward-Backward Consistency, Not Residual Error, Measures the  Prediction Accuracy of Extended Dynamic Mode Decomposition",
    "abstract": "Extended Dynamic Mode Decomposition (EDMD) is a popular data-driven method to approximate the action of the Koopman operator on a linear function space spanned by a dictionary of functions. The accuracy of EDMD model critically depends on the quality of the particular dictionary's span, specifically on how close it is to being invariant under the Koopman operator. Motivated by the observation that the residual error of EDMD, typically used for dictionary learning, does not encode the quality of the function space and is sensitive to the choice of basis, we introduce the novel concept of consistency index. We show that this measure, based on using EDMD forward and backward in time, enjoys a number of desirable qualities that make it suitable for data-driven modeling of dynamical systems: it measures the quality of the function space, it is invariant under the choice of basis, can be computed in closed form from the data, and provides a tight upper-bound for the relative root mean square error of all function predictions on the entire span of the dictionary. ",
    "url": "https://arxiv.org/abs/2207.07719",
    "authors": [
      "Masih Haseli",
      "Jorge Cort\u00e9s"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2207.07721",
    "title": "FLIP: A Utility Preserving Privacy Mechanism for Time Series",
    "abstract": "Guaranteeing privacy in released data is an important goal for data-producing agencies. There has been extensive research on developing suitable privacy mechanisms in recent years. Particularly notable is the idea of noise addition with the guarantee of differential privacy. There are, however, concerns about compromising data utility when very stringent privacy mechanisms are applied. Such compromises can be quite stark in correlated data, such as time series data. Adding white noise to a stochastic process may significantly change the correlation structure, a facet of the process that is essential to optimal prediction. We propose the use of all-pass filtering as a privacy mechanism for regularly sampled time series data, showing that this procedure preserves utility while also providing sufficient privacy guarantees to entity-level time series. ",
    "url": "https://arxiv.org/abs/2207.07721",
    "authors": [
      "Tucker McElroy",
      "Anindya Roy",
      "Gaurab Hore"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2207.07731",
    "title": "Distributed Learning of Neural Lyapunov Functions for Large-Scale  Networked Dissipative Systems",
    "abstract": "This paper considers the problem of characterizing the stability region of a large-scale networked system comprised of dissipative nonlinear subsystems, in a distributed and computationally tractable way. One standard approach to estimate the stability region of a general nonlinear system is to first find a Lyapunov function for the system and characterize its region of attraction as the stability region. However, classical approaches, such as sum-of-squares methods and quadratic approximation, for finding a Lyapunov function either do not scale to large systems or give very conservative estimates for the stability region. In this context, we propose a new distributed learning based approach by exploiting the dissipativity structure of the subsystems. Our approach has two parts: the first part is a distributed approach to learn the storage functions (similar to the Lyapunov functions) for all the subsystems, and the second part is a distributed optimization approach to find the Lyapunov function for the networked system using the learned storage functions of the subsystems. We demonstrate the superior performance of our proposed approach through extensive case studies in microgrid networks. ",
    "url": "https://arxiv.org/abs/2207.07731",
    "authors": [
      "Amit Jena",
      "Tong Huang",
      "S. Sivaranjani",
      "Dileep Kalathil",
      "Le Xie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07739",
    "title": "Adversarial Focal Loss: Asking Your Discriminator for Hard Examples",
    "abstract": "Focal Loss has reached incredible popularity as it uses a simple technique to identify and utilize hard examples to achieve better performance on classification. However, this method does not easily generalize outside of classification tasks, such as in keypoint detection. In this paper, we propose a novel adaptation of Focal Loss for keypoint detection tasks, called Adversarial Focal Loss (AFL). AFL not only is semantically analogous to Focal loss, but also works as a plug-and-chug upgrade for arbitrary loss functions. While Focal Loss requires output from a classifier, AFL leverages a separate adversarial network to produce a difficulty score for each input. This difficulty score can then be used to dynamically prioritize learning on hard examples, even in absence of a classifier. In this work, we show AFL's effectiveness in enhancing existing methods in keypoint detection and verify its capability to re-weigh examples based on difficulty. ",
    "url": "https://arxiv.org/abs/2207.07739",
    "authors": [
      "Chen Liu",
      "Xiaomeng Dong",
      "Michael Potter",
      "Hsi-Ming Chang",
      "Ravi Soni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07740",
    "title": "Knowledge Representation in Digital Agriculture: A Step Towards  Standardised Model",
    "abstract": "In recent years, data science has evolved significantly. Data analysis and mining processes become routines in all sectors of the economy where datasets are available. Vast data repositories have been collected, curated, stored, and used for extracting knowledge. And this is becoming commonplace. Subsequently, we extract a large amount of knowledge, either directly from the data or through experts in the given domain. The challenge now is how to exploit all this large amount of knowledge that is previously known for efficient decision-making processes. Until recently, much of the knowledge gained through a number of years of research is stored in static knowledge bases or ontologies, while more diverse and dynamic knowledge acquired from data mining studies is not centrally and consistently managed. In this research, we propose a novel model called ontology-based knowledge map to represent and store the results (knowledge) of data mining in crop farming to build, maintain, and enrich the process of knowledge discovery. The proposed model consists of six main sets: concepts, attributes, relations, transformations, instances, and states. This model is dynamic and facilitates the access, updates, and exploitation of the knowledge at any time. This paper also proposes an architecture for handling this knowledge-based model. The system architecture includes knowledge modelling, extraction, assessment, publishing, and exploitation. This system has been implemented and used in agriculture for crop management and monitoring. It is proven to be very effective and promising for its extension to other domains. ",
    "url": "https://arxiv.org/abs/2207.07740",
    "authors": [
      "Quoc Hung Ngo",
      "Tahar Kechadi",
      "Nhien-An Le-Khac"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.07742",
    "title": "Human keypoint detection for close proximity human-robot interaction",
    "abstract": "We study the performance of state-of-the-art human keypoint detectors in the context of close proximity human-robot interaction. The detection in this scenario is specific in that only a subset of body parts such as hands and torso are in the field of view. In particular, (i) we survey existing datasets with human pose annotation from the perspective of close proximity images and prepare and make publicly available a new Human in Close Proximity (HiCP) dataset; (ii) we quantitatively and qualitatively compare state-of-the-art human whole-body 2D keypoint detection methods (OpenPose, MMPose, AlphaPose, Detectron2) on this dataset; (iii) since accurate detection of hands and fingers is critical in applications with handovers, we evaluate the performance of the MediaPipe hand detector; (iv) we deploy the algorithms on a humanoid robot with an RGB-D camera on its head and evaluate the performance in 3D human keypoint detection. A motion capture system is used as reference. The best performing whole-body keypoint detectors in close proximity were MMPose and AlphaPose, but both had difficulty with finger detection. Thus, we propose a combination of MMPose or AlphaPose for the body and MediaPipe for the hands in a single framework providing the most accurate and robust detection. We also analyse the failure modes of individual detectors -- for example, to what extent the absence of the head of the person in the image degrades performance. Finally, we demonstrate the framework in a scenario where a humanoid robot interacting with a person uses the detected 3D keypoints for whole-body avoidance maneuvers. ",
    "url": "https://arxiv.org/abs/2207.07742",
    "authors": [
      "Jan Docekal",
      "Jakub Rozlivek",
      "Jiri Matas",
      "Matej Hoffmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.07743",
    "title": "HOME: High-Order Mixed-Moment-based Embedding for Representation  Learning",
    "abstract": "Minimum redundancy among different elements of an embedding in a latent space is a fundamental requirement or major preference in representation learning to capture intrinsic informational structures. Current self-supervised learning methods minimize a pair-wise covariance matrix to reduce the feature redundancy and produce promising results. However, such representation features of multiple variables may contain the redundancy among more than two feature variables that cannot be minimized via the pairwise regularization. Here we propose the High-Order Mixed-Moment-based Embedding (HOME) strategy to reduce the redundancy between any sets of feature variables, which is to our best knowledge the first attempt to utilize high-order statistics/information in this context. Multivariate mutual information is minimum if and only if multiple variables are mutually independent, which suggests the necessary conditions of factorized mixed moments among multiple variables. Based on these statistical and information theoretic principles, our general HOME framework is presented for self-supervised representation learning. Our initial experiments show that a simple version in the form of a three-order HOME scheme already significantly outperforms the current two-order baseline method (i.e., Barlow Twins) in terms of the linear evaluation on representation features. ",
    "url": "https://arxiv.org/abs/2207.07743",
    "authors": [
      "Chuang Niu",
      "Ge Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07745",
    "title": "GLIN: A Lightweight Learned Indexing Mechanism for Complex Geometries",
    "abstract": "Although spatial index structures shorten the query response time, they rely on complex tree structures to narrow down the search space. Such structures in turn yield additional storage overhead and take a toll on index maintenance. Recently, there has been a flurry on works attempting to leverage machine-Learning(ML) models to simplify the index structures. Some follow-up works extend the idea to support geospatial point data. These approaches partition the multidimensional space to cells and assign IDs to these cells using space-filling curve(e.g., Z-order curve) or mathematical equations. These approaches work well for geospatial points but are not able to handle complex geometries such as polygons and trajectories which are widely available in geospatial data. This paper introduces GLIN, a lightweight learned index for spatial range queries on complex geometries. To achieve that, GLIN transforms geometries to Z-address intervals, and builds a hierarchical model to learn the cumulative distribution function between these intervals and the record positions. The lightweight hierarchical model greatly shortens the index probing time. Furthermore, GLIN augments spatial query windows using an add-on function to guarantee the query accuracy for both Contains and Intersects spatial relationships. Our experiments on real-world and synthetic datasets show that GLIN occupies 40-70 times less storage overhead than popular spatial indexes such as Quad-Tree while still showing similar query response time in medium selectivity queries. Moreover, GLIN's maintenance speed is around 1.5 times higher on insertion and 3-5 times higher on deletion. ",
    "url": "https://arxiv.org/abs/2207.07745",
    "authors": [
      "Congying Wang",
      "Jia Yu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2207.07749",
    "title": "Bootstrap State Representation using Style Transfer for Better  Generalization in Deep Reinforcement Learning",
    "abstract": "Deep Reinforcement Learning (RL) agents often overfit the training environment, leading to poor generalization performance. In this paper, we propose Thinker, a bootstrapping method to remove adversarial effects of confounding features from the observation in an unsupervised way, and thus, it improves RL agents' generalization. Thinker first clusters experience trajectories into several clusters. These trajectories are then bootstrapped by applying a style transfer generator, which translates the trajectories from one cluster's style to another while maintaining the content of the observations. The bootstrapped trajectories are then used for policy learning. Thinker has wide applicability among many RL settings. Experimental results reveal that Thinker leads to better generalization capability in the Procgen benchmark environments compared to base algorithms and several data augmentation techniques. ",
    "url": "https://arxiv.org/abs/2207.07749",
    "authors": [
      "Md Masudur Rahman",
      "Yexiang Xue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.07774",
    "title": "BDPC: Controlling Application Delay in the Industrial Internet of Things  for 6TiSCH networks",
    "abstract": "One of the essential requirements of the Industrial Internet of Things (IIoT), is to have an extremely high packet delivery rate, generally over 99.9\\%. However, packets which arrive after a predefined deadline shall be considered lost too. Industrial applications require a predictable delay. To solve this problem, we propose a new mechanism, called BDPC (Bounded Delay Packet Control). BDPC combines the knowledge of a node's delay to its root with the time budget of a data packet traversing the IoT network, to allocate cells in 6TiSCH slotFrames in order to fulfill the application's maximum delay requirements in a controlled manner: the application packets must arrive before the deadline, but not faster. This is achieved by allocating cells from a parent node to a child node, thereby adapting the cell capacity and attaining the bounded delay goal, by the analysis of the new variable $latePaqs$. In other words, the resource allocation is a function of $latePaqs$. Moreover, the number of packets arriving after the predefined deadline can be controlled by two thresholds: sfMax and sfMin. Our results show that using BDPC, the number of packets arriving before the deadline can be improved more than 2.6 times compared to the case when using the default Minimal Scheduling Function from the standard. As a further advantage, BDPC involves minor modifications to the 6TiSCH protocol stack, which makes it compatible with current implementations. ",
    "url": "https://arxiv.org/abs/2207.07774",
    "authors": [
      "Lucas Aimaretto",
      "Diego Dujovne"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.07783",
    "title": "Learning Long-Term Spatial-Temporal Graphs for Active Speaker Detection",
    "abstract": "Active speaker detection (ASD) in videos with multiple speakers is a challenging task as it requires learning effective audiovisual features and spatial-temporal correlations over long temporal windows. In this paper, we present SPELL, a novel spatial-temporal graph learning framework that can solve complex tasks such as ASD. To this end, each person in a video frame is first encoded in a unique node for that frame. Nodes corresponding to a single person across frames are connected to encode their temporal dynamics. Nodes within a frame are also connected to encode inter-person relationships. Thus, SPELL reduces ASD to a node classification task. Importantly, SPELL is able to reason over long temporal contexts for all nodes without relying on computationally expensive fully connected graph neural networks. Through extensive experiments on the AVA-ActiveSpeaker dataset, we demonstrate that learning graph-based representations can significantly improve the active speaker detection performance owing to its explicit spatial and temporal structure. SPELL outperforms all previous state-of-the-art approaches while requiring significantly lower memory and computational resources. Our code is publicly available at https://github.com/SRA2/SPELL ",
    "url": "https://arxiv.org/abs/2207.07783",
    "authors": [
      "Kyle Min",
      "Sourya Roy",
      "Subarna Tripathi",
      "Tanaya Guha",
      "Somdeb Majumdar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07793",
    "title": "Towards the Desirable Decision Boundary by Moderate-Margin Adversarial  Training",
    "abstract": "Adversarial training, as one of the most effective defense methods against adversarial attacks, tends to learn an inclusive decision boundary to increase the robustness of deep learning models. However, due to the large and unnecessary increase in the margin along adversarial directions, adversarial training causes heavy cross-over between natural examples and adversarial examples, which is not conducive to balancing the trade-off between robustness and natural accuracy. In this paper, we propose a novel adversarial training scheme to achieve a better trade-off between robustness and natural accuracy. It aims to learn a moderate-inclusive decision boundary, which means that the margins of natural examples under the decision boundary are moderate. We call this scheme Moderate-Margin Adversarial Training (MMAT), which generates finer-grained adversarial examples to mitigate the cross-over problem. We also take advantage of logits from a teacher model that has been well-trained to guide the learning of our model. Finally, MMAT achieves high natural accuracy and robustness under both black-box and white-box attacks. On SVHN, for example, state-of-the-art robustness and natural accuracy are achieved. ",
    "url": "https://arxiv.org/abs/2207.07793",
    "authors": [
      "Xiaoyu Liang",
      "Yaguan Qian",
      "Jianchang Huang",
      "Xiang Ling",
      "Bin Wang",
      "Chunming Wu",
      "Wassim Swaileh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07795",
    "title": "RCRN: Real-world Character Image Restoration Network via Skeleton  Extraction",
    "abstract": "Constructing high-quality character image datasets is challenging because real-world images are often affected by image degradation. There are limitations when applying current image restoration methods to such real-world character images, since (i) the categories of noise in character images are different from those in general images; (ii) real-world character images usually contain more complex image degradation, e.g., mixed noise at different noise levels. To address these problems, we propose a real-world character restoration network (RCRN) to effectively restore degraded character images, where character skeleton information and scale-ensemble feature extraction are utilized to obtain better restoration performance. The proposed method consists of a skeleton extractor (SENet) and a character image restorer (CiRNet). SENet aims to preserve the structural consistency of the character and normalize complex noise. Then, CiRNet reconstructs clean images from degraded character images and their skeletons. Due to the lack of benchmarks for real-world character image restoration, we constructed a dataset containing 1,606 character images with real-world degradation to evaluate the validity of the proposed method. The experimental results demonstrate that RCRN outperforms state-of-the-art methods quantitatively and qualitatively. ",
    "url": "https://arxiv.org/abs/2207.07795",
    "authors": [
      "Daqian Shi",
      "Xiaolei Diao",
      "Hao Tang",
      "Xiaomin Li",
      "Hao Xing",
      "Hao Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07797",
    "title": "CARBEN: Composite Adversarial Robustness Benchmark",
    "abstract": "Prior literature on adversarial attack methods has mainly focused on attacking with and defending against a single threat model, e.g., perturbations bounded in Lp ball. However, multiple threat models can be combined into composite perturbations. One such approach, composite adversarial attack (CAA), not only expands the perturbable space of the image, but also may be overlooked by current modes of robustness evaluation. This paper demonstrates how CAA's attack order affects the resulting image, and provides real-time inferences of different models, which will facilitate users' configuration of the parameters of the attack level and their rapid evaluation of model prediction. A leaderboard to benchmark adversarial robustness against CAA is also introduced. ",
    "url": "https://arxiv.org/abs/2207.07797",
    "authors": [
      "Lei Hsiung",
      "Yun-Yun Tsai",
      "Pin-Yu Chen",
      "Tsung-Yi Ho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2207.07806",
    "title": "CHARM: A Hierarchical Deep Learning Model for Classification of Complex  Human Activities Using Motion Sensors",
    "abstract": "In this paper, we report a hierarchical deep learning model for classification of complex human activities using motion sensors. In contrast to traditional Human Activity Recognition (HAR) models used for event-based activity recognition, such as step counting, fall detection, and gesture identification, this new deep learning model, which we refer to as CHARM (Complex Human Activity Recognition Model), is aimed for recognition of high-level human activities that are composed of multiple different low-level activities in a non-deterministic sequence, such as meal preparation, house chores, and daily routines. CHARM not only quantitatively outperforms state-of-the-art supervised learning approaches for high-level activity recognition in terms of average accuracy and F1 scores, but also automatically learns to recognize low-level activities, such as manipulation gestures and locomotion modes, without any explicit labels for such activities. This opens new avenues for Human-Machine Interaction (HMI) modalities using wearable sensors, where the user can choose to associate an automated task with a high-level activity, such as controlling home automation (e.g., robotic vacuum cleaners, lights, and thermostats) or presenting contextually relevant information at the right time (e.g., reminders, status updates, and weather/news reports). In addition, the ability to learn low-level user activities when trained using only high-level activity labels may pave the way to semi-supervised learning of HAR tasks that are inherently difficult to label. ",
    "url": "https://arxiv.org/abs/2207.07806",
    "authors": [
      "Eric Rosen",
      "Doruk Senkal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.07811",
    "title": "Model order reduction for parameterized electromagnetic problems using  matrix decomposition and deep neural networks",
    "abstract": "A non-intrusive model order reduction (MOR) method for solving parameterized electromagnetic scattering problems is proposed in this paper. A database collecting snapshots of high-fidelity solutions is built by solving the parameterized time-domain Maxwell equations for some values of the material parameters using a fullwave solver based on a high order discontinuous Galerkin time-domain (DGTD) method. To perform a prior dimensionality reduction, a set of reduced basis (RB) functions are extracted from the database via a two-step proper orthogonal decomposition (POD) method. Projection coefficients of the reduced basis functions are further compressed through a convolutional autoencoder (CAE) network. Singular value decomposition (SVD) is then used to extract the principal components of the reduced-order matrices generated by CAE, and a cubic spline interpolation-based (CSI) approach is employed for approximating the dominating time- and parameter-modes of the reduced-order matrices. The generation of the reduced basis and the training of the CAE and CSI are accomplished in the offline stage, thus the RB solution for given time/parameter values can be quickly recovered via outputs of the interpolation model and decoder network. In particular, the offline and online stages of the proposed RB method are completely decoupled, which ensures the validity of the method. The performance of the proposed CAE-CSI ROM is illustrated with numerical experiments for scattering of a plane wave by a 2-D dielectric disk and a multi-layer heterogeneous medium. ",
    "url": "https://arxiv.org/abs/2207.07811",
    "authors": [
      "Xiao-Feng He",
      "Liang Li",
      "Stephane Lanteri",
      "Kun Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.07815",
    "title": "Self-calibrating Photometric Stereo by Neural Inverse Rendering",
    "abstract": "This paper tackles the task of uncalibrated photometric stereo for 3D object reconstruction, where both the object shape, object reflectance, and lighting directions are unknown. This is an extremely difficult task, and the challenge is further compounded with the existence of the well-known generalized bas-relief (GBR) ambiguity in photometric stereo. Previous methods to resolve this ambiguity either rely on an overly simplified reflectance model, or assume special light distribution. We propose a new method that jointly optimizes object shape, light directions, and light intensities, all under general surfaces and lights assumptions. The specularities are used explicitly to solve uncalibrated photometric stereo via a neural inverse rendering process. We gradually fit specularities from shiny to rough using novel progressive specular bases. Our method leverages a physically based rendering equation by minimizing the reconstruction error on a per-object-basis. Our method demonstrates state-of-the-art accuracy in light estimation and shape recovery on real-world datasets. ",
    "url": "https://arxiv.org/abs/2207.07815",
    "authors": [
      "Junxuan Li",
      "Hongdong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07816",
    "title": "Sotto Voce: Federated Speech Recognition with Differential Privacy  Guarantees",
    "abstract": "Speech data is expensive to collect, and incredibly sensitive to its sources. It is often the case that organizations independently collect small datasets for their own use, but often these are not performant for the demands of machine learning. Organizations could pool these datasets together and jointly build a strong ASR system; sharing data in the clear, however, comes with tremendous risk, in terms of intellectual property loss as well as loss of privacy of the individuals who exist in the dataset. In this paper, we offer a potential solution for learning an ML model across multiple organizations where we can provide mathematical guarantees limiting privacy loss. We use a Federated Learning approach built on a strong foundation of Differential Privacy techniques. We apply these to a senone classification prototype and demonstrate that the model improves with the addition of private data while still respecting privacy. ",
    "url": "https://arxiv.org/abs/2207.07816",
    "authors": [
      "Michael Shoemate",
      "Kevin Jett",
      "Ethan Cowan",
      "Sean Colbath",
      "James Honaker",
      "Prasanna Muthukumar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.07822",
    "title": "Adaptive Sketches for Robust Regression with Importance Sampling",
    "abstract": "We introduce data structures for solving robust regression through stochastic gradient descent (SGD) by sampling gradients with probability proportional to their norm, i.e., importance sampling. Although SGD is widely used for large scale machine learning, it is well-known for possibly experiencing slow convergence rates due to the high variance from uniform sampling. On the other hand, importance sampling can significantly decrease the variance but is usually difficult to implement because computing the sampling probabilities requires additional passes over the data, in which case standard gradient descent (GD) could be used instead. In this paper, we introduce an algorithm that approximately samples $T$ gradients of dimension $d$ from nearly the optimal importance sampling distribution for a robust regression problem over $n$ rows. Thus our algorithm effectively runs $T$ steps of SGD with importance sampling while using sublinear space and just making a single pass over the data. Our techniques also extend to performing importance sampling for second-order optimization. ",
    "url": "https://arxiv.org/abs/2207.07822",
    "authors": [
      "Sepideh Mahabadi",
      "David P. Woodruff",
      "Samson Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2207.07828",
    "title": "Structural Prior Guided Generative Adversarial Transformers for  Low-Light Image Enhancement",
    "abstract": "We propose an effective Structural Prior guided Generative Adversarial Transformer (SPGAT) to solve low-light image enhancement. Our SPGAT mainly contains a generator with two discriminators and a structural prior estimator (SPE). The generator is based on a U-shaped Transformer which is used to explore non-local information for better clear image restoration. The SPE is used to explore useful structures from images to guide the generator for better structural detail estimation. To generate more realistic images, we develop a new structural prior guided adversarial learning method by building the skip connections between the generator and discriminators so that the discriminators can better discriminate between real and fake features. Finally, we propose a parallel windows-based Swin Transformer block to aggregate different level hierarchical features for high-quality image restoration. Experimental results demonstrate that the proposed SPGAT performs favorably against recent state-of-the-art methods on both synthetic and real-world datasets. ",
    "url": "https://arxiv.org/abs/2207.07828",
    "authors": [
      "Cong Wang",
      "Jinshan Pan",
      "Xiao-Ming Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.07829",
    "title": "Robust AI Driving Strategy for Autonomous Vehicles",
    "abstract": "There has been significant progress in sensing, perception, and localization for automated driving, However, due to the wide spectrum of traffic/road structure scenarios and the long tail distribution of human driver behavior, it has remained an open challenge for an intelligent vehicle to always know how to make and execute the best decision on road given available sensing / perception / localization information. In this chapter, we talk about how artificial intelligence and more specifically, reinforcement learning, can take advantage of operational knowledge and safety reflex to make strategical and tactical decisions. We discuss some challenging problems related to the robustness of reinforcement learning solutions and their implications to the practical design of driving strategies for autonomous vehicles. We focus on automated driving on highway and the integration of reinforcement learning, vehicle motion control, and control barrier function, leading to a robust AI driving strategy that can learn and adapt safely. ",
    "url": "https://arxiv.org/abs/2207.07829",
    "authors": [
      "Subramanya Nageshrao",
      "Yousaf Rahman",
      "Vladimir Ivanovic",
      "Mrdjan Jankovic",
      "Eric Tseng",
      "Michael Hafner",
      "Dimitar Filev"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.07830",
    "title": "Profit Maximization using Social Networks in Two-Phase Setting",
    "abstract": "Now-a-days, \\emph{Online Social Networks} have been predominantly used by commercial houses for viral marketing where the goal is to maximize profit. In this paper, we study the problem of Profit Maximization in the two\\mbox{-}phase setting. The input to the problem is a \\emph{social network} where the users are associated with a cost and benefit value, and a fixed amount of budget splitted into two parts. Here, the cost and the benefit associated with a node signify its incentive demand and the amount of benefit that can be earned by influencing that user, respectively. The goal of this problem is to find out the optimal seed sets for both phases such that the aggregated profit at the end of the diffusion process is maximized. First, we develop a mathematical model based on the \\emph{Independent Cascade Model} of diffusion that captures the aggregated profit in an \\emph{expected} sense. Subsequently, we show that selecting an optimal seed set for the first phase even considering the optimal seed set for the second phase can be selected efficiently, is an $\\textsf{NP}$-Hard Problem. Next, we propose two solution methodologies, namely the \\emph{single greedy} and the \\emph{double greedy} approach for our problem that works based on marginal gain computation. A detailed analysis of both methodologies has been done to understand their time and space requirements. We perform an extensive set of experiments to demonstrate the effectiveness and efficiency of the proposed approaches with real-world datasets. From the experiments, we observe that the proposed solution approaches lead to more profit compared to the baseline methods and in particular, the double greedy approach leads to up to $5 \\%$ improvement compared to its single\\mbox{-}phase counterpart. ",
    "url": "https://arxiv.org/abs/2207.07830",
    "authors": [
      "Poonam Sharma",
      "Suman Banerjee"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2207.07831",
    "title": "Utility Driven Job Selection Problem on Road Networks",
    "abstract": "In this paper, we study the problem of \\textsc{Utility Driven Job Selection} on Road Networks for which the inputs are: a road network with the vertices as the set of Point-Of-Interests (Henceforth mentioned as POI) and the edges are road segments joining the POIs, a set of jobs with their originating POI, starting time, duration, and the utility. A worker can earn the utility associated with the job if (s)he performs this. As the jobs are originating at different POIs, the worker has to move from one POI to the other one to take up the job. Some budget is available for this purpose. Any two jobs can be taken up by the worker only if the finishing time of the first job plus traveling time from the POI of the first job to the second one should be less than or equal to the starting time of the second job. We call this constraint as the temporal constraint. The goal of this problem is to choose a subset of the jobs to maximize the earned utility such that the budget and temporal constraints should not be violated. We present two solution approaches with detailed analysis. First one of them works based on finding the locally optimal job at the end of every job and we call this approach as the \\emph{Best First Search Approach}. The other approach is based on the Nearest Neighbor Search on road networks. We perform a set of experiments with real\\mbox{-}world trajectory datasets to demonstrate the efficiency and effectiveness of the proposed solution approaches. We observe that the proposed approaches lead to more utility compared to baseline methods. ",
    "url": "https://arxiv.org/abs/2207.07831",
    "authors": [
      "Mayank Singhal",
      "Suman Banerjee"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2207.07832",
    "title": "Approximation Capabilities of Neural Networks using Morphological  Perceptrons and Generalizations",
    "abstract": "Standard artificial neural networks (ANNs) use sum-product or multiply-accumulate node operations with a memoryless nonlinear activation. These neural networks are known to have universal function approximation capabilities. Previously proposed morphological perceptrons use max-sum, in place of sum-product, node processing and have promising properties for circuit implementations. In this paper we show that these max-sum ANNs do not have universal approximation capabilities. Furthermore, we consider proposed signed-max-sum and max-star-sum generalizations of morphological ANNs and show that these variants also do not have universal approximation capabilities. We contrast these variations to log-number system (LNS) implementations which also avoid multiplications, but do exhibit universal approximation capabilities. ",
    "url": "https://arxiv.org/abs/2207.07832",
    "authors": [
      "William Chang",
      "Hassan Hamad",
      "Keith M. Chugg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2207.07847",
    "title": "Solving Graph Laplacians via Multilevel Sparsifiers",
    "abstract": "We consider effective preconditioners for solving Laplacians of general weighted graphs. Theoretically, spectral sparsifiers (SSs) provide preconditioners of optimal computational complexity. However, they are not easy to use for real-world applications due to the implementation complications. Multigrid (MG) methods, on the contrary, are computationally efficient but lack of theoretical justifications. To bridge the gap between theory and practice, we adopt ideas of MG and SS methods and proposed preconditioners that can be used in practice with theoretical guarantees. We expand the original graph based on a multilevel structure to obtain an equivalent expanded graph. Although the expanded graph has a low diameter, a favorable property for constructing SSs, it has negatively weighted edges, which is an unfavorable property for the SSs. We design an algorithm to properly eliminate the negatively weighted edges and prove that the resulting expanded graph with positively weighted edges is spectrally equivalent to the expanded graph, thus, the original graph. Due to the low-diameter property of the positively-weighted expanded graph preconditioner (PEGP), existing algorithms for finding SSs can be easily applied. To demonstrate the advantage of working with the PEGP, we propose a type of SS, multilevel sparsifier preconditioner (MSP), that can be constructed in an easy and deterministic manner. We provide some preliminary numerical experiments to verify our theoretical findings and illustrate the practical effectiveness of PEGP and MSP in real-world applications. ",
    "url": "https://arxiv.org/abs/2207.07847",
    "authors": [
      "Xiaozhe Hu",
      "Junyuan Lin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.07858",
    "title": "The Lottery Ticket Hypothesis for Self-attention in Convolutional Neural  Network",
    "abstract": "Recently many plug-and-play self-attention modules (SAMs) are proposed to enhance the model generalization by exploiting the internal information of deep convolutional neural networks (CNNs). In general, previous works ignore where to plug in the SAMs since they connect the SAMs individually with each block of the entire CNN backbone for granted, leading to incremental computational cost and the number of parameters with the growth of network depth. However, we empirically find and verify some counterintuitive phenomena that: (a) Connecting the SAMs to all the blocks may not always bring the largest performance boost, and connecting to partial blocks would be even better; (b) Adding the SAMs to a CNN may not always bring a performance boost, and instead it may even harm the performance of the original CNN backbone. Therefore, we articulate and demonstrate the Lottery Ticket Hypothesis for Self-attention Networks: a full self-attention network contains a subnetwork with sparse self-attention connections that can (1) accelerate inference, (2) reduce extra parameter increment, and (3) maintain accuracy. In addition to the empirical evidence, this hypothesis is also supported by our theoretical evidence. Furthermore, we propose a simple yet effective reinforcement-learning-based method to search the ticket, i.e., the connection scheme that satisfies the three above-mentioned conditions. Extensive experiments on widely-used benchmark datasets and popular self-attention networks show the effectiveness of our method. Besides, our experiments illustrate that our searched ticket has the capacity of transferring to some vision tasks, e.g., crowd counting and segmentation. ",
    "url": "https://arxiv.org/abs/2207.07858",
    "authors": [
      "Zhongzhan Huang",
      "Senwei Liang",
      "Mingfu Liang",
      "Wei He",
      "Haizhao Yang",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07867",
    "title": "Automatic dataset generation for specific object detection",
    "abstract": "In the past decade, object detection tasks are defined mostly by large public datasets. However, building object detection datasets is not scalable due to inefficient image collecting and labeling. Furthermore, most labels are still in the form of bounding boxes, which provide much less information than the real human visual system. In this paper, we present a method to synthesize object-in-scene images, which can preserve the objects' detailed features without bringing irrelevant information. In brief, given a set of images containing a target object, our algorithm first trains a model to find an approximate center of the object as an anchor, then makes an outline regression to estimate its boundary, and finally blends the object into a new scene. Our result shows that in the synthesized image, the boundaries of objects blend very well with the background. Experiments also show that SOTA segmentation models work well with our synthesized data. ",
    "url": "https://arxiv.org/abs/2207.07867",
    "authors": [
      "Xiaotian Lin",
      "Leiyang Xu",
      "Qiang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.07870",
    "title": "Scene Graph for Embodied Exploration in Cluttered Scenario",
    "abstract": "The ability to handle objects in cluttered environment has been long anticipated by robotic community. However, most of works merely focus on manipulation instead of rendering hidden semantic information in cluttered objects. In this work, we introduce the scene graph for embodied exploration in cluttered scenarios to solve this problem. To validate our method in cluttered scenario, we adopt the Manipulation Question Answering (MQA) tasks as our test benchmark, which requires an embodied robot to have the active exploration ability and semantic understanding ability of vision and language.As a general solution framework to the task, we propose an imitation learning method to generate manipulations for exploration. Meanwhile, a VQA model based on dynamic scene graph is adopted to comprehend a series of RGB frames from wrist camera of manipulator along with every step of manipulation is conducted to answer questions in our framework.The experiments on of MQA dataset with different interaction requirements demonstrate that our proposed framework is effective for MQA task a representative of tasks in cluttered scenario. ",
    "url": "https://arxiv.org/abs/2207.07870",
    "authors": [
      "Yuhong Deng",
      "Qie Sima",
      "Di Guo",
      "Huaping Liu",
      "Yi Wang",
      "Fuchun Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.07875",
    "title": "On the Importance of Hyperparameters and Data Augmentation for  Self-Supervised Learning",
    "abstract": "Self-Supervised Learning (SSL) has become a very active area of Deep Learning research where it is heavily used as a pre-training method for classification and other tasks. However, the rapid pace of advancements in this area comes at a price: training pipelines vary significantly across papers, which presents a potentially crucial confounding factor. Here, we show that, indeed, the choice of hyperparameters and data augmentation strategies can have a dramatic impact on performance. To shed light on these neglected factors and help maximize the power of SSL, we hyperparameterize these components and optimize them with Bayesian optimization, showing improvements across multiple datasets for the SimSiam SSL approach. Realizing the importance of data augmentations for SSL, we also introduce a new automated data augmentation algorithm, GroupAugment, which considers groups of augmentations and optimizes the sampling across groups. In contrast to algorithms designed for supervised learning, GroupAugment achieved consistently high linear evaluation accuracy across all datasets we considered. Overall, our results indicate the importance and likely underestimated role of data augmentation for SSL. ",
    "url": "https://arxiv.org/abs/2207.07875",
    "authors": [
      "Diane Wagner",
      "Fabio Ferreira",
      "Danny Stoll",
      "Robin Tibor Schirrmeister",
      "Samuel M\u00fcller",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07883",
    "title": "Neural Modal ODEs: Integrating Physics-based Modeling with Neural ODEs  for Modeling High Dimensional Monitored Structures",
    "abstract": "The order/dimension of models derived on the basis of data is commonly restricted by the number of observations, or in the context of monitored systems, sensing nodes. This is particularly true for structural systems (e.g. civil or mechanical structures), which are typically high-dimensional in nature. In the scope of physics-informed machine learning, this paper proposes a framework - termed Neural Modal ODEs - to integrate physics-based modeling with deep learning (particularly, Neural Ordinary Differential Equations -- Neural ODEs) for modeling the dynamics of monitored and high-dimensional engineered systems. In this initiating exploration, we restrict ourselves to linear or mildly nonlinear systems. We propose an architecture that couples a dynamic version of variational autoencoders with physics-informed Neural ODEs (Pi-Neural ODEs). An encoder, as a part of the autoencoder, learns the abstract mappings from the first few items of observational data to the initial values of the latent variables, which drive the learning of embedded dynamics via physics-informed Neural ODEs, imposing a \\textit{modal model} structure to that latent space. The decoder of the proposed model adopts the eigenmodes derived from an eigen-analysis applied to the linearized portion of a physics-based model: a process implicitly carrying the spatial relationship between degrees-of-freedom (DOFs). The framework is validated on a numerical example, and an experimental dataset of a scaled cable-stayed bridge, where the learned hybrid model is shown to outperform a purely physics-based approach to modeling. We further show the functionality of the proposed scheme within the context of virtual sensing, i.e., the recovery of generalized response quantities in unmeasured DOFs from spatially sparse data. ",
    "url": "https://arxiv.org/abs/2207.07883",
    "authors": [
      "Zhilu Lai",
      "Wei Liu",
      "Xudong Jian",
      "Kiran Bacsa",
      "Limin Sun",
      "Eleni Chatzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2207.07888",
    "title": "SizeShiftReg: a Regularization Method for Improving Size-Generalization  in Graph Neural Networks",
    "abstract": "In the past few years, graph neural networks (GNNs) have become the de facto model of choice for graph classification. While, from the theoretical viewpoint, most GNNs can operate on graphs of any size, it is empirically observed that their classification performance degrades when they are applied on graphs with sizes that differ from those in the training data. Previous works have tried to tackle this issue in graph classification by providing the model with inductive biases derived from assumptions on the generative process of the graphs, or by requiring access to graphs from the test domain. The first strategy is tied to the use of ad-hoc models and to the quality of the assumptions made on the generative process, leaving open the question of how to improve the performance of generic GNN models in general settings. On the other hand, the second strategy can be applied to any GNN, but requires access to information that is not always easy to obtain. In this work we consider the scenario in which we only have access to the training data, and we propose a regularization strategy that can be applied to any GNN to improve its generalization capabilities from smaller to larger graphs without requiring access to the test data. Our regularization is based on the idea of simulating a shift in the size of the training graphs using coarsening techniques, and enforcing the model to be robust to such a shift. Experimental results on standard datasets show that popular GNN models, trained on the 50% smallest graphs in the dataset and tested on the 10% largest graphs, obtain performance improvements of up to 30% when trained with our regularization strategy. ",
    "url": "https://arxiv.org/abs/2207.07888",
    "authors": [
      "Davide Buffelli",
      "Pietro Li\u00f2",
      "Fabio Vandin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07895",
    "title": "JPerceiver: Joint Perception Network for Depth, Pose and Layout  Estimation in Driving Scenes",
    "abstract": "Depth estimation, visual odometry (VO), and bird's-eye-view (BEV) scene layout estimation present three critical tasks for driving scene perception, which is fundamental for motion planning and navigation in autonomous driving. Though they are complementary to each other, prior works usually focus on each individual task and rarely deal with all three tasks together. A naive way is to accomplish them independently in a sequential or parallel manner, but there are many drawbacks, i.e., 1) the depth and VO results suffer from the inherent scale ambiguity issue; 2) the BEV layout is directly predicted from the front-view image without using any depth-related information, although the depth map contains useful geometry clues for inferring scene layouts. In this paper, we address these issues by proposing a novel joint perception framework named JPerceiver, which can simultaneously estimate scale-aware depth and VO as well as BEV layout from a monocular video sequence. It exploits the cross-view geometric transformation (CGT) to propagate the absolute scale from the road layout to depth and VO based on a carefully-designed scale loss. Meanwhile, a cross-view and cross-modal transfer (CCT) module is devised to leverage the depth clues for reasoning road and vehicle layout through an attention mechanism. JPerceiver can be trained in an end-to-end multi-task learning way, where the CGT scale loss and CCT module promote inter-task knowledge transfer to benefit feature learning of each task. Experiments on Argoverse, Nuscenes and KITTI show the superiority of JPerceiver over existing methods on all the above three tasks in terms of accuracy, model size, and inference speed. The code and models are available at~\\href{https://github.com/sunnyHelen/JPerceiver}{https://github.com/sunnyHelen/JPerceiver}. ",
    "url": "https://arxiv.org/abs/2207.07895",
    "authors": [
      "Haimei Zhao",
      "Jing Zhang",
      "Sen Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07898",
    "title": "SPSN: Superpixel Prototype Sampling Network for RGB-D Salient Object  Detection",
    "abstract": "RGB-D salient object detection (SOD) has been in the spotlight recently because it is an important preprocessing operation for various vision tasks. However, despite advances in deep learning-based methods, RGB-D SOD is still challenging due to the large domain gap between an RGB image and the depth map and low-quality depth maps. To solve this problem, we propose a novel superpixel prototype sampling network (SPSN) architecture. The proposed model splits the input RGB image and depth map into component superpixels to generate component prototypes. We design a prototype sampling network so that the network only samples prototypes corresponding to salient objects. In addition, we propose a reliance selection module to recognize the quality of each RGB and depth feature map and adaptively weight them in proportion to their reliability. The proposed method makes the model robust to inconsistencies between RGB images and depth maps and eliminates the influence of non-salient objects. Our method is evaluated on five popular datasets, achieving state-of-the-art performance. We prove the effectiveness of the proposed method through comparative experiments. ",
    "url": "https://arxiv.org/abs/2207.07898",
    "authors": [
      "Minhyeok Lee",
      "Chaewon Park",
      "Suhwan Cho",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07903",
    "title": "Unsupervised Ensemble Based Deep Learning Approach for Attack Detection  in IoT Network",
    "abstract": "The Internet of Things (IoT) has altered living by controlling devices/things over the Internet. IoT has specified many smart solutions for daily problems, transforming cyber-physical systems (CPS) and other classical fields into smart regions. Most of the edge devices that make up the Internet of Things have very minimal processing power. To bring down the IoT network, attackers can utilise these devices to conduct a variety of network attacks. In addition, as more and more IoT devices are added, the potential for new and unknown threats grows exponentially. For this reason, an intelligent security framework for IoT networks must be developed that can identify such threats. In this paper, we have developed an unsupervised ensemble learning model that is able to detect new or unknown attacks in an IoT network from an unlabelled dataset. The system-generated labelled dataset is used to train a deep learning model to detect IoT network attacks. Additionally, the research presents a feature selection mechanism for identifying the most relevant aspects in the dataset for detecting attacks. The study shows that the suggested model is able to identify the unlabelled IoT network datasets and DBN (Deep Belief Network) outperform the other models with a detection accuracy of 97.5% and a false alarm rate of 2.3% when trained using labelled dataset supplied by the proposed approach. ",
    "url": "https://arxiv.org/abs/2207.07903",
    "authors": [
      "Mir Shahnawaz Ahmed",
      "Shahid Mehraj Shah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07908",
    "title": "Multiscale Causal Structure Learning",
    "abstract": "The inference of causal structures from observed data plays a key role in unveiling the underlying dynamics of the system. This paper exposes a novel method, named Multiscale-Causal Structure Learning (MS-CASTLE), to estimate the structure of linear causal relationships occurring at different time scales. Differently from existing approaches, MS-CASTLE takes explicitly into account instantaneous and lagged inter-relations between multiple time series, represented at different scales, hinging on stationary wavelet transform and non-convex optimization. MS-CASTLE incorporates, as a special case, a single-scale version named SS-CASTLE, which compares favorably in terms of computational efficiency, performance and robustness with respect to the state of the art onto synthetic data. We used MS-CASTLE to study the multiscale causal structure of the risk of 15 global equity markets, during covid-19 pandemic, illustrating how MS-CASTLE can extract meaningful information thanks to its multiscale analysis, outperforming SS-CASTLE. We found that the most persistent and strongest interactions occur at mid-term time resolutions. Moreover, we identified the stock markets that drive the risk during the considered period: Brazil, Canada and Italy. The proposed approach can be exploited by financial investors who, depending to their investment horizon, can manage the risk within equity portfolios from a causal perspective. ",
    "url": "https://arxiv.org/abs/2207.07908",
    "authors": [
      "Gabriele D'Acunto",
      "Paolo Di Lorenzo",
      "Sergio Barbarossa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.07910",
    "title": "Improving Multi-Interest Network with Stable Learning",
    "abstract": "Modeling users' dynamic preferences from historical behaviors lies at the core of modern recommender systems. Due to the diverse nature of user interests, recent advances propose the multi-interest networks to encode historical behaviors into multiple interest vectors. In real scenarios, the corresponding items of captured interests are usually retrieved together to get exposure and collected into training data, which produces dependencies among interests. Unfortunately, multi-interest networks may incorrectly concentrate on subtle dependencies among captured interests. Misled by these dependencies, the spurious correlations between irrelevant interests and targets are captured, resulting in the instability of prediction results when training and test distributions do not match. In this paper, we introduce the widely used Hilbert-Schmidt Independence Criterion (HSIC) to measure the degree of independence among captured interests and empirically show that the continuous increase of HSIC may harm model performance. Based on this, we propose a novel multi-interest network, named DEep Stable Multi-Interest Learning (DESMIL), which tries to eliminate the influence of subtle dependencies among captured interests via learning weights for training samples and make model concentrate more on underlying true causation. We conduct extensive experiments on public recommendation datasets, a large-scale industrial dataset and the synthetic datasets which simulate the out-of-distribution data. Experimental results demonstrate that our proposed DESMIL outperforms state-of-the-art models by a significant margin. Besides, we also conduct comprehensive model analysis to reveal the reason why DESMIL works to a certain extent. ",
    "url": "https://arxiv.org/abs/2207.07910",
    "authors": [
      "Zhaocheng Liu",
      "Yingtao Luo",
      "Di Zeng",
      "Qiang Liu",
      "Daqing Chang",
      "Dongying Kong",
      "Zhi Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07911",
    "title": "Few-shot bioacoustic event detection at the DCASE 2022 challenge",
    "abstract": "Few-shot sound event detection is the task of detecting sound events, despite having only a few labelled examples of the class of interest. This framework is particularly useful in bioacoustics, where often there is a need to annotate very long recordings but the expert annotator time is limited. This paper presents an overview of the second edition of the few-shot bioacoustic sound event detection task included in the DCASE 2022 challenge. A detailed description of the task objectives, dataset, and baselines is presented, together with the main results obtained and characteristics of the submitted systems. This task received submissions from 15 different teams from which 13 scored higher than the baselines. The highest F-score was of 60% on the evaluation set, which leads to a huge improvement over last year's edition. Highly-performing methods made use of prototypical networks, transductive learning, and addressed the variable length of events from all target classes. Furthermore, by analysing results on each of the subsets we can identify the main difficulties that the systems face, and conclude that few-show bioacoustic sound event detection remains an open challenge. ",
    "url": "https://arxiv.org/abs/2207.07911",
    "authors": [
      "I. Nolasco",
      "S. Singh",
      "E. Vidana-Villa",
      "E. Grout",
      "J. Morford",
      "M. Emmerson",
      "F. Jensens",
      "H. Whitehead",
      "I. Kiskin",
      "A. Strandburg-Peshkin",
      "L. Gill",
      "H. Pamula",
      "V. Lostanlen",
      "V. Morfi",
      "D. Stowell"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.07913",
    "title": "Dual-branch Hybrid Learning Network for Unbiased Scene Graph Generation",
    "abstract": "The current studies of Scene Graph Generation (SGG) focus on solving the long-tailed problem for generating unbiased scene graphs. However, most de-biasing methods overemphasize the tail predicates and underestimate head ones throughout training, thereby wrecking the representation ability of head predicate features. Furthermore, these impaired features from head predicates harm the learning of tail predicates. In fact, the inference of tail predicates heavily depends on the general patterns learned from head ones, e.g., \"standing on\" depends on \"on\". Thus, these de-biasing SGG methods can neither achieve excellent performance on tail predicates nor satisfying behaviors on head ones. To address this issue, we propose a Dual-branch Hybrid Learning network (DHL) to take care of both head predicates and tail ones for SGG, including a Coarse-grained Learning Branch (CLB) and a Fine-grained Learning Branch (FLB). Specifically, the CLB is responsible for learning expertise and robust features of head predicates, while the FLB is expected to predict informative tail predicates. Furthermore, DHL is equipped with a Branch Curriculum Schedule (BCS) to make the two branches work well together. Experiments show that our approach achieves a new state-of-the-art performance on VG and GQA datasets and makes a trade-off between the performance of tail predicates and head ones. Moreover, extensive experiments on two downstream tasks (i.e., Image Captioning and Sentence-to-Graph Retrieval) further verify the generalization and practicability of our method. ",
    "url": "https://arxiv.org/abs/2207.07913",
    "authors": [
      "Chaofan Zheng",
      "Lianli Gao",
      "Xinyu Lyu",
      "Pengpeng Zeng",
      "Abdulmotaleb El Saddik",
      "Heng Tao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07919",
    "title": "Explainable vision transformer enabled convolutional neural network for  plant disease identification: PlantXViT",
    "abstract": "Plant diseases are the primary cause of crop losses globally, with an impact on the world economy. To deal with these issues, smart agriculture solutions are evolving that combine the Internet of Things and machine learning for early disease detection and control. Many such systems use vision-based machine learning methods for real-time disease detection and diagnosis. With the advancement in deep learning techniques, new methods have emerged that employ convolutional neural networks for plant disease detection and identification. Another trend in vision-based deep learning is the use of vision transformers, which have proved to be powerful models for classification and other problems. However, vision transformers have rarely been investigated for plant pathology applications. In this study, a Vision Transformer enabled Convolutional Neural Network model called \"PlantXViT\" is proposed for plant disease identification. The proposed model combines the capabilities of traditional convolutional neural networks with the Vision Transformers to efficiently identify a large number of plant diseases for several crops. The proposed model has a lightweight structure with only 0.8 million trainable parameters, which makes it suitable for IoT-based smart agriculture services. The performance of PlantXViT is evaluated on five publicly available datasets. The proposed PlantXViT network performs better than five state-of-the-art methods on all five datasets. The average accuracy for recognising plant diseases is shown to exceed 93.55%, 92.59%, and 98.33% on Apple, Maize, and Rice datasets, respectively, even under challenging background conditions. The efficiency in terms of explainability of the proposed model is evaluated using gradient-weighted class activation maps and Local Interpretable Model Agnostic Explanation. ",
    "url": "https://arxiv.org/abs/2207.07919",
    "authors": [
      "Poornima Singh Thakur",
      "Pritee Khanna",
      "Tanuja Sheorey",
      "Aparajita Ojha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07920",
    "title": "Physics Embedded Neural Network Vehicle Model and Applications in  Risk-Aware Autonomous Driving Using Latent Features",
    "abstract": "Non-holonomic vehicle motion has been studied extensively using physics-based models. Common approaches when using these models interpret the wheel/ground interactions using a linear tire model and thus may not fully capture the nonlinear and complex dynamics under various environments. On the other hand, neural network models have been widely employed in this domain, demonstrating powerful function approximation capabilities. However, these black-box learning strategies completely abandon the existing knowledge of well-known physics. In this paper, we seamlessly combine deep learning with a fully differentiable physics model to endow the neural network with available prior knowledge. The proposed model shows better generalization performance than the vanilla neural network model by a large margin. We also show that the latent features of our model can accurately represent lateral tire forces without the need for any additional training. Lastly, We develop a risk-aware model predictive controller using proprioceptive information derived from the latent features. We validate our idea in two autonomous driving tasks under unknown friction, outperforming the baseline control framework. ",
    "url": "https://arxiv.org/abs/2207.07920",
    "authors": [
      "Taekyung Kim",
      "Hojin Lee",
      "Wonsuk Lee"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.07933",
    "title": "Consistency of Implicit and Explicit Features Matters for Monocular 3D  Object Detection",
    "abstract": "Monocular 3D object detection is a common solution for low-cost autonomous agents to perceive their surrounding environment. Monocular detection has progressed into two categories: (1)Direct methods that infer 3D bounding boxes directly from a frontal-view image; (2)3D intermedia representation methods that map image features to 3D space for subsequent 3D detection. The second category is standing out not only because 3D detection forges ahead at the mercy of more meaningful and representative features, but because of emerging SOTA end-to-end prediction and planning paradigms that require a bird's-eye-view feature map from a perception pipeline. However, in transforming to 3D representation, these methods do not guarantee that objects' implicit orientations and locations in latent space are consistent with those explicitly observed in Euclidean space, which will hurt model performance. Hence, we argue that the consistency of implicit and explicit features matters and present a novel monocular detection method, named CIEF, with the first orientation-aware image backbone to eliminate the disparity of implicit and explicit features in subsequent 3D representation. As a second contribution, we introduce a ray attention mechanism. In contrast to previous methods that repeat features along the projection ray or rely on another intermedia frustum point cloud, we directly transform image features to voxel representations with well-localized features. We also propose a handcrafted gaussian positional encoding function that outperforms the sinusoidal encoding function but maintains the benefit of being continuous. CIEF ranked 1st among all reported methods on both 3D and BEV detection benchmark of KITTI at submission time. ",
    "url": "https://arxiv.org/abs/2207.07933",
    "authors": [
      "Qian Ye",
      "Ling Jiang",
      "Yuyang Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07935",
    "title": "Visually-aware Acoustic Event Detection using Heterogeneous Graphs",
    "abstract": "Perception of auditory events is inherently multimodal relying on both audio and visual cues. A large number of existing multimodal approaches process each modality using modality-specific models and then fuse the embeddings to encode the joint information. In contrast, we employ heterogeneous graphs to explicitly capture the spatial and temporal relationships between the modalities and represent detailed information about the underlying signal. Using heterogeneous graph approaches to address the task of visually-aware acoustic event classification, which serves as a compact, efficient and scalable way to represent data in the form of graphs. Through heterogeneous graphs, we show efficiently modelling of intra- and inter-modality relationships both at spatial and temporal scales. Our model can easily be adapted to different scales of events through relevant hyperparameters. Experiments on AudioSet, a large benchmark, shows that our model achieves state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2207.07935",
    "authors": [
      "Amir Shirian",
      "Krishna Somandepalli",
      "Victor Sanchez",
      "Tanaya Guha"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.07940",
    "title": "HQANN: Efficient and Robust Similarity Search for Hybrid Queries with  Structured and Unstructured Constraints",
    "abstract": "The in-memory approximate nearest neighbor search (ANNS) algorithms have achieved great success for fast high-recall query processing, but are extremely inefficient when handling hybrid queries with unstructured (i.e., feature vectors) and structured (i.e., related attributes) constraints. In this paper, we present HQANN, a simple yet highly efficient hybrid query processing framework which can be easily embedded into existing proximity graph-based ANNS algorithms. We guarantee both low latency and high recall by leveraging navigation sense among attributes and fusing vector similarity search with attribute filtering. Experimental results on both public and in-house datasets demonstrate that HQANN is 10x faster than the state-of-the-art hybrid ANNS solutions to reach the same recall quality and its performance is hardly affected by the complexity of attributes. It can reach 99\\% recall@10 in just around 50 microseconds On GLOVE-1.2M with thousands of attribute constraints. ",
    "url": "https://arxiv.org/abs/2207.07940",
    "authors": [
      "Wei Wu",
      "Junlin He",
      "Yu Qiao",
      "Guoheng Fu",
      "Li Liu",
      "Jin Yu"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2207.07941",
    "title": "MixTailor: Mixed Gradient Aggregation for Robust Learning Against  Tailored Attacks",
    "abstract": "Implementations of SGD on distributed and multi-GPU systems creates new vulnerabilities, which can be identified and misused by one or more adversarial agents. Recently, it has been shown that well-known Byzantine-resilient gradient aggregation schemes are indeed vulnerable to informed attackers that can tailor the attacks (Fang et al., 2020; Xie et al., 2020b). We introduce MixTailor, a scheme based on randomization of the aggregation strategies that makes it impossible for the attacker to be fully informed. Deterministic schemes can be integrated into MixTailor on the fly without introducing any additional hyperparameters. Randomization decreases the capability of a powerful adversary to tailor its attacks, while the resulting randomized aggregation scheme is still competitive in terms of performance. For both iid and non-iid settings, we establish almost sure convergence guarantees that are both stronger and more general than those available in the literature. Our empirical studies across various datasets, attacks, and settings, validate our hypothesis and show that MixTailor successfully defends when well-known Byzantine-tolerant schemes fail. ",
    "url": "https://arxiv.org/abs/2207.07941",
    "authors": [
      "Ali Ramezani-Kebrya",
      "Iman Tabrizian",
      "Fartash Faghri",
      "Petar Popovski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.07968",
    "title": "Assessing the impact of cyber attacks manipulating distributed energy  resources on power system operation",
    "abstract": "Successful cyber attacks on power systems cause severe disruptions. One possible manipulation strategy is the utilization of distributed energy resources (DERs) to disturb power system operation. In addition to the impact on bulk power system frequency, local cascading effects caused by DER control and protection can increase the severity of this strategy. To investigate these effects, manipulation scenarios including the disconnection as well as the manipulation of active (P) and reactive power (Q) setpoints of DERs are derived. The impact is analyzed using time-domain simulations and quantified using assessment criteria such as voltage band violation and plant protection triggering. Though DER disconnection leads to high amounts of lost P injection the manipulation of Q setpoints offers potential to disconnect additional DERs through local cascading effects. To mitigate the impact of the manipulation scenarios automated tap changer operation as well as a limitation of remotely accessible Q is suitable. ",
    "url": "https://arxiv.org/abs/2207.07968",
    "authors": [
      "Philipp Linnartz",
      "Alexander Winkens",
      "Andreas Ulbig"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.07971",
    "title": "A Survey of Decision Making in Adversarial Games",
    "abstract": "Game theory has by now found numerous applications in various fields, including economics, industry, jurisprudence, and artificial intelligence, where each player only cares about its own interest in a noncooperative or cooperative manner, but without obvious malice to other players. However, in many practical applications, such as poker, chess, evader pursuing, drug interdiction, coast guard, cyber-security, and national defense, players often have apparently adversarial stances, that is, selfish actions of each player inevitably or intentionally inflict loss or wreak havoc on other players. Along this line, this paper provides a systematic survey on three main game models widely employed in adversarial games, i.e., zero-sum normal-form and extensive-form games, Stackelberg (security) games, zero-sum differential games, from an array of perspectives, including basic knowledge of game models, (approximate) equilibrium concepts, problem classifications, research frontiers, (approximate) optimal strategy seeking techniques, prevailing algorithms, and practical applications. Finally, promising future research directions are also discussed for relevant adversarial games. ",
    "url": "https://arxiv.org/abs/2207.07971",
    "authors": [
      "Xiuxian Li",
      "Min Meng",
      "Yiguang Hong",
      "Jie Chen"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.07972",
    "title": "Certified Neural Network Watermarks with Randomized Smoothing",
    "abstract": "Watermarking is a commonly used strategy to protect creators' rights to digital images, videos and audio. Recently, watermarking methods have been extended to deep learning models -- in principle, the watermark should be preserved when an adversary tries to copy the model. However, in practice, watermarks can often be removed by an intelligent adversary. Several papers have proposed watermarking methods that claim to be empirically resistant to different types of removal attacks, but these new techniques often fail in the face of new or better-tuned adversaries. In this paper, we propose a certifiable watermarking method. Using the randomized smoothing technique proposed in Chiang et al., we show that our watermark is guaranteed to be unremovable unless the model parameters are changed by more than a certain l2 threshold. In addition to being certifiable, our watermark is also empirically more robust compared to previous watermarking methods. Our experiments can be reproduced with code at https://github.com/arpitbansal297/Certified_Watermarks ",
    "url": "https://arxiv.org/abs/2207.07972",
    "authors": [
      "Arpit Bansal",
      "Ping-yeh Chiang",
      "Michael Curry",
      "Rajiv Jain",
      "Curtis Wigington",
      "Varun Manjunatha",
      "John P Dickerson",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.07973",
    "title": "Learn-to-Decompose: Cascaded Decomposition Network for Cross-Domain  Few-Shot Facial Expression Recognition",
    "abstract": "Most existing compound facial expression recognition (FER) methods rely on large-scale labeled compound expression data for training. However, collecting such data is labor-intensive and time-consuming. In this paper, we address the compound FER task in the cross-domain few-shot learning (FSL) setting, which requires only a few samples of compound expressions in the target domain. Specifically, we propose a novel cascaded decomposition network (CDNet), which cascades several learn-to-decompose modules with shared parameters based on a sequential decomposition mechanism, to obtain a transferable feature space. To alleviate the overfitting problem caused by limited base classes in our task, a partial regularization strategy is designed to effectively exploit the best of both episodic training and batch training. By training across similar tasks on multiple basic expression datasets, CDNet learns the ability of learn-to-decompose that can be easily adapted to identify unseen compound expressions. Extensive experiments on both in-the-lab and in-the-wild compound expression datasets demonstrate the superiority of our proposed CDNet against several state-of-the-art FSL methods. Code is available at: https://github.com/zouxinyi0625/CDNet. ",
    "url": "https://arxiv.org/abs/2207.07973",
    "authors": [
      "Xinyi Zou",
      "Yan Yan",
      "Jing-Hao Xue",
      "Si Chen",
      "Hanzi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07974",
    "title": "Online Prediction in Sub-linear Space",
    "abstract": "We provide the first sub-linear space and sub-linear regret algorithm for online learning with expert advice (against an oblivious adversary), addressing an open question raised recently by Srinivas, Woodruff, Xu and Zhou (STOC 2022). We also demonstrate a separation between oblivious and (strong) adaptive adversaries by proving a linear memory lower bound of any sub-linear regret algorithm against an adaptive adversary. Our algorithm is based on a novel pool selection procedure that bypasses the traditional wisdom of leader selection for online learning, and a generic reduction that transforms any weakly sub-linear regret $o(T)$ algorithm to $T^{1-\\alpha}$ regret algorithm, which may be of independent interest. Our lower bound utilizes the connection of no-regret learning and equilibrium computation in zero-sum games, leading to a proof of a strong lower bound against an adaptive adversary. ",
    "url": "https://arxiv.org/abs/2207.07974",
    "authors": [
      "Binghui Peng",
      "Fred Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07976",
    "title": "Hyperparameter Tuning in Echo State Networks",
    "abstract": "Echo State Networks represent a type of recurrent neural network with a large randomly generated reservoir and a small number of readout connections trained via linear regression. The most common topology of the reservoir is a fully connected network of up to thousands of neurons. Over the years, researchers have introduced a variety of alternative reservoir topologies, such as a circular network or a linear path of connections. When comparing the performance of different topologies or other architectural changes, it is necessary to tune the hyperparameters for each of the topologies separately since their properties may significantly differ. The hyperparameter tuning is usually carried out manually by selecting the best performing set of parameters from a sparse grid of predefined combinations. Unfortunately, this approach may lead to underperforming configurations, especially for sensitive topologies. We propose an alternative approach of hyperparameter tuning based on the Covariance Matrix Adaptation Evolution Strategy (CMA-ES). Using this approach, we have improved multiple topology comparison results by orders of magnitude suggesting that topology alone does not play as important role as properly tuned hyperparameters. ",
    "url": "https://arxiv.org/abs/2207.07976",
    "authors": [
      "Filip Matzner"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2207.07979",
    "title": "Knowledge Guided Bidirectional Attention Network for Human-Object  Interaction Detection",
    "abstract": "Human Object Interaction (HOI) detection is a challenging task that requires to distinguish the interaction between a human-object pair. Attention based relation parsing is a popular and effective strategy utilized in HOI. However, current methods execute relation parsing in a \"bottom-up\" manner. We argue that the independent use of the bottom-up parsing strategy in HOI is counter-intuitive and could lead to the diffusion of attention. Therefore, we introduce a novel knowledge-guided top-down attention into HOI, and propose to model the relation parsing as a \"look and search\" process: execute scene-context modeling (i.e. look), and then, given the knowledge of the target pair, search visual clues for the discrimination of the interaction between the pair. We implement the process via unifying the bottom-up and top-down attention in a single encoder-decoder based model. The experimental results show that our model achieves competitive performance on the V-COCO and HICO-DET datasets. ",
    "url": "https://arxiv.org/abs/2207.07979",
    "authors": [
      "Jingjia Huang",
      "Baixiang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07983",
    "title": "New and improved approximation algorithms for Steiner Tree Augmentation  Problems",
    "abstract": "In the Steiner Tree Augmentation Problem (STAP), we are given a graph $G = (V,E)$, a set of terminals $R \\subseteq V$, and a Steiner tree $T$ spanning $R$. The edges $L := E \\setminus E(T)$ are called links and have non-negative costs. The goal is to augment $T$ by adding a minimum cost set of links, so that there are 2 edge-disjoint paths between each pair of vertices in $R$. This problem is a special case of the Survivable Network Design Problem which can be approximated to within a factor of 2 using iterative rounding \\cite{J2001}. We give the first polynomial time algorithm for STAP with approximation ratio better than 2. In particular we achieve a ratio of $(1+ \\ln 2 + \\varepsilon) \\approx 1.69 + \\varepsilon$. To do this, we use the Local Greedy approach of \\cite{TZ2021} for the Tree Augmentation Problem and generalize their main decomposition theorem from links (of size two) to hyper-links. We also consider the Node-Weighted Steiner Tree Augmentation Problem (NW-STAP) in which the non-terminal nodes have non-negative costs. We seek a cheapest subset $S \\subseteq V \\setminus R$ so that $G[R \\cup S]$ is 2-edge-connected. We provide a $O(\\log^2 (|R|))$-approximation algorithm for NW-STAP. To do this, we use a greedy algorithm leveraging the spider decomposition of optimal solutions. ",
    "url": "https://arxiv.org/abs/2207.07983",
    "authors": [
      "R. Ravi",
      "Weizhong Zhang",
      "Michael Zlatin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2207.07984",
    "title": "Characterization of Group-Fair Social Choice Rules under Single-Peaked  Preferences",
    "abstract": "We study fairness in social choice settings under single-peaked preferences. Construction and characterization of social choice rules in the single-peaked domain has been extensively studied in prior works. In fact, in the single-peaked domain, it is known that unanimous and strategy-proof deterministic rules have to be min-max rules and those that also satisfy anonymity have to be median rules. Further, random social choice rules satisfying these properties have been shown to be convex combinations of respective deterministic rules. We non-trivially add to this body of results by including fairness considerations in social choice. Our study directly addresses fairness for groups of agents. To study group-fairness, we consider an existing partition of the agents into logical groups, based on natural attributes such as gender, race, and location. To capture fairness within each group, we introduce the notion of group-wise anonymity. To capture fairness across the groups, we propose a weak notion as well as a strong notion of fairness. The proposed fairness notions turn out to be natural generalizations of existing individual-fairness notions and moreover provide non-trivial outcomes for strict ordinal preferences, unlike the existing group-fairness notions. We provide two separate characterizations of random social choice rules that satisfy group-fairness: (i) direct characterization (ii) extreme point characterization (as convex combinations of fair deterministic social choice rules). We also explore the special case where there are no groups and provide sharper characterizations of rules that achieve individual-fairness. ",
    "url": "https://arxiv.org/abs/2207.07984",
    "authors": [
      "Gogulapati Sreedurga",
      "Soumyarup Sadhukhan",
      "Souvik Roy",
      "Yadati Narahari"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ]
  },
  {
    "id": "arXiv:2207.07996",
    "title": "Optimal Strategic Mining Against Cryptographic Self-Selection in  Proof-of-Stake",
    "abstract": "Cryptographic Self-Selection is a subroutine used to select a leader for modern proof-of-stake consensus protocols, such as Algorand. In cryptographic self-selection, each round $r$ has a seed $Q_r$. In round $r$, each account owner is asked to digitally sign $Q_r$, hash their digital signature to produce a credential, and then broadcast this credential to the entire network. A publicly-known function scores each credential in a manner so that the distribution of the lowest scoring credential is identical to the distribution of stake owned by each account. The user who broadcasts the lowest-scoring credential is the leader for round $r$, and their credential becomes the seed $Q_{r+1}$. Such protocols leave open the possibility of a selfish-mining style attack: a user who owns multiple accounts that each produce low-scoring credentials in round $r$ can selectively choose which ones to broadcast in order to influence the seed for round $r+1$. Indeed, the user can pre-compute their credentials for round $r+1$ for each potential seed, and broadcast only the credential (among those with a low enough score to be the leader) that produces the most favorable seed. We consider an adversary who wishes to maximize the expected fraction of rounds in which an account they own is the leader. We show such an adversary always benefits from deviating from the intended protocol, regardless of the fraction of the stake controlled. We characterize the optimal strategy; first by proving the existence of optimal positive recurrent strategies whenever the adversary owns last than $38\\%$ of the stake. Then, we provide a Markov Decision Process formulation to compute the optimal strategy. ",
    "url": "https://arxiv.org/abs/2207.07996",
    "authors": [
      "Matheus V.X. Ferreira",
      "Ye Lin Sally Hahn",
      "S. Matthew Weinberg",
      "Catherine Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Theoretical Economics (econ.TH)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2207.08001",
    "title": "SVGraph: Learning Semantic Graphs from Instructional Videos",
    "abstract": "In this work, we focus on generating graphical representations of noisy, instructional videos for video understanding. We propose a self-supervised, interpretable approach that does not require any annotations for graphical representations, which would be expensive and time consuming to collect. We attempt to overcome \"black box\" learning limitations by presenting Semantic Video Graph or SVGraph, a multi-modal approach that utilizes narrations for semantic interpretability of the learned graphs. SVGraph 1) relies on the agreement between multiple modalities to learn a unified graphical structure with the help of cross-modal attention and 2) assigns semantic interpretation with the help of Semantic-Assignment, which captures the semantics from video narration. We perform experiments on multiple datasets and demonstrate the interpretability of SVGraph in semantic graph learning. ",
    "url": "https://arxiv.org/abs/2207.08001",
    "authors": [
      "Madeline C. Schiappa",
      "Yogesh S. Rawat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08003",
    "title": "SSMTL++: Revisiting Self-Supervised Multi-Task Learning for Video  Anomaly Detection",
    "abstract": "A self-supervised multi-task learning (SSMTL) framework for video anomaly detection was recently introduced in literature. Due to its highly accurate results, the method attracted the attention of many researchers. In this work, we revisit the self-supervised multi-task learning framework, proposing several updates to the original method. First, we study various detection methods, e.g. based on detecting high-motion regions using optical flow or background subtraction, since we believe the currently used pre-trained YOLOv3 is suboptimal, e.g. objects in motion or objects from unknown classes are never detected. Second, we modernize the 3D convolutional backbone by introducing multi-head self-attention modules, inspired by the recent success of vision transformers. As such, we alternatively introduce both 2D and 3D convolutional vision transformer (CvT) blocks. Third, in our attempt to further improve the model, we study additional self-supervised learning tasks, such as predicting segmentation maps through knowledge distillation, solving jigsaw puzzles, estimating body pose through knowledge distillation, predicting masked regions (inpainting), and adversarial learning with pseudo-anomalies. We conduct experiments to assess the performance impact of the introduced changes. Upon finding more promising configurations of the framework, dubbed SSMTL++v1 and SSMTL++v2, we extend our preliminary experiments to more data sets, demonstrating that our performance gains are consistent across all data sets. In most cases, our results on Avenue, ShanghaiTech and UBnormal raise the state-of-the-art performance to a new level. ",
    "url": "https://arxiv.org/abs/2207.08003",
    "authors": [
      "Antonio Barbalau",
      "Radu Tudor Ionescu",
      "Mariana-Iuliana Georgescu",
      "Jacob Dueholm",
      "Bharathkumar Ramachandra",
      "Kamal Nasrollahi",
      "Fahad Shahbaz Khan",
      "Thomas B. Moeslund",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08005",
    "title": "Exploring The Resilience of Control Execution Skips against False Data  Injection Attacks",
    "abstract": "Modern Cyber-Physical Systems (CPSs) are often designed as networked, software-based controller implementations which have been found to be vulnerable to network-level and physical level attacks. A number of research works have proposed CPS-specific attack detection schemes as well as techniques for attack resilient controller design. However, such schemes also incur platform-level overheads. In this regard, some recent works have leveraged the use of skips in control execution to enhance the resilience of a CPS against false data injection (FDI) attacks. In this paper, we provide an analytical discussion on when and how skipping a control execution can improve the resilience of the system against FDI attacks while maintaining the control performance requirement. We also propose a methodology to synthesize such optimal control execution patterns. To the best of our knowledge, no previous work has provided any quantitative analysis about the trade-off between attack resilience and control performance for such aperiodic control execution. Finally, we evaluate the proposed method on several safety-critical CPS benchmarks. ",
    "url": "https://arxiv.org/abs/2207.08005",
    "authors": [
      "Ipsita Koley",
      "Sunandan Adhikary",
      "Soumyajit Dey"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.08017",
    "title": "Is Soccer a lie or simply a complex system?",
    "abstract": "Understanding soccer as a complex system we base on nature and the collective behavior of many organisms that \"do calculations,\" seeking to generate solutions in a bioinspired way. When soccer mysteries appear, complex systems science emerges as a means to provide explanations. However, given the variety of interpretations that complexity and its associated properties can have and the understanding of what a complex system is, it is convenient to provide some elements to understand how unpredictability in soccer gives way to hundreds of counterintuitive results and how the science of complexity could contribute to the understanding of many phenomena in this sport. In this context, the manuscript's objective is to synthetically address some of the most important aspects of applied complexity to soccer to bring science and sport closer together ",
    "url": "https://arxiv.org/abs/2207.08017",
    "authors": [
      "Nelson Fernandez",
      "Ricardo Bernal"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2207.08018",
    "title": "Extend the lifetime of wireless sensor networks by modifying  cluster-based data collection",
    "abstract": "Wireless sensor networks have significant potential to increase our ability to view and control the physical environment, but the issue of power consumption in these networks has become an important parameter in their reliability and since in many applications of networks. Wireless sensor needs to guarantee end-to-end quality parameters, support for quality of service in these networks is of utmost importance. In wireless sensor networks, one of the most important issues is the lifetime of each network, which is directly related to the energy consumption of the network sensors. Increasing network lifetime is one of the most challenging requirements in these types of networks. This paper presents a clustering approach to reduce power consumption in wireless sensor networks, which is the most effective method for scalability and energy consumption reduction in sensor networks. The simulation results show that the proposed algorithm can reduce the energy consumption of the wireless sensor network and dramatically increase the lifetime of the network. ",
    "url": "https://arxiv.org/abs/2207.08018",
    "authors": [
      "Nahid Ebrahimi",
      "Ali Taghavirashidizadeh",
      "Seyyed Saeed Hosseini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.08023",
    "title": "Distance-Geometric Graph Attention Network (DG-GAT) for 3D Molecular  Geometry",
    "abstract": "Deep learning for molecular science has so far mainly focused on 2D molecular graphs. Recently, however, there has been work to extend it to 3D molecular geometry, due to its scientific significance and critical importance in real-world applications. The 3D distance-geometric graph representation (DG-GR) adopts a unified scheme (distance) for representing the geometry of 3D graphs. It is invariant to rotation and translation of the graph, and it reflects pair-wise node interactions and their generally local nature, particularly relevant for 3D molecular geometry. To facilitate the incorporation of 3D molecular geometry in deep learning for molecular science, we adopt the new graph attention network with dynamic attention (GATv2) for use with DG-GR and propose the 3D distance-geometric graph attention network (DG-GAT). GATv2 is a great fit for DG-GR since the attention can vary by node and by distance between nodes. Experimental results of DG-GAT for the ESOL and FreeSolv datasets show major improvement (31% and 38%, respectively) over those of the standard graph convolution network based on 2D molecular graphs. The same is true for the QM9 dataset. Our work demonstrates the utility and value of DG-GAT for deep learning based on 3D molecular geometry. ",
    "url": "https://arxiv.org/abs/2207.08023",
    "authors": [
      "Daniel T. Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2207.08034",
    "title": "Progress and limitations of deep networks to recognize objects in  unusual poses",
    "abstract": "Deep networks should be robust to rare events if they are to be successfully deployed in high-stakes real-world applications (e.g., self-driving cars). Here we study the capability of deep networks to recognize objects in unusual poses. We create a synthetic dataset of images of objects in unusual orientations, and evaluate the robustness of a collection of 38 recent and competitive deep networks for image classification. We show that classifying these images is still a challenge for all networks tested, with an average accuracy drop of 29.5% compared to when the objects are presented upright. This brittleness is largely unaffected by various network design choices, such as training losses (e.g., supervised vs. self-supervised), architectures (e.g., convolutional networks vs. transformers), dataset modalities (e.g., images vs. image-text pairs), and data-augmentation schemes. However, networks trained on very large datasets substantially outperform others, with the best network tested$\\unicode{x2014}$Noisy Student EfficentNet-L2 trained on JFT-300M$\\unicode{x2014}$showing a relatively small accuracy drop of only 14.5% on unusual poses. Nevertheless, a visual inspection of the failures of Noisy Student reveals a remaining gap in robustness with the human visual system. Furthermore, combining multiple object transformations$\\unicode{x2014}$3D-rotations and scaling$\\unicode{x2014}$further degrades the performance of all networks. Altogether, our results provide another measurement of the robustness of deep networks that is important to consider when using them in the real world. Code and datasets are available at https://github.com/amro-kamal/ObjectPose. ",
    "url": "https://arxiv.org/abs/2207.08034",
    "authors": [
      "Amro Abbas",
      "St\u00e9phane Deny"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08044",
    "title": "DIMBA: Discretely Masked Black-Box Attack in Single Object Tracking",
    "abstract": "The adversarial attack can force a CNN-based model to produce an incorrect output by craftily manipulating human-imperceptible input. Exploring such perturbations can help us gain a deeper understanding of the vulnerability of neural networks, and provide robustness to deep learning against miscellaneous adversaries. Despite extensive studies focusing on the robustness of image, audio, and NLP, works on adversarial examples of visual object tracking -- especially in a black-box manner -- are quite lacking. In this paper, we propose a novel adversarial attack method to generate noises for single object tracking under black-box settings, where perturbations are merely added on initial frames of tracking sequences, which is difficult to be noticed from the perspective of a whole video clip. Specifically, we divide our algorithm into three components and exploit reinforcement learning for localizing important frame patches precisely while reducing unnecessary computational queries overhead. Compared to existing techniques, our method requires fewer queries on initialized frames of a video to manipulate competitive or even better attack performance. We test our algorithm in both long-term and short-term datasets, including OTB100, VOT2018, UAV123, and LaSOT. Extensive experiments demonstrate the effectiveness of our method on three mainstream types of trackers: discrimination, Siamese-based, and reinforcement learning-based trackers. ",
    "url": "https://arxiv.org/abs/2207.08044",
    "authors": [
      "Xiangyu Yin",
      "Wenjie Ruan",
      "Jonathan Fieldsend"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08046",
    "title": "MDM:Visual Explanations for Neural Networks via Multiple Dynamic Mask",
    "abstract": "The active region lookup of a neural network tells us which regions the neural network focuses on when making a decision, which gives us a basis for interpretability when the neural network makes a classification decision. We propose an algorithm Multiple Dynamic Mask(MDM), which is a general saliency graph query method with interpretability of the inference process. Its proposal is based on an assumption: when a picture is input to a neural network that has been trained, the activation features related to classification will affect the classification results of the neural network, and the features unrelated to classification will hardly affect the classification results of the network. MDM: A learning-based end-to-end algorithm for finding regions of interest for neural network classification. It has the following advantages: 1. It has the interpretability of the reasoning process. 2. It is universal, it can be used for any neural network and does not depend on the internal structure of the neural network. 3. The search performance is better. Because the algorithm is based on learning to generate masks and has the ability to adapt to different data and networks, the performance is better than the method proposed in the previous paper. For the MDM saliency map search algorithm, we experimentally compared the performance indicators of various saliency map search methods and the MDM with ResNet and DenseNet as the trained neural networks. The search effect performance of the MDM reached the state of the art. We applied the MDM to the interpretable neural network ProtoPNet and XProtoNet, which improved the interpretability of the model and the prototype search performance. We visualize the performance of convolutional neural architecture and Transformer architecture on saliency map search. ",
    "url": "https://arxiv.org/abs/2207.08046",
    "authors": [
      "Yitao Peng",
      "Longzhen Yang",
      "Yihang Liu",
      "Lianghua He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08061",
    "title": "Leaderless and Multi-Leader Computation in Disconnected Anonymous  Dynamic Networks",
    "abstract": "We give a simple and complete characterization of which functions can be deterministically computed by anonymous processes in disconnected dynamic networks, depending on the number of leaders in the network. In addition, we provide efficient distributed algorithms for computing all such functions assuming minimal or no knowledge about the network. Each of our algorithms comes in two versions: one that terminates with the correct output and a faster one that stabilizes on the correct output without explicit termination. Notably, all of our algorithms have running times that scale linearly both with the number of processes and with a parameter of the network which we call \"dynamic disconnectivity\". We also provide matching lower bounds, showing that all our algorithms are asymptotically optimal for any fixed number of leaders. While most of the existing literature on anonymous dynamic networks relies on classical mass-distribution techniques, our work makes use of a recently introduced combinatorial structure called \"history tree\". Among other contributions, our results establish a new state of the art on two popular fundamental problems for anonymous dynamic networks: leaderless \"Average Consensus\" (i.e., computing the mean value of input numbers distributed among the processes) and multi-leader \"Counting\" (i.e., determining the exact number of processes in the network). ",
    "url": "https://arxiv.org/abs/2207.08061",
    "authors": [
      "Giuseppe A. Di Luna",
      "Giovanni Viglietta"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2207.08080",
    "title": "Neural Color Operators for Sequential Image Retouching",
    "abstract": "We propose a novel image retouching method by modeling the retouching process as performing a sequence of newly introduced trainable neural color operators. The neural color operator mimics the behavior of traditional color operators and learns pixelwise color transformation while its strength is controlled by a scalar. To reflect the homomorphism property of color operators, we employ equivariant mapping and adopt an encoder-decoder structure which maps the non-linear color transformation to a much simpler transformation (i.e., translation) in a high dimensional space. The scalar strength of each neural color operator is predicted using CNN based strength predictors by analyzing global image statistics. Overall, our method is rather lightweight and offers flexible controls. Experiments and user studies on public datasets show that our method consistently achieves the best results compared with SOTA methods in both quantitative measures and visual qualities. The code and data will be made publicly available. ",
    "url": "https://arxiv.org/abs/2207.08080",
    "authors": [
      "Yili Wang",
      "Xin Li",
      "Kun Xu",
      "Dongliang He",
      "Qi Zhang",
      "Fu Li",
      "Errui Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08089",
    "title": "Threat Model-Agnostic Adversarial Defense using Diffusion Models",
    "abstract": "Deep Neural Networks (DNNs) are highly sensitive to imperceptible malicious perturbations, known as adversarial attacks. Following the discovery of this vulnerability in real-world imaging and vision applications, the associated safety concerns have attracted vast research attention, and many defense techniques have been developed. Most of these defense methods rely on adversarial training (AT) -- training the classification network on images perturbed according to a specific threat model, which defines the magnitude of the allowed modification. Although AT leads to promising results, training on a specific threat model fails to generalize to other types of perturbations. A different approach utilizes a preprocessing step to remove the adversarial perturbation from the attacked image. In this work, we follow the latter path and aim to develop a technique that leads to robust classifiers across various realizations of threat models. To this end, we harness the recent advances in stochastic generative modeling, and means to leverage these for sampling from conditional distributions. Our defense relies on an addition of Gaussian i.i.d noise to the attacked image, followed by a pretrained diffusion process -- an architecture that performs a stochastic iterative process over a denoising network, yielding a high perceptual quality denoised outcome. The obtained robustness with this stochastic preprocessing step is validated through extensive experiments on the CIFAR-10 dataset, showing that our method outperforms the leading defense methods under various threat models. ",
    "url": "https://arxiv.org/abs/2207.08089",
    "authors": [
      "Tsachi Blau",
      "Roy Ganz",
      "Bahjat Kawar",
      "Alex Bronstein",
      "Michael Elad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.08098",
    "title": "Model-Agnostic and Diverse Explanations for Streaming Rumour Graphs",
    "abstract": "The propagation of rumours on social media poses an important threat to societies, so that various techniques for rumour detection have been proposed recently. Yet, existing work focuses on \\emph{what} entities constitute a rumour, but provides little support to understand \\emph{why} the entities have been classified as such. This prevents an effective evaluation of the detected rumours as well as the design of countermeasures. In this work, we argue that explanations for detected rumours may be given in terms of examples of related rumours detected in the past. A diverse set of similar rumours helps users to generalize, i.e., to understand the properties that govern the detection of rumours. Since the spread of rumours in social media is commonly modelled using feature-annotated graphs, we propose a query-by-example approach that, given a rumour graph, extracts the $k$ most similar and diverse subgraphs from past rumours. The challenge is that all of the computations require fast assessment of similarities between graphs. To achieve an efficient and adaptive realization of the approach in a streaming setting, we present a novel graph representation learning technique and report on implementation considerations. Our evaluation experiments show that our approach outperforms baseline techniques in delivering meaningful explanations for various rumour propagation behaviours. ",
    "url": "https://arxiv.org/abs/2207.08098",
    "authors": [
      "Thanh Tam Nguyen",
      "Thanh Cong Phan",
      "Minh Hieu Nguyen",
      "Matthias Weidlich",
      "Hongzhi Yin",
      "Jun Jo",
      "Quoc Viet Hung Nguyen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08109",
    "title": "Security Evaluation of Compressible Image Encryption for  Privacy-Preserving Image Classification against Ciphertext-only Attacks",
    "abstract": "The security of learnable image encryption schemes for image classification using deep neural networks against several attacks has been discussed. On the other hand, block scrambling image encryption using the vision transformer has been proposed, which applies to lossless compression methods such as JPEG standard by dividing an image into permuted blocks. Although robustness of the block scrambling image encryption against jigsaw puzzle solver attacks that utilize a correlation among the blocks has been evaluated under the condition of a large number of encrypted blocks, the security of encrypted images with a small number of blocks has never been evaluated. In this paper, the security of the block scrambling image encryption against ciphertext-only attacks is evaluated by using jigsaw puzzle solver attacks. ",
    "url": "https://arxiv.org/abs/2207.08109",
    "authors": [
      "Tatsuya Chuman",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.08132",
    "title": "E-NeRV: Expedite Neural Video Representation with Disentangled  Spatial-Temporal Context",
    "abstract": "Recently, the image-wise implicit neural representation of videos, NeRV, has gained popularity for its promising results and swift speed compared to regular pixel-wise implicit representations. However, the redundant parameters within the network structure can cause a large model size when scaling up for desirable performance. The key reason of this phenomenon is the coupled formulation of NeRV, which outputs the spatial and temporal information of video frames directly from the frame index input. In this paper, we propose E-NeRV, which dramatically expedites NeRV by decomposing the image-wise implicit neural representation into separate spatial and temporal context. Under the guidance of this new formulation, our model greatly reduces the redundant model parameters, while retaining the representation ability. We experimentally find that our method can improve the performance to a large extent with fewer parameters, resulting in a more than $8\\times$ faster speed on convergence. Code is available at https://github.com/kyleleey/E-NeRV. ",
    "url": "https://arxiv.org/abs/2207.08132",
    "authors": [
      "Zizhang Li",
      "Mengmeng Wang",
      "Huaijin Pi",
      "Kechun Xu",
      "Jianbiao Mei",
      "Yong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08137",
    "title": "Achieve Optimal Adversarial Accuracy for Adversarial Deep Learning using  Stackelberg Game",
    "abstract": "Adversarial deep learning is to train robust DNNs against adversarial attacks, which is one of the major research focuses of deep learning. Game theory has been used to answer some of the basic questions about adversarial deep learning such as the existence of a classifier with optimal robustness and the existence of optimal adversarial samples for a given class of classifiers. In most previous work, adversarial deep learning was formulated as a simultaneous game and the strategy spaces are assumed to be certain probability distributions in order for the Nash equilibrium to exist. But, this assumption is not applicable to the practical situation. In this paper, we give answers to these basic questions for the practical case where the classifiers are DNNs with a given structure, by formulating the adversarial deep learning as sequential games. The existence of Stackelberg equilibria for these games are proved. Furthermore, it is shown that the equilibrium DNN has the largest adversarial accuracy among all DNNs with the same structure, when Carlini-Wagner's margin loss is used. Trade-off between robustness and accuracy in adversarial deep learning is also studied from game theoretical aspect. ",
    "url": "https://arxiv.org/abs/2207.08137",
    "authors": [
      "Xiao-Shan Gao",
      "Shuang Liu",
      "Lijia Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2207.08145",
    "title": "Coupling Adversarial Learning with Selective Voting Strategy for  Distribution Alignment in Partial Domain Adaptation",
    "abstract": "In contrast to a standard closed-set domain adaptation task, partial domain adaptation setup caters to a realistic scenario by relaxing the identical label set assumption. The fact of source label set subsuming the target label set, however, introduces few additional obstacles as training on private source category samples thwart relevant knowledge transfer and mislead the classification process. To mitigate these issues, we devise a mechanism for strategic selection of highly-confident target samples essential for the estimation of class-importance weights. Furthermore, we capture class-discriminative and domain-invariant features by coupling the process of achieving compact and distinct class distributions with an adversarial objective. Experimental findings over numerous cross-domain classification tasks demonstrate the potential of the proposed technique to deliver superior and comparable accuracy over existing methods. ",
    "url": "https://arxiv.org/abs/2207.08145",
    "authors": [
      "Sandipan Choudhuri",
      "Hemanth Venkateswara",
      "Arunabha Sen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08148",
    "title": "Improving Deep Neural Network Random Initialization Through Neuronal  Rewiring",
    "abstract": "The deep learning literature is continuously updated with new architectures and training techniques. However, weight initialization is overlooked by most recent research, despite some intriguing findings regarding random weights. On the other hand, recent works have been approaching Network Science to understand the structure and dynamics of Artificial Neural Networks (ANNs) after training. Therefore, in this work, we analyze the centrality of neurons in randomly initialized networks. We show that a higher neuronal strength variance may decrease performance, while a lower neuronal strength variance usually improves it. A new method is then proposed to rewire neuronal connections according to a preferential attachment (PA) rule based on their strength, which significantly reduces the strength variance of layers initialized by common methods. In this sense, PA rewiring only reorganizes connections, while preserving the magnitude and distribution of the weights. We show through an extensive statistical analysis in image classification that performance is improved in most cases, both during training and testing, when using both simple and complex architectures and learning schedules. Our results show that, aside from the magnitude, the organization of the weights is also relevant for better initialization of deep ANNs. ",
    "url": "https://arxiv.org/abs/2207.08148",
    "authors": [
      "Leonardo Scabini",
      "Bernard De Baets",
      "Odemir M. Bruno"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2207.08150",
    "title": "FashionViL: Fashion-Focused Vision-and-Language Representation Learning",
    "abstract": "Large-scale Vision-and-Language (V+L) pre-training for representation learning has proven to be effective in boosting various downstream V+L tasks. However, when it comes to the fashion domain, existing V+L methods are inadequate as they overlook the unique characteristics of both the fashion V+L data and downstream tasks. In this work, we propose a novel fashion-focused V+L representation learning framework, dubbed as FashionViL. It contains two novel fashion-specific pre-training tasks designed particularly to exploit two intrinsic attributes with fashion V+L data. First, in contrast to other domains where a V+L data point contains only a single image-text pair, there could be multiple images in the fashion domain. We thus propose a Multi-View Contrastive Learning task for pulling closer the visual representation of one image to the compositional multimodal representation of another image+text. Second, fashion text (e.g., product description) often contains rich fine-grained concepts (attributes/noun phrases). To exploit this, a Pseudo-Attributes Classification task is introduced to encourage the learned unimodal (visual/textual) representations of the same concept to be adjacent. Further, fashion V+L tasks uniquely include ones that do not conform to the common one-stream or two-stream architectures (e.g., text-guided image retrieval). We thus propose a flexible, versatile V+L model architecture consisting of a modality-agnostic Transformer so that it can be flexibly adapted to any downstream tasks. Extensive experiments show that our FashionViL achieves a new state of the art across five downstream tasks. Code is available at https://github.com/BrandonHanx/mmf. ",
    "url": "https://arxiv.org/abs/2207.08150",
    "authors": [
      "Xiao Han",
      "Licheng Yu",
      "Xiatian Zhu",
      "Li Zhang",
      "Yi-Zhe Song",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08157",
    "title": "Automated Repair of Neural Networks",
    "abstract": "Over the last decade, Neural Networks (NNs) have been widely used in numerous applications including safety-critical ones such as autonomous systems. Despite their emerging adoption, it is well known that NNs are susceptible to Adversarial Attacks. Hence, it is highly important to provide guarantees that such systems work correctly. To remedy these issues we introduce a framework for repairing unsafe NNs w.r.t. safety specification, that is by utilizing satisfiability modulo theories (SMT) solvers. Our method is able to search for a new, safe NN representation, by modifying only a few of its weight values. In addition, our technique attempts to maximize the similarity to original network with regard to its decision boundaries. We perform extensive experiments which demonstrate the capability of our proposed framework to yield safe NNs w.r.t. the Adversarial Robustness property, with only a mild loss of accuracy (in terms of similarity). Moreover, we compare our method with a naive baseline to empirically prove its effectiveness. To conclude, we provide an algorithm to automatically repair NNs given safety properties, and suggest a few heuristics to improve its computational performance. Currently, by following this approach we are capable of producing small-sized (i.e., with up to few hundreds of parameters) correct NNs, composed of the piecewise linear ReLU activation function. Nevertheless, our framework is general in the sense that it can synthesize NNs w.r.t. any decidable fragment of first-order logic specification. ",
    "url": "https://arxiv.org/abs/2207.08157",
    "authors": [
      "Dor Cohen",
      "Ofer Strichman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.08163",
    "title": "Robust Transmission Scheduling for UAV-assisted Millimeter-Wave  Train-Ground Communication System",
    "abstract": "With the explosive growth of mobile data, the demand of high-speed railway (HSR) passengers for broadband wireless access services urgently needs the support of ultra-highspeed scenario broadband wireless communication. Millimeterwave (mmWave) can achieve high data transmission rates, but it is accompanied by high propagation loss and vulnerability to blockage. To address this issue, developments of directional antennas and unmanned aerial vehicles (UAVs) enhance the robustness of the mmWave train-ground communication system. In this paper, we propose a UAV and MRs relay assistance (UMRA) algorithm to effectively overcome link blockage, which can maximize the number of transmission flows on the premise of meeting QoS requirements and channel qualities. First, we formulate a mixed integer nonlinear programming (MINLP) problem for UAV trajectory design and transmission scheduling in the full-duplex (FD) mode. Then, in UMRA, the relay decision algorithm and transmission scheduling algorithm based on graph theory are proposed, which make a good tradeoff between computation complexity and system performance. Extensive simulation results show that a suitable UAV position will greatly improve the performance of the UMRA algorithm and make it close to the optimal solution. Compared with the other two existing benchmark schemes, with the high channel quality requirements and large-area blockage, UMRA can greatly improve the number of completed flows and system throughput. ",
    "url": "https://arxiv.org/abs/2207.08163",
    "authors": [
      "Yunhan Ma",
      "Yong Niu",
      "Zhu Han",
      "Bo Ai",
      "Kai Li",
      "Zhangdui Zhong",
      "Ning Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2207.08169",
    "title": "Ethnic Representation Analysis of Commercial Movie Posters",
    "abstract": "In the last decades, global awareness towards the importance of diverse representation has been increasing. Lack of diversity and discrimination toward minorities did not skip the film industry. Here, we examine ethnic bias in the film industry through commercial posters, the industry's primary advertisement medium for decades. Movie posters are designed to establish the viewer's initial impression. We developed a novel approach for evaluating ethnic bias in the film industry by analyzing nearly 125,000 posters using state-of-the-art deep learning models. Our analysis shows that while ethnic biases still exist, there is a trend of reduction of bias, as seen by several parameters. Particularly in English-speaking movies, the ethnic distribution of characters on posters from the last couple of years is reaching numbers that are approaching the actual ethnic composition of US population. An automatic approach to monitor ethnic diversity in the film industry, potentially integrated with financial value, may be of significant use for producers and policymakers. ",
    "url": "https://arxiv.org/abs/2207.08169",
    "authors": [
      "Dima Kagan",
      "Mor Levy",
      "Michael Fire",
      "Galit Fuhrmann Alpert"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.08178",
    "title": "Watermark Vaccine: Adversarial Attacks to Prevent Watermark Removal",
    "abstract": "As a common security tool, visible watermarking has been widely applied to protect copyrights of digital images. However, recent works have shown that visible watermarks can be removed by DNNs without damaging their host images. Such watermark-removal techniques pose a great threat to the ownership of images. Inspired by the vulnerability of DNNs on adversarial perturbations, we propose a novel defence mechanism by adversarial machine learning for good. From the perspective of the adversary, blind watermark-removal networks can be posed as our target models; then we actually optimize an imperceptible adversarial perturbation on the host images to proactively attack against watermark-removal networks, dubbed Watermark Vaccine. Specifically, two types of vaccines are proposed. Disrupting Watermark Vaccine (DWV) induces to ruin the host image along with watermark after passing through watermark-removal networks. In contrast, Inerasable Watermark Vaccine (IWV) works in another fashion of trying to keep the watermark not removed and still noticeable. Extensive experiments demonstrate the effectiveness of our DWV/IWV in preventing watermark removal, especially on various watermark removal networks. ",
    "url": "https://arxiv.org/abs/2207.08178",
    "authors": [
      "Xinwei Liu",
      "Jian Liu",
      "Yang Bai",
      "Jindong Gu",
      "Tao Chen",
      "Xiaojun Jia",
      "Xiaochun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08184",
    "title": "Zero-Shot Temporal Action Detection via Vision-Language Prompting",
    "abstract": "Existing temporal action detection (TAD) methods rely on large training data including segment-level annotations, limited to recognizing previously seen classes alone during inference. Collecting and annotating a large training set for each class of interest is costly and hence unscalable. Zero-shot TAD (ZS-TAD) resolves this obstacle by enabling a pre-trained model to recognize any unseen action classes. Meanwhile, ZS-TAD is also much more challenging with significantly less investigation. Inspired by the success of zero-shot image classification aided by vision-language (ViL) models such as CLIP, we aim to tackle the more complex TAD task. An intuitive method is to integrate an off-the-shelf proposal detector with CLIP style classification. However, due to the sequential localization (e.g, proposal generation) and classification design, it is prone to localization error propagation. To overcome this problem, in this paper we propose a novel zero-Shot Temporal Action detection model via Vision-LanguagE prompting (STALE). Such a novel design effectively eliminates the dependence between localization and classification by breaking the route for error propagation in-between. We further introduce an interaction mechanism between classification and localization for improved optimization. Extensive experiments on standard ZS-TAD video benchmarks show that our STALE significantly outperforms state-of-the-art alternatives. Besides, our model also yields superior results on supervised TAD over recent strong competitors. The PyTorch implementation of STALE is available at https://github.com/sauradip/STALE. ",
    "url": "https://arxiv.org/abs/2207.08184",
    "authors": [
      "Sauradip Nag",
      "Xiatian Zhu",
      "Yi-Zhe Song",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.08185",
    "title": "Mind the Gap: Polishing Pseudo labels for Accurate Semi-supervised  Object Detection",
    "abstract": "Exploiting pseudo labels (e.g., categories and bounding boxes) of unannotated objects produced by a teacher detector have underpinned much of recent progress in semi-supervised object detection (SSOD). However, due to the limited generalization capacity of the teacher detector caused by the scarce annotations, the produced pseudo labels often deviate from ground truth, especially those with relatively low classification confidences, thus limiting the generalization performance of SSOD. To mitigate this problem, we propose a dual pseudo-label polishing framework for SSOD. Instead of directly exploiting the pseudo labels produced by the teacher detector, we take the first attempt at reducing their deviation from ground truth using dual polishing learning, where two differently structured polishing networks are elaborately developed and trained using synthesized paired pseudo labels and the corresponding ground truth for categories and bounding boxes on the given annotated objects, respectively. By doing this, both polishing networks can infer more accurate pseudo labels for unannotated objects through sufficiently exploiting their context knowledge based on the initially produced pseudo labels, and thus improve the generalization performance of SSOD. Moreover, such a scheme can be seamlessly plugged into the existing SSOD framework for joint end-to-end learning. In addition, we propose to disentangle the polished pseudo categories and bounding boxes of unannotated objects for separate category classification and bounding box regression in SSOD, which enables introducing more unannotated objects during model training and thus further improve the performance. Experiments on both PASCAL VOC and MS COCO benchmarks demonstrate the superiority of the proposed method over existing state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2207.08185",
    "authors": [
      "Lei Zhang",
      "Yuxuan Sun",
      "Wei Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08187",
    "title": "Federated Self-Supervised Learning in Heterogeneous Settings: Limits of  a Baseline Approach on HAR",
    "abstract": "Federated Learning is a new machine learning paradigm dealing with distributed model learning on independent devices. One of the many advantages of federated learning is that training data stay on devices (such as smartphones), and only learned models are shared with a centralized server. In the case of supervised learning, labeling is entrusted to the clients. However, acquiring such labels can be prohibitively expensive and error-prone for many tasks, such as human activity recognition. Hence, a wealth of data remains unlabelled and unexploited. Most existing federated learning approaches that focus mainly on supervised learning have mostly ignored this mass of unlabelled data. Furthermore, it is unclear whether standard federated Learning approaches are suited to self-supervised learning. The few studies that have dealt with the problem have limited themselves to the favorable situation of homogeneous datasets. This work lays the groundwork for a reference evaluation of federated Learning with Semi-Supervised Learning in a realistic setting. We show that standard lightweight autoencoder and standard Federated Averaging fail to learn a robust representation for Human Activity Recognition with several realistic heterogeneous datasets. These findings advocate for a more intensive research effort in Federated Self Supervised Learning to exploit the mass of heterogeneous unlabelled data present on mobile devices. ",
    "url": "https://arxiv.org/abs/2207.08187",
    "authors": [
      "Sannara Ek",
      "Romain Rombourg",
      "Fran\u00e7ois Portet",
      "Philippe Lalanda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.08191",
    "title": "Stroke-Based Autoencoders: Self-Supervised Learners for Efficient  Zero-Shot Chinese Character Recognition",
    "abstract": "Chinese characters carry a wealth of morphological and semantic information; therefore, the semantic enhancement of the morphology of Chinese characters has drawn significant attention. The previous methods were intended to directly extract information from a whole Chinese character image, which usually cannot capture both global and local information simultaneously. In this paper, we develop a stroke-based autoencoder(SAE), to model the sophisticated morphology of Chinese characters with the self-supervised method. Following its canonical writing order, we first represent a Chinese character as a series of stroke images with a fixed writing order, and then our SAE model is trained to reconstruct this stroke image sequence. This pre-trained SAE model can predict the stroke image series for unseen characters, as long as their strokes or radicals appeared in the training set. We have designed two contrasting SAE architectures on different forms of stroke images. One is fine-tuned on existing stroke-based method for zero-shot recognition of handwritten Chinese characters, and the other is applied to enrich the Chinese word embeddings from their morphological features. The experimental results validate that after pre-training, our SAE architecture outperforms other existing methods in zero-shot recognition and enhances the representation of Chinese characters with their abundant morphological and semantic information. ",
    "url": "https://arxiv.org/abs/2207.08191",
    "authors": [
      "Zongze Chen",
      "Wenxia Yang",
      "Xin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.08194",
    "title": "Expectation-Maximization Based Defense Mechanism for Distributed Model  Predictive Control",
    "abstract": "Controlling large-scale systems sometimes requires decentralized computation. Communication among agents is crucial to achieving consensus and optimal global behavior. These negotiation mechanisms are sensitive to attacks on those exchanges. This paper proposes an algorithm based on Expectation Maximization to mitigate the effects of attacks in a resource allocation based distributed model predictive control. The performance is assessed through an academic example of the temperature control of multiple rooms under input power constraints. ",
    "url": "https://arxiv.org/abs/2207.08194",
    "authors": [
      "Rafael Acc\u00e1cio Nogueira",
      "Romain Bourdais",
      "Simon Leglaive",
      "Herv\u00e9 Gu\u00e9guen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.08201",
    "title": "INFWIDE: Image and Feature Space Wiener Deconvolution Network for  Non-blind Image Deblurring in Low-Light Conditions",
    "abstract": "Under low-light environment, handheld photography suffers from severe camera shake under long exposure settings. Although existing deblurring algorithms have shown promising performance on well-exposed blurry images, they still cannot cope with low-light snapshots. Sophisticated noise and saturation regions are two dominating challenges in practical low-light deblurring. In this work, we propose a novel non-blind deblurring method dubbed image and feature space Wiener deconvolution network (INFWIDE) to tackle these problems systematically. In terms of algorithm design, INFWIDE proposes a two-branch architecture, which explicitly removes noise and hallucinates saturated regions in the image space and suppresses ringing artifacts in the feature space, and integrates the two complementary outputs with a subtle multi-scale fusion network for high quality night photograph deblurring. For effective network training, we design a set of loss functions integrating a forward imaging model and backward reconstruction to form a close-loop regularization to secure good convergence of the deep neural network. Further, to optimize INFWIDE's applicability in real low-light conditions, a physical-process-based low-light noise model is employed to synthesize realistic noisy night photographs for model training. Taking advantage of the traditional Wiener deconvolution algorithm's physically driven characteristics and arisen deep neural network's representation ability, INFWIDE can recover fine details while suppressing the unpleasant artifacts during deblurring. Extensive experiments on synthetic data and real data demonstrate the superior performance of the proposed approach. ",
    "url": "https://arxiv.org/abs/2207.08201",
    "authors": [
      "Zhihong Zhang",
      "Yuxiao Cheng",
      "Jinli Suo",
      "Liheng Bian",
      "Qionghai Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.08210",
    "title": "A Simple Test-Time Method for Out-of-Distribution Detection",
    "abstract": "Neural networks are known to produce over-confident predictions on input images, even when these images are out-of-distribution (OOD) samples. This limits the applications of neural network models in real-world scenarios, where OOD samples exist. Many existing approaches identify the OOD instances via exploiting various cues, such as finding irregular patterns in the feature space, logits space, gradient space or the raw space of images. In contrast, this paper proposes a simple Test-time Linear Training (ETLT) method for OOD detection. Empirically, we find that the probabilities of input images being out-of-distribution are surprisingly linearly correlated to the features extracted by neural networks. To be specific, many state-of-the-art OOD algorithms, although designed to measure reliability in different ways, actually lead to OOD scores mostly linearly related to their image features. Thus, by simply learning a linear regression model trained from the paired image features and inferred OOD scores at test-time, we can make a more precise OOD prediction for the test instances. We further propose an online variant of the proposed method, which achieves promising performance and is more practical in real-world applications. Remarkably, we improve FPR95 from $51.37\\%$ to $12.30\\%$ on CIFAR-10 datasets with maximum softmax probability as the base OOD detector. Extensive experiments on several benchmark datasets show the efficacy of ETLT for OOD detection task. ",
    "url": "https://arxiv.org/abs/2207.08210",
    "authors": [
      "Ke Fan",
      "Yikai Wang",
      "Qian Yu",
      "Da Li",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08230",
    "title": "Troll Tweet Detection Using Contextualized Word Representations",
    "abstract": "In recent years, many troll accounts have emerged to manipulate social media opinion. Detecting and eradicating trolling is a critical issue for social-networking platforms because businesses, abusers, and nation-state-sponsored troll farms use false and automated accounts. NLP techniques are used to extract data from social networking text, such as Twitter tweets. In many text processing applications, word embedding representation methods, such as BERT, have performed better than prior NLP techniques, offering novel breaks to precisely comprehend and categorize social-networking information for various tasks. This paper implements and compares nine deep learning-based troll tweet detection architectures, with three models for each BERT, ELMo, and GloVe word embedding model. Precision, recall, F1 score, AUC, and classification accuracy are used to evaluate each architecture. From the experimental results, most architectures using BERT models improved troll tweet detection. A customized ELMo-based architecture with a GRU classifier has the highest AUC for detecting troll messages. The proposed architectures can be used by various social-based systems to detect troll messages in the future. ",
    "url": "https://arxiv.org/abs/2207.08230",
    "authors": [
      "Seyhmus Yilmaz",
      "Sultan Zavrak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.08236",
    "title": "Optimal Database Allocation in Finite Time with Efficient Communication  and Transmission Stopping over Dynamic Networks",
    "abstract": "In this paper, we focus on the problem of data sharing over a wireless computer network (i.e., a wireless grid). Given a set of available data, we present a distributed algorithm which operates over a dynamically changing network, and allows each node to calculate the optimal allocation of data in a finite number of time steps. We show that our proposed algorithm (i) converges to the optimal solution in finite time with very high probability, and (ii) once the optimal solution is reached, each node is able to cease transmissions without needing knowledge of a global parameter such as the network diameter. Furthermore, our algorithm (i) operates exclusively with quantized values (i.e., each node processes and transmits quantized information), (ii) relies on event-driven updates, and (iii) calculates the optimal solution in the form of a quantized fraction which avoids errors due to quantization. Finally, we demonstrate the operation, performance, and potential advantages of our algorithm over random dynamic networks. ",
    "url": "https://arxiv.org/abs/2207.08236",
    "authors": [
      "Apostolos I. Rikos",
      "Christoforos N. Hadjicostis",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2207.08240",
    "title": "Robust Action Governor for Uncertain Piecewise Affine Systems with  Non-convex Constraints and Safe Reinforcement Learning",
    "abstract": "The action governor is an add-on scheme to a nominal control loop that monitors and adjusts the control actions to enforce safety specifications expressed as pointwise-in-time state and control constraints. In this paper, we introduce the Robust Action Governor (RAG) for systems the dynamics of which can be represented using discrete-time Piecewise Affine (PWA) models with both parametric and additive uncertainties and subject to non-convex constraints. We develop the theoretical properties and computational approaches for the RAG. After that, we introduce the use of the RAG for realizing safe Reinforcement Learning (RL), i.e., ensuring all-time constraint satisfaction during online RL exploration-and-exploitation process. This development enables safe real-time evolution of the control policy and adaptation to changes in the operating environment and system parameters (due to aging, damage, etc.). We illustrate the effectiveness of the RAG in constraint enforcement and safe RL using the RAG by considering their applications to a soft-landing problem of a mass-spring-damper system. ",
    "url": "https://arxiv.org/abs/2207.08240",
    "authors": [
      "Yutong Li",
      "Nan Li",
      "H. Eric Tseng",
      "Anouck Girard",
      "Dimitar Filev",
      "Ilya Kolmanovsky"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.08244",
    "title": "Finite Time Privacy Preserving Quantized Average Consensus with  Transmission Stopping",
    "abstract": "Due to their flexibility, battery powered or energy-harvesting wireless networks are employed in diverse applications. Securing data transmissions between wireless devises is of critical importance in order to avoid privacy-sensitive user data leakage. In this paper, we focus on the scenario where some nodes are curious (but not malicious) and try to identify the initial states of one (or multiple) other nodes, while some nodes aim to preserve the privacy of their initial states from the curious nodes. We present a privacy preserving finite transmission event-triggered quantized average consensus algorithm. Its operation is suitable for battery-powered or energy-harvesting wireless network since it guarantees (i) efficient (quantized) communication, and (ii) transmission ceasing (which allows preservation of available energy). Furthermore, we present topological conditions under which the proposed algorithm allows nodes to preserve their privacy. We conclude with a comparison of our algorithm against other algorithms in the existing literature. ",
    "url": "https://arxiv.org/abs/2207.08244",
    "authors": [
      "Apostolos I. Rikos",
      "Christoforos N. Hadjicostis",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2207.08256",
    "title": "Representation Learning of Image Schema",
    "abstract": "Image schema is a recurrent pattern of reasoning where one entity is mapped into another. Image schema is similar to conceptual metaphor and is also related to metaphoric gesture. Our main goal is to generate metaphoric gestures for an Embodied Conversational Agent. We propose a technique to learn the vector representation of image schemas. As far as we are aware of, this is the first work which addresses that problem. Our technique uses Ravenet et al's algorithm which we use to compute the image schemas from the text input and also BERT and SenseBERT which we use as the base word embedding technique to calculate the final vector representation of the image schema. Our representation learning technique works by clustering: word embedding vectors which belong to the same image schema should be relatively closer to each other, and thus form a cluster. With the image schemas representable as vectors, it also becomes possible to have a notion that some image schemas are closer or more similar to each other than to the others because the distance between the vectors is a proxy of the dissimilarity between the corresponding image schemas. Therefore, after obtaining the vector representation of the image schemas, we calculate the distances between those vectors. Based on these, we create visualizations to illustrate the relative distances between the different image schemas. ",
    "url": "https://arxiv.org/abs/2207.08256",
    "authors": [
      "Fajrian Yunus",
      "Chlo\u00e9 Clavel",
      "Catherine Pelachaud"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08287",
    "title": "Spatial Distribution of Solar PV Deployment: An Application of the  Region-Based Convolutional Neural Network",
    "abstract": "This paper presents a comprehensive analysis of the social and environmental determinants of solar photovoltaic (PV) deployment rates in Colorado, USA. Using 652,795 satellite imagery and computer vision frameworks based on a convolutional neural network, we estimated the proportion of households with solar PV systems and the roof areas covered by solar panels. At the census block group level, 7% of Coloradan households have a rooftop PV system, and 2.5% of roof areas in Colorado are covered by solar panels as of 2021. Our machine learning models predict solar PV deployment based on 43 natural and social characteristics of neighborhoods. Using four algorithms (Random Forest, CATBoost, LightGBM, XGBoost), we find that the share of Democratic party votes, hail risks, strong wind risks, median home value, and solar PV permitting timelines are the most important predictors of solar PV count per household. In addition to the size of the houses, PV-to-roof area ratio is highly dependent on solar PV permitting timelines, proportion of renters and multifamily housing, and winter weather risks. We also find racial and ethnic disparities in rooftop solar deployment. The average marginal effects of median household income on solar deployment are lower in communities with a greater proportion of African American and Hispanic residents and are higher in communities with a greater proportion of White and Asian residents. In the ongoing energy transition, knowing the key predictors of solar deployment can better inform business and policy decision making for more efficient and equitable grid infrastructure investment and distributed energy resource management. ",
    "url": "https://arxiv.org/abs/2207.08287",
    "authors": [
      "Serena Y. Kim",
      "Koushik Ganesan",
      "Crystal Soderman",
      "Raven O'Rourke"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.08301",
    "title": "Vision-based Relative Detection and Tracking for Teams of Micro Aerial  Vehicles",
    "abstract": "In this paper, we address the vision-based detection and tracking problems of multiple aerial vehicles using a single camera and Inertial Measurement Unit (IMU) as well as the corresponding perception consensus problem (i.e., uniqueness and identical IDs across all observing agents). We design several vision-based decentralized Bayesian multi-tracking filtering strategies to resolve the association between the incoming unsorted measurements obtained by a visual detector algorithm and the tracked agents. We compare their accuracy in different operating conditions as well as their scalability according to the number of agents in the team. This analysis provides useful insights about the most appropriate design choice for the given task. We further show that the proposed perception and inference pipeline which includes a Deep Neural Network (DNN) as visual target detector is lightweight and capable of concurrently running control and planning with Size, Weight, and Power (SWaP) constrained robots on-board. Experimental results show the effective tracking of multiple drones in various challenging scenarios such as heavy occlusions. ",
    "url": "https://arxiv.org/abs/2207.08301",
    "authors": [
      "Rundong Ge",
      "Moonyoung Lee",
      "Vivek Radhakrishnan",
      "Yang Zhou",
      "Guanrui Li",
      "Giuseppe Loianno"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.08309",
    "title": "CULT: Continual Unsupervised Learning with Typicality-Based Environment  Detection",
    "abstract": "We introduce CULT (Continual Unsupervised Representation Learning with Typicality-Based Environment Detection), a new algorithm for continual unsupervised learning with variational auto-encoders. CULT uses a simple typicality metric in the latent space of a VAE to detect distributional shifts in the environment, which is used in conjunction with generative replay and an auxiliary environmental classifier to limit catastrophic forgetting in unsupervised representation learning. In our experiments, CULT significantly outperforms baseline continual unsupervised learning approaches. Code for this paper can be found here: https://github.com/oliveradk/cult ",
    "url": "https://arxiv.org/abs/2207.08309",
    "authors": [
      "Oliver Daniels-Koch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08319",
    "title": "Defect Transformer: An Efficient Hybrid Transformer Architecture for  Surface Defect Detection",
    "abstract": "Surface defect detection is an extremely crucial step to ensure the quality of industrial products. Nowadays, convolutional neural networks (CNNs) based on encoder-decoder architecture have achieved tremendous success in various defect detection tasks. However, due to the intrinsic locality of convolution, they commonly exhibit a limitation in explicitly modeling long-range interactions, critical for pixel-wise defect detection in complex cases, e.g., cluttered background and illegible pseudo-defects. Recent transformers are especially skilled at learning global image dependencies but with limited local structural information necessary for detailed defect location. To overcome the above limitations, we propose an efficient hybrid transformer architecture, termed Defect Transformer (DefT), for surface defect detection, which incorporates CNN and transformer into a unified model to capture local and non-local relationships collaboratively. Specifically, in the encoder module, a convolutional stem block is firstly adopted to retain more detailed spatial information. Then, the patch aggregation blocks are used to generate multi-scale representation with four hierarchies, each of them is followed by a series of DefT blocks, which respectively include a locally position-aware block for local position encoding, a lightweight multi-pooling self-attention to model multi-scale global contextual relationships with good computational efficiency, and a convolutional feed-forward network for feature transformation and further location information learning. Finally, a simple but effective decoder module is proposed to gradually recover spatial details from the skip connections in the encoder. Extensive experiments on three datasets demonstrate the superiority and efficiency of our method compared with other CNN- and transformer-based networks. ",
    "url": "https://arxiv.org/abs/2207.08319",
    "authors": [
      "Junpu Wang",
      "Guili Xu",
      "Fuju Yan",
      "Jinjin Wang",
      "Zhengsheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08320",
    "title": "GANzilla: User-Driven Direction Discovery in Generative Adversarial  Networks",
    "abstract": "Generative Adversarial Network (GAN) is widely adopted in numerous application areas, such as data preprocessing, image editing, and creativity support. However, GAN's 'black box' nature prevents non-expert users from controlling what data a model generates, spawning a plethora of prior work that focused on algorithm-driven approaches to extract editing directions to control GAN. Complementarily, we propose a GANzilla: a user-driven tool that empowers a user with the classic scatter/gather technique to iteratively discover directions to meet their editing goals. In a study with 12 participants, GANzilla users were able to discover directions that (i) edited images to match provided examples (closed-ended tasks) and that (ii) met a high-level goal, e.g., making the face happier, while showing diversity across individuals (open-ended tasks). ",
    "url": "https://arxiv.org/abs/2207.08320",
    "authors": [
      "Noyan Evirgen",
      "Xiang 'Anthony' Chen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08323",
    "title": "PlaneSDF-based Change Detection for Long-term Dense Mapping",
    "abstract": "The ability to process environment maps across multiple sessions is critical for robots operating over extended periods of time. Specifically, it is desirable for autonomous agents to detect changes amongst maps of different sessions so as to gain a conflict-free understanding of the current environment. In this paper, we look into the problem of change detection based on a novel map representation, dubbed Plane Signed Distance Fields (PlaneSDF), where dense maps are represented as a collection of planes and their associated geometric components in SDF volumes. Given point clouds of the source and target scenes, we propose a three-step PlaneSDF-based change detection approach: (1) PlaneSDF volumes are instantiated within each scene and registered across scenes using plane poses; 2D height maps and object maps are extracted per volume via height projection and connected component analysis. (2) Height maps are compared and intersected with the object map to produce a 2D change location mask for changed object candidates in the source scene. (3) 3D geometric validation is performed using SDF-derived features per object candidate for change mask refinement. We evaluate our approach on both synthetic and real-world datasets and demonstrate its effectiveness via the task of changed object detection. ",
    "url": "https://arxiv.org/abs/2207.08323",
    "authors": [
      "Jiahui Fu",
      "Chengyuan Lin",
      "Yuichi Taguchi",
      "Andrea Cohen",
      "Yifu Zhang",
      "Stephen Mylabathula",
      "John J. Leonard"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08329",
    "title": "Bayesian Quickest Change Detection of an Intruder in Acknowledgments for  Private Remote State Estimation",
    "abstract": "For geographically separated cyber-physical systems, state estimation at a remote monitoring or control site is important to ensure stability and reliability of the system. Often for safety or commercial reasons it is necessary to ensure confidentiality of the process state and control information. A current topic of interest is the private transmission of confidential state information. Many transmission encoding schemes rely on acknowledgments, which may be susceptible to interference from an adversary. We consider a stealthy intruder that selectively blocks acknowledgments allowing an eavesdropper to obtain a reliable state estimate defeating an encoding scheme. We utilize Bayesian Quickest Change Detection techniques to quickly detect online the presence of an intruder at both the remote transmitter and receiver. ",
    "url": "https://arxiv.org/abs/2207.08329",
    "authors": [
      "Justin M. Kennedy",
      "Jason J. Ford",
      "Daniel E. Quevedo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.08335",
    "title": "Concurrent Composition Theorems for all Standard Variants of  Differential Privacy",
    "abstract": "We study the concurrent composition properties of interactive differentially private mechanisms, whereby an adversary can arbitrarily interleave its queries to the different mechanisms. We prove that all composition theorems for non-interactive differentially private mechanisms extend to the concurrent composition of interactive differentially private mechanisms for all standard variants of differential privacy including $(\\eps,\\delta)$-DP with $\\delta>0$, R\\`enyi DP, and $f$-DP, thus answering the open question by \\cite{vadhan2021concurrent}. For $f$-DP, which captures $(\\eps,\\delta)$-DP as a special case, we prove the concurrent composition theorems by showing that every interactive $f$-DP mechanism can be simulated by interactive post-processing of a non-interactive $f$-DP mechanism. For R\\`enyi DP, we use a different approach by showing a triangle-like inequality of R\\`enyi divergence in the special setting of concurrent interaction. ",
    "url": "https://arxiv.org/abs/2207.08335",
    "authors": [
      "Salil Vadhan",
      "Wanrong Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2207.08338",
    "title": "MobileCodec: Neural Inter-frame Video Compression on Mobile Devices",
    "abstract": "Realizing the potential of neural video codecs on mobile devices is a big technological challenge due to the computational complexity of deep networks and the power-constrained mobile hardware. We demonstrate practical feasibility by leveraging Qualcomm's technology and innovation, bridging the gap from neural network-based codec simulations running on wall-powered workstations, to real-time operation on a mobile device powered by Snapdragon technology. We show the first-ever inter-frame neural video decoder running on a commercial mobile phone, decoding high-definition videos in real-time while maintaining a low bitrate and high visual quality. ",
    "url": "https://arxiv.org/abs/2207.08338",
    "authors": [
      "Hoang Le",
      "Liang Zhang",
      "Amir Said",
      "Guillaume Sautiere",
      "Yang Yang",
      "Pranav Shrestha",
      "Fei Yin",
      "Reza Pourreza",
      "Auke Wiggers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.08349",
    "title": "Retweet-BERT: Political Leaning Detection Using Language Features and  Information Diffusion on Social Networks",
    "abstract": "Estimating the political leanings of social media users is a challenging and ever more pressing problem given the increase in social media consumption. We introduce Retweet-BERT, a simple and scalable model to estimate the political leanings of Twitter users. Retweet-BERT leverages the retweet network structure and the language used in users' profile descriptions. Our assumptions stem from patterns of networks and linguistics homophily among people who share similar ideologies. Retweet-BERT demonstrates competitive performance against other state-of-the-art baselines, achieving 96%-97% macro-F1 on two recent Twitter datasets (a COVID-19 dataset and a 2020 United States presidential elections dataset). We also perform manual validation to validate the performance of Retweet-BERT on users not in the training data. Finally, in a case study of COVID-19, we illustrate the presence of political echo chambers on Twitter and show that it exists primarily among right-leaning users. Our code is open-sourced and our data is publicly available. ",
    "url": "https://arxiv.org/abs/2207.08349",
    "authors": [
      "Julie Jiang",
      "Xiang Ren",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2207.08356",
    "title": "Learning Knowledge Representation with Meta Knowledge Distillation for  Single Image Super-Resolution",
    "abstract": "Knowledge distillation (KD), which can efficiently transfer knowledge from a cumbersome network (teacher) to a compact network (student), has demonstrated its advantages in some computer vision applications. The representation of knowledge is vital for knowledge transferring and student learning, which is generally defined in hand-crafted manners or uses the intermediate features directly. In this paper, we propose a model-agnostic meta knowledge distillation method under the teacher-student architecture for the single image super-resolution task. It provides a more flexible and accurate way to help the teachers transmit knowledge in accordance with the abilities of students via knowledge representation networks (KRNets) with learnable parameters. In order to improve the perception ability of knowledge representation to students' requirements, we propose to solve the transformation process from intermediate outputs to transferred knowledge by employing the student features and the correlation between teacher and student in the KRNets. Specifically, the texture-aware dynamic kernels are generated and then extract texture features to be improved and the corresponding teacher guidance so as to decompose the distillation problem into texture-wise supervision for further promoting the recovery quality of high-frequency details. In addition, the KRNets are optimized in a meta-learning manner to ensure the knowledge transferring and the student learning are beneficial to improving the reconstructed quality of the student. Experiments conducted on various single image super-resolution datasets demonstrate that our proposed method outperforms existing defined knowledge representation related distillation methods, and can help super-resolution algorithms achieve better reconstruction quality without introducing any inference complexity. ",
    "url": "https://arxiv.org/abs/2207.08356",
    "authors": [
      "Han Zhu",
      "Zhenzhong Chen",
      "Shan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08362",
    "title": "Optimization of stochastic switching buffer network via DC programming",
    "abstract": "This letter deals with the optimization problems of stochastic switching buffer networks, where the switching law is governed by Markov process. The dynamical buffer network is introduced, and its application in modeling the car-sharing network is also presented. To address the nonconvexity for getting a solution as close-to-the-global-optimal as possible of the optimization problem, we adopt a succinct but effective nonconvex optimization method called \\emph{ DC (difference of convex functions) programming}. By resorting to the log-log convexity of a class of nonlinear functions called posynomials, the optimization problems can be reduced to DC programming problems. Finally, we verify the effectiveness of our results by simulation experiments. ",
    "url": "https://arxiv.org/abs/2207.08362",
    "authors": [
      "Chengyan Zhao",
      "Kazunori Sakurama",
      "Masaki Ogura"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.08363",
    "title": "Predictive Neural Speech Coding",
    "abstract": "Neural audio/speech coding has shown its capability to deliver a high quality at much lower bitrates than traditional methods recently. However, existing neural audio/speech codecs employ either acoustic features or learned blind features with a convolutional neural network for encoding, by which there are still temporal redundancies inside encoded features. This paper introduces latent-domain predictive coding into the VQ-VAE framework to fully remove such redundancies and proposes the TF-Codec for low-latency neural speech coding in an end-to-end way. Specifically, the extracted features are encoded conditioned on a prediction from past quantized latent frames so that temporal correlations are further removed. What's more, we introduce a learnable compression on the time-frequency input to adaptively adjust the attention paid on main frequencies and details at different bitrates. A differentiable vector quantization scheme based on distance-to-soft mapping and Gumbel-Softmax is proposed to better model the latent distributions with rate constraint. Subjective results on multilingual speech datasets show that with a latency of 40ms, the proposed TF-Codec at 1kbps can achieve a much better quality than Opus 9kbps and TF-Codec at 3kbps outperforms both EVS 9.6kbps and Opus 12kbps. Numerous studies are conducted to show the effectiveness of these techniques. ",
    "url": "https://arxiv.org/abs/2207.08363",
    "authors": [
      "Xue Jiang",
      "Xiulian Peng",
      "Huaying Xue",
      "Yuan Zhang",
      "Yan Lu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.08365",
    "title": "CausNet : Generational orderings based search for optimal Bayesian  networks via dynamic programming with parent set constraints",
    "abstract": "Finding a globally optimal Bayesian Network using exhaustive search is a problem with super-exponential complexity, which severely restricts the number of variables that it can work for. We implement a dynamic programming based algorithm with built-in dimensionality reduction and parent set identification. This reduces the search space drastically and can be applied to large-dimensional data. We use what we call generational orderings based search for optimal networks, which is a novel way to efficiently search the space of possible networks given the possible parent sets. The algorithm supports both continuous and categorical data, and categorical as well as survival outcomes. We demonstrate the efficacy of our algorithm on both synthetic and real data. In simulations, our algorithm performs better than three state-of-art algorithms that are currently used extensively. We then apply it to an Ovarian Cancer gene expression dataset with 513 genes and a survival outcome. Our algorithm is able to find an optimal network describing the disease pathway consisting of 6 genes leading to the outcome node in a few minutes on a basic computer. Our generational orderings based search for optimal networks, is both efficient and highly scalable approach to finding optimal Bayesian Networks, that can be applied to 1000s of variables. Using specifiable parameters - correlation, FDR cutoffs, and in-degree - one can increase or decrease the number of nodes and density of the networks. Availability of two scoring option-BIC and Bge-and implementation of survival outcomes and mixed data types makes our algorithm very suitable for many types of high dimensional biomedical data to find disease pathways. ",
    "url": "https://arxiv.org/abs/2207.08365",
    "authors": [
      "Nand Sharma",
      "Joshua Millstein"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.08367",
    "title": "Protecting Global Properties of Datasets with Distribution Privacy  Mechanisms",
    "abstract": "Alongside the rapid development of data collection and analysis techniques in recent years, there is increasingly an emphasis on the need to address information leakage associated with such usage of data. To this end, much work in the privacy literature is devoted to the protection of individual users and contributors of data. However, some situations instead require a different notion of data confidentiality involving global properties aggregated over the records of a dataset. Such notions of information protection are particularly applicable for business and organization data, where global properties may reflect trade secrets, or demographic data, which can be harmful if mishandled. Recent work on property inference attacks furthermore shows how data analysis algorithms can be susceptible to leaking these global properties of data, highlighting the importance of developing mechanisms that can protect such information. In this work, we demonstrate how a distribution privacy framework can be applied to formalize the problem of protecting global properties of datasets. Given this framework, we investigate several mechanisms and their tradeoffs for providing this notion of data confidentiality. We analyze the theoretical protection guarantees offered by these mechanisms under various data assumptions, then implement and empirically evaluate these mechanisms for several data analysis tasks. The results of our experiments show that our mechanisms can indeed reduce the effectiveness of practical property inference attacks while providing utility substantially greater than a crude group differential privacy baseline. Our work thus provides groundwork for theoretically supported mechanisms for protecting global properties of datasets. ",
    "url": "https://arxiv.org/abs/2207.08367",
    "authors": [
      "Michelle Chen",
      "Olga Ohrimenko"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08369",
    "title": "PerfCE: Performance Debugging on Databases with Chaos  Engineering-Enhanced Causality Analysis",
    "abstract": "Debugging performance anomalies in real-world databases is challenging. Causal inference techniques enable qualitative and quantitative root cause analysis of performance downgrade. Nevertheless, causality analysis is practically challenging, particularly due to limited observability. Recently, chaos engineering has been applied to test complex real-world software systems. Chaos frameworks like Chaos Mesh mutate a set of chaos variables to inject catastrophic events (e.g., network slowdowns) to \"stress\" software systems. The systems under chaos stress are then tested using methods like differential testing to check if they retain their normal functionality (e.g., SQL query output is always correct under stress). Despite its ubiquity in the industry, chaos engineering is now employed mostly to aid software testing rather for performance debugging. This paper identifies novel usage of chaos engineering on helping developers diagnose performance anomalies in databases. Our presented framework, PERFCE, comprises an offline phase and an online phase. The offline phase learns the statistical models of the target database system, whilst the online phase diagnoses the root cause of monitored performance anomalies on the fly. During the offline phase, PERFCE leverages both passive observations and proactive chaos experiments to constitute accurate causal graphs and structural equation models (SEMs). When observing performance anomalies during the online phase, causal graphs enable qualitative root cause identification (e.g., high CPU usage) and SEMs enable quantitative counterfactual analysis (e.g., determining \"when CPU usage is reduced to 45\\%, performance returns to normal\"). PERFCE notably outperforms prior works on common synthetic datasets, and our evaluation on real-world databases, MySQL and TiDB, shows that PERFCE is highly accurate and moderately expensive. ",
    "url": "https://arxiv.org/abs/2207.08369",
    "authors": [
      "Zhenlan Ji",
      "Pingchuan Ma",
      "Shuai Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2207.08374",
    "title": "Adversarial Contrastive Learning via Asymmetric InfoNCE",
    "abstract": "Contrastive learning (CL) has recently been applied to adversarial learning tasks. Such practice considers adversarial samples as additional positive views of an instance, and by maximizing their agreements with each other, yields better adversarial robustness. However, this mechanism can be potentially flawed, since adversarial perturbations may cause instance-level identity confusion, which can impede CL performance by pulling together different instances with separate identities. To address this issue, we propose to treat adversarial samples unequally when contrasted, with an asymmetric InfoNCE objective ($A-InfoNCE$) that allows discriminating considerations of adversarial samples. Specifically, adversaries are viewed as inferior positives that induce weaker learning signals, or as hard negatives exhibiting higher contrast to other negative samples. In the asymmetric fashion, the adverse impacts of conflicting objectives between CL and adversarial learning can be effectively mitigated. Experiments show that our approach consistently outperforms existing Adversarial CL methods across different finetuning schemes without additional computational cost. The proposed A-InfoNCE is also a generic form that can be readily extended to other CL methods. Code is available at https://github.com/yqy2001/A-InfoNCE. ",
    "url": "https://arxiv.org/abs/2207.08374",
    "authors": [
      "Qiying Yu",
      "Jieming Lou",
      "Xianyuan Zhan",
      "Qizhang Li",
      "Wangmeng Zuo",
      "Yang Liu",
      "Jingjing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08377",
    "title": "Deep Manifold Learning with Graph Mining",
    "abstract": "Admittedly, Graph Convolution Network (GCN) has achieved excellent results on graph datasets such as social networks, citation networks, etc. However, softmax used as the decision layer in these frameworks is generally optimized with thousands of iterations via gradient descent. Furthermore, due to ignoring the inner distribution of the graph nodes, the decision layer might lead to an unsatisfactory performance in semi-supervised learning with less label support. To address the referred issues, we propose a novel graph deep model with a non-gradient decision layer for graph mining. Firstly, manifold learning is unified with label local-structure preservation to capture the topological information of the nodes. Moreover, owing to the non-gradient property, closed-form solutions is achieved to be employed as the decision layer for GCN. Particularly, a joint optimization method is designed for this graph model, which extremely accelerates the convergence of the model. Finally, extensive experiments show that the proposed model has achieved state-of-the-art performance compared to the current models. ",
    "url": "https://arxiv.org/abs/2207.08377",
    "authors": [
      "Xuelong Li",
      "Ziheng Jiao",
      "Hongyuan Zhang",
      "Rui Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.08380",
    "title": "Visual Representations of Physiological Signals for Fake Video Detection",
    "abstract": "Realistic fake videos are a potential tool for spreading harmful misinformation given our increasing online presence and information intake. This paper presents a multimodal learning-based method for detection of real and fake videos. The method combines information from three modalities - audio, video, and physiology. We investigate two strategies for combining the video and physiology modalities, either by augmenting the video with information from the physiology or by novelly learning the fusion of those two modalities with a proposed Graph Convolutional Network architecture. Both strategies for combining the two modalities rely on a novel method for generation of visual representations of physiological signals. The detection of real and fake videos is then based on the dissimilarity between the audio and modified video modalities. The proposed method is evaluated on two benchmark datasets and the results show significant increase in detection performance compared to previous methods. ",
    "url": "https://arxiv.org/abs/2207.08380",
    "authors": [
      "Kalin Stefanov",
      "Bhawna Paliwal",
      "Abhinav Dhall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08386",
    "title": "Entity-enhanced Adaptive Reconstruction Network for Weakly Supervised  Referring Expression Grounding",
    "abstract": "Weakly supervised Referring Expression Grounding (REG) aims to ground a particular target in an image described by a language expression while lacking the correspondence between target and expression. Two main problems exist in weakly supervised REG. First, the lack of region-level annotations introduces ambiguities between proposals and queries. Second, most previous weakly supervised REG methods ignore the discriminative location and context of the referent, causing difficulties in distinguishing the target from other same-category objects. To address the above challenges, we design an entity-enhanced adaptive reconstruction network (EARN). Specifically, EARN includes three modules: entity enhancement, adaptive grounding, and collaborative reconstruction. In entity enhancement, we calculate semantic similarity as supervision to select the candidate proposals. Adaptive grounding calculates the ranking score of candidate proposals upon subject, location and context with hierarchical attention. Collaborative reconstruction measures the ranking result from three perspectives: adaptive reconstruction, language reconstruction and attribute classification. The adaptive mechanism helps to alleviate the variance of different referring expressions. Experiments on five datasets show EARN outperforms existing state-of-the-art methods. Qualitative results demonstrate that the proposed EARN can better handle the situation where multiple objects of a particular category are situated together. ",
    "url": "https://arxiv.org/abs/2207.08386",
    "authors": [
      "Xuejing Liu",
      "Liang Li",
      "Shuhui Wang",
      "Zheng-Jun Zha",
      "Zechao Li",
      "Qi Tian",
      "Qingming Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08387",
    "title": "A Semantic-aware Attention and Visual Shielding Network for  Cloth-changing Person Re-identification",
    "abstract": "Cloth-changing person reidentification (ReID) is a newly emerging research topic that aims to retrieve pedestrians whose clothes are changed. Since the human appearance with different clothes exhibits large variations, it is very difficult for existing approaches to extract discriminative and robust feature representations. Current works mainly focus on body shape or contour sketches, but the human semantic information and the potential consistency of pedestrian features before and after changing clothes are not fully explored or are ignored. To solve these issues, in this work, a novel semantic-aware attention and visual shielding network for cloth-changing person ReID (abbreviated as SAVS) is proposed where the key idea is to shield clues related to the appearance of clothes and only focus on visual semantic information that is not sensitive to view/posture changes. Specifically, a visual semantic encoder is first employed to locate the human body and clothing regions based on human semantic segmentation information. Then, a human semantic attention module (HSA) is proposed to highlight the human semantic information and reweight the visual feature map. In addition, a visual clothes shielding module (VCS) is also designed to extract a more robust feature representation for the cloth-changing task by covering the clothing regions and focusing the model on the visual semantic information unrelated to the clothes. Most importantly, these two modules are jointly explored in an end-to-end unified framework. Extensive experiments demonstrate that the proposed method can significantly outperform state-of-the-art methods, and more robust features can be extracted for cloth-changing persons. Compared with FSAM (published in CVPR 2021), this method can achieve improvements of 32.7% (16.5%) and 14.9% (-) on the LTCC and PRCC datasets in terms of mAP (rank-1), respectively. ",
    "url": "https://arxiv.org/abs/2207.08387",
    "authors": [
      "Zan Gao",
      "Hongwei Wei",
      "Weili Guan",
      "Jie Nie",
      "Meng Wang",
      "Shenyong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08409",
    "title": "TokenMix: Rethinking Image Mixing for Data Augmentation in Vision  Transformers",
    "abstract": "CutMix is a popular augmentation technique commonly used for training modern convolutional and transformer vision networks. It was originally designed to encourage Convolution Neural Networks (CNNs) to focus more on an image's global context instead of local information, which greatly improves the performance of CNNs. However, we found it to have limited benefits for transformer-based architectures that naturally have a global receptive field. In this paper, we propose a novel data augmentation technique TokenMix to improve the performance of vision transformers. TokenMix mixes two images at token level via partitioning the mixing region into multiple separated parts. Besides, we show that the mixed learning target in CutMix, a linear combination of a pair of the ground truth labels, might be inaccurate and sometimes counter-intuitive. To obtain a more suitable target, we propose to assign the target score according to the content-based neural activation maps of the two images from a pre-trained teacher model, which does not need to have high performance. With plenty of experiments on various vision transformer architectures, we show that our proposed TokenMix helps vision transformers focus on the foreground area to infer the classes and enhances their robustness to occlusion, with consistent performance gains. Notably, we improve DeiT-T/S/B with +1% ImageNet top-1 accuracy. Besides, TokenMix enjoys longer training, which achieves 81.2% top-1 accuracy on ImageNet with DeiT-S trained for 400 epochs. Code is available at https://github.com/Sense-X/TokenMix. ",
    "url": "https://arxiv.org/abs/2207.08409",
    "authors": [
      "Jihao Liu",
      "Boxiao Liu",
      "Hang Zhou",
      "Hongsheng Li",
      "Yu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08414",
    "title": "Outlier Explanation via Sum-Product Networks",
    "abstract": "Outlier explanation is the task of identifying a set of features that distinguish a sample from normal data, which is important for downstream (human) decision-making. Existing methods are based on beam search in the space of feature subsets. They quickly becomes computationally expensive, as they require to run an outlier detection algorithm from scratch for each feature subset. To alleviate this problem, we propose a novel outlier explanation algorithm based on Sum-Product Networks (SPNs), a class of probabilistic circuits. Our approach leverages the tractability of marginal inference in SPNs to compute outlier scores in feature subsets. By using SPNs, it becomes feasible to perform backwards elimination instead of the usual forward beam search, which is less susceptible to missing relevant features in an explanation, especially when the number of features is large. We empirically show that our approach achieves state-of-the-art results for outlier explanation, outperforming recent search-based as well as deep learning-based explanation methods ",
    "url": "https://arxiv.org/abs/2207.08414",
    "authors": [
      "Stefan L\u00fcdtke",
      "Christian Bartelt",
      "Heiner Stuckenschmidt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08417",
    "title": "Real-time End-to-End Video Text Spotter with Contrastive Representation  Learning",
    "abstract": "Video text spotting(VTS) is the task that requires simultaneously detecting, tracking and recognizing text in the video. Existing video text spotting methods typically develop sophisticated pipelines and multiple models, which is not friend for real-time applications. Here we propose a real-time end-to-end video text spotter with Contrastive Representation learning (CoText). Our contributions are three-fold: 1) CoText simultaneously address the three tasks (e.g., text detection, tracking, recognition) in a real-time end-to-end trainable framework. 2) With contrastive learning, CoText models long-range dependencies and learning temporal information across multiple frames. 3) A simple, lightweight architecture is designed for effective and accurate performance, including GPU-parallel detection post-processing, CTC-based recognition head with Masked RoI. Extensive experiments show the superiority of our method. Especially, CoText achieves an video text spotting IDF1 of 72.0% at 41.0 FPS on ICDAR2015video, with 10.5% and 32.0 FPS improvement the previous best method. The code can be found at github.com/weijiawu/CoText. ",
    "url": "https://arxiv.org/abs/2207.08417",
    "authors": [
      "Wejia Wu",
      "Zhuang Li",
      "Jiahong Li",
      "Chunhua Shen",
      "Hong Zhou",
      "Size Li",
      "Zhongyuan Wang",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08424",
    "title": "Fully trainable Gaussian derivative convolutional layer",
    "abstract": "The Gaussian kernel and its derivatives have already been employed for Convolutional Neural Networks in several previous works. Most of these papers proposed to compute filters by linearly combining one or several bases of fixed or slightly trainable Gaussian kernels with or without their derivatives. In this article, we propose a high-level configurable layer based on anisotropic, oriented and shifted Gaussian derivative kernels which generalize notions encountered in previous related works while keeping their main advantage. The results show that the proposed layer has competitive performance compared to previous works and that it can be successfully included in common deep architectures such as VGG16 for image classification and U-net for image segmentation. ",
    "url": "https://arxiv.org/abs/2207.08424",
    "authors": [
      "Valentin Penaud--Polge",
      "Santiago Velasco-Forero",
      "Jesus Angulo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.08426",
    "title": "Fast Convergence of Optimistic Gradient Ascent in Network Zero-Sum  Extensive Form Games",
    "abstract": "The study of learning in games has thus far focused primarily on normal form games. In contrast, our understanding of learning in extensive form games (EFGs) and particularly in EFGs with many agents lags far behind, despite them being closer in nature to many real world applications. We consider the natural class of Network Zero-Sum Extensive Form Games, which combines the global zero-sum property of agent payoffs, the efficient representation of graphical games as well the expressive power of EFGs. We examine the convergence properties of Optimistic Gradient Ascent (OGA) in these games. We prove that the time-average behavior of such online learning dynamics exhibits $O(1/T)$ rate convergence to the set of Nash Equilibria. Moreover, we show that the day-to-day behavior also converges to Nash with rate $O(c^{-t})$ for some game-dependent constant $c>0$. ",
    "url": "https://arxiv.org/abs/2207.08426",
    "authors": [
      "Georgios Piliouras",
      "Lillian Ratliff",
      "Ryann Sim",
      "Stratis Skoulakis"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2207.08436",
    "title": "Software Artifact Mining in Software Engineering Conferences: A  Meta-Analysis",
    "abstract": "Background: Software development results in the production of various types of artifacts: source code, version control system metadata, bug reports, mailing list conversations, test data, etc. Empirical software engineering (ESE) has thrived mining those artifacts to uncover the inner workings of software development and improve its practices. But which artifacts are studied in the field is a moving target, which we study empirically in this paper.Aims: We quantitatively characterize the most frequently mined and co-mined software artifacts in ESE research and the research purposes they support.Method: We conduct a meta-analysis of artifact mining studies published in 11 top conferences in ESE, for a total of 9621 papers. We use natural language processing (NLP) techniques to characterize the types of software artifacts that are most often mined and their evolution over a 16-year period (2004-2020). We analyze the combinations of artifact types that are most often mined together, as well as the relationship between study purposes and mined artifacts.Results: We find that: (1) mining happens in the vast majority of analyzed papers, (2) source code and test data are the most mined artifacts, (3) there is an increasing interest in mining novel artifacts, together with source code, (4) researchers are most interested in the evaluation of software systems and use all possible empirical signals to support that goal. ",
    "url": "https://arxiv.org/abs/2207.08436",
    "authors": [
      "Zeinab Abou Khalil",
      "Stefano Zacchiroli"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2207.08455",
    "title": "Open-world Semantic Segmentation via Contrasting and Clustering  Vision-Language Embedding",
    "abstract": "To bridge the gap between supervised semantic segmentation and real-world applications that acquires one model to recognize arbitrary new concepts, recent zero-shot segmentation attracts a lot of attention by exploring the relationships between unseen and seen object categories, yet requiring large amounts of densely-annotated data with diverse base classes. In this paper, we propose a new open-world semantic segmentation pipeline that makes the first attempt to learn to segment semantic objects of various open-world categories without any efforts on dense annotations, by purely exploiting the image-caption data that naturally exist on the Internet. Our method, Vision-language-driven Semantic Segmentation (ViL-Seg), employs an image and a text encoder to generate visual and text embeddings for the image-caption data, with two core components that endow its segmentation ability: First, the image encoder is jointly trained with a vision-based contrasting and a cross-modal contrasting, which encourage the visual embeddings to preserve both fine-grained semantics and high-level category information that are crucial for the segmentation task. Furthermore, an online clustering head is devised over the image encoder, which allows to dynamically segment the visual embeddings into distinct semantic groups such that they can be classified by comparing with various text embeddings to complete our segmentation pipeline. Experiments show that without using any data with dense annotations, our method can directly segment objects of arbitrary categories, outperforming zero-shot segmentation methods that require data labeling on three benchmark datasets. ",
    "url": "https://arxiv.org/abs/2207.08455",
    "authors": [
      "Quande Liu",
      "Youpeng Wen",
      "Jianhua Han",
      "Chunjing Xu",
      "Hang Xu",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08457",
    "title": "A Meta-Reinforcement Learning Algorithm for Causal Discovery",
    "abstract": "Causal discovery is a major task with the utmost importance for machine learning since causal structures can enable models to go beyond pure correlation-based inference and significantly boost their performance. However, finding causal structures from data poses a significant challenge both in computational effort and accuracy, let alone its impossibility without interventions in general. In this paper, we develop a meta-reinforcement learning algorithm that performs causal discovery by learning to perform interventions such that it can construct an explicit causal graph. Apart from being useful for possible downstream applications, the estimated causal graph also provides an explanation for the data-generating process. In this article, we show that our algorithm estimates a good graph compared to the SOTA approaches, even in environments whose underlying causal structure is previously unseen. Further, we make an ablation study that shows how learning interventions contribute to the overall performance of our approach. We conclude that interventions indeed help boost the performance, efficiently yielding an accurate estimate of the causal structure of a possibly unseen environment. ",
    "url": "https://arxiv.org/abs/2207.08457",
    "authors": [
      "Andreas Sauter",
      "Erman Acar",
      "Vincent Fran\u00e7ois-Lavet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2207.08483",
    "title": "wPINNs: Weak Physics informed neural networks for approximating entropy  solutions of hyperbolic conservation laws",
    "abstract": "Physics informed neural networks (PINNs) require regularity of solutions of the underlying PDE to guarantee accurate approximation. Consequently, they may fail at approximating discontinuous solutions of PDEs such as nonlinear hyperbolic equations. To ameliorate this, we propose a novel variant of PINNs, termed as weak PINNs (wPINNs) for accurate approximation of entropy solutions of scalar conservation laws. wPINNs are based on approximating the solution of a min-max optimization problem for a residual, defined in terms of Kruzkhov entropies, to determine parameters for the neural networks approximating the entropy solution as well as test functions. We prove rigorous bounds on the error incurred by wPINNs and illustrate their performance through numerical experiments to demonstrate that wPINNs can approximate entropy solutions accurately. ",
    "url": "https://arxiv.org/abs/2207.08483",
    "authors": [
      "Tim De Ryck",
      "Siddhartha Mishra",
      "Roberto Molinaro"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2207.08485",
    "title": "Hierarchical Feature Alignment Network for Unsupervised Video Object  Segmentation",
    "abstract": "Optical flow is an easily conceived and precious cue for advancing unsupervised video object segmentation (UVOS). Most of the previous methods directly extract and fuse the motion and appearance features for segmenting target objects in the UVOS setting. However, optical flow is intrinsically an instantaneous velocity of all pixels among consecutive frames, thus making the motion features not aligned well with the primary objects among the corresponding frames. To solve the above challenge, we propose a concise, practical, and efficient architecture for appearance and motion feature alignment, dubbed hierarchical feature alignment network (HFAN). Specifically, the key merits in HFAN are the sequential Feature AlignMent (FAM) module and the Feature AdaptaTion (FAT) module, which are leveraged for processing the appearance and motion features hierarchically. FAM is capable of aligning both appearance and motion features with the primary object semantic representations, respectively. Further, FAT is explicitly designed for the adaptive fusion of appearance and motion features to achieve a desirable trade-off between cross-modal features. Extensive experiments demonstrate the effectiveness of the proposed HFAN, which reaches a new state-of-the-art performance on DAVIS-16, achieving 88.7 $\\mathcal{J}\\&\\mathcal{F}$ Mean, i.e., a relative improvement of 3.5% over the best published result. ",
    "url": "https://arxiv.org/abs/2207.08485",
    "authors": [
      "Gensheng Pei",
      "Yazhou Yao",
      "Guo-Sen Xie",
      "Fumin Shen",
      "Zhenmin Tang",
      "Jinhui Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08486",
    "title": "Detection of Poisoning Attacks with Anomaly Detection in Federated  Learning for Healthcare Applications: A Machine Learning Approach",
    "abstract": "The application of Federated Learning (FL) is steadily increasing, especially in privacy-aware applications, such as healthcare. However, its applications have been limited by security concerns due to various adversarial attacks, such as poisoning attacks (model and data poisoning). Such attacks attempt to poison the local models and data to manipulate the global models in order to obtain undue benefits and malicious use. Traditional methods of data auditing to mitigate poisoning attacks find their limited applications in FL because the edge devices never share their raw data directly due to privacy concerns, and are globally distributed with no insight into their training data. Thereafter, it is challenging to develop appropriate strategies to address such attacks and minimize their impact on the global model in federated learning. In order to address such challenges in FL, we proposed a novel framework to detect poisoning attacks using deep neural networks and support vector machines, in the form of anomaly without acquiring any direct access or information about the underlying training data of local edge devices. We illustrate and evaluate the proposed framework using different state of art poisoning attacks for two different healthcare applications: Electrocardiograph classification and human activity recognition. Our experimental analysis shows that the proposed method can efficiently detect poisoning attacks and can remove the identified poisoned updated from the global aggregation. Thereafter can increase the performance of the federated global. ",
    "url": "https://arxiv.org/abs/2207.08486",
    "authors": [
      "Ali Raza",
      "Shujun Li",
      "Kim-Phuc Tran",
      "Ludovic Koehl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.08501",
    "title": "Explainable Deep Belief Network based Auto encoder using novel Extended  Garson Algorithm",
    "abstract": "The most difficult task in machine learning is to interpret trained shallow neural networks. Deep neural networks (DNNs) provide impressive results on a larger number of tasks, but it is generally still unclear how decisions are made by such a trained deep neural network. Providing feature importance is the most important and popular interpretation technique used in shallow and deep neural networks. In this paper, we develop an algorithm extending the idea of Garson Algorithm to explain Deep Belief Network based Auto-encoder (DBNA). It is used to determine the contribution of each input feature in the DBN. It can be used for any kind of neural network with many hidden layers. The effectiveness of this method is tested on both classification and regression datasets taken from literature. Important features identified by this method are compared against those obtained by Wald chi square (\\c{hi}2). For 2 out of 4 classification datasets and 2 out of 5 regression datasets, our proposed methodology resulted in the identification of better-quality features leading to statistically more significant results vis-\\`a-vis Wald \\c{hi}2. ",
    "url": "https://arxiv.org/abs/2207.08501",
    "authors": [
      "Satyam Kumar",
      "Vadlamani Ravi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2207.08531",
    "title": "DID-M3D: Decoupling Instance Depth for Monocular 3D Object Detection",
    "abstract": "Monocular 3D detection has drawn much attention from the community due to its low cost and setup simplicity. It takes an RGB image as input and predicts 3D boxes in the 3D space. The most challenging sub-task lies in the instance depth estimation. Previous works usually use a direct estimation method. However, in this paper we point out that the instance depth on the RGB image is non-intuitive. It is coupled by visual depth clues and instance attribute clues, making it hard to be directly learned in the network. Therefore, we propose to reformulate the instance depth to the combination of the instance visual surface depth (visual depth) and the instance attribute depth (attribute depth). The visual depth is related to objects' appearances and positions on the image. By contrast, the attribute depth relies on objects' inherent attributes, which are invariant to the object affine transformation on the image. Correspondingly, we decouple the 3D location uncertainty into visual depth uncertainty and attribute depth uncertainty. By combining different types of depths and associated uncertainties, we can obtain the final instance depth. Furthermore, data augmentation in monocular 3D detection is usually limited due to the physical nature, hindering the boost of performance. Based on the proposed instance depth disentanglement strategy, we can alleviate this problem. Evaluated on KITTI, our method achieves new state-of-the-art results, and extensive ablation studies validate the effectiveness of each component in our method. The codes are released at https://github.com/SPengLiang/DID-M3D. ",
    "url": "https://arxiv.org/abs/2207.08531",
    "authors": [
      "Liang Peng",
      "Xiaopei Wu",
      "Zheng Yang",
      "Haifeng Liu",
      "Deng Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08533",
    "title": "BrainCog: A Spiking Neural Network based Brain-inspired Cognitive  Intelligence Engine for Brain-inspired AI and Brain Simulation",
    "abstract": "Spiking neural networks (SNNs) have attracted extensive attentions in Brain-inspired Artificial Intelligence and computational neuroscience. They can be used to simulate biological information processing in the brain at multiple scales. More importantly, SNNs serve as an appropriate level of abstraction to bring inspirations from brain and cognition to Artificial Intelligence. In this paper, we present the Brain-inspired Cognitive Intelligence Engine (BrainCog) for creating brain-inspired AI and brain simulation models. BrainCog incorporates different types of spiking neuron models, learning rules, brain areas, etc., as essential modules provided by the platform. Based on these easy-to-use modules, BrainCog supports various brain-inspired cognitive functions, including Perception and Learning, Decision Making, Knowledge Representation and Reasoning, Motor Control, and Social Cognition. These brain-inspired AI models have been effectively validated on various supervised, unsupervised, and reinforcement learning tasks, and they can be used to enable AI models to be with multiple brain-inspired cognitive functions. For brain simulation, BrainCog realizes the function simulation of decision-making, working memory, the structure simulation of the Neural Circuit, and whole brain structure simulation of Mouse brain, Macaque brain, and Human brain. An AI engine named BORN is developed based on BrainCog, and it demonstrates how the components of BrainCog can be integrated and used to build AI models and applications. To enable the scientific quest to decode the nature of biological intelligence and create AI, BrainCog aims to provide essential and easy-to-use building blocks, and infrastructural support to develop brain-inspired spiking neural network based AI, and to simulate the cognitive brains at multiple scales. The online repository of BrainCog can be found at https://github.com/braincog-x. ",
    "url": "https://arxiv.org/abs/2207.08533",
    "authors": [
      "Yi Zeng",
      "Dongcheng Zhao",
      "Feifei Zhao",
      "Guobin Shen",
      "Yiting Dong",
      "Enmeng Lu",
      "Qian Zhang",
      "Yinqian Sun",
      "Qian Liang",
      "Yuxuan Zhao",
      "Zhuoya Zhao",
      "Hongjian Fang",
      "Yuwei Wang",
      "Yang Li",
      "Xin Liu",
      "Chengcheng Du",
      "Qingqun Kong",
      "Zizhe Ruan",
      "Weida Bi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2207.08534",
    "title": "The Vocal Signature of Social Anxiety: Exploration using  Hypothesis-Testing and Machine-Learning Approaches",
    "abstract": "Background - Social anxiety (SA) is a common and debilitating condition, negatively affecting life quality even at sub-diagnostic thresholds. We sought to characterize SA's acoustic signature using hypothesis-testing and machine learning (ML) approaches. Methods - Participants formed spontaneous utterances responding to instructions to refuse or consent to commands of alleged peers. Vocal properties (e.g., intensity and duration) of these utterances were analyzed. Results - Our prediction that, as compared to low-SA (n=31), high-SA (n=32) individuals exhibit a less confident vocal speech signature, especially with respect to refusal utterances, was only partially supported by the classical hypothesis-testing approach. However, the results of the ML analyses and specifically the decision tree classifier were consistent with such speech patterns in SA. Using a Gaussian Process (GP) classifier, we were able to distinguish between high- and low-SA individuals with high (75.6%) accuracy and good (.83 AUC) separability. We also expected and found that vocal properties differentiated between refusal and consent utterances. Conclusions - Our findings provide further support for the usefulness of ML approach for the study of psychopathology, highlighting the utility of developing automatic techniques to create behavioral markers of SAD. Clinically, the simplicity and accessibility of these procedures may encourage people to seek professional help. ",
    "url": "https://arxiv.org/abs/2207.08534",
    "authors": [
      "Or Alon-Ronen",
      "Yosi Shrem",
      "Yossi Keshet",
      "Eva Gilboa-Schechtman"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.08536",
    "title": "UniFormer: Unified Multi-view Fusion Transformer for Spatial-Temporal  Representation in Bird's-Eye-View",
    "abstract": "Bird's eye view (BEV) representation is a new perception formulation for autonomous driving, which is based on spatial fusion. Further, temporal fusion is also introduced in BEV representation and gains great success. In this work, we propose a new method that unifies both spatial and temporal fusion and merges them into a unified mathematical formulation. The unified fusion could not only provide a new perspective on BEV fusion but also brings new capabilities. With the proposed unified spatial-temporal fusion, our method could support long-range fusion, which is hard to achieve in conventional BEV methods. Moreover, the BEV fusion in our work is temporal-adaptive, and the weights of temporal fusion are learnable. In contrast, conventional methods mainly use fixed and equal weights for temporal fusion. Besides, the proposed unified fusion could avoid information lost in conventional BEV fusion methods and make full use of features. Extensive experiments and ablation studies on the NuScenes dataset show the effectiveness of the proposed method and our method gains the state-of-the-art performance in the map segmentation task. ",
    "url": "https://arxiv.org/abs/2207.08536",
    "authors": [
      "Zequn Qin",
      "Jingyu Chen",
      "Chao Chen",
      "Xiaozhi Chen",
      "Xi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08544",
    "title": "Hardware-agnostic Computation for Large-scale Knowledge Graph Embeddings",
    "abstract": "Knowledge graph embedding research has mainly focused on learning continuous representations of knowledge graphs towards the link prediction problem. Recently developed frameworks can be effectively applied in research related applications. Yet, these frameworks do not fulfill many requirements of real-world applications. As the size of the knowledge graph grows, moving computation from a commodity computer to a cluster of computers in these frameworks becomes more challenging. Finding suitable hyperparameter settings w.r.t. time and computational budgets are left to practitioners. In addition, the continual learning aspect in knowledge graph embedding frameworks is often ignored, although continual learning plays an important role in many real-world (deep) learning-driven applications. Arguably, these limitations explain the lack of publicly available knowledge graph embedding models for large knowledge graphs. We developed a framework based on the frameworks DASK, Pytorch Lightning and Hugging Face to compute embeddings for large-scale knowledge graphs in a hardware-agnostic manner, which is able to address real-world challenges pertaining to the scale of real application. We provide an open-source version of our framework along with a hub of pre-trained models having more than 11.4 B parameters. ",
    "url": "https://arxiv.org/abs/2207.08544",
    "authors": [
      "Caglar Demir",
      "Axel-Cyrille Ngonga Ngomo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2207.08562",
    "title": "DHGE: Dual-view Hyper-Relational Knowledge Graph Embedding for Link  Prediction and Entity Typing",
    "abstract": "In the field of representation learning on knowledge graphs (KGs), a hyper-relational fact consists of a main triple and several auxiliary attribute value descriptions, which is considered to be more comprehensive and specific than a triple-based fact. However, the existing hyper-relational KG embedding methods in a single view are limited in application due to weakening the hierarchical structure representing the affiliation between entities. To break this limitation, we propose a dual-view hyper-relational KG (DH-KG) structure which contains a hyper-relational instance view for entities and a hyper-relational ontology view for concepts abstracted hierarchically from entities to jointly model hyper-relational and hierarchical information. In this paper, we first define link prediction and entity typing tasks on DH-KG and construct two DH-KG datasets, JW44K-6K extracted from Wikidata and HTDM based on medical data. Furthermore, We propose a DH-KG embedding model DHGE, based on GRAN encoder, HGNN, and joint learning. Experimental results show that DHGE outperforms baseline models on DH-KG. We also provide an example of the application of this technology in the field of hypertension medication. Our model and datasets are publicly available. ",
    "url": "https://arxiv.org/abs/2207.08562",
    "authors": [
      "Haoran Luo",
      "Haihong E",
      "Ling Tan",
      "Xueyuan Lin",
      "Gengxian Zhou",
      "Jundi Li",
      "Tianyu Yao",
      "Kaiyang Wan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08579",
    "title": "Positive Dependency Graphs Revisited",
    "abstract": "Theory of stable models is the mathematical basis of answer set programming. Several results in that theory refer to the concept of the positive dependency graph of a logic program. We describe a modification of that concept and show that the new understanding of positive dependency makes it possible to strengthen some of these results. Under consideration in Theory and Practice of Logic Programming (TPLP). ",
    "url": "https://arxiv.org/abs/2207.08579",
    "authors": [
      "Jorge Fandinno",
      "Vladimir Lifschitz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2207.08583",
    "title": "MAD for Robust Reinforcement Learning in Machine Translation",
    "abstract": "We introduce a new distributed policy gradient algorithm and show that it outperforms existing reward-aware training procedures such as REINFORCE, minimum risk training (MRT) and proximal policy optimization (PPO) in terms of training stability and generalization performance when optimizing machine translation models. Our algorithm, which we call MAD (on account of using the mean absolute deviation in the importance weighting calculation), has distributed data generators sampling multiple candidates per source sentence on worker nodes, while a central learner updates the policy. MAD depends crucially on two variance reduction strategies: (1) a conditional reward normalization method that ensures each source sentence has both positive and negative reward translation examples and (2) a new robust importance weighting scheme that acts as a conditional entropy regularizer. Experiments on a variety of translation tasks show that policies learned using the MAD algorithm perform very well when using both greedy decoding and beam search, and that the learned policies are sensitive to the specific reward used during training. ",
    "url": "https://arxiv.org/abs/2207.08583",
    "authors": [
      "Domenic Donato",
      "Lei Yu",
      "Wang Ling",
      "Chris Dyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.08592",
    "title": "Symmetrized Robust Procrustes: Constant-Factor Approximation and Exact  Recovery",
    "abstract": "The classical $\\textit{Procrustes}$ problem is to find a rigid motion (orthogonal transformation and translation) that best aligns two given point-sets in the least-squares sense. The $\\textit{Robust Procrustes}$ problem is an important variant, in which a power-1 objective is used instead of least squares to improve robustness to outliers. While the optimal solution of the least-squares problem can be easily computed in closed form, dating back to Sch\\\"onemann (1966), no such solution is known for the power-1 problem. In this paper we propose a novel convex relaxation for the Robust Procrustes problem. Our relaxation enjoys several theoretical and practical advantages: Theoretically, we prove that our method provides a $\\sqrt{2}$-factor approximation to the Robust Procrustes problem, and that, under appropriate assumptions, it exactly recovers the true rigid motion from point correspondences contaminated by outliers. In practice, we find in numerical experiments on both synthetic and real robust Procrustes problems, that our method performs similarly to the standard Iteratively Reweighted Least Squares (IRLS). However the convexity of our algorithm allows incorporating additional convex penalties, which are not readily amenable to IRLS. This turns out to be a substantial advantage, leading to improved results in high-dimensional problems, including non-rigid shape alignment and semi-supervised interlingual word translation. ",
    "url": "https://arxiv.org/abs/2207.08592",
    "authors": [
      "Tal Amir",
      "Shahar Kovalsky",
      "Nadav Dym"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2207.08596",
    "title": "Data-driven Self-triggered Control via Trajectory Prediction",
    "abstract": "Self-triggered control, a well-documented technique for reducing the communication overhead while ensuring desired system performance, is gaining increasing popularity. However, existing methods for self-triggered control require explicit system models that are assumed perfectly known a priori. An end-to-end control paradigm known as data-driven control learns control laws directly from data, and offers a competing alternative to the routine system identification-then-control method. In this context, the present paper puts forth data-driven self-triggered control schemes for unknown linear systems using data collected offline. Specifically, for output feedback control systems, a data-driven model predictive control (MPC) scheme is proposed, which computes a sequence of control inputs while generating a predicted system trajectory. A data-driven self-triggering law is designed using the predicted trajectory, to determine the next triggering time once a new measurement becomes available. For state feedback control systems, instead of capitalizing on MPC to predict the trajectory, a data-fitting problem using the pre-collected input-state data is solved, whose solution is employed to construct the self-triggering mechanism. Both feasibility and stability are established for the proposed self-triggered controllers, which are validated using numerical examples. ",
    "url": "https://arxiv.org/abs/2207.08596",
    "authors": [
      "Wenjie Liu",
      "Jian Sun",
      "Gang Wang",
      "Francesco Bullo",
      "Jie Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.08597",
    "title": "FunQG: Molecular Representation Learning Via Quotient Graphs",
    "abstract": "Learning expressive molecular representations is crucial to facilitate the accurate prediction of molecular properties. Despite the significant advancement of graph neural networks (GNNs) in molecular representation learning, they generally face limitations such as neighbors-explosion, under-reaching, over-smoothing, and over-squashing. Also, GNNs usually have high computational complexity because of the large-scale number of parameters. Typically, such limitations emerge or increase when facing relatively large-size graphs or using a deeper GNN model architecture. An idea to overcome these problems is to simplify a molecular graph into a small, rich, and informative one, which is more efficient and less challenging to train GNNs. To this end, we propose a novel molecular graph coarsening framework named FunQG utilizing Functional groups, as influential building blocks of a molecule to determine its properties, based on a graph-theoretic concept called Quotient Graph. By experiments, we show that the resulting informative graphs are much smaller than the molecular graphs and thus are good candidates for training GNNs. We apply the FunQG on popular molecular property prediction benchmarks and then compare the performance of a GNN architecture on the obtained datasets with several state-of-the-art baselines on the original datasets. By experiments, this method significantly outperforms previous baselines on various datasets, besides its dramatic reduction in the number of parameters and low computational complexity. Therefore, the FunQG can be used as a simple, cost-effective, and robust method for solving the molecular representation learning problem. ",
    "url": "https://arxiv.org/abs/2207.08597",
    "authors": [
      "Hossein Hajiabolhassan",
      "Zahra Taheri",
      "Ali Hojatnia",
      "Yavar Taheri Yeganeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2207.08603",
    "title": "Abstraction between Structural Causal Models: A Review of Definitions  and Properties",
    "abstract": "Structural causal models (SCMs) are a widespread formalism to deal with causal systems. A recent direction of research has considered the problem of relating formally SCMs at different levels of abstraction, by defining maps between SCMs and imposing a requirement of interventional consistency. This paper offers a review of the solutions proposed so far, focusing on the formal properties of a map between SCMs, and highlighting the different layers (structural, distributional) at which these properties may be enforced. This allows us to distinguish families of abstractions that may or may not be permitted by choosing to guarantee certain properties instead of others. Such an understanding not only allows to distinguish among proposal for causal abstraction with more awareness, but it also allows to tailor the definition of abstraction with respect to the forms of abstraction relevant to specific applications. ",
    "url": "https://arxiv.org/abs/2207.08603",
    "authors": [
      "Fabio Massimo Zennaro"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08609",
    "title": "ExAgt: Expert-guided Augmentation for Representation Learning of Traffic  Scenarios",
    "abstract": "Representation learning in recent years has been addressed with self-supervised learning methods. The input data is augmented into two distorted views and an encoder learns the representations that are invariant to distortions -- cross-view prediction. Augmentation is one of the key components in cross-view self-supervised learning frameworks to learn visual representations. This paper presents ExAgt, a novel method to include expert knowledge for augmenting traffic scenarios, to improve the learnt representations without any human annotation. The expert-guided augmentations are generated in an automated fashion based on the infrastructure, the interactions between the EGO and the traffic participants and an ideal sensor model. The ExAgt method is applied in two state-of-the-art cross-view prediction methods and the representations learnt are tested in downstream tasks like classification and clustering. Results show that the ExAgt method improves representation learning compared to using only standard augmentations and it provides a better representation space stability. The code is available at \\url{https://github.com/lab176344/ExAgt}. ",
    "url": "https://arxiv.org/abs/2207.08609",
    "authors": [
      "Lakshman Balasubramanian",
      "Jonas Wurst",
      "Robin Egolf",
      "Michael Botsch",
      "Wolfgang Utschick",
      "Ke Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08610",
    "title": "Rapid and robust synchronization via weak synaptic coupling",
    "abstract": "This paper examines how weak synaptic coupling can achieve rapid synchronization in heterogeneous networks. The assumptions aim at capturing the key mathematical properties that make this possible for biophysical networks. In particular, the combination of nodal excitability and synaptic coupling are shown to be essential to the phenomenon. ",
    "url": "https://arxiv.org/abs/2207.08610",
    "authors": [
      "Jin Gyu Lee",
      "Rodolphe Sepulchre"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.08625",
    "title": "Unifying Event Detection and Captioning as Sequence Generation via  Pre-Training",
    "abstract": "Dense video captioning aims to generate corresponding text descriptions for a series of events in the untrimmed video, which can be divided into two sub-tasks, event detection and event captioning. Unlike previous works that tackle the two sub-tasks separately, recent works have focused on enhancing the inter-task association between the two sub-tasks. However, designing inter-task interactions for event detection and captioning is not trivial due to the large differences in their task specific solutions. Besides, previous event detection methods normally ignore temporal dependencies between events, leading to event redundancy or inconsistency problems. To tackle above the two defects, in this paper, we define event detection as a sequence generation task and propose a unified pre-training and fine-tuning framework to naturally enhance the inter-task association between event detection and captioning. Since the model predicts each event with previous events as context, the inter-dependency between events is fully exploited and thus our model can detect more diverse and consistent events in the video. Experiments on the ActivityNet dataset show that our model outperforms the state-of-the-art methods, and can be further boosted when pre-trained on extra large-scale video-text data. Code is available at \\url{https://github.com/QiQAng/UEDVC}. ",
    "url": "https://arxiv.org/abs/2207.08625",
    "authors": [
      "Qi Zhang",
      "Yuqing Song",
      "Qin Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08629",
    "title": "Comprehensive Graph Gradual Pruning for Sparse Training in Graph Neural  Networks",
    "abstract": "Graph Neural Networks (GNNs) tend to suffer from high computation costs due to the exponentially increasing scale of graph data and the number of model parameters, which restricts their utility in practical applications. To this end, some recent works focus on sparsifying GNNs with the lottery ticket hypothesis (LTH) to reduce inference costs while maintaining performance levels. However, the LTH-based methods suffer from two major drawbacks: 1) they require exhaustive and iterative training of dense models, resulting in an extremely large training computation cost, and 2) they only trim graph structures and model parameters but ignore the node feature dimension, where significant redundancy exists. To overcome the above limitations, we propose a comprehensive graph gradual pruning framework termed CGP. This is achieved by designing a during-training graph pruning paradigm to dynamically prune GNNs within one training process. Unlike LTH-based methods, the proposed CGP approach requires no re-training, which significantly reduces the computation costs. Furthermore, we design a co-sparsifying strategy to comprehensively trim all three core elements of GNNs: graph structures, node features, and model parameters. Meanwhile, aiming at refining the pruning operation, we introduce a regrowth process into our CGP framework, in order to re-establish the pruned but important connections. The proposed CGP is evaluated by using a node classification task across 6 GNN architectures, including shallow models (GCN and GAT), shallow-but-deep-propagation models (SGC and APPNP), and deep models (GCNII and ResGCN), on a total of 14 real-world graph datasets, including large-scale graph datasets from the challenging Open Graph Benchmark. Experiments reveal that our proposed strategy greatly improves both training and inference efficiency while matching or even exceeding the accuracy of existing methods. ",
    "url": "https://arxiv.org/abs/2207.08629",
    "authors": [
      "Chuang Liu",
      "Xueqi Ma",
      "Yinbing Zhan",
      "Liang Ding",
      "Dapeng Tao",
      "Bo Du",
      "Wenbin Hu",
      "Danilo Mandic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.08631",
    "title": "Latent Partition Implicit with Surface Codes for 3D Representation",
    "abstract": "Deep implicit functions have shown remarkable shape modeling ability in various 3D computer vision tasks. One drawback is that it is hard for them to represent a 3D shape as multiple parts. Current solutions learn various primitives and blend the primitives directly in the spatial space, which still struggle to approximate the 3D shape accurately. To resolve this problem, we introduce a novel implicit representation to represent a single 3D shape as a set of parts in the latent space, towards both highly accurate and plausibly interpretable shape modeling. Our insight here is that both the part learning and the part blending can be conducted much easier in the latent space than in the spatial space. We name our method Latent Partition Implicit (LPI), because of its ability of casting the global shape modeling into multiple local part modeling, which partitions the global shape unity. LPI represents a shape as Signed Distance Functions (SDFs) using surface codes. Each surface code is a latent code representing a part whose center is on the surface, which enables us to flexibly employ intrinsic attributes of shapes or additional surface properties. Eventually, LPI can reconstruct both the shape and the parts on the shape, both of which are plausible meshes. LPI is a multi-level representation, which can partition a shape into different numbers of parts after training. LPI can be learned without ground truth signed distances, point normals or any supervision for part partition. LPI outperforms the latest methods under the widely used benchmarks in terms of reconstruction accuracy and modeling interpretability. Our code, data and models are available at https://github.com/chenchao15/LPI. ",
    "url": "https://arxiv.org/abs/2207.08631",
    "authors": [
      "Chao Chen",
      "Yu-Shen Liu",
      "Zhihong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08648",
    "title": "Interpolation, extrapolation, and local generalization in common neural  networks",
    "abstract": "There has been a long history of works showing that neural networks have hard time extrapolating beyond the training set. A recent study by Balestriero et al. (2021) challenges this view: defining interpolation as the state of belonging to the convex hull of the training set, they show that the test set, either in input or neural space, cannot lie for the most part in this convex hull, due to the high dimensionality of the data, invoking the well known curse of dimensionality. Neural networks are then assumed to necessarily work in extrapolative mode. We here study the neural activities of the last hidden layer of typical neural networks. Using an autoencoder to uncover the intrinsic space underlying the neural activities, we show that this space is actually low-dimensional, and that the better the model, the lower the dimensionality of this intrinsic space. In this space, most samples of the test set actually lie in the convex hull of the training set: under the convex hull definition, the models thus happen to work in interpolation regime. Moreover, we show that belonging to the convex hull does not seem to be the relevant criteria. Different measures of proximity to the training set are actually better related to performance accuracy. Thus, typical neural networks do seem to operate in interpolation regime. Good generalization performances are linked to the ability of a neural network to operate well in such a regime. ",
    "url": "https://arxiv.org/abs/2207.08648",
    "authors": [
      "Laurent Bonnasse-Gahot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08655",
    "title": "An Enhanced Graph Representation for Machine Learning Based Automatic  Intersection Management",
    "abstract": "The improvement of traffic efficiency at urban intersections receives strong research interest in the field of automated intersection management. So far, mostly non-learning algorithms like reservation or optimization-based ones were proposed to solve the underlying multi-agent planning problem. At the same time, automated driving functions for a single ego vehicle are increasingly implemented using machine learning methods. In this work, we build upon a previously presented graph-based scene representation and graph neural network to approach the problem using reinforcement learning. The scene representation is improved in key aspects by using edge features in addition to the existing node features for the vehicles. This leads to an increased representation quality that is leveraged by an updated network architecture. The paper provides an in-depth evaluation of the proposed method against baselines that are commonly used in automatic intersection management. Compared to a traditional signalized intersection and an enhanced first-in-first-out scheme, a significant reduction of induced delay is observed at varying traffic densities. Finally, the generalization capability of the graph-based representation is evaluated by testing the policy on intersection layouts not seen during training. The model generalizes virtually without restrictions to smaller intersection layouts and within certain limits to larger ones. ",
    "url": "https://arxiv.org/abs/2207.08655",
    "authors": [
      "Marvin Klimke",
      "Jasper Gerigk",
      "Benjamin V\u00f6lz",
      "Michael Buchholz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08664",
    "title": "Action-based Contrastive Learning for Trajectory Prediction",
    "abstract": "Trajectory prediction is an essential task for successful human robot interaction, such as in autonomous driving. In this work, we address the problem of predicting future pedestrian trajectories in a first person view setting with a moving camera. To that end, we propose a novel action-based contrastive learning loss, that utilizes pedestrian action information to improve the learned trajectory embeddings. The fundamental idea behind this new loss is that trajectories of pedestrians performing the same action should be closer to each other in the feature space than the trajectories of pedestrians with significantly different actions. In other words, we argue that behavioral information about pedestrian action influences their future trajectory. Furthermore, we introduce a novel sampling strategy for trajectories that is able to effectively increase negative and positive contrastive samples. Additional synthetic trajectory samples are generated using a trained Conditional Variational Autoencoder (CVAE), which is at the core of several models developed for trajectory prediction. Results show that our proposed contrastive framework employs contextual information about pedestrian behavior, i.e. action, effectively, and it learns a better trajectory representation. Thus, integrating the proposed contrastive framework within a trajectory prediction model improves its results and outperforms state-of-the-art methods on three trajectory prediction benchmarks [31, 32, 26]. ",
    "url": "https://arxiv.org/abs/2207.08664",
    "authors": [
      "Marah Halawa",
      "Olaf Hellwich",
      "Pia Bideau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08699",
    "title": "Semantic Novelty Detection via Relational Reasoning",
    "abstract": "Semantic novelty detection aims at discovering unknown categories in the test data. This task is particularly relevant in safety-critical applications, such as autonomous driving or healthcare, where it is crucial to recognize unknown objects at deployment time and issue a warning to the user accordingly. Despite the impressive advancements of deep learning research, existing models still need a finetuning stage on the known categories in order to recognize the unknown ones. This could be prohibitive when privacy rules limit data access, or in case of strict memory and computational constraints (e.g. edge computing). We claim that a tailored representation learning strategy may be the right solution for effective and efficient semantic novelty detection. Besides extensively testing state-of-the-art approaches for this task, we propose a novel representation learning paradigm based on relational reasoning. It focuses on learning how to measure semantic similarity rather than recognizing known categories. Our experiments show that this knowledge is directly transferable to a wide range of scenarios, and it can be exploited as a plug-and-play module to convert closed-set recognition models into reliable open-set ones. ",
    "url": "https://arxiv.org/abs/2207.08699",
    "authors": [
      "Francesco Cappio Borlino",
      "Silvia Bucci",
      "Tatiana Tommasi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08736",
    "title": "Towards Diverse and Faithful One-shot Adaption of Generative Adversarial  Networks",
    "abstract": "One-shot generative domain adaption aims to transfer a pre-trained generator on one domain to a new domain using one reference image only. However, it remains very challenging for the adapted generator (i) to generate diverse images inherited from the pre-trained generator while (ii) faithfully acquiring the domain-specific attributes and styles of the reference image. In this paper, we present a novel one-shot generative domain adaption method, i.e., DiFa, for diverse generation and faithful adaptation. For global-level adaptation, we leverage the difference between the CLIP embedding of reference image and the mean embedding of source images to constrain the target generator. For local-level adaptation, we introduce an attentive style loss which aligns each intermediate token of adapted image with its corresponding token of the reference image. To facilitate diverse generation, selective cross-domain consistency is introduced to select and retain the domain-sharing attributes in the editing latent $\\mathcal{W}+$ space to inherit the diversity of pre-trained generator. Extensive experiments show that our method outperforms the state-of-the-arts both quantitatively and qualitatively, especially for the cases of large domain gaps. Moreover, our DiFa can easily be extended to zero-shot generative domain adaption with appealing results. Code is available at https://github.com/1170300521/DiFa. ",
    "url": "https://arxiv.org/abs/2207.08736",
    "authors": [
      "Yabo Zhang",
      "Mingshuai Yao",
      "Yuxiang Wei",
      "Zhilong Ji",
      "Jinfeng Bai",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08739",
    "title": "Rethinking Data Augmentation for Robust Visual Question Answering",
    "abstract": "Data Augmentation (DA) -- generating extra training samples beyond original training set -- has been widely-used in today's unbiased VQA models to mitigate the language biases. Current mainstream DA strategies are synthetic-based methods, which synthesize new samples by either editing some visual regions/words, or re-generating them from scratch. However, these synthetic samples are always unnatural and error-prone. To avoid this issue, a recent DA work composes new augmented samples by randomly pairing pristine images and other human-written questions. Unfortunately, to guarantee augmented samples have reasonable ground-truth answers, they manually design a set of heuristic rules for several question types, which extremely limits its generalization abilities. To this end, we propose a new Knowledge Distillation based Data Augmentation for VQA, dubbed KDDAug. Specifically, we first relax the requirements of reasonable image-question pairs, which can be easily applied to any question types. Then, we design a knowledge distillation (KD) based answer assignment to generate pseudo answers for all composed image-question pairs, which are robust to both in-domain and out-of-distribution settings. Since KDDAug is a model-agnostic DA strategy, it can be seamlessly incorporated into any VQA architectures. Extensive ablation studies on multiple backbones and benchmarks have demonstrated the effectiveness and generalization abilities of KDDAug. ",
    "url": "https://arxiv.org/abs/2207.08739",
    "authors": [
      "Long Chen",
      "Yuhang Zheng",
      "Jun Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.08773",
    "title": "Having your Privacy Cake and Eating it Too: Platform-supported Auditing  of Social Media Algorithms for Public Interest",
    "abstract": "Relevance estimators are algorithms used by major social media platforms to determine what content is shown to users and its presentation order. These algorithms aim to personalize the platforms' experience for users, increasing engagement and, therefore, platform revenue. However, at the large scale of many social media platforms, many have concerns that the relevance estimation and personalization algorithms are opaque and can produce outcomes that are harmful to individuals or society. Legislations have been proposed in both the U.S. and the E.U. that mandate auditing of social media algorithms by external researchers. But auditing at scale risks disclosure of users' private data and platforms' proprietary algorithms, and thus far there has been no concrete technical proposal that can provide such auditing. Our goal is to propose a new method for platform-supported auditing that can meet the goals of the proposed legislations. The first contribution of our work is to enumerate these challenges and the limitations of existing auditing methods to implement these policies at scale. Second, we suggest that limited, privileged access to relevance estimators is the key to enabling generalizable platform-supported auditing of social media platforms by external researchers. Third, we show platform-supported auditing need not risk user privacy nor disclosure of platforms' business interests by proposing an auditing framework that protects against these risks. For a particular fairness metric, we show that ensuring privacy imposes only a small constant factor increase (6.34x as an upper bound, and 4x for typical parameters) in the number of samples required for accurate auditing. Our technical contributions, combined with ongoing legal and policy efforts, can enable public oversight into how social media platforms affect individuals and society by moving past the privacy-vs-transparency hurdle. ",
    "url": "https://arxiv.org/abs/2207.08773",
    "authors": [
      "Basileal Imana",
      "Aleksandra Korolova",
      "John Heidemann"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.08779",
    "title": "Simplifying Clustering with Graph Neural Networks",
    "abstract": "The objective functions used in spectral clustering are usually composed of two terms: i) a term that minimizes the local quadratic variation of the cluster assignments on the graph and; ii) a term that balances the clustering partition and helps avoiding degenerate solutions. This paper shows that a graph neural network, equipped with suitable message passing layers, can generate good cluster assignments by optimizing only a balancing term. Results on attributed graph datasets show the effectiveness of the proposed approach in terms of clustering performance and computation time. ",
    "url": "https://arxiv.org/abs/2207.08779",
    "authors": [
      "Filippo Maria Bianchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08782",
    "title": "Instance-Aware Observer Network for Out-of-Distribution Object  Segmentation",
    "abstract": "Recent work on Observer Network has shown promising results on Out-Of-Distribution (OOD) detection for semantic segmentation. These methods have difficulty in precisely locating the point of interest in the image, i.e, the anomaly. This limitation is due to the difficulty of fine-grained prediction at the pixel level. To address this issue, we provide instance knowledge to the observer. We extend the approach of ObsNet by harnessing an instance-wise mask prediction. We use an additional, class agnostic, object detector to filter and aggregate observer predictions. Finally, we predict an unique anomaly score for each instance in the image. We show that our proposed method accurately disentangle in-distribution objects from Out-Of-Distribution objects on three datasets. ",
    "url": "https://arxiv.org/abs/2207.08782",
    "authors": [
      "Victor Besnier",
      "Andrei Bursuc",
      "David Picard",
      "Alexandre Briot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08794",
    "title": "DeFlowSLAM: Self-Supervised Scene Motion Decomposition for Dynamic Dense  SLAM",
    "abstract": "We present a novel dual-flow representation of scene motion that decomposes the optical flow into a static flow field caused by the camera motion and another dynamic flow field caused by the objects' movements in the scene. Based on this representation, we present a dynamic SLAM, dubbed DeFlowSLAM, that exploits both static and dynamic pixels in the images to solve the camera poses, rather than simply using static background pixels as other dynamic SLAM systems do. We propose a dynamic update module to train our DeFlowSLAM in a self-supervised manner, where a dense bundle adjustment layer takes in estimated static flow fields and the weights controlled by the dynamic mask and outputs the residual of the optimized static flow fields, camera poses, and inverse depths. The static and dynamic flow fields are estimated by warping the current image to the neighboring images, and the optical flow can be obtained by summing the two fields. Extensive experiments demonstrate that DeFlowSLAM generalizes well to both static and dynamic scenes as it exhibits comparable performance to the state-of-the-art DROID-SLAM in static and less dynamic scenes while significantly outperforming DROID-SLAM in highly dynamic environments. Code and data are available on the project webpage: \\urlstyle{tt} \\textcolor{url_color}{\\url{https://zju3dv.github.io/deflowslam/}}. ",
    "url": "https://arxiv.org/abs/2207.08794",
    "authors": [
      "Weicai Ye",
      "Xingyuan Yu",
      "Xinyue Lan",
      "Yuhang Ming",
      "Jinyu Li",
      "Hujun Bao",
      "Zhaopeng Cui",
      "Guofeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.08803",
    "title": "Adversarial Pixel Restoration as a Pretext Task for Transferable  Perturbations",
    "abstract": "Transferable adversarial attacks optimize adversaries from a pretrained surrogate model and known label space to fool the unknown black-box models. Therefore, these attacks are restricted by the availability of an effective surrogate model. In this work, we relax this assumption and propose Adversarial Pixel Restoration as a self-supervised alternative to train an effective surrogate model from scratch under the condition of no labels and few data samples. Our training approach is based on a min-max objective which reduces overfitting via an adversarial objective and thus optimizes for a more generalizable surrogate model. Our proposed attack is complimentary to our adversarial pixel restoration and is independent of any task specific objective as it can be launched in a self-supervised manner. We successfully demonstrate the adversarial transferability of our approach to Vision Transformers as well as Convolutional Neural Networks for the tasks of classification, object detection, and video segmentation. Our codes & pre-trained surrogate models are available at: https://github.com/HashmatShadab/APR ",
    "url": "https://arxiv.org/abs/2207.08803",
    "authors": [
      "Hashmat Shadab Malik",
      "Shahina K Kunhimon",
      "Muzammal Naseer",
      "Salman Khan",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07705",
    "title": "Untrained, physics-informed neural networks for structured illumination  microscopy",
    "abstract": "In recent years there has been great interest in using deep neural networks (DNN) for super-resolution image reconstruction including for structured illumination microscopy (SIM). While these methods have shown very promising results, they all rely on data-driven, supervised training strategies that need a large number of ground truth images, which is experimentally difficult to realize. For SIM imaging, there exists a need for a flexible, general, and open-source reconstruction method that can be readily adapted to different forms of structured illumination. We demonstrate that we can combine a deep neural network with the forward model of the structured illumination process to reconstruct sub-diffraction images without training data. The resulting physics-informed neural network (PINN) can be optimized on a single set of diffraction limited sub-images and thus doesn't require any training set. We show with simulated and experimental data that this PINN can be applied to a wide variety of SIM methods by simply changing the known illumination patterns used in the loss function and can achieve resolution improvements that match well with theoretical expectations. ",
    "url": "https://arxiv.org/abs/2207.07705",
    "authors": [
      "Zachary Burns",
      "Zhaowei Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2207.07734",
    "title": "COEM: Cross-Modal Embedding for MetaCell Identification",
    "abstract": "Metacells are disjoint and homogeneous groups of single-cell profiles, representing discrete and highly granular cell states. Existing metacell algorithms tend to use only one modality to infer metacells, even though single-cell multi-omics datasets profile multiple molecular modalities within the same cell. Here, we present \\textbf{C}ross-M\\textbf{O}dal \\textbf{E}mbedding for \\textbf{M}etaCell Identification (COEM), which utilizes an embedded space leveraging the information of both scATAC-seq and scRNA-seq to perform aggregation, balancing the trade-off between fine resolution and sufficient sequencing coverage. COEM outperforms the state-of-the-art method SEACells by efficiently identifying accurate and well-separated metacells across datasets with continuous and discrete cell types. Furthermore, COEM significantly improves peak-to-gene association analyses, and facilitates complex gene regulatory inference tasks. ",
    "url": "https://arxiv.org/abs/2207.07734",
    "authors": [
      "Haiyi Mao",
      "Minxue Jia",
      "Jason Xiaotian Dou Haotian Zhang Panayiotis V. Benos"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "General Literature (cs.GL)"
    ]
  },
  {
    "id": "arXiv:2207.07773",
    "title": "Segment-level Metric Learning for Few-shot Bioacoustic Event Detection",
    "abstract": "Few-shot bioacoustic event detection is a task that detects the occurrence time of a novel sound given a few examples. Previous methods employ metric learning to build a latent space with the labeled part of different sound classes, also known as positive events. In this study, we propose a segment-level few-shot learning framework that utilizes both the positive and negative events during model optimization. Training with negative events, which are larger in volume than positive events, can increase the generalization ability of the model. In addition, we use transductive inference on the validation set during training for better adaptation to novel classes. We conduct ablation studies on our proposed method with different setups on input features, training data, and hyper-parameters. Our final system achieves an F-measure of 62.73 on the DCASE 2022 challenge task 5 (DCASE2022-T5) validation set, outperforming the performance of the baseline prototypical network 34.02 by a large margin. Using the proposed method, our submitted system ranks 2nd in DCASE2022-T5. The code of this paper is fully open-sourced at https://github.com/haoheliu/DCASE_2022_Task_5. ",
    "url": "https://arxiv.org/abs/2207.07773",
    "authors": [
      "Haohe Liu",
      "Xubo Liu",
      "Xinhao Mei",
      "Qiuqiang Kong",
      "Wenwu Wang",
      "Mark D. Plumbley"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.07776",
    "title": "Adversarial Reweighting for Speaker Verification Fairness",
    "abstract": "We address performance fairness for speaker verification using the adversarial reweighting (ARW) method. ARW is reformulated for speaker verification with metric learning, and shown to improve results across different subgroups of gender and nationality, without requiring annotation of subgroups in the training data. An adversarial network learns a weight for each training sample in the batch so that the main learner is forced to focus on poorly performing instances. Using a min-max optimization algorithm, this method improves overall speaker verification fairness. We present three different ARWformulations: accumulated pairwise similarity, pseudo-labeling, and pairwise weighting, and measure their performance in terms of equal error rate (EER) on the VoxCeleb corpus. Results show that the pairwise weighting method can achieve 1.08% overall EER, 1.25% for male and 0.67% for female speakers, with relative EER reductions of 7.7%, 10.1% and 3.0%, respectively. For nationality subgroups, the proposed algorithm showed 1.04% EER for US speakers, 0.76% for UK speakers, and 1.22% for all others. The absolute EER gap between gender groups was reduced from 0.70% to 0.58%, while the standard deviation over nationality groups decreased from 0.21 to 0.19. ",
    "url": "https://arxiv.org/abs/2207.07776",
    "authors": [
      "Minho Jin",
      "Chelsea J.-T. Ju",
      "Zeya Chen",
      "Yi-Chieh Liu",
      "Jasha Droppo",
      "Andreas Stolcke"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2207.07918",
    "title": "Discriminative Kernel Convolution Network for Multi-Label Ophthalmic  Disease Detection on Imbalanced Fundus Image Dataset",
    "abstract": "It is feasible to recognize the presence and seriousness of eye disease by investigating the progressions in retinal biological structure. Fundus examination is a diagnostic procedure to examine the biological structure and anomaly of the eye. Ophthalmic diseases like glaucoma, diabetic retinopathy, and cataract are the main reason for visual impairment around the world. Ocular Disease Intelligent Recognition (ODIR-5K) is a benchmark structured fundus image dataset utilized by researchers for multi-label multi-disease classification of fundus images. This work presents a discriminative kernel convolution network (DKCNet), which explores discriminative region-wise features without adding extra computational cost. DKCNet is composed of an attention block followed by a squeeze and excitation (SE) block. The attention block takes features from the backbone network and generates discriminative feature attention maps. The SE block takes the discriminative feature maps and improves channel interdependencies. Better performance of DKCNet is observed with InceptionResnet backbone network for multi-label classification of ODIR-5K fundus images with 96.08 AUC, 94.28 F1-score and 0.81 kappa score. The proposed method splits the common target label for an eye pair based on the diagnostic keyword. Based on these labels oversampling and undersampling is done to resolve class imbalance. To check the biasness of proposed model towards training data, the model trained on ODIR dataset is tested on three publicly available benchmark datasets. It is found to give good performance on completely unseen fundus images also. ",
    "url": "https://arxiv.org/abs/2207.07918",
    "authors": [
      "Amit Bhati",
      "Neha Gour",
      "Pritee Khanna",
      "Aparajita Ojha"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08026",
    "title": "Rewiring Networks for Graph Neural Network Training Using Discrete  Geometry",
    "abstract": "Information over-squashing is a phenomenon of inefficient information propagation between distant nodes on networks. It is an important problem that is known to significantly impact the training of graph neural networks (GNNs), as the receptive field of a node grows exponentially. To mitigate this problem, a preprocessing procedure known as rewiring is often applied to the input network. In this paper, we investigate the use of discrete analogues of classical geometric notions of curvature to model information flow on networks and rewire them. We show that these classical notions achieve state-of-the-art performance in GNN training accuracy on a variety of real-world network datasets. Moreover, compared to the current state-of-the-art, these classical notions exhibit a clear advantage in computational runtime by several orders of magnitude. ",
    "url": "https://arxiv.org/abs/2207.08026",
    "authors": [
      "Jakub Bober",
      "Anthea Monod",
      "Emil Saucan",
      "Kevin N. Webster"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08032",
    "title": "Analysis of liver cancer detection based on image processing",
    "abstract": "Medical imaging is the most important tool for detecting complications in the inner body of medicine. Nowadays, with the development of image processing technology as well as changing the size of photos to higher resolution images in the field of digital medical imaging, there is an efficient and accurate system for segmenting this. Real-world images that for a variety of reasons have poor heterogeneity, noise and contrast are essential. Digital image segmentation in medicine is used for diagnostic and therapeutic analysis, which is very helpful for physicians. In this study, we aim at liver cancer photographs, which aim to more accurately detect the lesion or tumor of the liver because accurate and timely detection of the tumor is very important in the survival and life of the patient.The aim of this paper is to simplify the obnoxious study problems related to the study of MR images. The liver is the second organ most generic involved by metastatic disease being liver cancer one of the prominent causes of death worldwide. Without healthy liver a person cannot survive. It is life threatening disease which is very challenging perceptible for both medical and engineering technologists. Medical image processing is used as a non-invasive method to detect tumours. The chances of survival having liver Tumor highly depends on early detection of Tumor and then classification as cancerous and noncancerous tumours. Image processing techniques for automatic detection of brain are includes pre-processing and enhancement, image segmentation, classification and volume calculation, Poly techniques have been developed for the detection of liver Tumor and different liver toM oR detection algorithms and methodologies utilized for Tumor diagnosis. Novel methodology for the detection and diagnosis of liver Tumor. ",
    "url": "https://arxiv.org/abs/2207.08032",
    "authors": [
      "Mahmoudreza Moghimhanjani",
      "Ali Taghavirashidizadeh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08036",
    "title": "Single MR Image Super-Resolution using Generative Adversarial Network",
    "abstract": "Spatial resolution of medical images can be improved using super-resolution methods. Real Enhanced Super Resolution Generative Adversarial Network (Real-ESRGAN) is one of the recent effective approaches utilized to produce higher resolution images, given input images of lower resolution. In this paper, we apply this method to enhance the spatial resolution of 2D MR images. In our proposed approach, we slightly modify the structure of the Real-ESRGAN to train 2D Magnetic Resonance images (MRI) taken from the Brain Tumor Segmentation Challenge (BraTS) 2018 dataset. The obtained results are validated qualitatively and quantitatively by computing SSIM (Structural Similarity Index Measure), NRMSE (Normalized Root Mean Square Error), MAE (Mean Absolute Error), and VIF (Visual Information Fidelity) values. ",
    "url": "https://arxiv.org/abs/2207.08036",
    "authors": [
      "Shawkh Ibne Rashid",
      "Elham Shakibapour",
      "Mehran Ebrahimi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08189",
    "title": "Supplementing Recurrent Neural Networks with Annealing to Solve  Optimization Problems",
    "abstract": "Combinatorial optimization problems can be solved by heuristic algorithms such as simulated annealing (SA) which aims to find the global minima solution within a large search space through thermal fluctuations. The algorithm generates new solutions through Markov-chain Monte Carlo techniques. The latter can result in severe limitations, such as slow convergence and a tendency to stay within the same local search space at small temperatures. To overcome these shortcomings, we use the variational classical annealing (VCA) framework that combines autoregressive recurrent neural networks (RNNs) with traditional annealing to sample solutions independent of each other. In this paper, we demonstrate the potential of using VCA as an approach to solving real-world optimization problems. We explore VCA's performance in comparison with SA at solving three popular optimization problems: the maximum cut problem (Max-Cut), the nurse scheduling problem (NSP), and the traveling salesman problem (TSP). For all three problems, we find that VCA outperforms SA on average in the asymptotic limit. Interestingly, we reach large system sizes up to $256$ cities for the TSP. We conclude that in the best-case scenario, VCA can serve as a great alternative when SA fails to find the optimal solution. ",
    "url": "https://arxiv.org/abs/2207.08189",
    "authors": [
      "Shoummo Ahsan Khandoker",
      "Jawaril Munshad Abedin",
      "Mohamed Hibat-Allah"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2207.08200",
    "title": "Uncertainty Calibration in Bayesian Neural Networks via Distance-Aware  Priors",
    "abstract": "As we move away from the data, the predictive uncertainty should increase, since a great variety of explanations are consistent with the little available information. We introduce Distance-Aware Prior (DAP) calibration, a method to correct overconfidence of Bayesian deep learning models outside of the training domain. We define DAPs as prior distributions over the model parameters that depend on the inputs through a measure of their distance from the training set. DAP calibration is agnostic to the posterior inference method, and it can be performed as a post-processing step. We demonstrate its effectiveness against several baselines in a variety of classification and regression problems, including benchmarks designed to test the quality of predictive distributions away from the data. ",
    "url": "https://arxiv.org/abs/2207.08200",
    "authors": [
      "Gianluca Detommaso",
      "Alberto Gasparin",
      "Andrew Wilson",
      "Cedric Archambeau"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08208",
    "title": "Unsupervised Medical Image Translation with Adversarial Diffusion Models",
    "abstract": "Imputation of missing images via source-to-target modality translation can facilitate downstream tasks in medical imaging. A pervasive approach for synthesizing target images involves one-shot mapping through generative adversarial networks (GAN). Yet, GAN models that implicitly characterize the image distribution can suffer from limited sample fidelity and diversity. Here, we propose a novel method based on adversarial diffusion modeling, SynDiff, for improved reliability in medical image synthesis. To capture a direct correlate of the image distribution, SynDiff leverages a conditional diffusion process to progressively map noise and source images onto the target image. For fast and accurate image sampling during inference, large diffusion steps are coupled with adversarial projections in the reverse diffusion direction. To enable training on unpaired datasets, a cycle-consistent architecture is devised with two coupled diffusion processes to synthesize the target given source and the source given target. Extensive assessments are reported on the utility of SynDiff against competing GAN and diffusion models in multi-contrast MRI and MRI-CT translation. Our demonstrations indicate that SynDiff offers superior performance against competing baselines both qualitatively and quantitatively. ",
    "url": "https://arxiv.org/abs/2207.08208",
    "authors": [
      "Muzaffer \u00d6zbey",
      "Salman UH Dar",
      "Hasan A Bedel",
      "Onat Dalmaz",
      "\u015eaban \u00d6zturk",
      "Alper G\u00fcng\u00f6r",
      "Tolga \u00c7ukur"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08254",
    "title": "Improving tobacco social contagion models using agent-based simulations  on networks",
    "abstract": "Over the years, population-level tobacco control policies have considerably reduced smoking prevalence worldwide. However, the rate of decline of smoking prevalence is slowing down. Therefore, there is a need for models that capture the full complexity of the smoking epidemic. These models can then be used as test-beds to develop new policies to limit the spread of smoking. Current models of smoking dynamics mainly use ordinary differential equation (ODE) models, where studying the effect of an individual's contact network is challenging. They also do not consider all the interactions between individuals that can lead to changes in smoking behaviour, implying that they do not consider valuable information on the spread of smoking behaviour. In this context, we develop an agent-based model (ABM), calibrate and then validate it on historical trends observed in the US and UK. Our ABM considers spontaneous terms, interactions between agents, and the agent's contact network. To explore the effect of the underlying network on smoking dynamics, we test the ABM on six different networks, both synthetic and real-world. In addition, we also compare the ABM with an ODE model. Our results suggest that the dynamics from the ODE model are similar to the ABM only when the network structure is fully connected (FC). The FC network performs poorly in replicating the empirical trends in the data, while the real-world network best replicates it amongst the six networks. Further, when information on the real-world network is unavailable, our ABM on Lancichinetti-Fortunato-Radicchi benchmark networks (or networks with a similar average degree as the real-world network) can be used to model smoking behaviour. These results suggest that networks are essential for modelling smoking behaviour and that our ABM can be used to develop network-based intervention strategies and policies for tobacco control. ",
    "url": "https://arxiv.org/abs/2207.08254",
    "authors": [
      "Adarsh Prabhakaran",
      "Valerio Restocchi",
      "Benjamin D. Goddard"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.08306",
    "title": "Nonparametric regression with modified ReLU networks",
    "abstract": "We consider regression estimation with modified ReLU neural networks in which network weight matrices are first modified by a function $\\alpha$ before being multiplied by input vectors. We give an example of continuous, piecewise linear function $\\alpha$ for which the empirical risk minimizers over the classes of modified ReLU networks with $l_1$ and squared $l_2$ penalties attain, up to a logarithmic factor, the minimax rate of prediction of unknown $\\beta$-smooth function. ",
    "url": "https://arxiv.org/abs/2207.08306",
    "authors": [
      "Aleksandr Beknazaryan",
      "Hailin Sang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2207.08350",
    "title": "Towards Understanding The Semidefinite Relaxations of Truncated  Least-Squares in Robust Rotation Search",
    "abstract": "The rotation search problem aims to find a 3D rotation that best aligns a given number of point pairs. To induce robustness against outliers for rotation search, prior work considers truncated least-squares (TLS), which is a non-convex optimization problem, and its semidefinite relaxation (SDR) as a tractable alternative. Whether this SDR is theoretically tight in the presence of noise, outliers, or both has remained largely unexplored. We derive conditions that characterize the tightness of this SDR, showing that the tightness depends on the noise level, the truncation parameters of TLS, and the outlier distribution (random or clustered). In particular, we give a short proof for the tightness in the noiseless and outlier-free case, as opposed to the lengthy analysis of prior work. ",
    "url": "https://arxiv.org/abs/2207.08350",
    "authors": [
      "Liangzu Peng",
      "Mahyar Fazlyab",
      "Ren\u00e9 Vidal"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08435",
    "title": "Robust Simulation-Based Inference in Cosmology with Bayesian Neural  Networks",
    "abstract": "Simulation-based inference (SBI) is rapidly establishing itself as a standard machine learning technique for analyzing data in cosmological surveys. Despite continual improvements to the quality of density estimation by learned models, applications of such techniques to real data are entirely reliant on the generalization power of neural networks far outside the training distribution, which is mostly unconstrained. Due to the imperfections in scientist-created simulations, and the large computational expense of generating all possible parameter combinations, SBI methods in cosmology are vulnerable to such generalization issues. Here, we discuss the effects of both issues, and show how using a Bayesian neural network framework for training SBI can mitigate biases, and result in more reliable inference outside the training set. We introduce cosmoSWAG, the first application of Stochastic Weight Averaging to cosmology, and apply it to SBI trained for inference on the cosmic microwave background. ",
    "url": "https://arxiv.org/abs/2207.08435",
    "authors": [
      "Pablo Lemos",
      "Miles Cranmer",
      "Muntazir Abidi",
      "ChangHoon Hahn",
      "Michael Eickenberg",
      "Elena Massara",
      "David Yallup",
      "Shirley Ho"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08489",
    "title": "Neural Distributed Image Compression with Cross-Attention Feature  Alignment",
    "abstract": "We propose a novel deep neural network (DNN) architecture for compressing an image when a correlated image is available as side information only at the decoder side, a special case of the well-known and heavily studied distributed source coding (DSC) problem. In particular, we consider a pair of stereo images, which have overlapping fields of view, captured by a synchronized and calibrated pair of cameras; and therefore, are highly correlated. We assume that one image of the pair is to be compressed and transmitted, while the other image is available only at the decoder. In the proposed architecture, the encoder maps the input image to a latent space using a DNN, quantizes the latent representation, and compresses it losslessly using entropy coding. The proposed decoder extracts useful information common between the images solely from the available side information, as well as a latent representation of the side information. Then, the latent representations of the two images, one received from the encoder, the other extracted locally, along with the locally generated common information, are fed to the respective decoders of the two images. We employ a cross-attention module (CAM) to align the feature maps obtained in the intermediate layers of the respective decoders of the two images, thus allowing better utilization of the side information. We train and demonstrate the effectiveness of the proposed algorithm on various realistic setups, such as KITTI and Cityscape datasets of stereo image pairs. Our results show that the proposed architecture is capable of exploiting the decoder-only side information in a more efficient manner as it outperforms previous works. We also show that the proposed method is able to provide significant gains even in the case of uncalibrated and unsynchronized camera array use cases. ",
    "url": "https://arxiv.org/abs/2207.08489",
    "authors": [
      "Nitish Mital",
      "Ezgi Ozyilkan",
      "Ali Garjani",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1409.6182",
    "title": "A Benchmark Suite for Template Detection and Content Extraction",
    "abstract": " Comments: 13 pages, 3 tables ",
    "url": "https://arxiv.org/abs/1409.6182",
    "authors": [
      "Juli\u00e1n Alarte",
      "Josep Silva"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:1607.06444",
    "title": "The Complexity of Drawing Graphs on Few Lines and Few Planes",
    "abstract": " Comments: 28 pages, 9 figures. A preliminary version appeared in Proc. WADS 2017 ",
    "url": "https://arxiv.org/abs/1607.06444",
    "authors": [
      "Steven Chaplick",
      "Krzysztof Fleszar",
      "Fabian Lipp",
      "Alexander Ravsky",
      "Oleg Verbitsky",
      "Alexander Wolff"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:1901.10330",
    "title": "Canonisation and Definability for Graphs of Bounded Rank Width",
    "abstract": " Comments: 32 pages, 2 figures; second version corrects a small error in the proof of Theorem 1.1 and improves the presentation ",
    "url": "https://arxiv.org/abs/1901.10330",
    "authors": [
      "Martin Grohe",
      "Daniel Neuen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:1905.03527",
    "title": "Performance Analysis of Fog-Aided D2D Networks with Multicast-Based  Opportunistic Content Delivery",
    "abstract": " Comments: Technical error found in the paper ",
    "url": "https://arxiv.org/abs/1905.03527",
    "authors": [
      "Xiaoshi Song",
      "Mengying Yuan",
      "Huan Zhou",
      "Haijun Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:1911.08924",
    "title": "Geometric Planar Networks on Bichromatic Points",
    "abstract": " Comments: Appeared in Theoretical Computer Science (TCS) 2021 ",
    "url": "https://arxiv.org/abs/1911.08924",
    "authors": [
      "Sayan Bandyapadhyay",
      "Aritra Banik",
      "Sujoy Bhore",
      "Martin N\u00f6llenburg"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2006.01412",
    "title": "Federated Learning in Vehicular Networks",
    "abstract": " Comments: 2022 IEEE International Mediterranean Conference on Communications and Networking (MeditCom) ",
    "url": "https://arxiv.org/abs/2006.01412",
    "authors": [
      "Ahmet M. Elbir",
      "Burak Soner",
      "Sinem Coleri",
      "Deniz Gunduz",
      "Mehdi Bennis"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2006.03906",
    "title": "Identifying Causal Structure in Dynamical Systems",
    "abstract": " Comments: Accepted final versions to appear in the Transactions on Machine Learning Research ",
    "url": "https://arxiv.org/abs/2006.03906",
    "authors": [
      "Dominik Baumann",
      "Friedrich Solowjow",
      "Karl H. Johansson",
      "Sebastian Trimpe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2007.02764",
    "title": "Information Theoretic Data Injection Attacks with Sparsity Constraints",
    "abstract": " Comments: 6 pages, 3 figures, published in 2020 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm) ",
    "url": "https://arxiv.org/abs/2007.02764",
    "authors": [
      "Xiuzhen Ye",
      "I\u00f1aki Esnaola",
      "Samir M. Perlaza",
      "Robert F. Harrison"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2009.05683",
    "title": "MACE: A Flexible Framework for Membership Privacy Estimation in  Generative Models",
    "abstract": " Title: MACE: A Flexible Framework for Membership Privacy Estimation in  Generative Models ",
    "url": "https://arxiv.org/abs/2009.05683",
    "authors": [
      "Yixi Xu",
      "Sumit Mukherjee",
      "Xiyang Liu",
      "Shruti Tople",
      "Rahul Dodhia",
      "Juan Lavista Ferres"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2009.09213",
    "title": "Dodging DeepFake Detection via Implicit Spatial-Domain Notch Filtering",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2009.09213",
    "authors": [
      "Yihao Huang",
      "Felix Juefei-Xu",
      "Qing Guo",
      "Yang Liu",
      "Geguang Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2011.10725",
    "title": "Impact of signal-to-noise ratio and bandwidth on graph Laplacian  spectrum from high-dimensional noisy point cloud",
    "abstract": " Title: Impact of signal-to-noise ratio and bandwidth on graph Laplacian  spectrum from high-dimensional noisy point cloud ",
    "url": "https://arxiv.org/abs/2011.10725",
    "authors": [
      "Xiucai Ding",
      "Hau-Tieng Wu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Spectral Theory (math.SP)"
    ]
  },
  {
    "id": "arXiv:2103.04266",
    "title": "Resource Distribution Under Spatiotemporal Uncertainty of Disease  Spread: Stochastic versus Robust Approaches",
    "abstract": " Title: Resource Distribution Under Spatiotemporal Uncertainty of Disease  Spread: Stochastic versus Robust Approaches ",
    "url": "https://arxiv.org/abs/2103.04266",
    "authors": [
      "Beste Basciftci",
      "Xian Yu",
      "Siqian Shen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2103.13796",
    "title": "Active Structure Learning of Bayesian Networks in an Observational  Setting",
    "abstract": " Title: Active Structure Learning of Bayesian Networks in an Observational  Setting ",
    "url": "https://arxiv.org/abs/2103.13796",
    "authors": [
      "Noa Ben-David",
      "Sivan Sabato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2105.11953",
    "title": "Emotion Recognition in Horses with Convolutional Neural Networks",
    "abstract": " Comments: 14 pages, 11figures ",
    "url": "https://arxiv.org/abs/2105.11953",
    "authors": [
      "Luis A. Corujo",
      "Peter A. Gloor",
      "Emily Kieson",
      "Timo Schloesser"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2105.12356",
    "title": "The Graph Cut Kernel for Ranked Data",
    "abstract": " Title: The Graph Cut Kernel for Ranked Data ",
    "url": "https://arxiv.org/abs/2105.12356",
    "authors": [
      "Michelangelo Conserva",
      "Marc Peter Deisenroth",
      "K S Sesh Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.11076",
    "title": "Pro or Anti? A Social Influence Model of Online Stance Flipping",
    "abstract": " Comments: Published at this https URL ",
    "url": "https://arxiv.org/abs/2106.11076",
    "authors": [
      "Lynnette Hui Xian Ng",
      "Kathleen Carley"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2106.16046",
    "title": "Benchmarking Contextual Factor Generalizability in Spatiotemporal Crowd  Flow Prediction",
    "abstract": " Title: Benchmarking Contextual Factor Generalizability in Spatiotemporal Crowd  Flow Prediction ",
    "url": "https://arxiv.org/abs/2106.16046",
    "authors": [
      "Liyue Chen",
      "Leye Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2107.14204",
    "title": "Personalized Trajectory Prediction via Distribution Discrimination",
    "abstract": " Comments: Accepted to ICCV 2021. Code: this https URL ",
    "url": "https://arxiv.org/abs/2107.14204",
    "authors": [
      "Guangyi Chen",
      "Junlong Li",
      "Nuoxing Zhou",
      "Liangliang Ren",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.02756",
    "title": "BOSS: Bidirectional One-Shot Synthesis of Adversarial Examples",
    "abstract": " Title: BOSS: Bidirectional One-Shot Synthesis of Adversarial Examples ",
    "url": "https://arxiv.org/abs/2108.02756",
    "authors": [
      "Ismail R. Alkhouri",
      "Alvaro Velasquez",
      "George K. Atia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.10636",
    "title": "Layer-wise Adaptive Graph Convolution Networks Using Generalized  Pagerank",
    "abstract": " Title: Layer-wise Adaptive Graph Convolution Networks Using Generalized  Pagerank ",
    "url": "https://arxiv.org/abs/2108.10636",
    "authors": [
      "Kishan Wimalawarne",
      "Taiji Suzuki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.12944",
    "title": "Selective Differential Privacy for Language Modeling",
    "abstract": " Comments: NAACL 2022 ",
    "url": "https://arxiv.org/abs/2108.12944",
    "authors": [
      "Weiyan Shi",
      "Aiqi Cui",
      "Evan Li",
      "Ruoxi Jia",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2109.00783",
    "title": "Computer Vision Self-supervised Learning Methods on Time Series",
    "abstract": " Title: Computer Vision Self-supervised Learning Methods on Time Series ",
    "url": "https://arxiv.org/abs/2109.00783",
    "authors": [
      "Daesoo Lee",
      "Erlend Aune"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2109.03748",
    "title": "A robust approach for deep neural networks in presence of label noise:  relabelling and filtering instances during training",
    "abstract": " Comments: 24 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2109.03748",
    "authors": [
      "Anabel G\u00f3mez-R\u00edos",
      "Juli\u00e1n Luengo",
      "Francisco Herrera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2109.09901",
    "title": "Modeling Adversarial Noise for Adversarial Training",
    "abstract": " Title: Modeling Adversarial Noise for Adversarial Training ",
    "url": "https://arxiv.org/abs/2109.09901",
    "authors": [
      "Dawei Zhou",
      "Nannan Wang",
      "Bo Han",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.10209",
    "title": "Rapid Replanning in Consecutive Pick-and-Place Tasks with Lazy  Experience Graph",
    "abstract": " Title: Rapid Replanning in Consecutive Pick-and-Place Tasks with Lazy  Experience Graph ",
    "url": "https://arxiv.org/abs/2109.10209",
    "authors": [
      "Tin Lai",
      "Fabio Ramos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2109.11678",
    "title": "Improved optimization strategies for deep Multi-Task Networks",
    "abstract": " Title: Improved optimization strategies for deep Multi-Task Networks ",
    "url": "https://arxiv.org/abs/2109.11678",
    "authors": [
      "Lucas Pascal",
      "Pietro Michiardi",
      "Xavier Bost",
      "Benoit Huet",
      "Maria A. Zuluaga"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2109.15222",
    "title": "Natural Synthetic Anomalies for Self-Supervised Anomaly Detection and  Localization",
    "abstract": " Comments: Accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2109.15222",
    "authors": [
      "Hannah M. Schl\u00fcter",
      "Jeremy Tan",
      "Benjamin Hou",
      "Bernhard Kainz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.07291",
    "title": "Only Time Will Tell: Modelling Information Diffusion in Code Review with  Time-Varying Hypergraphs",
    "abstract": " Comments: 10 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2110.07291",
    "authors": [
      "Michael Dorner",
      "Darja \u0160mite",
      "Daniel Mendez",
      "Krzysztof Wnuk",
      "Jacek Czerwonka"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2110.08556",
    "title": "Multi-View Stereo Network with attention thin volume",
    "abstract": " Title: Multi-View Stereo Network with attention thin volume ",
    "url": "https://arxiv.org/abs/2110.08556",
    "authors": [
      "Zihang Wan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.09893",
    "title": "Visualizing Collective Idea Generation and Innovation Processes in  Social Networks",
    "abstract": " Title: Visualizing Collective Idea Generation and Innovation Processes in  Social Networks ",
    "url": "https://arxiv.org/abs/2110.09893",
    "authors": [
      "Yiding Cao",
      "Yingjun Dong",
      "Minjun Kim",
      "Neil G. MacLaren",
      "Sriniwas Pandey",
      "Shelley D. Dionne",
      "Francis J. Yammarino",
      "Hiroki Sayama"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2110.12521",
    "title": "Reachability Embeddings: Scalable Self-Supervised Representation  Learning from Mobility Trajectories for Multimodal Geospatial Computer Vision",
    "abstract": " Comments: Extended version of the accepted research track paper at the 23rd IEEE International Conference on Mobile Data Management (MDM), 2022, Paphos, Cyprus. 12 pages, 6 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2110.12521",
    "authors": [
      "Swetava Ganguli",
      "C. V. Krishnakumar Iyer",
      "Vipul Pandey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.13705",
    "title": "Causal Effect Estimation using Variational Information Bottleneck",
    "abstract": " Title: Causal Effect Estimation using Variational Information Bottleneck ",
    "url": "https://arxiv.org/abs/2110.13705",
    "authors": [
      "Zhenyu Lu",
      "Yurong Cheng",
      "Mingjun Zhong",
      "George Stoian",
      "Ye Yuan",
      "Guoren Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.06705",
    "title": "A compact butterfly-style silicon photonic-electronic neural chip for  hardware-efficient deep learning",
    "abstract": " Comments: 17 pages,5 figures ",
    "url": "https://arxiv.org/abs/2111.06705",
    "authors": [
      "Chenghao Feng",
      "Jiaqi Gu",
      "Hanqing Zhu",
      "Zhoufeng Ying",
      "Zheng Zhao",
      "David Z. Pan",
      "Ray T. Chen"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2111.08919",
    "title": "EMScore: Evaluating Video Captioning via Coarse-Grained and Fine-Grained  Embedding Matching",
    "abstract": " Comments: cvpr2022 ",
    "url": "https://arxiv.org/abs/2111.08919",
    "authors": [
      "Yaya Shi",
      "Xu Yang",
      "Haiyang Xu",
      "Chunfeng Yuan",
      "Bing Li",
      "Weiming Hu",
      "Zheng-Jun Zha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.09805",
    "title": "DICE: Leveraging Sparsification for Out-of-Distribution Detection",
    "abstract": " Comments: Accepted in ECCV2022 ",
    "url": "https://arxiv.org/abs/2111.09805",
    "authors": [
      "Yiyou Sun",
      "Yixuan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.10659",
    "title": "Are Vision Transformers Robust to Patch Perturbations?",
    "abstract": " Title: Are Vision Transformers Robust to Patch Perturbations? ",
    "url": "https://arxiv.org/abs/2111.10659",
    "authors": [
      "Jindong Gu",
      "Volker Tresp",
      "Yao Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2111.11430",
    "title": "Class-agnostic Object Detection with Multi-modal Transformer",
    "abstract": " Comments: ECCV 2022 accepted ",
    "url": "https://arxiv.org/abs/2111.11430",
    "authors": [
      "Muhammad Maaz",
      "Hanoona Rasheed",
      "Salman Khan",
      "Fahad Shahbaz Khan",
      "Rao Muhammad Anwer",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.12696",
    "title": "A Lightweight Graph Transformer Network for Human Mesh Reconstruction  from 2D Human Pose",
    "abstract": " Comments: ACM Multimedia 2022 ",
    "url": "https://arxiv.org/abs/2111.12696",
    "authors": [
      "Ce Zheng",
      "Matias Mendieta",
      "Pu Wang",
      "Aidong Lu",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2111.12924",
    "title": "Joint stereo 3D object detection and implicit surface reconstruction",
    "abstract": " Title: Joint stereo 3D object detection and implicit surface reconstruction ",
    "url": "https://arxiv.org/abs/2111.12924",
    "authors": [
      "Shichao Li",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2111.14834",
    "title": "Self-supervised Autoregressive Domain Adaptation for Time Series Data",
    "abstract": " Comments: Accepted for publication in IEEE Transactions on Neural Networks and Learning Systems ",
    "url": "https://arxiv.org/abs/2111.14834",
    "authors": [
      "Mohamed Ragab",
      "Emadeldeen Eldele",
      "Zhenghua Chen",
      "Min Wu",
      "Chee-Keong Kwoh",
      "Xiaoli Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.00833",
    "title": "AWESOME: Empowering Scalable Data Science on Social Media Data with an  Optimized Tri-Store Data System",
    "abstract": " Title: AWESOME: Empowering Scalable Data Science on Social Media Data with an  Optimized Tri-Store Data System ",
    "url": "https://arxiv.org/abs/2112.00833",
    "authors": [
      "Xiuwen Zheng",
      "Subhasis Dasgupta",
      "Arun Kumar",
      "Amarnath Gupta"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2112.01335",
    "title": "Semantic-Sparse Colorization Network for Deep Exemplar-based  Colorization",
    "abstract": " Comments: Accepted by ECCV2022; 14 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2112.01335",
    "authors": [
      "Yunpeng Bai",
      "Chao Dong",
      "Zenghao Chai",
      "Andong Wang",
      "Zhengzhuo Xu",
      "Chun Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.06380",
    "title": "Robust Voting Rules from Algorithmic Robust Statistics",
    "abstract": " Title: Robust Voting Rules from Algorithmic Robust Statistics ",
    "url": "https://arxiv.org/abs/2112.06380",
    "authors": [
      "Allen Liu",
      "Ankur Moitra"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.08670",
    "title": "Amortized Noisy Channel Neural Machine Translation",
    "abstract": " Comments: INLG 2022 ",
    "url": "https://arxiv.org/abs/2112.08670",
    "authors": [
      "Richard Yuanzhe Pang",
      "He He",
      "Kyunghyun Cho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.09205",
    "title": "AFDetV2: Rethinking the Necessity of the Second Stage for Object  Detection from Point Clouds",
    "abstract": " Comments: AAAI 2022; 1st Place Solution for the Real-time 3D Detection and the Most Efficient Model of the Waymo Open Dataset Challenges 2021 (this http URL) ",
    "url": "https://arxiv.org/abs/2112.09205",
    "authors": [
      "Yihan Hu",
      "Zhuangzhuang Ding",
      "Runzhou Ge",
      "Wenxin Shao",
      "Li Huang",
      "Kun Li",
      "Qiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.10166",
    "title": "FedNI: Federated Graph Learning with Network Inpainting for  Population-Based Disease Prediction",
    "abstract": " Title: FedNI: Federated Graph Learning with Network Inpainting for  Population-Based Disease Prediction ",
    "url": "https://arxiv.org/abs/2112.10166",
    "authors": [
      "Liang Peng",
      "Nan Wang",
      "Nicha Dvornek",
      "Xiaofeng Zhu",
      "Xiaoxiao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2201.00065",
    "title": "Stealth Data Injection Attacks with Sparsity Constraints",
    "abstract": " Comments: 10 pages, 6 figures, submited to IEEE Trans. Smart Grid ",
    "url": "https://arxiv.org/abs/2201.00065",
    "authors": [
      "Xiuzhen Ye",
      "I\u00f1aki Esnaola",
      "Samir M. Perlaza",
      "Robert F. Harrison"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2201.00430",
    "title": "Classifying Subset Feedback Vertex Set for $H$-Free Graphs",
    "abstract": " Title: Classifying Subset Feedback Vertex Set for $H$-Free Graphs ",
    "url": "https://arxiv.org/abs/2201.00430",
    "authors": [
      "Giacomo Paesani",
      "Dani\u00ebl Paulusma",
      "Pawe\u0142 Rz\u0105\u017cewski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2201.12876",
    "title": "DeepCatra: Learning Flow- and Graph-based Behaviors for Android Malware  Detection",
    "abstract": " Comments: IET Information Security (to appear) ",
    "url": "https://arxiv.org/abs/2201.12876",
    "authors": [
      "Yafei Wu",
      "Jian Shi",
      "Peicheng Wang",
      "Dongrui Zeng",
      "Cong Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.00097",
    "title": "Self-supervised Graphs for Audio Representation Learning with Limited  Labeled Data",
    "abstract": " Title: Self-supervised Graphs for Audio Representation Learning with Limited  Labeled Data ",
    "url": "https://arxiv.org/abs/2202.00097",
    "authors": [
      "Amir Shirian",
      "Krishna Somandepalli",
      "Tanaya Guha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2202.01943",
    "title": "PSO-PINN: Physics-Informed Neural Networks Trained with Particle Swarm  Optimization",
    "abstract": " Title: PSO-PINN: Physics-Informed Neural Networks Trained with Particle Swarm  Optimization ",
    "url": "https://arxiv.org/abs/2202.01943",
    "authors": [
      "Caio Davi",
      "Ulisses Braga-Neto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2202.03532",
    "title": "MINER: Multiscale Implicit Neural Representations",
    "abstract": " Comments: 14 pages, accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2202.03532",
    "authors": [
      "Vishwanath Saragadam",
      "Jasper Tan",
      "Guha Balakrishnan",
      "Richard G. Baraniuk",
      "Ashok Veeraraghavan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.04731",
    "title": "Graph Neural Network for Cell Tracking in Microscopy Videos",
    "abstract": " Comments: Accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2202.04731",
    "authors": [
      "Tal Ben-Haim",
      "Tammy Riklin Raviv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07054",
    "title": "Universal Adversarial Examples in Remote Sensing: Methodology and  Benchmark",
    "abstract": " Title: Universal Adversarial Examples in Remote Sensing: Methodology and  Benchmark ",
    "url": "https://arxiv.org/abs/2202.07054",
    "authors": [
      "Yonghao Xu",
      "Pedram Ghamisi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07570",
    "title": "ScoreNet: Learning Non-Uniform Attention and Augmentation for  Transformer-Based Histopathological Image Classification",
    "abstract": " Comments: 19 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2202.07570",
    "authors": [
      "Thomas Stegm\u00fcller",
      "Behzad Bozorgtabar",
      "Antoine Spahr",
      "Jean-Philippe Thiran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.08036",
    "title": "No One Left Behind: Inclusive Federated Learning over Heterogeneous  Devices",
    "abstract": " Comments: Accepted by KDD22 ",
    "url": "https://arxiv.org/abs/2202.08036",
    "authors": [
      "Ruixuan Liu",
      "Fangzhao Wu",
      "Chuhan Wu",
      "Yanlin Wang",
      "Lingjuan Lyu",
      "Hong Chen",
      "Xing Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2202.08603",
    "title": "Cross-Silo Heterogeneous Model Federated Multitask Learning",
    "abstract": " Title: Cross-Silo Heterogeneous Model Federated Multitask Learning ",
    "url": "https://arxiv.org/abs/2202.08603",
    "authors": [
      "Xingjian Cao",
      "Zonghang Li",
      "Gang Sun",
      "Hongfang Yu",
      "Mohsen Guizani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.09403",
    "title": "Multiple Ancillary Services Provision by Distributed Energy Resources in  Active Distribution Networks",
    "abstract": " Comments: In proceedings of the 11th Bulk Power Systems Dynamics and Control Symposium (IREP 2022), July 25-30, 2022, Banff, Canada ",
    "url": "https://arxiv.org/abs/2202.09403",
    "authors": [
      "Ognjen Stanojev",
      "Yi Guo",
      "Petros Aristidou",
      "Gabriela Hug"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.09667",
    "title": "Doubly Robust Distributionally Robust Off-Policy Evaluation and Learning",
    "abstract": " Comments: Short Talk at ICML 2022 ",
    "url": "https://arxiv.org/abs/2202.09667",
    "authors": [
      "Nathan Kallus",
      "Xiaojie Mao",
      "Kaiwen Wang",
      "Zhengyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.11595",
    "title": "Induced Disjoint Paths and Connected Subgraphs for $H$-Free Graphs",
    "abstract": " Title: Induced Disjoint Paths and Connected Subgraphs for $H$-Free Graphs ",
    "url": "https://arxiv.org/abs/2202.11595",
    "authors": [
      "Barnaby Martin",
      "Dani\u00ebl Paulusma",
      "Siani Smith",
      "Erik Jan van Leeuwen"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2203.01298",
    "title": "Pareto Frontier Approximation Network (PA-Net) to Solve Bi-objective TSP",
    "abstract": " Comments: Accepted at 2022 IEEE 18th International Conference on Automation Science and Engineering ",
    "url": "https://arxiv.org/abs/2203.01298",
    "authors": [
      "Ishaan Mehta",
      "Sharareh Taghipour",
      "Sajad Saeedi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.02511",
    "title": "Self-Supervised Learning for Joint Pushing and Grasping Policies in  Highly Cluttered Environments",
    "abstract": " Title: Self-Supervised Learning for Joint Pushing and Grasping Policies in  Highly Cluttered Environments ",
    "url": "https://arxiv.org/abs/2203.02511",
    "authors": [
      "Kamal Mokhtar",
      "Cock Heemskerk",
      "Hamidreza Kasaei"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.04616",
    "title": "PALI-NLP at SemEval-2022 Task 4: Discriminative Fine-tuning of  Transformers for Patronizing and Condescending Language Detection",
    "abstract": " Comments: 8 pages, submitted in SemEval-2022 Workshop (co-located with NAACL) ",
    "url": "https://arxiv.org/abs/2203.04616",
    "authors": [
      "Dou Hu",
      "Mengyuan Zhou",
      "Xiyang Du",
      "Mengfei Yuan",
      "Meizhi Jin",
      "Lianxin Jiang",
      "Yang Mo",
      "Xiaofeng Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.05469",
    "title": "Prediction-Guided Distillation for Dense Object Detection",
    "abstract": " Comments: ECCV 2022 ",
    "url": "https://arxiv.org/abs/2203.05469",
    "authors": [
      "Chenhongyi Yang",
      "Mateusz Ochal",
      "Amos Storkey",
      "Elliot J. Crowley"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.08606",
    "title": "A Reachability Index for Recursive Label-Concatenated Graph Queries",
    "abstract": " Title: A Reachability Index for Recursive Label-Concatenated Graph Queries ",
    "url": "https://arxiv.org/abs/2203.08606",
    "authors": [
      "Chao Zhang",
      "Angela Bonifati",
      "Hugo Kapp",
      "Vlad Ioan Haprian",
      "Jean-Pierre Lozi"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2203.12257",
    "title": "IAM: A Comprehensive and Large-Scale Dataset for Integrated Argument  Mining Tasks",
    "abstract": " Comments: 11 pages, 3 figures, accepted by ACL 2022 ",
    "url": "https://arxiv.org/abs/2203.12257",
    "authors": [
      "Liying Cheng",
      "Lidong Bing",
      "Ruidan He",
      "Qian Yu",
      "Yan Zhang",
      "Luo Si"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.13214",
    "title": "A Perturbation-Constrained Adversarial Attack for Evaluating the  Robustness of Optical Flow",
    "abstract": " Comments: Accepted at the European Conference on Computer Vision (ECCV) 2022 ",
    "url": "https://arxiv.org/abs/2203.13214",
    "authors": [
      "Jenny Schmalfuss",
      "Philipp Scholze",
      "Andr\u00e9s Bruhn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.14044",
    "title": "Contrastive Graph Learning for Population-based fMRI Classification",
    "abstract": " Title: Contrastive Graph Learning for Population-based fMRI Classification ",
    "url": "https://arxiv.org/abs/2203.14044",
    "authors": [
      "Xuesong Wang",
      "Lina Yao",
      "Islem Rekik",
      "Yu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.16513",
    "title": "PromptDet: Towards Open-vocabulary Detection using Uncurated Images",
    "abstract": " Comments: ECCV2022 ",
    "url": "https://arxiv.org/abs/2203.16513",
    "authors": [
      "Chengjian Feng",
      "Yujie Zhong",
      "Zequn Jie",
      "Xiangxiang Chu",
      "Haibing Ren",
      "Xiaolin Wei",
      "Weidi Xie",
      "Lin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.01877",
    "title": "Non-Euclidean Monotone Operator Theory with Applications to Recurrent  Neural Networks",
    "abstract": " Title: Non-Euclidean Monotone Operator Theory with Applications to Recurrent  Neural Networks ",
    "url": "https://arxiv.org/abs/2204.01877",
    "authors": [
      "Alexander Davydov",
      "Saber Jafarpour",
      "Anton V. Proskurnikov",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.04236",
    "title": "ChildCI Framework: Analysis of Motor and Cognitive Development in  Children-Computer Interaction for Age Detection",
    "abstract": " Comments: 11 pages, 3 figures, 6 tables ",
    "url": "https://arxiv.org/abs/2204.04236",
    "authors": [
      "Juan Carlos Ruiz-Garcia",
      "Ruben Tolosana",
      "Ruben Vera-Rodriguez",
      "Julian Fierrez",
      "Jaime Herreros-Rodriguez"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.06255",
    "title": "Neural Operator with Regularity Structure for Modeling Dynamics Driven  by SPDEs",
    "abstract": " Title: Neural Operator with Regularity Structure for Modeling Dynamics Driven  by SPDEs ",
    "url": "https://arxiv.org/abs/2204.06255",
    "authors": [
      "Peiyan Hu",
      "Qi Meng",
      "Bingguang Chen",
      "Shiqi Gong",
      "Yue Wang",
      "Wei Chen",
      "Rongchan Zhu",
      "Zhi-Ming Ma",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2205.10365",
    "title": "A Correlation Information-based Spatiotemporal Network for Traffic Flow  Forecasting",
    "abstract": " Comments: 19 pages, 13 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2205.10365",
    "authors": [
      "Weiguo Zhu",
      "Yongqi Sun",
      "Xintong Yi",
      "Yan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10840",
    "title": "Self-mentoring: a new deep learning pipeline to train a self-supervised  U-net for few-shot learning of bio-artificial capsule segmentation",
    "abstract": " Title: Self-mentoring: a new deep learning pipeline to train a self-supervised  U-net for few-shot learning of bio-artificial capsule segmentation ",
    "url": "https://arxiv.org/abs/2205.10840",
    "authors": [
      "Arnaud Deleruyelle",
      "Cristian Versari",
      "John Klein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11283",
    "title": "SelfReformer: Self-Refined Network with Transformer for Salient Object  Detection",
    "abstract": " Title: SelfReformer: Self-Refined Network with Transformer for Salient Object  Detection ",
    "url": "https://arxiv.org/abs/2205.11283",
    "authors": [
      "Yi Ke Yun",
      "Weisi Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13061",
    "title": "RENs: Relevance Encoding Networks",
    "abstract": " Title: RENs: Relevance Encoding Networks ",
    "url": "https://arxiv.org/abs/2205.13061",
    "authors": [
      "Krithika Iyer",
      "Riddhish Bhalodia",
      "Shireen Elhabian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13972",
    "title": "Counterfactual Fairness with Partially Known Causal Graph",
    "abstract": " Title: Counterfactual Fairness with Partially Known Causal Graph ",
    "url": "https://arxiv.org/abs/2205.13972",
    "authors": [
      "Aoqi Zuo",
      "Susan Wei",
      "Tongliang Liu",
      "Bo Han",
      "Kun Zhang",
      "Mingming Gong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14354",
    "title": "Multi-Task Learning with Multi-Query Transformer for Dense Prediction",
    "abstract": " Title: Multi-Task Learning with Multi-Query Transformer for Dense Prediction ",
    "url": "https://arxiv.org/abs/2205.14354",
    "authors": [
      "Yangyang Xu",
      "Xiangtai Li",
      "Haobo Yuan",
      "Yibo Yang",
      "Jing Zhang",
      "Yunhai Tong",
      "Lefei Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00594",
    "title": "Sparse graphs with bounded induced cycle packing number have logarithmic  treewidth",
    "abstract": " Comments: 28 pages, 6 figures. v3: improved complexity results ",
    "url": "https://arxiv.org/abs/2206.00594",
    "authors": [
      "Marthe Bonamy",
      "\u00c9douard Bonnet",
      "Hugues D\u00e9pr\u00e9s",
      "Louis Esperet",
      "Colin Geniet",
      "Claire Hilaire",
      "St\u00e9phan Thomass\u00e9",
      "Alexandra Wesolek"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2206.01899",
    "title": "Evaluation of creating scoring opportunities for teammates in soccer via  trajectory prediction",
    "abstract": " Comments: 22 pages, 8 figures, accepted in 9th Workshop on Machine Learning and Data Mining for Sports Analytics 2022 (MLSA'22) co-located with ECML-PKDD'22 ",
    "url": "https://arxiv.org/abs/2206.01899",
    "authors": [
      "Masakiyo Teranishi",
      "Kazushi Tsutsui",
      "Kazuya Takeda",
      "Keisuke Fujii"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2206.02395",
    "title": "Product structure of graph classes with bounded treewidth",
    "abstract": " Title: Product structure of graph classes with bounded treewidth ",
    "url": "https://arxiv.org/abs/2206.02395",
    "authors": [
      "Rutger Campbell",
      "Katie Clinch",
      "Marc Distel",
      "J. Pascal Gollin",
      "Kevin Hendrey",
      "Robert Hickingbotham",
      "Tony Huynh",
      "Freddie Illingworth",
      "Youri Tamitegama",
      "Jane Tan",
      "David R. Wood"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2206.03181",
    "title": "Detecting Global Community Structure in a COVID-19 Activity Correlation  Network",
    "abstract": " Comments: 11 pages, 4 figures, 1 table; accepted for publication in Complex Networks & Their Applications XI: Proceedings of The Eleventh International Conference on Complex Networks and their Applications: COMPLEX NETWORKS 2022 - Volume 1 (Hocine Cherifi, Rosario Nunzio Mantegna, Luis M. Rocha, Chantal Cherifi, Salvatore Micciche, eds.) ",
    "url": "https://arxiv.org/abs/2206.03181",
    "authors": [
      "Hiroki Sayama"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2206.03823",
    "title": "Multi-channel neural networks for predicting influenza A virus hosts and  antigenic types",
    "abstract": " Comments: Accepted for publication at IC3K (KDIR) 2022 ",
    "url": "https://arxiv.org/abs/2206.03823",
    "authors": [
      "Yanhua Xu",
      "Dominik Wojtczak"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.05483",
    "title": "Bilateral Dependency Optimization: Defending Against Model-inversion  Attacks",
    "abstract": " Comments: Accepted to KDD 2022 (Research Track) ",
    "url": "https://arxiv.org/abs/2206.05483",
    "authors": [
      "Xiong Peng",
      "Feng Liu",
      "Jingfen Zhang",
      "Long Lan",
      "Junjie Ye",
      "Tongliang Liu",
      "Bo Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.05731",
    "title": "Human Mobility Prediction with Causal and Spatial-constrained Multi-task  Network",
    "abstract": " Comments: The experimental results in the paper need to be updated, so we withdraw the original version ",
    "url": "https://arxiv.org/abs/2206.05731",
    "authors": [
      "Zongyuan Huang",
      "Shengyuan Xu",
      "Menghan Wang",
      "Hansi Wu",
      "Yanyan Xu",
      "Yaohui Jin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.11233",
    "title": "Automatic Autism Spectrum Disorder Detection Using Artificial  Intelligence Methods with MRI Neuroimaging: A Review",
    "abstract": " Title: Automatic Autism Spectrum Disorder Detection Using Artificial  Intelligence Methods with MRI Neuroimaging: A Review ",
    "url": "https://arxiv.org/abs/2206.11233",
    "authors": [
      "Parisa Moridian",
      "Navid Ghassemi",
      "Mahboobeh Jafari",
      "Salam Salloum-Asfar",
      "Delaram Sadeghi",
      "Marjane Khodatars",
      "Afshin Shoeibi",
      "Abbas Khosravi",
      "Sai Ho Ling",
      "Abdulhamit Subasi",
      "Roohallah Alizadehsani",
      "Juan M. Gorriz",
      "Sara A Abdulla",
      "U. Rajendra Acharya"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.12879",
    "title": "Data Augmentation for Dementia Detection in Spoken Language",
    "abstract": " Comments: Accepted to INTERSPEECH 2022 ",
    "url": "https://arxiv.org/abs/2206.12879",
    "authors": [
      "Anna Hl\u00e9dikov\u00e1",
      "Dominika Woszczyk",
      "Alican Akman",
      "Soteris Demetriou",
      "Bj\u00f6rn Schuller"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.13076",
    "title": "SearchMorph:Multi-scale Correlation Iterative Network for Deformable  Registration",
    "abstract": " Title: SearchMorph:Multi-scale Correlation Iterative Network for Deformable  Registration ",
    "url": "https://arxiv.org/abs/2206.13076",
    "authors": [
      "Xiao Fan",
      "Shuxin Zhuang",
      "Zhemin Zhuang",
      "Ye Yuan",
      "Shunmin Qiu",
      "Alex Noel Joseph Raj",
      "Yibiao Rong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01573",
    "title": "Embedding contrastive unsupervised features to cluster in- and  out-of-distribution noise in corrupted image datasets",
    "abstract": " Comments: Accepted at ECCV 2022 ",
    "url": "https://arxiv.org/abs/2207.01573",
    "authors": [
      "Paul Albert",
      "Eric Arazo",
      "Noel E. O'Connor",
      "Kevin McGuinness"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.02739",
    "title": "Robust Counterfactual Explanations for Tree-Based Ensembles",
    "abstract": " Comments: Accepted at ICML 2022 ",
    "url": "https://arxiv.org/abs/2207.02739",
    "authors": [
      "Sanghamitra Dutta",
      "Jason Long",
      "Saumitra Mishra",
      "Cecilia Tilli",
      "Daniele Magazzeni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.02970",
    "title": "Network Binarization via Contrastive Learning",
    "abstract": " Comments: Accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2207.02970",
    "authors": [
      "Yuzhang Shang",
      "Dan Xu",
      "Ziliang Zong",
      "Liqiang Nie",
      "Yan Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04364",
    "title": "Sequential Manipulation Planning on Scene Graph",
    "abstract": " Comments: 8 pages, 6 figures. Accepted by IROS 2022 ",
    "url": "https://arxiv.org/abs/2207.04364",
    "authors": [
      "Ziyuan Jiao",
      "Yida Niu",
      "Zeyu Zhang",
      "Song-Chun Zhu",
      "Yixin Zhu",
      "Hangxin Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.04693",
    "title": "Exploring Contextual Relationships for Cervical Abnormal Cell Detection",
    "abstract": " Comments: 10 pages, 14 tables, and 3 figures ",
    "url": "https://arxiv.org/abs/2207.04693",
    "authors": [
      "Yixiong Liang",
      "Shuo Feng",
      "Qing Liu",
      "Hulin Kuang",
      "Jianfeng Liu",
      "Liyan Liao",
      "Yun Du",
      "Jianxin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05188",
    "title": "Knowledge Graph Induction enabling Recommending and Trend Analysis: A  Corporate Research Community Use Case",
    "abstract": " Comments: Accepted at ISWC 2022 ",
    "url": "https://arxiv.org/abs/2207.05188",
    "authors": [
      "Nandana Mihindukulasooriya",
      "Mike Sava",
      "Gaetano Rossiello",
      "Md Faisal Mahbub Chowdhury",
      "Irene Yachbes",
      "Aditya Gidh",
      "Jillian Duckwitz",
      "Kovit Nisar",
      "Michael Santos",
      "Alfio Gliozzo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2207.05342",
    "title": "Video Graph Transformer for Video Question Answering",
    "abstract": " Comments: ECCV'22 ",
    "url": "https://arxiv.org/abs/2207.05342",
    "authors": [
      "Junbin Xiao",
      "Pan Zhou",
      "Tat-Seng Chua",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05748",
    "title": "Physics-Informed Deep Neural Operator Networks",
    "abstract": " Comments: 33 pages, 14 figures. arXiv admin note: text overlap with arXiv:2204.00997 by other authors ",
    "url": "https://arxiv.org/abs/2207.05748",
    "authors": [
      "Somdatta Goswami",
      "Aniruddha Bora",
      "Yue Yu",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.06540",
    "title": "Lipschitz Continuity Retained Binary Neural Network",
    "abstract": " Comments: Paper accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2207.06540",
    "authors": [
      "Yuzhang Shang",
      "Dan Xu",
      "Bin Duan",
      "Ziliang Zong",
      "Liqiang Nie",
      "Yan Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.06887",
    "title": "Dynamic Spanning Trees for Connectivity Queries on Fully-dynamic  Undirected Graphs (Extended version)",
    "abstract": " Title: Dynamic Spanning Trees for Connectivity Queries on Fully-dynamic  Undirected Graphs (Extended version) ",
    "url": "https://arxiv.org/abs/2207.06887",
    "authors": [
      "Qing Chen",
      "Oded Lachish",
      "Sven Helmer",
      "Michael B\u00f6hlen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2207.07039",
    "title": "Convolutional Bypasses Are Better Vision Transformer Adapters",
    "abstract": " Title: Convolutional Bypasses Are Better Vision Transformer Adapters ",
    "url": "https://arxiv.org/abs/2207.07039",
    "authors": [
      "Shibo Jie",
      "Zhi-Hong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07316",
    "title": "Privacy-Preserving Face Recognition with Learnable Privacy Budgets in  Frequency Domain",
    "abstract": " Comments: ECCV 2022; Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2207.07316",
    "authors": [
      "Jiazhen Ji",
      "Huan Wang",
      "Yuge Huang",
      "Jiaxiang Wu",
      "Xingkun Xu",
      "Shouhong Ding",
      "ShengChuan Zhang",
      "Liujuan Cao",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07563",
    "title": "QSAN: A Near-term Achievable Quantum Self-Attention Network",
    "abstract": " Title: QSAN: A Near-term Achievable Quantum Self-Attention Network ",
    "url": "https://arxiv.org/abs/2207.07563",
    "authors": [
      "Ren-xin Zhao",
      "Jinjing Shi",
      "Shichao Zhang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  }
]