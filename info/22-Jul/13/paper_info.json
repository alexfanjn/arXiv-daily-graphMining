[
  {
    "id": "arXiv:2207.05055",
    "title": "WeShort: Out-of-distribution Detection With Weak Shortcut structure",
    "abstract": "Neural networks have achieved impressive performance for data in the distribution which is the same as the training set but can produce an overconfident incorrect result for the data these networks have never seen. Therefore, it is essential to detect whether inputs come from out-of-distribution(OOD) in order to guarantee the safety of neural networks deployed in the real world. In this paper, we propose a simple and effective post-hoc technique, WeShort, to reduce the overconfidence of neural networks on OOD data. Our method is inspired by the observation of the internal residual structure, which shows the separation of the OOD and in-distribution (ID) data in the shortcut layer. Our method is compatible with different OOD detection scores and can generalize well to different architectures of networks. We demonstrate our method on various OOD datasets to show its competitive performances and provide reasonable hypotheses to explain why our method works. On the ImageNet benchmark, Weshort achieves state-of-the-art performance on the false positive rate (FPR95) and the area under the receiver operating characteristic (AUROC) on the family of post-hoc methods. ",
    "url": "https://arxiv.org/abs/2207.05055",
    "authors": [
      "Jinhong Lin",
      "Yu Hen Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05064",
    "title": "Adaptive Graph Spatial-Temporal Transformer Network for Traffic Flow  Forecasting",
    "abstract": "Traffic flow forecasting on graphs has real-world applications in many fields, such as transportation system and computer networks. Traffic forecasting can be highly challenging due to complex spatial-temporal correlations and non-linear traffic patterns. Existing works mostly model such spatial-temporal dependencies by considering spatial correlations and temporal correlations separately and fail to model the direct spatial-temporal correlations. Inspired by the recent success of transformers in the graph domain, in this paper, we propose to directly model the cross-spatial-temporal correlations on the spatial-temporal graph using local multi-head self-attentions. To reduce the time complexity, we set the attention receptive field to the spatially neighboring nodes, and we also introduce an adaptive graph to capture the hidden spatial-temporal dependencies. Based on these attention mechanisms, we propose a novel Adaptive Graph Spatial-Temporal Transformer Network (ASTTN), which stacks multiple spatial-temporal attention layers to apply self-attention on the input graph, followed by linear layers for predictions. Experimental results on public traffic network datasets, METR-LA PEMS-BAY, PeMSD4, and PeMSD7, demonstrate the superior performance of our model. ",
    "url": "https://arxiv.org/abs/2207.05064",
    "authors": [
      "Aosong Feng",
      "Leandros Tassiulas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.05067",
    "title": "On the Representation of Causal Background Knowledge and its  Applications in Causal Inference",
    "abstract": "Causal background knowledge about the existence or the absence of causal edges and paths is frequently encountered in observational studies. The shared directed edges and links of a subclass of Markov equivalent DAGs refined due to background knowledge can be represented by a causal maximally partially directed acyclic graph (MPDAG). In this paper, we first provide a sound and complete graphical characterization of causal MPDAGs and give a minimal representation of a causal MPDAG. Then, we introduce a novel representation called direct causal clause (DCC) to represent all types of causal background knowledge in a unified form. Using DCCs, we study the consistency and equivalency of causal background knowledge and show that any causal background knowledge set can be equivalently decomposed into a causal MPDAG plus a minimal residual set of DCCs. Polynomial-time algorithms are also provided for checking the consistency, equivalency, and finding the decomposed MPDAG and residual DCCs. Finally, with causal background knowledge, we prove a sufficient and necessary condition to identify causal effects and surprisingly find that the identifiability of causal effects only depends on the decomposed MPDAG. We also develop a local IDA-type algorithm to estimate the possible values of an unidentifiable effect. Simulations suggest that causal background knowledge can significantly improve the identifiability of causal effects. ",
    "url": "https://arxiv.org/abs/2207.05067",
    "authors": [
      "Zhuangyan Fang",
      "Ruiqi Zhao",
      "Yue Liu",
      "Yangbo He"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.05068",
    "title": "Few-Shot Semantic Relation Prediction across Heterogeneous Graphs",
    "abstract": "Semantic relation prediction aims to mine the implicit relationships between objects in heterogeneous graphs, which consist of different types of objects and different types of links. In real-world scenarios, new semantic relations constantly emerge and they typically appear with only a few labeled data. Since a variety of semantic relations exist in multiple heterogeneous graphs, the transferable knowledge can be mined from some existing semantic relations to help predict the new semantic relations with few labeled data. This inspires a novel problem of few-shot semantic relation prediction across heterogeneous graphs. However, the existing methods cannot solve this problem because they not only require a large number of labeled samples as input, but also focus on a single graph with a fixed heterogeneity. Targeting this novel and challenging problem, in this paper, we propose a Meta-learning based Graph neural network for Semantic relation prediction, named MetaGS. Firstly, MetaGS decomposes the graph structure between objects into multiple normalized subgraphs, then adopts a two-view graph neural network to capture local heterogeneous information and global structure information of these subgraphs. Secondly, MetaGS aggregates the information of these subgraphs with a hyper-prototypical network, which can learn from existing semantic relations and adapt to new semantic relations. Thirdly, using the well-initialized two-view graph neural network and hyper-prototypical network, MetaGS can effectively learn new semantic relations from different graphs while overcoming the limitation of few labeled data. Extensive experiments on three real-world datasets have demonstrated the superior performance of MetaGS over the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2207.05068",
    "authors": [
      "Pengfei Ding",
      "Yan Wang",
      "Guanfeng Liu",
      "Xiaofang Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.05072",
    "title": "An On-demand Photonic Ising Machine with Simplified Hamiltonian  Calculation by Phase-encoding and Intensity Detection",
    "abstract": "Photonic Ising machine is a new paradigm of optical computing, which is based on the characteristics of light wave propagation, parallel processing and low loss transmission. Thus, the process of solving the combinatorial optimization problems can be accelerated through photonic/optoelectronic devices. In this work, we have proposed and demonstrated the so-called Phase-Encoding and Intensity Detection Ising Annealer (PEIDIA) to solve arbitrary Ising problems on demand. The PEIDIA is based on the simulated annealing algorithm and requires only one step of optical linear transformation with simplified Hamiltonian calculation. With PEIDIA, the Ising spins are encoded on the phase term of the optical field and only intensity detection is required during the solving process. As a proof of principle, several 20-dimensional Ising problems have been solved with high ground state probability (0.98 within 1000 iterations for antiferromagnetic cubic model and 1 within 4000 iterations for a random spin-glass model, respectively). It should be mentioned that our proposal is also potential to be implemented with integrated photonic devices such as tunable metasurfaces to achieve large-scale and on-demand photonic Ising machines. ",
    "url": "https://arxiv.org/abs/2207.05072",
    "authors": [
      "Jiayi Ouyang",
      "Yuxuan Liao",
      "Zhiyao Ma",
      "Deyang Kong",
      "Xue Feng",
      "Xiang Zhang",
      "Xiaowen Dong",
      "Kaiyu Cui",
      "Fang Liu",
      "Wei Zhang",
      "Yidong Huang"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2207.05127",
    "title": "RUSH: Robust Contrastive Learning via Randomized Smoothing",
    "abstract": "Recently, adversarial training has been incorporated in self-supervised contrastive pre-training to augment label efficiency with exciting adversarial robustness. However, the robustness came at a cost of expensive adversarial training. In this paper, we show a surprising fact that contrastive pre-training has an interesting yet implicit connection with robustness, and such natural robustness in the pre trained representation enables us to design a powerful robust algorithm against adversarial attacks, RUSH, that combines the standard contrastive pre-training and randomized smoothing. It boosts both standard accuracy and robust accuracy, and significantly reduces training costs as compared with adversarial training. We use extensive empirical studies to show that the proposed RUSH outperforms robust classifiers from adversarial training, by a significant margin on common benchmarks (CIFAR-10, CIFAR-100, and STL-10) under first-order attacks. In particular, under $\\ell_{\\infty}$-norm perturbations of size 8/255 PGD attack on CIFAR-10, our model using ResNet-18 as backbone reached 77.8% robust accuracy and 87.9% standard accuracy. Our work has an improvement of over 15% in robust accuracy and a slight improvement in standard accuracy, compared to the state-of-the-arts. ",
    "url": "https://arxiv.org/abs/2207.05127",
    "authors": [
      "Yijiang Pang",
      "Boyang Liu",
      "Jiayu Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05132",
    "title": "Dev2vec: Representing Domain Expertise of Developers in an Embedding  Space",
    "abstract": "Accurate assessment of the domain expertise of developers is important for assigning the proper candidate to contribute to a project or to attend a job role. Since the potential candidate can come from a large pool, the automated assessment of this domain expertise is a desirable goal. While previous methods have had some success within a single software project, the assessment of a developer's domain expertise from contributions across multiple projects is more challenging. In this paper, we employ doc2vec to represent the domain expertise of developers as embedding vectors. These vectors are derived from different sources that contain evidence of developers' expertise, such as the description of repositories that they contributed, their issue resolving history, and API calls in their commits. We name it dev2vec and demonstrate its effectiveness in representing the technical specialization of developers. Our results indicate that encoding the expertise of developers in an embedding vector outperforms state-of-the-art methods and improves the F1-score up to 21%. Moreover, our findings suggest that ``issue resolving history'' of developers is the most informative source of information to represent the domain expertise of developers in embedding spaces. ",
    "url": "https://arxiv.org/abs/2207.05132",
    "authors": [
      "Arghavan Moradi Dakhel",
      "Michel C. Desmarais",
      "Foutse Khomh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05133",
    "title": "Overview of the Shared Task on Fake News Detection in Urdu at FIRE 2021",
    "abstract": "Automatic detection of fake news is a highly important task in the contemporary world. This study reports the 2nd shared task called UrduFake@FIRE2021 on identifying fake news detection in Urdu. The goal of the shared task is to motivate the community to come up with efficient methods for solving this vital problem, particularly for the Urdu language. The task is posed as a binary classification problem to label a given news article as a real or a fake news article. The organizers provide a dataset comprising news in five domains: (i) Health, (ii) Sports, (iii) Showbiz, (iv) Technology, and (v) Business, split into training and testing sets. The training set contains 1300 annotated news articles -- 750 real news, 550 fake news, while the testing set contains 300 news articles -- 200 real, 100 fake news. 34 teams from 7 different countries (China, Egypt, Israel, India, Mexico, Pakistan, and UAE) registered to participate in the UrduFake@FIRE2021 shared task. Out of those, 18 teams submitted their experimental results, and 11 of those submitted their technical reports, which is substantially higher compared to the UrduFake shared task in 2020 when only 6 teams submitted their technical reports. The technical reports submitted by the participants demonstrated different data representation techniques ranging from count-based BoW features to word vector embeddings as well as the use of numerous machine learning algorithms ranging from traditional SVM to various neural network architectures including Transformers such as BERT and RoBERTa. In this year's competition, the best performing system obtained an F1-macro score of 0.679, which is lower than the past year's best result of 0.907 F1-macro. Admittedly, while training sets from the past and the current years overlap to a large extent, the testing set provided this year is completely different. ",
    "url": "https://arxiv.org/abs/2207.05133",
    "authors": [
      "Maaz Amjad",
      "Sabur Butt",
      "Hamza Imam Amjad",
      "Alisa Zhila",
      "Grigori Sidorov",
      "Alexander Gelbukh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.05137",
    "title": "Towards Effective Multi-Label Recognition Attacks via Knowledge Graph  Consistency",
    "abstract": "Many real-world applications of image recognition require multi-label learning, whose goal is to find all labels in an image. Thus, robustness of such systems to adversarial image perturbations is extremely important. However, despite a large body of recent research on adversarial attacks, the scope of the existing works is mainly limited to the multi-class setting, where each image contains a single label. We show that the naive extensions of multi-class attacks to the multi-label setting lead to violating label relationships, modeled by a knowledge graph, and can be detected using a consistency verification scheme. Therefore, we propose a graph-consistent multi-label attack framework, which searches for small image perturbations that lead to misclassifying a desired target set while respecting label hierarchies. By extensive experiments on two datasets and using several multi-label recognition models, we show that our method generates extremely successful attacks that, unlike naive multi-label perturbations, can produce model predictions consistent with the knowledge graph. ",
    "url": "https://arxiv.org/abs/2207.05137",
    "authors": [
      "Hassan Mahmood",
      "Ehsan Elhamifar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05146",
    "title": "Safe Control for Nonlinear Systems under Faults and Attacks via Control  Barrier Functions",
    "abstract": "Safety is one of the most important properties of control systems. Sensor faults and attacks and actuator failures may cause errors in the sensor measurements and system dynamics, which leads to erroneous control inputs and hence safety violations. In this paper, we improve the robustness against sensor faults and actuator failures by proposing a class of Fault-Tolerant Control Barrier Functions (FT-CBFs) for nonlinear systems. Our approach maintains a set of state estimators according to fault patterns and incorporates CBF-based linear constraints for each state estimator. We then propose a framework for joint safety and stability by integrating FT-CBFs with Control Lyapunov Functions. With a similar philosophy of utilizing redundancy, we proposed High order CBF-based approach to ensure safety when actuator failures occur. We propose a sum-of-squares (SOS) based approach to verify the feasibility of FT-CBFs for both sensor faults and actuator failures. We evaluate our approach via two case studies, namely, a wheeled mobile robot (WMR) system in the presence of a sensor attack and a Boeing 747 lateral control system under actuator failures. ",
    "url": "https://arxiv.org/abs/2207.05146",
    "authors": [
      "Hongchao Zhang",
      "Zhouchi Li",
      "Andrew Clark"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.05188",
    "title": "Knowledge Graph Induction enabling Recommending and Trend Analysis: A  Corporate Research Community Use Case",
    "abstract": "A research division plays an important role of driving innovation in an organization. Drawing insights, following trends, keeping abreast of new research, and formulating strategies are increasingly becoming more challenging for both researchers and executives as the amount of information grows in both velocity and volume. In this paper we present a use case of how a corporate research community, IBM Research, utilizes Semantic Web technologies to induce a unified Knowledge Graph from both structured and textual data obtained by integrating various applications used by the community related to research projects, academic papers, datasets, achievements and recognition. In order to make the Knowledge Graph more accessible to application developers, we identified a set of common patterns for exploiting the induced knowledge and exposed them as APIs. Those patterns were born out of user research which identified the most valuable use cases or user pain points to be alleviated. We outline two distinct scenarios: recommendation and analytics for business use. We will discuss these scenarios in detail and provide an empirical evaluation on entity recommendation specifically. The methodology used and the lessons learned from this work can be applied to other organizations facing similar challenges. ",
    "url": "https://arxiv.org/abs/2207.05188",
    "authors": [
      "Nandana Mihindukulasooriya",
      "Mike Sava",
      "Gaetano Rossiello",
      "Md Faisal Mahbub Chowdhury",
      "Irene Yachbes",
      "Aditya Gidh",
      "Jillian Duckwitz",
      "Kovit Nisar",
      "Michael Santos",
      "Alfio Gliozzo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2207.05194",
    "title": "Towards Neural Numeric-To-Text Generation From Temporal Personal Health  Data",
    "abstract": "With an increased interest in the production of personal health technologies designed to track user data (e.g., nutrient intake, step counts), there is now more opportunity than ever to surface meaningful behavioral insights to everyday users in the form of natural language. This knowledge can increase their behavioral awareness and allow them to take action to meet their health goals. It can also bridge the gap between the vast collection of personal health data and the summary generation required to describe an individual's behavioral tendencies. Previous work has focused on rule-based time-series data summarization methods designed to generate natural language summaries of interesting patterns found within temporal personal health data. We examine recurrent, convolutional, and Transformer-based encoder-decoder models to automatically generate natural language summaries from numeric temporal personal health data. We showcase the effectiveness of our models on real user health data logged in MyFitnessPal and show that we can automatically generate high-quality natural language summaries. Our work serves as a first step towards the ambitious goal of automatically generating novel and meaningful temporal summaries from personal health data. ",
    "url": "https://arxiv.org/abs/2207.05194",
    "authors": [
      "Jonathan Harris",
      "Mohammed J. Zaki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.05200",
    "title": "Real-Time And Robust 3D Object Detection with Roadside LiDARs",
    "abstract": "This work aims to address the challenges in autonomous driving by focusing on the 3D perception of the environment using roadside LiDARs. We design a 3D object detection model that can detect traffic participants in roadside LiDARs in real-time. Our model uses an existing 3D detector as a baseline and improves its accuracy. To prove the effectiveness of our proposed modules, we train and evaluate the model on three different vehicle and infrastructure datasets. To show the domain adaptation ability of our detector, we train it on an infrastructure dataset from China and perform transfer learning on a different dataset recorded in Germany. We do several sets of experiments and ablation studies for each module in the detector that show that our model outperforms the baseline by a significant margin, while the inference speed is at 45 Hz (22 ms). We make a significant contribution with our LiDAR-based 3D detector that can be used for smart city applications to provide connected and automated vehicles with a far-reaching view. Vehicles that are connected to the roadside sensors can get information about other vehicles around the corner to improve their path and maneuver planning and to increase road traffic safety. ",
    "url": "https://arxiv.org/abs/2207.05200",
    "authors": [
      "Walter Zimmer",
      "Jialong Wu",
      "Xingcheng Zhou",
      "Alois C. Knoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05205",
    "title": "Scaling Novel Object Detection with Weakly Supervised Detection  Transformers",
    "abstract": "Weakly supervised object detection (WSOD) enables object detectors to be trained using image-level class labels. However, the practical application of current WSOD models is limited, as they operate at small scales and require extensive training and refinement. We propose the Weakly Supervised Detection Transformer, which enables efficient knowledge transfer from a large-scale pretraining dataset to WSOD finetuning on hundreds of novel objects. We leverage pretrained knowledge to improve the multiple instance learning framework used in WSOD, and experiments show our approach outperforms the state-of-the-art on datasets with twice the novel classes than previously shown. ",
    "url": "https://arxiv.org/abs/2207.05205",
    "authors": [
      "Tyler LaBonte",
      "Yale Song",
      "Xin Wang",
      "Vibhav Vineet",
      "Neel Joshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05207",
    "title": "Counterexample Generation for Infinite-State Chemical Reaction Networks",
    "abstract": "Counterexample generation is an indispensable part of model checking process. In stochastic model checking, counterexample generation is a challenging problem as it is not enough to find a single trace that violates the given property. Instead, a potentially large set of traces with enough probability to violate the property needs to be found. This paper considers counterexample generation for chemical reaction network (CRN) models with potentially infinite state space. A method based on bounded model checking using SMT solving is developed for counterexample generation for CRNs. It intends to find a small set of property violating paths of a given model such that they collectively have a total probability that is above a given threshold. A unique challenge is due to the highly connected state space of CRNs where a counterexample is only a tiny subset of all property violating paths. To address such challenges, this paper presents a number of optimizations including a divide-and-conquer technique to scale up the counterexample generation method for large CRN models. This paper reports results from experiments on a number of infinite-state CRN models. ",
    "url": "https://arxiv.org/abs/2207.05207",
    "authors": [
      "Mohammad Ahmadi",
      "Zhen Zhang",
      "Chris Myers",
      "Chris Winstead",
      "Hao Zheng"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2207.05209",
    "title": "Fourier Neural Operator with Learned Deformations for PDEs on General  Geometries",
    "abstract": "Deep learning surrogate models have shown promise in solving partial differential equations (PDEs). Among them, the Fourier neural operator (FNO) achieves good accuracy, and is significantly faster compared to numerical solvers, on a variety of PDEs, such as fluid flows. However, the FNO uses the Fast Fourier transform (FFT), which is limited to rectangular domains with uniform grids. In this work, we propose a new framework, viz., geo-FNO, to solve PDEs on arbitrary geometries. Geo-FNO learns to deform the input (physical) domain, which may be irregular, into a latent space with a uniform grid. The FNO model with the FFT is applied in the latent space. The resulting geo-FNO model has both the computation efficiency of FFT and the flexibility of handling arbitrary geometries. Our geo-FNO is also flexible in terms of its input formats, viz., point clouds, meshes, and design parameters are all valid inputs. We consider a variety of PDEs such as the Elasticity, Plasticity, Euler's, and Navier-Stokes equations, and both forward modeling and inverse design problems. Geo-FNO is $10^5$ times faster than the standard numerical solvers and twice more accurate compared to direct interpolation on existing ML-based PDE solvers such as the standard FNO. ",
    "url": "https://arxiv.org/abs/2207.05209",
    "authors": [
      "Zongyi Li",
      "Daniel Zhengyu Huang",
      "Burigede Liu",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.05225",
    "title": "Susceptibility of Continual Learning Against Adversarial Attacks",
    "abstract": "The recent advances in continual (incremental or lifelong) learning have concentrated on the prevention of forgetting that can lead to catastrophic consequences, but there are two outstanding challenges that must be addressed. The first is the evaluation of the robustness of the proposed methods. The second is ensuring the security of learned tasks remains largely unexplored. This paper presents a comprehensive study of the susceptibility of the continually learned tasks (including both current and previously learned tasks) that are vulnerable to forgetting. Such vulnerability of tasks against adversarial attacks raises profound issues in data integrity and privacy. We consider the task incremental learning (Task-IL) scenario and explore three regularization-based experiments, three replay-based experiments, and one hybrid technique based on the reply and exemplar approach. We examine the robustness of these methods. In particular, we consider cases where we demonstrate that any class belonging to the current or previously learned tasks is prone to misclassification. Our observations highlight the potential limitations of existing Task-IL approaches. Our empirical study recommends that the research community consider the robustness of the proposed continual learning approaches and invest extensive efforts in mitigating catastrophic forgetting. ",
    "url": "https://arxiv.org/abs/2207.05225",
    "authors": [
      "Hikmat Khan",
      "Pir Masoom Shah",
      "Syed Farhan Alam Zaidi",
      "Saif ul Islam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05244",
    "title": "Robust Key-Frame Stereo Visual SLAM with low-threshold Point and Line  Features",
    "abstract": "In this paper, we develop a robust, efficient visual SLAM system that utilizes spatial inhibition of low threshold, baseline lines, and closed-loop keyframe features. Using ORB-SLAM2, our methods include stereo matching, frame tracking, local bundle adjustment, and line and point global bundle adjustment. In particular, we contribute re-projection in line with the baseline. Fusing lines in the system consume colossal time, and we reduce the time from distributing points to utilizing spatial suppression of feature points. In addition, low threshold key points can be more effective in dealing with low textures. In order to overcome Tracking keyframe redundant problems, an efficient and robust closed-loop tracking key frame is proposed. The proposed SLAM has been extensively tested in KITTI and EuRoC datasets, demonstrating that the proposed system is superior to state-of-the-art methods in various scenarios. ",
    "url": "https://arxiv.org/abs/2207.05244",
    "authors": [
      "Meiyu Zhi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.05252",
    "title": "Dynamic Proposals for Efficient Object Detection",
    "abstract": "Object detection is a basic computer vision task to loccalize and categorize objects in a given image. Most state-of-the-art detection methods utilize a fixed number of proposals as an intermediate representation of object candidates, which is unable to adapt to different computational constraints during inference. In this paper, we propose a simple yet effective method which is adaptive to different computational resources by generating dynamic proposals for object detection. We first design a module to make a single query-based model to be able to inference with different numbers of proposals. Further, we extend it to a dynamic model to choose the number of proposals according to the input image, greatly reducing computational costs. Our method achieves significant speed-up across a wide range of detection models including two-stage and query-based models while obtaining similar or even better accuracy. ",
    "url": "https://arxiv.org/abs/2207.05252",
    "authors": [
      "Yiming Cui",
      "Linjie Yang",
      "Ding Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05254",
    "title": "Hunting Group Clues with Transformers for Social Group Activity  Recognition",
    "abstract": "This paper presents a novel framework for social group activity recognition. As an expanded task of group activity recognition, social group activity recognition requires recognizing multiple sub-group activities and identifying group members. Most existing methods tackle both tasks by refining region features and then summarizing them into activity features. Such heuristic feature design renders the effectiveness of features susceptible to incomplete person localization and disregards the importance of scene contexts. Furthermore, region features are sub-optimal to identify group members because the features may be dominated by those of people in the regions and have different semantics. To overcome these drawbacks, we propose to leverage attention modules in transformers to generate effective social group features. Our method is designed in such a way that the attention modules identify and then aggregate features relevant to social group activities, generating an effective feature for each social group. Group member information is embedded into the features and thus accessed by feed-forward networks. The outputs of feed-forward networks represent groups so concisely that group members can be identified with simple Hungarian matching between groups and individuals. Experimental results show that our method outperforms state-of-the-art methods on the Volleyball and Collective Activity datasets. ",
    "url": "https://arxiv.org/abs/2207.05254",
    "authors": [
      "Masato Tamura",
      "Rahul Vishwakarma",
      "Ravigopal Vennelakanti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05259",
    "title": "Language-Based Causal Representation Learning",
    "abstract": "Consider the finite state graph that results from a simple, discrete, dynamical system in which an agent moves in a rectangular grid picking up and dropping packages. Can the state variables of the problem, namely, the agent location and the package locations, be recovered from the structure of the state graph alone without having access to information about the objects, the structure of the states, or any background knowledge? We show that this is possible provided that the dynamics is learned over a suitable domain-independent first-order causal language that makes room for objects and relations that are not assumed to be known. The preference for the most compact representation in the language that is compatible with the data provides a strong and meaningful learning bias that makes this possible. The language of structured causal models (SCMs) is the standard language for representing (static) causal models but in dynamic worlds populated by objects, first-order causal languages such as those used in \"classical AI planning\" are required. While \"classical AI\" requires handcrafted representations, similar representations can be learned from unstructured data over the same languages. Indeed, it is the languages and the preference for compact representations in those languages that provide structure to the world, uncovering objects, relations, and causes. ",
    "url": "https://arxiv.org/abs/2207.05259",
    "authors": [
      "Blai Bonet",
      "Hector Geffner"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.05261",
    "title": "Building Korean Sign Language Augmentation (KoSLA) Corpus with Data  Augmentation Technique",
    "abstract": "We present an efficient framework of corpus for sign language translation. Aided with a simple but dramatic data augmentation technique, our method converts text into annotated forms with minimum information loss. Sign languages are composed of manual signals, non-manual signals, and iconic features. According to professional sign language interpreters, non-manual signals such as facial expressions and gestures play an important role in conveying exact meaning. By considering the linguistic features of sign language, our proposed framework is a first and unique attempt to build a multimodal sign language augmentation corpus (hereinafter referred to as the KoSLA corpus) containing both manual and non-manual modalities. The corpus we built demonstrates confident results in the hospital context, showing improved performance with augmented datasets. To overcome data scarcity, we resorted to data augmentation techniques such as synonym replacement to boost the efficiency of our translation model and available data, while maintaining grammatical and semantic structures of sign language. For the experimental support, we verify the effectiveness of data augmentation technique and usefulness of our corpus by performing a translation task between normal sentences and sign language annotations on two tokenizers. The result was convincing, proving that the BLEU scores with the KoSLA corpus were significant. ",
    "url": "https://arxiv.org/abs/2207.05261",
    "authors": [
      "Changnam An",
      "Eunkyung Han",
      "Dongmyeong Noh",
      "Ohkyoon Kwon",
      "Sumi Lee",
      "Hyunshim Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05275",
    "title": "Size and depth of monotone neural networks: interpolation and  approximation",
    "abstract": "Monotone functions and data sets arise in a variety of applications. We study the interpolation problem for monotone data sets: The input is a monotone data set with $n$ points, and the goal is to find a size and depth efficient monotone neural network, with non negative parameters and threshold units, that interpolates the data set. We show that there are monotone data sets that cannot be interpolated by a monotone network of depth $2$. On the other hand, we prove that for every monotone data set with $n$ points in $\\mathbb{R}^d$, there exists an interpolating monotone network of depth $4$ and size $O(nd)$. Our interpolation result implies that every monotone function over $[0,1]^d$ can be approximated arbitrarily well by a depth-4 monotone network, improving the previous best-known construction of depth $d+1$. Finally, building on results from Boolean circuit complexity, we show that the inductive bias of having positive parameters can lead to a super-polynomial blow-up in the number of neurons when approximating monotone functions. ",
    "url": "https://arxiv.org/abs/2207.05275",
    "authors": [
      "Dan Mikulincer",
      "Daniel Reichman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.05286",
    "title": "Revisiting Inlier and Outlier Specification for Improved  Out-of-Distribution Detection",
    "abstract": "Accurately detecting out-of-distribution (OOD) data with varying levels of semantic and covariate shifts with respect to the in-distribution (ID) data is critical for deployment of safe and reliable models. This is particularly the case when dealing with highly consequential applications (e.g. medical imaging, self-driving cars, etc). The goal is to design a detector that can accept meaningful variations of the ID data, while also rejecting examples from OOD regimes. In practice, this dual objective can be realized by enforcing consistency using an appropriate scoring function (e.g., energy) and calibrating the detector to reject a curated set of OOD data (referred to as outlier exposure or shortly OE). While OE methods are widely adopted, assembling representative OOD datasets is both costly and challenging due to the unpredictability of real-world scenarios, hence the recent trend of designing OE-free detectors. In this paper, we make a surprising finding that controlled generalization to ID variations and exposure to diverse (synthetic) outlier examples are essential to simultaneously improving semantic and modality shift detection. In contrast to existing methods, our approach samples inliers in the latent space, and constructs outlier examples via negative data augmentation. Through a rigorous empirical study on medical imaging benchmarks (MedMNIST, ISIC2019 and NCT), we demonstrate significant performance gains ($15\\% - 35\\%$ in AUROC) over existing OE-free, OOD detection approaches under both semantic and modality shifts. ",
    "url": "https://arxiv.org/abs/2207.05286",
    "authors": [
      "Vivek Narayanaswamy",
      "Yamen Mubarka",
      "Rushil Anirudh",
      "Deepta Rajan",
      "Andreas Spanias",
      "Jayaraman J. Thiagarajan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05291",
    "title": "Pseudo value-based Deep Neural Networks for Multi-state Survival  Analysis",
    "abstract": "Multi-state survival analysis (MSA) uses multi-state models for the analysis of time-to-event data. In medical applications, MSA can provide insights about the complex disease progression in patients. A key challenge in MSA is the accurate subject-specific prediction of multi-state model quantities such as transition probability and state occupation probability in the presence of censoring. Traditional multi-state methods such as Aalen-Johansen (AJ) estimators and Cox-based methods are respectively limited by Markov and proportional hazards assumptions and are infeasible for making subject-specific predictions. Neural ordinary differential equations for MSA relax these assumptions but are computationally expensive and do not directly model the transition probabilities. To address these limitations, we propose a new class of pseudo-value-based deep learning models for multi-state survival analysis, where we show that pseudo values - designed to handle censoring - can be a natural replacement for estimating the multi-state model quantities when derived from a consistent estimator. In particular, we provide an algorithm to derive pseudo values from consistent estimators to directly predict the multi-state survival quantities from the subject's covariates. Empirical results on synthetic and real-world datasets show that our proposed models achieve state-of-the-art results under various censoring settings. ",
    "url": "https://arxiv.org/abs/2207.05291",
    "authors": [
      "Md Mahmudur Rahman",
      "Sanjay Purushotham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2207.05293",
    "title": "Towards Hard-Positive Query Mining for DETR-based Human-Object  Interaction Detection",
    "abstract": "Human-Object Interaction (HOI) detection is a core task for high-level image understanding. Recently, Detection Transformer (DETR)-based HOI detectors have become popular due to their superior performance and efficient structure. However, these approaches typically adopt fixed HOI queries for all testing images, which is vulnerable to the location change of objects in one specific image. Accordingly, in this paper, we propose to enhance DETR's robustness by mining hard-positive queries, which are forced to make correct predictions using partial visual cues. First, we explicitly compose hard-positive queries according to the ground-truth (GT) position of labeled human-object pairs for each training image. Specifically, we shift the GT bounding boxes of each labeled human-object pair so that the shifted boxes cover only a certain portion of the GT ones. We encode the coordinates of the shifted boxes for each labeled human-object pair into an HOI query. Second, we implicitly construct another set of hard-positive queries by masking the top scores in cross-attention maps of the decoder layers. The masked attention maps then only cover partial important cues for HOI predictions. Finally, an alternate strategy is proposed that efficiently combines both types of hard queries. In each iteration, both DETR's learnable queries and one selected type of hard-positive queries are adopted for loss computation. Experimental results show that our proposed approach can be widely applied to existing DETR-based HOI detectors. Moreover, we consistently achieve state-of-the-art performance on three benchmarks: HICO-DET, V-COCO, and HOI-A. Code is available at https://github.com/MuchHair/HQM. ",
    "url": "https://arxiv.org/abs/2207.05293",
    "authors": [
      "Xubin Zhong",
      "Changxing Ding",
      "Zijian Li",
      "Shaoli Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05295",
    "title": "TabSynDex: A Universal Metric for Robust Evaluation of Synthetic Tabular  Data",
    "abstract": "Synthetic tabular data generation becomes crucial when real data is limited, expensive to collect, or simply cannot be used due to privacy concerns. However, producing good quality synthetic data is challenging. Several probabilistic, statistical, and generative adversarial networks (GANs) based approaches have been presented for synthetic tabular data generation. Once generated, evaluating the quality of the synthetic data is quite challenging. Some of the traditional metrics have been used in the literature but there is lack of a common, robust, and single metric. This makes it difficult to properly compare the effectiveness of different synthetic tabular data generation methods. In this paper we propose a new universal metric, TabSynDex, for robust evaluation of synthetic data. TabSynDex assesses the similarity of synthetic data with real data through different component scores which evaluate the characteristics that are desirable for \"high quality\" synthetic data. Being a single score metric, TabSynDex can also be used to observe and evaluate the training of neural network based approaches. This would help in obtaining insights that was not possible earlier. Further, we present several baseline models for comparative analysis of the proposed evaluation metric with existing generative models. ",
    "url": "https://arxiv.org/abs/2207.05295",
    "authors": [
      "Vikram S Chundawat",
      "Ayush K Tarun",
      "Murari Mandal",
      "Mukund Lahoti",
      "Pratik Narang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05297",
    "title": "Efficient and Privacy Preserving Group Signature for Federated Learning",
    "abstract": "Federated Learning (FL) is a Machine Learning (ML) technique that aims to reduce the threats to user data privacy. Training is done using the raw data on the users' device, called clients, and only the training results, called gradients, are sent to the server to be aggregated and generate an updated model. However, we cannot assume that the server can be trusted with private information, such as metadata related to the owner or source of the data. So, hiding the client information from the server helps reduce privacy-related attacks. Therefore, the privacy of the client's identity, along with the privacy of the client's data, is necessary to make such attacks more difficult. This paper proposes an efficient and privacy-preserving protocol for FL based on group signature. A new group signature for federated learning, called GSFL, is designed to not only protect the privacy of the client's data and identity but also significantly reduce the computation and communication costs considering the iterative process of federated learning. We show that GSFL outperforms existing approaches in terms of computation, communication, and signaling costs. Also, we show that the proposed protocol can handle various security attacks in the federated learning environment. ",
    "url": "https://arxiv.org/abs/2207.05297",
    "authors": [
      "Sneha Kanchan",
      "Jae Won Jang",
      "Jun Yong Yoon",
      "Bong Jun Choi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.05301",
    "title": "Edge Augmentation on Disconnected Graphs via Eigenvalue Elevation",
    "abstract": "The graph-theoretical task of determining most likely inter-community edges based on disconnected subgraphs' intra-community connectivity is proposed. An algorithm is developed for this edge augmentation task, based on elevating the zero eigenvalues of graph's spectrum. Upper bounds for eigenvalue elevation amplitude and for the corresponding augmented edge density are derived and are authenticated with simulation on random graphs. The algorithm works consistently across synthetic and real networks, yielding desirable performance at connecting graph components. Edge augmentation reverse-engineers graph partition under different community detection methods (Girvan-Newman method, greedy modularity maximization, label propagation, Louvain method, and fluid community), in most cases producing inter-community edges at >50% frequency. ",
    "url": "https://arxiv.org/abs/2207.05301",
    "authors": [
      "Tianyi Li"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.05302",
    "title": "Causal Conceptions of Fairness and their Consequences",
    "abstract": "Recent work highlights the role of causality in designing equitable decision-making algorithms. It is not immediately clear, however, how existing causal conceptions of fairness relate to one another, or what the consequences are of using these definitions as design principles. Here, we first assemble and categorize popular causal definitions of algorithmic fairness into two broad families: (1) those that constrain the effects of decisions on counterfactual disparities; and (2) those that constrain the effects of legally protected characteristics, like race and gender, on decisions. We then show, analytically and empirically, that both families of definitions \\emph{almost always} -- in a measure theoretic sense -- result in strongly Pareto dominated decision policies, meaning there is an alternative, unconstrained policy favored by every stakeholder with preferences drawn from a large, natural class. For example, in the case of college admissions decisions, policies constrained to satisfy causal fairness definitions would be disfavored by every stakeholder with neutral or positive preferences for both academic preparedness and diversity. Indeed, under a prominent definition of causal fairness, we prove the resulting policies require admitting all students with the same probability, regardless of academic qualifications or group membership. Our results highlight formal limitations and potential adverse consequences of common mathematical notions of causal fairness. ",
    "url": "https://arxiv.org/abs/2207.05302",
    "authors": [
      "Hamed Nilforoshan",
      "Johann Gaebler",
      "Ravi Shroff",
      "Sharad Goel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.05316",
    "title": "Twin identification over viewpoint change: A deep convolutional neural  network surpasses humans",
    "abstract": "Deep convolutional neural networks (DCNNs) have achieved human-level accuracy in face identification (Phillips et al., 2018), though it is unclear how accurately they discriminate highly-similar faces. Here, humans and a DCNN performed a challenging face-identity matching task that included identical twins. Participants (N=87) viewed pairs of face images of three types: same-identity, general imposter pairs (different identities from similar demographic groups), and twin imposter pairs (identical twin siblings). The task was to determine whether the pairs showed the same person or different people. Identity comparisons were tested in three viewpoint-disparity conditions: frontal to frontal, frontal to 45-degree profile, and frontal to 90-degree profile. Accuracy for discriminating matched-identity pairs from twin-imposters and general imposters was assessed in each viewpoint-disparity condition. Humans were more accurate for general-imposter pairs than twin-imposter pairs, and accuracy declined with increased viewpoint disparity between the images in a pair. A DCNN trained for face identification (Ranjan et al., 2018) was tested on the same image pairs presented to humans. Machine performance mirrored the pattern of human accuracy, but with performance at or above all humans in all but one condition. Human and machine similarity scores were compared across all image-pair types. This item-level analysis showed that human and machine similarity ratings correlated significantly in six of nine image-pair types [range r=0.38 to r=0.63], suggesting general accord between the perception of face similarity by humans and the DCNN. These findings also contribute to our understanding of DCNN performance for discriminating high-resemblance faces, demonstrate that the DCNN performs at a level at or above humans, and suggest a degree of parity between the features used by humans and the DCNN. ",
    "url": "https://arxiv.org/abs/2207.05316",
    "authors": [
      "Connor J. Parde",
      "Virginia E. Strehle",
      "Vivekjyoti Banerjee",
      "Ying Hu",
      "Jacqueline G. Cavazos",
      "Carlos D. Castillo",
      "Alice J. O'Toole"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05317",
    "title": "CPO: Change Robust Panorama to Point Cloud Localization",
    "abstract": "We present CPO, a fast and robust algorithm that localizes a 2D panorama with respect to a 3D point cloud of a scene possibly containing changes. To robustly handle scene changes, our approach deviates from conventional feature point matching, and focuses on the spatial context provided from panorama images. Specifically, we propose efficient color histogram generation and subsequent robust localization using score maps. By utilizing the unique equivariance of spherical projections, we propose very fast color histogram generation for a large number of camera poses without explicitly rendering images for all candidate poses. We accumulate the regional consistency of the panorama and point cloud as 2D/3D score maps, and use them to weigh the input color values to further increase robustness. The weighted color distribution quickly finds good initial poses and achieves stable convergence for gradient-based optimization. CPO is lightweight and achieves effective localization in all tested scenarios, showing stable performance despite scene changes, repetitive structures, or featureless regions, which are typical challenges for visual localization with perspective cameras. ",
    "url": "https://arxiv.org/abs/2207.05317",
    "authors": [
      "Junho Kim",
      "Hojun Jang",
      "Changwoon Choi",
      "Young Min Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05321",
    "title": "Bi-fidelity Evolutionary Multiobjective Search for Adversarially Robust  Deep Neural Architectures",
    "abstract": "Deep neural networks have been found vulnerable to adversarial attacks, thus raising potentially concerns in security-sensitive contexts. To address this problem, recent research has investigated the adversarial robustness of deep neural networks from the architectural point of view. However, searching for architectures of deep neural networks is computationally expensive, particularly when coupled with adversarial training process. To meet the above challenge, this paper proposes a bi-fidelity multiobjective neural architecture search approach. First, we formulate the NAS problem for enhancing adversarial robustness of deep neural networks into a multiobjective optimization problem. Specifically, in addition to a low-fidelity performance predictor as the first objective, we leverage an auxiliary-objective -- the value of which is the output of a surrogate model trained with high-fidelity evaluations. Secondly, we reduce the computational cost by combining three performance estimation methods, i.e., parameter sharing, low-fidelity evaluation, and surrogate-based predictor. The effectiveness of the proposed approach is confirmed by extensive experiments conducted on CIFAR-10, CIFAR-100 and SVHN datasets. ",
    "url": "https://arxiv.org/abs/2207.05321",
    "authors": [
      "Jia Liu",
      "Ran Cheng",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2207.05324",
    "title": "CompoundE: Knowledge Graph Embedding with Translation, Rotation and  Scaling Compound Operations",
    "abstract": "Translation, rotation, and scaling are three commonly used geometric manipulation operations in image processing. Besides, some of them are successfully used in developing effective knowledge graph embedding (KGE) models such as TransE and RotatE. Inspired by the synergy, we propose a new KGE model by leveraging all three operations in this work. Since translation, rotation, and scaling operations are cascaded to form a compound one, the new model is named CompoundE. By casting CompoundE in the framework of group theory, we show that quite a few scoring-function-based KGE models are special cases of CompoundE. CompoundE extends the simple distance-based relation to relation-dependent compound operations on head and/or tail entities. To demonstrate the effectiveness of CompoundE, we conduct experiments on three popular KG completion datasets. Experimental results show that CompoundE consistently achieves the state of-the-art performance. ",
    "url": "https://arxiv.org/abs/2207.05324",
    "authors": [
      "Xiou Ge",
      "Yun-Cheng Wang",
      "Bin Wang",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05327",
    "title": "Certified Adversarial Robustness via Anisotropic Randomized Smoothing",
    "abstract": "Randomized smoothing has achieved great success for certified robustness against adversarial perturbations. Given any arbitrary classifier, randomized smoothing can guarantee the classifier's prediction over the perturbed input with provable robustness bound by injecting noise into the classifier. However, all of the existing methods rely on fixed i.i.d. probability distribution to generate noise for all dimensions of the data (e.g., all the pixels in an image), which ignores the heterogeneity of inputs and data dimensions. Thus, existing randomized smoothing methods cannot provide optimal protection for all the inputs. To address this limitation, we propose the first anisotropic randomized smoothing method which ensures provable robustness guarantee based on pixel-wise noise distributions. Also, we design a novel CNN-based noise generator to efficiently fine-tune the pixel-wise noise distributions for all the pixels in each input. Experimental results demonstrate that our method significantly outperforms the state-of-the-art randomized smoothing methods. ",
    "url": "https://arxiv.org/abs/2207.05327",
    "authors": [
      "Hanbin Hong",
      "Yuan Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05329",
    "title": "Deep Learning with Coherent VCSEL Neural Networks",
    "abstract": "Deep neural networks (DNNs) are reshaping the field of information processing. With their exponential growth challenging existing electronic hardware, optical neural networks (ONNs) are emerging to process DNN tasks in the optical domain with high clock rates, parallelism and low-loss data transmission. However, to explore the potential of ONNs, it is necessary to investigate the full-system performance incorporating the major DNN elements, including matrix algebra and nonlinear activation. Existing challenges to ONNs are high energy consumption due to low electro-optic (EO) conversion efficiency, low compute density due to large device footprint and channel crosstalk, and long latency due to the lack of inline nonlinearity. Here we experimentally demonstrate an ONN system that simultaneously overcomes all these challenges. We exploit neuron encoding with volume-manufactured micron-scale vertical-cavity surface-emitting laser (VCSEL) transmitter arrays that exhibit high EO conversion (<5 attojoule/symbol with $V_\\pi$=4 mV), high operation bandwidth (up to 25 GS/s), and compact footprint (<0.01 mm$^2$ per device). Photoelectric multiplication allows low-energy matrix operations at the shot-noise quantum limit. Homodyne detection-based nonlinearity enables nonlinear activation with instantaneous response. The full-system energy efficiency and compute density reach 7 femtojoules per operation (fJ/OP) and 25 TeraOP/(mm$^2\\cdot$ s), both representing a >100-fold improvement over state-of-the-art digital computers, with substantially several more orders of magnitude for future improvement. Beyond neural network inference, its feature of rapid weight updating is crucial for training deep learning models. Our technique opens an avenue to large-scale optoelectronic processors to accelerate machine learning tasks from data centers to decentralized edge devices. ",
    "url": "https://arxiv.org/abs/2207.05329",
    "authors": [
      "Zaijun Chen",
      "Alexander Sludds",
      "Ronald Davis",
      "Ian Christen",
      "Liane Bernstein",
      "Tobias Heuser",
      "Niels Heermeier",
      "James A. Lott",
      "Stephan Reitzenstein",
      "Ryan Hamerly",
      "Dirk Englund"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2207.05331",
    "title": "Robotic Detection of a Human-Comprehensible Gestural Language for  Underwater Multi-Human-Robot Collaboration",
    "abstract": "In this paper, we present a motion-based robotic communication framework that enables non-verbal communication among autonomous underwater vehicles (AUVs) and human divers. We design a gestural language for AUV-to-AUV communication which can be easily understood by divers observing the conversation unlike typical radio frequency, light, or audio based AUV communication. To allow AUVs to visually understand a gesture from another AUV, we propose a deep network (RRCommNet) which exploits a self-attention mechanism to learn to recognize each message by extracting maximally discriminative spatio-temporal features. We train this network on diverse simulated and real-world data. Our experimental evaluations, both in simulation and in closed-water robot trials, demonstrate that the proposed RRCommNet architecture is able to decipher gesture-based messages with an average accuracy of 88-94% on simulated data, 73-83% on real data (depending on the version of the model used). Further, by performing a message transcription study with human participants, we also show that the proposed language can be understood by humans, with an overall transcription accuracy of 88%. Finally, we discuss the inference runtime of RRCommNet on embedded GPU hardware, for real-time use on board AUVs in the field. ",
    "url": "https://arxiv.org/abs/2207.05331",
    "authors": [
      "Sadman Sakib Enan",
      "Michael Fulton",
      "Junaed Sattar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05334",
    "title": "Cycle Self-Training for Semi-Supervised Object Detection with  Distribution Consistency Reweighting",
    "abstract": "Recently, many semi-supervised object detection (SSOD) methods adopt teacher-student framework and have achieved state-of-the-art results. However, the teacher network is tightly coupled with the student network since the teacher is an exponential moving average (EMA) of the student, which causes a performance bottleneck. To address the coupling problem, we propose a Cycle Self-Training (CST) framework for SSOD, which consists of two teachers T1 and T2, two students S1 and S2. Based on these networks, a cycle self-training mechanism is built, i.e., S1${\\rightarrow}$T1${\\rightarrow}$S2${\\rightarrow}$T2${\\rightarrow}$S1. For S${\\rightarrow}$T, we also utilize the EMA weights of the students to update the teachers. For T${\\rightarrow}$S, instead of providing supervision for its own student S1(S2) directly, the teacher T1(T2) generates pseudo-labels for the student S2(S1), which looses the coupling effect. Moreover, owing to the property of EMA, the teacher is most likely to accumulate the biases from the student and make the mistakes irreversible. To mitigate the problem, we also propose a distribution consistency reweighting strategy, where pseudo-labels are reweighted based on distribution consistency across the teachers T1 and T2. With the strategy, the two students S2 and S1 can be trained robustly with noisy pseudo labels to avoid confirmation biases. Extensive experiments prove the superiority of CST by consistently improving the AP over the baseline and outperforming state-of-the-art methods by 2.1% absolute AP improvements with scarce labeled data. ",
    "url": "https://arxiv.org/abs/2207.05334",
    "authors": [
      "Hao Liu",
      "Bin Chen",
      "Bo Wang",
      "Chunpeng Wu",
      "Feng Dai",
      "Peng Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05340",
    "title": "Dual Contrastive Learning for Spatio-temporal Representation",
    "abstract": "Contrastive learning has shown promising potential in self-supervised spatio-temporal representation learning. Most works naively sample different clips to construct positive and negative pairs. However, we observe that this formulation inclines the model towards the background scene bias. The underlying reasons are twofold. First, the scene difference is usually more noticeable and easier to discriminate than the motion difference. Second, the clips sampled from the same video often share similar backgrounds but have distinct motions. Simply regarding them as positive pairs will draw the model to the static background rather than the motion pattern. To tackle this challenge, this paper presents a novel dual contrastive formulation. Concretely, we decouple the input RGB video sequence into two complementary modes, static scene and dynamic motion. Then, the original RGB features are pulled closer to the static features and the aligned dynamic features, respectively. In this way, the static scene and the dynamic motion are simultaneously encoded into the compact RGB representation. We further conduct the feature space decoupling via activation maps to distill static- and dynamic-related features. We term our method as \\textbf{D}ual \\textbf{C}ontrastive \\textbf{L}earning for spatio-temporal \\textbf{R}epresentation (DCLR). Extensive experiments demonstrate that DCLR learns effective spatio-temporal representations and obtains state-of-the-art or comparable performance on UCF-101, HMDB-51, and Diving-48 datasets. ",
    "url": "https://arxiv.org/abs/2207.05340",
    "authors": [
      "Shuangrui Ding",
      "Rui Qian",
      "Hongkai Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05342",
    "title": "Video Graph Transformer for Video Question Answering",
    "abstract": "This paper proposes a Video Graph Transformer (VGT) model for Video Quetion Answering (VideoQA). VGT's uniqueness are two-fold: 1) it designs a dynamic graph transformer module which encodes video by explicitly capturing the visual objects, their relations, and dynamics for complex spatio-temporal reasoning; and 2) it exploits disentangled video and text Transformers for relevance comparison between the video and text to perform QA, instead of entangled cross-modal Transformer for answer classification. Vision-text communication is done by additional cross-modal interaction modules. With more reasonable video encoding and QA solution, we show that VGT can achieve much better performances on VideoQA tasks that challenge dynamic relation reasoning than prior arts in the pretraining-free scenario. Its performances even surpass those models that are pretrained with millions of external data. We further show that VGT can also benefit a lot from self-supervised cross-modal pretraining, yet with orders of magnitude smaller data. These results clearly demonstrate the effectiveness and superiority of VGT, and reveal its potential for more data-efficient pretraining. With comprehensive analyses and some heuristic observations, we hope that VGT can promote VQA research beyond coarse recognition/description towards fine-grained relation reasoning in realistic videos. Our code is available at https://github.com/sail-sg/VGT. ",
    "url": "https://arxiv.org/abs/2207.05342",
    "authors": [
      "Junbin Xiao",
      "Pan Zhou",
      "Tat-Seng Chua",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05345",
    "title": "HEAD: HEtero-Assists Distillation for Heterogeneous Object Detectors",
    "abstract": "Conventional knowledge distillation (KD) methods for object detection mainly concentrate on homogeneous teacher-student detectors. However, the design of a lightweight detector for deployment is often significantly different from a high-capacity detector. Thus, we investigate KD among heterogeneous teacher-student pairs for a wide application. We observe that the core difficulty for heterogeneous KD (hetero-KD) is the significant semantic gap between the backbone features of heterogeneous detectors due to the different optimization manners. Conventional homogeneous KD (homo-KD) methods suffer from such a gap and are hard to directly obtain satisfactory performance for hetero-KD. In this paper, we propose the HEtero-Assists Distillation (HEAD) framework, leveraging heterogeneous detection heads as assistants to guide the optimization of the student detector to reduce this gap. In HEAD, the assistant is an additional detection head with the architecture homogeneous to the teacher head attached to the student backbone. Thus, a hetero-KD is transformed into a homo-KD, allowing efficient knowledge transfer from the teacher to the student. Moreover, we extend HEAD into a Teacher-Free HEAD (TF-HEAD) framework when a well-trained teacher detector is unavailable. Our method has achieved significant improvement compared to current detection KD methods. For example, on the MS-COCO dataset, TF-HEAD helps R18 RetinaNet achieve 33.9 mAP (+2.2), while HEAD further pushes the limit to 36.2 mAP (+4.5). ",
    "url": "https://arxiv.org/abs/2207.05345",
    "authors": [
      "Luting Wang",
      "Xiaojie Li",
      "Yue Liao",
      "Zeren Jiang",
      "Jianlong Wu",
      "Fei Wang",
      "Chen Qian",
      "Si Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05372",
    "title": "Diversity-aware social robots meet people: beyond context-aware embodied  AI",
    "abstract": "The article introduces the concept of \"diversity-aware\" robotics and discusses the need to develop computational models to embed robots with diversity-awareness: that is, robots capable of adapting and re-configuring their behavior to recognize, respect, and value the uniqueness of the person they interact with to promote inclusion regardless of their age, race, gender, cognitive or physical capabilities, etc. Finally, the article discusses possible technical solutions based on Ontologies and Bayesian Networks, starting from previous experience with culturally competent robots. ",
    "url": "https://arxiv.org/abs/2207.05372",
    "authors": [
      "Carmine Recchiuto",
      "Antonio Sgorbissa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.05375",
    "title": "Occluded Human Body Capture with Self-Supervised Spatial-Temporal Motion  Prior",
    "abstract": "Although significant progress has been achieved on monocular maker-less human motion capture in recent years, it is still hard for state-of-the-art methods to obtain satisfactory results in occlusion scenarios. There are two main reasons: the one is that the occluded motion capture is inherently ambiguous as various 3D poses can map to the same 2D observations, which always results in an unreliable estimation. The other is that no sufficient occluded human data can be used for training a robust model. To address the obstacles, our key-idea is to employ non-occluded human data to learn a joint-level spatial-temporal motion prior for occluded human with a self-supervised strategy. To further reduce the gap between synthetic and real occlusion data, we build the first 3D occluded motion dataset~(OcMotion), which can be used for both training and testing. We encode the motions in 2D maps and synthesize occlusions on non-occluded data for the self-supervised training. A spatial-temporal layer is then designed to learn joint-level correlations. The learned prior reduces the ambiguities of occlusions and is robust to diverse occlusion types, which is then adopted to assist the occluded human motion capture. Experimental results show that our method can generate accurate and coherent human motions from occluded videos with good generalization ability and runtime efficiency. The dataset and code are publicly available at \\url{https://github.com/boycehbz/CHOMP}. ",
    "url": "https://arxiv.org/abs/2207.05375",
    "authors": [
      "Buzhen Huang",
      "Yuan Shu",
      "Jingyi Ju",
      "Yangang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05378",
    "title": "Collaborative Neural Rendering using Anime Character Sheets",
    "abstract": "Drawing images of characters at desired poses is an essential but laborious task in anime production. In this paper, we present the Collaborative Neural Rendering~(CoNR) method to create new images from a few arbitrarily posed reference images available in character sheets. In general, the high diversity of body shapes of anime characters defies the employment of universal body models for real-world humans, like SMPL. To overcome this difficulty, CoNR uses a compact and easy-to-obtain landmark encoding to avoid creating a unified UV mapping in the pipeline. In addition, CoNR's performance can be significantly increased when having multiple reference images by using feature space cross-view dense correspondence and warping in a specially designed neural network construct. Moreover, we collect a character sheet dataset containing over 700,000 hand-drawn and synthesized images of diverse poses to facilitate research in this area. ",
    "url": "https://arxiv.org/abs/2207.05378",
    "authors": [
      "Zuzeng Lin",
      "Ailin Huang",
      "Zhewei Huang",
      "Chen Hu",
      "Shuchang Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05382",
    "title": "Frequency Domain Model Augmentation for Adversarial Attack",
    "abstract": "For black-box attacks, the gap between the substitute model and the victim model is usually large, which manifests as a weak attack performance. Motivated by the observation that the transferability of adversarial examples can be improved by attacking diverse models simultaneously, model augmentation methods which simulate different models by using transformed images are proposed. However, existing transformations for spatial domain do not translate to significantly diverse augmented models. To tackle this issue, we propose a novel spectrum simulation attack to craft more transferable adversarial examples against both normally trained and defense models. Specifically, we apply a spectrum transformation to the input and thus perform the model augmentation in the frequency domain. We theoretically prove that the transformation derived from frequency domain leads to a diverse spectrum saliency map, an indicator we proposed to reflect the diversity of substitute models. Notably, our method can be generally combined with existing attacks. Extensive experiments on the ImageNet dataset demonstrate the effectiveness of our method, \\textit{e.g.}, attacking nine state-of-the-art defense models with an average success rate of \\textbf{95.4\\%}. Our code is available in \\url{https://github.com/yuyang-long/SSA}. ",
    "url": "https://arxiv.org/abs/2207.05382",
    "authors": [
      "Yuyang Long",
      "Qilong Zhang",
      "Boheng Zeng",
      "Lianli Gao",
      "Xianglong Liu",
      "Jian Zhang",
      "Jingkuan Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05383",
    "title": "Opportunistic Wiretapping/Jamming: A New Attack Model in Millimeter-Wave  Wireless Networks",
    "abstract": "While the millimeter-wave (mmWave) communication is robust against the conventional wiretapping attack due to its short transmission range and directivity, this paper proposes a new opportunistic wiretapping and jamming (OWJ) attack model in mmWave wireless networks. With OWJ, an eavesdropper can opportunistically conduct wiretapping or jamming to initiate a more hazardous attack based on the instantaneous costs of wiretapping and jamming. We also provide three realizations of the OWJ attack, which are mainly determined by the cost models relevant to distance, path loss and received power, respectively. To understand the impact of the new attack on mmWave network security, we first develop novel approximation techniques to characterize the irregular distributions of wiretappers, jammers and interferers under three OWJ realizations. With the help of the results of node distributions, we then derive analytical expressions for the secrecy transmission capacity to depict the network security performance under OWJ. Finally, we provide extensive numerical results to illustrate the effect of OWJ and to demonstrate that the new attack can more significantly degrade the network security performance than the pure wiretapping or jamming attack. ",
    "url": "https://arxiv.org/abs/2207.05383",
    "authors": [
      "Yuanyu Zhang",
      "Zhumeng Zheng",
      "Ji He",
      "Shuangrui Zhao",
      "Qianyue Qu",
      "Yulong Shen",
      "Xiaohong Jiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.05403",
    "title": "Design of Dynamics Invariant LSTM for Touch Based Human-UAV Interaction  Detection",
    "abstract": "The field of Unmanned Aerial Vehicles (UAVs) has reached a high level of maturity in the last few years. Hence, bringing such platforms from closed labs, to day-to-day interactions with humans is important for commercialization of UAVs. One particular human-UAV scenario of interest for this paper is the payload handover scheme, where a UAV hands over a payload to a human upon their request. In this scope, this paper presents a novel real-time human-UAV interaction detection approach, where Long short-term memory (LSTM) based neural network is developed to detect state profiles resulting from human interaction dynamics. A novel data pre-processing technique is presented; this technique leverages estimated process parameters of training and testing UAVs to build dynamics invariant testing data. The proposed detection algorithm is lightweight and thus can be deployed in real-time using off the shelf UAV platforms; in addition, it depends solely on inertial and position measurements present on any classical UAV platform. The proposed approach is demonstrated on a payload handover task between multirotor UAVs and humans. Training and testing data were collected using real-time experiments. The detection approach has achieved an accuracy of 96\\%, giving no false positives even in the presence of external wind disturbances, and when deployed and tested on two different UAVs. ",
    "url": "https://arxiv.org/abs/2207.05403",
    "authors": [
      "Anees Peringal",
      "Mohamad Chehadeh",
      "Rana Azzam",
      "Mahmoud Hamandi",
      "Igor Boiko",
      "Yahya Zweiri"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.05432",
    "title": "Synergistic Self-supervised and Quantization Learning",
    "abstract": "With the success of self-supervised learning (SSL), it has become a mainstream paradigm to fine-tune from self-supervised pretrained models to boost the performance on downstream tasks. However, we find that current SSL models suffer severe accuracy drops when performing low-bit quantization, prohibiting their deployment in resource-constrained applications. In this paper, we propose a method called synergistic self-supervised and quantization learning (SSQL) to pretrain quantization-friendly self-supervised models facilitating downstream deployment. SSQL contrasts the features of the quantized and full precision models in a self-supervised fashion, where the bit-width for the quantized model is randomly selected in each step. SSQL not only significantly improves the accuracy when quantized to lower bit-widths, but also boosts the accuracy of full precision models in most cases. By only training once, SSQL can then benefit various downstream tasks at different bit-widths simultaneously. Moreover, the bit-width flexibility is achieved without additional storage overhead, requiring only one copy of weights during training and inference. We theoretically analyze the optimization process of SSQL, and conduct exhaustive experiments on various benchmarks to further demonstrate the effectiveness of our method. Our code is available at https://github.com/megvii-research/SSQL-ECCV2022. ",
    "url": "https://arxiv.org/abs/2207.05432",
    "authors": [
      "Yun-Hao Cao",
      "Peiqin Sun",
      "Yechang Huang",
      "Jianxin Wu",
      "Shuchang Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05436",
    "title": "Markov Decision Process For Automatic Cyber Defense",
    "abstract": "It is challenging for a security analyst to detect or defend against cyber-attacks. Moreover, traditional defense deployment methods require the security analyst to manually enforce the defenses in the presence of uncertainties about the defense to deploy. As a result, it is essential to develop an automated and resilient defense deployment mechanism to thwart the new generation of attacks. In this paper, we propose a framework based on Markov Decision Process (MDP) and Q-learning to automatically generate optimal defense solutions for networked system states. The framework consists of four phases namely; the model initialization phase, model generation phase, Q-learning phase, and the conclusion phase. The proposed model collects real network information as inputs and then builds them into structural data. We implement a Q-learning process in the model to learn the quality of a defense action in a particular state. To investigate the feasibility of the proposed model, we perform simulation experiments and the result reveals that the model can reduce the risk of network systems from cyber attacks. Furthermore, the experiment shows that the model has shown a certain level of flexibility when different parameters are used for Q-learning. ",
    "url": "https://arxiv.org/abs/2207.05436",
    "authors": [
      "Simon Yusuf Enoch",
      "Simon Yusuf Enoch",
      "Dong Seong Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.05437",
    "title": "Simultaneously Learning Stochastic and Adversarial Bandits under the  Position-Based Model",
    "abstract": "Online learning to rank (OLTR) interactively learns to choose lists of items from a large collection based on certain click models that describe users' click behaviors. Most recent works for this problem focus on the stochastic environment where the item attractiveness is assumed to be invariant during the learning process. In many real-world scenarios, however, the environment could be dynamic or even arbitrarily changing. This work studies the OLTR problem in both stochastic and adversarial environments under the position-based model (PBM). We propose a method based on the follow-the-regularized-leader (FTRL) framework with Tsallis entropy and develop a new self-bounding constraint especially designed for PBM. We prove the proposed algorithm simultaneously achieves $O(\\log{T})$ regret in the stochastic environment and $O(m\\sqrt{nT})$ regret in the adversarial environment, where $T$ is the number of rounds, $n$ is the number of items and $m$ is the number of positions. We also provide a lower bound of order $\\Omega(m\\sqrt{nT})$ for adversarial PBM, which matches our upper bound and improves over the state-of-the-art lower bound. The experiments show that our algorithm could simultaneously learn in both stochastic and adversarial environments and is competitive compared to existing methods that are designed for a single environment. ",
    "url": "https://arxiv.org/abs/2207.05437",
    "authors": [
      "Cheng Chen",
      "Canzhe Zhao",
      "Shuai Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05444",
    "title": "Category-Level 6D Object Pose and Size Estimation using Self-Supervised  Deep Prior Deformation Networks",
    "abstract": "It is difficult to precisely annotate object instances and their semantics in 3D space, and as such, synthetic data are extensively used for these tasks, e.g., category-level 6D object pose and size estimation. However, the easy annotations in synthetic domains bring the downside effect of synthetic-to-real (Sim2Real) domain gap. In this work, we aim to address this issue in the task setting of Sim2Real, unsupervised domain adaptation for category-level 6D object pose and size estimation. We propose a method that is built upon a novel Deep Prior Deformation Network, shortened as DPDN. DPDN learns to deform features of categorical shape priors to match those of object observations, and is thus able to establish deep correspondence in the feature space for direct regression of object poses and sizes. To reduce the Sim2Real domain gap, we formulate a novel self-supervised objective upon DPDN via consistency learning; more specifically, we apply two rigid transformations to each object observation in parallel, and feed them into DPDN respectively to yield dual sets of predictions; on top of the parallel learning, an inter-consistency term is employed to keep cross consistency between dual predictions for improving the sensitivity of DPDN to pose changes, while individual intra-consistency ones are used to enforce self-adaptation within each learning itself. We train DPDN on both training sets of the synthetic CAMERA25 and real-world REAL275 datasets; our results outperform the existing methods on REAL275 test set under both the unsupervised and supervised settings. Ablation studies also verify the efficacy of our designs. Our code is released publicly at https://github.com/JiehongLin/Self-DPDN. ",
    "url": "https://arxiv.org/abs/2207.05444",
    "authors": [
      "Jiehong Lin",
      "Zewei Wei",
      "Changxing Ding",
      "Kui Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05451",
    "title": "Adversarial Robustness Assessment of NeuroEvolution Approaches",
    "abstract": "NeuroEvolution automates the generation of Artificial Neural Networks through the application of techniques from Evolutionary Computation. The main goal of these approaches is to build models that maximize predictive performance, sometimes with an additional objective of minimizing computational complexity. Although the evolved models achieve competitive results performance-wise, their robustness to adversarial examples, which becomes a concern in security-critical scenarios, has received limited attention. In this paper, we evaluate the adversarial robustness of models found by two prominent NeuroEvolution approaches on the CIFAR-10 image classification task: DENSER and NSGA-Net. Since the models are publicly available, we consider white-box untargeted attacks, where the perturbations are bounded by either the L2 or the Linfinity-norm. Similarly to manually-designed networks, our results show that when the evolved models are attacked with iterative methods, their accuracy usually drops to, or close to, zero under both distance metrics. The DENSER model is an exception to this trend, showing some resistance under the L2 threat model, where its accuracy only drops from 93.70% to 18.10% even with iterative attacks. Additionally, we analyzed the impact of pre-processing applied to the data before the first layer of the network. Our observations suggest that some of these techniques can exacerbate the perturbations added to the original inputs, potentially harming robustness. Thus, this choice should not be neglected when automatically designing networks for applications where adversarial attacks are prone to occur. ",
    "url": "https://arxiv.org/abs/2207.05451",
    "authors": [
      "In\u00eas Valentim",
      "Nuno Louren\u00e7o",
      "Nuno Antunes"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05456",
    "title": "TransFA: Transformer-based Representation for Face Attribute Evaluation",
    "abstract": "Face attribute evaluation plays an important role in video surveillance and face analysis. Although methods based on convolution neural networks have made great progress, they inevitably only deal with one local neighborhood with convolutions at a time. Besides, existing methods mostly regard face attribute evaluation as the individual multi-label classification task, ignoring the inherent relationship between semantic attributes and face identity information. In this paper, we propose a novel \\textbf{trans}former-based representation for \\textbf{f}ace \\textbf{a}ttribute evaluation method (\\textbf{TransFA}), which could effectively enhance the attribute discriminative representation learning in the context of attention mechanism. The multiple branches transformer is employed to explore the inter-correlation between different attributes in similar semantic regions for attribute feature learning. Specially, the hierarchical identity-constraint attribute loss is designed to train the end-to-end architecture, which could further integrate face identity discriminative information to boost performance. Experimental results on multiple face attribute benchmarks demonstrate that the proposed TransFA achieves superior performances compared with state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2207.05456",
    "authors": [
      "Decheng Liu",
      "Weijie He",
      "Chunlei Peng",
      "Nannan Wang",
      "Jie Li",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05462",
    "title": "Adaptive and Robust Cross-Voltage-Level Power Flow Control of Active  Distribution Networks",
    "abstract": "The large-scale integration of Distributed Energy Resources (DERs) into the electric power system offers new opportunities to ensure stability. For example, Active Distribution Networks (ADNs) can be used in (sub-)transmission systems in the emergency state, as far as high robustness and performance of the ADN control are guaranteed. This paper presents an adaptive control system for ADN's cross-voltage-level power flow control. For this purpose, the gain scheduling approach is used. Furthermore, this work introduces a method for control parameter tuning. In order to validate the control parameter tuning, the adaptive control system is analyzed regarding robustness and performance using an exemplary medium voltage grid. In addition, the influence of uncertainties is examined. Finally, the operation of the adaptive control system is demonstrated by performing time-domain simulations. ",
    "url": "https://arxiv.org/abs/2207.05462",
    "authors": [
      "Jannik Zwartscholten",
      "Christian Rehtanz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.05473",
    "title": "A developmental approach for training deep belief networks",
    "abstract": "Deep belief networks (DBNs) are stochastic neural networks that can extract rich internal representations of the environment from the sensory data. DBNs had a catalytic effect in triggering the deep learning revolution, demonstrating for the very first time the feasibility of unsupervised learning in networks with many layers of hidden neurons. Thanks to their biological and cognitive plausibility, these hierarchical architectures have been also successfully exploited to build computational models of human perception and cognition in a variety of domains. However, learning in DBNs is usually carried out in a greedy, layer-wise fashion, which does not allow to simulate the holistic development of cortical circuits. Here we present iDBN, an iterative learning algorithm for DBNs that allows to jointly update the connection weights across all layers of the hierarchy. We test our algorithm on two different sets of visual stimuli, and we show that network development can also be tracked in terms of graph theoretical properties. DBNs trained using our iterative approach achieve a final performance comparable to that of the greedy counterparts, at the same time allowing to accurately analyze the gradual development of internal representations in the generative model. Our work paves the way to the use of iDBN for modeling neurocognitive development. ",
    "url": "https://arxiv.org/abs/2207.05473",
    "authors": [
      "Matteo Zambra",
      "Alberto Testolin",
      "Michele De Filippo De Grazia",
      "Marco Zorzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2207.05493",
    "title": "Skeletal Human Action Recognition using Hybrid Attention based Graph  Convolutional Network",
    "abstract": "In skeleton-based action recognition, Graph Convolutional Networks model human skeletal joints as vertices and connect them through an adjacency matrix, which can be seen as a local attention mask. However, in most existing Graph Convolutional Networks, the local attention mask is defined based on natural connections of human skeleton joints and ignores the dynamic relations for example between head, hands and feet joints. In addition, the attention mechanism has been proven effective in Natural Language Processing and image description, which is rarely investigated in existing methods. In this work, we proposed a new adaptive spatial attention layer that extends local attention map to global based on relative distance and relative angle information. Moreover, we design a new initial graph adjacency matrix that connects head, hands and feet, which shows visible improvement in terms of action recognition accuracy. The proposed model is evaluated on two large-scale and challenging datasets in the field of human activities in daily life: NTU-RGB+D and Kinetics skeleton. The results demonstrate that our model has strong performance on both dataset. ",
    "url": "https://arxiv.org/abs/2207.05493",
    "authors": [
      "Hao Xing",
      "Darius Burschka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05497",
    "title": "Paint and Distill: Boosting 3D Object Detection with Semantic Passing  Network",
    "abstract": "3D object detection task from lidar or camera sensors is essential for autonomous driving. Pioneer attempts at multi-modality fusion complement the sparse lidar point clouds with rich semantic texture information from images at the cost of extra network designs and overhead. In this work, we propose a novel semantic passing framework, named SPNet, to boost the performance of existing lidar-based 3D detection models with the guidance of rich context painting, with no extra computation cost during inference. Our key design is to first exploit the potential instructive semantic knowledge within the ground-truth labels by training a semantic-painted teacher model and then guide the pure-lidar network to learn the semantic-painted representation via knowledge passing modules at different granularities: class-wise passing, pixel-wise passing and instance-wise passing. Experimental results show that the proposed SPNet can seamlessly cooperate with most existing 3D detection frameworks with 1~5% AP gain and even achieve new state-of-the-art 3D detection performance on the KITTI test benchmark. Code is available at: https://github.com/jb892/SPNet. ",
    "url": "https://arxiv.org/abs/2207.05497",
    "authors": [
      "Bo Ju",
      "Zhikang Zou",
      "Xiaoqing Ye",
      "Minyue Jiang",
      "Xiao Tan",
      "Errui Ding",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05500",
    "title": "Modality-Aware Contrastive Instance Learning with Self-Distillation for  Weakly-Supervised Audio-Visual Violence Detection",
    "abstract": "Weakly-supervised audio-visual violence detection aims to distinguish snippets containing multimodal violence events with video-level labels. Many prior works perform audio-visual integration and interaction in an early or intermediate manner, yet overlooking the modality heterogeneousness over the weakly-supervised setting. In this paper, we analyze the modality asynchrony and undifferentiated instances phenomena of the multiple instance learning (MIL) procedure, and further investigate its negative impact on weakly-supervised audio-visual learning. To address these issues, we propose a modality-aware contrastive instance learning with self-distillation (MACIL-SD) strategy. Specifically, we leverage a lightweight two-stream network to generate audio and visual bags, in which unimodal background, violent, and normal instances are clustered into semi-bags in an unsupervised way. Then audio and visual violent semi-bag representations are assembled as positive pairs, and violent semi-bags are combined with background and normal instances in the opposite modality as contrastive negative pairs. Furthermore, a self-distillation module is applied to transfer unimodal visual knowledge to the audio-visual model, which alleviates noises and closes the semantic gap between unimodal and multimodal features. Experiments show that our framework outperforms previous methods with lower complexity on the large-scale XD-Violence dataset. Results also demonstrate that our proposed approach can be used as plug-in modules to enhance other networks. Codes are available at https://github.com/JustinYuu/MACIL_SD. ",
    "url": "https://arxiv.org/abs/2207.05500",
    "authors": [
      "Jiashuo Yu",
      "Jinyu Liu",
      "Ying Cheng",
      "Rui Feng",
      "Yuejie Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.05514",
    "title": "A semi-supervised geometric-driven methodology for supervised fishing  activity detection on multi-source AIS tracking messages",
    "abstract": "Automatic Identification System (AIS) messages are useful for tracking vessel activity across oceans worldwide using radio links and satellite transceivers. Such data plays a significant role in tracking vessel activity and mapping mobility patterns such as those found in fishing. Accordingly, this paper proposes a geometric-driven semi-supervised approach for fishing activity detection from AIS data. Through the proposed methodology we show how to explore the information included in the messages to extract features describing the geometry of the vessel route. To this end, we leverage the unsupervised nature of cluster analysis to label the trajectory geometry highlighting the changes in the vessel's moving pattern which tends to indicate fishing activity. The labels obtained by the proposed unsupervised approach are used to detect fishing activities, which we approach as a time-series classification task. In this context, we propose a solution using recurrent neural networks on AIS data streams with roughly 87% of the overall $F$-score on the whole trajectories of 50 different unseen fishing vessels. Such results are accompanied by a broad benchmark study assessing the performance of different Recurrent Neural Network (RNN) architectures. In conclusion, this work contributes by proposing a thorough process that includes data preparation, labeling, data modeling, and model validation. Therefore, we present a novel solution for mobility pattern detection that relies upon unfolding the trajectory in time and observing their inherent geometry. ",
    "url": "https://arxiv.org/abs/2207.05514",
    "authors": [
      "Martha Dais Ferreira",
      "Gabriel Spadon",
      "Amilcar Soares",
      "Stan Matwin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05516",
    "title": "Age-of-Information in Clocked Networks",
    "abstract": "We derive key features of the Age-of-Information distribution in a system whose activities are strictly limited to periodic instances on a global time grid. In particular, one agent periodically generates updates while the other agent periodically uses the most recently received of those updates. Likewise, transmission of those updates over a network can only occur periodically. All periods may differ. We derive results for two different models: a basic one in which the mathematical problems can be handled directly and an extended model which, among others, can also account for stochastic transmission failure, making the results applicable to instances with wireless communication. For both models, a suitable approximation for the expected Age-of-Information and an upper bound for its largest occurring value are developed. For the extended model (which is the more relevant one from a practical standpoint) we also present numerical results for the distribution of the approximation error for numerous parameter choices. ",
    "url": "https://arxiv.org/abs/2207.05516",
    "authors": [
      "R. Schoeffauer",
      "G. Wunder"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.05532",
    "title": "Utilizing Excess Resources in Training Neural Networks",
    "abstract": "In this work, we suggest Kernel Filtering Linear Overparameterization (KFLO), where a linear cascade of filtering layers is used during training to improve network performance in test time. We implement this cascade in a kernel filtering fashion, which prevents the trained architecture from becoming unnecessarily deeper. This also allows using our approach with almost any network architecture and let combining the filtering layers into a single layer in test time. Thus, our approach does not add computational complexity during inference. We demonstrate the advantage of KFLO on various network models and datasets in supervised learning. ",
    "url": "https://arxiv.org/abs/2207.05532",
    "authors": [
      "Amit Henig",
      "Raja Giryes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05536",
    "title": "DTG-SSOD: Dense Teacher Guidance for Semi-Supervised Object Detection",
    "abstract": "The Mean-Teacher (MT) scheme is widely adopted in semi-supervised object detection (SSOD). In MT, the sparse pseudo labels, offered by the final predictions of the teacher (e.g., after Non Maximum Suppression (NMS) post-processing), are adopted for the dense supervision for the student via hand-crafted label assignment. However, the sparse-to-dense paradigm complicates the pipeline of SSOD, and simultaneously neglects the powerful direct, dense teacher supervision. In this paper, we attempt to directly leverage the dense guidance of teacher to supervise student training, i.e., the dense-to-dense paradigm. Specifically, we propose the Inverse NMS Clustering (INC) and Rank Matching (RM) to instantiate the dense supervision, without the widely used, conventional sparse pseudo labels. INC leads the student to group candidate boxes into clusters in NMS as the teacher does, which is implemented by learning grouping information revealed in NMS procedure of the teacher. After obtaining the same grouping scheme as the teacher via INC, the student further imitates the rank distribution of the teacher over clustered candidates through Rank Matching. With the proposed INC and RM, we integrate Dense Teacher Guidance into Semi-Supervised Object Detection (termed DTG-SSOD), successfully abandoning sparse pseudo labels and enabling more informative learning on unlabeled data. On COCO benchmark, our DTG-SSOD achieves state-of-the-art performance under various labelling ratios. For example, under 10% labelling ratio, DTG-SSOD improves the supervised baseline from 26.9 to 35.9 mAP, outperforming the previous best method Soft Teacher by 1.9 points. ",
    "url": "https://arxiv.org/abs/2207.05536",
    "authors": [
      "Gang Li",
      "Xiang Li",
      "Yujie Wang",
      "Yichao Wu",
      "Ding Liang",
      "Shanshan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.05548",
    "title": "Practical Attacks on Machine Learning: A Case Study on Adversarial  Windows Malware",
    "abstract": "While machine learning is vulnerable to adversarial examples, it still lacks systematic procedures and tools for evaluating its security in different application contexts. In this article, we discuss how to develop automated and scalable security evaluations of machine learning using practical attacks, reporting a use case on Windows malware detection. ",
    "url": "https://arxiv.org/abs/2207.05548",
    "authors": [
      "Luca Demetrio",
      "Battista Biggio",
      "Fabio Roli"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05559",
    "title": "A fully algebraic and robust two-level Schwarz method based on optimal  local approximation spaces",
    "abstract": "Two-level domain decomposition preconditioners lead to fast convergence and scalability of iterative solvers. However, for highly heterogeneous problems, where the coefficient function is varying rapidly on several possibly non-separated scales, the condition number of the preconditioned system generally depends on the contrast of the coefficient function leading to a deterioration of convergence. Enhancing the methods by coarse spaces constructed from suitable local eigenvalue problems, also denoted as adaptive or spectral coarse spaces, restores robust, contrast-independent convergence. However, these eigenvalue problems typically rely on non-algebraic information, such that the adaptive coarse spaces cannot be constructed from the fully assembled system matrix. In this paper, a novel algebraic adaptive coarse space, which relies on the a-orthogonal decomposition of (local) finite element (FE) spaces into functions that solve the partial differential equation (PDE) with some trace and FE functions that are zero on the boundary, is proposed. In particular, the basis is constructed from eigenmodes of two types of local eigenvalue problems associated with the edges of the domain decomposition. To approximate functions that solve the PDE locally, we employ a transfer eigenvalue problem, which has originally been proposed for the construction of optimal local approximation spaces for multiscale methods. In addition, we make use of a Dirichlet eigenvalue problem that is a slight modification of the Neumann eigenvalue problem used in the adaptive generalized Dryja-Smith-Widlund (AGDSW) coarse space. Both eigenvalue problems rely solely on local Dirichlet matrices, which can be extracted from the fully assembled system matrix. By combining arguments from multiscale and domain decomposition methods we derive a contrast-independent upper bound for the condition number. ",
    "url": "https://arxiv.org/abs/2207.05559",
    "authors": [
      "Alexander Heinlein",
      "Kathrin Smetana"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2207.05561",
    "title": "Brain-inspired Graph Spiking Neural Networks for Commonsense Knowledge  Representation and Reasoning",
    "abstract": "How neural networks in the human brain represent commonsense knowledge, and complete related reasoning tasks is an important research topic in neuroscience, cognitive science, psychology, and artificial intelligence. Although the traditional artificial neural network using fixed-length vectors to represent symbols has gained good performance in some specific tasks, it is still a black box that lacks interpretability, far from how humans perceive the world. Inspired by the grandmother-cell hypothesis in neuroscience, this work investigates how population encoding and spiking timing-dependent plasticity (STDP) mechanisms can be integrated into the learning of spiking neural networks, and how a population of neurons can represent a symbol via guiding the completion of sequential firing between different neuron populations. The neuron populations of different communities together constitute the entire commonsense knowledge graph, forming a giant graph spiking neural network. Moreover, we introduced the Reward-modulated spiking timing-dependent plasticity (R-STDP) mechanism to simulate the biological reinforcement learning process and completed the related reasoning tasks accordingly, achieving comparable accuracy and faster convergence speed than the graph convolutional artificial neural networks. For the fields of neuroscience and cognitive science, the work in this paper provided the foundation of computational modeling for further exploration of the way the human brain represents commonsense knowledge. For the field of artificial intelligence, this paper indicated the exploration direction for realizing a more robust and interpretable neural network by constructing a commonsense knowledge representation and reasoning spiking neural networks with solid biological plausibility. ",
    "url": "https://arxiv.org/abs/2207.05561",
    "authors": [
      "Hongjian Fang",
      "Yi Zeng",
      "Jianbo Tang",
      "Yuwei Wang",
      "Yao Liang",
      "Xin Liu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2207.05579",
    "title": "Are We Building on the Rock? On the Importance of Data Preprocessing for  Code Summarization",
    "abstract": "Code summarization, the task of generating useful comments given the code, has long been of interest. Most of the existing code summarization models are trained and validated on widely-used code comment benchmark datasets. However, little is known about the quality of the benchmark datasets built from real-world projects. Are the benchmark datasets as good as expected? To bridge the gap, we conduct a systematic research to assess and improve the quality of four benchmark datasets widely used for code summarization tasks. First, we propose an automated code-comment cleaning tool that can accurately detect noisy data caused by inappropriate data preprocessing operations from existing benchmark datasets. Then, we apply the tool to further assess the data quality of the four benchmark datasets, based on the detected noises. Finally, we conduct comparative experiments to investigate the impact of noisy data on the performance of code summarization models. The results show that these data preprocessing noises widely exist in all four benchmark datasets, and removing these noisy data leads to a significant improvement on the performance of code summarization. We believe that the findings and insights will enable a better understanding of data quality in code summarization tasks, and pave the way for relevant research and practice. ",
    "url": "https://arxiv.org/abs/2207.05579",
    "authors": [
      "Lin Shi",
      "Fangwen Mu",
      "Xiao Chen",
      "Song Wang",
      "Junjie Wang",
      "Ye Yang",
      "Ge Li",
      "Xin Xia",
      "Qing Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2207.05580",
    "title": "Online Video Instance Segmentation via Robust Context Fusion",
    "abstract": "Video instance segmentation (VIS) aims at classifying, segmenting and tracking object instances in video sequences. Recent transformer-based neural networks have demonstrated their powerful capability of modeling spatio-temporal correlations for the VIS task. Relying on video- or clip-level input, they suffer from high latency and computational cost. We propose a robust context fusion network to tackle VIS in an online fashion, which predicts instance segmentation frame-by-frame with a few preceding frames. To acquire the precise and temporal-consistent prediction for each frame efficiently, the key idea is to fuse effective and compact context from reference frames into the target frame. Considering the different effects of reference and target frames on the target prediction, we first summarize contextual features through importance-aware compression. A transformer encoder is adopted to fuse the compressed context. Then, we leverage an order-preserving instance embedding to convey the identity-aware information and correspond the identities to predicted instance masks. We demonstrate that our robust fusion network achieves the best performance among existing online VIS methods and is even better than previously published clip-level methods on the Youtube-VIS 2019 and 2021 benchmarks. In addition, visual objects often have acoustic signatures that are naturally synchronized with them in audio-bearing video recordings. By leveraging the flexibility of our context fusion network on multi-modal data, we further investigate the influence of audios on the video-dense prediction task, which has never been discussed in existing works. We build up an Audio-Visual Instance Segmentation dataset, and demonstrate that acoustic signals in the wild scenarios could benefit the VIS task. ",
    "url": "https://arxiv.org/abs/2207.05580",
    "authors": [
      "Xiang Li",
      "Jinglu Wang",
      "Xiaohao Xu",
      "Bhiksha Raj",
      "Yan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05605",
    "title": "Towards Real-time High-Definition Image Snow Removal: Efficient Pyramid  Network with Asymmetrical Encoder-decoder Architecture",
    "abstract": "In winter scenes, the degradation of images taken under snow can be pretty complex, where the spatial distribution of snowy degradation is varied from image to image. Recent methods adopt deep neural networks to directly recover clean scenes from snowy images. However, due to the paradox caused by the variation of complex snowy degradation, achieving reliable High-Definition image desnowing performance in real time is a considerable challenge. We develop a novel Efficient Pyramid Network with asymmetrical encoder-decoder architecture for real-time HD image desnowing. The general idea of our proposed network is to utilize the multi-scale feature flow fully and implicitly mine clean cues from features. Compared with previous state-of-the-art desnowing methods, our approach achieves a better complexity-performance trade-off and effectively handles the processing difficulties of HD and Ultra-HD images. The extensive experiments on three large-scale image desnowing datasets demonstrate that our method surpasses all state-of-the-art approaches by a large margin both quantitatively and qualitatively, boosting the PSNR metric from 31.76 dB to 34.10 dB on the CSD test dataset and from 28.29 dB to 30.87 dB on the SRRS test dataset. ",
    "url": "https://arxiv.org/abs/2207.05605",
    "authors": [
      "Tian Ye",
      "Sixiang Chen",
      "Yun Liu",
      "Yi Ye",
      "Erkang Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05613",
    "title": "Making Python Code Idiomatic by Automatic Refactoring Non-Idiomatic  Python Code with Pythonic Idioms",
    "abstract": "Compared to other programming languages (e.g., Java), Python has more idioms to make Python code concise and efficient. Although pythonic idioms are well accepted in the Python community, Python programmers are often faced with many challenges in using them, for example, being unaware of certain pythonic idioms or do not know how to use them properly. Based on an analysis of 7,638 Python repositories on GitHub, we find that non-idiomatic Python code that can be implemented with pythonic idioms occurs frequently and widely. Unfortunately, there is no tool for automatically refactoring such non-idiomatic code into idiomatic code. In this paper, we design and implement an automatic refactoring tool to make Python code idiomatic. We identify nine pythonic idioms by systematically contrasting the abstract syntax grammar of Python and Java. Then we define the syntactic patterns for detecting non-idiomatic code for each pythonic idiom. Finally, we devise atomic AST-rewriting operations and refactoring steps to refactor non-idiomatic code into idiomatic code. We test and review over 4,115 refactorings applied to 1,065 Python projects from GitHub, and submit 90 pull requests for the 90 randomly sampled refactorings to 84 projects. These evaluations confirm the high-accuracy, practicality and usefulness of our refactoring tool on real-world Python code. Our refactoring tool can be accessed at 47.242.131.128:5000. ",
    "url": "https://arxiv.org/abs/2207.05613",
    "authors": [
      "Zejun Zhang",
      "Zhenchang Xing",
      "Xin Xia",
      "Xiwei Xu",
      "Liming Zhu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2207.05620",
    "title": "LudVision -- Remote Detection of Exotic Invasive Aquatic Floral Species  using Drone-Mounted Multispectral Data",
    "abstract": "Remote sensing is the process of detecting and monitoring the physical characteristics of an area by measuring its reflected and emitted radiation at a distance. It is being broadly used to monitor ecosystems, mainly for their preservation. Ever-growing reports of invasive species have affected the natural balance of ecosystems. Exotic invasive species have a critical impact when introduced into new ecosystems and may lead to the extinction of native species. In this study, we focus on Ludwigia peploides, considered by the European Union as an aquatic invasive species. Its presence can negatively impact the surrounding ecosystem and human activities such as agriculture, fishing, and navigation. Our goal was to develop a method to identify the presence of the species. We used images collected by a drone-mounted multispectral sensor to achieve this, creating our LudVision data set. To identify the targeted species on the collected images, we propose a new method for detecting Ludwigia p. in multispectral images. The method is based on existing state-of-the-art semantic segmentation methods modified to handle multispectral data. The proposed method achieved a producer's accuracy of 0.799 and a user's accuracy of 0.955. ",
    "url": "https://arxiv.org/abs/2207.05620",
    "authors": [
      "Ant\u00f3nio J. Abreu",
      "Lu\u00eds A. Alexandre",
      "Jo\u00e3o A. Santos",
      "Filippo Basso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.05623",
    "title": "Attacking (and defending) the Maritime Radar System",
    "abstract": "Operation of radar equipment is one of the key facilities used by navigators to gather situational awareness about their surroundings. With an ever increasing need for always-running logistics and tighter shipping schedules, operators are relying more and more on computerized instruments and their indications. As a result, modern ships have become a complex cyber-physical system in which sensors and computers constantly communicate and coordinate. In this work, we discuss novel threats related to the radar system, which is one of the most security-sensitive component on a ship. In detail, we first discuss some new attacks capable of compromising the integrity of data displayed on a radar system, with potentially catastrophic impacts on the crew' situational awareness or even safety itself. Then, we present a detection system aimed at highlighting anomalies in the radar video feed, requiring no modifications to the target ship configuration. Finally, we stimulate our detection system by performing the attacks inside of a simulated environment. The experimental results clearly indicate that the attacks are feasible, rather easy to carry out, and hard-to-detect. Moreover, they prove that the proposed detection technique is effective. ",
    "url": "https://arxiv.org/abs/2207.05623",
    "authors": [
      "G. Longo",
      "E. Russo",
      "A. Armando",
      "A. Merlo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.05641",
    "title": "Backdoor Attacks on Crowd Counting",
    "abstract": "Crowd counting is a regression task that estimates the number of people in a scene image, which plays a vital role in a range of safety-critical applications, such as video surveillance, traffic monitoring and flow control. In this paper, we investigate the vulnerability of deep learning based crowd counting models to backdoor attacks, a major security threat to deep learning. A backdoor attack implants a backdoor trigger into a target model via data poisoning so as to control the model's predictions at test time. Different from image classification models on which most of existing backdoor attacks have been developed and tested, crowd counting models are regression models that output multi-dimensional density maps, thus requiring different techniques to manipulate. In this paper, we propose two novel Density Manipulation Backdoor Attacks (DMBA$^{-}$ and DMBA$^{+}$) to attack the model to produce arbitrarily large or small density estimations. Experimental results demonstrate the effectiveness of our DMBA attacks on five classic crowd counting models and four types of datasets. We also provide an in-depth analysis of the unique challenges of backdooring crowd counting models and reveal two key elements of effective attacks: 1) full and dense triggers and 2) manipulation of the ground truth counts or density maps. Our work could help evaluate the vulnerability of crowd counting models to potential backdoor attacks. ",
    "url": "https://arxiv.org/abs/2207.05641",
    "authors": [
      "Yuhua Sun",
      "Tailai Zhang",
      "Xingjun Ma",
      "Pan Zhou",
      "Jian Lou",
      "Zichuan Xu",
      "Xing Di",
      "Yu Cheng",
      "Lichao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.05659",
    "title": "Approximate Distance Oracles for Planar Graphs with Subpolynomial Error  Dependency",
    "abstract": "Thorup [FOCS'01, JACM'04] and Klein [SODA'01] independently showed that there exists a $(1+\\epsilon)$-approximate distance oracle for planar graphs with $O(n (\\log n)\\epsilon^{-1})$ space and $O(\\epsilon^{-1})$ query time. While the dependency on $n$ is nearly linear, the space-query product of their oracles depend quadratically on $1/\\epsilon$. Many follow-up results either improved the space \\emph{or} the query time of the oracles while having the same, sometimes worst, dependency on $1/\\epsilon$. Kawarabayashi, Sommer, and Thorup [SODA'13] were the first to improve the dependency on $1/\\epsilon$ from quadratic to nearly linear (at the cost of $\\log^*(n)$ factors). It is plausible to conjecture that the linear dependency on $1/\\epsilon$ is optimal: for many known distance-related problems in planar graphs, it was proved that the dependency on $1/\\epsilon$ is at least linear. In this work, we disprove this conjecture by reducing the dependency of the space-query product on $1/\\epsilon$ from linear all the way down to \\emph{subpolynomial} $(1/\\epsilon)^{o(1)}$. More precisely, we construct an oracle with $O(n\\log(n)(\\epsilon^{-o(1)} + \\log^*n))$ space and $\\log^{2+o(1)}(1/\\epsilon)$ query time. Our construction is the culmination of several different ideas developed over the past two decades. ",
    "url": "https://arxiv.org/abs/2207.05659",
    "authors": [
      "Hung Le"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2207.05669",
    "title": "From Spectral Graph Convolutions to Large Scale Graph Convolutional  Networks",
    "abstract": "Graph Convolutional Networks (GCNs) have been shown to be a powerful concept that has been successfully applied to a large variety of tasks across many domains over the past years. In this work we study the theory that paved the way to the definition of GCN, including related parts of classical graph theory. We also discuss and experimentally demonstrate key properties and limitations of GCNs such as those caused by the statistical dependency of samples, introduced by the edges of the graph, which causes the estimates of the full gradient to be biased. Another limitation we discuss is the negative impact of minibatch sampling on the model performance. As a consequence, during parameter update, gradients are computed on the whole dataset, undermining scalability to large graphs. To account for this, we research alternative methods which allow to safely learn good parameters while sampling only a subset of data per iteration. We reproduce the results reported in the work of Kipf et al. and propose an implementation inspired to SIGN, which is a sampling-free minibatch method. Eventually we compare the two implementations on a benchmark dataset, proving that they are comparable in terms of prediction accuracy for the task of semi-supervised node classification. ",
    "url": "https://arxiv.org/abs/2207.05669",
    "authors": [
      "Matteo Bunino"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05672",
    "title": "DDI Prediction via Heterogeneous Graph Attention Networks",
    "abstract": "Polypharmacy, defined as the use of multiple drugs together, is a standard treatment method, especially for severe and chronic diseases. However, using multiple drugs together may cause interactions between drugs. Drug-drug interaction (DDI) is the activity that occurs when the impact of one drug changes when combined with another. DDIs may obstruct, increase, or decrease the intended effect of either drug or, in the worst-case scenario, create adverse side effects. While it is critical to detect DDIs on time, it is timeconsuming and expensive to identify them in clinical trials due to their short duration and many possible drug pairs to be considered for testing. As a result, computational methods are needed for predicting DDIs. In this paper, we present a novel heterogeneous graph attention model, HAN-DDI to predict drug-drug interactions. We create a heterogeneous network of drugs with different biological entities. Then, we develop a heterogeneous graph attention network to learn DDIs using relations of drugs with other entities. It consists of an attention-based heterogeneous graph node encoder for obtaining drug node representations and a decoder for predicting drug-drug interactions. Further, we utilize comprehensive experiments to evaluate of our model and to compare it with state-of-the-art models. Experimental results show that our proposed method, HAN-DDI, outperforms the baselines significantly and accurately predicts DDIs, even for new drugs. ",
    "url": "https://arxiv.org/abs/2207.05672",
    "authors": [
      "Farhan Tanvir",
      "Khaled Mohammed Saifuddin",
      "Esra Akbas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2207.05723",
    "title": "Latent Variable Models for Bayesian Causal Discovery",
    "abstract": "Learning predictors that do not rely on spurious correlations involves building causal representations. However, learning such a representation is very challenging. We, therefore, formulate the problem of learning a causal representation from high dimensional data and study causal recovery with synthetic data. This work introduces a latent variable decoder model, Decoder BCD, for Bayesian causal discovery and performs experiments in mildly supervised and unsupervised settings. We present a series of synthetic experiments to characterize important factors for causal discovery and show that using known intervention targets as labels helps in unsupervised Bayesian inference over structure and parameters of linear Gaussian additive noise latent structural causal models. ",
    "url": "https://arxiv.org/abs/2207.05723",
    "authors": [
      "Jithendaraa Subramanian",
      "Yashas Annadani",
      "Ivaxi Sheth",
      "Stefan Bauer",
      "Derek Nowrouzezahrai",
      "Samira Ebrahimi Kahou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.05729",
    "title": "Physical Passive Patch Adversarial Attacks on Visual Odometry Systems",
    "abstract": "Deep neural networks are known to be susceptible to adversarial perturbations -- small perturbations that alter the output of the network and exist under strict norm limitations. While such perturbations are usually discussed as tailored to a specific input, a universal perturbation can be constructed to alter the model's output on a set of inputs. Universal perturbations present a more realistic case of adversarial attacks, as awareness of the model's exact input is not required. In addition, the universal attack setting raises the subject of generalization to unseen data, where given a set of inputs, the universal perturbations aim to alter the model's output on out-of-sample data. In this work, we study physical passive patch adversarial attacks on visual odometry-based autonomous navigation systems. A visual odometry system aims to infer the relative camera motion between two corresponding viewpoints, and is frequently used by vision-based autonomous navigation systems to estimate their state. For such navigation systems, a patch adversarial perturbation poses a severe security issue, as it can be used to mislead a system onto some collision course. To the best of our knowledge, we show for the first time that the error margin of a visual odometry model can be significantly increased by deploying patch adversarial attacks in the scene. We provide evaluation on synthetic closed-loop drone navigation data and demonstrate that a comparable vulnerability exists in real data. A reference implementation of the proposed method and the reported experiments is provided at https://github.com/patchadversarialattacks/patchadversarialattacks. ",
    "url": "https://arxiv.org/abs/2207.05729",
    "authors": [
      "Yaniv Nemcovsky",
      "Matan Yaakoby",
      "Alex M. Bronstein",
      "Chaim Baskin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05733",
    "title": "A Skeleton-aware Graph Convolutional Network for Human-Object  Interaction Detection",
    "abstract": "Detecting human-object interactions is essential for comprehensive understanding of visual scenes. In particular, spatial connections between humans and objects are important cues for reasoning interactions. To this end, we propose a skeleton-aware graph convolutional network for human-object interaction detection, named SGCN4HOI. Our network exploits the spatial connections between human keypoints and object keypoints to capture their fine-grained structural interactions via graph convolutions. It fuses such geometric features with visual features and spatial configuration features obtained from human-object pairs. Furthermore, to better preserve the object structural information and facilitate human-object interaction detection, we propose a novel skeleton-based object keypoints representation. The performance of SGCN4HOI is evaluated in the public benchmark V-COCO dataset. Experimental results show that the proposed approach outperforms the state-of-the-art pose-based models and achieves competitive performance against other models. ",
    "url": "https://arxiv.org/abs/2207.05733",
    "authors": [
      "Manli Zhu",
      "Edmond S. L. Ho",
      "Hubert P. H. Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.05231",
    "title": "Regression Metric Loss: Learning a Semantic Representation Space for  Medical Images",
    "abstract": "Regression plays an essential role in many medical imaging applications for estimating various clinical risk or measurement scores. While training strategies and loss functions have been studied for the deep neural networks in medical image classification tasks, options for regression tasks are very limited. One of the key challenges is that the high-dimensional feature representation learned by existing popular loss functions like Mean Squared Error or L1 loss is hard to interpret. In this paper, we propose a novel Regression Metric Loss (RM-Loss), which endows the representation space with the semantic meaning of the label space by finding a representation manifold that is isometric to the label space. Experiments on two regression tasks, i.e. coronary artery calcium score estimation and bone age assessment, show that RM-Loss is superior to the existing popular regression losses on both performance and interpretability. Code is available at https://github.com/DIAL-RPI/Regression-Metric-Loss. ",
    "url": "https://arxiv.org/abs/2207.05231",
    "authors": [
      "Hanqing Chao",
      "Jiajin Zhang",
      "Pingkun Yan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05250",
    "title": "Efficient Real-world Testing of Causal Decision Making via Bayesian  Experimental Design for Contextual Optimisation",
    "abstract": "The real-world testing of decisions made using causal machine learning models is an essential prerequisite for their successful application. We focus on evaluating and improving contextual treatment assignment decisions: these are personalised treatments applied to e.g. customers, each with their own contextual information, with the aim of maximising a reward. In this paper we introduce a model-agnostic framework for gathering data to evaluate and improve contextual decision making through Bayesian Experimental Design. Specifically, our method is used for the data-efficient evaluation of the regret of past treatment assignments. Unlike approaches such as A/B testing, our method avoids assigning treatments that are known to be highly sub-optimal, whilst engaging in some exploration to gather pertinent information. We achieve this by introducing an information-based design objective, which we optimise end-to-end. Our method applies to discrete and continuous treatments. Comparing our information-theoretic approach to baselines in several simulation studies demonstrates the superior performance of our proposed approach. ",
    "url": "https://arxiv.org/abs/2207.05250",
    "authors": [
      "Desi R. Ivanova",
      "Joel Jennings",
      "Cheng Zhang",
      "Adam Foster"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2207.05364",
    "title": "A Bipartite Graph Neural Network Approach for Scalable Beamforming  Optimization",
    "abstract": "Deep learning (DL) techniques have been intensively studied for the optimization of multi-user multiple-input single-output (MU-MISO) downlink systems owing to the capability of handling nonconvex formulations. However, the fixed computation structure of existing deep neural networks (DNNs) lacks flexibility with respect to the system size, i.e., the number of antennas or users. This paper develops a bipartite graph neural network (BGNN) framework, a scalable DL solution designed for multi-antenna beamforming optimization. The MU-MISO system is first characterized by a bipartite graph where two disjoint vertex sets, each of which consists of transmit antennas and users, are connected via pairwise edges. These vertex interconnection states are modeled by channel fading coefficients. Thus, a generic beamforming optimization process is interpreted as a computation task over a weight bipartite graph. This approach partitions the beamforming optimization procedure into multiple suboperations dedicated to individual antenna vertices and user vertices. Separated vertex operations lead to scalable beamforming calculations that are invariant to the system size. The vertex operations are realized by a group of DNN modules that collectively form the BGNN architecture. Identical DNNs are reused at all antennas and users so that the resultant learning structure becomes flexible to the network size. Component DNNs of the BGNN are trained jointly over numerous MU-MISO configurations with randomly varying network sizes. As a result, the trained BGNN can be universally applied to arbitrary MU-MISO systems. Numerical results validate the advantages of the BGNN framework over conventional methods. ",
    "url": "https://arxiv.org/abs/2207.05364",
    "authors": [
      "Junbeom Kim",
      "Hoon Lee",
      "Seung-Eun Hong",
      "Seok-Hwan Park"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05442",
    "title": "Wasserstein multivariate auto-regressive models for modeling  distributional time series and its application in graph learning",
    "abstract": "We propose a new auto-regressive model for the statistical analysis of multivariate distributional time series. The data of interest consist of a collection of multiple series of probability measures supported over a bounded interval of the real line, and that are indexed by distinct time instants. The probability measures are modelled as random objects in the Wasserstein space. We establish the auto-regressive model in the tangent space at the Lebesgue measure by first centering all the raw measures so that their Fr\\'echet means turn to be the Lebesgue measure. Using the theory of iterated random function systems, results on the existence, uniqueness and stationarity of the solution of such a model are provided. We also propose a consistent estimator for the model coefficient. In addition to the analysis of simulated data, the proposed model is illustrated with two real data sets made of observations from age distribution in different countries and bike sharing network in Paris. Finally, due to the positive and boundedness constraints that we impose on the model coefficients, the proposed estimator that is learned under these constraints, naturally has a sparse structure. The sparsity allows furthermore the application of the proposed model in learning a graph of temporal dependency from the multivariate distributional time series. ",
    "url": "https://arxiv.org/abs/2207.05442",
    "authors": [
      "Yiye Jiang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05481",
    "title": "End-to-End Capacities of Imperfect-Repeater Quantum Networks",
    "abstract": "The optimal performance of a communication network is limited not only by the quality of point-to-point channels, but by the efficacy of its constituent technologies. Understanding the limits of quantum networks requires an understanding of both the ultimate capacities of quantum channels and the efficiency of imperfect quantum repeaters. In this work, using a recently developed node-splitting technique which introduces internal losses and noise into repeater devices, we present achievable end-to-end rates for noisy-repeater quantum networks. These are obtained by extending the coherent and reverse coherent information (single channel capacity lower bounds) into end-to-end capacity lower bounds, both in the context of single-path and multi-path routing. These achievable rates are completely general, and apply to networks composed of arbitrary channels arranged in general topologies. Through this general formalism, we show how tight upper-bounds can also be derived by supplementing appropriate single-edge capacity bounds. As a result, we develop tools which provide tight performance bounds for quantum networks constituent of channels whose capacities are not exactly known, and reveal critical network properties which are necessary for high-rate quantum communications. This permits the investigation of pertinent classes of quantum networks with realistic technologies; qubit amplitude damping networks and bosonic thermal-loss networks. ",
    "url": "https://arxiv.org/abs/2207.05481",
    "authors": [
      "Cillian Harney",
      "Stefano Pirandola"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.05482",
    "title": "End-to-End Capacities of Hybrid Quantum Networks",
    "abstract": "Future quantum networks will be hybrid structures, constructed from complex architectures of quantum repeaters interconnected by quantum channels that describe a variety of physical domains; predominantly optical-fiber and free-space links. In this hybrid setting, the interplay between the channel quality within network sub-structures must be carefully considered, and is pivotal for ensuring high-rate end-to-end quantum communication. In this work, we combine recent advances in the theory of point-to-point free-space channel capacities and end-to-end quantum network capacities in order to develop critical tools for the study of hybrid, free-space quantum networks. We present a general formalism for studying the capacities of arbitrary, hybrid quantum networks, before specifying to the regime of atmospheric and space-based quantum channels. We then introduce a class of modular quantum network architectures which offer a realistic and readily analysable framework for hybrid quantum networks. By considering a physically motivated, highly connected modular structure we are able to idealize network performance and derive channel conditions for which optimal performance is guaranteed. This allows us to reveal vital properties for which distance-independent rates are achieved, so that the end-to-end capacity has no dependence on the physical separation between users. Our analytical method elucidates key infrastructure demands for a future satellite-based global quantum internet, and for hybrid wired/wireless metropolitan quantum networks. ",
    "url": "https://arxiv.org/abs/2207.05482",
    "authors": [
      "Cillian Harney",
      "Alasdair I. Fletcher",
      "Stefano Pirandola"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.05506",
    "title": "Label-Efficient Self-Supervised Speaker Verification With Information  Maximization and Contrastive Learning",
    "abstract": "State-of-the-art speaker verification systems are inherently dependent on some kind of human supervision as they are trained on massive amounts of labeled data. However, manually annotating utterances is slow, expensive and not scalable to the amount of data available today. In this study, we explore self-supervised learning for speaker verification by learning representations directly from raw audio. The objective is to produce robust speaker embeddings that have small intra-speaker and large inter-speaker variance. Our approach is based on recent information maximization learning frameworks and an intensive data augmentation pre-processing step. We evaluate the ability of these methods to work without contrastive samples before showing that they achieve better performance when combined with a contrastive loss. Furthermore, we conduct experiments to show that our method reaches competitive results compared to existing techniques and can get better performances compared to a supervised baseline when fine-tuned with a small portion of labeled data. ",
    "url": "https://arxiv.org/abs/2207.05506",
    "authors": [
      "Th\u00e9o Lepage",
      "R\u00e9da Dehak"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2207.05647",
    "title": "How Much Entanglement Does a Quantum Code Need?",
    "abstract": "In the setting of entanglement-assisted quantum error-correcting codes (EAQECCs), the sender and the receiver have access to pre-shared entanglement. Such codes promise better information rates or improved error handling properties. Entanglement incurs costs and must be judiciously calibrated in designing quantum codes with good performance, relative to their deployment parameters. Revisiting known constructions, we devise tools from classical coding theory to better understand how the amount of entanglement can be varied. We present three new propagation rules and discuss how each of them affects the error handling. Tables listing the parameters of the best performing qubit and qutrit EAQECCs that we can explicitly construct are supplied for reference and comparison. ",
    "url": "https://arxiv.org/abs/2207.05647",
    "authors": [
      "Gaojun Luo",
      "Martianus Frederic Ezerman",
      "Markus Grassl",
      "San Ling"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:1907.02919",
    "title": "Hitting Topological Minor Models in Planar Graphs is Fixed Parameter  Tractable",
    "abstract": " Comments: A preliminary version of these results appeared in [Petr A. Golovach, Giannos Stamoulis, Dimitrios M. Thilikos: Hitting Topological Minor Models in Planar Graphs is Fixed Parameter Tractable. SODA 2020: 931-950] ",
    "url": "https://arxiv.org/abs/1907.02919",
    "authors": [
      "Petr A. Golovach",
      "Giannos Stamoulis",
      "Dimitrios M. Thilikos"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:1907.11422",
    "title": "Almost Shortest Paths with Near-Additive Error in Weighted Graphs",
    "abstract": " Title: Almost Shortest Paths with Near-Additive Error in Weighted Graphs ",
    "url": "https://arxiv.org/abs/1907.11422",
    "authors": [
      "Michael Elkin",
      "Yuval Gitlitz",
      "Ofer Neiman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2009.06303",
    "title": "Robustness and Personalization in Federated Learning: A Unified Approach  via Regularization",
    "abstract": " Comments: Accepted by IEEE EDGE 2022 (16 pages, 4 figures, 2 tables) ",
    "url": "https://arxiv.org/abs/2009.06303",
    "authors": [
      "Achintya Kundu",
      "Pengqian Yu",
      "Laura Wynter",
      "Shiau Hong Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2009.07092",
    "title": "Multi-structure bone segmentation in pediatric MR images with combined  regularization from shape priors and adversarial network",
    "abstract": " Comments: 21 pages, 11 figures, 7 tables, Accepted for publication in the Journal of Artificial Intelligence in Medicine ",
    "url": "https://arxiv.org/abs/2009.07092",
    "authors": [
      "Arnaud Boutillon",
      "Bhushan Borotikar",
      "Val\u00e9rie Burdin",
      "Pierre-Henri Conze"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2102.01732",
    "title": "Truly Sparse Neural Networks at Scale",
    "abstract": " Comments: 30 pages, 17 figures ",
    "url": "https://arxiv.org/abs/2102.01732",
    "authors": [
      "Selima Curci",
      "Decebal Constantin Mocanu",
      "Mykola Pechenizkiyi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2102.03049",
    "title": "Benchmarking of eight recurrent neural network variants for breath phase  and adventitious sound detection on a self-developed open-access lung sound  database-HF_Lung_V1",
    "abstract": " Comments: 48 pages, 8 figures. Accepted by PLoS One ",
    "url": "https://arxiv.org/abs/2102.03049",
    "authors": [
      "Fu-Shun Hsu",
      "Shang-Ran Huang",
      "Chien-Wen Huang",
      "Chao-Jung Huang",
      "Yuan-Ren Cheng",
      "Chun-Chieh Chen",
      "Jack Hsiao",
      "Chung-Wei Chen",
      "Li-Chin Chen",
      "Yen-Chun Lai",
      "Bi-Fang Hsu",
      "Nian-Jhen Lin",
      "Wan-Lin Tsai",
      "Yi-Lin Wu",
      "Tzu-Ling Tseng",
      "Ching-Ting Tseng",
      "Yi-Tsun Chen",
      "Feipei Lai"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2102.04625",
    "title": "WheaCha: A Method for Explaining the Predictions of Models of Code",
    "abstract": " Title: WheaCha: A Method for Explaining the Predictions of Models of Code ",
    "url": "https://arxiv.org/abs/2102.04625",
    "authors": [
      "Yu Wang",
      "Ke Wang",
      "Linzhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2103.00387",
    "title": "LQG Reference Tracking with Safety and Reachability Guarantees under  Unknown False Data Injection Attacks",
    "abstract": " Comments: 13 pages, 4 figures, extended version of a Transactions on Automatic Control paper ",
    "url": "https://arxiv.org/abs/2103.00387",
    "authors": [
      "Zhouchi Li",
      "Luyao Niu",
      "Andrew Clark"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2103.10994",
    "title": "Self-Supervised Classification Network",
    "abstract": " Comments: ECCV 2022 camera-ready with supplementary ",
    "url": "https://arxiv.org/abs/2103.10994",
    "authors": [
      "Elad Amrani",
      "Leonid Karlinsky",
      "Alex Bronstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.08228",
    "title": "Weakly-supervised Part-Attention and Mentored Networks for Vehicle  Re-Identification",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2107.08228",
    "authors": [
      "Lisha Tang",
      "Yi Wang",
      "Lap-Pui Chau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.12038",
    "title": "Neural Video Compression using GANs for Detail Synthesis and Propagation",
    "abstract": " Comments: First two authors contributed equally. ECCV Camera ready version ",
    "url": "https://arxiv.org/abs/2107.12038",
    "authors": [
      "Fabian Mentzer",
      "Eirikur Agustsson",
      "Johannes Ball\u00e9",
      "David Minnen",
      "Nick Johnston",
      "George Toderici"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.13802",
    "title": "RigNet: Repetitive Image Guided Network for Depth Completion",
    "abstract": " Comments: Accepted by ECCV2022 ",
    "url": "https://arxiv.org/abs/2107.13802",
    "authors": [
      "Zhiqiang Yan",
      "Kun Wang",
      "Xiang Li",
      "Zhenyu Zhang",
      "Baobei Xu",
      "Jun Li",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.00833",
    "title": "Communication Models for Reconfigurable Intelligent Surfaces: From  Surface Electromagnetics to Wireless Networks Optimization",
    "abstract": " Comments: Submitted for publication ",
    "url": "https://arxiv.org/abs/2110.00833",
    "authors": [
      "Marco Di Renzo",
      "Fadil H. Danufane",
      "Sergei Tretyakov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2111.11858",
    "title": "Asteroid Flyby Cycler Trajectory Design Using Deep Neural Networks",
    "abstract": " Title: Asteroid Flyby Cycler Trajectory Design Using Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2111.11858",
    "authors": [
      "Naoya Ozaki",
      "Kanta Yanagida",
      "Takuya Chikazawa",
      "Nishanth Pushparaj",
      "Naoya Takeishi",
      "Ryuki Hyodo"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2111.12374",
    "title": "MM-Pyramid: Multimodal Pyramid Attentional Network for Audio-Visual  Event Localization and Video Parsing",
    "abstract": " Comments: ACM MM 2022 ",
    "url": "https://arxiv.org/abs/2111.12374",
    "authors": [
      "Jiashuo Yu",
      "Ying Cheng",
      "Rui-Wei Zhao",
      "Rui Feng",
      "Yuejie Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.15097",
    "title": "EAGAN: Efficient Two-stage Evolutionary Architecture Search for GANs",
    "abstract": " Comments: Accepted in ECCV2022, Guohao Yin and Xin He contributed equally ",
    "url": "https://arxiv.org/abs/2111.15097",
    "authors": [
      "Guohao Ying",
      "Xin He",
      "Bin Gao",
      "Bo Han",
      "Xiaowen Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2112.10325",
    "title": "Incremental Cross-view Mutual Distillation for Self-supervised Medical  CT Synthesis",
    "abstract": " Comments: Accepted by CVPR2022 ",
    "url": "https://arxiv.org/abs/2112.10325",
    "authors": [
      "Chaowei Fang",
      "Liang Wang",
      "Dingwen Zhang",
      "Jun Xu",
      "Yixuan Yuan",
      "Junwei Han"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.02555",
    "title": "On robust risk-based active-learning algorithms for enhanced decision  support",
    "abstract": " Comments: Author accepted manuscript, 48 pages, 39 figures, published in Mechanical Systems and Signal Processing ",
    "url": "https://arxiv.org/abs/2201.02555",
    "authors": [
      "Aidan J. Hughes",
      "Lawrence A. Bull",
      "Paul Gardner",
      "Nikolaos Dervilis",
      "Keith Worden"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.05946",
    "title": "Understanding Political Polarization via Jointly Modeling Users,  Connections and Multimodal Contents on Heterogeneous Graphs",
    "abstract": " Comments: Accepted for publication in Proceedings of the 30th ACM International Conference on Multimedia, 2022 ",
    "url": "https://arxiv.org/abs/2201.05946",
    "authors": [
      "Hanjia Lyu",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2201.09396",
    "title": "Dynamic Label Assignment for Object Detection by Combining Predicted  IoUs and Anchor IoUs",
    "abstract": " Title: Dynamic Label Assignment for Object Detection by Combining Predicted  IoUs and Anchor IoUs ",
    "url": "https://arxiv.org/abs/2201.09396",
    "authors": [
      "Tianxiao Zhang",
      "Bo Luo",
      "Ajay Sharda",
      "Guanghui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.10485",
    "title": "Concurrent NetKAT: Modeling and analyzing stateful, concurrent networks",
    "abstract": " Title: Concurrent NetKAT: Modeling and analyzing stateful, concurrent networks ",
    "url": "https://arxiv.org/abs/2201.10485",
    "authors": [
      "Jana Wagemaker",
      "Nate Foster",
      "Tobias Kapp\u00e9",
      "Dexter Kozen",
      "Jurriaan Rot",
      "Alexandra Silva"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2201.11895",
    "title": "\"That's so cute!\": The CARE Dataset for Affective Response Detection",
    "abstract": " Title: \"That's so cute!\": The CARE Dataset for Affective Response Detection ",
    "url": "https://arxiv.org/abs/2201.11895",
    "authors": [
      "Jane Dwivedi-Yu",
      "Alon Y. Halevy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2201.12020",
    "title": "A Robust and Flexible EM Algorithm for Mixtures of Elliptical  Distributions with Missing Data",
    "abstract": " Title: A Robust and Flexible EM Algorithm for Mixtures of Elliptical  Distributions with Missing Data ",
    "url": "https://arxiv.org/abs/2201.12020",
    "authors": [
      "Florian Mouret",
      "Alexandre Hippert-Ferrer",
      "Fr\u00e9d\u00e9ric Pascal",
      "Jean-Yves Tourneret"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12725",
    "title": "Generalized Global Ranking-Aware Neural Architecture Ranker for  Efficient Image Classifier Search",
    "abstract": " Title: Generalized Global Ranking-Aware Neural Architecture Ranker for  Efficient Image Classifier Search ",
    "url": "https://arxiv.org/abs/2201.12725",
    "authors": [
      "Bicheng Guo",
      "Tao Chen",
      "Shibo He",
      "Haoyu Liu",
      "Lilin Xu",
      "Peng Ye",
      "Jiming Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.02570",
    "title": "Proper conflict-free and unique-maximum colorings of planar graphs with  respect to neighborhoods",
    "abstract": " Title: Proper conflict-free and unique-maximum colorings of planar graphs with  respect to neighborhoods ",
    "url": "https://arxiv.org/abs/2202.02570",
    "authors": [
      "Igor Fabrici",
      "Borut Lu\u017ear",
      "Simona Rindo\u0161ov\u00e1",
      "Roman Sot\u00e1k"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2202.03990",
    "title": "Equivariance versus Augmentation for Spherical Images",
    "abstract": " Comments: Accepted to ICML2022, updated according to ICML-reviewer comments, 18 pages of which 9 in main body, 16 figures, ",
    "url": "https://arxiv.org/abs/2202.03990",
    "authors": [
      "Jan E. Gerken",
      "Oscar Carlsson",
      "Hampus Linander",
      "Fredrik Ohlsson",
      "Christoffer Petersson",
      "Daniel Persson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07998",
    "title": "DeepTx: Deep Learning Beamforming with Channel Prediction",
    "abstract": " Comments: 27 pages, this work has been submitted to the IEEE for possible publication; v2: Fixed typo in author name, v3: a revision ",
    "url": "https://arxiv.org/abs/2202.07998",
    "authors": [
      "Janne M.J. Huttunen",
      "Dani Korpi",
      "Mikko Honkala"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.11429",
    "title": "A Novel Self-Supervised Cross-Modal Image Retrieval Method In Remote  Sensing",
    "abstract": " Comments: Accepted at IEEE International Conference on Image Processing (ICIP) 2022. Our code is available at this https URL ",
    "url": "https://arxiv.org/abs/2202.11429",
    "authors": [
      "Gencer Sumbul",
      "Markus M\u00fcller",
      "Beg\u00fcm Demir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.13078",
    "title": "SWIS: Self-Supervised Representation Learning For Writer Independent  Offline Signature Verification",
    "abstract": " Comments: Accepted at IEEE ICIP 2022 ",
    "url": "https://arxiv.org/abs/2202.13078",
    "authors": [
      "Siladittya Manna",
      "Soumitri Chattopadhyay",
      "Saumik Bhattacharya",
      "Umapada Pal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2202.13080",
    "title": "Improved Hard Example Mining Approach for Single Shot Object Detectors",
    "abstract": " Comments: ICIP 2022. 5 pages, 2 figures, 7 tables. The codes are available at this https URL ",
    "url": "https://arxiv.org/abs/2202.13080",
    "authors": [
      "Aybora Koksal",
      "Onder Tuzcuoglu",
      "Kutalmis Gokalp Ince",
      "Yoldas Ataseven",
      "A. Aydin Alatan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11444",
    "title": "Root-aligned SMILES: A Tight Representation for Chemical Reaction  Prediction",
    "abstract": " Comments: Chemical Science 2022. Main paper: 16 pages, 5 figures, and 6 tables; supplementary information: 8 pages, 5 figures and 3 tables. Code repository: this https URL ",
    "url": "https://arxiv.org/abs/2203.11444",
    "authors": [
      "Zipeng Zhong",
      "Jie Song",
      "Zunlei Feng",
      "Tiantao Liu",
      "Lingxiang Jia",
      "Shaolun Yao",
      "Min Wu",
      "Tingjun Hou",
      "Mingli Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2203.11652",
    "title": "Weakly-Supervised Salient Object Detection Using Point Supervision",
    "abstract": " Comments: accepted by AAAI2022 ",
    "url": "https://arxiv.org/abs/2203.11652",
    "authors": [
      "Shuyong Gao",
      "Wei Zhang",
      "Yan Wang",
      "Qianyu Guo",
      "Chenglong Zhang",
      "Yangji He",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.15937",
    "title": "Improving Mispronunciation Detection with Wav2vec2-based Momentum  Pseudo-Labeling for Accentedness and Intelligibility Assessment",
    "abstract": " Comments: Accepted to Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2203.15937",
    "authors": [
      "Mu Yang",
      "Kevin Hirschi",
      "Stephen D. Looney",
      "Okim Kang",
      "John H. L. Hansen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.13317",
    "title": "MMRotate: A Rotated Object Detection Benchmark using Pytorch",
    "abstract": " Comments: 5 pages, 2 tables, MMRotate is accepted by ACM MM 2022. Yue Zhou and Xue Yang provided equal contribution. The code is publicly released at this https URL ",
    "url": "https://arxiv.org/abs/2204.13317",
    "authors": [
      "Yue Zhou",
      "Xue Yang",
      "Gefan Zhang",
      "Jiabao Wang",
      "Yanyi Liu",
      "Liping Hou",
      "Xue Jiang",
      "Xingzhao Liu",
      "Junchi Yan",
      "Chengqi Lyu",
      "Wenwei Zhang",
      "Kai Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.04956",
    "title": "Parallel Batch-Dynamic Minimum Spanning Forest and the Efficiency of  Dynamic Agglomerative Graph Clustering",
    "abstract": " Comments: SPAA 2022 ",
    "url": "https://arxiv.org/abs/2205.04956",
    "authors": [
      "Tom Tseng",
      "Laxman Dhulipala",
      "Julian Shun"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.06153",
    "title": "TreeMix: Compositional Constituency-based Data Augmentation for Natural  Language Understanding",
    "abstract": " Comments: Accepted to NAACL2022 main conference ",
    "url": "https://arxiv.org/abs/2205.06153",
    "authors": [
      "Le Zhang",
      "Zichao Yang",
      "Diyi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.06918",
    "title": "Representation learning with function call graph transformations for  malware open set recognition",
    "abstract": " Title: Representation learning with function call graph transformations for  malware open set recognition ",
    "url": "https://arxiv.org/abs/2205.06918",
    "authors": [
      "Jingyun Jia",
      "Philip K. Chan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.07310",
    "title": "Uncertainty estimation for Cross-dataset performance in Trajectory  prediction",
    "abstract": " Comments: Workshop on Fresh Perspectives on the Future of Autonomous Driving, ICRA 2022 ",
    "url": "https://arxiv.org/abs/2205.07310",
    "authors": [
      "Thomas Gilles",
      "Stefano Sabatini",
      "Dzmitry Tsishkou",
      "Bogdan Stanciulescu",
      "Fabien Moutarde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.09248",
    "title": "MESH2IR: Neural Acoustic Impulse Response Generator for Complex 3D  Scenes",
    "abstract": " Comments: Accepted to ACM Multimedia 2022. More results and source code is available at this https URL ",
    "url": "https://arxiv.org/abs/2205.09248",
    "authors": [
      "Anton Ratnarajah",
      "Zhenyu Tang",
      "Rohith Chandrashekar Aralikatti",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.09944",
    "title": "6G Network AI Architecture for Everyone-Centric Customized Services",
    "abstract": " Title: 6G Network AI Architecture for Everyone-Centric Customized Services ",
    "url": "https://arxiv.org/abs/2205.09944",
    "authors": [
      "Yang Yang",
      "Mulei Ma",
      "Hequan Wu",
      "Quan Yu",
      "Ping Zhang",
      "Xiaohu You",
      "Jianjun Wu",
      "Chenghui Peng",
      "Tak-Shing Peter Yum",
      "Sherman Shen",
      "Hamid Aghvami",
      "Geoffrey Y Li",
      "Jiangzhou Wang",
      "Guangyi Liu",
      "Peng Gao",
      "Xiongyan Tang",
      "Chang Cao",
      "John Thompson",
      "Kat-Kit Wong",
      "Shanzhi Chen",
      "Zhiqin Wang",
      "Merouane Debbah",
      "Schahram Dustdar",
      "Frank Eliassen",
      "Tao Chen",
      "Xiangyang Duan",
      "Shaohui Sun",
      "Xiaofeng Tao",
      "Qinyu Zhang",
      "Jianwei Huang",
      "Shuguang Cui",
      "Wenjun Zhang",
      "Jie Li",
      "Yue Gao",
      "Honggang Zhang",
      "Xu Chen",
      "Xiaohu Ge",
      "Yong Xiao",
      "Cheng-Xiang Wang",
      "Zaichen Zhang",
      "Song Ci",
      "Guoqiang Mao",
      "Changle Li",
      "Ziyu Shao",
      "Yong Zhou",
      "Junrui Liang",
      "Kai Li",
      "Liantao Wu",
      "Fanglei Sun",
      "Kunlun Wang",
      "Zening Liu",
      "Kun Yang",
      "Jun Wang",
      "Teng Gao",
      "Hongfeng Shu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.10450",
    "title": "Temporally Precise Action Spotting in Soccer Videos Using Dense  Detection Anchors",
    "abstract": " Comments: Accepted in International Conference on Image Processing (ICIP), 2022 ",
    "url": "https://arxiv.org/abs/2205.10450",
    "authors": [
      "Jo\u00e3o V. B. Soares",
      "Avijit Shah",
      "Topojoy Biswas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13326",
    "title": "SHREC 2022: pothole and crack detection in the road pavement using  images and RGB-D data",
    "abstract": " Title: SHREC 2022: pothole and crack detection in the road pavement using  images and RGB-D data ",
    "url": "https://arxiv.org/abs/2205.13326",
    "authors": [
      "Elia Moscoso Thompson",
      "Andrea Ranieri",
      "Silvia Biasotti",
      "Miguel Chicchon",
      "Ivan Sipiran",
      "Minh-Khoi Pham",
      "Thang-Long Nguyen-Ho",
      "Hai-Dang Nguyen",
      "Minh-Triet Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2205.15083",
    "title": "CGMN: A Contrastive Graph Matching Network for Self-Supervised Graph  Similarity Learning",
    "abstract": " Comments: 7 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2205.15083",
    "authors": [
      "Di Jin",
      "Luzhi Wang",
      "Yizhen Zheng",
      "Xiang Li",
      "Fei Jiang",
      "Wei Lin",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.15921",
    "title": "Online Meta-Learning in Adversarial Multi-Armed Bandits",
    "abstract": " Comments: v1: The paper is submitted to NeurIPS 2022. An older version was rejected from ICML 2022 v2: Added a reference to concurrent work in Prior Art section ",
    "url": "https://arxiv.org/abs/2205.15921",
    "authors": [
      "Ilya Osadchiy",
      "Kfir Y. Levy",
      "Ron Meir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.00913",
    "title": "Improving the Robustness and Generalization of Deep Neural Network with  Confidence Threshold Reduction",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2206.00913",
    "authors": [
      "Xiangyuan Yang",
      "Jie Lin",
      "Hanlin Zhang",
      "Xinyu Yang",
      "Peng Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.02603",
    "title": "CAN-MM: Multiplexed Message Authentication Code for Controller Area  Network message authentication in road vehicles",
    "abstract": " Title: CAN-MM: Multiplexed Message Authentication Code for Controller Area  Network message authentication in road vehicles ",
    "url": "https://arxiv.org/abs/2206.02603",
    "authors": [
      "Franco Oberti",
      "Ernesto Sanchez",
      "Alessandro Savino",
      "Filippo Parisi",
      "Stefano Di Carlo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.02806",
    "title": "Quantum Neural Network Classifiers: A Tutorial",
    "abstract": " Comments: 30 pages, 5 figures, 6 tables ",
    "url": "https://arxiv.org/abs/2206.02806",
    "authors": [
      "Weikang Li",
      "Zhide Lu",
      "Dong-Ling Deng"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.04042",
    "title": "Learning Ego 3D Representation as Ray Tracing",
    "abstract": " Comments: ECCV 2022. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2206.04042",
    "authors": [
      "Jiachen Lu",
      "Zheyuan Zhou",
      "Xiatian Zhu",
      "Hang Xu",
      "Li Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.08428",
    "title": "EyeNeRF: A Hybrid Representation for Photorealistic Synthesis, Animation  and Relighting of Human Eyes",
    "abstract": " Comments: 16 pages, 16 figures, 1 table, to be published in ACM Transactions on Graphics (TOG) (Volume: 41, Issue: 4), 2022 ",
    "url": "https://arxiv.org/abs/2206.08428",
    "authors": [
      "Gengyan Li",
      "Abhimitra Meka",
      "Franziska M\u00fcller",
      "Marcel C. B\u00fchler",
      "Otmar Hilliges",
      "Thabo Beeler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.10261",
    "title": "Interpretable Deep Causal Learning for Moderation Effects",
    "abstract": " Title: Interpretable Deep Causal Learning for Moderation Effects ",
    "url": "https://arxiv.org/abs/2206.10261",
    "authors": [
      "Alberto Caron",
      "Gianluca Baio",
      "Ioanna Manolopoulou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.10303",
    "title": "Prediction of Maneuvering Status for Aerial Vehicles using Supervised  Learning Methods",
    "abstract": " Comments: 9 pages. To appear in proceedings of 2nd International Conference on Machine Learning and Big Data Analytics (ICMLBDA) 2022 ",
    "url": "https://arxiv.org/abs/2206.10303",
    "authors": [
      "Abhishek Gupta",
      "Sarvesh Thustu",
      "Riti Thakor",
      "Saniya Patil",
      "Raunak Joshi",
      "Ronald Melvin Laban"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.15398",
    "title": "PolarFormer: Multi-camera 3D Object Detection with Polar Transformers",
    "abstract": " Title: PolarFormer: Multi-camera 3D Object Detection with Polar Transformers ",
    "url": "https://arxiv.org/abs/2206.15398",
    "authors": [
      "Yanqin Jiang",
      "Li Zhang",
      "Zhenwei Miao",
      "Xiatian Zhu",
      "Jin Gao",
      "Weiming Hu",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.01030",
    "title": "Boosting Single-Frame 3D Object Detection by Simulating Multi-Frame  Point Clouds",
    "abstract": " Comments: Accepted by ACM MM 2022 ",
    "url": "https://arxiv.org/abs/2207.01030",
    "authors": [
      "Wu Zheng",
      "Li Jiang",
      "Fanbin Lu",
      "Yangyang Ye",
      "Chi-Wing Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01056",
    "title": "Counterfactually Measuring and Eliminating Social Bias in  Vision-Language Pre-training Models",
    "abstract": " Title: Counterfactually Measuring and Eliminating Social Bias in  Vision-Language Pre-training Models ",
    "url": "https://arxiv.org/abs/2207.01056",
    "authors": [
      "Yi Zhang",
      "Junyang Wang",
      "Jitao Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.01377",
    "title": "Detection of ADHD based on Eye Movements during Natural Viewing",
    "abstract": " Comments: Pre-print for Proceedings of the European Conference on Machine Learning, 2022 ",
    "url": "https://arxiv.org/abs/2207.01377",
    "authors": [
      "Shuwen Deng",
      "Paul Prasse",
      "David R. Reich",
      "Sabine Dziemian",
      "Maja Stegenwallner-Sch\u00fctz",
      "Daniel Krakowczyk",
      "Silvia Makowski",
      "Nicolas Langer",
      "Tobias Scheffer",
      "Lena A. J\u00e4ger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01528",
    "title": "VEM$^2$L: A Plug-and-play Framework for Fusing Text and Structure  Knowledge on Sparse Knowledge Graph Completion",
    "abstract": " Comments: 13 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2207.01528",
    "authors": [
      "Tao He",
      "Tianwen Jiang",
      "Zihao Zheng",
      "Haichao Zhu",
      "Jingrun Zhang",
      "Ming Liu",
      "Sendong Zhao",
      "Bing Qin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.02970",
    "title": "Network Binarization via Contrastive Learning",
    "abstract": " Comments: Accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2207.02970",
    "authors": [
      "Yuzhang Shang",
      "Dan Xu",
      "Ziliang Zong",
      "Liqiang Nie",
      "Yan Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.03579",
    "title": "DGraph: A Large-Scale Financial Dataset for Graph Anomaly Detection",
    "abstract": " Comments: 9 pages ",
    "url": "https://arxiv.org/abs/2207.03579",
    "authors": [
      "Xuanwen Huang",
      "Yang Yang",
      "Yang Wang",
      "Chunping Wang",
      "Zhisheng Zhang",
      "Jiarong Xu",
      "Lei Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.03689",
    "title": "Guiding the retraining of convolutional neural networks against  adversarial inputs",
    "abstract": " Title: Guiding the retraining of convolutional neural networks against  adversarial inputs ",
    "url": "https://arxiv.org/abs/2207.03689",
    "authors": [
      "Francisco Dur\u00e1n L\u00f3pez",
      "Silverio Mart\u00ednez-Fern\u00e1ndez",
      "Michael Felderer",
      "Xavier Franch"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.03790",
    "title": "Complementing Brightness Constancy with Deep Networks for Optical Flow  Prediction",
    "abstract": " Title: Complementing Brightness Constancy with Deep Networks for Optical Flow  Prediction ",
    "url": "https://arxiv.org/abs/2207.03790",
    "authors": [
      "Vincent Le Guen",
      "Cl\u00e9ment Rambour",
      "Nicolas Thome"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.04364",
    "title": "Planning Sequential Tasks on Contact Graph",
    "abstract": " Comments: 8 pages, 6 figures. Accepted by IROS 2022 ",
    "url": "https://arxiv.org/abs/2207.04364",
    "authors": [
      "Ziyuan Jiao",
      "Yida Niu",
      "Zeyu Zhang",
      "Song-Chun Zhu",
      "Yixin Zhu",
      "Hangxin Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.04581",
    "title": "How Robust is your Fair Model? Exploring the Robustness of Diverse  Fairness Strategies",
    "abstract": " Comments: 12 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2207.04581",
    "authors": [
      "Edward Small",
      "Wei Shao",
      "Zeliang Zhang",
      "Peihan Liu",
      "Jeffrey Chan",
      "Kacper Sokol",
      "Flora Salim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  }
]