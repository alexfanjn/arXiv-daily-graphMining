[
  {
    "id": "arXiv:2207.10719",
    "title": "Synthetic Dataset Generation for Adversarial Machine Learning Research",
    "abstract": "Existing adversarial example research focuses on digitally inserted perturbations on top of existing natural image datasets. This construction of adversarial examples is not realistic because it may be difficult, or even impossible, for an attacker to deploy such an attack in the real-world due to sensing and environmental effects. To better understand adversarial examples against cyber-physical systems, we propose approximating the real-world through simulation. In this paper we describe our synthetic dataset generation tool that enables scalable collection of such a synthetic dataset with realistic adversarial examples. We use the CARLA simulator to collect such a dataset and demonstrate simulated attacks that undergo the same environmental transforms and processing as real-world images. Our tools have been used to collect datasets to help evaluate the efficacy of adversarial examples, and can be found at https://github.com/carla-simulator/carla/pull/4992. ",
    "url": "https://arxiv.org/abs/2207.10719",
    "authors": [
      "Xiruo Liu",
      "Shibani Singh",
      "Cory Cornelius",
      "Colin Busho",
      "Mike Tan",
      "Anindya Paul",
      "Jason Martin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10721",
    "title": "Heterogeneous Ensemble Learning for Enhanced Crash Forecasts -- A  Frequentest and Machine Learning based Stacking Framework",
    "abstract": "A variety of statistical and machine learning methods are used to model crash frequency on specific roadways with machine learning methods generally having a higher prediction accuracy. Recently, heterogeneous ensemble methods (HEM), including stacking, have emerged as more accurate and robust intelligent techniques and are often used to solve pattern recognition problems by providing more reliable and accurate predictions. In this study, we apply one of the key HEM methods, Stacking, to model crash frequency on five lane undivided segments (5T) of urban and suburban arterials. The prediction performance of Stacking is compared with parametric statistical models (Poisson and negative binomial) and three state of the art machine learning techniques (Decision tree, random forest, and gradient boosting), each of which is termed as the base learner. By employing an optimal weight scheme to combine individual base learners through stacking, the problem of biased predictions in individual base-learners due to differences in specifications and prediction accuracies is avoided. Data including crash, traffic, and roadway inventory were collected and integrated from 2013 to 2017. The data are split into training, validation, and testing datasets. Estimation results of statistical models reveal that besides other factors, crashes increase with density (number per mile) of different types of driveways. Comparison of out-of-sample predictions of various models confirms the superiority of Stacking over the alternative methods considered. From a practical standpoint, stacking can enhance prediction accuracy (compared to using only one base learner with a particular specification). When applied systemically, stacking can help identify more appropriate countermeasures. ",
    "url": "https://arxiv.org/abs/2207.10721",
    "authors": [
      "Numan Ahmad",
      "Behram Wali",
      "Asad J. Khattak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2207.10725",
    "title": "A Deep Neural Network/Meshfree Method for Solving Dynamic Two-phase  Interface Problems",
    "abstract": "In this paper, a meshfree method using the deep neural network (DNN) approach is developed for solving two kinds of dynamic two-phase interface problems governed by different dynamic partial differential equations on either side of the stationary interface with the jump and high-contrast coefficients. The first type of two-phase interface problem to be studied is the fluid-fluid (two-phase flow) interface problem modeled by Navier-Stokes equations with high-contrast physical parameters across the interface. The second one belongs to fluid-structure interaction (FSI) problems modeled by Navier-Stokes equations on one side of the interface and the structural equation on the other side of the interface, both the fluid and the structure interact with each other via the kinematic- and the dynamic interface conditions across the interface. The DNN/meshfree method is respectively developed for the above two-phase interface problems by representing solutions of PDEs using the DNNs' structure and reformulating the dynamic interface problem as a least-squares minimization problem based upon a space-time sampling point set. Approximation error analyses are also carried out for each kind of interface problem, which reveals an intrinsic strategy about how to efficiently build a sampling-point training dataset to obtain a more accurate DNNs' approximation. In addition, compared with traditional discretization approaches, the proposed DNN/meshfree method and its error analysis technique can be smoothly extended to many other dynamic interface problems with fixed interfaces. Numerical experiments are conducted to illustrate the accuracies of the proposed DNN/meshfree method for the presented two-phase interface problems. Theoretical results are validated to some extent through three numerical examples. ",
    "url": "https://arxiv.org/abs/2207.10725",
    "authors": [
      "Xingwen Zhu",
      "Xiaozhe Hu",
      "Pengtao Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.10728",
    "title": "Decision-Feedback Detection for Bidirectional Molecular Relaying with  Direct Links",
    "abstract": "In this paper, we consider bidirectional relaying between two diffusion-based molecular transceivers (bio-nodes). As opposed to existing literature, we incorporate the effect of direct diffusion links between the nodes and leverage it to improve performance. Assuming network coding type operation at the relay, we devise a detection strategy, based on the maximum-likelihood principle, that combines the signal received from the relay and that received from the direct link. At the same time, since a diffusion-based molecular communication channel is characterized by high inter-symbol interference (ISI), we utilize a decision feedback mechanism to mitigate its effect. Simulation results indicate that the proposed setup incorporating the direct link can achieve notable improvement in error performance over conventional detection schemes that do not exploit the direct link and/or do not attempt to mitigate the effect of ISI. ",
    "url": "https://arxiv.org/abs/2207.10728",
    "authors": [
      "Maryam Khalid",
      "Momin Uppal"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.10758",
    "title": "DEVIANT: Depth EquiVarIAnt NeTwork for Monocular 3D Object Detection",
    "abstract": "Modern neural networks use building blocks such as convolutions that are equivariant to arbitrary 2D translations. However, these vanilla blocks are not equivariant to arbitrary 3D translations in the projective manifold. Even then, all monocular 3D detectors use vanilla blocks to obtain the 3D coordinates, a task for which the vanilla blocks are not designed for. This paper takes the first step towards convolutions equivariant to arbitrary 3D translations in the projective manifold. Since the depth is the hardest to estimate for monocular detection, this paper proposes Depth EquiVarIAnt NeTwork (DEVIANT) built with existing scale equivariant steerable blocks. As a result, DEVIANT is equivariant to the depth translations in the projective manifold whereas vanilla networks are not. The additional depth equivariance forces the DEVIANT to learn consistent depth estimates, and therefore, DEVIANT achieves state-of-the-art monocular 3D detection results on KITTI and Waymo datasets in the image-only category and performs competitively to methods using extra information. Moreover, DEVIANT works better than vanilla networks in cross-dataset evaluation. Code and models at https://github.com/abhi1kumar/DEVIANT ",
    "url": "https://arxiv.org/abs/2207.10758",
    "authors": [
      "Abhinav Kumar",
      "Garrick Brazil",
      "Enrique Corona",
      "Armin Parchami",
      "Xiaoming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10767",
    "title": "Modeling User Behavior With Interaction Networks for Spam Detection",
    "abstract": "Spam is a serious problem plaguing web-scale digital platforms which facilitate user content creation and distribution. It compromises platform's integrity, performance of services like recommendation and search, and overall business. Spammers engage in a variety of abusive and evasive behavior which are distinct from non-spammers. Users' complex behavior can be well represented by a heterogeneous graph rich with node and edge attributes. Learning to identify spammers in such a graph for a web-scale platform is challenging because of its structural complexity and size. In this paper, we propose SEINE (Spam DEtection using Interaction NEtworks), a spam detection model over a novel graph framework. Our graph simultaneously captures rich users' details and behavior and enables learning on a billion-scale graph. Our model considers neighborhood along with edge types and attributes, allowing it to capture a wide range of spammers. SEINE, trained on a real dataset of tens of millions of nodes and billions of edges, achieves a high performance of 80% recall with 1% false positive rate. SEINE achieves comparable performance to the state-of-the-art techniques on a public dataset while being pragmatic to be used in a large-scale production system. ",
    "url": "https://arxiv.org/abs/2207.10767",
    "authors": [
      "Prabhat Agarwal",
      "Manisha Srivastava",
      "Vishwakarma Singh",
      "Charles Rosenberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.10774",
    "title": "Focused Decoding Enables 3D Anatomical Detection by Transformers",
    "abstract": "Detection Transformers represent end-to-end object detection approaches based on a Transformer encoder-decoder architecture, exploiting the attention mechanism for global relation modeling. Although Detection Transformers deliver results on par with or even superior to their highly optimized CNN-based counterparts operating on 2D natural images, their success is closely coupled to access to a vast amount of training data. This, however, restricts the feasibility of employing Detection Transformers in the medical domain, as access to annotated data is typically limited. To tackle this issue and facilitate the advent of medical Detection Transformers, we propose a novel Detection Transformer for 3D anatomical structure detection, dubbed Focused Decoder. Focused Decoder leverages information from an anatomical region atlas to simultaneously deploy query anchors and restrict the cross-attention's field of view to regions of interest, which allows for a precise focus on relevant anatomical structures. We evaluate our proposed approach on two publicly available CT datasets and demonstrate that Focused Decoder not only provides strong detection results and thus alleviates the need for a vast amount of annotated data but also exhibits exceptional and highly intuitive explainability of results via attention weights. Code for Focused Decoder is available in our medical Vision Transformer library github.com/bwittmann/transoar. ",
    "url": "https://arxiv.org/abs/2207.10774",
    "authors": [
      "Bastian Wittmann",
      "Fernando Navarro",
      "Suprosanna Shit",
      "Bjoern Menze"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.10796",
    "title": "Multiple Robust Learning for Recommendation",
    "abstract": "In recommender systems, a common problem is the presence of various biases in the collected data, which deteriorates the generalization ability of the recommendation models and leads to inaccurate predictions. Doubly robust (DR) learning has been studied in many tasks in RS, with the advantage that unbiased learning can be achieved when either a single imputation or a single propensity model is accurate. In this paper, we propose a multiple robust (MR) estimator that can take the advantage of multiple candidate imputation and propensity models to achieve unbiasedness. Specifically, the MR estimator is unbiased when any of the imputation or propensity models, or a linear combination of these models is accurate. Theoretical analysis shows that the proposed MR is an enhanced version of DR when only having a single imputation and propensity model, and has a smaller bias. Inspired by the generalization error bound of MR, we further propose a novel multiple robust learning approach with stabilization. We conduct extensive experiments on real-world and semi-synthetic datasets, which demonstrates the superiority of the proposed approach over state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2207.10796",
    "authors": [
      "Haoxuan Li",
      "Quanyu Dai",
      "Yuru Li",
      "Yan Lyu",
      "Zhenhua Dong",
      "Peng Wu",
      "Xiao-Hua Zhou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.10801",
    "title": "PhishSim: Aiding Phishing Website Detection with a Feature-Free Tool",
    "abstract": "In this paper, we propose a feature-free method for detecting phishing websites using the Normalized Compression Distance (NCD), a parameter-free similarity measure which computes the similarity of two websites by compressing them, thus eliminating the need to perform any feature extraction. It also removes any dependence on a specific set of website features. This method examines the HTML of webpages and computes their similarity with known phishing websites, in order to classify them. We use the Furthest Point First algorithm to perform phishing prototype extractions, in order to select instances that are representative of a cluster of phishing webpages. We also introduce the use of an incremental learning algorithm as a framework for continuous and adaptive detection without extracting new features when concept drift occurs. On a large dataset, our proposed method significantly outperforms previous methods in detecting phishing websites, with an AUC score of 98.68%, a high true positive rate (TPR) of around 90%, while maintaining a low false positive rate (FPR) of 0.58%. Our approach uses prototypes, eliminating the need to retain long term data in the future, and is feasible to deploy in real systems with a processing time of roughly 0.3 seconds. ",
    "url": "https://arxiv.org/abs/2207.10801",
    "authors": [
      "Rizka Purwanto",
      "Arindam Pal",
      "Alan Blair",
      "Sanjay Jha"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10802",
    "title": "Active Data Pattern Extraction Attacks on Generative Language Models",
    "abstract": "With the wide availability of large pre-trained language model checkpoints, such as GPT-2 and BERT, the recent trend has been to fine-tune them on a downstream task to achieve the state-of-the-art performance with a small computation overhead. One natural example is the Smart Reply application where a pre-trained model is fine-tuned for suggesting a number of responses given a query message. In this work, we set out to investigate potential information leakage vulnerabilities in a typical Smart Reply pipeline and show that it is possible for an adversary, having black-box or gray-box access to a Smart Reply model, to extract sensitive user information present in the training data. We further analyse the privacy impact of specific components, e.g. the decoding strategy, pertained to this application through our attack settings. We explore potential mitigation strategies and demonstrate how differential privacy can be a strong defense mechanism to such data extraction attacks. ",
    "url": "https://arxiv.org/abs/2207.10802",
    "authors": [
      "Bargav Jayaraman",
      "Esha Ghosh",
      "Huseyin Inan",
      "Melissa Chase",
      "Sambuddha Roy",
      "Wei Dai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10803",
    "title": "NFDLM: A Lightweight Network Flow based Deep Learning Model for DDoS  Attack Detection in IoT Domains",
    "abstract": "In the recent years, Distributed Denial of Service (DDoS) attacks on Internet of Things (IoT) devices have become one of the prime concerns to Internet users around the world. One of the sources of the attacks on IoT ecosystems are botnets. Intruders force IoT devices to become unavailable for its legitimate users by sending large number of messages within a short interval. This study proposes NFDLM, a lightweight and optimised Artificial Neural Network (ANN) based Distributed Denial of Services (DDoS) attack detection framework with mutual correlation as feature selection method which produces a superior result when compared with Long Short Term Memory (LSTM) and simple ANN. Overall, the detection performance achieves approximately 99\\% accuracy for the detection of attacks from botnets. In this work, we have designed and compared four different models where two are based on ANN and the other two are based on LSTM to detect the attack types of DDoS. ",
    "url": "https://arxiv.org/abs/2207.10803",
    "authors": [
      "Kumar Saurabh",
      "Tanuj Kumar",
      "Uphar Singh",
      "O.P. Vyas",
      "Rahamatullah Khondoker"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10804",
    "title": "Suppressing Poisoning Attacks on Federated Learning for Medical Imaging",
    "abstract": "Collaboration among multiple data-owning entities (e.g., hospitals) can accelerate the training process and yield better machine learning models due to the availability and diversity of data. However, privacy concerns make it challenging to exchange data while preserving confidentiality. Federated Learning (FL) is a promising solution that enables collaborative training through exchange of model parameters instead of raw data. However, most existing FL solutions work under the assumption that participating clients are \\emph{honest} and thus can fail against poisoning attacks from malicious parties, whose goal is to deteriorate the global model performance. In this work, we propose a robust aggregation rule called Distance-based Outlier Suppression (DOS) that is resilient to byzantine failures. The proposed method computes the distance between local parameter updates of different clients and obtains an outlier score for each client using Copula-based Outlier Detection (COPOD). The resulting outlier scores are converted into normalized weights using a softmax function, and a weighted average of the local parameters is used for updating the global model. DOS aggregation can effectively suppress parameter updates from malicious clients without the need for any hyperparameter selection, even when the data distributions are heterogeneous. Evaluation on two medical imaging datasets (CheXpert and HAM10000) demonstrates the higher robustness of DOS method against a variety of poisoning attacks in comparison to other state-of-the-art methods. The code can be found here https://github.com/Naiftt/SPAFD. ",
    "url": "https://arxiv.org/abs/2207.10804",
    "authors": [
      "Naif Alkhunaizi",
      "Dmitry Kamzolov",
      "Martin Tak\u00e1\u010d",
      "Karthik Nandakumar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2207.10805",
    "title": "PowerFDNet: Deep Learning-Based Stealthy False Data Injection Attack  Detection for AC-model Transmission Systems",
    "abstract": "Recent studies have demonstrated that smart grids are vulnerable to stealthy false data injection attacks (SFDIAs), as SFDIAs can bypass residual-based bad data detection mechanisms. The SFDIA detection has become one of the focuses of smart grid research. Methods based on deep learning technology have shown promising accuracy in the detection of SFDIAs. However, most existing methods rely on the temporal structure of a sequence of measurements but do not take account of the spatial structure between buses and transmission lines. To address this issue, we propose a spatiotemporal deep network, PowerFDNet, for the SFDIA detection in AC-model power grids. The PowerFDNet consists of two sub-architectures: spatial architecture (SA) and temporal architecture (TA). The SA is aimed at extracting representations of bus/line measurements and modeling the spatial structure based on their representations. The TA is aimed at modeling the temporal structure of a sequence of measurements. Therefore, the proposed PowerFDNet can effectively model the spatiotemporal structure of measurements. Case studies on the detection of SFDIAs on the benchmark smart grids show that the PowerFDNet achieved significant improvement compared with the state-of-the-art SFDIA detection methods. In addition, an IoT-oriented lightweight prototype of size 52 MB is implemented and tested for mobile devices, which demonstrates the potential applications on mobile devices. The trained model will be available at \\textit{https://github.com/FrankYinXF/PowerFDNet}. ",
    "url": "https://arxiv.org/abs/2207.10805",
    "authors": [
      "Xuefei Yin",
      "Yanming Zhu",
      "Yi Xie",
      "Jiankun Hu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.10810",
    "title": "A Convolutional Attention Based Deep Network Solution for UAV Network  Attack Recognition over Fading Channels and Interference",
    "abstract": "When users exchange data with Unmanned Aerial vehicles - (UAVs) over air-to-ground (A2G) wireless communication networks, they expose the link to attacks that could increase packet loss and might disrupt connectivity. For example, in emergency deliveries, losing control information (i.e data related to the UAV control communication) might result in accidents that cause UAV destruction and damage to buildings or other elements in a city. To prevent these problems, these issues must be addressed in 5G and 6G scenarios. This research offers a deep learning (DL) approach for detecting attacks in UAVs equipped with orthogonal frequency division multiplexing (OFDM) receivers on Clustered Delay Line (CDL) channels in highly complex scenarios involving authenticated terrestrial users, as well as attackers in unknown locations. We use the two observable parameters available in 5G UAV connections: the Received Signal Strength Indicator (RSSI) and the Signal to Interference plus Noise Ratio (SINR). The prospective algorithm is generalizable regarding attack identification, which does not occur during training. Further, it can identify all the attackers in the environment with 20 terrestrial users. A deeper investigation into the timing requirements for recognizing attacks show that after training, the minimum time necessary after the attack begins is 100 ms, and the minimum attack power is 2 dBm, which is the same power that the authenticated UAV uses. Our algorithm also detects moving attackers from a distance of 500 m. ",
    "url": "https://arxiv.org/abs/2207.10810",
    "authors": [
      "Joseanne Viana",
      "Hamed Farkhari",
      "Luis Miguel Campos",
      "Pedro Sebastiao",
      "Katerina Koutlia",
      "Sandra Lagen",
      "Luis Bernardo",
      "Rui Dinis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.10812",
    "title": "RSU-Based Online Intrusion Detection and Mitigation for VANET",
    "abstract": "Secure vehicular communication is a critical factor for secure traffic management. Effective security in intelligent transportation systems (ITS) requires effective and timely intrusion detection systems (IDS). In this paper, we consider false data injection attacks and distributed denial-of-service (DDoS) attacks, especially the stealthy DDoS attacks, targeting the integrity and availability, respectively, in vehicular ad-hoc networks (VANET). Novel statistical intrusion detection and mitigation techniques based on centralized communications through roadside units (RSU) are proposed for the considered attacks. The performance of the proposed methods are evaluated using a traffic simulator and a real traffic dataset. Comparisons with the state-of-the-art solutions clearly demonstrate the superior performance of the proposed methods in terms of quick and accurate detection and localization of cyberattacks. ",
    "url": "https://arxiv.org/abs/2207.10812",
    "authors": [
      "Ammar Haydari",
      "Yasin Yilmaz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.10814",
    "title": "Supervised Contrastive ResNet and Transfer Learning for the In-vehicle  Intrusion Detection System",
    "abstract": "High-end vehicles have been furnished with a number of electronic control units (ECUs), which provide upgrading functions to enhance the driving experience. The controller area network (CAN) is a well-known protocol that connects these ECUs because of its modesty and efficiency. However, the CAN bus is vulnerable to various types of attacks. Although the intrusion detection system (IDS) is proposed to address the security problem of the CAN bus, most previous studies only provide alerts when attacks occur without knowing the specific type of attack. Moreover, an IDS is designed for a specific car model due to diverse car manufacturers. In this study, we proposed a novel deep learning model called supervised contrastive (SupCon) ResNet, which can handle multiple attack identification on the CAN bus. Furthermore, the model can be used to improve the performance of a limited-size dataset using a transfer learning technique. The capability of the proposed model is evaluated on two real car datasets. When tested with the car hacking dataset, the experiment results show that the SupCon ResNet model improves the overall false-negative rates of four types of attack by four times on average, compared to other models. In addition, the model achieves the highest F1 score at 0.9994 on the survival dataset by utilizing transfer learning. Finally, the model can adapt to hardware constraints in terms of memory size and running time. ",
    "url": "https://arxiv.org/abs/2207.10814",
    "authors": [
      "Thien-Nu Hoang",
      "Daehee Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10816",
    "title": "Mathematical Model of Strong Physically Unclonable Functions Based on  Hybrid Boolean Networks",
    "abstract": "We introduce a mathematical framework for simulating Hybrid Boolean Network (HBN) Physically Unclonable Functions (PUFs, HBN-PUFs). We verify that the model is able to reproduce the experimentally observed PUF statistics for uniqueness $\\mu_{inter}$ and reliability $\\mu_{intra}$ obtained from experiments of HBN-PUFs on Cyclone V FPGAs. Our results suggest that the HBN-PUF is a true `strong' PUF in the sense that its security properties depend exponentially on both the manufacturing variation and the challenge-response space. Our Python simulation methods are open-source and available at https://github.com/Noeloikeau/networkm. ",
    "url": "https://arxiv.org/abs/2207.10816",
    "authors": [
      "Noeloikeau Charlot",
      "Daniel J. Gauthier",
      "Daniel Canaday",
      "Andrew Pomerance"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.10817",
    "title": "End-to-End and Self-Supervised Learning for ComParE 2022 Stuttering  Sub-Challenge",
    "abstract": "In this paper, we present end-to-end and speech embedding based systems trained in a self-supervised fashion to participate in the ACM Multimedia 2022 ComParE Challenge, specifically the stuttering sub-challenge. In particular, we exploit the embeddings from the pre-trained Wav2Vec2.0 model for stuttering detection (SD) on the KSoF dataset. After embedding extraction, we benchmark with several methods for SD. Our proposed self-supervised based SD system achieves a UAR of 36.9% and 41.0% on validation and test sets respectively, which is 31.32% (validation set) and 1.49% (test set) higher than the best (DeepSpectrum) challenge baseline (CBL). Moreover, we show that concatenating layer embeddings with Mel-frequency cepstral coefficients (MFCCs) features further improves the UAR of 33.81% and 5.45% on validation and test sets respectively over the CBL. Finally, we demonstrate that the summing information across all the layers of Wav2Vec2.0 surpasses the CBL by a relative margin of 45.91% and 5.69% on validation and test sets respectively. Grand-challenge: Computational Paralinguistics ChallengE ",
    "url": "https://arxiv.org/abs/2207.10817",
    "authors": [
      "Shakeel Ahmad Sheikh",
      "Md Sahidullah",
      "Fabrice Hirsch",
      "Slim Ouni"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.10825",
    "title": "Just Rotate it: Deploying Backdoor Attacks via Rotation Transformation",
    "abstract": "Recent works have demonstrated that deep learning models are vulnerable to backdoor poisoning attacks, where these attacks instill spurious correlations to external trigger patterns or objects (e.g., stickers, sunglasses, etc.). We find that such external trigger signals are unnecessary, as highly effective backdoors can be easily inserted using rotation-based image transformation. Our method constructs the poisoned dataset by rotating a limited amount of objects and labeling them incorrectly; once trained with it, the victim's model will make undesirable predictions during run-time inference. It exhibits a significantly high attack success rate while maintaining clean performance through comprehensive empirical studies on image classification and object detection tasks. Furthermore, we evaluate standard data augmentation techniques and four different backdoor defenses against our attack and find that none of them can serve as a consistent mitigation approach. Our attack can be easily deployed in the real world since it only requires rotating the object, as we show in both image classification and object detection applications. Overall, our work highlights a new, simple, physically realizable, and highly effective vector for backdoor attacks. Our video demo is available at https://youtu.be/6JIF8wnX34M. ",
    "url": "https://arxiv.org/abs/2207.10825",
    "authors": [
      "Tong Wu",
      "Tianhao Wang",
      "Vikash Sehwag",
      "Saeed Mahloujifar",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10830",
    "title": "Automated Dilated Spatio-Temporal Synchronous Graph Modeling for Traffic  Prediction",
    "abstract": "Accurate traffic prediction is a challenging task in intelligent transportation systems because of the complex spatio-temporal dependencies in transportation networks. Many existing works utilize sophisticated temporal modeling approaches to incorporate with graph convolution networks (GCNs) for capturing short-term and long-term spatio-temporal dependencies. However, these separated modules with complicated designs could restrict effectiveness and efficiency of spatio-temporal representation learning. Furthermore, most previous works adopt the fixed graph construction methods to characterize the global spatio-temporal relations, which limits the learning capability of the model for different time periods and even different data scenarios. To overcome these limitations, we propose an automated dilated spatio-temporal synchronous graph network, named Auto-DSTSGN for traffic prediction. Specifically, we design an automated dilated spatio-temporal synchronous graph (Auto-DSTSG) module to capture the short-term and long-term spatio-temporal correlations by stacking deeper layers with dilation factors in an increasing order. Further, we propose a graph structure search approach to automatically construct the spatio-temporal synchronous graph that can adapt to different data scenarios. Extensive experiments on four real-world datasets demonstrate that our model can achieve about 10% improvements compared with the state-of-art methods. Source codes are available at https://github.com/jinguangyin/Auto-DSTSGN. ",
    "url": "https://arxiv.org/abs/2207.10830",
    "authors": [
      "Guangyin Jin",
      "Fuxian Li",
      "Jinlei Zhang",
      "Mudan Wang",
      "Jincai Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10833",
    "title": "Few-shot Image Generation Using Discrete Content Representation",
    "abstract": "Few-shot image generation and few-shot image translation are two related tasks, both of which aim to generate new images for an unseen category with only a few images. In this work, we make the first attempt to adapt few-shot image translation method to few-shot image generation task. Few-shot image translation disentangles an image into style vector and content map. An unseen style vector can be combined with different seen content maps to produce different images. However, it needs to store seen images to provide content maps and the unseen style vector may be incompatible with seen content maps. To adapt it to few-shot image generation task, we learn a compact dictionary of local content vectors via quantizing continuous content maps into discrete content maps instead of storing seen images. Furthermore, we model the autoregressive distribution of discrete content map conditioned on style vector, which can alleviate the incompatibility between content map and style vector. Qualitative and quantitative results on three real datasets demonstrate that our model can produce images of higher diversity and fidelity for unseen categories than previous methods. ",
    "url": "https://arxiv.org/abs/2207.10833",
    "authors": [
      "Yan Hong",
      "Li Niu",
      "Jianfu Zhang",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10835",
    "title": "Characterizing Coherent Integrated Photonic Neural Networks under  Imperfections",
    "abstract": "Integrated photonic neural networks (IPNNs) are emerging as promising successors to conventional electronic AI accelerators as they offer substantial improvements in computing speed and energy efficiency. In particular, coherent IPNNs use arrays of Mach-Zehnder interferometers (MZIs) for unitary transformations to perform energy-efficient matrix-vector multiplication. However, the underlying MZI devices in IPNNs are susceptible to uncertainties stemming from optical lithographic variations and thermal crosstalk and can experience imprecisions due to non-uniform MZI insertion loss and quantization errors due to low-precision encoding in the tuned phase angles. In this paper, we, for the first time, systematically characterize the impact of such uncertainties and imprecisions (together referred to as imperfections) in IPNNs using a bottom-up approach. We show that their impact on IPNN accuracy can vary widely based on the tuned parameters (e.g., phase angles) of the affected components, their physical location, and the nature and distribution of the imperfections. To improve reliability measures, we identify critical IPNN building blocks that, under imperfections, can lead to catastrophic degradation in the classification accuracy. We show that under multiple simultaneous imperfections, the IPNN inferencing accuracy can degrade by up to 46%, even when the imperfection parameters are restricted within a small range. Our results also indicate that the inferencing accuracy is sensitive to imperfections affecting the MZIs in the linear layers next to the input layer of the IPNN. ",
    "url": "https://arxiv.org/abs/2207.10835",
    "authors": [
      "Sanmitra Banerjee",
      "Mahdi Nikdast",
      "Krishnendu Chakrabarty"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.10836",
    "title": "Soft-input, soft-output joint detection and GRAND",
    "abstract": "Guessing random additive noise decoding (GRAND) is a maximum likelihood (ML) decoding method that identifies the noise effects corrupting code-words of arbitrary code-books. In a joint detection and decoding framework, this work demonstrates how GRAND can leverage crude soft information in received symbols and channel state information to generate, through guesswork, soft bit reliability outputs in log-likelihood ratios (LLRs). The LLRs are generated via successive computations of Euclidean-distance metrics corresponding to candidate noise-recovered words. Noting that the entropy of noise is much smaller than that of information bits, a small number of noise effect guesses generally suffices to hit a code-word, which allows generating LLRs for critical bits; LLR saturation is applied to the remaining bits. In an iterative (turbo) mode, the generated LLRs at a given soft-input, soft-output GRAND iteration serve as enhanced a priori information that adapts noise-sequence guess ordering in a subsequent iteration. Simulations demonstrate that a few turbo-GRAND iterations match the performance of ML-detection-based soft-GRAND in both AWGN and Rayleigh fading channels at a complexity cost that, on average, grows linearly (instead of exponentially) with the number of symbols. ",
    "url": "https://arxiv.org/abs/2207.10836",
    "authors": [
      "Hadi Sarieddeen",
      "Muriel M\u00e9dard",
      "Ken. R. Duffy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2207.10839",
    "title": "Robust Knowledge Adaptation for Dynamic Graph Neural Networks",
    "abstract": "Graph structured data often possess dynamic characters in nature, e.g., the addition of links and nodes, in many real-world applications. Recent years have witnessed the increasing attentions paid to dynamic graph neural networks for modelling such graph data, where almost all the existing approaches assume that when a new link is built, the embeddings of the neighbor nodes should be updated by learning the temporal dynamics to propagate new information. However, such approaches suffer from the limitation that if the node introduced by a new connection contains noisy information, propagating its knowledge to other nodes is not reliable and even leads to the collapse of the model. In this paper, we propose AdaNet: a robust knowledge Adaptation framework via reinforcement learning for dynamic graph neural Networks. In contrast to previous approaches immediately updating the embeddings of the neighbor nodes once adding a new link, AdaNet attempts to adaptively determine which nodes should be updated because of the new link involved. Considering that the decision whether to update the embedding of one neighbor node will have great impact on other neighbor nodes, we thus formulate the selection of node update as a sequence decision problem, and address this problem via reinforcement learning. By this means, we can adaptively propagate knowledge to other nodes for learning robust node embedding representations. To the best of our knowledge, our approach constitutes the first attempt to explore robust knowledge adaptation via reinforcement learning for dynamic graph neural networks. Extensive experiments on three benchmark datasets demonstrate that AdaNet achieves the state-of-the-art performance. In addition, we perform the experiments by adding different degrees of noise into the dataset, quantitatively and qualitatively illustrating the robustness of AdaNet. ",
    "url": "https://arxiv.org/abs/2207.10839",
    "authors": [
      "Hanjie Li",
      "Changsheng Li",
      "Kaituo Feng",
      "Ye Yuan",
      "Guoren Wang",
      "Hongyuan Zha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10840",
    "title": "Robust and Safe Autonomous Navigation for Systems with Learned SE(3)  Hamiltonian Dynamics",
    "abstract": "Stability and safety are critical properties for successful deployment of automatic control systems. As a motivating example, consider autonomous mobile robot navigation in a complex environment. A control design that generalizes to different operational conditions requires a model of the system dynamics, robustness to modeling errors, and satisfaction of safety \\NEWZL{constraints}, such as collision avoidance. This paper develops a neural ordinary differential equation network to learn the dynamics of a Hamiltonian system from trajectory data. The learned Hamiltonian model is used to synthesize an energy-shaping passivity-based controller and analyze its \\emph{robustness} to uncertainty in the learned model and its \\emph{safety} with respect to constraints imposed by the environment. Given a desired reference path for the system, we extend our design using a virtual reference governor to achieve tracking control. The governor state serves as a regulation point that moves along the reference path adaptively, balancing the system energy level, model uncertainty bounds, and distance to safety violation to guarantee robustness and safety. Our Hamiltonian dynamics learning and tracking control techniques are demonstrated on \\Revised{simulated hexarotor and quadrotor robots} navigating in cluttered 3D environments. ",
    "url": "https://arxiv.org/abs/2207.10840",
    "authors": [
      "Zhichao Li",
      "Thai Duong",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.10849",
    "title": "ASR Error Detection via Audio-Transcript entailment",
    "abstract": "Despite improved performances of the latest Automatic Speech Recognition (ASR) systems, transcription errors are still unavoidable. These errors can have a considerable impact in critical domains such as healthcare, when used to help with clinical documentation. Therefore, detecting ASR errors is a critical first step in preventing further error propagation to downstream applications. To this end, we propose a novel end-to-end approach for ASR error detection using audio-transcript entailment. To the best of our knowledge, we are the first to frame this problem as an end-to-end entailment task between the audio segment and its corresponding transcript segment. Our intuition is that there should be a bidirectional entailment between audio and transcript when there is no recognition error and vice versa. The proposed model utilizes an acoustic encoder and a linguistic encoder to model the speech and transcript respectively. The encoded representations of both modalities are fused to predict the entailment. Since doctor-patient conversations are used in our experiments, a particular emphasis is placed on medical terms. Our proposed model achieves classification error rates (CER) of 26.2% on all transcription errors and 23% on medical errors specifically, leading to improvements upon a strong baseline by 12% and 15.4%, respectively. ",
    "url": "https://arxiv.org/abs/2207.10849",
    "authors": [
      "Nimshi Venkat Meripo",
      "Sandeep Konam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.10851",
    "title": "Uncertainty-aware Multi-modal Learning via Cross-modal Random Network  Prediction",
    "abstract": "Multi-modal learning focuses on training models by equally combining multiple input data modalities during the prediction process. However, this equal combination can be detrimental to the prediction accuracy because different modalities are usually accompanied by varying levels of uncertainty. Using such uncertainty to combine modalities has been studied by a couple of approaches, but with limited success because these approaches are either designed to deal with specific classification or segmentation problems and cannot be easily translated into other tasks, or suffer from numerical instabilities. In this paper, we propose a new Uncertainty-aware Multi-modal Learner that estimates uncertainty by measuring feature density via Cross-modal Random Network Prediction (CRNP). CRNP is designed to require little adaptation to translate between different prediction tasks, while having a stable training process. From a technical point of view, CRNP is the first approach to explore random network prediction to estimate uncertainty and to combine multi-modal data. Experiments on two 3D multi-modal medical image segmentation tasks and three 2D multi-modal computer vision classification tasks show the effectiveness, adaptability and robustness of CRNP. Also, we provide an extensive discussion on different fusion functions and visualization to validate the proposed model. ",
    "url": "https://arxiv.org/abs/2207.10851",
    "authors": [
      "Hu Wang",
      "Jianpeng Zhang",
      "Yuanhong Chen",
      "Congbo Ma",
      "Jodie Avery",
      "Louise Hull",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10852",
    "title": "Spatio-Temporal Deformable Attention Network for Video Deblurring",
    "abstract": "The key success factor of the video deblurring methods is to compensate for the blurry pixels of the mid-frame with the sharp pixels of the adjacent video frames. Therefore, mainstream methods align the adjacent frames based on the estimated optical flows and fuse the alignment frames for restoration. However, these methods sometimes generate unsatisfactory results because they rarely consider the blur levels of pixels, which may introduce blurry pixels from video frames. Actually, not all the pixels in the video frames are sharp and beneficial for deblurring. To address this problem, we propose the spatio-temporal deformable attention network (STDANet) for video delurring, which extracts the information of sharp pixels by considering the pixel-wise blur levels of the video frames. Specifically, STDANet is an encoder-decoder network combined with the motion estimator and spatio-temporal deformable attention (STDA) module, where motion estimator predicts coarse optical flows that are used as base offsets to find the corresponding sharp pixels in STDA module. Experimental results indicate that the proposed STDANet performs favorably against state-of-the-art methods on the GoPro, DVD, and BSD datasets. ",
    "url": "https://arxiv.org/abs/2207.10852",
    "authors": [
      "Huicong Zhang",
      "Haozhe Xie",
      "Hongxun Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10862",
    "title": "On Higher Adversarial Susceptibility of Contrastive Self-Supervised  Learning",
    "abstract": "Contrastive self-supervised learning (CSL) has managed to match or surpass the performance of supervised learning in image and video classification. However, it is still largely unknown if the nature of the representation induced by the two learning paradigms is similar. We investigate this under the lens of adversarial robustness. Our analytical treatment of the problem reveals intrinsic higher sensitivity of CSL over supervised learning. It identifies the uniform distribution of data representation over a unit hypersphere in the CSL representation space as the key contributor to this phenomenon. We establish that this increases model sensitivity to input perturbations in the presence of false negatives in the training data. Our finding is supported by extensive experiments for image and video classification using adversarial perturbations and other input corruptions. Building on the insights, we devise strategies that are simple, yet effective in improving model robustness with CSL training. We demonstrate up to 68% reduction in the performance gap between adversarially attacked CSL and its supervised counterpart. Finally, we contribute to robust CSL paradigm by incorporating our findings in adversarial self-supervised learning. We demonstrate an average gain of about 5% over two different state-of-the-art methods in this domain. ",
    "url": "https://arxiv.org/abs/2207.10862",
    "authors": [
      "Rohit Gupta",
      "Naveed Akhtar",
      "Ajmal Mian",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10866",
    "title": "Cost Aggregation with 4D Convolutional Swin Transformer for Few-Shot  Segmentation",
    "abstract": "This paper presents a novel cost aggregation network, called Volumetric Aggregation with Transformers (VAT), for few-shot segmentation. The use of transformers can benefit correlation map aggregation through self-attention over a global receptive field. However, the tokenization of a correlation map for transformer processing can be detrimental, because the discontinuity at token boundaries reduces the local context available near the token edges and decreases inductive bias. To address this problem, we propose a 4D Convolutional Swin Transformer, where a high-dimensional Swin Transformer is preceded by a series of small-kernel convolutions that impart local context to all pixels and introduce convolutional inductive bias. We additionally boost aggregation performance by applying transformers within a pyramidal structure, where aggregation at a coarser level guides aggregation at a finer level. Noise in the transformer output is then filtered in the subsequent decoder with the help of the query's appearance embedding. With this model, a new state-of-the-art is set for all the standard benchmarks in few-shot segmentation. It is shown that VAT attains state-of-the-art performance for semantic correspondence as well, where cost aggregation also plays a central role. ",
    "url": "https://arxiv.org/abs/2207.10866",
    "authors": [
      "Sunghwan Hong",
      "Seokju Cho",
      "Jisu Nam",
      "Stephen Lin",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10868",
    "title": "On the Spatial Pattern of Input-Output Metrics for a Network  Synchronization Process",
    "abstract": "A graph-theoretic analysis is undertaken for a compendium of input-output (transfer) metrics of a standard discrete-time linear synchronization model, including lp gains, frequency responses, frequency-band energy, and Markov parameters. We show that these transfer metrics exhibit a spatial degradation, such that they are monotonically nonincreasing along vertex cutsets away from an exogenous input. We use this spatial analysis to characterize signal-to-noise ratios (SNRs) in diffusive networks driven by process noise, and to develop a notion of propagation stability for dynamical networks. Finally, the formal results are illustrated through an example. ",
    "url": "https://arxiv.org/abs/2207.10868",
    "authors": [
      "Subir Sarker",
      "Sandip Roy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.10872",
    "title": "Assessing mortality prediction through different representation models  based on concepts extracted from clinical notes",
    "abstract": "Recent years have seen particular interest in using electronic medical records (EMRs) for secondary purposes to enhance the quality and safety of healthcare delivery. EMRs tend to contain large amounts of valuable clinical notes. Learning of embedding is a method for converting notes into a format that makes them comparable. Transformer-based representation models have recently made a great leap forward. These models are pre-trained on large online datasets to understand natural language texts effectively. The quality of a learning embedding is influenced by how clinical notes are used as input to representation models. A clinical note has several sections with different levels of information value. It is also common for healthcare providers to use different expressions for the same concept. Existing methods use clinical notes directly or with an initial preprocessing as input to representation models. However, to learn a good embedding, we identified the most essential clinical notes section. We then mapped the extracted concepts from selected sections to the standard names in the Unified Medical Language System (UMLS). We used the standard phrases corresponding to the unique concepts as input for clinical models. We performed experiments to measure the usefulness of the learned embedding vectors in the task of hospital mortality prediction on a subset of the publicly available Medical Information Mart for Intensive Care (MIMIC-III) dataset. According to the experiments, clinical transformer-based representation models produced better results with getting input generated by standard names of extracted unique concepts compared to other input formats. The best-performing models were BioBERT, PubMedBERT, and UmlsBERT, respectively. ",
    "url": "https://arxiv.org/abs/2207.10872",
    "authors": [
      "Hoda Memarzadeh",
      "Nasser Ghadiri",
      "Maryam Lotfi Shahreza"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10887",
    "title": "Geolocated Social Media Posts are Happier: Understanding the  Characteristics of Check-in Posts on Twitter",
    "abstract": "The increasing prevalence of location-sharing features on social media has enabled researchers to ground computational social science research using geolocated data, affording opportunities to study human mobility, the impact of real-world events, and more. This paper analyzes what crucially separates posts with geotags from those without. We find that users who share location are not representative of the social media user population at large, jeopardizing the generalizability of research that uses only geolocated data.We consider three aspects: affect -- sentiment and emotions, content -- textual and non-textual, and audience engagement. By comparing a dataset of 1.3 million geotagged tweets with a random dataset of the same size, we show that geotagged posts on Twitter exhibit significantly more positivity, are often about joyous and special events such as weddings or graduations, convey more collectivism rather than individualism, and contain more additional features such as hashtags or objects in images, but at the same time generate substantially less engagement. These findings suggest there exist significant differences in the messages conveyed in geotagged posts. Our research carries important implications for future research utilizing geolocation social media data. ",
    "url": "https://arxiv.org/abs/2207.10887",
    "authors": [
      "Julie Jiang",
      "Jesse Thomason",
      "Francesco Barbieri",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.10896",
    "title": "Privacy and Transparency in Graph Machine Learning: A Unified  Perspective",
    "abstract": "Graph Machine Learning (GraphML), whereby classical machine learning is generalized to irregular graph domains, has enjoyed a recent renaissance, leading to a dizzying array of models and their applications in several domains. With its growing applicability to sensitive domains and regulations by government agencies for trustworthy AI systems, researchers have started looking into the issues of transparency and privacy of graph learning. However, these topics have been mainly investigated independently. In this position paper, we provide a unified perspective on the interplay of privacy and transparency in GraphML. ",
    "url": "https://arxiv.org/abs/2207.10896",
    "authors": [
      "Megha Khosla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.10899",
    "title": "Decoupled Adversarial Contrastive Learning for Self-supervised  Adversarial Robustness",
    "abstract": "Adversarial training (AT) for robust representation learning and self-supervised learning (SSL) for unsupervised representation learning are two active research fields. Integrating AT into SSL, multiple prior works have accomplished a highly significant yet challenging task: learning robust representation without labels. A widely used framework is adversarial contrastive learning which couples AT and SSL, and thus constitute a very complex optimization problem. Inspired by the divide-and-conquer philosophy, we conjecture that it might be simplified as well as improved by solving two sub-problems: non-robust SSL and pseudo-supervised AT. This motivation shifts the focus of the task from seeking an optimal integrating strategy for a coupled problem to finding sub-solutions for sub-problems. With this said, this work discards prior practices of directly introducing AT to SSL frameworks and proposed a two-stage framework termed Decoupled Adversarial Contrastive Learning (DeACL). Extensive experimental results demonstrate that our DeACL achieves SOTA self-supervised adversarial robustness while significantly reducing the training time, which validates its effectiveness and efficiency. Moreover, our DeACL constitutes a more explainable solution, and its success also bridges the gap with semi-supervised AT for exploiting unlabeled samples for robust representation learning. The code is publicly accessible at https://github.com/pantheon5100/DeACL. ",
    "url": "https://arxiv.org/abs/2207.10899",
    "authors": [
      "Chaoning Zhang",
      "Kang Zhang",
      "Chenshuang Zhang",
      "Axi Niu",
      "Jiu Feng",
      "Chang D. Yoo",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10909",
    "title": "DBQ-SSD: Dynamic Ball Query for Efficient 3D Object Detection",
    "abstract": "Many point-based 3D detectors adopt point-feature sampling strategies to drop some points for efficient inference. These strategies are typically based on fixed and handcrafted rules, making difficult to handle complicated scenes. Different from them, we propose a Dynamic Ball Query (DBQ) network to adaptively select a subset of input points according to the input features, and assign the feature transform with suitable receptive field for each selected point. It can be embedded into some state-of-the-art 3D detectors and trained in an end-to-end manner, which significantly reduces the computational cost. Extensive experiments demonstrate that our method can reduce latency by 30%-60% on KITTI and Waymo datasets. Specifically, the inference speed of our detector can reach 162 FPS and 30 FPS with negligible performance degradation on KITTI and Waymo datasets, respectively. ",
    "url": "https://arxiv.org/abs/2207.10909",
    "authors": [
      "Jinrong Yang",
      "Lin Song",
      "Songtao Liu",
      "Zeming Li",
      "Xiaoping Li",
      "Hongbin Sun",
      "Jian Sun",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10937",
    "title": "Physics-informed convolutional neural network with bicubic spline  interpolation for sound field estimation",
    "abstract": "A sound field estimation method based on a physics-informed convolutional neural network (PICNN) using spline interpolation is proposed. Most of the sound field estimation methods are based on wavefunction expansion, making the estimated function satisfy the Helmholtz equation. However, these methods rely only on physical properties; thus, they suffer from a significant deterioration of accuracy when the number of measurements is small. Recent learning-based methods based on neural networks have advantages in estimating from sparse measurements when training data are available. However, since physical properties are not taken into consideration, the estimated function can be a physically infeasible solution. We propose the application of PICNN to the sound field estimation problem by using a loss function that penalizes deviation from the Helmholtz equation. Since the output of CNN is a spatially discretized pressure distribution, it is difficult to directly evaluate the Helmholtz-equation loss function. Therefore, we incorporate bicubic spline interpolation in the PICNN framework. Experimental results indicated that accurate and physically feasible estimation from sparse measurements can be achieved with the proposed method. ",
    "url": "https://arxiv.org/abs/2207.10937",
    "authors": [
      "Kazuhide Shigemi",
      "Shoichi Koyama",
      "Tomohiko Nakamura",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.10942",
    "title": "Efficient Testing of Deep Neural Networks via Decision Boundary Analysis",
    "abstract": "Deep learning plays a more and more important role in our daily life due to its competitive performance in multiple industrial application domains. As the core of DL-enabled systems, deep neural networks automatically learn knowledge from carefully collected and organized training data to gain the ability to predict the label of unseen data. Similar to the traditional software systems that need to be comprehensively tested, DNNs also need to be carefully evaluated to make sure the quality of the trained model meets the demand. In practice, the de facto standard to assess the quality of DNNs in industry is to check their performance (accuracy) on a collected set of labeled test data. However, preparing such labeled data is often not easy partly because of the huge labeling effort, i.e., data labeling is labor-intensive, especially with the massive new incoming unlabeled data every day. Recent studies show that test selection for DNN is a promising direction that tackles this issue by selecting minimal representative data to label and using these data to assess the model. However, it still requires human effort and cannot be automatic. In this paper, we propose a novel technique, named Aries, that can estimate the performance of DNNs on new unlabeled data using only the information obtained from the original test data. The key insight behind our technique is that the model should have similar prediction accuracy on the data which have similar distances to the decision boundary. We performed a large-scale evaluation of our technique on 13 types of data transformation methods. The results demonstrate the usefulness of our technique that the estimated accuracy by Aries is only 0.03% -- 2.60% (on average 0.61%) off the true accuracy. Besides, Aries also outperforms the state-of-the-art selection-labeling-based methods in most (96 out of 128) cases. ",
    "url": "https://arxiv.org/abs/2207.10942",
    "authors": [
      "Qiang Hu",
      "Yuejun Guo",
      "Xiaofei Xie",
      "Maxime Cordy",
      "Lei Ma",
      "Mike Papadakis",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.10948",
    "title": "Dynamic Local Aggregation Network with Adaptive Clusterer for Anomaly  Detection",
    "abstract": "Existing methods for anomaly detection based on memory-augmented autoencoder (AE) have the following drawbacks: (1) Establishing a memory bank requires additional memory space. (2) The fixed number of prototypes from subjective assumptions ignores the data feature differences and diversity. To overcome these drawbacks, we introduce DLAN-AC, a Dynamic Local Aggregation Network with Adaptive Clusterer, for anomaly detection. First, The proposed DLAN can automatically learn and aggregate high-level features from the AE to obtain more representative prototypes, while freeing up extra memory space. Second, The proposed AC can adaptively cluster video data to derive initial prototypes with prior information. In addition, we also propose a dynamic redundant clustering strategy (DRCS) to enable DLAN for automatically eliminating feature clusters that do not contribute to the construction of prototypes. Extensive experiments on benchmarks demonstrate that DLAN-AC outperforms most existing methods, validating the effectiveness of our method. Our code is publicly available at https://github.com/Beyond-Zw/DLAN-AC. ",
    "url": "https://arxiv.org/abs/2207.10948",
    "authors": [
      "Zhiwei Yang",
      "Peng Wu",
      "Jing Liu",
      "Xiaotao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10949",
    "title": "Maximizing Nash Social Welfare in 2-Value Instances: The Half-Integer  Case",
    "abstract": "We consider the problem of maximizing the Nash social welfare when allocating a set $G$ of indivisible goods to a set $N$ of agents. We study instances, in which all agents have 2-value additive valuations: The value of a good $g \\in G$ for an agent $i \\in N$ is either $1$ or $s$, where $s$ is an odd multiple of $\\frac{1}{2}$ larger than one. We show that the problem is solvable in polynomial time. Akrami et at. showed that this problem is solvable in polynomial time if $s$ is integral and is NP-hard whenever $s = \\frac{p}{q}$, $p \\in \\mathbb{N}$ and $q\\in \\mathbb{N}$ are co-prime and $p > q \\ge 3$. For the latter situation, an approximation algorithm was also given. It obtains an approximation ratio of at most $1.0345$. Moreover, the problem is APX-hard, with a lower bound of $1.000015$ achieved at $\\frac{p}{q} = \\frac{5}{4}$. The case $q = 2$ and odd $p$ was left open. In the case of integral $s$, the problem is separable in the sense that the optimal allocation of the heavy goods (= value $s$ for some agent) is independent of the number of light goods (= value $1$ for all agents). This leads to an algorithm that first computes an optimal allocation of the heavy goods and then adds the light goods greedily. This separation no longer holds for $s = \\frac{3}{2}$; a simple example is given in the introduction. Thus an algorithm has to consider heavy and light goods together. This complicates matters considerably. Our algorithm is based on a collection of improvement rules that transfers any allocation into an optimal allocation and exploits a connection to matchings with parity constraints. ",
    "url": "https://arxiv.org/abs/2207.10949",
    "authors": [
      "Hannaneh Akrami",
      "Bhaskar Ray Chaudhury",
      "Martin Hoefer",
      "Kurt Mehlhorn",
      "Marco Schmalhofer",
      "Golnoosh Shahkarami",
      "Giovanna Varricchio",
      "Quentin Vermande",
      "Ernest van Wijland"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2207.10950",
    "title": "Scale dependant layer for self-supervised nuclei encoding",
    "abstract": "Recent developments in self-supervised learning give us the possibility to further reduce human intervention in multi-step pipelines where the focus evolves around particular objects of interest. In the present paper, the focus lays in the nuclei in histopathology images. In particular we aim at extracting cellular information in an unsupervised manner for a downstream task. As nuclei present themselves in a variety of sizes, we propose a new Scale-dependant convolutional layer to bypass scaling issues when resizing nuclei. On three nuclei datasets, we benchmark the following methods: handcrafted, pre-trained ResNet, supervised ResNet and self-supervised features. We show that the proposed convolution layer boosts performance and that this layer combined with Barlows-Twins allows for better nuclei encoding compared to the supervised paradigm in the low sample setting and outperforms all other proposed unsupervised methods. In addition, we extend the existing TNBC dataset to incorporate nuclei class annotation in order to enrich and publicly release a small sample setting dataset for nuclei segmentation and classification. ",
    "url": "https://arxiv.org/abs/2207.10950",
    "authors": [
      "Peter Naylor",
      "Yao-Hung Hubert Tsai",
      "Marick La\u00e9",
      "Makoto Yamada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10952",
    "title": "Vision-based Human Fall Detection Systems using Deep Learning: A Review",
    "abstract": "Human fall is one of the very critical health issues, especially for elders and disabled people living alone. The number of elder populations is increasing steadily worldwide. Therefore, human fall detection is becoming an effective technique for assistive living for those people. For assistive living, deep learning and computer vision have been used largely. In this review article, we discuss deep learning (DL)-based state-of-the-art non-intrusive (vision-based) fall detection techniques. We also present a survey on fall detection benchmark datasets. For a clear understanding, we briefly discuss different metrics which are used to evaluate the performance of the fall detection systems. This article also gives a future direction on vision-based human fall detection techniques. ",
    "url": "https://arxiv.org/abs/2207.10952",
    "authors": [
      "Ekram Alam",
      "Abu Sufian",
      "Paramartha Dutta",
      "Marco Leo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.10959",
    "title": "QueryProp: Object Query Propagation for High-Performance Video Object  Detection",
    "abstract": "Video object detection has been an important yet challenging topic in computer vision. Traditional methods mainly focus on designing the image-level or box-level feature propagation strategies to exploit temporal information. This paper argues that with a more effective and efficient feature propagation framework, video object detectors can gain improvement in terms of both accuracy and speed. For this purpose, this paper studies object-level feature propagation, and proposes an object query propagation (QueryProp) framework for high-performance video object detection. The proposed QueryProp contains two propagation strategies: 1) query propagation is performed from sparse key frames to dense non-key frames to reduce the redundant computation on non-key frames; 2) query propagation is performed from previous key frames to the current key frame to improve feature representation by temporal context modeling. To further facilitate query propagation, an adaptive propagation gate is designed to achieve flexible key frame selection. We conduct extensive experiments on the ImageNet VID dataset. QueryProp achieves comparable accuracy with state-of-the-art methods and strikes a decent accuracy/speed trade-off. Code is available at https://github.com/hf1995/QueryProp. ",
    "url": "https://arxiv.org/abs/2207.10959",
    "authors": [
      "Fei He",
      "Naiyu Gao",
      "Jian Jia",
      "Xin Zhao",
      "Kaiqi Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10970",
    "title": "Opportunistic hip fracture risk prediction in Men from X-ray: Findings  from the Osteoporosis in Men (MrOS) Study",
    "abstract": "Osteoporosis is a common disease that increases fracture risk. Hip fractures, especially in elderly people, lead to increased morbidity, decreased quality of life and increased mortality. Being a silent disease before fracture, osteoporosis often remains undiagnosed and untreated. Areal bone mineral density (aBMD) assessed by dual-energy X-ray absorptiometry (DXA) is the gold-standard method for osteoporosis diagnosis and hence also for future fracture prediction (prognostic). However, the required special equipment is not broadly available everywhere, in particular not to patients in developing countries. We propose a deep learning classification model (FORM) that can directly predict hip fracture risk from either plain radiographs (X-ray) or 2D projection images of computed tomography (CT) data. Our method is fully automated and therefore well suited for opportunistic screening settings, identifying high risk patients in a broader population without additional screening. FORM was trained and evaluated on X-rays and CT projections from the Osteoporosis in Men (MrOS) study. 3108 X-rays (89 incident hip fractures) or 2150 CTs (80 incident hip fractures) with a 80/20 split were used. We show that FORM can correctly predict the 10-year hip fracture risk with a validation AUC of 81.44 +- 3.11% / 81.04 +- 5.54% (mean +- STD) including additional information like age, BMI, fall history and health background across a 5-fold cross validation on the X-ray and CT cohort, respectively. Our approach significantly (p < 0.01) outperforms previous methods like Cox Proportional-Hazards Model and \\frax with 70.19 +- 6.58 and 74.72 +- 7.21 respectively on the X-ray cohort. Our model outperform on both cohorts hip aBMD based predictions. We are confident that FORM can contribute on improving osteoporosis diagnosis at an early stage. ",
    "url": "https://arxiv.org/abs/2207.10970",
    "authors": [
      "Lars Schmarje",
      "Stefan Reinhold",
      "Timo Damm",
      "Eric Orwoll",
      "Claus-C. Gl\u00fcer",
      "Reinhard Koch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10985",
    "title": "NeurAR: Neural Uncertainty for Autonomous 3D Reconstruction",
    "abstract": "Implicit neural representations have shown compelling results in offline 3D reconstruction and also recently demonstrated the potential for online SLAM systems. However, applying them to autonomous 3D reconstruction, where robots are required to explore a scene and plan a view path for the reconstruction, has not been studied. In this paper, we explore for the first time the possibility of using implicit neural representations for autonomous 3D scene reconstruction by addressing two key challenges: 1) seeking a criterion to measure the quality of the candidate viewpoints for the view planning based on the new representations, and 2) learning the criterion from data that can generalize to different scenes instead of hand-crafting one. For the first challenge, a proxy of Peak Signal-to-Noise Ratio (PSNR) is proposed to quantify a viewpoint quality. The proxy is acquired by treating the color of a spatial point in a scene as a random variable under a Gaussian distribution rather than a deterministic one; the variance of the distribution quantifies the uncertainty of the reconstruction and composes the proxy. For the second challenge, the proxy is optimized jointly with the parameters of an implicit neural network for the scene. With the proposed view quality criterion, we can then apply the new representations to autonomous 3D reconstruction. Our method demonstrates significant improvements on various metrics for the rendered image quality and the geometry quality of the reconstructed 3D models when compared with variants using TSDF or reconstruction without view planning. ",
    "url": "https://arxiv.org/abs/2207.10985",
    "authors": [
      "Yunlong Ran",
      "Jing Zeng",
      "Shibo He",
      "Lincheng Li",
      "Yingfeng Chen",
      "Gimhee Lee",
      "Jiming Chen",
      "Qi Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10988",
    "title": "Few-shot Object Counting and Detection",
    "abstract": "We tackle a new task of few-shot object counting and detection. Given a few exemplar bounding boxes of a target object class, we seek to count and detect all objects of the target class. This task shares the same supervision as the few-shot object counting but additionally outputs the object bounding boxes along with the total object count. To address this challenging problem, we introduce a novel two-stage training strategy and a novel uncertainty-aware few-shot object detector: Counting-DETR. The former is aimed at generating pseudo ground-truth bounding boxes to train the latter. The latter leverages the pseudo ground-truth provided by the former but takes the necessary steps to account for the imperfection of pseudo ground-truth. To validate the performance of our method on the new task, we introduce two new datasets named FSCD-147 and FSCD-LVIS. Both datasets contain images with complex scenes, multiple object classes per image, and a huge variation in object shapes, sizes, and appearance. Our proposed approach outperforms very strong baselines adapted from few-shot object counting and few-shot object detection with a large margin in both counting and detection metrics. The code and models are available at \\url{https://github.com/VinAIResearch/Counting-DETR}. ",
    "url": "https://arxiv.org/abs/2207.10988",
    "authors": [
      "Thanh Nguyen",
      "Chau Pham",
      "Khoi Nguyen",
      "Minh Hoai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10992",
    "title": "Taguchi based Design of Sequential Convolution Neural Network for  Classification of Defective Fasteners",
    "abstract": "Fasteners play a critical role in securing various parts of machinery. Deformations such as dents, cracks, and scratches on the surface of fasteners are caused by material properties and incorrect handling of equipment during production processes. As a result, quality control is required to ensure safe and reliable operations. The existing defect inspection method relies on manual examination, which consumes a significant amount of time, money, and other resources; also, accuracy cannot be guaranteed due to human error. Automatic defect detection systems have proven impactful over the manual inspection technique for defect analysis. However, computational techniques such as convolutional neural networks (CNN) and deep learning-based approaches are evolutionary methods. By carefully selecting the design parameter values, the full potential of CNN can be realised. Using Taguchi-based design of experiments and analysis, an attempt has been made to develop a robust automatic system in this study. The dataset used to train the system has been created manually for M14 size nuts having two labeled classes: Defective and Non-defective. There are a total of 264 images in the dataset. The proposed sequential CNN comes up with a 96.3% validation accuracy, 0.277 validation loss at 0.001 learning rate. ",
    "url": "https://arxiv.org/abs/2207.10992",
    "authors": [
      "Manjeet Kaur",
      "Krishan Kumar Chauhan",
      "Tanya Aggarwal",
      "Pushkar Bharadwaj",
      "Renu Vig",
      "Isibor Kennedy Ihianle",
      "Garima Joshi",
      "Kayode Owa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.10999",
    "title": "Applying Machine Learning on RSRP-based Features for False Base Station  Detection",
    "abstract": "False base stations -- IMSI catchers, Stingrays -- are devices that impersonate legitimate base stations, as a part of malicious activities like unauthorized surveillance or communication sabotage. Detecting them on the network side using 3GPP standardized measurement reports is a promising technique. While applying predetermined detection rules works well when an attacker operates a false base station with an illegitimate Physical Cell Identifiers (PCI), the detection will produce false negatives when a more resourceful attacker operates the false base station with one of the legitimate PCIs obtained by scanning the neighborhood first. In this paper, we show how Machine Learning (ML) can be applied to alleviate such false negatives. We demonstrate our approach by conducting experiments in a simulation setup using the ns-3 LTE module. We propose three robust ML features (COL, DIST, XY) based on Reference Signal Received Power (RSRP) contained in measurement reports and cell locations. We evaluate four ML models (Regression Clustering, Anomaly Detection Forest, Autoencoder, and RCGAN) and show that several of them have a high precision in detection even when the false base station is using a legitimate PCI. In our experiments with a layout of 12 cells, where one cell acts as a moving false cell, between 75-95\\% of the false positions are detected by the best model at a cost of 0.5\\% false positives. ",
    "url": "https://arxiv.org/abs/2207.10999",
    "authors": [
      "Prajwol Kumar Nakarmi",
      "Jakob Sternby",
      "Ikram Ullah"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.11001",
    "title": "POP: Mining POtential Performance of new fashion products via webly  cross-modal query expansion",
    "abstract": "We propose a data-centric pipeline able to generate exogenous observation data for the New Fashion Product Performance Forecasting (NFPPF) problem, i.e., predicting the performance of a brand-new clothing probe with no available past observations. Our pipeline manufactures the missing past starting from a single, available image of the clothing probe. It starts by expanding textual tags associated with the image, querying related fashionable or unfashionable images uploaded on the web at a specific time in the past. A binary classifier is robustly trained on these web images by confident learning, to learn what was fashionable in the past and how much the probe image conforms to this notion of fashionability. This compliance produces the POtential Performance (POP) time series, indicating how performing the probe could have been if it were available earlier. POP proves to be highly predictive for the probe's future performance, ameliorating the sales forecasts of all state-of-the-art models on the recent VISUELLE fast-fashion dataset. We also show that POP reflects the ground-truth popularity of new styles (ensembles of clothing items) on the Fashion Forward benchmark, demonstrating that our webly-learned signal is a truthful expression of popularity, accessible by everyone and generalizable to any time of analysis. Forecasting code, data and the POP time series are available at: https://github.com/HumaticsLAB/POP-Mining-POtential-Performance ",
    "url": "https://arxiv.org/abs/2207.11001",
    "authors": [
      "Christian Joppi",
      "Geri Skenderi",
      "Marco Cristani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11005",
    "title": "Revisiting Parameter Reuse to Overcome Catastrophic Forgetting in Neural  Networks",
    "abstract": "Neural networks tend to forget previously learned knowledge when continuously learning on datasets with varying distributions, a phenomenon known as catastrophic forgetting. More significant distribution shifts among datasets lead to more forgetting. Recently, parameter-isolation-based approaches have shown great potential in overcoming forgetting with significant distribution shifts. However, they suffer from poor generalization as they fix the neural path for each dataset during training and require dataset labels during inference. In addition, they do not support backward knowledge transfer as they prioritize past data over future ones. In this paper, we propose a new adaptive learning method, named AdaptCL, that fully reuses and grows on learned parameters to overcome catastrophic forgetting and allows the positive backward transfer without requiring dataset labels. Our proposed technique adaptively grows on the same neural path by allowing optimal reuse of frozen parameters. Besides, it uses parameter-level data-driven pruning to assign equal priority to the data. We conduct extensive experiments on MNIST Variants, DomainNet, and Food Freshness Detection datasets under different intensities of distribution shifts without requiring dataset labels. Results demonstrate that our proposed method is superior to alternative baselines in minimizing forgetting and enabling positive backward knowledge transfer. ",
    "url": "https://arxiv.org/abs/2207.11005",
    "authors": [
      "Yuqing Zhao",
      "Divya Saxena",
      "Jiannong Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11007",
    "title": "Gradual Drift Detection in Process Models Using Conformance Metrics",
    "abstract": "Changes, planned or unexpected, are common during the execution of real-life processes. Detecting these changes is a must for optimizing the performance of organizations running such processes. Most of the algorithms present in the state-of-the-art focus on the detection of sudden changes, leaving aside other types of changes. In this paper, we will focus on the automatic detection of gradual drifts, a special type of change, in which the cases of two models overlap during a period of time. The proposed algorithm relies on conformance checking metrics to carry out the automatic detection of the changes, performing also a fully automatic classification of these changes into sudden or gradual. The approach has been validated with a synthetic dataset consisting of 120 logs with different distributions of changes, getting better results in terms of detection and classification accuracy, delay and change region overlapping than the main state-of-the-art algorithms. ",
    "url": "https://arxiv.org/abs/2207.11007",
    "authors": [
      "Victor Gallego-Fontenla",
      "Juan C. Vidal",
      "Manuel Lama"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.11018",
    "title": "Learning from what we know: How to perform vulnerability prediction  using noisy historical data",
    "abstract": "Vulnerability prediction refers to the problem of identifying system components that are most likely to be vulnerable. Typically, this problem is tackled by training binary classifiers on historical data. Unfortunately, recent research has shown that such approaches underperform due to the following two reasons: a) the imbalanced nature of the problem, and b) the inherently noisy historical data, i.e., most vulnerabilities are discovered much later than they are introduced. This misleads classifiers as they learn to recognize actual vulnerable components as non-vulnerable. To tackle these issues, we propose TROVON, a technique that learns from known vulnerable components rather than from vulnerable and non-vulnerable components, as typically performed. We perform this by contrasting the known vulnerable, and their respective fixed components. This way, TROVON manages to learn from the things we know, i.e., vulnerabilities, hence reducing the effects of noisy and unbalanced data. We evaluate TROVON by comparing it with existing techniques on three security-critical open source systems, i.e., Linux Kernel, OpenSSL, and Wireshark, with historical vulnerabilities that have been reported in the National Vulnerability Database (NVD). Our evaluation demonstrates that the prediction capability of TROVON significantly outperforms existing vulnerability prediction techniques such as Software Metrics, Imports, Function Calls, Text Mining, Devign, LSTM, and LSTM-RF with an improvement of 40.84% in Matthews Correlation Coefficient (MCC) score under Clean Training Data Settings, and an improvement of 35.52% under Realistic Training Data Settings. ",
    "url": "https://arxiv.org/abs/2207.11018",
    "authors": [
      "Aayush Garg",
      "Renzo Degiovanni",
      "Matthieu Jimenez",
      "Maxime Cordy",
      "Mike Papadakis",
      "Yves LeTraon"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2207.11030",
    "title": "A Transferable Intersection Reconstruction Network for Traffic Speed  Prediction",
    "abstract": "Traffic speed prediction is the key to many valuable applications, and it is also a challenging task because of its various influencing factors. Recent work attempts to obtain more information through various hybrid models, thereby improving the prediction accuracy. However, the spatial information acquisition schemes of these methods have two-level differentiation problems. Either the modeling is simple but contains little spatial information, or the modeling is complete but lacks flexibility. In order to introduce more spatial information on the basis of ensuring flexibility, this paper proposes IRNet (Transferable Intersection Reconstruction Network). First, this paper reconstructs the intersection into a virtual intersection with the same structure, which simplifies the topology of the road network. Then, the spatial information is subdivided into intersection information and sequence information of traffic flow direction, and spatiotemporal features are obtained through various models. Third, a self-attention mechanism is used to fuse spatiotemporal features for prediction. In the comparison experiment with the baseline, not only the prediction effect, but also the transfer performance has obvious advantages. ",
    "url": "https://arxiv.org/abs/2207.11030",
    "authors": [
      "Pengyu Fu",
      "Liang Chu",
      "Zhuoran Hou",
      "Jincheng Hu",
      "Yanjun Huang",
      "Yuanjian Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11031",
    "title": "MobileDenseNet: A new approach to object detection on mobile devices",
    "abstract": "Object detection problem solving has developed greatly within the past few years. There is a need for lighter models in instances where hardware limitations exist, as well as a demand for models to be tailored to mobile devices. In this article, we will assess the methods used when creating algorithms that address these issues. The main goal of this article is to increase accuracy in state-of-the-art algorithms while maintaining speed and real-time efficiency. The most significant issues in one-stage object detection pertains to small objects and inaccurate localization. As a solution, we created a new network by the name of MobileDenseNet suitable for embedded systems. We also developed a light neck FCPNLite for mobile devices that will aid with the detection of small objects. Our research revealed that very few papers cited necks in embedded systems. What differentiates our network from others is our use of concatenation features. A small yet significant change to the head of the network amplified accuracy without increasing speed or limiting parameters. In short, our focus on the challenging CoCo and Pascal VOC datasets were 24.8 and 76.8 in percentage terms respectively - a rate higher than that recorded by other state-of-the-art systems thus far. Our network is able to increase accuracy while maintaining real-time efficiency on mobile devices. We calculated operational speed on Pixel 3 (Snapdragon 845) to 22.8 fps. The source code of this research is available on https://github.com/hajizadeh/MobileDenseNet. ",
    "url": "https://arxiv.org/abs/2207.11031",
    "authors": [
      "Mohammad Hajizadeh",
      "Mohammad Sabokrou",
      "Adel Rahmani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2207.11033",
    "title": "GesSure -- A Robust Face-Authentication enabled Dynamic Gesture  Recognition GUI Application",
    "abstract": "Using physical interactive devices like mouse and keyboards hinders naturalistic human-machine interaction and increases the probability of surface contact during a pandemic. Existing gesture-recognition systems do not possess user authentication, making them unreliable. Static gestures in current gesture-recognition technology introduce long adaptation periods and reduce user compatibility. Our technology places a strong emphasis on user recognition and safety. We use meaningful and relevant gestures for task operation, resulting in a better user experience. This paper aims to design a robust, face-verification-enabled gesture recognition system that utilizes a graphical user interface and primarily focuses on security through user recognition and authorization. The face model uses MTCNN and FaceNet to verify the user, and our LSTM-CNN architecture for gesture recognition, achieving an accuracy of 95% with five classes of gestures. The prototype developed through our research has successfully executed context-dependent tasks like save, print, control video-player operations and exit, and context-free operating system tasks like sleep, shut-down, and unlock intuitively. Our application and dataset are available as open source. ",
    "url": "https://arxiv.org/abs/2207.11033",
    "authors": [
      "Ankit Jha",
      "Ishita Pratham G. Shenwai",
      "Ayush Batra",
      "Siddharth Kotian",
      "Piyush Modi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11034",
    "title": "Spatial-Temporal Feature Extraction and Evaluation Network for Citywide  Traffic Condition Prediction",
    "abstract": "Traffic prediction plays an important role in the realization of traffic control and scheduling tasks in intelligent transportation systems. With the diversification of data sources, reasonably using rich traffic data to model the complex spatial-temporal dependence and nonlinear characteristics in traffic flow are the key challenge for intelligent transportation system. In addition, clearly evaluating the importance of spatial-temporal features extracted from different data becomes a challenge. A Double Layer - Spatial Temporal Feature Extraction and Evaluation (DL-STFEE) model is proposed. The lower layer of DL-STFEE is spatial-temporal feature extraction layer. The spatial and temporal features in traffic data are extracted by multi-graph graph convolution and attention mechanism, and different combinations of spatial and temporal features are generated. The upper layer of DL-STFEE is the spatial-temporal feature evaluation layer. Through the attention score matrix generated by the high-dimensional self-attention mechanism, the spatial-temporal features combinations are fused and evaluated, so as to get the impact of different combinations on prediction effect. Three sets of experiments are performed on actual traffic datasets to show that DL-STFEE can effectively capture the spatial-temporal features and evaluate the importance of different spatial-temporal feature combinations. ",
    "url": "https://arxiv.org/abs/2207.11034",
    "authors": [
      "Shilin Pu",
      "Liang Chu",
      "Zhuoran Hou",
      "Jincheng Hu",
      "Yanjun Huang",
      "Yuanjian Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11048",
    "title": "Quantized Sparse Weight Decomposition for Neural Network Compression",
    "abstract": "In this paper, we introduce a novel method of neural network weight compression. In our method, we store weight tensors as sparse, quantized matrix factors, whose product is computed on the fly during inference to generate the target model's weights. We use projected gradient descent methods to find quantized and sparse factorization of the weight tensors. We show that this approach can be seen as a unification of weight SVD, vector quantization, and sparse PCA. Combined with end-to-end fine-tuning our method exceeds or is on par with previous state-of-the-art methods in terms of the trade-off between accuracy and model size. Our method is applicable to both moderate compression regimes, unlike vector quantization, and extreme compression regimes. ",
    "url": "https://arxiv.org/abs/2207.11048",
    "authors": [
      "Andrey Kuzmin",
      "Mart van Baalen",
      "Markus Nagel",
      "Arash Behboodi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11057",
    "title": "Efficient Prior Publication Identification for Open Source Code",
    "abstract": "Free/Open Source Software (FOSS) enables large-scale reuse of preexisting software components. The main drawback is increased complexity in software supply chain management. A common approach to tame such complexity is automated open source compliance, which consists in automating the verication of adherence to various open source management best practices about license obligation fulllment, vulnerability tracking, software composition analysis, and nearby concerns.We consider the problem of auditing a source code base to determine which of its parts have been published before, which is an important building block of automated open source compliance toolchains. Indeed, if source code allegedly developed in house is recognized as having been previously published elsewhere, alerts should be raised to investigate where it comes from and whether this entails that additional obligations shall be fullled before product shipment.We propose an ecient approach for prior publication identication that relies on a knowledge base of known source code artifacts linked together in a global Merkle direct acyclic graph and a dedicated discovery protocol. We introduce swh-scanner, a source code scanner that realizes the proposed approach in practice using as knowledge base Software Heritage, the largest public archive of source code artifacts. We validate experimentally the proposed approach, showing its eciency in both abstract (number of queries) and concrete terms (wall-clock time), performing benchmarks on 16 845 real-world public code bases of various sizes, from small to very large. ",
    "url": "https://arxiv.org/abs/2207.11057",
    "authors": [
      "Daniele Serafini",
      "Stefano Zacchiroli"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2207.11088",
    "title": "Layer-refined Graph Convolutional Networks for Recommendation",
    "abstract": "Recommendation models utilizing Graph Convolutional Networks (GCNs) have achieved state-of-the-art performance, as they can integrate both the node information and the topological structure of the user-item interaction graph. However, these GCN-based recommendation models not only suffer from over-smoothing when stacking too many layers but also bear performance degeneration resulting from the existence of noise in user-item interactions. In this paper, we first identify a recommendation dilemma of over-smoothing and solution collapsing in current GCN-based models. Specifically, these models usually aggregate all layer embeddings for node updating and achieve their best recommendation performance within a few layers because of over-smoothing. Conversely, if we place learnable weights on layer embeddings for node updating, the weight space will always collapse to a fixed point, at which the weighting of the ego layer almost holds all. We propose a layer-refined GCN model, dubbed LayerGCN, that refines layer representations during information propagation and node updating of GCN. Moreover, previous GCN-based recommendation models aggregate all incoming information from neighbors without distinguishing the noise nodes, which deteriorates the recommendation performance. Our model further prunes the edges of the user-item interaction graph following a degree-sensitive probability instead of the uniform distribution. Experimental results show that the proposed model outperforms the state-of-the-art models significantly on four public datasets with fast training convergence. The implementation code of the proposed method is available at https://github.com/enoche/ImRec. ",
    "url": "https://arxiv.org/abs/2207.11088",
    "authors": [
      "Xin Zhou",
      "Donghui Lin",
      "Yong Liu",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2207.11104",
    "title": "CARBON: A Counterfactual Reasoning based Framework for Neural Code  Comprehension Debiasing",
    "abstract": "Previous studies have demonstrated that code intelligence models are sensitive to program transformation among which identifier renaming is particularly easy to apply and effective. By simply renaming one identifier in source code, the models would output completely different results. The prior research generally mitigates the problem by generating more training samples. Such an approach is less than ideal since its effectiveness depends on the quantity and quality of the generated samples. Different from these studies, we are devoted to adjusting models for explicitly distinguishing the influence of identifier names on the results, called naming bias in this paper, and thereby making the models robust to identifier renaming. Specifically, we formulate the naming bias with a structural causal model (SCM), and propose a counterfactual reasoning based framework named CARBON for eliminating the naming bias in neural code comprehension. CARBON explicitly captures the naming bias through multi-task learning in the training stage, and reduces the bias by counterfactual inference in the inference stage. We evaluate CARBON on three neural code comprehension tasks, including function naming, defect detection and code classification. Experiment results show that CARBON achieves relatively better performance (e.g., +0.5% on the function naming task at F1 score) than the baseline models on the original benchmark datasets, and significantly improvement (e.g., +37.9% on the function naming task at F1 score) on the datasets with identifiers renamed. The proposed framework provides a causal view for improving the robustness of code intelligence models. ",
    "url": "https://arxiv.org/abs/2207.11104",
    "authors": [
      "Shuzheng Gao",
      "Cuiyun Gao",
      "Chaozheng Wang",
      "Jun Sun",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2207.11117",
    "title": "Near Real-Time Distributed State Estimation via AI/ML-Empowered 5G  Networks",
    "abstract": "Fifth-Generation (5G) networks have a potential to accelerate power system transition to a flexible, softwarized, data-driven, and intelligent grid. With their evolving support for Machine Learning (ML)/Artificial Intelligence (AI) functions, 5G networks are expected to enable novel data-centric Smart Grid (SG) services. In this paper, we explore how data-driven SG services could be integrated with ML/AI-enabled 5G networks in a symbiotic relationship. We focus on the State Estimation (SE) function as a key element of the energy management system and focus on two main questions. Firstly, in a tutorial fashion, we present an overview on how distributed SE can be integrated with the elements of the 5G core network and radio access network architecture. Secondly, we present and compare two powerful distributed SE methods based on: i) graphical models and belief propagation, and ii) graph neural networks. We discuss their performance and capability to support a near real-time distributed SE via 5G network, taking into account communication delays. ",
    "url": "https://arxiv.org/abs/2207.11117",
    "authors": [
      "Ognjen Kundacina",
      "Miodrag Forcan",
      "Mirsad Cosovic",
      "Darijo Raca",
      "Merim Dzaferagic",
      "Dragisa Miskovic",
      "Mirjana Maksimovic",
      "Dejan Vukobratovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.11132",
    "title": "Proactive Distributed Constraint Optimization of Heterogeneous Incident  Vehicle Teams",
    "abstract": "Traditionally, traffic incident management (TIM) programs coordinate the deployment of emergency resources to immediate incident requests without accommodating the interdependencies on incident evolutions in the environment. However, ignoring inherent interdependencies on the evolution of incidents in the environment while making current deployment decisions is shortsighted, and the resulting naive deployment strategy can significantly worsen the overall incident delay impact on the network. The interdependencies on incident evolution in the environment, including those between incident occurrences, and those between resource availability in near-future requests and the anticipated duration of the immediate incident request, should be considered through a look-ahead model when making current-stage deployment decisions. This study develops a new proactive framework based on the distributed constraint optimization problem (DCOP) to address the above limitations, overcoming conventional TIM models that cannot accommodate the dependencies in the TIM problem. Furthermore, the optimization objective is formulated to incorporate Unmanned Aerial Vehicles (UAVs). The UAVs' role in TIM includes exploring uncertain traffic conditions, detecting unexpected events, and augmenting information from roadway traffic sensors. Robustness analysis of our model for multiple TIM scenarios shows satisfactory performance using local search exploration heuristics. Overall, our model reports a significant reduction in total incident delay compared to conventional TIM models. With UAV support, we demonstrate a further decrease in the overall incident delay through the shorter response time of emergency vehicles, and a reduction in uncertainties associated with the estimated incident delay impact. ",
    "url": "https://arxiv.org/abs/2207.11132",
    "authors": [
      "Justice Darko",
      "Hyoshin Park"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2207.11134",
    "title": "Development of monitoring systems for anomaly detection using ASTD  specifications",
    "abstract": "Anomaly-based intrusion detection systems are essential defenses against cybersecurity threats because they can identify anomalies in current activities. However, these systems have difficulties providing entity processing independence through a programming language. In addition, a degradation of the detection process is caused by the complexity of scheduling the training and detection processes, which are required to keep the anomaly detection system continuously updated. This paper shows how to use the algebraic state-transition diagram (ASTD) language to develop flexible anomaly detection systems. This paper provides a model for detecting point anomalies using the unsupervised non-parametric technique Kernel Density Estimation to estimate the probability density of event occurrence. The proposed model caters for both the training and the detection phase continuously. The ASTD language streamlines the modeling of detection systems thanks to its process algebraic operators that provide a solution to overcome these challenges. By delegating the combination of anomaly-based detection processes to the ASTD language, the effort and complexity are reduced during detection models development. Finally, using a qualitative evaluation, this study demonstrates that the algebraic operators in the ASTD specification language overcome these challenges. ",
    "url": "https://arxiv.org/abs/2207.11134",
    "authors": [
      "El Jabri Chaymae",
      "Frappier Marc",
      "Ecarot Thibaud",
      "Tardif Pierre-Martin"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2207.11169",
    "title": "Rethinking Few-Shot Object Detection on a Multi-Domain Benchmark",
    "abstract": "Most existing works on few-shot object detection (FSOD) focus on a setting where both pre-training and few-shot learning datasets are from a similar domain. However, few-shot algorithms are important in multiple domains; hence evaluation needs to reflect the broad applications. We propose a Multi-dOmain Few-Shot Object Detection (MoFSOD) benchmark consisting of 10 datasets from a wide range of domains to evaluate FSOD algorithms. We comprehensively analyze the impacts of freezing layers, different architectures, and different pre-training datasets on FSOD performance. Our empirical results show several key factors that have not been explored in previous works: 1) contrary to previous belief, on a multi-domain benchmark, fine-tuning (FT) is a strong baseline for FSOD, performing on par or better than the state-of-the-art (SOTA) algorithms; 2) utilizing FT as the baseline allows us to explore multiple architectures, and we found them to have a significant impact on down-stream few-shot tasks, even with similar pre-training performances; 3) by decoupling pre-training and few-shot learning, MoFSOD allows us to explore the impact of different pre-training datasets, and the right choice can boost the performance of the down-stream tasks significantly. Based on these findings, we list possible avenues of investigation for improving FSOD performance and propose two simple modifications to existing algorithms that lead to SOTA performance on the MoFSOD benchmark. The code is available at https://github.com/amazon-research/few-shot-object-detection-benchmark. ",
    "url": "https://arxiv.org/abs/2207.11169",
    "authors": [
      "Kibok Lee",
      "Hao Yang",
      "Satyaki Chakraborty",
      "Zhaowei Cai",
      "Gurumurthy Swaminathan",
      "Avinash Ravichandran",
      "Onkar Dabeer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11171",
    "title": "Silent Spring: Prototype Pollution Leads to Remote Code Execution in  Node.js",
    "abstract": "Prototype pollution is a dangerous vulnerability affecting prototype-based languages like JavaScript and the Node.js platform. It refers to the ability of an attacker to inject properties into an object's root prototype at runtime and subsequently trigger the execution of legitimate code gadgets that access these properties on the object's prototype, leading to attacks such as DoS, privilege escalation, and remote code execution (RCE). While there is anecdotal evidence that prototype pollution leads to RCE, current research does not tackle the challenge of gadget detection, thus only showing feasibility of DoS attacks against Node.js libraries. In this paper, we set out to study the problem in a holistic way, from the detection of prototype pollution to detection of gadgets, with the ambitious goal of finding end-to-end exploits beyond DoS, in full-fledged Node.js applications. We build the first multi-staged framework that uses multi-label static taint analysis to identify prototype pollution in Node.js libraries and applications, as well as a hybrid approach to detect universal gadgets, notably, by analyzing the Node.js source code. We implement our framework on top of GitHub's static analysis framework CodeQL to find 11 universal gadgets in core Node.js APIs, leading to code execution. Furthermore, we use our methodology in a study of 15 popular Node.js applications to identify prototype pollutions and gadgets. We manually exploit RCE in two high-profile applications. Our results provide alarming evidence that prototype pollution in combination with powerful universal gadgets lead to RCE in Node.js. ",
    "url": "https://arxiv.org/abs/2207.11171",
    "authors": [
      "Mikhail Shcherbakov",
      "Musard Balliu",
      "Cristian-Alexandru Staicu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2207.11175",
    "title": "Explaining Dynamic Graph Neural Networks via Relevance Back-propagation",
    "abstract": "Graph Neural Networks (GNNs) have shown remarkable effectiveness in capturing abundant information in graph-structured data. However, the black-box nature of GNNs hinders users from understanding and trusting the models, thus leading to difficulties in their applications. While recent years witness the prosperity of the studies on explaining GNNs, most of them focus on static graphs, leaving the explanation of dynamic GNNs nearly unexplored. It is challenging to explain dynamic GNNs, due to their unique characteristic of time-varying graph structures. Directly using existing models designed for static graphs on dynamic graphs is not feasible because they ignore temporal dependencies among the snapshots. In this work, we propose DGExplainer to provide reliable explanation on dynamic GNNs. DGExplainer redistributes the output activation score of a dynamic GNN to the relevances of the neurons of its previous layer, which iterates until the relevance scores of the input neuron are obtained. We conduct quantitative and qualitative experiments on real-world datasets to demonstrate the effectiveness of the proposed framework for identifying important nodes for link prediction and node regression for dynamic GNNs. ",
    "url": "https://arxiv.org/abs/2207.11175",
    "authors": [
      "Jiaxuan Xie",
      "Yezi Liu",
      "Yanning Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11177",
    "title": "Training Certifiably Robust Neural Networks Against Semantic  Perturbations",
    "abstract": "Semantic image perturbations, such as scaling and rotation, have been shown to easily deceive deep neural networks (DNNs). Hence, training DNNs to be certifiably robust to these perturbations is critical. However, no prior work has been able to incorporate the objective of deterministic semantic robustness into the training procedure, as existing deterministic semantic verifiers are exceedingly slow. To address these challenges, we propose Certified Semantic Training (CST), the first training framework for deterministic certified robustness against semantic image perturbations. Our framework leverages a novel GPU-optimized verifier that, unlike existing works, is fast enough for use in training. Our results show that networks trained via CST consistently achieve both better provable semantic robustness and clean accuracy, compared to networks trained via baselines based on existing works. ",
    "url": "https://arxiv.org/abs/2207.11177",
    "authors": [
      "Rem Yang",
      "Jacob Laurel",
      "Sasa Misailovic",
      "Gagandeep Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11184",
    "title": "Multi-Faceted Distillation of Base-Novel Commonality for Few-shot Object  Detection",
    "abstract": "Most of existing methods for few-shot object detection follow the fine-tuning paradigm, which potentially assumes that the class-agnostic generalizable knowledge can be learned and transferred implicitly from base classes with abundant samples to novel classes with limited samples via such a two-stage training strategy. However, it is not necessarily true since the object detector can hardly distinguish between class-agnostic knowledge and class-specific knowledge automatically without explicit modeling. In this work we propose to learn three types of class-agnostic commonalities between base and novel classes explicitly: recognition-related semantic commonalities, localization-related semantic commonalities and distribution commonalities. We design a unified distillation framework based on a memory bank, which is able to perform distillation of all three types of commonalities jointly and efficiently. Extensive experiments demonstrate that our method can be readily integrated into most of existing fine-tuning based methods and consistently improve the performance by a large margin. ",
    "url": "https://arxiv.org/abs/2207.11184",
    "authors": [
      "Shuang Wu",
      "Wenjie Pei",
      "Dianwen Mei",
      "Fanglin Chen",
      "Jiandong Tian",
      "Guangming Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11228",
    "title": "Classifying Crop Types using Gaussian Bayesian Models and Neural  Networks on GHISACONUS USGS data from NASA Hyperspectral Satellite Imagery",
    "abstract": "Hyperspectral Imagining is a type of digital imaging in which each pixel contains typically hundreds of wavelengths of light providing spectroscopic information about the materials present in the pixel. In this paper we provide classification methods for determining crop type in the USGS GHISACONUS data, which contains around 7,000 pixel spectra from the five major U.S. agricultural crops (winter wheat, rice, corn, soybeans, and cotton) collected by the NASA Hyperion satellite, and includes the spectrum, geolocation, crop type, and stage of growth for each pixel. We apply standard LDA and QDA as well as Bayesian custom versions that compute the joint probability of crop type and stage, and then the marginal probability for crop type, outperforming the non-Bayesian methods. We also test a single layer neural network with dropout on the data, which performs comparable to LDA and QDA but not as well as the Bayesian methods. ",
    "url": "https://arxiv.org/abs/2207.11228",
    "authors": [
      "Bill Basener"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.11230",
    "title": "You Actually Look Twice At it (YALTAi): using an object detection  approach instead of region segmentation within the Kraken engine",
    "abstract": "Layout Analysis (the identification of zones and their classification) is the first step along line segmentation in Optical Character Recognition and similar tasks. The ability of identifying main body of text from marginal text or running titles makes the difference between extracting the work full text of a digitized book and noisy outputs. We show that most segmenters focus on pixel classification and that polygonization of this output has not been used as a target for the latest competition on historical document (ICDAR 2017 and onwards), despite being the focus in the early 2010s. We propose to shift, for efficiency, the task from a pixel classification-based polygonization to an object detection using isothetic rectangles. We compare the output of Kraken and YOLOv5 in terms of segmentation and show that the later severely outperforms the first on small datasets (1110 samples and below). We release two datasets for training and evaluation on historical documents as well as a new package, YALTAi, which injects YOLOv5 in the segmentation pipeline of Kraken 4.1. ",
    "url": "https://arxiv.org/abs/2207.11230",
    "authors": [
      "Thibault Cl\u00e9rice"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.11232",
    "title": "Seeing 3D Objects in a Single Image via Self-Supervised Static-Dynamic  Disentanglement",
    "abstract": "Human perception reliably identifies movable and immovable parts of 3D scenes, and completes the 3D structure of objects and background from incomplete observations. We learn this skill not via labeled examples, but simply by observing objects move. In this work, we propose an approach that observes unlabeled multi-view videos at training time and learns to map a single image observation of a complex scene, such as a street with cars, to a 3D neural scene representation that is disentangled into movable and immovable parts while plausibly completing its 3D structure. We separately parameterize movable and immovable scene parts via 2D neural ground plans. These ground plans are 2D grids of features aligned with the ground plane that can be locally decoded into 3D neural radiance fields. Our model is trained self-supervised via neural rendering. We demonstrate that the structure inherent to our disentangled 3D representation enables a variety of downstream tasks in street-scale 3D scenes using simple heuristics, such as extraction of object-centric 3D representations, novel view synthesis, instance segmentation, and 3D bounding box prediction, highlighting its value as a backbone for data-efficient 3D scene understanding models. This disentanglement further enables scene editing via object manipulation such as deletion, insertion, and rigid-body motion. ",
    "url": "https://arxiv.org/abs/2207.11232",
    "authors": [
      "Prafull Sharma",
      "Ayush Tewari",
      "Yilun Du",
      "Sergey Zakharov",
      "Rares Ambrus",
      "Adrien Gaidon",
      "William T. Freeman",
      "Fredo Durand",
      "Joshua B. Tenenbaum",
      "Vincent Sitzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11233",
    "title": "E2N: Error Estimation Networks for Goal-Oriented Mesh Adaptation",
    "abstract": "Given a partial differential equation (PDE), goal-oriented error estimation allows us to understand how errors in a diagnostic quantity of interest (QoI), or goal, occur and accumulate in a numerical approximation, for example using the finite element method. By decomposing the error estimates into contributions from individual elements, it is possible to formulate adaptation methods, which modify the mesh with the objective of minimising the resulting QoI error. However, the standard error estimate formulation involves the true adjoint solution, which is unknown in practice. As such, it is common practice to approximate it with an 'enriched' approximation (e.g. in a higher order space or on a refined mesh). Doing so generally results in a significant increase in computational cost, which can be a bottleneck compromising the competitiveness of (goal-oriented) adaptive simulations. The central idea of this paper is to develop a \"data-driven\" goal-oriented mesh adaptation approach through the selective replacement of the expensive error estimation step with an appropriately configured and trained neural network. In doing so, the error estimator may be obtained without even constructing the enriched spaces. An element-by-element construction is employed here, whereby local values of various parameters related to the mesh geometry and underlying problem physics are taken as inputs, and the corresponding contribution to the error estimator is taken as output. We demonstrate that this approach is able to obtain the same accuracy with a reduced computational cost, for adaptive mesh test cases related to flow around tidal turbines, which interact via their downstream wakes, and where the overall power output of the farm is taken as the QoI. Moreover, we demonstrate that the element-by-element approach implies reasonably low training costs. ",
    "url": "https://arxiv.org/abs/2207.11233",
    "authors": [
      "Joseph G. Wallwork",
      "Jingyi Lu",
      "Mingrui Zhang",
      "Matthew D. Piggott"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2207.11237",
    "title": "Defending Substitution-Based Profile Pollution Attacks on Sequential  Recommenders",
    "abstract": "While sequential recommender systems achieve significant improvements on capturing user dynamics, we argue that sequential recommenders are vulnerable against substitution-based profile pollution attacks. To demonstrate our hypothesis, we propose a substitution-based adversarial attack algorithm, which modifies the input sequence by selecting certain vulnerable elements and substituting them with adversarial items. In both untargeted and targeted attack scenarios, we observe significant performance deterioration using the proposed profile pollution algorithm. Motivated by such observations, we design an efficient adversarial defense method called Dirichlet neighborhood sampling. Specifically, we sample item embeddings from a convex hull constructed by multi-hop neighbors to replace the original items in input sequences. During sampling, a Dirichlet distribution is used to approximate the probability distribution in the neighborhood such that the recommender learns to combat local perturbations. Additionally, we design an adversarial training method tailored for sequential recommender systems. In particular, we represent selected items with one-hot encodings and perform gradient ascent on the encodings to search for the worst case linear combination of item embeddings in training. As such, the embedding function learns robust item representations and the trained recommender is resistant to test-time adversarial examples. Extensive experiments show the effectiveness of both our attack and defense methods, which consistently outperform baselines by a significant margin across model architectures and datasets. ",
    "url": "https://arxiv.org/abs/2207.11237",
    "authors": [
      "Zhenrui Yue",
      "Huimin Zeng",
      "Ziyi Kou",
      "Lanyu Shang",
      "Dong Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11243",
    "title": "Multiface: A Dataset for Neural Face Rendering",
    "abstract": "Photorealistic avatars of human faces have come a long way in recent years, yet research along this area is limited by a lack of publicly available, high-quality datasets covering both, dense multi-view camera captures, and rich facial expressions of the captured subjects. In this work, we present Multiface, a new multi-view, high-resolution human face dataset collected from 13 identities at Reality Labs Research for neural face rendering. We introduce Mugsy, a large scale multi-camera apparatus to capture high-resolution synchronized videos of a facial performance. The goal of Multiface is to close the gap in accessibility to high quality data in the academic community and to enable research in VR telepresence. Along with the release of the dataset, we conduct ablation studies on the influence of different model architectures toward the model's interpolation capacity of novel viewpoint and expressions. With a conditional VAE model serving as our baseline, we found that adding spatial bias, texture warp field, and residual connections improves performance on novel view synthesis. Our code and data is available at: https://github.com/facebookresearch/multiface ",
    "url": "https://arxiv.org/abs/2207.11243",
    "authors": [
      "Cheng-hsin Wuu",
      "Ningyuan Zheng",
      "Scott Ardisson",
      "Rohan Bali",
      "Danielle Belko",
      "Eric Brockmeyer",
      "Lucas Evans",
      "Timothy Godisart",
      "Hyowon Ha",
      "Alexander Hypes",
      "Taylor Koska",
      "Steven Krenn",
      "Stephen Lombardi",
      "Xiaomin Luo",
      "Kevyn McPhail",
      "Laura Millerschoen",
      "Michal Perdoch",
      "Mark Pitts",
      "Alexander Richard",
      "Jason Saragih",
      "Junko Saragih",
      "Takaaki Shiratori",
      "Tomas Simon",
      "Matt Stewart",
      "Autumn Trimble",
      "Xinshuo Weng",
      "David Whitewolf",
      "Chenglei Wu",
      "Shoou-I Yu",
      "Yaser Sheikh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2207.11244",
    "title": "Deep Learning Hyperparameter Optimization for Breast Mass Detection in  Mammograms",
    "abstract": "Accurate breast cancer diagnosis through mammography has the potential to save millions of lives around the world. Deep learning (DL) methods have shown to be very effective for mass detection in mammograms. Additional improvements of current DL models will further improve the effectiveness of these methods. A critical issue in this context is how to pick the right hyperparameters for DL models. In this paper, we present GA-E2E, a new approach for tuning the hyperparameters of DL models for brest cancer detection using Genetic Algorithms (GAs). Our findings reveal that differences in parameter values can considerably alter the area under the curve (AUC), which is used to determine a classifier's performance. ",
    "url": "https://arxiv.org/abs/2207.11244",
    "authors": [
      "Adarsh Sehgal",
      "Muskan Sehgal",
      "Hung Manh La",
      "George Bebis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11247",
    "title": "Panoptic Scene Graph Generation",
    "abstract": "Existing research addresses scene graph generation (SGG) -- a critical technology for scene understanding in images -- from a detection perspective, i.e., objects are detected using bounding boxes followed by prediction of their pairwise relationships. We argue that such a paradigm causes several problems that impede the progress of the field. For instance, bounding box-based labels in current datasets usually contain redundant classes like hairs, and leave out background information that is crucial to the understanding of context. In this work, we introduce panoptic scene graph generation (PSG), a new problem task that requires the model to generate a more comprehensive scene graph representation based on panoptic segmentations rather than rigid bounding boxes. A high-quality PSG dataset, which contains 49k well-annotated overlapping images from COCO and Visual Genome, is created for the community to keep track of its progress. For benchmarking, we build four two-stage baselines, which are modified from classic methods in SGG, and two one-stage baselines called PSGTR and PSGFormer, which are based on the efficient Transformer-based detector, i.e., DETR. While PSGTR uses a set of queries to directly learn triplets, PSGFormer separately models the objects and relations in the form of queries from two Transformer decoders, followed by a prompting-like relation-object matching mechanism. In the end, we share insights on open challenges and future directions. ",
    "url": "https://arxiv.org/abs/2207.11247",
    "authors": [
      "Jingkang Yang",
      "Yi Zhe Ang",
      "Zujin Guo",
      "Kaiyang Zhou",
      "Wayne Zhang",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.07680",
    "title": "Network structural origin of instabilities in large complex systems",
    "abstract": "A central issue in the study of large complex network systems, such as power grids, financial networks, and ecological systems, is to understand their response to dynamical perturbations. Recent studies recognize that many real networks show nonnormality and that nonnormality can give rise to reactivity--the capacity of a linearly stable system to amplify its response to perturbations, oftentimes exciting nonlinear instabilities. Here, we identify network structural properties underlying the pervasiveness of nonnormality and reactivity in real directed networks, which we establish using the most extensive data set of such networks studied in this context to date. The identified properties are imbalances between incoming and outgoing network links and paths at each node. Based on this characterization, we develop a theory that quantitatively predicts nonnormality and reactivity and explains the observed pervasiveness. We suggest that these results can be used to design, upgrade, control, and manage networks to avoid or promote network instabilities. ",
    "url": "https://arxiv.org/abs/2207.07680",
    "authors": [
      "Chao Duan",
      "Takashi Nishikawa",
      "Deniz Eroglu",
      "Adilson E. Motter"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2207.10771",
    "title": "Reticula: A temporal network and hypergraph analysis software package",
    "abstract": "In the last decade, temporal networks and static and temporal hypergraphs have enabled modelling connectivity and spreading processes in a wide array of real-world complex systems such as economic transactions, information spreading, brain activity and disease spreading. In this manuscript, we present the Reticula C++ library and Python package: A comprehensive suite of tools for working with real-world and synthetic static and temporal networks and hypergraphs. This includes various methods of creating synthetic networks and randomised null models based on real-world data, calculating reachability and simulating compartmental models on networks. The library is designed principally on an extensible, cache-friendly representation of networks, with an aim of easing multi-thread use in the high-performance computing environment. ",
    "url": "https://arxiv.org/abs/2207.10771",
    "authors": [
      "Arash Badie-Modiri",
      "Mikko Kivel\u00e4"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.10772",
    "title": "Deep Sufficient Representation Learning via Mutual Information",
    "abstract": "We propose a mutual information-based sufficient representation learning (MSRL) approach, which uses the variational formulation of the mutual information and leverages the approximation power of deep neural networks. MSRL learns a sufficient representation with the maximum mutual information with the response and a user-selected distribution. It can easily handle multi-dimensional continuous or categorical response variables. MSRL is shown to be consistent in the sense that the conditional probability density function of the response variable given the learned representation converges to the conditional probability density function of the response variable given the predictor. Non-asymptotic error bounds for MSRL are also established under suitable conditions. To establish the error bounds, we derive a generalized Dudley's inequality for an order-two U-process indexed by deep neural networks, which may be of independent interest. We discuss how to determine the intrinsic dimension of the underlying data distribution. Moreover, we evaluate the performance of MSRL via extensive numerical experiments and real data analysis and demonstrate that MSRL outperforms some existing nonlinear sufficient dimension reduction methods. ",
    "url": "https://arxiv.org/abs/2207.10772",
    "authors": [
      "Siming Zheng",
      "Yuanyuan Lin",
      "Jian Huang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10794",
    "title": "Neuroimaging Feature Extraction using a Neural Network Classifier for  Imaging Genetics",
    "abstract": "A major issue in the association of genes to neuroimaging phenotypes is the high dimension of both genetic data and neuroimaging data. In this article, we tackle the latter problem with an eye toward developing solutions that are relevant for disease prediction. Supported by a vast literature on the predictive power of neural networks, our proposed solution uses neural networks to extract from neuroimaging data features that are relevant for predicting Alzheimer's Disease (AD) for subsequent relation to genetics. Our neuroimaging-genetic pipeline is comprised of image processing, neuroimaging feature extraction and genetic association steps. We propose a neural network classifier for extracting neuroimaging features that are related with disease and a multivariate Bayesian group sparse regression model for genetic association. We compare the predictive power of these features to expert selected features and take a closer look at the SNPs identified with the new neuroimaging features. ",
    "url": "https://arxiv.org/abs/2207.10794",
    "authors": [
      "C\u00e9dric Beaulac",
      "Sidi Wu",
      "Erin Gibson",
      "Michelle F. Miranda",
      "Jiguo Cao",
      "Leno Rocha",
      "Mirza Faisal Beg",
      "Farouk S. Nathoo"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11050",
    "title": "Graph Spatio-Spectral Total Variation Model for Hyperspectral Image  Denoising",
    "abstract": "The spatio-spectral total variation (SSTV) model has been widely used as an effective regularization of hyperspectral images (HSI) for various applications such as mixed noise removal. However, since SSTV computes local spatial differences uniformly, it is difficult to remove noise while preserving complex spatial structures with fine edges and textures, especially in situations of high noise intensity. To solve this problem, we propose a new TV-type regularization called Graph-SSTV (GSSTV), which generates a graph explicitly reflecting the spatial structure of the target HSI from noisy HSIs and incorporates a weighted spatial difference operator designed based on this graph. Furthermore, we formulate the mixed noise removal problem as a convex optimization problem involving GSSTV and develop an efficient algorithm based on the primal-dual splitting method to solve this problem. Finally, we demonstrate the effectiveness of GSSTV compared with existing HSI regularization models through experiments on mixed noise removal. The source code will be available at https://www.mdi.c.titech.ac.jp/publications/gsstv. ",
    "url": "https://arxiv.org/abs/2207.11050",
    "authors": [
      "Shingo Takemoto",
      "Kazuki Naganuma",
      "Shunsuke Ono"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11095",
    "title": "Multi-temporal speckle reduction with self-supervised deep neural  networks",
    "abstract": "Speckle filtering is generally a prerequisite to the analysis of synthetic aperture radar (SAR) images. Tremendous progress has been achieved in the domain of single-image despeckling. Latest techniques rely on deep neural networks to restore the various structures and textures peculiar to SAR images. The availability of time series of SAR images offers the possibility of improving speckle filtering by combining different speckle realizations over the same area. The supervised training of deep neural networks requires ground-truth speckle-free images. Such images can only be obtained indirectly through some form of averaging, by spatial or temporal integration, and are imperfect. Given the potential of very high quality restoration reachable by multi-temporal speckle filtering, the limitations of ground-truth images need to be circumvented. We extend a recent self-supervised training strategy for single-look complex SAR images, called MERLIN, to the case of multi-temporal filtering. This requires modeling the sources of statistical dependencies in the spatial and temporal dimensions as well as between the real and imaginary components of the complex amplitudes. Quantitative analysis on datasets with simulated speckle indicates a clear improvement of speckle reduction when additional SAR images are included. Our method is then applied to stacks of TerraSAR-X images and shown to outperform competing multi-temporal speckle filtering approaches. The code of the trained models is made freely available on the $\\href{https://gitlab.telecom-paris.fr/ring/multi-temporal-merlin/}{\\text{GitLab}}$ of the IMAGES team of the LTCI Lab, T\\'el\\'ecom Paris Institut Polytechnique de Paris. ",
    "url": "https://arxiv.org/abs/2207.11095",
    "authors": [
      "In\u00e8s Meraoumia",
      "Emanuele Dalsasso",
      "Lo\u00efc Denis",
      "R\u00e9my Abergel",
      "Florence Tupin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11159",
    "title": "Fairness-aware Network Revenue Management with Demand Learning",
    "abstract": "In addition to maximizing the total revenue, decision-makers in lots of industries would like to guarantee fair consumption across different resources and avoid saturating certain resources. Motivated by these practical needs, this paper studies the price-based network revenue management problem with both demand learning and fairness concern about the consumption across different resources. We introduce the regularized revenue, i.e., the total revenue with a fairness regularization, as our objective to incorporate fairness into the revenue maximization goal. We propose a primal-dual-type online policy with the Upper-Confidence-Bound (UCB) demand learning method to maximize the regularized revenue. We adopt several innovative techniques to make our algorithm a unified and computationally efficient framework for the continuous price set and a wide class of fairness regularizers. Our algorithm achieves a worst-case regret of $\\tilde O(N^{5/2}\\sqrt{T})$, where $N$ denotes the number of products and $T$ denotes the number of time periods. Numerical experiments in a few NRM examples demonstrate the effectiveness of our algorithm for balancing revenue and fairness. ",
    "url": "https://arxiv.org/abs/2207.11159",
    "authors": [
      "Xi Chen",
      "Jiameng Lyu",
      "Yining Wang",
      "Yuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11174",
    "title": "Low cost prediction of probability distributions of molecular properties  for early virtual screening",
    "abstract": "While there is a general focus on predictions of values, mathematically more appropriate is prediction of probability distributions: with additional possibilities like prediction of uncertainty, higher moments and quantiles. For the purpose of the computer-aided drug design field, this article applies Hierarchical Correlation Reconstruction approach, previously applied in the analysis of demographic, financial and astronomical data. Instead of a single linear regression to predict values, it uses multiple linear regressions to independently predict multiple moments, finally combining them into predicted probability distribution, here of several ADMET properties based on substructural fingerprint developed by Klekota\\&Roth. Discussed application example is inexpensive selection of a percentage of molecules with properties nearly certain to be in a predicted or chosen range during virtual screening. Such an approach can facilitate the interpretation of the results as the predictions characterized by high rate of uncertainty are automatically detected. In addition, for each of the investigated predictive problems, we detected crucial structural features, which should be carefully considered when optimizing compounds towards particular property. The whole methodology developed in the study constitutes therefore a great support for medicinal chemists, as it enable fast rejection of compounds with the lowest potential of desired physicochemical/ADMET characteristic and guides the compound optimization process. ",
    "url": "https://arxiv.org/abs/2207.11174",
    "authors": [
      "Jarek Duda",
      "Sabina Podlewska"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:1907.05878",
    "title": "Composing Neural Learning and Symbolic Reasoning with an Application to  Visual Discrimination",
    "abstract": " Comments: Published at IJCAI 2022 ",
    "url": "https://arxiv.org/abs/1907.05878",
    "authors": [
      "Adithya Murali",
      "Atharva Sehgal",
      "Paul Krogmeier",
      "P. Madhusudan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:1912.03207",
    "title": "NASA: Neural Articulated Shape Approximation",
    "abstract": " Comments: ECCV 2020; Project Page: this https URL ",
    "url": "https://arxiv.org/abs/1912.03207",
    "authors": [
      "Boyang Deng",
      "JP Lewis",
      "Timothy Jeruzalski",
      "Gerard Pons-Moll",
      "Geoffrey Hinton",
      "Mohammad Norouzi",
      "Andrea Tagliasacchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2010.04918",
    "title": "Automatically Deriving Control-Flow Graph Generators from Operational  Semantics",
    "abstract": " Title: Automatically Deriving Control-Flow Graph Generators from Operational  Semantics ",
    "url": "https://arxiv.org/abs/2010.04918",
    "authors": [
      "James Koppel",
      "Jackson Kearl",
      "Armando Solar-Lezama"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2011.09290",
    "title": "Practical Privacy Attacks on Vertical Federated Learning",
    "abstract": " Title: Practical Privacy Attacks on Vertical Federated Learning ",
    "url": "https://arxiv.org/abs/2011.09290",
    "authors": [
      "Haiqin Weng",
      "Juntao Zhang",
      "Xingjun Ma",
      "Feng Xue",
      "Tao Wei",
      "Shouling Ji",
      "Zhiyuan Zong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2012.06568",
    "title": "Learning Energy-Based Models With Adversarial Training",
    "abstract": " Comments: ECCV2022, code is available at this https URL ",
    "url": "https://arxiv.org/abs/2012.06568",
    "authors": [
      "Xuwang Yin",
      "Shiying Li",
      "Gustavo K. Rohde"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2103.14453",
    "title": "Data Augmentation in Natural Language Processing: A Novel Text  Generation Approach for Long and Short Text Classifiers",
    "abstract": " Comments: 17 pages, 3 figure, 5 tables ",
    "url": "https://arxiv.org/abs/2103.14453",
    "authors": [
      "Markus Bayer",
      "Marc-Andr\u00e9 Kaufhold",
      "Bj\u00f6rn Buchhold",
      "Marcel Keller",
      "J\u00f6rg Dallmeyer",
      "Christian Reuter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2103.16365",
    "title": "FoV-NeRF: Foveated Neural Radiance Fields for Virtual Reality",
    "abstract": " Comments: 9 pages ",
    "url": "https://arxiv.org/abs/2103.16365",
    "authors": [
      "Nianchen Deng",
      "Zhenyi He",
      "Jiannan Ye",
      "Budmonde Duinkharjav",
      "Praneeth Chakravarthula",
      "Xubo Yang",
      "Qi Sun"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.09340",
    "title": "Code Structure Guided Transformer for Source Code Summarization",
    "abstract": " Title: Code Structure Guided Transformer for Source Code Summarization ",
    "url": "https://arxiv.org/abs/2104.09340",
    "authors": [
      "Shuzheng Gao",
      "Cuiyun Gao",
      "Yulan He",
      "Jichuan Zeng",
      "Lun Yiu Nie",
      "Xin Xia",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2107.01809",
    "title": "Boosting Transferability of Targeted Adversarial Examples via  Hierarchical Generative Networks",
    "abstract": " Title: Boosting Transferability of Targeted Adversarial Examples via  Hierarchical Generative Networks ",
    "url": "https://arxiv.org/abs/2107.01809",
    "authors": [
      "Xiao Yang",
      "Yinpeng Dong",
      "Tianyu Pang",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2107.03158",
    "title": "A Survey on Data Augmentation for Text Classification",
    "abstract": " Comments: 43 pages, 5 figures, 9 tables ",
    "url": "https://arxiv.org/abs/2107.03158",
    "authors": [
      "Markus Bayer",
      "Marc-Andr\u00e9 Kaufhold",
      "Christian Reuter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2108.12821",
    "title": "Analyzing and Mitigating Interference in Neural Architecture Search",
    "abstract": " Comments: ICML 2022, Spotlight ",
    "url": "https://arxiv.org/abs/2108.12821",
    "authors": [
      "Jin Xu",
      "Xu Tan",
      "Kaitao Song",
      "Renqian Luo",
      "Yichong Leng",
      "Tao Qin",
      "Tie-Yan Liu",
      "Jian Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.00161",
    "title": "Simultaneous Neural Network Approximation for Smooth Functions",
    "abstract": " Title: Simultaneous Neural Network Approximation for Smooth Functions ",
    "url": "https://arxiv.org/abs/2109.00161",
    "authors": [
      "Sean Hon",
      "Haizhao Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2109.05776",
    "title": "Learning to Predict Diverse Human Motions from a Single Image via  Mixture Density Networks",
    "abstract": " Title: Learning to Predict Diverse Human Motions from a Single Image via  Mixture Density Networks ",
    "url": "https://arxiv.org/abs/2109.05776",
    "authors": [
      "Chunzhi Gu",
      "Yan Zhao",
      "Chao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.03892",
    "title": "Bounding-box deep calibration for high performance face detection",
    "abstract": " Comments: 12 pages, 7 figures, 5 tables, 1 algorithm, 9 equation, 2 definition ",
    "url": "https://arxiv.org/abs/2110.03892",
    "authors": [
      "Shi Luo",
      "Xiongfei Li",
      "Xiaoli Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.07291",
    "title": "Only Time Will Tell: Modelling Information Diffusion in Code Review with  Time-Varying Hypergraphs",
    "abstract": " Comments: 10 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2110.07291",
    "authors": [
      "Michael Dorner",
      "Darja \u0160mite",
      "Daniel Mendez",
      "Krzysztof Wnuk",
      "Jacek Czerwonka"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2110.07682",
    "title": "Sound and Complete Neural Network Repair with Minimality and Locality  Guarantees",
    "abstract": " Comments: 17 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2110.07682",
    "authors": [
      "Feisi Fu",
      "Wenchao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.00232",
    "title": "MFNet: Multi-class Few-shot Segmentation Network with Pixel-wise Metric  Learning",
    "abstract": " Comments: Accepted on IEEE Transactions on Circuits and Systems for Video Technology ",
    "url": "https://arxiv.org/abs/2111.00232",
    "authors": [
      "Miao Zhang",
      "Miaojing Shi",
      "Li Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.12485",
    "title": "Understanding the Dynamics of DNNs Using Graph Modularity",
    "abstract": " Comments: Accepted by ECCV 2022 ",
    "url": "https://arxiv.org/abs/2111.12485",
    "authors": [
      "Yao Lu",
      "Wen Yang",
      "Yunzhe Zhang",
      "Zuohui Chen",
      "Jinyin Chen",
      "Qi Xuan",
      "Zhen Wang",
      "Xiaoniu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.02308",
    "title": "MoFaNeRF: Morphable Facial Neural Radiance Field",
    "abstract": " Comments: accepted to ECCV2022; code available at this http URL ",
    "url": "https://arxiv.org/abs/2112.02308",
    "authors": [
      "Yiyu Zhuang",
      "Hao Zhu",
      "Xusen Sun",
      "Xun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2112.10644",
    "title": "Self-attention Presents Low-dimensional Knowledge Graph Embeddings for  Link Prediction",
    "abstract": " Comments: 13 pages, 2 figure, 5 tables ",
    "url": "https://arxiv.org/abs/2112.10644",
    "authors": [
      "Peyman Baghershahi",
      "Reshad Hosseini",
      "Hadi Moradi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.11449",
    "title": "Doubly-Valid/Doubly-Sharp Sensitivity Analysis for Causal Inference with  Unmeasured Confounding",
    "abstract": " Title: Doubly-Valid/Doubly-Sharp Sensitivity Analysis for Causal Inference with  Unmeasured Confounding ",
    "url": "https://arxiv.org/abs/2112.11449",
    "authors": [
      "Jacob Dorn",
      "Kevin Guo",
      "Nathan Kallus"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.13951",
    "title": "Improving Nonparametric Classification via Local Radial Regression with  an Application to Stock Prediction",
    "abstract": " Comments: 23pages, 10 figures, first two authors (R. Cao and A. Okuno) contributed equally to this work ",
    "url": "https://arxiv.org/abs/2112.13951",
    "authors": [
      "Ruixing Cao",
      "Akifumi Okuno",
      "Kei Nakagawa",
      "Hidetoshi Shimodaira"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2201.09263",
    "title": "Differential Geometry for Neural Implicit Models",
    "abstract": " Title: Differential Geometry for Neural Implicit Models ",
    "url": "https://arxiv.org/abs/2201.09263",
    "authors": [
      "Tiago Novello",
      "Guilherme Schardong",
      "Luiz Schirmer",
      "Vinicius da Silva",
      "Helio Lopes",
      "Luiz Velho"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.10374",
    "title": "Multiscale modeling of linear elastic heterogeneous structures via  localized model order reduction",
    "abstract": " Title: Multiscale modeling of linear elastic heterogeneous structures via  localized model order reduction ",
    "url": "https://arxiv.org/abs/2201.10374",
    "authors": [
      "Philipp Diercks",
      "Karen Veroy",
      "Annika Robens-Radermacher",
      "J\u00f6rg F. Unger"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2201.11113",
    "title": "Post-training Quantization for Neural Networks with Provable Guarantees",
    "abstract": " Title: Post-training Quantization for Neural Networks with Provable Guarantees ",
    "url": "https://arxiv.org/abs/2201.11113",
    "authors": [
      "Jinjie Zhang",
      "Yixuan Zhou",
      "Rayan Saab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.11729",
    "title": "Implicit Regularization in Hierarchical Tensor Factorization and Deep  Convolutional Neural Networks",
    "abstract": " Comments: Accepted to ICML 2022 ",
    "url": "https://arxiv.org/abs/2201.11729",
    "authors": [
      "Noam Razin",
      "Asaf Maman",
      "Nadav Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.12362",
    "title": "Physics-informed neural networks to learn cardiac fiber orientation from  multiple electroanatomical maps",
    "abstract": " Comments: 29 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2201.12362",
    "authors": [
      "Carlos Ruiz Herrera",
      "Thomas Grandits",
      "Gernot Plank",
      "Paris Perdikaris",
      "Francisco Sahli Costabal",
      "Simone Pezzuto"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)",
      "Tissues and Organs (q-bio.TO)"
    ]
  },
  {
    "id": "arXiv:2201.12532",
    "title": "Modeling Complex Dependencies for Session-based Recommendations via  Graph Neural Networks",
    "abstract": " Comments: 12 pages, 4 figures, conference ",
    "url": "https://arxiv.org/abs/2201.12532",
    "authors": [
      "Qian Zhang",
      "Wenpeng Lu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.13311",
    "title": "Neighbour Interaction based Click-Through Rate Prediction via  Graph-masked Transformer",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2201.13311",
    "authors": [
      "Erxue Min",
      "Yu Rong",
      "Tingyang Xu",
      "Yatao Bian",
      "Peilin Zhao",
      "Junzhou Huang",
      "Da Luo",
      "Kangyi Lin",
      "Sophia Ananiadou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13166",
    "title": "Self-supervised Video-centralised Transformer for Video Face Clustering",
    "abstract": " Title: Self-supervised Video-centralised Transformer for Video Face Clustering ",
    "url": "https://arxiv.org/abs/2203.13166",
    "authors": [
      "Yujiang Wang",
      "Mingzhi Dong",
      "Jie Shen",
      "Yiming Luo",
      "Yiming Lin",
      "Pingchuan Ma",
      "Stavros Petridis",
      "Maja Pantic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.17218",
    "title": "Improved Relation Networks for End-to-End Speaker Verification and  Identification",
    "abstract": " Comments: Accepted to Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2203.17218",
    "authors": [
      "Ashutosh Chaubey",
      "Sparsh Sinha",
      "Susmita Ghose"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.11424",
    "title": "It Takes Two Flints to Make a Fire: Multitask Learning of Neural  Relation and Explanation Classifiers",
    "abstract": " Title: It Takes Two Flints to Make a Fire: Multitask Learning of Neural  Relation and Explanation Classifiers ",
    "url": "https://arxiv.org/abs/2204.11424",
    "authors": [
      "Zheng Tang",
      "Mihai Surdeanu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.01414",
    "title": "Multimodal Detection of Unknown Objects on Roads for Autonomous Driving",
    "abstract": " Comments: Daniel Bogdoll, Enrico Eisen, Maximilian Nitsche, and Christin Scheib contributed equally. Accepted for publication at SMC 2022 ",
    "url": "https://arxiv.org/abs/2205.01414",
    "authors": [
      "Daniel Bogdoll",
      "Enrico Eisen",
      "Maximilian Nitsche",
      "Christin Scheib",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.06155",
    "title": "Concept Identification for Complex Engineering Datasets",
    "abstract": " Comments: 19 pages, 14 figures, accepted at Advanced Engineering Informatics ",
    "url": "https://arxiv.org/abs/2206.06155",
    "authors": [
      "Felix Lanfermann",
      "Sebastian Schmitt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07765",
    "title": "US News and Social Media Framing around Vaping",
    "abstract": " Title: US News and Social Media Framing around Vaping ",
    "url": "https://arxiv.org/abs/2206.07765",
    "authors": [
      "Keyu Chen",
      "Marzieh Babaeianjelodar",
      "Yiwen Shi",
      "Rohan Aanegola",
      "Lam Yin Cheung",
      "Preslav Ivanov Nakov",
      "Shweta Yadav",
      "Angus Bancroft",
      "Ashiqur R. KhudaBukhsh",
      "Munmun De Choudhury",
      "Frederick L. Altice",
      "Navin Kumar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.04589",
    "title": "Learned Video Compression via Heterogeneous Deformable Compensation  Network",
    "abstract": " Title: Learned Video Compression via Heterogeneous Deformable Compensation  Network ",
    "url": "https://arxiv.org/abs/2207.04589",
    "authors": [
      "Huairui Wang",
      "Zhenzhong Chen",
      "Chang Wen Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.06067",
    "title": "Pyramid Transformer for Traffic Sign Detection",
    "abstract": " Title: Pyramid Transformer for Traffic Sign Detection ",
    "url": "https://arxiv.org/abs/2207.06067",
    "authors": [
      "Omid Nejati Manzari",
      "Amin Boudesh",
      "Shahriar B. Shokouhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.06202",
    "title": "Adversarially-Aware Robust Object Detector",
    "abstract": " Comments: ECCV2022 oral paper ",
    "url": "https://arxiv.org/abs/2207.06202",
    "authors": [
      "Ziyi Dong",
      "Pengxu Wei",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.06706",
    "title": "SHREC 2022 Track on Online Detection of Heterogeneous Gestures",
    "abstract": " Comments: Accepted on Computer & Graphics journal ",
    "url": "https://arxiv.org/abs/2207.06706",
    "authors": [
      "Ariel Caputo",
      "Marco Emporio",
      "Andrea Giachetti",
      "Marco Cristani",
      "Guido Borghi",
      "Andrea D'Eusanio",
      "Minh-Quan Le",
      "Hai-Dang Nguyen",
      "Minh-Triet Tran",
      "F. Ambellan",
      "M. Hanik",
      "E. Nava-Yazdani",
      "C. von Tycowicz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08046",
    "title": "MDM:Visual Explanations for Neural Networks via Multiple Dynamic Mask",
    "abstract": " Title: MDM:Visual Explanations for Neural Networks via Multiple Dynamic Mask ",
    "url": "https://arxiv.org/abs/2207.08046",
    "authors": [
      "Yitao Peng",
      "Longzhen Yang",
      "Yihang Liu",
      "Lianghua He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08531",
    "title": "DID-M3D: Decoupling Instance Depth for Monocular 3D Object Detection",
    "abstract": " Comments: ECCV 2022 ",
    "url": "https://arxiv.org/abs/2207.08531",
    "authors": [
      "Liang Peng",
      "Xiaopei Wu",
      "Zheng Yang",
      "Haifeng Liu",
      "Deng Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09675",
    "title": "ERA: Expert Retrieval and Assembly for Early Action Prediction",
    "abstract": " Comments: Accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2207.09675",
    "authors": [
      "Lin Geng Foo",
      "Tianjiao Li",
      "Hossein Rahmani",
      "Qiuhong Ke",
      "Jun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09777",
    "title": "AU-Supervised Convolutional Vision Transformers for Synthetic Facial  Expression Recognition",
    "abstract": " Title: AU-Supervised Convolutional Vision Transformers for Synthetic Facial  Expression Recognition ",
    "url": "https://arxiv.org/abs/2207.09777",
    "authors": [
      "Shuyi Mao",
      "Xinpeng Li",
      "Junyao Chen",
      "Xiaojiang Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09933",
    "title": "Robust Landmark-based Stent Tracking in X-ray Fluoroscopy",
    "abstract": " Comments: Accepted by ECCV 2022 ",
    "url": "https://arxiv.org/abs/2207.09933",
    "authors": [
      "Luojie Huang",
      "Yikang Liu",
      "Li Chen",
      "Eric Z. Chen",
      "Xiao Chen",
      "Shanhui Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10172",
    "title": "Video Anomaly Detection by Solving Decoupled Spatio-Temporal Jigsaw  Puzzles",
    "abstract": " Comments: Accepted by ECCV'2022; Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2207.10172",
    "authors": [
      "Guodong Wang",
      "Yunhong Wang",
      "Jie Qin",
      "Dongming Zhang",
      "Xiuguo Bao",
      "Di Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10241",
    "title": "Unsupervised Legendre-Galerkin Neural Network for Stiff Partial  Differential Equations",
    "abstract": " Comments: 29 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2207.10241",
    "authors": [
      "Junho Choi",
      "Namjung Kim",
      "Youngjoon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  }
]