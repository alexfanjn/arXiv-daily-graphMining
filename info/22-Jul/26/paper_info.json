[
  {
    "id": "arXiv:2207.11311",
    "title": "Understanding Non-linearity in Graph Neural Networks from the  Bayesian-Inference Perspective",
    "abstract": "Graph neural networks (GNNs) have shown superiority in many prediction tasks over graphs due to their impressive capability of capturing nonlinear relations in graph-structured data. However, for node classification tasks, often, only marginal improvement of GNNs over their linear counterparts has been observed. Previous works provide very few understandings of this phenomenon. In this work, we resort to Bayesian learning to deeply investigate the functions of non-linearity in GNNs for node classification tasks. Given a graph generated from the statistical model CSBM, we observe that the max-a-posterior estimation of a node label given its own and neighbors' attributes consists of two types of non-linearity, a possibly non-linear transformation of node attributes and a ReLU-activated feature aggregation from neighbors. The latter surprisingly matches the type of non-linearity used in many GNN models. By further imposing Gaussian assumption on node attributes, we prove that the superiority of those ReLU activations is only significant when the node attributes are far more informative than the graph structure, which nicely matches many previous empirical observations. A similar argument can be achieved when there is a distribution shift of node attributes between the training and testing datasets. Finally, we verify our theory on both synthetic and real-world networks. ",
    "url": "https://arxiv.org/abs/2207.11311",
    "authors": [
      "Rongzhe Wei",
      "Haoteng Yin",
      "Junteng Jia",
      "Austin R. Benson",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.11321",
    "title": "A flexible PageRank-based graph embedding framework closely related to  spectral eigenvector embeddings",
    "abstract": "We study a simple embedding technique based on a matrix of personalized PageRank vectors seeded on a random set of nodes. We show that the embedding produced by the element-wise logarithm of this matrix (1) are related to the spectral embedding for a class of graphs where spectral embeddings are significant, and hence useful representation of the data, (2) can be done for the entire network or a smaller part of it, which enables precise local representation, and (3) uses a relatively small number of PageRank vectors compared to the size of the networks. Most importantly, the general nature of this embedding strategy opens up many emerging applications, where eigenvector and spectral techniques may not be well established, to the PageRank-based relatives. For instance, similar techniques can be used on PageRank vectors from hypergraphs to get \"spectral-like\" embeddings. ",
    "url": "https://arxiv.org/abs/2207.11321",
    "authors": [
      "Disha Shur",
      "Yufan Huang",
      "David F. Gleich"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11325",
    "title": "PieTrack: An MOT solution based on synthetic data training and  self-supervised domain adaptation",
    "abstract": "In order to cope with the increasing demand for labeling data and privacy issues with human detection, synthetic data has been used as a substitute and showing promising results in human detection and tracking tasks. We participate in the 7th Workshop on Benchmarking Multi-Target Tracking (BMTT), themed on \"How Far Can Synthetic Data Take us\"? Our solution, PieTrack, is developed based on synthetic data without using any pre-trained weights. We propose a self-supervised domain adaptation method that enables mitigating the domain shift issue between the synthetic (e.g., MOTSynth) and real data (e.g., MOT17) without involving extra human labels. By leveraging the proposed multi-scale ensemble inference, we achieved a final HOTA score of 58.7 on the MOT17 testing set, ranked third place in the challenge. ",
    "url": "https://arxiv.org/abs/2207.11325",
    "authors": [
      "Yirui Wang",
      "Shenghua He",
      "Youbao Tang",
      "Jingyu Chen",
      "Honghao Zhou",
      "Sanliang Hong",
      "Junjie Liang",
      "Yanxin Huang",
      "Ning Zhang",
      "Ruei-Sung Lin",
      "Mei Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11333",
    "title": "Scalable training of graph convolutional neural networks for fast and  accurate predictions of HOMO-LUMO gap in molecules",
    "abstract": "Graph Convolutional Neural Network (GCNN) is a popular class of deep learning (DL) models in material science to predict material properties from the graph representation of molecular structures. Training an accurate and comprehensive GCNN surrogate for molecular design requires large-scale graph datasets and is usually a time-consuming process. Recent advances in GPUs and distributed computing open a path to reduce the computational cost for GCNN training effectively. However, efficient utilization of high performance computing (HPC) resources for training requires simultaneously optimizing large-scale data management and scalable stochastic batched optimization techniques. In this work, we focus on building GCNN models on HPC systems to predict material properties of millions of molecules. We use HydraGNN, our in-house library for large-scale GCNN training, leveraging distributed data parallelism in PyTorch. We use ADIOS, a high-performance data management framework for efficient storage and reading of large molecular graph data. We perform parallel training on two open-source large-scale graph datasets to build a GCNN predictor for an important quantum property known as the HOMO-LUMO gap. We measure the scalability, accuracy, and convergence of our approach on two DOE supercomputers: the Summit supercomputer at the Oak Ridge Leadership Computing Facility (OLCF) and the Perlmutter system at the National Energy Research Scientific Computing Center (NERSC). We present our experimental results with HydraGNN showing i) reduction of data loading time up to 4.2 times compared with a conventional method and ii) linear scaling performance for training up to 1,024 GPUs on both Summit and Perlmutter. ",
    "url": "https://arxiv.org/abs/2207.11333",
    "authors": [
      "Jong Youl Choi",
      "Pei Zhang",
      "Kshitij Mehta",
      "Andrew Blanchard",
      "Massimiliano Lupo Pasini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2207.11335",
    "title": "Generalizing Homophily to Simplicial Complexes",
    "abstract": "Group interactions occur frequently in social settings, yet their properties beyond pairwise relationships in network models remain unexplored. In this work, we study homophily, the nearly ubiquitous phenomena wherein similar individuals are more likely than random to form connections with one another, and define it on simplicial complexes, a generalization of network models that goes beyond dyadic interactions. While some group homophily definitions have been proposed in the literature, we provide theoretical and empirical evidence that prior definitions mostly inherit properties of homophily in pairwise interactions rather than capture the homophily of group dynamics. Hence, we propose a new measure, $k$-simplicial homophily, which properly identifies homophily in group dynamics. Across 16 empirical networks, $k$-simplicial homophily provides information uncorrelated with homophily measures on pairwise interactions. Moreover, we show the empirical value of $k$-simplicial homophily in identifying when metadata on nodes is useful for predicting group interactions, whereas previous measures are uninformative. ",
    "url": "https://arxiv.org/abs/2207.11335",
    "authors": [
      "Arnab Sarker",
      "Natalie Northrup",
      "Ali Jadbabaie"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Algebraic Topology (math.AT)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2207.11341",
    "title": "Dynamic Graph Reasoning for Multi-person 3D Pose Estimation",
    "abstract": "Multi-person 3D pose estimation is a challenging task because of occlusion and depth ambiguity, especially in the cases of crowd scenes. To solve these problems, most existing methods explore modeling body context cues by enhancing feature representation with graph neural networks or adding structural constraints. However, these methods are not robust for their single-root formulation that decoding 3D poses from a root node with a pre-defined graph. In this paper, we propose GR-M3D, which models the \\textbf{M}ulti-person \\textbf{3D} pose estimation with dynamic \\textbf{G}raph \\textbf{R}easoning. The decoding graph in GR-M3D is predicted instead of pre-defined. In particular, It firstly generates several data maps and enhances them with a scale and depth aware refinement module (SDAR). Then multiple root keypoints and dense decoding paths for each person are estimated from these data maps. Based on them, dynamic decoding graphs are built by assigning path weights to the decoding paths, while the path weights are inferred from those enhanced data maps. And this process is named dynamic graph reasoning (DGR). Finally, the 3D poses are decoded according to dynamic decoding graphs for each detected person. GR-M3D can adjust the structure of the decoding graph implicitly by adopting soft path weights according to input data, which makes the decoding graphs be adaptive to different input persons to the best extent and more capable of handling occlusion and depth ambiguity than previous methods. We empirically show that the proposed bottom-up approach even outperforms top-down methods and achieves state-of-the-art results on three 3D pose datasets. ",
    "url": "https://arxiv.org/abs/2207.11341",
    "authors": [
      "Zhongwei Qiu",
      "Qiansheng Yang",
      "Jian Wang",
      "Dongmei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11347",
    "title": "An Impartial Take to the CNN vs Transformer Robustness Contest",
    "abstract": "Following the surge of popularity of Transformers in Computer Vision, several studies have attempted to determine whether they could be more robust to distribution shifts and provide better uncertainty estimates than Convolutional Neural Networks (CNNs). The almost unanimous conclusion is that they are, and it is often conjectured more or less explicitly that the reason of this supposed superiority is to be attributed to the self-attention mechanism. In this paper we perform extensive empirical analyses showing that recent state-of-the-art CNNs (particularly, ConvNeXt) can be as robust and reliable or even sometimes more than the current state-of-the-art Transformers. However, there is no clear winner. Therefore, although it is tempting to state the definitive superiority of one family of architectures over another, they seem to enjoy similar extraordinary performances on a variety of tasks while also suffering from similar vulnerabilities such as texture, background, and simplicity biases. ",
    "url": "https://arxiv.org/abs/2207.11347",
    "authors": [
      "Francesco Pinto",
      "Philip H.S. Torr",
      "Puneet K. Dokania"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11352",
    "title": "Deep neural network heatmaps capture Alzheimer's disease patterns  reported in a large meta-analysis of neuroimaging studies",
    "abstract": "Deep neural networks currently provide the most advanced and accurate machine learning models to distinguish between structural MRI scans of subjects with Alzheimer's disease and healthy controls. Unfortunately, the subtle brain alterations captured by these models are difficult to interpret because of the complexity of these multi-layer and non-linear models. Several heatmap methods have been proposed to address this issue and analyze the imaging patterns extracted from the deep neural networks, but no quantitative comparison between these methods has been carried out so far. In this work, we explore these questions by deriving heatmaps from Convolutional Neural Networks (CNN) trained using T1 MRI scans of the ADNI data set, and by comparing these heatmaps with brain maps corresponding to Support Vector Machines (SVM) coefficients. Three prominent heatmap methods are studied: Layer-wise Relevance Propagation (LRP), Integrated Gradients (IG), and Guided Grad-CAM (GGC). Contrary to prior studies where the quality of heatmaps was visually or qualitatively assessed, we obtained precise quantitative measures by computing overlap with a ground-truth map from a large meta-analysis that combined 77 voxel-based morphometry (VBM) studies independently from ADNI. Our results indicate that all three heatmap methods were able to capture brain regions covering the meta-analysis map and achieved better results than SVM coefficients. Among them, IG produced the heatmaps with the best overlap with the independent meta-analysis. ",
    "url": "https://arxiv.org/abs/2207.11352",
    "authors": [
      "Di Wang",
      "Nicolas Honnorat",
      "Peter T. Fox",
      "Kerstin Ritter",
      "Simon B. Eickhoff",
      "Sudha Seshadri",
      "Mohamad Habes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11360",
    "title": "Hardware-based Scheduler Implementation for Dynamic Workloads on  Heterogeneous SoCs",
    "abstract": "Non-uniform performance and power consumption across the processing elements (PEs) of heterogeneous SoCs increase the computation complexity of the task scheduling problem compared to homogeneous architectures. Latency of a software-based scheduler with the increased heterogeneity level in terms of number and types of PEs creates the necessity of deploying a scheduler as an overlay processor in hardware to be able to make scheduling decisions rapidly and enable deployment of real-life applications on heterogeneous SoCs. In this study we present the design trade-offs involved for implementing and deploying the runtime variant of the heterogeneous earliest finish time algorithm (HEFT_RT) on the FPGA. We conduct performance evaluations on a SoC configuration emulated over the Xilinx Zynq ZCU102 platform. In a runtime environment we demonstrate hardware-based HEFT_RT's ability to make scheduling decisions with 9.144 ns latency on average, process 26.7% more tasks per second compared to its software counterpart, and reduce the scheduling latency by up to a factor of 183x based on workloads composed of mixture of dynamically arriving real-life signal processing applications. ",
    "url": "https://arxiv.org/abs/2207.11360",
    "authors": [
      "Alexander Fusco",
      "Sahil Hassan",
      "Joshua Mack",
      "Ali Akoglu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2207.11363",
    "title": "Knowledge-Grounded Conversational Data Augmentation with Generative  Conversational Networks",
    "abstract": "While rich, open-domain textual data are generally available and may include interesting phenomena (humor, sarcasm, empathy, etc.) most are designed for language processing tasks, and are usually in a non-conversational format. In this work, we take a step towards automatically generating conversational data using Generative Conversational Networks, aiming to benefit from the breadth of available language and knowledge data, and train open domain social conversational agents. We evaluate our approach on conversations with and without knowledge on the Topical Chat dataset using automatic metrics and human evaluators. Our results show that for conversations without knowledge grounding, GCN can generalize from the seed data, producing novel conversations that are less relevant but more engaging and for knowledge-grounded conversations, it can produce more knowledge-focused, fluent, and engaging conversations. Specifically, we show that for open-domain conversations with 10\\% of seed data, our approach performs close to the baseline that uses 100% of the data, while for knowledge-grounded conversations, it achieves the same using only 1% of the data, on human ratings of engagingness, fluency, and relevance. ",
    "url": "https://arxiv.org/abs/2207.11363",
    "authors": [
      "Yen-Ting Lin",
      "Alexandros Papangelis",
      "Seokhwan Kim",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.11378",
    "title": "Do Perceptually Aligned Gradients Imply Adversarial Robustness?",
    "abstract": "In the past decade, deep learning-based networks have achieved unprecedented success in numerous tasks, including image classification. Despite this remarkable achievement, recent studies have demonstrated that such networks are easily fooled by small malicious perturbations, also known as adversarial examples. This security weakness led to extensive research aimed at obtaining robust models. Beyond the clear robustness benefits of such models, it was also observed that their gradients with respect to the input align with human perception. Several works have identified Perceptually Aligned Gradients (PAG) as a byproduct of robust training, but none have considered it as a standalone phenomenon nor studied its own implications. In this work, we focus on this trait and test whether Perceptually Aligned Gradients imply Robustness. To this end, we develop a novel objective to directly promote PAG in training classifiers and examine whether models with such gradients are more robust to adversarial attacks. Extensive experiments on CIFAR-10 and STL validate that such models have improved robust performance, exposing the surprising bidirectional connection between PAG and robustness. ",
    "url": "https://arxiv.org/abs/2207.11378",
    "authors": [
      "Roy Ganz",
      "Bahjat Kawar",
      "Michael Elad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11382",
    "title": "Density-Aware Personalized Training for Risk Prediction in Imbalanced  Medical Data",
    "abstract": "Medical events of interest, such as mortality, often happen at a low rate in electronic medical records, as most admitted patients survive. Training models with this imbalance rate (class density discrepancy) may lead to suboptimal prediction. Traditionally this problem is addressed through ad-hoc methods such as resampling or reweighting but performance in many cases is still limited. We propose a framework for training models for this imbalance issue: 1) we first decouple the feature extraction and classification process, adjusting training batches separately for each component to mitigate bias caused by class density discrepancy; 2) we train the network with both a density-aware loss and a learnable cost matrix for misclassifications. We demonstrate our model's improved performance in real-world medical datasets (TOPCAT and MIMIC-III) to show improved AUC-ROC, AUC-PRC, Brier Skill Score compared with the baselines in the domain. ",
    "url": "https://arxiv.org/abs/2207.11382",
    "authors": [
      "Zepeng Huo",
      "Xiaoning Qian",
      "Shuai Huang",
      "Zhangyang Wang",
      "Bobak Mortazavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11385",
    "title": "Causal Fairness Analysis",
    "abstract": "Decision-making systems based on AI and machine learning have been used throughout a wide range of real-world scenarios, including healthcare, law enforcement, education, and finance. It is no longer far-fetched to envision a future where autonomous systems will be driving entire business decisions and, more broadly, supporting large-scale decision-making infrastructure to solve society's most challenging problems. Issues of unfairness and discrimination are pervasive when decisions are being made by humans, and remain (or are potentially amplified) when decisions are made using machines with little transparency, accountability, and fairness. In this paper, we introduce a framework for \\textit{causal fairness analysis} with the intent of filling in this gap, i.e., understanding, modeling, and possibly solving issues of fairness in decision-making settings. The main insight of our approach will be to link the quantification of the disparities present on the observed data with the underlying, and often unobserved, collection of causal mechanisms that generate the disparity in the first place, challenge we call the Fundamental Problem of Causal Fairness Analysis (FPCFA). In order to solve the FPCFA, we study the problem of decomposing variations and empirical measures of fairness that attribute such variations to structural mechanisms and different units of the population. Our effort culminates in the Fairness Map, which is the first systematic attempt to organize and explain the relationship between different criteria found in the literature. Finally, we study which causal assumptions are minimally needed for performing causal fairness analysis and propose a Fairness Cookbook, which allows data scientists to assess the existence of disparate impact and disparate treatment. ",
    "url": "https://arxiv.org/abs/2207.11385",
    "authors": [
      "Drago Plecko",
      "Elias Bareinboim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.11386",
    "title": "Learning to Route in Mobile Wireless Networks",
    "abstract": "Designing effective routing strategies for mobile wireless networks is challenging due to the need to seamlessly adapt routing behavior to spatially diverse and temporally changing network conditions. In this work, we use deep reinforcement learning (DeepRL) to learn a scalable and generalizable single-copy routing strategy for such networks. We make the following contributions: i) we design a reward function that enables the DeepRL agent to explicitly trade-off competing network goals, such as minimizing delay vs. the number of transmissions per packet; ii) we propose a novel set of relational neighborhood, path, and context features to characterize mobile wireless networks and model device mobility independently of a specific network topology; and iii) we use a flexible training approach that allows us to combine data from all packets and devices into a single offline centralized training set to train a single DeepRL agent. To evaluate generalizeability and scalability, we train our DeepRL agent on one mobile network scenario and then test it on other mobile scenarios, varying the number of devices and transmission ranges. Our results show our learned single-copy routing strategy outperforms all other strategies in terms of delay except for the optimal strategy, even on scenarios on which the DeepRL agent was not trained. ",
    "url": "https://arxiv.org/abs/2207.11386",
    "authors": [
      "Victoria Manfredi",
      "Alicia P. Wolfe",
      "Xiaolan Zhang",
      "Bing Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11396",
    "title": "Orientation and Context Entangled Network for Retinal Vessel  Segmentation",
    "abstract": "Most of the existing deep learning based methods for vessel segmentation neglect two important aspects of retinal vessels, one is the orientation information of vessels, and the other is the contextual information of the whole fundus region. In this paper, we propose a robust Orientation and Context Entangled Network (denoted as OCE-Net), which has the capability of extracting complex orientation and context information of the blood vessels. To achieve complex orientation aware, a Dynamic Complex Orientation Aware Convolution (DCOA Conv) is proposed to extract complex vessels with multiple orientations for improving the vessel continuity. To simultaneously capture the global context information and emphasize the important local information, a Global and Local Fusion Module (GLFM) is developed to simultaneously model the long-range dependency of vessels and focus sufficient attention on local thin vessels. A novel Orientation and Context Entangled Non-local (OCE-NL) module is proposed to entangle the orientation and context information together. In addition, an Unbalanced Attention Refining Module (UARM) is proposed to deal with the unbalanced pixel numbers of background, thick and thin vessels. Extensive experiments were performed on several commonly used datasets (DRIVE, STARE and CHASEDB1) and some more challenging datasets (AV-WIDE, UoA-DR, RFMiD and UK Biobank). The ablation study shows that the proposed method achieves promising performance on maintaining the continuity of thin vessels and the comparative experiments demonstrate that our OCE-Net can achieve state-of-the-art performance on retinal vessel segmentation. ",
    "url": "https://arxiv.org/abs/2207.11396",
    "authors": [
      "Xinxu Wei",
      "Kaifu Yang",
      "Danilo Bzdok",
      "Yongjie Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11402",
    "title": "A Novel Rapid-flooding Approach with Real-time Delay Compensation for  Wireless Sensor Network Time Synchronization",
    "abstract": "One-way-broadcast based flooding time synchronization algorithms are commonly used in wireless sensor networks (WSNs). However, the packet delay and clock drift pose challenges to accuracy, as they entail serious by-hop error accumulation problems in the WSNs. To overcome it, a rapid flooding multi-broadcast time synchronization with real-time delay compensation (RDC-RMTS) is proposed in this paper. By using a rapid-flooding protocol, flooding latency of the referenced time information is significantly reduced in the RDC-RMTS. In addition, a new joint clock skew-offset maximum likelihood estimation is developed to obtain the accurate clock parameter estimations, and the real-time packet delay estimation. Moreover, an innovative implementation of the RDC-RMTS is designed with an adaptive clock offset estimation. The experimental results indicate that, the RDC-RMTS can easily reduce the variable delay and significantly slow the growth of by-hop error accumulation. Thus, the proposed RDC-RMTS can achieve accurate time synchronization in large-scale complex WSNs. ",
    "url": "https://arxiv.org/abs/2207.11402",
    "authors": [
      "Fanrong Shi",
      "Simon X. Yang",
      "Xianguo Tuo",
      "Lili Ran",
      "Yuqing Huang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.11406",
    "title": "PS-NeRF: Neural Inverse Rendering for Multi-view Photometric Stereo",
    "abstract": "Traditional multi-view photometric stereo (MVPS) methods are often composed of multiple disjoint stages, resulting in noticeable accumulated errors. In this paper, we present a neural inverse rendering method for MVPS based on implicit representation. Given multi-view images of a non-Lambertian object illuminated by multiple unknown directional lights, our method jointly estimates the geometry, materials, and lights. Our method first employs multi-light images to estimate per-view surface normal maps, which are used to regularize the normals derived from the neural radiance field. It then jointly optimizes the surface normals, spatially-varying BRDFs, and lights based on a shadow-aware differentiable rendering layer. After optimization, the reconstructed object can be used for novel-view rendering, relighting, and material editing. Experiments on both synthetic and real datasets demonstrate that our method achieves far more accurate shape reconstruction than existing MVPS and neural rendering methods. Our code and model can be found at https://ywq.github.io/psnerf. ",
    "url": "https://arxiv.org/abs/2207.11406",
    "authors": [
      "Wenqi Yang",
      "Guanying Chen",
      "Chaofeng Chen",
      "Zhenfang Chen",
      "Kwan-Yee K. Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.11412",
    "title": "Satellite Detection in Unresolved Space Imagery for Space Domain  Awareness Using Neural Networks",
    "abstract": "This work utilizes a MobileNetV2 Convolutional Neural Network (CNN) for fast, mobile detection of satellites, and rejection of stars, in cluttered unresolved space imagery. First, a custom database is created using imagery from a synthetic satellite image program and labeled with bounding boxes over satellites for \"satellite-positive\" images. The CNN is then trained on this database and the inference is validated by checking the accuracy of the model on an external dataset constructed of real telescope imagery. In doing so, the trained CNN provides a method of rapid satellite identification for subsequent utilization in ground-based orbit estimation. ",
    "url": "https://arxiv.org/abs/2207.11412",
    "authors": [
      "Jarred Jordan",
      "Daniel Posada",
      "David Zuehlke",
      "Angelica Radulovic",
      "Aryslan Malik",
      "Troy Henderson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11413",
    "title": "Detection and Initial Assessment of Lunar Landing Sites Using Neural  Networks",
    "abstract": "Robotic and human lunar landings are a focus of future NASA missions. Precision landing capabilities are vital to guarantee the success of the mission, and the safety of the lander and crew. During the approach to the surface there are multiple challenges associated with Hazard Relative Navigation to ensure safe landings. This paper will focus on a passive autonomous hazard detection and avoidance sub-system to generate an initial assessment of possible landing regions for the guidance system. The system uses a single camera and the MobileNetV2 neural network architecture to detect and discern between safe landing sites and hazards such as rocks, shadows, and craters. Then a monocular structure from motion will recreate the surface to provide slope and roughness analysis. ",
    "url": "https://arxiv.org/abs/2207.11413",
    "authors": [
      "Daniel Posada",
      "Jarred Jordan",
      "Angelica Radulovic",
      "Lillian Hong",
      "Aryslan Malik",
      "Troy Henderson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11417",
    "title": "Multiscale Neural Operator: Learning Fast and Grid-independent PDE  Solvers",
    "abstract": "Numerical simulations in climate, chemistry, or astrophysics are computationally too expensive for uncertainty quantification or parameter-exploration at high-resolution. Reduced-order or surrogate models are multiple orders of magnitude faster, but traditional surrogates are inflexible or inaccurate and pure machine learning (ML)-based surrogates too data-hungry. We propose a hybrid, flexible surrogate model that exploits known physics for simulating large-scale dynamics and limits learning to the hard-to-model term, which is called parametrization or closure and captures the effect of fine- onto large-scale dynamics. Leveraging neural operators, we are the first to learn grid-independent, non-local, and flexible parametrizations. Our \\textit{multiscale neural operator} is motivated by a rich literature in multiscale modeling, has quasilinear runtime complexity, is more accurate or flexible than state-of-the-art parametrizations and demonstrated on the chaotic equation multiscale Lorenz96. ",
    "url": "https://arxiv.org/abs/2207.11417",
    "authors": [
      "Bj\u00f6rn L\u00fctjens",
      "Catherine H. Crawford",
      "Campbell D Watson",
      "Christopher Hill",
      "Dava Newman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2207.11436",
    "title": "Facing Changes: Continual Entity Alignment for Growing Knowledge Graphs",
    "abstract": "Entity alignment is a basic and vital technique in knowledge graph (KG) integration. Over the years, research on entity alignment has resided on the assumption that KGs are static, which neglects the nature of growth of real-world KGs. As KGs grow, previous alignment results face the need to be revisited while new entity alignment waits to be discovered. In this paper, we propose and dive into a realistic yet unexplored setting, referred to as continual entity alignment. To avoid retraining an entire model on the whole KGs whenever new entities and triples come, we present a continual alignment method for this task. It reconstructs an entity's representation based on entity adjacency, enabling it to generate embeddings for new entities quickly and inductively using their existing neighbors. It selects and replays partial pre-aligned entity pairs to train only parts of KGs while extracting trustworthy alignment for knowledge augmentation. As growing KGs inevitably contain non-matchable entities, different from previous works, the proposed method employs bidirectional nearest neighbor matching to find new entity alignment and update old alignment. Furthermore, we also construct new datasets by simulating the growth of multilingual DBpedia. Extensive experiments demonstrate that our continual alignment method is more effective than baselines based on retraining or inductive learning. ",
    "url": "https://arxiv.org/abs/2207.11436",
    "authors": [
      "Yuxin Wang",
      "Yuanning Cui",
      "Wenqiang Liu",
      "Zequn Sun",
      "Yiqiao Jiang",
      "Kexin Han",
      "Wei Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2207.11437",
    "title": "The prediction of the quality of results in Logic Synthesis using  Transformer and Graph Neural Networks",
    "abstract": "In the logic synthesis stage, structure transformations in the synthesis tool need to be combined into optimization sequences and act on the circuit to meet the specified circuit area and delay. However, logic synthesis optimization sequences are time-consuming to run, and predicting the quality of the results (QoR) against the synthesis optimization sequence for a circuit can help engineers find a better optimization sequence faster. In this work, we propose a deep learning method to predict the QoR of unseen circuit-optimization sequences pairs. Specifically, the structure transformations are translated into vectors by embedding methods and advanced natural language processing (NLP) technology (Transformer) is used to extract the features of the optimization sequences. In addition, to enable the prediction process of the model to be generalized from circuit to circuit, the graph representation of the circuit is represented as an adjacency matrix and a feature matrix. Graph neural networks(GNN) are used to extract the structural features of the circuits. For this problem, the Transformer and three typical GNNs are used. Furthermore, the Transformer and GNNs are adopted as a joint learning policy for the QoR prediction of the unseen circuit-optimization sequences. The methods resulting from the combination of Transformer and GNNs are benchmarked. The experimental results show that the joint learning of Transformer and GraphSage gives the best results. The Mean Absolute Error (MAE) of the predicted result is 0.412. ",
    "url": "https://arxiv.org/abs/2207.11437",
    "authors": [
      "Chenghao Yang",
      "Yinshui Xia",
      "Zhufei Chu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11441",
    "title": "Meta Spatio-Temporal Debiasing for Video Scene Graph Generation",
    "abstract": "Video scene graph generation (VidSGG) aims to parse the video content into scene graphs, which involves modeling the spatio-temporal contextual information in the video. However, due to the long-tailed training data in datasets, the generalization performance of existing VidSGG models can be affected by the spatio-temporal conditional bias problem. In this work, from the perspective of meta-learning, we propose a novel Meta Video Scene Graph Generation (MVSGG) framework to address such a bias problem. Specifically, to handle various types of spatio-temporal conditional biases, our framework first constructs a support set and a group of query sets from the training data, where the data distribution of each query set is different from that of the support set w.r.t. a type of conditional bias. Then, by performing a novel meta training and testing process to optimize the model to obtain good testing performance on these query sets after training on the support set, our framework can effectively guide the model to learn to well generalize against biases. Extensive experiments demonstrate the efficacy of our proposed framework. ",
    "url": "https://arxiv.org/abs/2207.11441",
    "authors": [
      "Li Xu",
      "Haoxuan Qu",
      "Jason Kuen",
      "Jiuxiang Gu",
      "Jun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11442",
    "title": "$\u03bc\\text{KG}$: A Library for Multi-source Knowledge Graph Embeddings  and Applications",
    "abstract": "This paper presents $\\mu\\text{KG}$, an open-source Python library for representation learning over knowledge graphs. $\\mu\\text{KG}$ supports joint representation learning over multi-source knowledge graphs (and also a single knowledge graph), multiple deep learning libraries (PyTorch and TensorFlow2), multiple embedding tasks (link prediction, entity alignment, entity typing, and multi-source link prediction), and multiple parallel computing modes (multi-process and multi-GPU computing). It currently implements 26 popular knowledge graph embedding models and supports 16 benchmark datasets. $\\mu\\text{KG}$ provides advanced implementations of embedding techniques with simplified pipelines of different tasks. It also comes with high-quality documentation for ease of use. $\\mu\\text{KG}$ is more comprehensive than existing knowledge graph embedding libraries. It is useful for a thorough comparison and analysis of various embedding models and tasks. We show that the jointly learned embeddings can greatly help knowledge-powered downstream tasks, such as multi-hop knowledge graph question answering. We will stay abreast of the latest developments in the related fields and incorporate them into $\\mu\\text{KG}$. ",
    "url": "https://arxiv.org/abs/2207.11442",
    "authors": [
      "Xindi Luo",
      "Zequn Sun",
      "Wei Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11455",
    "title": "UC-OWOD: Unknown-Classified Open World Object Detection",
    "abstract": "Open World Object Detection (OWOD) is a challenging computer vision problem that requires detecting unknown objects and gradually learning the identified unknown classes. However, it cannot distinguish unknown instances as multiple unknown classes. In this work, we propose a novel OWOD problem called Unknown-Classified Open World Object Detection (UC-OWOD). UC-OWOD aims to detect unknown instances and classify them into different unknown classes. Besides, we formulate the problem and devise a two-stage object detector to solve UC-OWOD. First, unknown label-aware proposal and unknown-discriminative classification head are used to detect known and unknown objects. Then, similarity-based unknown classification and unknown clustering refinement modules are constructed to distinguish multiple unknown classes. Moreover, two novel evaluation protocols are designed to evaluate unknown-class detection. Abundant experiments and visualizations prove the effectiveness of the proposed method. Code is available at https://github.com/JohnWuzh/UC-OWOD. ",
    "url": "https://arxiv.org/abs/2207.11455",
    "authors": [
      "Zhiheng Wu",
      "Yue Lu",
      "Xingyu Chen",
      "Zhengxing Wu",
      "Liwen Kang",
      "Junzhi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11463",
    "title": "When Counting Meets HMER: Counting-Aware Network for Handwritten  Mathematical Expression Recognition",
    "abstract": "Recently, most handwritten mathematical expression recognition (HMER) methods adopt the encoder-decoder networks, which directly predict the markup sequences from formula images with the attention mechanism. However, such methods may fail to accurately read formulas with complicated structure or generate long markup sequences, as the attention results are often inaccurate due to the large variance of writing styles or spatial layouts. To alleviate this problem, we propose an unconventional network for HMER named Counting-Aware Network (CAN), which jointly optimizes two tasks: HMER and symbol counting. Specifically, we design a weakly-supervised counting module that can predict the number of each symbol class without the symbol-level position annotations, and then plug it into a typical attention-based encoder-decoder model for HMER. Experiments on the benchmark datasets for HMER validate that both joint optimization and counting results are beneficial for correcting the prediction errors of encoder-decoder models, and CAN consistently outperforms the state-of-the-art methods. In particular, compared with an encoder-decoder model for HMER, the extra time cost caused by the proposed counting module is marginal. The source code is available at https://github.com/LBH1024/CAN. ",
    "url": "https://arxiv.org/abs/2207.11463",
    "authors": [
      "Bohan Li",
      "Ye Yuan",
      "Dingkang Liang",
      "Xiao Liu",
      "Zhilong Ji",
      "Jinfeng Bai",
      "Wenyu Liu",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.11464",
    "title": "Learning Object Placement via Dual-path Graph Completion",
    "abstract": "Object placement aims to place a foreground object over a background image with a suitable location and size. In this work, we treat object placement as a graph completion problem and propose a novel graph completion module (GCM). The background scene is represented by a graph with multiple nodes at different spatial locations with various receptive fields. The foreground object is encoded as a special node that should be inserted at a reasonable place in this graph. We also design a dual-path framework upon the structure of GCM to fully exploit annotated composite images. With extensive experiments on OPA dataset, our method proves to significantly outperform existing methods in generating plausible object placement without loss of diversity. ",
    "url": "https://arxiv.org/abs/2207.11464",
    "authors": [
      "Siyuan Zhou",
      "Liu Liu",
      "Li Niu",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11465",
    "title": "Distributed Nonlinear State Estimation in Electric Power Systems using  Graph Neural Networks",
    "abstract": "Nonlinear state estimation (SE), with the goal of estimating complex bus voltages based on all types of measurements available in the power system, is usually solved using the iterative Gauss-Newton method. The nonlinear SE presents some difficulties when considering inputs from both phasor measurement units and supervisory control and data acquisition system. These include numerical instabilities, convergence time depending on the starting point of the iterative method, and the quadratic computational complexity of a single iteration regarding the number of state variables. This paper introduces an original graph neural network based SE implementation over the augmented factor graph of the nonlinear power system SE, capable of incorporating measurements on both branches and buses, as well as both phasor and legacy measurements. The proposed regression model has linear computational complexity during the inference time once trained, with a possibility of distributed implementation. Since the method is noniterative and non-matrix-based, it is resilient to the problems that the Gauss-Newton solver is prone to. Aside from prediction accuracy on the test set, the proposed model demonstrates robustness when simulating cyber attacks and unobservable scenarios due to communication irregularities. In those cases, prediction errors are sustained locally, with no effect on the rest of the power system's results. ",
    "url": "https://arxiv.org/abs/2207.11465",
    "authors": [
      "Ognjen Kundacina",
      "Mirsad Cosovic",
      "Dragisa Miskovic",
      "Dejan Vukobratovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11466",
    "title": "Anomaly Detection for Fraud in Cryptocurrency Time Series",
    "abstract": "Since the inception of Bitcoin in 2009, the market of cryptocurrencies has grown beyond initial expectations as daily trades exceed $10 billion. As industries become automated, the need for an automated fraud detector becomes very apparent. Detecting anomalies in real time prevents potential accidents and economic losses. Anomaly detection in multivariate time series data poses a particular challenge because it requires simultaneous consideration of temporal dependencies and relationships between variables. Identifying an anomaly in real time is not an easy task specifically because of the exact anomalistic behavior they observe. Some points may present pointwise global or local anomalistic behavior, while others may be anomalistic due to their frequency or seasonal behavior or due to a change in the trend. In this paper we suggested working on real time series of trades of Ethereum from specific accounts and surveyed a large variety of different algorithms traditional and new. We categorized them according to the strategy and the anomalistic behavior which they search and showed that when bundling them together to different groups, they can prove to be a good real-time detector with an alarm time of no longer than a few seconds and with very high confidence. ",
    "url": "https://arxiv.org/abs/2207.11466",
    "authors": [
      "Eran Kaufman",
      "Andrey Iaremenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.11474",
    "title": "Investigating the Validity of Botometer-based Social Bot Studies",
    "abstract": "The idea that social media platforms like Twitter are inhabited by vast numbers of social bots has become widely accepted in recent years. Social bots are assumed to be automated social media accounts operated by malicious actors with the goal of manipulating public opinion. They are credited with the ability to produce content autonomously and to interact with human users. Social bot activity has been reported in many different political contexts, including the U.S. presidential elections, discussions about migration, climate change, and COVID-19. However, the relevant publications either use crude and questionable heuristics to discriminate between supposed social bots and humans or -- in the vast majority of the cases -- fully rely on the output of automatic bot detection tools, most commonly Botometer. In this paper, we point out a fundamental theoretical flaw in the widely-used study design for estimating the prevalence of social bots. Furthermore, we empirically investigate the validity of peer-reviewed Botometer-based studies by closely and systematically inspecting hundreds of accounts that had been counted as social bots. We were unable to find a single social bot. Instead, we found mostly accounts undoubtedly operated by human users, the vast majority of them using Twitter in an inconspicuous and unremarkable fashion without the slightest traces of automation. We conclude that studies claiming to investigate the prevalence, properties, or influence of social bots based on Botometer have, in reality, just investigated false positives and artifacts of this approach. ",
    "url": "https://arxiv.org/abs/2207.11474",
    "authors": [
      "Florian Gallwitz",
      "Michael Kreil"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2207.11477",
    "title": "All you need for horizontal slicing in 5G network",
    "abstract": "The telecommunication field has seen unprecedented growth in the last decade that has led to the release of several generations that have been committed to satisfy users by increasing the data rate and reducing the latency, especially in the 5G network. With fully commercialized 5G networks that is already launched in many country, Software-defined network (SDN) and network function virtualization (NFV) will facilitate the implementation of NS. SDN and NFV will serve as the basis for NS, allowing efficient use of both physical and virtual resources. This paper makes it possible to analyze, propose an efficient model, and utilize all of the available resources of the 5G network. ",
    "url": "https://arxiv.org/abs/2207.11477",
    "authors": [
      "Hamza Kheddar",
      "Soufiane Ouldkhaoua",
      "Riadh Bouguerra"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.11484",
    "title": "GraphFit: Learning Multi-scale Graph-Convolutional Representation for  Point Cloud Normal Estimation",
    "abstract": "We propose a precise and efficient normal estimation method that can deal with noise and nonuniform density for unstructured 3D point clouds. Unlike existing approaches that directly take patches and ignore the local neighborhood relationships, which make them susceptible to challenging regions such as sharp edges, we propose to learn graph convolutional feature representation for normal estimation, which emphasizes more local neighborhood geometry and effectively encodes intrinsic relationships. Additionally, we design a novel adaptive module based on the attention mechanism to integrate point features with their neighboring features, hence further enhancing the robustness of the proposed normal estimator against point density variations. To make it more distinguishable, we introduce a multi-scale architecture in the graph block to learn richer geometric features. Our method outperforms competitors with the state-of-the-art accuracy on various benchmark datasets, and is quite robust against noise, outliers, as well as the density variations. ",
    "url": "https://arxiv.org/abs/2207.11484",
    "authors": [
      "Keqiang Li",
      "Mingyang Zhao",
      "Huaiyu Wu",
      "Dong-Ming Yan",
      "Zhen Shen",
      "Fei-Yue Wang",
      "Gang Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11486",
    "title": "Time Series Prediction under Distribution Shift using Differentiable  Forgetting",
    "abstract": "Time series prediction is often complicated by distribution shift which demands adaptive models to accommodate time-varying distributions. We frame time series prediction under distribution shift as a weighted empirical risk minimisation problem. The weighting of previous observations in the empirical risk is determined by a forgetting mechanism which controls the trade-off between the relevancy and effective sample size that is used for the estimation of the predictive model. In contrast to previous work, we propose a gradient-based learning method for the parameters of the forgetting mechanism. This speeds up optimisation and therefore allows more expressive forgetting mechanisms. ",
    "url": "https://arxiv.org/abs/2207.11486",
    "authors": [
      "Stefanos Bennett",
      "Jase Clarkson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)"
    ]
  },
  {
    "id": "arXiv:2207.11490",
    "title": "Towards Smart Fake News Detection Through Explainable AI",
    "abstract": "People now see social media sites as their sole source of information due to their popularity. The Majority of people get their news through social media. At the same time, fake news has grown exponentially on social media platforms in recent years. Several artificial intelligence-based solutions for detecting fake news have shown promising results. On the other hand, these detection systems lack explanation capabilities, i.e., the ability to explain why they made a prediction. This paper highlights the current state of the art in explainable fake news detection. We discuss the pitfalls in the current explainable AI-based fake news detection models and present our ongoing research on multi-modal explainable fake news detection model. ",
    "url": "https://arxiv.org/abs/2207.11490",
    "authors": [
      "Athira A B",
      "S D Madhu Kumar",
      "Anu Mary Chacko"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.11497",
    "title": "Patent Search Using Triplet Networks Based Fine-Tuned SciBERT",
    "abstract": "In this paper, we propose a novel method for the prior-art search task. We fine-tune SciBERT transformer model using Triplet Network approach, allowing us to represent each patent with a fixed-size vector. This also enables us to conduct efficient vector similarity computations to rank patents in query time. In our experiments, we show that our proposed method outperforms baseline methods. ",
    "url": "https://arxiv.org/abs/2207.11497",
    "authors": [
      "Utku Umur Acikalin",
      "Mucahid Kutlu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2207.11500",
    "title": "Catch Me If You Can: Deceiving Stance Detection and Geotagging Models to  Protect Privacy of Individuals on Twitter",
    "abstract": "The recent advances in natural language processing have yielded many exciting developments in text analysis and language understanding models; however, these models can also be used to track people, bringing severe privacy concerns. In this work, we investigate what individuals can do to avoid being detected by those models while using social media platforms. We ground our investigation in two exposure-risky tasks, stance detection and geotagging. We explore a variety of simple techniques for modifying text, such as inserting typos in salient words, paraphrasing, and adding dummy social media posts. Our experiments show that the performance of BERT-based models fined tuned for stance detection decreases significantly due to typos, but it is not affected by paraphrasing. Moreover, we find that typos have minimal impact on state-of-the-art geotagging models due to their increased reliance on social networks; however, we show that users can deceive those models by interacting with different users, reducing their performance by almost 50%. ",
    "url": "https://arxiv.org/abs/2207.11500",
    "authors": [
      "Dilara Dogan",
      "Bahadir Altun",
      "Muhammed Said Zengin",
      "Mucahid Kutlu",
      "Tamer Elsayed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.11504",
    "title": "Intelligent 3D Network Protocol for Multimedia Data Classification using  Deep Learning",
    "abstract": "In videos, the human's actions are of three-dimensional (3D) signals. These videos investigate the spatiotemporal knowledge of human behavior. The promising ability is investigated using 3D convolution neural networks (CNNs). The 3D CNNs have not yet achieved high output for their well-established two-dimensional (2D) equivalents in still photographs. Board 3D Convolutional Memory and Spatiotemporal fusion face training difficulty preventing 3D CNN from accomplishing remarkable evaluation. In this paper, we implement Hybrid Deep Learning Architecture that combines STIP and 3D CNN features to enhance the performance of 3D videos effectively. After implementation, the more detailed and deeper charting for training in each circle of space-time fusion. The training model further enhances the results after handling complicated evaluations of models. The video classification model is used in this implemented model. Intelligent 3D Network Protocol for Multimedia Data Classification using Deep Learning is introduced to further understand spacetime association in human endeavors. In the implementation of the result, the well-known dataset, i.e., UCF101 to, evaluates the performance of the proposed hybrid technique. The results beat the proposed hybrid technique that substantially beats the initial 3D CNNs. The results are compared with state-of-the-art frameworks from literature for action recognition on UCF101 with an accuracy of 95%. ",
    "url": "https://arxiv.org/abs/2207.11504",
    "authors": [
      "Arslan Syed",
      "Eman A. Aldhahri",
      "Muhammad Munawar Iqbal",
      "Abid Ali",
      "Ammar Muthanna",
      "Harun Jamil",
      "Faisal Jamil"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.11524",
    "title": "Audio-driven Neural Gesture Reenactment with Video Motion Graphs",
    "abstract": "Human speech is often accompanied by body gestures including arm and hand gestures. We present a method that reenacts a high-quality video with gestures matching a target speech audio. The key idea of our method is to split and re-assemble clips from a reference video through a novel video motion graph encoding valid transitions between clips. To seamlessly connect different clips in the reenactment, we propose a pose-aware video blending network which synthesizes video frames around the stitched frames between two clips. Moreover, we developed an audio-based gesture searching algorithm to find the optimal order of the reenacted frames. Our system generates reenactments that are consistent with both the audio rhythms and the speech content. We evaluate our synthesized video quality quantitatively, qualitatively, and with user studies, demonstrating that our method produces videos of much higher quality and consistency with the target audio compared to previous work and baselines. ",
    "url": "https://arxiv.org/abs/2207.11524",
    "authors": [
      "Yang Zhou",
      "Jimei Yang",
      "Dingzeyu Li",
      "Jun Saito",
      "Deepali Aneja",
      "Evangelos Kalogerakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11539",
    "title": "HPS-Det: Dynamic Sample Assignment with Hyper-Parameter Search for  Object Detection",
    "abstract": "Sample assignment plays a prominent part in modern object detection approaches. However, most existing methods rely on manual design to assign positive / negative samples, which do not explicitly establish the relationships between sample assignment and object detection performance. In this work, we propose a novel dynamic sample assignment scheme based on hyper-parameter search. We first define the number of positive samples assigned to each ground truth as the hyper-parameters and employ a surrogate optimization algorithm to derive the optimal choices. Then, we design a dynamic sample assignment procedure to dynamically select the optimal number of positives at each training iteration. Experiments demonstrate that the resulting HPS-Det brings improved performance over different object detection baselines. Moreover, We analyze the hyper-parameter reusability when transferring between different datasets and between different backbones for object detection, which exhibits the superiority and versatility of our method. ",
    "url": "https://arxiv.org/abs/2207.11539",
    "authors": [
      "Ji Liu",
      "Dong Li",
      "Zekun Li",
      "Han Liu",
      "Wenjing Ke",
      "Lu Tian",
      "Yi Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11541",
    "title": "FastATDC: Fast Anomalous Trajectory Detection and Classification",
    "abstract": "Automated detection of anomalous trajectories is an important problem with considerable applications in intelligent transportation systems. Many existing studies have focused on distinguishing anomalous trajectories from normal trajectories, ignoring the large differences between anomalous trajectories. A recent study has made great progress in identifying abnormal trajectory patterns and proposed a two-stage algorithm for anomalous trajectory detection and classification (ATDC). This algorithm has excellent performance but suffers from a few limitations, such as high time complexity and poor interpretation. Here, we present a careful theoretical and empirical analysis of the ATDC algorithm, showing that the calculation of anomaly scores in both stages can be simplified, and that the second stage of the algorithm is much more important than the first stage. Hence, we develop a FastATDC algorithm that introduces a random sampling strategy in both stages. Experimental results show that FastATDC is 10 to 20 times faster than ATDC on real datasets. Moreover, FastATDC outperforms the baseline algorithms and is comparable to the ATDC algorithm. ",
    "url": "https://arxiv.org/abs/2207.11541",
    "authors": [
      "Tianle Ni",
      "Jingwei Wang",
      "Yunlong Ma",
      "Shuang Wang",
      "Min Liu",
      "Weiming Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11542",
    "title": "Annealed Training for Combinatorial Optimization on Graphs",
    "abstract": "The hardness of combinatorial optimization (CO) problems hinders collecting solutions for supervised learning. However, learning neural networks for CO problems is notoriously difficult in lack of the labeled data as the training is easily trapped at local optima. In this work, we propose a simple but effective annealed training framework for CO problems. In particular, we transform CO problems into unbiased energy-based models (EBMs). We carefully selected the penalties terms so as to make the EBMs as smooth as possible. Then we train graph neural networks to approximate the EBMs. To prevent the training from being stuck at local optima near the initialization, we introduce an annealed loss function. An experimental evaluation demonstrates that our annealed training framework obtains substantial improvements. In four types of CO problems, our method achieves performance substantially better than other unsupervised neural methods on both synthetic and real-world graphs. ",
    "url": "https://arxiv.org/abs/2207.11542",
    "authors": [
      "Haoran Sun",
      "Etash K. Guha",
      "Hanjun Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11562",
    "title": "Better Reasoning Behind Classification Predictions with BERT for Fake  News Detection",
    "abstract": "Fake news detection has become a major task to solve as there has been an increasing number of fake news on the internet in recent years. Although many classification models have been proposed based on statistical learning methods showing good results, reasoning behind the classification performances may not be enough. In the self-supervised learning studies, it has been highlighted that a quality of representation (embedding) space matters and directly affects a downstream task performance. In this study, a quality of the representation space is analyzed visually and analytically in terms of linear separability for different classes on a real and fake news dataset. To further add interpretability to a classification model, a modification of Class Activation Mapping (CAM) is proposed. The modified CAM provides a CAM score for each word token, where the CAM score on a word token denotes a level of focus on that word token to make the prediction. Finally, it is shown that the naive BERT model topped with a learnable linear layer is enough to achieve robust performance while being compatible with CAM. ",
    "url": "https://arxiv.org/abs/2207.11562",
    "authors": [
      "Daesoo Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.11564",
    "title": "A general-purpose method for applying Explainable AI for Anomaly  Detection",
    "abstract": "The need for explainable AI (XAI) is well established but relatively little has been published outside of the supervised learning paradigm. This paper focuses on a principled approach to applying explainability and interpretability to the task of unsupervised anomaly detection. We argue that explainability is principally an algorithmic task and interpretability is principally a cognitive task, and draw on insights from the cognitive sciences to propose a general-purpose method for practical diagnosis using explained anomalies. We define Attribution Error, and demonstrate, using real-world labeled datasets, that our method based on Integrated Gradients (IG) yields significantly lower attribution errors than alternative methods. ",
    "url": "https://arxiv.org/abs/2207.11564",
    "authors": [
      "John Sipple",
      "Abdou Youssef"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.11575",
    "title": "Testing the Robustness of Learned Index Structures",
    "abstract": "While early empirical evidence has supported the case for learned index structures as having favourable average-case performance, little is known about their worst-case performance. By contrast, classical structures are known to achieve optimal worst-case behaviour. This work evaluates the robustness of learned index structures in the presence of adversarial workloads. To simulate adversarial workloads, we carry out a data poisoning attack on linear regression models that manipulates the cumulative distribution function (CDF) on which the learned index model is trained. The attack deteriorates the fit of the underlying ML model by injecting a set of poisoning keys into the training dataset, which leads to an increase in the prediction error of the model and thus deteriorates the overall performance of the learned index structure. We assess the performance of various regression methods and the learned index implementations ALEX and PGM-Index. We show that learned index structures can suffer from a significant performance deterioration of up to 20% when evaluated on poisoned vs. non-poisoned datasets. ",
    "url": "https://arxiv.org/abs/2207.11575",
    "authors": [
      "Matthias Bachfischer",
      "Renata Borovica-Gajic",
      "Benjamin I. P. Rubinstein"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11577",
    "title": "Augmented Bilinear Network for Incremental Multi-Stock Time-Series  Classification",
    "abstract": "Deep Learning models have become dominant in tackling financial time-series analysis problems, overturning conventional machine learning and statistical methods. Most often, a model trained for one market or security cannot be directly applied to another market or security due to differences inherent in the market conditions. In addition, as the market evolves through time, it is necessary to update the existing models or train new ones when new data is made available. This scenario, which is inherent in most financial forecasting applications, naturally raises the following research question: How to efficiently adapt a pre-trained model to a new set of data while retaining performance on the old data, especially when the old data is not accessible? In this paper, we propose a method to efficiently retain the knowledge available in a neural network pre-trained on a set of securities and adapt it to achieve high performance in new ones. In our method, the prior knowledge encoded in a pre-trained neural network is maintained by keeping existing connections fixed, and this knowledge is adjusted for the new securities by a set of augmented connections, which are optimized using the new data. The auxiliary connections are constrained to be of low rank. This not only allows us to rapidly optimize for the new task but also reduces the storage and run-time complexity during the deployment phase. The efficiency of our approach is empirically validated in the stock mid-price movement prediction problem using a large-scale limit order book dataset. Experimental results show that our approach enhances prediction performance as well as reduces the overall number of network parameters. ",
    "url": "https://arxiv.org/abs/2207.11577",
    "authors": [
      "Mostafa Shabani",
      "Dat Thanh Tran",
      "Juho Kanniainen",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)"
    ]
  },
  {
    "id": "arXiv:2207.11578",
    "title": "A Scalable Bayesian Persuasion Framework for Epidemic Containment on  Heterogeneous Networks",
    "abstract": "During an epidemic, the information available to individuals in the society deeply influences their belief of the epidemic spread, and consequently the preventive measures they take to stay safe from the infection. In this paper, we develop a scalable framework for ascertaining the optimal information disclosure a government must make to individuals in a networked society for the purpose of epidemic containment. This problem of information design problem is complicated by the heterogeneous nature of the society, the positive externalities faced by individuals, and the variety in the public response to such disclosures. We use a networked public goods model to capture the underlying societal structure. Our first main result is a structural decomposition of the government's objectives into two independent components -- a component dependent on the utility function of individuals, and another dependent on properties of the underlying network. Since the network dependent term in this decomposition is unaffected by the signals sent by the government, this characterization simplifies the problem of finding the optimal information disclosure policies. We find explicit conditions, in terms of the risk aversion and prudence, under which no disclosure, full disclosure, exaggeration and downplay are the optimal policies. The structural decomposition results are also helpful in studying other forms of interventions like incentive design and network design. ",
    "url": "https://arxiv.org/abs/2207.11578",
    "authors": [
      "Shraddha Pathak",
      "Ankur A. Kulkarni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2207.11581",
    "title": "Self-Supervised Learning of Echocardiogram Videos Enables Data-Efficient  Clinical Diagnosis",
    "abstract": "Given the difficulty of obtaining high-quality labels for medical image recognition tasks, there is a need for deep learning techniques that can be adequately fine-tuned on small labeled data sets. Recent advances in self-supervised learning techniques have shown that such an in-domain representation learning approach can provide a strong initialization for supervised fine-tuning, proving much more data-efficient than standard transfer learning from a supervised pretraining task. However, these applications are not adapted to applications to medical diagnostics captured in a video format. With this progress in mind, we developed a self-supervised learning approach catered to echocardiogram videos with the goal of learning strong representations for downstream fine-tuning on the task of diagnosing aortic stenosis (AS), a common and dangerous disease of the aortic valve. When fine-tuned on 1% of the training data, our best self-supervised learning model achieves 0.818 AUC (95% CI: 0.794, 0.840), while the standard transfer learning approach reaches 0.644 AUC (95% CI: 0.610, 0.677). We also find that our self-supervised model attends more closely to the aortic valve when predicting severe AS as demonstrated by saliency map visualizations. ",
    "url": "https://arxiv.org/abs/2207.11581",
    "authors": [
      "Gregory Holste",
      "Evangelos K. Oikonomou",
      "Bobak Mortazavi",
      "Zhangyang Wang",
      "Rohan Khera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11586",
    "title": "Path Tracing in 2D, 3D, and Physicalized Networks",
    "abstract": "It is common to advise against using 3D to visualize abstract data such as networks, however Ware and Mitchell's 2008 study showed that path tracing in a network is less error prone in 3D than in 2D. It is unclear, however, if 3D retains its advantage when the 2D presentation of a network is improved using edge-routing, and when simple interaction techniques for exploring the network are available. We address this with two studies of path tracing under new conditions. The first study was preregistered, involved 34 users, and compared 2D and 3D layouts that the user could rotate and move in virtual reality with a handheld controller. Error rates were lower in 3D than in 2D, despite the use of edge-routing in 2D and the use of mouse-driven interactive highlighting of edges. The second study involved 12 users and investigated data physicalization, comparing 3D layouts in virtual reality versus physical 3D printouts of networks augmented with a Microsoft HoloLens headset. No difference was found in error rate, but users performed a variety of actions with their fingers in the physical condition which can inform new interaction techniques. ",
    "url": "https://arxiv.org/abs/2207.11586",
    "authors": [
      "Michael J. McGuffin",
      "Ryan Servera",
      "Marie Forest"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2207.11615",
    "title": "SyncPCN/PSyncPCN: Payment Channel Networks without Blockchain Synchrony",
    "abstract": "Payment channel networks (PCNs) enhance the scalability of blockchains by allowing parties to conduct transactions off-chain, i.e, without broadcasting every transaction to all blockchain participants. To conduct transactions, a sender and a receiver can either establish a direct payment channel with a funding blockchain transaction or leverage existing channels in a multi-hop payment. The security of PCNs usually relies on the synchrony of the underlying blockchain, i.e., evidence of misbehavior needs to be published on the blockchain within a time limit. Alternative payment channel proposals that do not require blockchain synchrony rely on quorum certificates and use a committee to register the transactions of a channel. However, these proposals do not support multi-hop payments, a limitation we aim to overcome. In this paper, we demonstrate that it is in fact impossible to design a multi-hop payment protocol with both network asynchrony and faulty channels, i.e., channels that may not correctly follow the protocol. We then detail two committee-based multi-hop payment protocols that respectively assume synchronous communications and possibly faulty channels, or asynchronous communication and correct channels. The first protocol relies on possibly faulty committees instead of the blockchain to resolve channel disputes, and enforces privacy properties within a synchronous network. The second one relies on committees that contain at most f faulty members out of 3f+1 and successively delegate to each other the role of eventually completing a multi-hop payment. We show that both protocols satisfy the security requirements of a multi-hop payment and compare their communication complexity and latency. ",
    "url": "https://arxiv.org/abs/2207.11615",
    "authors": [
      "O\u011fuzhan Ersoy",
      "J\u00e9r\u00e9mie Decouchant",
      "Satwik Prabhu Kimble",
      "Stefanie Roos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2207.11620",
    "title": "Instant Neural Representation for Interactive Volume Rendering",
    "abstract": "Neural networks have shown great potential in compressing volumetric data for scientific visualization. However, due to the high cost of training and inference, such volumetric neural representations have thus far only been applied to offline data processing and non-interactive rendering. In this paper, we demonstrate that by simultaneously leveraging modern GPU tensor cores, a native CUDA neural network framework, and online training, we can achieve high-performance and high-fidelity interactive ray tracing using volumetric neural representations. Additionally, our method is fully generalizable and can adapt to time-varying datasets on-the-fly. We present three strategies for online training with each leveraging a different combination of the GPU, the CPU, and out-of-core-streaming techniques. We also develop three rendering implementations that allow interactive ray tracing to be coupled with real-time volume decoding, sample streaming, and in-shader neural network inference. We demonstrate that our volumetric neural representations can scale up to terascale for regular-grid volume visualization, and can easily support irregular data structures such as OpenVDB, unstructured, AMR, and particle volume data. ",
    "url": "https://arxiv.org/abs/2207.11620",
    "authors": [
      "Qi Wu",
      "Michael J. Doyle",
      "David Bauer",
      "Kwan-Liu Ma"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11623",
    "title": "A Simplistic and Cost-Effective Design for Real-World Development of an  Ambient Assisted Living System for Fall Detection and Indoor Localization:  Proof of Concept",
    "abstract": "Falls, highly common in the constantly increasing global aging population, can have a variety of negative effects on their health, well-being, and quality of life, including restricting their capabilities to conduct Activities of Daily Living (ADLs), which are crucial for one's sustenance. Timely assistance during falls is highly necessary, which involves tracking the indoor location of the elderly during their diverse navigational patterns associated with ADLs to detect the precise location of a fall. With the decreasing caregiver population on a global scale, it is important that the future of intelligent living environments can detect falls during ADLs while being able to track the indoor location of the elderly in the real world. To address these challenges, this work proposes a cost-effective and simplistic design paradigm for an Ambient Assisted Living system that can capture multimodal components of user behaviors during ADLs that are necessary for performing fall detection and indoor localization in a simultaneous manner in the real world. Proof of concept results from real-world experiments are presented to uphold the effective working of the system. The findings from two comparison studies with prior works in this field are also presented to uphold the novelty of this work. The first comparison study shows how the proposed system outperforms prior works in the areas of indoor localization and fall detection in terms of the effectiveness of its software design and hardware design. The second comparison study shows that the cost for the development of this system is the least as compared to prior works in these fields, which involved real-world development of the underlining systems, thereby upholding its cost-effective nature. ",
    "url": "https://arxiv.org/abs/2207.11623",
    "authors": [
      "Nirmalya Thakur",
      "Chia Y. Han"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11627",
    "title": "Example Driven Code Review Explanation",
    "abstract": "Background: Code reviewing is an essential part of software development to ensure software quality. However, the abundance of review tasks and the intensity of the workload for reviewers negatively impact the quality of the reviews. The short review text is often unactionable, which needs further interaction between the reviewer and the developer. The problem becomes more critical in dynamic teams and in the case of new team members who are less familiar with their reviewers and perspectives. Aims: We are proposing the Example Driven Review Explanation (EDRE) method to facilitate the code review process by adding additional explanations through examples. EDRE recommends similar code reviews as examples to further explain a review and help a developer to understand the received reviews with less communication overhead. Method: Through an empirical study in an industrial setting and by analyzing 3,722 code reviews across three open-source projects, we compared five methods of data retrieval, text classification, and text recommendation. Results: EDRE using TF-IDF word embedding along with an SVM classifier can provide practical examples for each code review with 92% F-score and 90% Accuracy. Conclusions: The example-based explanation is an established method for assisting experts in explaining decisions. EDRE was developed based on the same philosophy and can accurately provide a set of context-specific examples to facilitate the code review process in software teams. ",
    "url": "https://arxiv.org/abs/2207.11627",
    "authors": [
      "Shadikur Rahman",
      "Umme Ayman Koana",
      "Maleknaz Nayebi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2207.11641",
    "title": "Clustered Cell-Free Networking: A Graph Partitioning Approach",
    "abstract": "By moving to millimeter wave (mmWave) frequencies, base stations (BSs) will be densely deployed to provide seamless coverage in sixth generation (6G) mobile communication systems, which, unfortunately, leads to severe cell-edge problem. In addition, with massive multiple-input-multiple-output (MIMO) antenna arrays employed at BSs, the beamspace channel is sparse for each user, and thus there is no need to serve all the users in a cell by all the beams therein jointly. Therefore, it is of paramount importance to develop a flexible clustered cell-free networking scheme that can decompose the whole network into a number of weakly interfered small subnetworks operating independently and in parallel. Given a per-user rate constraint for service quality guarantee, this paper aims to maximize the number of decomposed subnetworks so as to reduce the signaling overhead and system complexity as much as possible. By formulating it as a bipartite graph partitioning problem, a rate-constrained network decomposition (RC-NetDecomp) algorithm is proposed, which can smoothly tune the network structure from the current cellular network with simple beam allocation to a fully cooperative network by increasing the required per-user rate. Simulation results demonstrate that the proposed RC-NetDecomp algorithm outperforms existing baselines in terms of average per-user rate, fairness among users and energy efficiency. ",
    "url": "https://arxiv.org/abs/2207.11641",
    "authors": [
      "Junyuan Wang",
      "Lin Dai",
      "Lu Yang",
      "Bo Bai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.11643",
    "title": "Robust Scene Inference under Noise-Blur Dual Corruptions",
    "abstract": "Scene inference under low-light is a challenging problem due to severe noise in the captured images. One way to reduce noise is to use longer exposure during the capture. However, in the presence of motion (scene or camera motion), longer exposures lead to motion blur, resulting in loss of image information. This creates a trade-off between these two kinds of image degradations: motion blur (due to long exposure) vs. noise (due to short exposure), also referred as a dual image corruption pair in this paper. With the rise of cameras capable of capturing multiple exposures of the same scene simultaneously, it is possible to overcome this trade-off. Our key observation is that although the amount and nature of degradation varies for these different image captures, the semantic content remains the same across all images. To this end, we propose a method to leverage these multi exposure captures for robust inference under low-light and motion. Our method builds on a feature consistency loss to encourage similar results from these individual captures, and uses the ensemble of their final predictions for robust visual recognition. We demonstrate the effectiveness of our approach on simulated images as well as real captures with multiple exposures, and across the tasks of object detection and image classification. ",
    "url": "https://arxiv.org/abs/2207.11643",
    "authors": [
      "Bhavya Goyal",
      "Jean-Fran\u00e7ois Lalonde",
      "Yin Li",
      "Mohit Gupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11646",
    "title": "A Parallel Novelty Search Metaheuristic Applied to a Wildfire Prediction  System",
    "abstract": "Wildfires are a highly prevalent multi-causal environmental phenomenon. The impact of this phenomenon includes human losses, environmental damage and high economic costs. To mitigate these effects, several computer simulation systems have been developed in order to predict fire behavior based on a set of input parameters, also called a scenario (wind speed and direction; temperature; etc.). However, the results of a simulation usually have a high degree of error due to the uncertainty in the values of some variables, because they are not known, or because their measurement may be imprecise, erroneous, or impossible to perform in real time. Previous works have proposed the combination of multiple results in order to reduce this uncertainty. State-of-the-art methods are based on parallel optimization strategies that use a fitness function to guide the search among all possible scenarios. Although these methods have shown improvements in the quality of predictions, they have some limitations related to the algorithms used for the selection of scenarios. To overcome these limitations, in this work we propose to apply the Novelty Search paradigm, which replaces the objective function by a measure of the novelty of the solutions found, which allows the search to continuously generate solutions with behaviors that differ from one another. This approach avoids local optima and may be able to find useful solutions that would be difficult or impossible to find by other algorithms. As with existing methods, this proposal may also be adapted to other propagation models (floods, avalanches or landslides). ",
    "url": "https://arxiv.org/abs/2207.11646",
    "authors": [
      "Jan Strappa",
      "Paola Caymes-Scutari",
      "Germ\u00e1n Bianchini"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2207.11649",
    "title": "OCTAL: Graph Representation Learning for LTL Model Checking",
    "abstract": "Model Checking is widely applied in verifying the correctness of complex and concurrent systems against a specification. Pure symbolic approaches while popular, still suffer from the state space explosion problem that makes them impractical for large scale systems and/or specifications. In this paper, we propose to use graph representation learning (GRL) for solving linear temporal logic (LTL) model checking, where the system and the specification are expressed by a B\\\"uchi automaton and an LTL formula respectively. A novel GRL-based framework OCTAL, is designed to learn the representation of the graph-structured system and specification, which reduces the model checking problem to binary classification in the latent space. The empirical experiments show that OCTAL achieves comparable accuracy against canonical SOTA model checkers on three different datasets, with up to $5\\times$ overall speedup and above $63\\times$ for satisfiability checking alone. ",
    "url": "https://arxiv.org/abs/2207.11649",
    "authors": [
      "Prasita Mukherjee",
      "Haoteng Yin",
      "Susheel Suresh",
      "Tiark Rompf"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11661",
    "title": "Degree Centrality Algorithms For Homogeneous Multilayer Networks",
    "abstract": "Centrality measures for simple graphs/networks are well-defined and each has numerous main-memory algorithms. However, for modeling complex data sets with multiple types of entities and relationships, simple graphs are not ideal. Multilayer networks (or MLNs) have been proposed for modeling them and have been shown to be better suited in many ways. Since there are no algorithms for computing centrality measures directly on MLNs, existing strategies reduce (aggregate or collapse) the MLN layers to simple networks using Boolean AND or OR operators. This approach negates the benefits of MLN modeling as these computations tend to be expensive and furthermore results in loss of structure and semantics. In this paper, we propose heuristic-based algorithms for computing centrality measures (specifically, degree centrality) on MLNs directly (i.e., without reducing them to simple graphs) using a newly-proposed decoupling-based approach which is efficient as well as structure and semantics preserving. We propose multiple heuristics to calculate the degree centrality using the network decoupling-based approach and compare accuracy and precision with Boolean OR aggregated Homogeneous MLNs (HoMLN) for ground truth. The network decoupling approach can take advantage of parallelism and is more efficient compared to aggregation-based approaches. Extensive experimental analysis is performed on large synthetic and real-world data sets of varying characteristics to validate the accuracy and efficiency of our proposed algorithms. ",
    "url": "https://arxiv.org/abs/2207.11661",
    "authors": [
      "Hamza Reza Pavel",
      "Abhishek Santra",
      "Sharma Chakravarthy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.11662",
    "title": "Closeness Centrality Algorithms For Multilayer Networks",
    "abstract": "Centrality measures for simple graphs are well-defined and several main-memory algorithms exist for each. Simple graphs are not adequate for modeling complex data sets with multiple entities and relationships. Multilayer networks (MLNs) have been shown to be better suited, but there are very few algorithms for centrality computation directly on MLNs. They are converted (aggregated or collapsed) to simple graphs using Boolean AND or OR operators to compute centrality, which is not only inefficient but incurs a loss of structure and semantics. In this paper, we propose algorithms that compute closeness centrality on an MLN directly using a novel decoupling-based approach. Individual results of layers (or simple graphs) of an MLN are used and a composition function developed to compute the centrality for the MLN. The challenge is to do this accurately and efficiently. However, since these algorithms do not have complete information of the MLN, computing a global measure such as closeness centrality is a challenge. Hence, these algorithms rely on heuristics derived from intuition. The advantage is that this approach lends itself to parallelism and is more efficient compared to the traditional approach. We present two heuristics for composition and experimentally validate accuracy and efficiency on a large number of synthetic and real-world graphs with diverse characteristics. ",
    "url": "https://arxiv.org/abs/2207.11662",
    "authors": [
      "Hamza Reza Pavel",
      "Abhishek Santra",
      "Sharma Chakravarthy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.11669",
    "title": "Distributed Robust Principal Analysis",
    "abstract": "We study the robust principal component analysis (RPCA) problem in a distributed setting. The goal of RPCA is to find an underlying low-rank estimation for a raw data matrix when the data matrix is subject to the corruption of gross sparse errors. Previous studies have developed RPCA algorithms that provide stable solutions with fast convergence. However, these algorithms are typically hard to scale and cannot be implemented distributedly, due to the use of either SVD or large matrix multiplication. In this paper, we propose the first distributed robust principal analysis algorithm based on consensus factorization, dubbed DCF-PCA. We prove the convergence of DCF-PCA and evaluate DCF-PCA on various problem setting ",
    "url": "https://arxiv.org/abs/2207.11669",
    "authors": [
      "Wenda Chu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11670",
    "title": "Modeling Associative Plasticity between Synapses to Enhance Learning of  Spiking Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs) are the third generation of artificial neural networks that enable energy-efficient implementation on neuromorphic hardware. However, the discrete transmission of spikes brings significant challenges to the robust and high-performance learning mechanism. Most existing works focus solely on learning between neurons but ignore the influence between synapses, resulting in a loss of robustness and accuracy. To address this problem, we propose a robust and effective learning mechanism by modeling the associative plasticity between synapses (APBS) observed from the physiological phenomenon of associative long-term potentiation (ALTP). With the proposed APBS method, synapses of the same neuron interact through a shared factor when concurrently stimulated by other neurons. In addition, we propose a spatiotemporal cropping and flipping (STCF) method to improve the generalization ability of our network. Extensive experiments demonstrate that our approaches achieve superior performance on static CIFAR-10 datasets and state-of-the-art performance on neuromorphic MNIST-DVS, CIFAR10-DVS datasets by a lightweight convolution network. To our best knowledge, this is the first time to explore a learning method between synapses and an extended approach for neuromorphic data. ",
    "url": "https://arxiv.org/abs/2207.11670",
    "authors": [
      "Haibo Shen",
      "Juyu Xiao",
      "Yihao Luo",
      "Xiang Cao",
      "Liangqi Zhang",
      "Tianjiang Wang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2207.11680",
    "title": "No More Fine-Tuning? An Experimental Evaluation of Prompt Tuning in Code  Intelligence",
    "abstract": "Pre-trained models have been shown effective in many code intelligence tasks. These models are pre-trained on large-scale unlabeled corpus and then fine-tuned in downstream tasks. However, as the inputs to pre-training and downstream tasks are in different forms, it is hard to fully explore the knowledge of pre-trained models. Besides, the performance of fine-tuning strongly relies on the amount of downstream data, while in practice, the scenarios with scarce data are common. Recent studies in the natural language processing (NLP) field show that prompt tuning, a new paradigm for tuning, alleviates the above issues and achieves promising results in various NLP tasks. In prompt tuning, the prompts inserted during tuning provide task-specific knowledge, which is especially beneficial for tasks with relatively scarce data. In this paper, we empirically evaluate the usage and effect of prompt tuning in code intelligence tasks. We conduct prompt tuning on popular pre-trained models CodeBERT and CodeT5 and experiment with three code intelligence tasks including defect prediction, code summarization, and code translation. Our experimental results show that prompt tuning consistently outperforms fine-tuning in all three tasks. In addition, prompt tuning shows great potential in low-resource scenarios, e.g., improving the BLEU scores of fine-tuning by more than 26\\% on average for code summarization. Our results suggest that instead of fine-tuning, we could adapt prompt tuning for code intelligence tasks to achieve better performance, especially when lacking task-specific data. ",
    "url": "https://arxiv.org/abs/2207.11680",
    "authors": [
      "Chaozheng Wang",
      "Yuanhang Yang",
      "Cuiyun Gao",
      "Yun Peng",
      "Hongyu Zhang",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.11681",
    "title": "Learning Graph Neural Networks for Image Style Transfer",
    "abstract": "State-of-the-art parametric and non-parametric style transfer approaches are prone to either distorted local style patterns due to global statistics alignment, or unpleasing artifacts resulting from patch mismatching. In this paper, we study a novel semi-parametric neural style transfer framework that alleviates the deficiency of both parametric and non-parametric stylization. The core idea of our approach is to establish accurate and fine-grained content-style correspondences using graph neural networks (GNNs). To this end, we develop an elaborated GNN model with content and style local patches as the graph vertices. The style transfer procedure is then modeled as the attention-based heterogeneous message passing between the style and content nodes in a learnable manner, leading to adaptive many-to-one style-content correlations at the local patch level. In addition, an elaborated deformable graph convolutional operation is introduced for cross-scale style-content matching. Experimental results demonstrate that the proposed semi-parametric image stylization approach yields encouraging results on the challenging style patterns, preserving both global appearance and exquisite details. Furthermore, by controlling the number of edges at the inference stage, the proposed method also triggers novel functionalities like diversified patch-based stylization with a single model. ",
    "url": "https://arxiv.org/abs/2207.11681",
    "authors": [
      "Yongcheng Jing",
      "Yining Mao",
      "Yiding Yang",
      "Yibing Zhan",
      "Mingli Song",
      "Xinchao Wang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11694",
    "title": "Proving Common Mechanisms Shared by Twelve Methods of Boosting  Adversarial Transferability",
    "abstract": "Although many methods have been proposed to enhance the transferability of adversarial perturbations, these methods are designed in a heuristic manner, and the essential mechanism for improving adversarial transferability is still unclear. This paper summarizes the common mechanism shared by twelve previous transferability-boosting methods in a unified view, i.e., these methods all reduce game-theoretic interactions between regional adversarial perturbations. To this end, we focus on the attacking utility of all interactions between regional adversarial perturbations, and we first discover and prove the negative correlation between the adversarial transferability and the attacking utility of interactions. Based on this discovery, we theoretically prove and empirically verify that twelve previous transferability-boosting methods all reduce interactions between regional adversarial perturbations. More crucially, we consider the reduction of interactions as the essential reason for the enhancement of adversarial transferability. Furthermore, we design the interaction loss to directly penalize interactions between regional adversarial perturbations during attacking. Experimental results show that the interaction loss significantly improves the transferability of adversarial perturbations. ",
    "url": "https://arxiv.org/abs/2207.11694",
    "authors": [
      "Quanshi Zhang",
      "Xin Wang",
      "Jie Ren",
      "Xu Cheng",
      "Shuyun Lin",
      "Yisen Wang",
      "Xiangming Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11708",
    "title": "Towards an Improved Understanding of Software Vulnerability Assessment  Using Data-Driven Approaches",
    "abstract": "The thesis advances the field of software security by providing knowledge and automation support for software vulnerability assessment using data-driven approaches. Software vulnerability assessment provides important and multifaceted information to prevent and mitigate dangerous cyber-attacks in the wild. The key contributions include a systematisation of knowledge, along with a suite of novel data-driven techniques and practical recommendations for researchers and practitioners in the area. The thesis results help improve the understanding and inform the practice of assessing ever-increasing vulnerabilities in real-world software systems. This in turn enables more thorough and timely fixing prioritisation and planning of these critical security issues. ",
    "url": "https://arxiv.org/abs/2207.11708",
    "authors": [
      "Triet H. M. Le"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11727",
    "title": "Can we achieve robustness from data alone?",
    "abstract": "Adversarial training and its variants have come to be the prevailing methods to achieve adversarially robust classification using neural networks. However, its increased computational cost together with the significant gap between standard and robust performance hinder progress and beg the question of whether we can do better. In this work, we take a step back and ask: Can models achieve robustness via standard training on a suitably optimized set? To this end, we devise a meta-learning method for robust classification, that optimizes the dataset prior to its deployment in a principled way, and aims to effectively remove the non-robust parts of the data. We cast our optimization method as a multi-step PGD procedure on kernel regression, with a class of kernels that describe infinitely wide neural nets (Neural Tangent Kernels - NTKs). Experiments on MNIST and CIFAR-10 demonstrate that the datasets we produce enjoy very high robustness against PGD attacks, when deployed in both kernel regression classifiers and neural networks. However, this robustness is somewhat fallacious, as alternative attacks manage to fool the models, which we find to be the case for previous similar works in the literature as well. We discuss potential reasons for this and outline further avenues of research. ",
    "url": "https://arxiv.org/abs/2207.11727",
    "authors": [
      "Nikolaos Tsilivis",
      "Jingtong Su",
      "Julia Kempe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11735",
    "title": "AMS-Net: Adaptive Multiscale Sparse Neural Network with Interpretable  Basis Expansion for Multiphase Flow Problems",
    "abstract": "In this work, we propose an adaptive sparse learning algorithm that can be applied to learn the physical processes and obtain a sparse representation of the solution given a large snapshot space. Assume that there is a rich class of precomputed basis functions that can be used to approximate the quantity of interest. We then design a neural network architecture to learn the coefficients of solutions in the spaces which are spanned by these basis functions. The information of the basis functions are incorporated in the loss function, which minimizes the differences between the downscaled reduced order solutions and reference solutions at multiple time steps. The network contains multiple submodules and the solutions at different time steps can be learned simultaneously. We propose some strategies in the learning framework to identify important degrees of freedom. To find a sparse solution representation, a soft thresholding operator is applied to enforce the sparsity of the output coefficient vectors of the neural network. To avoid over-simplification and enrich the approximation space, some degrees of freedom can be added back to the system through a greedy algorithm. In both scenarios, that is, removing and adding degrees of freedom, the corresponding network connections are pruned or reactivated guided by the magnitude of the solution coefficients obtained from the network outputs. The proposed adaptive learning process is applied to some toy case examples to demonstrate that it can achieve a good basis selection and accurate approximation. More numerical tests are performed on two-phase multiscale flow problems to show the capability and interpretability of the proposed method on complicated applications. ",
    "url": "https://arxiv.org/abs/2207.11735",
    "authors": [
      "Yating Wang",
      "Wing Tat Leung",
      "Guang Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11757",
    "title": "Learning Generalizable Light Field Networks from Few Images",
    "abstract": "We explore a new strategy for few-shot novel view synthesis based on a neural light field representation. Given a target camera pose, an implicit neural network maps each ray to its target pixel's color directly. The network is conditioned on local ray features generated by coarse volumetric rendering from an explicit 3D feature volume. This volume is built from the input images using a 3D ConvNet. Our method achieves competitive performances on synthetic and real MVS data with respect to state-of-the-art neural radiance field based competition, while offering a 100 times faster rendering. ",
    "url": "https://arxiv.org/abs/2207.11757",
    "authors": [
      "Qian Li",
      "Franck Multon",
      "Adnane Boukhayma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.11761",
    "title": "SGAT: Simplicial Graph Attention Network",
    "abstract": "Heterogeneous graphs have multiple node and edge types and are semantically richer than homogeneous graphs. To learn such complex semantics, many graph neural network approaches for heterogeneous graphs use metapaths to capture multi-hop interactions between nodes. Typically, features from non-target nodes are not incorporated into the learning procedure. However, there can be nonlinear, high-order interactions involving multiple nodes or edges. In this paper, we present Simplicial Graph Attention Network (SGAT), a simplicial complex approach to represent such high-order interactions by placing features from non-target nodes on the simplices. We then use attention mechanisms and upper adjacencies to generate representations. We empirically demonstrate the efficacy of our approach with node classification tasks on heterogeneous graph datasets and further show SGAT's ability in extracting structural information by employing random node features. Numerical experiments indicate that SGAT performs better than other current state-of-the-art heterogeneous graph learning methods. ",
    "url": "https://arxiv.org/abs/2207.11761",
    "authors": [
      "See Hian Lee",
      "Feng Ji",
      "Wee Peng Tay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11769",
    "title": "CODiT: Conformal Out-of-Distribution Detection in Time-Series Data",
    "abstract": "Machine learning models are prone to making incorrect predictions on inputs that are far from the training distribution. This hinders their deployment in safety-critical applications such as autonomous vehicles and healthcare. The detection of a shift from the training distribution of individual datapoints has gained attention. A number of techniques have been proposed for such out-of-distribution (OOD) detection. But in many applications, the inputs to a machine learning model form a temporal sequence. Existing techniques for OOD detection in time-series data either do not exploit temporal relationships in the sequence or do not provide any guarantees on detection. We propose using deviation from the in-distribution temporal equivariance as the non-conformity measure in conformal anomaly detection framework for OOD detection in time-series data.Computing independent predictions from multiple conformal detectors based on the proposed measure and combining these predictions by Fisher's method leads to the proposed detector CODiT with guarantees on false detection in time-series data. We illustrate the efficacy of CODiT by achieving state-of-the-art results on computer vision datasets in autonomous driving. We also show that CODiT can be used for OOD detection in non-vision datasets by performing experiments on the physiological GAIT sensory dataset. Code, data, and trained models are available at https://github.com/kaustubhsridhar/time-series-OOD. ",
    "url": "https://arxiv.org/abs/2207.11769",
    "authors": [
      "Ramneet Kaur",
      "Kaustubh Sridhar",
      "Sangdon Park",
      "Susmit Jha",
      "Anirban Roy",
      "Oleg Sokolsky",
      "Insup Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11771",
    "title": "Image Denoising Using Convolutional Autoencoder",
    "abstract": "With the inexorable digitalisation of the modern world, every subset in the field of technology goes through major advancements constantly. One such subset is digital images which are ever so popular. Images can not always be as visually pleasing or clear as you would want them to be and are often distorted or obscured with noise. A number of techniques to enhance images have come up as the years passed, all with their own respective pros and cons. In this paper, we look at one such particular technique which accomplishes this task with the help of a neural network model commonly known as an autoencoder. We construct different architectures for the model and compare results in order to decide the one best suited for the task. The characteristics and working of the model are discussed briefly knowing which can help set a path for future research. ",
    "url": "https://arxiv.org/abs/2207.11771",
    "authors": [
      "Prashanth Venkataraman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.11773",
    "title": "N-LIMB: Neural Limb Optimization for Efficient Morphological Design",
    "abstract": "A robot's ability to complete a task is heavily dependent on its physical design. However, identifying an optimal physical design and its corresponding control policy is inherently challenging. The freedom to choose the number of links, their type, and how they are connected results in a combinatorial design space, and the evaluation of any design in that space requires deriving its optimal controller. In this work, we present N-LIMB, an efficient approach to optimizing the design and control of a robot over large sets of morphologies. Central to our framework is a universal, design-conditioned control policy capable of controlling a diverse sets of designs. This policy greatly improves the sample efficiency of our approach by allowing the transfer of experience across designs and reducing the cost to evaluate new designs. We train this policy to maximize expected return over a distribution of designs, which is simultaneously updated towards higher performing designs under the universal policy. In this way, our approach converges towards a design distribution peaked around high-performing designs and a controller that is effectively fine-tuned for those designs. We demonstrate the potential of our approach on a series of locomotion tasks across varying terrains and show the discovery novel and high-performing design-control pairs. ",
    "url": "https://arxiv.org/abs/2207.11773",
    "authors": [
      "Charles Schaff",
      "Matthew R. Walter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.11776",
    "title": "Incorporating Heterogeneous User Behaviors and Social Influences for  Predictive Analysis",
    "abstract": "Behavior prediction based on historical behavioral data have practical real-world significance. It has been applied in recommendation, predicting academic performance, etc. With the refinement of user data description, the development of new functions, and the fusion of multiple data sources, heterogeneous behavioral data which contain multiple types of behaviors become more and more common. In this paper, we aim to incorporate heterogeneous user behaviors and social influences for behavior predictions. To this end, this paper proposes a variant of Long-Short Term Memory (LSTM) which can consider context information while modeling a behavior sequence, a projection mechanism which can model multi-faceted relationships among different types of behaviors, and a multi-faceted attention mechanism which can dynamically find out informative periods from different facets. Many kinds of behavioral data belong to spatio-temporal data. An unsupervised way to construct a social behavior graph based on spatio-temporal data and to model social influences is proposed. Moreover, a residual learning-based decoder is designed to automatically construct multiple high-order cross features based on social behavior representation and other types of behavior representations. Qualitative and quantitative experiments on real-world datasets have demonstrated the effectiveness of this model. ",
    "url": "https://arxiv.org/abs/2207.11776",
    "authors": [
      "Haobing Liu",
      "Yanmin Zhu",
      "Chunyang Wang",
      "Jianyu Ding",
      "Jiadi Yu",
      "Feilong Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.11788",
    "title": "Privacy Against Inference Attacks in Vertical Federated Learning",
    "abstract": "Vertical federated learning is considered, where an active party, having access to true class labels, wishes to build a classification model by utilizing more features from a passive party, which has no access to the labels, to improve the model accuracy. In the prediction phase, with logistic regression as the classification model, several inference attack techniques are proposed that the adversary, i.e., the active party, can employ to reconstruct the passive party's features, regarded as sensitive information. These attacks, which are mainly based on a classical notion of the center of a set, i.e., the Chebyshev center, are shown to be superior to those proposed in the literature. Moreover, several theoretical performance guarantees are provided for the aforementioned attacks. Subsequently, we consider the minimum amount of information that the adversary needs to fully reconstruct the passive party's features. In particular, it is shown that when the passive party holds one feature, and the adversary is only aware of the signs of the parameters involved, it can perfectly reconstruct that feature when the number of predictions is large enough. Next, as a defense mechanism, two privacy-preserving schemes are proposed that worsen the adversary's reconstruction attacks, while preserving the full benefits that VFL brings to the active party. Finally, experimental results demonstrate the effectiveness of the proposed attacks and the privacy-preserving schemes. ",
    "url": "https://arxiv.org/abs/2207.11788",
    "authors": [
      "Borzoo Rassouli",
      "Morteza Varasteh",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2207.11789",
    "title": "Hierarchical Semi-Supervised Contrastive Learning for  Contamination-Resistant Anomaly Detection",
    "abstract": "Anomaly detection aims at identifying deviant samples from the normal data distribution. Contrastive learning has provided a successful way to sample representation that enables effective discrimination on anomalies. However, when contaminated with unlabeled abnormal samples in training set under semi-supervised settings, current contrastive-based methods generally 1) ignore the comprehensive relation between training data, leading to suboptimal performance, and 2) require fine-tuning, resulting in low efficiency. To address the above two issues, in this paper, we propose a novel hierarchical semi-supervised contrastive learning (HSCL) framework, for contamination-resistant anomaly detection. Specifically, HSCL hierarchically regulates three complementary relations: sample-to-sample, sample-to-prototype, and normal-to-abnormal relations, enlarging the discrimination between normal and abnormal samples with a comprehensive exploration of the contaminated data. Besides, HSCL is an end-to-end learning approach that can efficiently learn discriminative representations without fine-tuning. HSCL achieves state-of-the-art performance in multiple scenarios, such as one-class classification and cross-dataset detection. Extensive ablation studies further verify the effectiveness of each considered relation. The code is available at https://github.com/GaoangW/HSCL. ",
    "url": "https://arxiv.org/abs/2207.11789",
    "authors": [
      "Gaoang Wang",
      "Yibing Zhan",
      "Xinchao Wang",
      "Mingli Song",
      "Klara Nahrstedt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11793",
    "title": "Reconstructing degree distribution and triangle counts from edge-sampled  graphs",
    "abstract": "Often, due to prohibitively large size or to limits to data collecting APIs, it is not possible to work with a complete network dataset and sampling is required. A type of sampling which is consistent with Twitter API restrictions is uniform edge sampling. In this paper, we propose a methodology for the recovery of two fundamental network properties from an edge-sampled network: the degree distribution and the triangle count (we estimate the totals for the network and the counts associated with each edge). We use a Bayesian approach and show a range of methods for constructing a prior which does not require assumptions about the original network. Our approach is tested on two synthetic and two real datasets with diverse degree and triangle count distributions. ",
    "url": "https://arxiv.org/abs/2207.11793",
    "authors": [
      "Naomi A. Arnold",
      "Raul J. Mondragon",
      "Richard G. Clegg"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.11805",
    "title": "Weakly-Supervised Temporal Action Detection for Fine-Grained Videos with  Hierarchical Atomic Actions",
    "abstract": "Action understanding has evolved into the era of fine granularity, as most human behaviors in real life have only minor differences. To detect these fine-grained actions accurately in a label-efficient way, we tackle the problem of weakly-supervised fine-grained temporal action detection in videos for the first time. Without the careful design to capture subtle differences between fine-grained actions, previous weakly-supervised models for general action detection cannot perform well in the fine-grained setting. We propose to model actions as the combinations of reusable atomic actions which are automatically discovered from data through self-supervised clustering, in order to capture the commonality and individuality of fine-grained actions. The learnt atomic actions, represented by visual concepts, are further mapped to fine and coarse action labels leveraging the semantic label hierarchy. Our approach constructs a visual representation hierarchy of four levels: clip level, atomic action level, fine action class level and coarse action class level, with supervision at each level. Extensive experiments on two large-scale fine-grained video datasets, FineAction and FineGym, show the benefit of our proposed weakly-supervised model for fine-grained action detection, and it achieves state-of-the-art results. ",
    "url": "https://arxiv.org/abs/2207.11805",
    "authors": [
      "Zhi Li",
      "Lu He",
      "Huijuan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.11808",
    "title": "ArmanEmo: A Persian Dataset for Text-based Emotion Detection",
    "abstract": "With the recent proliferation of open textual data on social media platforms, Emotion Detection (ED) from Text has received more attention over the past years. It has many applications, especially for businesses and online service providers, where emotion detection techniques can help them make informed commercial decisions by analyzing customers/users' feelings towards their products and services. In this study, we introduce ArmanEmo, a human-labeled emotion dataset of more than 7000 Persian sentences labeled for seven categories. The dataset has been collected from different resources, including Twitter, Instagram, and Digikala (an Iranian e-commerce company) comments. Labels are based on Ekman's six basic emotions (Anger, Fear, Happiness, Hatred, Sadness, Wonder) and another category (Other) to consider any other emotion not included in Ekman's model. Along with the dataset, we have provided several baseline models for emotion classification focusing on the state-of-the-art transformer-based language models. Our best model achieves a macro-averaged F1 score of 75.39 percent across our test dataset. Moreover, we also conduct transfer learning experiments to compare our proposed dataset's generalization against other Persian emotion datasets. Results of these experiments suggest that our dataset has superior generalizability among the existing Persian emotion datasets. ArmanEmo is publicly available for non-commercial use at https://github.com/Arman-Rayan-Sharif/arman-text-emotion. ",
    "url": "https://arxiv.org/abs/2207.11808",
    "authors": [
      "Hossein Mirzaee",
      "Javad Peymanfard",
      "Hamid Habibzadeh Moshtaghin",
      "Hossein Zeinali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.11812",
    "title": "Federated Graph Machine Learning: A Survey of Concepts, Techniques, and  Applications",
    "abstract": "Graph machine learning has gained great attention in both academia and industry recently. Most of the graph machine learning models, such as Graph Neural Networks (GNNs), are trained over massive graph data. However, in many real-world scenarios, such as hospitalization prediction in healthcare systems, the graph data is usually stored at multiple data owners and cannot be directly accessed by any other parties due to privacy concerns and regulation restrictions. Federated Graph Machine Learning (FGML) is a promising solution to tackle this challenge by training graph machine learning models in a federated manner. In this survey, we conduct a comprehensive review of the literature in FGML. Specifically, we first provide a new taxonomy to divide the existing problems in FGML into two settings, namely, \\emph{FL with structured data} and \\emph{structured FL}. Then, we review the mainstream techniques in each setting and elaborate on how they address the challenges under FGML. In addition, we summarize the real-world applications of FGML from different domains and introduce open graph datasets and platforms adopted in FGML. Finally, we present several limitations in the existing studies with promising research directions in this field. ",
    "url": "https://arxiv.org/abs/2207.11812",
    "authors": [
      "Xingbo Fu",
      "Binchi Zhang",
      "Yushun Dong",
      "Chen Chen",
      "Jundong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11817",
    "title": "A Multiple-Entanglement Routing Framework for Quantum Networks",
    "abstract": "Quantum networks are gaining momentum in finding applications in a wide range of domains. However, little research has investigated the potential of a quantum network framework to enable highly reliable communications. The goal of this work is to investigate and design the multiple-entanglement routing framework, namely k-entangled routing. In particular, the $k$-entangled routing will enable k paths connecting all demands (source-destination pairs) in the network. To design the $k$-entangled routing, we propose two algorithms that are called Sequential Multi-path Scheduling Algorithm and Min-Cut-based Multi-path Scheduling Algorithm. In addition, we evaluate the performance of the proposed algorithms and models through a realistic quantum network simulator, NetSquid, that models the stochastic processes underlying quantum communications. The results show that the proposed algorithms (SMPSA and MCSA) largely enhance the network's traffic flexibility. The proposed paradigms would lay the foundation for further research on the area of entanglement routing. ",
    "url": "https://arxiv.org/abs/2207.11817",
    "authors": [
      "Tu N. Nguyen",
      "Kashyab J. Ambarani",
      "Linh Le",
      "Ivan Djordjevic",
      "Zhi-Li Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.11820",
    "title": "Optimizing Resource Allocation and VNF Embedding in RAN Slicing",
    "abstract": "5G radio access network (RAN) with network slicing methodology plays a key role in the development of the next-generation network system. RAN slicing focuses on splitting the substrate's resources into a set of self-contained programmable RAN slices. Leveraged by network function virtualization (NFV), a RAN slice is constituted by various virtual network functions (VNFs) and virtual links that are embedded as instances on substrate nodes. In this work, we focus on the following fundamental tasks: i) establishing the theoretical foundation for constructing a VNF mapping plan for RAN slice recovery optimization and ii) developing algorithms needed to map/embed VNFs efficiently. In particular, we propose four efficient algorithms, including Resource-based Algorithm (RBA), Connectivity-based Algorithm (CBA), Group-based Algorithm (GBA), and Group-Connectivity-based Algorithm (GCBA) to solve the resource allocation and VNF mapping problem. Extensive experiments are also conducted to validate the robustness of RAN slicing via the proposed algorithms. ",
    "url": "https://arxiv.org/abs/2207.11820",
    "authors": [
      "Tu N. Nguyen",
      "Kashyab J. Ambarani",
      "My T. Thai"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.11822",
    "title": "Efficient Embedding VNFs in 5G Network Slicing: A Deep Reinforcement  Learning Approach",
    "abstract": "5G radio access network (RAN) slicing aims to logically split an infrastructure into a set of self-contained programmable RAN slices, with each slice built on top of the underlying physical RAN (substrate) is a separate logical mobile network, which delivers a set of services with similar characteristics. Each RAN slice is constituted by various virtual network functions (VNFs) distributed geographically in numerous substrate nodes. A key challenge in building a robust RAN slicing is, therefore, designing a RAN slicing (RS)-configuration scheme that can utilize information such as resource availability in substrate networks as well as the interdependent relationships among slices to map (embed) VNFs onto live substrate nodes. With such motivation, we propose a machine-learning-powered RAN slicing scheme that aims to accommodate maximum numbers of slices (a set of connected Virtual Network Functions - VNFs) within a given request set. More specifically, we present a deep reinforcement scheme that is called Deep Allocation Agent (DAA). In short, DAA utilizes an empirically designed deep neural network that observes the current states of the substrate network and the requested slices to schedule the slices of which VNFs are then mapped to substrate nodes using an optimization algorithm. DAA is trained towards the goal of maximizing the number of accommodated slices in the given set by using an explicitly designed reward function. Our experiment study shows that, on average, DAA is able to maintain a rate of successfully routed slices above 80% in a resource-limited substrate network, and about 60% in extreme conditions, i.e., the available resources are much less than the demands. ",
    "url": "https://arxiv.org/abs/2207.11822",
    "authors": [
      "Linh Le",
      "Tu N. Nguyen",
      "Kun Suo",
      "Jing He"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.11824",
    "title": "Contention Resolution for Coded Radio Networks",
    "abstract": "Randomized backoff protocols, such as exponential backoff, are a powerful tool for managing access to a shared resource, often a wireless communication channel (e.g., [1]). For a wireless device to transmit successfully, it uses a backoff protocol to ensure exclusive access to the channel. Modern radios, however, do not need exclusive access to the channel to communicate; in particular, they have the ability to receive useful information even when more than one device transmits at the same time. These capabilities have now been exploited for many years by systems that rely on interference cancellation, physical layer network coding and analog network coding to improve efficiency. For example, Zigzag decoding [56] demonstrated how a base station can decode messages sent by multiple devices simultaneously. In this paper, we address the following question: Can we design a backoff protocol that is better than exponential backoff when exclusive channel access is not required. We define the Coded Radio Network Model, which generalizes traditional radio network models (e.g., [30]). We then introduce the Decodable Backoff Algorithm, a randomized backoff protocol that achieves an optimal throughput of $1-o(1)$. (Throughput $1$ is optimal, as simultaneous reception does not increase the channel capacity.) The algorithm breaks the constant throughput lower bound for traditional radio networks [47-49], showing the power of these new hardware capabilities. ",
    "url": "https://arxiv.org/abs/2207.11824",
    "authors": [
      "Michael A. Bender",
      "Seth Gilbert",
      "Fabian Kuhn",
      "John Kuszmaul",
      "Muriel M\u00e9dard"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2207.11836",
    "title": "Federated Graph Contrastive Learning",
    "abstract": "Graph learning models are critical tools for researchers to explore graph-structured data. To train a capable graph learning model, a conventional method uses sufficient training data to train a graph model on a single device. However, it is prohibitive to do so in real-world scenarios due to privacy concerns. Federated learning provides a feasible solution to address such limitations via introducing various privacy-preserving mechanisms, such as differential privacy on graph edges. Nevertheless, differential privacy in federated graph learning secures the classified information maintained in graphs. It degrades the performances of the graph learning models. In this paper, we investigate how to implement differential privacy on graph edges and observe the performances decreasing in the experiments. We also note that the differential privacy on graph edges introduces noises to perturb graph proximity, which is one of the graph augmentations in graph contrastive learning. Inspired by that, we propose to leverage the advantages of graph contrastive learning to alleviate the performance dropping caused by differential privacy. Extensive experiments are conducted with several representative graph models and widely-used datasets, showing that contrastive learning indeed alleviates the models' performance dropping caused by differential privacy. ",
    "url": "https://arxiv.org/abs/2207.11836",
    "authors": [
      "Haoran Yang",
      "Xiangyu Zhao",
      "Muyang Li",
      "Hongxu Chen",
      "Guandong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11837",
    "title": "Inter-model Interpretability: Self-supervised Models as a Case Study",
    "abstract": "Since early machine learning models, metrics such as accuracy and precision have been the de facto way to evaluate and compare trained models. However, a single metric number doesn't fully capture the similarities and differences between models, especially in the computer vision domain. A model with high accuracy on a certain dataset might provide a lower accuracy on another dataset, without any further insights. To address this problem we build on a recent interpretability technique called Dissect to introduce \\textit{inter-model interpretability}, which determines how models relate or complement each other based on the visual concepts they have learned (such as objects and materials). Towards this goal, we project 13 top-performing self-supervised models into a Learned Concepts Embedding (LCE) space that reveals proximities among models from the perspective of learned concepts. We further crossed this information with the performance of these models on four computer vision tasks and 15 datasets. The experiment allowed us to categorize the models into three categories and revealed for the first time the type of visual concepts different tasks requires. This is a step forward for designing cross-task learning algorithms. ",
    "url": "https://arxiv.org/abs/2207.11837",
    "authors": [
      "Ahmad Mustapha",
      "Wael Khreich",
      "Wassim Masri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11844",
    "title": "Enhancing Image Rescaling using Dual Latent Variables in Invertible  Neural Network",
    "abstract": "Normalizing flow models have been used successfully for generative image super-resolution (SR) by approximating complex distribution of natural images to simple tractable distribution in latent space through Invertible Neural Networks (INN). These models can generate multiple realistic SR images from one low-resolution (LR) input using randomly sampled points in the latent space, simulating the ill-posed nature of image upscaling where multiple high-resolution (HR) images correspond to the same LR. Lately, the invertible process in INN has also been used successfully by bidirectional image rescaling models like IRN and HCFlow for joint optimization of downscaling and inverse upscaling, resulting in significant improvements in upscaled image quality. While they are optimized for image downscaling too, the ill-posed nature of image downscaling, where one HR image could be downsized to multiple LR images depending on different interpolation kernels and resampling methods, is not considered. A new downscaling latent variable, in addition to the original one representing uncertainties in image upscaling, is introduced to model variations in the image downscaling process. This dual latent variable enhancement is applicable to different image rescaling models and it is shown in extensive experiments that it can improve image upscaling accuracy consistently without sacrificing image quality in downscaled LR images. It is also shown to be effective in enhancing other INN-based models for image restoration applications like image hiding. ",
    "url": "https://arxiv.org/abs/2207.11844",
    "authors": [
      "Min Zhang",
      "Zhihong Pan",
      "Xin Zhou",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.11846",
    "title": "Mixture of Input-Output Hidden Markov Models for Heterogeneous Disease  Progression Modeling",
    "abstract": "A particular challenge for disease progression modeling is the heterogeneity of a disease and its manifestations in the patients. Existing approaches often assume the presence of a single disease progression characteristics which is unlikely for neurodegenerative disorders such as Parkinson's disease. In this paper, we propose a hierarchical time-series model that can discover multiple disease progression dynamics. The proposed model is an extension of an input-output hidden Markov model that takes into account the clinical assessments of patients' health status and prescribed medications. We illustrate the benefits of our model using a synthetically generated dataset and a real-world longitudinal dataset for Parkinson's disease. ",
    "url": "https://arxiv.org/abs/2207.11846",
    "authors": [
      "Taha Ceritli",
      "Andrew P. Creagh",
      "David A. Clifton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.11862",
    "title": "Improving Bot Response Contradiction Detection via Utterance Rewriting",
    "abstract": "Though chatbots based on large neural models can often produce fluent responses in open domain conversations, one salient error type is contradiction or inconsistency with the preceding conversation turns. Previous work has treated contradiction detection in bot responses as a task similar to natural language inference, e.g., detect the contradiction between a pair of bot utterances. However, utterances in conversations may contain co-references or ellipsis, and using these utterances as is may not always be sufficient for identifying contradictions. This work aims to improve the contradiction detection via rewriting all bot utterances to restore antecedents and ellipsis. We curated a new dataset for utterance rewriting and built a rewriting model on it. We empirically demonstrate that this model can produce satisfactory rewrites to make bot utterances more complete. Furthermore, using rewritten utterances improves contradiction detection performance significantly, e.g., the AUPR and joint accuracy scores (detecting contradiction along with evidence) increase by 6.5% and 4.5% (absolute increase), respectively. ",
    "url": "https://arxiv.org/abs/2207.11862",
    "authors": [
      "Di Jin",
      "Sijia Liu",
      "Yang Liu",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.11871",
    "title": "Towards Complex Document Understanding By Discrete Reasoning",
    "abstract": "Document Visual Question Answering (VQA) aims to understand visually-rich documents to answer questions in natural language, which is an emerging research topic for both Natural Language Processing and Computer Vision. In this work, we introduce a new Document VQA dataset, named TAT-DQA, which consists of 3,067 document pages comprising semi-structured table(s) and unstructured text as well as 16,558 question-answer pairs by extending the TAT-QA dataset. These documents are sampled from real-world financial reports and contain lots of numbers, which means discrete reasoning capability is demanded to answer questions on this dataset. Based on TAT-DQA, we further develop a novel model named MHST that takes into account the information in multi-modalities, including text, layout and visual image, to intelligently address different types of questions with corresponding strategies, i.e., extraction or reasoning. Extensive experiments show that the MHST model significantly outperforms the baseline methods, demonstrating its effectiveness. However, the performance still lags far behind that of expert humans. We expect that our new TAT-DQA dataset would facilitate the research on deep understanding of visually-rich documents combining vision and language, especially for scenarios that require discrete reasoning. Also, we hope the proposed model would inspire researchers to design more advanced Document VQA models in future. ",
    "url": "https://arxiv.org/abs/2207.11871",
    "authors": [
      "Fengbin Zhu",
      "Wenqiang Lei",
      "Fuli Feng",
      "Chao Wang",
      "Haozhou Zhang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.11887",
    "title": "HIRE: Distilling High-order Relational Knowledge From Heterogeneous  Graph Neural Networks",
    "abstract": "Researchers have recently proposed plenty of heterogeneous graph neural networks (HGNNs) due to the ubiquity of heterogeneous graphs in both academic and industrial areas. Instead of pursuing a more powerful HGNN model, in this paper, we are interested in devising a versatile plug-and-play module, which accounts for distilling relational knowledge from pre-trained HGNNs. To the best of our knowledge, we are the first to propose a HIgh-order RElational (HIRE) knowledge distillation framework on heterogeneous graphs, which can significantly boost the prediction performance regardless of model architectures of HGNNs. Concretely, our HIRE framework initially performs first-order node-level knowledge distillation, which encodes the semantics of the teacher HGNN with its prediction logits. Meanwhile, the second-order relation-level knowledge distillation imitates the relational correlation between node embeddings of different types generated by the teacher HGNN. Extensive experiments on various popular HGNNs models and three real-world heterogeneous graphs demonstrate that our method obtains consistent and considerable performance enhancement, proving its effectiveness and generalization ability. ",
    "url": "https://arxiv.org/abs/2207.11887",
    "authors": [
      "Jing Liu",
      "Tongya Zheng",
      "Qinfen Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11889",
    "title": "Salient Object Detection for Point Clouds",
    "abstract": "This paper researches the unexplored task-point cloud salient object detection (SOD). Differing from SOD for images, we find the attention shift of point clouds may provoke saliency conflict, i.e., an object paradoxically belongs to salient and non-salient categories. To eschew this issue, we present a novel view-dependent perspective of salient objects, reasonably reflecting the most eye-catching objects in point cloud scenarios. Following this formulation, we introduce PCSOD, the first dataset proposed for point cloud SOD consisting of 2,872 in-/out-door 3D views. The samples in our dataset are labeled with hierarchical annotations, e.g., super-/sub-class, bounding box, and segmentation map, which endows the brilliant generalizability and broad applicability of our dataset verifying various conjectures. To evidence the feasibility of our solution, we further contribute a baseline model and benchmark five representative models for a comprehensive comparison. The proposed model can effectively analyze irregular and unordered points for detecting salient objects. Thanks to incorporating the task-tailored designs, our method shows visible superiority over other baselines, producing more satisfactory results. Extensive experiments and discussions reveal the promising potential of this research field, paving the way for further study. ",
    "url": "https://arxiv.org/abs/2207.11889",
    "authors": [
      "Songlin Fan",
      "Wei Gao",
      "Ge Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11893",
    "title": "Overview of the Shared Task on Fake News Detection in Urdu at FIRE 2020",
    "abstract": "This overview paper describes the first shared task on fake news detection in Urdu language. The task was posed as a binary classification task, in which the goal is to differentiate between real and fake news. We provided a dataset divided into 900 annotated news articles for training and 400 news articles for testing. The dataset contained news in five domains: (i) Health, (ii) Sports, (iii) Showbiz, (iv) Technology, and (v) Business. 42 teams from 6 different countries (India, China, Egypt, Germany, Pakistan, and the UK) registered for the task. 9 teams submitted their experimental results. The participants used various machine learning methods ranging from feature-based traditional machine learning to neural networks techniques. The best performing system achieved an F-score value of 0.90, showing that the BERT-based approach outperforms other machine learning techniques ",
    "url": "https://arxiv.org/abs/2207.11893",
    "authors": [
      "Maaz Amjad",
      "Grigori Sidorov",
      "Alisa Zhila",
      "Alexander Gelbukh",
      "Paolo Rosso"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.11900",
    "title": "GA2MIF: Graph and Attention-based Two-stage Multi-source Information  Fusion for Conversational Emotion Detection",
    "abstract": "To enable artificial intelligence in providing empathetic services, multimodal Emotion Recognition in Conversation (ERC) plays an influential role in the field of human-computer interaction and conversational robotics. Multimodal data modeling is an up-and-coming research area in recent years, which is inspired by human multi-sensory integration capabilities. Up until now, there are few studies on multimodal-based conversational emotion recognition. Most of existing Multimodal ERC methods do not model cross-modal interactions and are incapable of extracting inter-modal complementary information. Several graph-based approaches claim to capture inter-modal complementary information, but it is difficult to obtain optimal solution using graph-based models due to the heterogeneity of multimodal data. In this work, we introduce a Graph and Attention-based Two-stage Multi-source Information Fusion (GA2MIF) approach for multimodal fusion. Our GA2MIF focuses on contextual modeling and cross-modal modeling leveraging Multi-head Directed Graph ATtention networks (MDGATs) and Multi-head Pairwise Cross-modal ATtention networks (MPCATs), respectively. Extensive experiments on two common datasets show that proposed GA2MIF can effectively capture intra-modal local and long-range contextual information as well as inter-modal complementary information, and outperforms existing State-Of-The-Art (SOTA) baselines by an absolute margin. ",
    "url": "https://arxiv.org/abs/2207.11900",
    "authors": [
      "Jiang Li",
      "Xiaoping Wang",
      "Guoqing Lv",
      "Zhigang Zeng"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.11903",
    "title": "Minimax Rates for Robust Community Detection",
    "abstract": "In this work, we study the problem of community detection in the stochastic block model with adversarial node corruptions. Our main result is an efficient algorithm that can tolerate an $\\epsilon$-fraction of corruptions and achieves error $O(\\epsilon) + e^{-\\frac{C}{2} (1 \\pm o(1))}$ where $C = (\\sqrt{a} - \\sqrt{b})^2$ is the signal-to-noise ratio and $a/n$ and $b/n$ are the inter-community and intra-community connection probabilities respectively. These bounds essentially match the minimax rates for the SBM without corruptions. We also give robust algorithms for $\\mathbb{Z}_2$-synchronization. At the heart of our algorithm is a new semidefinite program that uses global information to robustly boost the accuracy of a rough clustering. Moreover, we show that our algorithms are doubly-robust in the sense that they work in an even more challenging noise model that mixes adversarial corruptions with unbounded monotone changes, from the semi-random model. ",
    "url": "https://arxiv.org/abs/2207.11903",
    "authors": [
      "Allen Liu",
      "Ankur Moitra"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.11911",
    "title": "NeuMesh: Learning Disentangled Neural Mesh-based Implicit Field for  Geometry and Texture Editing",
    "abstract": "Very recently neural implicit rendering techniques have been rapidly evolved and shown great advantages in novel view synthesis and 3D scene reconstruction. However, existing neural rendering methods for editing purposes offer limited functionality, e.g., rigid transformation, or not applicable for fine-grained editing for general objects from daily lives. In this paper, we present a novel mesh-based representation by encoding the neural implicit field with disentangled geometry and texture codes on mesh vertices, which facilitates a set of editing functionalities, including mesh-guided geometry editing, designated texture editing with texture swapping, filling and painting operations. To this end, we develop several techniques including learnable sign indicators to magnify spatial distinguishability of mesh-based representation, distillation and fine-tuning mechanism to make a steady convergence, and the spatial-aware optimization strategy to realize precise texture editing. Extensive experiments and editing examples on both real and synthetic data demonstrate the superiority of our method on representation quality and editing ability. Code is available on the project webpage: https://zju3dv.github.io/neumesh/. ",
    "url": "https://arxiv.org/abs/2207.11911",
    "authors": [
      "Bangbang Yang",
      "Chong Bao",
      "Junyi Zeng",
      "Hujun Bao",
      "Yinda Zhang",
      "Zhaopeng Cui",
      "Guofeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2207.11919",
    "title": "Patchwork++: Fast and Robust Ground Segmentation Solving Partial  Under-Segmentation Using 3D Point Cloud",
    "abstract": "In the field of 3D perception using 3D LiDAR sensors, ground segmentation is an essential task for various purposes, such as traversable area detection and object recognition. Under these circumstances, several ground segmentation methods have been proposed. However, some limitations are still encountered. First, some ground segmentation methods require fine-tuning of parameters depending on the surroundings, which is excessively laborious and time-consuming. Moreover, even if the parameters are well adjusted, a partial under-segmentation problem can still emerge, which implies ground segmentation failures in some regions. Finally, ground segmentation methods typically fail to estimate an appropriate ground plane when the ground is above another structure, such as a retaining wall. To address these problems, we propose a robust ground segmentation method called Patchwork++, an extension of Patchwork. Patchwork++ exploits adaptive ground likelihood estimation (A-GLE) to calculate appropriate parameters adaptively based on the previous ground segmentation results. Moreover, temporal ground revert (TGR) alleviates a partial under-segmentation problem by using the temporary ground property. Also, region-wise vertical plane fitting (R-VPF) is introduced to segment the ground plane properly even if the ground is elevated with different layers. Finally, we present reflected noise removal (RNR) to eliminate virtual noise points efficiently based on the 3D LiDAR reflection model. We demonstrate the qualitative and quantitative evaluations using a SemanticKITTI dataset. Our code is available at https://github.com/url-kaist/patchwork-plusplus ",
    "url": "https://arxiv.org/abs/2207.11919",
    "authors": [
      "Seungjae Lee",
      "Hyungtae Lim",
      "Hyun Myung"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11950",
    "title": "One-off Negative Sequential Pattern Mining",
    "abstract": "Negative sequential pattern mining (SPM) is an important SPM research topic. Unlike positive SPM, negative SPM can discover events that should have occurred but have not occurred, and it can be used for financial risk management and fraud detection. However, existing methods generally ignore the repetitions of the pattern and do not consider gap constraints, which can lead to mining results containing a large number of patterns that users are not interested in. To solve this problem, this paper discovers frequent one-off negative sequential patterns (ONPs). This problem has the following two characteristics. First, the support is calculated under the one-off condition, which means that any character in the sequence can only be used once at most. Second, the gap constraint can be given by the user. To efficiently mine patterns, this paper proposes the ONP-Miner algorithm, which employs depth-first and backtracking strategies to calculate the support. Therefore, ONP-Miner can effectively avoid creating redundant nodes and parent-child relationships. Moreover, to effectively reduce the number of candidate patterns, ONP-Miner uses pattern join and pruning strategies to generate and further prune the candidate patterns, respectively. Experimental results show that ONP-Miner not only improves the mining efficiency, but also has better mining performance than the state-of-the-art algorithms. More importantly, ONP mining can find more interesting patterns in traffic volume data to predict future traffic. ",
    "url": "https://arxiv.org/abs/2207.11950",
    "authors": [
      "Youxi Wu",
      "Mingjie Chen",
      "Yan Li",
      "Jing Liu",
      "Zhao Li",
      "Jinyan Li",
      "Xindong Wu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2207.11983",
    "title": "Distributed Coordination of Charging Stations with Shared Energy Storage  in a Distribution Network",
    "abstract": "Electric vehicle (EV) charging stations have experienced rapid growth, whose impacts on the power grid have become non-negligible. Though charging stations can install battery energy storage to reduce their impacts on the grid, the conventional \"one charging station, one battery storage\" method may be uneconomical due to the high upfront cost of battery storage. Shared energy storage can be a potential solution. However, effective management of charging stations with shared energy storage in a distribution network is challenging due to the complex coupling, competing interests, and information asymmetry between different agents. To address the aforementioned challenges, this paper proposes a distributed coordination mechanism, with a prediction and a correction step, to guide the behaviors of different agents. In particular, three groups of strategic agents are involved. Each charging station determines the flexible EV charging plan inside it; each shared energy storage operator decides on the amount of energy provided to its connected charging stations; and the distribution system operator monitors power flow in the network. We theoretically prove that the proposed mechanism will converge to the centrally optimal solution. Numerical experiments and comprehensive performance comparisons are conducted to validate the theoretical results and show the advantages of the proposed mechanism. ",
    "url": "https://arxiv.org/abs/2207.11983",
    "authors": [
      "Dongxiang Yan",
      "Yue Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.11984",
    "title": "RA-Depth: Resolution Adaptive Self-Supervised Monocular Depth Estimation",
    "abstract": "Existing self-supervised monocular depth estimation methods can get rid of expensive annotations and achieve promising results. However, these methods suffer from severe performance degradation when directly adopting a model trained on a fixed resolution to evaluate at other different resolutions. In this paper, we propose a resolution adaptive self-supervised monocular depth estimation method (RA-Depth) by learning the scale invariance of the scene depth. Specifically, we propose a simple yet efficient data augmentation method to generate images with arbitrary scales for the same scene. Then, we develop a dual high-resolution network that uses the multi-path encoder and decoder with dense interactions to aggregate multi-scale features for accurate depth inference. Finally, to explicitly learn the scale invariance of the scene depth, we formulate a cross-scale depth consistency loss on depth predictions with different scales. Extensive experiments on the KITTI, Make3D and NYU-V2 datasets demonstrate that RA-Depth not only achieves state-of-the-art performance, but also exhibits a good ability of resolution adaptation. ",
    "url": "https://arxiv.org/abs/2207.11984",
    "authors": [
      "Mu He",
      "Le Hui",
      "Yikai Bian",
      "Jian Ren",
      "Jin Xie",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11995",
    "title": "3D Siamese Transformer Network for Single Object Tracking on Point  Clouds",
    "abstract": "Siamese network based trackers formulate 3D single object tracking as cross-correlation learning between point features of a template and a search area. Due to the large appearance variation between the template and search area during tracking, how to learn the robust cross correlation between them for identifying the potential target in the search area is still a challenging problem. In this paper, we explicitly use Transformer to form a 3D Siamese Transformer network for learning robust cross correlation between the template and the search area of point clouds. Specifically, we develop a Siamese point Transformer network to learn shape context information of the target. Its encoder uses self-attention to capture non-local information of point clouds to characterize the shape information of the object, and the decoder utilizes cross-attention to upsample discriminative point features. After that, we develop an iterative coarse-to-fine correlation network to learn the robust cross correlation between the template and the search area. It formulates the cross-feature augmentation to associate the template with the potential target in the search area via cross attention. To further enhance the potential target, it employs the ego-feature augmentation that applies self-attention to the local k-NN graph of the feature space to aggregate target features. Experiments on the KITTI, nuScenes, and Waymo datasets show that our method achieves state-of-the-art performance on the 3D single object tracking task. ",
    "url": "https://arxiv.org/abs/2207.11995",
    "authors": [
      "Le Hui",
      "Lingpeng Wang",
      "Linghua Tang",
      "Kaihao Lan",
      "Jin Xie",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11996",
    "title": "Generative Subgraph Contrast for Self-Supervised Graph Representation  Learning",
    "abstract": "Contrastive learning has shown great promise in the field of graph representation learning. By manually constructing positive/negative samples, most graph contrastive learning methods rely on the vector inner product based similarity metric to distinguish the samples for graph representation. However, the handcrafted sample construction (e.g., the perturbation on the nodes or edges of the graph) may not effectively capture the intrinsic local structures of the graph. Also, the vector inner product based similarity metric cannot fully exploit the local structures of the graph to characterize the graph difference well. To this end, in this paper, we propose a novel adaptive subgraph generation based contrastive learning framework for efficient and robust self-supervised graph representation learning, and the optimal transport distance is utilized as the similarity metric between the subgraphs. It aims to generate contrastive samples by capturing the intrinsic structures of the graph and distinguish the samples based on the features and structures of subgraphs simultaneously. Specifically, for each center node, by adaptively learning relation weights to the nodes of the corresponding neighborhood, we first develop a network to generate the interpolated subgraph. We then construct the positive and negative pairs of subgraphs from the same and different nodes, respectively. Finally, we employ two types of optimal transport distances (i.e., Wasserstein distance and Gromov-Wasserstein distance) to construct the structured contrastive loss. Extensive node classification experiments on benchmark datasets verify the effectiveness of our graph contrastive learning method. ",
    "url": "https://arxiv.org/abs/2207.11996",
    "authors": [
      "Yuehui Han",
      "Le Hui",
      "Haobo Jiang",
      "Jianjun Qian",
      "Jin Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.12000",
    "title": "GNN Transformation Framework for Improving Efficiency and Scalability",
    "abstract": "We propose a framework that automatically transforms non-scalable GNNs into precomputation-based GNNs which are efficient and scalable for large-scale graphs. The advantages of our framework are two-fold; 1) it transforms various non-scalable GNNs to scale well to large-scale graphs by separating local feature aggregation from weight learning in their graph convolution, 2) it efficiently executes precomputation on GPU for large-scale graphs by decomposing their edges into small disjoint and balanced sets. Through extensive experiments with large-scale graphs, we demonstrate that the transformed GNNs run faster in training time than existing GNNs while achieving competitive accuracy to the state-of-the-art GNNs. Consequently, our transformation framework provides simple and efficient baselines for future research on scalable GNNs. ",
    "url": "https://arxiv.org/abs/2207.12000",
    "authors": [
      "Seiji Maekawa",
      "Yuya Sasaki",
      "George Fletcher",
      "Makoto Onizuka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.12004",
    "title": "Deep dual stream residual network with contextual attention for  pansharpening of remote sensing images",
    "abstract": "Pansharpening enhances spatial details of high spectral resolution multispectral images using features of high spatial resolution panchromatic image. There are a number of traditional pansharpening approaches but producing an image exhibiting high spectral and spatial fidelity is still an open problem. Recently, deep learning has been used to produce promising pansharpened images; however, most of these approaches apply similar treatment to both multispectral and panchromatic images by using the same network for feature extraction. In this work, we present present a novel dual attention-based two-stream network. It starts with feature extraction using two separate networks for both images, an encoder with attention mechanism to recalibrate the extracted features. This is followed by fusion of the features forming a compact representation fed into an image reconstruction network to produce a pansharpened image. The experimental results on the Pl\\'{e}iades dataset using standard quantitative evaluation metrics and visual inspection demonstrates that the proposed approach performs better than other approaches in terms of pansharpened image quality. ",
    "url": "https://arxiv.org/abs/2207.12004",
    "authors": [
      "Syeda Roshana Ali",
      "Anis Ur Rahman",
      "Muhammad Shahzad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.12007",
    "title": "LETS-GZSL: A Latent Embedding Model for Time Series Generalized Zero  Shot Learning",
    "abstract": "One of the recent developments in deep learning is generalized zero-shot learning (GZSL), which aims to recognize objects from both seen and unseen classes, when only the labeled examples from seen classes are provided. Over the past couple of years, GZSL has picked up traction and several models have been proposed to solve this problem. Whereas an extensive amount of research on GZSL has been carried out in fields such as computer vision and natural language processing, no such research has been carried out to deal with time series data. GZSL is used for applications such as detecting abnormalities from ECG and EEG data and identifying unseen classes from sensor, spectrograph and other devices' data. In this regard, we propose a Latent Embedding for Time Series - GZSL (LETS-GZSL) model that can solve the problem of GZSL for time series classification (TSC). We utilize an embedding-based approach and combine it with attribute vectors to predict the final class labels. We report our results on the widely popular UCR archive datasets. Our framework is able to achieve a harmonic mean value of at least 55% on most of the datasets except when the number of unseen classes is greater than 3 or the amount of data is very low (less than 100 training examples). ",
    "url": "https://arxiv.org/abs/2207.12007",
    "authors": [
      "Sathvik Bhaskarpandit",
      "Priyanka Gupta",
      "Manik Gupta"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.12013",
    "title": "Effective and Interpretable Information Aggregation with Capacity  Networks",
    "abstract": "How to aggregate information from multiple instances is a key question multiple instance learning. Prior neural models implement different variants of the well-known encoder-decoder strategy according to which all input features are encoded a single, high-dimensional embedding which is then decoded to generate an output. In this work, inspired by Choquet capacities, we propose Capacity networks. Unlike encoder-decoders, Capacity networks generate multiple interpretable intermediate results which can be aggregated in a semantically meaningful space to obtain the final output. Our experiments show that implementing this simple inductive bias leads to improvements over different encoder-decoder architectures in a wide range of experiments. Moreover, the interpretable intermediate results make Capacity networks interpretable by design, which allows a semantically meaningful inspection, evaluation, and regularization of the network internals. ",
    "url": "https://arxiv.org/abs/2207.12013",
    "authors": [
      "Markus Zopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.12021",
    "title": "Neural Generation Meets Real People: Building a Social, Informative  Open-Domain Dialogue Agent",
    "abstract": "We present Chirpy Cardinal, an open-domain social chatbot. Aiming to be both informative and conversational, our bot chats with users in an authentic, emotionally intelligent way. By integrating controlled neural generation with scaffolded, hand-written dialogue, we let both the user and bot take turns driving the conversation, producing an engaging and socially fluent experience. Deployed in the fourth iteration of the Alexa Prize Socialbot Grand Challenge, Chirpy Cardinal handled thousands of conversations per day, placing second out of nine bots with an average user rating of 3.58/5. ",
    "url": "https://arxiv.org/abs/2207.12021",
    "authors": [
      "Ethan A. Chi",
      "Ashwin Paranjape",
      "Abigail See",
      "Caleb Chiam",
      "Kathleen Kenealy",
      "Swee Kiat Lim",
      "Amelia Hardy",
      "Chetanya Rastogi",
      "Haojun Li",
      "Alexander Iyabor",
      "Yutong He",
      "Hari Sowrirajan",
      "Peng Qi",
      "Kaushik Ram Sadagopan",
      "Nguyet Minh Phu",
      "Dilara Soylu",
      "Jillian Tang",
      "Avanika Narayan",
      "Giovanni Campagna",
      "Christopher D. Manning"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.12029",
    "title": "Evaluating the Accuracy of Stochastic Geometry Based Models for LEO  Satellite Networks Analysis",
    "abstract": "This paper investigates the accuracy of recently proposed stochastic geometry-based modeling of low earth orbit (LEO) satellite networks. In particular, we use the Wasserstein Distance-inspired method to analyze the distances between different models, including Fibonacci lattice and orbit models. We propose an algorithm to calculate the distance between the generated point sets. Next, we test the algorithm's performance and analyze the distance between the stochastic geometry model and other more widely acceptable models using numerical results. ",
    "url": "https://arxiv.org/abs/2207.12029",
    "authors": [
      "Ruibo Wang",
      "Mustafa A. Kishk",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.12032",
    "title": "Cost Volume Pyramid Network with Multi-strategies Range Searching for  Multi-view Stereo",
    "abstract": "Multi-view stereo is an important research task in computer vision while still keeping challenging. In recent years, deep learning-based methods have shown superior performance on this task. Cost volume pyramid network-based methods which progressively refine depth map in coarse-to-fine manner, have yielded promising results while consuming less memory. However, these methods fail to take fully consideration of the characteristics of the cost volumes in each stage, leading to adopt similar range search strategies for each cost volume stage. In this work, we present a novel cost volume pyramid based network with different searching strategies for multi-view stereo. By choosing different depth range sampling strategies and applying adaptive unimodal filtering, we are able to obtain more accurate depth estimation in low resolution stages and iteratively upsample depth map to arbitrary resolution. We conducted extensive experiments on both DTU and BlendedMVS datasets, and results show that our method outperforms most state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2207.12032",
    "authors": [
      "Shiyu Gao",
      "Zhaoxin Li",
      "Zhaoqi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.12049",
    "title": "Few-Shot Object Detection by Knowledge Distillation Using  Bag-of-Visual-Words Representations",
    "abstract": "While fine-tuning based methods for few-shot object detection have achieved remarkable progress, a crucial challenge that has not been addressed well is the potential class-specific overfitting on base classes and sample-specific overfitting on novel classes. In this work we design a novel knowledge distillation framework to guide the learning of the object detector and thereby restrain the overfitting in both the pre-training stage on base classes and fine-tuning stage on novel classes. To be specific, we first present a novel Position-Aware Bag-of-Visual-Words model for learning a representative bag of visual words (BoVW) from a limited size of image set, which is used to encode general images based on the similarities between the learned visual words and an image. Then we perform knowledge distillation based on the fact that an image should have consistent BoVW representations in two different feature spaces. To this end, we pre-learn a feature space independently from the object detection, and encode images using BoVW in this space. The obtained BoVW representation for an image can be considered as distilled knowledge to guide the learning of object detector: the extracted features by the object detector for the same image are expected to derive the consistent BoVW representations with the distilled knowledge. Extensive experiments validate the effectiveness of our method and demonstrate the superiority over other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2207.12049",
    "authors": [
      "Wenjie Pei",
      "Shuang Wu",
      "Dianwen Mei",
      "Fanglin Chen",
      "Jiandong Tian",
      "Guangming Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.12051",
    "title": "Flowsheet synthesis through hierarchical reinforcement learning and  graph neural networks",
    "abstract": "Process synthesis experiences a disruptive transformation accelerated by digitization and artificial intelligence. We propose a reinforcement learning algorithm for chemical process design based on a state-of-the-art actor-critic logic. Our proposed algorithm represents chemical processes as graphs and uses graph convolutional neural networks to learn from process graphs. In particular, the graph neural networks are implemented within the agent architecture to process the states and make decisions. Moreover, we implement a hierarchical and hybrid decision-making process to generate flowsheets, where unit operations are placed iteratively as discrete decisions and corresponding design variables are selected as continuous decisions. We demonstrate the potential of our method to design economically viable flowsheets in an illustrative case study comprising equilibrium reactions, azeotropic separation, and recycles. The results show quick learning in discrete, continuous, and hybrid action spaces. Due to the flexible architecture of the proposed reinforcement learning agent, the method is predestined to include large action-state spaces and an interface to process simulators in future research. ",
    "url": "https://arxiv.org/abs/2207.12051",
    "authors": [
      "Laura Stops",
      "Roel Leenhouts",
      "Qinghe Gao",
      "Artur M. Schweidtmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.12062",
    "title": "Meta Neural Ordinary Differential Equations For Adaptive Asynchronous  Control",
    "abstract": "Model-based Reinforcement Learning and Control have demonstrated great potential in various sequential decision making problem domains, including in robotics settings. However, real-world robotics systems often present challenges that limit the applicability of those methods. In particular, we note two problems that jointly happen in many industrial systems: 1) Irregular/asynchronous observations and actions and 2) Dramatic changes in environment dynamics from an episode to another (e.g. varying payload inertial properties). We propose a general framework that overcomes those difficulties by meta-learning adaptive dynamics models for continuous-time prediction and control. We evaluate the proposed approach on a simulated industrial robot. Evaluations on real robotic systems will be added in future iterations of this pre-print. ",
    "url": "https://arxiv.org/abs/2207.12062",
    "authors": [
      "Achkan Salehi",
      "Steffen R\u00fchl",
      "Stephane Doncieux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.12065",
    "title": "Dynamic Channel Selection in Self-Supervised Learning",
    "abstract": "Whilst computer vision models built using self-supervised approaches are now commonplace, some important questions remain. Do self-supervised models learn highly redundant channel features? What if a self-supervised network could dynamically select the important channels and get rid of the unnecessary ones? Currently, convnets pre-trained with self-supervision have obtained comparable performance on downstream tasks in comparison to their supervised counterparts in computer vision. However, there are drawbacks to self-supervised models including their large numbers of parameters, computationally expensive training strategies and a clear need for faster inference on downstream tasks. In this work, our goal is to address the latter by studying how a standard channel selection method developed for supervised learning can be applied to networks trained with self-supervision. We validate our findings on a range of target budgets $t_{d}$ for channel computation on image classification task across different datasets, specifically CIFAR-10, CIFAR-100, and ImageNet-100, obtaining comparable performance to that of the original network when selecting all channels but at a significant reduction in computation reported in terms of FLOPs. ",
    "url": "https://arxiv.org/abs/2207.12065",
    "authors": [
      "Tarun Krishna",
      "Ayush K. Rai",
      "Yasser A. D. Djilali",
      "Alan F. Smeaton",
      "Kevin McGuinness",
      "Noel E. O'Connor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.12068",
    "title": "A Novel Framework for Dataset Generation for profiling Disassembly  attacks using Side-Channel Leakages and Deep Neural Networks",
    "abstract": "Various studies among side-channel attacks have tried to extract information through leakages from electronic devices to reach the instruction flow of some appliances. However, previous methods highly depend on the resolution of traced data. Obtaining low-noise traces is not always feasible in real attack scenarios. This study proposes two deep models to extract low and high-level features from side-channel traces and classify them to related instructions. We aim to evaluate the accuracy of a side-channel attack on low-resolution data with a more robust feature extractor thanks to neural networks. As inves-tigated, instruction flow in real programs is predictable and follows specific distributions. This leads to proposing a LSTM model to estimate these distributions, which could expedite the reverse engineering process and also raise the accuracy. The proposed model for leakage classification reaches 54.58% accuracy on average and outperforms other existing methods on our datasets. Also, LSTM model reaches 94.39% accuracy for instruction prediction on standard implementation of cryptographic algorithms. ",
    "url": "https://arxiv.org/abs/2207.12068",
    "authors": [
      "Pouya Narimani",
      "Seyed Amin Habibi",
      "Mohammad Ali Akhaee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.12100",
    "title": "IGFormer: Interaction Graph Transformer for Skeleton-based Human  Interaction Recognition",
    "abstract": "Human interaction recognition is very important in many applications. One crucial cue in recognizing an interaction is the interactive body parts. In this work, we propose a novel Interaction Graph Transformer (IGFormer) network for skeleton-based interaction recognition via modeling the interactive body parts as graphs. More specifically, the proposed IGFormer constructs interaction graphs according to the semantic and distance correlations between the interactive body parts, and enhances the representation of each person by aggregating the information of the interactive body parts based on the learned graphs. Furthermore, we propose a Semantic Partition Module to transform each human skeleton sequence into a Body-Part-Time sequence to better capture the spatial and temporal information of the skeleton sequence for learning the graphs. Extensive experiments on three benchmark datasets demonstrate that our model outperforms the state-of-the-art with a significant margin. ",
    "url": "https://arxiv.org/abs/2207.12100",
    "authors": [
      "Yunsheng Pang",
      "Qiuhong Ke",
      "Hossein Rahmani",
      "James Bailey",
      "Jun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.12104",
    "title": "W2N:Switching From Weak Supervision to Noisy Supervision for Object  Detection",
    "abstract": "Weakly-supervised object detection (WSOD) aims to train an object detector only requiring the image-level annotations. Recently, some works have managed to select the accurate boxes generated from a well-trained WSOD network to supervise a semi-supervised detection framework for better performance. However, these approaches simply divide the training set into labeled and unlabeled sets according to the image-level criteria, such that sufficient mislabeled or wrongly localized box predictions are chosen as pseudo ground-truths, resulting in a sub-optimal solution of detection performance. To overcome this issue, we propose a novel WSOD framework with a new paradigm that switches from weak supervision to noisy supervision (W2N). Generally, with given pseudo ground-truths generated from the well-trained WSOD network, we propose a two-module iterative training algorithm to refine pseudo labels and supervise better object detector progressively. In the localization adaptation module, we propose a regularization loss to reduce the proportion of discriminative parts in original pseudo ground-truths, obtaining better pseudo ground-truths for further training. In the semi-supervised module, we propose a two tasks instance-level split method to select high-quality labels for training a semi-supervised detector. Experimental results on different benchmarks verify the effectiveness of W2N, and our W2N outperforms all existing pure WSOD methods and transfer learning methods. Our code is publicly available at https://github.com/1170300714/w2n_wsod. ",
    "url": "https://arxiv.org/abs/2207.12104",
    "authors": [
      "Zitong Huang",
      "Yiping Bao",
      "Bowen Dong",
      "Erjin Zhou",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.12105",
    "title": "Ego-graph Replay based Continual Learning for Misinformation Engagement  Prediction",
    "abstract": "Online social network platforms have a problem with misinformation. One popular way of addressing this problem is via the use of machine learning based automated misinformation detection systems to classify if a post is misinformation. Instead of post hoc detection, we propose to predict if a user will engage with misinformation in advance and design an effective graph neural network classifier based on ego-graphs for this task. However, social networks are highly dynamic, reflecting continual changes in user behaviour, as well as the content being posted. This is problematic for machine learning models which are typically trained on a static training dataset, and can thus become outdated when the social network changes. Inspired by the success of continual learning on such problems, we propose an ego-graphs replay strategy in continual learning (EgoCL) using graph neural networks to effectively address this issue. We have evaluated the performance of our method on user engagement with misinformation on two Twitter datasets across nineteen misinformation and conspiracy topics. Our experimental results show that our approach EgoCL has better performance in terms of predictive accuracy and computational resources than the state of the art. ",
    "url": "https://arxiv.org/abs/2207.12105",
    "authors": [
      "Hongbo Bo",
      "Ryan McConville",
      "Jun Hong",
      "Weiru Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.12112",
    "title": "Active Learning Strategies for Weakly-supervised Object Detection",
    "abstract": "Object detectors trained with weak annotations are affordable alternatives to fully-supervised counterparts. However, there is still a significant performance gap between them. We propose to narrow this gap by fine-tuning a base pre-trained weakly-supervised detector with a few fully-annotated samples automatically selected from the training set using ``box-in-box'' (BiB), a novel active learning strategy designed specifically to address the well-documented failure modes of weakly-supervised detectors. Experiments on the VOC07 and COCO benchmarks show that BiB outperforms other active learning techniques and significantly improves the base weakly-supervised detector's performance with only a few fully-annotated images per class. BiB reaches 97% of the performance of fully-supervised Fast RCNN with only 10% of fully-annotated images on VOC07. On COCO, using on average 10 fully-annotated images per class, or equivalently 1% of the training set, BiB also reduces the performance gap (in AP) between the weakly-supervised detector and the fully-supervised Fast RCNN by over 70%, showing a good trade-off between performance and data efficiency. Our code is publicly available at https://github.com/huyvvo/BiB. ",
    "url": "https://arxiv.org/abs/2207.12112",
    "authors": [
      "Huy V. Vo",
      "Oriane Sim\u00e9oni",
      "Spyros Gidaris",
      "Andrei Bursuc",
      "Patrick P\u00e9rez",
      "Jean Ponce"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.12121",
    "title": "Cross-Modal Contrastive Representation Learning for Audio-to-Image  Generation",
    "abstract": "Multiple modalities for certain information provide a variety of perspectives on that information, which can improve the understanding of the information. Thus, it may be crucial to generate data of different modality from the existing data to enhance the understanding. In this paper, we investigate the cross-modal audio-to-image generation problem and propose Cross-Modal Contrastive Representation Learning (CMCRL) to extract useful features from audios and use it in the generation phase. Experimental results show that CMCRL enhances quality of images generated than previous research. ",
    "url": "https://arxiv.org/abs/2207.12121",
    "authors": [
      "HaeChun Chung",
      "JooYong Shim",
      "Jong-Kook Kim"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.12150",
    "title": "Moving-Horizon State Estimation for Power Networks and Synchronous  Generators",
    "abstract": "Power network and generators state estimation are usually tackled as separate problems. We propose a dynamic scheme for the simultaneous estimation of the network and the generator states. The estimation is formulated as an optimization problem on a moving-horizon of past observations. The framework is a generalization of static state estimation; it can handle incomplete model knowledge and does not require static network observability by PMUs. The numerical results show an improved estimation accuracy compared to static state estimation. Moreover, accurate estimation of the internal states of generators without PMUs on their terminals can be achieved. Finally, we highlight the capability of the proposed estimator to detect and identify bad data. ",
    "url": "https://arxiv.org/abs/2207.12150",
    "authors": [
      "Milos Katanic",
      "John Lygeros",
      "Gabriela Hug"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.12166",
    "title": "Graph Querying for Semantic Annotations",
    "abstract": "This paper presents how the online tool GREW-MATCH can be used to make queries and visualise data from existing semantically annotated corpora. A dedicated syntax is available to construct simple to complex queries and execute them against a corpus. Such queries give transverse views of the annotated data, these views can help for checking the consistency of annotations in one corpus or across several corpora. GREW-MATCH can then be seen as an error mining tool: when inconsistencies are detected, it helps finding the sentences which should be fixed. Finally, GREW-MATCH can also be used as a side tool to assist annotation tasks helping to find annotation examples in existing corpora to be compared to the data to be annotated. ",
    "url": "https://arxiv.org/abs/2207.12166",
    "authors": [
      "Maxime Amblard",
      "Bruno Guillaume",
      "Siyana Pavlova",
      "Guy Perrier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.12170",
    "title": "Generalized weights of convolutional codes",
    "abstract": "In 1997 Rosenthal and York defined generalized Hamming weights for convolutional codes, by regarding a convolutional code as an infinite dimensional linear code endowed with the Hamming metric. In this paper, we propose a new definition of generalized weights of convolutional codes, that takes into account the underlying module structure of the code. We derive the basic properties of our generalized weights and discuss the relation with the previous definition. We establish upper bounds on the weight hierarchy of MDS and MDP codes and show that that, depending on the code parameters, some or all of the generalized weights of MDS codes are determined by the length, rank, and internal degree of the code. We also prove an anticode bound for convolutional codes and define optimal anticodes as the codes which meet the anticode bound. Finally, we classify optimal anticodes and compute their weight hierarchy. ",
    "url": "https://arxiv.org/abs/2207.12170",
    "authors": [
      "Elisa Gorla",
      "Flavio Salizzoni"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2207.12201",
    "title": "Calibrated One-class Classification for Unsupervised Time Series Anomaly  Detection",
    "abstract": "Unsupervised time series anomaly detection is instrumental in monitoring and alarming potential faults of target systems in various domains. Current state-of-the-art time series anomaly detectors mainly focus on devising advanced neural network structures and new reconstruction/prediction learning objectives to learn data normality (normal patterns and behaviors) as accurately as possible. However, these one-class learning methods can be deceived by unknown anomalies in the training data (i.e., anomaly contamination). Further, their normality learning also lacks knowledge about the anomalies of interest. Consequently, they often learn a biased, inaccurate normality boundary. This paper proposes a novel one-class learning approach, named calibrated one-class classification, to tackle this problem. Our one-class classifier is calibrated in two ways: (1) by adaptively penalizing uncertain predictions, which helps eliminate the impact of anomaly contamination while accentuating the predictions that the one-class model is confident in, and (2) by discriminating the normal samples from native anomaly examples that are generated to simulate genuine time series abnormal behaviors on the basis of original data. These two calibrations result in contamination-tolerant, anomaly-informed one-class learning, yielding a significantly improved normality modeling. Extensive experiments on six real-world datasets show that our model substantially outperforms twelve state-of-the-art competitors and obtains 6% - 31% F1 score improvement. The source code is available at \\url{https://github.com/xuhongzuo/couta}. ",
    "url": "https://arxiv.org/abs/2207.12201",
    "authors": [
      "Hongzuo Xu",
      "Yijie Wang",
      "Songlei Jian",
      "Qing Liao",
      "Yongjun Wang",
      "Guansong Pang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.12203",
    "title": "Improving Adversarial Robustness via Mutual Information Estimation",
    "abstract": "Deep neural networks (DNNs) are found to be vulnerable to adversarial noise. They are typically misled by adversarial samples to make wrong predictions. To alleviate this negative effect, in this paper, we investigate the dependence between outputs of the target model and input adversarial samples from the perspective of information theory, and propose an adversarial defense method. Specifically, we first measure the dependence by estimating the mutual information (MI) between outputs and the natural patterns of inputs (called natural MI) and MI between outputs and the adversarial patterns of inputs (called adversarial MI), respectively. We find that adversarial samples usually have larger adversarial MI and smaller natural MI compared with those w.r.t. natural samples. Motivated by this observation, we propose to enhance the adversarial robustness by maximizing the natural MI and minimizing the adversarial MI during the training process. In this way, the target model is expected to pay more attention to the natural pattern that contains objective semantics. Empirical evaluations demonstrate that our method could effectively improve the adversarial accuracy against multiple attacks. ",
    "url": "https://arxiv.org/abs/2207.12203",
    "authors": [
      "Dawei Zhou",
      "Nannan Wang",
      "Xinbo Gao",
      "Bo Han",
      "Xiaoyu Wang",
      "Yibing Zhan",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.12208",
    "title": "Series2Graph: Graph-based Subsequence Anomaly Detection for Time Series",
    "abstract": "Subsequence anomaly detection in long sequences is an important problem with applications in a wide range of domains. However, the approaches proposed so far in the literature have severe limitations: they either require prior domain knowledge used to design the anomaly discovery algorithms, or become cumbersome and expensive to use in situations with recurrent anomalies of the same type. In this work, we address these problems, and propose an unsupervised method suitable for domain agnostic subsequence anomaly detection. Our method, Series2Graph, is based on a graph representation of a novel low-dimensionality embedding of subsequences. Series2Graph needs neither labeled instances (like supervised techniques) nor anomaly-free data (like zero-positive learning techniques), and identifies anomalies of varying lengths. The experimental results, on the largest set of synthetic and real datasets used to date, demonstrate that the proposed approach correctly identifies single and recurrent anomalies without any prior knowledge of their characteristics, outperforming by a large margin several competing approaches in accuracy, while being up to orders of magnitude faster. This paper has appeared in VLDB 2020. ",
    "url": "https://arxiv.org/abs/2207.12208",
    "authors": [
      "Paul Boniol",
      "Themis Palpanas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.12231",
    "title": "FAT-PIM: Low-Cost Error Detection for Processing-In-Memory",
    "abstract": "Processing In Memory (PIM) accelerators are promising architecture that can provide massive parallelization and high efficiency in various applications. Such architectures can instantaneously provide ultra-fast operation over extensive data, allowing real-time performance in data-intensive workloads. For instance, Resistive Memory (ReRAM) based PIM architectures are widely known for their inherent dot-product computation capability. While the performance of such architecture is essential, reliability and accuracy are also important, especially in mission-critical real-time systems. Unfortunately, the PIM architectures have a fundamental limitation in guaranteeing error-free operation. As a result, current methods must pay high implementation costs or performance penalties to achieve reliable execution in the PIM accelerator. In this paper, we make a fundamental observation of this reliability limitation of ReRAM based PIM architecture. Accordingly, we propose a novel solution--Falut Tolerant PIM or FAT-PIM, that can improve reliability for such systems significantly at a low cost. Our evaluation shows that we can improve the error tolerance significantly with only 4.9% performance cost and 3.9% storage overhead. ",
    "url": "https://arxiv.org/abs/2207.12231",
    "authors": [
      "Kazi Abu Zubair",
      "Sumit Kumar Jha",
      "David Mohaisen",
      "Clayton Hughes",
      "Amro Awad"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2207.12236",
    "title": "Personality-Driven Social Multimedia Content Recommendation",
    "abstract": "Social media marketing plays a vital role in promoting brand and product values to wide audiences. In order to boost their advertising revenues, global media buying platforms such as Facebook Ads constantly reduce the reach of branded organic posts, pushing brands to spend more on paid media ads. In order to run organic and paid social media marketing efficiently, it is necessary to understand the audience, tailoring the content to fit their interests and online behaviours, which is impossible to do manually at a large scale. At the same time, various personality type categorization schemes such as the Myers-Briggs Personality Type indicator make it possible to reveal the dependencies between personality traits and user content preferences on a wider scale by categorizing audience behaviours in a unified and structured manner. This problem is yet to be studied in depth by the research community, while the level of impact of different personality traits on content recommendation accuracy has not been widely utilised and comprehensively evaluated so far. Specifically, in this work we investigate the impact of human personality traits on the content recommendation model by applying a novel personality-driven multi-view content recommender system called Personality Content Marketing Recommender Engine, or PersiC. Our experimental results and real-world case study demonstrate not just PersiC's ability to perform efficient human personality-driven multi-view content recommendation, but also allow for actionable digital ad strategy recommendations, which when deployed are able to improve digital advertising efficiency by over 420% as compared to the original human-guided approach. ",
    "url": "https://arxiv.org/abs/2207.12236",
    "authors": [
      "Qi Yang",
      "Sergey Nikolenko",
      "Alfred Huang",
      "Aleksandr Farseev"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.12245",
    "title": "Decentralized digital twins of complex dynamical systems",
    "abstract": "In this paper, we introduce a decentralized digital twin (DDT) framework for dynamical systems and discuss the prospects of the DDT modeling paradigm in computational science and engineering applications. The DDT approach is built on a federated learning concept, a branch of machine learning that encourages knowledge sharing without sharing the actual data. This approach enables clients to collaboratively learn an aggregated model while keeping all the training data on each client. We demonstrate the feasibility of the DDT framework with various dynamical systems, which are often considered prototypes for modeling complex transport phenomena in spatiotemporally extended systems. Our results indicate that federated machine learning might be a key enabler for designing highly accurate decentralized digital twins in complex nonlinear spatiotemporal systems. ",
    "url": "https://arxiv.org/abs/2207.12245",
    "authors": [
      "Omer San",
      "Suraj Pawar",
      "Adil Rasheed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2207.12261",
    "title": "GraphCFC: A Directed Graph based Cross-modal Feature Complementation  Approach for Multimodal Conversational Emotion Recognition",
    "abstract": "Emotion Recognition in Conversation (ERC) plays a significant part in Human-Computer Interaction (HCI) systems since it can provide empathetic services. Multimodal ERC can mitigate the drawbacks of uni-modal approaches. Recently, Graph Neural Networks (GNNs) have been widely used in a variety of fields due to their superior performance in relation modeling. In multimodal ERC, GNNs are capable of extracting both long-distance contextual information and inter-modal interactive information. Unfortunately, since existing methods such as MMGCN directly fuse multiple modalities, redundant information may be generated and heterogeneous information may be lost. In this work, we present a directed Graph based Cross-modal Feature Complementation (GraphCFC) module that can efficiently model contextual and interactive information. GraphCFC alleviates the problem of heterogeneity gap in multimodal fusion by utilizing multiple subspace extractors and Pair-wise Cross-modal Complementary (PairCC) strategy. We extract various types of edges from the constructed graph for encoding, thus enabling GNNs to extract crucial contextual and interactive information more accurately when performing message passing. Furthermore, we design a GNN structure called GAT-MLP, which can provide a new unified network framework for multimodal learning. The experimental results on two benchmark datasets show that our GraphCFC outperforms the state-of-the-art (SOTA) approaches. ",
    "url": "https://arxiv.org/abs/2207.12261",
    "authors": [
      "Jiang Li",
      "Xiaoping Wang",
      "Guoqing Lv",
      "Zhigang Zeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.12263",
    "title": "SecretGen: Privacy Recovery on Pre-Trained Models via Distribution  Discrimination",
    "abstract": "Transfer learning through the use of pre-trained models has become a growing trend for the machine learning community. Consequently, numerous pre-trained models are released online to facilitate further research. However, it raises extensive concerns on whether these pre-trained models would leak privacy-sensitive information of their training data. Thus, in this work, we aim to answer the following questions: \"Can we effectively recover private information from these pre-trained models? What are the sufficient conditions to retrieve such sensitive information?\" We first explore different statistical information which can discriminate the private training distribution from other distributions. Based on our observations, we propose a novel private data reconstruction framework, SecretGen, to effectively recover private information. Compared with previous methods which can recover private data with the ground true prediction of the targeted recovery instance, SecretGen does not require such prior knowledge, making it more practical. We conduct extensive experiments on different datasets under diverse scenarios to compare SecretGen with other baselines and provide a systematic benchmark to better understand the impact of different auxiliary information and optimization operations. We show that without prior knowledge about true class prediction, SecretGen is able to recover private data with similar performance compared with the ones that leverage such prior knowledge. If the prior knowledge is given, SecretGen will significantly outperform baseline methods. We also propose several quantitative metrics to further quantify the privacy vulnerability of pre-trained models, which will help the model selection for privacy-sensitive applications. Our code is available at: https://github.com/AI-secure/SecretGen. ",
    "url": "https://arxiv.org/abs/2207.12263",
    "authors": [
      "Zhuowen Yuan",
      "Fan Wu",
      "Yunhui Long",
      "Chaowei Xiao",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.12271",
    "title": "NN2Rules: Extracting Rule List from Neural Networks",
    "abstract": "We present an algorithm, NN2Rules, to convert a trained neural network into a rule list. Rule lists are more interpretable since they align better with the way humans make decisions. NN2Rules is a decompositional approach to rule extraction, i.e., it extracts a set of decision rules from the parameters of the trained neural network model. We show that the decision rules extracted have the same prediction as the neural network on any input presented to it, and hence the same accuracy. A key contribution of NN2Rules is that it allows hidden neuron behavior to be either soft-binary (eg. sigmoid activation) or rectified linear (ReLU) as opposed to existing decompositional approaches that were developed with the assumption of soft-binary activation. ",
    "url": "https://arxiv.org/abs/2207.12271",
    "authors": [
      "G Roshan Lal",
      "Varun Mithal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.12278",
    "title": "A Survey on Graph Problems Parameterized Above and Below Guaranteed  Values",
    "abstract": "We survey the field of algorithms and complexity for graph problems parameterized above or below guaranteed values, a research area which was pioneered by Venkatesh Raman. Those problems seek, for a given graph $G$, a solution whose value is at least $g(G)+k$ or at most $g(G)-k$, where $g(G)$ is a guarantee on the value that any solution on $G$ takes. The goal is to design algorithms which find such solution in time whose complexity in k is decoupled from that in the guarantee, or to rule out the existence of such algorithms by means of intractability results. We discuss a large number of algorithms and intractability results, and complement them by several open problems. ",
    "url": "https://arxiv.org/abs/2207.12278",
    "authors": [
      "Gregory Gutin",
      "Matthias Mnich"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2207.12280",
    "title": "ArtFID: Quantitative Evaluation of Neural Style Transfer",
    "abstract": "The field of neural style transfer has experienced a surge of research exploring different avenues ranging from optimization-based approaches and feed-forward models to meta-learning methods. The developed techniques have not just progressed the field of style transfer, but also led to breakthroughs in other areas of computer vision, such as all of visual synthesis. However, whereas quantitative evaluation and benchmarking have become pillars of computer vision research, the reproducible, quantitative assessment of style transfer models is still lacking. Even in comparison to other fields of visual synthesis, where widely used metrics exist, the quantitative evaluation of style transfer is still lagging behind. To support the automatic comparison of different style transfer approaches and to study their respective strengths and weaknesses, the field would greatly benefit from a quantitative measurement of stylization performance. Therefore, we propose a method to complement the currently mostly qualitative evaluation schemes. We provide extensive evaluations and a large-scale user study to show that the proposed metric strongly coincides with human judgment. ",
    "url": "https://arxiv.org/abs/2207.12280",
    "authors": [
      "Matthias Wright",
      "Bj\u00f6rn Ommer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.12283",
    "title": "MedML: Fusing Medical Knowledge and Machine Learning Models for Early  Pediatric COVID-19 Hospitalization and Severity Prediction",
    "abstract": "The COVID-19 pandemic has caused devastating economic and social disruption, straining the resources of healthcare institutions worldwide. This has led to a nationwide call for models to predict hospitalization and severe illness in patients with COVID-19 to inform distribution of limited healthcare resources. We respond to one of these calls specific to the pediatric population. To address this challenge, we study two prediction tasks for the pediatric population using electronic health records: 1) predicting which children are more likely to be hospitalized, and 2) among hospitalized children, which individuals are more likely to develop severe symptoms. We respond to the national Pediatric COVID-19 data challenge with a novel machine learning model, MedML. MedML extracts the most predictive features based on medical knowledge and propensity scores from over 6 million medical concepts and incorporates the inter-feature relationships between heterogeneous medical features via graph neural networks (GNN). We evaluate MedML across 143,605 patients for the hospitalization prediction task and 11,465 patients for the severity prediction task using data from the National Cohort Collaborative (N3C) dataset. We also report detailed group-level and individual-level feature importance analyses to evaluate the model interpretability. MedML achieves up to a 7% higher AUROC score and up to a 14% higher AUPRC score compared to the best baseline machine learning models and performs well across all nine national geographic regions and over all three-month spans since the start of the pandemic. Our cross-disciplinary research team has developed a method of incorporating clinical domain knowledge as the framework for a new type of machine learning model that is more predictive and explainable than current state-of-the-art data-driven feature selection methods. ",
    "url": "https://arxiv.org/abs/2207.12283",
    "authors": [
      "Junyi Gao",
      "Chaoqi Yang",
      "George Heintz",
      "Scott Barrows",
      "Elise Albers",
      "Mary Stapel",
      "Sara Warfield",
      "Adam Cross",
      "Jimeng Sun",
      "N3C consortium"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.12303",
    "title": "Continual Few-Shot Learning with Adversarial Class Storage",
    "abstract": "Humans have a remarkable ability to quickly and effectively learn new concepts in a continuous manner without forgetting old knowledge. Though deep learning has made tremendous successes on various computer vision tasks, it faces challenges for achieving such human-level intelligence. In this paper, we define a new problem called continual few-shot learning, in which tasks arrive sequentially and each task is associated with a few training samples. We propose Continual Meta-Learner (CML) to solve this problem. CML integrates metric-based classification and a memory-based mechanism along with adversarial learning into a meta-learning framework, which leads to the desirable properties: 1) it can quickly and effectively learn to handle a new task; 2) it overcomes catastrophic forgetting; 3) it is model-agnostic. We conduct extensive experiments on two image datasets, MiniImageNet and CIFAR100. Experimental results show that CML delivers state-of-the-art performance in terms of classification accuracy on few-shot learning tasks without catastrophic forgetting. ",
    "url": "https://arxiv.org/abs/2207.12303",
    "authors": [
      "Kun Wu",
      "Chengxiang Yin",
      "Jian Tang",
      "Zhiyuan Xu",
      "Yanzhi Wang",
      "Dejun Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.12308",
    "title": "FAD: A Chinese Dataset for Fake Audio Detection",
    "abstract": "Fake audio detection is a growing concern and some relevant datasets have been designed for research. But there is no standard public Chinese dataset under additive noise conditions. In this paper, we aim to fill in the gap and design a Chinese fake audio detection dataset (FAD) for studying more generalized detection methods. Twelve mainstream speech generation techniques are used to generate fake audios. To simulate the real-life scenarios, three noise datasets are selected for noisy adding at five different signal noise ratios. FAD dataset can be used not only for fake audio detection, but also for detecting the algorithms of fake utterances for audio forensics. Baseline results are presented with analysis. The results that show fake audio detection methods with generalization remain challenging. The FAD dataset is publicly available. ",
    "url": "https://arxiv.org/abs/2207.12308",
    "authors": [
      "Haoxin Ma",
      "Jiangyan Yi",
      "Chenglong Wang",
      "Xinrui Yan",
      "Jianhua Tao",
      "Tao Wang",
      "Shiming Wang",
      "Le Xu",
      "Ruibo Fu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.12314",
    "title": "AutoCellLibX: Automated Standard Cell Library Extension Based on Pattern  Mining",
    "abstract": "Custom standard cell libraries can improve the final quality of the corresponding VLSI designs but properly customizing standard cell libraries remains challenging due to the complex characteristics of the VLSI designs. This paper presents an automatic standard-cell library extension framework, AutoCellLibX. It can find a set of standard cell cluster pattern candidates from the post-technology mapping gate-level netlist, with the consideration of standard cell characteristics and technology mapping constraints, based on our high-efficiency frequent subgraph mining algorithm. Meanwhile, to maximize the area benefit of standard cell customization for the given gate-level netlist, AutoCellLibX includes our proposed pattern combination algorithm which can iteratively find a set of gate-level patterns from numerous candidates as the extension part of the given initial standard cell library. To the best of our knowledge, AutoCellLibX is the first automated standard cell extension framework that closes the optimization loop between the analysis of gate-level netlist and standard cell library customization for VLSI design productivity. The experiments with FreePDK45 library and benchmarks from various domains show that AutoCellLibX can generate the library extension with up to 5 custom standard cells within 1.1 hours for each of the 31 benchmark designs and the resultant extension of the standard cell library can save design area by 4.49% averagely. ",
    "url": "https://arxiv.org/abs/2207.12314",
    "authors": [
      "Tingyuan Liang",
      "Jingsong Chen",
      "Lei Li",
      "Wei Zhang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2207.12315",
    "title": "Stable Parallel Training of Wasserstein Conditional Generative  Adversarial Neural Networks",
    "abstract": "We propose a stable, parallel approach to train Wasserstein Conditional Generative Adversarial Neural Networks (W-CGANs) under the constraint of a fixed computational budget. Differently from previous distributed GANs training techniques, our approach avoids inter-process communications, reduces the risk of mode collapse and enhances scalability by using multiple generators, each one of them concurrently trained on a single data label. The use of the Wasserstein metric also reduces the risk of cycling by stabilizing the training of each generator. We illustrate the approach on the CIFAR10, CIFAR100, and ImageNet1k datasets, three standard benchmark image datasets, maintaining the original resolution of the images for each dataset. Performance is assessed in terms of scalability and final accuracy within a limited fixed computational time and computational resources. To measure accuracy, we use the inception score, the Frechet inception distance, and image quality. An improvement in inception score and Frechet inception distance is shown in comparison to previous results obtained by performing the parallel approach on deep convolutional conditional generative adversarial neural networks (DC-CGANs) as well as an improvement of image quality of the new images created by the GANs approach. Weak scaling is attained on both datasets using up to 2,000 NVIDIA V100 GPUs on the OLCF supercomputer Summit. ",
    "url": "https://arxiv.org/abs/2207.12315",
    "authors": [
      "Massimiliano Lupo Pasini",
      "Junqi Yin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2207.12316",
    "title": "A Theoretical Framework for Inference and Learning in Predictive Coding  Networks",
    "abstract": "Predictive coding (PC) is an influential theory in computational neuroscience, which argues that the cortex forms unsupervised world models by implementing a hierarchical process of prediction error minimization. PC networks (PCNs) are trained in two phases. First, neural activities are updated to optimize the network's response to external stimuli. Second, synaptic weights are updated to consolidate this change in activity -- an algorithm called \\emph{prospective configuration}. While previous work has shown how in various limits, PCNs can be found to approximate backpropagation (BP), recent work has demonstrated that PCNs operating in this standard regime, which does not approximate BP, nevertheless obtain competitive training and generalization performance to BP-trained networks while outperforming them on tasks such as online, few-shot, and continual learning, where brains are known to excel. Despite this promising empirical performance, little is understood theoretically about the properties and dynamics of PCNs in this regime. In this paper, we provide a comprehensive theoretical analysis of the properties of PCNs trained with prospective configuration. We first derive analytical results concerning the inference equilibrium for PCNs and a previously unknown close connection relationship to target propagation (TP). Secondly, we provide a theoretical analysis of learning in PCNs as a variant of generalized expectation-maximization and use that to prove the convergence of PCNs to critical points of the BP loss function, thus showing that deep PCNs can, in theory, achieve the same generalization performance as BP, while maintaining their unique advantages. ",
    "url": "https://arxiv.org/abs/2207.12316",
    "authors": [
      "Beren Millidge",
      "Yuhang Song",
      "Tommaso Salvatori",
      "Thomas Lukasiewicz",
      "Rafal Bogacz"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.12319",
    "title": "OpenFilter: A Framework to Democratize Research Access to Social Media  AR Filters",
    "abstract": "Augmented Reality or AR filters on selfies have become very popular on social media platforms for a variety of applications, including marketing, entertainment and aesthetics. Given the wide adoption of AR face filters and the importance of faces in our social structures and relations, there is increased interest by the scientific community to analyze the impact of such filters from a psychological, artistic and sociological perspective. However, there are few quantitative analyses in this area mainly due to a lack of publicly available datasets of facial images with applied AR filters. The proprietary, close nature of most social media platforms does not allow users, scientists and practitioners to access the code and the details of the available AR face filters. Scraping faces from these platforms to collect data is ethically unacceptable and should, therefore, be avoided in research. In this paper, we present OpenFilter, a flexible framework to apply AR filters available in social media platforms on existing large collections of human faces. Moreover, we share FairBeauty and B-LFW, two beautified versions of the publicly available FairFace and LFW datasets and we outline insights derived from the analysis of these beautified datasets. ",
    "url": "https://arxiv.org/abs/2207.12319",
    "authors": [
      "Piera Riccio",
      "Bill Psomas",
      "Francesco Galati",
      "Francisco Escolano",
      "Thomas Hofmann",
      "Nuria Oliver"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.12321",
    "title": "RSG-Net: Towards Rich Sematic Relationship Prediction for Intelligent  Vehicle in Complex Environments",
    "abstract": "Behavioral and semantic relationships play a vital role on intelligent self-driving vehicles and ADAS systems. Different from other research focused on trajectory, position, and bounding boxes, relationship data provides a human understandable description of the object's behavior, and it could describe an object's past and future status in an amazingly brief way. Therefore it is a fundamental method for tasks such as risk detection, environment understanding, and decision making. In this paper, we propose RSG-Net (Road Scene Graph Net): a graph convolutional network designed to predict potential semantic relationships from object proposals, and produces a graph-structured result, called \"Road Scene Graph\". The experimental results indicate that this network, trained on Road Scene Graph dataset, could efficiently predict potential semantic relationships among objects around the ego-vehicle. ",
    "url": "https://arxiv.org/abs/2207.12321",
    "authors": [
      "Yafu Tian",
      "Alexander Carballo",
      "Ruifeng Li",
      "Kazuya Takeda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.12327",
    "title": "Technical Report: Assisting Backdoor Federated Learning with Whole  Population Knowledge Alignment",
    "abstract": "Due to the distributed nature of Federated Learning (FL), researchers have uncovered that FL is vulnerable to backdoor attacks, which aim at injecting a sub-task into the FL without corrupting the performance of the main task. Single-shot backdoor attack achieves high accuracy on both the main task and backdoor sub-task when injected at the FL model convergence. However, the early-injected single-shot backdoor attack is ineffective because: (1) the maximum backdoor effectiveness is not reached at injection because of the dilution effect from normal local updates; (2) the backdoor effect decreases quickly as the backdoor will be overwritten by the newcoming normal local updates. In this paper, we strengthen the early-injected single-shot backdoor attack utilizing FL model information leakage. We show that the FL convergence can be expedited if the client trains on a dataset that mimics the distribution and gradients of the whole population. Based on this observation, we proposed a two-phase backdoor attack, which includes a preliminary phase for the subsequent backdoor attack. In the preliminary phase, the attacker-controlled client first launches a whole population distribution inference attack and then trains on a locally crafted dataset that is aligned with both the gradient and inferred distribution. Benefiting from the preliminary phase, the later injected backdoor achieves better effectiveness as the backdoor effect will be less likely to be diluted by the normal model updates. Extensive experiments are conducted on MNIST dataset under various data heterogeneity settings to evaluate the effectiveness of the proposed backdoor attack. Results show that the proposed backdoor outperforms existing backdoor attacks in both success rate and longevity, even when defense mechanisms are in place. ",
    "url": "https://arxiv.org/abs/2207.12327",
    "authors": [
      "Tian Liu",
      "Xueyang Hu",
      "Tao Shu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.12339",
    "title": "Localization of Coordinated Cyber-Physical Attacks in Power Grids Using  Moving Target Defense and Deep Learning",
    "abstract": "As one of the most sophisticated attacks against power grids, coordinated cyber-physical attacks (CCPAs) damage the power grid's physical infrastructure and use a simultaneous cyber attack to mask its effect. This work proposes a novel approach to detect such attacks and identify the location of the line outages (due to the physical attack). The proposed approach consists of three parts. Firstly, moving target defense (MTD) is applied to expose the physical attack by actively perturbing transmission line reactance via distributed flexible AC transmission system (D-FACTS) devices. MTD invalidates the attackers' knowledge required to mask their physical attack. Secondly, convolution neural networks (CNNs) are applied to localize line outage position from the compromised measurements. Finally, model agnostic meta-learning (MAML) is used to accelerate the training speed of CNN following the topology reconfigurations (due to MTD) and reduce the data/retraining time requirements. Simulations are carried out using IEEE test systems. The experimental results demonstrate that the proposed approach can effectively localize line outages in stealthy CCPAs. ",
    "url": "https://arxiv.org/abs/2207.12339",
    "authors": [
      "Yexiang Chen",
      "Subhash Lakshminarayana",
      "Fei Teng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.12355",
    "title": "Developing Optimal Causal Cyber-Defence Agents via Cyber Security  Simulation",
    "abstract": "In this paper we explore cyber security defence, through the unification of a novel cyber security simulator with models for (causal) decision-making through optimisation. Particular attention is paid to a recently published approach: dynamic causal Bayesian optimisation (DCBO). We propose that DCBO can act as a blue agent when provided with a view of a simulated network and a causal model of how a red agent spreads within that network. To investigate how DCBO can perform optimal interventions on host nodes, in order to reduce the cost of intrusions caused by the red agent. Through this we demonstrate a complete cyber-simulation system, which we use to generate observational data for DCBO and provide numerical quantitative results which lay the foundations for future work in this space. ",
    "url": "https://arxiv.org/abs/2207.12355",
    "authors": [
      "Alex Andrew",
      "Sam Spillard",
      "Joshua Collyer",
      "Neil Dhir"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.12377",
    "title": "A Confident Deep Learning loss function for one-step Conformal  Prediction approximation",
    "abstract": "Deep Learning predictions with measurable confidence are increasingly desirable for real-world problems, especially in high-risk settings. The Conformal Prediction (CP) framework is a versatile solution that automatically guarantees a maximum error rate. However, CP suffers from computational inefficiencies that limit its application to large-scale datasets. In this paper, we propose a novel conformal loss function that approximates the traditionally two-step CP approach in a single step. By evaluating and penalising deviations from the stringent expected CP output distribution, a Deep Learning model may learn the direct relationship between input data and conformal p-values. Our approach achieves significant training time reductions up to 86% compared to Aggregated Conformal Prediction (ACP), an accepted CP approximation variant. In terms of approximate validity and predictive efficiency, we carry out a comprehensive empirical evaluation to show our novel loss function's competitiveness with ACP on the well-established MNIST dataset. ",
    "url": "https://arxiv.org/abs/2207.12377",
    "authors": [
      "Julia A. Meister",
      "Khuong An Nguyen",
      "Zhiyuan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.12380",
    "title": "Task-Relevant Failure Detection for Trajectory Predictors in Autonomous  Vehicles",
    "abstract": "In modern autonomy stacks, prediction modules are paramount to planning motions in the presence of other mobile agents. However, failures in prediction modules can mislead the downstream planner into making unsafe decisions. Indeed, the high uncertainty inherent to the task of trajectory forecasting ensures that such mispredictions occur frequently. Motivated by the need to improve safety of autonomous vehicles without compromising on their performance, we develop a probabilistic run-time monitor that detects when a \"harmful\" prediction failure occurs, i.e., a task-relevant failure detector. We achieve this by propagating trajectory prediction errors to the planning cost to reason about their impact on the AV. Furthermore, our detector comes equipped with performance measures on the false-positive and the false-negative rate and allows for data-free calibration. In our experiments we compared our detector with various others and found that our detector has the highest area under the receiver operator characteristic curve. ",
    "url": "https://arxiv.org/abs/2207.12380",
    "authors": [
      "Alec Farid",
      "Sushant Veer",
      "Boris Ivanovic",
      "Karen Leung",
      "Marco Pavone"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.12391",
    "title": "SegPGD: An Effective and Efficient Adversarial Attack for Evaluating and  Boosting Segmentation Robustness",
    "abstract": "Deep neural network-based image classifications are vulnerable to adversarial perturbations. The image classifications can be easily fooled by adding artificial small and imperceptible perturbations to input images. As one of the most effective defense strategies, adversarial training was proposed to address the vulnerability of classification models, where the adversarial examples are created and injected into training data during training. The attack and defense of classification models have been intensively studied in past years. Semantic segmentation, as an extension of classifications, has also received great attention recently. Recent work shows a large number of attack iterations are required to create effective adversarial examples to fool segmentation models. The observation makes both robustness evaluation and adversarial training on segmentation models challenging. In this work, we propose an effective and efficient segmentation attack method, dubbed SegPGD. Besides, we provide a convergence analysis to show the proposed SegPGD can create more effective adversarial examples than PGD under the same number of attack iterations. Furthermore, we propose to apply our SegPGD as the underlying attack method for segmentation adversarial training. Since SegPGD can create more effective adversarial examples, the adversarial training with our SegPGD can boost the robustness of segmentation models. Our proposals are also verified with experiments on popular Segmentation model architectures and standard segmentation datasets. ",
    "url": "https://arxiv.org/abs/2207.12391",
    "authors": [
      "Jindong Gu",
      "Hengshuang Zhao",
      "Volker Tresp",
      "Philip Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.11248",
    "title": "Brain tumor detection using artificial convolutional neural networks",
    "abstract": "In this paper, a convolutional neural network (CNN) was used to classify NMR images of human brains with 4 different types of tumors: meningioma, glioma and pituitary gland tumors. During the training phase of this project, an accuracy of 100% was obtained, meanwhile, in the evaluation phase the precision was 96%. ",
    "url": "https://arxiv.org/abs/2207.11248",
    "authors": [
      "Javier Melchor",
      "Balam Sotelo",
      "Jorge Vera",
      "Horacio Corral"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11297",
    "title": "Accelerated and Quantitative 3D Semisolid MT/CEST Imaging using a  Generative Adversarial Network (GAN-CEST)",
    "abstract": "Purpose: To substantially shorten the acquisition time required for quantitative 3D chemical exchange saturation transfer (CEST) and semisolid magnetization transfer (MT) imaging and allow for rapid chemical exchange parameter map reconstruction. Methods: Three-dimensional CEST and MT magnetic resonance fingerprinting (MRF) datasets of L-arginine phantoms, whole-brains, and calf muscles from healthy volunteers, cancer patients, and cardiac patients were acquired using 3T clinical scanners at 3 different sites, using 3 different scanner models and coils. A generative adversarial network supervised framework (GAN-CEST) was then designed and trained to learn the mapping from a reduced input data space to the quantitative exchange parameter space, while preserving perceptual and quantitative content. Results: The GAN-CEST 3D acquisition time was 42-52 seconds, 70% shorter than CEST-MRF. The quantitative reconstruction of the entire brain took 0.8 seconds. An excellent agreement was observed between the ground truth and GAN-based L-arginine concentration and pH values (Pearson's r > 0.97, NRMSE < 1.5%). GAN-CEST images from a brain-tumor subject yielded a semi-solid volume fraction and exchange rate NRMSE of 3.8$\\pm$1.3% and 4.6$\\pm$1.3%, respectively, and SSIM of 96.3$\\pm$1.6% and 95.0$\\pm$2.4%, respectively. The mapping of the calf-muscle exchange parameters in a cardiac patient, yielded NRMSE < 7% and SSIM > 94% for the semi-solid exchange parameters. In regions with large susceptibility artifacts, GAN-CEST has demonstrated improved performance and reduced noise compared to MRF. Conclusion: GAN-CEST can substantially reduce the acquisition time for quantitative semisolid MT/CEST mapping, while retaining performance even when facing pathologies and scanner models that were not available during training. ",
    "url": "https://arxiv.org/abs/2207.11297",
    "authors": [
      "Jonah Weigand-Whittier",
      "Maria Sedykh",
      "Kai Herz",
      "Jaume Coll-Font",
      "Anna N. Foster",
      "Elizabeth R. Gerstner",
      "Christopher Nguyen",
      "Moritz Zaiss",
      "Christian T. Farrar",
      "Or Perlman"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11388",
    "title": "Low-Complexity Acoustic Echo Cancellation with Neural Kalman Filtering",
    "abstract": "The Kalman filter has been adopted in acoustic echo cancellation due to its robustness to double-talk, fast convergence, and good steady-state performance. The performance of Kalman filter is closely related to the estimation accuracy of the state noise covariance and the observation noise covariance. The estimation error may lead to unacceptable results, especially when the echo path suffers abrupt changes, the tracking performance of the Kalman filter could be degraded significantly. In this paper, we propose the neural Kalman filtering (NKF), which uses neural networks to implicitly model the covariance of the state noise and observation noise and to output the Kalman gain in real-time. Experimental results on both synthetic test sets and real-recorded test sets show that, the proposed NKF has superior convergence and re-convergence performance while ensuring low near-end speech degradation comparing with the state-of-the-art model-based methods. Moreover, the model size of the proposed NKF is merely 5.3 K and the RTF is as low as 0.09, which indicates that it can be deployed in low-resource platforms. ",
    "url": "https://arxiv.org/abs/2207.11388",
    "authors": [
      "Dong Yang",
      "Fei Jiang",
      "Wei Wu",
      "Xuefei Fang",
      "Muyong Cao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2207.11491",
    "title": "Dimensional Reduction of Solvency Contagion Dynamics on Financial  Networks",
    "abstract": "Modelling systems with networks has been a powerful approach to tame the complexity of several phenomena. Unfortunately, such an approach is often made difficult by the large number of variables to take into consideration. Methods of dimensional reduction are useful tools to rescale a complex dynamical network down to a low-dimensional effective system and thus to capture the global features of the dynamics. Here we study the application of the degree-weighted and spectral reduction methods to an important class of dynamical processes on networks: the propagation of credit shocks within an interbank network, modelled according to the DebtRank algorithm. In particular we introduce an effective version of the dynamics, characterised by functions with continuous derivatives that can be handled by the dimensional reduction. We test the reduction methods against the full dynamical system in different interbank market settings: homogeneous and heterogeneous networks generated from state-of-the-art reconstruction methods as well as networks derived from empirical e-MID data. Our results indicate that, for proper choices of the bank default probability, reduction methods are able to provide reliable estimates of systemic risk in the market, with the spectral reduction better handling heterogeneous networks. Finally we provide new physical insights on the nature and working principles of dimensional reduction methods. ",
    "url": "https://arxiv.org/abs/2207.11491",
    "authors": [
      "Gianmarco Ricciardi",
      "Guido Montagna",
      "Guido Caldarelli",
      "Giulio Cimini"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Risk Management (q-fin.RM)"
    ]
  },
  {
    "id": "arXiv:2207.11583",
    "title": "Boosting the Efficiency of Parametric Detection with Hierarchical Neural  Networks",
    "abstract": "Gravitational wave astronomy is a vibrant field that leverages both classic and modern data processing techniques for the understanding of the universe. Various approaches have been proposed for improving the efficiency of the detection scheme, with hierarchical matched filtering being an important strategy. Meanwhile, deep learning methods have recently demonstrated both consistency with matched filtering methods and remarkable statistical performance. In this work, we propose Hierarchical Detection Network (HDN), a novel approach to efficient detection that combines ideas from hierarchical matching and deep learning. The network is trained using a novel loss function, which encodes simultaneously the goals of statistical accuracy and efficiency. We discuss the source of complexity reduction of the proposed model, and describe a general recipe for initialization with each layer specializing in different regions. We demonstrate the performance of HDN with experiments using open LIGO data and synthetic injections, and observe with two-layer models a $79\\%$ efficiency gain compared with matched filtering at an equal error rate of $0.2\\%$. Furthermore, we show how training a three-layer HDN initialized using two-layer model can further boost both accuracy and efficiency, highlighting the power of multiple simple layers in efficient detection. ",
    "url": "https://arxiv.org/abs/2207.11583",
    "authors": [
      "Jingkai Yan",
      "Robert Colgan",
      "John Wright",
      "Zsuzsa M\u00e1rka",
      "Imre Bartos",
      "Szabolcs M\u00e1rka"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ]
  },
  {
    "id": "arXiv:2207.11593",
    "title": "A very sharp threshold for first order logic distinguishability of  random graphs",
    "abstract": "In this paper we find an integer $h=h(n)$ such that the minimum number of variables of a first order sentence that distinguishes between two independent uniformly distributed random graphs of size $n$ with the asymptotically largest possible probability $\\frac{1}{4}-o(1)$ belongs to $\\{h,h+1,h+2,h+3\\}$. We also prove that the minimum (random) $k$ such that two independent random graphs are distinguishable by a first order sentence with $k$ variables belongs to $\\{h,h+1,h+2\\}$ with probability $1-o(1)$. ",
    "url": "https://arxiv.org/abs/2207.11593",
    "authors": [
      "Itai Benjamini",
      "Maksim Zhukovskii"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2207.11628",
    "title": "Prediction Intervals in the Beta Autoregressive Moving Average Model",
    "abstract": "In this paper, we propose five prediction intervals for the beta autoregressive moving average model. This model is suitable for modeling and forecasting variables that assume values in the interval $(0,1)$. Two of the proposed prediction intervals are based on approximations considering the normal distribution and the quantile function of the beta distribution. We also consider bootstrap-based prediction intervals, namely: (i) bootstrap prediction errors (BPE) interval; (ii) bias-corrected and acceleration (BCa) prediction interval; and (iii) percentile prediction interval based on the quantiles of the bootstrap-predicted values for two different bootstrapping schemes. The proposed prediction intervals were evaluated according to Monte Carlo simulations. The BCa prediction interval offered the best performance among the evaluated intervals, showing lower coverage rate distortion and small average length. We applied our methodology for predicting the water level of the Cantareira water supply system in S\\~ao Paulo, Brazil. ",
    "url": "https://arxiv.org/abs/2207.11628",
    "authors": [
      "B. G. Palm",
      "F. M. Bayer",
      "R. J. Cintra"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2207.11678",
    "title": "FD-MAR: Fourier Dual-domain Network for CT Metal Artifact Reduction",
    "abstract": "The presence of high-density objects such as metal implants and dental fillings can introduce severely streak-like artifacts in computed tomography (CT) images, greatly limiting subsequent diagnosis. Although various deep neural networks-based methods have been proposed for metal artifact reduction (MAR), they usually suffer from poor performance due to limited exploitation of global context in the sinogram domain, secondary artifacts introduced in the image domain, and the requirement of precise metal masks. To address these issues, this paper explores fast Fourier convolution for MAR in both sinogram and image domains, and proposes a Fourier dual-domain network for MAR, termed FD-MAR. Specifically, we first propose a Fourier sinogram restoration network, which can leverage sinogram-wide receptive context to fill in the metal-corrupted region from uncorrupted region and, hence, is robust to the metal trace. Second, we propose a Fourier refinement network in the image domain, which can refine the reconstructed images in a local-to-global manner by exploring image-wide context information. As a result, the proposed FD-MAR can explore the sinogram- and image-wide receptive fields for MAR. By optimizing FD-MAR with a composite loss function, extensive experimental results demonstrate the superiority of the proposed FD-MAR over the state-of-the-art MAR methods in terms of quantitative metrics and visual comparison. Notably, FD-MAR does not require precise metal masks, which is of great importance in clinical routine. ",
    "url": "https://arxiv.org/abs/2207.11678",
    "authors": [
      "Zilong Li",
      "Qi Gao",
      "Yaping Wu",
      "Chuang Niu",
      "Junping Zhang",
      "Meiyun Wang",
      "Ge Wang",
      "Hongming Shan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11683",
    "title": "PCA: Semi-supervised Segmentation with Patch Confidence Adversarial  Training",
    "abstract": "Deep learning based semi-supervised learning (SSL) methods have achieved strong performance in medical image segmentation, which can alleviate doctors' expensive annotation by utilizing a large amount of unlabeled data. Unlike most existing semi-supervised learning methods, adversarial training based methods distinguish samples from different sources by learning the data distribution of the segmentation map, leading the segmenter to generate more accurate predictions. We argue that the current performance restrictions for such approaches are the problems of feature extraction and learning preference. In this paper, we propose a new semi-supervised adversarial method called Patch Confidence Adversarial Training (PCA) for medical image segmentation. Rather than single scalar classification results or pixel-level confidence maps, our proposed discriminator creates patch confidence maps and classifies them at the scale of the patches. The prediction of unlabeled data learns the pixel structure and context information in each patch to get enough gradient feedback, which aids the discriminator in convergent to an optimal state and improves semi-supervised segmentation performance. Furthermore, at the discriminator's input, we supplement semantic information constraints on images, making it simpler for unlabeled data to fit the expected data distribution. Extensive experiments on the Automated Cardiac Diagnosis Challenge (ACDC) 2017 dataset and the Brain Tumor Segmentation (BraTS) 2019 challenge dataset show that our method outperforms the state-of-the-art semi-supervised methods, which demonstrates its effectiveness for medical image segmentation. ",
    "url": "https://arxiv.org/abs/2207.11683",
    "authors": [
      "Zihang Xu",
      "Zhenghua Xu",
      "Shuo Zhang",
      "Thomas Lukasiewicz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11882",
    "title": "Sparse-based Domain Adaptation Network for OCTA Image Super-Resolution  Reconstruction",
    "abstract": "Retinal Optical Coherence Tomography Angiography (OCTA) with high-resolution is important for the quantification and analysis of retinal vasculature. However, the resolution of OCTA images is inversely proportional to the field of view at the same sampling frequency, which is not conducive to clinicians for analyzing larger vascular areas. In this paper, we propose a novel Sparse-based domain Adaptation Super-Resolution network (SASR) for the reconstruction of realistic 6x6 mm2/low-resolution (LR) OCTA images to high-resolution (HR) representations. To be more specific, we first perform a simple degradation of the 3x3 mm2/high-resolution (HR) image to obtain the synthetic LR image. An efficient registration method is then employed to register the synthetic LR with its corresponding 3x3 mm2 image region within the 6x6 mm2 image to obtain the cropped realistic LR image. We then propose a multi-level super-resolution model for the fully-supervised reconstruction of the synthetic data, guiding the reconstruction of the realistic LR images through a generative-adversarial strategy that allows the synthetic and realistic LR images to be unified in the feature domain. Finally, a novel sparse edge-aware loss is designed to dynamically optimize the vessel edge structure. Extensive experiments on two OCTA sets have shown that our method performs better than state-of-the-art super-resolution reconstruction methods. In addition, we have investigated the performance of the reconstruction results on retina structure segmentations, which further validate the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2207.11882",
    "authors": [
      "Huaying Hao",
      "Cong Xu",
      "Dan Zhang",
      "Qifeng Yan",
      "Jiong Zhang",
      "Yue Liu",
      "Yitian Zhao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11957",
    "title": "Uniqueness of a solution to a general class of discrete system defined  on connected graphs",
    "abstract": "In this work we prove uniqueness result for an implicit discrete system defined on connected graphs. Our discrete system is motivated from a certain class of spatial segregation of reaction-diffusion equations. ",
    "url": "https://arxiv.org/abs/2207.11957",
    "authors": [
      "Avetik Arakelyan"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Combinatorics (math.CO)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.12056",
    "title": "REPNP: Plug-and-Play with Deep Reinforcement Learning Prior for Robust  Image Restoration",
    "abstract": "Image restoration schemes based on the pre-trained deep models have received great attention due to their unique flexibility for solving various inverse problems. In particular, the Plug-and-Play (PnP) framework is a popular and powerful tool that can integrate an off-the-shelf deep denoiser for different image restoration tasks with known observation models. However, obtaining the observation model that exactly matches the actual one can be challenging in practice. Thus, the PnP schemes with conventional deep denoisers may fail to generate satisfying results in some real-world image restoration tasks. We argue that the robustness of the PnP framework is largely limited by using the off-the-shelf deep denoisers that are trained by deterministic optimization. To this end, we propose a novel deep reinforcement learning (DRL) based PnP framework, dubbed RePNP, by leveraging a light-weight DRL-based denoiser for robust image restoration tasks. Experimental results demonstrate that the proposed RePNP is robust to the observation model used in the PnP scheme deviating from the actual one. Thus, RePNP can generate more reliable restoration results for image deblurring and super resolution tasks. Compared with several state-of-the-art deep image restoration baselines, RePNP achieves better results subjective to model deviation with fewer model parameters. ",
    "url": "https://arxiv.org/abs/2207.12056",
    "authors": [
      "Chong Wang",
      "Rongkai Zhang",
      "Saiprasad Ravishankar",
      "Bihan Wen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.12124",
    "title": "Inference of Regulatory Networks Through Temporally Sparse Data",
    "abstract": "A major goal in genomics is to properly capture the complex dynamical behaviors of gene regulatory networks (GRNs). This includes inferring the complex interactions between genes, which can be used for a wide range of genomics analyses, including diagnosis or prognosis of diseases and finding effective treatments for chronic diseases such as cancer. Boolean networks have emerged as a successful class of models for capturing the behavior of GRNs. In most practical settings, inference of GRNs should be achieved through limited and temporally sparse genomics data. A large number of genes in GRNs leads to a large possible topology candidate space, which often cannot be exhaustively searched due to the limitation in computational resources. This paper develops a scalable and efficient topology inference for GRNs using Bayesian optimization and kernel-based methods. Rather than an exhaustive search over possible topologies, the proposed method constructs a Gaussian Process (GP) with a topology-inspired kernel function to account for correlation in the likelihood function. Then, using the posterior distribution of the GP model, the Bayesian optimization efficiently searches for the topology with the highest likelihood value by optimally balancing between exploration and exploitation. The performance of the proposed method is demonstrated through comprehensive numerical experiments using a well-known mammalian cell-cycle network. ",
    "url": "https://arxiv.org/abs/2207.12124",
    "authors": [
      "Mohammad Alali",
      "Mahdi Imani"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.12135",
    "title": "Label Uncertainty Modeling and Prediction for Speech Emotion Recognition  using t-Distributions",
    "abstract": "As different people perceive others' emotional expressions differently, their annotation in terms of arousal and valence are per se subjective. To address this, these emotion annotations are typically collected by multiple annotators and averaged across annotators in order to obtain labels for arousal and valence. However, besides the average, also the uncertainty of a label is of interest, and should also be modeled and predicted for automatic emotion recognition. In the literature, for simplicity, label uncertainty modeling is commonly approached with a Gaussian assumption on the collected annotations. However, as the number of annotators is typically rather small due to resource constraints, we argue that the Gaussian approach is a rather crude assumption. In contrast, in this work we propose to model the label distribution using a Student's t-distribution which allows us to account for the number of annotations available. With this model, we derive the corresponding Kullback-Leibler divergence based loss function and use it to train an estimator for the distribution of emotion labels, from which the mean and uncertainty can be inferred. Through qualitative and quantitative analysis, we show the benefits of the t-distribution over a Gaussian distribution. We validate our proposed method on the AVEC'16 dataset. Results reveal that our t-distribution based approach improves over the Gaussian approach with state-of-the-art uncertainty modeling results in speech-based emotion recognition, along with an optimal and even faster convergence. ",
    "url": "https://arxiv.org/abs/2207.12135",
    "authors": [
      "Navin Raj Prabhu",
      "Nale Lehmann-Willenbrock",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2207.12209",
    "title": "Lagrangian Density Space-Time Deep Neural Network Topology",
    "abstract": "As a network-based functional approximator, we have proposed a \"Lagrangian Density Space-Time Deep Neural Networks\" (LDDNN) topology. It is qualified for unsupervised training and learning to predict the dynamics of underlying physical science governed phenomena. The prototypical network respects the fundamental conservation laws of nature through the succinctly described Lagrangian and Hamiltonian density of the system by a given data-set of generalized nonlinear partial differential equations. The objective is to parameterize the Lagrangian density over a neural network and directly learn from it through data instead of hand-crafting an exact time-dependent \"Action solution\" of Lagrangian density for the physical system. With this novel approach, can understand and open up the information inference aspect of the \"Black-box deep machine learning representation\" for the physical dynamics of nature by constructing custom-tailored network interconnect topologies, activation, and loss/cost functions based on the underlying physical differential operators. This article will discuss statistical physics interpretation of neural networks in the Lagrangian and Hamiltonian domains. ",
    "url": "https://arxiv.org/abs/2207.12209",
    "authors": [
      "Bhupesh Bishnoi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.12218",
    "title": "Cov3d: Detection of the presence and severity of COVID-19 from CT scans  using 3D ResNets",
    "abstract": "Deep learning has been used to assist in the analysis of medical imaging. One such use is the classification of Computed Tomography (CT) scans when detecting for COVID-19 in subjects. This paper presents Cov3d, a three dimensional convolutional neural network for detecting the presence and severity of COVID19 from chest CT scans. Trained on the COV19-CT-DB dataset with human expert annotations, it achieves a macro f1 score of 0.9476 on the validation set for the task of detecting the presence of COVID19. For the task of classifying the severity of COVID19, it achieves a macro f1 score of 0.7552. Both results improve on the baseline results of the `AI-enabled Medical Image Analysis Workshop and Covid-19 Diagnosis Competition' (MIA-COV19D) in 2022. ",
    "url": "https://arxiv.org/abs/2207.12218",
    "authors": [
      "Robert Turnbull"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.12238",
    "title": "OCTAve: 2D en face Optical Coherence Tomography Angiography Vessel  Segmentation in Weakly-Supervised Learning with Locality Augmentation",
    "abstract": "While there have been increased researches using deep learning techniques for the extraction of vascular structure from the 2D en face OCTA, for such approach, it is known that the data annotation process on the curvilinear structure like the retinal vasculature is very costly and time consuming, albeit few tried to address the annotation problem. In this work, we propose the application of the scribble-base weakly-supervised learning method to automate the pixel-level annotation. The proposed method, called OCTAve, combines the weakly-supervised learning using scribble-annotated ground truth augmented with an adversarial and a novel self-supervised deep supervision. Our novel mechanism is designed to utilize the discriminative outputs from the discrimination layer of a UNet-like architecture where the Kullback-Liebler Divergence between the aggregate discriminative outputs and the segmentation map predicate is minimized during the training. This combined method leads to the better localization of the vascular structure as shown in our experiments. We validate our proposed method on the large public datasets i.e., ROSE, OCTA-500. The segmentation performance is compared against both state-of-the-art fully-supervised and scribble-based weakly-supervised approaches. The implementation of our work used in the experiments is located at [LINK]. ",
    "url": "https://arxiv.org/abs/2207.12238",
    "authors": [
      "Amrest Chinkamol",
      "Vetit Kanjaras",
      "Phattarapong Sawangjai",
      "Yitian Zhao",
      "Thapanun Sudhawiyangkul",
      "Chantana Chantrapornchai",
      "Cuntai Guan",
      "Theerawit Wilaiprasitporn"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.12373",
    "title": "Dimension of Activity in Random Neural Networks",
    "abstract": "Neural networks are high-dimensional nonlinear dynamical systems that process information through the coordinated activity of many interconnected units. Understanding how biological and machine-learning networks function and learn requires knowledge of the structure of this coordinated activity, information contained in cross-covariances between units. Although dynamical mean field theory (DMFT) has elucidated several features of random neural networks -- in particular, that they can generate chaotic activity -- existing DMFT approaches do not support the calculation of cross-covariances. We solve this longstanding problem by extending the DMFT approach via a two-site cavity method. This reveals, for the first time, several spatial and temporal features of activity coordination, including the effective dimension, defined as the participation ratio of the spectrum of the covariance matrix. Our results provide a general analytical framework for studying the structure of collective activity in random neural networks and, more broadly, in high-dimensional nonlinear dynamical systems with quenched disorder. ",
    "url": "https://arxiv.org/abs/2207.12373",
    "authors": [
      "David G. Clark",
      "L.F. Abbott",
      "Ashok Litwin-Kumar"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:1804.10726",
    "title": "QDR-Tree: An Efficient Index Scheme for Complex Spatial Keyword Query",
    "abstract": " Title: QDR-Tree: An Efficient Index Scheme for Complex Spatial Keyword Query ",
    "url": "https://arxiv.org/abs/1804.10726",
    "authors": [
      "Xinshi Zang",
      "Peiwen Hao",
      "Xiaofeng Gao",
      "Bin Yao",
      "Guihai Chen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:1809.10283",
    "title": "Adding Neural Network Controllers to Behavior Trees without Destroying  Performance Guarantees",
    "abstract": " Comments: Accepted as Regular Paper to The 61th IEEE Conference on Decision and Control (CDC 2022) ",
    "url": "https://arxiv.org/abs/1809.10283",
    "authors": [
      "Christopher Iliffe Sprague",
      "Petter \u00d6gren"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:1812.11775",
    "title": "Learning and Selfconfirming Equilibria in Network Games",
    "abstract": " Title: Learning and Selfconfirming Equilibria in Network Games ",
    "url": "https://arxiv.org/abs/1812.11775",
    "authors": [
      "Pierpaolo Battigalli",
      "Fabrizio Panebianco",
      "Paolo Pin"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:1903.09793",
    "title": "Connections between spectral properties of asymptotic mappings and  solutions to wireless network problems",
    "abstract": " Title: Connections between spectral properties of asymptotic mappings and  solutions to wireless network problems ",
    "url": "https://arxiv.org/abs/1903.09793",
    "authors": [
      "Renato Lu\u00eds Garrido Cavalcante",
      "Qi Liao",
      "Slawomir Sta\u0144czak"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:1904.09615",
    "title": "Explaining a prediction in some nonlinear models",
    "abstract": " Comments: This paper has been withdrawn by the author as it misses a relevant part of the literature ",
    "url": "https://arxiv.org/abs/1904.09615",
    "authors": [
      "Cosimo Izzo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2002.01642",
    "title": "Learning Test-time Augmentation for Content-based Image Retrieval",
    "abstract": " Title: Learning Test-time Augmentation for Content-based Image Retrieval ",
    "url": "https://arxiv.org/abs/2002.01642",
    "authors": [
      "Osman Tursun",
      "Simon Denman",
      "Sridha Sridharan",
      "Clinton Fookes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2005.01004",
    "title": "Explaining How Deep Neural Networks Forget by Deep Visualization",
    "abstract": " Comments: 12 pages, 4 figures, 1 table. arXiv admin note: substantial text overlap with arXiv:2001.01578. Keywords: XAI, Catastrophic Forgetting, Attribution map, Continual Learning and Regularization ",
    "url": "https://arxiv.org/abs/2005.01004",
    "authors": [
      "Giang Nguyen",
      "Shuan Chen",
      "Tae Joon Jun",
      "Daeyoung Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2008.12138",
    "title": "How to \"Improve\" Prediction Using Behavior Modification",
    "abstract": " Title: How to \"Improve\" Prediction Using Behavior Modification ",
    "url": "https://arxiv.org/abs/2008.12138",
    "authors": [
      "Galit Shmueli",
      "Ali Tafti"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2012.08181",
    "title": "Fast-Convergent Dynamics for Distributed Allocation of Resources Over  Switching Sparse Networks with Quantized Communication Links",
    "abstract": " Comments: ECC2022 ",
    "url": "https://arxiv.org/abs/2012.08181",
    "authors": [
      "Mohammadreza Doostmohammadian",
      "Alireza Aghasi",
      "Mohammad Pirani",
      "Ehsan Nekouei",
      "Usman A. Khan",
      "Themistoklis Charalambous"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2102.13640",
    "title": "NOMU: Neural Optimization-based Model Uncertainty",
    "abstract": " Comments: 9 pages + appendix ",
    "url": "https://arxiv.org/abs/2102.13640",
    "authors": [
      "Jakob Heiss",
      "Jakob Weissteiner",
      "Hanna Wutte",
      "Sven Seuken",
      "Josef Teichmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2103.00486",
    "title": "Community Detection in Weighted Multilayer Networks with Ambient Noise",
    "abstract": " Comments: 20 pages ",
    "url": "https://arxiv.org/abs/2103.00486",
    "authors": [
      "Mark He",
      "Dylan Lu",
      "Jason Xu",
      "Rose Mary Xavier"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2104.00735",
    "title": "Graph Attention Networks for Channel Estimation in RIS-assisted  Satellite IoT Communications",
    "abstract": " Comments: 11 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2104.00735",
    "authors": [
      "K\u00fcr\u015fat Tekb\u0131y\u0131k",
      "G\u00fcne\u015f Karabulut Kurt",
      "Ali R\u0131za Ekti",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2104.09035",
    "title": "Lidar Point Cloud Guided Monocular 3D Object Detection",
    "abstract": " Comments: ECCV 2022 ",
    "url": "https://arxiv.org/abs/2104.09035",
    "authors": [
      "Liang Peng",
      "Fei Liu",
      "Zhengxu Yu",
      "Senbo Yan",
      "Dan Deng",
      "Zheng Yang",
      "Haifeng Liu",
      "Deng Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.06543",
    "title": "Policy Optimization in Dynamic Bayesian Network Hybrid Models of  Biomanufacturing Processes",
    "abstract": " Comments: 36 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2105.06543",
    "authors": [
      "Hua Zheng",
      "Wei Xie",
      "Ilya O. Ryzhov",
      "Dongming Xie"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.13929",
    "title": "Quantifying and Localizing Usable Information Leakage from Neural  Network Gradients",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2105.13929",
    "authors": [
      "Fan Mo",
      "Anastasia Borovykh",
      "Mohammad Malekzadeh",
      "Soteris Demetriou",
      "Deniz G\u00fcnd\u00fcz",
      "Hamed Haddadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.07352",
    "title": "MOLEMAN: Mention-Only Linking of Entities with a Mention Annotation  Network",
    "abstract": " Comments: Accepted to ACL 2021, edit to add missing Turkish results in Tables 2 and 7 ",
    "url": "https://arxiv.org/abs/2106.07352",
    "authors": [
      "Nicholas FitzGerald",
      "Jan A. Botha",
      "Daniel Gillick",
      "Daniel M. Bikel",
      "Tom Kwiatkowski",
      "Andrew McCallum"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2106.07767",
    "title": "How does Heterophily Impact the Robustness of Graph Neural Networks?  Theoretical Connections and Practical Implications",
    "abstract": " Comments: KDD 2022 camera ready version + full appendix; 20 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2106.07767",
    "authors": [
      "Jiong Zhu",
      "Junchen Jin",
      "Donald Loveland",
      "Michael T. Schaub",
      "Danai Koutra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.09645",
    "title": "Prototypical Graph Contrastive Learning",
    "abstract": " Comments: To appear in TNNLS 2022 ",
    "url": "https://arxiv.org/abs/2106.09645",
    "authors": [
      "Shuai Lin",
      "Pan Zhou",
      "Zi-Yuan Hu",
      "Shuojia Wang",
      "Ruihui Zhao",
      "Yefeng Zheng",
      "Liang Lin",
      "Eric Xing",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.11239",
    "title": "2D vs. 3D LiDAR-based Person Detection on Mobile Robots",
    "abstract": " Comments: Shortened version accepted at the International Conference on Intelligent Robots and Systems (IROS) 2022 ",
    "url": "https://arxiv.org/abs/2106.11239",
    "authors": [
      "Dan Jia",
      "Alexander Hermans",
      "Bastian Leibe"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.13123",
    "title": "Break it, Fix it: Attack and Defense for \"Add-on'' Access Control  Solutions in Distributed Data Analytics Platforms",
    "abstract": " Title: Break it, Fix it: Attack and Defense for \"Add-on'' Access Control  Solutions in Distributed Data Analytics Platforms ",
    "url": "https://arxiv.org/abs/2106.13123",
    "authors": [
      "Fahad Shaon",
      "Sazzadur Rahaman",
      "Murat Kantarcioglu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2107.07065",
    "title": "Why Crypto-detectors Fail: A Systematic Evaluation of Cryptographic  Misuse Detection Techniques",
    "abstract": " Comments: 18 pages, 2 figures, 2 tables; paper published at 2022 IEEE Symposium on Security and Privacy (S&P) ",
    "url": "https://arxiv.org/abs/2107.07065",
    "authors": [
      "Amit Seal Ami",
      "Nathan Cooper",
      "Kaushal Kafle",
      "Kevin Moran",
      "Denys Poshyvanyk",
      "Adwait Nadkarni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2107.13715",
    "title": "Hierarchical Self-supervised Augmented Knowledge Distillation",
    "abstract": " Comments: 13 pages, IJCAI-2021 ",
    "url": "https://arxiv.org/abs/2107.13715",
    "authors": [
      "Chuanguang Yang",
      "Zhulin An",
      "Linhang Cai",
      "Yongjun Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.13824",
    "title": "VMNet: Voxel-Mesh Network for Geodesic-Aware 3D Semantic Segmentation",
    "abstract": " Comments: V1: ICCV2021(Oral), supplementary materials included V2: TPAMI(ICCV2021 SI), supplementary materials included ",
    "url": "https://arxiv.org/abs/2107.13824",
    "authors": [
      "Zeyu Hu",
      "Xuyang Bai",
      "Jiaxiang Shang",
      "Runze Zhang",
      "Jiayu Dong",
      "Xin Wang",
      "Guangyuan Sun",
      "Hongbo Fu",
      "Chiew-Lan Tai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.01806",
    "title": "Neural Scene Decoration from a Single Photograph",
    "abstract": " Comments: ECCV 2022 paper. 14 pages of main content, 4 pages of references, and 11 pages of appendix ",
    "url": "https://arxiv.org/abs/2108.01806",
    "authors": [
      "Hong-Wing Pang",
      "Yingshu Chen",
      "Phuoc-Hieu Le",
      "Binh-Son Hua",
      "Duc Thanh Nguyen",
      "Sai-Kit Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2108.12144",
    "title": "Lyra: A Benchmark for Turducken-Style Code Generation",
    "abstract": " Title: Lyra: A Benchmark for Turducken-Style Code Generation ",
    "url": "https://arxiv.org/abs/2108.12144",
    "authors": [
      "Qingyuan Liang",
      "Zeyu Sun",
      "Qihao Zhu",
      "Wenjie Zhang",
      "Lian Yu",
      "Yingfei Xiong",
      "Lu Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2108.13811",
    "title": "TREND: Trigger-Enhanced Relation-Extraction Network for Dialogues",
    "abstract": " Comments: Accepted to SIGDIAL 2022; The first two authors contributed to this work equally ",
    "url": "https://arxiv.org/abs/2108.13811",
    "authors": [
      "Po-Wei Lin",
      "Shang-Yu Su",
      "Yun-Nung Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2109.01621",
    "title": "Stochastic Physics-Informed Neural Ordinary Differential Equations",
    "abstract": " Title: Stochastic Physics-Informed Neural Ordinary Differential Equations ",
    "url": "https://arxiv.org/abs/2109.01621",
    "authors": [
      "Jared O'Leary",
      "Joel A. Paulson",
      "Ali Mesbah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2109.14210",
    "title": "Spatially Coupled PLDPC-Hadamard Convolutional Codes",
    "abstract": " Comments: 36 pages, 8 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2109.14210",
    "authors": [
      "Peng W. Zhang",
      "Francis C.M. Lau",
      "Chiu-W. Sham"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2109.15222",
    "title": "Natural Synthetic Anomalies for Self-Supervised Anomaly Detection and  Localization",
    "abstract": " Comments: Accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2109.15222",
    "authors": [
      "Hannah M. Schl\u00fcter",
      "Jeremy Tan",
      "Benjamin Hou",
      "Bernhard Kainz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.05240",
    "title": "Evaluating generative networks using Gaussian mixtures of image features",
    "abstract": " Title: Evaluating generative networks using Gaussian mixtures of image features ",
    "url": "https://arxiv.org/abs/2110.05240",
    "authors": [
      "Lorenzo Luzi",
      "Carlos Ortiz Marrero",
      "Nile Wynar",
      "Richard G. Baraniuk",
      "Michael J. Henry"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.07550",
    "title": "The Irrationality of Neural Rationale Models",
    "abstract": " Comments: NAACL Workshop on Trustworthy Natural Language Processing (TrustNLP) 2022 ",
    "url": "https://arxiv.org/abs/2110.07550",
    "authors": [
      "Yiming Zheng",
      "Serena Booth",
      "Julie Shah",
      "Yilun Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2110.07718",
    "title": "Adversarial Attack across Datasets",
    "abstract": " Title: Adversarial Attack across Datasets ",
    "url": "https://arxiv.org/abs/2110.07718",
    "authors": [
      "Yunxiao Qin",
      "Yuanhao Xiong",
      "Jinfeng Yi",
      "Lihong Cao",
      "Cho-Jui Hsieh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.13613",
    "title": "Subsampling Spectral Clustering for Large-Scale Social Networks",
    "abstract": " Title: Subsampling Spectral Clustering for Large-Scale Social Networks ",
    "url": "https://arxiv.org/abs/2110.13613",
    "authors": [
      "Jiayi Deng",
      "Yi Ding",
      "Yingqiu Zhu",
      "Danyang Huang",
      "Bingyi Jing",
      "Bo Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2111.01495",
    "title": "Constructing Neural Network-Based Models for Simulating Dynamical  Systems",
    "abstract": " Title: Constructing Neural Network-Based Models for Simulating Dynamical  Systems ",
    "url": "https://arxiv.org/abs/2111.01495",
    "authors": [
      "Christian M\u00f8ldrup Legaard",
      "Thomas Schranz",
      "Gerald Schweiger",
      "J\u00e1n Drgo\u0148a",
      "Basak Falay",
      "Cl\u00e1udio Gomes",
      "Alexandros Iosifidis",
      "Mahdi Abkar",
      "Peter Gorm Larsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.14341",
    "title": "OOD-CV: A Benchmark for Robustness to Out-of-Distribution Shifts of  Individual Nuisances in Natural Images",
    "abstract": " Comments: Project webpage: this https URL, this work is accepted as Oral at ECCV 2022 ",
    "url": "https://arxiv.org/abs/2111.14341",
    "authors": [
      "Bingchen Zhao",
      "Shaozuo Yu",
      "Wufei Ma",
      "Mingxin Yu",
      "Shenxiao Mei",
      "Angtian Wang",
      "Ju He",
      "Alan Yuille",
      "Adam Kortylewski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.00891",
    "title": "Event Neural Networks",
    "abstract": " Comments: Accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2112.00891",
    "authors": [
      "Matthew Dutson",
      "Yin Li",
      "Mohit Gupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.01740",
    "title": "AirDet: Few-Shot Detection without Fine-tuning for Autonomous  Exploration",
    "abstract": " Comments: 23 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2112.01740",
    "authors": [
      "Bowen Li",
      "Chen Wang",
      "Pranay Reddy",
      "Seungchan Kim",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.01988",
    "title": "ROCA: Robust CAD Model Retrieval and Alignment from a Single Image",
    "abstract": " Title: ROCA: Robust CAD Model Retrieval and Alignment from a Single Image ",
    "url": "https://arxiv.org/abs/2112.01988",
    "authors": [
      "Can G\u00fcmeli",
      "Angela Dai",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.05504",
    "title": "BungeeNeRF: Progressive Neural Radiance Field for Extreme Multi-scale  Scene Rendering",
    "abstract": " Comments: Accepted to ECCV22; Previous version: CityNeRF: Building NeRF at City Scale; Project page can be found in this https URL ",
    "url": "https://arxiv.org/abs/2112.05504",
    "authors": [
      "Yuanbo Xiangli",
      "Linning Xu",
      "Xingang Pan",
      "Nanxuan Zhao",
      "Anyi Rao",
      "Christian Theobalt",
      "Bo Dai",
      "Dahua Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.00065",
    "title": "Stealth Data Injection Attacks with Sparsity Constraints",
    "abstract": " Comments: 10 pages, 6 figures, submited to IEEE Trans. Smart Grid ",
    "url": "https://arxiv.org/abs/2201.00065",
    "authors": [
      "Xiuzhen Ye",
      "I\u00f1aki Esnaola",
      "Samir M. Perlaza",
      "Robert F. Harrison"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2201.07199",
    "title": "Invariant Representation Driven Neural Classifier for Anti-QCD Jet  Tagging",
    "abstract": " Comments: 30 pages, 14 figures ",
    "url": "https://arxiv.org/abs/2201.07199",
    "authors": [
      "Taoli Cheng",
      "Aaron Courville"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2201.10291",
    "title": "Rank-adaptive time integration of tree tensor networks",
    "abstract": " Title: Rank-adaptive time integration of tree tensor networks ",
    "url": "https://arxiv.org/abs/2201.10291",
    "authors": [
      "Gianluca Ceruti",
      "Christian Lubich",
      "Dominik Sulz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2201.13290",
    "title": "Model-Based Engineering of CPPS Functions and Code Generation for Skills",
    "abstract": " Title: Model-Based Engineering of CPPS Functions and Code Generation for Skills ",
    "url": "https://arxiv.org/abs/2201.13290",
    "authors": [
      "Aljosha K\u00f6cher",
      "Alexander Hayward",
      "Alexander Fay"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.00660",
    "title": "Interactron: Embodied Adaptive Object Detection",
    "abstract": " Comments: CVPR 2022 ",
    "url": "https://arxiv.org/abs/2202.00660",
    "authors": [
      "Klemen Kotar",
      "Roozbeh Mottaghi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.01059",
    "title": "PINNs and GaLS: A Priori Error Estimates for Shallow Physics Informed  Neural Networks Applied to Elliptic Problems",
    "abstract": " Comments: This work has been accepted at MathMOD and will appear on IFAC Conference Papers ",
    "url": "https://arxiv.org/abs/2202.01059",
    "authors": [
      "Umberto Zerbinati"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2202.09275",
    "title": "Rethinking Pareto Frontier for Performance Evaluation of Deep Neural  Networks",
    "abstract": " Title: Rethinking Pareto Frontier for Performance Evaluation of Deep Neural  Networks ",
    "url": "https://arxiv.org/abs/2202.09275",
    "authors": [
      "Vahid Partovi Nia",
      "Alireza Ghaffari",
      "Mahdi Zolnouri",
      "Yvon Savaria"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2202.09791",
    "title": "Contextual Semantic Embeddings for Ontology Subsumption Prediction",
    "abstract": " Title: Contextual Semantic Embeddings for Ontology Subsumption Prediction ",
    "url": "https://arxiv.org/abs/2202.09791",
    "authors": [
      "Jiaoyan Chen",
      "Yuan He",
      "Yuxia Geng",
      "Ernesto Jimenez-Ruiz",
      "Hang Dong",
      "Ian Horrocks"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.08207",
    "title": "SocialVAE: Human Trajectory Prediction using Timewise Latents",
    "abstract": " Comments: In the 17th European Conference on Computer Vision (ECCV 2022). Code: this https URL ",
    "url": "https://arxiv.org/abs/2203.08207",
    "authors": [
      "Pei Xu",
      "Jean-Bernard Hayet",
      "Ioannis Karamouzas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.08253",
    "title": "Integrated System Models for Networks with Generators & Inverters",
    "abstract": " Comments: In proceedings of the 11th Bulk Power Systems Dynamics and Control Symposium (IREP 2022), July 25-30, 2022, Banff, Canada ",
    "url": "https://arxiv.org/abs/2203.08253",
    "authors": [
      "D. Venkatramanan",
      "Manish K. Singh",
      "Olaolu Ajala",
      "Alejandro Dominguez-Garcia",
      "Sairaj Dhople"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2203.08381",
    "title": "Optimization of ARQ Distribution for HARQ Strategies in Delay-Bounded  Networks",
    "abstract": " Comments: Introduction rewritten to include the connection between the deadline constraint and the total ARQ budget. Accepted for presentation at WiOpt 2022 ",
    "url": "https://arxiv.org/abs/2203.08381",
    "authors": [
      "Jaya Goel",
      "J. Harshan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.09034",
    "title": "GATE: Graph CCA for Temporal SElf-supervised Learning for  Label-efficient fMRI Analysis",
    "abstract": " Title: GATE: Graph CCA for Temporal SElf-supervised Learning for  Label-efficient fMRI Analysis ",
    "url": "https://arxiv.org/abs/2203.09034",
    "authors": [
      "Liang Peng",
      "Nan Wang",
      "Jie Xu",
      "Xiaofeng Zhu",
      "Xiaoxiao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.10093",
    "title": "Deep reinforcement learning guided graph neural networks for brain  network analysis",
    "abstract": " Title: Deep reinforcement learning guided graph neural networks for brain  network analysis ",
    "url": "https://arxiv.org/abs/2203.10093",
    "authors": [
      "Xusheng Zhao",
      "Jia Wu",
      "Hao Peng",
      "Amin Beheshti",
      "Jessica J.M. Monaghan",
      "David McAlpine",
      "Heivet Hernandez-Perez",
      "Mark Dras",
      "Qiong Dai",
      "Yangyang Li",
      "Philip S. Yu",
      "Lifang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2203.10647",
    "title": "A Framework for Automating Deployment and Evaluation of Blockchain  Network",
    "abstract": " Comments: Published in the Journal of Network and Computer Applications ",
    "url": "https://arxiv.org/abs/2203.10647",
    "authors": [
      "Nguyen Khoi Tran",
      "M. Ali Babar",
      "Andrew Walters"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2203.12647",
    "title": "Robust Onboard Localization in Changing Environments Exploiting Text  Spotting",
    "abstract": " Comments: This work has been accepted to IROS 2022. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2203.12647",
    "authors": [
      "Nicky Zimmerman",
      "Louis Wiesmann",
      "Tiziano Guadagnino",
      "Thomas L\u00e4be",
      "Jens Behley",
      "Cyrill Stachniss"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.14250",
    "title": "End-to-End Active Speaker Detection",
    "abstract": " Title: End-to-End Active Speaker Detection ",
    "url": "https://arxiv.org/abs/2203.14250",
    "authors": [
      "Juan Leon Alcazar",
      "Moritz Cordes",
      "Chen Zhao",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.16104",
    "title": "Improving Distortion Robustness of Self-supervised Speech Processing  Tasks with Domain Adaptation",
    "abstract": " Comments: Accepted at Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2203.16104",
    "authors": [
      "Kuan Po Huang",
      "Yu-Kuan Fu",
      "Yu Zhang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.16265",
    "title": "SeqTR: A Simple yet Universal Network for Visual Grounding",
    "abstract": " Comments: 21 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2203.16265",
    "authors": [
      "Chaoyang Zhu",
      "Yiyi Zhou",
      "Yunhang Shen",
      "Gen Luo",
      "Xingjia Pan",
      "Mingbao Lin",
      "Chao Chen",
      "Liujuan Cao",
      "Xiaoshuai Sun",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.16939",
    "title": "Hypergraph Convolutional Networks via Equivalency between Hypergraphs  and Undirected Graphs",
    "abstract": " Comments: ICML2022 Workshop (this https URL) ",
    "url": "https://arxiv.org/abs/2203.16939",
    "authors": [
      "Jiying Zhang",
      "Fuyang Li",
      "Xi Xiao",
      "Tingyang Xu",
      "Yu Rong",
      "Junzhou Huang",
      "Yatao Bian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.17056",
    "title": "Weakly toll convexity and proper interval graphs",
    "abstract": " Comments: 19 pages ",
    "url": "https://arxiv.org/abs/2203.17056",
    "authors": [
      "Mitre C. Dourado",
      "Marisa Gutierrez",
      "F\u00e1bio Protti",
      "Silvia Tondato"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2203.17261",
    "title": "R2L: Distilling Neural Radiance Field to Neural Light Field for  Efficient Novel View Synthesis",
    "abstract": " Comments: Accepted by ECCV 2022. Code: this https URL ",
    "url": "https://arxiv.org/abs/2203.17261",
    "authors": [
      "Huan Wang",
      "Jian Ren",
      "Zeng Huang",
      "Kyle Olszewski",
      "Menglei Chai",
      "Yun Fu",
      "Sergey Tulyakov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.00833",
    "title": "PixelFolder: An Efficient Progressive Pixel Synthesis Network for Image  Generation",
    "abstract": " Comments: Accepted by ECCV2022. The code is available at this https URL ",
    "url": "https://arxiv.org/abs/2204.00833",
    "authors": [
      "Jing He",
      "Yiyi Zhou",
      "Qi Zhang",
      "Jun Peng",
      "Yunhang Shen",
      "Xiaoshuai Sun",
      "Chao Chen",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2204.05483",
    "title": "Redwood: Using Collision Detection to Grow a Large-Scale Intent  Classification Dataset",
    "abstract": " Comments: SIGDIAL 2022 ",
    "url": "https://arxiv.org/abs/2204.05483",
    "authors": [
      "Stefan Larson",
      "Kevin Leach"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.09136",
    "title": "The White-Box Adversarial Data Stream Model",
    "abstract": " Comments: PODS 2022 ",
    "url": "https://arxiv.org/abs/2204.09136",
    "authors": [
      "Miklos Ajtai",
      "Vladimir Braverman",
      "T.S. Jayram",
      "Sandeep Silwal",
      "Alec Sun",
      "David P. Woodruff",
      "Samson Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2204.12442",
    "title": "Multi-task Deep Neural Networks for Massive MIMO CSI Feedback",
    "abstract": " Comments: 5 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2204.12442",
    "authors": [
      "Boyuan Zhang",
      "Haozhen Li",
      "Xin Liang",
      "Xinyu Gu",
      "Lin Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.13734",
    "title": "Flexible and scalable privacy assessment for very large datasets, with  an application to official governmental microdata",
    "abstract": " Title: Flexible and scalable privacy assessment for very large datasets, with  an application to official governmental microdata ",
    "url": "https://arxiv.org/abs/2204.13734",
    "authors": [
      "M\u00e1rio S. Alvim",
      "Natasha Fernandes",
      "Annabelle McIver",
      "Carroll Morgan",
      "Gabriel H. Nunes"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2204.13883",
    "title": "Autonomous In-Situ Soundscape Augmentation via Joint Selection of Masker  and Gain",
    "abstract": " Comments: Accepted to IEEE Signal Processing Letters. (c) 2022 IEEE ",
    "url": "https://arxiv.org/abs/2204.13883",
    "authors": [
      "Karn N. Watcharasupat",
      "Kenneth Ooi",
      "Bhan Lam",
      "Trevor Wong",
      "Zhen-Ting Ong",
      "Woon-Seng Gan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2205.01398",
    "title": "Neural language models for network configuration: Opportunities and  reality check",
    "abstract": " Title: Neural language models for network configuration: Opportunities and  reality check ",
    "url": "https://arxiv.org/abs/2205.01398",
    "authors": [
      "Zied Ben Houidi",
      "Dario Rossi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.05177",
    "title": "ConfLab: A Rich Multimodal Multisensor Dataset of Free-Standing Social  Interactions in the Wild",
    "abstract": " Comments: v2 is the version submitted to Neurips 2022 Datasets and Benchmarks Track ",
    "url": "https://arxiv.org/abs/2205.05177",
    "authors": [
      "Chirag Raman",
      "Jose Vargas-Quiros",
      "Stephanie Tan",
      "Ekin Gedik",
      "Ashraful Islam",
      "Hayley Hung"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.08455",
    "title": "Utterance Weighted Multi-Dilation Temporal Convolutional Networks for  Monaural Speech Dereverberation",
    "abstract": " Comments: Accepted at IWAENC 2022 ",
    "url": "https://arxiv.org/abs/2205.08455",
    "authors": [
      "William Ravenscroft",
      "Stefan Goetze",
      "Thomas Hain"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.09850",
    "title": "Human Gender Prediction Based on Deep Transfer Learning from Panoramic  Radiograph Images",
    "abstract": " Comments: 36 pages, 13 figures, 10 tables ",
    "url": "https://arxiv.org/abs/2205.09850",
    "authors": [
      "I. Atas"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10217",
    "title": "Memorization and Optimization in Deep Neural Networks with Minimum  Over-parameterization",
    "abstract": " Comments: Fixed a bug in the proofs of Appendix D Removed third assumption on the activation function ",
    "url": "https://arxiv.org/abs/2205.10217",
    "authors": [
      "Simone Bombari",
      "Mohammad Hossein Amani",
      "Marco Mondelli"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10272",
    "title": "Salient Skin Lesion Segmentation via Dilated Scale-Wise Feature Fusion  Network",
    "abstract": " Title: Salient Skin Lesion Segmentation via Dilated Scale-Wise Feature Fusion  Network ",
    "url": "https://arxiv.org/abs/2205.10272",
    "authors": [
      "Pourya Shamsolmoali",
      "Masoumeh Zareapoor",
      "Eric Granger",
      "Huiyu Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11925",
    "title": "Robust 3D Object Detection in Cold Weather Conditions",
    "abstract": " Comments: Oral ",
    "url": "https://arxiv.org/abs/2205.11925",
    "authors": [
      "Aldi Piroli",
      "Vinzenz Dallabetta",
      "Marc Walessa",
      "Daniel Meissner",
      "Johannes Kopp",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12902",
    "title": "RADNet: Ensemble Model for Robust Glaucoma Classification in Color  Fundus Images",
    "abstract": " Comments: Keywords: Glaucoma Classification, Color Fundus Images. Computer Aided Diagnosis ",
    "url": "https://arxiv.org/abs/2205.12902",
    "authors": [
      "Ahmed Al Mahrooqi",
      "Dmitrii Medvedev",
      "Rand Muhtaseb"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13522",
    "title": "Dynamically Relative Position Encoding-Based Transformer for Automatic  Code Edit",
    "abstract": " Title: Dynamically Relative Position Encoding-Based Transformer for Automatic  Code Edit ",
    "url": "https://arxiv.org/abs/2205.13522",
    "authors": [
      "Shiyi Qi",
      "Yaoxian Li",
      "Cuiyun Gao",
      "Xiaohong Su",
      "Shuzheng Gao",
      "Zibin Zheng",
      "Chuanyi Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.14249",
    "title": "Experience report of physics-informed neural networks in fluid  simulations: pitfalls and frustration",
    "abstract": " Comments: 8 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2205.14249",
    "authors": [
      "Pi-Yueh Chuang",
      "Lorena A. Barba"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.15307",
    "title": "A Unified Weight Initialization Paradigm for Tensorial Convolutional  Neural Networks",
    "abstract": " Comments: Accepted in ICML 2022 ",
    "url": "https://arxiv.org/abs/2205.15307",
    "authors": [
      "Yu Pan",
      "Zeyong Su",
      "Ao Liu",
      "Jingquan Wang",
      "Nannan Li",
      "Zenglin Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.15364",
    "title": "Associative Learning Mechanism for Drug-Target Interaction Prediction",
    "abstract": " Comments: Submitted to Chinese Association for Artificial Intelligence (CAAI) ",
    "url": "https://arxiv.org/abs/2205.15364",
    "authors": [
      "Zhiqin Zhu",
      "Zheng Yao",
      "Guanqiu Qi",
      "Neal Mazur",
      "Baisen Cong"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.01068",
    "title": "Min orderings and list homomorphism dichotomies for signed and unsigned  graphs",
    "abstract": " Title: Min orderings and list homomorphism dichotomies for signed and unsigned  graphs ",
    "url": "https://arxiv.org/abs/2206.01068",
    "authors": [
      "Jan Bok",
      "Richard Brewster",
      "Pavol Hell",
      "Nikola Jedli\u010dkov\u00e1",
      "Arash Rafiey"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2206.03491",
    "title": "EiX-GNN : Concept-level eigencentrality explainer for graph neural  networks",
    "abstract": " Title: EiX-GNN : Concept-level eigencentrality explainer for graph neural  networks ",
    "url": "https://arxiv.org/abs/2206.03491",
    "authors": [
      "Adrien Raison",
      "Pascal Bourdon",
      "David Helbert"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.04790",
    "title": "Learn2Augment: Learning to Composite Videos for Data Augmentation in  Action Recognition",
    "abstract": " Comments: Accepted to ECCV-2022 ",
    "url": "https://arxiv.org/abs/2206.04790",
    "authors": [
      "Shreyank N Gowda",
      "Marcus Rohrbach",
      "Frank Keller",
      "Laura Sevilla-Lara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.05238",
    "title": "Dimensional Modeling of Emotions in Text with Appraisal Theories: Corpus  Creation, Annotation Reliability, and Prediction",
    "abstract": " Comments: revision 1, 71 pages, 13 figures, 19 tables ",
    "url": "https://arxiv.org/abs/2206.05238",
    "authors": [
      "Enrica Troiano",
      "Laura Oberl\u00e4nder",
      "Roman Klinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.07219",
    "title": "A Projection-Based K-space Transformer Network for Undersampled Radial  MRI Reconstruction with Limited Training Subjects",
    "abstract": " Comments: Accepted at MICCAI 2022 ",
    "url": "https://arxiv.org/abs/2206.07219",
    "authors": [
      "Chang Gao",
      "Shu-Fu Shih",
      "J. Paul Finn",
      "Xiaodong Zhong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.11357",
    "title": "GACT: Activation Compressed Training for Generic Network Architectures",
    "abstract": " Title: GACT: Activation Compressed Training for Generic Network Architectures ",
    "url": "https://arxiv.org/abs/2206.11357",
    "authors": [
      "Xiaoxuan Liu",
      "Lianmin Zheng",
      "Dequan Wang",
      "Yukuo Cen",
      "Weize Chen",
      "Xu Han",
      "Jianfei Chen",
      "Zhiyuan Liu",
      "Jie Tang",
      "Joey Gonzalez",
      "Michael Mahoney",
      "Alvin Cheung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.12038",
    "title": "BYOL-S: Learning Self-supervised Speech Representations by Bootstrapping",
    "abstract": " Comments: Submitted to HEAR-PMLR 2021 ",
    "url": "https://arxiv.org/abs/2206.12038",
    "authors": [
      "Gasser Elbanna",
      "Neil Scheidwasser-Clow",
      "Mikolaj Kegler",
      "Pierre Beckmann",
      "Karl El Hajal",
      "Milos Cernak"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.15031",
    "title": "Timestamp-Supervised Action Segmentation with Graph Convolutional  Networks",
    "abstract": " Comments: Accepted to IROS 2022 ",
    "url": "https://arxiv.org/abs/2206.15031",
    "authors": [
      "Hamza Khan",
      "Sanjay Haresh",
      "Awais Ahmed",
      "Shakeeb Siddiqui",
      "Andrey Konin",
      "M. Zeeshan Zia",
      "Quoc-Huy Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00813",
    "title": "Interpretable Graph Neural Networks for Connectome-Based Brain Disorder  Analysis",
    "abstract": " Comments: Previous version presented at icml-imlh 2021 (no proceedings, archived at 2107.05097), this version is accepted to miccai 2022 ",
    "url": "https://arxiv.org/abs/2207.00813",
    "authors": [
      "Hejie Cui",
      "Wei Dai",
      "Yanqiao Zhu",
      "Xiaoxiao Li",
      "Lifang He",
      "Carl Yang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.01129",
    "title": "A Gray Code of Ordered Trees",
    "abstract": " Comments: 14 pages ",
    "url": "https://arxiv.org/abs/2207.01129",
    "authors": [
      "Shin-ichi Nakano"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2207.01780",
    "title": "CodeRL: Mastering Code Generation through Pretrained Models and Deep  Reinforcement Learning",
    "abstract": " Title: CodeRL: Mastering Code Generation through Pretrained Models and Deep  Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2207.01780",
    "authors": [
      "Hung Le",
      "Yue Wang",
      "Akhilesh Deepak Gotmare",
      "Silvio Savarese",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2207.03264",
    "title": "A Solver + Gradient Descent Training Algorithm for Deep Neural Networks",
    "abstract": " Title: A Solver + Gradient Descent Training Algorithm for Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2207.03264",
    "authors": [
      "Dhananjay Ashok",
      "Vineel Nagisetty",
      "Christopher Srinivasa",
      "Vijay Ganesh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2207.06680",
    "title": "Equivariant Hypergraph Diffusion Neural Operators",
    "abstract": " Comments: Code: this https URL ",
    "url": "https://arxiv.org/abs/2207.06680",
    "authors": [
      "Peihao Wang",
      "Shenghao Yang",
      "Yunyu Liu",
      "Zhangyang Wang",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.06819",
    "title": "Anomal-E: A Self-Supervised Network Intrusion Detection System based on  Graph Neural Networks",
    "abstract": " Title: Anomal-E: A Self-Supervised Network Intrusion Detection System based on  Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2207.06819",
    "authors": [
      "Evan Caville",
      "Wai Weng Lo",
      "Siamak Layeghy",
      "Marius Portmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.07734",
    "title": "COEM: Cross-Modal Embedding for MetaCell Identification",
    "abstract": " Comments: 5 pages, 2 figures, ICML workshop on computational biology ",
    "url": "https://arxiv.org/abs/2207.07734",
    "authors": [
      "Haiyi Mao",
      "Minxue Jia",
      "Jason Xiaotian Dou",
      "Haotian Zhang",
      "Panayiotis V. Benos"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "General Literature (cs.GL)"
    ]
  },
  {
    "id": "arXiv:2207.08046",
    "title": "MDM:Visual Explanations for Neural Networks via Multiple Dynamic Mask",
    "abstract": " Title: MDM:Visual Explanations for Neural Networks via Multiple Dynamic Mask ",
    "url": "https://arxiv.org/abs/2207.08046",
    "authors": [
      "Yitao Peng",
      "Longzhen Yang",
      "Yihang Liu",
      "Lianghua He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08631",
    "title": "Latent Partition Implicit with Surface Codes for 3D Representation",
    "abstract": " Comments: 20pages,14figures. Accepted by ECCV 2022 ",
    "url": "https://arxiv.org/abs/2207.08631",
    "authors": [
      "Chao Chen",
      "Yu-Shen Liu",
      "Zhizhong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09524",
    "title": "Identification and characterization of misinformation superspreaders on  social media",
    "abstract": " Title: Identification and characterization of misinformation superspreaders on  social media ",
    "url": "https://arxiv.org/abs/2207.09524",
    "authors": [
      "Matthew R. DeVerna",
      "Rachith Aiyappa",
      "Diogo Pacheco",
      "John Bryden",
      "Filippo Menczer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2207.11018",
    "title": "Learning from what we know: How to perform vulnerability prediction  using noisy historical data",
    "abstract": " Comments: Please do not consider this new version of the article for citations. The article (with its previous versions) is already available here: arXiv:2012.11701 ",
    "url": "https://arxiv.org/abs/2207.11018",
    "authors": [
      "Aayush Garg",
      "Renzo Degiovanni",
      "Matthieu Jimenez",
      "Maxime Cordy",
      "Mike Papadakis",
      "Yves LeTraon"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2207.11095",
    "title": "Multi-temporal speckle reduction with self-supervised deep neural  networks",
    "abstract": " Title: Multi-temporal speckle reduction with self-supervised deep neural  networks ",
    "url": "https://arxiv.org/abs/2207.11095",
    "authors": [
      "In\u00e8s Meraoumia",
      "Emanuele Dalsasso",
      "Lo\u00efc Denis",
      "R\u00e9my Abergel",
      "Florence Tupin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]