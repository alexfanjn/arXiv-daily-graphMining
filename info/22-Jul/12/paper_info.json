[
  {
    "id": "arXiv:2207.04045",
    "title": "Runtime Analysis for Permutation-based Evolutionary Algorithms",
    "abstract": "While the theoretical analysis of evolutionary algorithms (EAs) has made significant progress for pseudo-Boolean optimization problems in the last 25 years, only sporadic theoretical results exist on how EAs solve permutation-based problems. To overcome the lack of permutation-based benchmark problems, we propose a general way to transfer the classic pseudo-Boolean benchmarks into benchmarks defined on sets of permutations. We then conduct a rigorous runtime analysis of the permutation-based $(1+1)$ EA proposed by Scharnow, Tinnefeld, and Wegener (2004) on the analogues of the \\textsc{LeadingOnes} and \\textsc{Jump} benchmarks. The latter shows that, different from bit-strings, it is not only the Hamming distance that determines how difficult it is to mutate a permutation $\\sigma$ into another one $\\tau$, but also the precise cycle structure of $\\sigma \\tau^{-1}$. For this reason, we also regard the more symmetric scramble mutation operator. We observe that it not only leads to simpler proofs, but also reduces the runtime on jump functions with odd jump size by a factor of $\\Theta(n)$. Finally, we show that a heavy-tailed version of the scramble operator, as in the bit-string case, leads to a speed-up of order $m^{\\Theta(m)}$ on jump functions with jump size~$m$.% ",
    "url": "https://arxiv.org/abs/2207.04045",
    "authors": [
      "Benjamin Doerr",
      "Yassine Ghannane",
      "Marouane Ibn Brahim"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.04049",
    "title": "Learning Causal Effects on Hypergraphs",
    "abstract": "Hypergraphs provide an effective abstraction for modeling multi-way group interactions among nodes, where each hyperedge can connect any number of nodes. Different from most existing studies which leverage statistical dependencies, we study hypergraphs from the perspective of causality. Specifically, in this paper, we focus on the problem of individual treatment effect (ITE) estimation on hypergraphs, aiming to estimate how much an intervention (e.g., wearing face covering) would causally affect an outcome (e.g., COVID-19 infection) of each individual node. Existing works on ITE estimation either assume that the outcome on one individual should not be influenced by the treatment assignments on other individuals (i.e., no interference), or assume the interference only exists between pairs of connected individuals in an ordinary graph. We argue that these assumptions can be unrealistic on real-world hypergraphs, where higher-order interference can affect the ultimate ITE estimations due to the presence of group interactions. In this work, we investigate high-order interference modeling, and propose a new causality learning framework powered by hypergraph neural networks. Extensive experiments on real-world hypergraphs verify the superiority of our framework over existing baselines. ",
    "url": "https://arxiv.org/abs/2207.04049",
    "authors": [
      "Jing Ma",
      "Mengting Wan",
      "Longqi Yang",
      "Jundong Li",
      "Brent Hecht",
      "Jaime Teevan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.04052",
    "title": "Robust optimal investment and risk control for an insurer with general  insider information",
    "abstract": "In this paper, we study the robust optimal investment and risk control problem for an insurer who owns the insider information about the financial market and the insurance market under model uncertainty. Both financial risky asset process and insurance risk process are assumed to be very general jump diffusion processes. The insider information is of the most general form rather than the initial enlargement type. We use the theory of forward integrals to give the first half characterization of the robust optimal strategy and transform the anticipating stochastic differential game problem into the nonanticipative stochastic differential game problem. Then we adopt the stochastic maximum principle to obtain the total characterization of the robust strategy. We discuss the two typical situations when the insurer is `small' and `large' by Malliavin calculus. For the `small' insurer, we obtain the closed-form solution in the continuous case and the half closed-form solution in the case with jumps. For the `large' insurer, we reduce the problem to the quadratic backward stochastic differential equation (BSDE) and obtain the closed-form solution in the continuous case without model uncertainty. We discuss some impacts of the model uncertainty, insider information and the `large' insurer on the optimal strategy. ",
    "url": "https://arxiv.org/abs/2207.04052",
    "authors": [
      "Chao Yu",
      "Yuhan Cheng",
      "Yilun Song"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.04053",
    "title": "On the Need and Applicability of Causality for Fair Machine Learning",
    "abstract": "Causal reasoning has an indispensable role in how humans make sense of the world and come to decisions in everyday life. While $20th$ century science was reserved from making causal claims as too strong and not achievable, the $21st$ century is marked by the return of causality encouraged by the mathematization of causal notions and the introduction of the non-deterministic concept of cause~\\cite{illari2011look}. Besides its common use cases in epidemiology, political, and social sciences, causality turns out to be crucial in evaluating the fairness of automated decisions, both in a legal and everyday sense. We provide arguments and examples of why causality is particularly important for fairness evaluation. In particular, we point out the social impact of non-causal predictions and the legal anti-discrimination process that relies on causal claims. We conclude with a discussion about the challenges and limitations of applying causality in practical scenarios as well as possible solutions. ",
    "url": "https://arxiv.org/abs/2207.04053",
    "authors": [
      "R\u016bta Binkyt\u0117",
      "Sami Zhioua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.04055",
    "title": "Causal Discovery using Model Invariance through Knockoff Interventions",
    "abstract": "Cause-effect analysis is crucial to understand the underlying mechanism of a system. We propose to exploit model invariance through interventions on the predictors to infer causality in nonlinear multivariate systems of time series. We model nonlinear interactions in time series using DeepAR and then expose the model to different environments using Knockoffs-based interventions to test model invariance. Knockoff samples are pairwise exchangeable, in-distribution and statistically null variables generated without knowing the response. We test model invariance where we show that the distribution of the response residual does not change significantly upon interventions on non-causal predictors. We evaluate our method on real and synthetically generated time series. Overall our method outperforms other widely used causality methods, i.e, VAR Granger causality, VARLiNGAM and PCMCI+. ",
    "url": "https://arxiv.org/abs/2207.04055",
    "authors": [
      "Wasim Ahmad",
      "Maha Shadaydeh",
      "Joachim Denzler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.04056",
    "title": "Large Scale Mask Optimization Via Convolutional Fourier Neural Operator  and Litho-Guided Self Training",
    "abstract": "Machine learning techniques have been extensively studied for mask optimization problems, aiming at better mask printability, shorter turnaround time, better mask manufacturability, and so on. However, most of these researches are focusing on the initial solution generation of small design regions. To further realize the potential of machine learning techniques on mask optimization tasks, we present a Convolutional Fourier Neural Operator (CFNO) that can efficiently learn layout tile dependencies and hence promise stitch-less large-scale mask optimization with the limited intervention of legacy tools. We discover the possibility of litho-guided self-training (LGST) through a trained machine learning model when solving non-convex optimization problems, which allows iterative model and dataset update and brings significant model performance improvement. Experimental results show that, for the first time, our machine learning-based framework outperforms state-of-the-art academic numerical mask optimizers with an order of magnitude speedup. ",
    "url": "https://arxiv.org/abs/2207.04056",
    "authors": [
      "Haoyu Yang",
      "Zongyi Li",
      "Kumara Sastry",
      "Saumyadip Mukhopadhyay",
      "Anima Anandkumar",
      "Brucek Khailany",
      "Vivek Singh",
      "Haoxing Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.04075",
    "title": "Models Out of Line: A Fourier Lens on Distribution Shift Robustness",
    "abstract": "Improving the accuracy of deep neural networks (DNNs) on out-of-distribution (OOD) data is critical to an acceptance of deep learning (DL) in real world applications. It has been observed that accuracies on in-distribution (ID) versus OOD data follow a linear trend and models that outperform this baseline are exceptionally rare (and referred to as \"effectively robust\"). Recently, some promising approaches have been developed to improve OOD robustness: model pruning, data augmentation, and ensembling or zero-shot evaluating large pretrained models. However, there still is no clear understanding of the conditions on OOD data and model properties that are required to observe effective robustness. We approach this issue by conducting a comprehensive empirical study of diverse approaches that are known to impact OOD robustness on a broad range of natural and synthetic distribution shifts of CIFAR-10 and ImageNet. In particular, we view the \"effective robustness puzzle\" through a Fourier lens and ask how spectral properties of both models and OOD data influence the corresponding effective robustness. We find this Fourier lens offers some insight into why certain robust models, particularly those from the CLIP family, achieve OOD robustness. However, our analysis also makes clear that no known metric is consistently the best explanation (or even a strong explanation) of OOD robustness. Thus, to aid future research into the OOD puzzle, we address the gap in publicly-available models with effective robustness by introducing a set of pretrained models--RobustNets--with varying levels of OOD robustness. ",
    "url": "https://arxiv.org/abs/2207.04075",
    "authors": [
      "Sara Fridovich-Keil",
      "Brian R. Bartoldson",
      "James Diffenderfer",
      "Bhavya Kailkhura",
      "Peer-Timo Bremer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04084",
    "title": "Adaptive Self-supervision Algorithms for Physics-informed Neural  Networks",
    "abstract": "Physics-informed neural networks (PINNs) incorporate physical knowledge from the problem domain as a soft constraint on the loss function, but recent work has shown that this can lead to optimization difficulties. Here, we study the impact of the location of the collocation points on the trainability of these models. We find that the vanilla PINN performance can be significantly boosted by adapting the location of the collocation points as training proceeds. Specifically, we propose a novel adaptive collocation scheme which progressively allocates more collocation points (without increasing their number) to areas where the model is making higher errors (based on the gradient of the loss function in the domain). This, coupled with a judicious restarting of the training during any optimization stalls (by simply resampling the collocation points in order to adjust the loss landscape) leads to better estimates for the prediction error. We present results for several problems, including a 2D Poisson and diffusion-advection system with different forcing functions. We find that training vanilla PINNs for these problems can result in up to 70% prediction error in the solution, especially in the regime of low collocation points. In contrast, our adaptive schemes can achieve up to an order of magnitude smaller error, with similar computational complexity as the baseline. Furthermore, we find that the adaptive methods consistently perform on-par or slightly better than vanilla PINN method, even for large collocation point regimes. The code for all the experiments has been open sourced. ",
    "url": "https://arxiv.org/abs/2207.04084",
    "authors": [
      "Shashank Subramanian",
      "Robert M. Kirby",
      "Michael W. Mahoney",
      "Amir Gholami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2207.04103",
    "title": "StatMix: Data augmentation method that relies on image statistics in  federated learning",
    "abstract": "Availability of large amount of annotated data is one of the pillars of deep learning success. Although numerous big datasets have been made available for research, this is often not the case in real life applications (e.g. companies are not able to share data due to GDPR or concerns related to intellectual property rights protection). Federated learning (FL) is a potential solution to this problem, as it enables training a global model on data scattered across multiple nodes, without sharing local data itself. However, even FL methods pose a threat to data privacy, if not handled properly. Therefore, we propose StatMix, an augmentation approach that uses image statistics, to improve results of FL scenario(s). StatMix is empirically tested on CIFAR-10 and CIFAR-100, using two neural network architectures. In all FL experiments, application of StatMix improves the average accuracy, compared to the baseline training (with no use of StatMix). Some improvement can also be observed in non-FL setups. ",
    "url": "https://arxiv.org/abs/2207.04103",
    "authors": [
      "Dominik Lewy",
      "Jacek Ma\u0144dziuk",
      "Maria Ganzha",
      "Marcin Paprzycki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04104",
    "title": "Evaluating Systemic Error Detection Methods using Synthetic Images",
    "abstract": "We introduce SpotCheck, a framework for generating synthetic datasets to use for evaluating methods for discovering blindspots (i.e., systemic errors) in image classifiers. We use SpotCheck to run controlled studies of how various factors influence the performance of blindspot discovery methods. Our experiments reveal several shortcomings of existing methods, such as relatively poor performance in settings with multiple blindspots and sensitivity to hyperparameters. Further, we find that a method based on dimensionality reduction, PlaneSpot, is competitive with existing methods, which has promising implications for the development of interactive tools. ",
    "url": "https://arxiv.org/abs/2207.04104",
    "authors": [
      "Gregory Plumb",
      "Nari Johnson",
      "\u00c1ngel Alexander Cabrera",
      "Marco Tulio Ribeiro",
      "Ameet Talwalkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04122",
    "title": "Sudowoodo: Contrastive Self-supervised Learning for Multi-purpose Data  Integration and Preparation",
    "abstract": "Machine learning (ML) is playing an increasingly important role in data management tasks, particularly in Data Integration and Preparation (DI&P). The success of ML-based approaches, however, heavily relies on the availability of large-scale, high-quality labeled datasets for different tasks. Moreover, the wide variety of DI&P tasks and pipelines oftentimes requires customizing ML solutions which can incur a significant cost for model engineering and experimentation. These factors inevitably hold back the adoption of ML-based approaches to new domains and tasks. In this paper, we propose Sudowoodo, a multi-purpose DI&P framework based on contrastive representation learning. Sudowoodo features a unified, matching-based problem definition capturing a wide range of DI&P tasks including Entity Matching (EM) in data integration, error correction in data cleaning, semantic type detection in data discovery, and more. Contrastive learning enables Sudowoodo to learn similarity-aware data representations from a large corpus of data items (e.g., entity entries, table columns) without using any labels. The learned representations can later be either directly used or facilitate fine-tuning with only a few labels to support different DI&P tasks. Our experiment results show that Sudowoodo achieves multiple state-of-the-art results on different levels of supervision and outperforms previous best specialized blocking or matching solutions for EM. Sudowoodo also achieves promising results in data cleaning and semantic type detection tasks showing its versatility in DI&P applications. ",
    "url": "https://arxiv.org/abs/2207.04122",
    "authors": [
      "Runhui Wang",
      "Yuliang Li",
      "Jin Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2207.04125",
    "title": "Out of Distribution Detection via Neural Network Anchoring",
    "abstract": "Our goal in this paper is to exploit heteroscedastic temperature scaling as a calibration strategy for out of distribution (OOD) detection. Heteroscedasticity here refers to the fact that the optimal temperature parameter for each sample can be different, as opposed to conventional approaches that use the same value for the entire distribution. To enable this, we propose a new training strategy called anchoring that can estimate appropriate temperature values for each sample, leading to state-of-the-art OOD detection performance across several benchmarks. Using NTK theory, we show that this temperature function estimate is closely linked to the epistemic uncertainty of the classifier, which explains its behavior. In contrast to some of the best-performing OOD detection approaches, our method does not require exposure to additional outlier datasets, custom calibration objectives, or model ensembling. Through empirical studies with different OOD detection settings -- far OOD, near OOD, and semantically coherent OOD - we establish a highly effective OOD detection approach. Code and models can be accessed here -- https://github.com/rushilanirudh/AMP ",
    "url": "https://arxiv.org/abs/2207.04125",
    "authors": [
      "Rushil Anirudh",
      "Jayaraman J. Thiagarajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04129",
    "title": "Not all broken defenses are equal: The dead angles of adversarial  accuracy",
    "abstract": "Robustness to adversarial attack is typically evaluated with adversarial accuracy. This metric is however too coarse to properly capture all robustness properties of machine learning models. Many defenses, when evaluated against a strong attack, do not provide accuracy improvements while still contributing partially to adversarial robustness. Popular certification methods suffer from the same issue, as they provide a lower bound to accuracy. To capture finer robustness properties we propose a new metric for L2 robustness, adversarial angular sparsity, which partially answers the question \"how many adversarial examples are there around an input\". We demonstrate its usefulness by evaluating both \"strong\" and \"weak\" defenses. We show that some state-of-the-art defenses, delivering very similar accuracy, can have very different sparsity on the inputs that they are not robust on. We also show that some weak defenses actually decrease robustness, while others strengthen it in a measure that accuracy cannot capture. These differences are predictive of how useful such defenses can become when combined with adversarial training. ",
    "url": "https://arxiv.org/abs/2207.04129",
    "authors": [
      "Raphael Olivier",
      "Bhiksha Raj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.04149",
    "title": "Cyber-Physical Attack Leveraging Subsynchronous Resonance",
    "abstract": "This paper discusses how a cyber attack could take advantage of torsional resonances in the shaft of turbo-generators to inflict severe physical damage to a power system. If attackers were able to take over the control of a battery energy storage device, they could modulate the injection of this device at a frequency that matches one of the sub-synchronous resonance frequencies of a generator. Small changes in injection might be sufficient to excite one of these mechanical resonances, resulting in metal fatigue and ultimately a catastrophic failure in the shaft of the generator. Using a state-space model of the electromechanical system, the paper develops transfer functions linking the magnitude of the malicious injections to the magnitude of oscillations in the speed and angle of the various masses connected to the shaft. Numerical results from a two-area power system demonstrate the existence of vulnerable frequencies and show that damaging mechanical oscillations can be triggered without causing easily detectable signals at the generator terminals. ",
    "url": "https://arxiv.org/abs/2207.04149",
    "authors": [
      "Bosong Li",
      "Baosen Zhang",
      "Daniel S. Kirschen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.04153",
    "title": "Probing Classifiers are Unreliable for Concept Removal and Detection",
    "abstract": "Neural network models trained on text data have been found to encode undesired linguistic or sensitive attributes in their representation. Removing such attributes is non-trivial because of a complex relationship between the attribute, text input, and the learnt representation. Recent work has proposed post-hoc and adversarial methods to remove such unwanted attributes from a model's representation. Through an extensive theoretical and empirical analysis, we show that these methods can be counter-productive: they are unable to remove the attributes entirely, and in the worst case may end up destroying all task-relevant features. The reason is the methods' reliance on a probing classifier as a proxy for the attribute. Even under the most favorable conditions when an attribute's features in representation space can alone provide 100% accuracy for learning the probing classifier, we prove that post-hoc or adversarial methods will fail to remove the attribute correctly. These theoretical implications are confirmed by empirical experiments on models trained on synthetic, Multi-NLI, and Twitter datasets. For sensitive applications of attribute removal such as fairness, we recommend caution against using these methods and propose a spuriousness metric to gauge the quality of the final classifier. ",
    "url": "https://arxiv.org/abs/2207.04153",
    "authors": [
      "Abhinav Kumar",
      "Chenhao Tan",
      "Amit Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.04179",
    "title": "Transformer Neural Processes: Uncertainty-Aware Meta Learning Via  Sequence Modeling",
    "abstract": "Neural Processes (NPs) are a popular class of approaches for meta-learning. Similar to Gaussian Processes (GPs), NPs define distributions over functions and can estimate uncertainty in their predictions. However, unlike GPs, NPs and their variants suffer from underfitting and often have intractable likelihoods, which limit their applications in sequential decision making. We propose Transformer Neural Processes (TNPs), a new member of the NP family that casts uncertainty-aware meta learning as a sequence modeling problem. We learn TNPs via an autoregressive likelihood-based objective and instantiate it with a novel transformer-based architecture. The model architecture respects the inductive biases inherent to the problem structure, such as invariance to the observed data points and equivariance to the unobserved points. We further investigate knobs within the TNP framework that tradeoff expressivity of the decoding distribution with extra computation. Empirically, we show that TNPs achieve state-of-the-art performance on various benchmark problems, outperforming all previous NP variants on meta regression, image completion, contextual multi-armed bandits, and Bayesian optimization. ",
    "url": "https://arxiv.org/abs/2207.04179",
    "authors": [
      "Tung Nguyen",
      "Aditya Grover"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.04183",
    "title": "Learning Robust Representation for Joint Grading of Ophthalmic Diseases  via Adaptive Curriculum and Feature Disentanglement",
    "abstract": "Diabetic retinopathy (DR) and diabetic macular edema (DME) are leading causes of permanent blindness worldwide. Designing an automatic grading system with good generalization ability for DR and DME is vital in clinical practice. However, prior works either grade DR or DME independently, without considering internal correlations between them, or grade them jointly by shared feature representation, yet ignoring potential generalization issues caused by difficult samples and data bias. Aiming to address these problems, we propose a framework for joint grading with the dynamic difficulty-aware weighted loss (DAW) and the dual-stream disentangled learning architecture (DETACH). Inspired by curriculum learning, DAW learns from simple samples to difficult samples dynamically via measuring difficulty adaptively. DETACH separates features of grading tasks to avoid potential emphasis on the bias. With the addition of DAW and DETACH, the model learns robust disentangled feature representations to explore internal correlations between DR and DME and achieve better grading performance. Experiments on three benchmarks show the effectiveness and robustness of our framework under both the intra-dataset and cross-dataset tests. ",
    "url": "https://arxiv.org/abs/2207.04183",
    "authors": [
      "Haoxuan Che",
      "Haibo Jin",
      "Hao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04186",
    "title": "A Study on Self-Supervised Object Detection Pretraining",
    "abstract": "In this work, we study different approaches to self-supervised pretraining of object detection models. We first design a general framework to learn a spatially consistent dense representation from an image, by randomly sampling and projecting boxes to each augmented view and maximizing the similarity between corresponding box features. We study existing design choices in the literature, such as box generation, feature extraction strategies, and using multiple views inspired by its success on instance-level image representation learning techniques. Our results suggest that the method is robust to different choices of hyperparameters, and using multiple views is not as effective as shown for instance-level image representation learning. We also design two auxiliary tasks to predict boxes in one view from their features in the other view, by (1) predicting boxes from the sampled set by using a contrastive loss, and (2) predicting box coordinates using a transformer, which potentially benefits downstream object detection tasks. We found that these tasks do not lead to better object detection performance when finetuning the pretrained model on labeled data. ",
    "url": "https://arxiv.org/abs/2207.04186",
    "authors": [
      "Trung Dang",
      "Simon Kornblith",
      "Huy Thong Nguyen",
      "Peter Chin",
      "Maryam Khademi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04201",
    "title": "Human-centric Spatio-Temporal Video Grounding via the Combination of  Mutual Matching Network and TubeDETR",
    "abstract": "In this technical report, we represent our solution for the Human-centric Spatio-Temporal Video Grounding (HC-STVG) track of the 4th Person in Context (PIC) workshop and challenge. Our solution is built on the basis of TubeDETR and Mutual Matching Network (MMN). Specifically, TubeDETR exploits a video-text encoder and a space-time decoder to predict the starting time, the ending time and the tube of the target person. MMN detects persons in images, links them as tubes, extracts features of person tubes and the text description, and predicts the similarities between them to choose the most likely person tube as the grounding result. Our solution finally finetunes the results by combining the spatio localization of MMN and with temporal localization of TubeDETR. In the HC-STVG track of the 4th PIC challenge, our solution achieves the third place. ",
    "url": "https://arxiv.org/abs/2207.04201",
    "authors": [
      "Fan Yu",
      "Zhixiang Zhao",
      "Yuchen Wang",
      "Yi Xu",
      "Tongwei Ren",
      "Gangshan Wu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.04209",
    "title": "Invisible Backdoor Attacks Using Data Poisoning in the Frequency Domain",
    "abstract": "With the broad application of deep neural networks (DNNs), backdoor attacks have gradually attracted attention. Backdoor attacks are insidious, and poisoned models perform well on benign samples and are only triggered when given specific inputs, which cause the neural network to produce incorrect outputs. The state-of-the-art backdoor attack work is implemented by data poisoning, i.e., the attacker injects poisoned samples into the dataset, and the models trained with that dataset are infected with the backdoor. However, most of the triggers used in the current study are fixed patterns patched on a small fraction of an image and are often clearly mislabeled, which is easily detected by humans or defense methods such as Neural Cleanse and SentiNet. Also, it's difficult to be learned by DNNs without mislabeling, as they may ignore small patterns. In this paper, we propose a generalized backdoor attack method based on the frequency domain, which can implement backdoor implantation without mislabeling and accessing the training process. It is invisible to human beings and able to evade the commonly used defense methods. We evaluate our approach in the no-label and clean-label cases on three datasets (CIFAR-10, STL-10, and GTSRB) with two popular scenarios (self-supervised learning and supervised learning). The results show our approach can achieve a high attack success rate (above 90%) on all the tasks without significant performance degradation on main tasks. Also, we evaluate the bypass performance of our approach for different kinds of defenses, including the detection of training data (i.e., Activation Clustering), the preprocessing of inputs (i.e., Filtering), the detection of inputs (i.e., SentiNet), and the detection of models (i.e., Neural Cleanse). The experimental results demonstrate that our approach shows excellent robustness to such defenses. ",
    "url": "https://arxiv.org/abs/2207.04209",
    "authors": [
      "Chang Yue",
      "Peizhuo Lv",
      "Ruigang Liang",
      "Kai Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.04211",
    "title": "BOSS: Bottom-up Cross-modal Semantic Composition with Hybrid  Counterfactual Training for Robust Content-based Image Retrieval",
    "abstract": "Content-Based Image Retrieval (CIR) aims to search for a target image by concurrently comprehending the composition of an example image and a complementary text, which potentially impacts a wide variety of real-world applications, such as internet search and fashion retrieval. In this scenario, the input image serves as an intuitive context and background for the search, while the corresponding language expressly requests new traits on how specific characteristics of the query image should be modified in order to get the intended target image. This task is challenging since it necessitates learning and understanding the composite image-text representation by incorporating cross-granular semantic updates. In this paper, we tackle this task by a novel \\underline{\\textbf{B}}ottom-up cr\\underline{\\textbf{O}}ss-modal \\underline{\\textbf{S}}emantic compo\\underline{\\textbf{S}}ition (\\textbf{BOSS}) with Hybrid Counterfactual Training framework, which sheds new light on the CIR task by studying it from two previously overlooked perspectives: \\emph{implicitly bottom-up composition of visiolinguistic representation} and \\emph{explicitly fine-grained correspondence of query-target construction}. On the one hand, we leverage the implicit interaction and composition of cross-modal embeddings from the bottom local characteristics to the top global semantics, preserving and transforming the visual representation conditioned on language semantics in several continuous steps for effective target image search. On the other hand, we devise a hybrid counterfactual training strategy that can reduce the model's ambiguity for similar queries. ",
    "url": "https://arxiv.org/abs/2207.04211",
    "authors": [
      "Wenqiao Zhang",
      "Jiannan Guo",
      "Mengze Li",
      "Haochen Shi",
      "Shengyu Zhang",
      "Juncheng Li",
      "Siliang Tang",
      "Yueting Zhuang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.04216",
    "title": "Wasserstein Graph Distance based on $L_1$-Approximated Tree Edit  Distance between Weisfeiler-Lehman Subtrees",
    "abstract": "The Weisfeiler-Lehman (WL) test has been widely applied to graph kernels, metrics, and neural networks. However, it considers only the graph consistency, resulting in the weak descriptive power of structural information. Thus, it limits the performance improvement of applied methods. In addition, the similarity and distance between graphs defined by the WL test are in coarse measurements. To the best of our knowledge, this paper clarifies these facts for the first time and defines a metric we call the Wasserstein WL subtree (WWLS) distance. We introduce the WL subtree as the structural information in the neighborhood of nodes and assign it to each node. Then we define a new graph embedding space based on $L_1$-approximated tree edit distance ($L_1$-TED): the $L_1$ norm of the difference between node feature vectors on the space is the $L_1$-TED between these nodes. We further propose a fast algorithm for graph embedding. Finally, we use the Wasserstein distance to reflect the $L_1$-TED to the graph level. The WWLS can capture small changes in structure that are difficult with traditional metrics. We demonstrate its performance in several graph classification and metric validation experiments. ",
    "url": "https://arxiv.org/abs/2207.04216",
    "authors": [
      "Zhongxi Fang",
      "Jianming Huang",
      "Xun Su",
      "Hiroyuki Kasai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.04224",
    "title": "SiaTrans: Siamese Transformer Network for RGB-D Salient Object Detection  with Depth Image Classification",
    "abstract": "RGB-D SOD uses depth information to handle challenging scenes and obtain high-quality saliency maps. Existing state-of-the-art RGB-D saliency detection methods overwhelmingly rely on the strategy of directly fusing depth information. Although these methods improve the accuracy of saliency prediction through various cross-modality fusion strategies, misinformation provided by some poor-quality depth images can affect the saliency prediction result. To address this issue, a novel RGB-D salient object detection model (SiaTrans) is proposed in this paper, which allows training on depth image quality classification at the same time as training on SOD. In light of the common information between RGB and depth images on salient objects, SiaTrans uses a Siamese transformer network with shared weight parameters as the encoder and extracts RGB and depth features concatenated on the batch dimension, saving space resources without compromising performance. SiaTrans uses the Class token in the backbone network (T2T-ViT) to classify the quality of depth images without preventing the token sequence from going on with the saliency detection task. Transformer-based cross-modality fusion module (CMF) can effectively fuse RGB and depth information. And in the testing process, CMF can choose to fuse cross-modality information or enhance RGB information according to the quality classification signal of the depth image. The greatest benefit of our designed CMF and decoder is that they maintain the consistency of RGB and RGB-D information decoding: SiaTrans decodes RGB-D or RGB information under the same model parameters according to the classification signal during testing. Comprehensive experiments on nine RGB-D SOD benchmark datasets show that SiaTrans has the best overall performance and the least computation compared with recent state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2207.04224",
    "authors": [
      "Xingzhao Jia",
      "Dongye Changlei",
      "Yanjun Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04227",
    "title": "On the Robustness and Anomaly Detection of Sparse Neural Networks",
    "abstract": "The robustness and anomaly detection capability of neural networks are crucial topics for their safe adoption in the real-world. Moreover, the over-parameterization of recent networks comes with high computational costs and raises questions about its influence on robustness and anomaly detection. In this work, we show that sparsity can make networks more robust and better anomaly detectors. To motivate this even further, we show that a pre-trained neural network contains, within its parameter space, sparse subnetworks that are better at these tasks without any further training. We also show that structured sparsity greatly helps in reducing the complexity of expensive robustness and detection methods, while maintaining or even improving their results on these tasks. Finally, we introduce a new method, SensNorm, which uses the sensitivity of weights derived from an appropriate pruning method to detect anomalous samples in the input. ",
    "url": "https://arxiv.org/abs/2207.04227",
    "authors": [
      "Morgane Ayle",
      "Bertrand Charpentier",
      "John Rachwan",
      "Daniel Z\u00fcgner",
      "Simon Geisler",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04231",
    "title": "CEG4N: Counter-Example Guided Neural Network Quantization Refinement",
    "abstract": "Neural networks are essential components of learning-based software systems. However, their high compute, memory, and power requirements make using them in low resources domains challenging. For this reason, neural networks are often quantized before deployment. Existing quantization techniques tend to degrade the network accuracy. We propose Counter-Example Guided Neural Network Quantization Refinement (CEG4N). This technique combines search-based quantization and equivalence verification: the former minimizes the computational requirements, while the latter guarantees that the network's output does not change after quantization. We evaluate CEG4N~on a diverse set of benchmarks, including large and small networks. Our technique successfully quantizes the networks in our evaluation while producing models with up to 72% better accuracy than state-of-the-art techniques. ",
    "url": "https://arxiv.org/abs/2207.04231",
    "authors": [
      "Jo\u00e3o Batista P. Matos Jr.",
      "Iury Bessa",
      "Edoardo Manino",
      "Xidan Song",
      "Lucas C. Cordeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2207.04238",
    "title": "Complexity of Public Goods Games on Graphs",
    "abstract": "We study the computational complexity of \"public goods games on networks\". In this model, each vertex in a graph is an agent that needs to take a binary decision of whether to \"produce a good\" or not. Each agent's utility depends on the number of its neighbors in the graph that produce the good, as well as on its own action. This dependence can be captured by a \"pattern\" $T:{\\rm I\\!N}\\rightarrow\\{0,1\\}$ that describes an agent's best response to every possible number of neighbors that produce the good. Answering a question of [Papadimitriou and Peng, 2021], we prove that for some simple pattern $T$ the problem of determining whether a non-trivial pure Nash equilibrium exists is NP-complete. We extend our result to a wide class of such $T$, but also find a new polynomial time algorithm for some specific simple pattern $T$. We leave open the goal of characterizing the complexity for all patterns. ",
    "url": "https://arxiv.org/abs/2207.04238",
    "authors": [
      "Matan Gilboa",
      "Noam Nisan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2207.04268",
    "title": "Cell-average based neural network method for high dimensional parabolic  differential equations",
    "abstract": "In this paper, we introduce cell-average based neural network (CANN) method to solve high-dimensional parabolic partial differential equations. The method is based on the integral or weak formulation of partial differential equations. A feedforward network is considered to train the solution average of cells in neighboring time. Initial values and approximate solution at $t=\\Delta t$ obtained by high order numerical method are taken as the inputs and outputs of network, respectively. We use supervised training combined with a simple backpropagation algorithm to train the network parameters. We find that the neural network has been trained to optimality for high-dimensional problems, the CFL condition is not strictly limited for CANN method and the trained network is used to solve the same problem with different initial values. For the high-dimensional parabolic equations, the convergence is observed and the errors are shown related to spatial mesh size but independent of time step size. ",
    "url": "https://arxiv.org/abs/2207.04268",
    "authors": [
      "Hong Zhang",
      "Hongying Huang",
      "Jue Yan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.04285",
    "title": "A Closer Look into Transformer-Based Code Intelligence Through Code  Transformation: Challenges and Opportunities",
    "abstract": "Transformer-based models have demonstrated state-of-the-art performance in many intelligent coding tasks such as code comment generation and code completion. Previous studies show that deep learning models are sensitive to the input variations, but few studies have systematically studied the robustness of Transformer under perturbed input code. In this work, we empirically study the effect of semantic-preserving code transformation on the performance of Transformer. Specifically, 24 and 27 code transformation strategies are implemented for two popular programming languages, Java and Python, respectively. For facilitating analysis, the strategies are grouped into five categories: block transformation, insertion/deletion transformation, grammatical statement transformation, grammatical token transformation, and identifier transformation. Experiments on three popular code intelligence tasks, including code completion, code summarization and code search, demonstrate insertion/deletion transformation and identifier transformation show the greatest impact on the performance of Transformer. Our results also suggest that Transformer based on abstract syntax trees (ASTs) shows more robust performance than the model based on only code sequence under most code transformations. Besides, the design of positional encoding can impact the robustness of Transformer under code transformation. Based on our findings, we distill some insights about the challenges and opportunities for Transformer-based code intelligence. ",
    "url": "https://arxiv.org/abs/2207.04285",
    "authors": [
      "Yaoxian Li",
      "Shiyi Qi",
      "Cuiyun Gao",
      "Yun Peng",
      "David Lo",
      "Zenglin Xu",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2207.04297",
    "title": "SHDM-NET: Heat Map Detail Guidance with Image Matting for Industrial  Weld Semantic Segmentation Network",
    "abstract": "In actual industrial production, the assessment of the steel plate welding effect is an important task, and the segmentation of the weld section is the basis of the assessment. This paper proposes an industrial weld segmentation network based on a deep learning semantic segmentation algorithm fused with heatmap detail guidance and Image Matting to solve the automatic segmentation problem of weld regions. In the existing semantic segmentation networks, the boundary information can be preserved by fusing the features of both high-level and low-level layers. However, this method can lead to insufficient expression of the spatial information in the low-level layer, resulting in inaccurate segmentation boundary positioning. We propose a detailed guidance module based on heatmaps to fully express the segmented region boundary information in the low-level network to address this problem. Specifically, the expression of boundary information can be enhanced by adding a detailed branch to predict segmented boundary and then matching it with the boundary heat map generated by mask labels to calculate the mean square error loss. In addition, although deep learning has achieved great success in the field of semantic segmentation, the precision of the segmentation boundary region is not high due to the loss of detailed information caused by the classical segmentation network in the process of encoding and decoding process. This paper introduces a matting algorithm to calibrate the boundary of the segmentation region of the semantic segmentation network to solve this problem. Through many experiments on industrial weld data sets, the effectiveness of our method is demonstrated, and the MIOU reaches 97.93%. It is worth noting that this performance is comparable to human manual segmentation ( MIOU 97.96%). ",
    "url": "https://arxiv.org/abs/2207.04297",
    "authors": [
      "Qi Wang",
      "Jingwu Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04305",
    "title": "Training Robust Deep Models for Time-Series Domain: Novel Algorithms and  Theoretical Analysis",
    "abstract": "Despite the success of deep neural networks (DNNs) for real-world applications over time-series data such as mobile health, little is known about how to train robust DNNs for time-series domain due to its unique characteristics compared to images and text data. In this paper, we propose a novel algorithmic framework referred as RObust Training for Time-Series (RO-TS) to create robust DNNs for time-series classification tasks. Specifically, we formulate a min-max optimization problem over the model parameters by explicitly reasoning about the robustness criteria in terms of additive perturbations to time-series inputs measured by the global alignment kernel (GAK) based distance. We also show the generality and advantages of our formulation using the summation structure over time-series alignments by relating both GAK and dynamic time warping (DTW). This problem is an instance of a family of compositional min-max optimization problems, which are challenging and open with unclear theoretical guarantee. We propose a principled stochastic compositional alternating gradient descent ascent (SCAGDA) algorithm for this family of optimization problems. Unlike traditional methods for time-series that require approximate computation of distance measures, SCAGDA approximates the GAK based distance on-the-fly using a moving average approach. We theoretically analyze the convergence rate of SCAGDA and provide strong theoretical support for the estimation of GAK based distance. Our experiments on real-world benchmarks demonstrate that RO-TS creates more robust DNNs when compared to adversarial training using prior methods that rely on data augmentation or new definitions of loss functions. We also demonstrate the importance of GAK for time-series data over the Euclidean distance. The source code of RO-TS algorithms is available at https://github.com/tahabelkhouja/Robust-Training-for-Time-Series ",
    "url": "https://arxiv.org/abs/2207.04305",
    "authors": [
      "Taha Belkhouja",
      "Yan Yan",
      "Janardhan Rao Doppa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04306",
    "title": "Out-of-Distribution Detection in Time-Series Domain: A Novel Seasonal  Ratio Scoring Approach",
    "abstract": "Safe deployment of time-series classifiers for real-world applications relies on the ability to detect the data which is not generated from the same distribution as training data. This task is referred to as out-of-distribution (OOD) detection. We consider the novel problem of OOD detection for the time-series domain. We discuss the unique challenges posed by time-series data and explain why prior methods from the image domain will perform poorly. Motivated by these challenges, this paper proposes a novel {\\em Seasonal Ratio Scoring (SRS)} approach. SRS consists of three key algorithmic steps. First, each input is decomposed into class-wise semantic component and remainder. Second, this decomposition is employed to estimate the class-wise conditional likelihoods of the input and remainder using deep generative models. The seasonal ratio score is computed from these estimates. Third, a threshold interval is identified from the in-distribution data to detect OOD examples. Experiments on diverse real-world benchmarks demonstrate that the SRS method is well-suited for time-series OOD detection when compared to baseline methods. Open-source code for SRS method is provided at https://github.com/tahabelkhouja/SRS ",
    "url": "https://arxiv.org/abs/2207.04306",
    "authors": [
      "Taha Belkhouja",
      "Yan Yan",
      "Janardhan Rao Doppa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04307",
    "title": "Adversarial Framework with Certified Robustness for Time-Series Domain  via Statistical Features",
    "abstract": "Time-series data arises in many real-world applications (e.g., mobile health) and deep neural networks (DNNs) have shown great success in solving them. Despite their success, little is known about their robustness to adversarial attacks. In this paper, we propose a novel adversarial framework referred to as Time-Series Attacks via STATistical Features (TSA-STAT)}. To address the unique challenges of time-series domain, TSA-STAT employs constraints on statistical features of the time-series data to construct adversarial examples. Optimized polynomial transformations are used to create attacks that are more effective (in terms of successfully fooling DNNs) than those based on additive perturbations. We also provide certified bounds on the norm of the statistical features for constructing adversarial examples. Our experiments on diverse real-world benchmark datasets show the effectiveness of TSA-STAT in fooling DNNs for time-series domain and in improving their robustness. The source code of TSA-STAT algorithms is available at https://github.com/tahabelkhouja/Time-Series-Attacks-via-STATistical-Features ",
    "url": "https://arxiv.org/abs/2207.04307",
    "authors": [
      "Taha Belkhouja",
      "Janardhan Rao Doppa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04308",
    "title": "Dynamic Time Warping based Adversarial Framework for Time-Series Domain",
    "abstract": "Despite the rapid progress on research in adversarial robustness of deep neural networks (DNNs), there is little principled work for the time-series domain. Since time-series data arises in diverse applications including mobile health, finance, and smart grid, it is important to verify and improve the robustness of DNNs for the time-series domain. In this paper, we propose a novel framework for the time-series domain referred as {\\em Dynamic Time Warping for Adversarial Robustness (DTW-AR)} using the dynamic time warping measure. Theoretical and empirical evidence is provided to demonstrate the effectiveness of DTW over the standard Euclidean distance metric employed in prior methods for the image domain. We develop a principled algorithm justified by theoretical analysis to efficiently create diverse adversarial examples using random alignment paths. Experiments on diverse real-world benchmarks show the effectiveness of DTW-AR to fool DNNs for time-series data and to improve their robustness using adversarial training. The source code of DTW-AR algorithms is available at https://github.com/tahabelkhouja/DTW-AR ",
    "url": "https://arxiv.org/abs/2207.04308",
    "authors": [
      "Taha Belkhouja",
      "Yan Yan",
      "Janardhan Rao Doppa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04325",
    "title": "Unsupervised Joint Image Transfer and Uncertainty Quantification using  Patch Invariant Networks",
    "abstract": "Unsupervised image transfer enables intra- and inter-modality transfer for medical applications where a large amount of paired training data is not abundant. To ensure a structure-preserving mapping from the input to the target domain, existing methods for unpaired medical image transfer are commonly based on cycle-consistency, causing additional computation resources and instability due to the learning of an inverse mapping. This paper presents a novel method for uni-directional domain mapping where no paired data is needed throughout the entire training process. A reasonable transfer is ensured by employing the GAN architecture and a novel generator loss based on patch invariance. To be more precise, generator outputs are evaluated and compared on different scales, which brings increased attention to high-frequency details as well as implicit data augmentation. This novel term also gives the opportunity to predict aleatoric uncertainty by modeling an input-dependent scale map for the patch residuals. The proposed method is comprehensively evaluated on three renowned medical databases. Superior accuracy on these datasets compared to four different state-of-the-art methods for unpaired image transfer suggests the great potential of this approach for uncertainty-aware medical image translation. Implementation of the proposed framework is released here: https://github.com/anger-man/unsupervised-image-transfer-and-uq. ",
    "url": "https://arxiv.org/abs/2207.04325",
    "authors": [
      "Christoph Angermann",
      "Markus Haltmeier",
      "Ahsan Raza Siyal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.04356",
    "title": "A Comparative Study of Self-supervised Speech Representation Based Voice  Conversion",
    "abstract": "We present a large-scale comparative study of self-supervised speech representation (S3R)-based voice conversion (VC). In the context of recognition-synthesis VC, S3Rs are attractive owing to their potential to replace expensive supervised representations such as phonetic posteriorgrams (PPGs), which are commonly adopted by state-of-the-art VC systems. Using S3PRL-VC, an open-source VC software we previously developed, we provide a series of in-depth objective and subjective analyses under three VC settings: intra-/cross-lingual any-to-one (A2O) and any-to-any (A2A) VC, using the voice conversion challenge 2020 (VCC2020) dataset. We investigated S3R-based VC in various aspects, including model type, multilinguality, and supervision. We also studied the effect of a post-discretization process with k-means clustering and showed how it improves in the A2A setting. Finally, the comparison with state-of-the-art VC systems demonstrates the competitiveness of S3R-based VC and also sheds light on the possible improving directions. ",
    "url": "https://arxiv.org/abs/2207.04356",
    "authors": [
      "Wen-Chin Huang",
      "Shu-Wen Yang",
      "Tomoki Hayashi",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.04359",
    "title": "A Privacy-Preserving Energy Management System for Cooperative  Multi-Microgrid Networks",
    "abstract": "This paper presents an Energy Management System (EMS) that considers power exchanges between a set of interconnected microgrids (MGs) and the main grid, in the context of Multi-MG (MMG) systems. The model is first formulated as a centralized optimization problem, which is then decomposed into subproblems corresponding to each MG, using Lagrangian relaxation, and solved through a distributed approach using a subgradient method. The proposed model determines the power exchanges minimizing the operation cost of each MG, considering grid constraints and preserving the privacy of each MG by not revealing their generation cost and demand information. The distributed approach is validated with respect to the centralized problem, and various case studies are presented to demonstrate the performance of the proposed approach, comparing the costs of the MGs operating individually and cooperatively. The results show that all MGs in the MMG system improve their cost as consequence of the power exchanges, thus demonstrating the advantages of interconnecting MGs. ",
    "url": "https://arxiv.org/abs/2207.04359",
    "authors": [
      "Carlos Ceja-Espinosa",
      "Mehrdad Pirnia",
      "Claudio A. Ca\u00f1izares"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.04364",
    "title": "Planning Sequential Tasks on Contact Graph",
    "abstract": "We devise a 3D scene graph representation, contact graph+ (cg+), for efficient sequential task planning. Augmented with predicate-like attributes, this contact graph-based representation abstracts scene layouts with succinct geometric information and valid robot-scene interactions. Goal configurations, naturally specified on contact graphs, can be produced by a genetic algorithm with a stochastic optimization method. A task plan is then initialized by computing the Graph Editing Distance (GED) between the initial contact graphs and the goal configurations, which generates graph edit operations corresponding to possible robot actions. We finalize the task plan by imposing constraints to regulate the temporal feasibility of graph edit operations, ensuring valid task and motion correspondences. In a series of simulations and experiments, robots successfully complete complex sequential object rearrangement tasks that are difficult to specify using conventional planning language like Planning Domain Definition Language (PDDL), demonstrating the high feasibility and potential of robot sequential task planning on contact graph. ",
    "url": "https://arxiv.org/abs/2207.04364",
    "authors": [
      "Ziyuan Jiao",
      "Yida Niu",
      "Zeyu Zhang",
      "Song-Chun Zhu",
      "Yixin Zhu",
      "Hangxin Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.04376",
    "title": "On Graph Neural Network Fairness in the Presence of Heterophilous  Neighborhoods",
    "abstract": "We study the task of node classification for graph neural networks (GNNs) and establish a connection between group fairness, as measured by statistical parity and equal opportunity, and local assortativity, i.e., the tendency of linked nodes to have similar attributes. Such assortativity is often induced by homophily, the tendency for nodes of similar properties to connect. Homophily can be common in social networks where systemic factors have forced individuals into communities which share a sensitive attribute. Through synthetic graphs, we study the interplay between locally occurring homophily and fair predictions, finding that not all node neighborhoods are equal in this respect -- neighborhoods dominated by one category of a sensitive attribute often struggle to obtain fair treatment, especially in the case of diverging local class and sensitive attribute homophily. After determining that a relationship between local homophily and fairness exists, we investigate if the issue of unfairness can be associated to the design of the applied GNN model. We show that by adopting heterophilous GNN designs capable of handling disassortative group labels, group fairness in locally heterophilous neighborhoods can be improved by up to 25% over homophilous designs in real and synthetic datasets. ",
    "url": "https://arxiv.org/abs/2207.04376",
    "authors": [
      "Donald Loveland",
      "Jiong Zhu",
      "Mark Heimann",
      "Ben Fish",
      "Michael T. Schaub",
      "Danai Koutra"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04380",
    "title": "Connect the Dots: Tighter Discrete Approximations of Privacy Loss  Distributions",
    "abstract": "The privacy loss distribution (PLD) provides a tight characterization of the privacy loss of a mechanism in the context of differential privacy (DP). Recent work has shown that PLD-based accounting allows for tighter $(\\varepsilon, \\delta)$-DP guarantees for many popular mechanisms compared to other known methods. A key question in PLD-based accounting is how to approximate any (potentially continuous) PLD with a PLD over any specified discrete support. We present a novel approach to this problem. Our approach supports both pessimistic estimation, which overestimates the hockey-stick divergence (i.e., $\\delta$) for any value of $\\varepsilon$, and optimistic estimation, which underestimates the hockey-stick divergence. Moreover, we show that our pessimistic estimate is the best possible among all pessimistic estimates. Experimental evaluation shows that our approach can work with much larger discretization intervals while keeping a similar error bound compared to previous approaches and yet give a better approximation than existing methods. ",
    "url": "https://arxiv.org/abs/2207.04380",
    "authors": [
      "Vadym Doroshenko",
      "Badih Ghazi",
      "Pritish Kamath",
      "Ravi Kumar",
      "Pasin Manurangsi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04381",
    "title": "Faster Privacy Accounting via Evolving Discretization",
    "abstract": "We introduce a new algorithm for numerical composition of privacy random variables, useful for computing the accurate differential privacy parameters for composition of mechanisms. Our algorithm achieves a running time and memory usage of $\\mathrm{polylog}(k)$ for the task of self-composing a mechanism, from a broad class of mechanisms, $k$ times; this class, e.g., includes the sub-sampled Gaussian mechanism, that appears in the analysis of differentially private stochastic gradient descent. By comparison, recent work by Gopi et al. (NeurIPS 2021) has obtained a running time of $\\widetilde{O}(\\sqrt{k})$ for the same task. Our approach extends to the case of composing $k$ different mechanisms in the same class, improving upon their running time and memory usage from $\\widetilde{O}(k^{1.5})$ to $\\widetilde{O}(k)$. ",
    "url": "https://arxiv.org/abs/2207.04381",
    "authors": [
      "Badih Ghazi",
      "Pritish Kamath",
      "Ravi Kumar",
      "Pasin Manurangsi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04396",
    "title": "Scalable Privacy-enhanced Benchmark Graph Generative Model for Graph  Convolutional Networks",
    "abstract": "A surge of interest in Graph Convolutional Networks (GCN) has produced thousands of GCN variants, with hundreds introduced every year. In contrast, many GCN models re-use only a handful of benchmark datasets as many graphs of interest, such as social or commercial networks, are proprietary. We propose a new graph generation problem to enable generating a diverse set of benchmark graphs for GCNs following the distribution of a source graph -- possibly proprietary -- with three requirements: 1) benchmark effectiveness as a substitute for the source graph for GCN research, 2) scalability to process large-scale real-world graphs, and 3) a privacy guarantee for end-users. With a novel graph encoding scheme, we reframe large-scale graph generation problem into medium-length sequence generation problem and apply the strong generation power of the Transformer architecture to the graph domain. Extensive experiments across a vast body of graph generative models show that our model can successfully generate benchmark graphs with the realistic graph structure, node attributes, and node labels required to benchmark GCNs on node classification tasks. ",
    "url": "https://arxiv.org/abs/2207.04396",
    "authors": [
      "Minji Yoon",
      "Yue Wu",
      "John Palowitch",
      "Bryan Perozzi",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.04398",
    "title": "Self-supervised Learning with Local Contrastive Loss for Detection and  Semantic Segmentation",
    "abstract": "We present a self-supervised learning (SSL) method suitable for semi-global tasks such as object detection and semantic segmentation. We enforce local consistency between self-learned features, representing corresponding image locations of transformed versions of the same image, by minimizing a pixel-level local contrastive (LC) loss during training. LC-loss can be added to existing self-supervised learning methods with minimal overhead. We evaluate our SSL approach on two downstream tasks -- object detection and semantic segmentation, using COCO, PASCAL VOC, and CityScapes datasets. Our method outperforms the existing state-of-the-art SSL approaches by 1.9% on COCO object detection, 1.4% on PASCAL VOC detection, and 0.6% on CityScapes segmentation. ",
    "url": "https://arxiv.org/abs/2207.04398",
    "authors": [
      "Ashraful Islam",
      "Ben Lundell",
      "Harpreet Sawhney",
      "Sudipta Sinha",
      "Peter Morales",
      "Richard J. Radke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.04423",
    "title": "Dual-Correction Adaptation Network for Noisy Knowledge Transfer",
    "abstract": "Previous unsupervised domain adaptation (UDA) methods aim to promote target learning via a single-directional knowledge transfer from label-rich source domain to unlabeled target domain, while its reverse adaption from target to source has not jointly been considered yet so far. In fact, in some real teaching practice, a teacher helps students learn while also gets promotion from students to some extent, which inspires us to explore a dual-directional knowledge transfer between domains, and thus propose a Dual-Correction Adaptation Network (DualCAN) in this paper. However, due to the asymmetrical label knowledge across domains, transfer from unlabeled target to labeled source poses a more difficult challenge than the common source-to-target counterpart. First, the target pseudo-labels predicted by source commonly involve noises due to model bias, hence in the reverse adaptation, they may hurt the source performance and bring a negative target-to-source transfer. Secondly, source domain usually contains innate noises, which will inevitably aggravate the target noises, leading to noise amplification across domains. To this end, we further introduce a Noise Identification and Correction (NIC) module to correct and recycle noises in both domains. To our best knowledge, this is the first naive attempt of dual-directional adaptation for noisy UDA, and naturally applicable to noise-free UDA. A theory justification is given to state the rationality of our intuition. Empirical results confirm the effectiveness of DualCAN with remarkable performance gains over state-of-the-arts, particularly for extreme noisy tasks (e.g., ~+ 15% on Pw->Pr and Pr->Rw of Office-Home). ",
    "url": "https://arxiv.org/abs/2207.04423",
    "authors": [
      "Yunyun Wang",
      "Weiwen Zheng",
      "Songcan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04448",
    "title": "Mix-Teaching: A Simple, Unified and Effective Semi-Supervised Learning  Framework for Monocular 3D Object Detection",
    "abstract": "Monocular 3D object detection is an essential perception task for autonomous driving. However, the high reliance on large-scale labeled data make it costly and time-consuming during model optimization. To reduce such over-reliance on human annotations, we propose Mix-Teaching, an effective semi-supervised learning framework applicable to employ both labeled and unlabeled images in training stage. Mix-Teaching first generates pseudo-labels for unlabeled images by self-training. The student model is then trained on the mixed images possessing much more intensive and precise labeling by merging instance-level image patches into empty backgrounds or labeled images. This is the first to break the image-level limitation and put high-quality pseudo labels from multi frames into one image for semi-supervised training. Besides, as a result of the misalignment between confidence score and localization quality, it's hard to discriminate high-quality pseudo-labels from noisy predictions using only confidence-based criterion. To that end, we further introduce an uncertainty-based filter to help select reliable pseudo boxes for the above mixing operation. To the best of our knowledge, this is the first unified SSL framework for monocular 3D object detection. Mix-Teaching consistently improves MonoFlex and GUPNet by significant margins under various labeling ratios on KITTI dataset. For example, our method achieves around +6.34% AP@0.7 improvement against the GUPNet baseline on validation set when using only 10% labeled data. Besides, by leveraging full training set and the additional 48K raw images of KITTI, it can further improve the MonoFlex by +4.65% improvement on AP@0.7 for car detection, reaching 18.54% AP@0.7, which ranks the 1st place among all monocular based methods on KITTI test leaderboard. The code and pretrained models will be released at https://github.com/yanglei18/Mix-Teaching. ",
    "url": "https://arxiv.org/abs/2207.04448",
    "authors": [
      "Lei Yang",
      "Xinyu Zhang",
      "Li Wang",
      "Minghan Zhu",
      "Chuang Zhang",
      "Jun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04457",
    "title": "TCR: A Transformer Based Deep Network for Predicting Cancer Drugs  Response",
    "abstract": "Predicting clinical outcomes to anti-cancer drugs on a personalized basis is challenging in cancer treatment due to the heterogeneity of tumors. Traditional computational efforts have been made to model the effect of drug response on individual samples depicted by their molecular profile, yet overfitting occurs because of the high dimension for omics data, hindering models from clinical application. Recent research shows that deep learning is a promising approach to build drug response models by learning alignment patterns between drugs and samples. However, existing studies employed the simple feature fusion strategy and only considered the drug features as a whole representation while ignoring the substructure information that may play a vital role when aligning drugs and genes. Hereby in this paper, we propose TCR (Transformer based network for Cancer drug Response) to predict anti-cancer drug response. By utilizing an attention mechanism, TCR is able to learn the interactions between drug atom/sub-structure and molecular signatures efficiently in our study. Furthermore, a dual loss function and cross sampling strategy were designed to improve the prediction power of TCR. We show that TCR outperformed all other methods under various data splitting strategies on all evaluation matrices (some with significant improvement). Extensive experiments demonstrate that TCR shows significantly improved generalization ability on independent in-vitro experiments and in-vivo real patient data. Our study highlights the prediction power of TCR and its potential value for cancer drug repurpose and precision oncology treatment. ",
    "url": "https://arxiv.org/abs/2207.04457",
    "authors": [
      "Jie Gao",
      "Jing Hu",
      "Wanqing Sun",
      "Yili Shen",
      "Xiaonan Zhang",
      "Xiaomin Fang",
      "Fan Wang",
      "Guodong Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2207.04465",
    "title": "Progressively-connected Light Field Network for Efficient View Synthesis",
    "abstract": "This paper presents a Progressively-connected Light Field network (ProLiF), for the novel view synthesis of complex forward-facing scenes. ProLiF encodes a 4D light field, which allows rendering a large batch of rays in one training step for image- or patch-level losses. Directly learning a neural light field from images has difficulty in rendering multi-view consistent images due to its unawareness of the underlying 3D geometry. To address this problem, we propose a progressive training scheme and regularization losses to infer the underlying geometry during training, both of which enforce the multi-view consistency and thus greatly improves the rendering quality. Experiments demonstrate that our method is able to achieve significantly better rendering quality than the vanilla neural light fields and comparable results to NeRF-like rendering methods on the challenging LLFF dataset and Shiny Object dataset. Moreover, we demonstrate better compatibility with LPIPS loss to achieve robustness to varying light conditions and CLIP loss to control the rendering style of the scene. Project page: https://totoro97.github.io/projects/prolif. ",
    "url": "https://arxiv.org/abs/2207.04465",
    "authors": [
      "Peng Wang",
      "Yuan Liu",
      "Guying Lin",
      "Jiatao Gu",
      "Lingjie Liu",
      "Taku Komura",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2207.04467",
    "title": "Noisy Heuristics NAS: A Network Morphism based Neural Architecture  Search using Heuristics",
    "abstract": "Network Morphism based Neural Architecture Search (NAS) is one of the most efficient methods, however, knowing where and when to add new neurons or remove dis-functional ones is generally left to black-box Reinforcement Learning models. In this paper, we present a new Network Morphism based NAS called Noisy Heuristics NAS which uses heuristics learned from manually developing neural network models and inspired by biological neuronal dynamics. Firstly, we add new neurons randomly and prune away some to select only the best fitting neurons. Secondly, we control the number of layers in the network using the relationship of hidden units to the number of input-output connections. Our method can increase or decrease the capacity or non-linearity of models online which is specified with a few meta-parameters by the user. Our method generalizes both on toy datasets and on real-world data sets such as MNIST, CIFAR-10, and CIFAR-100. The performance is comparable to the hand-engineered architecture ResNet-18 with the similar parameters. ",
    "url": "https://arxiv.org/abs/2207.04467",
    "authors": [
      "Suman Sapkota",
      "Binod Bhattarai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2207.04471",
    "title": "Towards Proper Contrastive Self-supervised Learning Strategies For Music  Audio Representation",
    "abstract": "The common research goal of self-supervised learning is to extract a general representation which an arbitrary downstream task would benefit from. In this work, we investigate music audio representation learned from different contrastive self-supervised learning schemes and empirically evaluate the embedded vectors on various music information retrieval (MIR) tasks where different levels of the music perception are concerned. We analyze the results to discuss the proper direction of contrastive learning strategies for different MIR tasks. We show that these representations convey a comprehensive information about the auditory characteristics of music in general, although each of the self-supervision strategies has its own effectiveness in certain aspect of information. ",
    "url": "https://arxiv.org/abs/2207.04471",
    "authors": [
      "Jeong Choi",
      "Seongwon Jang",
      "Hyunsouk Cho",
      "Sehee Chung"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.04476",
    "title": "Myers-Briggs personality classification from social media text using  pre-trained language models",
    "abstract": "In Natural Language Processing, the use of pre-trained language models has been shown to obtain state-of-the-art results in many downstream tasks such as sentiment analysis, author identification and others. In this work, we address the use of these methods for personality classification from text. Focusing on the Myers-Briggs (MBTI) personality model, we describe a series of experiments in which the well-known Bidirectional Encoder Representations from Transformers (BERT) model is fine-tuned to perform MBTI classification. Our main findings suggest that the current approach significantly outperforms well-known text classification models based on bag-of-words and static word embeddings alike across multiple evaluation scenarios, and generally outperforms previous work in the field. ",
    "url": "https://arxiv.org/abs/2207.04476",
    "authors": [
      "Vitor Garcia dos Santos",
      "Ivandr\u00e9 Paraboni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.04491",
    "title": "DPText-DETR: Towards Better Scene Text Detection with Dynamic Points in  Transformer",
    "abstract": "Recently, Transformer-based methods, which predict polygon points or Bezier curve control points to localize texts, are quite popular in scene text detection. However, the used point label form implies the reading order of humans, which affects the robustness of Transformer model. As for the model architecture, the formulation of queries used in decoder has not been fully explored by previous methods. In this paper, we propose a concise dynamic point scene text detection Transformer network termed DPText-DETR, which directly uses point coordinates as queries and dynamically updates them between decoder layers. We point out a simple yet effective positional point label form to tackle the side effect of the original one. Moreover, an Enhanced Factorized Self-Attention module is designed to explicitly model the circular shape of polygon point sequences beyond non-local attention. Extensive experiments prove the training efficiency, robustness, and state-of-the-art performance on various arbitrary shape scene text benchmarks. Beyond detector, we observe that existing end-to-end spotters struggle to recognize inverse-like texts. To evaluate their performance objectively and facilitate future research, we propose an Inverse-Text test set containing 500 manually labeled images. The code and Inverse-Text test set will be available at https://github.com/ymy-k/DPText-DETR. ",
    "url": "https://arxiv.org/abs/2207.04491",
    "authors": [
      "Maoyuan Ye",
      "Jing Zhang",
      "Shanshan Zhao",
      "Juhua Liu",
      "Bo Du",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04497",
    "title": "One-shot Neural Backdoor Erasing via Adversarial Weight Masking",
    "abstract": "Recent studies show that despite achieving high accuracy on a number of real-world applications, deep neural networks (DNNs) can be backdoored: by injecting triggered data samples into the training dataset, the adversary can mislead the trained model into classifying any test data to the target class as long as the trigger pattern is presented. To nullify such backdoor threats, various methods have been proposed. Particularly, a line of research aims to purify the potentially compromised model. However, one major limitation of this line of work is the requirement to access sufficient original training data: the purifying performance is a lot worse when the available training data is limited. In this work, we propose Adversarial Weight Masking (AWM), a novel method capable of erasing the neural backdoors even in the one-shot setting. The key idea behind our method is to formulate this into a min-max optimization problem: first, adversarially recover the trigger patterns and then (soft) mask the network weights that are sensitive to the recovered patterns. Comprehensive evaluations of several benchmark datasets suggest that AWM can largely improve the purifying effects over other state-of-the-art methods on various available training dataset sizes. ",
    "url": "https://arxiv.org/abs/2207.04497",
    "authors": [
      "Shuwen Chai",
      "Jinghui Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.04502",
    "title": "Building Open Knowledge Graph for Metal-Organic Frameworks (MOF-KG):  Challenges and Case Studies",
    "abstract": "Metal-Organic Frameworks (MOFs) are a class of modular, porous crystalline materials that have great potential to revolutionize applications such as gas storage, molecular separations, chemical sensing, catalysis, and drug delivery. The Cambridge Structural Database (CSD) reports 10,636 synthesized MOF crystals which in addition contains ca. 114,373 MOF-like structures. The sheer number of synthesized (plus potentially synthesizable) MOF structures requires researchers pursue computational techniques to screen and isolate MOF candidates. In this demo paper, we describe our effort on leveraging knowledge graph methods to facilitate MOF prediction, discovery, and synthesis. We present challenges and case studies about (1) construction of a MOF knowledge graph (MOF-KG) from structured and unstructured sources and (2) leveraging the MOF-KG for discovery of new or missing knowledge. ",
    "url": "https://arxiv.org/abs/2207.04502",
    "authors": [
      "Yuan An",
      "Jane Greenberg",
      "Xintong Zhao",
      "Xiaohua Hu",
      "Scott McCLellan",
      "Alex Kalinowski",
      "Fernando J. Uribe-Romo",
      "Kyle Langlois",
      "Jacob Furst",
      "Diego A. G\u00f3mez-Gualdr\u00f3n",
      "Fernando Fajardo-Rojas",
      "Katherine Ardila"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.04503",
    "title": "BotNet Intrusion Detection System in Internet of Things with Developed  Deep Learning",
    "abstract": "The rapid growth of technology has led to the creation of computing networks. The applications of the Internet of Things are becoming more and more visible with the expansion and development of sensors and the use of a series of equipment to connect to the Internet. Of course, the growth of any network will also provide some challenges. The main challenge of IoT like any other network is its security. In the field of security, there are issues such as attack detection, authentication, encryption and the so on. One of the most important attack is cyber-attacks that disrupt the network usage. One of the most important attacks on the IoT is BotNet attack. The most important challenges of this topic include very high computational complexity, lack of comparison with previous methods, lack of scalability, high execution time, lack of review of the proposed approach in terms of accuracy to detect and classify attacks and intrusions. Using intrusion detection systems for the IoT is an important step in identifying and detecting various attacks. Therefore, an algorithm that can solve these challenges has provided a near-optimal method. Using training-based models and algorithms such as Deep Dearning-Reinforcement Learning and XGBoost learning in combination (DRL-XGBoost) models can be an interesting approach to overcoming previous weaknesses. The data of this research is Bot-IoT-2018. ",
    "url": "https://arxiv.org/abs/2207.04503",
    "authors": [
      "Amirabas Kabiri Zamani",
      "Amirahmad Chapnevis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.04539",
    "title": "Multi-task Envisioning Transformer-based Autoencoder for Corporate  Credit Rating Migration Early Prediction",
    "abstract": "Corporate credit ratings issued by third-party rating agencies are quantified assessments of a company's creditworthiness. Credit Ratings highly correlate to the likelihood of a company defaulting on its debt obligations. These ratings play critical roles in investment decision-making as one of the key risk factors. They are also central to the regulatory framework such as BASEL II in calculating necessary capital for financial institutions. Being able to predict rating changes will greatly benefit both investors and regulators alike. In this paper, we consider the corporate credit rating migration early prediction problem, which predicts the credit rating of an issuer will be upgraded, unchanged, or downgraded after 12 months based on its latest financial reporting information at the time. We investigate the effectiveness of different standard machine learning algorithms and conclude these models deliver inferior performance. As part of our contribution, we propose a new Multi-task Envisioning Transformer-based Autoencoder (META) model to tackle this challenging problem. META consists of Positional Encoding, Transformer-based Autoencoder, and Multi-task Prediction to learn effective representations for both migration prediction and rating prediction. This enables META to better explore the historical data in the training stage for one-year later prediction. Experimental results show that META outperforms all baseline models. ",
    "url": "https://arxiv.org/abs/2207.04539",
    "authors": [
      "Han Yue",
      "Steve Xia",
      "Hongfu Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04560",
    "title": "A polynomial-time approximation to a minimum dominating set in a graph",
    "abstract": "A {\\em dominating set} of a graph $G=(V,E)$ is a subset of vertices $S\\subseteq V$ such that every vertex $v\\in V\\setminus S$ has at least one neighbor in $S$. Finding a dominating set with the minimum cardinality in a connected graph $G=(V,E)$ is known to be NP-hard. A polynomial-time approximation algorithm for this problem, described here, works in two stages. At the first stage a dominant set is generated by a greedy algorithm, and at the second stage this dominating set is purified (reduced). The reduction is achieved by the analysis of the flowchart of the algorithm of the first stage and a special kind of clustering of the dominating set generated at the first stage. The clustering of the dominating set naturally leads to a special kind of a spanning forest of graph $G$, which serves as a basis for the second purification stage. We expose some types of graphs for which the algorithm of the first stage already delivers an optimal solution and derive sufficient conditions when the overall algorithm constructs an optimal solution. We give three alternative approximation ratios for the algorithm of the first stage, two of which are expressed in terms of solely invariant problem instance parameters, and we also give one additional approximation ratio for the overall two-stage algorithm. The greedy algorithm of the first stage turned out to be essentially the same as the earlier known state-of-the-art algorithms for the set cover and dominating set problem Chv\\'atal \\cite{chvatal} and Parekh \\cite{parekh}. The second purification stage results in a significant reduction of the dominant set created at the first stage, in practice. The practical behavior of both stages was verified for randomly generated problem instances. The computational experiments emphasize the gap between a solution of Stage 1 and a solution of Stage 2. ",
    "url": "https://arxiv.org/abs/2207.04560",
    "authors": [
      "Frank Hernandez",
      "Ernesto Parra",
      "Jose Maria Sigarreta",
      "Nodari Vakhania"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2207.04567",
    "title": "A discontinuous Galerkin based multiscale method for heterogeneous  elastic wave equations",
    "abstract": "In this paper, we develop a local multiscale model reduction strategy for the elastic wave equation in strongly heterogeneous media, which is achieved by solving the problem in a coarse mesh with multiscale basis functions. We use the interior penalty discontinuous Galerkin (IPDG) to couple the multiscale basis functions that contain important heterogeneous media information. The construction of efficient multiscale basis functions starts with extracting dominant modes of carefully defined spectral problems to represent important media feature, which is followed by solving a constraint energy minimization problems. Then a Petrov-Galerkin projection and systematization onto the coarse grid is applied. As a result, an explicit and energy conserving scheme is obtained for fast online simulation. The method exhibits both coarse-mesh and spectral convergence as long as one appropriately chose the oversampling size. We rigorously analyze the stability and convergence of the proposed method. Numerical results are provided to show the performance of the multiscale method and confirm the theoretical results. ",
    "url": "https://arxiv.org/abs/2207.04567",
    "authors": [
      "Zhongqian Wang",
      "Shubin Fu",
      "Zishang Li",
      "Eric Chung"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2207.04581",
    "title": "How Robust is your Fair Model? Exploring the Robustness of Diverse  Fairness Strategies",
    "abstract": "With the introduction of machine learning in high-stakes decision making, ensuring algorithmic fairness has become an increasingly important problem to solve. In response to this, many mathematical definitions of fairness have been proposed, and a variety of optimisation techniques have been developed, all designed to maximise a defined notion of fairness. However, fair solutions are reliant on the quality of the training data, and can be highly sensitive to noise. Recent studies have shown that robustness (the ability for a model to perform well on unseen data) plays a significant role in the type of strategy that should be used when approaching a new problem and, hence, measuring the robustness of these strategies has become a fundamental problem. In this work, we therefore propose a new criterion to measure the robustness of various fairness optimisation strategies - the \\textit{robustness ratio}. We conduct multiple extensive experiments on five bench mark fairness data sets using three of the most popular fairness strategies with respect to four of the most popular definitions of fairness. Our experiments empirically show that fairness methods that rely on threshold optimisation are very sensitive to noise in all the evaluated data sets, despite mostly outperforming other methods. This is in contrast to the other two methods, which are less fair for low noise scenarios but fairer for high noise ones. To the best of our knowledge, we are the first to quantitatively evaluate the robustness of fairness optimisation strategies. This can potentially can serve as a guideline in choosing the most suitable fairness strategy for various data sets. ",
    "url": "https://arxiv.org/abs/2207.04581",
    "authors": [
      "Edward Small",
      "Wei Shao",
      "Zeliang Zhang",
      "Peihan Liu",
      "Jeffrey Chan",
      "Kacper Sokol",
      "Flora Salim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.04582",
    "title": "Numerical Approximations of the Allen-Cahn-Ohta-Kawasaki (ACOK) Equation  with Modified Physics Informed Neural Networks (PINNs)",
    "abstract": "The physics informed neural networks (PINNs) has been widely utilized to numerically approximate PDE problems. While PINNs has achieved good results in producing solutions for many partial differential equations, studies have shown that it does not perform well on phase field models. In this paper, we partially address this issue by introducing a modified physics informed neural networks. In particular, they are used to numerically approximate Allen-Cahn-Ohta-Kawasaki (ACOK) equation with a volume constraint. ",
    "url": "https://arxiv.org/abs/2207.04582",
    "authors": [
      "Jingjing Xu",
      "Jia Zhao",
      "Yanxiang Zhao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.04584",
    "title": "HEGrid: A High Efficient Multi-Channel Radio Astronomical Data Gridding  Framework in Heterogeneous Computing Environments",
    "abstract": "The challenge to fully exploit the potential of existing and upcoming scientific instruments like large single-dish radio telescopes is to process the collected massive data effectively and efficiently. As a \"quasi 2D stencil computation\" with the \"Moore neighborhood pattern,\" gridding is the most computationally intensive step in data reduction pipeline for radio astronomy studies, enabling astronomers to create correct sky images for further analysis. However, the existing gridding frameworks can either only run on multi-core CPU architecture or do not support high-concurrency, multi-channel data gridding. Their performance is then limited, and there are emerging needs for innovative gridding frameworks to process data from large single-dish radio telescopes like the Five-hundred-meter Aperture Spherical Telescope (FAST). To address those challenges, we developed a High Efficient Gridding framework, HEGrid, by overcoming the above limitations. Specifically, we propose and construct the gridding pipeline in heterogeneous computing environments and achieve multi-pipeline concurrency for high performance multi-channel processing. Furthermore, we propose pipeline-based co-optimization to alleviate the potential negative performance impact of possible intra- and inter-pipeline low computation and I/O utilization, including component share-based redundancy elimination, thread-level data reuse and overlapping I/O and computation. Our experiments are based on both simulated datasets and actual FAST observational datasets. The results show that HEGrid outperforms other state-of-the-art gridding frameworks by up to 5.5x and has robust hardware portability, including AMD Radeon Instinct GPU and NVIDIA GPU. ",
    "url": "https://arxiv.org/abs/2207.04584",
    "authors": [
      "Hao Wang",
      "Ce Yu",
      "Jian Xiao",
      "Shanjiang Tang",
      "Min Long",
      "Ming Zhu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2207.04585",
    "title": "A multi-level interpretable sleep stage scoring system by infusing  experts' knowledge into a deep network architecture",
    "abstract": "In recent years, deep learning has shown potential and efficiency in a wide area including computer vision, image and signal processing. Yet, translational challenges remain for user applications due to a lack of interpretability of algorithmic decisions and results. This black box problem is particularly problematic for high-risk applications such as medical-related decision-making. The current study goal was to design an interpretable deep learning system for time series classification of electroencephalogram (EEG) for sleep stage scoring as a step toward designing a transparent system. We have developed an interpretable deep neural network that includes a kernel-based layer based on a set of principles used for sleep scoring by human experts in the visual analysis of polysomnographic records. A kernel-based convolutional layer was defined and used as the first layer of the system and made available for user interpretation. The trained system and its results were interpreted in four levels from the microstructure of EEG signals, such as trained kernels and the effect of each kernel on the detected stages, to macrostructures, such as the transition between stages. The proposed system demonstrated greater performance than prior studies and the results of interpretation showed that the system learned information which was consistent with expert knowledge. ",
    "url": "https://arxiv.org/abs/2207.04585",
    "authors": [
      "Hamid Niknazar",
      "Sara C. Mednick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04602",
    "title": "Adaptive Fine-Grained Predicates Learning for Scene Graph Generation",
    "abstract": "The performance of current Scene Graph Generation (SGG) models is severely hampered by hard-to-distinguish predicates, e.g., woman-on/standing on/walking on-beach. As general SGG models tend to predict head predicates and re-balancing strategies prefer tail categories, none of them can appropriately handle hard-to-distinguish predicates. To tackle this issue, inspired by fine-grained image classification, which focuses on differentiating hard-to-distinguish objects, we propose an Adaptive Fine-Grained Predicates Learning (FGPL-A) which aims at differentiating hard-to-distinguish predicates for SGG. First, we introduce an Adaptive Predicate Lattice (PL-A) to figure out hard-to-distinguish predicates, which adaptively explores predicate correlations in keeping with model's dynamic learning pace. Practically, PL-A is initialized from SGG dataset, and gets refined by exploring model's predictions of current mini-batch. Utilizing PL-A, we propose an Adaptive Category Discriminating Loss (CDL-A) and an Adaptive Entity Discriminating Loss (EDL-A), which progressively regularize model's discriminating process with fine-grained supervision concerning model's dynamic learning status, ensuring balanced and efficient learning process. Extensive experimental results show that our proposed model-agnostic strategy significantly boosts performance of benchmark models on VG-SGG and GQA-SGG datasets by up to 175% and 76% on Mean Recall@100, achieving new state-of-the-art performance. Moreover, experiments on Sentence-to-Graph Retrieval and Image Captioning tasks further demonstrate practicability of our method. ",
    "url": "https://arxiv.org/abs/2207.04602",
    "authors": [
      "Xinyu Lyu",
      "Lianli Gao",
      "Pengpeng Zeng",
      "Heng Tao Shen",
      "Jingkuan Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.04614",
    "title": "Instance Shadow Detection with A Single-Stage Detector",
    "abstract": "This paper formulates a new problem, instance shadow detection, which aims to detect shadow instance and the associated object instance that cast each shadow in the input image. To approach this task, we first compile a new dataset with the masks for shadow instances, object instances, and shadow-object associations. We then design an evaluation metric for quantitative evaluation of the performance of instance shadow detection. Further, we design a single-stage detector to perform instance shadow detection in an end-to-end manner, where the bidirectional relation learning module and the deformable maskIoU head are proposed in the detector to directly learn the relation between shadow instances and object instances and to improve the accuracy of the predicted masks. Finally, we quantitatively and qualitatively evaluate our method on the benchmark dataset of instance shadow detection and show the applicability of our method on light direction estimation and photo editing. ",
    "url": "https://arxiv.org/abs/2207.04614",
    "authors": [
      "Tianyu Wang",
      "Xiaowei Hu",
      "Pheng-Ann Heng",
      "Chi-Wing Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2207.04622",
    "title": "Edge-preserving Near-light Photometric Stereo with Neural Surfaces",
    "abstract": "This paper presents a near-light photometric stereo method that faithfully preserves sharp depth edges in the 3D reconstruction. Unlike previous methods that rely on finite differentiation for approximating depth partial derivatives and surface normals, we introduce an analytically differentiable neural surface in near-light photometric stereo for avoiding differentiation errors at sharp depth edges, where the depth is represented as a neural function of the image coordinates. By further formulating the Lambertian albedo as a dependent variable resulting from the surface normal and depth, our method is insusceptible to inaccurate depth initialization. Experiments on both synthetic and real-world scenes demonstrate the effectiveness of our method for detailed shape recovery with edge preservation. ",
    "url": "https://arxiv.org/abs/2207.04622",
    "authors": [
      "Heng Guo",
      "Hiroaki Santo",
      "Boxin Shi",
      "Yasuyuki Matsushita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04623",
    "title": "Deep neural network based adaptive learning for switched systems",
    "abstract": "In this paper, we present a deep neural network based adaptive learning (DNN-AL) approach for switched systems. Currently, deep neural network based methods are actively developed for learning governing equations in unknown dynamic systems, but their efficiency can degenerate for switching systems, where structural changes exist at discrete time instants. In this new DNN-AL strategy, observed datasets are adaptively decomposed into subsets, such that no structural changes within each subset. During the adaptive procedures, DNNs are hierarchically constructed, and unknown switching time instants are gradually identified. Especially, network parameters at previous iteration steps are reused to initialize networks for the later iteration steps, which gives efficient training procedures for the DNNs. For the DNNs obtained through our DNN-AL, bounds of the prediction error are established. Numerical studies are conducted to demonstrate the efficiency of DNN-AL. ",
    "url": "https://arxiv.org/abs/2207.04623",
    "authors": [
      "Junjie He",
      "Zhihang Xu",
      "Qifeng Liao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.04639",
    "title": "A Dual-Polarization Information Guided Network for SAR Ship  Classification",
    "abstract": "How to fully utilize polarization to enhance synthetic aperture radar (SAR) ship classification remains an unresolved issue. Thus, we propose a dual-polarization information guided network (DPIG-Net) to solve it. ",
    "url": "https://arxiv.org/abs/2207.04639",
    "authors": [
      "Tianwen Zhang",
      "Xiaoling Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04646",
    "title": "DelightfulTTS 2: End-to-End Speech Synthesis with Adversarial  Vector-Quantized Auto-Encoders",
    "abstract": "Current text to speech (TTS) systems usually leverage a cascaded acoustic model and vocoder pipeline with mel-spectrograms as the intermediate representations, which suffer from two limitations: 1) the acoustic model and vocoder are separately trained instead of jointly optimized, which incurs cascaded errors; 2) the intermediate speech representations (e.g., mel-spectrogram) are pre-designed and lose phase information, which are sub-optimal. To solve these problems, in this paper, we develop DelightfulTTS 2, a new end-to-end speech synthesis system with automatically learned speech representations and jointly optimized acoustic model and vocoder. Specifically, 1) we propose a new codec network based on vector-quantized auto-encoders with adversarial training (VQ-GAN) to extract intermediate frame-level speech representations (instead of traditional representations like mel-spectrograms) and reconstruct speech waveform; 2) we jointly optimize the acoustic model (based on DelightfulTTS) and the vocoder (the decoder of VQ-GAN), with an auxiliary loss on the acoustic model to predict intermediate speech representations. Experiments show that DelightfulTTS 2 achieves a CMOS gain +0.14 over DelightfulTTS, and more method analyses further verify the effectiveness of the developed system. ",
    "url": "https://arxiv.org/abs/2207.04646",
    "authors": [
      "Yanqing Liu",
      "Ruiqing Xue",
      "Lei He",
      "Xu Tan",
      "Sheng Zhao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.04648",
    "title": "Learning Large-scale Universal User Representation with Sparse Mixture  of Experts",
    "abstract": "Learning user sequence behaviour embedding is very sophisticated and challenging due to the complicated feature interactions over time and high dimensions of user features. Recent emerging foundation models, e.g., BERT and its variants, encourage a large body of researchers to investigate in this field. However, unlike natural language processing (NLP) tasks, the parameters of user behaviour model come mostly from user embedding layer, which makes most existing works fail in training a universal user embedding of large scale. Furthermore, user representations are learned from multiple downstream tasks, and the past research work do not address the seesaw phenomenon. In this paper, we propose SUPERMOE, a generic framework to obtain high quality user representation from multiple tasks. Specifically, the user behaviour sequences are encoded by MoE transformer, and we can thus increase the model capacity to billions of parameters, or even to trillions of parameters. In order to deal with seesaw phenomenon when learning across multiple tasks, we design a new loss function with task indicators. We perform extensive offline experiments on public datasets and online experiments on private real-world business scenarios. Our approach achieves the best performance over state-of-the-art models, and the results demonstrate the effectiveness of our framework. ",
    "url": "https://arxiv.org/abs/2207.04648",
    "authors": [
      "Caigao Jiang",
      "Siqiao Xue",
      "James Zhang",
      "Lingyue Liu",
      "Zhibo Zhu",
      "Hongyan Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.04664",
    "title": "Robust finite element discretization and solvers for distributed  elliptic optimal control problems",
    "abstract": "We consider standard tracking-type, distributed elliptic optimal control problems with $L^2$ regularization, and their finite element discretization. We are investigating the $L^2$ error between the finite element approximation $u_{\\varrho h}$ of the state $u_\\varrho$ and the desired state (target) $\\bar{u}$ in terms of the regularization parameter $\\varrho$ and the mesh size $h$ that leads to the optimal choice $\\varrho = h^4$. It turns out that, for this choice of the regularization parameter, we can devise simple Jacobi-like preconditioned MINRES or Bramble-Pasciak CG methods that allow us to solve the reduced discrete optimality system in asymptotically optimal complexity with respect to the arithmetical operations and memory demand. The theoretical results are confirmed by several benchmark problems with targets of various regularities including discontinuous targets. ",
    "url": "https://arxiv.org/abs/2207.04664",
    "authors": [
      "Ulrich Langer",
      "Richard L\u00f6scher",
      "Olaf Steinbach",
      "Huidong Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2207.04674",
    "title": "CAMS: An Annotated Corpus for Causal Analysis of Mental Health Issues in  Social Media Posts",
    "abstract": "Research community has witnessed substantial growth in the detection of mental health issues and their associated reasons from analysis of social media. We introduce a new dataset for Causal Analysis of Mental health issues in Social media posts (CAMS). Our contributions for causal analysis are two-fold: causal interpretation and causal categorization. We introduce an annotation schema for this task of causal analysis. We demonstrate the efficacy of our schema on two different datasets: (i) crawling and annotating 3155 Reddit posts and (ii) re-annotating the publicly available SDCNL dataset of 1896 instances for interpretable causal analysis. We further combine these into the CAMS dataset and make this resource publicly available along with associated source code: https://github.com/drmuskangarg/CAMS. We present experimental results of models learned from CAMS dataset and demonstrate that a classic Logistic Regression model outperforms the next best (CNN-LSTM) model by 4.9\\% accuracy. ",
    "url": "https://arxiv.org/abs/2207.04674",
    "authors": [
      "Muskan Garg",
      "Chandni Saxena",
      "Veena Krishnan",
      "Ruchi Joshi",
      "Sriparna Saha",
      "Vijay Mago",
      "Bonnie J Dorr"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.04691",
    "title": "Performance Bounds for Cooperative Localisation in the Starlink Network",
    "abstract": "Mega-constellations in Low Earth Orbit have the potential to revolutionise worldwide internet access. The concomitant potential of these mega-constellations to impact space sustainability, however, has prompted concern from space actors as well as provoking concern in the ground-based astronomy community. Increasing the knowledge of the orbital state of satellites in mega-constellations improves space situations awareness, reducing the need for collision avoidance manoeuvres and allowing astronomers to prepare better observational mitigation strategies. In this paper, we create a model of Phase 1 of Starlink, one of the more well-studied megaconstellations, and investigate the potential of cooperative localisation using time-ofarrival measurements from the optical inter-satellite links in the constellation. To this end, we study the performance of any unbiased estimator for localisation, by calculating the instantaneous Cram$\\acute{\\text{e}}$r-Rao bound for two situations; one in which inter-satellite measurements and measurements from ground stations were considered, and one in which only relative navigation from inter-satellite measurements were considered. Our results show that localisation determined from a combination of inter-satellite measurements and ground stations can have at best an an average RMSE of approximately 10.15 metres over the majority of a satellite's orbit. Relative localisation using only inter-satellite measurements has a slightly poorer performance with an average RMSE of 10.68 metres. The results show that both anchored and anchorless inter-satellite cooperative localisation are dependent on the constellation's geometry and the characteristics of the inter-satellite links, both of which could inform the use of relative navigation in large satellite constellations in future. ",
    "url": "https://arxiv.org/abs/2207.04691",
    "authors": [
      "Calum Spring-Turner",
      "Raj Thilak Rajan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ]
  },
  {
    "id": "arXiv:2207.04692",
    "title": "PUF-Phenotype: A Robust and Noise-Resilient Approach to Aid  Intra-Group-based Authentication with DRAM-PUFs Using Machine Learning",
    "abstract": "As the demand for highly secure and dependable lightweight systems increases in the modern world, Physically Unclonable Functions (PUFs) continue to promise a lightweight alternative to high-cost encryption techniques and secure key storage. While the security features promised by PUFs are highly attractive for secure system designers, they have been shown to be vulnerable to various sophisticated attacks - most notably Machine Learning (ML) based modelling attacks (ML-MA) which attempt to digitally clone the PUF behaviour and thus undermine their security. More recent ML-MA have even exploited publicly known helper data required for PUF error correction in order to predict PUF responses without requiring knowledge of response data. In response to this, research is beginning to emerge regarding the authentication of PUF devices with the assistance of ML as opposed to traditional PUF techniques of storage and comparison of pre-known Challenge-Response pairs (CRPs). In this article, we propose a classification system using ML based on a novel `PUF-Phenotype' concept to accurately identify the origin and determine the validity of noisy memory derived (DRAM) PUF responses as an alternative to helper data-reliant denoising techniques. To our best knowledge, we are the first to perform classification over multiple devices per model to enable a group-based PUF authentication scheme. We achieve up to 98\\% classification accuracy using a modified deep convolutional neural network (CNN) for feature extraction in conjunction with several well-established classifiers. We also experimentally verified the performance of our model on a Raspberry Pi device to determine the suitability of deploying our proposed model in a resource-constrained environment. ",
    "url": "https://arxiv.org/abs/2207.04692",
    "authors": [
      "Owen Millwood",
      "Jack Miskelly",
      "Bohao Yang",
      "Prosanta Gope",
      "Elif Kavun",
      "Chenghua Lin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04693",
    "title": "Exploring Contextual Relationships for Cervical Abnormal Cell Detection",
    "abstract": "Cervical abnormal cell detection is a challenging task as the morphological differences between abnormal cells and normal cells are usually subtle. To determine whether a cervical cell is normal or abnormal, cytopathologists always take surrounding cells as references and make careful comparison to identify its abnormality. To mimic these clinical behaviors, we propose to explore contextual relationships to boost the performance of cervical abnormal cell detection. Specifically, both contextual relationships between cells and cell-to-global images are exploited to enhance features of each region of interest (RoI) proposals. Accordingly, two modules, termed as RoI-relationship attention module (RRAM) and global RoI attention module (GRAM) are developed and their combination strategies are also investigated. We setup strong baselines by using single-head or double-head Faster R-CNN with feature pyramid network (FPN) and integrate our RRAM and GRAM into them to validate the effectiveness of the proposed modules. Experiments conducted on a large cervical cell detection dataset consisting of 40,000 cytology images reveal that the introduction of RRAM and GRAM both achieves better average precision (AP) than the baseline methods. Moreover, when cascading RRAM and GRAM, our method outperforms the state-of-the-art (SOTA) methods. Furthermore, we also show the proposed feature enhancing scheme can facilitate the image-level and smear-level classification. The code and trained models are publicly available at https://github.com/CVIU-CSU/CR4CACD. ",
    "url": "https://arxiv.org/abs/2207.04693",
    "authors": [
      "Yixiong Liang",
      "Shuo Feng",
      "Qing Liu",
      "Hulin Kuang",
      "Liyan Liao",
      "Yun Du",
      "Nanying Che",
      "Jianfeng Liu",
      "Jianxin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04706",
    "title": "What Your Wearable Devices Revealed About You and Possibilities of  Non-Cooperative 802.11 Presence Detection During Your Last IPIN Visit",
    "abstract": "The focus on privacy-related measures regarding wireless networks grew in last couple of years. This is especially important with technologies like Wi-Fi or Bluetooth, which are all around us and our smartphones use them not just for connection to the internet or other devices, but for localization purposes as well. In this paper, we analyze and evaluate probe request frames of 802.11 wireless protocol captured during the 11th international conference on Indoor Positioning and Indoor Navigation (IPIN) 2021. We explore the temporal occupancy of the conference space during four days of the conference as well as non-cooperatively track the presence of devices in the proximity of the session rooms using 802.11 management frames, with and without using MAC address randomization. We carried out this analysis without trying to identify/reveal the identity of the users or in any way reverse the MAC address randomization. As a result of the analysis, we detected that there are still many devices not adopting MAC randomization, because either it is not implemented, or users disabled it. In addition, many devices can be easily tracked despite employing MAC randomization. ",
    "url": "https://arxiv.org/abs/2207.04706",
    "authors": [
      "Tomas Bravenec",
      "Joaqu\u00edn Torres-Sospedra",
      "Michael Gould",
      "Tomas Fryza"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.04709",
    "title": "A Baselined Gated Attention Recurrent Network for Request Prediction in  Ridesharing",
    "abstract": "Ridesharing has received global popularity due to its convenience and cost efficiency for both drivers and passengers and its strong potential to contribute to the implementation of the UN Sustainable Development Goals. As a result recent years have witnessed an explosion of research interest in the RSODP (Origin-Destination Prediction for Ridesharing) problem with the goal of predicting the future ridesharing requests and providing schedules for vehicles ahead of time. Most of existing prediction models utilise Deep Learning, however they fail to effectively consider both spatial and temporal dynamics. In this paper the Baselined Gated Attention Recurrent Network (BGARN), is proposed, which uses graph convolution with multi-head gated attention to extract spatial features, a recurrent module to extract temporal features, and a baselined transferring layer to calculate the final results. The model is implemented with PyTorch and DGL (Deep Graph Library) and is experimentally evaluated using the New York Taxi Demand Dataset. The results show that BGARN outperforms all the other existing models in terms of prediction accuracy. ",
    "url": "https://arxiv.org/abs/2207.04709",
    "authors": [
      "Jingran Shen",
      "Nikos Tziritas",
      "Georgios Theodoropoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2207.04713",
    "title": "GMN: Generative Multi-modal Network for Practical Document Information  Extraction",
    "abstract": "Document Information Extraction (DIE) has attracted increasing attention due to its various advanced applications in the real world. Although recent literature has already achieved competitive results, these approaches usually fail when dealing with complex documents with noisy OCR results or mutative layouts. This paper proposes Generative Multi-modal Network (GMN) for real-world scenarios to address these problems, which is a robust multi-modal generation method without predefined label categories. With the carefully designed spatial encoder and modal-aware mask module, GMN can deal with complex documents that are hard to serialized into sequential order. Moreover, GMN tolerates errors in OCR results and requires no character-level annotation, which is vital because fine-grained annotation of numerous documents is laborious and even requires annotators with specialized domain knowledge. Extensive experiments show that GMN achieves new state-of-the-art performance on several public DIE datasets and surpasses other methods by a large margin, especially in realistic scenes. ",
    "url": "https://arxiv.org/abs/2207.04713",
    "authors": [
      "Haoyu Cao",
      "Jiefeng Ma",
      "Antai Guo",
      "Yiqing Hu",
      "Hao Liu",
      "Deqiang Jiang",
      "Yinsong Liu",
      "Bo Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.04718",
    "title": "Physical Attack on Monocular Depth Estimation with Optimal Adversarial  Patches",
    "abstract": "Deep learning has substantially boosted the performance of Monocular Depth Estimation (MDE), a critical component in fully vision-based autonomous driving (AD) systems (e.g., Tesla and Toyota). In this work, we develop an attack against learning-based MDE. In particular, we use an optimization-based method to systematically generate stealthy physical-object-oriented adversarial patches to attack depth estimation. We balance the stealth and effectiveness of our attack with object-oriented adversarial design, sensitive region localization, and natural style camouflage. Using real-world driving scenarios, we evaluate our attack on concurrent MDE models and a representative downstream task for AD (i.e., 3D object detection). Experimental results show that our method can generate stealthy, effective, and robust adversarial patches for different target objects and models and achieves more than 6 meters mean depth estimation error and 93% attack success rate (ASR) in object detection with a patch of 1/9 of the vehicle's rear area. Field tests on three different driving routes with a real vehicle indicate that we cause over 6 meters mean depth estimation error and reduce the object detection rate from 90.70% to 5.16% in continuous video frames. ",
    "url": "https://arxiv.org/abs/2207.04718",
    "authors": [
      "Zhiyuan Cheng",
      "James Liang",
      "Hongjun Choi",
      "Guanhong Tao",
      "Zhiwen Cao",
      "Dongfang Liu",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04726",
    "title": "On the Convergence of the Backward Reachable Sets of Robust Controlled  Invariant Sets For Discrete-time Linear Systems",
    "abstract": "This paper considers discrete-time linear systems with bounded additive disturbances, and studies the convergence properties of the backward reachable sets of robust controlled invariant sets (RCIS). Under a simple condition, we prove that the backward reachable sets of an RCIS are guaranteed to converge to the maximal RCIS in Hausdorff distance, with an exponential convergence rate. When all sets are represented by polytopes, this condition can be checked numerically via a linear program. We discuss how the developed condition generalizes the existing conditions in the literature for (controlled) invariant sets of systems without disturbances (or without control inputs). ",
    "url": "https://arxiv.org/abs/2207.04726",
    "authors": [
      "Zexiang Liu",
      "Necmiye Ozay"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2207.04733",
    "title": "Collaborative Load Management in Smart Home Area Network",
    "abstract": "An efficient Home Area Network (HAN) acts as a base of an Advanced Metering Infrastructure (AMI). A HAN not only facilitates AMI with efficient real-time monitoring of the electricity consumption but also manages the load profile of the whole system. However, the existing works on implementing HAN are mostly centralized and suffer from well-known problems. In this work, we propose an IoT-based efficient decentralized strategy using synchronous transmission to practically realize HAN. An inter-device coordination strategy is proposed to minimize the peak load as well as reduce the sudden changes in the overall system without compromising the users requirements. Through experiments over IoT-testbeds, we demonstrate that the proposed strategy can reduce the peak load upto 50% and reduce the load variations upto 58% for even a high and random rate of requests for execution of power-hungry house appliances. ",
    "url": "https://arxiv.org/abs/2207.04733",
    "authors": [
      "Jagnyashini Debadarshini",
      "Sudipta Saha"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.04738",
    "title": "Robust Beamforming Design for IRS-Aided URLLC in D2D Networks",
    "abstract": "Intelligent reflecting surface (IRS) and device-to-device (D2D) communication are two promising technologies for improving transmission reliability between transceivers in communication systems. In this paper, we consider the design of reliable communication between the access point (AP) and actuators for a downlink multiuser multiple-input single-output (MISO) system in the industrial IoT (IIoT) scenario. We propose a two-stage protocol combining IRS with D2D communication so that all actuators can successfully receive the message from AP within a given delay. The superiority of the protocol is that the communication reliability between AP and actuators is doubly augmented by the IRS-aided first-stage transmission and the second-stage D2D transmission. A joint optimization problem of active and passive beamforming is formulated, which aims to maximize the number of actuators with successful decoding. We study the joint beamforming problem for cases where the channel state information (CSI) is perfect and imperfect. For each case, we develop efficient algorithms that include convergence and complexity analysis. Simulation results demonstrate the necessity and role of IRS with a well-optimized reflection matrix, and the D2D network in promoting reliable communication. Moreover, the proposed protocol can enable reliable communication even in the presence of stringent latency requirements and CSI estimation errors. ",
    "url": "https://arxiv.org/abs/2207.04738",
    "authors": [
      "Jing Cheng",
      "Chao Shen",
      "Zheng Chen",
      "Nikolaos Pappas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.04754",
    "title": "Snow Mask Guided Adaptive Residual Network for Image Snow Removal",
    "abstract": "Image restoration under severe weather is a challenging task. Most of the past works focused on removing rain and haze phenomena in images. However, snow is also an extremely common atmospheric phenomenon that will seriously affect the performance of high-level computer vision tasks, such as object detection and semantic segmentation. Recently, some methods have been proposed for snow removing, and most methods deal with snow images directly as the optimization object. However, the distribution of snow location and shape is complex. Therefore, failure to detect snowflakes / snow streak effectively will affect snow removing and limit the model performance. To solve these issues, we propose a Snow Mask Guided Adaptive Residual Network (SMGARN). Specifically, SMGARN consists of three parts, Mask-Net, Guidance-Fusion Network (GF-Net), and Reconstruct-Net. Firstly, we build a Mask-Net with Self-pixel Attention (SA) and Cross-pixel Attention (CA) to capture the features of snowflakes and accurately localized the location of the snow, thus predicting an accurate snow mask. Secondly, the predicted snow mask is sent into the specially designed GF-Net to adaptively guide the model to remove snow. Finally, an efficient Reconstruct-Net is used to remove the veiling effect and correct the image to reconstruct the final snow-free image. Extensive experiments show that our SMGARN numerically outperforms all existing snow removal methods, and the reconstructed images are clearer in visual contrast. All codes will be available. ",
    "url": "https://arxiv.org/abs/2207.04754",
    "authors": [
      "Bodong Cheng",
      "Juncheng Li",
      "Ying Chen",
      "Shuyi Zhang",
      "Tieyong Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04781",
    "title": "MT-Net Submission to the Waymo 3D Detection Leaderboard",
    "abstract": "In this technical report, we introduce our submission to the Waymo 3D Detection leaderboard. Our network is based on the Centerpoint architecture, but with significant improvements. We design a 2D backbone to utilize multi-scale features for better detecting objects with various sizes, together with an optimal transport-based target assignment strategy, which dynamically assigns richer supervision signals to the detection candidates. We also apply test-time augmentation and model-ensemble for further improvements. Our submission currently ranks 4th place with 78.45 mAPH on the Waymo 3D Detection leaderboard. ",
    "url": "https://arxiv.org/abs/2207.04781",
    "authors": [
      "Shaoxiang Chen",
      "Zequn Jie",
      "Xiaolin Wei",
      "Lin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04785",
    "title": "SALSA: Attacking Lattice Cryptography with Transformers",
    "abstract": "Currently deployed public-key cryptosystems will be vulnerable to attacks by full-scale quantum computers. Consequently, \"quantum resistant\" cryptosystems are in high demand, and lattice-based cryptosystems, based on a hard problem known as Learning With Errors (LWE), have emerged as strong contenders for standardization. In this work, we train transformers to perform modular arithmetic and combine half-trained models with statistical cryptanalysis techniques to propose SALSA: a machine learning attack on LWE-based cryptographic schemes. SALSA can fully recover secrets for small-to-mid size LWE instances with sparse binary secrets, and may scale to attack real-world LWE-based cryptosystems. ",
    "url": "https://arxiv.org/abs/2207.04785",
    "authors": [
      "Emily Wenger",
      "Mingjie Chen",
      "Fran\u00e7ois Charton",
      "Kristin Lauter"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04791",
    "title": "Leader-Follower Dynamics in Complex Obstacle Avoidance Task",
    "abstract": "A question that many researchers in social robotics are addressing is how to create more human-like behaviour in robots to make the collaboration between a human and a robot more intuitive to the human partner. In order to develop a human-like collaborative robotic system, however, human collaboration must first be better understood. Human collaboration is something we are all familiar with, however not that much is known about it from a kinematic standpoint. One dynamic that hasn't been researched thoroughly, yet naturally occurs in human collaboration, is for instance leader-follower dynamics. In our previous study, we tackled the question of leader-follower role allocation in human dyads during a collaborative reaching task, where the results implied that the subjects who performed higher in the individual experiment would naturally assume the role of a leader when in physical collaboration. In this study, we build upon the leader-follower role allocation study in human dyads by observing how the leader-follower dynamics change when the collaborative task becomes more complex. Here, the study was performed on a reaching task, where one subject in a dyad was faced with an additional task of obstacle avoidance when performing a 2D reaching task, while their partner was not aware of the obstacle. We have found that subjects change their roles throughout the task in order to complete it successfully, however looking at the overall task leader the higher-performing individual will always dominate over the lower-performing one, regardless of whether they are aware of the additional task of obstacle avoidance or not. ",
    "url": "https://arxiv.org/abs/2207.04791",
    "authors": [
      "Rebeka Kropiv\u0161ek Leskovar",
      "Jernej \u010camernik",
      "Tadej Petri\u010d"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.04806",
    "title": "Repairing Neural Networks by Leaving the Right Past Behind",
    "abstract": "Prediction failures of machine learning models often arise from deficiencies in training data, such as incorrect labels, outliers, and selection biases. However, such data points that are responsible for a given failure mode are generally not known a priori, let alone a mechanism for repairing the failure. This work draws on the Bayesian view of continual learning, and develops a generic framework for both, identifying training examples that have given rise to the target failure, and fixing the model through erasing information about them. This framework naturally allows leveraging recent advances in continual learning to this new problem of model repairment, while subsuming the existing works on influence functions and data deletion as specific instances. Experimentally, the proposed approach outperforms the baselines for both identification of detrimental training data and fixing model failures in a generalisable manner. ",
    "url": "https://arxiv.org/abs/2207.04806",
    "authors": [
      "Ryutaro Tanno",
      "Melanie F. Pradier",
      "Aditya Nori",
      "Yingzhen Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04809",
    "title": "Fingerprint Liveness Detection Based on Quality Measures",
    "abstract": "A new fingerprint parameterization for liveness detection based on quality measures is presented. The novel feature set is used in a complete liveness detection system and tested on the development set of the LivDET competition, comprising over 4,500 real and fake images acquired with three different optical sensors. The proposed solution proves to be robust to the multi-sensor scenario, and presents an overall rate of 93% of correctly classified samples. Furthermore, the liveness detection method presented has the added advantage over previously studied techniques of needing just one image from a finger to decide whether it is real or fake. ",
    "url": "https://arxiv.org/abs/2207.04809",
    "authors": [
      "Javier Galbally",
      "Fernando Alonso-Fernandez",
      "Julian Fierrez",
      "Javier Ortega-Garcia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.04812",
    "title": "A clinically motivated self-supervised approach for content-based image  retrieval of CT liver images",
    "abstract": "Deep learning-based approaches for content-based image retrieval (CBIR) of CT liver images is an active field of research, but suffers from some critical limitations. First, they are heavily reliant on labeled data, which can be challenging and costly to acquire. Second, they lack transparency and explainability, which limits the trustworthiness of deep CBIR systems. We address these limitations by (1) proposing a self-supervised learning framework that incorporates domain-knowledge into the training procedure and (2) providing the first representation learning explainability analysis in the context of CBIR of CT liver images. Results demonstrate improved performance compared to the standard self-supervised approach across several metrics, as well as improved generalisation across datasets. Further, we conduct the first representation learning explainability analysis in the context of CBIR, which reveals new insights into the feature extraction process. Lastly, we perform a case study with cross-examination CBIR that demonstrates the usability of our proposed framework. We believe that our proposed framework could play a vital role in creating trustworthy deep CBIR systems that can successfully take advantage of unlabeled data. ",
    "url": "https://arxiv.org/abs/2207.04812",
    "authors": [
      "Kristoffer Knutsen Wickstr\u00f8m",
      "Eirik Agnalt \u00d8stmo",
      "Keyur Radiya",
      "Karl \u00d8yvind Mikalsen",
      "Michael Christian Kampffmeyer",
      "Robert Jenssen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.04813",
    "title": "On the vulnerability of fingerprint verification systems to fake  fingerprint attacks",
    "abstract": "A new method to generate gummy fingers is presented. A medium-size fake fingerprint database is described and two different fingerprint verification systems are evaluated on it. Three different scenarios are considered in the experiments, namely: enrollment and test with real fingerprints, enrollment and test with fake fingerprints, and enrollment with real fingerprints and test with fake fingerprints. Results for an optical and a thermal sweeping sensors are given. Both systems are shown to be vulnerable to direct attacks. ",
    "url": "https://arxiv.org/abs/2207.04813",
    "authors": [
      "Javier Galbally",
      "Julian Fierrez-Aguilar",
      "Joaquin Rodriguez-Gonzalez",
      "Fernando Alonso-Fernandez",
      "Javier Ortega-Garcia",
      "Marino Tapiador"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.04814",
    "title": "High-Order Coupled Fully-Connected Tensor Network Decomposition for  Hyperspectral Image Super-Resolution",
    "abstract": "Hyperspectral image super-resolution addresses the problem of fusing a low-resolution hyperspectral image (LR-HSI) and a high-resolution multispectral image (HR-MSI) to produce a high-resolution hyperspectral image (HR-HSI). Tensor analysis has been proven to be an efficient method for hyperspectral image processing. However, the existing tensor-based methods of hyperspectral image super-resolution like the tensor train and tensor ring decomposition only establish an operation between adjacent two factors and are highly sensitive to the permutation of tensor modes, leading to an inadequate and inflexible representation. In this paper, we propose a novel method for hyperspectral image super-resolution by utilizing the specific properties of high-order tensors in fully-connected tensor network decomposition. The proposed method first tensorizes the target HR-HSI into a high-order tensor that has multiscale spatial structures. Then, a coupled fully-connected tensor network decomposition model is proposed to fuse the corresponding high-order tensors of LR-HSI and HR-MSI. Moreover, a weighted-graph regularization is imposed on the spectral core tensors to preserve spectral information. In the proposed model, the superiorities of the fully-connected tensor network decomposition lie in the outstanding capability for characterizing adequately the intrinsic correlations between any two modes of tensors and the essential invariance for transposition. Experimental results on three data sets show the effectiveness of the proposed approach as compared to other hyperspectral image super-resolution methods. ",
    "url": "https://arxiv.org/abs/2207.04814",
    "authors": [
      "Diyi Jin",
      "Jianjun Liu",
      "Jinlong Yang",
      "Zebin Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.04818",
    "title": "Cross-modal Prototype Driven Network for Radiology Report Generation",
    "abstract": "Radiology report generation (RRG) aims to describe automatically a radiology image with human-like language and could potentially support the work of radiologists, reducing the burden of manual reporting. Previous approaches often adopt an encoder-decoder architecture and focus on single-modal feature learning, while few studies explore cross-modal feature interaction. Here we propose a Cross-modal PROtotype driven NETwork (XPRONET) to promote cross-modal pattern learning and exploit it to improve the task of radiology report generation. This is achieved by three well-designed, fully differentiable and complementary modules: a shared cross-modal prototype matrix to record the cross-modal prototypes; a cross-modal prototype network to learn the cross-modal prototypes and embed the cross-modal information into the visual and textual features; and an improved multi-label contrastive loss to enable and enhance multi-label prototype learning. XPRONET obtains substantial improvements on the IU-Xray and MIMIC-CXR benchmarks, where its performance exceeds recent state-of-the-art approaches by a large margin on IU-Xray and comparable performance on MIMIC-CXR. ",
    "url": "https://arxiv.org/abs/2207.04818",
    "authors": [
      "Jun Wang",
      "Abhir Bhalerao",
      "Yulan He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.04820",
    "title": "Assessing Ranking and Effectiveness of Evolutionary Algorithm  Hyperparameters Using Global Sensitivity Analysis Methodologies",
    "abstract": "We present a comprehensive global sensitivity analysis of two single-objective and two multi-objective state-of-the-art global optimization evolutionary algorithms as an algorithm configuration problem. That is, we investigate the quality of influence hyperparameters have on the performance of algorithms in terms of their direct effect and interaction effect with other hyperparameters. Using three sensitivity analysis methods, Morris LHS, Morris, and Sobol, to systematically analyze tunable hyperparameters of covariance matrix adaptation evolutionary strategy, differential evolution, non-dominated sorting genetic algorithm III, and multi-objective evolutionary algorithm based on decomposition, the framework reveals the behaviors of hyperparameters to sampling methods and performance metrics. That is, it answers questions like what hyperparameters influence patterns, how they interact, how much they interact, and how much their direct influence is. Consequently, the ranking of hyperparameters suggests their order of tuning, and the pattern of influence reveals the stability of the algorithms. ",
    "url": "https://arxiv.org/abs/2207.04820",
    "authors": [
      "Varun Ojha",
      "Jon Timmis",
      "Giuseppe Nicosia"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.04821",
    "title": "Long-term Reproducibility for Neural Architecture Search",
    "abstract": "It is a sad reflection of modern academia that code is often ignored after publication -- there is no academic 'kudos' for bug fixes / maintenance. Code is often unavailable or, if available, contains bugs, is incomplete, or relies on out-of-date / unavailable libraries. This has a significant impact on reproducibility and general scientific progress. Neural Architecture Search (NAS) is no exception to this, with some prior work in reproducibility. However, we argue that these do not consider long-term reproducibility issues. We therefore propose a checklist for long-term NAS reproducibility. We evaluate our checklist against common NAS approaches along with proposing how we can retrospectively make these approaches more long-term reproducible. ",
    "url": "https://arxiv.org/abs/2207.04821",
    "authors": [
      "David Towers",
      "Matthew Forshaw",
      "Amir Atapour-Abarghouei",
      "Andrew Stephen McGough"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04829",
    "title": "Low-complexity Joint Phase Adjustment and Receive Beamforming for  Directional Modulation Networks via IRS",
    "abstract": "Intelligent reflecting surface (IRS) is a revolutionary and low-cost technology for boosting the spectrum and energy efficiencies in future wireless communication network. In order to create controllable multipath transmission in the conventional line-of-sight (LOS) wireless communication environment, an IRS-aided directional modulation (DM) network is considered. In this paper, to improve the transmission security of the system and maximize the receive power sum (Max-RPS), two alternately optimizing schemes of jointly designing receive beamforming (RBF) vectors and IRS phase shift matrix (PSM) are proposed: Max-RPS using general alternating optimization (Max-RPS-GAO) algorithm and Max-RPS using zero-forcing (Max-RPS-ZF) algorithm. Simulation results show that, compared with the no-IRS-assisted scheme and the no-PSM optimization scheme, the proposed IRS-assisted Max-RPS-GAO method and Max-RPS-ZF method can significantly improve the secrecy rate (SR) performance of the DM system. Moreover, compared with the Max-RPS-GAO method, the proposed Max-RPS-ZF method has a faster convergence speed and a certain lower computational complexity. ",
    "url": "https://arxiv.org/abs/2207.04829",
    "authors": [
      "Rongen Dong",
      "Shaohua Jiang",
      "Xinhai Hua",
      "Yin Teng",
      "Feng Shu",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.04843",
    "title": "Statistical Detection of Adversarial examples in Blockchain-based  Federated Forest In-vehicle Network Intrusion Detection Systems",
    "abstract": "The internet-of-Vehicle (IoV) can facilitate seamless connectivity between connected vehicles (CV), autonomous vehicles (AV), and other IoV entities. Intrusion Detection Systems (IDSs) for IoV networks can rely on machine learning (ML) to protect the in-vehicle network from cyber-attacks. Blockchain-based Federated Forests (BFFs) could be used to train ML models based on data from IoV entities while protecting the confidentiality of the data and reducing the risks of tampering with the data. However, ML models created this way are still vulnerable to evasion, poisoning, and exploratory attacks using adversarial examples. This paper investigates the impact of various possible adversarial examples on the BFF-IDS. We proposed integrating a statistical detector to detect and extract unknown adversarial samples. By including the unknown detected samples into the dataset of the detector, we augment the BFF-IDS with an additional model to detect original known attacks and the new adversarial inputs. The statistical adversarial detector confidently detected adversarial examples at the sample size of 50 and 100 input samples. Furthermore, the augmented BFF-IDS (BFF-IDS(AUG)) successfully mitigates the adversarial examples with more than 96% accuracy. With this approach, the model will continue to be augmented in a sandbox whenever an adversarial sample is detected and subsequently adopt the BFF-IDS(AUG) as the active security model. Consequently, the proposed integration of the statistical adversarial detector and the subsequent augmentation of the BFF-IDS with detected adversarial samples provides a sustainable security framework against adversarial examples and other unknown attacks. ",
    "url": "https://arxiv.org/abs/2207.04843",
    "authors": [
      "Ibrahim Aliyu",
      "Selinde van Engelenburg",
      "Muhammed Bashir Muazu",
      "Jinsul Kim",
      "Chang Gyoon Lim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.04857",
    "title": "Emergence of Novelty in Evolutionary Algorithms",
    "abstract": "One of the main problems of evolutionary algorithms is the convergence of the population to local minima. In this paper, we explore techniques that can avoid this problem by encouraging a diverse behavior of the agents through a shared reward system. The rewards are randomly distributed in the environment, and the agents are only rewarded for collecting them first. This leads to an emergence of a novel behavior of the agents. We introduce our approach to the maze problem and compare it to the previously proposed solution, denoted as Novelty Search (Lehman and Stanley, 2011a). We find that our solution leads to an improved performance while being significantly simpler. Building on that, we generalize the problem and apply our approach to a more advanced set of tasks, Atari Games, where we observe a similar performance quality with much less computational power needed. ",
    "url": "https://arxiv.org/abs/2207.04857",
    "authors": [
      "David Herel",
      "Dominika Zogatova",
      "Matej Kripner",
      "Tomas Mikolov"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04860",
    "title": "Risk assessment and optimal allocation of security measures under  stealthy false data injection attacks",
    "abstract": "This paper firstly addresses the problem of risk assessment under false data injection attacks on uncertain control systems. We consider an adversary with complete system knowledge, injecting stealthy false data into an uncertain control system. We then use the Value-at-Risk to characterize the risk associated with the attack impact caused by the adversary. The worst-case attack impact is characterized by the recently proposed output-to-output gain. We observe that the risk assessment problem corresponds to an infinite non-convex robust optimization problem. To this end, we use dissipative system theory and the scenario approach to approximate the risk-assessment problem into a convex problem and also provide probabilistic certificates on approximation. Secondly, we consider the problem of security measure allocation. We consider an operator with a constraint on the security budget. Under this constraint, we propose an algorithm to optimally allocate the security measures using the calculated risk such that the resulting Value-at-risk is minimized. Finally, we illustrate the results through a numerical example. The numerical example also illustrates that the security allocation using the Value-at-risk, and the impact on the nominal system may have different outcomes: thereby depicting the benefit of using risk metrics. ",
    "url": "https://arxiv.org/abs/2207.04860",
    "authors": [
      "Sribalaji C. Anand",
      "Andr\u00e9 M. H. Teixeira",
      "Anders Ahl\u00e9n"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2207.04866",
    "title": "Bayesian Optimization-based Nonlinear Adaptive PID Controller Design for  Robust Mobile Manipulation",
    "abstract": "In this paper, we propose to use a nonlinear adaptive PID controller to regulate the joint variables of a mobile manipulator. The motion of the mobile base forces undue disturbances on the joint controllers of the manipulator. In designing a conventional PID controller, one should make a trade-off between the performance and agility of the closed-loop system and its stability margins. The proposed nonlinear adaptive PID controller provides a mechanism to relax the need for such a compromise by adapting the gains according to the magnitude of the error without expert tuning. Therefore, we can achieve agile performance for the system while seeing damped overshoot in the output and track the reference as close as possible, even in the presence of external disturbances and uncertainties in the modeling of the system. We have employed a Bayesian optimization approach to choose the parameters of a nonlinear adaptive PID controller to achieve the best performance in tracking the reference input and rejecting disturbances. The results demonstrate that a well-designed nonlinear adaptive PID controller can effectively regulate a mobile manipulator's joint variables while carrying an unspecified heavy load and an abrupt base movement occurs. ",
    "url": "https://arxiv.org/abs/2207.04866",
    "authors": [
      "Hadi Hajieghrary",
      "Marc Peter Deisenroth",
      "Yasemin Bekiroglu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.04874",
    "title": "Hebbian Continual Representation Learning",
    "abstract": "Continual Learning aims to bring machine learning into a more realistic scenario, where tasks are learned sequentially and the i.i.d. assumption is not preserved. Although this setting is natural for biological systems, it proves very difficult for machine learning models such as artificial neural networks. To reduce this performance gap, we investigate the question whether biologically inspired Hebbian learning is useful for tackling continual challenges. In particular, we highlight a realistic and often overlooked unsupervised setting, where the learner has to build representations without any supervision. By combining sparse neural networks with Hebbian learning principle, we build a simple yet effective alternative (HebbCL) to typical neural network models trained via the gradient descent. Due to Hebbian learning, the network have easily interpretable weights, which might be essential in critical application such as security or healthcare. We demonstrate the efficacy of HebbCL in an unsupervised learning setting applied to MNIST and Omniglot datasets. We also adapt the algorithm to the supervised scenario and obtain promising results in the class-incremental learning. ",
    "url": "https://arxiv.org/abs/2207.04874",
    "authors": [
      "Pawe\u0142 Morawiecki",
      "Andrii Krutsylo",
      "Maciej Wo\u0142czyk",
      "Marek \u015amieja"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04876",
    "title": "Structural Stability of Spiking Neural Networks",
    "abstract": "The past decades have witnessed an increasing interest in spiking neural networks (SNNs) due to their great potential of modeling time-dependent data. Many algorithms and techniques have been developed; however, theoretical understandings of many aspects of spiking neural networks are still cloudy. A recent work [Zhang et al. 2021] disclosed that typical SNNs could hardly withstand both internal and external perturbations due to their bifurcation dynamics and suggested that self-connection has to be added. In this paper, we investigate the theoretical properties of SNNs with self-connection, and develop an in-depth analysis on structural stability by specifying the lower and upper bounds of the maximum number of bifurcation solutions. Numerical experiments conducted on simulation and practical tasks demonstrate the effectiveness of the proposed results. ",
    "url": "https://arxiv.org/abs/2207.04876",
    "authors": [
      "G. Zhang",
      "S.-Q. Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04881",
    "title": "Simple and complex spiking neurons: perspectives and analysis in a  simple STDP scenario",
    "abstract": "Spiking neural networks (SNNs) are largely inspired by biology and neuroscience and leverage ideas and theories to create fast and efficient learning systems. Spiking neuron models are adopted as core processing units in neuromorphic systems because they enable event-based processing. The integrate-and-fire (I&F) models are often adopted, with the simple Leaky I&F (LIF) being the most used. The reason for adopting such models is their efficiency and/or biological plausibility. Nevertheless, rigorous justification for adopting LIF over other neuron models for use in artificial learning systems has not yet been studied. This work considers various neuron models in the literature and then selects computational neuron models that are single-variable, efficient, and display different types of complexities. From this selection, we make a comparative study of three simple I&F neuron models, namely the LIF, the Quadratic I&F (QIF) and the Exponential I&F (EIF), to understand whether the use of more complex models increases the performance of the system and whether the choice of a neuron model can be directed by the task to be completed. Neuron models are tested within an SNN trained with Spike-Timing Dependent Plasticity (STDP) on a classification task on the N-MNIST and DVS Gestures datasets. Experimental results reveal that more complex neurons manifest the same ability as simpler ones to achieve high levels of accuracy on a simple dataset (N-MNIST), albeit requiring comparably more hyper-parameter tuning. However, when the data possess richer Spatio-temporal features, the QIF and EIF neuron models steadily achieve better results. This suggests that accurately selecting the model based on the richness of the feature spectrum of the data could improve the whole system's performance. Finally, the code implementing the spiking neurons in the SpykeTorch framework is made publicly available. ",
    "url": "https://arxiv.org/abs/2207.04881",
    "authors": [
      "Davide Liberato Manna",
      "Alex Vicente Sola",
      "Paul Kirkland",
      "Trevor Bihl",
      "Gaetano Di Caterina"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04889",
    "title": "Linear Leaky-Integrate-and-Fire Neuron Model Based Spiking Neural  Networks and Its Mapping Relationship to Deep Neural Networks",
    "abstract": "Spiking neural networks (SNNs) are brain-inspired machine learning algorithms with merits such as biological plausibility and unsupervised learning capability. Previous works have shown that converting Artificial Neural Networks (ANNs) into SNNs is a practical and efficient approach for implementing an SNN. However, the basic principle and theoretical groundwork are lacking for training a non-accuracy-loss SNN. This paper establishes a precise mathematical mapping between the biological parameters of the Linear Leaky-Integrate-and-Fire model (LIF)/SNNs and the parameters of ReLU-AN/Deep Neural Networks (DNNs). Such mapping relationship is analytically proven under certain conditions and demonstrated by simulation and real data experiments. It can serve as the theoretical basis for the potential combination of the respective merits of the two categories of neural networks. ",
    "url": "https://arxiv.org/abs/2207.04889",
    "authors": [
      "Sijia Lu",
      "Feng Xu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04892",
    "title": "Adversarial Style Augmentation for Domain Generalized Urban-Scene  Segmentation",
    "abstract": "In this paper, we consider the problem of domain generalization in semantic segmentation, which aims to learn a robust model using only labeled synthetic (source) data. The model is expected to perform well on unseen real (target) domains. Our study finds that the image style variation can largely influence the model's performance and the style features can be well represented by the channel-wise mean and standard deviation of images. Inspired by this, we propose a novel adversarial style augmentation (AdvStyle) approach, which can dynamically generate hard stylized images during training and thus can effectively prevent the model from overfitting on the source domain. Specifically, AdvStyle regards the style feature as a learnable parameter and updates it by adversarial training. The learned adversarial style feature is used to construct an adversarial image for robust model training. AdvStyle is easy to implement and can be readily applied to different models. Experiments on two synthetic-to-real semantic segmentation benchmarks demonstrate that AdvStyle can significantly improve the model performance on unseen real domains and show that we can achieve the state of the art. Moreover, AdvStyle can be employed to domain generalized image classification and produces a clear improvement on the considered datasets. ",
    "url": "https://arxiv.org/abs/2207.04892",
    "authors": [
      "Zhun Zhong",
      "Yuyang Zhao",
      "Gim Hee Lee",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04900",
    "title": "UM4: Unified Multilingual Multiple Teacher-Student Model for  Zero-Resource Neural Machine Translation",
    "abstract": "Most translation tasks among languages belong to the zero-resource translation problem where parallel corpora are unavailable. Multilingual neural machine translation (MNMT) enables one-pass translation using shared semantic space for all languages compared to the two-pass pivot translation but often underperforms the pivot-based method. In this paper, we propose a novel method, named as Unified Multilingual Multiple teacher-student Model for NMT (UM4). Our method unifies source-teacher, target-teacher, and pivot-teacher models to guide the student model for the zero-resource translation. The source teacher and target teacher force the student to learn the direct source to target translation by the distilled knowledge on both source and target sides. The monolingual corpus is further leveraged by the pivot-teacher model to enhance the student model. Experimental results demonstrate that our model of 72 directions significantly outperforms previous methods on the WMT benchmark. ",
    "url": "https://arxiv.org/abs/2207.04900",
    "authors": [
      "Jian Yang",
      "Yuwei Yin",
      "Shuming Ma",
      "Dongdong Zhang",
      "Shuangzhi Wu",
      "Hongcheng Guo",
      "Zhoujun Li",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04906",
    "title": "High-resource Language-specific Training for Multilingual Neural Machine  Translation",
    "abstract": "Multilingual neural machine translation (MNMT) trained in multiple language pairs has attracted considerable attention due to fewer model parameters and lower training costs by sharing knowledge among multiple languages. Nonetheless, multilingual training is plagued by language interference degeneration in shared parameters because of the negative interference among different translation directions, especially on high-resource languages. In this paper, we propose the multilingual translation model with the high-resource language-specific training (HLT-MT) to alleviate the negative interference, which adopts the two-stage training with the language-specific selection mechanism. Specifically, we first train the multilingual model only with the high-resource pairs and select the language-specific modules at the top of the decoder to enhance the translation quality of high-resource directions. Next, the model is further trained on all available corpora to transfer knowledge from high-resource languages (HRLs) to low-resource languages (LRLs). Experimental results show that HLT-MT outperforms various strong baselines on WMT-10 and OPUS-100 benchmarks. Furthermore, the analytic experiments validate the effectiveness of our method in mitigating the negative interference in multilingual training. ",
    "url": "https://arxiv.org/abs/2207.04906",
    "authors": [
      "Jian Yang",
      "Yuwei Yin",
      "Shuming Ma",
      "Dongdong Zhang",
      "Zhoujun Li",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04907",
    "title": "A4T: Hierarchical Affordance Detection for Transparent Objects Depth  Reconstruction and Manipulation",
    "abstract": "Transparent objects are widely used in our daily lives and therefore robots need to be able to handle them. However, transparent objects suffer from light reflection and refraction, which makes it challenging to obtain the accurate depth maps required to perform handling tasks. In this paper, we propose a novel affordance-based framework for depth reconstruction and manipulation of transparent objects, named A4T. A hierarchical AffordanceNet is first used to detect the transparent objects and their associated affordances that encode the relative positions of an object's different parts. Then, given the predicted affordance map, a multi-step depth reconstruction method is used to progressively reconstruct the depth maps of transparent objects. Finally, the reconstructed depth maps are employed for the affordance-based manipulation of transparent objects. To evaluate our proposed method, we construct a real-world dataset TRANS-AFF with affordances and depth maps of transparent objects, which is the first of its kind. Extensive experiments show that our proposed methods can predict accurate affordance maps, and significantly improve the depth reconstruction of transparent objects compared to the state-of-the-art method, with the Root Mean Squared Error in meters significantly decreased from 0.097 to 0.042. Furthermore, we demonstrate the effectiveness of our proposed method with a series of robotic manipulation experiments on transparent objects. See supplementary video and results at https://sites.google.com/view/affordance4trans. ",
    "url": "https://arxiv.org/abs/2207.04907",
    "authors": [
      "Jiaqi Jiang",
      "Guanqun Cao",
      "Thanh-Toan Do",
      "Shan Luo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.04908",
    "title": "Detection of Condensed Vehicle Gas Exhaust in LiDAR Point Clouds",
    "abstract": "LiDAR sensors used in autonomous driving applications are negatively affected by adverse weather conditions. One common, but understudied effect, is the condensation of vehicle gas exhaust in cold weather. This everyday phenomenon can severely impact the quality of LiDAR measurements, resulting in a less accurate environment perception by creating artifacts like ghost object detections. In the literature, the semantic segmentation of adverse weather effects like rain and fog is achieved using learning-based approaches. However, such methods require large sets of labeled data, which can be extremely expensive and laborious to get. We address this problem by presenting a two-step approach for the detection of condensed vehicle gas exhaust. First, we identify for each vehicle in a scene its emission area and detect gas exhaust if present. Then, isolated clouds are detected by modeling through time the regions of space where gas exhaust is likely to be present. We test our method on real urban data, showing that our approach can reliably detect gas exhaust in different scenarios, making it appealing for offline pre-labeling and online applications such as ghost object detection. ",
    "url": "https://arxiv.org/abs/2207.04908",
    "authors": [
      "Aldi Piroli",
      "Vinzenz Dallabetta",
      "Marc Walessa",
      "Daniel Meissner",
      "Johannes Kopp",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04911",
    "title": "CougaR: Fast and Eclipse-Resilient Dissemination for Blockchain Networks",
    "abstract": "Despite their development for over a decade, a key problem blockchains are still facing is scalability in terms of throughput, typically limited to a few transactions per second. A fundamental factor limiting this metric is the propagation latency of blocks through the underlying peer-to-peer network, which is typically constructed by means of random connectivity. Disseminating blocks fast improves not only the transaction throughput, but also the security of the system as it reduces the probability of forks. In this paper we present CougaR: a simple yet efficient, eclipse-resistant, decentralized protocol that substantially reduces the block dissemination time in blockchain networks. CougaR's key advantages stem from its link selection policy, which combines a network latency criterion with randomness to offer fast and reliable block dissemination to the entire network. Moreover, CougaR is eclipse-resistant by design, as nodes are protected from having all their links directly or indirectly imposed on them by others, which is the typical vulnerability exploited to deploy eclipse attacks. We rigorously evaluate CougaR by an extensive set of experiments, both against a wide spectrum of parameter settings, and in comparison to the current state of the art. ",
    "url": "https://arxiv.org/abs/2207.04911",
    "authors": [
      "Evangelos Kolyvas",
      "Spyros Voulgaris"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.04913",
    "title": "Generalizing to Unseen Domains with Wasserstein Distributional  Robustness under Limited Source Knowledge",
    "abstract": "Domain generalization aims at learning a universal model that performs well on unseen target domains, incorporating knowledge from multiple source domains. In this research, we consider the scenario where different domain shifts occur among conditional distributions of different classes across domains. When labeled samples in the source domains are limited, existing approaches are not sufficiently robust. To address this problem, we propose a novel domain generalization framework called Wasserstein Distributionally Robust Domain Generalization (WDRDG), inspired by the concept of distributionally robust optimization. We encourage robustness over conditional distributions within class-specific Wasserstein uncertainty sets and optimize the worst-case performance of a classifier over these uncertainty sets. We further develop a test-time adaptation module leveraging optimal transport to quantify the relationship between the unseen target domain and source domains to make adaptive inference for target data. Experiments on the Rotated MNIST, PACS and the VLCS datasets demonstrate that our method could effectively balance the robustness and discriminability in challenging generalization scenarios. ",
    "url": "https://arxiv.org/abs/2207.04913",
    "authors": [
      "Jingge Wang",
      "Liyan Xie",
      "Yao Xie",
      "Shao-Lun Huang",
      "Yang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04950",
    "title": "Neural and gpc operator surrogates: construction and expression rate  bounds",
    "abstract": "Approximation rates are analyzed for deep surrogates of maps between infinite-dimensional function spaces, arising e.g. as data-to-solution maps of linear and nonlinear partial differential equations. Specifically, we study approximation rates for Deep Neural Operator and Generalized Polynomial Chaos (gpc) Operator surrogates for nonlinear, holomorphic maps between infinite-dimensional, separable Hilbert spaces. Operator in- and outputs from function spaces are assumed to be parametrized by stable, affine representation systems. Admissible representation systems comprise orthonormal bases, Riesz bases or suitable tight frames of the spaces under consideration. Algebraic expression rate bounds are established for both, deep neural and gpc operator surrogates acting in scales of separable Hilbert spaces containing domain and range of the map to be expressed, with finite Sobolev or Besov regularity. We illustrate the abstract concepts by expression rate bounds for the coefficient-to-solution map for a linear elliptic PDE on the torus. ",
    "url": "https://arxiv.org/abs/2207.04950",
    "authors": [
      "Lukas Herrmann",
      "Christoph Schwab",
      "Jakob Zech"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04955",
    "title": "Fair Throughput Optimization with a Dynamic Network of Drone Relays",
    "abstract": "Aiding the ground cellular network with aerial base stations carried by drones has experienced an intensive raise of interest in the past years. Reconfigurable air-to-ground channels enable aerial stations to enhance users access links by means of seeking good line-of-sight connectivity while hovering in the air. In this paper, we propose an analytical framework for the 3D placement of a fleet of coordinated drone relays. This framework optimizes network performance in terms of user throughput fairness, expressed through the {\\alpha}-fairness metric. The optimization problem is formulated as a mixed-integer non-convex program, which is intractable. Hence, we propose an extremal-optimization-based algorithm, Parallelized Alpha-fair Drone Deployment, that solves the problem online, in low-degree polynomial time. We evaluate our proposal by means of numerical simulations over the real topology of a dense city. We discuss the advantages of integrating drone relay stations in current networks and test several resource scheduling approaches in both static and dynamic scenarios, including with progressively larger and denser crowds. ",
    "url": "https://arxiv.org/abs/2207.04955",
    "authors": [
      "Edgar Arribas",
      "Vincenzo Mancuso",
      "Vicent Cholvi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.04974",
    "title": "Sparsifying Binary Networks",
    "abstract": "Binary neural networks (BNNs) have demonstrated their ability to solve complex tasks with comparable accuracy as full-precision deep neural networks (DNNs), while also reducing computational power and storage requirements and increasing the processing speed. These properties make them an attractive alternative for the development and deployment of DNN-based applications in Internet-of-Things (IoT) devices. Despite the recent improvements, they suffer from a fixed and limited compression factor that may result insufficient for certain devices with very limited resources. In this work, we propose sparse binary neural networks (SBNNs), a novel model and training scheme which introduces sparsity in BNNs and a new quantization function for binarizing the network's weights. The proposed SBNN is able to achieve high compression factors and it reduces the number of operations and parameters at inference time. We also provide tools to assist the SBNN design, while respecting hardware resource constraints. We study the generalization properties of our method for different compression factors through a set of experiments on linear and convolutional networks on three datasets. Our experiments confirm that SBNNs can achieve high compression rates, without compromising generalization, while further reducing the operations of BNNs, making SBNNs a viable option for deploying DNNs in cheap, low-cost, limited-resources IoT devices and sensors. ",
    "url": "https://arxiv.org/abs/2207.04974",
    "authors": [
      "Riccardo Schiavone",
      "Maria A. Zuluaga"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04978",
    "title": "Wave-ViT: Unifying Wavelet and Transformers for Visual Representation  Learning",
    "abstract": "Multi-scale Vision Transformer (ViT) has emerged as a powerful backbone for computer vision tasks, while the self-attention computation in Transformer scales quadratically w.r.t. the input patch number. Thus, existing solutions commonly employ down-sampling operations (e.g., average pooling) over keys/values to dramatically reduce the computational cost. In this work, we argue that such over-aggressive down-sampling design is not invertible and inevitably causes information dropping especially for high-frequency components in objects (e.g., texture details). Motivated by the wavelet theory, we construct a new Wavelet Vision Transformer (\\textbf{Wave-ViT}) that formulates the invertible down-sampling with wavelet transforms and self-attention learning in a unified way. This proposal enables self-attention learning with lossless down-sampling over keys/values, facilitating the pursuing of a better efficiency-vs-accuracy trade-off. Furthermore, inverse wavelet transforms are leveraged to strengthen self-attention outputs by aggregating local contexts with enlarged receptive field. We validate the superiority of Wave-ViT through extensive experiments over multiple vision tasks (e.g., image recognition, object detection and instance segmentation). Its performances surpass state-of-the-art ViT backbones with comparable FLOPs. Source code is available at \\url{https://github.com/YehLi/ImageNetModel}. ",
    "url": "https://arxiv.org/abs/2207.04978",
    "authors": [
      "Ting Yao",
      "Yingwei Pan",
      "Yehao Li",
      "Chong-Wah Ngo",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04979",
    "title": "Start Small, Think Big: On Hyperparameter Optimization for Large-Scale  Knowledge Graph Embeddings",
    "abstract": "Knowledge graph embedding (KGE) models are an effective and popular approach to represent and reason with multi-relational data. Prior studies have shown that KGE models are sensitive to hyperparameter settings, however, and that suitable choices are dataset-dependent. In this paper, we explore hyperparameter optimization (HPO) for very large knowledge graphs, where the cost of evaluating individual hyperparameter configurations is excessive. Prior studies often avoided this cost by using various heuristics; e.g., by training on a subgraph or by using fewer epochs. We systematically discuss and evaluate the quality and cost savings of such heuristics and other low-cost approximation techniques. Based on our findings, we introduce GraSH, an efficient multi-fidelity HPO algorithm for large-scale KGEs that combines both graph and epoch reduction techniques and runs in multiple rounds of increasing fidelities. We conducted an experimental study and found that GraSH obtains state-of-the-art results on large graphs at a low cost (three complete training runs in total). ",
    "url": "https://arxiv.org/abs/2207.04979",
    "authors": [
      "Adrian Kochsiek",
      "Fritz Niesel",
      "Rainer Gemulla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.04993",
    "title": "Embedding Recycling for Language Models",
    "abstract": "Training and inference with large neural models is expensive. However, for many application domains, while new tasks and models arise frequently, the underlying documents being modeled remain mostly unchanged. We study how to decrease computational cost in such settings through embedding recycling (ER): re-using activations from previous model runs when performing training or inference. In contrast to prior work focusing on freezing small classification heads for finetuning which often leads to notable drops in performance, we propose caching an intermediate layer's output from a pretrained model and finetuning the remaining layers for new tasks. We show that our method provides a 100% speedup during training and a 55-86% speedup for inference, and has negligible impacts on accuracy for text classification and entity recognition tasks in the scientific domain. For general-domain question answering tasks, ER offers a similar speedup and lowers accuracy by a small amount. Finally, we identify several open challenges and future directions for ER. ",
    "url": "https://arxiv.org/abs/2207.04993",
    "authors": [
      "Jon Saad-Falcon",
      "Amanpreet Singh",
      "Luca Soldaini",
      "Mike D'Arcy",
      "Arman Cohan",
      "Doug Downey"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.04997",
    "title": "A Closer Look at Invariances in Self-supervised Pre-training for 3D  Vision",
    "abstract": "Self-supervised pre-training for 3D vision has drawn increasing research interest in recent years. In order to learn informative representations, a lot of previous works exploit invariances of 3D features, \\eg, perspective-invariance between views of the same scene, modality-invariance between depth and RGB images, format-invariance between point clouds and voxels. Although they have achieved promising results, previous researches lack a systematic and fair comparison of these invariances. To address this issue, our work, for the first time, introduces a unified framework, under which various pre-training methods can be investigated. We conduct extensive experiments and provide a closer look at the contributions of different invariances in 3D pre-training. Also, we propose a simple but effective method that jointly pre-trains a 3D encoder and a depth map encoder using contrastive learning. Models pre-trained with our method gain significant performance boost in downstream tasks. For instance, a pre-trained VoteNet outperforms previous methods on SUN RGB-D and ScanNet object detection benchmarks with a clear margin. ",
    "url": "https://arxiv.org/abs/2207.04997",
    "authors": [
      "Lanxiao Li",
      "Michael Heizmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05006",
    "title": "TASKOGRAPHY: Evaluating robot task planning over large 3D scene graphs",
    "abstract": "3D scene graphs (3DSGs) are an emerging description; unifying symbolic, topological, and metric scene representations. However, typical 3DSGs contain hundreds of objects and symbols even for small environments; rendering task planning on the full graph impractical. We construct TASKOGRAPHY, the first large-scale robotic task planning benchmark over 3DSGs. While most benchmarking efforts in this area focus on vision-based planning, we systematically study symbolic planning, to decouple planning performance from visual representation learning. We observe that, among existing methods, neither classical nor learning-based planners are capable of real-time planning over full 3DSGs. Enabling real-time planning demands progress on both (a) sparsifying 3DSGs for tractable planning and (b) designing planners that better exploit 3DSG hierarchies. Towards the former goal, we propose SCRUB, a task-conditioned 3DSG sparsification method; enabling classical planners to match and in some cases surpass state-of-the-art learning-based planners. Towards the latter goal, we propose SEEK, a procedure enabling learning-based planners to exploit 3DSG structure, reducing the number of replanning queries required by current best approaches by an order of magnitude. We will open-source all code and baselines to spur further research along the intersections of robot task planning, learning and 3DSGs. ",
    "url": "https://arxiv.org/abs/2207.05006",
    "authors": [
      "Christopher Agia",
      "Krishna Murthy Jatavallabhula",
      "Mohamed Khodeir",
      "Ondrej Miksik",
      "Vibhav Vineet",
      "Mustafa Mukadam",
      "Liam Paull",
      "Florian Shkurti"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05009",
    "title": "A Learned Radiance-Field Representation for Complex Luminaires",
    "abstract": "We propose an efficient method for rendering complex luminaires using a high-quality octree-based representation of the luminaire emission. Complex luminaires are a particularly challenging problem in rendering, due to their caustic light paths inside the luminaire. We reduce the geometric complexity of luminaires by using a simple proxy geometry and encode the visually-complex emitted light field by using a neural radiance field. We tackle the multiple challenges of using NeRFs for representing luminaires, including their high dynamic range, high-frequency content and null-emission areas, by proposing a specialized loss function. For rendering, we distill our luminaires' NeRF into a Plenoctree, which we can be easily integrated into traditional rendering systems. Our approach allows for speed-ups of up to 2 orders of magnitude in scenes containing complex luminaires introducing minimal error. ",
    "url": "https://arxiv.org/abs/2207.05009",
    "authors": [
      "Jorge Condor",
      "Adri\u00e1n Jarabo"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.05027",
    "title": "Unsupervised Semantic Segmentation with Self-supervised Object-centric  Representations",
    "abstract": "In this paper, we show that recent advances in self-supervised feature learning enable unsupervised object discovery and semantic segmentation with a performance that matches the state of the field on supervised semantic segmentation 10 years ago. We propose a methodology based on unsupervised saliency masks and self-supervised feature clustering to kickstart object discovery followed by training a semantic segmentation network on pseudo-labels to bootstrap the system on images with multiple objects. We present results on PASCAL VOC that go far beyond the current state of the art (47.3 mIoU), and we report for the first time results on MS COCO for the whole set of 81 classes: our method discovers 34 categories with more than $20\\%$ IoU, while obtaining an average IoU of 19.6 for all 81 categories. ",
    "url": "https://arxiv.org/abs/2207.05027",
    "authors": [
      "Andrii Zadaianchuk",
      "Matthaeus Kleindessner",
      "Yi Zhu",
      "Francesco Locatello",
      "Thomas Brox"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04130",
    "title": "Multi-view Attention for gestational age at birth prediction",
    "abstract": "We present our method for gestational age at birth prediction for the SLCN (surface learning for clinical neuroimaging) challenge. Our method is based on a multi-view shape analysis technique that captures 2D renderings of a 3D object from different viewpoints. We render the brain features on the surface of the sphere and then the 2D images are analyzed via 2D CNNs and an attention layer for the regression task. The regression task achieves a MAE of 1.637 +- 1.3 on the Native space and MAE of 1.38 +- 1.14 on the template space. The source code for this project is available in our github repository https://github.com/MathieuLeclercq/SLCN_challenge_UNC ",
    "url": "https://arxiv.org/abs/2207.04130",
    "authors": [
      "Mathieu Leclercq",
      "Martin Styner",
      "Juan Carlos Prieto"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04248",
    "title": "A Statistically-Based Approach to Feedforward Neural Network Model  Selection",
    "abstract": "Feedforward neural networks (FNNs) can be viewed as non-linear regression models, where covariates enter the model through a combination of weighted summations and non-linear functions. Although these models have some similarities to the models typically used in statistical modelling, the majority of neural network research has been conducted outside of the field of statistics. This has resulted in a lack of statistically-based methodology, and, in particular, there has been little emphasis on model parsimony. Determining the input layer structure is analogous to variable selection, while the structure for the hidden layer relates to model complexity. In practice, neural network model selection is often carried out by comparing models using out-of-sample performance. However, in contrast, the construction of an associated likelihood function opens the door to information-criteria-based variable and architecture selection. A novel model selection method, which performs both input- and hidden-node selection, is proposed using the Bayesian information criterion (BIC) for FNNs. The choice of BIC over out-of-sample performance as the model selection objective function leads to an increased probability of recovering the true model, while parsimoniously achieving favourable out-of-sample performance. Simulation studies are used to evaluate and justify the proposed method, and applications on real data are investigated. ",
    "url": "https://arxiv.org/abs/2207.04248",
    "authors": [
      "Andrew McInerney",
      "Kevin Burke"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04333",
    "title": "Emerging Patterns in the Continuum Representation of Protein-Lipid  Fingerprints",
    "abstract": "Capturing intricate biological phenomena often requires multiscale modeling where coarse and inexpensive models are developed using limited components of expensive and high-fidelity models. Here, we consider such a multiscale framework in the context of cancer biology and address the challenge of evaluating the descriptive capabilities of a continuum model developed using 1-dimensional statistics from a molecular dynamics model. Using deep learning, we develop a highly predictive classification model that identifies complex and emergent behavior from the continuum model. With over 99.9% accuracy demonstrated for two simulations, our approach confirms the existence of protein-specific \"lipid fingerprints\", i.e. spatial rearrangements of lipids in response to proteins of interest. Through this demonstration, our model also provides external validation of the continuum model, affirms the value of such multiscale modeling, and can foster new insights through further analysis of these fingerprints. ",
    "url": "https://arxiv.org/abs/2207.04333",
    "authors": [
      "Konstantia Georgouli",
      "Helgi I Ing\u00f3lfsson",
      "Fikret Aydin",
      "Mark Heimann",
      "Felice C Lightstone",
      "Peer-Timo Bremer",
      "Harsh Bhatia"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04345",
    "title": "Segmentation of Blood Vessels, Optic Disc Localization, Detection of  Exudates and Diabetic Retinopathy Diagnosis from Digital Fundus Images",
    "abstract": "Diabetic Retinopathy (DR) is a complication of long-standing, unchecked diabetes and one of the leading causes of blindness in the world. This paper focuses on improved and robust methods to extract some of the features of DR, viz. Blood Vessels and Exudates. Blood vessels are segmented using multiple morphological and thresholding operations. For the segmentation of exudates, k-means clustering and contour detection on the original images are used. Extensive noise reduction is performed to remove false positives from the vessel segmentation algorithm's results. The localization of Optic Disc using k-means clustering and template matching is also performed. Lastly, this paper presents a Deep Convolutional Neural Network (DCNN) model with 14 Convolutional Layers and 2 Fully Connected Layers, for the automatic, binary diagnosis of DR. The vessel segmentation, optic disc localization and DCNN achieve accuracies of 95.93%, 98.77% and 75.73% respectively. The source code and pre-trained model are available https://github.com/Sohambasu07/DR_2021 ",
    "url": "https://arxiv.org/abs/2207.04345",
    "authors": [
      "Soham Basu",
      "Sayantan Mukherjee",
      "Ankit Bhattacharya",
      "Anindya Sen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04514",
    "title": "Large independent sets in Markov random graphs",
    "abstract": "Computing the maximum size of an independent set in a graph is a famously hard combinatorial problem. There have been many analyses for the classical binomial random graph model of Erd\\\"os-R\\'enyi-Gilbert and as a result, tight asymptotic bounds are known for these graphs. However, this classical model does not capture any dependency structure between edges that is widely prevalent in real-world networks. We initiate study in this direction by considering random graphs whose existence of edges is determined by a Markov process that is also governed by a decay parameter $\\delta\\in(0,1]$. We prove that the maximum size of an independent set in such an $n$-vertex random graph is with high probability lower bounded by $(\\frac{1-\\delta}{2+\\epsilon}) \\pi(n)$ for arbitrary $\\epsilon > 0$, where $\\pi(n)$ is the prime-counting function, and upper bounded by $c_{\\delta} n$, where $c_{\\delta} := e^{-\\delta} + \\delta/10$ is an explicit constant. Since our random graph model collapses to the classical binomial random graph model when there is no decay (i.e., $\\delta=1$) and the latter are known to have independent sets roughly be of size no more than $\\log{n}$, it follows from our lower bound that having even the slightest bit of dependency in the random graph construction leads to the presence of large independent sets and thus our random model has a phase transition at its boundary value. We also prove that a greedy algorithm for finding a maximal independent set gives w.h.p. an output of size $\\Omega(n^{1/(1+\\tau)})$ where $\\tau=\\lceil 1/(1-\\delta) \\rceil$. ",
    "url": "https://arxiv.org/abs/2207.04514",
    "authors": [
      "Akshay Gupte",
      "Yiran Zhu"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2207.04540",
    "title": "Multi-Frequency Information Enhanced Channel Attention Module for  Speaker Representation Learning",
    "abstract": "Recently, attention mechanisms have been applied successfully in neural network-based speaker verification systems. Incorporating the Squeeze-and-Excitation block into convolutional neural networks has achieved remarkable performance. However, it uses global average pooling (GAP) to simply average the features along time and frequency dimensions, which is incapable of preserving sufficient speaker information in the feature maps. In this study, we show that GAP is a special case of a discrete cosine transform (DCT) on time-frequency domain mathematically using only the lowest frequency component in frequency decomposition. To strengthen the speaker information extraction ability, we propose to utilize multi-frequency information and design two novel and effective attention modules, called Single-Frequency Single-Channel (SFSC) attention module and Multi-Frequency Single-Channel (MFSC) attention module. The proposed attention modules can effectively capture more speaker information from multiple frequency components on the basis of DCT. We conduct comprehensive experiments on the VoxCeleb datasets and a probe evaluation on the 1st 48-UTD forensic corpus. Experimental results demonstrate that our proposed SFSC and MFSC attention modules can efficiently generate more discriminative speaker representations and outperform ResNet34-SE and ECAPA-TDNN systems with relative 20.9% and 20.2% reduction in EER, without adding extra network parameters. ",
    "url": "https://arxiv.org/abs/2207.04540",
    "authors": [
      "Mufan Sang",
      "John H.L. Hansen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2207.04565",
    "title": "Automating Detection of Papilledema in Pediatric Fundus Images with  Explainable Machine Learning",
    "abstract": "Papilledema is an ophthalmic neurologic disorder in which increased intracranial pressure leads to swelling of the optic nerves. Undiagnosed papilledema in children may lead to blindness and may be a sign of life-threatening conditions, such as brain tumors. Robust and accurate clinical diagnosis of this syndrome can be facilitated by automated analysis of fundus images using deep learning, especially in the presence of challenges posed by pseudopapilledema that has similar fundus appearance but distinct clinical implications. We present a deep learning-based algorithm for the automatic detection of pediatric papilledema. Our approach is based on optic disc localization and detection of explainable papilledema indicators through data augmentation. Experiments on real-world clinical data demonstrate that our proposed method is effective with a diagnostic accuracy comparable to expert ophthalmologists. ",
    "url": "https://arxiv.org/abs/2207.04565",
    "authors": [
      "Kleanthis Avramidis",
      "Mohammad Rostami",
      "Melinda Chang",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04589",
    "title": "Learned Video Compression via Heterogeneous Deformable Compensation  Network",
    "abstract": "Learned video compression has recently emerged as an essential research topic in developing advanced video compression technologies, where motion compensation is considered one of the most challenging issues. In this paper, we propose a learned video compression framework via heterogeneous deformable compensation strategy (HDCVC) to tackle the problems of unstable compression performance caused by single-size deformable kernels in downsampled feature domain. More specifically, instead of utilizing optical flow warping or single-size-kernel deformable alignment, the proposed algorithm extracts features from the two adjacent frames to estimate content-adaptive heterogeneous deformable (HetDeform) kernel offsets. Then we transform the reference features with the HetDeform convolution to accomplish motion compensation. Moreover, we design a Spatial-Neighborhood-Conditioned Divisive Normalization (SNCDN) to achieve more effective data Gaussianization combined with the Generalized Divisive Normalization. Furthermore, we propose a multi-frame enhanced reconstruction module for exploiting context and temporal information for final quality enhancement. Experimental results indicate that HDCVC achieves superior performance than the recent state-of-the-art learned video compression approaches. ",
    "url": "https://arxiv.org/abs/2207.04589",
    "authors": [
      "Huairui Wang",
      "Zhenzhong Chen",
      "Chang Wen Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.04710",
    "title": "Weighted simplicial complexes and their representation power of  higher-order network data and topology",
    "abstract": "Hypergraphs and simplical complexes both capture the higher-order interactions of complex systems, ranging from higher-order collaboration networks to brain networks. One open problem in the field is what should drive the choice of the adopted mathematical framework to describe higher-order networks starting from data of higher-order interactions. Unweighted simplicial complexes typically involve a loss of information of the data, though having the benefit to capture the higher-order topology of the data. In this work we show that weighted simplicial complexes allow to circumvent all the limitations of unweighted simplicial complexes to represent higher-order interactions. In particular, weighted simplicial complexes can represent higher-order networks without loss of information, allowing at the same time to capture the weighted topology of the data. The higher-order topology is probed by studying the spectral properties of suitably defined weighted Hodge Laplacians displaying a normalized spectrum. The higher-order spectrum of (weighted) normalized Hodge Laplacians is here studied combining cohomology theory with information theory. In the proposed framework, we quantify and compare the information content of higher-order spectra of different dimension using higher-order spectral entropies and spectral relative entropies. The proposed methodology is tested on real higher-order collaboration networks and on the weighted version of the simplicial complex model \"Network Geometry with Flavor\". ",
    "url": "https://arxiv.org/abs/2207.04710",
    "authors": [
      "Federica Baccini",
      "Filippo Geraci",
      "Ginestra Bianconi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.04717",
    "title": "Analysis of risk propagation using the world trade network",
    "abstract": "An economic system is an exemplar of a complex system in which all agents interact simultaneously. Interactions between countries have generally been studied using the flow of resources across diverse trade networks, in which the degree of dependence between two countries is typically measured based on the trade volume. However, indirect influences may not be immediately apparent. Herein, we compared a direct trade network to a trade network constructed using the personalized PageRank (PPR) encompassing indirect influences. By analyzing the correlation of the gross domestic product (GDP) between countries, we discovered that the PPR trade network has greater explanatory power on the propagation of economic events than direct trade by analyzing the GDP correlation between countries. To further validate our observations, an agent-based model of the spreading economic crisis was implemented for the Russia-Ukraine war of 2022. The model also demonstrates that the PPR explains the actual impact more effectively than the direct trade network. Our research highlights the significance of indirect and long-range relationships, which have often been overlooked ",
    "url": "https://arxiv.org/abs/2207.04717",
    "authors": [
      "Sungyong Kim",
      "Jinhyuk Yun"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.04749",
    "title": "DeepSNR: A deep learning foundation for offline gravitational wave  detection",
    "abstract": "All scientific claims of gravitational wave discovery to date rely on the offline statistical analysis of candidate observations in order to quantify significance relative to background processes. The current foundation in such offline detection pipelines in experiments at LIGO is the matched-filter algorithm, which produces a signal-to-noise-ratio-based statistic for ranking candidate observations. Existing deep-learning-based attempts to detect gravitational waves, which have shown promise in both signal sensitivity and computational efficiency, output probability scores. However, probability scores are not easily integrated into discovery workflows, limiting the use of deep learning thus far to non-discovery-oriented applications. In this paper, the Deep Learning Signal-to-Noise Ratio (DeepSNR) detection pipeline, which uses a novel method for generating a signal-to-noise ratio ranking statistic from deep learning classifiers, is introduced, providing the first foundation for the use of deep learning algorithms in discovery-oriented pipelines. The performance of DeepSNR is demonstrated by identifying binary black hole merger candidates versus noise sources in open LIGO data from the first observation run. High-fidelity simulations of the LIGO detector responses are used to present the first sensitivity estimates of deep learning models in terms of physical observables. The robustness of DeepSNR under various experimental considerations is also investigated. The results pave the way for DeepSNR to be used in the scientific discovery of gravitational waves and rare signals in broader contexts, potentially enabling the detection of fainter signals and never-before-observed phenomena. ",
    "url": "https://arxiv.org/abs/2207.04749",
    "authors": [
      "Michael Andrews",
      "Manfred Paulini",
      "Luke Sellers",
      "Alexey Bobrick",
      "Gianni Martire",
      "Haydn Vestal"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04869",
    "title": "Graph-based Molecular Representation Learning",
    "abstract": "Molecular representation learning (MRL) is a key step to build the connection between machine learning and chemical science. In particular, it encodes molecules as numerical vectors preserving the molecular structures and features, on top of which the downstream tasks (e.g., property prediction) can be performed. Recently, MRL has achieved considerable progress, especially in deep molecular graph learning-based methods. In this survey, we systematically review these graph-based molecular representation techniques. Specifically, we first introduce the data and features of the 2D and 3D graph molecular datasets. Then we summarize the methods specially designed for MRL and categorize them into four strategies. Furthermore, we discuss some typical chemical applications supported by MRL. To facilitate studies in this fast-developing area, we also list the benchmarks and commonly used datasets in the paper. Finally, we share our thoughts on future research directions. ",
    "url": "https://arxiv.org/abs/2207.04869",
    "authors": [
      "Zhichun Guo",
      "Bozhao Nan",
      "Yijun Tian",
      "Olaf Wiest",
      "Chuxu Zhang",
      "Nitesh V. Chawla"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04878",
    "title": "Stacked Autoencoder Based Multi-Omics Data Integration for Cancer  Survival Prediction",
    "abstract": "Cancer survival prediction is important for developing personalized treatments and inducing disease-causing mechanisms. Multi-omics data integration is attracting widespread interest in cancer research for providing information for understanding cancer progression at multiple genetic levels. Many works, however, are limited because of the high dimensionality and heterogeneity of multi-omics data. In this paper, we propose a novel method to integrate multi-omics data for cancer survival prediction, called Stacked AutoEncoder-based Survival Prediction Neural Network (SAEsurv-net). In the cancer survival prediction for TCGA cases, SAEsurv-net addresses the curse of dimensionality with a two-stage dimensionality reduction strategy and handles multi-omics heterogeneity with a stacked autoencoder model. The two-stage dimensionality reduction strategy achieves a balance between computation complexity and information exploiting. The stacked autoencoder model removes most heterogeneities such as data's type and size in the first group of autoencoders, and integrates multiple omics data in the second autoencoder. The experiments show that SAEsurv-net outperforms models based on a single type of data as well as other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2207.04878",
    "authors": [
      "Xing Wu",
      "Qiulian Fang"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2207.04890",
    "title": "The Mean Dimension of Neural Networks -- What causes the interaction  effects?",
    "abstract": "Owen and Hoyt recently showed that the effective dimension offers key structural information about the input-output mapping underlying an artificial neural network. Along this line of research, this work proposes an estimation procedure that allows the calculation of the mean dimension from a given dataset, without resampling from external distributions. The design yields total indices when features are independent and a variant of total indices when features are correlated. We show that this variant possesses the zero independence property. With synthetic datasets, we analyse how the mean dimension evolves layer by layer and how the activation function impacts the magnitude of interactions. We then use the mean dimension to study some of the most widely employed convolutional architectures for image recognition (LeNet, ResNet, DenseNet). To account for pixel correlations, we propose calculating the mean dimension after the addition of an inverse PCA layer that allows one to work on uncorrelated PCA-transformed features, without the need to retrain the neural network. We use the generalized total indices to produce heatmaps for post-hoc explanations, and we employ the mean dimension on the PCA-transformed features for cross comparisons of the artificial neural networks structures. Results provide several insights on the difference in magnitude of interactions across the architectures, as well as indications on how the mean dimension evolves during training. ",
    "url": "https://arxiv.org/abs/2207.04890",
    "authors": [
      "Roman Hahn",
      "Christoph Feinauer",
      "Emanuele Borgonovo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04932",
    "title": "On the Stochastic Gradient Descent and Inverse Variance-flatness  Relation in Artificial Neural Networks",
    "abstract": "Stochastic gradient descent (SGD), a widely used algorithm in deep-learning neural networks has attracted continuing studies for the theoretical principles behind its success. A recent work uncovered a generic inverse variance-flatness (IVF) relation between the variance of neural weights and the landscape flatness of loss function near solutions under SGD [Feng & Tu, PNAS 118,0027 (2021)]. To investigate this seemly violation of statistical principle, we deploy a stochastic decomposition to analyze the dynamical properties of SGD. The method constructs the true \"energy\" function which can be used by Boltzmann distribution. The new energy differs from the usual cost function and explains the IVF relation under SGD. We further verify the scaling relation identified in Feng's work. Our approach may bridge the gap between the classical statistical mechanics and the emerging discipline of artificial intelligence, with potential for better algorithm to the latter. ",
    "url": "https://arxiv.org/abs/2207.04932",
    "authors": [
      "Xia Xiong",
      "Yong-Cong Chen",
      "Chunxiao Shi",
      "Ping Ao"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04949",
    "title": "pMCT: Patched Multi-Condition Training for Robust Speech Recognition",
    "abstract": "We propose a novel Patched Multi-Condition Training (pMCT) method for robust Automatic Speech Recognition (ASR). pMCT employs Multi-condition Audio Modification and Patching (MAMP) via mixing {\\it patches} of the same utterance extracted from clean and distorted speech. Training using patch-modified signals improves robustness of models in noisy reverberant scenarios. Our proposed pMCT is evaluated on the LibriSpeech dataset showing improvement over using vanilla Multi-Condition Training (MCT). For analyses on robust ASR, we employed pMCT on the VOiCES dataset which is a noisy reverberant dataset created using utterances from LibriSpeech. In the analyses, pMCT achieves 23.1% relative WER reduction compared to the MCT. ",
    "url": "https://arxiv.org/abs/2207.04949",
    "authors": [
      "Pablo Peso Parada",
      "Agnieszka Dobrowolska",
      "Karthikeyan Saravanan",
      "Mete Ozay"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2207.05013",
    "title": "Boosting Heterogeneous Catalyst Discovery by Structurally Constrained  Deep Learning Models",
    "abstract": "The discovery of new catalysts is one of the significant topics of computational chemistry as it has the potential to accelerate the adoption of renewable energy sources. Recently developed deep learning approaches such as graph neural networks (GNNs) open new opportunity to significantly extend scope for modelling novel high-performance catalysts. Nevertheless, the graph representation of particular crystal structure is not a straightforward task due to the ambiguous connectivity schemes and numerous embeddings of nodes and edges. Here we present embedding improvement for GNN that has been modified by Voronoi tesselation and is able to predict the energy of catalytic systems within Open Catalyst Project dataset. Enrichment of the graph was calculated via Voronoi tessellation and the corresponding contact solid angles and types (direct or indirect) were considered as features of edges and Voronoi volumes were used as node characteristics. The auxiliary approach was enriching node representation by intrinsic atomic properties (electronegativity, period and group position). Proposed modifications allowed us to improve the mean absolute error of the original model and the final error equals to 651 meV per atom on the Open Catalyst Project dataset and 6 meV per atom on the intermetallics dataset. Also, by consideration of additional dataset, we show that a sensible choice of data can decrease the error to values above physically-based 20 meV per atom threshold. ",
    "url": "https://arxiv.org/abs/2207.05013",
    "authors": [
      "Alexey N. Korovin",
      "Innokentiy S. Humonen",
      "Artem I. Samtsevich",
      "Roman A. Eremin",
      "Artem I. Vasilyev",
      "Vladimir D. Lazarev",
      "Semen A. Budennyy"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05046",
    "title": "Dynamic random graphs with vertex removal",
    "abstract": "We introduce and analyse a Dynamic Random Graph with Vertex Removal (DRGVR) defined as follows. At every step, with probability $p > 1/2$ a new vertex is introduced, and with probability $1-p$ a vertex, chosen uniformly at random among the present ones (if any), is removed from the graph together with all edges adjacent to it. In the former case, the new vertex connects by an edge to every other vertex with probability proportional to the number of vertices already present. We prove that the DRGVR converges to a local limit and determine this limit. Moreover, we analyse its component structure and distinguish a subcritical and a supercritical regime with respect to the existence of a giant component. As a byproduct of this analysis, we obtain upper and lower bounds for the critical parameter. Furthermore, we provide precise expression of the maximum degree (as well as in- and out-degree for a natural orientation of the DRGVR). Several concentration and stability results complete the study. ",
    "url": "https://arxiv.org/abs/2207.05046",
    "authors": [
      "Josep D\u00edaz",
      "Lyuben Lichev",
      "Bas Lodewijks"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:1904.07404",
    "title": "swTVM: Towards Optimized Tensor Code Generation for Deep Learning on  Sunway Many-Core Processor",
    "abstract": " Title: swTVM: Towards Optimized Tensor Code Generation for Deep Learning on  Sunway Many-Core Processor ",
    "url": "https://arxiv.org/abs/1904.07404",
    "authors": [
      "Mingzhen Li",
      "Changxi Liu",
      "Jianjin Liao",
      "Xuegui Zheng",
      "Hailong Yang",
      "Rujun Sun",
      "Jun Xu",
      "Lin Gan",
      "Guangwen Yang",
      "Zhongzhi Luan",
      "Depei Qian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1908.11221",
    "title": "Multi-Channel Deep Networks for Block-Based Image Compressive Sensing",
    "abstract": " Comments: 14 pages, 10 figures ",
    "url": "https://arxiv.org/abs/1908.11221",
    "authors": [
      "Siwang Zhou",
      "Yan He",
      "Yonghe Liu",
      "Chengqing Li",
      "Jianming Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1910.04183",
    "title": "Robust Dynamic Assortment Optimization in the Presence of Outlier  Customers",
    "abstract": " Title: Robust Dynamic Assortment Optimization in the Presence of Outlier  Customers ",
    "url": "https://arxiv.org/abs/1910.04183",
    "authors": [
      "Xi Chen",
      "Akshay Krishnamurthy",
      "Yining Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2002.05777",
    "title": "Semi-Structured Distributional Regression -- Extending Structured  Additive Models by Arbitrary Deep Neural Networks and Data Modalities",
    "abstract": " Title: Semi-Structured Distributional Regression -- Extending Structured  Additive Models by Arbitrary Deep Neural Networks and Data Modalities ",
    "url": "https://arxiv.org/abs/2002.05777",
    "authors": [
      "David R\u00fcgamer",
      "Chris Kolb",
      "Nadja Klein"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2008.08157",
    "title": "Heteroscedastic Uncertainty for Robust Generative Latent Dynamics",
    "abstract": " Comments: In IEEE Robotics and Automation Letters (RA-L) and presented at the IEEE International Conference on Intelligent Robots and Systems (IROS'20), Las Vegas, USA, October 25-29, 2020 ",
    "url": "https://arxiv.org/abs/2008.08157",
    "authors": [
      "Oliver Limoyo",
      "Bryan Chan",
      "Filip Mari\u0107",
      "Brandon Wagstaff",
      "Rupam Mahmood",
      "Jonathan Kelly"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2008.09864",
    "title": "Tackling Over-Smoothing for General Graph Convolutional Networks",
    "abstract": " Comments: Submitted to TPAMI, 15 pages ",
    "url": "https://arxiv.org/abs/2008.09864",
    "authors": [
      "Wenbing Huang",
      "Yu Rong",
      "Tingyang Xu",
      "Fuchun Sun",
      "Junzhou Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2009.00150",
    "title": "Exactly Optimal Bayesian Quickest Change Detection for Hidden Markov  Models",
    "abstract": " Title: Exactly Optimal Bayesian Quickest Change Detection for Hidden Markov  Models ",
    "url": "https://arxiv.org/abs/2009.00150",
    "authors": [
      "Jason J. Ford",
      "Jasmin James",
      "Timothy L. Molloy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2009.14393",
    "title": "TensorBNN: Bayesian Inference for Neural Networks using Tensorflow",
    "abstract": " Title: TensorBNN: Bayesian Inference for Neural Networks using Tensorflow ",
    "url": "https://arxiv.org/abs/2009.14393",
    "authors": [
      "Braden Kronheim",
      "Michelle Kuchera",
      "Harrison Prosper"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2010.10028",
    "title": "Towards an Ethical Framework in the Complex Digital Era",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2003.06530 ",
    "url": "https://arxiv.org/abs/2010.10028",
    "authors": [
      "David Pastor-Escuredo",
      "Ricardo Vinuesa"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2012.15685",
    "title": "A Survey on Deep Learning-based Single Image Crowd Counting: Network  Design, Loss Function and Supervisory Signal",
    "abstract": " Comments: Neurocomputing minor revision. Project page is at this https URL ",
    "url": "https://arxiv.org/abs/2012.15685",
    "authors": [
      "Haoyue Bai",
      "Jiageng Mao",
      "S.-H. Gary Chan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2101.00436",
    "title": "Baleen: Robust Multi-Hop Reasoning at Scale via Condensed Retrieval",
    "abstract": " Comments: NeurIPS 2021 (Spotlight) ",
    "url": "https://arxiv.org/abs/2101.00436",
    "authors": [
      "Omar Khattab",
      "Christopher Potts",
      "Matei Zaharia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2102.04270",
    "title": "Enabling Binary Neural Network Training on the Edge",
    "abstract": " Title: Enabling Binary Neural Network Training on the Edge ",
    "url": "https://arxiv.org/abs/2102.04270",
    "authors": [
      "Erwei Wang",
      "James J. Davis",
      "Daniele Moro",
      "Piotr Zielinski",
      "Jia Jie Lim",
      "Claudionor Coelho",
      "Satrajit Chatterjee",
      "Peter Y. K. Cheung",
      "George A. Constantinides"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2102.04341",
    "title": "Learned Camera Gain and Exposure Control for Improved Visual Feature  Detection and Matching",
    "abstract": " Comments: In IEEE Robotics and Automation Letters (RA-L) and presented at the IEEE International Conference on Robotics and Automation (ICRA'21), Xi'an, China, May 30-Jun. 5, 2021 ",
    "url": "https://arxiv.org/abs/2102.04341",
    "authors": [
      "Justin Tomasi",
      "Brandon Wagstaff",
      "Steven L. Waslander",
      "Jonathan Kelly"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2102.12238",
    "title": "Inductive Bias of Multi-Channel Linear Convolutional Networks with  Bounded Weight Norm",
    "abstract": " Comments: Appeared at COLT 2022 ",
    "url": "https://arxiv.org/abs/2102.12238",
    "authors": [
      "Meena Jagadeesan",
      "Ilya Razenshteyn",
      "Suriya Gunasekar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2103.14198",
    "title": "Exploiting Playbacks in Unsupervised Domain Adaptation for 3D Object  Detection",
    "abstract": " Comments: Accepted by ICRA 2022 ",
    "url": "https://arxiv.org/abs/2103.14198",
    "authors": [
      "Yurong You",
      "Carlos Andres Diaz-Ruiz",
      "Yan Wang",
      "Wei-Lun Chao",
      "Bharath Hariharan",
      "Mark Campbell",
      "Kilian Q Weinberger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.01214",
    "title": "Modeling Censored Mobility Demand through Quantile Regression Neural  Networks",
    "abstract": " Comments: 13 pages, 9 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2104.01214",
    "authors": [
      "Frederik Boe H\u00fcttel",
      "Inon Peled",
      "Filipe Rodrigues",
      "Francisco C. Pereira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2104.06401",
    "title": "Self-supervised object detection from audio-visual correspondence",
    "abstract": " Comments: Accepted to CVPR 2022 ",
    "url": "https://arxiv.org/abs/2104.06401",
    "authors": [
      "Triantafyllos Afouras",
      "Yuki M. Asano",
      "Francois Fagan",
      "Andrea Vedaldi",
      "Florian Metze"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.13482",
    "title": "Stochastic Neural Networks for Automatic Cell Tracking in Microscopy  Image Sequences of Bacterial Colonies",
    "abstract": " Comments: 35 pages, 8 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2104.13482",
    "authors": [
      "Sorena Sarmadi",
      "James J. Winkle",
      "Razan N. Alnahhas",
      "Matthew R. Bennett",
      "Kre\u0161imir Josi\u0107",
      "Andreas Mang",
      "Robert Azencott"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.12837",
    "title": "Fooling Partial Dependence via Data Poisoning",
    "abstract": " Comments: Accepted at ECML PKDD 2022 ",
    "url": "https://arxiv.org/abs/2105.12837",
    "authors": [
      "Hubert Baniecki",
      "Wojciech Kretowicz",
      "Przemyslaw Biecek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.04007",
    "title": "On the Coupling of Depth and Egomotion Networks for Self-Supervised  Structure from Motion",
    "abstract": " Comments: In IEEE Robotics and Automation Letters (RA-L) and presented at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS'22), Kyoto, Japan, Oct. 23-27, 2022 ",
    "url": "https://arxiv.org/abs/2106.04007",
    "authors": [
      "Brandon Wagstaff",
      "Valentin Peretroukhin",
      "Jonathan Kelly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2106.06927",
    "title": "Inverting Adversarially Robust Networks for Image Synthesis",
    "abstract": " Title: Inverting Adversarially Robust Networks for Image Synthesis ",
    "url": "https://arxiv.org/abs/2106.06927",
    "authors": [
      "Renan A. Rojas-Gomez",
      "Raymond A. Yeh",
      "Minh N. Do",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2106.15961",
    "title": "On Tree Equilibria in Max-Distance Network Creation Games",
    "abstract": " Title: On Tree Equilibria in Max-Distance Network Creation Games ",
    "url": "https://arxiv.org/abs/2106.15961",
    "authors": [
      "Qian Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2107.01999",
    "title": "FINT: Field-aware INTeraction Neural Network For CTR Prediction",
    "abstract": " Comments: 5 pages, accepted by ICASSP 2022 ",
    "url": "https://arxiv.org/abs/2107.01999",
    "authors": [
      "Zhishan Zhao",
      "Sen Yang",
      "Guohui Liu",
      "Dawei Feng",
      "Kele Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.13068",
    "title": "End-to-End Balancing for Causal Continuous Treatment-Effect Estimation",
    "abstract": " Comments: To be presented in ICML 2022 ",
    "url": "https://arxiv.org/abs/2107.13068",
    "authors": [
      "Mohammad Taha Bahadori",
      "Eric Tchetgen Tchetgen",
      "David E. Heckerman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2108.12851",
    "title": "Lower Bounds for the MMSE via Neural Network Estimation and Their  Applications to Privacy",
    "abstract": " Comments: 42 pages ",
    "url": "https://arxiv.org/abs/2108.12851",
    "authors": [
      "Mario Diaz",
      "Peter Kairouz",
      "Lalitha Sankar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2108.13097",
    "title": "A theory of representation learning in deep neural networks gives a deep  generalisation of kernel methods",
    "abstract": " Title: A theory of representation learning in deep neural networks gives a deep  generalisation of kernel methods ",
    "url": "https://arxiv.org/abs/2108.13097",
    "authors": [
      "Adam X. Yang",
      "Maxime Robeyns",
      "Edward Milsom",
      "Nandi Schoots",
      "Laurence Aitchison"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.10255",
    "title": "Multi-Task Learning with Sentiment, Emotion, and Target Detection to  Recognize Hate Speech and Offensive Language",
    "abstract": " Comments: publication at FIRE 2021 as system description paper in the HASOC-FIRE shared task on hate speech and offensive language detection. The original publication can be found at this http URL ",
    "url": "https://arxiv.org/abs/2109.10255",
    "authors": [
      "Flor Miriam Plaza-del-Arco",
      "Sercan Halat",
      "Sebastian Pad\u00f3",
      "Roman Klinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2110.13424",
    "title": "Phish-Defence: Phishing Detection Using Deep Recurrent Neural Networks",
    "abstract": " Comments: 9 pages, 10 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2110.13424",
    "authors": [
      "Aman Rangapur",
      "Tarun Kanakam",
      "Dr Ajith Jubilson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2110.13473",
    "title": "CTRN: Class-Temporal Relational Network for Action Detection",
    "abstract": " Title: CTRN: Class-Temporal Relational Network for Action Detection ",
    "url": "https://arxiv.org/abs/2110.13473",
    "authors": [
      "Rui Dai",
      "Srijan Das",
      "Francois Bremond"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.03438",
    "title": "IPAL: Breaking up Silos of Protocol-dependent and Domain-specific  Industrial Intrusion Detection Systems",
    "abstract": " Title: IPAL: Breaking up Silos of Protocol-dependent and Domain-specific  Industrial Intrusion Detection Systems ",
    "url": "https://arxiv.org/abs/2111.03438",
    "authors": [
      "Konrad Wolsing",
      "Eric Wagner",
      "Antoine Saillard",
      "Martin Henze"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2111.05408",
    "title": "Robust deep learning-based semantic organ segmentation in hyperspectral  images",
    "abstract": " Comments: The first two authors (Silvia Seidlitz and Jan Sellner) contributed equally to this paper ",
    "url": "https://arxiv.org/abs/2111.05408",
    "authors": [
      "Silvia Seidlitz",
      "Jan Sellner",
      "Jan Odenthal",
      "Berkin \u00d6zdemir",
      "Alexander Studier-Fischer",
      "Samuel Kn\u00f6dler",
      "Leonardo Ayala",
      "Tim J. Adler",
      "Hannes G. Kenngott",
      "Minu Tizabi",
      "Martin Wagner",
      "Felix Nickel",
      "Beat P. M\u00fcller-Stich",
      "Lena Maier-Hein"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.08974",
    "title": "Pedestrian Detection by Exemplar-Guided Contrastive Learning",
    "abstract": " Title: Pedestrian Detection by Exemplar-Guided Contrastive Learning ",
    "url": "https://arxiv.org/abs/2111.08974",
    "authors": [
      "Zebin Lin",
      "Wenjie Pei",
      "Fanglin Chen",
      "David Zhang",
      "Guangming Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.01759",
    "title": "NeRF-SR: High-Quality Neural Radiance Fields using Super-Sampling",
    "abstract": " Comments: Accepted to MM 2022. Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2112.01759",
    "authors": [
      "Chen Wang",
      "Xian Wu",
      "Yuan-Chen Guo",
      "Song-Hai Zhang",
      "Yu-Wing Tai",
      "Shi-Min Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2112.03212",
    "title": "Physically Consistent Neural Networks for building thermal modeling:  theory and analysis",
    "abstract": " Comments: Preprint submitted to Applied Energy. 13 pages in the main text + 5 in appendix, 11 figures ",
    "url": "https://arxiv.org/abs/2112.03212",
    "authors": [
      "Loris Di Natale",
      "Bratislav Svetozarevic",
      "Philipp Heer",
      "Colin N. Jones"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2112.04108",
    "title": "Fully Attentional Network for Semantic Segmentation",
    "abstract": " Comments: Accepted by AAAI 2022 ",
    "url": "https://arxiv.org/abs/2112.04108",
    "authors": [
      "Qi Song",
      "Jie Li",
      "Chenghong Li",
      "Hao Guo",
      "Rui Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.05935",
    "title": "Nonsmooth Control Barrier Function Design of Continuous Constraints for  Network Connectivity Maintenance",
    "abstract": " Comments: submitted to Automatica ",
    "url": "https://arxiv.org/abs/2112.05935",
    "authors": [
      "Pio Ong",
      "Beatrice Capelli",
      "Lorenzo Sabattini",
      "Jorge Cortes"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2112.08547",
    "title": "Learning Rich Representation of Keyphrases from Text",
    "abstract": " Title: Learning Rich Representation of Keyphrases from Text ",
    "url": "https://arxiv.org/abs/2112.08547",
    "authors": [
      "Mayank Kulkarni",
      "Debanjan Mahata",
      "Ravneet Arora",
      "Rajarshi Bhowmik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.08548",
    "title": "Isochrony-Aware Neural Machine Translation for Automatic Dubbing",
    "abstract": " Comments: Published at InterSpeech 2022 (this https URL) - scheduled for September 18-22 2022, Incheon Korea ",
    "url": "https://arxiv.org/abs/2112.08548",
    "authors": [
      "Derek Tam",
      "Surafel M. Lakew",
      "Yogesh Virkar",
      "Prashant Mathur",
      "Marcello Federico"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.12002",
    "title": "Looking Beyond Corners: Contrastive Learning of Visual Representations  for Keypoint Detection and Description Extraction",
    "abstract": " Comments: Accepted at IEEE WCCI 2022 ",
    "url": "https://arxiv.org/abs/2112.12002",
    "authors": [
      "Henrique Siqueira",
      "Patrick Ruhkamp",
      "Ibrahim Halfaoui",
      "Markus Karmann",
      "Onay Urfalioglu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.00850",
    "title": "Selective Inhibition and Recruitment of Linear-Threshold Thalamocortical  Networks",
    "abstract": " Comments: 13 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2201.00850",
    "authors": [
      "Michael McCreesh",
      "Jorge Cort\u00e9s"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2201.10432",
    "title": "Parameterized Analysis of Reconfigurable Broadcast Networks (Long  Version)",
    "abstract": " Comments: This is the long version of a paper accepted at FoSSaCS 2022. Erratum: The proof of Theorem 2 contains a mistake, kindly pointed out by Nicolas Waldburger. We are working on a solution ",
    "url": "https://arxiv.org/abs/2201.10432",
    "authors": [
      "A. R. Balasubramanian",
      "Lucie Guillou",
      "Chana Weil-Kennedy"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2201.10460",
    "title": "Conditional entropy minimization principle for learning domain invariant  representation features",
    "abstract": " Comments: 10 pages, this paper was accepted at 26th International Conference on Pattern Recognition (ICPR-2022) ",
    "url": "https://arxiv.org/abs/2201.10460",
    "authors": [
      "Thuan Nguyen",
      "Boyang Lyu",
      "Prakash Ishwar",
      "Matthias Scheutz",
      "Shuchin Aeron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.12091",
    "title": "Linear Adversarial Concept Erasure",
    "abstract": " Comments: Accepted in ICML 2022 ",
    "url": "https://arxiv.org/abs/2201.12091",
    "authors": [
      "Shauli Ravfogel",
      "Michael Twiton",
      "Yoav Goldberg",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2201.12165",
    "title": "ReGAE: Graph autoencoder based on recursive neural networks",
    "abstract": " Title: ReGAE: Graph autoencoder based on recursive neural networks ",
    "url": "https://arxiv.org/abs/2201.12165",
    "authors": [
      "Adam Ma\u0142kowski",
      "Jakub Grzechoci\u0144ski",
      "Pawe\u0142 Wawrzy\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03323",
    "title": "Motion-Plane-Adaptive Inter Prediction in 360-Degree Video Coding",
    "abstract": " Comments: 14 pages, 12 figures, 6 tables; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2202.03323",
    "authors": [
      "Andy Regensky",
      "Christian Herglotz",
      "Andr\u00e9 Kaup"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.04124",
    "title": "An Adaptive Mini-Block Fisher Method for Deep Neural Networks",
    "abstract": " Title: An Adaptive Mini-Block Fisher Method for Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2202.04124",
    "authors": [
      "Achraf Bahamou",
      "Donald Goldfarb",
      "Yi Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.06060",
    "title": "Depth-Cooperated Trimodal Network for Video Salient Object Detection",
    "abstract": " Comments: 5 pages, 3 figures, Accepted at ICIP-2022 ",
    "url": "https://arxiv.org/abs/2202.06060",
    "authors": [
      "Yukang Lu",
      "Dingyao Min",
      "Keren Fu",
      "Qijun Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07054",
    "title": "Universal Adversarial Examples in Remote Sensing: Methodology and  Benchmark",
    "abstract": " Title: Universal Adversarial Examples in Remote Sensing: Methodology and  Benchmark ",
    "url": "https://arxiv.org/abs/2202.07054",
    "authors": [
      "Yonghao Xu",
      "Pedram Ghamisi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.08333",
    "title": "Self-Supervised Representation Learning via Latent Graph Prediction",
    "abstract": " Comments: 18 pages, 2 figures, supplement included. Accepted by ICML 2022 ",
    "url": "https://arxiv.org/abs/2202.08333",
    "authors": [
      "Yaochen Xie",
      "Zhao Xu",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.09275",
    "title": "Rethinking Pareto Frontier for Performance Evaluation of Deep Neural  Networks",
    "abstract": " Title: Rethinking Pareto Frontier for Performance Evaluation of Deep Neural  Networks ",
    "url": "https://arxiv.org/abs/2202.09275",
    "authors": [
      "Vahid Partovi Nia",
      "Alireza Ghaffari",
      "Mahdi Zolnouri",
      "Yvon Savaria"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2202.09704",
    "title": "MANet: Improving Video Denoising with a Multi-Alignment Network",
    "abstract": " Comments: 5 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2202.09704",
    "authors": [
      "Yaping Zhao",
      "Haitian Zheng",
      "Zhongrui Wang",
      "Jiebo Luo",
      "Edmund Y. Lam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.09741",
    "title": "Visual Attention Network",
    "abstract": " Comments: Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2202.09741",
    "authors": [
      "Meng-Hao Guo",
      "Cheng-Ze Lu",
      "Zheng-Ning Liu",
      "Ming-Ming Cheng",
      "Shi-Min Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.10408",
    "title": "Embarrassingly Simple Performance Prediction for Abductive Natural  Language Inference",
    "abstract": " Comments: Published at NAACL 2022 at this https URL Please cite according to this https URL ",
    "url": "https://arxiv.org/abs/2202.10408",
    "authors": [
      "Em\u012bls Kadi\u0137is",
      "Vaibhav Srivastav",
      "Roman Klinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.11453",
    "title": "Bitwidth Heterogeneous Federated Learning with Progressive Weight  Dequantization",
    "abstract": " Comments: Accepted to ICML 2022 ",
    "url": "https://arxiv.org/abs/2202.11453",
    "authors": [
      "Jaehong Yoon",
      "Geon Park",
      "Wonyong Jeong",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2202.12838",
    "title": "RelMobNet: End-to-end relative camera pose estimation using a robust  two-stage training",
    "abstract": " Comments: 15 pages, 7 figures, 2 tables - RelMobNet revised draft ",
    "url": "https://arxiv.org/abs/2202.12838",
    "authors": [
      "Praveen Kumar Rajendran",
      "Sumit Mishra",
      "Luiz Felipe Vecchietti",
      "Dongsoo Har"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.13056",
    "title": "Automated Identification of Toxic Code Reviews Using ToxiCR",
    "abstract": " Title: Automated Identification of Toxic Code Reviews Using ToxiCR ",
    "url": "https://arxiv.org/abs/2202.13056",
    "authors": [
      "Jaydeb Sarker",
      "Asif Kamal Turzo",
      "Ming Dong",
      "Amiangshu Bosu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00300",
    "title": "Towards Decentralized Identity Management in Multi-stakeholder 6G  Networks",
    "abstract": " Comments: Published at the 1st International Conference on 6G Networking (6GNet 2022) in Paris, France ",
    "url": "https://arxiv.org/abs/2203.00300",
    "authors": [
      "Sandro Rodriguez Garzon",
      "Hakan Yildiz",
      "Axel K\u00fcpper"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.01474",
    "title": "Spatio-Temporal Gating-Adjacency GCN for Human Motion Prediction",
    "abstract": " Comments: We declare that the evaluation metric we used is following STSGCN, that is, the average error over frames (denoted by *), which we only found when we checked their test code on July 9, 2022 ",
    "url": "https://arxiv.org/abs/2203.01474",
    "authors": [
      "Chongyang Zhong",
      "Lei Hu",
      "Zihao Zhang",
      "Yongjing Ye",
      "Shihong Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03605",
    "title": "DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object  Detection",
    "abstract": " Title: DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object  Detection ",
    "url": "https://arxiv.org/abs/2203.03605",
    "authors": [
      "Hao Zhang",
      "Feng Li",
      "Shilong Liu",
      "Lei Zhang",
      "Hang Su",
      "Jun Zhu",
      "Lionel M. Ni",
      "Heung-Yeung Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05823",
    "title": "Learning Discriminative Representations and Decision Boundaries for Open  Intent Detection",
    "abstract": " Comments: 13 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2203.05823",
    "authors": [
      "Hanlei Zhang",
      "Hua Xu",
      "Shaojie Zhao",
      "Qianrui Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.07471",
    "title": "Robust Dynamic Walking for a 3D Dual-SLIP Model under One-Step  Unilateral Stiffness Perturbations: Towards Bipedal Locomotion over Compliant  Terrain",
    "abstract": " Comments: This work was published in the 30th Mediterranean Conference on Control and Automation, MED'22 ",
    "url": "https://arxiv.org/abs/2203.07471",
    "authors": [
      "Chrysostomos Karakasis",
      "Ioannis Poulakakis",
      "Panagiotis Artemiadis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.08245",
    "title": "Reconstructing Missing EHRs Using Time-Aware Within- and Cross-Visit  Information for Septic Shock Early Prediction",
    "abstract": " Comments: 12 pages, accepted at IEEE ICHI'22 ",
    "url": "https://arxiv.org/abs/2203.08245",
    "authors": [
      "Ge Gao",
      "Farzaneh Khoshnevisan",
      "Min Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2203.10533",
    "title": "Strategic Analysis of Griefing Attack in Lightning Network",
    "abstract": " Comments: 17 pages ",
    "url": "https://arxiv.org/abs/2203.10533",
    "authors": [
      "Subhra Mazumdar",
      "Prabal Banerjee",
      "Abhinandan Sinha",
      "Sushmita Ruj",
      "Bimal Roy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2203.11805",
    "title": "Robust Classification using Contractive Hamiltonian Neural ODEs",
    "abstract": " Title: Robust Classification using Contractive Hamiltonian Neural ODEs ",
    "url": "https://arxiv.org/abs/2203.11805",
    "authors": [
      "Muhammad Zakwan",
      "Liang Xu",
      "Giancarlo Ferrari-Trecate"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16930",
    "title": "WavThruVec: Latent speech representation as intermediate features for  neural speech synthesis",
    "abstract": " Comments: Accepted to INTERSPEECH 2022. Audio samples are available at: this https URL ",
    "url": "https://arxiv.org/abs/2203.16930",
    "authors": [
      "Hubert Siuzdak",
      "Piotr Dura",
      "Pol van Rijn",
      "Nori Jacoby"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.02128",
    "title": "Computing in Anonymous Dynamic Networks Is Linear",
    "abstract": " Comments: 34 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2204.02128",
    "authors": [
      "Giuseppe A. Di Luna",
      "Giovanni Viglietta"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2204.11190",
    "title": "Knowledge-aware Document Summarization: A Survey of Knowledge, Embedding  Methods and Architectures",
    "abstract": " Comments: 29 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2204.11190",
    "authors": [
      "Yutong Qu",
      "Wei Emma Zhang",
      "Jian Yang",
      "Lingfei Wu",
      "Jia Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.13630",
    "title": "Rotationally Equivariant 3D Object Detection",
    "abstract": " Comments: CVPR 2022, project website: this https URL ",
    "url": "https://arxiv.org/abs/2204.13630",
    "authors": [
      "Hong-Xing Yu",
      "Jiajun Wu",
      "Li Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.13990",
    "title": "Particle Swarm Optimization Based Demand Response Using Artificial  Neural Network Based Load Prediction",
    "abstract": " Title: Particle Swarm Optimization Based Demand Response Using Artificial  Neural Network Based Load Prediction ",
    "url": "https://arxiv.org/abs/2204.13990",
    "authors": [
      "Nasrin Bayat"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.06811",
    "title": "Nearly Optimal Algorithms for Linear Contextual Bandits with Adversarial  Corruptions",
    "abstract": " Comments: 25 pages, 1 table. This version simplifies the proof of the regret upper bound in Version 1, and provides a stronger result for the lower bound ",
    "url": "https://arxiv.org/abs/2205.06811",
    "authors": [
      "Jiafan He",
      "Dongruo Zhou",
      "Tong Zhang",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.11680",
    "title": "HiPAL: A Deep Framework for Physician Burnout Prediction Using Activity  Logs in Electronic Health Records",
    "abstract": " Comments: 11 pages including appendices. Accepted by KDD'22 ",
    "url": "https://arxiv.org/abs/2205.11680",
    "authors": [
      "Hanyang Liu",
      "Sunny S. Lou",
      "Benjamin C. Warner",
      "Derek R. Harford",
      "Thomas Kannampallil",
      "Chenyang Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12454",
    "title": "Recipe for a General, Powerful, Scalable Graph Transformer",
    "abstract": " Title: Recipe for a General, Powerful, Scalable Graph Transformer ",
    "url": "https://arxiv.org/abs/2205.12454",
    "authors": [
      "Ladislav Ramp\u00e1\u0161ek",
      "Mikhail Galkin",
      "Vijay Prakash Dwivedi",
      "Anh Tuan Luu",
      "Guy Wolf",
      "Dominique Beaini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13038",
    "title": "Improving Subgraph Representation Learning via Multi-View Augmentation",
    "abstract": " Title: Improving Subgraph Representation Learning via Multi-View Augmentation ",
    "url": "https://arxiv.org/abs/2205.13038",
    "authors": [
      "Yili Shen",
      "Jiaxu Yan",
      "Cheng-Wei Ju",
      "Jun Yi",
      "Zhou Lin",
      "Hui Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13135",
    "title": "LAMP 2.0: A Robust Multi-Robot SLAM System for Operation in Challenging  Large-Scale Underground Environments",
    "abstract": " Title: LAMP 2.0: A Robust Multi-Robot SLAM System for Operation in Challenging  Large-Scale Underground Environments ",
    "url": "https://arxiv.org/abs/2205.13135",
    "authors": [
      "Yun Chang",
      "Kamak Ebadi",
      "Christopher E. Denniston",
      "Muhammad Fadhil Ginting",
      "Antoni Rosinol",
      "Andrzej Reinke",
      "Matteo Palieri",
      "Jingnan Shi",
      "Arghya Chatterjee",
      "Benjamin Morrell",
      "Ali-akbar Agha-mohammadi",
      "Luca Carlone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2205.15234",
    "title": "Few-Shot Adaptation of Pre-Trained Networks for Domain Shift",
    "abstract": " Comments: Accepted to IJCAI 2022 ",
    "url": "https://arxiv.org/abs/2205.15234",
    "authors": [
      "Wenyu Zhang",
      "Li Shen",
      "Wanyue Zhang",
      "Chuan-Sheng Foo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.06575",
    "title": "Med-DANet: Dynamic Architecture Network for Efficient Medical Volumetric  Segmentation",
    "abstract": " Title: Med-DANet: Dynamic Architecture Network for Efficient Medical Volumetric  Segmentation ",
    "url": "https://arxiv.org/abs/2206.06575",
    "authors": [
      "Wenxuan Wang",
      "Chen Chen",
      "Jing Wang",
      "Sen Zha",
      "Yan Zhang",
      "Jiangyun Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07634",
    "title": "Real3D-Aug: Point Cloud Augmentation by Placing Real Objects with  Occlusion Handling for 3D Detection and Segmentation",
    "abstract": " Comments: Submitted on 15th June 2022 to IEEE RA-L journal ",
    "url": "https://arxiv.org/abs/2206.07634",
    "authors": [
      "Petr \u0160ebek",
      "\u0160imon Pokorn\u00fd",
      "Patrik Vacek",
      "Tom\u00e1\u0161 Svoboda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.08496",
    "title": "Self-Supervised Contrastive Pre-Training For Time Series via  Time-Frequency Consistency",
    "abstract": " Comments: Under review; the anonymouse code repo link will be made non-anonymous after acceptance; 24 pages (13 pages main paper + 11 pages supplementary materials) ",
    "url": "https://arxiv.org/abs/2206.08496",
    "authors": [
      "Xiang Zhang",
      "Ziyuan Zhao",
      "Theodoros Tsiligkaridis",
      "Marinka Zitnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.10088",
    "title": "Renormalized Sparse Neural Network Pruning",
    "abstract": " Title: Renormalized Sparse Neural Network Pruning ",
    "url": "https://arxiv.org/abs/2206.10088",
    "authors": [
      "Michael G. Rawson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.10421",
    "title": "Rethinking Audio-visual Synchronization for Active Speaker Detection",
    "abstract": " Comments: Accepted by IEEE International Workshop on Machine Learning for Signal Processing (MLSP 2022) ",
    "url": "https://arxiv.org/abs/2206.10421",
    "authors": [
      "Abudukelimu Wuerkaixi",
      "You Zhang",
      "Zhiyao Duan",
      "Changshui Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.12790",
    "title": "APPFLChain: A Privacy Protection Distributed Artificial-Intelligence  Architecture Based on Federated Learning and Consortium Blockchain",
    "abstract": " Comments: We found that the simulation part in section V is not completed. We need to add more experiments to support it ",
    "url": "https://arxiv.org/abs/2206.12790",
    "authors": [
      "Jun-Teng Yang",
      "Wen-Yuan Chen",
      "Che-Hua Li",
      "Scott C.-H. Huang",
      "Hsiao-Chun Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.12901",
    "title": "Noise-aware Physics-informed Machine Learning for Robust PDE Discovery",
    "abstract": " Comments: 13 pages, 8 figures, v2: corrected typos, v3: corrected author names, corrected typos, v4: improved notations ",
    "url": "https://arxiv.org/abs/2206.12901",
    "authors": [
      "Pongpisit Thanasutives",
      "Takashi Morita",
      "Masayuki Numao",
      "Ken-ichi Fukui"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2206.13497",
    "title": "Robustness Implies Generalization via Data-Dependent Generalization  Bounds",
    "abstract": " Comments: Accepted by ICML 2022, and selected for ICML long presentation (top 2% of submissions) ",
    "url": "https://arxiv.org/abs/2206.13497",
    "authors": [
      "Kenji Kawaguchi",
      "Zhun Deng",
      "Kyle Luh",
      "Jiaoyang Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.14282",
    "title": "Neural Integro-Differential Equations",
    "abstract": " Comments: 15 pages (including 4 pages Appendix), 8 figures and 4 tables ",
    "url": "https://arxiv.org/abs/2206.14282",
    "authors": [
      "Emanuele Zappala",
      "Antonio Henrique de Oliveira Fonseca",
      "Andrew Henry Moberly",
      "Michael James Higley",
      "Chadi Abdallah",
      "Jessica Cardin",
      "David van Dijk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.15398",
    "title": "PolarFormer: Multi-camera 3D Object Detection with Polar Transformers",
    "abstract": " Title: PolarFormer: Multi-camera 3D Object Detection with Polar Transformers ",
    "url": "https://arxiv.org/abs/2206.15398",
    "authors": [
      "Yanqin Jiang",
      "Li Zhang",
      "Zhenwei Miao",
      "Xiatian Zhu",
      "Jin Gao",
      "Weiming Hu",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.00506",
    "title": "How Far Can I Go ? : A Self-Supervised Approach for Deterministic Video  Depth Forecasting",
    "abstract": " Comments: Accepted in ML4AD Workshop, NeurIPS 2021 ",
    "url": "https://arxiv.org/abs/2207.00506",
    "authors": [
      "Sauradip Nag",
      "Nisarg Shah",
      "Anran Qi",
      "Raghavendra Ramachandra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2207.00718",
    "title": "Triangle-oriented Community Detection considering Node Features and  Network Topology",
    "abstract": " Title: Triangle-oriented Community Detection considering Node Features and  Network Topology ",
    "url": "https://arxiv.org/abs/2207.00718",
    "authors": [
      "Guangliang Gao",
      "Weichao Liang",
      "Ming Yuan",
      "Hanwei Qian",
      "Qun Wang",
      "Jie Cao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.01127",
    "title": "DecisioNet: A Binary-Tree Structured Neural Network",
    "abstract": " Comments: This paper is under review of a conference, hence the code may not be published yet. It will be publicly available on github after the paper is published ",
    "url": "https://arxiv.org/abs/2207.01127",
    "authors": [
      "Noam Gottlieb",
      "Michael Werman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.01129",
    "title": "A Gray Code of Ordered Trees",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2207.01129",
    "authors": [
      "Shin-ichi Nakano"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2207.01377",
    "title": "Detection of ADHD based on Eye Movements during Natural Viewing",
    "abstract": " Comments: Pre-print for Proceedings of the European Conference on Machine Learning, 2022 ",
    "url": "https://arxiv.org/abs/2207.01377",
    "authors": [
      "Shuwen Deng",
      "Paul Prasse",
      "David R. Reich",
      "Sabine Dziemian",
      "Maja Stegenwallner-Sch\u00fctz",
      "Daniel Krakowczyk",
      "Silvia Makowski",
      "Nicolas Langer",
      "Tobias Scheffer",
      "Lena A. J\u00e4ger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01886",
    "title": "WeSinger 2: Fully Parallel Singing Voice Synthesis via Multi-Singer  Conditional Adversarial Training",
    "abstract": " Comments: update writing ",
    "url": "https://arxiv.org/abs/2207.01886",
    "authors": [
      "Zewang Zhang",
      "Yibin Zheng",
      "Xinhui Li",
      "Li Lu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.02013",
    "title": "Multiview Detection with Cardboard Human Modeling",
    "abstract": " Comments: The thesis is not perfect enough ",
    "url": "https://arxiv.org/abs/2207.02013",
    "authors": [
      "Jiahao Ma",
      "Zicheng Duan",
      "Yunzhong Hou",
      "Liang Zheng",
      "Chuong Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.02152",
    "title": "UniCR: Universally Approximated Certified Robustness via Randomized  Smoothing",
    "abstract": " Comments: Accepted by ECCV2022 ",
    "url": "https://arxiv.org/abs/2207.02152",
    "authors": [
      "Hanbin Hong",
      "Binghui Wang",
      "Yuan Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.02327",
    "title": "TractoFormer: A Novel Fiber-level Whole Brain Tractography Analysis  Framework Using Spectral Embedding and Vision Transformers",
    "abstract": " Comments: 11 pages. 5 figures, MICCAI 2022 ",
    "url": "https://arxiv.org/abs/2207.02327",
    "authors": [
      "Fan Zhang",
      "Tengfei Xue",
      "Weidong Cai",
      "Yogesh Rathi",
      "Carl-Fredrik Westin",
      "Lauren J O'Donnell"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.03116",
    "title": "Equivariant Representation Learning via Class-Pose Decomposition",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2207.03116",
    "authors": [
      "Giovanni Luca Marchetti",
      "Gustaf Tegn\u00e9r",
      "Anastasiia Varava",
      "Danica Kragic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Group Theory (math.GR)"
    ]
  }
]