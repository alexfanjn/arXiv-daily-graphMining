[
  {
    "id": "arXiv:2207.07150",
    "title": "Making Linear MDPs Practical via Contrastive Representation Learning",
    "abstract": "It is common to address the curse of dimensionality in Markov decision processes (MDPs) by exploiting low-rank representations. This motivates much of the recent theoretical study on linear MDPs. However, most approaches require a given representation under unrealistic assumptions about the normalization of the decomposition or introduce unresolved computational challenges in practice. Instead, we consider an alternative definition of linear MDPs that automatically ensures normalization while allowing efficient representation learning via contrastive estimation. The framework also admits confidence-adjusted index algorithms, enabling an efficient and principled approach to incorporating optimism or pessimism in the face of uncertainty. To the best of our knowledge, this provides the first practical representation learning method for linear MDPs that achieves both strong theoretical guarantees and empirical performance. Theoretically, we prove that the proposed algorithm is sample efficient in both the online and offline settings. Empirically, we demonstrate superior performance over existing state-of-the-art model-based and model-free algorithms on several benchmarks. ",
    "url": "https://arxiv.org/abs/2207.07150",
    "authors": [
      "Tianjun Zhang",
      "Tongzheng Ren",
      "Mengjiao Yang",
      "Joseph E. Gonzalez",
      "Dale Schuurmans",
      "Bo Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.07160",
    "title": "Case study on quantum convolutional neural network scalability",
    "abstract": "One of the crucial tasks in computer science is the processing time reduction of various data types, i.e., images, which is important for different fields -- from medicine and logistics to virtual shopping. Compared to classical computers, quantum computers are capable of parallel data processing, which reduces the data processing time. This quality of quantum computers inspired intensive research of the potential of quantum technologies applicability to real-life tasks. Some progress has already revealed on a smaller volumes of the input data. In this research effort, I aimed to increase the amount of input data (I used images from 2 x 2 to 8 x 8), while reducing the processing time, by way of skipping intermediate measurement steps. The hypothesis was that, for increased input data, the omitting of intermediate measurement steps after each quantum convolution layer will improve output metric results and accelerate data processing. To test the hypothesis, I performed experiments to chose the best activation function and its derivative in each network. The hypothesis was partly confirmed in terms of output mean squared error (MSE) -- it dropped from 0.25 in the result of classical convolutional neural network (CNN) training to 0.23 in the result of quantum convolutional neural network (QCNN) training. In terms of the training time, however, which was 1.5 minutes for CNN and 4 hours 37 minutes in the least lengthy training iteration, the hypothesis was rejected. ",
    "url": "https://arxiv.org/abs/2207.07160",
    "authors": [
      "Marina O. Lisnichenko",
      "Stanislav I. Protasov"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07165",
    "title": "Estimating Emotion Contagion on Social Media via Localized Diffusion in  Dynamic Graphs",
    "abstract": "We present a computational approach for estimating emotion contagion on social media networks. Built on a foundation of psychology literature, our approach estimates the degree to which the perceivers' emotional states (positive or negative) start to match those of the expressors, based on the latter's content. We use a combination of deep learning and social network analysis to model emotion contagion as a diffusion process in dynamic social network graphs, taking into consideration key aspects like causality, homophily, and interference. We evaluate our approach on user behavior data obtained from a popular social media platform for sharing short videos. We analyze the behavior of 48 users over a span of 8 weeks (over 200k audio-visual short posts analyzed) and estimate how contagious the users with whom they engage with are on social media. As per the theory of diffusion, we account for the videos a user watches during this time (inflow) and the daily engagements; liking, sharing, downloading or creating new videos (outflow) to estimate contagion. To validate our approach and analysis, we obtain human feedback on these 48 social media platform users with an online study by collecting responses of about 150 participants. We report users who interact with more number of creators on the platform are 12% less prone to contagion, and those who consume more content of `negative' sentiment are 23% more prone to contagion. We will publicly release our code upon acceptance. ",
    "url": "https://arxiv.org/abs/2207.07165",
    "authors": [
      "Trisha Mittal",
      "Puneet Mathur",
      "Rohan Chandra",
      "Apurva Bhatt",
      "Vikram Gupta",
      "Debdoot Mukherjee",
      "Aniket Bera",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.07173",
    "title": "Image Clustering with Contrastive Learning and Multi-scale Graph  Convolutional Networks",
    "abstract": "Deep clustering has recently attracted significant attention. Despite the remarkable progress, most of the previous deep clustering works still suffer from two limitations. First, many of them focus on some distribution-based clustering loss, lacking the ability to exploit sample-wise (or augmentation-wise) relationships via contrastive learning. Second, they often neglect the indirect sample-wise structure information, overlooking the rich possibilities of multi-scale neighborhood structure learning. In view of this, this paper presents a new deep clustering approach termed Image clustering with contrastive learning and multi-scale Graph Convolutional Networks (IcicleGCN), which bridges the gap between convolutional neural network (CNN) and graph convolutional network (GCN) as well as the gap between contrastive learning and multi-scale neighborhood structure learning for the image clustering task. The proposed IcicleGCN framework consists of four main modules, namely, the CNN-based backbone, the Instance Similarity Module (ISM), the Joint Cluster Structure Learning and Instance reconstruction Module (JC-SLIM), and the Multi-scale GCN module (M-GCN). Specifically, with two random augmentations performed on each image, the backbone network with two weight-sharing views is utilized to learn the representations for the augmented samples, which are then fed to ISM and JC-SLIM for instance-level and cluster-level contrastive learning, respectively. Further, to enforce multi-scale neighborhood structure learning, two streams of GCNs and an auto-encoder are simultaneously trained via (i) the layer-wise interaction with representation fusion and (ii) the joint self-adaptive learning that ensures their last-layer output distributions to be consistent. Experiments on multiple image datasets demonstrate the superior clustering performance of IcicleGCN over the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2207.07173",
    "authors": [
      "Yuanku Xu",
      "Dong Huang",
      "Chang-Dong Wang",
      "Jian-Huang Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07174",
    "title": "Causal Graphs Underlying Generative Models: Path to Learning with  Limited Data",
    "abstract": "Training generative models that capture rich semantics of the data and interpreting the latent representations encoded by such models are very important problems in unsupervised learning. In this work, we provide a simple algorithm that relies on perturbation experiments on latent codes of a pre-trained generative autoencoder to uncover a causal graph that is implied by the generative model. We leverage pre-trained attribute classifiers and perform perturbation experiments to check for influence of a given latent variable on a subset of attributes. Given this, we show that one can fit an effective causal graph that models a structural equation model between latent codes taken as exogenous variables and attributes taken as observed variables. One interesting aspect is that a single latent variable controls multiple overlapping subsets of attributes unlike conventional approach that tries to impose full independence. Using a pre-trained RNN-based generative autoencoder trained on a dataset of peptide sequences, we demonstrate that the learnt causal graph from our algorithm between various attributes and latent codes can be used to predict a specific property for sequences which are unseen. We compare prediction models trained on either all available attributes or only the ones in the Markov blanket and empirically show that in both the unsupervised and supervised regimes, typically, using the predictor that relies on Markov blanket attributes generalizes better for out-of-distribution sequences. ",
    "url": "https://arxiv.org/abs/2207.07174",
    "authors": [
      "Samuel C. Hoffman",
      "Kahini Wadhawan",
      "Payel Das",
      "Prasanna Sattigeri",
      "Karthikeyan Shanmugam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.07180",
    "title": "Contrastive Adapters for Foundation Model Group Robustness",
    "abstract": "While large pretrained foundation models (FMs) have shown remarkable zero-shot classification robustness to dataset-level distribution shifts, their robustness to subpopulation or group shifts is relatively underexplored. We study this problem, and find that FMs such as CLIP may not be robust to various group shifts. Across 9 robustness benchmarks, zero-shot classification with their embeddings results in gaps of up to 80.7 percentage points (pp) between average and worst-group accuracy. Unfortunately, existing methods to improve robustness require retraining, which can be prohibitively expensive on large foundation models. We also find that efficient ways to improve model inference (e.g., via adapters, lightweight networks with FM embeddings as inputs) do not consistently improve and can sometimes hurt group robustness compared to zero-shot (e.g., increasing the accuracy gap by 50.1 pp on CelebA). We thus develop an adapter training strategy to effectively and efficiently improve FM group robustness. Our motivating observation is that while poor robustness results from groups in the same class being embedded far apart in the foundation model \"embedding space,\" standard adapter training may not bring these points closer together. We thus propose contrastive adapting, which trains adapters with contrastive learning to bring sample embeddings close to both their ground-truth class embeddings and other sample embeddings in the same class. Across the 9 benchmarks, our approach consistently improves group robustness, raising worst-group accuracy by 8.5 to 56.0 pp over zero-shot. Our approach is also efficient, doing so without any FM finetuning and only a fixed set of frozen FM embeddings. On benchmarks such as Waterbirds and CelebA, this leads to worst-group accuracy comparable to state-of-the-art methods that retrain entire models, while only training $\\leq$1% of the model parameters. ",
    "url": "https://arxiv.org/abs/2207.07180",
    "authors": [
      "Michael Zhang",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07187",
    "title": "NASRec: Weight Sharing Neural Architecture Search for Recommender  Systems",
    "abstract": "The rise of deep neural networks provides an important driver in optimizing recommender systems. However, the success of recommender systems lies in delicate architecture fabrication, and thus calls for Neural Architecture Search (NAS) to further improve its modeling. We propose NASRec, a paradigm that trains a single supernet and efficiently produces abundant models/sub-architectures by weight sharing. To overcome the data multi-modality and architecture heterogeneity challenges in recommendation domain, NASRec establishes a large supernet (i.e., search space) to search the full architectures, with the supernet incorporating versatile operator choices and dense connectivity minimizing human prior for flexibility. The scale and heterogeneity in NASRec impose challenges in search, such as training inefficiency, operator-imbalance, and degraded rank correlation. We tackle these challenges by proposing single-operator any-connection sampling, operator-balancing interaction modules, and post-training fine-tuning. Our results on three Click-Through Rates (CTR) prediction benchmarks show that NASRec can outperform both manually designed models and existing NAS methods, achieving state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2207.07187",
    "authors": [
      "Tunhou Zhang",
      "Dehua Cheng",
      "Yuchen He",
      "Zhengxing Chen",
      "Xiaoliang Dai",
      "Liang Xiong",
      "Feng Yan",
      "Hai Li",
      "Yiran Chen",
      "Wei Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07194",
    "title": "A serendipity fully discrete div-div complex on polygonal meshes",
    "abstract": "In this work we address the reduction of face degrees of freedom (DOFs) for discrete elasticity complexes. Specifically, using serendipity techniques, we develop a reduced version of a recently introduced two-dimensional complex arising from traces of the three-dimensional elasticity complex. The keystone of the reduction process is a new estimate of symmetric tensor-valued polynomial fields in terms of boundary values, completed with suitable projections of internal values for higher degrees. We prove an extensive set of new results for the original complex and show that the reduced complex has the same homological and analytical properties as the original one. This paper also contains an appendix with proofs of general Poincar\\'e--Korn-type inequalities for hybrid fields. ",
    "url": "https://arxiv.org/abs/2207.07194",
    "authors": [
      "Michele Botti",
      "Daniele A. Di Pietro",
      "Marwa Salah"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.07208",
    "title": "Provably Adversarially Robust Nearest Prototype Classifiers",
    "abstract": "Nearest prototype classifiers (NPCs) assign to each input point the label of the nearest prototype with respect to a chosen distance metric. A direct advantage of NPCs is that the decisions are interpretable. Previous work could provide lower bounds on the minimal adversarial perturbation in the $\\ell_p$-threat model when using the same $\\ell_p$-distance for the NPCs. In this paper we provide a complete discussion on the complexity when using $\\ell_p$-distances for decision and $\\ell_q$-threat models for certification for $p,q \\in \\{1,2,\\infty\\}$. In particular we provide scalable algorithms for the \\emph{exact} computation of the minimal adversarial perturbation when using $\\ell_2$-distance and improved lower bounds in other cases. Using efficient improved lower bounds we train our Provably adversarially robust NPC (PNPC), for MNIST which have better $\\ell_2$-robustness guarantees than neural networks. Additionally, we show up to our knowledge the first certification results w.r.t. to the LPIPS perceptual metric which has been argued to be a more realistic threat model for image classification than $\\ell_p$-balls. Our PNPC has on CIFAR10 higher certified robust accuracy than the empirical robust accuracy reported in (Laidlaw et al., 2021). The code is available in our repository. ",
    "url": "https://arxiv.org/abs/2207.07208",
    "authors": [
      "V\u00e1clav Vor\u00e1\u010dek",
      "Matthias Hein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07216",
    "title": "On the use of graph neural networks and shape-function-based gradient  computation in the deep energy method",
    "abstract": "A graph neural network (GCN) is employed in the deep energy method (DEM) model to solve the momentum balance equation in 3D for the deformation of linear elastic and hyperelastic materials due to its ability to handle irregular domains over the traditional DEM method based on a multilayer perceptron (MLP) network. Its accuracy and solution time are compared to the DEM model based on a MLP network. We demonstrate that the GCN-based model delivers similar accuracy while having a shorter run time through numerical examples. Two different spatial gradient computation techniques, one based on automatic differentiation (AD) and the other based on shape function (SF) gradients, are also accessed. We provide a simple example to demonstrate the strain localization instability associated with the AD-based gradient computation and show that the instability exists in more general cases by four numerical examples. The SF-based gradient computation is shown to be more robust and delivers an accurate solution even at severe deformations. Therefore, the combination of the GCN-based DEM model and SF-based gradient computation is potentially a promising candidate for solving problems involving severe material and geometric nonlinearities. ",
    "url": "https://arxiv.org/abs/2207.07216",
    "authors": [
      "Junyan He",
      "Diab Abueidda",
      "Seid Koric",
      "Iwona Jasiuk"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2207.07219",
    "title": "Dynamic 5G Network Slice Management Middleware for Industrial Internet  of Things: Industry Paper",
    "abstract": "This paper addresses the challenges of delivering fine-grained Quality of Service (QoS) and communication determinism over 5G wireless networks for real-time and autonomous needs of Industrial Internet of Things (IIoT) applications while effectively sharing network resources. Specifically, this work presents DANSM, a dynamic and autonomous network slice management middleware for 5G-based IIoT use cases, such as adaptive robotic repair. The novelty of our approach lies in (1) its use of multiple M/M/1 queues to formulate a 5G network resource scheduling optimization problem comprising service-level and system-level objectives; (2) the design of a heuristics-based solution to overcome the NP-hard properties of this optimization problem, and (3) how it dynamically and autonomously provisions and manages 5G network slices used to deliver predictable communications to IIoT use cases. The results of experiments evaluating DANSM on our testbed comprising a Free5GC-based core and UERANSIM-based simulations reveal that it can efficiently balance the traffic load in the data plane thereby reducing the end-to-end response time and improve the service performance by finishing 64% of subtasks more than First Fit Descending (FFD) baseline approach while minimizing the operation cost. ",
    "url": "https://arxiv.org/abs/2207.07219",
    "authors": [
      "Ziran Min",
      "Shashank Shekhar",
      "Charif Mahmoudi",
      "Valerio Formicola",
      "Swapna Gokhale",
      "Aniruddha Gokhale"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.07232",
    "title": "Lipschitz Bound Analysis of Neural Networks",
    "abstract": "Lipschitz Bound Estimation is an effective method of regularizing deep neural networks to make them robust against adversarial attacks. This is useful in a variety of applications ranging from reinforcement learning to autonomous systems. In this paper, we highlight the significant gap in obtaining a non-trivial Lipschitz bound certificate for Convolutional Neural Networks (CNNs) and empirically support it with extensive graphical analysis. We also show that unrolling Convolutional layers or Toeplitz matrices can be employed to convert Convolutional Neural Networks (CNNs) to a Fully Connected Network. Further, we propose a simple algorithm to show the existing 20x-50x gap in a particular data distribution between the actual lipschitz constant and the obtained tight bound. We also ran sets of thorough experiments on various network architectures and benchmark them on datasets like MNIST and CIFAR-10. All these proposals are supported by extensive testing, graphs, histograms and comparative analysis. ",
    "url": "https://arxiv.org/abs/2207.07232",
    "authors": [
      "Sarosij Bose"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07256",
    "title": "Improving Task-free Continual Learning by Distributionally Robust Memory  Evolution",
    "abstract": "Task-free continual learning (CL) aims to learn a non-stationary data stream without explicit task definitions and not forget previous knowledge. The widely adopted memory replay approach could gradually become less effective for long data streams, as the model may memorize the stored examples and overfit the memory buffer. Second, existing methods overlook the high uncertainty in the memory data distribution since there is a big gap between the memory data distribution and the distribution of all the previous data examples. To address these problems, for the first time, we propose a principled memory evolution framework to dynamically evolve the memory data distribution by making the memory buffer gradually harder to be memorized with distributionally robust optimization (DRO). We then derive a family of methods to evolve the memory buffer data in the continuous probability measure space with Wasserstein gradient flow (WGF). The proposed DRO is w.r.t the worst-case evolved memory data distribution, thus guarantees the model performance and learns significantly more robust features than existing memory-replay-based methods. Extensive experiments on existing benchmarks demonstrate the effectiveness of the proposed methods for alleviating forgetting. As a by-product of the proposed framework, our method is more robust to adversarial examples than existing task-free CL methods. ",
    "url": "https://arxiv.org/abs/2207.07256",
    "authors": [
      "Zhenyi Wang",
      "Li Shen",
      "Le Fang",
      "Qiuling Suo",
      "Tiehang Duan",
      "Mingchen Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07269",
    "title": "Weakly Supervised Video Salient Object Detection via Point Supervision",
    "abstract": "Video salient object detection models trained on pixel-wise dense annotation have achieved excellent performance, yet obtaining pixel-by-pixel annotated datasets is laborious. Several works attempt to use scribble annotations to mitigate this problem, but point supervision as a more labor-saving annotation method (even the most labor-saving method among manual annotation methods for dense prediction), has not been explored. In this paper, we propose a strong baseline model based on point supervision. To infer saliency maps with temporal information, we mine inter-frame complementary information from short-term and long-term perspectives, respectively. Specifically, we propose a hybrid token attention module, which mixes optical flow and image information from orthogonal directions, adaptively highlighting critical optical flow information (channel dimension) and critical token information (spatial dimension). To exploit long-term cues, we develop the Long-term Cross-Frame Attention module (LCFA), which assists the current frame in inferring salient objects based on multi-frame tokens. Furthermore, we label two point-supervised datasets, P-DAVIS and P-DAVSOD, by relabeling the DAVIS and the DAVSOD dataset. Experiments on the six benchmark datasets illustrate our method outperforms the previous state-of-the-art weakly supervised methods and even is comparable with some fully supervised approaches. Source code and datasets are available. ",
    "url": "https://arxiv.org/abs/2207.07269",
    "authors": [
      "Shuyong Gao",
      "Haozhe Xing",
      "Wei Zhang",
      "Yan Wang",
      "Qianyu Guo",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07316",
    "title": "Privacy-Preserving Face Recognition with Learnable Privacy Budgets in  Frequency Domain",
    "abstract": "Face recognition technology has been used in many fields due to its high recognition accuracy, including the face unlocking of mobile devices, community access control systems, and city surveillance. As the current high accuracy is guaranteed by very deep network structures, facial images often need to be transmitted to third-party servers with high computational power for inference. However, facial images visually reveal the user's identity information. In this process, both untrusted service providers and malicious users can significantly increase the risk of a personal privacy breach. Current privacy-preserving approaches to face recognition are often accompanied by many side effects, such as a significant increase in inference time or a noticeable decrease in recognition accuracy. This paper proposes a privacy-preserving face recognition method using differential privacy in the frequency domain. Due to the utilization of differential privacy, it offers a guarantee of privacy in theory. Meanwhile, the loss of accuracy is very slight. This method first converts the original image to the frequency domain and removes the direct component termed DC. Then a privacy budget allocation method can be learned based on the loss of the back-end face recognition network within the differential privacy framework. Finally, it adds the corresponding noise to the frequency domain features. Our method performs very well with several classical face recognition test sets according to the extensive experiments. ",
    "url": "https://arxiv.org/abs/2207.07316",
    "authors": [
      "Jiazhen Ji",
      "Huan Wang",
      "Yuge Huang",
      "Jiaxiang Wu",
      "Xingkun Xu",
      "Shouhong Ding",
      "ShengChuan Zhang",
      "Liujuan Cao",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07333",
    "title": "Rain Rate Estimation with SAR using NEXRAD measurements with  Convolutional Neural Networks",
    "abstract": "Remote sensing of rainfall events is critical for both operational and scientific needs, including for example weather forecasting, extreme flood mitigation, water cycle monitoring, etc. Ground-based weather radars, such as NOAA's Next-Generation Radar (NEXRAD), provide reflectivity and precipitation measurements of rainfall events. However, the observation range of such radars is limited to a few hundred kilometers, prompting the exploration of other remote sensing methods, paricularly over the open ocean, that represents large areas not covered by land-based radars. For a number of decades, C-band SAR imagery such a such as Sentinel-1 imagery has been known to exhibit rainfall signatures over the sea surface. However, the development of SAR-derived rainfall products remains a challenge. Here we propose a deep learning approach to extract rainfall information from SAR imagery. We demonstrate that a convolutional neural network, such as U-Net, trained on a colocated and preprocessed Sentinel-1/NEXRAD dataset clearly outperforms state-of-the-art filtering schemes. Our results indicate high performance in segmenting precipitation regimes, delineated by thresholds at 1, 3, and 10 mm/h. Compared to current methods that rely on Koch filters to draw binary rainfall maps, these multi-threshold learning-based models can provide rainfall estimation for higher wind speeds and thus may be of great interest for data assimilation weather forecasting or for improving the qualification of SAR-derived wind field data. ",
    "url": "https://arxiv.org/abs/2207.07333",
    "authors": [
      "Aur\u00e9lien Colin",
      "Pierre Tandeo",
      "Charles Peureux",
      "Romain Husson",
      "Nicolas Longepe",
      "Ronan Fablet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07335",
    "title": "Learning Parallax Transformer Network for Stereo Image JPEG Artifacts  Removal",
    "abstract": "Under stereo settings, the performance of image JPEG artifacts removal can be further improved by exploiting the additional information provided by a second view. However, incorporating this information for stereo image JPEG artifacts removal is a huge challenge, since the existing compression artifacts make pixel-level view alignment difficult. In this paper, we propose a novel parallax transformer network (PTNet) to integrate the information from stereo image pairs for stereo image JPEG artifacts removal. Specifically, a well-designed symmetric bi-directional parallax transformer module is proposed to match features with similar textures between different views instead of pixel-level view alignment. Due to the issues of occlusions and boundaries, a confidence-based cross-view fusion module is proposed to achieve better feature fusion for both views, where the cross-view features are weighted with confidence maps. Especially, we adopt a coarse-to-fine design for the cross-view interaction, leading to better performance. Comprehensive experimental results demonstrate that our PTNet can effectively remove compression artifacts and achieves superior performance than other testing state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2207.07335",
    "authors": [
      "Xuhao Jiang",
      "Weimin Tan",
      "Ri Cheng",
      "Shili Zhou",
      "Bo Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07338",
    "title": "Context-sensitive neocortical neurons transform the effectiveness and  efficiency of neural information processing",
    "abstract": "There is ample neurobiological evidence that context-sensitive neocortical neurons use their apical inputs as context to amplify the transmission of coherent feedforward (FF) inputs. However, it has not been demonstrated until now how this known mechanism can provide useful neural computation. Here we show for the first time that the processing and learning capabilities of this form of neural information processing are well-matched to the abilities of mammalian neocortex. Specifically, we show that a network composed of such local processors restricts the transmission of conflicting information to higher levels and greatly reduces the amount of activity required to process large amounts of heterogeneous real-world data e.g., when processing audiovisual speech, these local processors use seen lip movements to selectively amplify FF transmission of the auditory information that those movements generate and vice versa. As this mechanism is shown to be far more effective and efficient than the best available forms of deep neural nets, it offers a step-change in understanding the brain's mysterious energy-saving mechanism and inspires advances in designing enhanced forms of biologically plausible machine learning algorithms. ",
    "url": "https://arxiv.org/abs/2207.07338",
    "authors": [
      "Ahsan Adeel",
      "Mario Franco",
      "Mohsin Raza",
      "Khubaib Ahmed"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07347",
    "title": "Feasibility of Inconspicuous GAN-generated Adversarial Patches against  Object Detection",
    "abstract": "Standard approaches for adversarial patch generation lead to noisy conspicuous patterns, which are easily recognizable by humans. Recent research has proposed several approaches to generate naturalistic patches using generative adversarial networks (GANs), yet only a few of them were evaluated on the object detection use case. Moreover, the state of the art mostly focuses on suppressing a single large bounding box in input by overlapping it with the patch directly. Suppressing objects near the patch is a different, more complex task. In this work, we have evaluated the existing approaches to generate inconspicuous patches. We have adapted methods, originally developed for different computer vision tasks, to the object detection use case with YOLOv3 and the COCO dataset. We have evaluated two approaches to generate naturalistic patches: by incorporating patch generation into the GAN training process and by using the pretrained GAN. For both cases, we have assessed a trade-off between performance and naturalistic patch appearance. Our experiments have shown, that using a pre-trained GAN helps to gain realistic-looking patches while preserving the performance similar to conventional adversarial patches. ",
    "url": "https://arxiv.org/abs/2207.07347",
    "authors": [
      "Svetlana Pavlitskaya",
      "Bianca-Marina Cod\u0103u",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07351",
    "title": "Diverse Human Motion Prediction via Gumbel-Softmax Sampling from an  Auxiliary Space",
    "abstract": "Diverse human motion prediction aims at predicting multiple possible future pose sequences from a sequence of observed poses. Previous approaches usually employ deep generative networks to model the conditional distribution of data, and then randomly sample outcomes from the distribution. While different results can be obtained, they are usually the most likely ones which are not diverse enough. Recent work explicitly learns multiple modes of the conditional distribution via a deterministic network, which however can only cover a fixed number of modes within a limited range. In this paper, we propose a novel sampling strategy for sampling very diverse results from an imbalanced multimodal distribution learned by a deep generative model. Our method works by generating an auxiliary space and smartly making randomly sampling from the auxiliary space equivalent to the diverse sampling from the target distribution. We propose a simple yet effective network architecture that implements this novel sampling strategy, which incorporates a Gumbel-Softmax coefficient matrix sampling method and an aggressive diversity promoting hinge loss function. Extensive experiments demonstrate that our method significantly improves both the diversity and accuracy of the samplings compared with previous state-of-the-art sampling approaches. Code and pre-trained models are available at https://github.com/Droliven/diverse_sampling. ",
    "url": "https://arxiv.org/abs/2207.07351",
    "authors": [
      "Lingwei Dang",
      "Yongwei Nie",
      "Chengjiang Long",
      "Qing Zhang",
      "Guiqing Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07361",
    "title": "Registration based Few-Shot Anomaly Detection",
    "abstract": "This paper considers few-shot anomaly detection (FSAD), a practical yet under-studied setting for anomaly detection (AD), where only a limited number of normal images are provided for each category at training. So far, existing FSAD studies follow the one-model-per-category learning paradigm used for standard AD, and the inter-category commonality has not been explored. Inspired by how humans detect anomalies, i.e., comparing an image in question to normal images, we here leverage registration, an image alignment task that is inherently generalizable across categories, as the proxy task, to train a category-agnostic anomaly detection model. During testing, the anomalies are identified by comparing the registered features of the test image and its corresponding support (normal) images. As far as we know, this is the first FSAD method that trains a single generalizable model and requires no re-training or parameter fine-tuning for new categories. Experimental results have shown that the proposed method outperforms the state-of-the-art FSAD methods by 3%-8% in AUC on the MVTec and MPDD benchmarks. ",
    "url": "https://arxiv.org/abs/2207.07361",
    "authors": [
      "Chaoqin Huang",
      "Haoyan Guan",
      "Aofan Jiang",
      "Ya Zhang",
      "Michael Spratling",
      "Yan-Feng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07362",
    "title": "Error analysis for deep neural network approximations of parametric  hyperbolic conservation laws",
    "abstract": "We derive rigorous bounds on the error resulting from the approximation of the solution of parametric hyperbolic scalar conservation laws with ReLU neural networks. We show that the approximation error can be made as small as desired with ReLU neural networks that overcome the curse of dimensionality. In addition, we provide an explicit upper bound on the generalization error in terms of the training error, number of training samples and the neural network size. The theoretical results are illustrated by numerical experiments. ",
    "url": "https://arxiv.org/abs/2207.07362",
    "authors": [
      "Tim De Ryck",
      "Siddhartha Mishra"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07381",
    "title": "A Dual-Masked Auto-Encoder for Robust Motion Capture with  Spatial-Temporal Skeletal Token Completion",
    "abstract": "Multi-person motion capture can be challenging due to ambiguities caused by severe occlusion, fast body movement, and complex interactions. Existing frameworks build on 2D pose estimations and triangulate to 3D coordinates via reasoning the appearance, trajectory, and geometric consistencies among multi-camera observations. However, 2D joint detection is usually incomplete and with wrong identity assignments due to limited observation angle, which leads to noisy 3D triangulation results. To overcome this issue, we propose to explore the short-range autoregressive characteristics of skeletal motion using transformer. First, we propose an adaptive, identity-aware triangulation module to reconstruct 3D joints and identify the missing joints for each identity. To generate complete 3D skeletal motion, we then propose a Dual-Masked Auto-Encoder (D-MAE) which encodes the joint status with both skeletal-structural and temporal position encoding for trajectory completion. D-MAE's flexible masking and encoding mechanism enable arbitrary skeleton definitions to be conveniently deployed under the same framework. In order to demonstrate the proposed model's capability in dealing with severe data loss scenarios, we contribute a high-accuracy and challenging motion capture dataset of multi-person interactions with severe occlusion. Evaluations on both benchmark and our new dataset demonstrate the efficiency of our proposed model, as well as its advantage against the other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2207.07381",
    "authors": [
      "Junkun Jiang",
      "Jie Chen",
      "Yike Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07386",
    "title": "ChoreoGraph: Music-conditioned Automatic Dance Choreography over a Style  and Tempo Consistent Dynamic Graph",
    "abstract": "To generate dance that temporally and aesthetically matches the music is a challenging problem, as the following factors need to be considered. First, the aesthetic styles and messages conveyed by the motion and music should be consistent. Second, the beats of the generated motion should be locally aligned to the musical features. And finally, basic choreomusical rules should be observed, and the motion generated should be diverse. To address these challenges, we propose ChoreoGraph, which choreographs high-quality dance motion for a given piece of music over a Dynamic Graph. A data-driven learning strategy is proposed to evaluate the aesthetic style and rhythmic connections between music and motion in a progressively learned cross-modality embedding space. The motion sequences will be beats-aligned based on the music segments and then incorporated as nodes of a Dynamic Motion Graph. Compatibility factors such as the style and tempo consistency, motion context connection, action completeness, and transition smoothness are comprehensively evaluated to determine the node transition in the graph. We demonstrate that our repertoire-based framework can generate motions with aesthetic consistency and robustly extensible in diversity. Both quantitative and qualitative experiment results show that our proposed model outperforms other baseline models. ",
    "url": "https://arxiv.org/abs/2207.07386",
    "authors": [
      "Ho Yin Au",
      "Jie Chen",
      "Junkun Jiang",
      "Yike Guo"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.07399",
    "title": "An Approach for Link Prediction in Directed Complex Networks based on  Asymmetric Similarity-Popularity",
    "abstract": "Complex networks are graphs representing real-life systems that exhibit unique characteristics not found in purely regular or completely random graphs. The study of such systems is vital but challenging due to the complexity of the underlying processes. This task has nevertheless been made easier in recent decades thanks to the availability of large amounts of networked data. Link prediction in complex networks aims to estimate the likelihood that a link between two nodes is missing from the network. Links can be missing due to imperfections in data collection or simply because they are yet to appear. Discovering new relationships between entities in networked data has attracted researchers' attention in various domains such as sociology, computer science, physics, and biology. Most existing research focuses on link prediction in undirected complex networks. However, not all real-life systems can be faithfully represented as undirected networks. This simplifying assumption is often made when using link prediction algorithms but inevitably leads to loss of information about relations among nodes and degradation in prediction performance. This paper introduces a link prediction method designed explicitly for directed networks. It is based on the similarity-popularity paradigm, which has recently proven successful in undirected networks. The presented algorithms handle the asymmetry in node relationships by modeling it as asymmetry in similarity and popularity. Given the observed network topology, the algorithms approximate the hidden similarities as shortest path distances using edge weights that capture and factor out the links' asymmetry and nodes' popularity. The proposed approach is evaluated on real-life networks, and the experimental results demonstrate its effectiveness in predicting missing links across a broad spectrum of networked data types and sizes. ",
    "url": "https://arxiv.org/abs/2207.07399",
    "authors": [
      "Hafida Benhidour",
      "Lama Almeshkhas",
      "Said Kerrache"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07408",
    "title": "pathGCN: Learning General Graph Spatial Operators from Paths",
    "abstract": "Graph Convolutional Networks (GCNs), similarly to Convolutional Neural Networks (CNNs), are typically based on two main operations - spatial and point-wise convolutions. In the context of GCNs, differently from CNNs, a pre-determined spatial operator based on the graph Laplacian is often chosen, allowing only the point-wise operations to be learnt. However, learning a meaningful spatial operator is critical for developing more expressive GCNs for improved performance. In this paper we propose pathGCN, a novel approach to learn the spatial operator from random paths on the graph. We analyze the convergence of our method and its difference from existing GCNs. Furthermore, we discuss several options of combining our learnt spatial operator with point-wise convolutions. Our extensive experiments on numerous datasets suggest that by properly learning both the spatial and point-wise convolutions, phenomena like over-smoothing can be inherently avoided, and new state-of-the-art performance is achieved. ",
    "url": "https://arxiv.org/abs/2207.07408",
    "authors": [
      "Moshe Eliasof",
      "Eldad Haber",
      "Eran Treister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07413",
    "title": "SATAn: Air-Gap Exfiltration Attack via Radio Signals From SATA Cables",
    "abstract": "This paper introduces a new type of attack on isolated, air-gapped workstations. Although air-gap computers have no wireless connectivity, we show that attackers can use the SATA cable as a wireless antenna to transfer radio signals at the 6 GHz frequency band. The Serial ATA (SATA) is a bus interface widely used in modern computers and connects the host bus to mass storage devices such as hard disk drives, optical drives, and solid-state drives. The prevalence of the SATA interface makes this attack highly available to attackers in a wide range of computer systems and IT environments. We discuss related work on this topic and provide technical background. We show the design of the transmitter and receiver and present the implementation of these components. We also demonstrate the attack on different computers and provide the evaluation. The results show that attackers can use the SATA cable to transfer a brief amount of sensitive information from highly secured, air-gap computers wirelessly to a nearby receiver. Furthermore, we show that the attack can operate from user mode, is effective even from inside a Virtual Machine (VM), and can successfully work with other running workloads in the background. Finally, we discuss defense and mitigation techniques for this new air-gap attack. ",
    "url": "https://arxiv.org/abs/2207.07413",
    "authors": [
      "Mordechai Guri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.07417",
    "title": "Low Rank Approximation for General Tensor Networks",
    "abstract": "We study the problem of approximating a given tensor with $q$ modes $A \\in \\mathbb{R}^{n \\times \\ldots \\times n}$ with an arbitrary tensor network of rank $k$ -- that is, a graph $G = (V, E)$, where $|V| = q$, together with a collection of tensors $\\{U_v \\mid v \\in V\\}$ which are contracted in the manner specified by $G$ to obtain a tensor $T$. For each mode of $U_v$ corresponding to an edge incident to $v$, the dimension is $k$, and we wish to find $U_v$ such that the Frobenius norm distance between $T$ and $A$ is minimized. This generalizes a number of well-known tensor network decompositions, such as the Tensor Train, Tensor Ring, Tucker, and PEPS decompositions. We approximate $A$ by a binary tree network $T'$ with $O(q)$ cores, such that the dimension on each edge of this network is at most $\\widetilde{O}(k^{O(dt)} \\cdot q/\\varepsilon)$, where $d$ is the maximum degree of $G$ and $t$ is its treewidth, such that $\\|A - T'\\|_F^2 \\leq (1 + \\varepsilon) \\|A - T\\|_F^2$. The running time of our algorithm is $O(q \\cdot \\text{nnz}(A)) + n \\cdot \\text{poly}(k^{dt}q/\\varepsilon)$, where $\\text{nnz}(A)$ is the number of nonzero entries of $A$. Our algorithm is based on a new dimensionality reduction technique for tensor decomposition which may be of independent interest. We also develop fixed-parameter tractable $(1 + \\varepsilon)$-approximation algorithms for Tensor Train and Tucker decompositions, improving the running time of Song, Woodruff and Zhong (SODA, 2019) and avoiding the use of generic polynomial system solvers. We show that our algorithms have a nearly optimal dependence on $1/\\varepsilon$ assuming that there is no $O(1)$-approximation algorithm for the $2 \\to 4$ norm with better running time than brute force. Finally, we give additional results for Tucker decomposition with robust loss functions, and fixed-parameter tractable CP decomposition. ",
    "url": "https://arxiv.org/abs/2207.07417",
    "authors": [
      "Arvind V. Mahankali",
      "David P. Woodruff",
      "Ziyu Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07454",
    "title": "Multi-Object Tracking and Segmentation via Neural Message Passing",
    "abstract": "Graphs offer a natural way to formulate Multiple Object Tracking (MOT) and Multiple Object Tracking and Segmentation (MOTS) within the tracking-by-detection paradigm. However, they also introduce a major challenge for learning methods, as defining a model that can operate on such structured domain is not trivial. In this work, we exploit the classical network flow formulation of MOT to define a fully differentiable framework based on Message Passing Networks (MPNs). By operating directly on the graph domain, our method can reason globally over an entire set of detections and exploit contextual features. It then jointly predicts both final solutions for the data association problem and segmentation masks for all objects in the scene while exploiting synergies between the two tasks. We achieve state-of-the-art results for both tracking and segmentation in several publicly available datasets. Our code is available at github.com/ocetintas/MPNTrackSeg. ",
    "url": "https://arxiv.org/abs/2207.07454",
    "authors": [
      "Guillem Braso",
      "Orcun Cetintas",
      "Laura Leal-Taixe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07465",
    "title": "Creating an Explainable Intrusion Detection System Using Self Organizing  Maps",
    "abstract": "Modern Artificial Intelligence (AI) enabled Intrusion Detection Systems (IDS) are complex black boxes. This means that a security analyst will have little to no explanation or clarification on why an IDS model made a particular prediction. A potential solution to this problem is to research and develop Explainable Intrusion Detection Systems (X-IDS) based on current capabilities in Explainable Artificial Intelligence (XAI). In this paper, we create a Self Organizing Maps (SOMs) based X-IDS system that is capable of producing explanatory visualizations. We leverage SOM's explainability to create both global and local explanations. An analyst can use global explanations to get a general idea of how a particular IDS model computes predictions. Local explanations are generated for individual datapoints to explain why a certain prediction value was computed. Furthermore, our SOM based X-IDS was evaluated on both explanation generation and traditional accuracy tests using the NSL-KDD and the CIC-IDS-2017 datasets. ",
    "url": "https://arxiv.org/abs/2207.07465",
    "authors": [
      "Jesse Ables",
      "Thomas Kirby",
      "William Anderson",
      "Sudip Mittal",
      "Shahram Rahimi",
      "Ioana Banicescu",
      "Maria Seale"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07469",
    "title": "USegScene: Unsupervised Learning of Depth, Optical Flow and Ego-Motion  with Semantic Guidance and Coupled Networks",
    "abstract": "In this paper we propose USegScene, a framework for semantically guided unsupervised learning of depth, optical flow and ego-motion estimation for stereo camera images using convolutional neural networks. Our framework leverages semantic information for improved regularization of depth and optical flow maps, multimodal fusion and occlusion filling considering dynamic rigid object motions as independent SE(3) transformations. Furthermore, complementary to pure photo-metric matching, we propose matching of semantic features, pixel-wise classes and object instance borders between the consecutive images. In contrast to previous methods, we propose a network architecture that jointly predicts all outputs using shared encoders and allows passing information across the task-domains, e.g., the prediction of optical flow can benefit from the prediction of the depth. Furthermore, we explicitly learn the depth and optical flow occlusion maps inside the network, which are leveraged in order to improve the predictions in therespective regions. We present results on the popular KITTI dataset and show that our approach outperforms other methods by a large margin. ",
    "url": "https://arxiv.org/abs/2207.07469",
    "authors": [
      "Johan Vertens",
      "Wolfram Burgard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.07478",
    "title": "Yourfeed: Towards open science and interoperable systems for social  media",
    "abstract": "Existing social media platforms (SMPs) make it incredibly difficult for researchers to conduct studies on social media, which in turn has created a knowledge gap between academia and industry about the effects of platform design on user behavior. To close the gap, we introduce Yourfeed, a research tool for conducting ecologically valid social media research. We introduce the platform architecture, as well key opportunities such as assessing the effects of exposure of content on downstream beliefs and attitudes, measuring attentional exposure via dwell time, and evaluating heterogeneous newsfeed algorithms. We discuss the underlying philosophy of interoperability for social media and future developments for the platform. ",
    "url": "https://arxiv.org/abs/2207.07478",
    "authors": [
      "Ziv Epstein",
      "Hause Lin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.07482",
    "title": "The Mechanical Neural Network(MNN) -- A physical implementation of a  multilayer perceptron for education and hands-on experimentation",
    "abstract": "In this paper the Mechanical Neural Network(MNN) is introduced, a physical implementation of a multilayer perceptron(MLP) with ReLU activation functions, two input neurons, four hidden neurons and two output neurons. This physical model of a MLP is used in education to give a hands on experience and allow students to experience the effect of changing the parameters of the network on the output. Neurons are small wooden levers which are connected by threads. Students can adapt the weights between the neurons by moving the clamps connecting a neuron via a thread to the next. The MNN can model real valued functions and logical operators including XOR. ",
    "url": "https://arxiv.org/abs/2207.07482",
    "authors": [
      "Axel Schaffland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07488",
    "title": "Iterative solution of spatial network models by subspace decomposition",
    "abstract": "We present and analyze a preconditioned conjugate gradient method (PCG) for solving spatial network problems. Primarily, we consider diffusion and structural mechanics simulations for fiber based materials, but the methodology can be applied to a wide range of models, fulfilling a set of abstract assumptions. The proposed method builds on a classical subspace decomposition into a coarse subspace, realized as the restriction of a finite element space to the nodes of the spatial network, and localized subspaces with support on mesh stars. The main contribution of this work is the convergence analysis of the proposed method. The analysis translates results from finite element theory, including interpolation bounds, to the spatial network setting. A convergence rate of the PCG algorithm, only depending on global bounds of the operator and homogeneity, connectivity and locality constants of the network, is established. The theoretical results are confirmed by several numerical experiments. ",
    "url": "https://arxiv.org/abs/2207.07488",
    "authors": [
      "Morgan G\u00f6rtz",
      "Fredrik Hellman",
      "Axel M\u00e5lqvist"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.07497",
    "title": "Low-bit Shift Network for End-to-End Spoken Language Understanding",
    "abstract": "Deep neural networks (DNN) have achieved impressive success in multiple domains. Over the years, the accuracy of these models has increased with the proliferation of deeper and more complex architectures. Thus, state-of-the-art solutions are often computationally expensive, which makes them unfit to be deployed on edge computing platforms. In order to mitigate the high computation, memory, and power requirements of inferring convolutional neural networks (CNNs), we propose the use of power-of-two quantization, which quantizes continuous parameters into low-bit power-of-two values. This reduces computational complexity by removing expensive multiplication operations and with the use of low-bit weights. ResNet is adopted as the building block of our solution and the proposed model is evaluated on a spoken language understanding (SLU) task. Experimental results show improved performance for shift neural network architectures, with our low-bit quantization achieving 98.76 \\% on the test set which is comparable performance to its full-precision counterpart and state-of-the-art solutions. ",
    "url": "https://arxiv.org/abs/2207.07497",
    "authors": [
      "Anderson R. Avila",
      "Khalil Bibi",
      "Rui Heng Yang",
      "Xinlin Li",
      "Chao Xing",
      "Xiao Chen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.07503",
    "title": "Explainable Sparse Knowledge Graph Completion via High-order Graph  Reasoning Network",
    "abstract": "Knowledge Graphs (KGs) are becoming increasingly essential infrastructures in many applications while suffering from incompleteness issues. The KG completion task (KGC) automatically predicts missing facts based on an incomplete KG. However, existing methods perform unsatisfactorily in real-world scenarios. On the one hand, their performance will dramatically degrade along with the increasing sparsity of KGs. On the other hand, the inference procedure for prediction is an untrustworthy black box. This paper proposes a novel explainable model for sparse KGC, compositing high-order reasoning into a graph convolutional network, namely HoGRN. It can not only improve the generalization ability to mitigate the information insufficiency issue but also provide interpretability while maintaining the model's effectiveness and efficiency. There are two main components that are seamlessly integrated for joint optimization. First, the high-order reasoning component learns high-quality relation representations by capturing endogenous correlation among relations. This can reflect logical rules to justify a broader of missing facts. Second, the entity updating component leverages a weight-free Graph Convolutional Network (GCN) to efficiently model KG structures with interpretability. Unlike conventional methods, we conduct entity aggregation and design composition-based attention in the relational space without additional parameters. The lightweight design makes HoGRN better suitable for sparse settings. For evaluation, we have conducted extensive experiments-the results of HoGRN on several sparse KGs present impressive improvements (9% MRR gain on average). Further ablation and case studies demonstrate the effectiveness of the main components. Our codes will be released upon acceptance. ",
    "url": "https://arxiv.org/abs/2207.07503",
    "authors": [
      "Weijian Chen",
      "Yixin Cao",
      "Fuli Feng",
      "Xiangnan He",
      "Yongdong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.07517",
    "title": "On the Usefulness of Deep Ensemble Diversity for Out-of-Distribution  Detection",
    "abstract": "The ability to detect Out-of-Distribution (OOD) data is important in safety-critical applications of deep learning. The aim is to separate In-Distribution (ID) data drawn from the training distribution from OOD data using a measure of uncertainty extracted from a deep neural network. Deep Ensembles are a well-established method of improving the quality of uncertainty estimates produced by deep neural networks, and have been shown to have superior OOD detection performance compared to single models. An existing intuition in the literature is that the diversity of Deep Ensemble predictions indicates distributional shift, and so measures of diversity such as Mutual Information (MI) should be used for OOD detection. We show experimentally that this intuition is not valid on ImageNet-scale OOD detection -- using MI leads to 30-40% worse %FPR@95 compared to single-model entropy on some OOD datasets. We suggest an alternative explanation for Deep Ensembles' better OOD detection performance -- OOD detection is binary classification and we are ensembling diverse classifiers. As such we show that practically, even better OOD detection performance can be achieved for Deep Ensembles by averaging task-specific detection scores such as Energy over the ensemble. ",
    "url": "https://arxiv.org/abs/2207.07517",
    "authors": [
      "Guoxuan Xia",
      "Christos-Savvas Bouganis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07520",
    "title": "Short-Term Trajectory Prediction for Full-Immersive Multiuser Virtual  Reality with Redirected Walking",
    "abstract": "Full-immersive multiuser Virtual Reality (VR) envisions supporting unconstrained mobility of the users in the virtual worlds, while at the same time constraining their physical movements inside VR setups through redirected walking. For enabling delivery of high data rate video content in real-time, the supporting wireless networks will leverage highly directional communication links that will \"track\" the users for maintaining the Line-of-Sight (LoS) connectivity. Recurrent Neural Networks (RNNs) and in particular Long Short-Term Memory (LSTM) networks have historically presented themselves as a suitable candidate for near-term movement trajectory prediction for natural human mobility, and have also recently been shown as applicable in predicting VR users' mobility under the constraints of redirected walking. In this work, we extend these initial findings by showing that Gated Recurrent Unit (GRU) networks, another candidate from the RNN family, generally outperform the traditionally utilized LSTMs. Second, we show that context from a virtual world can enhance the accuracy of the prediction if used as an additional input feature in comparison to the more traditional utilization of solely the historical physical movements of the VR users. Finally, we show that the prediction system trained on a static number of coexisting VR users be scaled to a multi-user system without significant accuracy degradation. ",
    "url": "https://arxiv.org/abs/2207.07520",
    "authors": [
      "Filip Lemic",
      "Jakob Struye",
      "Jeroen Famaey"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.07539",
    "title": "3DVerifier: Efficient Robustness Verification for 3D Point Cloud Models",
    "abstract": "3D point cloud models are widely applied in safety-critical scenes, which delivers an urgent need to obtain more solid proofs to verify the robustness of models. Existing verification method for point cloud model is time-expensive and computationally unattainable on large networks. Additionally, they cannot handle the complete PointNet model with joint alignment network (JANet) that contains multiplication layers, which effectively boosts the performance of 3D models. This motivates us to design a more efficient and general framework to verify various architectures of point cloud models. The key challenges in verifying the large-scale complete PointNet models are addressed as dealing with the cross-non-linearity operations in the multiplication layers and the high computational complexity of high-dimensional point cloud inputs and added layers. Thus, we propose an efficient verification framework, 3DVerifier, to tackle both challenges by adopting a linear relaxation function to bound the multiplication layer and combining forward and backward propagation to compute the certified bounds of the outputs of the point cloud models. Our comprehensive experiments demonstrate that 3DVerifier outperforms existing verification algorithms for 3D models in terms of both efficiency and accuracy. Notably, our approach achieves an orders-of-magnitude improvement in verification efficiency for the large network, and the obtained certified bounds are also significantly tighter than the state-of-the-art verifiers. We release our tool 3DVerifier via https://github.com/TrustAI/3DVerifier for use by the community. ",
    "url": "https://arxiv.org/abs/2207.07539",
    "authors": [
      "Ronghui Mu",
      "Wenjie Ruan",
      "Leandro S. Marcolino",
      "Qiang Ni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07562",
    "title": "How many others have shared this? Experimentally investigating the  effects of social cues on engagement, misinformation, and unpredictability on  social media",
    "abstract": "Unlike traditional media, social media typically provides quantified metrics of how many users have engaged with each piece of content. Some have argued that the presence of these cues promotes the spread of misinformation. Here we investigate the causal effect of social cues on users' engagement with social media posts. We conducted an experiment with N=628 Americans on a custom-built newsfeed interface where we systematically varied the presence and strength of social cues. We find that when cues are shown, indicating that a larger number of others have engaged with a post, users were more likely to share and like that post. Furthermore, relative to a control without social cues, the presence of social cues increased the sharing of true relative to false news. The presence of social cues also makes it more difficult to precisely predict how popular any given post would be. Together, our results suggest that -- instead of distracting users or causing them to share low-quality news -- social cues may, in certain circumstances, actually boost truth discernment and reduce the sharing of misinformation. Our work suggests that social cues play important roles in shaping users' attention and engagement on social media, and platforms should understand the effects of different cues before making changes to what cues are displayed and how. ",
    "url": "https://arxiv.org/abs/2207.07562",
    "authors": [
      "Ziv Epstein",
      "Hause Lin",
      "Gordon Pennycook",
      "David Rand"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2207.07572",
    "title": "Outlier detection of vital sign trajectories from COVID-19 patients",
    "abstract": "There is growing interest in continuous wearable vital sign sensors for monitoring patients remotely at home. These monitors are usually coupled to an alerting system, which is triggered when vital sign measurements fall outside a predefined normal range. Trends in vital signs, such as an increasing heart rate, are often indicative of deteriorating health, but are rarely incorporated into alerting systems. In this work, we present a novel outlier detection algorithm to identify such abnormal vital sign trends. We introduce a distance-based measure to compare vital sign trajectories. For each patient in our dataset, we split vital sign time series into 180 minute, non-overlapping epochs. We then calculated a distance between all pairs of epochs using the dynamic time warp distance. Each epoch was characterized by its mean pairwise distance (average link distance) to all other epochs, with large distances considered as outliers. We applied this method to a pilot dataset collected over 1561 patient-hours from 8 patients who had recently been discharged from hospital after contracting COVID-19. We show that outlier epochs correspond well with patients who were subsequently readmitted to hospital. We also show, descriptively, how epochs transition from normal to abnormal for one such patient. ",
    "url": "https://arxiv.org/abs/2207.07572",
    "authors": [
      "Sara Summerton",
      "Ann Tivey",
      "Rohan Shotton",
      "Gavin Brown",
      "Oliver C. Redfern",
      "Rachel Oakley",
      "John Radford",
      "David C. Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.07580",
    "title": "Analysis, Characterization, Prediction and Attribution of Extreme  Atmospheric Events with Machine Learning: a Review",
    "abstract": "Atmospheric Extreme Events (EEs) cause severe damages to human societies and ecosystems. The frequency and intensity of EEs and other associated events are increasing in the current climate change and global warming risk. The accurate prediction, characterization, and attribution of atmospheric EEs is therefore a key research field, in which many groups are currently working by applying different methodologies and computational tools. Machine Learning (ML) methods have arisen in the last years as powerful techniques to tackle many of the problems related to atmospheric EEs. This paper reviews the ML algorithms applied to the analysis, characterization, prediction, and attribution of the most important atmospheric EEs. A summary of the most used ML techniques in this area, and a comprehensive critical review of literature related to ML in EEs, are provided. A number of examples is discussed and perspectives and outlooks on the field are drawn. ",
    "url": "https://arxiv.org/abs/2207.07580",
    "authors": [
      "Sancho Salcedo-Sanz",
      "Jorge P\u00e9rez-Aracil",
      "Guido Ascenso",
      "Javier Del Ser",
      "David Casillas-P\u00e9rez",
      "Christopher Kadow",
      "Dusan Fister",
      "David Barriopedro",
      "Ricardo Garc\u00eda-Herrera",
      "Marcello Restelli",
      "Mateo Giuliani",
      "Andrea Castelletti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2207.07611",
    "title": "Position Prediction as an Effective Pretraining Strategy",
    "abstract": "Transformers have gained increasing popularity in a wide range of applications, including Natural Language Processing (NLP), Computer Vision and Speech Recognition, because of their powerful representational capacity. However, harnessing this representational capacity effectively requires a large amount of data, strong regularization, or both, to mitigate overfitting. Recently, the power of the Transformer has been unlocked by self-supervised pretraining strategies based on masked autoencoders which rely on reconstructing masked inputs, directly, or contrastively from unmasked content. This pretraining strategy which has been used in BERT models in NLP, Wav2Vec models in Speech and, recently, in MAE models in Vision, forces the model to learn about relationships between the content in different parts of the input using autoencoding related objectives. In this paper, we propose a novel, but surprisingly simple alternative to content reconstruction~-- that of predicting locations from content, without providing positional information for it. Doing so requires the Transformer to understand the positional relationships between different parts of the input, from their content alone. This amounts to an efficient implementation where the pretext task is a classification problem among all possible positions for each input token. We experiment on both Vision and Speech benchmarks, where our approach brings improvements over strong supervised training baselines and is comparable to modern unsupervised/self-supervised pretraining methods. Our method also enables Transformers trained without position embeddings to outperform ones trained with full position information. ",
    "url": "https://arxiv.org/abs/2207.07611",
    "authors": [
      "Shuangfei Zhai",
      "Navdeep Jaitly",
      "Jason Ramapuram",
      "Dan Busbridge",
      "Tatiana Likhomanenko",
      "Joseph Yitan Cheng",
      "Walter Talbott",
      "Chen Huang",
      "Hanlin Goh",
      "Joshua Susskind"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.07613",
    "title": "Improved Algorithms for Recognizing Perfect Graphs and Finding Shortest  Odd and Even Holes",
    "abstract": "Various classes of induced subgraphs are involved in the deepest results of graph theory and graph algorithms. A prominent example concerns the {\\em perfection} of $G$ that the chromatic number of each induced subgraph $H$ of $G$ equals the clique number of $H$. The seminal Strong Perfect Graph Theorem confirms that the perfection of $G$ can be determined by detecting odd holes in $G$ and its complement. Chudnovsky et al. show in 2005 an $O(n^9)$ algorithm for recognizing perfect graphs, which can be implemented to run in $O(n^{6+\\omega})$ time for the exponent $\\omega<2.373$ of square-matrix multiplication. We show the following improved algorithms. 1. The tractability of detecting odd holes was open for decades until the major breakthrough of Chudnovsky et al. in 2020. Their $O(n^9)$ algorithm is later implemented by Lai et al. to run in $O(n^8)$ time, leading to the best formerly known algorithm for recognizing perfect graphs. Our first result is an $O(n^7)$ algorithm for detecting odd holes, implying an $O(n^7)$ algorithm for recognizing perfect graphs. 2. Chudnovsky et al. extend in 2021 the $O(n^9)$ algorithms for detecting odd holes (2020) and recognizing perfect graphs (2005) into the first polynomial algorithm for obtaining a shortest odd hole, which runs in $O(n^{14})$ time. We reduce the time for finding a shortest odd hole to $O(n^{13})$. 3. Conforti et al. show in 1997 the first polynomial algorithm for detecting even holes, running in about $O(n^{40})$ time. It then takes a line of intensive efforts in the literature to bring down the complexity to $O(n^{31})$, $O(n^{19})$, $O(n^{11})$, and finally $O(n^9)$. On the other hand, the tractability of finding a shortest even hole has been open for 16 years until the very recent $O(n^{31})$ algorithm of Cheong and Lu in 2022. We improve the time of finding a shortest even hole to $O(n^{23})$. ",
    "url": "https://arxiv.org/abs/2207.07613",
    "authors": [
      "Yung-Chung Chiu",
      "Kai-Yuan Lai",
      "Hsueh-I Lu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2207.07619",
    "title": "A Non-Anatomical Graph Structure for isolated hand gesture separation in  continuous gesture sequences",
    "abstract": "Continuous Hand Gesture Recognition (CHGR) has been extensively studied by researchers in the last few decades. Recently, one model has been presented to deal with the challenge of the boundary detection of isolated gestures in a continuous gesture video [17]. To enhance the model performance and also replace the handcrafted feature extractor in the presented model in [17], we propose a GCN model and combine it with the stacked Bi-LSTM and Attention modules to push the temporal information in the video stream. Considering the breakthroughs of GCN models for skeleton modality, we propose a two-layer GCN model to empower the 3D hand skeleton features. Finally, the class probabilities of each isolated gesture are fed to the post-processing module, borrowed from [17]. Furthermore, we replace the anatomical graph structure with some non-anatomical graph structures. Due to the lack of a large dataset, including both the continuous gesture sequences and the corresponding isolated gestures, three public datasets in Dynamic Hand Gesture Recognition (DHGR), RKS-PERSIANSIGN, and ASLVID, are used for evaluation. Experimental results show the superiority of the proposed model in dealing with isolated gesture boundaries detection in continuous gesture sequences ",
    "url": "https://arxiv.org/abs/2207.07619",
    "authors": [
      "Razieh Rastgoo",
      "Kourosh Kiani",
      "Sergio Escalera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07621",
    "title": "MegaPortraits: One-shot Megapixel Neural Head Avatars",
    "abstract": "In this work, we advance the neural head avatar technology to the megapixel resolution while focusing on the particularly challenging task of cross-driving synthesis, i.e., when the appearance of the driving image is substantially different from the animated source image. We propose a set of new neural architectures and training methods that can leverage both medium-resolution video data and high-resolution image data to achieve the desired levels of rendered image quality and generalization to novel views and motion. We demonstrate that suggested architectures and methods produce convincing high-resolution neural avatars, outperforming the competitors in the cross-driving scenario. Lastly, we show how a trained high-resolution neural avatar model can be distilled into a lightweight student model which runs in real-time and locks the identities of neural avatars to several dozens of pre-defined source images. Real-time operation and identity lock are essential for many practical applications head avatar systems. ",
    "url": "https://arxiv.org/abs/2207.07621",
    "authors": [
      "Nikita Drobyshev",
      "Jenya Chelishev",
      "Taras Khakhulin",
      "Aleksei Ivakhnenko",
      "Victor Lempitsky",
      "Egor Zakharov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07626",
    "title": "Computing-In-Memory Neural Network Accelerators for Safety-Critical  Systems: Can Small Device Variations Be Disastrous?",
    "abstract": "Computing-in-Memory (CiM) architectures based on emerging non-volatile memory (NVM) devices have demonstrated great potential for deep neural network (DNN) acceleration thanks to their high energy efficiency. However, NVM devices suffer from various non-idealities, especially device-to-device variations due to fabrication defects and cycle-to-cycle variations due to the stochastic behavior of devices. As such, the DNN weights actually mapped to NVM devices could deviate significantly from the expected values, leading to large performance degradation. To address this issue, most existing works focus on maximizing average performance under device variations. This objective would work well for general-purpose scenarios. But for safety-critical applications, the worst-case performance must also be considered. Unfortunately, this has been rarely explored in the literature. In this work, we formulate the problem of determining the worst-case performance of CiM DNN accelerators under the impact of device variations. We further propose a method to effectively find the specific combination of device variation in the high-dimensional space that leads to the worst-case performance. We find that even with very small device variations, the accuracy of a DNN can drop drastically, causing concerns when deploying CiM accelerators in safety-critical applications. Finally, we show that surprisingly none of the existing methods used to enhance average DNN performance in CiM accelerators are very effective when extended to enhance the worst-case performance, and further research down the road is needed to address this problem. ",
    "url": "https://arxiv.org/abs/2207.07626",
    "authors": [
      "Zheyu Yan",
      "Xiaobo Sharon Hu",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07635",
    "title": "Is a Caption Worth a Thousand Images? A Controlled Study for  Representation Learning",
    "abstract": "The development of CLIP [Radford et al., 2021] has sparked a debate on whether language supervision can result in vision models with more transferable representations than traditional image-only methods. Our work studies this question through a carefully controlled comparison of two approaches in terms of their ability to learn representations that generalize to downstream classification tasks. We find that when the pre-training dataset meets certain criteria -- it is sufficiently large and contains descriptive captions with low variability -- image-only methods do not match CLIP's transfer performance, even when they are trained with more image data. However, contrary to what one might expect, there are practical settings in which these criteria are not met, wherein added supervision through captions is actually detrimental. Motivated by our findings, we devise simple prescriptions to enable CLIP to better leverage the language information present in existing pre-training datasets. ",
    "url": "https://arxiv.org/abs/2207.07635",
    "authors": [
      "Shibani Santurkar",
      "Yann Dubois",
      "Rohan Taori",
      "Percy Liang",
      "Tatsunori Hashimoto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.07273",
    "title": "Direction-Aware Joint Adaptation of Neural Speech Enhancement and  Recognition in Real Multiparty Conversational Environments",
    "abstract": "This paper describes noisy speech recognition for an augmented reality headset that helps verbal communication within real multiparty conversational environments. A major approach that has actively been studied in simulated environments is to sequentially perform speech enhancement and automatic speech recognition (ASR) based on deep neural networks (DNNs) trained in a supervised manner. In our task, however, such a pretrained system fails to work due to the mismatch between the training and test conditions and the head movements of the user. To enhance only the utterances of a target speaker, we use beamforming based on a DNN-based speech mask estimator that can adaptively extract the speech components corresponding to a head-relative particular direction. We propose a semi-supervised adaptation method that jointly updates the mask estimator and the ASR model at run-time using clean speech signals with ground-truth transcriptions and noisy speech signals with highly-confident estimated transcriptions. Comparative experiments using the state-of-the-art distant speech recognition system show that the proposed method significantly improves the ASR performance. ",
    "url": "https://arxiv.org/abs/2207.07273",
    "authors": [
      "Yicheng Du",
      "Aditya Arie Nugraha",
      "Kouhei Sekiguchi",
      "Yoshiaki Bando",
      "Mathieu Fontaine",
      "Kazuyoshi Yoshii"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2207.07296",
    "title": "Direction-Aware Adaptive Online Neural Speech Enhancement with an  Augmented Reality Headset in Real Noisy Conversational Environments",
    "abstract": "This paper describes the practical response- and performance-aware development of online speech enhancement for an augmented reality (AR) headset that helps a user understand conversations made in real noisy echoic environments (e.g., cocktail party). One may use a state-of-the-art blind source separation method called fast multichannel nonnegative matrix factorization (FastMNMF) that works well in various environments thanks to its unsupervised nature. Its heavy computational cost, however, prevents its application to real-time processing. In contrast, a supervised beamforming method that uses a deep neural network (DNN) for estimating spatial information of speech and noise readily fits real-time processing, but suffers from drastic performance degradation in mismatched conditions. Given such complementary characteristics, we propose a dual-process robust online speech enhancement method based on DNN-based beamforming with FastMNMF-guided adaptation. FastMNMF (back end) is performed in a mini-batch style and the noisy and enhanced speech pairs are used together with the original parallel training data for updating the direction-aware DNN (front end) with backpropagation at a computationally-allowable interval. This method is used with a blind dereverberation method called weighted prediction error (WPE) for transcribing the noisy reverberant speech of a speaker, which can be detected from video or selected by a user's hand gesture or eye gaze, in a streaming manner and spatially showing the transcriptions with an AR technique. Our experiment showed that the word error rate was improved by more than 10 points with the run-time adaptation using only twelve minutes of observation. ",
    "url": "https://arxiv.org/abs/2207.07296",
    "authors": [
      "Kouhei Sekiguchi",
      "Aditya Arie Nugraha",
      "Yicheng Du",
      "Yoshiaki Bando",
      "Mathieu Fontaine",
      "Kazuyoshi Yoshii"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2207.07301",
    "title": "Robust Deep Compressive Sensing with Recurrent-Residual Structural  Constraints",
    "abstract": "Existing deep compressive sensing (CS) methods either ignore adaptive online optimization or depend on costly iterative optimizer during reconstruction. This work explores a novel image CS framework with recurrent-residual structural constraint, termed as R$^2$CS-NET. The R$^2$CS-NET first progressively optimizes the acquired samplings through a novel recurrent neural network. The cascaded residual convolutional network then fully reconstructs the image from optimized latent representation. As the first deep CS framework efficiently bridging adaptive online optimization, the R$^2$CS-NET integrates the robustness of online optimization with the efficiency and nonlinear capacity of deep learning methods. Signal correlation has been addressed through the network architecture. The adaptive sensing nature further makes it an ideal candidate for color image CS via leveraging channel correlation. Numerical experiments verify the proposed recurrent latent optimization design not only fulfills the adaptation motivation, but also outperforms classic long short-term memory (LSTM) architecture in the same scenario. The overall framework demonstrates hardware implementation feasibility, with leading robustness and generalization capability among existing deep CS benchmarks. ",
    "url": "https://arxiv.org/abs/2207.07301",
    "authors": [
      "Jun Niu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07303",
    "title": "Towards Better Dermoscopic Image Feature Representation Learning for  Melanoma Classification",
    "abstract": "Deep learning-based melanoma classification with dermoscopic images has recently shown great potential in automatic early-stage melanoma diagnosis. However, limited by the significant data imbalance and obvious extraneous artifacts, i.e., the hair and ruler markings, discriminative feature extraction from dermoscopic images is very challenging. In this study, we seek to resolve these problems respectively towards better representation learning for lesion features. Specifically, a GAN-based data augmentation (GDA) strategy is adapted to generate synthetic melanoma-positive images, in conjunction with the proposed implicit hair denoising (IHD) strategy. Wherein the hair-related representations are implicitly disentangled via an auxiliary classifier network and reversely sent to the melanoma-feature extraction backbone for better melanoma-specific representation learning. Furthermore, to train the IHD module, the hair noises are additionally labeled on the ISIC2020 dataset, making it the first large-scale dermoscopic dataset with annotation of hair-like artifacts. Extensive experiments demonstrate the superiority of the proposed framework as well as the effectiveness of each component. The improved dataset publicly avaliable at https://github.com/kirtsy/DermoscopicDataset. ",
    "url": "https://arxiv.org/abs/2207.07303",
    "authors": [
      "ChengHui Yu",
      "MingKang Tang",
      "ShengGe Yang",
      "MingQing Wang",
      "Zhe Xu",
      "JiangPeng Yan",
      "HanMo Chen",
      "Yu Yang",
      "Xiao-Jun Zeng",
      "Xiu Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07307",
    "title": "MIMO-DoAnet: Multi-channel Input and Multiple Outputs DoA Network with  Unknown Number of Sound Sources",
    "abstract": "Recent neural network based Direction of Arrival (DoA) estimation algorithms have performed well on unknown number of sound sources scenarios. These algorithms are usually achieved by mapping the multi-channel audio input to the single output (i.e. overall spatial pseudo-spectrum (SPS) of all sources), that is called MISO. However, such MISO algorithms strongly depend on empirical threshold setting and the angle assumption that the angles between the sound sources are greater than a fixed angle. To address these limitations, we propose a novel multi-channel input and multiple outputs DoA network called MIMO-DoAnet. Unlike the general MISO algorithms, MIMO-DoAnet predicts the SPS coding of each sound source with the help of the informative spatial covariance matrix. By doing so, the threshold task of detecting the number of sound sources becomes an easier task of detecting whether there is a sound source in each output, and the serious interaction between sound sources disappears during inference stage. Experimental results show that MIMO-DoAnet achieves relative 18.6% and absolute 13.3%, relative 34.4% and absolute 20.2% F1 score improvement compared with the MISO baseline system in 3, 4 sources scenes. The results also demonstrate MIMO-DoAnet alleviates the threshold setting problem and solves the angle assumption problem effectively. ",
    "url": "https://arxiv.org/abs/2207.07307",
    "authors": [
      "Haoran Yin",
      "Meng Ge",
      "Yanjie Fu",
      "Gaoyan Zhang",
      "Longbiao Wang",
      "Lei Zhang",
      "Lin Qiu",
      "Jianwu Dang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2207.07334",
    "title": "Computer Vision for Volunteer Cotton Detection in a Corn Field with UAS  Remote Sensing Imagery and Spot Spray Applications",
    "abstract": "To control boll weevil (Anthonomus grandis L.) pest re-infestation in cotton fields, the current practices of volunteer cotton (VC) (Gossypium hirsutum L.) plant detection in fields of rotation crops like corn (Zea mays L.) and sorghum (Sorghum bicolor L.) involve manual field scouting at the edges of fields. This leads to many VC plants growing in the middle of fields remain undetected that continue to grow side by side along with corn and sorghum. When they reach pinhead squaring stage (5-6 leaves), they can serve as hosts for the boll weevil pests. Therefore, it is required to detect, locate and then precisely spot-spray them with chemicals. In this paper, we present the application of YOLOv5m on radiometrically and gamma-corrected low resolution (1.2 Megapixel) multispectral imagery for detecting and locating VC plants growing in the middle of tasseling (VT) growth stage of cornfield. Our results show that VC plants can be detected with a mean average precision (mAP) of 79% and classification accuracy of 78% on images of size 1207 x 923 pixels at an average inference speed of nearly 47 frames per second (FPS) on NVIDIA Tesla P100 GPU-16GB and 0.4 FPS on NVIDIA Jetson TX2 GPU. We also demonstrate the application of a customized unmanned aircraft systems (UAS) for spot-spray applications based on the developed computer vision (CV) algorithm and how it can be used for near real-time detection and mitigation of VC plants growing in corn fields for efficient management of the boll weevil pests. ",
    "url": "https://arxiv.org/abs/2207.07334",
    "authors": [
      "Pappu Kumar Yadav",
      "J. Alex Thomasson",
      "Stephen W. Searcy",
      "Robert G. Hardin",
      "Ulisses Braga-Neto",
      "Sorin C. Popescu",
      "Daniel E. Martin",
      "Roberto Rodriguez",
      "Karem Meza",
      "Juan Enciso",
      "Jorge Solorzano Diaz",
      "Tianyi Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.07368",
    "title": "Trainable Joint Bilateral Filters for Enhanced Prediction Stability in  Low-dose CT",
    "abstract": "Low-dose computed tomography (CT) denoising algorithms aim to enable reduced patient dose in routine CT acquisitions while maintaining high image quality. Recently, deep learning~(DL)-based methods were introduced, outperforming conventional denoising algorithms on this task due to their high model capacity. However, for the transition of DL-based denoising to clinical practice, these data-driven approaches must generalize robustly beyond the seen training data. We, therefore, propose a hybrid denoising approach consisting of a set of trainable joint bilateral filters (JBFs) combined with a convolutional DL-based denoising network to predict the guidance image. Our proposed denoising pipeline combines the high model capacity enabled by DL-based feature extraction with the reliability of the conventional JBF. The pipeline's ability to generalize is demonstrated by training on abdomen CT scans without metal implants and testing on abdomen scans with metal implants as well as on head CT data. When embedding two well-established DL-based denoisers (RED-CNN/QAE) in our pipeline, the denoising performance is improved by $10\\,\\%$/$82\\,\\%$ (RMSE) and $3\\,\\%$/$81\\,\\%$ (PSNR) in regions containing metal and by $6\\,\\%$/$78\\,\\%$ (RMSE) and $2\\,\\%$/$4\\,\\%$ (PSNR) on head CT data, compared to the respective vanilla model. Concluding, the proposed trainable JBFs limit the error bound of deep neural networks to facilitate the applicability of DL-based denoisers in low-dose CT pipelines. ",
    "url": "https://arxiv.org/abs/2207.07368",
    "authors": [
      "Fabian Wagner",
      "Mareike Thies",
      "Felix Denzinger",
      "Mingxuan Gu",
      "Mayank Patwari",
      "Stefan Ploner",
      "Noah Maul",
      "Laura Pfaff",
      "Yixing Huang",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07414",
    "title": "Space-based gravitational wave signal detection and extraction with deep  neural network",
    "abstract": "Space-based gravitational wave (GW) detectors will be able to observe signals from sources that are otherwise nearly impossible from current ground-based detection. Consequently, the well established signal detection method, matched filtering, will require a complex template bank, leading to a computational cost that is too expensive in practice. Here, we develop a high-accuracy GW signal detection and extraction method for all space-based GW sources. As a proof of concept, we show that a science-driven and uniform multi-stage deep neural network can identify synthetic signals that are submerged in Gaussian noise. Our method has more than 99% accuracy for signal detection of various sources while obtaining at least 95% similarity compared with target signals. We further demonstrate the interpretability and strong generalization behavior for several extended scenarios. ",
    "url": "https://arxiv.org/abs/2207.07414",
    "authors": [
      "Tianyu Zhao",
      "Ruoxi Lyu",
      "Zhixiang Ren",
      "He Wang",
      "Zhoujian Cao"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.07458",
    "title": "Joint Application of the Target Trial Causal Framework and Machine  Learning Modeling to Optimize Antibiotic Therapy: Use Case on Acute Bacterial  Skin and Skin Structure Infections due to Methicillin-resistant  Staphylococcus aureus",
    "abstract": "Bacterial infections are responsible for high mortality worldwide. Antimicrobial resistance underlying the infection, and multifaceted patient's clinical status can hamper the correct choice of antibiotic treatment. Randomized clinical trials provide average treatment effect estimates but are not ideal for risk stratification and optimization of therapeutic choice, i.e., individualized treatment effects (ITE). Here, we leverage large-scale electronic health record data, collected from Southern US academic clinics, to emulate a clinical trial, i.e., 'target trial', and develop a machine learning model of mortality prediction and ITE estimation for patients diagnosed with acute bacterial skin and skin structure infection (ABSSSI) due to methicillin-resistant Staphylococcus aureus (MRSA). ABSSSI-MRSA is a challenging condition with reduced treatment options - vancomycin is the preferred choice, but it has non-negligible side effects. First, we use propensity score matching to emulate the trial and create a treatment randomized (vancomycin vs. other antibiotics) dataset. Next, we use this data to train various machine learning methods (including boosted/LASSO logistic regression, support vector machines, and random forest) and choose the best model in terms of area under the receiver characteristic (AUC) through bootstrap validation. Lastly, we use the models to calculate ITE and identify possible averted deaths by therapy change. The out-of-bag tests indicate that SVM and RF are the most accurate, with AUC of 81% and 78%, respectively, but BLR/LASSO is not far behind (76%). By calculating the counterfactuals using the BLR/LASSO, vancomycin increases the risk of death, but it shows a large variation (odds ratio 1.2, 95% range 0.4-3.8) and the contribution to outcome probability is modest. Instead, the RF exhibits stronger changes in ITE, suggesting more complex treatment heterogeneity. ",
    "url": "https://arxiv.org/abs/2207.07458",
    "authors": [
      "Inyoung Jun",
      "Simone Marini",
      "Christina A. Boucher",
      "J. Glenn Morris",
      "Jiang Bian",
      "Mattia Prosperi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07563",
    "title": "QSAN: A Near-term Achievable Quantum Self-Attention Network",
    "abstract": "Self-attention mechanism, an important component of machine learning, has been relatively little investigated in the field of quantum machine learning. Inspired by the variational Quantum Algorithm (VQA) framework and classical selfattention mechanism, Quantum Self-Attention Network (QSAN) that can be implemented on a near-term quantum computer is proposed. Theoretically, Quantum Self-Attention Mechanism (QSAM) is defined, which is a new interpretation of the classical self-attention mechanism after linearization and logicalization. Quantum Logical Similarity (QLS) is one of the cores of QSAM, which replaces the similarity operation of inner product with logical operation, allowing a better execution of QSAM on quantum computers. Quantum Bit Self-Attention Score Matrix (QBSASM) is another centerpiece, which is a QLS-based density matrix used to represent the output distribution. In practice, QSAN is realized based on the QSAM framework, and the concept of quantum coordinates is introduced to simplify circuit design. Finally, QSAN is tested on a quantum computer with a small sample of data, laying the foundation for Quantum Natural Language Processing (QNLP). ",
    "url": "https://arxiv.org/abs/2207.07563",
    "authors": [
      "Ren-xin Zhao",
      "Jinjing Shi",
      "Shichao Zhang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07622",
    "title": "Brain MRI study for glioma segmentation using convolutional neural  networks and original post-processing techniques with low computational  demand",
    "abstract": "Gliomas are brain tumors composed of different highly heterogeneous histological subregions. Image analysis techniques to identify relevant tumor substructures have high potential for improving patient diagnosis, treatment and prognosis. However, due to the high heterogeneity of gliomas, the segmentation task is currently a major challenge in the field of medical image analysis. In the present work, the database of the Brain Tumor Segmentation (BraTS) Challenge 2018, composed of multimodal MRI scans of gliomas, was studied. A segmentation methodology based on the design and application of convolutional neural networks (CNNs) combined with original post-processing techniques with low computational demand was proposed. The post-processing techniques were the main responsible for the results obtained in the segmentations. The segmented regions were the whole tumor, the tumor core, and the enhancing tumor core, obtaining averaged Dice coefficients equal to 0.8934, 0.8376, and 0.8113, respectively. These results reached the state of the art in glioma segmentation determined by the winners of the challenge. ",
    "url": "https://arxiv.org/abs/2207.07622",
    "authors": [
      "Jos\u00e9 Gerardo Su\u00e1rez-Garc\u00eda Javier Miguel Hern\u00e1ndez-L\u00f3pez",
      "Eduardo Moreno-Barbosa",
      "Benito de Celis-Alonso"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2001.02658",
    "title": "Distributionally Robust Deep Learning using Hardness Weighted Sampling",
    "abstract": " Comments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) this https URL ",
    "url": "https://arxiv.org/abs/2001.02658",
    "authors": [
      "Lucas Fidon",
      "Michael Aertsen",
      "Thomas Deprest",
      "Doaa Emam",
      "Fr\u00e9d\u00e9ric Guffens",
      "Nada Mufti",
      "Esther Van Elslander",
      "Ernst Schwartz",
      "Michael Ebner",
      "Daniela Prayer",
      "Gregor Kasprian",
      "Anna L. David",
      "Andrew Melbourne",
      "S\u00e9bastien Ourselin",
      "Jan Deprest",
      "Georg Langs",
      "Tom Vercauteren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2011.14522",
    "title": "Feature Learning in Infinite-Width Neural Networks",
    "abstract": " Comments: 4th paper in the Tensor Programs series. Appearing in ICML 2021 ",
    "url": "https://arxiv.org/abs/2011.14522",
    "authors": [
      "Greg Yang",
      "Edward J. Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2101.07555",
    "title": "JigsawGAN: Auxiliary Learning for Solving Jigsaw Puzzles with Generative  Adversarial Networks",
    "abstract": " Comments: Accepted by IEEE Transactions on Image Processing (TIP) ",
    "url": "https://arxiv.org/abs/2101.07555",
    "authors": [
      "Ru Li",
      "Shuaicheng Liu",
      "Guangfu Wang",
      "Guanghui Liu",
      "Bing Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2102.01850",
    "title": "UPHDR-GAN: Generative Adversarial Network for High Dynamic Range Imaging  with Unpaired Data",
    "abstract": " Comments: Accepted by IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) ",
    "url": "https://arxiv.org/abs/2102.01850",
    "authors": [
      "Ru Li",
      "Chuan Wang",
      "Jue Wang",
      "Guanghui Liu",
      "Heng-Yu Zhang",
      "Bing Zeng",
      "Shuaicheng Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.04092",
    "title": "Online Learning Robust Control of Nonlinear Dynamical Systems",
    "abstract": " Title: Online Learning Robust Control of Nonlinear Dynamical Systems ",
    "url": "https://arxiv.org/abs/2106.04092",
    "authors": [
      "Deepan Muthirayan",
      "Pramod P. Khargonekar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2107.04466",
    "title": "Greedy Training Algorithms for Neural Networks and Applications to PDEs",
    "abstract": " Comments: has been merged with arXiv:2104.02903 ",
    "url": "https://arxiv.org/abs/2107.04466",
    "authors": [
      "Jonathan W. Siegel",
      "Qingguo Hong",
      "Xianlin Jin",
      "Wenrui Hao",
      "Jinchao Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2107.10450",
    "title": "Learning Sparse Fixed-Structure Gaussian Bayesian Networks",
    "abstract": " Comments: 30 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2107.10450",
    "authors": [
      "Arnab Bhattacharyya",
      "Davin Choo",
      "Rishikesh Gajjala",
      "Sutanu Gayen",
      "Yuhao Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.12636",
    "title": "Exploring Sequence Feature Alignment for Domain Adaptive Detection  Transformers",
    "abstract": " Comments: Fix a typo in Eq. 13 ",
    "url": "https://arxiv.org/abs/2107.12636",
    "authors": [
      "Wen Wang",
      "Yang Cao",
      "Jing Zhang",
      "Fengxiang He",
      "Zheng-Jun Zha",
      "Yonggang Wen",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.00767",
    "title": "Sublinear Approximation Algorithm for Nash Social Welfare with XOS  Valuations",
    "abstract": " Comments: 41 pages ",
    "url": "https://arxiv.org/abs/2110.00767",
    "authors": [
      "Siddharth Barman",
      "Anand Krishna",
      "Pooja Kulkarni",
      "Shivika Narang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2110.14081",
    "title": "A Controlled Experiment of Different Code Representations for  Learning-Based Bug Repair",
    "abstract": " Title: A Controlled Experiment of Different Code Representations for  Learning-Based Bug Repair ",
    "url": "https://arxiv.org/abs/2110.14081",
    "authors": [
      "Marjane Namavar",
      "Noor Nashid",
      "Ali Mesbah"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2111.00083",
    "title": "A Scalable AutoML Approach Based on Graph Neural Networks",
    "abstract": " Comments: 14 pages, 9 figures. Accepted in VLDB22 ",
    "url": "https://arxiv.org/abs/2111.00083",
    "authors": [
      "Mossad Helali",
      "Essam Mansour",
      "Ibrahim Abdelaziz",
      "Julian Dolby",
      "Kavitha Srinivas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.02572",
    "title": "A Constant-Factor Approximation for Quasi-bipartite Directed Steiner  Tree on Minor-Free Graphs",
    "abstract": " Comments: 24 pages ",
    "url": "https://arxiv.org/abs/2111.02572",
    "authors": [
      "Zachary Friggstad",
      "Ramin Mousavi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2112.06189",
    "title": "An original model for multi-target learning of logical rules for  knowledge graph reasoning",
    "abstract": " Title: An original model for multi-target learning of logical rules for  knowledge graph reasoning ",
    "url": "https://arxiv.org/abs/2112.06189",
    "authors": [
      "Yuliang Wei",
      "Haotian Li",
      "Guodong Xin",
      "Yao Wang",
      "Bailing Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.11648",
    "title": "Out-of-distribution Detection with Boundary Aware Learning",
    "abstract": " Title: Out-of-distribution Detection with Boundary Aware Learning ",
    "url": "https://arxiv.org/abs/2112.11648",
    "authors": [
      "Sen Pei",
      "Xin Zhang",
      "Bin Fan",
      "Gaofeng Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12175",
    "title": "Recur, Attend or Convolve? On Whether Temporal Modeling Matters for  Cross-Domain Robustness in Action Recognition",
    "abstract": " Title: Recur, Attend or Convolve? On Whether Temporal Modeling Matters for  Cross-Domain Robustness in Action Recognition ",
    "url": "https://arxiv.org/abs/2112.12175",
    "authors": [
      "Sofia Broom\u00e9",
      "Ernest Pokropek",
      "Boyu Li",
      "Hedvig Kjellstr\u00f6m"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.00378",
    "title": "Graph Signal Reconstruction Techniques for IoT Air Pollution Monitoring  Platforms",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2201.00378",
    "authors": [
      "Pau Ferrer-Cid",
      "Jose M. Barcelo-Ordinas",
      "Jorge Garcia-Vidal"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2201.01763",
    "title": "Robust Self-Supervised Audio-Visual Speech Recognition",
    "abstract": " Comments: Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2201.01763",
    "authors": [
      "Bowen Shi",
      "Wei-Ning Hsu",
      "Abdelrahman Mohamed"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2201.13317",
    "title": "Hyper-Class Representation of Data",
    "abstract": " Title: Hyper-Class Representation of Data ",
    "url": "https://arxiv.org/abs/2201.13317",
    "authors": [
      "Shichao Zhang",
      "Jiaye Li",
      "Wenzhen Zhang",
      "Yongsong Qin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2202.01300",
    "title": "Causal Inference Through the Structural Causal Marginal Problem",
    "abstract": " Comments: 32 pages (9 pages main paper + bibliography and appendix), 6 figures ",
    "url": "https://arxiv.org/abs/2202.01300",
    "authors": [
      "Luigi Gresele",
      "Julius von K\u00fcgelgen",
      "Jonas M. K\u00fcbler",
      "Elke Kirschbaum",
      "Bernhard Sch\u00f6lkopf",
      "Dominik Janzing"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04104",
    "title": "Teaching Networks to Solve Optimization Problems",
    "abstract": " Title: Teaching Networks to Solve Optimization Problems ",
    "url": "https://arxiv.org/abs/2202.04104",
    "authors": [
      "Xinran Liu",
      "Yuzhe Lu",
      "Ali Abbasi",
      "Meiyi Li",
      "Javad Mohammadi",
      "Soheil Kolouri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06257",
    "title": "Fine-Grained Population Mobility Data-Based Community-Level COVID-19  Prediction Model",
    "abstract": " Comments: Accepted by Cybernetics and Systems ",
    "url": "https://arxiv.org/abs/2202.06257",
    "authors": [
      "Pengyue Jia",
      "Ling Chen",
      "Dandan Lyu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.11312",
    "title": "Are We Ready for Robust and Resilient SLAM? A Framework For Quantitative  Characterization of SLAM Datasets",
    "abstract": " Comments: 7 Pages, Accepted to IROS 2022, updating to the latest submitted version ",
    "url": "https://arxiv.org/abs/2202.11312",
    "authors": [
      "Islam Ali",
      "Hong Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.11604",
    "title": "The Segment Number: Algorithms and Universal Lower Bounds for Some  Classes of Planar Graphs",
    "abstract": " Comments: Appears in the Proceedings of the 48th International Workshop on Graph-Theoretic Concepts in Computer Science (WG2022) ",
    "url": "https://arxiv.org/abs/2202.11604",
    "authors": [
      "Ina Goe\u00dfmann",
      "Jonathan Klawitter",
      "Boris Klemz",
      "Felix Klesen",
      "Stephen Kobourov",
      "Myroslav Kryven",
      "Alexander Wolff",
      "Johannes Zink"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2203.06585",
    "title": "CVFNet: Real-time 3D Object Detection by Learning Cross View Features",
    "abstract": " Comments: 7 pages, 5 figures, accepted by IROS 2022 ",
    "url": "https://arxiv.org/abs/2203.06585",
    "authors": [
      "Jiaqi Gu",
      "Zhiyu Xiang",
      "Pan Zhao",
      "Tingming Bai",
      "Lingxuan Wang",
      "Xijun Zhao",
      "Zhiyuan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.06841",
    "title": "STDAN: Deformable Attention Network for Space-Time Video  Super-Resolution",
    "abstract": " Title: STDAN: Deformable Attention Network for Space-Time Video  Super-Resolution ",
    "url": "https://arxiv.org/abs/2203.06841",
    "authors": [
      "Hai Wang",
      "Xiaoyu Xiang",
      "Yapeng Tian",
      "Wenming Yang",
      "Qingmin Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09091",
    "title": "deepNIR: Datasets for generating synthetic NIR images and improved fruit  detection system using deep learning techniques",
    "abstract": " Comments: 35 pages, 27 figures, published in MDPI Remote Sensing journal ",
    "url": "https://arxiv.org/abs/2203.09091",
    "authors": [
      "Inkyu Sa",
      "JongYoon Lim",
      "Ho Seok Ahn",
      "Bruce MacDonald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.13694",
    "title": "Implicit Neural Representations for Variable Length Human Motion  Generation",
    "abstract": " Comments: Accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2203.13694",
    "authors": [
      "Pablo Cervantes",
      "Yusuke Sekikawa",
      "Ikuro Sato",
      "Koichi Shinoda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.16090",
    "title": "A simple suboptimal moving horizon estimation scheme with guaranteed  robust stability",
    "abstract": " Title: A simple suboptimal moving horizon estimation scheme with guaranteed  robust stability ",
    "url": "https://arxiv.org/abs/2203.16090",
    "authors": [
      "Julian D. Schiller",
      "Boyang Wu",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.03117",
    "title": "BiSyn-GAT+: Bi-Syntax Aware Graph Attention Network for Aspect-based  Sentiment Analysis",
    "abstract": " Comments: Findings of ACL 2022 ",
    "url": "https://arxiv.org/abs/2204.03117",
    "authors": [
      "Shuo Liang",
      "Wei Wei",
      "Xian-Ling Mao",
      "Fei Wang",
      "Zhiyong He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.03286",
    "title": "Entailment Graph Learning with Textual Entailment and Soft Transitivity",
    "abstract": " Comments: 9 pages, 2 figures, accepted to ACL 2022 (main conference). 10 pages for version 2 ",
    "url": "https://arxiv.org/abs/2204.03286",
    "authors": [
      "Zhibin Chen",
      "Yansong Feng",
      "Dongyan Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.07129",
    "title": "On The Complexity of Matching Cut for Graphs of Bounded Radius and  $H$-Free Graphs",
    "abstract": " Title: On The Complexity of Matching Cut for Graphs of Bounded Radius and  $H$-Free Graphs ",
    "url": "https://arxiv.org/abs/2204.07129",
    "authors": [
      "Felicia Lucke",
      "Dani\u00ebl Paulusma",
      "Bernard Ries"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2204.07827",
    "title": "Local treewidth of random and noisy graphs with applications to stopping  contagion in networks",
    "abstract": " Comments: Accepted to RANDOM 2022 ",
    "url": "https://arxiv.org/abs/2204.07827",
    "authors": [
      "Hermish Mehta",
      "Daniel Reichman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2204.08508",
    "title": "Entropy of labeled versus unlabeled networks",
    "abstract": " Title: Entropy of labeled versus unlabeled networks ",
    "url": "https://arxiv.org/abs/2204.08508",
    "authors": [
      "Jeremy Paton",
      "Harrison Hartle",
      "Jakob Stepanyants",
      "Pim van der Hoorn",
      "Dmitri Krioukov"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2204.11750",
    "title": "Efficient Recognition of Subgraphs of Planar Cubic Bridgeless Graphs",
    "abstract": " Title: Efficient Recognition of Subgraphs of Planar Cubic Bridgeless Graphs ",
    "url": "https://arxiv.org/abs/2204.11750",
    "authors": [
      "Miriam Goetze",
      "Paul Jungeblut",
      "Torsten Ueckerdt"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2205.01202",
    "title": "POCD: Probabilistic Object-Level Change Detection and Volumetric Mapping  in Semi-Static Scenes",
    "abstract": " Comments: Published in Robotics: Science and Systems (RSS) 2022 ",
    "url": "https://arxiv.org/abs/2205.01202",
    "authors": [
      "Jingxing Qian",
      "Veronica Chatrath",
      "Jun Yang",
      "James Servos",
      "Angela P. Schoellig",
      "Steven L. Waslander"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.01931",
    "title": "Self-supervised learning in non-small cell lung cancer discovers novel  morphological clusters linked to patient outcome and molecular phenotypes",
    "abstract": " Title: Self-supervised learning in non-small cell lung cancer discovers novel  morphological clusters linked to patient outcome and molecular phenotypes ",
    "url": "https://arxiv.org/abs/2205.01931",
    "authors": [
      "Adalberto Claudio Quiros",
      "Nicolas Coudray",
      "Anna Yeaton",
      "Xinyu Yang",
      "Luis Chiriboga",
      "Afreen Karimkhan",
      "Navneet Narula",
      "Harvey Pass",
      "Andre L. Moreira",
      "John Le Quesne",
      "Aristotelis Tsirigos",
      "Ke Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.03906",
    "title": "Dynamic categories, dynamic operads: From deep learning to prediction  markets",
    "abstract": " Comments: 14 pages + two appendices ",
    "url": "https://arxiv.org/abs/2205.03906",
    "authors": [
      "Brandon Shapiro",
      "David I. Spivak"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2205.09556",
    "title": "Neural Networks in Imandra: Matrix Representation as a Verification  Choice",
    "abstract": " Comments: FOMLAS'22, The 5th Workshop on Formal Methods for ML-Enabled Autonomous Systems ",
    "url": "https://arxiv.org/abs/2205.09556",
    "authors": [
      "Remi Desmartin",
      "Grant Passmore",
      "Ekaterina Komendantskaya"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2205.12840",
    "title": "SALAD: Source-free Active Label-Agnostic Domain Adaptation for  Classification, Segmentation and Detection",
    "abstract": " Title: SALAD: Source-free Active Label-Agnostic Domain Adaptation for  Classification, Segmentation and Detection ",
    "url": "https://arxiv.org/abs/2205.12840",
    "authors": [
      "Divya Kothandaraman",
      "Sumit Shekhar",
      "Abhilasha Sancheti",
      "Manoj Ghuhan",
      "Tripti Shukla",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00866",
    "title": "Analytical SNR Prediction in Long-Haul Optical Transmission using  General Dual-Polarization 4D Formats",
    "abstract": " Comments: 4 pages ",
    "url": "https://arxiv.org/abs/2206.00866",
    "authors": [
      "Zhiwei Liang",
      "Bin Chen",
      "Yi Lei",
      "Gabriele Liga",
      "Alex Alvarado"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2206.06443",
    "title": "The impact of NFT profile pictures within social network communities",
    "abstract": " Comments: In Proceedings of the ACM International Conference on Information Technology for Social Good (GoodIT'22), September 07--09, 2022, Cyprus ",
    "url": "https://arxiv.org/abs/2206.06443",
    "authors": [
      "Simone Casale-Brunet",
      "Mirko Zichichi",
      "Lee Hutchinson",
      "Marco Mattavelli",
      "Stefano Ferretti"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.12747",
    "title": "HyGNN: Drug-Drug Interaction Prediction via Hypergraph Neural Network",
    "abstract": " Comments: Some new experiments have been added. One more dataset has been considered. Theoretical part has been updated too ",
    "url": "https://arxiv.org/abs/2206.12747",
    "authors": [
      "Khaled Mohammed Saifuddin",
      "Briana Bumgardner",
      "Farhan Tanvir",
      "Esra Akbas"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.01616",
    "title": "Breaking Feedback Loops in Recommender Systems with Causal Inference",
    "abstract": " Title: Breaking Feedback Loops in Recommender Systems with Causal Inference ",
    "url": "https://arxiv.org/abs/2207.01616",
    "authors": [
      "Karl Krauth",
      "Yixin Wang",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.03574",
    "title": "Demystifying the Adversarial Robustness of Random Transformation  Defenses",
    "abstract": " Comments: ICML 2022 (short presentation), AAAI 2022 AdvML Workshop (best paper, oral presentation) ",
    "url": "https://arxiv.org/abs/2207.03574",
    "authors": [
      "Chawin Sitawarin",
      "Zachary Golan-Strieb",
      "David Wagner"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04906",
    "title": "HLT-MT: High-resource Language-specific Training for Multilingual Neural  Machine Translation",
    "abstract": " Comments: 7 pages, 7 figures, IJCAI-ECAI 2022 ",
    "url": "https://arxiv.org/abs/2207.04906",
    "authors": [
      "Jian Yang",
      "Yuwei Yin",
      "Shuming Ma",
      "Dongdong Zhang",
      "Zhoujun Li",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05297",
    "title": "Efficient and Privacy Preserving Group Signature for Federated Learning",
    "abstract": " Title: Efficient and Privacy Preserving Group Signature for Federated Learning ",
    "url": "https://arxiv.org/abs/2207.05297",
    "authors": [
      "Sneha Kanchan",
      "Jae Won Jang",
      "Jun Yong Yoon",
      "Bong Jun Choi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.06414",
    "title": "Modeling Long-term Dependencies and Short-term Correlations in Patient  Journey Data with Temporal Attention Networks for Health Prediction",
    "abstract": " Comments: 10 pages, 4 figures, accepted at ACM BCB 2022 ",
    "url": "https://arxiv.org/abs/2207.06414",
    "authors": [
      "Yuxi Liu",
      "Zhenhao Zhang",
      "Antonio Jimeno Yepes",
      "Flora D. Salim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.06887",
    "title": "Dynamic Spanning Trees for Connectivity Queries on Fully-dynamic  Undirected Graphs (Extended version)",
    "abstract": " Title: Dynamic Spanning Trees for Connectivity Queries on Fully-dynamic  Undirected Graphs (Extended version) ",
    "url": "https://arxiv.org/abs/2207.06887",
    "authors": [
      "Qing Chen",
      "Oded Lachish",
      "Sven Helmer",
      "Michael B\u00f6hlen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2207.07106",
    "title": "Benchmarking Omni-Vision Representation through the Lens of Visual  Realms",
    "abstract": " Comments: In ECCV 2022; The project page at this https URL ",
    "url": "https://arxiv.org/abs/2207.07106",
    "authors": [
      "Yuanhan Zhang",
      "Zhenfei Yin",
      "Jing Shao",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]