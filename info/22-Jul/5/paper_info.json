[
  {
    "id": "arXiv:2207.00586",
    "title": "PrUE: Distilling Knowledge from Sparse Teacher Networks",
    "abstract": "Although deep neural networks have enjoyed remarkable success across a wide variety of tasks, their ever-increasing size also imposes significant overhead on deployment. To compress these models, knowledge distillation was proposed to transfer knowledge from a cumbersome (teacher) network into a lightweight (student) network. However, guidance from a teacher does not always improve the generalization of students, especially when the size gap between student and teacher is large. Previous works argued that it was due to the high certainty of the teacher, resulting in harder labels that were difficult to fit. To soften these labels, we present a pruning method termed Prediction Uncertainty Enlargement (PrUE) to simplify the teacher. Specifically, our method aims to decrease the teacher's certainty about data, thereby generating soft predictions for students. We empirically investigate the effectiveness of the proposed method with experiments on CIFAR-10/100, Tiny-ImageNet, and ImageNet. Results indicate that student networks trained with sparse teachers achieve better performance. Besides, our method allows researchers to distill knowledge from deeper networks to improve students further. Our code is made public at: \\url{https://github.com/wangshaopu/prue}. ",
    "url": "https://arxiv.org/abs/2207.00586",
    "authors": [
      "Shaopu Wang",
      "Xiaojun Chen",
      "Mengzhen Kou",
      "Jinqiao Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00589",
    "title": "SSD-Faster Net: A Hybrid Network for Industrial Defect Inspection",
    "abstract": "The quality of industrial components is critical to the production of special equipment such as robots. Defect inspection of these components is an efficient way to ensure quality. In this paper, we propose a hybrid network, SSD-Faster Net, for industrial defect inspection of rails, insulators, commutators etc. SSD-Faster Net is a two-stage network, including SSD for quickly locating defective blocks, and an improved Faster R-CNN for defect segmentation. For the former, we propose a novel slice localization mechanism to help SSD scan quickly. The second stage is based on improved Faster R-CNN, using FPN, deformable kernel(DK) to enhance representation ability. It fuses multi-scale information, and self-adapts the receptive field. We also propose a novel loss function and use ROI Align to improve accuracy. Experiments show that our SSD-Faster Net achieves an average accuracy of 84.03%, which is 13.42% higher than the nearest competitor based on Faster R-CNN, 4.14% better than GAN-based methods, more than 10% higher than that of DNN-based detectors. And the computing speed is improved by nearly 7%, which proves its robustness and superior performance. ",
    "url": "https://arxiv.org/abs/2207.00589",
    "authors": [
      "Jingyao Wang",
      "Naigong Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00594",
    "title": "Time-aware Dynamic Graph Embedding for Asynchronous Structural Evolution",
    "abstract": "Dynamic graphs refer to graphs whose structure dynamically changes over time. Despite the benefits of learning vertex representations (i.e., embeddings) for dynamic graphs, existing works merely view a dynamic graph as a sequence of changes within the vertex connections, neglecting the crucial asynchronous nature of such dynamics where the evolution of each local structure starts at different times and lasts for various durations. To maintain asynchronous structural evolutions within the graph, we innovatively formulate dynamic graphs as temporal edge sequences associated with joining time of vertices (ToV) and timespan of edges (ToE). Then, a time-aware Transformer is proposed to embed vertices' dynamic connections and ToEs into the learned vertex representations. Meanwhile, we treat each edge sequence as a whole and embed its ToV of the first vertex to further encode the time-sensitive information. Extensive evaluations on several datasets show that our approach outperforms the state-of-the-art in a wide range of graph mining tasks. At the same time, it is very efficient and scalable for embedding large-scale dynamic graphs. ",
    "url": "https://arxiv.org/abs/2207.00594",
    "authors": [
      "Yu Yang",
      "Hongzhi Yin",
      "Jiannong Cao",
      "Tong Chen",
      "Quoc Viet Hung Nguyen",
      "Xiaofang Zhou",
      "Lei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.00610",
    "title": "A Temporal Fusion Transformer for Long-term Explainable Prediction of  Emergency Department Overcrowding",
    "abstract": "Emergency Departments (EDs) are a fundamental element of the Portuguese National Health Service, serving as an entry point for users with diverse and very serious medical problems. Due to the inherent characteristics of the ED; forecasting the number of patients using the services is particularly challenging. And a mismatch between the affluence and the number of medical professionals can lead to a decrease in the quality of the services provided and create problems that have repercussions for the entire hospital, with the requisition of health care workers from other departments and the postponement of surgeries. ED overcrowding is driven, in part, by non-urgent patients, that resort to emergency services despite not having a medical emergency and which represent almost half of the total number of daily patients. This paper describes a novel deep learning architecture, the Temporal Fusion Transformer, that uses calendar and time-series covariates to forecast prediction intervals and point predictions for a 4 week period. We have concluded that patient volume can be forecasted with a Mean Absolute Percentage Error (MAPE) of 5.90% for Portugal's Health Regional Areas (HRA) and a Root Mean Squared Error (RMSE) of 84.4102 people/day. The paper shows empirical evidence supporting the use of a multivariate approach with static and time-series covariates while surpassing other models commonly found in the literature. ",
    "url": "https://arxiv.org/abs/2207.00610",
    "authors": [
      "Francisco M. Caldas",
      "Cl\u00e1udia Soares"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00615",
    "title": "Synthesis of General Decoupling Networks Using Transmission Lines",
    "abstract": "In this paper, we introduce a synthesis technique for transmission line based decoupling networks, which find application in coupled systems such as multiple-antenna systems and antenna arrays. Employing the generalized $\\pi$-network and the transmission line analysis technique, we reduce the decoupling network design into simple matrix calculations. The synthesized decoupling network is essentially a generalized $\\pi$-network with transmission lines at all branches. The advantage of this proposed decoupling network is that it can be implemented using transmission lines, ensuring better control on loss, performance consistency and higher power handling capability, when compared with lumped components, and can be easily scaled for operation at different frequencies. ",
    "url": "https://arxiv.org/abs/2207.00615",
    "authors": [
      "Binbin Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.00623",
    "title": "Is this bug severe? A text-cum-graph based model for bug severity  prediction",
    "abstract": "Repositories of large software systems have become commonplace. This massive expansion has resulted in the emergence of various problems in these software platforms including identification of (i) bug-prone packages, (ii) critical bugs, and (iii) severity of bugs. One of the important goals would be to mine these bugs and recommend them to the developers to resolve them. The first step to this is that one has to accurately detect the extent of severity of the bugs. In this paper, we take up this task of predicting the severity of bugs in the near future. Contextualized neural models built on the text description of a bug and the user comments about the bug help to achieve reasonably good performance. Further information on how the bugs are related to each other in terms of the ways they affect packages can be summarised in the form of a graph and used along with the text to get additional benefits. ",
    "url": "https://arxiv.org/abs/2207.00623",
    "authors": [
      "Rima Hazra",
      "Arpit Dwivedi",
      "Animesh Mukherjee"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2207.00633",
    "title": "Hide me Behind the Noise: Local Differential Privacy for Indoor Location  Privacy",
    "abstract": "The advent of numerous indoor location-based services (LBSs) and the widespread use of many types of mobile devices in indoor environments have resulted in generating a massive amount of people's location data. While geo-spatial data contains sensitive information about personal activities, collecting it in its raw form may lead to the leak of personal information relating to the people, violating their privacy. This paper proposes a novel privacy-aware framework for aggregating the indoor location data employing the Local Differential Privacy (LDP) technique, in which the user location data is changed locally in the user's device and is sent to the aggregator afterward. Therefore, the users' locations are kept hidden from a server or any attackers. The practical feasibility of applying the proposed framework is verified by two real-world datasets. The impact of dataset properties, the privacy mechanisms, and the privacy level on our framework are also investigated. The experimental results indicate that the presented framework can protect the location information of users, and the accuracy of the population frequency of different zones in the indoor area is close to that of the original population frequency with no knowledge about the location of people indoors. ",
    "url": "https://arxiv.org/abs/2207.00633",
    "authors": [
      "Hojjat Navidan",
      "Vahideh Moghtadaiee",
      "Niki Nazaran",
      "Mina Alishahi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.00637",
    "title": "Ontology-Based Anomaly Detection for Air Traffic Control Systems",
    "abstract": "The Automatic Dependent Surveillance-Broadcast (ADS-B) protocol is increasingly being adopted by the aviation industry as a method for aircraft to relay their position to Air Traffic Control (ATC) monitoring systems. ADS-B provides greater precision compared to traditional radar-based technologies, however, it was designed without any encryption or authentication mechanisms and has been shown to be susceptible to spoofing attacks. A capable attacker can transmit falsified ADS-B messages with the intent of causing false information to be shown on ATC displays and threaten the safety of air traffic. Updating the ADS-B protocol will be a lengthy process, therefore, there is a need for systems to detect anomalous ADS-B communications. This paper presents ATC-Sense, an ADS-B anomaly detection system based on ontologies. An ATC ontology is used to model entities in a simulated controlled airspace and is used to detect falsified ADS-B messages by verifying that the entities conform to aviation constraints related to aircraft flight tracks, radar readings, and flight reports. We evaluate the computational performance of the proposed constraints-based detection approach with several ADS-B attack scenarios in a simulated ATC environment. We demonstrate how ontologies can be used for anomaly detection in a real-time environment and call for future work to investigate ways to improve the computational performance of such an approach. ",
    "url": "https://arxiv.org/abs/2207.00637",
    "authors": [
      "Christopher Neal",
      "Jean-Yves De Miceli",
      "David Barrera",
      "Jos\u00e9 Fernandez"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.00650",
    "title": "An Alternative Method for Solving Security-Constraint Unit Commitment  with Neural Network Based Battery Degradation Model",
    "abstract": "Battery energy storage system (BESS) can effectively mitigate the uncertainty of variable renewable generation and provide flexible ancillary services. However, degradation is a key concern for rechargeable batteries such as the most widely used Lithium-ion battery. A neural network based battery degradation (NNBD) model can accurately quantify the battery degradation. When incorporating the NNBD model into security-constrained unit commitment (SCUC), we can establish a battery degradation based SCUC (BD-SCUC) model that can consider the equivalent battery degradation cost precisely. However, the BD-SCUC may not be solved directly due to high non-linearity of the NNBD model. To address this issue, the NNBD model is linearized by converting the nonlinear activation function at each neuron into linear constraints, which enables BD-SCUC to become a linearized BD-SCUC (L-BD-SCUC) model. Case studies demonstrate the proposed L-BD-SCUC model can be efficiently solved for multiple BESS buses power system day-ahead scheduling problems with the lowest total cost including the equivalent degradation cost and normal operation cost. ",
    "url": "https://arxiv.org/abs/2207.00650",
    "authors": [
      "Cunzhi Zhao",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.00669",
    "title": "Differentiable Collision Detection for a Set of Convex Primitives",
    "abstract": "Collision detection between objects is critical for simulation, control, and learning for robotic systems. However, existing collision detection routines are inherently non-differentiable, limiting their usefulness in optimization-based algorithms. In this work, we propose a fully differentiable collision-detection framework that reasons about distances between a set of composable and highly expressive convex primitive shapes. This is achieved by formulating the collision detection problem as a convex optimization problem that seeks to find the minimum uniform scaling to be applied to each object before there is an intersection. The optimization problem is fully differentiable and is able to return both the collision detection status as well as the contact points on each object. ",
    "url": "https://arxiv.org/abs/2207.00669",
    "authors": [
      "Kevin Tracy",
      "Taylor A. Howell",
      "Zachary Manchester"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.00681",
    "title": "Human-Assisted Robotic Detection of Foreign Object Debris Inside  Confined Spaces of Marine Vessels Using Probabilistic Mapping",
    "abstract": "Many complex vehicular systems, such as large marine vessels, contain confined spaces like water tanks, which are critical for the safe functioning of the vehicles. It is particularly hazardous for humans to inspect such spaces due to limited accessibility, poor visibility, and unstructured configuration. While robots provide a viable alternative, they encounter the same set of challenges in realizing robust autonomy. In this work, we specifically address the problem of detecting foreign object debris (FODs) left inside the confined spaces using a visual mapping-based system that relies on Mahalanobis distance-driven comparisons between the nominal and online maps for local outlier identification. Simulation trials show extremely high recall but low precision for the outlier identification method. The assistance of remote humans is, therefore, taken to deal with the precision problem by going over the close-up robot camera images of the outlier regions. An online survey is conducted to show the usefulness of this assistance process. Physical experiments are also reported on a GPU-enabled mobile robot platform inside a scaled-down, prototype tank to demonstrate the feasibility of the FOD detection system. ",
    "url": "https://arxiv.org/abs/2207.00681",
    "authors": [
      "Benjamin Wong",
      "Wade Marquette",
      "Nikolay Bykov",
      "Tyler M. Paine",
      "Ashis G. Banerjee"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.00684",
    "title": "Transforming PageRank into an Infinite-Depth Graph Neural Network",
    "abstract": "Popular graph neural networks are shallow models, despite the success of very deep architectures in other application domains of deep learning. This reduces the modeling capacity and leaves models unable to capture long-range relationships. The primary reason for the shallow design results from over-smoothing, which leads node states to become more similar with increased depth. We build on the close connection between GNNs and PageRank, for which personalized PageRank introduces the consideration of a personalization vector. Adopting this idea, we propose the Personalized PageRank Graph Neural Network (PPRGNN), which extends the graph convolutional network to an infinite-depth model that has a chance to reset the neighbor aggregation back to the initial state in each iteration. We introduce a nicely interpretable tweak to the chance of resetting and prove the convergence of our approach to a unique solution without placing any constraints, even when taking infinitely many neighbor aggregations. As in personalized PageRank, our result does not suffer from over-smoothing. While doing so, time complexity remains linear while we keep memory complexity constant, independently of the depth of the network, making it scale well to large graphs. We empirically show the effectiveness of our approach for various node and graph classification tasks. PPRGNN outperforms comparable methods in almost all cases. ",
    "url": "https://arxiv.org/abs/2207.00684",
    "authors": [
      "Andreas Roth",
      "Thomas Liebig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00694",
    "title": "Efficient Adversarial Training With Data Pruning",
    "abstract": "Neural networks are susceptible to adversarial examples-small input perturbations that cause models to fail. Adversarial training is one of the solutions that stops adversarial examples; models are exposed to attacks during training and learn to be resilient to them. Yet, such a procedure is currently expensive-it takes a long time to produce and train models with adversarial samples, and, what is worse, it occasionally fails. In this paper we demonstrate data pruning-a method for increasing adversarial training efficiency through data sub-sampling.We empirically show that data pruning leads to improvements in convergence and reliability of adversarial training, albeit with different levels of utility degradation. For example, we observe that using random sub-sampling of CIFAR10 to drop 40% of data, we lose 8% adversarial accuracy against the strongest attackers, while by using only 20% of data we lose 14% adversarial accuracy and reduce runtime by a factor of 3. Interestingly, we discover that in some settings data pruning brings benefits from both worlds-it both improves adversarial accuracy and training time. ",
    "url": "https://arxiv.org/abs/2207.00694",
    "authors": [
      "Maximilian Kaufmann",
      "Yiren Zhao",
      "Ilia Shumailov",
      "Robert Mullins",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00705",
    "title": "Multivariate Time Series Anomaly Detection with Few Positive Samples",
    "abstract": "Given the scarcity of anomalies in real-world applications, the majority of literature has been focusing on modeling normality. The learned representations enable anomaly detection as the normality model is trained to capture certain key underlying data regularities under normal circumstances. In practical settings, particularly industrial time series anomaly detection, we often encounter situations where a large amount of normal operation data is available along with a small number of anomaly events collected over time. This practical situation calls for methodologies to leverage these small number of anomaly events to create a better anomaly detector. In this paper, we introduce two methodologies to address the needs of this practical situation and compared them with recently developed state of the art techniques. Our proposed methods anchor on representative learning of normal operation with autoregressive (AR) model along with loss components to encourage representations that separate normal versus few positive examples. We applied the proposed methods to two industrial anomaly detection datasets and demonstrated effective performance in comparison with approaches from literature. Our study also points out additional challenges with adopting such methods in practical applications. ",
    "url": "https://arxiv.org/abs/2207.00705",
    "authors": [
      "Feng Xue",
      "Weizhong Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2207.00718",
    "title": "Triangle-oriented Community Detection considering Node Features and  Network Topology",
    "abstract": "The joint use of node features and network topology to detect communities is called community detection in attributed networks. Most of the existing work along this line has been carried out through objective function optimization and has proposed numerous approaches. However, they tend to focus only on lower-order details, i.e., capture node features and network topology from node and edge views, and purely seek a higher degree of optimization to guarantee the quality of the found communities, which exacerbates unbalanced communities and free-rider effect. To further clarify and reveal the intrinsic nature of networks, we conduct triangle-oriented community detection considering node features and network topology. Specifically, we first introduce a triangle-based quality metric to preserve higher-order details of node features and network topology, and then formulate so-called two-level constraints to encode lower-order details of node features and network topology. Finally, we develop a local search framework based on optimizing our objective function consisting of the proposed quality metric and two-level constraints to achieve both non-overlapping and overlapping community detection in attributed networks. Extensive experiments demonstrate the effectiveness and efficiency of our framework and its potential in alleviating unbalanced communities and free-rider effect. ",
    "url": "https://arxiv.org/abs/2207.00718",
    "authors": [
      "Guangliang Gao",
      "Weichao Liang",
      "Ming Yuan",
      "Hanwei Qian",
      "Qun Wang",
      "Jie Cao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.00724",
    "title": "Noise and Edge Based Dual Branch Image Manipulation Detection",
    "abstract": "Unlike ordinary computer vision tasks that focus more on the semantic content of images, the image manipulation detection task pays more attention to the subtle information of image manipulation. In this paper, the noise image extracted by the improved constrained convolution is used as the input of the model instead of the original image to obtain more subtle traces of manipulation. Meanwhile, the dual-branch network, consisting of a high-resolution branch and a context branch, is used to capture the traces of artifacts as much as possible. In general, most manipulation leaves manipulation artifacts on the manipulation edge. A specially designed manipulation edge detection module is constructed based on the dual-branch network to identify these artifacts better. The correlation between pixels in an image is closely related to their distance. The farther the two pixels are, the weaker the correlation. We add a distance factor to the self-attention module to better describe the correlation between pixels. Experimental results on four publicly available image manipulation datasets demonstrate the effectiveness of our model. ",
    "url": "https://arxiv.org/abs/2207.00724",
    "authors": [
      "Zhongyuan Zhang",
      "Yi Qian",
      "Yanxiang Zhao",
      "Lin Zhu",
      "Jinjin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00726",
    "title": "ReCoAt: A Deep Learning-based Framework for Multi-Modal Motion  Prediction in Autonomous Driving Application",
    "abstract": "This paper proposes a novel deep learning framework for multi-modal motion prediction. The framework consists of three parts: recurrent neural networks to process the target agent's motion process, convolutional neural networks to process the rasterized environment representation, and a distance-based attention mechanism to process the interactions among different agents. We validate the proposed framework on a large-scale real-world driving dataset, Waymo open motion dataset, and compare its performance against other methods on the standard testing benchmark. The qualitative results manifest that the predicted trajectories given by our model are accurate, diverse, and in accordance with the road structure. The quantitative results on the standard benchmark reveal that our model outperforms other baseline methods in terms of prediction accuracy and other evaluation metrics. The proposed framework is the second-place winner of the 2021 Waymo open dataset motion prediction challenge. ",
    "url": "https://arxiv.org/abs/2207.00726",
    "authors": [
      "Zhiyu Huang",
      "Xiaoyu Mo",
      "Chen Lv"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.00728",
    "title": "Multi-scale Attentive Image De-raining Networks via Neural Architecture  Search",
    "abstract": "Multi-scale architectures and attention modules have shown effectiveness in many deep learning-based image de-raining methods. However, manually designing and integrating these two components into a neural network requires a bulk of labor and extensive expertise. In this article, a high-performance multi-scale attentive neural architecture search (MANAS) framework is technically developed for image deraining. The proposed method formulates a new multi-scale attention search space with multiple flexible modules that are favorite to the image de-raining task. Under the search space, multi-scale attentive cells are built, which are further used to construct a powerful image de-raining network. The internal multiscale attentive architecture of the de-raining network is searched automatically through a gradient-based search algorithm, which avoids the daunting procedure of the manual design to some extent. Moreover, in order to obtain a robust image de-raining model, a practical and effective multi-to-one training strategy is also presented to allow the de-raining network to get sufficient background information from multiple rainy images with the same background scene, and meanwhile, multiple loss functions including external loss, internal loss, architecture regularization loss, and model complexity loss are jointly optimized to achieve robust de-raining performance and controllable model complexity. Extensive experimental results on both synthetic and realistic rainy images, as well as the down-stream vision applications (i.e., objection detection and segmentation) consistently demonstrate the superiority of our proposed method. ",
    "url": "https://arxiv.org/abs/2207.00728",
    "authors": [
      "Lei Cai",
      "Yuli Fu",
      "Wanliang Huo",
      "Youjun Xiang",
      "Tao Zhu",
      "Ying Zhang",
      "Huanqiang Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.00733",
    "title": "Contrastive Cross-Modal Knowledge Sharing Pre-training for  Vision-Language Representation Learning and Retrieval",
    "abstract": "Recently, the cross-modal pre-training task has been a hotspot because of its wide application in various down-streaming researches including retrieval, captioning, question answering and so on. However, exiting methods adopt a one-stream pre-training model to explore the united vision-language representation for conducting cross-modal retrieval, which easily suffer from the calculation explosion. Moreover, although the conventional double-stream structures are quite efficient, they still lack the vital cross-modal interactions, resulting in low performances. Motivated by these challenges, we put forward a Contrastive Cross-Modal Knowledge Sharing Pre-training (COOKIE) to grasp the joint text-image representations. Structurally, COOKIE adopts the traditional double-stream structure because of the acceptable time consumption. To overcome the inherent defects of double-stream structure as mentioned above, we elaborately design two effective modules. Concretely, the first module is a weight-sharing transformer that builds on the head of the visual and textual encoders, aiming to semantically align text and image. This design enables visual and textual paths focus on the same semantics. The other one is three specially designed contrastive learning, aiming to share knowledge between different models. The shared cross-modal knowledge develops the study of unimodal representation greatly, promoting the single-modal retrieval tasks. Extensive experimental results on multi-modal matching researches that includes cross-modal retrieval, text matching, and image retrieval reveal the superiors in calculation efficiency and statistical indicators of our pre-training model. ",
    "url": "https://arxiv.org/abs/2207.00733",
    "authors": [
      "Keyu Wen",
      "Zhenshan Tan",
      "Qingrong Cheng",
      "Cheng Chen",
      "Xiaodong Gu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.00738",
    "title": "Golfer: Trajectory Prediction with Masked Goal Conditioning MnM Network",
    "abstract": "Transformers have enabled breakthroughs in NLP and computer vision, and have recently began to show promising performance in trajectory prediction for Autonomous Vehicle (AV). How to efficiently model the interactive relationships between the ego agent and other road and dynamic objects remains challenging for the standard attention module. In this work we propose a general Transformer-like architectural module MnM network equipped with novel masked goal conditioning training procedures for AV trajectory prediction. The resulted model, named golfer, achieves state-of-the-art performance, winning the 2nd place in the 2022 Waymo Open Dataset Motion Prediction Challenge and ranked 1st place according to minADE. ",
    "url": "https://arxiv.org/abs/2207.00738",
    "authors": [
      "Xiaocheng Tang",
      "Soheil Sadeghi Eshkevari",
      "Haoyu Chen",
      "Weidan Wu",
      "Wei Qian",
      "Xiaoming Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.00740",
    "title": "PhilaeX: Explaining the Failure and Success of AI Models in Malware  Detection",
    "abstract": "The explanation to an AI model's prediction used to support decision making in cyber security, is of critical importance. It is especially so when the model's incorrect prediction can lead to severe damages or even losses to lives and critical assets. However, most existing AI models lack the ability to provide explanations on their prediction results, despite their strong performance in most scenarios. In this work, we propose a novel explainable AI method, called PhilaeX, that provides the heuristic means to identify the optimized subset of features to form the complete explanations of AI models' predictions. It identifies the features that lead to the model's borderline prediction, and those with positive individual contributions are extracted. The feature attributions are then quantified through the optimization of a Ridge regression model. We verify the explanation fidelity through two experiments. First, we assess our method's capability in correctly identifying the activated features in the adversarial samples of Android malwares, through the features attribution values from PhilaeX. Second, the deduction and augmentation tests, are used to assess the fidelity of the explanations. The results show that PhilaeX is able to explain different types of classifiers correctly, with higher fidelity explanations, compared to the state-of-the-arts methods such as LIME and SHAP. ",
    "url": "https://arxiv.org/abs/2207.00740",
    "authors": [
      "Zhi Lu",
      "Vrizlynn L. L. Thing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00741",
    "title": "A Distributionally Robust Resilience Enhancement Strategy for  Distribution Grids Considering Decision-Dependent Contingencies",
    "abstract": "When performing resilience enhancement for distribution grids, suboptimal strategies induced by misspecified contingency models may lead to unanticipated regrets in retrospective analyses. However, there are two obstacles for reliably modeling uncertain contingencies: 1) decision-dependent uncertainty (DDU) resulting from different line hardening decisions, and 2) distributional ambiguity due to limited outage information under extreme weather events (EWEs). To address these two challenges, this paper constructs scenario-wise decision-dependent ambiguity sets (SWDD-ASs), where the DDU and distributional ambiguity inherent in EWE-induced contingencies are simultaneously captured under each possible EWE scenario. Then, a two-stage trilevel decision-dependent distributionally robust resilient enhancement (DD-DRRE) model is formulated, whose outputs include the optimal line hardening, distributed generation (DG) allocation, and proactive network reconfiguration strategy under the worst-case distributions in SWDD-ASs. Then, the DD-DRRE model are equivalently recast to a MILP-based master problem and multiple scenario-wise subproblems, facilitating the utilization of a customized column-and-constraint generation (C&CG) algorithm. Finally, numerical tests demonstrate a remarkable improvement in the out-of-sample performance of our model, compared to its prevailing stochastic and robust counterparts. Moreover, the potential values of incorporating the ambiguity and distributional information are quantitatively estimated, which can serve as a useful reference for planners with different budgets and risk-aversion levels. ",
    "url": "https://arxiv.org/abs/2207.00741",
    "authors": [
      "Yujia Li",
      "Shunbo Lei",
      "Wei Sun",
      "Chenxi Hu",
      "Yunhe Hou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.00744",
    "title": "Gaussian Kernel-based Cross Modal Network for Spatio-Temporal Video  Grounding",
    "abstract": "Spatial-Temporal Video Grounding (STVG) is a challenging task which aims to localize the spatio-temporal tube of the interested object semantically according to a natural language query. Most previous works not only severely rely on the anchor boxes extracted by Faster R-CNN, but also simply regard the video as a series of individual frames, thus lacking their temporal modeling. Instead, in this paper, we are the first to propose an anchor-free framework for STVG, called Gaussian Kernel-based Cross Modal Network (GKCMN). Specifically, we utilize the learned Gaussian Kernel-based heatmaps of each video frame to locate the query-related object. A mixed serial and parallel connection network is further developed to leverage both spatial and temporal relations among frames for better grounding. Experimental results on VidSTG dataset demonstrate the effectiveness of our proposed GKCMN. ",
    "url": "https://arxiv.org/abs/2207.00744",
    "authors": [
      "Zeyu Xiong",
      "Daizong Liu",
      "Pan Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00750",
    "title": "GUIM -- General User and Item Embedding with Mixture of Representation  in E-commerce",
    "abstract": "Our goal is to build general representation (embedding) for each user and each product item across Alibaba's businesses, including Taobao and Tmall which are among the world's biggest e-commerce websites. The representation of users and items has been playing a critical role in various downstream applications, including recommendation system, search, marketing, demand forecasting and so on. Inspired from the BERT model in natural language processing (NLP) domain, we propose a GUIM (General User Item embedding with Mixture of representation) model to achieve the goal with massive, structured, multi-modal data including the interactions among hundreds of millions of users and items. We utilize mixture of representation (MoR) as a novel representation form to model the diverse interests of each user. In addition, we use the InfoNCE from contrastive learning to avoid intractable computational costs due to the numerous size of item (token) vocabulary. Finally, we propose a set of representative downstream tasks to serve as a standard benchmark to evaluate the quality of the learned user and/or item embeddings, analogous to the GLUE benchmark in NLP domain. Our experimental results in these downstream tasks clearly show the comparative value of embeddings learned from our GUIM model. ",
    "url": "https://arxiv.org/abs/2207.00750",
    "authors": [
      "Chao Yang",
      "Ru He",
      "Fangquan Lin",
      "Suoyuan Song",
      "Jingqiao Zhang",
      "Cheng Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2207.00751",
    "title": "Informed Learning by Wide Neural Networks: Convergence, Generalization  and Sampling Complexity",
    "abstract": "By integrating domain knowledge with labeled samples, informed machine learning has been emerging to improve the learning performance for a wide range of applications. Nonetheless, rigorous understanding of the role of injected domain knowledge has been under-explored. In this paper, we consider an informed deep neural network (DNN) with over-parameterization and domain knowledge integrated into its training objective function, and study how and why domain knowledge benefits the performance. Concretely, we quantitatively demonstrate the two benefits of domain knowledge in informed learning - regularizing the label-based supervision and supplementing the labeled samples - and reveal the trade-off between label and knowledge imperfectness in the bound of the population risk. Based on the theoretical analysis, we propose a generalized informed training objective to better exploit the benefits of knowledge and balance the label and knowledge imperfectness, which is validated by the population risk bound. Our analysis on sampling complexity sheds lights on how to choose the hyper-parameters for informed learning, and further justifies the advantages of knowledge informed learning. ",
    "url": "https://arxiv.org/abs/2207.00751",
    "authors": [
      "Jianyi Yang",
      "Shaolei Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00755",
    "title": "Unsupervised Recurrent Federated Learning for Edge Popularity Prediction  in Privacy-Preserving Mobile Edge Computing Networks",
    "abstract": "Nowadays wireless communication is rapidly reshaping entire industry sectors. In particular, mobile edge computing (MEC) as an enabling technology for industrial Internet of things (IIoT) brings powerful computing/storage infrastructure closer to the mobile terminals and, thereby, significant lowers the response latency. To reap the benefit of proactive caching at the network edge, precise knowledge on the popularity pattern among the end devices is essential. However, the complex and dynamic nature of the content popularity over space and time as well as the data-privacy requirements in many IIoT scenarios pose tough challenges to its acquisition. In this article, we propose an unsupervised and privacy-preserving popularity prediction framework for MEC-enabled IIoT. The concepts of local and global popularities are introduced and the time-varying popularity of each user is modelled as a model-free Markov chain. On this basis, a novel unsupervised recurrent federated learning (URFL) algorithm is proposed to predict the distributed popularity while achieve privacy preservation and unsupervised training. Simulations indicate that the proposed framework can enhance the prediction accuracy in terms of a reduced root-mean-squared error by up to $60.5\\%-68.7\\%$. Additionally, manual labeling and violation of users' data privacy are both avoided. ",
    "url": "https://arxiv.org/abs/2207.00755",
    "authors": [
      "Chong Zheng",
      "Shengheng Liu",
      "Yongming Huang",
      "Wei Zhang",
      "Luxi Yang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00756",
    "title": "Learning Noise-independent Speech Representation for High-quality Voice  Conversion for Noisy Target Speakers",
    "abstract": "Building a voice conversion system for noisy target speakers, such as users providing noisy samples or Internet found data, is a challenging task since the use of contaminated speech in model training will apparently degrade the conversion performance. In this paper, we leverage the advances of our recently proposed Glow-WaveGAN and propose a noise-independent speech representation learning approach for high-quality voice conversion for noisy target speakers. Specifically, we learn a latent feature space where we ensure that the target distribution modeled by the conversion model is exactly from the modeled distribution of the waveform generator. With this premise, we further manage to make the latent feature to be noise-invariant. Specifically, we introduce a noise-controllable WaveGAN, which directly learns the noise-independent acoustic representation from waveform by the encoder and conducts noise control in the hidden space through a FiLM module in the decoder. As for the conversion model, importantly, we use a flow-based model to learn the distribution of noise-independent but speaker-related latent features from phoneme posteriorgrams. Experimental results demonstrate that the proposed model achieves high speech quality and speaker similarity in the voice conversion for noisy target speakers. ",
    "url": "https://arxiv.org/abs/2207.00756",
    "authors": [
      "Liumeng Xue",
      "Shan Yang",
      "Na Hu",
      "Dan Su",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.00759",
    "title": "Abstraction and Refinement: Towards Scalable and Exact Verification of  Neural Networks",
    "abstract": "As a new programming paradigm, deep neural networks (DNNs) have been increasingly deployed in practice, but the lack of robustness hinders their applications in safety-critical domains. While there are techniques for verifying DNNs with formal guarantees, they are limited in scalability and accuracy. In this paper, we present a novel abstraction-refinement approach for scalable and exact DNN verification. Specifically, we propose a novel abstraction to break down the size of DNNs by over-approximation. The result of verifying the abstract DNN is always conclusive if no spurious counterexample is reported. To eliminate spurious counterexamples introduced by abstraction, we propose a novel counterexample-guided refinement that refines the abstract DNN to exclude a given spurious counterexample while still over-approximating the original one. Our approach is orthogonal to and can be integrated with many existing verification techniques. For demonstration, we implement our approach using two promising and exact tools Marabou and Planet as the underlying verification engines, and evaluate on widely-used benchmarks ACAS Xu, MNIST and CIFAR-10. The results show that our approach can boost their performance by solving more problems and reducing up to 86.3% and 78.0% verification time, respectively. Compared to the most relevant abstraction-refinement approach, our approach is 11.6-26.6 times faster. ",
    "url": "https://arxiv.org/abs/2207.00759",
    "authors": [
      "Jiaxiang Liu",
      "Yunhan Xing",
      "Xiaomu Shi",
      "Fu Song",
      "Zhiwu Xu",
      "Zhong Ming"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00760",
    "title": "Unsupervised Symbolic Music Segmentation using Ensemble Temporal  Prediction Errors",
    "abstract": "Symbolic music segmentation is the process of dividing symbolic melodies into smaller meaningful groups, such as melodic phrases. We proposed an unsupervised method for segmenting symbolic music. The proposed model is based on an ensemble of temporal prediction error models. During training, each model predicts the next token to identify musical phrase changes. While at test time, we perform a peak detection algorithm to select segment candidates. Finally, we aggregate the predictions of each of the models participating in the ensemble to predict the final segmentation. Results suggest the proposed method reaches state-of-the-art performance on the Essen Folksong dataset under the unsupervised setting when considering F-Score and R-value. We additionally provide an ablation study to better assess the contribution of each of the model components to the final results. As expected, the proposed method is inferior to the supervised setting, which leaves room for improvement in future research considering closing the gap between unsupervised and supervised methods. ",
    "url": "https://arxiv.org/abs/2207.00760",
    "authors": [
      "Shahaf Bassan",
      "Yossi Adi",
      "Jeffrey S. Rosenschein"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.00762",
    "title": "Backdoor Attack is A Devil in Federated GAN-based Medical Image  Synthesis",
    "abstract": "Deep Learning-based image synthesis techniques have been applied in healthcare research for generating medical images to support open research. Training generative adversarial neural networks (GAN) usually requires large amounts of training data. Federated learning (FL) provides a way of training a central model using distributed data from different medical institutions while keeping raw data locally. However, FL is vulnerable to backdoor attack, an adversarial by poisoning training data, given the central server cannot access the original data directly. Most backdoor attack strategies focus on classification models and centralized domains. In this study, we propose a way of attacking federated GAN (FedGAN) by treating the discriminator with a commonly used data poisoning strategy in backdoor attack classification models. We demonstrate that adding a small trigger with size less than 0.5 percent of the original image size can corrupt the FL-GAN model. Based on the proposed attack, we provide two effective defense strategies: global malicious detection and local training regularization. We show that combining the two defense strategies yields a robust medical image generation. ",
    "url": "https://arxiv.org/abs/2207.00762",
    "authors": [
      "Ruinan Jin",
      "Xiaoxiao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.00763",
    "title": "Hierarchical Dynamic Routing in Complex Networks via  Topologically-decoupled and Cooperative Reinforcement Learning Agents",
    "abstract": "The transport capacity of a communication network can be characterized by the transition from a free-flow state to a congested state. Here, we propose a dynamic routing strategy in complex networks based on hierarchical bypass selections. The routing decisions are made by the reinforcement learning agents implemented at selected nodes with high betweenness centrality. The learning processes of the agents are decoupled from each other due to the degeneracy of their bypasses. Through interactions mediated by the underlying traffic dynamics, the agents act cooperatively, and coherent actions arise spontaneously. With only a small number of agents, the transport capacities are significantly improved, including in real-world Internet networks at the router level and the autonomous system level. Our strategy is also resilient to link removals. ",
    "url": "https://arxiv.org/abs/2207.00763",
    "authors": [
      "Shiyuan Hu",
      "Shihan Xiao"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2207.00788",
    "title": "Long-Tail Prediction Uncertainty Aware Trajectory Planning for  Self-driving Vehicles",
    "abstract": "A typical trajectory planner of autonomous driving usually relies on predicting the future behavior of surrounding obstacles. In recent years, prediction models based on deep learning have been widely used due to their impressive performance. However, recent studies have shown that deep learning models trained on a dataset following a long-tailed driving scenario distribution will suffer from large prediction errors in the \"tails,\" which might lead to failures of the planner. To this end, this work defines a notion of prediction model uncertainty to quantify high errors due to sparse data. Moreover, this work proposes a trajectory planner to consider such prediction uncertainty for safer performance. Firstly, the prediction model's uncertainty due to insufficient training data is estimated by an ensemble network structure. Then a trajectory planner is designed to consider the worst-case arising from prediction uncertainty. The results show that the proposed method can improve the safety of trajectory planning under the prediction uncertainty caused by insufficient data. At the same time, with sufficient data, the framework will not lead to overly conservative results. This technology helps to improve the safety and reliability of autonomous vehicles under the long-tail data distribution of the real world. ",
    "url": "https://arxiv.org/abs/2207.00788",
    "authors": [
      "Weitao Zhou",
      "Zhong Cao",
      "Nanshan Deng",
      "Xiaoyu Liu",
      "Kun Jiang",
      "Diange Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.00793",
    "title": "Prediction and validation of the strongly modulated forced response of  two beams undergoing frictional impacts",
    "abstract": "We consider two cantilevered beams undergoing frictional impacts at the free end. The beams are designed to be of similar geometry so that they have distinct but close natural frequencies. Under harmonic base excitation near the primary resonance with the higher-frequency fundamental bending mode, the system shows a strongly modulated non-periodic response. The purpose of this work is to analyze to what extent the non-periodic vibro-impact dynamics can be predicted. To this end, we use a recently developed modeling and simulation approach. The approach relies on component mode synthesis, the massless boundary concept and an appropriate time stepping scheme. Unilateral contact and dry friction are modeled as set-valued laws and imposed locally within the spatially resolved contact area. A linear model updating is carried out based on the natural frequencies and damping ratios identified in the regime without impacts. The nonlinear simulation of the steady-state response to forward and backward stepped sine excitation is compared against measurements. The results are in very good agreement, especially in the light of the uncertainty associated with the observed material loss in the contact region and the nonlinear behavior of the clamping. ",
    "url": "https://arxiv.org/abs/2207.00793",
    "authors": [
      "Carlo Monjaraz-Tec",
      "Lukas Kohlmann",
      "Stefan Schwarz",
      "Andreas Hartung",
      "Johann Gross",
      "Malte Krack"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.00794",
    "title": "Boundary-Guided Camouflaged Object Detection",
    "abstract": "Camouflaged object detection (COD), segmenting objects that are elegantly blended into their surroundings, is a valuable yet challenging task. Existing deep-learning methods often fall into the difficulty of accurately identifying the camouflaged object with complete and fine object structure. To this end, in this paper, we propose a novel boundary-guided network (BGNet) for camouflaged object detection. Our method explores valuable and extra object-related edge semantics to guide representation learning of COD, which forces the model to generate features that highlight object structure, thereby promoting camouflaged object detection of accurate boundary localization. Extensive experiments on three challenging benchmark datasets demonstrate that our BGNet significantly outperforms the existing 18 state-of-the-art methods under four widely-used evaluation metrics. Our code is publicly available at: https://github.com/thograce/BGNet. ",
    "url": "https://arxiv.org/abs/2207.00794",
    "authors": [
      "Yujia Sun",
      "Shuo Wang",
      "Chenglizhao Chen",
      "Tian-Zhu Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00797",
    "title": "Learning fast and agile quadrupedal locomotion over complex terrain",
    "abstract": "In this paper, we propose a robust controller that achieves natural and stably fast locomotion on a real blind quadruped robot. With only proprioceptive information, the quadruped robot can move at a maximum speed of 10 times its body length, and has the ability to pass through various complex terrains. The controller is trained in the simulation environment by model-free reinforcement learning. In this paper, the proposed loose neighborhood control architecture not only guarantees the learning rate, but also obtains an action network that is easy to transfer to a real quadruped robot. Our research finds that there is a problem of data symmetry loss during training, which leads to unbalanced performance of the learned controller on the left-right symmetric quadruped robot structure, and proposes a mirror-world neural network to solve the performance problem. The learned controller composed of the mirror-world network can make the robot achieve excellent anti-disturbance ability. No specific human knowledge such as a foot trajectory generator are used in the training architecture. The learned controller can coordinate the robot's gait frequency and locomotion speed, and the locomotion pattern is more natural and reasonable than the artificially designed controller. Our controller has excellent anti-disturbance performance, and has good generalization ability to reach locomotion speeds it has never learned and traverse terrains it has never seen before. ",
    "url": "https://arxiv.org/abs/2207.00797",
    "authors": [
      "Xu Chang",
      "Zhitong Zhang",
      "Honglei An",
      "Hongxu Ma",
      "Qing Wei"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.00816",
    "title": "Mining Tourism Experience on Twitter: A case study",
    "abstract": "With the increase of digital data and social network platforms the impact of social media science in driving company decision related to product/service features and customer care operations is becoming more crucial. In particular, platform such as Twitter where people can share experience about almost everything can drastically impact the reputation and offering of a company as well as of a place or tourism site. Text mining tools are researched and proposed in literature in order to gain value and perform trend topics and sentiment analysis on Twitter. As data are the fuels for these models, the \"right\" ones, i.e the domain-related ones makes a difference on their accuracy. In this paper, we describe a pipeline of \\textit{DataOps / MLOps} operations performed over a tourism related Twitter dataset in order to comprehend tourism motivation and interest. The gained knowledge can be exploit, by the travel/hospitality industry in order to develop data-driven strategic service, and by travelers which can consume relevant information about tourist destination. ",
    "url": "https://arxiv.org/abs/2207.00816",
    "authors": [
      "Davide Stirparo",
      "Beatrice Penna",
      "Mohammad Kazemi",
      "Ariona Shashaj"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.00824",
    "title": "Lane-GNN: Integrating GNN for Predicting Drivers Lane Change Intention",
    "abstract": "Nowadays, intelligent highway traffic network is playing an important role in modern transportation infrastructures. A variable speed limit (VSL) system can be facilitated in the highway traffic network to provide useful and dynamic speed limit information for drivers to travel with enhanced safety. Such system is usually designed with a steady advisory speed in mind so that traffic can move smoothly when drivers follow the speed, rather than speeding up whenever there is a gap and slowing down at congestion. However, little attention has been given to the research of vehicles' behaviours when drivers left the road network governed by a VSL system, which may largely involve unexpected acceleration, deceleration and frequent lane changes, resulting in chaos for the subsequent highway road users. In this paper, we focus on the detection of traffic flow anomaly due to drivers' lane change intention on the highway traffic networks after a VSL system. More specifically, we apply graph modelling on the traffic flow data generated by a popular mobility simulator, SUMO, at road segment levels. We then evaluate the performance of lane changing detection using the proposed Lane-GNN scheme, an attention temporal graph convolutional neural network, and compare its performance with a temporal convolutional neural network (TCNN) as our baseline. Our experimental results show that the proposed Lane-GNN can detect drivers' lane change intention within 90 seconds with an accuracy of 99.42% under certain assumptions. Finally, some interpretation methods are applied to the trained models with a view to further illustrate our findings. ",
    "url": "https://arxiv.org/abs/2207.00824",
    "authors": [
      "Hongde Wu",
      "Mingming Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00826",
    "title": "ImLoveNet: Misaligned Image-supported Registration Network for  Low-overlap Point Cloud Pairs",
    "abstract": "Low-overlap regions between paired point clouds make the captured features very low-confidence, leading cutting edge models to point cloud registration with poor quality. Beyond the traditional wisdom, we raise an intriguing question: Is it possible to exploit an intermediate yet misaligned image between two low-overlap point clouds to enhance the performance of cutting-edge registration models? To answer it, we propose a misaligned image supported registration network for low-overlap point cloud pairs, dubbed ImLoveNet. ImLoveNet first learns triple deep features across different modalities and then exports these features to a two-stage classifier, for progressively obtaining the high-confidence overlap region between the two point clouds. Therefore, soft correspondences are well established on the predicted overlap region, resulting in accurate rigid transformations for registration. ImLoveNet is simple to implement yet effective, since 1) the misaligned image provides clearer overlap information for the two low-overlap point clouds to better locate overlap parts; 2) it contains certain geometry knowledge to extract better deep features; and 3) it does not require the extrinsic parameters of the imaging device with respect to the reference frame of the 3D point cloud. Extensive qualitative and quantitative evaluations on different kinds of benchmarks demonstrate the effectiveness and superiority of our ImLoveNet over state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2207.00826",
    "authors": [
      "Honghua Chen",
      "Zeyong Wei",
      "Yabin Xu",
      "Mingqiang Wei",
      "Jun Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00837",
    "title": "UTD-Yolov5: A Real-time Underwater Targets Detection Method based on  Attention Improved YOLOv5",
    "abstract": "As the treasure house of nature, the ocean contains abundant resources. But the coral reefs, which are crucial to the sustainable development of marine life, are facing a huge crisis because of the existence of COTS and other organisms. The protection of society through manual labor is limited and inefficient. The unpredictable nature of the marine environment also makes manual operations risky. The use of robots for underwater operations has become a trend. However, the underwater image acquisition has defects such as weak light, low resolution, and many interferences, while the existing target detection algorithms are not effective. Based on this, we propose an underwater target detection algorithm based on Attention Improved YOLOv5, called UTD-Yolov5. It can quickly and efficiently detect COTS, which in turn provides a prerequisite for complex underwater operations. We adjusted the original network architecture of YOLOv5 in multiple stages, including: replacing the original Backbone with a two-stage cascaded CSP (CSP2); introducing the visual channel attention mechanism module SE; designing random anchor box similarity calculation method etc. These operations enable UTD-Yolov5 to detect more flexibly and capture features more accurately. In order to make the network more efficient, we also propose optimization methods such as WBF and iterative refinement mechanism. This paper conducts a lot of experiments based on the CSIRO dataset [1]. The results show that the average accuracy of our UTD-Yolov5 reaches 78.54%, which is a great improvement compared to the baseline. ",
    "url": "https://arxiv.org/abs/2207.00837",
    "authors": [
      "Jingyao Wang",
      "Naigong Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.00857",
    "title": "Tree-constrained Pointer Generator with Graph Neural Network Encodings  for Contextual Speech Recognition",
    "abstract": "Incorporating biasing words obtained as contextual knowledge is critical for many automatic speech recognition (ASR) applications. This paper proposes the use of graph neural network (GNN) encodings in a tree-constrained pointer generator (TCPGen) component for end-to-end contextual ASR. By encoding the biasing words in the prefix-tree with a tree-based GNN, lookahead for future wordpieces in end-to-end ASR decoding is achieved at each tree node by incorporating information about all wordpieces on the tree branches rooted from it, which allows a more accurate prediction of the generation probability of the biasing words. Systems were evaluated on the Librispeech corpus using simulated biasing tasks, and on the AMI corpus by proposing a novel visual-grounded contextual ASR pipeline that extracts biasing words from slides alongside each meeting. Results showed that TCPGen with GNN encodings achieved about a further 15% relative WER reduction on the biasing words compared to the original TCPGen, with a negligible increase in the computation cost for decoding. ",
    "url": "https://arxiv.org/abs/2207.00857",
    "authors": [
      "Guangzhi Sun",
      "Chao Zhang",
      "Philip C. Woodland"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.00865",
    "title": "ORA3D: Overlap Region Aware Multi-view 3D Object Detection",
    "abstract": "In multi-view 3D object detection tasks, disparity supervision over overlapping image regions substantially improves the overall detection performance. However, current multi-view 3D object detection methods often fail to detect objects in the overlap region properly, and the network's understanding of the scene is often limited to that of a monocular detection network. To mitigate this issue, we advocate for applying the traditional stereo disparity estimation method to obtain reliable disparity information for the overlap region. Given the disparity estimates as a supervision, we propose to regularize the network to fully utilize the geometric potential of binocular images, and improve the overall detection accuracy. Moreover, we propose to use an adversarial overlap region discriminator, which is trained to minimize the representational gap between non-overlap regions and overlapping regions where objects are often largely occluded or suffer from deformation due to camera distortion, causing a domain shift. We demonstrate the effectiveness of the proposed method with the large-scale multi-view 3D object detection benchmark, called nuScenes. Our experiment shows that our proposed method outperforms the current state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2207.00865",
    "authors": [
      "Wonseok Roh",
      "Gyusam Chang",
      "Seokha Moon",
      "Giljoo Nam",
      "Chanyoung Kim",
      "Younghyun Kim",
      "Sangpil Kim",
      "Jinkyu Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00872",
    "title": "FL-Defender: Combating Targeted Attacks in Federated Learning",
    "abstract": "Federated learning (FL) enables learning a global machine learning model from local data distributed among a set of participating workers. This makes it possible i) to train more accurate models due to learning from rich joint training data, and ii) to improve privacy by not sharing the workers' local private data with others. However, the distributed nature of FL makes it vulnerable to targeted poisoning attacks that negatively impact the integrity of the learned model while, unfortunately, being difficult to detect. Existing defenses against those attacks are limited by assumptions on the workers' data distribution, may degrade the global model performance on the main task and/or are ill-suited to high-dimensional models. In this paper, we analyze targeted attacks against FL and find that the neurons in the last layer of a deep learning (DL) model that are related to the attacks exhibit a different behavior from the unrelated neurons, making the last-layer gradients valuable features for attack detection. Accordingly, we propose \\textit{FL-Defender} as a method to combat FL targeted attacks. It consists of i) engineering more robust discriminative features by calculating the worker-wise angle similarity for the workers' last-layer gradients, ii) compressing the resulting similarity vectors using PCA to reduce redundant information, and iii) re-weighting the workers' updates based on their deviation from the centroid of the compressed similarity vectors. Experiments on three data sets with different DL model sizes and data distributions show the effectiveness of our method at defending against label-flipping and backdoor attacks. Compared to several state-of-the-art defenses, FL-Defender achieves the lowest attack success rates, maintains the performance of the global model on the main task and causes minimal computational overhead on the server. ",
    "url": "https://arxiv.org/abs/2207.00872",
    "authors": [
      "Najeeb Jebreel",
      "Josep Domingo-Ferrer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.00873",
    "title": "Energy-efficient User Clustering for UAV-enabled Wireless Networks Using  EM Algorithm",
    "abstract": "Unmanned Aerial Vehicles (UAVs) can be used to provide wireless connectivity to support the existing infrastructure in hot-spots or replace it in cases of destruction. UAV-enabled wireless provides several advantages in network performance due to drone small cells (DSCs) mobility despite the limited onboard energy. However, the problem of resource allocation has added complexity. In this paper, we propose an energy-efficient user clustering mechanism based on Gaussian mixture models (GMM) using a modified Expected-Maximization (EM) algorithm. The algorithm is intended to provide the initial user clustering and drone deployment upon which additional mechanisms can be employed to further enhance the system performance. The proposed algorithm improves the energy efficiency of the system by 25% and link reliability by 18.3% compared to other baseline methods. ",
    "url": "https://arxiv.org/abs/2207.00873",
    "authors": [
      "Salim Janji",
      "Adrian Kliks"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.00874",
    "title": "Neural Networks for Path Planning",
    "abstract": "The scientific community is able to present a new set of solutions to practical problems that substantially improve the performance of modern technology in terms of efficiency and speed of computation due to the advancement in neural networks architectures. We present the latest works considering the utilization of neural networks in robot path planning. Our survey shows the contrast between different formulations of the problems that consider different inputs, outputs, and environments and how different neural networks architectures are able to provide solutions to all of the presented problems. ",
    "url": "https://arxiv.org/abs/2207.00874",
    "authors": [
      "Salim Janji",
      "Adrian Kliks"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.00887",
    "title": "Towards Robust Video Object Segmentation with Adaptive Object  Calibration",
    "abstract": "In the booming video era, video segmentation attracts increasing research attention in the multimedia community. Semi-supervised video object segmentation (VOS) aims at segmenting objects in all target frames of a video, given annotated object masks of reference frames. Most existing methods build pixel-wise reference-target correlations and then perform pixel-wise tracking to obtain target masks. Due to neglecting object-level cues, pixel-level approaches make the tracking vulnerable to perturbations, and even indiscriminate among similar objects. Towards robust VOS, the key insight is to calibrate the representation and mask of each specific object to be expressive and discriminative. Accordingly, we propose a new deep network, which can adaptively construct object representations and calibrate object masks to achieve stronger robustness. First, we construct the object representations by applying an adaptive object proxy (AOP) aggregation method, where the proxies represent arbitrary-shaped segments at multi-levels for reference. Then, prototype masks are initially generated from the reference-target correlations based on AOP. Afterwards, such proto-masks are further calibrated through network modulation, conditioning on the object proxy representations. We consolidate this conditional mask calibration process in a progressive manner, where the object representations and proto-masks evolve to be discriminative iteratively. Extensive experiments are conducted on the standard VOS benchmarks, YouTube-VOS-18/19 and DAVIS-17. Our model achieves the state-of-the-art performance among existing published works, and also exhibits superior robustness against perturbations. Our project repo is at https://github.com/JerryX1110/Robust-Video-Object-Segmentation ",
    "url": "https://arxiv.org/abs/2207.00887",
    "authors": [
      "Xiaohao Xu",
      "Jinglu Wang",
      "Xiang Ming",
      "Yan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00894",
    "title": "Ransomware Classification and Detection With Machine Learning Algorithms",
    "abstract": "Malicious attacks, malware, and ransomware families pose critical security issues to cybersecurity, and it may cause catastrophic damages to computer systems, data centers, web, and mobile applications across various industries and businesses. Traditional anti-ransomware systems struggle to fight against newly created sophisticated attacks. Therefore, state-of-the-art techniques like traditional and neural network-based architectures can be immensely utilized in the development of innovative ransomware solutions. In this paper, we present a feature selection-based framework with adopting different machine learning algorithms including neural network-based architectures to classify the security level for ransomware detection and prevention. We applied multiple machine learning algorithms: Decision Tree (DT), Random Forest (RF), Naive Bayes (NB), Logistic Regression (LR) as well as Neural Network (NN)-based classifiers on a selected number of features for ransomware classification. We performed all the experiments on one ransomware dataset to evaluate our proposed framework. The experimental results demonstrate that RF classifiers outperform other methods in terms of accuracy, F-beta, and precision scores. ",
    "url": "https://arxiv.org/abs/2207.00894",
    "authors": [
      "Mohammad Masum",
      "Md Jobair Hossain Faruk",
      "Hossain Shahriar",
      "Kai Qian",
      "Dan Lo",
      "Muhaiminul Islam Adnan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.00899",
    "title": "Face Morphing Attack Detection Using Privacy-Aware Training Data",
    "abstract": "Images of morphed faces pose a serious threat to face recognition--based security systems, as they can be used to illegally verify the identity of multiple people with a single morphed image. Modern detection algorithms learn to identify such morphing attacks using authentic images of real individuals. This approach raises various privacy concerns and limits the amount of publicly available training data. In this paper, we explore the efficacy of detection algorithms that are trained only on faces of non--existing people and their respective morphs. To this end, two dedicated algorithms are trained with synthetic data and then evaluated on three real-world datasets, i.e.: FRLL-Morphs, FERET-Morphs and FRGC-Morphs. Our results show that synthetic facial images can be successfully employed for the training process of the detection algorithms and generalize well to real-world scenarios. ",
    "url": "https://arxiv.org/abs/2207.00899",
    "authors": [
      "Marija Ivanovska",
      "Andrej Kronov\u0161ek",
      "Peter Peer",
      "Vitomir \u0160truc",
      "Borut Batagelj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00903",
    "title": "A Structured Sparse Neural Network and Its Matrix Calculations Algorithm",
    "abstract": "Gradient descent optimizations and backpropagation are the most common methods for training neural networks, but they are computationally expensive for real time applications, need high memory resources, and are difficult to converge for many networks and large datasets. [Pseudo]inverse models for training neural network have emerged as powerful tools to overcome these issues. In order to effectively implement these methods, structured pruning maybe be applied to produce sparse neural networks. Although sparse neural networks are efficient in memory usage, most of their algorithms use the same fully loaded matrix calculation methods which are not efficient for sparse matrices. Tridiagonal matrices are one of the frequently used candidates for structuring neural networks, but they are not flexible enough to handle underfitting and overfitting problems as well as generalization properties. In this paper, we introduce a nonsymmetric, tridiagonal matrix with offdiagonal sparse entries and offset sub and super-diagonals as well algorithms for its [pseudo]inverse and determinant calculations. Traditional algorithms for matrix calculations, specifically inversion and determinant, of these forms are not efficient specially for large matrices, e.g. larger datasets or deeper networks. A decomposition for lower triangular matrices is developed and the original matrix is factorized into a set of matrices where their inverse matrices are calculated. For the cases where the matrix inverse does not exist, a least square type pseudoinverse is provided. The present method is a direct routine, i.e., executes in a predictable number of operations which is tested for randomly generated matrices with varying size. The results show significant improvement in computational costs specially when the size of matrix increases. ",
    "url": "https://arxiv.org/abs/2207.00903",
    "authors": [
      "Seyyed Mostafa Mousavi Janbeh Sarayi",
      "Mansour Nikkhah Bahrami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2207.00907",
    "title": "Emotion Analysis using Multi-Layered Networks for Graphical  Representation of Tweets",
    "abstract": "Anticipating audience reaction towards a certain piece of text is integral to several facets of society ranging from politics, research, and commercial industries. Sentiment analysis (SA) is a useful natural language processing (NLP) technique that utilizes both lexical/statistical and deep learning methods to determine whether different sized texts exhibit a positive, negative, or neutral emotion. However, there is currently a lack of tools that can be used to analyse groups of independent texts and extract the primary emotion from the whole set. Therefore, the current paper proposes a novel algorithm referred to as the Multi-Layered Tweet Analyzer (MLTA) that graphically models social media text using multi-layered networks (MLNs) in order to better encode relationships across independent sets of tweets. Graph structures are capable of capturing meaningful relationships in complex ecosystems compared to other representation methods. State of the art Graph Neural Networks (GNNs) are used to extract information from the Tweet-MLN and make predictions based on the extracted graph features. Results show that not only does the MLTA predict from a larger set of possible emotions, delivering a more accurate sentiment compared to the standard positive, negative or neutral, it also allows for accurate group-level predictions of Twitter data. ",
    "url": "https://arxiv.org/abs/2207.00907",
    "authors": [
      "Anna Nguyen",
      "Antonio Longa",
      "Massimiliano Luca",
      "Joe Kaul",
      "Gabriel Lopez"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.00909",
    "title": "Drift Reduction for Monocular Visual Odometry of Intelligent Vehicles  using Feedforward Neural Networks",
    "abstract": "In this paper, an approach for reducing the drift in monocular visual odometry algorithms is proposed based on a feedforward neural network. A visual odometry algorithm computes the incremental motion of the vehicle between the successive camera frames, then integrates these increments to determine the pose of the vehicle. The proposed neural network reduces the errors in the pose estimation of the vehicle which results from the inaccuracies in features detection and matching, camera intrinsic parameters, and so on. These inaccuracies are propagated to the motion estimation of the vehicle causing larger amounts of estimation errors. The drift reducing neural network identifies such errors based on the motion of features in the successive camera frames leading to more accurate incremental motion estimates. The proposed drift reducing neural network is trained and validated using the KITTI dataset and the results show the efficacy of the proposed approach in reducing the errors in the incremental orientation estimation, thus reducing the overall error in the pose estimation. ",
    "url": "https://arxiv.org/abs/2207.00909",
    "authors": [
      "Hassan Wagih",
      "Mostafa Osman",
      "Mohamed I. Awad",
      "Sherif Hammad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.00927",
    "title": "Decremental Matching in General Graphs",
    "abstract": "We consider the problem of maintaining an approximate maximum integral matching in a dynamic graph $G$, while the adversary makes changes to the edges of the graph. The goal is to maintain a $(1+\\epsilon)$-approximate maximum matching for constant $\\epsilon>0$, while minimizing the update time. In the fully dynamic setting, where both edge insertion and deletions are allowed, Gupta and Peng (see \\cite{GP13}) gave an algorithm for this problem with an update time of $O(\\sqrt{m}/\\epsilon^2)$. Motivated by the fact that the $O_{\\epsilon}(\\sqrt{m})$ barrier is hard to overcome (see Henzinger, Krinninger, Nanongkai, and Saranurak [HKNS15]); Kopelowitz, Pettie, and Porat [KPP16]), we study this problem in the \\emph{decremental} model, where the adversary is only allowed to delete edges. Recently, Bernstein, Probst-Gutenberg, and Saranurak (see [BPT20]) gave an $O_{\\epsilon}(1)$ update time decremental algorithm for this problem in \\emph{bipartite graphs}. However, beating $O(\\sqrt{m})$ update time remained an open problem for \\emph{general graphs}. In this paper, we bridge the gap between bipartite and general graphs, by giving an $O_{\\epsilon}(1)$ update time algorithm that maintains a $(1+\\epsilon)$-approximate maximum integral matching under adversarial deletions. Our algorithm is randomized, but works against an adaptive adversary. Together with the work of Grandoni, Leonardi, Sankowski, Schwiegelshohn, and Solomon [GLSSS19] who give an $O_{\\epsilon}(1)$ update time algorithm for general graphs in the \\emph{incremental} (insertion-only) model, our result essentially completes the picture for partially dynamic matching. ",
    "url": "https://arxiv.org/abs/2207.00927",
    "authors": [
      "Sepehr Assadi",
      "Aaron Bernstein",
      "Aditi Dudeja"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2207.00928",
    "title": "Continuous Sign Language Recognition via Temporal Super-Resolution  Network",
    "abstract": "Aiming at the problem that the spatial-temporal hierarchical continuous sign language recognition model based on deep learning has a large amount of computation, which limits the real-time application of the model, this paper proposes a temporal super-resolution network(TSRNet). The data is reconstructed into a dense feature sequence to reduce the overall model computation while keeping the final recognition accuracy loss to a minimum. The continuous sign language recognition model(CSLR) via TSRNet mainly consists of three parts: frame-level feature extraction, time series feature extraction and TSRNet, where TSRNet is located between frame-level feature extraction and time-series feature extraction, which mainly includes two branches: detail descriptor and rough descriptor. The sparse frame-level features are fused through the features obtained by the two designed branches as the reconstructed dense frame-level feature sequence, and the connectionist temporal classification(CTC) loss is used for training and optimization after the time-series feature extraction part. To better recover semantic-level information, the overall model is trained with the self-generating adversarial training method proposed in this paper to reduce the model error rate. The training method regards the TSRNet as the generator, and the frame-level processing part and the temporal processing part as the discriminator. In addition, in order to unify the evaluation criteria of model accuracy loss under different benchmarks, this paper proposes word error rate deviation(WERD), which takes the error rate between the estimated word error rate (WER) and the reference WER obtained by the reconstructed frame-level feature sequence and the complete original frame-level feature sequence as the WERD. Experiments on two large-scale sign language datasets demonstrate the effectiveness of the proposed model. ",
    "url": "https://arxiv.org/abs/2207.00928",
    "authors": [
      "Qidan Zhu",
      "Jing Li",
      "Fei Yuan",
      "Quan Gan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00931",
    "title": "Graph Learning based Generative Design for Resilience of Interdependent  Network Systems",
    "abstract": "Interconnected complex systems usually undergo disruptions due to internal uncertainties and external negative impacts such as those caused by harsh operating environments or regional natural disaster events. To maintain the operation of interconnected network systems under both internal and external challenges, design for resilience research has been conducted from both enhancing the reliability of the system through better designs and improving the failure recovery capabilities. As for enhancing the designs, challenges have arisen for designing a robust system due to the increasing scale of modern systems and the complicated underlying physical constraints. To tackle these challenges and design a resilient system efficiently, this study presents a generative design method that utilizes graph learning algorithms. The generative design framework contains a performance estimator and a candidate design generator. The generator can intelligently mine good properties from existing systems and output new designs that meet predefined performance criteria. While the estimator can efficiently predict the performance of the generated design for a fast iterative learning process. Case studies results based on power systems from the IEEE dataset have illustrated the applicability of the proposed method for designing resilient interconnected systems. ",
    "url": "https://arxiv.org/abs/2207.00931",
    "authors": [
      "Jiaxin Wu",
      "Pingfeng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.00934",
    "title": "Wireless Channel Prediction in Partially Observed Environments",
    "abstract": "Site-specific radio frequency (RF) propagation prediction increasingly relies on models built from visual data such as cameras and LIDAR sensors. When operating in dynamic settings, the environment may only be partially observed. This paper introduces a method to extract statistical channel models, given partial observations of the surrounding environment. We propose a simple heuristic algorithm that performs ray tracing on the partial environment and then uses machine-learning trained predictors to estimate the channel and its uncertainty from features extracted from the partial ray tracing results. It is shown that the proposed method can interpolate between fully statistical models when no partial information is available and fully deterministic models when the environment is completely observed. The method can also capture the degree of uncertainty of the propagation predictions depending on the amount of region that has been explored. The methodology is demonstrated in a robotic navigation application simulated on a set of indoor maps with detailed models constructed using state-of-the-art navigation, simultaneous localization and mapping (SLAM), and computer vision methods. ",
    "url": "https://arxiv.org/abs/2207.00934",
    "authors": [
      "Mingsheng Yin",
      "Yaqi Hu",
      "Tommy Azzino",
      "Seongjoon Kang",
      "Marco Mezzavilla",
      "Sundeep Rangan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.00943",
    "title": "Degradation-Guided Meta-Restoration Network for Blind Super-Resolution",
    "abstract": "Blind super-resolution (SR) aims to recover high-quality visual textures from a low-resolution (LR) image, which is usually degraded by down-sampling blur kernels and additive noises. This task is extremely difficult due to the challenges of complicated image degradations in the real-world. Existing SR approaches either assume a predefined blur kernel or a fixed noise, which limits these approaches in challenging cases. In this paper, we propose a Degradation-guided Meta-restoration network for blind Super-Resolution (DMSR) that facilitates image restoration for real cases. DMSR consists of a degradation extractor and meta-restoration modules. The extractor estimates the degradations in LR inputs and guides the meta-restoration modules to predict restoration parameters for different degradations on-the-fly. DMSR is jointly optimized by a novel degradation consistency loss and reconstruction losses. Through such an optimization, DMSR outperforms SOTA by a large margin on three widely-used benchmarks. A user study including 16 subjects further validates the superiority of DMSR in real-world blind SR tasks. ",
    "url": "https://arxiv.org/abs/2207.00943",
    "authors": [
      "Fuzhi Yang",
      "Huan Yang",
      "Yanhong Zeng",
      "Jianlong Fu",
      "Hongtao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.00956",
    "title": "Tricking the Hashing Trick: A Tight Lower Bound on the Robustness of  CountSketch to Adaptive Inputs",
    "abstract": "CountSketch and Feature Hashing (the \"hashing trick\") are popular randomized dimensionality reduction methods that support recovery of $\\ell_2$-heavy hitters (keys $i$ where $v_i^2 > \\epsilon \\|\\boldsymbol{v}\\|_2^2$) and approximate inner products. When the inputs are {\\em not adaptive} (do not depend on prior outputs), classic estimators applied to a sketch of size $O(\\ell/\\epsilon)$ are accurate for a number of queries that is exponential in $\\ell$. When inputs are adaptive, however, an adversarial input can be constructed after $O(\\ell)$ queries with the classic estimator and the best known robust estimator only supports $\\tilde{O}(\\ell^2)$ queries. In this work we show that this quadratic dependence is in a sense inherent: We design an attack that after $O(\\ell^2)$ queries produces an adversarial input vector whose sketch is highly biased. Our attack uses \"natural\" non-adaptive inputs (only the final adversarial input is chosen adaptively) and universally applies with any correct estimator, including one that is unknown to the attacker. In that, we expose inherent vulnerability of this fundamental method. ",
    "url": "https://arxiv.org/abs/2207.00956",
    "authors": [
      "Edith Cohen",
      "Jelani Nelson",
      "Tam\u00e1s Sarl\u00f3s",
      "Uri Stemmer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00960",
    "title": "WaferSegClassNet -- A Light-weight Network for Classification and  Segmentation of Semiconductor Wafer Defects",
    "abstract": "As the integration density and design intricacy of semiconductor wafers increase, the magnitude and complexity of defects in them are also on the rise. Since the manual inspection of wafer defects is costly, an automated artificial intelligence (AI) based computer-vision approach is highly desired. The previous works on defect analysis have several limitations, such as low accuracy and the need for separate models for classification and segmentation. For analyzing mixed-type defects, some previous works require separately training one model for each defect type, which is non-scalable. In this paper, we present WaferSegClassNet (WSCN), a novel network based on encoder-decoder architecture. WSCN performs simultaneous classification and segmentation of both single and mixed-type wafer defects. WSCN uses a \"shared encoder\" for classification, and segmentation, which allows training WSCN end-to-end. We use N-pair contrastive loss to first pretrain the encoder and then use BCE-Dice loss for segmentation, and categorical cross-entropy loss for classification. Use of N-pair contrastive loss helps in better embedding representation in the latent dimension of wafer maps. WSCN has a model size of only 0.51MB and performs only 0.2M FLOPS. Thus, it is much lighter than other state-of-the-art models. Also, it requires only 150 epochs for convergence, compared to 4,000 epochs needed by a previous work. We evaluate our model on the MixedWM38 dataset, which has 38,015 images. WSCN achieves an average classification accuracy of 98.2% and a dice coefficient of 0.9999. We are the first to show segmentation results on the MixedWM38 dataset. The source code can be obtained from https://github.com/ckmvigil/WaferSegClassNet. ",
    "url": "https://arxiv.org/abs/2207.00960",
    "authors": [
      "Subhrajit Nag",
      "Dhruv Makwana",
      "Sai Chandra Teja R",
      "Sparsh Mittal",
      "C Krishna Mohan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.00961",
    "title": "Digital-twin-enhanced metal tube bending forming real-time prediction  method based on Multi-source-input MTL",
    "abstract": "As one of the most widely used metal tube bending methods, the rotary draw bending (RDB) process enables reliable and high-precision metal tube bending forming (MTBF). The forming accuracy is seriously affected by the springback and other potential forming defects, of which the mechanism analysis is difficult to deal with. At the same time, the existing methods are mainly conducted in offline space, ignoring the real-time information in the physical world, which is unreliable and inefficient. To address this issue, a digital-twin-enhanced (DT-enhanced) metal tube bending forming real-time prediction method based on multi-source-input multi-task learning (MTL) is proposed. The new method can achieve comprehensive MTBF real-time prediction. By sharing the common feature of the multi-close domain and adopting group regularization strategy on feature sharing and accepting layers, the accuracy and efficiency of the multi-source-input MTL can be guaranteed. Enhanced by DT, the physical real-time deformation data is aligned in the image dimension by an improved Grammy Angle Field (GAF) conversion, realizing the reflection of the actual processing. Different from the traditional offline prediction methods, the new method integrates the virtual and physical data to achieve a more efficient and accurate real-time prediction result. and the DT mapping connection between virtual and physical systems can be achieved. To exclude the effects of equipment errors, the effectiveness of the proposed method is verified on the physical experiment-verified FE simulation scenarios. At the same time, the common pre-training networks are compared with the proposed method. The results show that the proposed DT-enhanced prediction method is more accurate and efficient. ",
    "url": "https://arxiv.org/abs/2207.00961",
    "authors": [
      "Chang Sun",
      "Zili Wang",
      "Shuyou Zhang",
      "Taotao Zhou",
      "Jie Li",
      "Jianrong Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.00965",
    "title": "Cycle-Interactive Generative Adversarial Network for Robust Unsupervised  Low-Light Enhancement",
    "abstract": "Getting rid of the fundamental limitations in fitting to the paired training data, recent unsupervised low-light enhancement methods excel in adjusting illumination and contrast of images. However, for unsupervised low light enhancement, the remaining noise suppression issue due to the lacking of supervision of detailed signal largely impedes the wide deployment of these methods in real-world applications. Herein, we propose a novel Cycle-Interactive Generative Adversarial Network (CIGAN) for unsupervised low-light image enhancement, which is capable of not only better transferring illumination distributions between low/normal-light images but also manipulating detailed signals between two domains, e.g., suppressing/synthesizing realistic noise in the cyclic enhancement/degradation process. In particular, the proposed low-light guided transformation feed-forwards the features of low-light images from the generator of enhancement GAN (eGAN) into the generator of degradation GAN (dGAN). With the learned information of real low-light images, dGAN can synthesize more realistic diverse illumination and contrast in low-light images. Moreover, the feature randomized perturbation module in dGAN learns to increase the feature randomness to produce diverse feature distributions, persuading the synthesized low-light images to contain realistic noise. Extensive experiments demonstrate both the superiority of the proposed method and the effectiveness of each module in CIGAN. ",
    "url": "https://arxiv.org/abs/2207.00965",
    "authors": [
      "Zhangkai Ni",
      "Wenhan Yang",
      "Hanli Wang",
      "Shiqi Wang",
      "Lin Ma",
      "Sam Kwong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.00987",
    "title": "Architecture Augmentation for Performance Predictor Based on Graph  Isomorphism",
    "abstract": "Neural Architecture Search (NAS) can automatically design architectures for deep neural networks (DNNs) and has become one of the hottest research topics in the current machine learning community. However, NAS is often computationally expensive because a large number of DNNs require to be trained for obtaining performance during the search process. Performance predictors can greatly alleviate the prohibitive cost of NAS by directly predicting the performance of DNNs. However, building satisfactory performance predictors highly depends on enough trained DNN architectures, which are difficult to obtain in most scenarios. To solve this critical issue, we propose an effective DNN architecture augmentation method named GIAug in this paper. Specifically, we first propose a mechanism based on graph isomorphism, which has the merit of efficiently generating a factorial of $\\boldsymbol n$ (i.e., $\\boldsymbol n!$) diverse annotated architectures upon a single architecture having $\\boldsymbol n$ nodes. In addition, we also design a generic method to encode the architectures into the form suitable to most prediction models. As a result, GIAug can be flexibly utilized by various existing performance predictors-based NAS algorithms. We perform extensive experiments on CIFAR-10 and ImageNet benchmark datasets on small-, medium- and large-scale search space. The experiments show that GIAug can significantly enhance the performance of most state-of-the-art peer predictors. In addition, GIAug can save three magnitude order of computation cost at most on ImageNet yet with similar performance when compared with state-of-the-art NAS algorithms. ",
    "url": "https://arxiv.org/abs/2207.00987",
    "authors": [
      "Xiangning Xie",
      "Yuqiao Liu",
      "Yanan Sun",
      "Mengjie Zhang",
      "Kay Chen Tan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2207.00993",
    "title": "Towards Error-Resilient Neural Speech Coding",
    "abstract": "Neural audio coding has shown very promising results recently in the literature to largely outperform traditional codecs but limited attention has been paid on its error resilience. Neural codecs trained considering only source coding tend to be extremely sensitive to channel noises, especially in wireless channels with high error rate. In this paper, we investigate how to elevate the error resilience of neural audio codecs for packet losses that often occur during real-time communications. We propose a feature-domain packet loss concealment algorithm (FD-PLC) for real-time neural speech coding. Specifically, we introduce a self-attention-based module on the received latent features to recover lost frames in the feature domain before the decoder. A hybrid segment-level and frame-level frequency-domain discriminator is employed to guide the network to focus on both the generative quality of lost frames and the continuity with neighbouring frames. Experimental results on several error patterns show that the proposed scheme can achieve better robustness compared with the corresponding error-free and error-resilient baselines. We also show that feature-domain concealment is superior to waveform-domain counterpart as post-processing. ",
    "url": "https://arxiv.org/abs/2207.00993",
    "authors": [
      "Huaying Xue",
      "Xiulian Peng",
      "Xue Jiang",
      "Yan Lu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.00997",
    "title": "Dynamic boxes fusion strategy in object detection",
    "abstract": "Object detection on microscopic scenarios is a popular task. As microscopes always have variable magnifications, the object can vary substantially in scale, which burdens the optimization of detectors. Moreover, different situations of camera focusing bring in the blurry images, which leads to great challenge of distinguishing the boundaries between objects and background. To solve the two issues mentioned above, we provide bags of useful training strategies and extensive experiments on Chula-ParasiteEgg-11 dataset, bring non-negligible results on ICIP 2022 Challenge: Parasitic Egg Detection and Classification in Microscopic Images, further more, we propose a new box selection strategy and an improved boxes fusion method for multi-model ensemble, as a result our method wins 1st place(mIoU 95.28%, mF1Score 99.62%), which is also the state-of-the-art method on Chula-ParasiteEgg-11 dataset. ",
    "url": "https://arxiv.org/abs/2207.00997",
    "authors": [
      "Zhijiang Wan",
      "Shichang Liu",
      "Manyu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01012",
    "title": "Mental Illness Classification on Social Media Texts using Deep Learning  and Transfer Learning",
    "abstract": "Given the current social distance restrictions across the world, most individuals now use social media as their major medium of communication. Millions of people suffering from mental diseases have been isolated due to this, and they are unable to get help in person. They have become more reliant on online venues to express themselves and seek advice on dealing with their mental disorders. According to the World health organization (WHO), approximately 450 million people are affected. Mental illnesses, such as depression, anxiety, etc., are immensely common and have affected an individuals' physical health. Recently Artificial Intelligence (AI) methods have been presented to help mental health providers, including psychiatrists and psychologists, in decision making based on patients' authentic information (e.g., medical records, behavioral data, social media utilization, etc.). AI innovations have demonstrated predominant execution in numerous real-world applications broadening from computer vision to healthcare. This study analyzes unstructured user data on the Reddit platform and classifies five common mental illnesses: depression, anxiety, bipolar disorder, ADHD, and PTSD. We trained traditional machine learning, deep learning, and transfer learning multi-class models to detect mental disorders of individuals. This effort will benefit the public health system by automating the detection process and informing appropriate authorities about people who require emergency assistance. ",
    "url": "https://arxiv.org/abs/2207.01012",
    "authors": [
      "Iqra Ameer",
      "Muhammad Arif",
      "Grigori Sidorov",
      "Helena G\u00f2mez-Adorno",
      "Alexander Gelbukh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.01015",
    "title": "One-off Events? An Empirical Study of Hackathon Code Creation and Reuse",
    "abstract": "Background: Hackathons have become popular events for teams to collaborate on projects and develop software prototypes. Most existing research focuses on activities during an event with limited attention to the evolution of the hackathon code. Aim: We aim to understand the evolution of code used in and created during hackathon events, with a particular focus on the code blobs, specifically, how frequently hackathon teams reuse pre-existing code, how much new code they develop, if that code gets reused afterward, and what factors affect reuse. Method: We collected information about 22,183 hackathon projects from DevPost and obtained related code blobs, authors, project characteristics, original author, code creation time, language, and size information from World of Code. We tracked the reuse of code blobs by identifying all commits containing blobs created during hackathons and identifying all projects that contain those commits. We also conducted a series of surveys in order to gain a deeper understanding of hackathon code evolution that we sent out to hackathon participants whose code was reused, whose code was not reused, and developers who reused some hackathon code. Result: 9.14% of the code blobs in hackathon repositories and 8% of the lines of code (LOC) are created during hackathons and around a third of the hackathon code gets reused in other projects by both blob count and LOC. The number of associated technologies and the number of participants in hackathons increase the reuse probability. Conclusion: The results of our study demonstrate hackathons are not always \"one-off\" events as common knowledge dictates and they can serve as a starting point for further studies in this area. ",
    "url": "https://arxiv.org/abs/2207.01015",
    "authors": [
      "Ahmed Samir Imam Mahmoud",
      "Tapajit Dey",
      "Alexander Nolte",
      "Audris Mockus",
      "James D. Herbsleb"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.01019",
    "title": "Comparative Analysis of Time Series Forecasting Approaches for Household  Electricity Consumption Prediction",
    "abstract": "As a result of increasing population and globalization, the demand for energy has greatly risen. Therefore, accurate energy consumption forecasting has become an essential prerequisite for government planning, reducing power wastage and stable operation of the energy management system. In this work we present a comparative analysis of major machine learning models for time series forecasting of household energy consumption. Specifically, we use Weka, a data mining tool to first apply models on hourly and daily household energy consumption datasets available from Kaggle data science community. The models applied are: Multilayer Perceptron, K Nearest Neighbor regression, Support Vector Regression, Linear Regression, and Gaussian Processes. Secondly, we also implemented time series forecasting models, ARIMA and VAR, in python to forecast household energy consumption of selected South Korean households with and without weather data. Our results show that the best methods for the forecasting of energy consumption prediction are Support Vector Regression followed by Multilayer Perceptron and Gaussian Process Regression. ",
    "url": "https://arxiv.org/abs/2207.01019",
    "authors": [
      "Muhammad Bilal",
      "Hyeok Kim",
      "Muhammad Fayaz",
      "Pravin Pawar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.01030",
    "title": "Boosting Single-Frame 3D Object Detection by Simulating Multi-Frame  Point Clouds",
    "abstract": "To boost a detector for single-frame 3D object detection, we present a new approach to train it to simulate features and responses following a detector trained on multi-frame point clouds. Our approach needs multi-frame point clouds only when training the single-frame detector, and once trained, it can detect objects with only single-frame point clouds as inputs during the inference. We design a novel Simulated Multi-Frame Single-Stage object Detector (SMF-SSD) framework to realize the approach: multi-view dense object fusion to densify ground-truth objects to generate a multi-frame point cloud; self-attention voxel distillation to facilitate one-to-many knowledge transfer from multi- to single-frame voxels; multi-scale BEV feature distillation to transfer knowledge in low-level spatial and high-level semantic BEV features; and adaptive response distillation to activate single-frame responses of high confidence and accurate localization. Experimental results on the Waymo test set show that our SMF-SSD consistently outperforms all state-of-the-art single-frame 3D object detectors for all object classes of difficulty levels 1 and 2 in terms of both mAP and mAPH. ",
    "url": "https://arxiv.org/abs/2207.01030",
    "authors": [
      "Wu Zheng",
      "Li Jiang",
      "Fanbin Lu",
      "Yangyang Ye",
      "Chi-Wing Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01033",
    "title": "Auto-Calibrating Admittance Controller for Robust Motion of Robotic  Systems",
    "abstract": "We demonstrate an admittance controller with auto-tuning that can be applied for single and multi-point contact robots (e.g., legged robots with point feet or multi-finger grippers). The controller's objective is to track wrench profiles of each contact point while considering the additional torque due to rotational friction. Our admittance controller is adaptive during online operation by using an auto-tuning method that tunes the gains of the controller while following several training objectives that facilitate controller stability, such as tracking the wrench profile as closely as possible, ensuring control outputs that are within force limits that minimize slippage, and avoids kinematic singularity. We demonstrate the robustness of our controller on hardware for both manipulation and locomotion tasks using a multi-limbed climbing robot. ",
    "url": "https://arxiv.org/abs/2207.01033",
    "authors": [
      "Alexander Schperberg",
      "Yuki Shirai",
      "Xuan Lin",
      "Yusuke Tanaka",
      "Dennis Hong"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.01045",
    "title": "FE${}^\\textbf{ANN}$ $-$ An efficient data-driven multiscale approach  based on physics-constrained neural networks and automated data mining",
    "abstract": "Herein, we present a new data-driven multiscale framework called FE${}^\\text{ANN}$ which is based on two main keystones: the usage of physics-constrained artificial neural networks (ANNs) as macroscopic surrogate models and an autonomous data mining process. Our approach allows the efficient simulation of materials with complex underlying microstructures which reveal an overall anisotropic and nonlinear behavior on the macroscale. Thereby, we restrict ourselves to finite strain hyperelasticity problems for now. By using a set of problem specific invariants as the input of the ANN and the Helmholtz free energy density as the output, several physical principles, e.g., objectivity, material symmetry, compatibility with the balance of angular momentum and thermodynamic consistency are fulfilled a priori. The necessary data for the training of the ANN-based surrogate model, i.e., macroscopic deformations and corresponding stresses, are collected via computational homogenization of representative volume elements (RVEs). Thereby, the core feature of the approach is given by a completely autonomous mining of the required data set within an overall loop. In each iteration of the loop, new data are generated by gathering the macroscopic deformation states from the macroscopic finite element (FE) simulation and a subsequently sorting by using the anisotropy class of the considered material. Finally, all unknown deformations are prescribed in the RVE simulation to get the corresponding stresses and thus to extend the data set. The proposed framework consequently allows to reduce the number of time-consuming microscale simulations to a minimum. It is exemplarily applied to several descriptive examples, where a fiber reinforced composite with a highly nonlinear Ogden-type behavior of the individual components is considered. ",
    "url": "https://arxiv.org/abs/2207.01045",
    "authors": [
      "Karl A. Kalina",
      "Lennart Linden",
      "J\u00f6rg Brummund",
      "Markus K\u00e4stner"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2207.01056",
    "title": "Counterfactually Measuring and Eliminating Social Bias in  Vision-Language Pre-training Models",
    "abstract": "Vision-Language Pre-training (VLP) models have achieved state-of-the-art performance in numerous cross-modal tasks. Since they are optimized to capture the statistical properties of intra- and inter-modality, there remains risk to learn social biases presented in the data as well. In this work, we (1) introduce a counterfactual-based bias measurement \\emph{CounterBias} to quantify the social bias in VLP models by comparing the [MASK]ed prediction probabilities of factual and counterfactual samples; (2) construct a novel VL-Bias dataset including 24K image-text pairs for measuring gender bias in VLP models, from which we observed that significant gender bias is prevalent in VLP models; and (3) propose a VLP debiasing method \\emph{FairVLP} to minimize the difference in the [MASK]ed prediction probabilities between factual and counterfactual image-text pairs for VLP debiasing. Although CounterBias and FairVLP focus on social bias, they are generalizable to serve as tools and provide new insights to probe and regularize more knowledge in VLP models. ",
    "url": "https://arxiv.org/abs/2207.01056",
    "authors": [
      "Yi Zhang",
      "Junyang Wang",
      "Jitao Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.01060",
    "title": "A 16-Channel Low-Power Neural Connectivity Extraction and Phase-Locked  Deep Brain Stimulation SoC",
    "abstract": "Growing evidence suggests that phase-locked deep brain stimulation (DBS) can effectively regulate abnormal brain connectivity in neurological and psychiatric disorders. This letter therefore presents a low-power SoC with both neural connectivity extraction and phase-locked DBS capabilities. A 16-channel low-noise analog front-end (AFE) records local field potentials (LFPs) from multiple brain regions with precise gain matching. A novel low-complexity phase estimator and neural connectivity processor subsequently enable energy-efficient, yet accurate measurement of the instantaneous phase and cross-regional synchrony measures. Through flexible combination of neural biomarkers such as phase synchrony and spectral energy, a four-channel charge-balanced neurostimulator is triggered to treat various pathological brain conditions. Fabricated in 65nm CMOS, the SoC occupies a silicon area of 2.24mm2 and consumes 60uW, achieving over 60% power saving in neural connectivity extraction compared to the state-of-the-art. Extensive in-vivo measurements demonstrate multi-channel LFP recording, real-time extraction of phase and neural connectivity measures, and phase-locked stimulation in rats. ",
    "url": "https://arxiv.org/abs/2207.01060",
    "authors": [
      "Uisub Shin",
      "Cong Ding",
      "Virginia Woods",
      "Alik S. Widge",
      "Mahsa Shoaran"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.01066",
    "title": "NP-Match: When Neural Processes meet Semi-Supervised Learning",
    "abstract": "Semi-supervised learning (SSL) has been widely explored in recent years, and it is an effective way of leveraging unlabeled data to reduce the reliance on labeled data. In this work, we adjust neural processes (NPs) to the semi-supervised image classification task, resulting in a new method named NP-Match. NP-Match is suited to this task for two reasons. Firstly, NP-Match implicitly compares data points when making predictions, and as a result, the prediction of each unlabeled data point is affected by the labeled data points that are similar to it, which improves the quality of pseudo-labels. Secondly, NP-Match is able to estimate uncertainty that can be used as a tool for selecting unlabeled samples with reliable pseudo-labels. Compared with uncertainty-based SSL methods implemented with Monte Carlo (MC) dropout, NP-Match estimates uncertainty with much less computational overhead, which can save time at both the training and the testing phases. We conducted extensive experiments on four public datasets, and NP-Match outperforms state-of-the-art (SOTA) results or achieves competitive results on them, which shows the effectiveness of NP-Match and its potential for SSL. ",
    "url": "https://arxiv.org/abs/2207.01066",
    "authors": [
      "Jianfeng Wang",
      "Thomas Lukasiewicz",
      "Daniela Massiceti",
      "Xiaolin Hu",
      "Vladimir Pavlovic",
      "Alexandros Neophytou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01072",
    "title": "Sub-cluster-aware Network for Few-shot Skin Disease Classification",
    "abstract": "This paper studies the few-shot skin disease classification problem. Based on a crucial observation that skin disease images often exist multiple sub-clusters within a class (i.e., the appearances of images within one class of disease vary and form multiple distinct sub-groups), we design a novel Sub-Cluster-Aware Network, namely SCAN, for rare skin disease diagnosis with enhanced accuracy. As the performance of few-shot learning highly depends on the quality of the learned feature encoder, the main principle guiding the design of SCAN is the intrinsic sub-clustered representation learning for each class so as to better describe feature distributions. Specifically, SCAN follows a dual-branch framework, where the first branch is to learn class-wise features to distinguish different skin diseases, and the second one aims to learn features which can effectively partition each class into several groups so as to preserve the sub-clustered structure within each class. To achieve the objective of the second branch, we present a cluster loss to learn image similarities via unsupervised clustering. To ensure that the samples in each sub-cluster are from the same class, we further design a purity loss to refine the unsupervised clustering results. We evaluate the proposed approach on two public datasets for few-shot skin disease classification. The experimental results validate that our framework outperforms the other state-of-the-art methods by around 2% to 4% on the SD-198 and Derm7pt datasets. ",
    "url": "https://arxiv.org/abs/2207.01072",
    "authors": [
      "Shuhan LI",
      "Xiaomeng Li",
      "Xiaowei Xu",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01088",
    "title": "FasterAI: A Lightweight Library for Creating Sparse Neural Networks",
    "abstract": "FasterAI is a PyTorch-based library, aiming to facilitate the utilization of deep neural networks compression techniques such as sparsification, pruning, knowledge distillation, or regularization. The library is built with the purpose of enabling quick implementation and experimentation. More particularly, compression techniques are leveraging Callback systems of libraries such as fastai and Pytorch Lightning to bring a user-friendly and high-level API. The main asset of FasterAI is its lightweight, yet powerful, simplicity of use. Indeed, because it was developed in a very granular way, users can create thousands of unique experiments by using different combinations of parameters. In this paper, we focus on the sparsifying capabilities of FasterAI, which represents the core of the library. Performing sparsification of a neural network in FasterAI only requires a single additional line of code in the traditional training loop, yet allows to perform state-of-the-art techniques such as Lottery Ticket Hypothesis experiments ",
    "url": "https://arxiv.org/abs/2207.01088",
    "authors": [
      "Nathan Hubens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.01090",
    "title": "Folding over Neural Networks",
    "abstract": "Neural networks are typically represented as data structures that are traversed either through iteration or by manual chaining of method calls. However, a deeper analysis reveals that structured recursion can be used instead, so that traversal is directed by the structure of the network itself. This paper shows how such an approach can be realised in Haskell, by encoding neural networks as recursive data types, and then their training as recursion scheme patterns. In turn, we promote a coherent implementation of neural networks that delineates between their structure and semantics, allowing for compositionality in both how they are built and how they are trained. ",
    "url": "https://arxiv.org/abs/2207.01090",
    "authors": [
      "Minh Nguyen",
      "Nicolas Wu"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.01091",
    "title": "Representation Heterogeneity",
    "abstract": "Semantic Heterogeneity is conventionally understood as the existence of variance in the representation of a target reality when modelled, by independent parties, in different databases, schemas and/ or data. We argue that the mere encoding of variance, while being necessary, is not sufficient enough to deal with the problem of representational heterogeneity, given that it is also necessary to encode the unifying basis on which such variance is manifested. To that end, this paper introduces a notion of Representation Heterogeneity in terms of the co-occurrent notions of Representation Unity and Representation Diversity. We have representation unity when two heterogeneous representations model the same target reality, representation diversity otherwise. In turn, this paper also highlights how these two notions get instantiated across the two layers of any representation, i.e., Language and Knowledge. ",
    "url": "https://arxiv.org/abs/2207.01091",
    "authors": [
      "Fausto Giunchiglia",
      "Mayukh Bagchi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2207.01105",
    "title": "Scalable Polar Code Construction for Successive Cancellation List  Decoding: A Graph Neural Network-Based Approach",
    "abstract": "While constructing polar codes for successive-cancellation decoding can be implemented efficiently by sorting the bit-channels, finding optimal polar-code constructions for the successive-cancellation list (SCL) decoding in an efficient and scalable manner still awaits investigation. This paper proposes a graph neural network (GNN)-based reinforcement learning algorithm, named the iterative message-passing (IMP) algorithm, to solve the polar-code construction problem for SCL decoding. The algorithm operates only on the local structure of the graph induced by polar-code's generator matrix. The size of the IMP model is independent of the blocklength and the code rate, making it scalable to construct polar codes with long blocklengths. Moreover, a single trained IMP model can be directly applied to a wide range of target blocklengths, code rates, and channel conditions, and corresponding polar codes can be generated without separate training. Numerical experiments show that the IMP algorithm finds polar-code constructions that significantly outperform the classical constructions under cyclic-redundancy-check-aided SCL (CA-SCL) decoding. Compared to other learning-based construction methods tailored to SCL/CA-SCL decoding, the IMP algorithm constructs polar codes with comparable or lower frame error rates, while reducing the training complexity significantly by eliminating the need of separate training at each target blocklength, code rate, and channel condition. ",
    "url": "https://arxiv.org/abs/2207.01105",
    "authors": [
      "Yun Liao",
      "Seyyed Ali Hashemi",
      "Hengjie Yang",
      "John M. Cioffi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.01106",
    "title": "Anomaly Detection with Adversarially Learned Perturbations of Latent  Space",
    "abstract": "Anomaly detection is to identify samples that do not conform to the distribution of the normal data. Due to the unavailability of anomalous data, training a supervised deep neural network is a cumbersome task. As such, unsupervised methods are preferred as a common approach to solve this task. Deep autoencoders have been broadly adopted as a base of many unsupervised anomaly detection methods. However, a notable shortcoming of deep autoencoders is that they provide insufficient representations for anomaly detection by generalizing to reconstruct outliers. In this work, we have designed an adversarial framework consisting of two competing components, an Adversarial Distorter, and an Autoencoder. The Adversarial Distorter is a convolutional encoder that learns to produce effective perturbations and the autoencoder is a deep convolutional neural network that aims to reconstruct the images from the perturbed latent feature space. The networks are trained with opposing goals in which the Adversarial Distorter produces perturbations that are applied to the encoder's latent feature space to maximize the reconstruction error and the autoencoder tries to neutralize the effect of these perturbations to minimize it. When applied to anomaly detection, the proposed method learns semantically richer representations due to applying perturbations to the feature space. The proposed method outperforms the existing state-of-the-art methods in anomaly detection on image and video datasets. ",
    "url": "https://arxiv.org/abs/2207.01106",
    "authors": [
      "Vahid Reza Khazaie",
      "Anthony Wong",
      "John Taylor Jewell",
      "Yalda Mohsenzadeh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.01114",
    "title": "Evaluating Error Bound for Physics-Informed Neural Networks on Linear  Dynamical Systems",
    "abstract": "There have been extensive studies on solving differential equations using physics-informed neural networks. While this method has proven advantageous in many cases, a major criticism lies in its lack of analytical error bounds. Therefore, it is less credible than its traditional counterparts, such as the finite difference method. This paper shows that one can mathematically derive explicit error bounds for physics-informed neural networks trained on a class of linear systems of differential equations. More importantly, evaluating such error bounds only requires evaluating the differential equation residual infinity norm over the domain of interest. Our work shows a link between network residuals, which is known and used as loss function, and the absolute error of solution, which is generally unknown. Our approach is semi-phenomonological and independent of knowledge of the actual solution or the complexity or architecture of the network. Using the method of manufactured solution on linear ODEs and system of linear ODEs, we empirically verify the error evaluation algorithm and demonstrate that the actual error strictly lies within our derived bound. ",
    "url": "https://arxiv.org/abs/2207.01114",
    "authors": [
      "Shuheng Liu",
      "Xiyue Huang",
      "Pavlos Protopapas"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.01127",
    "title": "DecisioNet -- A Binary-Tree Structured Neural Network",
    "abstract": "Deep neural networks (DNNs) and decision trees (DTs) are both state-of-the-art classifiers. DNNs perform well due to their representational learning capabilities, while DTs are computationally efficient as they perform inference along one route (root-to-leaf) that is dependent on the input data. In this paper, we present DecisioNet (DN), a binary-tree structured neural network. We propose a systematic way to convert an existing DNN into a DN to create a lightweight version of the original model. DecisioNet takes the best of both worlds - it uses neural modules to perform representational learning and utilizes its tree structure to perform only a portion of the computations. We evaluate various DN architectures, along with their corresponding baseline models on the FashionMNIST, CIFAR10, and CIFAR100 datasets. We show that the DN variants achieve similar accuracy while significantly reducing the computational cost of the original network. ",
    "url": "https://arxiv.org/abs/2207.01127",
    "authors": [
      "Noam Gottlieb",
      "Michael Werman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.01129",
    "title": "A Gray Code of Ordered Trees",
    "abstract": "A combinatorial Gray code for a set of combinatorial objects is a sequence of all combinatorial objects in the set so that each object is derived from the preceding object by changing a small part. In this paper we design a Gray code for ordered trees with $n$ vertices such that each ordered tree is derived from the preceding ordered tree by removing a leaf then appending a leaf elsewhere. Thus the change is just remove-and-append a leaf, which is the minimum. ",
    "url": "https://arxiv.org/abs/2207.01129",
    "authors": [
      "Shin-ichi Nakano"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2207.01149",
    "title": "RAF: Recursive Adversarial Attacks on Face Recognition Using Extremely  Limited Queries",
    "abstract": "Recent successful adversarial attacks on face recognition show that, despite the remarkable progress of face recognition models, they are still far behind the human intelligence for perception and recognition. It reveals the vulnerability of deep convolutional neural networks (CNNs) as state-of-the-art building block for face recognition models against adversarial examples, which can cause certain consequences for secure systems. Gradient-based adversarial attacks are widely studied before and proved to be successful against face recognition models. However, finding the optimized perturbation per each face needs to submitting the significant number of queries to the target model. In this paper, we propose recursive adversarial attack on face recognition using automatic face warping which needs extremely limited number of queries to fool the target model. Instead of a random face warping procedure, the warping functions are applied on specific detected regions of face like eyebrows, nose, lips, etc. We evaluate the robustness of proposed method in the decision-based black-box attack setting, where the attackers have no access to the model parameters and gradients, but hard-label predictions and confidence scores are provided by the target model. ",
    "url": "https://arxiv.org/abs/2207.01149",
    "authors": [
      "Keshav Kasichainula",
      "Hadi Mansourifar",
      "Weidong Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01156",
    "title": "Removing Batch Normalization Boosts Adversarial Training",
    "abstract": "Adversarial training (AT) defends deep neural networks against adversarial attacks. One challenge that limits its practical application is the performance degradation on clean samples. A major bottleneck identified by previous works is the widely used batch normalization (BN), which struggles to model the different statistics of clean and adversarial training samples in AT. Although the dominant approach is to extend BN to capture this mixture of distribution, we propose to completely eliminate this bottleneck by removing all BN layers in AT. Our normalizer-free robust training (NoFrost) method extends recent advances in normalizer-free networks to AT for its unexplored advantage on handling the mixture distribution challenge. We show that NoFrost achieves adversarial robustness with only a minor sacrifice on clean sample accuracy. On ImageNet with ResNet50, NoFrost achieves $74.06\\%$ clean accuracy, which drops merely $2.00\\%$ from standard training. In contrast, BN-based AT obtains $59.28\\%$ clean accuracy, suffering a significant $16.78\\%$ drop from standard training. In addition, NoFrost achieves a $23.56\\%$ adversarial robustness against PGD attack, which improves the $13.57\\%$ robustness in BN-based AT. We observe better model smoothness and larger decision margins from NoFrost, which make the models less sensitive to input perturbations and thus more robust. Moreover, when incorporating more data augmentations into NoFrost, it achieves comprehensive robustness against multiple distribution shifts. Code and pre-trained models are public at https://github.com/amazon-research/normalizer-free-robust-training. ",
    "url": "https://arxiv.org/abs/2207.01156",
    "authors": [
      "Haotao Wang",
      "Aston Zhang",
      "Shuai Zheng",
      "Xingjian Shi",
      "Mu Li",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01160",
    "title": "Partial and Asymmetric Contrastive Learning for Out-of-Distribution  Detection in Long-Tailed Recognition",
    "abstract": "Existing out-of-distribution (OOD) detection methods are typically benchmarked on training sets with balanced class distributions. However, in real-world applications, it is common for the training sets to have long-tailed distributions. In this work, we first demonstrate that existing OOD detection methods commonly suffer from significant performance degradation when the training set is long-tail distributed. Through analysis, we posit that this is because the models struggle to distinguish the minority tail-class in-distribution samples, from the true OOD samples, making the tail classes more prone to be falsely detected as OOD. To solve this problem, we propose Partial and Asymmetric Supervised Contrastive Learning (PASCL), which explicitly encourages the model to distinguish between tail-class in-distribution samples and OOD samples. To further boost in-distribution classification accuracy, we propose Auxiliary Branch Finetuning, which uses two separate branches of BN and classification layers for anomaly detection and in-distribution classification, respectively. The intuition is that in-distribution and OOD anomaly data have different underlying distributions. Our method outperforms previous state-of-the-art method by $1.29\\%$, $1.45\\%$, $0.69\\%$ anomaly detection false positive rate (FPR) and $3.24\\%$, $4.06\\%$, $7.89\\%$ in-distribution classification accuracy on CIFAR10-LT, CIFAR100-LT, and ImageNet-LT, respectively. Code and pre-trained models are available at https://github.com/amazon-research/long-tailed-ood-detection. ",
    "url": "https://arxiv.org/abs/2207.01160",
    "authors": [
      "Haotao Wang",
      "Aston Zhang",
      "Yi Zhu",
      "Shuai Zheng",
      "Mu Li",
      "Alex Smola",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.01164",
    "title": "Aug-NeRF: Training Stronger Neural Radiance Fields with Triple-Level  Physically-Grounded Augmentations",
    "abstract": "Neural Radiance Field (NeRF) regresses a neural parameterized scene by differentially rendering multi-view images with ground-truth supervision. However, when interpolating novel views, NeRF often yields inconsistent and visually non-smooth geometric results, which we consider as a generalization gap between seen and unseen views. Recent advances in convolutional neural networks have demonstrated the promise of advanced robust data augmentations, either random or learned, in enhancing both in-distribution and out-of-distribution generalization. Inspired by that, we propose Augmented NeRF (Aug-NeRF), which for the first time brings the power of robust data augmentations into regularizing the NeRF training. Particularly, our proposal learns to seamlessly blend worst-case perturbations into three distinct levels of the NeRF pipeline with physical grounds, including (1) the input coordinates, to simulate imprecise camera parameters at image capture; (2) intermediate features, to smoothen the intrinsic feature manifold; and (3) pre-rendering output, to account for the potential degradation factors in the multi-view image supervision. Extensive results demonstrate that Aug-NeRF effectively boosts NeRF performance in both novel view synthesis (up to 1.5dB PSNR gain) and underlying geometry reconstruction. Furthermore, thanks to the implicit smooth prior injected by the triple-level augmentations, Aug-NeRF can even recover scenes from heavily corrupted images, a highly challenging setting untackled before. Our codes are available in https://github.com/VITA-Group/Aug-NeRF. ",
    "url": "https://arxiv.org/abs/2207.01164",
    "authors": [
      "Tianlong Chen",
      "Peihao Wang",
      "Zhiwen Fan",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01168",
    "title": "How Robust is Your Fairness? Evaluating and Sustaining Fairness under  Unseen Distribution Shifts",
    "abstract": "Increasing concerns have been raised on deep learning fairness in recent years. Existing fairness-aware machine learning methods mainly focus on the fairness of in-distribution data. However, in real-world applications, it is common to have distribution shift between the training and test data. In this paper, we first show that the fairness achieved by existing methods can be easily broken by slight distribution shifts. To solve this problem, we propose a novel fairness learning method termed CUrvature MAtching (CUMA), which can achieve robust fairness generalizable to unseen domains with unknown distributional shifts. Specifically, CUMA enforces the model to have similar generalization ability on the majority and minority groups, by matching the loss curvature distributions of the two groups. We evaluate our method on three popular fairness datasets. Compared with existing methods, CUMA achieves superior fairness under unseen distribution shifts, without sacrificing either the overall accuracy or the in-distribution fairness. ",
    "url": "https://arxiv.org/abs/2207.01168",
    "authors": [
      "Haotao Wang",
      "Junyuan Hong",
      "Jiayu Zhou",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.01171",
    "title": "Portuguese Man-of-War Image Classification with Convolutional Neural  Networks",
    "abstract": "Portuguese man-of-war (PMW) is a gelatinous organism with long tentacles capable of causing severe burns, thus leading to negative impacts on human activities, such as tourism and fishing. There is a lack of information about the spatio-temporal dynamics of this species. Therefore, the use of alternative methods for collecting data can contribute to their monitoring. Given the widespread use of social networks and the eye-catching look of PMW, Instagram posts can be a promising data source for monitoring. The first task to follow this approach is to identify posts that refer to PMW. This paper reports on the use of convolutional neural networks for PMW images classification, in order to automate the recognition of Instagram posts. We created a suitable dataset, and trained three different neural networks: VGG-16, ResNet50, and InceptionV3, with and without a pre-trained step with the ImageNet dataset. We analyzed their results using accuracy, precision, recall, and F1 score metrics. The pre-trained ResNet50 network presented the best results, obtaining 94% of accuracy and 95% of precision, recall, and F1 score. These results show that convolutional neural networks can be very effective for recognizing PMW images from the Instagram social media. ",
    "url": "https://arxiv.org/abs/2207.01171",
    "authors": [
      "Alessandra Carneiro",
      "Lorena Nascimento",
      "Mauricio Noernberg",
      "Carmem Hara",
      "Aurora Pozo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.01172",
    "title": "TANet: Transformer-based Asymmetric Network for RGB-D Salient Object  Detection",
    "abstract": "Existing RGB-D SOD methods mainly rely on a symmetric two-stream CNN-based network to extract RGB and depth channel features separately. However, there are two problems with the symmetric conventional network structure: first, the ability of CNN in learning global contexts is limited; second, the symmetric two-stream structure ignores the inherent differences between modalities. In this paper, we propose a Transformer-based asymmetric network (TANet) to tackle the issues mentioned above. We employ the powerful feature extraction capability of Transformer (PVTv2) to extract global semantic information from RGB data and design a lightweight CNN backbone (LWDepthNet) to extract spatial structure information from depth data without pre-training. The asymmetric hybrid encoder (AHE) effectively reduces the number of parameters in the model while increasing speed without sacrificing performance. Then, we design a cross-modal feature fusion module (CMFFM), which enhances and fuses RGB and depth features with each other. Finally, we add edge prediction as an auxiliary task and propose an edge enhancement module (EEM) to generate sharper contours. Extensive experiments demonstrate that our method achieves superior performance over 14 state-of-the-art RGB-D methods on six public datasets. Our code will be released at https://github.com/lc012463/TANet. ",
    "url": "https://arxiv.org/abs/2207.01172",
    "authors": [
      "Chang Liu",
      "Gang Yang",
      "Shuo Wang",
      "Hangxu Wang",
      "Yunhua Zhang",
      "Yutao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01183",
    "title": "Fast Vehicle Detection and Tracking on Fisheye Traffic Monitoring Video  using CNN and Bounding Box Propagation",
    "abstract": "We design a fast car detection and tracking algorithm for traffic monitoring fisheye video mounted on crossroads. We use ICIP 2020 VIP Cup dataset and adopt YOLOv5 as the object detection base model. The nighttime video of this dataset is very challenging, and the detection accuracy (AP50) of the base model is about 54%. We design a reliable car detection and tracking algorithm based on the concept of bounding box propagation among frames, which provides 17.9 percentage points (pp) and 7 pp accuracy improvement over the base model for the nighttime and daytime videos, respectively. To speed up, the grayscale frame difference is used for the intermediate frames in a segment, which can double the processing speed. ",
    "url": "https://arxiv.org/abs/2207.01183",
    "authors": [
      "Sandy Ardianto",
      "Hsueh-Ming Hang",
      "Wen-Huang Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01193",
    "title": "A Customised Text Privatisation Mechanism with Differential Privacy",
    "abstract": "In Natural Language Understanding (NLU) applications, training an effective model often requires a massive amount of data. However, text data in the real world are scattered in different institutions or user devices. Directly sharing them with NLU service provider brings huge privacy risks, as text data often contains sensitive information, leading to potential privacy leakage. A typical way to protect privacy is to directly privatize raw text and leverage Differential Privacy (DP) to quantify the privacy protection level. However, existing text privatization mechanisms that privatize text by applying $d_{\\mathcal{\\chi}}$-privacy are not applicable for all similarity metrics and fail to achieve a good privacy-utility trade-off. This is primarily because (1) $d_{\\mathcal{\\chi}}$-privacy's strict requirements for similarity metrics; (2) they treat each input token equally. Bad utility-privacy trade-off performance impedes the adoption of current text privatization mechanisms in real-world applications. In this paper, we propose a Customised differentially private Text privatization mechanism (CusText) that assigns each input token a customized output set to provide more advanced adaptive privacy protection at the token level. It also overcomes the limitation for the similarity metrics caused by $d_{\\mathcal{\\chi}}$-privacy notion, by turning the mechanism to satisfy $\\epsilon$-DP. Furthermore, we provide two new text privatization strategies to boost the utility of privatized text without compromising privacy and design a new attack strategy for further evaluating the protection level of our mechanism empirically from a new attack's view. We also conduct extensive experiments on two widely used datasets to demonstrate that our proposed mechanism CusText can achieve a better privacy-utility trade-off and practical application value than the existing methods. ",
    "url": "https://arxiv.org/abs/2207.01193",
    "authors": [
      "Huimin Chen",
      "Fengran Mo",
      "Cen Chen",
      "Jamie Cui",
      "Jian-Yun Nie"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.01199",
    "title": "Identifying Rhythmic Patterns for Face Forgery Detection and  Categorization",
    "abstract": "With the emergence of GAN, face forgery technologies have been heavily abused. Achieving accurate face forgery detection is imminent. Inspired by remote photoplethysmography (rPPG) that PPG signal corresponds to the periodic change of skin color caused by heartbeat in face videos, we observe that despite the inevitable loss of PPG signal during the forgery process, there is still a mixture of PPG signals in the forgery video with a unique rhythmic pattern depending on its generation method. Motivated by this key observation, we propose a framework for face forgery detection and categorization consisting of: 1) a Spatial-Temporal Filtering Network (STFNet) for PPG signals filtering, and 2) a Spatial-Temporal Interaction Network (STINet) for constraint and interaction of PPG signals. Moreover, with insight into the generation of forgery methods, we further propose intra-source and inter-source blending to boost the performance of the framework. Overall, extensive experiments have proved the superiority of our method. ",
    "url": "https://arxiv.org/abs/2207.01199",
    "authors": [
      "Jiahao Liang",
      "Weihong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01200",
    "title": "S$^{5}$Mars: Self-Supervised and Semi-Supervised Learning for Mars  Segmentation",
    "abstract": "Deep learning has become a powerful tool for Mars exploration. Mars terrain segmentation is an important Martian vision task, which is the base of rover autonomous planning and safe driving. However, existing deep-learning-based terrain segmentation methods face two problems: one is the lack of sufficient detailed and high-confidence annotations, and the other is the over-reliance of models on annotated training data. In this paper, we address these two problems from the perspective of joint data and method design. We first present a new Mars terrain segmentation dataset which contains 6K high-resolution images and is sparsely annotated based on confidence, ensuring the high quality of labels. Then to learn from this sparse data, we propose a representation-learning-based framework for Mars terrain segmentation, including a self-supervised learning stage (for pre-training) and a semi-supervised learning stage (for fine-tuning). Specifically, for self-supervised learning, we design a multi-task mechanism based on the masked image modeling (MIM) concept to emphasize the texture information of images. For semi-supervised learning, since our dataset is sparsely annotated, we encourage the model to excavate the information of unlabeled area in each image by generating and utilizing pseudo-labels online. We name our dataset and method Self-Supervised and Semi-Supervised Segmentation for Mars (S$^{5}$Mars). Experimental results show that our method can outperform state-of-the-art approaches and improve terrain segmentation performance by a large margin. ",
    "url": "https://arxiv.org/abs/2207.01200",
    "authors": [
      "Jiahang Zhang",
      "Lilang Lin",
      "Zejia Fan",
      "Wenjing Wang",
      "Jiaying Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01203",
    "title": "R^2VOS: Robust Referring Video Object Segmentation via Relational  Multimodal Cycle Consistency",
    "abstract": "Referring video object segmentation (R-VOS) aims to segment the object masks in a video given a referring linguistic expression to the object. It is a recently introduced task attracting growing research attention. However, all existing works make a strong assumption: The object depicted by the expression must exist in the video, namely, the expression and video must have an object-level semantic consensus. This is often violated in real-world applications where an expression can be queried to false videos, and existing methods always fail in such false queries due to abusing the assumption. In this work, we emphasize that studying semantic consensus is necessary to improve the robustness of R-VOS. Accordingly, we pose an extended task from R-VOS without the semantic consensus assumption, named Robust R-VOS ($\\mathrm{R}^2$-VOS). The $\\mathrm{R}^2$-VOS task is essentially related to the joint modeling of the primary R-VOS task and its dual problem (text reconstruction). We embrace the observation that the embedding spaces have relational consistency through the cycle of text-video-text transformation, which connects the primary and dual problems. We leverage the cycle consistency to discriminate the semantic consensus, thus advancing the primary task. Parallel optimization of the primary and dual problems are enabled by introducing an early grounding medium. A new evaluation dataset, $\\mathrm{R}^2$-Youtube-VOS, is collected to measure the robustness of R-VOS models against unpaired videos and expressions. Extensive experiments demonstrate that our method not only identifies negative pairs of unrelated expressions and videos, but also improves the segmentation accuracy for positive pairs with a superior disambiguating ability. Our model achieves the state-of-the-art performance on Ref-DAVIS17, Ref-Youtube-VOS, and the novel $\\mathrm{R}^2$-Youtube-VOS dataset. ",
    "url": "https://arxiv.org/abs/2207.01203",
    "authors": [
      "Xiang Li",
      "Jinglu Wang",
      "Xiaohao Xu",
      "Xiao Li",
      "Yan Lu",
      "Bhiksha Raj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01204",
    "title": "Adversarial Pairwise Reverse Attention for Camera Performance Imbalance  in Person Re-identification: New Dataset and Metrics",
    "abstract": "Existing evaluation metrics for Person Re-Identification (Person ReID) models focus on system-wide performance. However, our studies reveal weaknesses due to the uneven data distributions among cameras and different camera properties that expose the ReID system to exploitation. In this work, we raise the long-ignored ReID problem of camera performance imbalance and collect a real-world privacy-aware dataset from 38 cameras to assist the study of the imbalance issue. We propose new metrics to quantify camera performance imbalance and further propose the Adversarial Pairwise Reverse Attention (APRA) Module to guide the model learning the camera invariant feature with a novel pairwise attention inversion mechanism. ",
    "url": "https://arxiv.org/abs/2207.01204",
    "authors": [
      "Eugene P.W. Ang",
      "Shan Lin",
      "Rahul Ahuja",
      "Nemath Ahmed",
      "Alex C. Kot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01208",
    "title": "Attributed Abnormality Graph Embedding for Clinically Accurate X-Ray  Report Generation",
    "abstract": "Automatic generation of medical reports from X-ray images can assist radiologists to perform the time-consuming and yet important reporting task. Yet, achieving clinically accurate generated reports remains challenging. Modeling the underlying abnormalities using the knowledge graph approach has been found promising in enhancing the clinical accuracy. In this paper, we introduce a novel fined-grained knowledge graph structure called an attributed abnormality graph (ATAG). The ATAG consists of interconnected abnormality nodes and attribute nodes, allowing it to better capture the abnormality details. In contrast to the existing methods where the abnormality graph was constructed manually, we propose a methodology to automatically construct the fine-grained graph structure based on annotations, medical reports in X-ray datasets, and the RadLex radiology lexicon. We then learn the ATAG embedding using a deep model with an encoder-decoder architecture for the report generation. In particular, graph attention networks are explored to encode the relationships among the abnormalities and their attributes. A gating mechanism is adopted and integrated with various decoders for the generation. We carry out extensive experiments based on the benchmark datasets, and show that the proposed ATAG-based deep model outperforms the SOTA methods by a large margin and can improve the clinical accuracy of the generated reports. ",
    "url": "https://arxiv.org/abs/2207.01208",
    "authors": [
      "Sixing Yan",
      "William K. Cheung",
      "Keith Chiu",
      "Terence M. Tong",
      "Charles K. Cheung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.01220",
    "title": "BusiNet -- a Light and Fast Text Detection Network for Business  Documents",
    "abstract": "For digitizing or indexing physical documents, Optical Character Recognition (OCR), the process of extracting textual information from scanned documents, is a vital technology. When a document is visually damaged or contains non-textual elements, existing technologies can yield poor results, as erroneous detection results can greatly affect the quality of OCR. In this paper we present a detection network dubbed BusiNet aimed at OCR of business documents. Business documents often include sensitive information and as such they cannot be uploaded to a cloud service for OCR. BusiNet was designed to be fast and light so it could run locally preventing privacy issues. Furthermore, BusiNet is built to handle scanned document corruption and noise using a specialized synthetic dataset. The model is made robust to unseen noise by employing adversarial training strategies. We perform an evaluation on publicly available datasets demonstrating the usefulness and broad applicability of our model. ",
    "url": "https://arxiv.org/abs/2207.01220",
    "authors": [
      "Oshri Naparstek",
      "Ophir Azulai",
      "Daniel Rotman",
      "Yevgeny Burshtein",
      "Peter Staar",
      "Udi Barzelay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.01223",
    "title": "A Survey on Label-efficient Deep Segmentation: Bridging the Gap between  Weak Supervision and Dense Prediction",
    "abstract": "The rapid development of deep learning has made a great progress in segmentation, one of the fundamental tasks of computer vision. However, the current segmentation algorithms mostly rely on the availability of pixel-level annotations, which are often expensive, tedious, and laborious. To alleviate this burden, the past years have witnessed an increasing attention in building label-efficient, deep-learning-based segmentation algorithms. This paper offers a comprehensive review on label-efficient segmentation methods. To this end, we first develop a taxonomy to organize these methods according to the supervision provided by different types of weak labels (including no supervision, coarse supervision, incomplete supervision and noisy supervision) and supplemented by the types of segmentation problems (including semantic segmentation, instance segmentation and panoptic segmentation). Next, we summarize the existing label-efficient segmentation methods from a unified perspective that discusses an important question: how to bridge the gap between weak supervision and dense prediction -- the current methods are mostly based on heuristic priors, such as cross-pixel similarity, cross-label constraint, cross-view consistency, cross-image relation, etc. Finally, we share our opinions about the future research directions for label-efficient deep segmentation. ",
    "url": "https://arxiv.org/abs/2207.01223",
    "authors": [
      "Wei Shen",
      "Zelin Peng",
      "Xuehui Wang",
      "Huayu Wang",
      "Jiazhong Cen",
      "Dongsheng Jiang",
      "Lingxi Xie",
      "Xiaokang Yang",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01234",
    "title": "Look beyond labels: Incorporating functional summary information in  Bayesian neural networks",
    "abstract": "Bayesian deep learning offers a principled approach to train neural networks that accounts for both aleatoric and epistemic uncertainty. In variational inference, priors are often specified over the weight parameters, but they do not capture the true prior knowledge in large and complex neural network architectures. We present a simple approach to incorporate summary information about the predicted probability (such as sigmoid or softmax score) outputs in Bayesian neural networks (BNNs). The available summary information is incorporated as augmented data and modeled with a Dirichlet process, and we derive the corresponding \\emph{Summary Evidence Lower BOund}. We show how the method can inform the model about task difficulty or class imbalance. Extensive empirical experiments show that, with negligible computational overhead, the proposed method yields a BNN with a better calibration of uncertainty. ",
    "url": "https://arxiv.org/abs/2207.01234",
    "authors": [
      "Vishnu Raj",
      "Tianyu Cui",
      "Markus Heinonen",
      "Pekka Marttinen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.01241",
    "title": "OS-MSL: One Stage Multimodal Sequential Link Framework for Scene  Segmentation and Classification",
    "abstract": "Scene segmentation and classification (SSC) serve as a critical step towards the field of video structuring analysis. Intuitively, jointly learning of these two tasks can promote each other by sharing common information. However, scene segmentation concerns more on the local difference between adjacent shots while classification needs the global representation of scene segments, which probably leads to the model dominated by one of the two tasks in the training phase. In this paper, from an alternate perspective to overcome the above challenges, we unite these two tasks into one task by a new form of predicting shots link: a link connects two adjacent shots, indicating that they belong to the same scene or category. To the end, we propose a general One Stage Multimodal Sequential Link Framework (OS-MSL) to both distinguish and leverage the two-fold semantics by reforming the two learning tasks into a unified one. Furthermore, we tailor a specific module called DiffCorrNet to explicitly extract the information of differences and correlations among shots. Extensive experiments on a brand-new large scale dataset collected from real-world applications, and MovieScenes are conducted. Both the results demonstrate the effectiveness of our proposed method against strong baselines. ",
    "url": "https://arxiv.org/abs/2207.01241",
    "authors": [
      "Ye Liu",
      "Lingfeng Qiao",
      "Di Yin",
      "Zhuoxuan Jiang",
      "Xinghua Jiang",
      "Deqiang Jiang",
      "Bo Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01242",
    "title": "Parametric and Multivariate Uncertainty Calibration for Regression and  Object Detection",
    "abstract": "Reliable spatial uncertainty evaluation of object detection models is of special interest and has been subject of recent work. In this work, we review the existing definitions for uncertainty calibration of probabilistic regression tasks. We inspect the calibration properties of common detection networks and extend state-of-the-art recalibration methods. Our methods use a Gaussian process (GP) recalibration scheme that yields parametric distributions as output (e.g. Gaussian or Cauchy). The usage of GP recalibration allows for a local (conditional) uncertainty calibration by capturing dependencies between neighboring samples. The use of parametric distributions such as as Gaussian allows for a simplified adaption of calibration in subsequent processes, e.g., for Kalman filtering in the scope of object tracking. In addition, we use the GP recalibration scheme to perform covariance estimation which allows for post-hoc introduction of local correlations between the output quantities, e.g., position, width, or height in object detection. To measure the joint calibration of multivariate and possibly correlated data, we introduce the quantile calibration error which is based on the Mahalanobis distance between the predicted distribution and the ground truth to determine whether the ground truth is within a predicted quantile. Our experiments show that common detection models overestimate the spatial uncertainty in comparison to the observed error. We show that the simple Isotonic Regression recalibration method is sufficient to achieve a good uncertainty quantification in terms of calibrated quantiles. In contrast, if normal distributions are required for subsequent processes, our GP-Normal recalibration method yields the best results. Finally, we show that our covariance estimation method is able to achieve best calibration results for joint multivariate calibration. ",
    "url": "https://arxiv.org/abs/2207.01242",
    "authors": [
      "Fabian K\u00fcppers",
      "Jonas Schneider",
      "Anselm Haselhoff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.01255",
    "title": "TMGAN-PLC: Audio Packet Loss Concealment using Temporal Memory  Generative Adversarial Network",
    "abstract": "Real-time communications in packet-switched networks have become widely used in daily communication, while they inevitably suffer from network delays and data losses in constrained real-time conditions. To solve these problems, audio packet loss concealment (PLC) algorithms have been developed to mitigate voice transmission failures by reconstructing the lost information. Limited by the transmission latency and device memory, it is still intractable for PLC to accomplish high-quality voice reconstruction using a relatively small packet buffer. In this paper, we propose a temporal memory generative adversarial network for audio PLC, dubbed TMGAN-PLC, which is comprised of a novel nested-UNet generator and the time-domain/frequency-domain discriminators. Specifically, a combination of the nested-UNet and temporal feature-wise linear modulation is elaborately devised in the generator to finely adjust the intra-frame information and establish inter-frame temporal dependencies. To complement the missing speech content caused by longer loss bursts, we employ multi-stage gated vector quantizers to capture the correct content and reconstruct the near-real smooth audio. Extensive experiments on the PLC Challenge dataset demonstrate that the proposed method yields promising performance in terms of speech quality, intelligibility, and PLCMOS. ",
    "url": "https://arxiv.org/abs/2207.01255",
    "authors": [
      "Yuansheng Guan",
      "Guochen Yu",
      "Andong Li",
      "Chengshi Zheng",
      "Jie Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.01271",
    "title": "FlowNAS: Neural Architecture Search for Optical Flow Estimation",
    "abstract": "Existing optical flow estimators usually employ the network architectures typically designed for image classification as the encoder to extract per-pixel features. However, due to the natural difference between the tasks, the architectures designed for image classification may be sub-optimal for flow estimation. To address this issue, we propose a neural architecture search method named FlowNAS to automatically find the better encoder architecture for flow estimation task. We first design a suitable search space including various convolutional operators and construct a weight-sharing super-network for efficiently evaluating the candidate architectures. Then, for better training the super-network, we propose Feature Alignment Distillation, which utilizes a well-trained flow estimator to guide the training of super-network. Finally, a resource-constrained evolutionary algorithm is exploited to find an optimal architecture (i.e., sub-network). Experimental results show that the discovered architecture with the weights inherited from the super-network achieves 4.67\\% F1-all error on KITTI, an 8.4\\% reduction of RAFT baseline, surpassing state-of-the-art handcrafted models GMA and AGFlow, while reducing the model complexity and latency. The source code and trained models will be released in https://github.com/VDIGPKU/FlowNAS. ",
    "url": "https://arxiv.org/abs/2207.01271",
    "authors": [
      "Zhiwei Lin",
      "Tingting Liang",
      "Taihong Xiao",
      "Yongtao Wang",
      "Zhi Tang",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01289",
    "title": "Game State Learning via Game Scene Augmentation",
    "abstract": "Having access to accurate game state information is of utmost importance for any game artificial intelligence task including game-playing, testing, player modeling, and procedural content generation. Self-Supervised Learning (SSL) techniques have shown to be capable of inferring accurate game state information from the high-dimensional pixel input of game's rendering into compressed latent representations. Contrastive Learning is one such popular paradigm of SSL where the visual understanding of the game's images comes from contrasting dissimilar and similar game states defined by simple image augmentation methods. In this study, we introduce a new game scene augmentation technique -- named GameCLR -- that takes advantage of the game-engine to define and synthesize specific, highly-controlled renderings of different game states, thereby, boosting contrastive learning performance. We test our GameCLR contrastive learning technique on images of the CARLA driving simulator environment and compare it against the popular SimCLR baseline SSL method. Our results suggest that GameCLR can infer the game's state information from game footage more accurately compared to the baseline. The introduced approach allows us to conduct game artificial intelligence research by directly utilizing screen pixels as input. ",
    "url": "https://arxiv.org/abs/2207.01289",
    "authors": [
      "Chintan Trivedi",
      "Konstantinos Makantasis",
      "Antonios Liapis",
      "Georgios N. Yannakakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01301",
    "title": "NodeTrans: A Graph Transfer Learning Approach for Traffic Prediction",
    "abstract": "Recently, deep learning methods have made great progress in traffic prediction, but their performance depends on a large amount of historical data. In reality, we may face the data scarcity issue. In this case, deep learning models fail to obtain satisfactory performance. Transfer learning is a promising approach to solve the data scarcity issue. However, existing transfer learning approaches in traffic prediction are mainly based on regular grid data, which is not suitable for the inherent graph data in the traffic network. Moreover, existing graph-based models can only capture shared traffic patterns in the road network, and how to learn node-specific patterns is also a challenge. In this paper, we propose a novel transfer learning approach to solve the traffic prediction with few data, which can transfer the knowledge learned from a data-rich source domain to a data-scarce target domain. First, a spatial-temporal graph neural network is proposed, which can capture the node-specific spatial-temporal traffic patterns of different road networks. Then, to improve the robustness of transfer, we design a pattern-based transfer strategy, where we leverage a clustering-based mechanism to distill common spatial-temporal patterns in the source domain, and use these knowledge to further improve the prediction performance of the target domain. Experiments on real-world datasets verify the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2207.01301",
    "authors": [
      "Xueyan Yin",
      "Feifan Li",
      "Yanming Shen",
      "Heng Qi",
      "Baocai Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.01336",
    "title": "Spectral Power Profile Optimization of Field-Deployed WDM Network by  Remote Link Modeling",
    "abstract": "A digital twin model of a multi-node WDM network is obtained from a single access point. The model is used to predict and optimize the transmit power profile for each link in the network and up to 2.2~dB of margin improvements are obtained w.r.t. unoptimized transmission. ",
    "url": "https://arxiv.org/abs/2207.01336",
    "authors": [
      "Rasmus T. Jones",
      "Kyle R. H. Bottrill",
      "Natsupa Taengnoi",
      "Periklis Petropoulos",
      "Metodi P. Yankov"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.01342",
    "title": "Explore Faster Localization Learning For Scene Text Detection",
    "abstract": "Generally pre-training and long-time training computation are necessary for obtaining a good-performance text detector based on deep networks. In this paper, we present a new scene text detection network (called FANet) with a Fast convergence speed and Accurate text localization. The proposed FANet is an end-to-end text detector based on transformer feature learning and normalized Fourier descriptor modeling, where the Fourier Descriptor Proposal Network and Iterative Text Decoding Network are designed to efficiently and accurately identify text proposals. Additionally, a Dense Matching Strategy and a well-designed loss function are also proposed for optimizing the network performance. Extensive experiments are carried out to demonstrate that the proposed FANet can achieve the SOTA performance with fewer training epochs and no pre-training. When we introduce additional data for pre-training, the proposed FANet can achieve SOTA performance on MSRATD500, CTW1500 and TotalText. The ablation experiments also verify the effectiveness of our contributions. ",
    "url": "https://arxiv.org/abs/2207.01342",
    "authors": [
      "Yuzhong Zhao",
      "Yuanqiang Cai",
      "Weijia Wu",
      "Weiqiang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01373",
    "title": "Forecasting Busy-Hour Downlink Traffic in Cellular Networks",
    "abstract": "The dramatic growth in cellular traffic volume requires cellular network operators to develop strategies to carefully dimension and manage the available network resources. Forecasting traffic volumes is a fundamental building block for any proactive management strategy and is therefore of great interest in such a context. Differently from what found in the literature, where network traffic is generally predicted in the short-term, in this work we tackle the problem of forecasting busy hour traffic, i.e., the time series of observed daily maxima traffic volumes. We tackle specifically forecasting in the long term (one, two months ahead) and we compare different approaches for the task at hand, considering different forecasting algorithms as well as relying or not on a cluster-based approach which first groups network cells with similar busy hour traffic profiles and then fits per-cluster forecasting models to predict the traffic loads. Results on a real cellular network dataset show that busy hour traffic can be forecasted with errors below 10% for look-ahead periods up to 2 months in the future. Moreover, when clusters are available, we improve forecasting accuracy up to 8% and 5% for look-ahead of 1 and 2 months, respectively. ",
    "url": "https://arxiv.org/abs/2207.01373",
    "authors": [
      "Andrea Pimpinella",
      "Federico Di Giusto",
      "Alessandro Redondi",
      "Luisa Venturini",
      "Andrea Pavon"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.01377",
    "title": "Detection of ADHD based on Eye Movements during Natural Viewing",
    "abstract": "Attention-deficit/hyperactivity disorder (ADHD) is a neurodevelopmental disorder that is highly prevalent and requires clinical specialists to diagnose. It is known that an individual's viewing behavior, reflected in their eye movements, is directly related to attentional mechanisms and higher-order cognitive processes. We therefore explore whether ADHD can be detected based on recorded eye movements together with information about the video stimulus in a free-viewing task. To this end, we develop an end-to-end deep learning-based sequence model %that makes use of eye movement scanpaths which we pre-train on a related task for which more data are available. We find that the method is in fact able to detect ADHD and outperforms relevant baselines. We investigate the relevance of the input features in an ablation study. Interestingly, we find that the model's performance is closely related to the content of the video, which provides insights for future experimental designs. ",
    "url": "https://arxiv.org/abs/2207.01377",
    "authors": [
      "Shuwen Deng",
      "Paul Prasse",
      "David R. Reich",
      "Sabine Dziemian",
      "Maja Stegenwallner-Sch\u00fctz",
      "Daniel Krakowczyk",
      "Silvia Makowski",
      "Nicolas Langer",
      "Tobias Scheffer",
      "Lena A. J\u00e4ger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01382",
    "title": "Lottery Ticket Hypothesis for Spiking Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs) have recently emerged as a new generation of low-power deep neural networks where binary spikes convey information across multiple timesteps. Pruning for SNNs is highly important as they become deployed on a resource-constraint mobile/edge device. The previous SNN pruning works focus on shallow SNNs (2~6 layers), however, deeper SNNs (>16 layers) are proposed by state-of-the-art SNN works, which is difficult to be compatible with the current pruning work. To scale up a pruning technique toward deep SNNs, we investigate Lottery Ticket Hypothesis (LTH) which states that dense networks contain smaller subnetworks (i.e., winning tickets) that achieve comparable performance to the dense networks. Our studies on LTH reveal that the winning tickets consistently exist in deep SNNs across various datasets and architectures, providing up to 97% sparsity without huge performance degradation. However, the iterative searching process of LTH brings a huge training computational cost when combined with the multiple timesteps of SNNs. To alleviate such heavy searching cost, we propose Early-Time (ET) ticket where we find the important weight connectivity from a smaller number of timesteps. The proposed ET ticket can be seamlessly combined with common pruning techniques for finding winning tickets, such as Iterative Magnitude Pruning (IMP) and Early-Bird (EB) tickets. Our experiment results show that the proposed ET ticket reduces search time by up to 38% compared to IMP or EB methods. ",
    "url": "https://arxiv.org/abs/2207.01382",
    "authors": [
      "Youngeun Kim",
      "Yuhang Li",
      "Hyoungseob Park",
      "Yeshwanth Venkatesha",
      "Ruokai Yin",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01388",
    "title": "Learning Disentangled Representations for Controllable Human Motion  Prediction",
    "abstract": "Generative model-based motion prediction techniques have recently realized predicting controlled human motions, such as predicting multiple upper human body motions with similar lower-body motions. However, to achieve this, the state-of-the-art methods require either subsequently learning mapping functions to seek similar motions or training the model repetitively to enable control over the desired portion of body. In this paper, we propose a novel framework to learn disentangled representations for controllable human motion prediction. Our network involves a conditional variational auto-encoder (CVAE) architecture to model full-body human motion, and an extra CVAE path to learn only the corresponding partial-body (e.g., lower-body) motion. Specifically, the inductive bias imposed by the extra CVAE path encourages two latent variables in two paths to respectively govern separate representations for each partial-body motion. With a single training, our model is able to provide two types of controls for the generated human motions: (i) strictly controlling one portion of human body and (ii) adaptively controlling the other portion, by sampling from a pair of latent spaces. Additionally, we extend and adapt a sampling strategy to our trained model to diversify the controllable predictions. Our framework also potentially allows new forms of control by flexibly customizing the input for the extra CVAE path. Extensive experimental results and ablation studies demonstrate that our approach is capable of predicting state-of-the-art controllable human motions both qualitatively and quantitatively. ",
    "url": "https://arxiv.org/abs/2207.01388",
    "authors": [
      "Chunzhi Gu",
      "Jun Yu",
      "Chao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01391",
    "title": "Task-oriented Self-supervised Learning for Anomaly Detection in  Electroencephalography",
    "abstract": "Accurate automated analysis of electroencephalography (EEG) would largely help clinicians effectively monitor and diagnose patients with various brain diseases. Compared to supervised learning with labelled disease EEG data which can train a model to analyze specific diseases but would fail to monitor previously unseen statuses, anomaly detection based on only normal EEGs can detect any potential anomaly in new EEGs. Different from existing anomaly detection strategies which do not consider any property of unavailable abnormal data during model development, a task-oriented self-supervised learning approach is proposed here which makes use of available normal EEGs and expert knowledge about abnormal EEGs to train a more effective feature extractor for the subsequent development of anomaly detector. In addition, a specific two branch convolutional neural network with larger kernels is designed as the feature extractor such that it can more easily extract both larger scale and small-scale features which often appear in unavailable abnormal EEGs. The effectively designed and trained feature extractor has shown to be able to extract better feature representations from EEGs for development of anomaly detector based on normal data and future anomaly detection for new EEGs, as demonstrated on three EEG datasets. The code is available at https://github.com/ironing/EEG-AD. ",
    "url": "https://arxiv.org/abs/2207.01391",
    "authors": [
      "Yaojia Zheng",
      "Zhouwu Liu",
      "Rong Mo",
      "Ziyi Chen",
      "Wei-shi Zheng",
      "Ruixuan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.01394",
    "title": "BiTAT: Neural Network Binarization with Task-dependent Aggregated  Transformation",
    "abstract": "Neural network quantization aims to transform high-precision weights and activations of a given neural network into low-precision weights/activations for reduced memory usage and computation, while preserving the performance of the original model. However, extreme quantization (1-bit weight/1-bit activations) of compactly-designed backbone architectures (e.g., MobileNets) often used for edge-device deployments results in severe performance degeneration. This paper proposes a novel Quantization-Aware Training (QAT) method that can effectively alleviate performance degeneration even with extreme quantization by focusing on the inter-weight dependencies, between the weights within each layer and across consecutive layers. To minimize the quantization impact of each weight on others, we perform an orthonormal transformation of the weights at each layer by training an input-dependent correlation matrix and importance vector, such that each weight is disentangled from the others. Then, we quantize the weights based on their importance to minimize the loss of the information from the original weights/activations. We further perform progressive layer-wise quantization from the bottom layer to the top, so that quantization at each layer reflects the quantized distributions of weights and activations at previous layers. We validate the effectiveness of our method on various benchmark datasets against strong neural quantization baselines, demonstrating that it alleviates the performance degeneration on ImageNet and successfully preserves the full-precision model performance on CIFAR-100 with compact backbone networks. ",
    "url": "https://arxiv.org/abs/2207.01394",
    "authors": [
      "Geon Park",
      "Jaehong Yoon",
      "Haiyang Zhang",
      "Xing Zhang",
      "Sung Ju Hwang",
      "Yonina C. Eldar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.01396",
    "title": "Hessian-Free Second-Order Adversarial Examples for Adversarial Learning",
    "abstract": "Recent studies show deep neural networks (DNNs) are extremely vulnerable to the elaborately designed adversarial examples. Adversarial learning with those adversarial examples has been proved as one of the most effective methods to defend against such an attack. At present, most existing adversarial examples generation methods are based on first-order gradients, which can hardly further improve models' robustness, especially when facing second-order adversarial attacks. Compared with first-order gradients, second-order gradients provide a more accurate approximation of the loss landscape with respect to natural examples. Inspired by this, our work crafts second-order adversarial examples and uses them to train DNNs. Nevertheless, second-order optimization involves time-consuming calculation for Hessian-inverse. We propose an approximation method through transforming the problem into an optimization in the Krylov subspace, which remarkably reduce the computational complexity to speed up the training procedure. Extensive experiments conducted on the MINIST and CIFAR-10 datasets show that our adversarial learning with second-order adversarial examples outperforms other fisrt-order methods, which can improve the model robustness against a wide range of attacks. ",
    "url": "https://arxiv.org/abs/2207.01396",
    "authors": [
      "Yaguan Qian",
      "Yuqi Wang",
      "Bin Wang",
      "Zhaoquan Gu",
      "Yuhan Guo",
      "Wassim Swaileh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01398",
    "title": "Large-scale Robustness Analysis of Video Action Recognition Models",
    "abstract": "We have seen a great progress in video action recognition in recent years. There are several models based on convolutional neural network (CNN) with some recent transformer based approaches which provide state-of-the-art performance on existing benchmark datasets. However, large-scale robustness has not been studied for these models which is a critical aspect for real-world applications. In this work we perform a large-scale robustness analysis of these existing models for video action recognition. We mainly focus on robustness against distribution shifts due to real-world perturbations instead of adversarial perturbations. We propose four different benchmark datasets, HMDB-51P, UCF-101P, Kinetics-400P, and SSv2P and study the robustness of six different state-of-the-art action recognition models against 90 different perturbations. The study reveals some interesting findings, 1) transformer based models are consistently more robust against most of the perturbations when compared with CNN based models, 2) Pretraining helps Transformer based models to be more robust to different perturbations than CNN based models, and 3) All of the studied models are robust to temporal perturbation on the Kinetics dataset, but not on SSv2; this suggests temporal information is much more important for action label prediction on SSv2 datasets than on the Kinetics dataset. We hope that this study will serve as a benchmark for future research in robust video action recognition. More details about the project are available at https://rose-ar.github.io/. ",
    "url": "https://arxiv.org/abs/2207.01398",
    "authors": [
      "Madeline C. Schiappa",
      "Naman Biyani",
      "Shruti Vyas",
      "Hamid Palangi",
      "Vibhav Vineet",
      "Yogesh Rawat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.01407",
    "title": "Vehicle Trajectory Prediction on Highways Using Bird Eye View  Representations and Deep Learning",
    "abstract": "This work presents a novel method for predicting vehicle trajectories in highway scenarios using efficient bird's eye view representations and convolutional neural networks. Vehicle positions, motion histories, road configuration, and vehicle interactions are easily included in the prediction model using basic visual representations. The U-net model has been selected as the prediction kernel to generate future visual representations of the scene using an image-to-image regression approach. A method has been implemented to extract vehicle positions from the generated graphical representations to achieve subpixel resolution. The method has been trained and evaluated using the PREVENTION dataset, an on-board sensor dataset. Different network configurations and scene representations have been evaluated. This study found that U-net with 6 depth levels using a linear terminal layer and a Gaussian representation of the vehicles is the best performing configuration. The use of lane markings was found to produce no improvement in prediction performance. The average prediction error is 0.47 and 0.38 meters and the final prediction error is 0.76 and 0.53 meters for longitudinal and lateral coordinates, respectively, for a predicted trajectory length of 2.0 seconds. The prediction error is up to 50% lower compared to the baseline method. ",
    "url": "https://arxiv.org/abs/2207.01407",
    "authors": [
      "Rub\u00e9n Izquierdo",
      "\u00c1lvaro Quintanar",
      "David Fern\u00e1ndez Llorca",
      "Iv\u00e1n Garc\u00eda Daza",
      "Noelia Hern\u00e1ndez",
      "Ignacio Parra",
      "Miguel \u00c1ngel Sotelo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.01419",
    "title": "A Robust Ensemble Model for Patasitic Egg Detection and Classification",
    "abstract": "Intestinal parasitic infections, as a leading causes of morbidity worldwide, still lacks time-saving, high-sensitivity and user-friendly examination method. The development of deep learning technique reveals its broad application potential in biological image. In this paper, we apply several object detectors such as YOLOv5 and variant cascadeRCNNs to automatically discriminate parasitic eggs in microscope images. Through specially-designed optimization including raw data augmentation, model ensemble, transfer learning and test time augmentation, our model achieves excellent performance on challenge dataset. In addition, our model trained with added noise gains a high robustness against polluted input, which further broaden its applicability in practice. ",
    "url": "https://arxiv.org/abs/2207.01419",
    "authors": [
      "Yuqi Wang",
      "Zhiqiang He",
      "Shenghui Huang",
      "Huabin Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01434",
    "title": "Cybersecurity Entity Alignment via Masked Graph Attention Networks",
    "abstract": "Cybersecurity vulnerability information is often recorded by multiple channels, including government vulnerability repositories, individual-maintained vulnerability-gathering platforms, or vulnerability-disclosure email lists and forums. Integrating vulnerability information from different channels enables comprehensive threat assessment and quick deployment to various security mechanisms. Efforts to automatically gather such information, however, are impeded by the limitations of today's entity alignment techniques. In our study, we annotate the first cybersecurity-domain entity alignment dataset and reveal the unique characteristics of security entities. Based on these observations, we propose the first cybersecurity entity alignment model, CEAM, which equips GNN-based entity alignment with two mechanisms: asymmetric masked aggregation and partitioned attention. Experimental results on cybersecurity-domain entity alignment datasets demonstrate that CEAM significantly outperforms state-of-the-art entity alignment methods. ",
    "url": "https://arxiv.org/abs/2207.01434",
    "authors": [
      "Yue Qin",
      "Xiaojing Liao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.01450",
    "title": "Discourse-Aware Graph Networks for Textual Logical Reasoning",
    "abstract": "Textual logical reasoning, especially question answering (QA) tasks with logical reasoning, requires awareness of particular logical structures. The passage-level logical relations represent entailment or contradiction between propositional units (e.g., a concluding sentence). However, such structures are unexplored as current QA systems focus on entity-based relations. In this work, we propose logic structural-constraint modeling to solve the logical reasoning QA and introduce discourse-aware graph networks (DAGNs). The networks perform two procedures: (1) logic graph construction that leverages in-line discourse connectives as well as generic logic theories, (2) logic representation learning by graph networks that produces structural logic features. This pipeline is applied to a general encoder, whose fundamental features are joined with the high-level logic features for answer prediction. Experiments on three textual logical reasoning datasets demonstrate the reasonability of the logical structures built in DAGNs and the effectiveness of the learned logic features. Moreover, zero-shot transfer results show the features' generality to unseen logical texts. ",
    "url": "https://arxiv.org/abs/2207.01450",
    "authors": [
      "Yinya Huang",
      "Lemao Liu",
      "Kun Xu",
      "Meng Fang",
      "Liang Lin",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.01457",
    "title": "Generalisable Methods for Early Prediction in Interactive Simulations  for Education",
    "abstract": "Interactive simulations allow students to discover the underlying principles of a scientific phenomenon through their own exploration. Unfortunately, students often struggle to learn effectively in these environments. Classifying students' interaction data in the simulations based on their expected performance has the potential to enable adaptive guidance and consequently improve students' learning. Previous research in this field has mainly focused on a-posteriori analyses or investigations limited to one specific predictive model and simulation. In this paper, we investigate the quality and generalisability of models for an early prediction of conceptual understanding based on clickstream data of students across interactive simulations. We first measure the students' conceptual understanding through their in-task performance. Then, we suggest a novel type of features that, starting from clickstream data, encodes both the state of the simulation and the action performed by the student. We finally propose to feed these features into GRU-based models, with and without attention, for prediction. Experiments on two different simulations and with two different populations show that our proposed models outperform shallow learning baselines and better generalise to different learning environments and populations. The inclusion of attention into the model increases interpretability in terms of effective inquiry. The source code is available on Github (https://github.com/epfl-ml4ed/beerslaw-lab.git). ",
    "url": "https://arxiv.org/abs/2207.01457",
    "authors": [
      "Jade Ma\u00ef Cock",
      "Mirko Marras",
      "Christian Giang",
      "Tanja K\u00e4ser"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.01459",
    "title": "Optimal Vertex-Cut Sparsification of Quasi-Bipartite Graphs",
    "abstract": "In vertex-cut sparsification, given a graph $G=(V,E)$ with a terminal set $T\\subseteq V$, we wish to construct a graph $G'=(V',E')$ with $T\\subseteq V'$, such that for every two sets of terminals $A,B\\subseteq T$, the size of a minimum $(A,B)$-vertex-cut in $G'$ is the same as in $G$. In the most basic setting, $G$ is unweighted and undirected, and we wish to bound the size of $G'$ by a function of $k=|T|$. Kratsch and Wahlstr\\\"om [JACM 2020] proved that every graph $G$ (possibly directed), admits a vertex-cut sparsifier $G'$ with $O(k^3)$ vertices, which can in fact be constructed in randomized polynomial time. We study (possibly directed) graphs $G$ that are quasi-bipartite, i.e., every edge has at least one endpoint in $T$, and prove that they admit a vertex-cut sparsifier with $O(k^2)$ edges and vertices, which can in fact be constructed in deterministic polynomial time. In fact, this bound naturally extends to all graphs with a small separator into bounded-size sets. Finally, we prove information-theoretically a nearly-matching lower bound, i.e., that $\\tilde{\\Omega}(k^2)$ edges are required to sparsify quasi-bipartite undirected graphs. ",
    "url": "https://arxiv.org/abs/2207.01459",
    "authors": [
      "Itai Boneh",
      "Robert Krauthgamer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2207.01463",
    "title": "Explicit Boundary Guided Semi-Push-Pull Contrastive Learning for Better  Anomaly Detection",
    "abstract": "Most of anomaly detection algorithms are mainly focused on modeling the distribution of normal samples and treating anomalies as outliers. However, the discriminative performance of the model may be insufficient due to the lack of knowledge about anomalies. Thus, anomalies should be exploited as possible. However, utilizing a few known anomalies during training may cause another issue that model may be biased by those known anomalies and fail to generalize to unseen anomalies. In this paper, we aim to exploit a few existing anomalies with a carefully designed explicit boundary guided semi-push-pull learning strategy, which can enhance discriminability while mitigating bias problem caused by insufficient known anomalies. Our model is based on two core designs: First, finding one explicit separating boundary as the guidance for further contrastive learning. Specifically, we employ normalizing flow to learn normal feature distribution, then find an explicit separating boundary close to the distribution edge. The obtained explicit and compact separating boundary only relies on the normal feature distribution, thus the bias problem caused by a few known anomalies can be mitigated. Second, learning more discriminative features under the guidance of the explicit separating boundary. A boundary guided semi-push-pull loss is developed to only pull the normal features together while pushing the abnormal features apart from the separating boundary beyond a certain margin region. In this way, our model can form a more explicit and discriminative decision boundary to achieve better results for known and also unseen anomalies, while also maintaining high training efficiency. Extensive experiments on the widely-used MVTecAD benchmark show that the proposed method achieves new state-of-the-art results, with the performance of 98.8% image-level AUROC and 99.4% pixel-level AUROC. ",
    "url": "https://arxiv.org/abs/2207.01463",
    "authors": [
      "Xincheng Yao",
      "Chongyang Zhang",
      "Ruoqi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01472",
    "title": "Deep Contrastive One-Class Time Series Anomaly Detection",
    "abstract": "The accumulation of time series data and the absence of labels make time-series Anomaly Detection (AD) a self-supervised deep learning task. Single-assumption-based methods may only touch on a certain aspect of the whole normality, not sufficient to detect various anomalies. Among them, contrastive learning methods adopted for AD always choose negative pairs that are both normal to push away, which is objecting to AD tasks' purpose. Existing multi-assumption-based methods are usually two-staged, firstly applying a pre-training process whose target may differ from AD, so the performance is limited by the pre-trained representations. This paper proposes a deep Contrastive One-Class Anomaly detection method of time series (COCA), which combines the normality assumptions of contrastive learning and one-class classification. The key idea is to treat the representation and reconstructed representation as the positive pair of negative-samples-free contrastive learning, and we name it sequence contrast. Then we apply a contrastive one-class loss function composed of invariance and variance terms, the former optimizing loss of the two assumptions simultaneously, and the latter preventing hypersphere collapse. Extensive experiments conducted on four real-world time-series datasets show the superior performance of the proposed method achieves state-of-the-art. The code is publicly available at https://github.com/ruiking04/COCA. ",
    "url": "https://arxiv.org/abs/2207.01472",
    "authors": [
      "Rui Wang",
      "Chongwei Liu",
      "Xudong Mou",
      "Xiaohui Guo",
      "Kai Gao",
      "Pin Liu",
      "Tianyu Wo",
      "Xudong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.01485",
    "title": "Machine Learning for Deferral of Care Prediction",
    "abstract": "Care deferral is the phenomenon where patients defer or are unable to receive healthcare services, such as seeing doctors, medications or planned surgery. Care deferral can be the result of patient decisions, service availability, service limitations, or restrictions due to cost. Continual care deferral in populations may lead to a decline in population health and compound health issues leading to higher social and financial costs in the long term. Consequently, identification of patients who may be at risk of deferring care is important towards improving population health and reducing care total costs. Additionally, minority and vulnerable populations are at a greater risk of care deferral due to socioeconomic factors. In this paper, we (a) address the problem of predicting care deferral for well-care visits; (b) observe that social determinants of health are relevant explanatory factors towards predicting care deferral, and (c) compute how fair the models are with respect to demographics, socioeconomic factors and selected comorbidities. Many health systems currently use rules-based techniques to retroactively identify patients who previously deferred care. The objective of this model is to identify patients at risk of deferring care and allow the health system to prevent care deferrals through direct outreach or social determinant mediation. ",
    "url": "https://arxiv.org/abs/2207.01485",
    "authors": [
      "Muhammad Aurangzeb Ahmad",
      "Raafia Ahmed",
      "Dr. Steve Overman",
      "Patrick Campbell",
      "Corinne Stroum",
      "Bipin Karunakaran"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.01494",
    "title": "Auxiliary Task Guided Interactive Attention Model for Question  Difficulty Prediction",
    "abstract": "Online learning platforms conduct exams to evaluate the learners in a monotonous way, where the questions in the database may be classified into Bloom's Taxonomy as varying levels in complexity from basic knowledge to advanced evaluation. The questions asked in these exams to all learners are very much static. It becomes important to ask new questions with different difficulty levels to each learner to provide a personalized learning experience. In this paper, we propose a multi-task method with an interactive attention mechanism, Qdiff, for jointly predicting Bloom's Taxonomy and difficulty levels of academic questions. We model the interaction between the predicted bloom taxonomy representations and the input representations using an attention mechanism to aid in difficulty prediction. The proposed learning method would help learn representations that capture the relationship between Bloom's taxonomy and difficulty labels. The proposed multi-task method learns a good input representation by leveraging the relationship between the related tasks and can be used in similar settings where the tasks are related. The results demonstrate that the proposed method performs better than training only on difficulty prediction. However, Bloom's labels may not always be given for some datasets. Hence we soft label another dataset with a model fine-tuned to predict Bloom's labels to demonstrate the applicability of our method to datasets with only difficulty labels. ",
    "url": "https://arxiv.org/abs/2207.01494",
    "authors": [
      "Venktesh V",
      "Md. Shad Akhtar",
      "Mukesh Mohania",
      "Vikram Goyal"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.01508",
    "title": "Understanding misinformation in India: The case for a meaningful  regulatory approach for social media platforms",
    "abstract": "For research, this paper has included numerous literature that are covering a variety of information on the topics of misinformation, social media and fake news, regulation of misinformation and social media platforms, all presented for India. Studies including thematic analysis of misinformation, brief history on social media and its amplification of misinformation, current and past policy interventions by the Indian government, history of self-regulations in industries, and an analysis of regulatory approaches in the Indian context. This paper aims at introducing a coherent reading into the context of misinformation in the country and the subsequent social and business disruptions that will follow. Utilizing lessons from history around industry regulations, existing policy research and framework analysis to convince the reader of the nature of policy intervention that will bode well for all stakeholders involved. The literature sources have been mentioned in their respective sections for reference. The research utilized the PASTEL framework to analyse data collected from other research efforts covering the topic of misinformation and regulation across academic whitepapers and news media blogs and articles, all available freely on the public domain. Relevant secondary data, in terms of information, previous analysis in other research efforts, and literature work included in respective sections in the paper have been reproduced, shared and/or indicated wherever necessary. ",
    "url": "https://arxiv.org/abs/2207.01508",
    "authors": [
      "Gandharv Dhruv Madan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.01523",
    "title": "On Finding Pure Nash Equilibria of Discrete Preference Games and Network  Coordination Games",
    "abstract": "This paper deals with the complexity of the problem of computing a pure Nash equilibrium for discrete preference games and network coordination games beyond $O(\\log n)$-treewidth and tree metric spaces. First, we estimate the number of iterations of the best response dynamics for a discrete preference game on a discrete metric space with at least three strategies. Second, we present a sufficient condition that we have a polynomial-time algorithm to find a pure Nash equilibrium for a discrete preference game on a grid graph. Finally, we discuss the complexity of finding a pure Nash equilibrium for a two-strategic network coordination game whose cost functions satisfy submodularity. In this case, if every cost function is symmetric, the games are polynomial-time reducible to a discrete preference game on a path metric space. ",
    "url": "https://arxiv.org/abs/2207.01523",
    "authors": [
      "Takashi Ishizuka",
      "Naoyuki Kamiyama"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2207.01524",
    "title": "Variational Neural Networks",
    "abstract": "Bayesian Neural Networks (BNNs) provide a tool to estimate the uncertainty of a neural network by considering a distribution over weights and sampling different models for each input. In this paper, we propose a method for uncertainty estimation in neural networks called Variational Neural Network that, instead of considering a distribution over weights, generates parameters for the output distribution of a layer by transforming its inputs with learnable sub-layers. In uncertainty quality estimation experiments, we show that VNNs achieve better uncertainty quality than Monte Carlo Dropout or Bayes By Backpropagation methods. ",
    "url": "https://arxiv.org/abs/2207.01524",
    "authors": [
      "Illia Oleksiienko",
      "Dat Thanh Tran",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.01528",
    "title": "VEM$^2$L: A Plug-and-play Framework for Fusing Text and Structure  Knowledge on Sparse Knowledge Graph Completion",
    "abstract": "Knowledge Graph Completion has been widely studied recently to complete missing elements within triples via mainly modeling graph structural features, but performs sensitive to the sparsity of graph structure. Relevant texts like entity names and descriptions, acting as another expression form for Knowledge Graphs (KGs), are expected to solve this challenge. Several methods have been proposed to utilize both structure and text messages with two encoders, but only achieved limited improvements due to the failure to balance weights between them. And reserving both structural and textual encoders during inference also suffers from heavily overwhelmed parameters. Motivated by Knowledge Distillation, we view knowledge as mappings from input to output probabilities and propose a plug-and-play framework VEM2L over sparse KGs to fuse knowledge extracted from text and structure messages into a unity. Specifically, we partition knowledge acquired by models into two nonoverlapping parts: one part is relevant to the fitting capacity upon training triples, which could be fused by motivating two encoders to learn from each other on training sets; the other reflects the generalization ability upon unobserved queries. And correspondingly, we propose a new fusion strategy proved by Variational EM algorithm to fuse the generalization ability of models, during which we also apply graph densification operations to further alleviate the sparse graph problem. By combining these two fusion methods, we propose VEM2L framework finally. Both detailed theoretical evidence, as well as quantitative and qualitative experiments, demonstrates the effectiveness and efficiency of our proposed framework. ",
    "url": "https://arxiv.org/abs/2207.01528",
    "authors": [
      "Tao He",
      "Tianwen Jiang",
      "Zihao Zheng",
      "Haichao Zhu",
      "Jingrun Zhang",
      "Ming Liu",
      "Sendong Zhao",
      "Bin Qin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.01531",
    "title": "Wild Networks: Exposure of 5G Network Infrastructures to Adversarial  Examples",
    "abstract": "Fifth Generation (5G) networks must support billions of heterogeneous devices while guaranteeing optimal Quality of Service (QoS). Such requirements are impossible to meet with human effort alone, and Machine Learning (ML) represents a core asset in 5G. ML, however, is known to be vulnerable to adversarial examples; moreover, as our paper will show, the 5G context is exposed to a yet another type of adversarial ML attacks that cannot be formalized with existing threat models. Proactive assessment of such risks is also challenging due to the lack of ML-powered 5G equipment available for adversarial ML research. To tackle these problems, we propose a novel adversarial ML threat model that is particularly suited to 5G scenarios, and is agnostic to the precise function solved by ML. In contrast to existing ML threat models, our attacks do not require any compromise of the target 5G system while still being viable due to the QoS guarantees and the open nature of 5G networks. Furthermore, we propose an original framework for realistic ML security assessments based on public data. We proactively evaluate our threat model on 6 applications of ML envisioned in 5G. Our attacks affect both the training and the inference stages, can degrade the performance of state-of-the-art ML systems, and have a lower entry barrier than previous attacks. ",
    "url": "https://arxiv.org/abs/2207.01531",
    "authors": [
      "Giovanni Apruzzese",
      "Rodion Vladimirov",
      "Aliya Tastemirova",
      "Pavel Laskov"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.01537",
    "title": "Non-Blind Strategies in Timed Network Congestion Games",
    "abstract": "Network congestion games are a convenient model for reasoning about routing problems in a network: agents have to move from a source to a target vertex while avoiding congestion, measured as a cost depending on the number of players using the same link. Network congestion games have been extensively studied over the last 40 years, while their extension with timing constraints were considered more recently. Most of the results on network congestion games consider blind strategies: they are static, and do not adapt to the strategies selected by the other players. We extend the recent results of [Bertrand et al., Dynamic network congestion games. FSTTCS'20] to timed network congestion games, in which the availability of the edges depend on (discrete) time. We prove that computing Nash equilibria satisfying some constraint on the total cost (and in particular, computing the best and worst Nash equilibria), and computing the social optimum, can be achieved in exponential space. The social optimum can be computed in polynomial space if all players have the same source and target. ",
    "url": "https://arxiv.org/abs/2207.01537",
    "authors": [
      "Aline Goeminne",
      "Nicolas Markey",
      "Ocan Sankur"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2207.01545",
    "title": "Masked Autoencoders in 3D Point Cloud Representation Learning",
    "abstract": "Transformer-based Self-supervised Representation Learning methods learn generic features from unlabeled datasets for providing useful network initialization parameters for downstream tasks. Recently, self-supervised learning based upon masking local surface patches for 3D point cloud data has been under-explored. In this paper, we propose masked Autoencoders in 3D point cloud representation learning (abbreviated as MAE3D), a novel autoencoding paradigm for self-supervised learning. We first split the input point cloud into patches and mask a portion of them, then use our Patch Embedding Module to extract the features of unmasked patches. Secondly, we employ patch-wise MAE3D Transformers to learn both local features of point cloud patches and high-level contextual relationships between patches and complete the latent representations of masked patches. We use our Point Cloud Reconstruction Module with multi-task loss to complete the incomplete point cloud as a result. We conduct self-supervised pre-training on ShapeNet55 with the point cloud completion pre-text task and fine-tune the pre-trained model on ModelNet40 and ScanObjectNN (PB\\_T50\\_RS, the hardest variant). Comprehensive experiments demonstrate that the local features extracted by our MAE3D from point cloud patches are beneficial for downstream classification tasks, soundly outperforming state-of-the-art methods ($93.4\\%$ and $86.2\\%$ classification accuracy, respectively). ",
    "url": "https://arxiv.org/abs/2207.01545",
    "authors": [
      "Jincen Jiang",
      "Xuequan Lu",
      "Lizhi Zhao",
      "Richard Dazeley",
      "Meili Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01546",
    "title": "Approximation bounds for convolutional neural networks in operator  learning",
    "abstract": "Recently, deep Convolutional Neural Networks (CNNs) have proven to be successful when employed in areas such as reduced order modeling of parametrized PDEs. Despite their accuracy and efficiency, the approaches available in the literature still lack a rigorous justification on their mathematical foundations. Motivated by this fact, in this paper we derive rigorous error bounds for the approximation of nonlinear operators by means of CNN models. More precisely, we address the case in which an operator maps a finite dimensional input $\\boldsymbol{\\mu}\\in\\mathbb{R}^{p}$ onto a functional output $u_{\\boldsymbol{\\mu}}:[0,1]^{d}\\to\\mathbb{R}$, and a neural network model is used to approximate a discretized version of the input-to-output map. The resulting error estimates provide a clear interpretation of the hyperparameters defining the neural network architecture. All the proofs are constructive, and they ultimately reveal a deep connection between CNNs and the discrete Fourier transform. Finally, we complement the derived error bounds by numerical experiments that illustrate their application. ",
    "url": "https://arxiv.org/abs/2207.01546",
    "authors": [
      "Nicola Rares Franco",
      "Stefania Fresca",
      "Andrea Manzoni",
      "Paolo Zunino"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.01548",
    "title": "Counterbalancing Teacher: Regularizing Batch Normalized Models for  Robustness",
    "abstract": "Batch normalization (BN) is a ubiquitous technique for training deep neural networks that accelerates their convergence to reach higher accuracy. However, we demonstrate that BN comes with a fundamental drawback: it incentivizes the model to rely on low-variance features that are highly specific to the training (in-domain) data, hurting generalization performance on out-of-domain examples. In this work, we investigate this phenomenon by first showing that removing BN layers across a wide range of architectures leads to lower out-of-domain and corruption errors at the cost of higher in-domain errors. We then propose Counterbalancing Teacher (CT), a method which leverages a frozen copy of the same model without BN as a teacher to enforce the student network's learning of robust representations by substantially adapting its weights through a consistency loss function. This regularization signal helps CT perform well in unforeseen data shifts, even without information from the target domain as in prior works. We theoretically show in an overparameterized linear regression setting why normalization leads to a model's reliance on such in-domain features, and empirically demonstrate the efficacy of CT by outperforming several baselines on robustness benchmarks such as CIFAR-10-C, CIFAR-100-C, and VLCS. ",
    "url": "https://arxiv.org/abs/2207.01548",
    "authors": [
      "Saeid Asgari Taghanaki",
      "Ali Gholami",
      "Fereshte Khani",
      "Kristy Choi",
      "Linh Tran",
      "Ran Zhang",
      "Aliasghar Khani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01567",
    "title": "Back to MLP: A Simple Baseline for Human Motion Prediction",
    "abstract": "This paper tackles the problem of human motion prediction, consisting in forecasting future body poses from historically observed sequences. Despite of their performance, current state-of-the-art approaches rely on deep learning architectures of arbitrary complexity, such as Recurrent Neural Networks~(RNN), Transformers or Graph Convolutional Networks~(GCN), typically requiring multiple training stages and more than 3 million of parameters. In this paper we show that the performance of these approaches can be surpassed by a light-weight and purely MLP architecture with only 0.14M parameters when appropriately combined with several standard practices such as representing the body pose with Discrete Cosine Transform (DCT), predicting residual displacement of joints and optimizing velocity as an auxiliary loss. An exhaustive evaluation on Human3.6M, AMASS and 3DPW datasets shows that our method, which we dub siMLPe, consistently outperforms all other approaches. We hope that our simple method could serve a strong baseline to the community and allow re-thinking the problem of human motion prediction and whether current benchmarks do really need intricate architectural designs. Our code is available at \\url{https://github.com/dulucas/siMLPe}. ",
    "url": "https://arxiv.org/abs/2207.01567",
    "authors": [
      "Wen Guo",
      "Yuming Du",
      "Xi Shen",
      "Vincent Lepetit",
      "Xavier Alameda-Pineda",
      "Francesc Moreno-Noguer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.01573",
    "title": "Embedding contrastive unsupervised features to cluster in- and  out-of-distribution noise in corrupted image datasets",
    "abstract": "Using search engines for web image retrieval is a tempting alternative to manual curation when creating an image dataset, but their main drawback remains the proportion of incorrect (noisy) samples retrieved. These noisy samples have been evidenced by previous works to be a mixture of in-distribution (ID) samples, assigned to the incorrect category but presenting similar visual semantics to other classes in the dataset, and out-of-distribution (OOD) images, which share no semantic correlation with any category from the dataset. The latter are, in practice, the dominant type of noisy images retrieved. To tackle this noise duality, we propose a two stage algorithm starting with a detection step where we use unsupervised contrastive feature learning to represent images in a feature space. We find that the alignment and uniformity principles of contrastive learning allow OOD samples to be linearly separated from ID samples on the unit hypersphere. We then spectrally embed the unsupervised representations using a fixed neighborhood size and apply an outlier sensitive clustering at the class level to detect the clean and OOD clusters as well as ID noisy outliers. We finally train a noise robust neural network that corrects ID noise to the correct category and utilizes OOD samples in a guided contrastive objective, clustering them to improve low-level features. Our algorithm improves the state-of-the-art results on synthetic noise image datasets as well as real-world web-crawled data. Our work is fully reproducible [github]. ",
    "url": "https://arxiv.org/abs/2207.01573",
    "authors": [
      "Paul Albert",
      "Eric Arazo",
      "Noel E. O'Connor",
      "Kevin McGuinness"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01580",
    "title": "Dynamic Spatial Sparsification for Efficient Vision Transformers and  Convolutional Neural Networks",
    "abstract": "In this paper, we present a new approach for model acceleration by exploiting spatial sparsity in visual data. We observe that the final prediction in vision Transformers is only based on a subset of the most informative tokens, which is sufficient for accurate image recognition. Based on this observation, we propose a dynamic token sparsification framework to prune redundant tokens progressively and dynamically based on the input to accelerate vision Transformers. Specifically, we devise a lightweight prediction module to estimate the importance score of each token given the current features. The module is added to different layers to prune redundant tokens hierarchically. While the framework is inspired by our observation of the sparse attention in vision Transformers, we find the idea of adaptive and asymmetric computation can be a general solution for accelerating various architectures. We extend our method to hierarchical models including CNNs and hierarchical vision Transformers as well as more complex dense prediction tasks that require structured feature maps by formulating a more generic dynamic spatial sparsification framework with progressive sparsification and asymmetric computation for different spatial locations. By applying lightweight fast paths to less informative features and using more expressive slow paths to more important locations, we can maintain the structure of feature maps while significantly reducing the overall computations. Extensive experiments demonstrate the effectiveness of our framework on various modern architectures and different visual recognition tasks. Our results clearly demonstrate that dynamic spatial sparsification offers a new and more effective dimension for model acceleration. Code is available at https://github.com/raoyongming/DynamicViT ",
    "url": "https://arxiv.org/abs/2207.01580",
    "authors": [
      "Yongming Rao",
      "Zuyan Liu",
      "Wenliang Zhao",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.01582",
    "title": "HiPE: Hierarchical Initialization for Pose Graphs",
    "abstract": "Pose graph optimization is a non-convex optimization problem encountered in many areas of robotics perception. Its convergence to an accurate solution is conditioned by two factors: the non-linearity of the cost function in use and the initial configuration of the pose variables. In this paper, we present HiPE, a novel hierarchical algorithm for pose graph initialization. Our approach exploits a coarse-grained graph that encodes an abstract representation of the problem geometry. We construct this graph by combining maximum likelihood estimates coming from local regions of the input. By leveraging the sparsity of this representation, we can initialize the pose graph in a non-linear fashion, without computational overhead compared to existing methods. The resulting initial guess can effectively bootstrap the fine-grained optimization that is used to obtain the final solution. In addition, we perform an empirical analysis on the impact of different cost functions on the final estimate. Our experimental evaluation shows that the usage of HiPE leads to a more efficient and robust optimization process, comparing favorably with state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2207.01582",
    "authors": [
      "Tiziano Guadagnino",
      "Luca Di Giammarino",
      "Giorgio Grisetti"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.01616",
    "title": "Breaking Feedback Loops in Recommender Systems with Causal Inference",
    "abstract": "Recommender systems play a key role in shaping modern web ecosystems. These systems alternate between (1) making recommendations (2) collecting user responses to these recommendations, and (3) retraining the recommendation algorithm based on this feedback. During this process the recommender system influences the user behavioral data that is subsequently used to update it, thus creating a feedback loop. Recent work has shown that feedback loops may compromise recommendation quality and homogenize user behavior, raising ethical and performance concerns when deploying recommender systems. To address these issues, we propose the Causal Adjustment for Feedback Loops (CAFL), an algorithm that provably breaks feedback loops using causal inference and can be applied to any recommendation algorithm that optimizes a training loss. Our main observation is that a recommender system does not suffer from feedback loops if it reasons about causal quantities, namely the intervention distributions of recommendations on user ratings. Moreover, we can calculate this intervention distribution from observational data by adjusting for the recommender system's predictions of user preferences. Using simulated environments, we demonstrate that CAFL improves recommendation quality when compared to prior correction methods. ",
    "url": "https://arxiv.org/abs/2207.01616",
    "authors": [
      "Karl Krauth",
      "Yixin Wang",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.00583",
    "title": "Feature-selected Graph Spatial Attention Network for Addictive  Brain-Networks Identification",
    "abstract": "Functional alterations in the relevant neural circuits occur from drug addiction over a certain period. And these significant alterations are also revealed by analyzing fMRI. However, because of fMRI's high dimensionality and poor signal-to-noise ratio, it is challenging to encode efficient and robust brain regional embeddings for both graph-level identification and region-level biomarkers detection tasks between nicotine addiction (NA) and healthy control (HC) groups. In this work, we represent the fMRI of the rat brain as a graph with biological attributes and propose a novel feature-selected graph spatial attention network(FGSAN) to extract the biomarkers of addiction and identify from these brain networks. Specially, a graph spatial attention encoder is employed to capture the features of spatiotemporal brain networks with spatial information. The method simultaneously adopts a Bayesian feature selection strategy to optimize the model and improve classification task by constraining features. Experiments on an addiction-related neural imaging dataset show that the proposed model can obtain superior performance and detect interpretable biomarkers associated with addiction-relevant neural circuits. ",
    "url": "https://arxiv.org/abs/2207.00583",
    "authors": [
      "Changwei Gong",
      "Changhong Jing",
      "Junren Pan",
      "Shuqiang Wang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.00591",
    "title": "Identification of Binary Neutron Star Mergers in Gravitational-Wave Data  Using YOLO One-Shot Object Detection",
    "abstract": "We demonstrate the application of the YOLOv5 model, a general purpose convolution-based single-shot object detection model, in the task of detecting binary neutron star (BNS) coalescence events from gravitational-wave data of current generation interferometer detectors. We also present a thorough explanation of the synthetic data generation and preparation tasks based on approximant waveform models used for the model training, validation and testing steps. Using this approach, we achieve mean average precision ($\\text{mAP}_{[0.50]}$) values of 0.945 for a single class validation dataset and as high as 0.978 for test datasets. Moreover, the trained model is successful in identifying the GW170817 event in the LIGO H1 detector data. The identification of this event is also possible for the LIGO L1 detector data with an additional pre-processing step, without the need of removing the large glitch in the final stages of the inspiral. The detection of the GW190425 event is less successful, which attests to performance degradation with the signal-to-noise ratio. Our study indicates that the YOLOv5 model is an interesting approach for first-stage detection alarm pipelines and, when integrated in more complex pipelines, for real-time inference of physical source parameters. ",
    "url": "https://arxiv.org/abs/2207.00591",
    "authors": [
      "Jo\u00e3o Aveiro",
      "Felipe F. Freitas",
      "M\u00e1rcio Ferreira",
      "Antonio Onofre",
      "Constan\u00e7a Provid\u00eancia",
      "Gon\u00e7alo Gon\u00e7alves",
      "Jos\u00e9 A. Font"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ]
  },
  {
    "id": "arXiv:2207.00813",
    "title": "Interpretable Graph Neural Networks for Connectome-Based Brain Disorder  Analysis",
    "abstract": "Human brains lie at the core of complex neurobiological systems, where the neurons, circuits, and subsystems interact in enigmatic ways. Understanding the structural and functional mechanisms of the brain has long been an intriguing pursuit for neuroscience research and clinical disorder therapy. Mapping the connections of the human brain as a network is one of the most pervasive paradigms in neuroscience. Graph Neural Networks (GNNs) have recently emerged as a potential method for modeling complex network data. Deep models, on the other hand, have low interpretability, which prevents their usage in decision-critical contexts like healthcare. To bridge this gap, we propose an interpretable framework to analyze disorder-specific Regions of Interest (ROIs) and prominent connections. The proposed framework consists of two modules: a brain-network-oriented backbone model for disease prediction and a globally shared explanation generator that highlights disorder-specific biomarkers including salient ROIs and important connections. We conduct experiments on three real-world datasets of brain disorders. The results verify that our framework can obtain outstanding performance and also identify meaningful biomarkers. All code for this work is available at https://github.com/HennyJie/IBGNN.git. ",
    "url": "https://arxiv.org/abs/2207.00813",
    "authors": [
      "Hejie Cui",
      "Wei Dai",
      "Yanqiao Zhu",
      "Xiaoxiao Li",
      "Lifang He",
      "Carl Yang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00815",
    "title": "Simulating reaction time for Eureka effect in visual object recognition  using artificial neural network",
    "abstract": "The human brain can recognize objects hidden in even severely degraded images after observing them for a while, which is known as a type of Eureka effect, possibly associated with human creativity. A previous psychological study suggests that the basis of this \"Eureka recognition\" is neural processes of coincidence of multiple stochastic activities. Here we constructed an artificial-neural-network-based model that simulated the characteristics of the human Eureka recognition. ",
    "url": "https://arxiv.org/abs/2207.00815",
    "authors": [
      "Kazufumi Hosoda",
      "Shigeto Seno",
      "Tsutomu Murata"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00940",
    "title": "A Graph Isomorphism Network with Weighted Multiple Aggregators for  Speech Emotion Recognition",
    "abstract": "Speech emotion recognition (SER) is an essential part of human-computer interaction. In this paper, we propose an SER network based on a Graph Isomorphism Network with Weighted Multiple Aggregators (WMA-GIN), which can effectively handle the problem of information confusion when neighbour nodes' features are aggregated together in GIN structure. Moreover, a Full-Adjacent (FA) layer is adopted for alleviating the over-squashing problem, which is existed in all Graph Neural Network (GNN) structures, including GIN. Furthermore, a multi-phase attention mechanism and multi-loss training strategy are employed to avoid missing the useful emotional information in the stacked WMA-GIN layers. We evaluated the performance of our proposed WMA-GIN on the popular IEMOCAP dataset. The experimental results show that WMA-GIN outperforms other GNN-based methods and is comparable to some advanced non-graph-based methods by achieving 72.48% of weighted accuracy (WA) and 67.72% of unweighted accuracy (UA). ",
    "url": "https://arxiv.org/abs/2207.00940",
    "authors": [
      "Ying Hu",
      "Yuwu Tang",
      "Hao Huang",
      "Liang He"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2207.00971",
    "title": "Features of a Splashing Drop on a Solid Surface and the Temporal  Evolution extracted through Image-Sequence Classification using an  Interpretable Feedforward Neural Network",
    "abstract": "This paper reports the features of a splashing drop on a solid surface and the temporal evolution, which are extracted through image-sequence classification using a highly interpretable feedforward neural network (FNN) with zero hidden layer. The image sequences used for training-validation and testing of the FNN show the early-stage deformation of milli-sized ethanol drops that impact a hydrophilic glass substrate with the Weber number ranges between 31-474 (splashing threshold about 173). Specific videographing conditions and digital image processing are performed to ensure the high similarity among the image sequences. As a result, the trained FNNs achieved a test accuracy higher than 96%. Remarkably, the feature extraction shows that the trained FNN identifies the temporal evolution of the ejected secondary droplets around the aerodynamically lifted lamella and the relatively high contour of the main body as the features of a splashing drop, while the relatively short and thick lamella as the feature of a nonsplashing drop. The physical interpretation for these features and their respective temporal evolution have been identified except for the difference in contour height of the main body between splashing and nonsplashing drops. The observation reported in this study is important for the development of a data-driven simulation for modeling the deformation of a splashing drop during the impact on a solid surface. ",
    "url": "https://arxiv.org/abs/2207.00971",
    "authors": [
      "Jingzu Yee",
      "Daichi Igarashi",
      "Akinori Yamanaka",
      "Yoshiyuki Tagawa"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.01039",
    "title": "Leveraging Acoustic Contextual Representation by Audio-textual  Cross-modal Learning for Conversational ASR",
    "abstract": "Leveraging context information is an intuitive idea to improve performance on conversational automatic speech recognition(ASR). Previous works usually adopt recognized hypotheses of historical utterances as preceding context, which may bias the current recognized hypothesis due to the inevitable historicalrecognition errors. To avoid this problem, we propose an audio-textual cross-modal representation extractor to learn contextual representations directly from preceding speech. Specifically, it consists of two modal-related encoders, extracting high-level latent features from speech and the corresponding text, and a cross-modal encoder, which aims to learn the correlation between speech and text. We randomly mask some input tokens and input sequences of each modality. Then a token-missing or modal-missing prediction with a modal-level CTC loss on the cross-modal encoder is performed. Thus, the model captures not only the bi-directional context dependencies in a specific modality but also relationships between different modalities. Then, during the training of the conversational ASR system, the extractor will be frozen to extract the textual representation of preceding speech, while such representation is used as context fed to the ASR decoder through attention mechanism. The effectiveness of the proposed approach is validated on several Mandarin conversation corpora and the highest character error rate (CER) reduction up to 16% is achieved on the MagicData dataset. ",
    "url": "https://arxiv.org/abs/2207.01039",
    "authors": [
      "Kun Wei",
      "Yike Zhang",
      "Sining Sun",
      "Lei Xie",
      "Long Ma"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2207.01051",
    "title": "On the minimum number of arcs in $k$-dicritical oriented graphs",
    "abstract": "The dichromatic number $\\dic(D)$ of a digraph $D$ is the least integer $k$ such that $D$ can be partitioned into $k$ directed acyclic digraphs. A digraph is $k$-dicritical if $\\dic(D) = k$ and each proper subgraph $D'$ of $D$ satisfies $\\dic(D') \\leq k-1$. An oriented graph is a digraph with no directed cycle of length $2$. For integers $k$ and $n$, we denote by $o_k(n)$ the minimum number of edges of a $k$-critical oriented graph on $n$ vertices (with the convention $o_k(n)=+\\infty$ if there is no $k$-dicritical oriented graph of order $n$). The main result of this paper is a proof that $o_3(n) \\geq \\frac{7n+2}{3}$ together with a construction witnessing that $o_3(n) \\leq \\left \\lceil \\frac{5n}{2} \\right \\rceil$ for all $n \\geq 12$. We also give a construction showing that for all sufficiently large $n$ and all $k\\geq 3$, $o_k(n) < (2k-3)n$, disproving a conjecture of Hoshino and Kawarabayashi. Finally, we prove that, for all $k\\geq 2$, $o_k(n) \\geq \\pth{ k - \\frac{3}{4}-\\frac{1}{4k-6}} n + \\frac{3}{4(2k-3)}$, improving the previous best known lower bound of Bang-Jensen, Bellitto, Schweser and Stiebitz. ",
    "url": "https://arxiv.org/abs/2207.01051",
    "authors": [
      "Pierre Aboulker",
      "Thomas Bellitto",
      "Fr\u00e9d\u00e9ric Havet",
      "Cl\u00e9ment Rambaud"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2207.01075",
    "title": "Training Patch Analysis and Mining Skills for Image Restoration Deep  Neural Networks",
    "abstract": "There have been numerous image restoration methods based on deep convolutional neural networks (CNNs). However, most of the literature on this topic focused on the network architecture and loss functions, while less detailed on the training methods. Hence, some of the works are not easily reproducible because it is required to know the hidden training skills to obtain the same results. To be specific with the training dataset, few works discussed how to prepare and order the training image patches. Moreover, it requires a high cost to capture new datasets to train a restoration network for the real-world scene. Hence, we believe it is necessary to study the preparation and selection of training data. In this regard, we present an analysis of the training patches and explore the consequences of different patch extraction methods. Eventually, we propose a guideline for the patch extraction from given training images. ",
    "url": "https://arxiv.org/abs/2207.01075",
    "authors": [
      "Jae Woong Soh",
      "Nam Ik Cho"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01110",
    "title": "Learning Noise with Generative Adversarial Networks: Explorations with  Classical Random Process Models",
    "abstract": "Random noise arising from physical processes is an inherent characteristic of measurements and a limiting factor for most signal processing tasks. Given the recent interest in generative adversarial networks (GANs) for data-driven signal modeling, it is important to determine to what extent GANs can faithfully reproduce noise in target data sets. In this paper, we present an empirical investigation that aims to shed light on this issue for time series. Namely, we examine the ability of two general-purpose time-series GANs, a direct time-series model and an image-based model using a short-time Fourier transform (STFT) representation, to learn a broad range of noise types commonly encountered in electronics and communication systems: band-limited thermal noise, power law noise, shot noise, and impulsive noise. We find that GANs are capable of learning many noise types, although they predictably struggle when the GAN architecture is not well suited to some aspects of the noise, e.g., impulsive time-series with extreme outliers. Our findings provide insights into the capabilities and potential limitations of current approaches to time-series GANs and highlight areas for further research. In addition, our battery of tests provides a useful benchmark to aid the development of deep generative models for time series. ",
    "url": "https://arxiv.org/abs/2207.01110",
    "authors": [
      "Adam Wunderlich",
      "Jack Sklar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.01187",
    "title": "ETF Portfolio Construction via Neural Network trained on Financial  Statement Data",
    "abstract": "Recently, the application of advanced machine learning methods for asset management has become one of the most intriguing topics. Unfortunately, the application of these methods, such as deep neural networks, is difficult due to the data shortage problem. To address this issue, we propose a novel approach using neural networks to construct a portfolio of exchange traded funds (ETFs) based on the financial statement data of their components. Although a number of ETFs and ETF-managed portfolios have emerged in the past few decades, the ability to apply neural networks to manage ETF portfolios is limited since the number and historical existence of ETFs are relatively smaller and shorter, respectively, than those of individual stocks. Therefore, we use the data of individual stocks to train our neural networks to predict the future performance of individual stocks and use these predictions and the portfolio deposit file (PDF) to construct a portfolio of ETFs. Multiple experiments have been performed, and we have found that our proposed method outperforms the baselines. We believe that our approach can be more beneficial when managing recently listed ETFs, such as thematic ETFs, of which there is relatively limited historical data for training advanced machine learning methods. ",
    "url": "https://arxiv.org/abs/2207.01187",
    "authors": [
      "Jinho Lee",
      "Sungwoo Park",
      "Jungyu Ahn",
      "Jonghun Kwak"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.01210",
    "title": "Reusing the H.264/AVC deblocking filter for efficient spatio-temporal  prediction in video coding",
    "abstract": "The prediction step is a very important part of hybrid video codecs for effectively compressing video sequences. While existing video codecs predict either in temporal or in spatial direction only, the compression efficiency can be increased by a combined spatio-temporal prediction. In this paper we propose an algorithm for reusing the H.264/AVC deblocking filter for spatio-temporal prediction. Reusing this highly op timized filter allows for a very low computational complexity of this prediction mode and an average rate reduction of up to 7.2% can be achieved. ",
    "url": "https://arxiv.org/abs/2207.01210",
    "authors": [
      "J\u00fcrgen Seiler",
      "Andr\u00e9 Kaup"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.01219",
    "title": "Masked Self-Supervision for Remaining Useful Lifetime Prediction in  Machine Tools",
    "abstract": "Prediction of Remaining Useful Lifetime(RUL) in the modern manufacturing and automation workplace for machines and tools is essential in Industry 4.0. This is clearly evident as continuous tool wear, or worse, sudden machine breakdown will lead to various manufacturing failures which would clearly cause economic loss. With the availability of deep learning approaches, the great potential and prospect of utilizing these for RUL prediction have resulted in several models which are designed driven by operation data of manufacturing machines. Current efforts in these which are based on fully-supervised models heavily rely on the data labeled with their RULs. However, the required RUL prediction data (i.e. the annotated and labeled data from faulty and/or degraded machines) can only be obtained after the machine breakdown occurs. The scarcity of broken machines in the modern manufacturing and automation workplace in real-world situations increases the difficulty of getting sufficient annotated and labeled data. In contrast, the data from healthy machines is much easier to be collected. Noting this challenge and the potential for improved effectiveness and applicability, we thus propose (and also fully develop) a method based on the idea of masked autoencoders which will utilize unlabeled data to do self-supervision. In thus the work here, a noteworthy masked self-supervised learning approach is developed and utilized. This is designed to seek to build a deep learning model for RUL prediction by utilizing unlabeled data. The experiments to verify the effectiveness of this development are implemented on the C-MAPSS datasets (which are collected from the data from the NASA turbofan engine). The results rather clearly show that our development and approach here perform better, in both accuracy and effectiveness, for RUL prediction when compared with approaches utilizing a fully-supervised model. ",
    "url": "https://arxiv.org/abs/2207.01219",
    "authors": [
      "Haoren Guo",
      "Haiyue Zhu",
      "Jiahui Wang",
      "Vadakkepat Prahlad",
      "Weng Khuen Ho",
      "Tong Heng Lee"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.01287",
    "title": "FFCNet: Fourier Transform-Based Frequency Learning and Complex  Convolutional Network for Colon Disease Classification",
    "abstract": "Reliable automatic classification of colonoscopy images is of great significance in assessing the stage of colonic lesions and formulating appropriate treatment plans. However, it is challenging due to uneven brightness, location variability, inter-class similarity, and intra-class dissimilarity, affecting the classification accuracy. To address the above issues, we propose a Fourier-based Frequency Complex Network (FFCNet) for colon disease classification in this study. Specifically, FFCNet is a novel complex network that enables the combination of complex convolutional networks with frequency learning to overcome the loss of phase information caused by real convolution operations. Also, our Fourier transform transfers the average brightness of an image to a point in the spectrum (the DC component), alleviating the effects of uneven brightness by decoupling image content and brightness. Moreover, the image patch scrambling module in FFCNet generates random local spectral blocks, empowering the network to learn long-range and local diseasespecific features and improving the discriminative ability of hard samples. We evaluated the proposed FFCNet on an in-house dataset with 2568 colonoscopy images, showing our method achieves high performance outperforming previous state-of-the art methods with an accuracy of 86:35% and an accuracy of 4.46% higher than the backbone. The project page with code is available at https://github.com/soleilssss/FFCNet. ",
    "url": "https://arxiv.org/abs/2207.01287",
    "authors": [
      "Kai-Ni Wang",
      "Yuting He",
      "Shuaishuai Zhuang",
      "Juzheng Miao",
      "Xiaopu He",
      "Ping Zhou",
      "Guanyu Yang",
      "Guang-Quan Zhou",
      "Shuo Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01302",
    "title": "Assessing the Performance of Automated Prediction and Ranking of Patient  Age from Chest X-rays Against Clinicians",
    "abstract": "Understanding the internal physiological changes accompanying the aging process is an important aspect of medical image interpretation, with the expected changes acting as a baseline when reporting abnormal findings. Deep learning has recently been demonstrated to allow the accurate estimation of patient age from chest X-rays, and shows potential as a health indicator and mortality predictor. In this paper we present a novel comparative study of the relative performance of radiologists versus state-of-the-art deep learning models on two tasks: (a) patient age estimation from a single chest X-ray, and (b) ranking of two time-separated images of the same patient by age. We train our models with a heterogeneous database of 1.8M chest X-rays with ground truth patient ages and investigate the limitations on model accuracy imposed by limited training data and image resolution, and demonstrate generalisation performance on public data. To explore the large performance gap between the models and humans on these age-prediction tasks compared with other radiological reporting tasks seen in the literature, we incorporate our age prediction model into a conditional Generative Adversarial Network (cGAN) allowing visualisation of the semantic features identified by the prediction model as significant to age prediction, comparing the identified features with those relied on by clinicians. ",
    "url": "https://arxiv.org/abs/2207.01302",
    "authors": [
      "Matthew MacPherson",
      "Keerthini Muthuswamy",
      "Ashik Amlani",
      "Charles Hutchinson",
      "Vicky Goh",
      "Giovanni Montana"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.01352",
    "title": "Terrorist attacks sharpen the binary perception of \"Us\" vs. \"Them\"",
    "abstract": "Terrorist attacks not only harm citizens but also shift their attention, which has long-lasting impacts on public opinion and government policies. Yet measuring the changes in public attention beyond media coverage has been methodologically challenging. Here we approach this problem by starting from Wikipedia's r\\'epertoire of 5.8 million articles and a sample of 15 recent terrorist attacks. We deploy a complex exclusion procedure to identify topics and themes that consistently received a significant increase in attention due to these incidents. Examining their contents reveals a clear picture: terrorist attacks foster establishing a sharp boundary between \"Us\" (the target society) and \"Them\" (the terrorist as the enemy). In the midst of this, one seeks to construct identities of both sides. This triggers curiosity to learn more about \"Them\" and soul-search for a clearer understanding of \"Us\". This systematic analysis of public reactions to disruptive events could help mitigate their societal consequences. ",
    "url": "https://arxiv.org/abs/2207.01352",
    "authors": [
      "Milan Jovi\u0107",
      "Lovro \u0160ubelj",
      "Tea Golob",
      "Matej Makarovi\u010d",
      "Taha Yasseri",
      "Danijela Boberi\u0107 Krsti\u0107ev",
      "Srdjan \u0160krbi\u0107",
      "Zoran Levnaji\u0107"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2207.01374",
    "title": "Probabilistic forecasting for geosteering in fluvial successions using a  generative adversarial network",
    "abstract": "Quantitative workflows utilizing real-time data to constrain ahead-of-bit uncertainty have the potential to improve geosteering significantly. Fast updates based on real-time data are essential when drilling in complex reservoirs with high uncertainties in pre-drill models. However, practical assimilation of real-time data requires effective geological modeling and mathematically robust parameterization. We propose a generative adversarial deep neural network (GAN), trained to reproduce geologically consistent 2D sections of fluvial successions. Offline training produces a fast GAN-based approximation of complex geology parameterized as a 60-dimensional model vector with standard Gaussian distribution of each component. Probabilistic forecasts are generated using an ensemble of equiprobable model vector realizations. A forward-modeling sequence, including a GAN, converts the initial (prior) ensemble of realizations into EM log predictions. An ensemble smoother minimizes statistical misfits between predictions and real-time data, yielding an update of model vectors and reduced uncertainty around the well. Updates can be then translated to probabilistic predictions of facies and resistivities. The present paper demonstrates a workflow for geosteering in an outcrop-based, synthetic fluvial succession. In our example, the method reduces uncertainty and correctly predicts most major geological features up to 500 meters ahead of drill-bit. ",
    "url": "https://arxiv.org/abs/2207.01374",
    "authors": [
      "Sergey Alyaev",
      "Jan Tveranger",
      "Kristian Fossum",
      "Ahmed H. Elsheikh"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.01397",
    "title": "First-order mean-field games on networks and Wardrop equilibrium",
    "abstract": "Here, we examine the Wardrop equilibrium model on networks with flow-dependent costs and its connection with stationary mean-field games (MFG). In the first part of this paper, we present the Wardrop and the first-order MFG models on networks. Then, we show how to reformulate the MFG problem into a Wardrop problem and prove that the MFG solution is the Wardrop equilibrium for the corresponding Wardrop problem. Moreover, we prove that the solution of the MFG problem can be recovered using the solution to the associated Wardrop problem. Finally, we study the cost properties and the calibration of MFG with Wardrop travel cost problems. We describe a novel approach to the calibration of MFGs. Further, we show that even simple travel costs can give rise to non-monotone MFGs. ",
    "url": "https://arxiv.org/abs/2207.01397",
    "authors": [
      "Fatimah Al Saleh",
      "Tigran Bakaryan",
      "Diogo A. Gomes",
      "Ricardo Ribeiro"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.01437",
    "title": "Representation Learning with Information Theory for COVID-19 Detection",
    "abstract": "Successful data representation is a fundamental factor in machine learning based medical imaging analysis. Deep Learning (DL) has taken an essential role in robust representation learning. However, the inability of deep models to generalize to unseen data can quickly overfit intricate patterns. Thereby, we can conveniently implement strategies to aid deep models in discovering useful priors from data to learn their intrinsic properties. Our model, which we call a dual role network (DRN), uses a dependency maximization approach based on Least Squared Mutual Information (LSMI). The LSMI leverages dependency measures to ensure representation invariance and local smoothness. While prior works have used information theory measures like mutual information, known to be computationally expensive due to a density estimation step, our LSMI formulation alleviates the issues of intractable mutual information estimation and can be used to approximate it. Experiments on CT based COVID-19 Detection and COVID-19 Severity Detection benchmarks demonstrate the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2207.01437",
    "authors": [
      "Abel D\u00edaz Berenguer",
      "Tanmoy Mukherjee",
      "Matias Bossa",
      "Nikos Deligiannis",
      "Hichem Sahli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01520",
    "title": "Adaptive GLCM sampling for transformer-based COVID-19 detection on CT",
    "abstract": "The world has suffered from COVID-19 (SARS-CoV-2) for the last two years, causing much damage and change in people's daily lives. Thus, automated detection of COVID-19 utilizing deep learning on chest computed tomography (CT) scans became promising, which helps correct diagnosis efficiently. Recently, transformer-based COVID-19 detection method on CT is proposed to utilize 3D information in CT volume. However, its sampling method for selecting slices is not optimal. To leverage rich 3D information in CT volume, we propose a transformer-based COVID-19 detection using a novel data curation and adaptive sampling method using gray level co-occurrence matrices (GLCM). To train the model which consists of CNN layer, followed by transformer architecture, we first executed data curation based on lung segmentation and utilized the entropy of GLCM value of every slice in CT volumes to select important slices for the prediction. The experimental results show that the proposed method improve the detection performance with large margin without much difficult modification to the model. ",
    "url": "https://arxiv.org/abs/2207.01520",
    "authors": [
      "Okchul Jung",
      "Dong Un Kang",
      "Gwanghyun Kim",
      "Se Young Chun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01538",
    "title": "Consistency of Neural Networks with Regularization",
    "abstract": "Neural networks have attracted a lot of attention due to its success in applications such as natural language processing and computer vision. For large scale data, due to the tremendous number of parameters in neural networks, overfitting is an issue in training neural networks. To avoid overfitting, one common approach is to penalize the parameters especially the weights in neural networks. Although neural networks has demonstrated its advantages in many applications, the theoretical foundation of penalized neural networks has not been well-established. Our goal of this paper is to propose the general framework of neural networks with regularization and prove its consistency. Under certain conditions, the estimated neural network will converge to true underlying function as the sample size increases. The method of sieves and the theory on minimal neural networks are used to overcome the issue of unidentifiability for the parameters. Two types of activation functions: hyperbolic tangent function(Tanh) and rectified linear unit(ReLU) have been taken into consideration. Simulations have been conducted to verify the validation of theorem of consistency. ",
    "url": "https://arxiv.org/abs/2207.01538",
    "authors": [
      "Xiaoxi Shen",
      "Jinghang Lin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2207.01547",
    "title": "Unify and Conquer: How Phonetic Feature Representation Affects Polyglot  Text-To-Speech (TTS)",
    "abstract": "An essential design decision for multilingual Neural Text-To-Speech (NTTS) systems is how to represent input linguistic features within the model. Looking at the wide variety of approaches in the literature, two main paradigms emerge, unified and separate representations. The former uses a shared set of phonetic tokens across languages, whereas the latter uses unique phonetic tokens for each language. In this paper, we conduct a comprehensive study comparing multilingual NTTS systems models trained with both representations. Our results reveal that the unified approach consistently achieves better cross-lingual synthesis with respect to both naturalness and accent. Separate representations tend to have an order of magnitude more tokens than unified ones, which may affect model capacity. For this reason, we carry out an ablation study to understand the interaction of the representation type with the size of the token embedding. We find that the difference between the two paradigms only emerges above a certain threshold embedding size. This study provides strong evidence that unified representations should be the preferred paradigm when building multilingual NTTS systems. ",
    "url": "https://arxiv.org/abs/2207.01547",
    "authors": [
      "Ariadna Sanchez",
      "Alessio Falai",
      "Ziyao Zhang",
      "Orazio Angelini",
      "Kayoko Yanagisawa"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.01578",
    "title": "Quantum Neural Network Compression",
    "abstract": "Model compression, such as pruning and quantization, has been widely applied to optimize neural networks on resource-limited classical devices. Recently, there are growing interest in variational quantum circuits (VQC), that is, a type of neural network on quantum computers (a.k.a., quantum neural networks). It is well known that the near-term quantum devices have high noise and limited resources (i.e., quantum bits, qubits); yet, how to compress quantum neural networks has not been thoroughly studied. One might think it is straightforward to apply the classical compression techniques to quantum scenarios. However, this paper reveals that there exist differences between the compression of quantum and classical neural networks. Based on our observations, we claim that the compilation/traspilation has to be involved in the compression process. On top of this, we propose the very first systematical framework, namely CompVQC, to compress quantum neural networks (QNNs).In CompVQC, the key component is a novel compression algorithm, which is based on the alternating direction method of multipliers (ADMM) approach. Experiments demonstrate the advantage of the CompVQC, reducing the circuit depth (almost over 2.5 %) with a negligible accuracy drop (<1%), which outperforms other competitors. Another promising truth is our CompVQC can indeed promote the robustness of the QNN on the near-term noisy quantum devices. ",
    "url": "https://arxiv.org/abs/2207.01578",
    "authors": [
      "Zhirui Hu",
      "Peiyan Dong",
      "Zhepeng Wang",
      "Youzuo Lin",
      "Yanzhi Wang",
      "Weiwen Jiang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.01584",
    "title": "Classification of Alzheimer's Disease Using the Convolutional Neural  Network (CNN) with Transfer Learning and Weighted Loss",
    "abstract": "Alzheimer's disease is a progressive neurodegenerative disorder that gradually deprives the patient of cognitive function and can end in death. With the advancement of technology today, it is possible to detect Alzheimer's disease through Magnetic Resonance Imaging (MRI) scans. So that MRI is the technique most often used for the diagnosis and analysis of the progress of Alzheimer's disease. With this technology, image recognition in the early diagnosis of Alzheimer's disease can be achieved automatically using machine learning. Although machine learning has many advantages, currently the use of deep learning is more widely applied because it has stronger learning capabilities and is more suitable for solving image recognition problems. However, there are still several challenges that must be faced to implement deep learning, such as the need for large datasets, requiring large computing resources, and requiring careful parameter setting to prevent overfitting or underfitting. In responding to the challenge of classifying Alzheimer's disease using deep learning, this study propose the Convolutional Neural Network (CNN) method with the Residual Network 18 Layer (ResNet-18) architecture. To overcome the need for a large and balanced dataset, transfer learning from ImageNet is used and weighting the loss function values so that each class has the same weight. And also in this study conducted an experiment by changing the network activation function to a mish activation function to increase accuracy. From the results of the tests that have been carried out, the accuracy of the model is 88.3 % using transfer learning, weighted loss and the mish activation function. This accuracy value increases from the baseline model which only gets an accuracy of 69.1 %. ",
    "url": "https://arxiv.org/abs/2207.01584",
    "authors": [
      "Muhammad Wildan Oktavian",
      "Novanto Yudistira",
      "Achmad Ridok"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01586",
    "title": "E2Efold-3D: End-to-End Deep Learning Method for accurate de novo RNA 3D  Structure Prediction",
    "abstract": "RNA structure determination and prediction can promote RNA-targeted drug development and engineerable synthetic elements design. But due to the intrinsic structural flexibility of RNAs, all the three mainstream structure determination methods (X-ray crystallography, NMR, and Cryo-EM) encounter challenges when resolving the RNA structures, which leads to the scarcity of the resolved RNA structures. Computational prediction approaches emerge as complementary to the experimental techniques. However, none of the \\textit{de novo} approaches is based on deep learning since too few structures are available. Instead, most of them apply the time-consuming sampling-based strategies, and their performance seems to hit the plateau. In this work, we develop the first end-to-end deep learning approach, E2Efold-3D, to accurately perform the \\textit{de novo} RNA structure prediction. Several novel components are proposed to overcome the data scarcity, such as a fully-differentiable end-to-end pipeline, secondary structure-assisted self-distillation, and parameter-efficient backbone formulation. Such designs are validated on the independent, non-overlapping RNA puzzle testing dataset and reach an average sub-4 \\AA{} root-mean-square deviation, demonstrating its superior performance compared to state-of-the-art approaches. Interestingly, it also achieves promising results when predicting RNA complex structures, a feat that none of the previous systems could accomplish. When E2Efold-3D is coupled with the experimental techniques, the RNA structure prediction field can be greatly advanced. ",
    "url": "https://arxiv.org/abs/2207.01586",
    "authors": [
      "Tao Shen",
      "Zhihang Hu",
      "Zhangzhi Peng",
      "Jiayang Chen",
      "Peng Xiong",
      "Liang Hong",
      "Liangzhen Zheng",
      "Yixuan Wang",
      "Irwin King",
      "Sheng Wang",
      "Siqi Sun",
      "Yu Li"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:1902.02804",
    "title": "SiamVGG: Visual Tracking using Deeper Siamese Networks",
    "abstract": " Title: SiamVGG: Visual Tracking using Deeper Siamese Networks ",
    "url": "https://arxiv.org/abs/1902.02804",
    "authors": [
      "Yuhong Li",
      "Xiaofan Zhang",
      "Deming Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2003.06068",
    "title": "Snapshot Samplings of the Bitcoin Transaction Network and Analysis of  Cryptocurrency Growth",
    "abstract": " Comments: 8 pages, 8 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2003.06068",
    "authors": [
      "Lambert T. Leong"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2009.13008",
    "title": "NAS-Navigator: Visual Steering for Explainable One-Shot Deep Neural  Network Synthesis",
    "abstract": " Comments: 9 pages, submitted to IEEE Transactions on Visualization and Computer Graphics, 2022 ",
    "url": "https://arxiv.org/abs/2009.13008",
    "authors": [
      "Anjul Tyagi",
      "Cong Xie",
      "Klaus Mueller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2010.04855",
    "title": "Kernel Methods for Causal Functions: Dose Response Curves and  Heterogeneous Treatment Effects",
    "abstract": " Comments: Formerly \"Kernel Methods for Policy Evaluation: Treatment Effects, Mediation Analysis, and Off-Policy Planning\" (2020) ",
    "url": "https://arxiv.org/abs/2010.04855",
    "authors": [
      "Rahul Singh",
      "Liyuan Xu",
      "Arthur Gretton"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2010.12249",
    "title": "Multi Scale Identity-Preserving Image-to-Image Translation Network for  Low-Resolution Face Recognition",
    "abstract": " Comments: Accepted in the 35th Canadian Conference on Artificial Intelligence ",
    "url": "https://arxiv.org/abs/2010.12249",
    "authors": [
      "Vahid Reza Khazaie",
      "Nicky Bayat",
      "Yalda Mohsenzadeh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2012.15445",
    "title": "Explainability in Graph Neural Networks: A Taxonomic Survey",
    "abstract": " Title: Explainability in Graph Neural Networks: A Taxonomic Survey ",
    "url": "https://arxiv.org/abs/2012.15445",
    "authors": [
      "Hao Yuan",
      "Haiyang Yu",
      "Shurui Gui",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2103.05213",
    "title": "Enhancing Medical Image Registration via Appearance Adjustment Networks",
    "abstract": " Comments: Published at NeuroImage ",
    "url": "https://arxiv.org/abs/2103.05213",
    "authors": [
      "Mingyuan Meng",
      "Lei Bi",
      "Michael Fulham",
      "David Dagan Feng",
      "Jinman Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2103.05220",
    "title": "Prediction of 5-year Progression-Free Survival in Advanced  Nasopharyngeal Carcinoma with Pretreatment PET/CT using Multi-Modality Deep  Learning-based Radiomics",
    "abstract": " Comments: Accepted at Frontiers in Oncology ",
    "url": "https://arxiv.org/abs/2103.05220",
    "authors": [
      "Bingxin Gu",
      "Mingyuan Meng",
      "Lei Bi",
      "Jinman Kim",
      "David Dagan Feng",
      "Shaoli Song"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2104.04794",
    "title": "Robust Egocentric Photo-realistic Facial Expression Transfer for Virtual  Reality",
    "abstract": " Title: Robust Egocentric Photo-realistic Facial Expression Transfer for Virtual  Reality ",
    "url": "https://arxiv.org/abs/2104.04794",
    "authors": [
      "Amin Jourabloo",
      "Baris Gecer",
      "Fernando De la Torre",
      "Jason Saragih",
      "Shih-En Wei",
      "Te-Li Wang",
      "Stephen Lombardi",
      "Danielle Belko",
      "Autumn Trimble",
      "Hernan Badino"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.07917",
    "title": "Hop-Count Based Self-Supervised Anomaly Detection on Attributed Networks",
    "abstract": " Comments: ECML2022 Accepted. 18 pages ",
    "url": "https://arxiv.org/abs/2104.07917",
    "authors": [
      "Tianjin Huang",
      "Yulong Pei",
      "Vlado Menkovski",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.04544",
    "title": "Proximal Causal Learning with Kernels: Two-Stage Estimation and Moment  Restriction",
    "abstract": " Comments: 44 pages, 5 figures, Figure 3, revised ",
    "url": "https://arxiv.org/abs/2105.04544",
    "authors": [
      "Afsaneh Mastouri",
      "Yuchen Zhu",
      "Limor Gultchin",
      "Anna Korba",
      "Ricardo Silva",
      "Matt J. Kusner",
      "Arthur Gretton",
      "Krikamol Muandet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.09737",
    "title": "Quantifying Topology In Pancreatic Tubular Networks From Live Imaging 3D  Microscopy",
    "abstract": " Comments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) this https URL\" ",
    "url": "https://arxiv.org/abs/2105.09737",
    "authors": [
      "Kasra Arnavaz",
      "Oswin Krause",
      "Kilian Zepf",
      "Jelena M. Krivokapic",
      "Silja Heilmann",
      "Jakob Andreas B\u00e6rentzen",
      "Pia Nyeng",
      "Aasa Feragen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.11620",
    "title": "Comparative Synthesis: Learning Near-Optimal Network Designs by Query",
    "abstract": " Title: Comparative Synthesis: Learning Near-Optimal Network Designs by Query ",
    "url": "https://arxiv.org/abs/2105.11620",
    "authors": [
      "Yanjun Wang",
      "Zixuan Li",
      "Chuan Jiang",
      "Xiaokang Qiu",
      "Sanjay G. Rao"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Human-Computer Interaction (cs.HC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2106.03305",
    "title": "Faster Cut-Equivalent Trees in Simple Graphs",
    "abstract": " Comments: Fix typos ",
    "url": "https://arxiv.org/abs/2106.03305",
    "authors": [
      "Tianyi Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2106.05965",
    "title": "Implicit-PDF: Non-Parametric Representation of Probability Distributions  on the Rotation Manifold",
    "abstract": " Comments: Additional implementation details ",
    "url": "https://arxiv.org/abs/2106.05965",
    "authors": [
      "Kieran Murphy",
      "Carlos Esteves",
      "Varun Jampani",
      "Srikumar Ramalingam",
      "Ameesh Makadia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.01149",
    "title": "Linking the Network Centrality Measures Closeness and Degree",
    "abstract": " Comments: v3 should be the same as the published version except for a couple of minor typos changed ",
    "url": "https://arxiv.org/abs/2108.01149",
    "authors": [
      "Tim S. Evans",
      "Bingsheng Chen"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2109.02394",
    "title": "Less is More: Lighter and Faster Deep Neural Architecture for Tomato  Leaf Disease Classification",
    "abstract": " Comments: 18 pages, 13 figures, 5 tables, Accepted in IEEE Access ",
    "url": "https://arxiv.org/abs/2109.02394",
    "authors": [
      "Sabbir Ahmed",
      "Md. Bakhtiar Hasan",
      "Tasnim Ahmed",
      "Redwan Karim Sony",
      "Md. Hasanul Kabir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.12389",
    "title": "RegMiner: Towards Constructing a Large Regression Dataset from Code  Evolution History",
    "abstract": " Comments: ISSTA'22 ",
    "url": "https://arxiv.org/abs/2109.12389",
    "authors": [
      "Xuezhi Song",
      "Yun Lin",
      "Siang Hwee Ng",
      "Yijian Wu",
      "Xin Peng",
      "Jin Song Dong",
      "Hong Mei"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2109.14164",
    "title": "Sample Complexity of the Robust LQG Regulator with Coprime Factors  Uncertainty",
    "abstract": " Comments: Minor Edits on closed loop identification, 30 pages, 2 figures, 3 algorithms ",
    "url": "https://arxiv.org/abs/2109.14164",
    "authors": [
      "Yifei Zhang",
      "Sourav Kumar Ukil",
      "Ephraim Neimand",
      "Serban Sabau",
      "Myron E. Hohil"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2110.01872",
    "title": "Permute Me Softly: Learning Soft Permutations for Graph Representations",
    "abstract": " Comments: Accepted at IEEE Transactions on Pattern Analysis and Machine Intelligence ",
    "url": "https://arxiv.org/abs/2110.01872",
    "authors": [
      "Giannis Nikolentzos",
      "George Dasoulas",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.11493",
    "title": "Surface code compilation via edge-disjoint paths",
    "abstract": " Comments: 48 pages, 20 figures. Published version in PRX Quantum. Includes new comparison table, tightened Theorem 3.3/3.4, and source code ",
    "url": "https://arxiv.org/abs/2110.11493",
    "authors": [
      "Michael Beverland",
      "Vadym Kliuchnikov",
      "Eddie Schoute"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2110.12981",
    "title": "Feasibility Study of Neural ODE and DAE Modules for Power System Dynamic  Component Modeling",
    "abstract": " Comments: 14 pages, 8 figures, 3 table. Under review by IEEE Transactions on Power Systems ",
    "url": "https://arxiv.org/abs/2110.12981",
    "authors": [
      "Tannan Xiao",
      "Ying Chen",
      "Shaowei Huang",
      "Tirui He",
      "Huizhe Guan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.15182",
    "title": "Dist2Cycle: A Simplicial Neural Network for Homology Localization",
    "abstract": " Comments: 9 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2110.15182",
    "authors": [
      "Alexandros Dimitrios Keros",
      "Vidit Nanda",
      "Kartic Subr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2111.12757",
    "title": "ACNet: Approaching-and-Centralizing Network for Zero-Shot Sketch-Based  Image Retrieval",
    "abstract": " Comments: the paper is under consideration at IEEE Transactions on Circuits and Systems for Video Technology ",
    "url": "https://arxiv.org/abs/2111.12757",
    "authors": [
      "Hao Ren",
      "Ziqiang Zheng",
      "Yang Wu",
      "Hong Lu",
      "Yang Yang",
      "Sai-Kit Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.14196",
    "title": "Subexponential Parameterized Algorithms for Cut and Cycle Hitting  Problems on H-Minor-Free Graphs",
    "abstract": " Comments: A preliminary version appears in SODA'22 ",
    "url": "https://arxiv.org/abs/2111.14196",
    "authors": [
      "Sayan Bandyapadhyay",
      "William Lochet",
      "Daniel Lokshtanov",
      "Saket Saurabh",
      "Jie Xue"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2112.04454",
    "title": "Greedy-based Value Representation for Optimal Coordination in  Multi-agent Reinforcement Learning",
    "abstract": " Title: Greedy-based Value Representation for Optimal Coordination in  Multi-agent Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2112.04454",
    "authors": [
      "Lipeng Wan",
      "Zeyang Liu",
      "Xingyu Chen",
      "Han Wang",
      "Xuguang Lan"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2112.06721",
    "title": "PM-MMUT: Boosted Phone-Mask Data Augmentation using Multi-Modeling Unit  Training for Phonetic-Reduction-Robust E2E Speech Recognition",
    "abstract": " Comments: Accepted to INTERSPEECH 2022 ",
    "url": "https://arxiv.org/abs/2112.06721",
    "authors": [
      "Guodong Ma",
      "Pengfei Hu",
      "Nurmemet Yolwas",
      "Shen Huang",
      "Hao Huang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2112.07238",
    "title": "Composing MPC with LQR and Neural Network for Amortized Efficient and  Stable Control",
    "abstract": " Comments: 13 pages, 10 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2112.07238",
    "authors": [
      "Fangyu Wu",
      "Guanhua Wang",
      "Siyuan Zhuang",
      "Kehan Wang",
      "Alexander Keimer",
      "Ion Stoica",
      "Alexandre Bayen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2112.08088",
    "title": "Image-Adaptive YOLO for Object Detection in Adverse Weather Conditions",
    "abstract": " Comments: AAAI 2022, Preprint version with Appendix ",
    "url": "https://arxiv.org/abs/2112.08088",
    "authors": [
      "Wenyu Liu",
      "Gaofeng Ren",
      "Runsheng Yu",
      "Shi Guo",
      "Jianke Zhu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.15031",
    "title": "Development of a face mask detection pipeline for mask-wearing  monitoring in the era of the COVID-19 pandemic: A modular approach",
    "abstract": " Comments: Accepted at the 19th International Joint Conference on Computer Science and Software Engineering (JCSSE 2022) ",
    "url": "https://arxiv.org/abs/2112.15031",
    "authors": [
      "Benjaphan Sommana",
      "Ukrit Watchareeruetai",
      "Ankush Ganguly",
      "Samuel W.F. Earp",
      "Taya Kitiyakara",
      "Suparee Boonmanunt",
      "Ratchainant Thammasudjarit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.03969",
    "title": "Multimodal Representations Learning Based on Mutual Information  Maximization and Minimization and Identity Embedding for Multimodal Sentiment  Analysis",
    "abstract": " Title: Multimodal Representations Learning Based on Mutual Information  Maximization and Minimization and Identity Embedding for Multimodal Sentiment  Analysis ",
    "url": "https://arxiv.org/abs/2201.03969",
    "authors": [
      "Jiahao Zheng",
      "Sen Zhang",
      "Xiaoping Wang",
      "Zhigang Zeng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.11692",
    "title": "SSLGuard: A Watermarking Scheme for Self-supervised Learning Pre-trained  Encoders",
    "abstract": " Title: SSLGuard: A Watermarking Scheme for Self-supervised Learning Pre-trained  Encoders ",
    "url": "https://arxiv.org/abs/2201.11692",
    "authors": [
      "Tianshuo Cong",
      "Xinlei He",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01380",
    "title": "Learning Mechanically Driven Emergent Behavior with Message Passing  Neural Networks",
    "abstract": " Comments: 24 pages, 14 figures; added section 3.5 and Appendix C; fixed minor typos; edited figures ",
    "url": "https://arxiv.org/abs/2202.01380",
    "authors": [
      "Peerasait Prachaseree",
      "Emma Lejeune"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2202.02943",
    "title": "Learning fair representation with a parametric integral probability  metric",
    "abstract": " Comments: 28 pages, including references and appendix ",
    "url": "https://arxiv.org/abs/2202.02943",
    "authors": [
      "Dongha Kim",
      "Kunwoong Kim",
      "Insung Kong",
      "Ilsang Ohn",
      "Yongdai Kim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03173",
    "title": "Towards Loosely-Coupling Knowledge Graph Embeddings and Ontology-based  Reasoning",
    "abstract": " Title: Towards Loosely-Coupling Knowledge Graph Embeddings and Ontology-based  Reasoning ",
    "url": "https://arxiv.org/abs/2202.03173",
    "authors": [
      "Zoi Kaoudi",
      "Abelardo Carlos Martinez Lorenzo",
      "Volker Markl"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04528",
    "title": "Multimodal Audio-Visual Information Fusion using Canonical-Correlated  Graph Neural Network for Energy-Efficient Speech Enhancement",
    "abstract": " Title: Multimodal Audio-Visual Information Fusion using Canonical-Correlated  Graph Neural Network for Energy-Efficient Speech Enhancement ",
    "url": "https://arxiv.org/abs/2202.04528",
    "authors": [
      "Leandro Aparecido Passos",
      "Jo\u00e3o Paulo Papa",
      "Javier Del Ser",
      "Amir Hussain",
      "Ahsan Adeel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2202.04781",
    "title": "Adversarial Attack and Defense of YOLO Detectors in Autonomous Driving  Scenarios",
    "abstract": " Comments: Accepted by 2022 IEEE Intelligent Vehicles Symposium (IV 2022) ",
    "url": "https://arxiv.org/abs/2202.04781",
    "authors": [
      "Jung Im Choi",
      "Qing Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.11393",
    "title": "Differential privacy for symmetric log-concave mechanisms",
    "abstract": " Comments: AISTATS 2022, v2 corrects typos ",
    "url": "https://arxiv.org/abs/2202.11393",
    "authors": [
      "Staal A. Vinterbo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.01137",
    "title": "Self-Supervised Scene Flow Estimation with 4-D Automotive Radar",
    "abstract": " Comments: Copyright (c) 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works ",
    "url": "https://arxiv.org/abs/2203.01137",
    "authors": [
      "Fangqiang Ding",
      "Zhijun Pan",
      "Yimin Deng",
      "Jianning Deng",
      "Chris Xiaoxuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.03844",
    "title": "Dynamic Dual Trainable Bounds for Ultra-low Precision Super-Resolution  Networks",
    "abstract": " Comments: ECCV2022 ",
    "url": "https://arxiv.org/abs/2203.03844",
    "authors": [
      "Yunshan Zhong",
      "Mingbao Lin",
      "Xunchao Li",
      "Ke Li",
      "Yunhang Shen",
      "Fei Chao",
      "Yongjian Wu",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.04959",
    "title": "ModDrop++: A Dynamic Filter Network with Intra-subject Co-training for  Multiple Sclerosis Lesion Segmentation with Missing Modalities",
    "abstract": " Comments: MICCAI 2022 ",
    "url": "https://arxiv.org/abs/2203.04959",
    "authors": [
      "Han Liu",
      "Yubo Fan",
      "Hao Li",
      "Jiacheng Wang",
      "Dewei Hu",
      "Can Cui",
      "Ho Hin Lee",
      "Huahong Zhang",
      "Ipek Oguz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07632",
    "title": "Graph Representation Learning for Popularity Prediction Problem: A  Survey",
    "abstract": " Comments: 30 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2203.07632",
    "authors": [
      "Tiantian Chen",
      "Jianxiong Guo",
      "Weili Wu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09780",
    "title": "Sparse Fuse Dense: Towards High Quality 3D Detection with Depth  Completion",
    "abstract": " Comments: Accepted by CVPR 2022 (Oral) ",
    "url": "https://arxiv.org/abs/2203.09780",
    "authors": [
      "Xiaopei Wu",
      "Liang Peng",
      "Honghui Yang",
      "Liang Xie",
      "Chenxi Huang",
      "Chengqi Deng",
      "Haifeng Liu",
      "Deng Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11864",
    "title": "On the (Non-)Robustness of Two-Layer Neural Networks in Different  Learning Regimes",
    "abstract": " Title: On the (Non-)Robustness of Two-Layer Neural Networks in Different  Learning Regimes ",
    "url": "https://arxiv.org/abs/2203.11864",
    "authors": [
      "Elvis Dohmatob",
      "Alberto Bietti"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.12363",
    "title": "Ethereum Fraud Detection with Heterogeneous Graph Neural Networks",
    "abstract": " Comments: 8 pages, 5 figures, Accepted to KDD'22 Workshop on Mining and Learning with Graphs ",
    "url": "https://arxiv.org/abs/2203.12363",
    "authors": [
      "Hiroki Kanezashi",
      "Toyotaro Suzumura",
      "Xin Liu",
      "Takahiro Hirofuchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.13779",
    "title": "Origins of Low-dimensional Adversarial Perturbations",
    "abstract": " Title: Origins of Low-dimensional Adversarial Perturbations ",
    "url": "https://arxiv.org/abs/2203.13779",
    "authors": [
      "Elvis Dohmatob",
      "Chuan Guo",
      "Morgane Goibert"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.14084",
    "title": "Self-Supervised Point Cloud Representation Learning with Occlusion  Auto-Encoder",
    "abstract": " Title: Self-Supervised Point Cloud Representation Learning with Occlusion  Auto-Encoder ",
    "url": "https://arxiv.org/abs/2203.14084",
    "authors": [
      "Junsheng Zhou",
      "Xin Wen",
      "Baorui Ma",
      "Yu-Shen Liu",
      "Yue Gao",
      "Yi Fang",
      "Zhizhong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15135",
    "title": "Filler Word Detection and Classification: A Dataset and Benchmark",
    "abstract": " Comments: To appear at Insterspeech 2022 ",
    "url": "https://arxiv.org/abs/2203.15135",
    "authors": [
      "Ge Zhu",
      "Juan-Pablo Caceres",
      "Justin Salamon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.02088",
    "title": "A Mixed supervised Learning Framework for Target Sound Detection",
    "abstract": " Comments: submitted to SPL2022 ",
    "url": "https://arxiv.org/abs/2204.02088",
    "authors": [
      "Dongchao Yang",
      "Helin Wang",
      "Yuexian Zou",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.05352",
    "title": "Large-Scale Streaming End-to-End Speech Translation with Neural  Transducers",
    "abstract": " Comments: The paper was submitted to Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2204.05352",
    "authors": [
      "Jian Xue",
      "Peidong Wang",
      "Jinyu Li",
      "Matt Post",
      "Yashesh Gaur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.05477",
    "title": "Deep Normed Embeddings for Patient Representation",
    "abstract": " Comments: A minimal implementation of this work can be found at this https URL ",
    "url": "https://arxiv.org/abs/2204.05477",
    "authors": [
      "Thesath Nanayakkara",
      "Gilles Clermont",
      "Christopher James Langmead",
      "David Swigon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2204.06403",
    "title": "Efficient Re-parameterization Operations Search for Easy-to-Deploy  Network Based on Directional Evolutionary Strategy",
    "abstract": " Comments: 21pages, 8figures ",
    "url": "https://arxiv.org/abs/2204.06403",
    "authors": [
      "Xinyi Yu",
      "Xiaowei Wang",
      "Jintao Rong",
      "Mingyang Zhang",
      "Linlin Ou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.07126",
    "title": "GIFS: Neural Implicit Function for General Shape Representation",
    "abstract": " Comments: Accepted to CVPR 2022. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2204.07126",
    "authors": [
      "Jianglong Ye",
      "Yuntao Chen",
      "Naiyan Wang",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.10965",
    "title": "CLIP-Dissect: Automatic Description of Neuron Representations in Deep  Vision Networks",
    "abstract": " Comments: Published in ICLR 2022 PAIR2Struct Workshop ",
    "url": "https://arxiv.org/abs/2204.10965",
    "authors": [
      "Tuomas Oikarinen",
      "Tsui-Wei Weng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.12202",
    "title": "Urban Change Detection Using a Dual-Task Siamese Network and  Semi-Supervised Learning",
    "abstract": " Comments: 4 pages, 4 figures, to be published in 2022 IEEE International Geoscience and Remote Sensing Symposium IGARSS ",
    "url": "https://arxiv.org/abs/2204.12202",
    "authors": [
      "Sebastian Hafner",
      "Yifang Ban",
      "Andrea Nascetti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.13784",
    "title": "AGIC: Approximate Gradient Inversion Attack on Federated Learning",
    "abstract": " Comments: This paper is accepted at the 41st International Symposium on Reliable Distributed Systems (SRDS 2022) ",
    "url": "https://arxiv.org/abs/2204.13784",
    "authors": [
      "Jin Xu",
      "Chi Hong",
      "Jiyue Huang",
      "Lydia Y. Chen",
      "J\u00e9r\u00e9mie Decouchant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.00376",
    "title": "Traffic Context Aware Data Augmentation for Rare Object Detection in  Autonomous Driving",
    "abstract": " Comments: The IEEE Conference on Robotics and Automation, ICRA 2022 ",
    "url": "https://arxiv.org/abs/2205.00376",
    "authors": [
      "Naifan Li",
      "Fan Song",
      "Ying Zhang",
      "Pengpeng Liang",
      "Erkang Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.00782",
    "title": "Type-aware Embeddings for Multi-Hop Reasoning over Knowledge Graphs",
    "abstract": " Comments: Accepted to IJCAI-ECAI 2022 ",
    "url": "https://arxiv.org/abs/2205.00782",
    "authors": [
      "Zhiwei Hu",
      "V\u00edctor Guti\u00e9rrez-Basulto",
      "Zhiliang Xiang",
      "Xiaoli Li",
      "Ru Li",
      "Jeff Z. Pan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01414",
    "title": "Multimodal Detection of Unknown Objects on Roads for Autonomous Driving",
    "abstract": " Comments: Daniel Bogdoll, Enrico Eisen, Maximilian Nitsche, and Christin Scheib contributed equally. Accepted for publication at SMC 2022 ",
    "url": "https://arxiv.org/abs/2205.01414",
    "authors": [
      "Daniel Bogdoll",
      "Enrico Eisen",
      "Maximilian Nitsche",
      "Christin Scheib",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.09723",
    "title": "Robust and Efficient Medical Imaging with Self-Supervision",
    "abstract": " Title: Robust and Efficient Medical Imaging with Self-Supervision ",
    "url": "https://arxiv.org/abs/2205.09723",
    "authors": [
      "Shekoofeh Azizi",
      "Laura Culp",
      "Jan Freyberg",
      "Basil Mustafa",
      "Sebastien Baur",
      "Simon Kornblith",
      "Ting Chen",
      "Patricia MacWilliams",
      "S. Sara Mahdavi",
      "Ellery Wulczyn",
      "Boris Babenko",
      "Megan Wilson",
      "Aaron Loh",
      "Po-Hsuan Cameron Chen",
      "Yuan Liu",
      "Pinal Bavishi",
      "Scott Mayer McKinney",
      "Jim Winkens",
      "Abhijit Guha Roy",
      "Zach Beaver",
      "Fiona Ryan",
      "Justin Krogue",
      "Mozziyar Etemadi",
      "Umesh Telang",
      "Yun Liu",
      "Lily Peng",
      "Greg S. Corrado",
      "Dale R. Webster",
      "David Fleet",
      "Geoffrey Hinton",
      "Neil Houlsby",
      "Alan Karthikesalingam",
      "Mohammad Norouzi",
      "Vivek Natarajan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10120",
    "title": "Privacy Preserving Image Registration",
    "abstract": " Title: Privacy Preserving Image Registration ",
    "url": "https://arxiv.org/abs/2205.10120",
    "authors": [
      "Riccardo Taiello",
      "Melek \u00d6nen",
      "Olivier Humbert",
      "Marco Lorenzi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.14625",
    "title": "Cervical Glandular Cell Detection from Whole Slide Image with  Out-Of-Distribution Data",
    "abstract": " Comments: 11 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2205.14625",
    "authors": [
      "Ziquan Wei",
      "Shenghua Cheng",
      "Jing Cai",
      "Shaoqun Zeng",
      "Xiuli Liu",
      "Zehua Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14839",
    "title": "Adversarial Bandits Robust to Switching Targets",
    "abstract": " Title: Adversarial Bandits Robust to Switching Targets ",
    "url": "https://arxiv.org/abs/2205.14839",
    "authors": [
      "Jung-hun Kim",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.04153",
    "title": "Unsupervised Key Event Detection from Massive Text Corpora",
    "abstract": " Comments: Accepted to KDD 2022 Research Track ",
    "url": "https://arxiv.org/abs/2206.04153",
    "authors": [
      "Yunyi Zhang",
      "Fang Guo",
      "Jiaming Shen",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.04979",
    "title": "Convolutional Layers are Equivariant to Discrete Shifts But Not  Continuous Translations",
    "abstract": " Title: Convolutional Layers are Equivariant to Discrete Shifts But Not  Continuous Translations ",
    "url": "https://arxiv.org/abs/2206.04979",
    "authors": [
      "Nick McGreivy",
      "Ammar Hakim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.05764",
    "title": "Mining Multi-Label Samples from Single Positive Labels",
    "abstract": " Title: Mining Multi-Label Samples from Single Positive Labels ",
    "url": "https://arxiv.org/abs/2206.05764",
    "authors": [
      "Youngin Cho",
      "Daejin Kim",
      "Mohammad Azam Khan",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.08255",
    "title": "Gradient-Based Adversarial and Out-of-Distribution Detection",
    "abstract": " Comments: International Conference on Machine Learning (ICML) Workshop on New Frontiers in Adversarial Machine Learning, July 2022 ",
    "url": "https://arxiv.org/abs/2206.08255",
    "authors": [
      "Jinsol Lee",
      "Mohit Prabhushankar",
      "Ghassan AlRegib"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09569",
    "title": "Shuffle Gaussian Mechanism for Differential Privacy",
    "abstract": " Comments: Fixed typos. The source code of our implementation is available at this http URL ",
    "url": "https://arxiv.org/abs/2206.09569",
    "authors": [
      "Seng Pei Liew",
      "Tsubasa Takahashi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.10158",
    "title": "Certifiably Robust Policy Learning against Adversarial Communication in  Multi-agent Systems",
    "abstract": " Title: Certifiably Robust Policy Learning against Adversarial Communication in  Multi-agent Systems ",
    "url": "https://arxiv.org/abs/2206.10158",
    "authors": [
      "Yanchao Sun",
      "Ruijie Zheng",
      "Parisa Hassanzadeh",
      "Yongyuan Liang",
      "Soheil Feizi",
      "Sumitra Ganesh",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2206.12901",
    "title": "Noise-aware Physics-informed Machine Learning for Robust PDE Discovery",
    "abstract": " Comments: 13 pages, 8 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice. v2: corrected typos, v3: corrected author names, corrected typos ",
    "url": "https://arxiv.org/abs/2206.12901",
    "authors": [
      "Pongpisit Thanasutives",
      "Takashi Morita",
      "Masayuki Numao",
      "Ken-ichi Fukui"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2206.12933",
    "title": "Latent Augmentation Improves Graph Self-Supervised Learning",
    "abstract": " Title: Latent Augmentation Improves Graph Self-Supervised Learning ",
    "url": "https://arxiv.org/abs/2206.12933",
    "authors": [
      "Jiashun Cheng",
      "Man Li",
      "Jia Li",
      "Fugee Tsung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.12943",
    "title": "Multi-view Feature Augmentation with Adaptive Class Activation Mapping",
    "abstract": " Comments: Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence (IJCAI-21) ",
    "url": "https://arxiv.org/abs/2206.12943",
    "authors": [
      "Xiang Gao",
      "Yingjie Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.13076",
    "title": "SearchMorph:Multi-scale Correlation Iterative Network for Deformable  Registration",
    "abstract": " Title: SearchMorph:Multi-scale Correlation Iterative Network for Deformable  Registration ",
    "url": "https://arxiv.org/abs/2206.13076",
    "authors": [
      "Xiao Fan",
      "Shuxin Zhuang",
      "Zhemin Zhuang",
      "Shunmin Qiu",
      "Alex Noel Joseph Raj",
      "Yibiao Rong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14477",
    "title": "Adversarial Ensemble Training by Jointly Learning Label Dependencies and  Member Models",
    "abstract": " Title: Adversarial Ensemble Training by Jointly Learning Label Dependencies and  Member Models ",
    "url": "https://arxiv.org/abs/2206.14477",
    "authors": [
      "Lele Wang",
      "Bin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.00259",
    "title": "Covid-19 Detection Using transfer Learning Approach from Computed  Temography Images",
    "abstract": " Title: Covid-19 Detection Using transfer Learning Approach from Computed  Temography Images ",
    "url": "https://arxiv.org/abs/2207.00259",
    "authors": [
      "Kenan Morani",
      "Muhammet Fatih Balikci",
      "Tayfun Yigit Altuntas",
      "Devrim Unay"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00278",
    "title": "BadHash: Invisible Backdoor Attacks against Deep Hashing with Clean  Label",
    "abstract": " Comments: conference ",
    "url": "https://arxiv.org/abs/2207.00278",
    "authors": [
      "Shengshan Hu",
      "Ziqi Zhou",
      "Yechao Zhang",
      "Leo Yu Zhang",
      "Yifeng Zheng",
      "Yuanyuan HE",
      "Hai Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00425",
    "title": "Transferable Graph Backdoor Attack",
    "abstract": " Comments: Accepted by the 25th International Symposium on Research in Attacks, Intrusions, and Defenses ",
    "url": "https://arxiv.org/abs/2207.00425",
    "authors": [
      "Shuiqiao Yang",
      "Bao Gia Doan",
      "Paul Montague",
      "Olivier De Vel",
      "Tamas Abraham",
      "Seyit Camtepe",
      "Damith C. Ranasinghe",
      "Salil S. Kanhere"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00473",
    "title": "Assessing the Effects of Hyperparameters on Knowledge Graph Embedding  Quality",
    "abstract": " Title: Assessing the Effects of Hyperparameters on Knowledge Graph Embedding  Quality ",
    "url": "https://arxiv.org/abs/2207.00473",
    "authors": [
      "Oliver Lloyd",
      "Yi Liu",
      "Tom Gaunt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  }
]