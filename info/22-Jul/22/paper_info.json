[
  {
    "id": "arXiv:2207.10078",
    "title": "The sparse representation related with fractional heat equations",
    "abstract": "This study introduces pre-orthogonal adaptive Fourier decomposition (POAFD) to obtain approximations and numerical solutions to the fractional Laplacian initial value problem and the extension problem of Caffarelli and Silvestre (generalized Poisson equation). The method, as the first step, expands the initial data function into a sparse series of the fundamental solutions with fast convergence, and, as the second step, makes use the semigroup or the reproducing kernel property of each of the expanding entries. Experiments show effectiveness and efficiency of the proposed series solutions. ",
    "url": "https://arxiv.org/abs/2207.10078",
    "authors": [
      "Pengtao Li",
      "Tao Qian",
      "Ieng Tak Leong",
      "Wei Qu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.10081",
    "title": "What Do We Maximize in Self-Supervised Learning?",
    "abstract": "In this paper, we examine self-supervised learning methods, particularly VICReg, to provide an information-theoretical understanding of their construction. As a first step, we demonstrate how information-theoretic quantities can be obtained for a deterministic network, offering a possible alternative to prior work that relies on stochastic models. This enables us to demonstrate how VICReg can be (re)discovered from first principles and its assumptions about data distribution. Furthermore, we empirically demonstrate the validity of our assumptions, confirming our novel understanding of VICReg. Finally, we believe that the derivation and insights we obtain can be generalized to many other SSL methods, opening new avenues for theoretical and practical understanding of SSL and transfer learning. ",
    "url": "https://arxiv.org/abs/2207.10081",
    "authors": [
      "Ravid Shwartz-Ziv",
      "Randall Balestriero",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.10128",
    "title": "Towards Better Evaluation for Dynamic Link Prediction",
    "abstract": "There has been recent success in learning from static graphs, but despite their prevalence, learning from time-evolving graphs remains challenging. We design new, more stringent evaluation procedures for link prediction specific to dynamic graphs, which reflect real-world considerations and can better compare different methods' strengths and weaknesses. In particular, we create two visualization techniques to understand the recurring patterns of edges over time. They show that many edges reoccur at later time steps. Therefore, we propose a pure memorization baseline called EdgeBank. It achieves surprisingly strong performance across multiple settings, partly due to the easy negative edges used in the current evaluation setting. Hence, we introduce two more challenging negative sampling strategies that improve robustness and can better match real-world applications. Lastly, we introduce five new dynamic graph datasets from a diverse set of domains missing from current benchmarks, providing new challenges and opportunities for future research. ",
    "url": "https://arxiv.org/abs/2207.10128",
    "authors": [
      "Farimah Poursafaei",
      "Shenyang Huang",
      "Kellin Pelrine",
      "Reihaneh Rabbany"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.10129",
    "title": "Dynamic Load Altering EV Attacks Against Power Grid Frequency Control",
    "abstract": "Driven by the necessity to combat climate change, Electric Vehicles (EV) are being deployed to take advantage of their ability in reducing emissions generated by the transportation sector. This deployment has left the power grid vulnerable to attacks through the EV infrastructure. This paper is written from an attacker\\'s perspective and proposes a dynamic load altering strategy through manipulating EV charging to destabilize the grid. The attack is formulated based on feedback control theory, i.e., designing an attack based on Linear Matrix Inequalities (LMIs). After the stability metric and controller design have been established, we demonstrate our attack method against the Kundur 2 area grid. The attack scenario includes a cap of 200 MW EV load controlled by the attacker. However, the results show that even with this limitation, the attacker would be successful in pushing the grid toward instability and blackout. ",
    "url": "https://arxiv.org/abs/2207.10129",
    "authors": [
      "Mohammad Ali Sayed",
      "Mohsen Ghafouri",
      "Mourad Debbabi",
      "Chadi Assi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.10137",
    "title": "A Generalized & Robust Framework For Timestamp Supervision in Temporal  Action Segmentation",
    "abstract": "In temporal action segmentation, Timestamp supervision requires only a handful of labelled frames per video sequence. For unlabelled frames, previous works rely on assigning hard labels, and performance rapidly collapses under subtle violations of the annotation assumptions. We propose a novel Expectation-Maximization (EM) based approach that leverages the label uncertainty of unlabelled frames and is robust enough to accommodate possible annotation errors. With accurate timestamp annotations, our proposed method produces SOTA results and even exceeds the fully-supervised setup in several metrics and datasets. When applied to timestamp annotations with missing action segments, our method presents stable performance. To further test our formulation's robustness, we introduce the new challenging annotation setup of Skip-tag supervision. This setup relaxes constraints and requires annotations of any fixed number of random frames in a video, making it more flexible than Timestamp supervision while remaining competitive. ",
    "url": "https://arxiv.org/abs/2207.10137",
    "authors": [
      "Rahul Rahaman",
      "Dipika Singhania",
      "Alexandre Thiery",
      "Angela Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10149",
    "title": "Digraphwave: Scalable Extraction of Structural Node Embeddings via  Diffusion on Directed Graphs",
    "abstract": "Structural node embeddings, vectors capturing local connectivity information for each node in a graph, have many applications in data mining and machine learning, e.g., network alignment and node classification, clustering and anomaly detection. For the analysis of directed graphs, e.g., transactions graphs, communication networks and social networks, the capability to capture directional information in the structural node embeddings is highly desirable, as is scalability of the embedding extraction method. Most existing methods are nevertheless only designed for undirected graph. Therefore, we present Digraphwave -- a scalable algorithm for extracting structural node embeddings on directed graphs. The Digraphwave embeddings consist of compressed diffusion pattern signatures, which are twice enhanced to increase their discriminate capacity. By proving a lower bound on the heat contained in the local vicinity of a diffusion initialization node, theoretically justified diffusion timescale values are established, and Digraphwave is left with only two easy-to-interpret hyperparameters: the embedding dimension and a neighbourhood resolution specifier. In our experiments, the two embedding enhancements, named transposition and aggregation, are shown to lead to a significant increase in macro F1 score for classifying automorphic identities, with Digraphwave outperforming all other structural embedding baselines. Moreover, Digraphwave either outperforms or matches the performance of all baselines on real graph datasets, displaying a particularly large performance gain in a network alignment task, while also being scalable to graphs with millions of nodes and edges, running up to 30x faster than a previous diffusion pattern based method and with a fraction of the memory consumption. ",
    "url": "https://arxiv.org/abs/2207.10149",
    "authors": [
      "Ciwan Ceylan",
      "Kambiz Ghoorchian",
      "Danica Kragic"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10156",
    "title": "Structural Causal 3D Reconstruction",
    "abstract": "This paper considers the problem of unsupervised 3D object reconstruction from in-the-wild single-view images. Due to ambiguity and intrinsic ill-posedness, this problem is inherently difficult to solve and therefore requires strong regularization to achieve disentanglement of different latent factors. Unlike existing works that introduce explicit regularizations into objective functions, we look into a different space for implicit regularization -- the structure of latent space. Specifically, we restrict the structure of latent space to capture a topological causal ordering of latent factors (i.e., representing causal dependency as a directed acyclic graph). We first show that different causal orderings matter for 3D reconstruction, and then explore several approaches to find a task-dependent causal factor ordering. Our experiments demonstrate that the latent space structure indeed serves as an implicit regularization and introduces an inductive bias beneficial for reconstruction. ",
    "url": "https://arxiv.org/abs/2207.10156",
    "authors": [
      "Weiyang Liu",
      "Zhen Liu",
      "Liam Paull",
      "Adrian Weller",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10158",
    "title": "GOCA: Guided Online Cluster Assignment for Self-Supervised Video  Representation Learning",
    "abstract": "Clustering is a ubiquitous tool in unsupervised learning. Most of the existing self-supervised representation learning methods typically cluster samples based on visually dominant features. While this works well for image-based self-supervision, it often fails for videos, which require understanding motion rather than focusing on background. Using optical flow as complementary information to RGB can alleviate this problem. However, we observe that a naive combination of the two views does not provide meaningful gains. In this paper, we propose a principled way to combine two views. Specifically, we propose a novel clustering strategy where we use the initial cluster assignment of each view as prior to guide the final cluster assignment of the other view. This idea will enforce similar cluster structures for both views, and the formed clusters will be semantically abstract and robust to noisy inputs coming from each individual view. Additionally, we propose a novel regularization strategy to address the feature collapse problem, which is common in cluster-based self-supervised learning methods. Our extensive evaluation shows the effectiveness of our learned representations on downstream tasks, e.g., video retrieval and action recognition. Specifically, we outperform the state of the art by 7% on UCF and 4% on HMDB for video retrieval, and 5% on UCF and 6% on HMDB for video classification ",
    "url": "https://arxiv.org/abs/2207.10158",
    "authors": [
      "Huseyin Coskun",
      "Alireza Zareian",
      "Joshua L. Moore",
      "Federico Tombari",
      "Chen Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10170",
    "title": "Illusionary Attacks on Sequential Decision Makers and Countermeasures",
    "abstract": "Autonomous intelligent agents deployed to the real-world need to be robust against adversarial attacks on sensory inputs. Existing work in reinforcement learning focuses on minimum-norm perturbation attacks, which were originally introduced to mimic a notion of perceptual invariance in computer vision. In this paper, we note that such minimum-norm perturbation attacks can be trivially detected by victim agents, as these result in observation sequences that are not consistent with the victim agent's actions. Furthermore, many real-world agents, such as physical robots, commonly operate under human supervisors, which are not susceptible to such perturbation attacks. As a result, we propose to instead focus on illusionary attacks, a novel form of attack that is consistent with the world model of the victim agent. We provide a formal definition of this novel attack framework, explore its characteristics under a variety of conditions, and conclude that agents must seek realism feedback to be robust to illusionary attacks. ",
    "url": "https://arxiv.org/abs/2207.10170",
    "authors": [
      "Tim Franzmeyer",
      "Jo\u00e3o F. Henriques",
      "Jakob N. Foerster",
      "Philip H.S. Torr",
      "Adel Bibi",
      "Christian Schroeder de Witt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.10172",
    "title": "Video Anomaly Detection by Solving Decoupled Spatio-Temporal Jigsaw  Puzzles",
    "abstract": "Video Anomaly Detection (VAD) is an important topic in computer vision. Motivated by the recent advances in self-supervised learning, this paper addresses VAD by solving an intuitive yet challenging pretext task, i.e., spatio-temporal jigsaw puzzles, which is cast as a multi-label fine-grained classification problem. Our method exhibits several advantages over existing works: 1) the spatio-temporal jigsaw puzzles are decoupled in terms of spatial and temporal dimensions, responsible for capturing highly discriminative appearance and motion features, respectively; 2) full permutations are used to provide abundant jigsaw puzzles covering various difficulty levels, allowing the network to distinguish subtle spatio-temporal differences between normal and abnormal events; and 3) the pretext task is tackled in an end-to-end manner without relying on any pre-trained models. Our method outperforms state-of-the-art counterparts on three public benchmarks. Especially on ShanghaiTech Campus, the result is superior to reconstruction and prediction-based methods by a large margin. ",
    "url": "https://arxiv.org/abs/2207.10172",
    "authors": [
      "Guodong Wang",
      "Yunhong Wang",
      "Jie Qin",
      "Dongming Zhang",
      "Xiuguo Bao",
      "Di Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10188",
    "title": "Bitwidth-Adaptive Quantization-Aware Neural Network Training: A  Meta-Learning Approach",
    "abstract": "Deep neural network quantization with adaptive bitwidths has gained increasing attention due to the ease of model deployment on various platforms with different resource budgets. In this paper, we propose a meta-learning approach to achieve this goal. Specifically, we propose MEBQAT, a simple yet effective way of bitwidth-adaptive quantization aware training (QAT) where meta-learning is effectively combined with QAT by redefining meta-learning tasks to incorporate bitwidths. After being deployed on a platform, MEBQAT allows the (meta-)trained model to be quantized to any candidate bitwidth then helps to conduct inference without much accuracy drop from quantization. Moreover, with a few-shot learning scenario, MEBQAT can also adapt a model to any bitwidth as well as any unseen target classes by adding conventional optimization or metric-based meta-learning. We design variants of MEBQAT to support both (1) a bitwidth-adaptive quantization scenario and (2) a new few-shot learning scenario where both quantization bitwidths and target classes are jointly adapted. We experimentally demonstrate their validity in multiple QAT schemes. By comparing their performance to (bitwidth-dedicated) QAT, existing bitwidth adaptive QAT and vanilla meta-learning, we find that merging bitwidths into meta-learning tasks achieves a higher level of robustness. ",
    "url": "https://arxiv.org/abs/2207.10188",
    "authors": [
      "Jiseok Youn",
      "Jaehun Song",
      "Hyung-Sin Kim",
      "Saewoong Bahk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10204",
    "title": "Watermark-Based Code Construction for Finite-State Markov Channel with  Synchronisation Errors",
    "abstract": "With advancements in telecommunications, data transmission over increasingly harsher channels that produce synchronisation errors is inevitable. Coding schemes for such channels are available through techniques such as the Davey-MacKay watermark coding; however, this is limited to memoryless channel estimates. Memory must be accounted for to ensure a realistic channel approximation - similar to a Finite State Markov Chain or Fritchman Model. A novel code construction and decoder are developed to correct synchronisation errors while considering the channel's correlated memory effects by incorporating ideas from the watermark scheme and memory modelling. Simulation results show that the proposed code construction and decoder rival the first and second-order Davey-MacKay type watermark decoder and even perform slightly better when the inner-channel capacity is higher than 0.9. The proposed system and decoder may prove helpful in fields such as free-space optics and possibly molecular communication, where harsh channels are used for communication. ",
    "url": "https://arxiv.org/abs/2207.10204",
    "authors": [
      "Shamin Achari",
      "Ling Cheng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.10205",
    "title": "On the Robustness of 3D Object Detectors",
    "abstract": "In recent years, significant progress has been achieved for 3D object detection on point clouds thanks to the advances in 3D data collection and deep learning techniques. Nevertheless, 3D scenes exhibit a lot of variations and are prone to sensor inaccuracies as well as information loss during pre-processing. Thus, it is crucial to design techniques that are robust against these variations. This requires a detailed analysis and understanding of the effect of such variations. This work aims to analyze and benchmark popular point-based 3D object detectors against several data corruptions. To the best of our knowledge, we are the first to investigate the robustness of point-based 3D object detectors. To this end, we design and evaluate corruptions that involve data addition, reduction, and alteration. We further study the robustness of different modules against local and global variations. Our experimental results reveal several intriguing findings. For instance, we show that methods that integrate Transformers at a patch or object level lead to increased robustness, compared to using Transformers at the point level. ",
    "url": "https://arxiv.org/abs/2207.10205",
    "authors": [
      "Fatima Albreiki",
      "Sultan Abughazal",
      "Jean Lahoud",
      "Rao Anwer",
      "Hisham Cholakkal",
      "Fahad Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10222",
    "title": "Direct Localization in Underwater Acoustics via Convolutional Neural  Networks: A Data-Driven Approach",
    "abstract": "Direct localization (DLOC) methods, which use the observed data to localize a source at an unknown position in a one-step procedure, generally outperform their indirect two-step counterparts (e.g., using time-difference of arrivals). However, underwater acoustic DLOC methods require prior knowledge of the environment, and are computationally costly, hence slow. We propose, what is to the best of our knowledge, the first data-driven DLOC method. Inspired by classical and contemporary optimal model-based DLOC solutions, and leveraging the capabilities of convolutional neural networks (CNNs), we devise a holistic CNN-based solution. Our method includes a specifically-tailored input structure, architecture, loss function, and a progressive training procedure, which are of independent interest in the broader context of machine learning. We demonstrate that our method outperforms attractive alternatives, and asymptotically matches the performance of an oracle optimal model-based solution. ",
    "url": "https://arxiv.org/abs/2207.10222",
    "authors": [
      "Amir Weiss",
      "Toros Arikan",
      "Gregory W. Wornell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.10234",
    "title": "Chance constrained day-ahead robust flexibility needs assessment for low  voltage distribution network",
    "abstract": "For market-based procurement of low voltage (LV) flexibility, DSOs identify the amount of flexibility needed for resolving probable distribution network (DN) voltage and thermal congestion. A framework is required to avoid over or under procurement of flexibility in the presence of uncertainty. To this end, we propose a scenario-based robust chance-constrained (CC) day-ahead flexibility needs assessment (FNA) framework. The CC level is analogous to the risk DSO is willing to take in flexibility planning. Multi-period optimal power flow is performed to calculate the amount of flexibility needed to avoid network issues. Flexibility is defined in terms of nodal power ramp-up and ramp-down and cumulative energy needs over a full day for each node. Future uncertainties are considered as multiple scenarios generated using multivariate Gaussian distribution and Cholesky decomposition. These scenarios are utilized to solve the flexibility needs assessment optimal power flow (FNA-OPF) problem. Zonal clustering of an LV feeder is performed using electrical distance as a measure and spatial partitioning. The FNA tool calculates ramp-up and ramp-down flexibility's power and energy requirements. Energy and power needs are often valued differently in many energy markets. We identify the marginal value of flexibility associated with energy and power needs separately. From numerical results for an LV feeder, it is observed that zonal flexibility needs assessment is more immune to uncertainty than nodal flexibility needs, making it more useful for DSOs to evaluate day-ahead flexibility procurement. We also propose a Pareto optimal mechanism for selecting CC level to reduce flexibility needs while reducing DN congestion. ",
    "url": "https://arxiv.org/abs/2207.10234",
    "authors": [
      "Md Umar Hashmi",
      "Arpan Koirala",
      "Hakan Ergun",
      "Dirk Van Hertem"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.10237",
    "title": "SPIN: An Empirical Evaluation on Sharing Parameters of Isotropic  Networks",
    "abstract": "Recent isotropic networks, such as ConvMixer and vision transformers, have found significant success across visual recognition tasks, matching or outperforming non-isotropic convolutional neural networks (CNNs). Isotropic architectures are particularly well-suited to cross-layer weight sharing, an effective neural network compression technique. In this paper, we perform an empirical evaluation on methods for sharing parameters in isotropic networks (SPIN). We present a framework to formalize major weight sharing design decisions and perform a comprehensive empirical evaluation of this design space. Guided by our experimental results, we propose a weight sharing strategy to generate a family of models with better overall efficiency, in terms of FLOPs and parameters versus accuracy, compared to traditional scaling methods alone, for example compressing ConvMixer by 1.9x while improving accuracy on ImageNet. Finally, we perform a qualitative study to further understand the behavior of weight sharing in isotropic architectures. The code is available at https://github.com/apple/ml-spin. ",
    "url": "https://arxiv.org/abs/2207.10237",
    "authors": [
      "Chien-Yu Lin",
      "Anish Prabhu",
      "Thomas Merth",
      "Sachin Mehta",
      "Anurag Ranjan",
      "Maxwell Horton",
      "Mohammad Rastegari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10241",
    "title": "Unsupervised Legendre-Galerkin Neural Network for Stiff Partial  Differential Equations",
    "abstract": "Machine learning methods have been lately used to solve differential equations and dynamical systems. These approaches have been developed into a novel research field known as scientific machine learning in which techniques such as deep neural networks and statistical learning are applied to classical problems of applied mathematics. Because neural networks provide an approximation capability, computational parameterization through machine learning and optimization methods achieve noticeable performance when solving various partial differential equations (PDEs). In this paper, we develop a novel numerical algorithm that incorporates machine learning and artificial intelligence to solve PDEs. In particular, we propose an unsupervised machine learning algorithm based on the Legendre-Galerkin neural network to find an accurate approximation to the solution of different types of PDEs. The proposed neural network is applied to the general 1D and 2D PDEs as well as singularly perturbed PDEs that possess boundary layer behavior. ",
    "url": "https://arxiv.org/abs/2207.10241",
    "authors": [
      "Junho Choi",
      "Namjung Kim",
      "Youngjoon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10246",
    "title": "GBDF: Gender Balanced DeepFake Dataset Towards Fair DeepFake Detection",
    "abstract": "Facial forgery by deepfakes has raised severe societal concerns. Several solutions have been proposed by the vision community to effectively combat the misinformation on the internet via automated deepfake detection systems. Recent studies have demonstrated that facial analysis-based deep learning models can discriminate based on protected attributes. For the commercial adoption and massive roll-out of the deepfake detection technology, it is vital to evaluate and understand the fairness (the absence of any prejudice or favoritism) of deepfake detectors across demographic variations such as gender and race. As the performance differential of deepfake detectors between demographic subgroups would impact millions of people of the deprived sub-group. This paper aims to evaluate the fairness of the deepfake detectors across males and females. However, existing deepfake datasets are not annotated with demographic labels to facilitate fairness analysis. To this aim, we manually annotated existing popular deepfake datasets with gender labels and evaluated the performance differential of current deepfake detectors across gender. Our analysis on the gender-labeled version of the datasets suggests (a) current deepfake datasets have skewed distribution across gender, and (b) commonly adopted deepfake detectors obtain unequal performance across gender with mostly males outperforming females. Finally, we contributed a gender-balanced and annotated deepfake dataset, GBDF, to mitigate the performance differential and to promote research and development towards fairness-aware deep fake detectors. The GBDF dataset is publicly available at: https://github.com/aakash4305/GBDF ",
    "url": "https://arxiv.org/abs/2207.10246",
    "authors": [
      "Aakash Varma Nadimpalli",
      "Ajita Rattani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10256",
    "title": "SGBANet: Semantic GAN and Balanced Attention Network for Arbitrarily  Oriented Scene Text Recognition",
    "abstract": "Scene text recognition is a challenging task due to the complex backgrounds and diverse variations of text instances. In this paper, we propose a novel Semantic GAN and Balanced Attention Network (SGBANet) to recognize the texts in scene images. The proposed method first generates the simple semantic feature using Semantic GAN and then recognizes the scene text with the Balanced Attention Module. The Semantic GAN aims to align the semantic feature distribution between the support domain and target domain. Different from the conventional image-to-image translation methods that perform at the image level, the Semantic GAN performs the generation and discrimination on the semantic level with the Semantic Generator Module (SGM) and Semantic Discriminator Module (SDM). For target images (scene text images), the Semantic Generator Module generates simple semantic features that share the same feature distribution with support images (clear text images). The Semantic Discriminator Module is used to distinguish the semantic features between the support domain and target domain. In addition, a Balanced Attention Module is designed to alleviate the problem of attention drift. The Balanced Attention Module first learns a balancing parameter based on the visual glimpse vector and semantic glimpse vector, and then performs the balancing operation for obtaining a balanced glimpse vector. Experiments on six benchmarks, including regular datasets, i.e., IIIT5K, SVT, ICDAR2013, and irregular datasets, i.e., ICDAR2015, SVTP, CUTE80, validate the effectiveness of our proposed method. ",
    "url": "https://arxiv.org/abs/2207.10256",
    "authors": [
      "Dajian Zhong",
      "Shujing Lyu",
      "Palaiahnakote Shivakumara",
      "Bing Yin",
      "Jiajia Wu",
      "Umapada Pal",
      "Yue Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10265",
    "title": "FOCUS: Fairness via Agent-Awareness for Federated Learning on  Heterogeneous Data",
    "abstract": "Federated learning (FL) provides an effective paradigm to train machine learning models over distributed data with privacy protection. However, recent studies show that FL is subject to various security, privacy, and fairness threats due to the potentially malicious and heterogeneous local agents. For instance, it is vulnerable to local adversarial agents who only contribute low-quality data, with the goal of harming the performance of those with high-quality data. This kind of attack hence breaks existing definitions of fairness in FL that mainly focus on a certain notion of performance parity. In this work, we aim to address this limitation and propose a formal definition of fairness via agent-awareness for FL (FAA), which takes the heterogeneous data contributions of local agents into account. In addition, we propose a fair FL training algorithm based on agent clustering (FOCUS) to achieve FAA. Theoretically, we prove the convergence and optimality of FOCUS under mild conditions for linear models and general convex loss functions with bounded smoothness. We also prove that FOCUS always achieves higher fairness measured by FAA compared with standard FedAvg protocol under both linear models and general convex loss functions. Empirically, we evaluate FOCUS on four datasets, including synthetic data, images, and texts under different settings, and we show that FOCUS achieves significantly higher fairness based on FAA while maintaining similar or even higher prediction accuracy compared with FedAvg. ",
    "url": "https://arxiv.org/abs/2207.10265",
    "authors": [
      "Wenda Chu",
      "Chulin Xie",
      "Boxin Wang",
      "Linyi Li",
      "Lang Yin",
      "Han Zhao",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.10275",
    "title": "Adversary Detection and Resilient Control for Multi-Agent Systems",
    "abstract": "This paper presents an adversary detection mechanism and a resilient control framework for multi-agent systems under spatiotemporal constraints. Safety in multi-agent systems is typically addressed under the assumption that all agents collaborate to ensure the forward invariance of a desired safe set. This work analyzes agent behaviors based on certain behavior metrics, and designs a proactive adversary detection mechanism based on the notion of the critical region for the system operation. In particular, the presented detection mechanism not only identifies adversarial agents, but also ensures all-time safety for intact agents. Then, based on the analysis and detection results, a resilient QP-based controller is presented to ensure safety and liveness constraints for intact agents. Simulation results validate the efficacy of the presented theoretical contributions. ",
    "url": "https://arxiv.org/abs/2207.10275",
    "authors": [
      "Aquib Mustafa",
      "Dimitra Panagou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.10278",
    "title": "Beyond single receptive field: A receptive field  fusion-and-stratification network for airborne laser scanning point cloud  classification",
    "abstract": "The classification of airborne laser scanning (ALS) point clouds is a critical task of remote sensing and photogrammetry fields. Although recent deep learning-based methods have achieved satisfactory performance, they have ignored the unicity of the receptive field, which makes the ALS point cloud classification remain challenging for the distinguishment of the areas with complex structures and extreme scale variations. In this article, for the objective of configuring multi-receptive field features, we propose a novel receptive field fusion-and-stratification network (RFFS-Net). With a novel dilated graph convolution (DGConv) and its extension annular dilated convolution (ADConv) as basic building blocks, the receptive field fusion process is implemented with the dilated and annular graph fusion (DAGFusion) module, which obtains multi-receptive field feature representation through capturing dilated and annular graphs with various receptive regions. The stratification of the receptive fields with point sets of different resolutions as the calculation bases is performed with Multi-level Decoders nested in RFFS-Net and driven by the multi-level receptive field aggregation loss (MRFALoss) to drive the network to learn in the direction of the supervision labels with different resolutions. With receptive field fusion-and-stratification, RFFS-Net is more adaptable to the classification of regions with complex structures and extreme scale variations in large-scale ALS point clouds. Evaluated on the ISPRS Vaihingen 3D dataset, our RFFS-Net significantly outperforms the baseline approach by 5.3% on mF1 and 5.4% on mIoU, accomplishing an overall accuracy of 82.1%, an mF1 of 71.6%, and an mIoU of 58.2%. Furthermore, experiments on the LASDU dataset and the 2019 IEEE-GRSS Data Fusion Contest dataset show that RFFS-Net achieves a new state-of-the-art classification performance. ",
    "url": "https://arxiv.org/abs/2207.10278",
    "authors": [
      "Yongqiang Mao",
      "Kaiqiang Chen",
      "Wenhui Diao",
      "Xian Sun",
      "Xiaonan Lu",
      "Kun Fu",
      "Martin Weinmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10282",
    "title": "An Evolutionary Game based Secure Clustering Protocol with Fuzzy Trust  Evaluation and Outlier Detection for Wireless Sensor Networks",
    "abstract": "Trustworthy and reliable data delivery is a challenging task in Wireless Sensor Networks (WSNs) due to unique characteristics and constraints. To acquire secured data delivery and address the conflict between security and energy, in this paper we present an evolutionary game based secure clustering protocol with fuzzy trust evaluation and outlier detection for WSNs. Firstly, a fuzzy trust evaluation method is presented to transform the transmission evidences into trust values while effectively alleviating the trust uncertainty. And then, a K-Means based outlier detection scheme is proposed to further analyze plenty of trust values obtained via fuzzy trust evaluation or trust recommendation. It can discover the commonalities and differences among sensor nodes while improving the accuracy of outlier detection. Finally, we present an evolutionary game based secure clustering protocol to achieve a trade-off between security assurance and energy saving for sensor nodes when electing for the cluster heads. A sensor node which failed to be the cluster head can securely choose its own head by isolating the suspicious nodes. Simulation results verify that our secure clustering protocol can effectively defend the network against the attacks from internal selfish or compromised nodes. Correspondingly, the timely data transfer rate can be improved significantly. ",
    "url": "https://arxiv.org/abs/2207.10282",
    "authors": [
      "Liu Yang",
      "Yinzhi Lu",
      "Simon X. Yang",
      "Yuanchang Zhong",
      "Tan Guo",
      "Zhifang Liang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.10283",
    "title": "Switching One-Versus-the-Rest Loss to Increase the Margin of Logits for  Adversarial Robustness",
    "abstract": "Defending deep neural networks against adversarial examples is a key challenge for AI safety. To improve the robustness effectively, recent methods focus on important data points near the decision boundary in adversarial training. However, these methods are vulnerable to Auto-Attack, which is an ensemble of parameter-free attacks for reliable evaluation. In this paper, we experimentally investigate the causes of their vulnerability and find that existing methods reduce margins between logits for the true label and the other labels while keeping their gradient norms non-small values. Reduced margins and non-small gradient norms cause their vulnerability since the largest logit can be easily flipped by the perturbation. Our experiments also show that the histogram of the logit margins has two peaks, i.e., small and large logit margins. From the observations, we propose switching one-versus-the-rest loss (SOVR), which uses one-versus-the-rest loss when data have small logit margins so that it increases the margins. We find that SOVR increases logit margins more than existing methods while keeping gradient norms small and outperforms them in terms of the robustness against Auto-Attack. ",
    "url": "https://arxiv.org/abs/2207.10283",
    "authors": [
      "Sekitoshi Kanai",
      "Shin'ya Yamaguchi",
      "Masanori Yamada",
      "Hiroshi Takahashi",
      "Yasutoshi Ida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.10286",
    "title": "Comparative Study on Supervised versus Semi-supervised Machine Learning  for Anomaly Detection of In-vehicle CAN Network",
    "abstract": "As the central nerve of the intelligent vehicle control system, the in-vehicle network bus is crucial to the security of vehicle driving. One of the best standards for the in-vehicle network is the Controller Area Network (CAN bus) protocol. However, the CAN bus is designed to be vulnerable to various attacks due to its lack of security mechanisms. To enhance the security of in-vehicle networks and promote the research in this area, based upon a large scale of CAN network traffic data with the extracted valuable features, this study comprehensively compared fully-supervised machine learning with semi-supervised machine learning methods for CAN message anomaly detection. Both traditional machine learning models (including single classifier and ensemble models) and neural network based deep learning models are evaluated. Furthermore, this study proposed a deep autoencoder based semi-supervised learning method applied for CAN message anomaly detection and verified its superiority over other semi-supervised methods. Extensive experiments show that the fully-supervised methods generally outperform semi-supervised ones as they are using more information as inputs. Typically the developed XGBoost based model obtained state-of-the-art performance with the best accuracy (98.65%), precision (0.9853), and ROC AUC (0.9585) beating other methods reported in the literature. ",
    "url": "https://arxiv.org/abs/2207.10286",
    "authors": [
      "Yongqi Dong",
      "Kejia Chen",
      "Yinxuan Peng",
      "Zhiyuan Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.10290",
    "title": "AugRmixAT: A Data Processing and Training Method for Improving Multiple  Robustness and Generalization Performance",
    "abstract": "Deep neural networks are powerful, but they also have shortcomings such as their sensitivity to adversarial examples, noise, blur, occlusion, etc. Moreover, ensuring the reliability and robustness of deep neural network models is crucial for their application in safety-critical areas. Much previous work has been proposed to improve specific robustness. However, we find that the specific robustness is often improved at the sacrifice of the additional robustness or generalization ability of the neural network model. In particular, adversarial training methods significantly hurt the generalization performance on unperturbed data when improving adversarial robustness. In this paper, we propose a new data processing and training method, called AugRmixAT, which can simultaneously improve the generalization ability and multiple robustness of neural network models. Finally, we validate the effectiveness of AugRmixAT on the CIFAR-10/100 and Tiny-ImageNet datasets. The experiments demonstrate that AugRmixAT can improve the model's generalization performance while enhancing the white-box robustness, black-box robustness, common corruption robustness, and partial occlusion robustness. ",
    "url": "https://arxiv.org/abs/2207.10290",
    "authors": [
      "Xiaoliang Liu",
      "Furao Shen",
      "Jian Zhao",
      "Changhai Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10292",
    "title": "Image Generation Network for Covert Transmission in Online Social  Network",
    "abstract": "Online social networks have stimulated communications over the Internet more than ever, making it possible for secret message transmission over such noisy channels. In this paper, we propose a Coverless Image Steganography Network, called CIS-Net, that synthesizes a high-quality image directly conditioned on the secret message to transfer. CIS-Net is composed of four modules, namely, the Generation, Adversarial, Extraction, and Noise Module. The receiver can extract the hidden message without any loss even the images have been distorted by JPEG compression attacks. To disguise the behaviour of steganography, we collected images in the context of profile photos and stickers and train our network accordingly. As such, the generated images are more inclined to escape from malicious detection and attack. The distinctions from previous image steganography methods are majorly the robustness and losslessness against diverse attacks. Experiments over diverse public datasets have manifested the superior ability of anti-steganalysis. ",
    "url": "https://arxiv.org/abs/2207.10292",
    "authors": [
      "Zhengxin You",
      "Qichao Ying",
      "Sheng Li",
      "Zhenxing Qian",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10293",
    "title": "Multi-task Cross Attention Network in Facial Behavior Analysis",
    "abstract": "Facial behavior analysis is a broad topic with various categories such as facial emotion recognition, age and gender recognition, ... Many studies focus on individual tasks while the multi-task learning approach is still open and requires more research. In this paper, we present our solution and experiment result for the Multi-Task Learning challenge of the Affective Behavior Analysis in-the-wild competition. The challenge is a combination of three tasks: action unit detection, facial expression recognition and valance-arousal estimation. To address this challenge, we introduce a cross-attentive module to improve multi-task learning performance. Additionally, a facial graph is applied to capture the association among action units. As a result, we achieve the evaluation measure of 1.24 on the validation data provided by the organizers, which is better than the baseline result of 0.30. ",
    "url": "https://arxiv.org/abs/2207.10293",
    "authors": [
      "Dang-Khanh Nguyen",
      "Sudarshan Pant",
      "Ngoc-Huynh Ho",
      "Guee-Sang Lee",
      "Soo-Huyng Kim",
      "Hyung-Jeong Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10296",
    "title": "Perspectives on distribution network flexible and curtailable resource  activation and needs assessment",
    "abstract": "A curtailable and flexible resource activation framework is proposed for solving distribution network (DN) voltage and thermal congestions. This framework utilizes network state in absence of such flexible or curtailable resources as an input for calculating flexibility activation signal (FAS). FAS design is motivated by volt-Var and volt-watt inverter control. The FAS has some similarities with optimal power flow duals, also referred to as locational marginal prices. These dual variables are active in case of network violations. FAS due to drooping design, corrects prior to any network limit violations. The nonlinear resource dispatch optimal power flow (RDOPF) is convexified using second-order cone (SOC) relaxations. Three case studies are performed, which are compared using performance indices proposed in this work. The first case study highlights the multi-objective nature of SOC relaxed RDOPF and provides a Pareto front tuning mechanism for reducing DN losses while also reducing the optimality gap of the SOC relaxed problem with respect to RDOPF. The second case study presents a methodology for evaluating temporal and locational flexibility needs assessment of a DN, which DSO's can utilize for flexibility planning. The last case study quantifies the impact of reactive power flexibility for a DN with varying load power factor. We observe that active power flexibility needs can be reduced by up to 50\\% for DN with power factor of 0.8. ",
    "url": "https://arxiv.org/abs/2207.10296",
    "authors": [
      "Md Umar Hashmi",
      "Arpan Koirala",
      "Hakan Ergun",
      "Dirk Van Hertem"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.10297",
    "title": "Action2Score: An Embedding Approach To Score Player Action",
    "abstract": "Multiplayer Online Battle Arena (MOBA) is one of the most successful game genres. MOBA games such as League of Legends have competitive environments where players race for their rank. In most MOBA games, a player's rank is determined by the match result (win or lose). It seems natural because of the nature of team play, but in some sense, it is unfair because the players who put a lot of effort lose their rank just in case of loss and some players even get free-ride on teammates' efforts in case of a win. To reduce the side-effects of the team-based ranking system and evaluate a player's performance impartially, we propose a novel embedding model that converts a player's actions into quantitative scores based on the actions' respective contribution to the team's victory. Our model is built using a sequence-based deep learning model with a novel loss function working on the team match. The sequence-based deep learning model process the action sequence from the game start to the end of a player in a team play using a GRU unit that takes a hidden state from the previous step and the current input selectively. The loss function is designed to help the action score to reflect the final score and the success of the team. We showed that our model can evaluate a player's individual performance fairly and analyze the contributions of the player's respective actions. ",
    "url": "https://arxiv.org/abs/2207.10297",
    "authors": [
      "Junho Jang",
      "Ji Young Woo",
      "Huy Kang Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10305",
    "title": "Subgraph Matching via Query-Conditioned Subgraph Matching Neural  Networks and Bi-Level Tree Search",
    "abstract": "Recent advances have shown the success of using reinforcement learning and search to solve NP-hard graph-related tasks, such as Traveling Salesman Optimization, Graph Edit Distance computation, etc. However, it remains unclear how one can efficiently and accurately detect the occurrences of a small query graph in a large target graph, which is a core operation in graph database search, biomedical analysis, social group finding, etc. This task is called Subgraph Matching which essentially performs subgraph isomorphism check between a query graph and a large target graph. One promising approach to this classical problem is the \"learning-to-search\" paradigm, where a reinforcement learning (RL) agent is designed with a learned policy to guide a search algorithm to quickly find the solution without any solved instances for supervision. However, for the specific task of Subgraph Matching, though the query graph is usually small given by the user as input, the target graph is often orders-of-magnitude larger. It poses challenges to the neural network design and can lead to solution and reward sparsity. In this paper, we propose N-BLS with two innovations to tackle the challenges: (1) A novel encoder-decoder neural network architecture to dynamically compute the matching information between the query and the target graphs at each search state; (2) A Monte Carlo Tree Search enhanced bi-level search framework for training the policy and value networks. Experiments on five large real-world target graphs show that N-BLS can significantly improve the subgraph matching performance. ",
    "url": "https://arxiv.org/abs/2207.10305",
    "authors": [
      "Yunsheng Bai",
      "Derek Xu",
      "Yizhou Sun",
      "Wei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10307",
    "title": "Knowledge-enhanced Black-box Attacks for Recommendations",
    "abstract": "Recent studies have shown that deep neural networks-based recommender systems are vulnerable to adversarial attacks, where attackers can inject carefully crafted fake user profiles (i.e., a set of items that fake users have interacted with) into a target recommender system to achieve malicious purposes, such as promote or demote a set of target items. Due to the security and privacy concerns, it is more practical to perform adversarial attacks under the black-box setting, where the architecture/parameters and training data of target systems cannot be easily accessed by attackers. However, generating high-quality fake user profiles under black-box setting is rather challenging with limited resources to target systems. To address this challenge, in this work, we introduce a novel strategy by leveraging items' attribute information (i.e., items' knowledge graph), which can be publicly accessible and provide rich auxiliary knowledge to enhance the generation of fake user profiles. More specifically, we propose a knowledge graph-enhanced black-box attacking framework (KGAttack) to effectively learn attacking policies through deep reinforcement learning techniques, in which knowledge graph is seamlessly integrated into hierarchical policy networks to generate fake user profiles for performing adversarial black-box attacks. Comprehensive experiments on various real-world datasets demonstrate the effectiveness of the proposed attacking framework under the black-box setting. ",
    "url": "https://arxiv.org/abs/2207.10307",
    "authors": [
      "Jingfan Chen",
      "Wenqi Fan",
      "Guanghui Zhu",
      "Xiangyu Zhao",
      "Chunfeng Yuan",
      "Qing Li",
      "Yihua Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2207.10309",
    "title": "A Survey on Leveraging Pre-trained Generative Adversarial Networks for  Image Editing and Restoration",
    "abstract": "Generative adversarial networks (GANs) have drawn enormous attention due to the simple yet effective training mechanism and superior image generation quality. With the ability to generate photo-realistic high-resolution (e.g., $1024\\times1024$) images, recent GAN models have greatly narrowed the gaps between the generated images and the real ones. Therefore, many recent works show emerging interest to take advantage of pre-trained GAN models by exploiting the well-disentangled latent space and the learned GAN priors. In this paper, we briefly review recent progress on leveraging pre-trained large-scale GAN models from three aspects, i.e., 1) the training of large-scale generative adversarial networks, 2) exploring and understanding the pre-trained GAN models, and 3) leveraging these models for subsequent tasks like image restoration and editing. More information about relevant methods and repositories can be found at https://github.com/csmliu/pretrained-GANs. ",
    "url": "https://arxiv.org/abs/2207.10309",
    "authors": [
      "Ming Liu",
      "Yuxiang Wei",
      "Xiaohe Wu",
      "Wangmeng Zuo",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.10312",
    "title": "AdaNeRF: Adaptive Sampling for Real-time Rendering of Neural Radiance  Fields",
    "abstract": "Novel view synthesis has recently been revolutionized by learning neural radiance fields directly from sparse observations. However, rendering images with this new paradigm is slow due to the fact that an accurate quadrature of the volume rendering equation requires a large number of samples for each ray. Previous work has mainly focused on speeding up the network evaluations that are associated with each sample point, e.g., via caching of radiance values into explicit spatial data structures, but this comes at the expense of model compactness. In this paper, we propose a novel dual-network architecture that takes an orthogonal direction by learning how to best reduce the number of required sample points. To this end, we split our network into a sampling and shading network that are jointly trained. Our training scheme employs fixed sample positions along each ray, and incrementally introduces sparsity throughout training to achieve high quality even at low sample counts. After fine-tuning with the target number of samples, the resulting compact neural representation can be rendered in real-time. Our experiments demonstrate that our approach outperforms concurrent compact neural representations in terms of quality and frame rate and performs on par with highly efficient hybrid representations. Code and supplementary material is available at https://thomasneff.github.io/adanerf. ",
    "url": "https://arxiv.org/abs/2207.10312",
    "authors": [
      "Andreas Kurz",
      "Thomas Neff",
      "Zhaoyang Lv",
      "Michael Zollh\u00f6fer",
      "Markus Steinberger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2207.10316",
    "title": "AutoAlignV2: Deformable Feature Aggregation for Dynamic Multi-Modal 3D  Object Detection",
    "abstract": "Point clouds and RGB images are two general perceptional sources in autonomous driving. The former can provide accurate localization of objects, and the latter is denser and richer in semantic information. Recently, AutoAlign presents a learnable paradigm in combining these two modalities for 3D object detection. However, it suffers from high computational cost introduced by the global-wise attention. To solve the problem, we propose Cross-Domain DeformCAFA module in this work. It attends to sparse learnable sampling points for cross-modal relational modeling, which enhances the tolerance to calibration error and greatly speeds up the feature aggregation across different modalities. To overcome the complex GT-AUG under multi-modal settings, we design a simple yet effective cross-modal augmentation strategy on convex combination of image patches given their depth information. Moreover, by carrying out a novel image-level dropout training scheme, our model is able to infer in a dynamic manner. To this end, we propose AutoAlignV2, a faster and stronger multi-modal 3D detection framework, built on top of AutoAlign. Extensive experiments on nuScenes benchmark demonstrate the effectiveness and efficiency of AutoAlignV2. Notably, our best model reaches 72.4 NDS on nuScenes test leaderboard, achieving new state-of-the-art results among all published multi-modal 3D object detectors. Code will be available at https://github.com/zehuichen123/AutoAlignV2. ",
    "url": "https://arxiv.org/abs/2207.10316",
    "authors": [
      "Zehui Chen",
      "Zhenyu Li",
      "Shiquan Zhang",
      "Liangji Fang",
      "Qinhong Jiang",
      "Feng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10334",
    "title": "Efficient Search of Multiple Neural Architectures with Different  Complexities via Importance Sampling",
    "abstract": "Neural architecture search (NAS) aims to automate architecture design processes and improve the performance of deep neural networks. Platform-aware NAS methods consider both performance and complexity and can find well-performing architectures with low computational resources. Although ordinary NAS methods result in tremendous computational costs owing to the repetition of model training, one-shot NAS, which trains the weights of a supernetwork containing all candidate architectures only once during the search process, has been reported to result in a lower search cost. This study focuses on the architecture complexity-aware one-shot NAS that optimizes the objective function composed of the weighted sum of two metrics, such as the predictive performance and number of parameters. In existing methods, the architecture search process must be run multiple times with different coefficients of the weighted sum to obtain multiple architectures with different complexities. This study aims at reducing the search cost associated with finding multiple architectures. The proposed method uses multiple distributions to generate architectures with different complexities and updates each distribution using the samples obtained from multiple distributions based on importance sampling. The proposed method allows us to obtain multiple architectures with different complexities in a single architecture search, resulting in reducing the search cost. The proposed method is applied to the architecture search of convolutional neural networks on the CIAFR-10 and ImageNet datasets. Consequently, compared with baseline methods, the proposed method finds multiple architectures with varying complexities while requiring less computational effort. ",
    "url": "https://arxiv.org/abs/2207.10334",
    "authors": [
      "Yuhei Noda",
      "Shota Saito",
      "Shinichi Shirakawa"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.10351",
    "title": "Auto Machine Learning for Medical Image Analysis by Unifying the Search  on Data Augmentation and Neural Architecture",
    "abstract": "Automated data augmentation, which aims at engineering augmentation policy automatically, recently draw a growing research interest. Many previous auto-augmentation methods utilized a Density Matching strategy by evaluating policies in terms of the test-time augmentation performance. In this paper, we theoretically and empirically demonstrated the inconsistency between the train and validation set of small-scale medical image datasets, referred to as in-domain sampling bias. Next, we demonstrated that the in-domain sampling bias might cause the inefficiency of Density Matching. To address the problem, an improved augmentation search strategy, named Augmented Density Matching, was proposed by randomly sampling policies from a prior distribution for training. Moreover, an efficient automatical machine learning(AutoML) algorithm was proposed by unifying the search on data augmentation and neural architecture. Experimental results indicated that the proposed methods outperformed state-of-the-art approaches on MedMNIST, a pioneering benchmark designed for AutoML in medical image analysis. ",
    "url": "https://arxiv.org/abs/2207.10351",
    "authors": [
      "Jianwei Zhang",
      "Dong Li",
      "Lituan Wang",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10355",
    "title": "Unimodal vs. Multimodal Siamese Networks for Outfit Completion",
    "abstract": "The popularity of online fashion shopping continues to grow. The ability to offer an effective recommendation to customers is becoming increasingly important. In this work, we focus on Fashion Outfits Challenge, part of SIGIR 2022 Workshop on eCommerce. The challenge is centered around Fill in the Blank (FITB) task that implies predicting the missing outfit, given an incomplete outfit and a list of candidates. In this paper, we focus on applying siamese networks on the task. More specifically, we explore how combining information from multiple modalities (textual and visual modality) impacts the performance of the model on the task. We evaluate our model on the test split provided by the challenge organizers and the test split with gold assignments that we created during the development phase. We discover that using both visual, and visual and textual data demonstrates promising results on the task. We conclude by suggesting directions for further improvement of our method. ",
    "url": "https://arxiv.org/abs/2207.10355",
    "authors": [
      "Mariya Hendriksen",
      "Viggo Overes"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.10367",
    "title": "EC-KitY: Evolutionary Computation Tool Kit in Python with Seamless  Machine Learning Integration",
    "abstract": "EC-KitY is a comprehensive Python library for doing evolutionary computation (EC), licensed under GNU General Public License v3.0, and compatible with scikit-learn. Designed with modern software engineering and machine learning integration in mind, EC-KitY can support all popular EC paradigms, including genetic algorithms, genetic programming, coevolution, evolutionary multi-objective optimization, and more. This paper provides an overview of the package, including the ease of setting up an EC experiment, the architecture, the main features, and a comparison with other libraries. ",
    "url": "https://arxiv.org/abs/2207.10367",
    "authors": [
      "Moshe Sipper",
      "Tomer Halperin",
      "Itai Tzruia",
      "Achiya Elyasaf"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.10379",
    "title": "Temporal Saliency Query Network for Efficient Video Recognition",
    "abstract": "Efficient video recognition is a hot-spot research topic with the explosive growth of multimedia data on the Internet and mobile devices. Most existing methods select the salient frames without awareness of the class-specific saliency scores, which neglect the implicit association between the saliency of frames and its belonging category. To alleviate this issue, we devise a novel Temporal Saliency Query (TSQ) mechanism, which introduces class-specific information to provide fine-grained cues for saliency measurement. Specifically, we model the class-specific saliency measuring process as a query-response task. For each category, the common pattern of it is employed as a query and the most salient frames are responded to it. Then, the calculated similarities are adopted as the frame saliency scores. To achieve it, we propose a Temporal Saliency Query Network (TSQNet) that includes two instantiations of the TSQ mechanism based on visual appearance similarities and textual event-object relations. Afterward, cross-modality interactions are imposed to promote the information exchange between them. Finally, we use the class-specific saliencies of the most confident categories generated by two modalities to perform the selection of salient frames. Extensive experiments demonstrate the effectiveness of our method by achieving state-of-the-art results on ActivityNet, FCVID and Mini-Kinetics datasets. Our project page is at https://lawrencexia2008.github.io/projects/tsqnet . ",
    "url": "https://arxiv.org/abs/2207.10379",
    "authors": [
      "Boyang Xia",
      "Zhihao Wang",
      "Wenhao Wu",
      "Haoran Wang",
      "Jungong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10395",
    "title": "Sobolev Training for Implicit Neural Representations with Approximated  Image Derivatives",
    "abstract": "Recently, Implicit Neural Representations (INRs) parameterized by neural networks have emerged as a powerful and promising tool to represent different kinds of signals due to its continuous, differentiable properties, showing superiorities to classical discretized representations. However, the training of neural networks for INRs only utilizes input-output pairs, and the derivatives of the target output with respect to the input, which can be accessed in some cases, are usually ignored. In this paper, we propose a training paradigm for INRs whose target output is image pixels, to encode image derivatives in addition to image values in the neural network. Specifically, we use finite differences to approximate image derivatives. We show how the training paradigm can be leveraged to solve typical INRs problems, i.e., image regression and inverse rendering, and demonstrate this training paradigm can improve the data-efficiency and generalization capabilities of INRs. The code of our method is available at \\url{https://github.com/megvii-research/Sobolev_INRs}. ",
    "url": "https://arxiv.org/abs/2207.10395",
    "authors": [
      "Wentao Yuan",
      "Qingtian Zhu",
      "Xiangyue Liu",
      "Yikang Ding",
      "Haotian Zhang",
      "Chi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10397",
    "title": "CodeT: Code Generation with Generated Tests",
    "abstract": "Given a programming problem, pre-trained language models such as Codex have demonstrated the ability to generate multiple different code solutions via sampling. However, selecting a correct or best solution from those samples still remains a challenge. While an easy way to verify the correctness of a code solution is through executing test cases, producing high-quality test cases is prohibitively expensive. In this paper, we explore the use of pre-trained language models to automatically generate test cases, calling our method CodeT: Code generation with generated Tests. CodeT executes the code solutions using the generated test cases, and then chooses the best solution based on a dual execution agreement with both the generated test cases and other generated solutions. We evaluate CodeT on five different pre-trained models with both HumanEval and MBPP benchmarks. Extensive experimental results demonstrate CodeT can achieve significant, consistent, and surprising improvements over previous methods. For example, CodeT improves the pass@1 on HumanEval to 65.8%, an increase of absolute 18.8% on the code-davinci-002 model, and an absolute 20+% improvement over previous state-of-the-art results. ",
    "url": "https://arxiv.org/abs/2207.10397",
    "authors": [
      "Bei Chen",
      "Fengji Zhang",
      "Anh Nguyen",
      "Daoguang Zan",
      "Zeqi Lin",
      "Jian-Guang Lou",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2207.10398",
    "title": "D2-TPred: Discontinuous Dependency for Trajectory Prediction under  Traffic Lights",
    "abstract": "A profound understanding of inter-agent relationships and motion behaviors is important to achieve high-quality planning when navigating in complex scenarios, especially at urban traffic intersections. We present a trajectory prediction approach with respect to traffic lights, D2-TPred, which uses a spatial dynamic interaction graph (SDG) and a behavior dependency graph (BDG) to handle the problem of discontinuous dependency in the spatial-temporal space. Specifically, the SDG is used to capture spatial interactions by reconstructing sub-graphs for different agents with dynamic and changeable characteristics during each frame. The BDG is used to infer motion tendency by modeling the implicit dependency of the current state on priors behaviors, especially the discontinuous motions corresponding to acceleration, deceleration, or turning direction. Moreover, we present a new dataset for vehicle trajectory prediction under traffic lights called VTP-TL. Our experimental results show that our model achieves more than {20.45% and 20.78% }improvement in terms of ADE and FDE, respectively, on VTP-TL as compared to other trajectory prediction algorithms. The dataset and code are available at: https://github.com/VTP-TL/D2-TPred. ",
    "url": "https://arxiv.org/abs/2207.10398",
    "authors": [
      "Yuzhen Zhang",
      "Wentong Wang",
      "Weizhi Guo",
      "Pei Lv",
      "Mingliang Xu",
      "Wei Chen",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10401",
    "title": "Detection and Mitigation of Corrupted Information in Distributed Model  Predictive Control Based on Resource Allocation",
    "abstract": "In distributed predictive control structures, communication among agents is required to achieve a consensus and approach an optimal global behavior. Such negotiation mechanisms are sensitive to attacks on these exchanges. This paper proposes a monitoring scheme that detects and mitigates these attacks' effects in a resource allocation framework. The performance of the proposed method is illustrated through simulations of the temperature control of multiple rooms under power scarcity. ",
    "url": "https://arxiv.org/abs/2207.10401",
    "authors": [
      "Rafael Acc\u00e1cio Nogueira",
      "Romain Bourdais",
      "Herv\u00e9 Gu\u00e9guen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2207.10422",
    "title": "Differentiable Integrated Motion Prediction and Planning with Learnable  Cost Function for Autonomous Driving",
    "abstract": "Predicting the future states of surrounding traffic participants and planning a safe, smooth, and socially compliant trajectory accordingly is crucial for autonomous vehicles. There are two major issues with the current autonomous driving system: the prediction module is often decoupled from the planning module and the cost function for planning is hard to specify and tune. To tackle these issues, we propose an end-to-end differentiable framework that integrates prediction and planning modules and is able to learn the cost function from data. Specifically, we employ a differentiable nonlinear optimizer as the motion planner, which takes the predicted trajectories of surrounding agents given by the neural network as input and optimizes the trajectory for the autonomous vehicle, thus enabling all operations in the framework to be differentiable including the cost function weights. The proposed framework is trained on a large-scale real-world driving dataset to imitate human driving trajectories in the entire driving scene and validated in both open-loop and closed-loop manners. The open-loop testing results reveal that the proposed method outperforms the baseline methods across a variety of metrics and delivers planning-centric prediction results, allowing the planning module to output close-to-human trajectories. In closed-loop testing, the proposed method shows the ability to handle complex urban driving scenarios and robustness against the distributional shift that imitation learning methods suffer from. Importantly, we find that joint training of planning and prediction modules achieves better performance than planning with a separate trained prediction module in both open-loop and closed-loop tests. Moreover, the ablation study indicates that the learnable components in the framework are essential to ensure planning stability and performance. ",
    "url": "https://arxiv.org/abs/2207.10422",
    "authors": [
      "Zhiyu Huang",
      "Haochen Liu",
      "Jingda Wu",
      "Chen Lv"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.10425",
    "title": "KD-MVS: Knowledge Distillation Based Self-supervised Learning for MVS",
    "abstract": "Supervised multi-view stereo (MVS) methods have achieved remarkable progress in terms of reconstruction quality, but suffer from the challenge of collecting large-scale ground-truth depth. In this paper, we propose a novel self-supervised training pipeline for MVS based on knowledge distillation, termed \\textit{KD-MVS}, which mainly consists of self-supervised teacher training and distillation-based student training. Specifically, the teacher model is trained in a self-supervised fashion using both photometric and featuremetric consistency. Then we distill the knowledge of the teacher model to the student model through probabilistic knowledge transferring. With the supervision of validated knowledge, the student model is able to outperform its teacher by a large margin. Extensive experiments performed on multiple datasets show our method can even outperform supervised methods. ",
    "url": "https://arxiv.org/abs/2207.10425",
    "authors": [
      "Yikang Ding",
      "Qingtian Zhu",
      "Xiangyue Liu",
      "Wentao Yuan",
      "Haotian Zhang",
      "CHi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10430",
    "title": "The Neural Race Reduction: Dynamics of Abstraction in Gated Networks",
    "abstract": "Our theoretical understanding of deep learning has not kept pace with its empirical success. While network architecture is known to be critical, we do not yet understand its effect on learned representations and network behavior, or how this architecture should reflect task structure.In this work, we begin to address this gap by introducing the Gated Deep Linear Network framework that schematizes how pathways of information flow impact learning dynamics within an architecture. Crucially, because of the gating, these networks can compute nonlinear functions of their input. We derive an exact reduction and, for certain cases, exact solutions to the dynamics of learning. Our analysis demonstrates that the learning dynamics in structured networks can be conceptualized as a neural race with an implicit bias towards shared representations, which then govern the model's ability to systematically generalize, multi-task, and transfer. We validate our key insights on naturalistic datasets and with relaxed assumptions. Taken together, our work gives rise to general hypotheses relating neural architecture to learning and provides a mathematical approach towards understanding the design of more complex architectures and the role of modularity and compositionality in solving real-world problems. The code and results are available at https://www.saxelab.org/gated-dln . ",
    "url": "https://arxiv.org/abs/2207.10430",
    "authors": [
      "Andrew M. Saxe",
      "Shagun Sodhani",
      "Sam Lewallen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.10432",
    "title": "A Wavelet Transform and self-supervised learning-based framework for  bearing fault diagnosis with limited labeled data",
    "abstract": "Traditional supervised bearing fault diagnosis methods rely on massive labelled data, yet annotations may be very time-consuming or infeasible. The fault diagnosis approach that utilizes limited labelled data is becoming increasingly popular. In this paper, a Wavelet Transform (WT) and self-supervised learning-based bearing fault diagnosis framework is proposed to address the lack of supervised samples issue. Adopting the WT and cubic spline interpolation technique, original measured vibration signals are converted to the time-frequency maps (TFMs) with a fixed scale as inputs. The Vision Transformer (ViT) is employed as the encoder for feature extraction, and the self-distillation with no labels (DINO) algorithm is introduced in the proposed framework for self-supervised learning with limited labelled data and sufficient unlabeled data. Two rolling bearing fault datasets are used for validations. In the case of both datasets only containing 1% labelled samples, utilizing the feature vectors extracted by the trained encoder without fine-tuning, over 90\\% average diagnosis accuracy can be obtained based on the simple K-Nearest Neighbor (KNN) classifier. Furthermore, the superiority of the proposed method is demonstrated in comparison with other self-supervised fault diagnosis methods. ",
    "url": "https://arxiv.org/abs/2207.10432",
    "authors": [
      "Yuhong Jin",
      "Lei Hou",
      "Ming Du",
      "Yushu Chen"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2207.10433",
    "title": "StreamYOLO: Real-time Object Detection for Streaming Perception",
    "abstract": "The perceptive models of autonomous driving require fast inference within a low latency for safety. While existing works ignore the inevitable environmental changes after processing, streaming perception jointly evaluates the latency and accuracy into a single metric for video online perception, guiding the previous works to search trade-offs between accuracy and speed. In this paper, we explore the performance of real time models on this metric and endow the models with the capacity of predicting the future, significantly improving the results for streaming perception. Specifically, we build a simple framework with two effective modules. One is a Dual Flow Perception module (DFP). It consists of dynamic flow and static flow in parallel to capture moving tendency and basic detection feature, respectively. Trend Aware Loss (TAL) is the other module which adaptively generates loss weight for each object with its moving speed. Realistically, we consider multiple velocities driving scene and further propose Velocity-awared streaming AP (VsAP) to jointly evaluate the accuracy. In this realistic setting, we design a efficient mix-velocity training strategy to guide detector perceive any velocities. Our simple method achieves the state-of-the-art performance on Argoverse-HD dataset and improves the sAP and VsAP by 4.7% and 8.2% respectively compared to the strong baseline, validating its effectiveness. ",
    "url": "https://arxiv.org/abs/2207.10433",
    "authors": [
      "Jinrong Yang",
      "Songtao Liu",
      "Zeming Li",
      "Xiaoping Li",
      "Jian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10434",
    "title": "DC-ShadowNet: Single-Image Hard and Soft Shadow Removal Using  Unsupervised Domain-Classifier Guided Network",
    "abstract": "Shadow removal from a single image is generally still an open problem. Most existing learning-based methods use supervised learning and require a large number of paired images (shadow and corresponding non-shadow images) for training. A recent unsupervised method, Mask-ShadowGAN, addresses this limitation. However, it requires a binary mask to represent shadow regions, making it inapplicable to soft shadows. To address the problem, in this paper, we propose an unsupervised domain-classifier guided shadow removal network, DC-ShadowNet. Specifically, we propose to integrate a shadow/shadow-free domain classifier into a generator and its discriminator, enabling them to focus on shadow regions. To train our network, we introduce novel losses based on physics-based shadow-free chromaticity, shadow-robust perceptual features, and boundary smoothness. Moreover, we show that our unsupervised network can be used for test-time training that further improves the results. Our experiments show that all these novel components allow our method to handle soft shadows, and also to perform better on hard shadows both quantitatively and qualitatively than the existing state-of-the-art shadow removal methods. ",
    "url": "https://arxiv.org/abs/2207.10434",
    "authors": [
      "Yeying Jin",
      "Aashish Sharma",
      "Robby T. Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10435",
    "title": "Human Trajectory Prediction via Neural Social Physics",
    "abstract": "Trajectory prediction has been widely pursued in many fields, and many model-based and model-free methods have been explored. The former include rule-based, geometric or optimization-based models, and the latter are mainly comprised of deep learning approaches. In this paper, we propose a new method combining both methodologies based on a new Neural Differential Equation model. Our new model (Neural Social Physics or NSP) is a deep neural network within which we use an explicit physics model with learnable parameters. The explicit physics model serves as a strong inductive bias in modeling pedestrian behaviors, while the rest of the network provides a strong data-fitting capability in terms of system parameter estimation and dynamics stochasticity modeling. We compare NSP with 15 recent deep learning methods on 6 datasets and improve the state-of-the-art performance by 5.56%-70%. Besides, we show that NSP has better generalizability in predicting plausible trajectories in drastically different scenarios where the density is 2-5 times as high as the testing data. Finally, we show that the physics model in NSP can provide plausible explanations for pedestrian behaviors, as opposed to black-box deep learning. Code is available: https://github.com/realcrane/Human-Trajectory-Prediction-via-Neural-Social-Physics. ",
    "url": "https://arxiv.org/abs/2207.10435",
    "authors": [
      "Jiangbei Yue",
      "Dinesh Manocha",
      "He Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10436",
    "title": "Mining Relations among Cross-Frame Affinities for Video Semantic  Segmentation",
    "abstract": "The essence of video semantic segmentation (VSS) is how to leverage temporal information for prediction. Previous efforts are mainly devoted to developing new techniques to calculate the cross-frame affinities such as optical flow and attention. Instead, this paper contributes from a different angle by mining relations among cross-frame affinities, upon which better temporal information aggregation could be achieved. We explore relations among affinities in two aspects: single-scale intrinsic correlations and multi-scale relations. Inspired by traditional feature processing, we propose Single-scale Affinity Refinement (SAR) and Multi-scale Affinity Aggregation (MAA). To make it feasible to execute MAA, we propose a Selective Token Masking (STM) strategy to select a subset of consistent reference tokens for different scales when calculating affinities, which also improves the efficiency of our method. At last, the cross-frame affinities strengthened by SAR and MAA are adopted for adaptively aggregating temporal information. Our experiments demonstrate that the proposed method performs favorably against state-of-the-art VSS methods. The code is publicly available at https://github.com/GuoleiSun/VSS-MRCFA ",
    "url": "https://arxiv.org/abs/2207.10436",
    "authors": [
      "Guolei Sun",
      "Yun Liu",
      "Hao Tang",
      "Ajad Chhatkuli",
      "Le Zhang",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10448",
    "title": "An Efficient Spatio-Temporal Pyramid Transformer for Action Detection",
    "abstract": "The task of action detection aims at deducing both the action category and localization of the start and end moment for each action instance in a long, untrimmed video. While vision Transformers have driven the recent advances in video understanding, it is non-trivial to design an efficient architecture for action detection due to the prohibitively expensive self-attentions over a long sequence of video clips. To this end, we present an efficient hierarchical Spatio-Temporal Pyramid Transformer (STPT) for action detection, building upon the fact that the early self-attention layers in Transformers still focus on local patterns. Specifically, we propose to use local window attention to encode rich local spatio-temporal representations in the early stages while applying global attention modules to capture long-term space-time dependencies in the later stages. In this way, our STPT can encode both locality and dependency with largely reduced redundancy, delivering a promising trade-off between accuracy and efficiency. For example, with only RGB input, the proposed STPT achieves 53.6% mAP on THUMOS14, surpassing I3D+AFSD RGB model by over 10% and performing favorably against state-of-the-art AFSD that uses additional flow features with 31% fewer GFLOPs, which serves as an effective and efficient end-to-end Transformer-based framework for action detection. ",
    "url": "https://arxiv.org/abs/2207.10448",
    "authors": [
      "Yuetian Weng",
      "Zizheng Pan",
      "Mingfei Han",
      "Xiaojun Chang",
      "Bohan Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10482",
    "title": "LPYOLO: Low Precision YOLO for Face Detection on FPGA",
    "abstract": "In recent years, number of edge computing devices and artificial intelligence applications on them have advanced excessively. In edge computing, decision making processes and computations are moved from servers to edge devices. Hence, cheap and low power devices are required. FPGAs are very low power, inclined to do parallel operations and deeply suitable devices for running Convolutional Neural Networks (CNN) which are the fundamental unit of an artificial intelligence application. Face detection on surveillance systems is the most expected application on the security market. In this work, TinyYolov3 architecture is redesigned and deployed for face detection. It is a CNN based object detection method and developed for embedded systems. PYNQ-Z2 is selected as a target board which has low-end Xilinx Zynq 7020 System-on-Chip (SoC) on it. Redesigned TinyYolov3 model is defined in numerous bit width precisions with Brevitas library which brings fundamental CNN layers and activations in integer quantized form. Then, the model is trained in a quantized structure with WiderFace dataset. In order to decrease latency and power consumption, onchip memory of the FPGA is configured as a storage of whole network parameters and the last activation function is modified as rescaled HardTanh instead of Sigmoid. Also, high degree of parallelism is applied to logical resources of the FPGA. The model is converted to an HLS based application with using FINN framework and FINN-HLS library which includes the layer definitions in C++. Later, the model is synthesized and deployed. CPU of the SoC is employed with multithreading mechanism and responsible for preprocessing, postprocessing and TCP/IP streaming operations. Consequently, 2.4 Watt total board power consumption, 18 Frames-Per-Second (FPS) throughput and 0.757 mAP accuracy rate on Easy category of the WiderFace are achieved with 4 bits precision model. ",
    "url": "https://arxiv.org/abs/2207.10482",
    "authors": [
      "Bestami G\u00fcnay",
      "Sefa Burak Okcu",
      "Hasan \u015eakir Bilge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10483",
    "title": "Noncommutative extensions of parameters in the asymptotic spectrum of  graphs",
    "abstract": "The zero-error capacity of a classical channel is a parameter of its confusability graph, and is equal to the minimum of the values of graph parameters that are additive under the disjoint union, multiplicative under the strong product, monotone under homomorphisms between the complements, and normalized. We show that any such function either has uncountably many extensions to noncommutative graphs with similar properties, or no such extensions at all. More precisely, we find that every extension has an exponent that characterizes its values on the confusability graphs of identity quantum channels, and the set of admissible exponents is either an unbounded subinterval of $[1,\\infty)$ or empty. In particular, the set of admissible exponents for the Lov\\'asz number, the projective rank, and the fractional Haemers bound over the complex numbers are maximal, while the fractional clique cover number does not have any extensions. ",
    "url": "https://arxiv.org/abs/2207.10483",
    "authors": [
      "P\u00e9ter Vrana"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2207.10498",
    "title": "Towards Efficient Adversarial Training on Vision Transformers",
    "abstract": "Vision Transformer (ViT), as a powerful alternative to Convolutional Neural Network (CNN), has received much attention. Recent work showed that ViTs are also vulnerable to adversarial examples like CNNs. To build robust ViTs, an intuitive way is to apply adversarial training since it has been shown as one of the most effective ways to accomplish robust CNNs. However, one major limitation of adversarial training is its heavy computational cost. The self-attention mechanism adopted by ViTs is a computationally intense operation whose expense increases quadratically with the number of input patches, making adversarial training on ViTs even more time-consuming. In this work, we first comprehensively study fast adversarial training on a variety of vision transformers and illustrate the relationship between the efficiency and robustness. Then, to expediate adversarial training on ViTs, we propose an efficient Attention Guided Adversarial Training mechanism. Specifically, relying on the specialty of self-attention, we actively remove certain patch embeddings of each layer with an attention-guided dropping strategy during adversarial training. The slimmed self-attention modules accelerate the adversarial training on ViTs significantly. With only 65\\% of the fast adversarial training time, we match the state-of-the-art results on the challenging ImageNet benchmark. ",
    "url": "https://arxiv.org/abs/2207.10498",
    "authors": [
      "Boxi Wu",
      "Jindong Gu",
      "Zhifeng Li",
      "Deng Cai",
      "Xiaofei He",
      "Wei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10506",
    "title": "Multi-modal Retinal Image Registration Using a Keypoint-Based Vessel  Structure Aligning Network",
    "abstract": "In ophthalmological imaging, multiple imaging systems, such as color fundus, infrared, fluorescein angiography, optical coherence tomography (OCT) or OCT angiography, are often involved to make a diagnosis of retinal disease. Multi-modal retinal registration techniques can assist ophthalmologists by providing a pixel-based comparison of aligned vessel structures in images from different modalities or acquisition times. To this end, we propose an end-to-end trainable deep learning method for multi-modal retinal image registration. Our method extracts convolutional features from the vessel structure for keypoint detection and description and uses a graph neural network for feature matching. The keypoint detection and description network and graph neural network are jointly trained in a self-supervised manner using synthetic multi-modal image pairs and are guided by synthetically sampled ground truth homographies. Our method demonstrates higher registration accuracy as competing methods for our synthetic retinal dataset and generalizes well for our real macula dataset and a public fundus dataset. ",
    "url": "https://arxiv.org/abs/2207.10506",
    "authors": [
      "Aline Sindel",
      "Bettina Hohberger",
      "Andreas Maier",
      "Vincent Christlein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10517",
    "title": "MQRetNN: Multi-Horizon Time Series Forecasting with Retrieval  Augmentation",
    "abstract": "Multi-horizon probabilistic time series forecasting has wide applicability to real-world tasks such as demand forecasting. Recent work in neural time-series forecasting mainly focus on the use of Seq2Seq architectures. For example, MQTransformer - an improvement of MQCNN - has shown the state-of-the-art performance in probabilistic demand forecasting. In this paper, we consider incorporating cross-entity information to enhance model performance by adding a cross-entity attention mechanism along with a retrieval mechanism to select which entities to attend over. We demonstrate how our new neural architecture, MQRetNN, leverages the encoded contexts from a pretrained baseline model on the entire population to improve forecasting accuracy. Using MQCNN as the baseline model (due to computational constraints, we do not use MQTransformer), we first show on a small demand forecasting dataset that it is possible to achieve ~3% improvement in test loss by adding a cross-entity attention mechanism where each entity attends to all others in the population. We then evaluate the model with our proposed retrieval methods - as a means of approximating an attention over a large population - on a large-scale demand forecasting application with over 2 million products and observe ~1% performance gain over the MQCNN baseline. ",
    "url": "https://arxiv.org/abs/2207.10517",
    "authors": [
      "Sitan Yang",
      "Carson Eisenach",
      "Dhruv Madeka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.10530",
    "title": "Neural Network Learning of Chemical Bond Representations in Spectral  Indices and Features",
    "abstract": "In this paper we investigate neural networks for classification in hyperspectral imaging with a focus on connecting the architecture of the network with the physics of the sensing and materials present. Spectroscopy is the process of measuring light reflected or emitted by a material as a function wavelength. Molecular bonds present in the material have vibrational frequencies which affect the amount of light measured at each wavelength. Thus the measured spectrum contains information about the particular chemical constituents and types of bonds. For example, chlorophyll reflects more light in the near-IR rage (800-900nm) than in the red (625-675nm) range, and this difference can be measured using a normalized vegetation difference index (NDVI), which is commonly used to detect vegetation presence, health, and type in imagery collected at these wavelengths. In this paper we show that the weights in a Neural Network trained on different vegetation classes learn to measure this difference in reflectance. We then show that a Neural Network trained on a more complex set of ten different polymer materials will learn spectral 'features' evident in the weights for the network, and these features can be used to reliably distinguish between the different types of polymers. Examination of the weights provides a human-interpretable understanding of the network. ",
    "url": "https://arxiv.org/abs/2207.10530",
    "authors": [
      "Bill Basener"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Instrumentation and Detectors (physics.ins-det)"
    ]
  },
  {
    "id": "arXiv:2207.10547",
    "title": "Surrey System for DCASE 2022 Task 5: Few-shot Bioacoustic Event  Detection with Segment-level Metric Learning",
    "abstract": "Few-shot audio event detection is a task that detects the occurrence time of a novel sound class given a few examples. In this work, we propose a system based on segment-level metric learning for the DCASE 2022 challenge of few-shot bioacoustic event detection (task 5). We make better utilization of the negative data within each sound class to build the loss function, and use transductive inference to gain better adaptation on the evaluation set. For the input feature, we find the per-channel energy normalization concatenated with delta mel-frequency cepstral coefficients to be the most effective combination. We also introduce new data augmentation and post-processing procedures for this task. Our final system achieves an f-measure of 68.74 on the DCASE task 5 validation set, outperforming the baseline performance of 29.5 by a large margin. Our system is fully open-sourced at https://github.com/haoheliu/DCASE_2022_Task_5. ",
    "url": "https://arxiv.org/abs/2207.10547",
    "authors": [
      "Haohe Liu",
      "Xubo Liu",
      "Xinhao Mei",
      "Qiuqiang Kong",
      "Wenwu Wang",
      "Mark D. Plumbley"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.10553",
    "title": "The MABe22 Benchmarks for Representation Learning of Multi-Agent  Behavior",
    "abstract": "Real-world behavior is often shaped by complex interactions between multiple agents. To scalably study multi-agent behavior, advances in unsupervised and self-supervised learning have enabled a variety of different behavioral representations to be learned from trajectory data. To date, there does not exist a unified set of benchmarks that can enable comparing methods quantitatively and systematically across a broad set of behavior analysis settings. We aim to address this by introducing a large-scale, multi-agent trajectory dataset from real-world behavioral neuroscience experiments that covers a range of behavior analysis tasks. Our dataset consists of trajectory data from common model organisms, with 9.6 million frames of mouse data and 4.4 million frames of fly data, in a variety of experimental settings, such as different strains, lengths of interaction, and optogenetic stimulation. A subset of the frames also consist of expert-annotated behavior labels. Improvements on our dataset corresponds to behavioral representations that work across multiple organisms and is able to capture differences for common behavior analysis tasks. ",
    "url": "https://arxiv.org/abs/2207.10553",
    "authors": [
      "Jennifer J. Sun",
      "Andrew Ulmer",
      "Dipam Chakraborty",
      "Brian Geuther",
      "Edward Hayes",
      "Heng Jia",
      "Vivek Kumar",
      "Zachary Partridge",
      "Alice Robie",
      "Catherine E. Schretter",
      "Chao Sun",
      "Keith Sheppard",
      "Param Uttarwar",
      "Pietro Perona",
      "Yisong Yue",
      "Kristin Branson",
      "Ann Kennedy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2207.10562",
    "title": "CheckINN: Wide Range Neural Network Verification in Imandra",
    "abstract": "Neural networks are increasingly relied upon as components of complex safety-critical systems such as autonomous vehicles. There is high demand for tools and methods that embed neural network verification in a larger verification cycle. However, neural network verification is difficult due to a wide range of verification properties of interest, each typically only amenable to verification in specialised solvers. In this paper, we show how Imandra, a functional programming language and a theorem prover originally designed for verification, validation and simulation of financial infrastructure can offer a holistic infrastructure for neural network verification. We develop a novel library CheckINN that formalises neural networks in Imandra, and covers different important facets of neural network verification. ",
    "url": "https://arxiv.org/abs/2207.10562",
    "authors": [
      "Remi Desmartin",
      "Grant Passmore",
      "Ekaterina Komendantskaya",
      "Matthew Daggitt"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2207.10574",
    "title": "Face-to-Face Co-Located Human-Human Social Interaction Analysis using  Nonverbal Cues: A Survey",
    "abstract": "This work presents a systematic review of recent efforts (since 2010) aimed at automatic analysis of nonverbal cues displayed in face-to-face co-located human-human social interactions. The main reason for focusing on nonverbal cues is that these are the physical, machine detectable traces of social and psychological phenomena. Therefore, detecting and understanding nonverbal cues means, at least to a certain extent, to detect and understand social and psychological phenomena. The covered topics are categorized into three as: a) modeling social traits, such as leadership, dominance, personality traits, b) social role recognition and social relations detection and c) interaction dynamics analysis in terms of group cohesion, empathy, rapport and so forth. We target the co-located interactions, in which the interactants are always humans. The survey covers a wide spectrum of settings and scenarios, including free-standing interactions, meetings, indoor and outdoor social exchanges, dyadic conversations, and crowd dynamics. For each of them, the survey considers the three main elements of nonverbal cues analysis, namely data, sensing approaches and computational methodologies. The goal is to highlight the main advances of the last decade, to point out existing limitations, and to outline future directions. ",
    "url": "https://arxiv.org/abs/2207.10574",
    "authors": [
      "Cigdem Beyan",
      "Alessandro Vinciarelli",
      "Alessio Del Bue"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.10582",
    "title": "Designing An Illumination-Aware Network for Deep Image Relighting",
    "abstract": "Lighting is a determining factor in photography that affects the style, expression of emotion, and even quality of images. Creating or finding satisfying lighting conditions, in reality, is laborious and time-consuming, so it is of great value to develop a technology to manipulate illumination in an image as post-processing. Although previous works have explored techniques based on the physical viewpoint for relighting images, extensive supervisions and prior knowledge are necessary to generate reasonable images, restricting the generalization ability of these works. In contrast, we take the viewpoint of image-to-image translation and implicitly merge ideas of the conventional physical viewpoint. In this paper, we present an Illumination-Aware Network (IAN) which follows the guidance from hierarchical sampling to progressively relight a scene from a single image with high efficiency. In addition, an Illumination-Aware Residual Block (IARB) is designed to approximate the physical rendering process and to extract precise descriptors of light sources for further manipulations. We also introduce a depth-guided geometry encoder for acquiring valuable geometry- and structure-related representations once the depth information is available. Experimental results show that our proposed method produces better quantitative and qualitative relighting results than previous state-of-the-art methods. The code and models are publicly available on https://github.com/NK-CS-ZZL/IAN. ",
    "url": "https://arxiv.org/abs/2207.10582",
    "authors": [
      "Zuo-Liang Zhu",
      "Zhen Li",
      "Rui-Xun Zhang",
      "Chun-Le Guo",
      "Ming-Ming Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10589",
    "title": "Boosting 3D Object Detection via Object-Focused Image Fusion",
    "abstract": "3D object detection has achieved remarkable progress by taking point clouds as the only input. However, point clouds often suffer from incomplete geometric structures and the lack of semantic information, which makes detectors hard to accurately classify detected objects. In this work, we focus on how to effectively utilize object-level information from images to boost the performance of point-based 3D detector. We present DeMF, a simple yet effective method to fuse image information into point features. Given a set of point features and image feature maps, DeMF adaptively aggregates image features by taking the projected 2D location of the 3D point as reference. We evaluate our method on the challenging SUN RGB-D dataset, improving state-of-the-art results by a large margin (+2.1 mAP@0.25 and +2.3mAP@0.5). Code is available at https://github.com/haoy945/DeMF. ",
    "url": "https://arxiv.org/abs/2207.10589",
    "authors": [
      "Hao Yang",
      "Chen Shi",
      "Yihong Chen",
      "Liwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10603",
    "title": "Unsupervised pre-training of graph transformers on patient population  graphs",
    "abstract": "Pre-training has shown success in different areas of machine learning, such as Computer Vision, Natural Language Processing (NLP), and medical imaging. However, it has not been fully explored for clinical data analysis. An immense amount of clinical records are recorded, but still, data and labels can be scarce for data collected in small hospitals or dealing with rare diseases. In such scenarios, pre-training on a larger set of unlabelled clinical data could improve performance. In this paper, we propose novel unsupervised pre-training techniques designed for heterogeneous, multi-modal clinical data for patient outcome prediction inspired by masked language modeling (MLM), by leveraging graph deep learning over population graphs. To this end, we further propose a graph-transformer-based network, designed to handle heterogeneous clinical data. By combining masking-based pre-training with a transformer-based network, we translate the success of masking-based pre-training in other domains to heterogeneous clinical data. We show the benefit of our pre-training method in a self-supervised and a transfer learning setting, utilizing three medical datasets TADPOLE, MIMIC-III, and a Sepsis Prediction Dataset. We find that our proposed pre-training methods help in modeling the data at a patient and population level and improve performance in different fine-tuning tasks on all datasets. ",
    "url": "https://arxiv.org/abs/2207.10603",
    "authors": [
      "Chantal Pellegrini",
      "Nassir Navab",
      "Anees Kazi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10617",
    "title": "Leveraging Natural Supervision for Language Representation Learning and  Generation",
    "abstract": "Recent breakthroughs in Natural Language Processing (NLP) have been driven by language models trained on a massive amount of plain text. While powerful, deriving supervision from textual resources is still an open question. For example, language model pretraining often neglects the rich, freely-available structures in textual data. In this thesis, we describe three lines of work that seek to improve the training and evaluation of neural models using naturally-occurring supervision. We first investigate self-supervised training losses to help enhance the performance of pretrained language models for various NLP tasks. Specifically, we alter the sentence prediction loss to make it better suited to other pretraining losses and more challenging to solve. We design an intermediate finetuning step that uses self-supervised training to promote models' ability in cross-task generalization. Then we describe methods to leverage the structures in Wikipedia and paraphrases. In particular, we propose training losses to exploit hyperlinks, article structures, and article category graphs for entity-, discourse-, entailment-related knowledge. We propose a framework that uses paraphrase pairs to disentangle semantics and syntax in sentence representations. We extend the framework for a novel generation task that controls the syntax of output text with a sentential exemplar. Lastly, we discuss our work on tailoring textual resources for establishing challenging evaluation tasks. We introduce three datasets by defining novel tasks using various fan-contributed websites, including a long-form data-to-text generation dataset, a screenplay summarization dataset, and a long-form story generation dataset. These datasets have unique characteristics offering challenges to future work in their respective task settings. ",
    "url": "https://arxiv.org/abs/2207.10617",
    "authors": [
      "Mingda Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.10639",
    "title": "Session-based Cyberbullying Detection in Social Media: A Survey",
    "abstract": "Cyberbullying is a pervasive problem in online social media, where a bully abuses a victim through a social media session. By investigating cyberbullying perpetrated through social media sessions, recent research has looked into mining patterns and features for modeling and understanding the two defining characteristics of cyberbullying: repetitive behavior and power imbalance. In this survey paper, we define the Session-based Cyberbullying Detection framework that encapsulates the different steps and challenges of the problem. Based on this framework, we provide a comprehensive overview of session-based cyberbullying detection in social media, delving into existing efforts from a data and methodological perspective. Our review leads us to propose evidence-based criteria for a set of best practices to create session-based cyberbullying datasets. In addition, we perform benchmark experiments comparing the performance of state-of-the-art session-based cyberbullying detection models as well as large pre-trained language models across two different datasets. Through our review, we also put forth a set of open challenges as future research directions. ",
    "url": "https://arxiv.org/abs/2207.10639",
    "authors": [
      "Peiling Yi",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.10649",
    "title": "Multilingual Disinformation Detection for Digital Advertising",
    "abstract": "In today's world, the presence of online disinformation and propaganda is more widespread than ever. Independent publishers are funded mostly via digital advertising, which is unfortunately also the case for those publishing disinformation content. The question of how to remove such publishers from advertising inventory has long been ignored, despite the negative impact on the open internet. In this work, we make the first step towards quickly detecting and red-flagging websites that potentially manipulate the public with disinformation. We build a machine learning model based on multilingual text embeddings that first determines whether the page mentions a topic of interest, then estimates the likelihood of the content being malicious, creating a shortlist of publishers that will be reviewed by human experts. Our system empowers internal teams to proactively, rather than defensively, blacklist unsafe content, thus protecting the reputation of the advertisement provider. ",
    "url": "https://arxiv.org/abs/2207.10649",
    "authors": [
      "Zofia Trstanova",
      "Nadir El Manouzi",
      "Maryline Chen",
      "Andre L. V. da Cunha",
      "Sergei Ivanov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10653",
    "title": "RepFair-GAN: Mitigating Representation Bias in GANs Using Gradient  Clipping",
    "abstract": "Fairness has become an essential problem in many domains of Machine Learning (ML), such as classification, natural language processing, and Generative Adversarial Networks (GANs). In this research effort, we study the unfairness of GANs. We formally define a new fairness notion for generative models in terms of the distribution of generated samples sharing the same protected attributes (gender, race, etc.). The defined fairness notion (representational fairness) requires the distribution of the sensitive attributes at the test time to be uniform, and, in particular for GAN model, we show that this fairness notion is violated even when the dataset contains equally represented groups, i.e., the generator favors generating one group of samples over the others at the test time. In this work, we shed light on the source of this representation bias in GANs along with a straightforward method to overcome this problem. We first show on two widely used datasets (MNIST, SVHN) that when the norm of the gradient of one group is more important than the other during the discriminator's training, the generator favours sampling data from one group more than the other at test time. We then show that controlling the groups' gradient norm by performing group-wise gradient norm clipping in the discriminator during the training leads to a more fair data generation in terms of representational fairness compared to existing models while preserving the quality of generated samples. ",
    "url": "https://arxiv.org/abs/2207.10653",
    "authors": [
      "Patrik Joslin Kenfack",
      "Kamil Sabbagh",
      "Ad\u00edn Ram\u00edrez Rivera",
      "Adil Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.10654",
    "title": "Emotion detection of social data: APIs comparative study",
    "abstract": "The development of emotion detection technology has emerged as a highly valuable possibility in the corporate sector due to the nearly limitless uses of this new discipline, particularly with the unceasing propagation of social data. In recent years, the electronic marketplace has witnessed the establishment of a large number of start-up businesses with an almost sole focus on building new commercial and open-source tools and APIs for emotion detection and recognition. Yet, these tools and APIs must be continuously reviewed and evaluated, and their performances should be reported and discussed. There is a lack of research to empirically compare current emotion detection technologies in terms of the results obtained from each model using the same textual dataset. Also, there is a lack of comparative studies that apply benchmark comparison to social data. This study compares eight technologies; IBM Watson NLU, ParallelDots, Symanto-Ekman, Crystalfeel, Text to Emotion, Senpy, Textprobe, and NLP Cloud. The comparison was undertaken using two different datasets. The emotions from the chosen datasets were then derived using the incorporated APIs. The performance of these APIs was assessed using the aggregated scores that they delivered as well as the theoretically proven evaluation metrics such as the micro-average of accuracy, classification error, precision, recall, and f1-score. Lastly, the assessment of these APIs incorporating the evaluation measures is reported and discussed. ",
    "url": "https://arxiv.org/abs/2207.10654",
    "authors": [
      "Bilal Abu-Salih",
      "Mohammad Alhabashneh",
      "Dengya Zhu",
      "Albara Awajan",
      "Yazan Alshamaileh",
      "Bashar Al-Shboul",
      "Mohammad Alshraideh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.10660",
    "title": "Omni3D: A Large Benchmark and Model for 3D Object Detection in the Wild",
    "abstract": "Recognizing scenes and objects in 3D from a single image is a longstanding goal of computer vision with applications in robotics and AR/VR. For 2D recognition, large datasets and scalable solutions have led to unprecedented advances. In 3D, existing benchmarks are small in size and approaches specialize in few object categories and specific domains, e.g. urban driving scenes. Motivated by the success of 2D recognition, we revisit the task of 3D object detection by introducing a large benchmark, called Omni3D. Omni3D re-purposes and combines existing datasets resulting in 234k images annotated with more than 3 million instances and 97 categories.3D detection at such scale is challenging due to variations in camera intrinsics and the rich diversity of scene and object types. We propose a model, called Cube R-CNN, designed to generalize across camera and scene types with a unified approach. We show that Cube R-CNN outperforms prior works on the larger Omni3D and existing benchmarks. Finally, we prove that Omni3D is a powerful dataset for 3D object recognition, show that it improves single-dataset performance and can accelerate learning on new smaller datasets via pre-training. ",
    "url": "https://arxiv.org/abs/2207.10660",
    "authors": [
      "Garrick Brazil",
      "Julian Straub",
      "Nikhila Ravi",
      "Justin Johnson",
      "Georgia Gkioxari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10661",
    "title": "In Defense of Online Models for Video Instance Segmentation",
    "abstract": "In recent years, video instance segmentation (VIS) has been largely advanced by offline models, while online models gradually attracted less attention possibly due to their inferior performance. However, online methods have their inherent advantage in handling long video sequences and ongoing videos while offline models fail due to the limit of computational resources. Therefore, it would be highly desirable if online models can achieve comparable or even better performance than offline models. By dissecting current online models and offline models, we demonstrate that the main cause of the performance gap is the error-prone association between frames caused by the similar appearance among different instances in the feature space. Observing this, we propose an online framework based on contrastive learning that is able to learn more discriminative instance embeddings for association and fully exploit history information for stability. Despite its simplicity, our method outperforms all online and offline methods on three benchmarks. Specifically, we achieve 49.5 AP on YouTube-VIS 2019, a significant improvement of 13.2 AP and 2.1 AP over the prior online and offline art, respectively. Moreover, we achieve 30.2 AP on OVIS, a more challenging dataset with significant crowding and occlusions, surpassing the prior art by 14.8 AP. The proposed method won first place in the video instance segmentation track of the 4th Large-scale Video Object Segmentation Challenge (CVPR2022). We hope the simplicity and effectiveness of our method, as well as our insight into current methods, could shed light on the exploration of VIS models. ",
    "url": "https://arxiv.org/abs/2207.10661",
    "authors": [
      "Junfeng Wu",
      "Qihao Liu",
      "Yi Jiang",
      "Song Bai",
      "Alan Yuille",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10662",
    "title": "Generalizable Patch-Based Neural Rendering",
    "abstract": "Neural rendering has received tremendous attention since the advent of Neural Radiance Fields (NeRF), and has pushed the state-of-the-art on novel-view synthesis considerably. The recent focus has been on models that overfit to a single scene, and the few attempts to learn models that can synthesize novel views of unseen scenes mostly consist of combining deep convolutional features with a NeRF-like model. We propose a different paradigm, where no deep features and no NeRF-like volume rendering are needed. Our method is capable of predicting the color of a target ray in a novel scene directly, just from a collection of patches sampled from the scene. We first leverage epipolar geometry to extract patches along the epipolar lines of each reference view. Each patch is linearly projected into a 1D feature vector and a sequence of transformers process the collection. For positional encoding, we parameterize rays as in a light field representation, with the crucial difference that the coordinates are canonicalized with respect to the target ray, which makes our method independent of the reference frame and improves generalization. We show that our approach outperforms the state-of-the-art on novel view synthesis of unseen scenes even when being trained with considerably less data than prior work. ",
    "url": "https://arxiv.org/abs/2207.10662",
    "authors": [
      "Mohammed Suhail",
      "Carlos Esteves",
      "Leonid Sigal",
      "Ameesh Makadia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10663",
    "title": "Neural Pixel Composition: 3D-4D View Synthesis from Multi-Views",
    "abstract": "We present Neural Pixel Composition (NPC), a novel approach for continuous 3D-4D view synthesis given only a discrete set of multi-view observations as input. Existing state-of-the-art approaches require dense multi-view supervision and an extensive computational budget. The proposed formulation reliably operates on sparse and wide-baseline multi-view imagery and can be trained efficiently within a few seconds to 10 minutes for hi-res (12MP) content, i.e., 200-400X faster convergence than existing methods. Crucial to our approach are two core novelties: 1) a representation of a pixel that contains color and depth information accumulated from multi-views for a particular location and time along a line of sight, and 2) a multi-layer perceptron (MLP) that enables the composition of this rich information provided for a pixel location to obtain the final color output. We experiment with a large variety of multi-view sequences, compare to existing approaches, and achieve better results in diverse and challenging settings. Finally, our approach enables dense 3D reconstruction from sparse multi-views, where COLMAP, a state-of-the-art 3D reconstruction approach, struggles. ",
    "url": "https://arxiv.org/abs/2207.10663",
    "authors": [
      "Aayush Bansal",
      "Michael Zollhoefer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2207.10665",
    "title": "One-dimensional Tensor Network Recovery",
    "abstract": "We study the recovery of the underlying graphs or permutations for tensors in tensor ring or tensor train format. Our proposed algorithms compare the matricization ranks after down-sampling, whose complexity is $O(d\\log d)$ for $d$-th order tensors. We prove that our algorithms can almost surely recover the correct graph or permutation when tensor entries can be observed without noise. We further establish the robustness of our algorithms against observational noise. The theoretical results are validated by numerical experiments. ",
    "url": "https://arxiv.org/abs/2207.10665",
    "authors": [
      "Ziang Chen",
      "Jianfeng Lu",
      "Anru R. Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2207.10289",
    "title": "A comprehensive study of non-adaptive and residual-based adaptive  sampling for physics-informed neural networks",
    "abstract": "Physics-informed neural networks (PINNs) have shown to be an effective tool for solving forward and inverse problems of partial differential equations (PDEs). PINNs embed the PDEs into the loss of the neural network, and this PDE loss is evaluated at a set of scattered residual points. The distribution of these points are highly important to the performance of PINNs. However, in the existing studies on PINNs, only a few simple residual point sampling methods have mainly been used. Here, we present a comprehensive study of two categories of sampling: non-adaptive uniform sampling and adaptive nonuniform sampling. We consider six uniform sampling, including (1) equispaced uniform grid, (2) uniformly random sampling, (3) Latin hypercube sampling, (4) Halton sequence, (5) Hammersley sequence, and (6) Sobol sequence. We also consider a resampling strategy for uniform sampling. To improve the sampling efficiency and the accuracy of PINNs, we propose two new residual-based adaptive sampling methods: residual-based adaptive distribution (RAD) and residual-based adaptive refinement with distribution (RAR-D), which dynamically improve the distribution of residual points based on the PDE residuals during training. Hence, we have considered a total of 10 different sampling methods, including six non-adaptive uniform sampling, uniform sampling with resampling, two proposed adaptive sampling, and an existing adaptive sampling. We extensively tested the performance of these sampling methods for four forward problems and two inverse problems in many setups. Our numerical results presented in this study are summarized from more than 6000 simulations of PINNs. We show that the proposed adaptive sampling methods of RAD and RAR-D significantly improve the accuracy of PINNs with fewer residual points. The results obtained in this study can also be used as a practical guideline in choosing sampling methods. ",
    "url": "https://arxiv.org/abs/2207.10289",
    "authors": [
      "Chenxi Wu",
      "Min Zhu",
      "Qinyang Tan",
      "Yadhu Kartha",
      "Lu Lu"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10324",
    "title": "Improved Generative Model for Weakly Supervised Chest Anomaly  Localization via Pseudo-paired Registration with Bilaterally Symmetrical Data  Augmentation",
    "abstract": "Image translation based on a generative adversarial network (GAN-IT) is a promising method for precise localization of abnormal regions in chest X-ray images (AL-CXR). However, heterogeneous unpaired datasets undermine existing methods to extract key features and distinguish normal from abnormal cases, resulting in inaccurate and unstable AL-CXR. To address this problem, we propose an improved two-stage GAN-IT involving registration and data augmentation. For the first stage, we introduce an invertible deep-learning-based registration technique that virtually and reasonably converts unpaired data into paired data for learning registration maps. This novel approach achieves high registration performance. For the second stage, we apply data augmentation to diversify anomaly locations by swapping the left and right lung regions on the uniform registered frames, further improving the performance by alleviating imbalance in data distribution showing left and right lung lesions. Our method is intended for application to existing GAN-IT models, allowing existing architecture to benefit from key features for translation. By showing that the AL-CXR performance is uniformly improved when applying the proposed method, we believe that GAN-IT for AL-CXR can be deployed in clinical environments, even if learning data are scarce. ",
    "url": "https://arxiv.org/abs/2207.10324",
    "authors": [
      "Kyung-Su Kim",
      "Seong Je Oh",
      "Tae Uk Kim",
      "Myung Jin Chung"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10442",
    "title": "Estimation of Non-Crossing Quantile Regression Process with Deep ReQU  Neural Networks",
    "abstract": "We propose a penalized nonparametric approach to estimating the quantile regression process (QRP) in a nonseparable model using rectifier quadratic unit (ReQU) activated deep neural networks and introduce a novel penalty function to enforce non-crossing of quantile regression curves. We establish the non-asymptotic excess risk bounds for the estimated QRP and derive the mean integrated squared error for the estimated QRP under mild smoothness and regularity conditions. To establish these non-asymptotic risk and estimation error bounds, we also develop a new error bound for approximating $C^s$ smooth functions with $s >0$ and their derivatives using ReQU activated neural networks. This is a new approximation result for ReQU networks and is of independent interest and may be useful in other problems. Our numerical experiments demonstrate that the proposed method is competitive with or outperforms two existing methods, including methods using reproducing kernels and random forests, for nonparametric quantile regression. ",
    "url": "https://arxiv.org/abs/2207.10442",
    "authors": [
      "Guohao Shen",
      "Yuling Jiao",
      "Yuanyuan Lin",
      "Joel L. Horowitz",
      "Jian Huang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10485",
    "title": "Towards Confident Detection of Prostate Cancer using High Resolution  Micro-ultrasound",
    "abstract": "MOTIVATION: Detection of prostate cancer during transrectal ultrasound-guided biopsy is challenging. The highly heterogeneous appearance of cancer, presence of ultrasound artefacts, and noise all contribute to these difficulties. Recent advancements in high-frequency ultrasound imaging - micro-ultrasound - have drastically increased the capability of tissue imaging at high resolution. Our aim is to investigate the development of a robust deep learning model specifically for micro-ultrasound-guided prostate cancer biopsy. For the model to be clinically adopted, a key challenge is to design a solution that can confidently identify the cancer, while learning from coarse histopathology measurements of biopsy samples that introduce weak labels. METHODS: We use a dataset of micro-ultrasound images acquired from 194 patients, who underwent prostate biopsy. We train a deep model using a co-teaching paradigm to handle noise in labels, together with an evidential deep learning method for uncertainty estimation. We evaluate the performance of our model using the clinically relevant metric of accuracy vs. confidence. RESULTS: Our model achieves a well-calibrated estimation of predictive uncertainty with area under the curve of 88$\\%$. The use of co-teaching and evidential deep learning in combination yields significantly better uncertainty estimation than either alone. We also provide a detailed comparison against state-of-the-art in uncertainty estimation. ",
    "url": "https://arxiv.org/abs/2207.10485",
    "authors": [
      "Mahdi Gilany",
      "Paul Wilson",
      "Amoon Jamzad",
      "Fahimeh Fooladgar",
      "Minh Nguyen Nhat To",
      "Brian Wodlinger",
      "Purang Abolmaesumi",
      "Parvin Mousavi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1909.04881",
    "title": "Algebraic Property Graphs",
    "abstract": " Title: Algebraic Property Graphs ",
    "url": "https://arxiv.org/abs/1909.04881",
    "authors": [
      "Joshua Shinavier",
      "Ryan Wisnesky",
      "Joshua G. Meyers"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2002.03938",
    "title": "Distribution Approximation and Statistical Estimation Guarantees of  Generative Adversarial Networks",
    "abstract": " Comments: Version two extends to low-dimensional linear and mixture distributions ",
    "url": "https://arxiv.org/abs/2002.03938",
    "authors": [
      "Minshuo Chen",
      "Wenjing Liao",
      "Hongyuan Zha",
      "Tuo Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2007.08600",
    "title": "Denial-of-Service Vulnerability of Hash-based Transaction Sharding:  Attack and Countermeasure",
    "abstract": " Comments: To be published in IEEE Transactions on Computers ",
    "url": "https://arxiv.org/abs/2007.08600",
    "authors": [
      "Truc Nguyen",
      "My T. Thai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2007.15820",
    "title": "Photorealism in Driving Simulations: Blending Generative Adversarial  Image Synthesis with Rendering",
    "abstract": " Comments: 10 pages, 5 figures, IEEE Transactions on Intelligent Transportation Systems ",
    "url": "https://arxiv.org/abs/2007.15820",
    "authors": [
      "Ekim Yurtsever",
      "Dongfang Yang",
      "Ibrahim Mert Koc",
      "Keith A. Redmill"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2101.09818",
    "title": "Encrypted Internet traffic classification using a supervised Spiking  Neural Network",
    "abstract": " Comments: 22 pages, 8 figures. Neurocomputing (2022) ",
    "url": "https://arxiv.org/abs/2101.09818",
    "authors": [
      "Ali Rasteh",
      "Florian Delpech",
      "Carlos Aguilar-Melchor",
      "Romain Zimmer",
      "Saeed Bagheri Shouraki",
      "Timoth\u00e9e Masquelier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2104.12081",
    "title": "How Well Does Self-Supervised Pre-Training Perform with Streaming Data?",
    "abstract": " Comments: Accepted to ICLR 2022 ",
    "url": "https://arxiv.org/abs/2104.12081",
    "authors": [
      "Dapeng Hu",
      "Shipeng Yan",
      "Qizhengqiu Lu",
      "Lanqing Hong",
      "Hailin Hu",
      "Yifan Zhang",
      "Zhenguo Li",
      "Xinchao Wang",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.09401",
    "title": "Contrastive Learning with Complex Heterogeneity",
    "abstract": " Comments: Accepted by KDD22 ",
    "url": "https://arxiv.org/abs/2105.09401",
    "authors": [
      "Lecheng Zheng",
      "Jinjun Xiong",
      "Yada Zhu",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.11020",
    "title": "Emotion analysis and detection during COVID-19",
    "abstract": " Comments: LREC 2022 ",
    "url": "https://arxiv.org/abs/2107.11020",
    "authors": [
      "Tiberiu Sosea",
      "Chau Pham",
      "Alexander Tekle",
      "Cornelia Caragea",
      "Junyi Jessy Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2108.01199",
    "title": "Neural Image Representations for Multi-Image Fusion and Layer Separation",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2108.01199",
    "authors": [
      "Seonghyeon Nam",
      "Marcus A. Brubaker",
      "Michael S. Brown"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.13650",
    "title": "Heterogeneous Graph Neural Network with Multi-view Representation  Learning",
    "abstract": " Comments: Submitted to TKDE ",
    "url": "https://arxiv.org/abs/2108.13650",
    "authors": [
      "Zezhi Shao",
      "Yongjun Xu",
      "Wei Wei",
      "Fei Wang",
      "Zhao Zhang",
      "Feida Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2109.06126",
    "title": "Neural Network Guided Evolutionary Fuzzing for Finding Traffic  Violations of Autonomous Vehicles",
    "abstract": " Title: Neural Network Guided Evolutionary Fuzzing for Finding Traffic  Violations of Autonomous Vehicles ",
    "url": "https://arxiv.org/abs/2109.06126",
    "authors": [
      "Ziyuan Zhong",
      "Gail Kaiser",
      "Baishakhi Ray"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2110.08708",
    "title": "Robust Pedestrian Attribute Recognition Using Group Sparsity for  Occlusion Videos",
    "abstract": " Comments: 9 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2110.08708",
    "authors": [
      "Geonu Lee",
      "Kimin Yun",
      "Jungchan Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.14284",
    "title": "APPTeK: Agent-Based Predicate Prediction in Temporal Knowledge Graphs",
    "abstract": " Title: APPTeK: Agent-Based Predicate Prediction in Temporal Knowledge Graphs ",
    "url": "https://arxiv.org/abs/2110.14284",
    "authors": [
      "Christian M.M. Frey",
      "Yunpu Ma",
      "Matthias Schubert"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.14755",
    "title": "Algorithmic encoding of protected characteristics in image-based models  for disease detection",
    "abstract": " Comments: Code available on this https URL ",
    "url": "https://arxiv.org/abs/2110.14755",
    "authors": [
      "Ben Glocker",
      "Charles Jones",
      "Melanie Bernhardt",
      "Stefan Winzeck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.03463",
    "title": "RADAMS: Resilient and Adaptive Alert and Attention Management Strategy  against Informational Denial-of-Service (IDoS) Attacks",
    "abstract": " Title: RADAMS: Resilient and Adaptive Alert and Attention Management Strategy  against Informational Denial-of-Service (IDoS) Attacks ",
    "url": "https://arxiv.org/abs/2111.03463",
    "authors": [
      "Linan Huang",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2111.13362",
    "title": "Data Invariants to Understand Unsupervised Out-of-Distribution Detection",
    "abstract": " Comments: ECCV 2022 ",
    "url": "https://arxiv.org/abs/2111.13362",
    "authors": [
      "Lars Doorenbos",
      "Raphael Sznitman",
      "Pablo M\u00e1rquez-Neila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.00826",
    "title": "Inducing Causal Structure for Interpretable Neural Networks",
    "abstract": " Title: Inducing Causal Structure for Interpretable Neural Networks ",
    "url": "https://arxiv.org/abs/2112.00826",
    "authors": [
      "Atticus Geiger",
      "Zhengxuan Wu",
      "Hanson Lu",
      "Josh Rozner",
      "Elisa Kreiss",
      "Thomas Icard",
      "Noah D. Goodman",
      "Christopher Potts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.01759",
    "title": "NeRF-SR: High-Quality Neural Radiance Fields using Supersampling",
    "abstract": " Comments: Accepted to MM 2022. Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2112.01759",
    "authors": [
      "Chen Wang",
      "Xian Wu",
      "Yuan-Chen Guo",
      "Song-Hai Zhang",
      "Yu-Wing Tai",
      "Shi-Min Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2112.02274",
    "title": "Self-supervised Graph Learning for Occasional Group Recommendation",
    "abstract": " Comments: This paper uses self-supervised learning technique to enhance the embeddings of users/groups/items, the idea is novel in group recommendation scenario. However, some presentations need to be revised, so as to let the readers understand ",
    "url": "https://arxiv.org/abs/2112.02274",
    "authors": [
      "Bowen Hao",
      "Hongzhi Yin",
      "Cuiping Li",
      "Hong Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.03478",
    "title": "Generative Adversarial Networks for Labeled Acceleration Data  Augmentation for Structural Damage Detection",
    "abstract": " Title: Generative Adversarial Networks for Labeled Acceleration Data  Augmentation for Structural Damage Detection ",
    "url": "https://arxiv.org/abs/2112.03478",
    "authors": [
      "Furkan Luleci",
      "F. Necati Catbas",
      "Onur Avci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.06569",
    "title": "Triangle Attack: A Query-efficient Decision-based Adversarial Attack",
    "abstract": " Comments: Accepted by ECCV 2022, code is available at this https URL ",
    "url": "https://arxiv.org/abs/2112.06569",
    "authors": [
      "Xiaosen Wang",
      "Zeliang Zhang",
      "Kangheng Tong",
      "Dihong Gong",
      "Kun He",
      "Zhifeng Li",
      "Wei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.08684",
    "title": "Mimic Embedding via Adaptive Aggregation: Learning Generalizable Person  Re-identification",
    "abstract": " Comments: ECCV 2022 ",
    "url": "https://arxiv.org/abs/2112.08684",
    "authors": [
      "Boqiang Xu",
      "Jian Liang",
      "Lingxiao He",
      "Zhenan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.08775",
    "title": "DProST: Dynamic Projective Spatial Transformer Network for 6D Pose  Estimation",
    "abstract": " Comments: Accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2112.08775",
    "authors": [
      "Jaewoo Park",
      "Nam Ik Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.08879",
    "title": "Bottom Up Top Down Detection Transformers for Language Grounding in  Images and Point Clouds",
    "abstract": " Comments: First two authors contributed equally | ECCV 2022 Camera Ready ",
    "url": "https://arxiv.org/abs/2112.08879",
    "authors": [
      "Ayush Jain",
      "Nikolaos Gkanatsios",
      "Ishita Mediratta",
      "Katerina Fragkiadaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.09217",
    "title": "High-Dimensional Inference in Bayesian Networks",
    "abstract": " Title: High-Dimensional Inference in Bayesian Networks ",
    "url": "https://arxiv.org/abs/2112.09217",
    "authors": [
      "Fritz M. Bayer",
      "Giusi Moffa",
      "Niko Beerenwinkel",
      "Jack Kuipers"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.13715",
    "title": "SmoothNet: A Plug-and-Play Network for Refining Human Poses in Videos",
    "abstract": " Comments: Accepted by ECCV 2022 ",
    "url": "https://arxiv.org/abs/2112.13715",
    "authors": [
      "Ailing Zeng",
      "Lei Yang",
      "Xuan Ju",
      "Jiefeng Li",
      "Jianyi Wang",
      "Qiang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.14303",
    "title": "A proof system for graph (non)-isomorphism verification",
    "abstract": " Comments: 36 pages, 11 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2112.14303",
    "authors": [
      "Milan Bankovi\u0107",
      "Ivan Drecun",
      "Filip Mari\u0107"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2201.00689",
    "title": "CausalMTA: Eliminating the User Confounding Bias for Causal Multi-touch  Attribution",
    "abstract": " Comments: 11 pages, 5 figures This paper has been accepted in KDD 2022 ",
    "url": "https://arxiv.org/abs/2201.00689",
    "authors": [
      "Di Yao",
      "Chang Gong",
      "Lei Zhang",
      "Sheng Chen",
      "Jingping Bi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.10355",
    "title": "Neural Architecture Search for Spiking Neural Networks",
    "abstract": " Comments: Accepted to European Conference on Computer Vision (ECCV) 2022 ",
    "url": "https://arxiv.org/abs/2201.10355",
    "authors": [
      "Youngeun Kim",
      "Yuhang Li",
      "Hyoungseob Park",
      "Yeshwanth Venkatesha",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2201.12765",
    "title": "Improving Robustness by Enhancing Weak Subnets",
    "abstract": " Comments: To appear in ECCV 2022 ",
    "url": "https://arxiv.org/abs/2201.12765",
    "authors": [
      "Yong Guo",
      "David Stutz",
      "Bernt Schiele"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.00553",
    "title": "Neural Tangent Kernel Beyond the Infinite-Width Limit: Effects of Depth  and Initialization",
    "abstract": " Title: Neural Tangent Kernel Beyond the Infinite-Width Limit: Effects of Depth  and Initialization ",
    "url": "https://arxiv.org/abs/2202.00553",
    "authors": [
      "Mariia Seleznova",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.03390",
    "title": "Geometric Multimodal Contrastive Representation Learning",
    "abstract": " Comments: ICML 2022 Camera ready version ",
    "url": "https://arxiv.org/abs/2202.03390",
    "authors": [
      "Petra Poklukar",
      "Miguel Vasco",
      "Hang Yin",
      "Francisco S. Melo",
      "Ana Paiva",
      "Danica Kragic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.03874",
    "title": "Combining Intra-Risk and Contagion Risk for Enterprise Bankruptcy  Prediction Using Graph Neural Networks",
    "abstract": " Comments: 12 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2202.03874",
    "authors": [
      "Yu Zhao",
      "Shaopeng Wei",
      "Yu Guo",
      "Qing Yang",
      "Xingyan Chen",
      "Qing Li",
      "Fuzhen Zhuang",
      "Ji Liu",
      "Gang Kou"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.08578",
    "title": "An Equivalence Between Data Poisoning and Byzantine Gradient Attacks",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2106.02398 ",
    "url": "https://arxiv.org/abs/2202.08578",
    "authors": [
      "Sadegh Farhadkhani",
      "Rachid Guerraoui",
      "L\u00ea-Nguy\u00ean Hoang",
      "Oscar Villemaud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.05684",
    "title": "PC-SwinMorph: Patch Representation for Unsupervised Medical Image  Registration and Segmentation",
    "abstract": " Comments: 10 pages, 7 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2203.05684",
    "authors": [
      "Lihao Liu",
      "Zhening Huang",
      "Pietro Li\u00f2",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Angelica I. Aviles-Rivero"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07694",
    "title": "Implicit field supervision for robust non-rigid shape matching",
    "abstract": " Comments: ECCV 2022 ",
    "url": "https://arxiv.org/abs/2203.07694",
    "authors": [
      "Ramana Sundararaman",
      "Gautam Pai",
      "Maks Ovsjanikov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10157",
    "title": "ViewFormer: NeRF-free Neural Rendering from Few Images Using  Transformers",
    "abstract": " Comments: ECCV 2022 poster ",
    "url": "https://arxiv.org/abs/2203.10157",
    "authors": [
      "Jon\u00e1\u0161 Kulh\u00e1nek",
      "Erik Derner",
      "Torsten Sattler",
      "Robert Babu\u0161ka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10821",
    "title": "Sem2NeRF: Converting Single-View Semantic Masks to Neural Radiance  Fields",
    "abstract": " Comments: ECCV2022, Code: this https URL Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2203.10821",
    "authors": [
      "Yuedong Chen",
      "Qianyi Wu",
      "Chuanxia Zheng",
      "Tat-Jen Cham",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2203.11305",
    "title": "Generative Adversarial Network for Future Hand Segmentation from  Egocentric Video",
    "abstract": " Title: Generative Adversarial Network for Future Hand Segmentation from  Egocentric Video ",
    "url": "https://arxiv.org/abs/2203.11305",
    "authors": [
      "Wenqi Jia",
      "Miao Liu",
      "James M. Rehg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13104",
    "title": "R-DFCIL: Relation-Guided Representation Learning for Data-Free Class  Incremental Learning",
    "abstract": " Comments: Accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2203.13104",
    "authors": [
      "Qiankun Gao",
      "Chen Zhao",
      "Bernard Ghanem",
      "Jian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13571",
    "title": "Adaptive Neural Network-based OFDM Receivers",
    "abstract": " Comments: Submitted to SPAWC 2022 ",
    "url": "https://arxiv.org/abs/2203.13571",
    "authors": [
      "Moritz Benedikt Fischer",
      "Sebastian D\u00f6rner",
      "Sebastian Cammerer",
      "Takayuki Shimizu",
      "Hongsheng Lu",
      "Stephan ten Brink"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2204.01702",
    "title": "Personalized Prediction of Future Lesion Activity and Treatment Effect  in Multiple Sclerosis from Baseline MRI",
    "abstract": " Comments: Accepted to MIDL 2022 ",
    "url": "https://arxiv.org/abs/2204.01702",
    "authors": [
      "Joshua Durso-Finley",
      "Jean-Pierre R. Falet",
      "Brennan Nichyporuk",
      "Douglas L. Arnold",
      "Tal Arbel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07159",
    "title": "A Level Set Theory for Neural Implicit Evolution under Explicit Flows",
    "abstract": " Comments: ECCV 2022 (Oral); Project Page at this https URL ",
    "url": "https://arxiv.org/abs/2204.07159",
    "authors": [
      "Ishit Mehta",
      "Manmohan Chandraker",
      "Ravi Ramamoorthi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.10740",
    "title": "Embracing AWKWARD! Real-time Adjustment of Reactive Plans Using Social  Norms",
    "abstract": " Comments: 18 pages, 2 figures, 3 Tables, 4 Formalisms, Accepted at COINE 2022 Workshop ",
    "url": "https://arxiv.org/abs/2204.10740",
    "authors": [
      "Leila Methnani",
      "Andreas Antoniades",
      "Andreas Theodorou"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.13749",
    "title": "Learning to Split for Automatic Bias Detection",
    "abstract": " Title: Learning to Split for Automatic Bias Detection ",
    "url": "https://arxiv.org/abs/2204.13749",
    "authors": [
      "Yujia Bao",
      "Regina Barzilay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.03268",
    "title": "Robustness of Neural Architectures for Audio Event Detection",
    "abstract": " Title: Robustness of Neural Architectures for Audio Event Detection ",
    "url": "https://arxiv.org/abs/2205.03268",
    "authors": [
      "Juncheng B Li",
      "Zheng Wang",
      "Shuhui Qu",
      "Florian Metze"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.15814",
    "title": "Contrasting quadratic assignments for set-based representation learning",
    "abstract": " Title: Contrasting quadratic assignments for set-based representation learning ",
    "url": "https://arxiv.org/abs/2205.15814",
    "authors": [
      "Artem Moskalev",
      "Ivan Sosnovik",
      "Volker Fischer",
      "Arnold Smeulders"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00065",
    "title": "FELARE: Fair Scheduling of Machine Learning Tasks on Heterogeneous Edge  Systems",
    "abstract": " Title: FELARE: Fair Scheduling of Machine Learning Tasks on Heterogeneous Edge  Systems ",
    "url": "https://arxiv.org/abs/2206.00065",
    "authors": [
      "Ali Mokhtari",
      "Md Abir Hossen",
      "Pooyan Jamshidi",
      "Mohsen Amini Salehi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2206.07434",
    "title": "Self-Supervised Implicit Attention: Guided Attention by The Model Itself",
    "abstract": " Title: Self-Supervised Implicit Attention: Guided Attention by The Model Itself ",
    "url": "https://arxiv.org/abs/2206.07434",
    "authors": [
      "Jinyi Wu",
      "Xun Gong",
      "Zhemin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07765",
    "title": "US News and Social Media Framing around Vaping",
    "abstract": " Title: US News and Social Media Framing around Vaping ",
    "url": "https://arxiv.org/abs/2206.07765",
    "authors": [
      "Keyu Chen",
      "Marzieh Babaeianjelodar",
      "Yiwen Shi",
      "Rohan Aanegola",
      "Lam Yin Cheung",
      "Preslav Ivanov Nakov",
      "Shweta Yadav",
      "Angus Bancroft",
      "Ashiqur R. KhudaBukhsh",
      "Munmun De Choudhury",
      "Frederick L. Altice",
      "Navin Kumar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.13179",
    "title": "AixBench: A Code Generation Benchmark Dataset",
    "abstract": " Title: AixBench: A Code Generation Benchmark Dataset ",
    "url": "https://arxiv.org/abs/2206.13179",
    "authors": [
      "Yiyang Hao",
      "Ge Li",
      "Yongqiang Liu",
      "Xiaowei Miao",
      "He Zong",
      "Siyuan Jiang",
      "Yang Liu",
      "He Wei"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2206.13979",
    "title": "Attack Agnostic Dataset: Towards Generalization and Stabilization of  Audio DeepFake Detection",
    "abstract": " Comments: Proceedings of INTERSPEECH 2022 (Updated version: corrected ASVspoof dataset description) ",
    "url": "https://arxiv.org/abs/2206.13979",
    "authors": [
      "Piotr Kawa",
      "Marcin Plata",
      "Piotr Syga"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.15475",
    "title": "Causal Machine Learning: A Survey and Open Problems",
    "abstract": " Comments: 191 pages. v02. Work in progress. Feedback and comments are highly appreciated! ",
    "url": "https://arxiv.org/abs/2206.15475",
    "authors": [
      "Jean Kaddour",
      "Aengus Lynch",
      "Qi Liu",
      "Matt J. Kusner",
      "Ricardo Silva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2207.01382",
    "title": "Exploring Lottery Ticket Hypothesis in Spiking Neural Networks",
    "abstract": " Comments: Accepted to European Conference on Computer Vision (ECCV) 2022 ",
    "url": "https://arxiv.org/abs/2207.01382",
    "authors": [
      "Youngeun Kim",
      "Yuhang Li",
      "Hyoungseob Park",
      "Yeshwanth Venkatesha",
      "Ruokai Yin",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04574",
    "title": "Brain-Aware Replacements for Supervised Contrastive Learning in  Detection of Alzheimer's Disease",
    "abstract": " Title: Brain-Aware Replacements for Supervised Contrastive Learning in  Detection of Alzheimer's Disease ",
    "url": "https://arxiv.org/abs/2207.04574",
    "authors": [
      "Mehmet Sayg\u0131n Seyfio\u011flu",
      "Zixuan Liu",
      "Pranav Kamath",
      "Sadjyot Gangolli",
      "Sheng Wang",
      "Thomas Grabowski",
      "Linda Shapiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05342",
    "title": "Video Graph Transformer for Video Question Answering",
    "abstract": " Comments: ECCV'22 ",
    "url": "https://arxiv.org/abs/2207.05342",
    "authors": [
      "Junbin Xiao",
      "Pan Zhou",
      "Tat-Seng Chua",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.06652",
    "title": "Every Preference Changes Differently: Neural Multi-Interest Preference  Model with Temporal Dynamics for Recommendation",
    "abstract": " Title: Every Preference Changes Differently: Neural Multi-Interest Preference  Model with Temporal Dynamics for Recommendation ",
    "url": "https://arxiv.org/abs/2207.06652",
    "authors": [
      "Hui Shi",
      "Yupeng Gu",
      "Yitong Zhou",
      "Bo Zhao",
      "Sicun Gao",
      "Jishen Zhao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.06819",
    "title": "Anomal-E: A Self-Supervised Network Intrusion Detection System based on  Graph Neural Networks",
    "abstract": " Title: Anomal-E: A Self-Supervised Network Intrusion Detection System based on  Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2207.06819",
    "authors": [
      "Evan Caville",
      "Wai Weng Lo",
      "Siamak Layeghy",
      "Marius Portmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.07656",
    "title": "FLOWGEN: Fast and slow graph generation",
    "abstract": " Comments: This version to be presented at Dynn workshop @ ICML 2022 ",
    "url": "https://arxiv.org/abs/2207.07656",
    "authors": [
      "Aman Madaan",
      "Yiming Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.08350",
    "title": "Towards Understanding The Semidefinite Relaxations of Truncated  Least-Squares in Robust Rotation Search",
    "abstract": " Comments: presented in part in ECCV 2022 ",
    "url": "https://arxiv.org/abs/2207.08350",
    "authors": [
      "Liangzu Peng",
      "Mahyar Fazlyab",
      "Ren\u00e9 Vidal"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08631",
    "title": "Latent Partition Implicit with Surface Codes for 3D Representation",
    "abstract": " Comments: 20pages,14figures ",
    "url": "https://arxiv.org/abs/2207.08631",
    "authors": [
      "Chao Chen",
      "Yu-Shen Liu",
      "Zhizhong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09314",
    "title": "Self-Supervised Interactive Object Segmentation Through a  Singulation-and-Grasping Approach",
    "abstract": " Comments: Accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2207.09314",
    "authors": [
      "Houjian Yu",
      "Changhyun Choi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09675",
    "title": "ERA: Expert Retrieval and Assembly for Early Action Prediction",
    "abstract": " Comments: Accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2207.09675",
    "authors": [
      "Lin Geng Foo",
      "Tianjiao Li",
      "Hossein Rahmani",
      "Qiuhong Ke",
      "Jun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09933",
    "title": "Robust Landmark-based Stent Tracking in X-ray Fluoroscopy",
    "abstract": " Comments: Accepted by ECCV 2022 ",
    "url": "https://arxiv.org/abs/2207.09933",
    "authors": [
      "Luojie Huang",
      "Yikang Liu",
      "Li Chen",
      "Eric Z. Chen",
      "Xiao Chen",
      "Shanhui Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09971",
    "title": "NeuralNEB -- Neural Networks can find Reaction Paths Fast",
    "abstract": " Title: NeuralNEB -- Neural Networks can find Reaction Paths Fast ",
    "url": "https://arxiv.org/abs/2207.09971",
    "authors": [
      "Mathias Schreiner",
      "Arghya Bhowmik",
      "Tejs Vegge",
      "Ole Winther"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2207.10025",
    "title": "Learning from Synthetic Data: Facial Expression Classification based on  Ensemble of Multi-task Networks",
    "abstract": " Comments: Page 3, Added reference [2], [33] ",
    "url": "https://arxiv.org/abs/2207.10025",
    "authors": [
      "Jae-Yeop Jeong",
      "Yeong-Gi Hong",
      "JiYeon Oh",
      "Sumin Hong",
      "Jin-Woo Jeong",
      "Yuchul Jung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10047",
    "title": "Densely Constrained Depth Estimator for Monocular 3D Object Detection",
    "abstract": " Comments: Accepted by ECCV2022 ",
    "url": "https://arxiv.org/abs/2207.10047",
    "authors": [
      "Yingyan Li",
      "Yuntao Chen",
      "Jiawei He",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]