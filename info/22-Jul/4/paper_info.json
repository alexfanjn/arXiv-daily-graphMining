[
  {
    "id": "arXiv:2207.00008",
    "title": "Smart Application for Fall Detection Using Wearable ECG & Accelerometer  Sensors",
    "abstract": "Timely and reliable detection of falls is a large and rapidly growing field of research due to the medical and financial demand of caring for a constantly growing elderly population. Within the past 2 decades, the availability of high-quality hardware (high-quality sensors and AI microchips) and software (machine learning algorithms) technologies has served as a catalyst for this research by giving developers the capabilities to develop such systems. This study developed multiple application components in order to investigate the development challenges and choices for fall detection systems, and provide materials for future research. The smart application developed using this methodology was validated by the results from fall detection modelling experiments and model mobile deployment. The best performing model overall was the ResNet152 on a standardised, and shuffled dataset with a 2s window size which achieved 92.8% AUC, 7.28% sensitivity, and 98.33% specificity. Given these results it is evident that accelerometer and ECG sensors are beneficial for fall detection, and allow for the discrimination between falls and other activities. This study leaves a significant amount of room for improvement due to weaknesses identified in the resultant dataset. These improvements include using a labelling protocol for the critical phase of a fall, increasing the number of dataset samples, improving the test subject representation, and experimenting with frequency domain preprocessing. ",
    "url": "https://arxiv.org/abs/2207.00008",
    "authors": [
      "Harry Wixley"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00012",
    "title": "Reliable Representations Make A Stronger Defender: Unsupervised  Structure Refinement for Robust GNN",
    "abstract": "Benefiting from the message passing mechanism, Graph Neural Networks (GNNs) have been successful on flourish tasks over graph data. However, recent studies have shown that attackers can catastrophically degrade the performance of GNNs by maliciously modifying the graph structure. A straightforward solution to remedy this issue is to model the edge weights by learning a metric function between pairwise representations of two end nodes, which attempts to assign low weights to adversarial edges. The existing methods use either raw features or representations learned by supervised GNNs to model the edge weights. However, both strategies are faced with some immediate problems: raw features cannot represent various properties of nodes (e.g., structure information), and representations learned by supervised GNN may suffer from the poor performance of the classifier on the poisoned graph. We need representations that carry both feature information and as mush correct structure information as possible and are insensitive to structural perturbations. To this end, we propose an unsupervised pipeline, named STABLE, to optimize the graph structure. Finally, we input the well-refined graph into a downstream classifier. For this part, we design an advanced GCN that significantly enhances the robustness of vanilla GCN without increasing the time complexity. Extensive experiments on four real-world graph benchmarks demonstrate that STABLE outperforms the state-of-the-art methods and successfully defends against various attacks. ",
    "url": "https://arxiv.org/abs/2207.00012",
    "authors": [
      "Kuan Li",
      "Yang Liu",
      "Xiang Ao",
      "Jianfeng Chi",
      "Jinghua Feng",
      "Hao Yang",
      "Qing He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.00048",
    "title": "Privacy-preserving Graph Analytics: Secure Generation and Federated  Learning",
    "abstract": "Directly motivated by security-related applications from the Homeland Security Enterprise, we focus on the privacy-preserving analysis of graph data, which provides the crucial capacity to represent rich attributes and relationships. In particular, we discuss two directions, namely privacy-preserving graph generation and federated graph learning, which can jointly enable the collaboration among multiple parties each possessing private graph data. For each direction, we identify both \"quick wins\" and \"hard problems\". Towards the end, we demonstrate a user interface that can facilitate model explanation, interpretation, and visualization. We believe that the techniques developed in these directions will significantly enhance the capabilities of the Homeland Security Enterprise to tackle and mitigate the various security risks. ",
    "url": "https://arxiv.org/abs/2207.00048",
    "authors": [
      "Dongqi Fu",
      "Jingrui He",
      "Hanghang Tong",
      "Ross Maciejewski"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00066",
    "title": "Advances in Prediction of Readmission Rates Using Long Term Short Term  Memory Networks on Healthcare Insurance Data",
    "abstract": "30-day hospital readmission is a long standing medical problem that affects patients' morbidity and mortality and costs billions of dollars annually. Recently, machine learning models have been created to predict risk of inpatient readmission for patients with specific diseases, however no model exists to predict this risk across all patients. We developed a bi-directional Long Short Term Memory (LSTM) Network that is able to use readily available insurance data (inpatient visits, outpatient visits, and drug prescriptions) to predict 30 day re-admission for any admitted patient, regardless of reason. The top-performing model achieved an ROC AUC of 0.763 (0.011) when using historical, inpatient, and post-discharge data. The LSTM model significantly outperformed a baseline random forest classifier, indicating that understanding the sequence of events is important for model prediction. Incorporation of 30-days of historical data also significantly improved model performance compared to inpatient data alone, indicating that a patients clinical history prior to admission, including outpatient visits and pharmacy data is a strong contributor to readmission. Our results demonstrate that a machine learning model is able to predict risk of inpatient readmission with reasonable accuracy for all patients using structured insurance billing data. Because billing data or equivalent surrogates can be extracted from sites, such a model could be deployed to identify patients at risk for readmission before they are discharged, or to assign more robust follow up (closer follow up, home health, mailed medications) to at-risk patients after discharge. ",
    "url": "https://arxiv.org/abs/2207.00066",
    "authors": [
      "Shuja Khalid",
      "Francisco Matos",
      "Ayman Abunimer",
      "Joel Bartlett",
      "Richard Duszak",
      "Michal Horny",
      "Judy Gichoya",
      "Imon Banerjee",
      "Hari Trivedi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.00068",
    "title": "Sparse Periodic Systolic Dataflow for Lowering Latency and Power  Dissipation of Convolutional Neural Network Accelerators",
    "abstract": "This paper introduces the sparse periodic systolic (SPS) dataflow, which advances the state-of-the-art hardware accelerator for supporting lightweight neural networks. Specifically, the SPS dataflow enables a novel hardware design approach unlocked by an emergent pruning scheme, periodic pattern-based sparsity (PPS). By exploiting the regularity of PPS, our sparsity-aware compiler optimally reorders the weights and uses a simple indexing unit in hardware to create matches between the weights and activations. Through the compiler-hardware codesign, SPS dataflow enjoys higher degrees of parallelism while being free of the high indexing overhead and without model accuracy loss. Evaluated on popular benchmarks such as VGG and ResNet, the SPS dataflow and accompanying neural network compiler outperform prior work in convolutional neural network (CNN) accelerator designs targeting FPGA devices. Against other sparsity-supporting weight storage formats, SPS results in 4.49x energy efficiency gain while lowering storage requirements by 3.67x for total weight storage (non-pruned weights plus indexing) and 22,044x for indexing memory. ",
    "url": "https://arxiv.org/abs/2207.00068",
    "authors": [
      "Jung Hwan Heo",
      "Arash Fayyazi",
      "Amirhossein Esmaili",
      "Massoud Pedram"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00083",
    "title": "DarKnight: An Accelerated Framework for Privacy and Integrity Preserving  Deep Learning Using Trusted Hardware",
    "abstract": "Privacy and security-related concerns are growing as machine learning reaches diverse application domains. The data holders want to train or infer with private data while exploiting accelerators, such as GPUs, that are hosted in the cloud. Cloud systems are vulnerable to attackers that compromise the privacy of data and integrity of computations. Tackling such a challenge requires unifying theoretical privacy algorithms with hardware security capabilities. This paper presents DarKnight, a framework for large DNN training while protecting input privacy and computation integrity. DarKnight relies on cooperative execution between trusted execution environments (TEE) and accelerators, where the TEE provides privacy and integrity verification, while accelerators perform the bulk of the linear algebraic computation to optimize the performance. In particular, DarKnight uses a customized data encoding strategy based on matrix masking to create input obfuscation within a TEE. The obfuscated data is then offloaded to GPUs for fast linear algebraic computation. DarKnight's data obfuscation strategy provides provable data privacy and computation integrity in the cloud servers. While prior works tackle inference privacy and cannot be utilized for training, DarKnight's encoding scheme is designed to support both training and inference. ",
    "url": "https://arxiv.org/abs/2207.00083",
    "authors": [
      "Hanieh Hashemi",
      "Yongqin Wang",
      "Murali Annavaram"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00090",
    "title": "Graph Similarity Based on Matrix Norms",
    "abstract": "Quantifying the similarity between two graphs is a fundamental algorithmic problem at the heart of many data analysis tasks for graph-based data. In this paper, we study the computational complexity of a family of similarity measures based on quantifying the mismatch between the two graphs, that is, the \"symmetric difference\" of the graphs under an optimal alignment of the vertices. An important example is similarity based on graph edit distance. While edit distance calculates the \"global\" mismatch, that is, the number of edges in the symmetric difference, our main focus is on \"local\" measures calculating the maximum mismatch per vertex. Mathematically, our similarity measures are best expressed in terms of the adjacency matrices: the mismatch between graphs is expressed as the difference of their adjacency matrices (under an optimal alignment), and we measure it by applying some matrix norm. Roughly speaking, global measures like graph edit distance correspond to entrywise matrix norms like the Frobenius norm and local measures correspond to operator norms like the spectral norm. We prove a number of strong NP-hardness and inapproximability results even for very restricted graph classes such as bounded-degree trees. ",
    "url": "https://arxiv.org/abs/2207.00090",
    "authors": [
      "Timo Gervens",
      "Martin Grohe"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2207.00106",
    "title": "GaitForeMer: Self-Supervised Pre-Training of Transformers via Human  Motion Forecasting for Few-Shot Gait Impairment Severity Estimation",
    "abstract": "Parkinson's disease (PD) is a neurological disorder that has a variety of observable motor-related symptoms such as slow movement, tremor, muscular rigidity, and impaired posture. PD is typically diagnosed by evaluating the severity of motor impairments according to scoring systems such as the Movement Disorder Society Unified Parkinson's Disease Rating Scale (MDS-UPDRS). Automated severity prediction using video recordings of individuals provides a promising route for non-intrusive monitoring of motor impairments. However, the limited size of PD gait data hinders model ability and clinical potential. Because of this clinical data scarcity and inspired by the recent advances in self-supervised large-scale language models like GPT-3, we use human motion forecasting as an effective self-supervised pre-training task for the estimation of motor impairment severity. We introduce GaitForeMer, Gait Forecasting and impairment estimation transforMer, which is first pre-trained on public datasets to forecast gait movements and then applied to clinical data to predict MDS-UPDRS gait impairment severity. Our method outperforms previous approaches that rely solely on clinical data by a large margin, achieving an F1 score of 0.76, precision of 0.79, and recall of 0.75. Using GaitForeMer, we show how public human movement data repositories can assist clinical use cases through learning universal motion representations. The code is available at https://github.com/markendo/GaitForeMer . ",
    "url": "https://arxiv.org/abs/2207.00106",
    "authors": [
      "Mark Endo",
      "Kathleen L. Poston",
      "Edith V. Sullivan",
      "Li Fei-Fei",
      "Kilian M. Pohl",
      "Ehsan Adeli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.00107",
    "title": "Modularity Optimization as a Training Criterion for Graph Neural  Networks",
    "abstract": "Graph convolution is a recent scalable method for performing deep feature learning on attributed graphs by aggregating local node information over multiple layers. Such layers only consider attribute information of node neighbors in the forward model and do not incorporate knowledge of global network structure in the learning task. In particular, the modularity function provides a convenient source of information about the community structure of networks. In this work we investigate the effect on the quality of learned representations by the incorporation of community structure preservation objectives of networks in the graph convolutional model. We incorporate the objectives in two ways, through an explicit regularization term in the cost function in the output layer and as an additional loss term computed via an auxiliary layer. We report the effect of community structure preserving terms in the graph convolutional architectures. Experimental evaluation on two attributed bibilographic networks showed that the incorporation of the community-preserving objective improves semi-supervised node classification accuracy in the sparse label regime. ",
    "url": "https://arxiv.org/abs/2207.00107",
    "authors": [
      "Tsuyoshi Murata",
      "Naveed Afzal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.00137",
    "title": "Robustness of Epinets against Distributional Shifts",
    "abstract": "Recent work introduced the epinet as a new approach to uncertainty modeling in deep learning. An epinet is a small neural network added to traditional neural networks, which, together, can produce predictive distributions. In particular, using an epinet can greatly improve the quality of joint predictions across multiple inputs, a measure of how well a neural network knows what it does not know. In this paper, we examine whether epinets can offer similar advantages under distributional shifts. We find that, across ImageNet-A/O/C, epinets generally improve robustness metrics. Moreover, these improvements are more significant than those afforded by even very large ensembles at orders of magnitude lower computational costs. However, these improvements are relatively small compared to the outstanding issues in distributionally-robust deep learning. Epinets may be a useful tool in the toolbox, but they are far from the complete solution. ",
    "url": "https://arxiv.org/abs/2207.00137",
    "authors": [
      "Xiuyuan Lu",
      "Ian Osband",
      "Seyed Mohammad Asghari",
      "Sven Gowal",
      "Vikranth Dwaracherla",
      "Zheng Wen",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00147",
    "title": "ChrSNet: Chromosome Straightening using Self-attention Guided Networks",
    "abstract": "Karyotyping is an important procedure to assess the possible existence of chromosomal abnormalities. However, because of the non-rigid nature, chromosomes are usually heavily curved in microscopic images and such deformed shapes hinder the chromosome analysis for cytogeneticists. In this paper, we present a self-attention guided framework to erase the curvature of chromosomes. The proposed framework extracts spatial information and local textures to preserve banding patterns in a regression module. With complementary information from the bent chromosome, a refinement module is designed to further improve fine details. In addition, we propose two dedicated geometric constraints to maintain the length and restore the distortion of chromosomes. To train our framework, we create a synthetic dataset where curved chromosomes are generated from the real-world straight chromosomes by grid-deformation. Quantitative and qualitative experiments are conducted on synthetic and real-world data. Experimental results show that our proposed method can effectively straighten bent chromosomes while keeping banding details and length. ",
    "url": "https://arxiv.org/abs/2207.00147",
    "authors": [
      "Sunyi Zheng",
      "Jingxiong Li",
      "Zhongyi Shui",
      "Chenglu Zhu",
      "Yunlong Zhang",
      "Pingyi Chen",
      "Lin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00148",
    "title": "Generating Counterfactual Hard Negative Samples for Graph Contrastive  Learning",
    "abstract": "Graph contrastive learning has emerged as a powerful tool for unsupervised graph representation learning. The key to the success of graph contrastive learning is to acquire high-quality positive and negative samples as contrasting pairs for the purpose of learning underlying structural semantics of the input graph. Recent works usually sample negative samples from the same training batch with the positive samples, or from an external irrelevant graph. However, a significant limitation lies in such strategies, which is the unavoidable problem of sampling false negative samples. In this paper, we propose a novel method to utilize \\textbf{C}ounterfactual mechanism to generate artificial hard negative samples for \\textbf{G}raph \\textbf{C}ontrastive learning, namely \\textbf{CGC}, which has a different perspective compared to those sampling-based strategies. We utilize counterfactual mechanism to produce hard negative samples, which ensures that the generated samples are similar to, but have labels that different from the positive sample. The proposed method achieves satisfying results on several datasets compared to some traditional unsupervised graph learning methods and some SOTA graph contrastive learning methods. We also conduct some supplementary experiments to give an extensive illustration of the proposed method, including the performances of CGC with different hard negative samples and evaluations for hard negative samples generated with different similarity measurements. ",
    "url": "https://arxiv.org/abs/2207.00148",
    "authors": [
      "Haoran Yang",
      "Hongxu Chen",
      "Sixiao Zhang",
      "Xiangguo Sun",
      "Qian Li",
      "Guandong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.00153",
    "title": "An Analytical Study on Functional Split in Martian 3D Networks",
    "abstract": "As space agencies are planning manned missions to reach Mars, researchers need to pave the way for supporting astronauts during their sojourn. This will also be achieved by providing broadband and low-latency connectivity through wireless network infrastructures. In such a framework, we propose a Martian deployment of a 3-Dimensional (3D) network acting as Cloud Radio Access Network (C-RAN). The scenario consists, mostly, of unmanned aerial vehicles (UAVs) and nanosatellites. Thanks to the thin Martian atmosphere, CubeSats can stably orbit at very-low-altitude. This allows to meet strict delay requirements to split functions of the baseband processing between drones and CubeSats. The detailed analytical study, presented in this paper, confirmed the viability of the proposed 3D architecture, under some constraints and trade-off concerning the involved Space communication infrastructures, that are discussed in detail. ",
    "url": "https://arxiv.org/abs/2207.00153",
    "authors": [
      "Stefano Bonafini",
      "Claudio Sacchi",
      "Riccardo Bassoli",
      "Fabrizio Granelli",
      "Koteswararao Kondepu",
      "Frank H. P. Fitzek"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.00158",
    "title": "Experimental Demonstration of Delay-Bounded Wireless Network Based on  Precise Time Synchronization",
    "abstract": "Low latency and reliable information transfer are highly demanded in 5G and beyond 5G wireless communications. However, the conventional media access control (MAC) protocol for local wireless networks sometimes unexpectedly yields significant delays due to its stochastic arbitration mechanism, resulting in the incapability of limiting the maximum delay. In the meantime, the latest precise time synchronization technology, especially wireless two-way interferometry (Wi-Wi), paves a new way to overcome such fundamental difficulties. Indeed, Yamasaki et al. proposed a new delay-bounded wireless MAC protocol named Carrier Sense Multiple Access with Arbitration Point (CSMA/AP), exploiting precise time synchronization among all devices in the network. CSMA/AP enables collision-free and delay-bounded communications with a simple autonomous arbitration mechanism, unlike conventional methods such as CSMA/CA. The former study, however, was limited only to numerical examinations. Experimental demonstration and verification in wireless environments are one of the most critical steps. This paper experimentally demonstrates the fundamental principles of CSMA/AP by constructing a star-topology wireless network using software-defined radio terminals combined with precise time synchronization devices. We show that CSMA/AP is successfully operated, including the dynamic change of the spatial position of the terminal or the capability to accommodate mobility, thanks to the real-time adaption to the dynamically changing environment by Wi-Wi. We also experimentally confirm that the proposed CSMA/AP principle cannot be executed without Wi-Wi, which validates the impact of precise time synchronization. This study paves a way toward realizing delay-bounded wireless communications for future low-latency and highly reliable critical applications. ",
    "url": "https://arxiv.org/abs/2207.00158",
    "authors": [
      "Haruaki Tanaka",
      "Yusuke Yamasaki",
      "Satoshi Yasuda",
      "Nobuyasu Shiga",
      "Kenichi Takizawa",
      "Nicolas Chauvet",
      "Ryoichi Horisaki",
      "Makoto Naruse"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2207.00159",
    "title": "Game-theoretic Learning Anti-jamming Approaches in Wireless Networks",
    "abstract": "In this article, the anti-jamming communication problem is investigated from a game-theoretic learning perspective. By exploring and analyzing intelligent anti-jamming communication, we present the characteristics of jammers and the requirements of an intelligent anti-jamming approach. Such approach is required of self-sensing, self-decision making, self-coordination, self-evaluation, and learning ability. Then, a game-theoretic learning anti-jamming (GTLAJ) paradigm is proposed, and its framework and challenges of GTLAJ are introduced. Moreover, through three cases, i.e., Stackelberg anti-jamming game, Markov anti-jamming game and hypergraph-based anti-jamming game, different anti-jamming game models and applications are discussed, and some future directions are presented. ",
    "url": "https://arxiv.org/abs/2207.00159",
    "authors": [
      "Luliang Jia",
      "Nan Qi",
      "Feihuang Chu",
      "Shengliang Fang",
      "Ximing Wang",
      "Shuli Ma",
      "Shuo Feng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2207.00161",
    "title": "Mitigating Presentation Attack using DCGAN and Deep CNN",
    "abstract": "Biometric based authentication is currently playing an essential role over conventional authentication system; however, the risk of presentation attacks subsequently rising. Our research aims at identifying the areas where presentation attack can be prevented even though adequate biometric image samples of users are limited. Our work focusses on generating photorealistic synthetic images from the real image sets by implementing Deep Convolution Generative Adversarial Net (DCGAN). We have implemented the temporal and spatial augmentation during the fake image generation. Our work detects the presentation attacks on facial and iris images using our deep CNN, inspired by VGGNet [1]. We applied the deep neural net techniques on three different biometric image datasets, namely MICHE I [2], VISOB [3], and UBIPr [4]. The datasets, used in this research, contain images that are captured both in controlled and uncontrolled environment along with different resolutions and sizes. We obtained the best test accuracy of 97% on UBI-Pr [4] Iris datasets. For MICHE-I [2] and VISOB [3] datasets, we achieved the test accuracies of 95% and 96% respectively. ",
    "url": "https://arxiv.org/abs/2207.00161",
    "authors": [
      "Nyle Siddiqui",
      "Rushit Dave"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.00165",
    "title": "Secure Forward Aggregation for Vertical Federated Neural Networks",
    "abstract": "Vertical federated learning (VFL) is attracting much attention because it enables cross-silo data cooperation in a privacy-preserving manner. While most research works in VFL focus on linear and tree models, deep models (e.g., neural networks) are not well studied in VFL. In this paper, we focus on SplitNN, a well-known neural network framework in VFL, and identify a trade-off between data security and model performance in SplitNN. Briefly, SplitNN trains the model by exchanging gradients and transformed data. On the one hand, SplitNN suffers from the loss of model performance since multiply parties jointly train the model using transformed data instead of raw data, and a large amount of low-level feature information is discarded. On the other hand, a naive solution of increasing the model performance through aggregating at lower layers in SplitNN (i.e., the data is less transformed and more low-level feature is preserved) makes raw data vulnerable to inference attacks. To mitigate the above trade-off, we propose a new neural network protocol in VFL called Security Forward Aggregation (SFA). It changes the way of aggregating the transformed data and adopts removable masks to protect the raw data. Experiment results show that networks with SFA achieve both data security and high model performance. ",
    "url": "https://arxiv.org/abs/2207.00165",
    "authors": [
      "Shuowei Cai",
      "Di Chai",
      "Liu Yang",
      "Junxue Zhang",
      "Yilun Jin",
      "Leye Wang",
      "Kun Guo",
      "Kai Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00166",
    "title": "Variational Autoencoder Assisted Neural Network Likelihood RSRP  Prediction Model",
    "abstract": "Measuring customer experience on mobile data is of utmost importance for global mobile operators. The reference signal received power (RSRP) is one of the important indicators for current mobile network management, evaluation and monitoring. Radio data gathered through the minimization of drive test (MDT), a 3GPP standard technique, is commonly used for radio network analysis. Collecting MDT data in different geographical areas is inefficient and constrained by the terrain conditions and user presence, hence is not an adequate technique for dynamic radio environments. In this paper, we study a generative model for RSRP prediction, exploiting MDT data and a digital twin (DT), and propose a data-driven, two-tier neural network (NN) model. In the first tier, environmental information related to user equipment (UE), base stations (BS) and network key performance indicators (KPI) are extracted through a variational autoencoder (VAE). The second tier is designed as a likelihood model. Here, the environmental features and real MDT data features are adopted, formulating an integrated training process. On validation, our proposed model that uses real-world data demonstrates an accuracy improvement of about 20% or more compared with the empirical model and about 10% when compared with a fully connected prediction network. ",
    "url": "https://arxiv.org/abs/2207.00166",
    "authors": [
      "Peizheng Li",
      "Xiaoyang Wang",
      "Robert Piechocki",
      "Shipra Kapoor",
      "Angela Doufexi",
      "Arjun Parekh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.00169",
    "title": "Novel Recursive Inclusion-Exclusion Technology Based on BAT and MPs for  Heterogeneous-Arc Binary-State Network Reliability Problems",
    "abstract": "Current network applications, such as utility networks (gas, water, electricity, and 4G/5G), the Internet of Things (IoT), social networks, and supply chains, are all based on binary state networks. Reliability is one of the most commonly used tools for evaluating network performance, and the minimal path (MP) is a basic algorithm for calculating reliability. However, almost all existing algorithms assume that all undirected arcs are homogeneous; that is, the probability of an arc from nodes a to b is equal to that from nodes b to a. Therefore, based on MPs, the binary-addition-tree algorithm (BAT), and the inclusion-exclusion technique (IET), a novel recursive inclusion-exclusion technology algorithm known as recursive BAT-based IET (RIE) is proposed to solve the heterogeneous-arc binary-state network reliability problem to overcome the above obstacles in applications. The computational complexity of the proposed RIE is analyzed using an illustrative example. Finally, 11 benchmark problems are used to verify the performance of RIE. ",
    "url": "https://arxiv.org/abs/2207.00169",
    "authors": [
      "Wei-Chang Yeh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2207.00170",
    "title": "TENET: Transformer Encoding Network for Effective Temporal Flow on  Motion Prediction",
    "abstract": "This technical report presents an effective method for motion prediction in autonomous driving. We develop a Transformer-based method for input encoding and trajectory prediction. Besides, we propose the Temporal Flow Header to enhance the trajectory encoding. In the end, an efficient K-means ensemble method is used. Using our Transformer network and ensemble method, we win the first place of Argoverse 2 Motion Forecasting Challenge with the state-of-the-art brier-minFDE score of 1.90. ",
    "url": "https://arxiv.org/abs/2207.00170",
    "authors": [
      "Yuting Wang",
      "Hangning Zhou",
      "Zhigang Zhang",
      "Chen Feng",
      "Huadong Lin",
      "Chaofei Gao",
      "Yizhi Tang",
      "Zhenting Zhao",
      "Shiyu Zhang",
      "Jie Guo",
      "Xuefeng Wang",
      "Ziyao Xu",
      "Chi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.00177",
    "title": "Deep Motion Network for Freehand 3D Ultrasound Reconstruction",
    "abstract": "Freehand 3D ultrasound (US) has important clinical value due to its low cost and unrestricted field of view. Recently deep learning algorithms have removed its dependence on bulky and expensive external positioning devices. However, improving reconstruction accuracy is still hampered by difficult elevational displacement estimation and large cumulative drift. In this context, we propose a novel deep motion network (MoNet) that integrates images and a lightweight sensor known as the inertial measurement unit (IMU) from a velocity perspective to alleviate the obstacles mentioned above. Our contribution is two-fold. First, we introduce IMU acceleration for the first time to estimate elevational displacements outside the plane. We propose a temporal and multi-branch structure to mine the valuable information of low signal-to-noise ratio (SNR) acceleration. Second, we propose a multi-modal online self-supervised strategy that leverages IMU information as weak labels for adaptive optimization to reduce drift errors and further ameliorate the impacts of acceleration noise. Experiments show that our proposed method achieves the superior reconstruction performance, exceeding state-of-the-art methods across the board. ",
    "url": "https://arxiv.org/abs/2207.00177",
    "authors": [
      "Mingyuan Luo",
      "Xin Yang",
      "Hongzhang Wang",
      "Liwei Du",
      "Dong Ni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.00187",
    "title": "An Understanding-Oriented Robust Machine Reading Comprehension Model",
    "abstract": "Although existing machine reading comprehension models are making rapid progress on many datasets, they are far from robust. In this paper, we propose an understanding-oriented machine reading comprehension model to address three kinds of robustness issues, which are over sensitivity, over stability and generalization. Specifically, we first use a natural language inference module to help the model understand the accurate semantic meanings of input questions so as to address the issues of over sensitivity and over stability. Then in the machine reading comprehension module, we propose a memory-guided multi-head attention method that can further well understand the semantic meanings of input questions and passages. Third, we propose a multilanguage learning mechanism to address the issue of generalization. Finally, these modules are integrated with a multi-task learning based method. We evaluate our model on three benchmark datasets that are designed to measure models robustness, including DuReader (robust) and two SQuAD-related datasets. Extensive experiments show that our model can well address the mentioned three kinds of robustness issues. And it achieves much better results than the compared state-of-the-art models on all these datasets under different evaluation metrics, even under some extreme and unfair evaluations. The source code of our work is available at: https://github.com/neukg/RobustMRC. ",
    "url": "https://arxiv.org/abs/2207.00187",
    "authors": [
      "Feiliang Ren",
      "Yongkang Liu",
      "Bochao Li",
      "Shilei Liu",
      "Bingchao Wang",
      "Jiaqi Wang",
      "Chunchao Liu",
      "Qi Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.00193",
    "title": "Reading and Writing: Discriminative and Generative Modeling for  Self-Supervised Text Recognition",
    "abstract": "Existing text recognition methods usually need large-scale training data. Most of them rely on synthetic training data due to the lack of annotated real images. However, there is a domain gap between the synthetic data and real data, which limits the performance of the text recognition models. Recent self-supervised text recognition methods attempted to utilize unlabeled real images by introducing contrastive learning, which mainly learns the discrimination of the text images. Inspired by the observation that humans learn to recognize the texts through both reading and writing, we propose to learn discrimination and generation by integrating contrastive learning and masked image modeling in our self-supervised method. The contrastive learning branch is adopted to learn the discrimination of text images, which imitates the reading behavior of humans. Meanwhile, masked image modeling is firstly introduced for text recognition to learn the context generation of the text images, which is similar to the writing behavior. The experimental results show that our method outperforms previous self-supervised text recognition methods by 10.2%-20.2% on irregular scene text recognition datasets. Moreover, our proposed text recognizer exceeds previous state-of-the-art text recognition methods by averagely 5.3% on 11 benchmarks, with similar model size. We also demonstrate that our pre-trained model can be easily applied to other text-related tasks with obvious performance gain. ",
    "url": "https://arxiv.org/abs/2207.00193",
    "authors": [
      "Mingkun Yang",
      "Minghui Liao",
      "Pu Lu",
      "Jing Wang",
      "Shenggao Zhu",
      "Hualin Luo",
      "Qi Tian",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00202",
    "title": "DiffPills: Differentiable Collision Detection for Capsules and Padded  Polygons",
    "abstract": "Collision detection plays an important role in simulation, control, and learning for robotic systems. However, no existing method is differentiable with respect to the configurations of the objects, greatly limiting the sort of algorithms that can be built on top of collision detection. In this work, we propose a set of differentiable collision detection algorithms between capsules and padded polygons by formulating these problems as differentiable convex quadratic programs. The resulting algorithms are able to return a proximity value indicating if a collision has taken place, as well as the closest points between objects, all of which are differentiable. As a result, they can be used reliably within other gradient-based optimization methods, including trajectory optimization, state estimation, and reinforcement learning methods. ",
    "url": "https://arxiv.org/abs/2207.00202",
    "authors": [
      "Kevin Tracy",
      "Taylor A. Howell",
      "Zachary Manchester"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.00208",
    "title": "e-CLIP: Large-Scale Vision-Language Representation Learning in  E-commerce",
    "abstract": "Understanding vision and language representations of product content is vital for search and recommendation applications in e-commerce. As a backbone for online shopping platforms and inspired by the recent success in representation learning research, we propose a contrastive learning framework that aligns language and visual models using unlabeled raw product text and images. We present techniques we used to train large-scale representation learning models and share solutions that address domain-specific challenges. We study the performance using our pre-trained model as backbones for diverse downstream tasks, including category classification, attribute extraction, product matching, product clustering, and adult product recognition. Experimental results show that our proposed method outperforms the baseline in each downstream task regarding both single modality and multiple modalities. ",
    "url": "https://arxiv.org/abs/2207.00208",
    "authors": [
      "Wonyoung Shin",
      "Jonghun Park",
      "Taekang Woo",
      "Yongwoo Cho",
      "Kwangjin Oh",
      "Hwanjun Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00210",
    "title": "Neural Parameterization for Dynamic Human Head Editing",
    "abstract": "Implicit radiance functions emerged as a powerful scene representation for reconstructing and rendering photo-realistic views of a 3D scene. These representations, however, suffer from poor editability. On the other hand, explicit representations such as polygonal meshes allow easy editing but are not as suitable for reconstructing accurate details in dynamic human heads, such as fine facial features, hair, teeth, and eyes. In this work, we present Neural Parameterization (NeP), a hybrid representation that provides the advantages of both implicit and explicit methods. NeP is capable of photo-realistic rendering while allowing fine-grained editing of the scene geometry and appearance. We first disentangle the geometry and appearance by parameterizing the 3D geometry into 2D texture space. We enable geometric editability by introducing an explicit linear deformation blending layer. The deformation is controlled by a set of sparse key points, which can be explicitly and intuitively displaced to edit the geometry. For appearance, we develop a hybrid 2D texture consisting of an explicit texture map for easy editing and implicit view and time-dependent residuals to model temporal and view variations. We compare our method to several reconstruction and editing baselines. The results show that the NeP achieves almost the same level of rendering accuracy while maintaining high editability. ",
    "url": "https://arxiv.org/abs/2207.00210",
    "authors": [
      "Li Ma",
      "Xiaoyu Li",
      "Jing Liao",
      "Xuan Wang",
      "Qi Zhang",
      "Jue Wang",
      "Pedro Sander"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2207.00222",
    "title": "Bayesian causal inference in automotive software engineering and online  evaluation",
    "abstract": "Randomised field experiments, such as A/B testing, have long been the gold standard for evaluating software changes. In the automotive domain, running randomised field experiments is not always desired, possible, or even ethical. In the face of such limitations, we develop a framework BOAT (Bayesian causal modelling for ObvservAtional Testing), utilising observational studies in combination with Bayesian causal inference, in order to understand real-world impacts from complex automotive software updates and help software development organisations arrive at causal conclusions. In this study, we present three causal inference models in the Bayesian framework and their corresponding cases to address three commonly experienced challenges of software evaluation in the automotive domain. We develop the BOAT framework with our industry collaborator, and demonstrate the potential of causal inference by conducting empirical studies on a large fleet of vehicles. Moreover, we relate the causal assumption theories to their implications in practise, aiming to provide a comprehensive guide on how to apply the causal models in automotive software engineering. We apply Bayesian propensity score matching for producing balanced control and treatment groups when we do not have access to the entire user base, Bayesian regression discontinuity design for identifying covariate dependent treatment assignments and the local treatment effect, and Bayesian difference-in-differences for causal inference of treatment effect overtime and implicitly control unobserved confounding factors. Each one of the demonstrative case has its grounds in practise, and is a scenario experienced when randomisation is not feasible. With the BOAT framework, we enable online software evaluation in the automotive domain without the need of a fully randomised experiment. ",
    "url": "https://arxiv.org/abs/2207.00222",
    "authors": [
      "Yuchu Liu",
      "David Issa Mattos",
      "Jan Bosch",
      "Helena Holmstr\u00f6m Olsson",
      "Jonn Lantz"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2207.00232",
    "title": "Multi-features based Semantic Augmentation Networks for Named Entity  Recognition in Threat Intelligence",
    "abstract": "Extracting cybersecurity entities such as attackers and vulnerabilities from unstructured network texts is an important part of security analysis. However, the sparsity of intelligence data resulted from the higher frequency variations and the randomness of cybersecurity entity names makes it difficult for current methods to perform well in extracting security-related concepts and entities. To this end, we propose a semantic augmentation method which incorporates different linguistic features to enrich the representation of input tokens to detect and classify the cybersecurity names over unstructured text. In particular, we encode and aggregate the constituent feature, morphological feature and part of speech feature for each input token to improve the robustness of the method. More than that, a token gets augmented semantic information from its most similar K words in cybersecurity domain corpus where an attentive module is leveraged to weigh differences of the words, and from contextual clues based on a large-scale general field corpus. We have conducted experiments on the cybersecurity datasets DNRTI and MalwareTextDB, and the results demonstrate the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2207.00232",
    "authors": [
      "Peipei Liu",
      "Hong Li",
      "Zuoguang Wang",
      "Jie Liu",
      "Yimo Ren",
      "Hongsong Zhu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2207.00234",
    "title": "Visual Transformer Meets CutMix for Improved Accuracy, Communication  Efficiency, and Data Privacy in Split Learning",
    "abstract": "This article seeks for a distributed learning solution for the visual transformer (ViT) architectures. Compared to convolutional neural network (CNN) architectures, ViTs often have larger model sizes, and are computationally expensive, making federated learning (FL) ill-suited. Split learning (SL) can detour this problem by splitting a model and communicating the hidden representations at the split-layer, also known as smashed data. Notwithstanding, the smashed data of ViT are as large as and as similar as the input data, negating the communication efficiency of SL while violating data privacy. To resolve these issues, we propose a new form of CutSmashed data by randomly punching and compressing the original smashed data. Leveraging this, we develop a novel SL framework for ViT, coined CutMixSL, communicating CutSmashed data. CutMixSL not only reduces communication costs and privacy leakage, but also inherently involves the CutMix data augmentation, improving accuracy and scalability. Simulations corroborate that CutMixSL outperforms baselines such as parallelized SL and SplitFed that integrates FL with SL. ",
    "url": "https://arxiv.org/abs/2207.00234",
    "authors": [
      "Sihun Baek",
      "Jihong Park",
      "Praneeth Vepakomma",
      "Ramesh Raskar",
      "Mehdi Bennis",
      "Seong-Lyun Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2207.00246",
    "title": "Point Cloud Change Detection With Stereo V-SLAM:Dataset, Metrics and  Baseline",
    "abstract": "Localization and navigation are basic robotic tasks requiring an accurate and up-to-date map to finish these tasks, with crowdsourced data to detect map changes posing an appealing solution. Collecting and processing crowdsourced data requires low-cost sensors and algorithms, but existing methods rely on expensive sensors or computationally expensive algorithms. Additionally, there is no existing dataset to evaluate point cloud change detection. Thus, this paper proposes a novel framework using low-cost sensors like stereo cameras and IMU to detect changes in a point cloud map. Moreover, we create a dataset and the corresponding metrics to evaluate point cloud change detection with the help of the high-fidelity simulator Unreal Engine 4. Experiments show that our visualbased framework can effectively detect the changes in our dataset. ",
    "url": "https://arxiv.org/abs/2207.00246",
    "authors": [
      "Zihan Lin",
      "Jincheng Yu",
      "Lipu Zhou",
      "Xudong Zhang",
      "Jian Wang",
      "Yu Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.00255",
    "title": "Trajectory Forecasting on Temporal Graphs",
    "abstract": "Predicting future locations of agents in the scene is an important problem in self-driving. In recent years, there has been a significant progress in representing the scene and the agents in it. The interactions of agents with the scene and with each other are typically modeled with a Graph Neural Network. However, the graph structure is mostly static and fails to represent the temporal changes in highly dynamic scenes. In this work, we propose a temporal graph representation to better capture the dynamics in traffic scenes. We complement our representation with two types of memory modules; one focusing on the agent of interest and the other on the entire scene. This allows us to learn temporally-aware representations that can achieve good results even with simple regression of multiple futures. When combined with goal-conditioned prediction, we show better results that can reach the state-of-the-art performance on the Argoverse benchmark. ",
    "url": "https://arxiv.org/abs/2207.00255",
    "authors": [
      "G\u00f6rkay Aydemir",
      "Adil Kaan Akan",
      "Fatma G\u00fcney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.00263",
    "title": "Effect of Homomorphic Encryption on the Performance of Training  Federated Learning Generative Adversarial Networks",
    "abstract": "A Generative Adversarial Network (GAN) is a deep-learning generative model in the field of Machine Learning (ML) that involves training two Neural Networks (NN) using a sizable data set. In certain fields, such as medicine, the training data may be hospital patient records that are stored across different hospitals. The classic centralized approach would involve sending the data to a centralized server where the model would be trained. However, that would involve breaching the privacy and confidentiality of the patients and their data, which would be unacceptable. Therefore, Federated Learning (FL), an ML technique that trains ML models in a distributed setting without data ever leaving the host device, would be a better alternative to the centralized option. In this ML technique, only parameters and certain metadata would be communicated. In spite of that, there still exist attacks that can infer user data using the parameters and metadata. A fully privacy-preserving solution involves homomorphically encrypting (HE) the data communicated. This paper will focus on the performance loss of training an FL-GAN with three different types of Homomorphic Encryption: Partial Homomorphic Encryption (PHE), Somewhat Homomorphic Encryption (SHE), and Fully Homomorphic Encryption (FHE). We will also test the performance loss of Multi-Party Computations (MPC), as it has homomorphic properties. The performances will be compared to the performance of training an FL-GAN without encryption as well. Our experiments show that the more complex the encryption method is, the longer it takes, with the extra time taken for HE is quite significant in comparison to the base case of FL. ",
    "url": "https://arxiv.org/abs/2207.00263",
    "authors": [
      "Ignjat Pejic",
      "Rui Wang",
      "Kaitai Liang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00264",
    "title": "A Functional Architecture for 6G Special Purpose Industrial IoT Networks",
    "abstract": "Future industrial applications will encompass compelling new use cases requiring stringent performance guarantees over multiple key performance indicators (KPI) such as reliability, dependability, latency, time synchronization, security, etc. Achieving such stringent and diverse service requirements necessitates the design of a special-purpose Industrial Internet of Things (IIoT) network comprising a multitude of specialized functionalities and technological enablers. This article proposes an innovative architecture for such a special-purpose 6G IIoT network incorporating seven functional building blocks categorized into: special-purpose functionalities and enabling technologies. The former consists of Wireless Environment Control, Traffic/Channel Prediction, Proactive Resource Management and End-to-End Optimization functions; whereas the latter includes Synchronization and Coordination, Machine Learning and Artificial Intelligence Algorithms, and Auxiliary Functions. The proposed architecture aims at providing a resource-efficient and holistic solution for the complex and dynamically challenging requirements imposed by future 6G industrial use cases. Selected test scenarios are provided and assessed to illustrate cross-functional collaboration and demonstrate the applicability of the proposed architecture in a wireless IIoT network. ",
    "url": "https://arxiv.org/abs/2207.00264",
    "authors": [
      "{Nurul Huda Mahmood",
      "Gilberto Berardinelli",
      "Emil J. Khatib",
      "Ramin Hashemi",
      "Carlos de Lima",
      "Matti Latva-aho"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.00278",
    "title": "BadHash: Invisible Backdoor Attacks against Deep Hashing with Clean  Label",
    "abstract": "Due to its powerful feature learning capability and high efficiency, deep hashing has achieved great success in large-scale image retrieval. Meanwhile, extensive works have demonstrated that deep neural networks (DNNs) are susceptible to adversarial examples, and exploring adversarial attack against deep hashing has attracted many research efforts. Nevertheless, backdoor attack, another famous threat to DNNs, has not been studied for deep hashing yet. Although various backdoor attacks have been proposed in the field of image classification, existing approaches failed to realize a truly imperceptive backdoor attack that enjoys invisible triggers and clean label setting simultaneously, and they also cannot meet the intrinsic demand of image retrieval backdoor. In this paper, we propose BadHash, the first generative-based imperceptible backdoor attack against deep hashing, which can effectively generate invisible and input-specific poisoned images with clean label. Specifically, we first propose a new conditional generative adversarial network (cGAN) pipeline to effectively generate poisoned samples. For any given benign image, it seeks to generate a natural-looking poisoned counterpart with a unique invisible trigger. In order to improve the attack effectiveness, we introduce a label-based contrastive learning network LabCLN to exploit the semantic characteristics of different labels, which are subsequently used for confusing and misleading the target model to learn the embedded trigger. We finally explore the mechanism of backdoor attacks on image retrieval in the hash space. Extensive experiments on multiple benchmark datasets verify that BadHash can generate imperceptible poisoned samples with strong attack ability and transferability over state-of-the-art deep hashing schemes. Primary Subject Area: [Engagement] Multimedia Search and Recommendation ",
    "url": "https://arxiv.org/abs/2207.00278",
    "authors": [
      "Shengshan Hu",
      "Ziqi Zhou",
      "Yechao Zhang",
      "Leo Yu Zhang",
      "Yifeng Zheng",
      "Yuanyuan HE",
      "Hai Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00282",
    "title": "(Un)likelihood Training for Interpretable Embedding",
    "abstract": "Cross-modal representation learning has become a new normal for bridging the semantic gap between text and visual data. Learning modality agnostic representations in a continuous latent space, however, is often treated as a black-box data-driven training process. It is well-known that the effectiveness of representation learning depends heavily on the quality and scale of training data. For video representation learning, having a complete set of labels that annotate the full spectrum of video content for training is highly difficult if not impossible. These issues, black-box training and dataset bias, make representation learning practically challenging to be deployed for video understanding due to unexplainable and unpredictable results. In this paper, we propose two novel training objectives, likelihood and unlikelihood functions, to unroll semantics behind embeddings while addressing the label sparsity problem in training. The likelihood training aims to interpret semantics of embeddings beyond training labels, while the unlikelihood training leverages prior knowledge for regularization to ensure semantically coherent interpretation. With both training objectives, a new encoder-decoder network, which learns interpretable cross-modal representation, is proposed for ad-hoc video search. Extensive experiments on TRECVid and MSR-VTT datasets show the proposed network outperforms several state-of-the-art retrieval models with a statistically significant performance margin. ",
    "url": "https://arxiv.org/abs/2207.00282",
    "authors": [
      "Jiaxin Wu",
      "Chong-Wah Ngo",
      "Wing-Kwong Chan",
      "Zhijian Hou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.00291",
    "title": "A Comparative Study of Graph Matching Algorithms in Computer Vision",
    "abstract": "The graph matching optimization problem is an essential component for many tasks in computer vision, such as bringing two deformable objects in correspondence. Naturally, a wide range of applicable algorithms have been proposed in the last decades. Since a common standard benchmark has not been developed, their performance claims are often hard to verify as evaluation on differing problem instances and criteria make the results incomparable. To address these shortcomings, we present a comparative study of graph matching algorithms. We create a uniform benchmark where we collect and categorize a large set of existing and publicly available computer vision graph matching problems in a common format. At the same time we collect and categorize the most popular open-source implementations of graph matching algorithms. Their performance is evaluated in a way that is in line with the best practices for comparing optimization algorithms. The study is designed to be reproducible and extensible to serve as a valuable resource in the future. Our study provides three notable insights: 1.) popular problem instances are exactly solvable in substantially less than 1 second and, therefore, are insufficient for future empirical evaluations; 2.) the most popular baseline methods are highly inferior to the best available methods; 3.) despite the NP-hardness of the problem, instances coming from vision applications are often solvable in a few seconds even for graphs with more than 500 vertices. ",
    "url": "https://arxiv.org/abs/2207.00291",
    "authors": [
      "Stefan Haller",
      "Lorenz Feineis",
      "Lisa Hutschenreiter",
      "Florian Bernard",
      "Carsten Rother",
      "Dagmar Kainm\u00fcller",
      "Paul Swoboda",
      "Bogdan Savchynskyy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2207.00292",
    "title": "Offset equivariant networks and their applications",
    "abstract": "In this paper we present a framework for the design and implementation of offset equivariant networks, that is, neural networks that preserve in their output uniform increments in the input. In a suitable color space this kind of networks achieves equivariance with respect to the photometric transformations that characterize changes in the lighting conditions. We verified the framework on three different problems: image recognition, illuminant estimation, and image inpainting. Our experiments show that the performance of offset equivariant networks are comparable to those in the state of the art on regular data. Differently from conventional networks, however, equivariant networks do behave consistently well when the color of the illuminant changes. ",
    "url": "https://arxiv.org/abs/2207.00292",
    "authors": [
      "Marco Cotogni",
      "Claudio Cusano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00300",
    "title": "Robust Bayesian Learning for Reliable Wireless AI: Framework and  Applications",
    "abstract": "This work takes a critical look at the application of conventional machine learning methods to wireless communication problems through the lens of reliability and robustness. Deep learning techniques adopt a frequentist framework, and are known to provide poorly calibrated decisions that do not reproduce the true uncertainty caused by limitations in the size of the training data. Bayesian learning, while in principle capable of addressing this shortcoming, is in practice impaired by model misspecification and by the presence of outliers. Both problems are pervasive in wireless communication settings, in which the capacity of machine learning models is subject to resource constraints and training data is affected by noise and interference. In this context, we explore the application of the framework of robust Bayesian learning. After a tutorial-style introduction to robust Bayesian learning, we showcase the merits of robust Bayesian learning on several important wireless communication problems in terms of accuracy, calibration, and robustness to outliers and misspecification. ",
    "url": "https://arxiv.org/abs/2207.00300",
    "authors": [
      "Matteo Zecchin",
      "Sangwoo Park",
      "Osvaldo Simeone",
      "Marios Kountouris",
      "David Gesbert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2207.00309",
    "title": "A Tensor-Product Finite Element Cochain Complex with Arbitrary  Continuity",
    "abstract": "We develop tensor product finite element cochain complexes of arbitrary smoothness on Cartesian meshes of arbitrary dimension. The first step is the construction of a one-dimensional $C^m$-conforming finite element cochain complex based on a modified Hermite interpolation operator, which is proved to commute with the exterior derivative by means of a general commutation lemma. Adhering to a strict tensor product construction we then derive finite element complexes in higher dimensions. ",
    "url": "https://arxiv.org/abs/2207.00309",
    "authors": [
      "Francesca Bonizzoni",
      "Guido Kanschat"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.00328",
    "title": "TopicFM: Robust and Interpretable Feature Matching with Topic-assisted",
    "abstract": "Finding correspondences across images is an important task in many visual applications. Recent state-of-the-art methods focus on end-to-end learning-based architectures designed in a coarse-to-fine manner. They use a very deep CNN or multi-block Transformer to learn robust representation, which requires high computation power. Moreover, these methods learn features without reasoning about objects, shapes inside images, thus lacks of interpretability. In this paper, we propose an architecture for image matching which is efficient, robust, and interpretable. More specifically, we introduce a novel feature matching module called TopicFM which can roughly organize same spatial structure across images into a topic and then augment the features inside each topic for accurate matching. To infer topics, we first learn global embedding of topics and then use a latent-variable model to detect-then-assign the image structures into topics. Our method can only perform matching in co-visibility regions to reduce computations. Extensive experiments in both outdoor and indoor datasets show that our method outperforms the recent methods in terms of matching performance and computational efficiency. The code is available at https://github.com/TruongKhang/TopicFM. ",
    "url": "https://arxiv.org/abs/2207.00328",
    "authors": [
      "Khang Truong Giang",
      "Soohwan Song",
      "Sungho Jo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00329",
    "title": "Literature on Hand GESTURE Recognition using Graph based methods",
    "abstract": "Skeleton based recognition systems are gaining popularity and machine learning models focusing on points or joints in a skeleton have proved to be computationally effective and application in many areas like Robotics. It is easy to track points and thereby preserving spatial and temporal information, which plays an important role in abstracting the required information, classification becomes an easy task. In this paper, we aim to study these points but using a cloud mechanism, where we define a cloud as collection of points. However, when we add temporal information, it may not be possible to retrieve the coordinates of a point in each frame and hence instead of focusing on a single point, we can use k-neighbors to retrieve the state of the point under discussion. Our focus is to gather such information using weight sharing but making sure that when we try to retrieve the information from neighbors, we do not carry noise with it. LSTM which has capability of long-term modelling and can carry both temporal and spatial information. In this article we tried to summarise graph based gesture recognition method. ",
    "url": "https://arxiv.org/abs/2207.00329",
    "authors": [
      "Neha Baranwal",
      "Varun Sharma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00368",
    "title": "Multi-Objective Coordination Graphs for the Expected Scalarised Returns  with Generative Flow Models",
    "abstract": "Many real-world problems contain multiple objectives and agents, where a trade-off exists between objectives. Key to solving such problems is to exploit sparse dependency structures that exist between agents. For example, in wind farm control a trade-off exists between maximising power and minimising stress on the systems components. Dependencies between turbines arise due to the wake effect. We model such sparse dependencies between agents as a multi-objective coordination graph (MO-CoG). In multi-objective reinforcement learning a utility function is typically used to model a users preferences over objectives, which may be unknown a priori. In such settings a set of optimal policies must be computed. Which policies are optimal depends on which optimality criterion applies. If the utility function of a user is derived from multiple executions of a policy, the scalarised expected returns (SER) must be optimised. If the utility of a user is derived from a single execution of a policy, the expected scalarised returns (ESR) criterion must be optimised. For example, wind farms are subjected to constraints and regulations that must be adhered to at all times, therefore the ESR criterion must be optimised. For MO-CoGs, the state-of-the-art algorithms can only compute a set of optimal policies for the SER criterion, leaving the ESR criterion understudied. To compute a set of optimal polices under the ESR criterion, also known as the ESR set, distributions over the returns must be maintained. Therefore, to compute a set of optimal policies under the ESR criterion for MO-CoGs, we present a novel distributional multi-objective variable elimination (DMOVE) algorithm. We evaluate DMOVE in realistic wind farm simulations. Given the returns in real-world wind farm settings are continuous, we utilise a model known as real-NVP to learn the continuous return distributions to calculate the ESR set. ",
    "url": "https://arxiv.org/abs/2207.00368",
    "authors": [
      "Conor F. Hayes",
      "Timothy Verstraeten",
      "Diederik M. Roijers",
      "Enda Howley",
      "Patrick Mannion"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00377",
    "title": "Anisotropic, Sparse and Interpretable Physics-Informed Neural Networks  for PDEs",
    "abstract": "There has been a growing interest in the use of Deep Neural Networks (DNNs) to solve Partial Differential Equations (PDEs). Despite the promise that such approaches hold, there are various aspects where they could be improved. Two such shortcomings are (i) their computational inefficiency relative to classical numerical methods, and (ii) the non-interpretability of a trained DNN model. In this work we present ASPINN, an anisotropic extension of our earlier work called SPINN--Sparse, Physics-informed, and Interpretable Neural Networks--to solve PDEs that addresses both these issues. ASPINNs generalize radial basis function networks. We demonstrate using a variety of examples involving elliptic and hyperbolic PDEs that the special architecture we propose is more efficient than generic DNNs, while at the same time being directly interpretable. Further, they improve upon the SPINN models we proposed earlier in that fewer nodes are require to capture the solution using ASPINN than using SPINN, thanks to the anisotropy of the local zones of influence of each node. The interpretability of ASPINN translates to a ready visualization of their weights and biases, thereby yielding more insight into the nature of the trained model. This in turn provides a systematic procedure to improve the architecture based on the quality of the computed solution. ASPINNs thus serve as an effective bridge between classical numerical algorithms and modern DNN based methods to solve PDEs. In the process, we also streamline the training of ASPINNs into a form that is closer to that of supervised learning algorithms. ",
    "url": "https://arxiv.org/abs/2207.00377",
    "authors": [
      "Amuthan A. Ramabathiran",
      "Prabhu Ramachandran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00411",
    "title": "Adversarial Robustness is at Odds with Lazy Training",
    "abstract": "Recent works show that random neural networks are vulnerable against adversarial attacks [Daniely and Schacham, 2020] and that such attacks can be easily found using a single step of gradient descent [Bubeck et al., 2021]. In this work, we take it one step further and show that a single gradient step can find adversarial examples for networks trained in the so-called lazy regime. This regime is interesting because even though the neural network weights remain close to the initialization, there exist networks with small generalization error, which can be found efficiently using first-order methods. Our work challenges the model of the lazy regime, the dominant regime in which neural networks are provably efficiently learnable. We show that the networks trained in this regime, even though they enjoy good theoretical computational guarantees, remain vulnerable to adversarial examples. To the best of our knowledge, this is the first work to prove that such well-generalizable neural networks are still vulnerable to adversarial attacks. ",
    "url": "https://arxiv.org/abs/2207.00411",
    "authors": [
      "Yunjuan Wang",
      "Enayat Ullah",
      "Poorya Mianjy",
      "Raman Arora"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.00414",
    "title": "Artificial Intelligence Techniques for Next-Generation Mega Satellite  Networks",
    "abstract": "Space communications, particularly mega satellite networks, re-emerged as an appealing candidate for next generation networks due to major advances in space launching, electronics, processing power, and miniaturization. However, mega satellite networks rely on numerous underlying and intertwined processes that cannot be truly captured using conventionally used models, due to their dynamic and unique features such as orbital speed, inter-satellite links, short time pass, and satellite footprint, among others. Hence, new approaches are needed to enable the network to proactively adjust to the rapidly varying conditions associated within the link. Artificial intelligence (AI) provides a pathway to capture these processes, analyze their behavior, and model their effect on the network. This article introduces the application of AI techniques for integrated terrestrial satellite networks, particularly mega satellite network communications. It details the unique features of mega satellite networks, and the overarching challenges concomitant with their integration into the current communication infrastructure. Moreover, the article provides insights into state-of-the-art AI techniques across various layers of the communication link. This entails applying AI for forecasting the highly dynamic radio channel, spectrum sensing and classification, signal detection and demodulation, inter-satellite link and satellite access network optimization, and network security. Moreover, future paradigms and the mapping of these mechanisms onto practical networks are outlined. ",
    "url": "https://arxiv.org/abs/2207.00414",
    "authors": [
      "Bassel Al Homssi",
      "Kosta Dakic",
      "Ke Wang",
      "Tansu Alpcan",
      "Ben Allen",
      "Sithamparanathan Kandeepan",
      "Akram Al-Hourani",
      "Walid Saad"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.00415",
    "title": "AI in 6G: Energy-Efficient Distributed Machine Learning for Multilayer  Heterogeneous Networks",
    "abstract": "Adept network management is key for supporting extremely heterogeneous applications with stringent quality of service (QoS) requirements; this is more so when envisioning the complex and ultra-dense 6G mobile heterogeneous network (HetNet). From both the environmental and economical perspectives, non-homogeneous QoS demands obstruct the minimization of the energy footprints and operational costs of the envisioned robust networks. As such, network intelligentization is expected to play an essential role in the realization of such sophisticated aims. The fusion of artificial intelligence (AI) and mobile networks will allow for the dynamic and automatic configuration of network functionalities. Machine learning (ML), one of the backbones of AI, will be instrumental in forecasting changes in network loads and resource utilization, estimating channel conditions, optimizing network slicing, and enhancing security and encryption. However, it is well known that ML tasks themselves incur massive computational burdens and energy costs. To overcome such obstacles, we propose a novel layer-based HetNet architecture which optimally distributes tasks associated with different ML approaches across network layers and entities; such a HetNet boasts multiple access schemes as well as device-to-device (D2D) communications to enhance energy efficiency via collaborative learning and communications. ",
    "url": "https://arxiv.org/abs/2207.00415",
    "authors": [
      "Mohammad Arif Hossain",
      "Abdullah Ridwan Hossain",
      "Nirwan Ansari"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00416",
    "title": "Energy Efficient Routing For Underwater Acoustic Sensor Network Using  Genetic Algorithm",
    "abstract": "In underwater acoustic sensor networks (UWASN), energy-reliable data transmission is a challenging task. This is due to acoustic transmission disturbances caused by excessive noise, exceptionally long propagation delays, a high bit error rate, limited bandwidth capability, and interference. One of the most important issues of UWASN for research is how to extend the life span of data transmission. Data transfer from a source node to a destination node in UWASN is a complicated topic for researchers. Many routing algorithms, such as vector base forwarding and depth base routing, have been developed in past years. We propose a genetic algorithm-based optimization method for improving the energy efficiency of data transmission in the routing path from a source node to a destination node. ",
    "url": "https://arxiv.org/abs/2207.00416",
    "authors": [
      "Arjun Prasad Chaurasiya",
      "Roshan Sah",
      "Dr.V.Sivakumar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.00419",
    "title": "Self-Supervised Learning for Videos: A Survey",
    "abstract": "The remarkable success of deep learning in various domains relies on the availability of large-scale annotated datasets. However, the use of human-generated annotations leads to models with biased learning, poor domain generalization, and poor robustness. Obtaining annotations is also expensive and requires great effort, which is especially challenging for videos. As an alternative, self-supervised learning provides a way for representation learning which does not require annotations and has shown promise in both image and video domains. Different from the image domain, learning video representations are more challenging due to the temporal dimension, bringing in motion and other environmental dynamics. This also provides opportunities for exclusive ideas which can advance self-supervised learning in the video and multimodal domain. In this survey, we provide a review of existing approaches on self-supervised learning focusing on the video domain. We summarize these methods into three different categories based on their learning objectives: pre-text tasks, generative modeling, and contrastive learning. These approaches also differ in terms of the modality which are being used: video, video-audio, video-text, and video-audio-text. We further introduce the commonly used datasets, downstream evaluation tasks, insights into the limitations of existing works, and the potential future directions in this area. ",
    "url": "https://arxiv.org/abs/2207.00419",
    "authors": [
      "Madeline C. Schiappa",
      "Yogesh S. Rawat",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.00420",
    "title": "Cactus Mechanisms: Optimal Differential Privacy Mechanisms in the  Large-Composition Regime",
    "abstract": "Most differential privacy mechanisms are applied (i.e., composed) numerous times on sensitive data. We study the design of optimal differential privacy mechanisms in the limit of a large number of compositions. As a consequence of the law of large numbers, in this regime the best privacy mechanism is the one that minimizes the Kullback-Leibler divergence between the conditional output distributions of the mechanism given two different inputs. We formulate an optimization problem to minimize this divergence subject to a cost constraint on the noise. We first prove that additive mechanisms are optimal. Since the optimization problem is infinite dimensional, it cannot be solved directly; nevertheless, we quantize the problem to derive near-optimal additive mechanisms that we call \"cactus mechanisms\" due to their shape. We show that our quantization approach can be arbitrarily close to an optimal mechanism. Surprisingly, for quadratic cost, the Gaussian mechanism is strictly sub-optimal compared to this cactus mechanism. Finally, we provide numerical results which indicate that cactus mechanism outperforms the Gaussian mechanism for a finite number of compositions. ",
    "url": "https://arxiv.org/abs/2207.00420",
    "authors": [
      "Wael Alghamdi",
      "Shahab Asoodeh",
      "Flavio P. Calmon",
      "Oliver Kosut",
      "Lalitha Sankar",
      "Fei Wei"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00421",
    "title": "Generative Adversarial Networks and Image-Based Malware Classification",
    "abstract": "For efficient malware removal, determination of malware threat levels, and damage estimation, malware family classification plays a critical role. In this paper, we extract features from malware executable files and represent them as images using various approaches. We then focus on Generative Adversarial Networks (GAN) for multiclass classification and compare our GAN results to other popular machine learning techniques, including Support Vector Machine (SVM), XGBoost, and Restricted Boltzmann Machines (RBM). We find that the AC-GAN discriminator is generally competitive with other machine learning techniques. We also evaluate the utility of the GAN generative model for adversarial attacks on image-based malware detection. While AC-GAN generated images are visually impressive, we find that they are easily distinguished from real malware images using any of several learning techniques. This result indicates that our GAN generated images would be of little value in adversarial attacks. ",
    "url": "https://arxiv.org/abs/2207.00421",
    "authors": [
      "Huy Nguyen",
      "Fabio Di Troia",
      "Genya Ishigaki",
      "Mark Stamp"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00424",
    "title": "LBDMIDS: LSTM Based Deep Learning Model for Intrusion Detection Systems  for IoT Networks",
    "abstract": "In the recent years, we have witnessed a huge growth in the number of Internet of Things (IoT) and edge devices being used in our everyday activities. This demands the security of these devices from cyber attacks to be improved to protect its users. For years, Machine Learning (ML) techniques have been used to develop Network Intrusion Detection Systems (NIDS) with the aim of increasing their reliability/robustness. Among the earlier ML techniques DT performed well. In the recent years, Deep Learning (DL) techniques have been used in an attempt to build more reliable systems. In this paper, a Deep Learning enabled Long Short Term Memory (LSTM) Autoencoder and a 13-feature Deep Neural Network (DNN) models were developed which performed a lot better in terms of accuracy on UNSW-NB15 and Bot-IoT datsets. Hence we proposed LBDMIDS, where we developed NIDS models based on variants of LSTMs namely, stacked LSTM and bidirectional LSTM and validated their performance on the UNSW\\_NB15 and BoT\\-IoT datasets. This paper concludes that these variants in LBDMIDS outperform classic ML techniques and perform similarly to the DNN models that have been suggested in the past. ",
    "url": "https://arxiv.org/abs/2207.00424",
    "authors": [
      "Kumar Saurabh",
      "Saksham Sood",
      "P. Aditya Kumar",
      "Uphar Singh",
      "Ranjana Vyas",
      "O.P. Vyas",
      "Rahamatullah Khondoker"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00425",
    "title": "Transferable Graph Backdoor Attack",
    "abstract": "Graph Neural Networks (GNNs) have achieved tremendous success in many graph mining tasks, benefitting from the message passing strategy that fuses the local structure and node features for much better graph representation learning. Despite the excellent performance of GNNs, but similar to other type of deep neural networks, the robustness of GNNs is unsatisfactory. It have been disclosed by many works that GNNs are vulnerable to unnoticeable perturbations on both graph structure and node features. Many adversarial attacks have been proposed to disclose the fragility of GNNs under different perturbation strategies to create adversarial examples. However, less work has been done to show the vulnerability of GNNs under backdoor attack. To fill this gap, in this paper, we present GHAT, transferable GrapH bAckdoor aTtack. The core principle of GHAT is to poison training dataset with perturbation triggers that can lead to effective and transferable backdoor attack. The perturbation trigger for a graph is generated by performing the perturbation actions on the graph structure via a gradient based score matrix. Compared with the prior works, GHAT is different in several ways: it exploits a surrogate GCN model to generate perturbation trigger for black-box based backdoor attack; it generates sample-specific perturbation triggers which do not have fixed pattern; the attack of GHAT can be transferable to different GNN models when trained with the poisoned training dataset forged by GHAT. Through extensive evaluation on four real-world datasets, we demonstrate that GHAT shows much better attack effectiveness in regard to transferable backdoor attack on GNNs. ",
    "url": "https://arxiv.org/abs/2207.00425",
    "authors": [
      "Shuiqiao Yang",
      "Bao Gia Doan",
      "Paul Montague",
      "Olivier De Vel",
      "Tamas Abraham",
      "Seyit Camtepe",
      "Damith C. Ranasinghe",
      "Salil S. Kanhere"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00428",
    "title": "FLVoogd: Robust And Privacy Preserving Federated Learning",
    "abstract": "In this work, we propose FLVoogd, an updated federated learning method in which servers and clients collaboratively eliminate Byzantine attacks while preserving privacy. In particular, servers use automatic Density-based Spatial Clustering of Applications with Noise (DBSCAN) combined with S2PC to cluster the benign majority without acquiring sensitive personal information. Meanwhile, clients build dual models and perform test-based distance controlling to adjust their local models toward the global one to achieve personalizing. Our framework is automatic and adaptive that servers/clients don't need to tune the parameters during the training. In addition, our framework leverages Secure Multi-party Computation (SMPC) operations, including multiplications, additions, and comparison, where costly operations, like division and square root, are not required. Evaluations are carried out on some conventional datasets from the image classification field. The result shows that FLVoogd can effectively reject malicious uploads in most scenarios; meanwhile, it avoids data leakage from the server-side. ",
    "url": "https://arxiv.org/abs/2207.00428",
    "authors": [
      "Yuhang Tian",
      "Rui Wang",
      "Yanqi Qiao",
      "Emmanouil Panaousis",
      "Kaitai Liang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00429",
    "title": "Modular Lifelong Reinforcement Learning via Neural Composition",
    "abstract": "Humans commonly solve complex problems by decomposing them into easier subproblems and then combining the subproblem solutions. This type of compositional reasoning permits reuse of the subproblem solutions when tackling future tasks that share part of the underlying compositional structure. In a continual or lifelong reinforcement learning (RL) setting, this ability to decompose knowledge into reusable components would enable agents to quickly learn new RL tasks by leveraging accumulated compositional structures. We explore a particular form of composition based on neural modules and present a set of RL problems that intuitively admit compositional solutions. Empirically, we demonstrate that neural composition indeed captures the underlying structure of this space of problems. We further propose a compositional lifelong RL method that leverages accumulated neural components to accelerate the learning of future tasks while retaining performance on previous tasks via off-line RL over replayed experiences. ",
    "url": "https://arxiv.org/abs/2207.00429",
    "authors": [
      "Jorge A. Mendez",
      "Harm van Seijen",
      "Eric Eaton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.00432",
    "title": "A Rare Topic Discovery Model for Short Texts Based on Co-occurrence word  Network",
    "abstract": "We provide a simple and general solution for the discovery of scarce topics in unbalanced short-text datasets, namely, a word co-occurrence network-based model CWIBTD, which can simultaneously address the sparsity and unbalance of short-text topics and attenuate the effect of occasional pairwise occurrences of words, allowing the model to focus more on the discovery of scarce topics. Unlike previous approaches, CWIBTD uses co-occurrence word networks to model the topic distribution of each word, which improves the semantic density of the data space and ensures its sensitivity in identify-ing rare topics by improving the way node activity is calculated and normal-izing scarce topics and large topics to some extent. In addition, using the same Gibbs sampling as LDA makes CWIBTD easy to be extended to vari-ous application scenarios. Extensive experimental validation in the unbal-anced short text dataset confirms the superiority of CWIBTD over the base-line approach in discovering rare topics. Our model can be used for early and accurate discovery of emerging topics or unexpected events on social platforms. ",
    "url": "https://arxiv.org/abs/2207.00432",
    "authors": [
      "Chengjie Ma",
      "Junping Du",
      "Yingxia Shao",
      "Ang Li",
      "Zeli Guan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00433",
    "title": "PROTOtypical Logic Tensor Networks (PROTO-LTN) for Zero Shot Learning",
    "abstract": "Semantic image interpretation can vastly benefit from approaches that combine sub-symbolic distributed representation learning with the capability to reason at a higher level of abstraction. Logic Tensor Networks (LTNs) are a class of neuro-symbolic systems based on a differentiable, first-order logic grounded into a deep neural network. LTNs replace the classical concept of training set with a knowledge base of fuzzy logical axioms. By defining a set of differentiable operators to approximate the role of connectives, predicates, functions and quantifiers, a loss function is automatically specified so that LTNs can learn to satisfy the knowledge base. We focus here on the subsumption or \\texttt{isOfClass} predicate, which is fundamental to encode most semantic image interpretation tasks. Unlike conventional LTNs, which rely on a separate predicate for each class (e.g., dog, cat), each with its own set of learnable weights, we propose a common \\texttt{isOfClass} predicate, whose level of truth is a function of the distance between an object embedding and the corresponding class prototype. The PROTOtypical Logic Tensor Networks (PROTO-LTN) extend the current formulation by grounding abstract concepts as parametrized class prototypes in a high-dimensional embedding space, while reducing the number of parameters required to ground the knowledge base. We show how this architecture can be effectively trained in the few and zero-shot learning scenarios. Experiments on Generalized Zero Shot Learning benchmarks validate the proposed implementation as a competitive alternative to traditional embedding-based approaches. The proposed formulation opens up new opportunities in zero shot learning settings, as the LTN formalism allows to integrate background knowledge in the form of logical axioms to compensate for the lack of labelled examples. ",
    "url": "https://arxiv.org/abs/2207.00433",
    "authors": [
      "Simone Martone",
      "Francesco Manigrasso",
      "Lamberti Fabrizio",
      "Lia Morra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00445",
    "title": "A Neural Network Based Novel Test Selector",
    "abstract": "Machine learning (ML) has been used to accelerate the progress of functional coverage in simulation-based verification. A supervised ML algorithm, as a prevalent option in the previous work, is used to bias the test generation or filter the generated tests. However, for missing coverage events, these algorithms lack the positive examples to learn from in the training phase. Therefore, the tests generated or filtered by the algorithms cannot effectively fill the coverage holes. This is more severe when verifying large-scale design because the coverage space is larger and the functionalities are more complex. This paper presents a configurable framework of test selection based on neural networks (NN), which can achieve a similar coverage gain as random simulation with far less simulation effort under three configurations of the framework. Moreover, the performance of the framework is not limited by the number of coverage events being hit. A commercial signal processing unit is used in the experiment to demonstrate the effectiveness of the framework. Compared to the random simulation, NNBNTS can reduce up to 53.74% of simulation time to reach 99% coverage level. ",
    "url": "https://arxiv.org/abs/2207.00445",
    "authors": [
      "Xuan Zheng",
      "Kerstin Eder",
      "Tim Blackmore"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00449",
    "title": "Dissecting Self-Supervised Learning Methods for Surgical Computer Vision",
    "abstract": "The field of surgical computer vision has undergone considerable breakthroughs in recent years with the rising popularity of deep neural network-based methods. However, standard fully-supervised approaches for training such models require vast amounts of annotated data, imposing a prohibitively high cost; especially in the clinical domain. Self-Supervised Learning (SSL) methods, which have begun to gain traction in the general computer vision community, represent a potential solution to these annotation costs, allowing to learn useful representations from only unlabeled data. Still, the effectiveness of SSL methods in more complex and impactful domains, such as medicine and surgery, remains limited and unexplored. In this work, we address this critical need by investigating four state-of-the-art SSL methods (MoCo v2, SimCLR, DINO, SwAV) in the context of surgical computer vision. We present an extensive analysis of the performance of these methods on the Cholec80 dataset for two fundamental and popular tasks in surgical context understanding, phase recognition and tool presence detection. We examine their parameterization, then their behavior with respect to training data quantities in semi-supervised settings. Correct transfer of these methods to surgery, as described and conducted in this work, leads to substantial performance gains over generic uses of SSL - up to 7% on phase recognition and 20% on tool presence detection - as well as state-of-the-art semi-supervised phase recognition approaches by up to 14%. The code will be made available at https://github.com/CAMMA-public/SelfSupSurg. ",
    "url": "https://arxiv.org/abs/2207.00449",
    "authors": [
      "Sanat Ramesh",
      "Vinkle Srivastav",
      "Deepak Alapatt",
      "Tong Yu",
      "Aditya Murali",
      "Luca Sestini",
      "Chinedu Innocent Nwoye",
      "Idris Hamoud",
      "Antoine Fleurentin",
      "Georgios Exarchakis",
      "Alexandros Karargyris",
      "Nicolas Padoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00463",
    "title": "Counting Dominating Sets in Directed Path Graphs",
    "abstract": "A dominating set of a graph is a set of vertices such that every vertex not in the set has at least one neighbor in the set. The problem of counting dominating sets is #P-complete for chordal graphs but solvable in polynomial time for its subclass of interval graphs. The complexity status of the corresponding problem is still undetermined for directed path graphs, which are a well-known class of graphs that falls between chordal graphs and interval graphs. This paper reveals that the problem of counting dominating sets remains #P-complete for directed path graphs but a stricter constraint to rooted directed path graphs admits a polynomial-time solution. ",
    "url": "https://arxiv.org/abs/2207.00463",
    "authors": [
      "Min-Sheng Lin"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2207.00473",
    "title": "Assessing the Effects of Hyperparameters on Knowledge Graph Embedding  Quality",
    "abstract": "Embedding knowledge graphs into low-dimensional spaces is a popular method for applying approaches, such as link prediction or node classification, to these databases. This embedding process is very costly in terms of both computational time and space. Part of the reason for this is the optimisation of hyperparameters, which involves repeatedly sampling, by random, guided, or brute-force selection, from a large hyperparameter space and testing the resulting embeddings for their quality. However, not all hyperparameters in this search space will be equally important. In fact, with prior knowledge of the relative importance of the hyperparameters, some could be eliminated from the search altogether without significantly impacting the overall quality of the outputted embeddings. To this end, we ran a Sobol sensitivity analysis to evaluate the effects of tuning different hyperparameters on the variance of embedding quality. This was achieved by performing thousands of embedding trials, each time measuring the quality of embeddings produced by different hyperparameter configurations. We regressed the embedding quality on those hyperparameter configurations, using this model to generate Sobol sensitivity indices for each of the hyperparameters. By evaluating the correlation between Sobol indices, we find substantial variability in the hyperparameter sensitivities between knowledge graphs with differing dataset characteristics as the probable cause of these inconsistencies. As an additional contribution of this work we identify several relations in the UMLS knowledge graph that may cause data leakage via inverse relations, and derive and present UMLS-43, a leakage-robust variant of that graph. ",
    "url": "https://arxiv.org/abs/2207.00473",
    "authors": [
      "Oliver Lloyd",
      "Yi Liu",
      "Tom Gaunt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.00476",
    "title": "Online Reflective Learning for Robust Medical Image Segmentation",
    "abstract": "Deep segmentation models often face the failure risks when the testing image presents unseen distributions. Improving model robustness against these risks is crucial for the large-scale clinical application of deep models. In this study, inspired by human learning cycle, we propose a novel online reflective learning framework (RefSeg) to improve segmentation robustness. Based on the reflection-on-action conception, our RefSeg firstly drives the deep model to take action to obtain semantic segmentation. Then, RefSeg triggers the model to reflect itself. Because making deep models realize their segmentation failures during testing is challenging, RefSeg synthesizes a realistic proxy image from the semantic mask to help deep models build intuitive and effective reflections. This proxy translates and emphasizes the segmentation flaws. By maximizing the structural similarity between the raw input and the proxy, the reflection-on-action loop is closed with segmentation robustness improved. RefSeg runs in the testing phase and is general for segmentation models. Extensive validation on three medical image segmentation tasks with a public cardiac MR dataset and two in-house large ultrasound datasets show that our RefSeg remarkably improves model robustness and reports state-of-the-art performance over strong competitors. ",
    "url": "https://arxiv.org/abs/2207.00476",
    "authors": [
      "Yuhao Huang",
      "Xin Yang",
      "Xiaoqiong Huang",
      "Jiamin Liang",
      "Xinrui Zhou",
      "Cheng Chen",
      "Haoran Dou",
      "Xindi Hu",
      "Yan Cao",
      "Dong Ni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00477",
    "title": "Vision-based Conflict Detection within Crowds based on High-Resolution  Human Pose Estimation for Smart and Safe Airport",
    "abstract": "Future airports are becoming more complex and congested with the increasing number of travellers. While the airports are more likely to become hotspots for potential conflicts to break out which can cause serious delays to flights and several safety issues. An intelligent algorithm which renders security surveillance more effective in detecting conflicts would bring many benefits to the passengers in terms of their safety, finance, and travelling efficiency. This paper details the development of a machine learning model to classify conflicting behaviour in a crowd. HRNet is used to segment the images and then two approaches are taken to classify the poses of people in the frame via multiple classifiers. Among them, it was found that the support vector machine (SVM) achieved the most performant achieving precision of 94.37%. Where the model falls short is against ambiguous behaviour such as a hug or losing track of a subject in the frame. The resulting model has potential for deployment within an airport if improvements are made to cope with the vast number of potential passengers in view as well as training against further ambiguous behaviours which will arise in an airport setting. In turn, will provide the capability to enhance security surveillance and improve airport safety. ",
    "url": "https://arxiv.org/abs/2207.00477",
    "authors": [
      "Karan Kheta",
      "Claire Delgove",
      "Ruolin Liu",
      "Adeola Aderogba",
      "Marc-Olivier Pokam",
      "Muhammed Mehmet Unal",
      "Yang Xing",
      "Weisi Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00489",
    "title": "Panning for gold: Lessons learned from the platform-agnostic automated  detection of political content in textual data",
    "abstract": "The growing availability of data about online information behaviour enables new possibilities for political communication research. However, the volume and variety of these data makes them difficult to analyse and prompts the need for developing automated content approaches relying on a broad range of natural language processing techniques (e.g. machine learning- or neural network-based ones). In this paper, we discuss how these techniques can be used to detect political content across different platforms. Using three validation datasets, which include a variety of political and non-political textual documents from online platforms, we systematically compare the performance of three groups of detection techniques relying on dictionaries, supervised machine learning, or neural networks. We also examine the impact of different modes of data preprocessing (e.g. stemming and stopword removal) on the low-cost implementations of these techniques using a large set (n = 66) of detection models. Our results show the limited impact of preprocessing on model performance, with the best results for less noisy data being achieved by neural network- and machine-learning-based models, in contrast to the more robust performance of dictionary-based models on noisy data. ",
    "url": "https://arxiv.org/abs/2207.00489",
    "authors": [
      "Mykola Makhortykh",
      "Ernesto de Le\u00f3n",
      "Aleksandra Urman",
      "Clara Christner",
      "Maryna Sydorova",
      "Silke Adam",
      "Michaela Maier",
      "Teresa Gil-Lopez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.00506",
    "title": "How Far Can I Go ? : A Self-Supervised Approach for Deterministic Video  Depth Forecasting",
    "abstract": "In this paper we present a novel self-supervised method to anticipate the depth estimate for a future, unobserved real-world urban scene. This work is the first to explore self-supervised learning for estimation of monocular depth of future unobserved frames of a video. Existing works rely on a large number of annotated samples to generate the probabilistic prediction of depth for unseen frames. However, this makes it unrealistic due to its requirement for large amount of annotated depth samples of video. In addition, the probabilistic nature of the case, where one past can have multiple future outcomes often leads to incorrect depth estimates. Unlike previous methods, we model the depth estimation of the unobserved frame as a view-synthesis problem, which treats the depth estimate of the unseen video frame as an auxiliary task while synthesizing back the views using learned pose. This approach is not only cost effective - we do not use any ground truth depth for training (hence practical) but also deterministic (a sequence of past frames map to an immediate future). To address this task we first develop a novel depth forecasting network DeFNet which estimates depth of unobserved future by forecasting latent features. Second, we develop a channel-attention based pose estimation network that estimates the pose of the unobserved frame. Using this learned pose, estimated depth map is reconstructed back into the image domain, thus forming a self-supervised solution. Our proposed approach shows significant improvements in Abs Rel metric compared to state-of-the-art alternatives on both short and mid-term forecasting setting, benchmarked on KITTI and Cityscapes. Code is available at https://github.com/sauradip/depthForecasting ",
    "url": "https://arxiv.org/abs/2207.00506",
    "authors": [
      "Suaradip Nag",
      "Nisarg Shah",
      "Anran Qi",
      "Raghavendra Ramachandra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2207.00531",
    "title": "Masked Autoencoders for Self-Supervised Learning on Automotive Point  Clouds",
    "abstract": "Masked autoencoding has become a successful pre-training paradigm for Transformer models for text, images, and recently, point clouds. Raw automotive datasets are a suitable candidate for self-supervised pre-training as they generally are cheap to collect compared to annotations for tasks like 3D object detection (OD). However, development of masked autoencoders for point clouds has focused solely on synthetic and indoor data. Consequently, existing methods have tailored their representations and models toward point clouds which are small, dense and have homogeneous point density. In this work, we study masked autoencoding for point clouds in an automotive setting, which are sparse and for which the point density can vary drastically among objects in the same scene. To this end, we propose Voxel-MAE, a simple masked autoencoding pre-training scheme designed for voxel representations. We pre-train the backbone of a Transformer-based 3D object detector to reconstruct masked voxels and to distinguish between empty and non-empty voxels. Our method improves the 3D OD performance by 1.75 mAP points and 1.05 NDS on the challenging nuScenes dataset. Compared to existing self-supervised methods for automotive data, Voxel-MAE displays up to $2\\times$ performance increase. Further, we show that by pre-training with Voxel-MAE, we require only 40% of the annotated data to outperform a randomly initialized equivalent. Code will be released. ",
    "url": "https://arxiv.org/abs/2207.00531",
    "authors": [
      "Georg Hess",
      "Johan Jaxing",
      "Elias Svensson",
      "David Hagerman",
      "Christoffer Petersson",
      "Lennart Svensson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00545",
    "title": "Transforming Image Generation from Scene Graphs",
    "abstract": "Generating images from semantic visual knowledge is a challenging task, that can be useful to condition the synthesis process in complex, subtle, and unambiguous ways, compared to alternatives such as class labels or text descriptions. Although generative methods conditioned by semantic representations exist, they do not provide a way to control the generation process aside from the specification of constraints between objects. As an example, the possibility to iteratively generate or modify images by manually adding specific items is a desired property that, to our knowledge, has not been fully investigated in the literature. In this work we propose a transformer-based approach conditioned by scene graphs that, conversely to recent transformer-based methods, also employs a decoder to autoregressively compose images, making the synthesis process more effective and controllable. The proposed architecture is composed by three modules: 1) a graph convolutional network, to encode the relationships of the input graph; 2) an encoder-decoder transformer, which autoregressively composes the output image; 3) an auto-encoder, employed to generate representations used as input/output of each generation step by the transformer. Results obtained on CIFAR10 and MNIST images show that our model is able to satisfy semantic constraints defined by a scene graph and to model relations between visual objects in the scene by taking into account a user-provided partial rendering of the desired target. ",
    "url": "https://arxiv.org/abs/2207.00545",
    "authors": [
      "Renato Sortino",
      "Simone Palazzo",
      "Concetto Spampinato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00551",
    "title": "Evaluating the Explainers: Black-Box Explainable Machine Learning for  Student Success Prediction in MOOCs",
    "abstract": "Neural networks are ubiquitous in applied machine learning for education. Their pervasive success in predictive performance comes alongside a severe weakness, the lack of explainability of their decisions, especially relevant in human-centric fields. We implement five state-of-the-art methodologies for explaining black-box machine learning models (LIME, PermutationSHAP, KernelSHAP, DiCE, CEM) and examine the strengths of each approach on the downstream task of student performance prediction for five massive open online courses. Our experiments demonstrate that the families of explainers do not agree with each other on feature importance for the same Bidirectional LSTM models with the same representative set of students. We use Principal Component Analysis, Jensen-Shannon distance, and Spearman's rank-order correlation to quantitatively cross-examine explanations across methods and courses. Furthermore, we validate explainer performance across curriculum-based prerequisite relationships. Our results come to the concerning conclusion that the choice of explainer is an important decision and is in fact paramount to the interpretation of the predictive results, even more so than the course the model is trained on. Source code and models are released at this http URL ",
    "url": "https://arxiv.org/abs/2207.00551",
    "authors": [
      "Vinitra Swamy",
      "Bahar Radmehr",
      "Natasa Krco",
      "Mirko Marras",
      "Tanja K\u00e4ser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.00559",
    "title": "Ultra-low latency recurrent neural network inference on FPGAs for  physics applications with hls4ml",
    "abstract": "Recurrent neural networks have been shown to be effective architectures for many tasks in high energy physics, and thus have been widely adopted. Their use in low-latency environments has, however, been limited as a result of the difficulties of implementing recurrent architectures on field-programmable gate arrays (FPGAs). In this paper we present an implementation of two types of recurrent neural network layers -- long short-term memory and gated recurrent unit -- within the hls4ml framework. We demonstrate that our implementation is capable of producing effective designs for both small and large models, and can be customized to meet specific design requirements for inference latencies and FPGA resources. We show the performance and synthesized designs for multiple neural networks, many of which are trained specifically for jet identification tasks at the CERN Large Hadron Collider. ",
    "url": "https://arxiv.org/abs/2207.00559",
    "authors": [
      "Elham E Khoda",
      "Dylan Rankin",
      "Rafael Teixeira de Lima",
      "Philip Harris",
      "Scott Hauck",
      "Shih-Chieh Hsu",
      "Michael Kagan",
      "Vladimir Loncar",
      "Chaitanya Paikara",
      "Richa Rao",
      "Sioni Summers",
      "Caterina Vernieri",
      "Aaron Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.00560",
    "title": "Is neural language acquisition similar to natural? A chronological  probing study",
    "abstract": "The probing methodology allows one to obtain a partial representation of linguistic phenomena stored in the inner layers of the neural network, using external classifiers and statistical analysis. Pre-trained transformer-based language models are widely used both for natural language understanding (NLU) and natural language generation (NLG) tasks making them most commonly used for downstream applications. However, little analysis was carried out, whether the models were pre-trained enough or contained knowledge correlated with linguistic theory. We are presenting the chronological probing study of transformer English models such as MultiBERT and T5. We sequentially compare the information about the language learned by the models in the process of training on corpora. The results show that 1) linguistic information is acquired in the early stages of training 2) both language models demonstrate capabilities to capture various features from various levels of language, including morphology, syntax, and even discourse, while they also can inconsistently fail on tasks that are perceived as easy. We also introduce the open-source framework for chronological probing research, compatible with other transformer-based models. https://github.com/EkaterinaVoloshina/chronological_probing ",
    "url": "https://arxiv.org/abs/2207.00560",
    "authors": [
      "Ekaterina Voloshina",
      "Oleg Serikov",
      "Tatiana Shavrina"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2201.09541",
    "title": "Image features of a splashing drop on a solid surface extracted using a  feedforward neural network",
    "abstract": "This article reports nonintuitive characteristic of a splashing drop on a solid surface discovered through extracting image features using a feedforward neural network (FNN). Ethanol of area-equivalent radius about 1.29 mm was dropped from impact heights ranging from 4 cm to 60 cm (splashing threshold 20 cm) and impacted on a hydrophilic surface. The images captured when half of the drop impacted the surface were labeled according to their outcome, splashing or nonsplashing, and were used to train an FNN. A classification accuracy higher than 96% was achieved. To extract the image features identified by the FNN for classification, the weight matrix of the trained FNN for identifying splashing drops was visualized. Remarkably, the visualization showed that the trained FNN identified the contour height of the main body of the impacting drop as an important characteristic differentiating between splashing and nonsplashing drops, which has not been reported in previous studies. This feature was found throughout the impact, even when one and three-quarters of the drop impacted the surface. To confirm the importance of this image feature, the FNN was retrained to classify using only the main body without checking for the presence of ejected secondary droplets. The accuracy was still higher than 82%, confirming that the contour height is an important feature distinguishing splashing from nonsplashing drops. Several aspects of drop impact are analyzed and discussed with the aim of identifying the possible mechanism underlying the difference in contour height between splashing and nonsplashing drops. ",
    "url": "https://arxiv.org/abs/2201.09541",
    "authors": [
      "Jingzu Yee",
      "Akinori Yamanaka",
      "Yoshiyuki Tagawa"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00095",
    "title": "End-to-end Learning for Image-based Detection of Molecular Alterations  in Digital Pathology",
    "abstract": "Current approaches for classification of whole slide images (WSI) in digital pathology predominantly utilize a two-stage learning pipeline. The first stage identifies areas of interest (e.g. tumor tissue), while the second stage processes cropped tiles from these areas in a supervised fashion. During inference, a large number of tiles are combined into a unified prediction for the entire slide. A major drawback of such approaches is the requirement for task-specific auxiliary labels which are not acquired in clinical routine. We propose a novel learning pipeline for WSI classification that is trainable end-to-end and does not require any auxiliary annotations. We apply our approach to predict molecular alterations for a number of different use-cases, including detection of microsatellite instability in colorectal tumors and prediction of specific mutations for colon, lung, and breast cancer cases from The Cancer Genome Atlas. Results reach AUC scores of up to 94% and are shown to be competitive with state of the art two-stage pipelines. We believe our approach can facilitate future research in digital pathology and contribute to solve a large range of problems around the prediction of cancer phenotypes, hopefully enabling personalized therapies for more patients in future. ",
    "url": "https://arxiv.org/abs/2207.00095",
    "authors": [
      "Marvin Teichmann",
      "Andre Aichert",
      "Hanibal Bohnenberger",
      "Philipp Str\u00f6bel",
      "Tobias Heimann"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2207.00141",
    "title": "A New Dataset and A Baseline Model for Breast Lesion Detection in  Ultrasound Videos",
    "abstract": "Breast lesion detection in ultrasound is critical for breast cancer diagnosis. Existing methods mainly rely on individual 2D ultrasound images or combine unlabeled video and labeled 2D images to train models for breast lesion detection. In this paper, we first collect and annotate an ultrasound video dataset (188 videos) for breast lesion detection. Moreover, we propose a clip-level and video-level feature aggregated network (CVA-Net) for addressing breast lesion detection in ultrasound videos by aggregating video-level lesion classification features and clip-level temporal features. The clip-level temporal features encode local temporal information of ordered video frames and global temporal information of shuffled video frames. In our CVA-Net, an inter-video fusion module is devised to fuse local features from original video frames and global features from shuffled video frames, and an intra-video fusion module is devised to learn the temporal information among adjacent video frames. Moreover, we learn video-level features to classify the breast lesions of the original video as benign or malignant lesions to further enhance the final breast lesion detection performance in ultrasound videos. Experimental results on our annotated dataset demonstrate that our CVA-Net clearly outperforms state-of-the-art methods. The corresponding code and dataset are publicly available at \\url{https://github.com/jhl-Det/CVA-Net}. ",
    "url": "https://arxiv.org/abs/2207.00141",
    "authors": [
      "Zhi Lin",
      "Junhao Lin",
      "Lei Zhu",
      "Huazhu Fu",
      "Jing Qin",
      "Liansheng Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00223",
    "title": "On the Performance of Data Compression in Clustered Fog Radio Access  Networks",
    "abstract": "The fog-radio-access-network (F-RAN) has been proposed to address the strict latency requirements, which offloads computation tasks generated in user equipments (UEs) to the edge to reduce the processing latency. However, it incorporates the task transmission latency, which may become the bottleneck of latency requirements. Data compression (DC) has been considered as one of the promising techniques to reduce the transmission latency. By compressing the computation tasks before transmitting, the transmission delay is reduced due to the shrink transmitted data size, and the original computing task can be retrieved by employing data decompressing (DD) at the edge nodes or the centre cloud. Nevertheless, the DC and DD incorporate extra processing latency, and the latency performance has not been investigated in the large-scale DC-enabled F-RAN. Therefore, in this work, the successful data compression probability (SDCP) is defined to analyse the latency performance of the F-RAN. Moreover, to analyse the effect of compression offloading ratio (COR), a novel hybrid compression mode is proposed based on the queueing theory. Based on this, the closed-form result of SDCP in the large-scale DC-enabled F-RAN is derived by combining the Matern cluster process and M/G/1 queueing model, and validated by Monte Carlo simulations. Based on the derived SDCP results, the effects of COR on the SDCP is analysed numerically. The results show that the SDCP with the optimal COR can be enhanced with a maximum value of 0.3 and 0.55 as compared with the cases of compressing all computing tasks at the edge and at the UE, respectively. Moreover, for the system requiring the minimal latency, the proposed hybrid compression mode can alleviate the requirement on the backhaul capacity. ",
    "url": "https://arxiv.org/abs/2207.00223",
    "authors": [
      "Haonan Hu",
      "Yan Jiang",
      "Jiliang Zhang",
      "Yanan Zheng",
      "Qianbin Chen",
      "Jie Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.00259",
    "title": "Covid-19 detection using transfer learning approach from computed  temography images",
    "abstract": "Our main goal in this study is to propose a transfer learning based method for COVID-19 detection from Computed Tomography (CT) images. The transfer learning model used for the task is a pretrained Xception model. Both model architecture and pre-trained weights on ImageNet were used. The resulting modified model was trained with 128 batch size and 224x224, 3 channeled input images, converted from original 512x512, grayscale images. The dataset used is a the COV19-CT-DB. Labels in the dataset include COVID-19 cases and Non-COVID-19 cases for COVID-1919 detection. Firstly, a accuracy and loss on the validation partition of the dataset as well as precision recall and macro F1 score were used to measure the performance of the proposed method. The resulting Macro F1 score on the validation set exceeded the baseline model. ",
    "url": "https://arxiv.org/abs/2207.00259",
    "authors": [
      "Kenan Mornai",
      "Muhammet Fatih Balikci",
      "Tayfun Yigit Altuntas",
      "Devrim Unay"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00367",
    "title": "A geometric framework for outlier detection in high-dimensional data",
    "abstract": "Outlier or anomaly detection is an important task in data analysis. We discuss the problem from a geometrical perspective and provide a framework that exploits the metric structure of a data set. Our approach rests on the manifold assumption, i.e., that the observed, nominally high-dimensional data lie on a much lower dimensional manifold and that this intrinsic structure can be inferred with manifold learning methods. We show that exploiting this structure significantly improves the detection of outlying observations in high-dimensional data. We also suggest a novel, mathematically precise, and widely applicable distinction between distributional and structural outliers based on the geometry and topology of the data manifold that clarifies conceptual ambiguities prevalent throughout the literature. Our experiments focus on functional data as one class of structured high-dimensional data, but the framework we propose is completely general and we include image and graph data applications. Our results show that the outlier structure of high-dimensional and non-tabular data can be detected and visualized using manifold learning methods and quantified using standard outlier scoring methods applied to the manifold embedding vectors. ",
    "url": "https://arxiv.org/abs/2207.00367",
    "authors": [
      "Moritz Herrmann",
      "Florian Pfisterer",
      "Fabian Scheipl"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00378",
    "title": "Rapid training of quantum recurrent neural network",
    "abstract": "Time series prediction is the crucial task for many human activities e.g. weather forecasts or predicting stock prices. One solution to this problem is to use Recurrent Neural Networks (RNNs). Although they can yield accurate predictions, their learning process is slow and complex. Here we propose a Quantum Recurrent Neural Network (QRNN) to address these obstacles. The design of the network is based on the continuous-variable quantum computing paradigm. We demonstrate that the network is capable of learning time dependence of a few types of temporal data. Our numerical simulations show that the QRNN converges to optimal weights in fewer epochs than the classical network. Furthermore, for a small number of trainable parameters it can achieve lower loss than the latter. ",
    "url": "https://arxiv.org/abs/2207.00378",
    "authors": [
      "Micha\u0142 Siemaszko",
      "Thomas McDermott",
      "Adam Buraczewski",
      "Bertrand Le Saux",
      "Magdalena Stobi\u0144ska"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00379",
    "title": "Average submodularity of maximizing anticoordination in network games",
    "abstract": "We consider the control of decentralized learning dynamics for agents in an anti-coordination network game. In the anti-coordination network game, there is a preferred action in the absence of neighbors' actions, and the utility an agent receives from the preferred action decreases as more of its neighbors select the preferred action, potentially causing the agent to select a less desirable action. The decentralized dynamics that is based on the iterated elimination of dominated strategies converge for the considered game. Given a convergent action profile, we measure anti-coordination by the number of edges in the underlying graph that have at least one agent in either end of the edge not taking the preferred action. The maximum anti-coordination (MAC) problem seeks to find an optimal set of agents to control under a finite budget so that the overall network disconnect is maximized on game convergence as a result of the dynamics. We show that the MAC is submodular in expectation in dense bipartite networks for any realization of the utility constants in the population. Utilizing this result, we obtain a performance guarantee for the greedy agent selection algorithm for MAC. Finally, we provide a computational study to show the effectiveness of greedy node selection strategies to solve MAC on general bipartite networks. ",
    "url": "https://arxiv.org/abs/2207.00379",
    "authors": [
      "Soham Das",
      "Ceyhun Eksin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2207.00450",
    "title": "Packing cycles in planar and bounded-genus graphs",
    "abstract": "We devise constant-factor approximation algorithms for finding as many disjoint cycles as possible from a certain family of cycles in a given planar or bounded-genus graph. Here disjoint can mean vertex-disjoint or edge-disjoint, and the graph can be undirected or directed. The family of cycles under consideration must satisfy two properties: it must be uncrossable and allow for an oracle access that finds a weight-minimal cycle in that family for given nonnegative edge weights or (in planar graphs) the union of all remaining cycles in that family after deleting a given subset of edges. Our setting generalizes many problems that were studied separately in the past. For example, three families that satisfy the above properties are (i) all cycles in a directed or undirected graph, (ii) all odd cycles in an undirected graph, and (iii) all cycles in an undirected graph that contain precisely one demand edge, where the demand edges form a subset of the edge set. The latter family (iii) corresponds to the classical disjoint paths problem in fully planar and bounded-genus instances. While constant-factor approximation algorithms were known for edge-disjoint paths in such instances, we improve the constant in the planar case and obtain the first such algorithms for vertex-disjoint paths. We also obtain approximate min-max theorems of the Erd\\H{o}s--P\\'osa type. For example, the minimum feedback vertex set in a planar digraph is at most 12 times the maximum number of vertex-disjoint cycles. ",
    "url": "https://arxiv.org/abs/2207.00450",
    "authors": [
      "Niklas Schlomberg",
      "Hanjo Thiele",
      "Jens Vygen"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Geometric Topology (math.GT)"
    ]
  },
  {
    "id": "arXiv:2207.00458",
    "title": "SD-LayerNet: Semi-supervised retinal layer segmentation in OCT using  disentangled representation with anatomical priors",
    "abstract": "Optical coherence tomography (OCT) is a non-invasive 3D modality widely used in ophthalmology for imaging the retina. Achieving automated, anatomically coherent retinal layer segmentation on OCT is important for the detection and monitoring of different retinal diseases, like Age-related Macular Disease (AMD) or Diabetic Retinopathy. However, the majority of state-of-the-art layer segmentation methods are based on purely supervised deep-learning, requiring a large amount of pixel-level annotated data that is expensive and hard to obtain. With this in mind, we introduce a semi-supervised paradigm into the retinal layer segmentation task that makes use of the information present in large-scale unlabeled datasets as well as anatomical priors. In particular, a novel fully differentiable approach is used for converting surface position regression into a pixel-wise structured segmentation, allowing to use both 1D surface and 2D layer representations in a coupled fashion to train the model. In particular, these 2D segmentations are used as anatomical factors that, together with learned style factors, compose disentangled representations used for reconstructing the input image. In parallel, we propose a set of anatomical priors to improve network training when a limited amount of labeled data is available. We demonstrate on the real-world dataset of scans with intermediate and wet-AMD that our method outperforms state-of-the-art when using our full training set, but more importantly largely exceeds state-of-the-art when it is trained with a fraction of the labeled data. ",
    "url": "https://arxiv.org/abs/2207.00458",
    "authors": [
      "Botond Fazekas",
      "Guilherme Aresta",
      "Dmitrii Lachinov",
      "Sophie Riedl",
      "Julia Mai",
      "Ursula Schmidt-Erfurth",
      "Hrvoje Bogunovic"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.00555",
    "title": "FitHuBERT: Going Thinner and Deeper for Knowledge Distillation of Speech  Self-Supervised Learning",
    "abstract": "Large-scale speech self-supervised learning (SSL) has emerged to the main field of speech processing, however, the problem of computational cost arising from its vast size makes a high entry barrier to academia. In addition, existing distillation techniques of speech SSL models compress the model by reducing layers, which induces performance degradation in linguistic pattern recognition tasks such as phoneme recognition (PR). In this paper, we propose FitHuBERT, which makes thinner in dimension throughout almost all model components and deeper in layer compared to prior speech SSL distillation works. Moreover, we employ a time-reduction layer to speed up inference time and propose a method of hint-based distillation for less performance degradation. Our method reduces the model to 23.8% in size and 35.9% in inference time compared to HuBERT. Also, we achieve 12.1% word error rate and 13.3% phoneme error rate on the SUPERB benchmark which is superior than prior work. ",
    "url": "https://arxiv.org/abs/2207.00555",
    "authors": [
      "Yeonghyeon Lee",
      "Kangwook Jang",
      "Jahyun Goo",
      "Youngmoon Jung",
      "Hoirin Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00574",
    "title": "Embedding phylogenetic trees in networks of low treewidth",
    "abstract": "Given a rooted, binary phylogenetic network and a rooted, binary phylogenetic tree, can the tree be embedded into the network? This problem, called \\textsc{Tree Containment}, arises when validating networks constructed by phylogenetic inference methods.We present the first algorithm for (rooted) \\textsc{Tree Containment} using the treewidth $t$ of the input network $N$ as parameter, showing that the problem can be solved in $2^{O(t^2)}\\cdot|N|$~time and space. ",
    "url": "https://arxiv.org/abs/2207.00574",
    "authors": [
      "Leo van Iersel",
      "Mark Jones",
      "Mathias Weller"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:0805.1877",
    "title": "Perfect tag identification protocol in RFID networks",
    "abstract": " Comments: There is a technical error ",
    "url": "https://arxiv.org/abs/0805.1877",
    "authors": [
      "Maurizio A. Bonuccelli",
      "Francesca Lonetti",
      "Francesca Martelli"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:1810.02180",
    "title": "Improved Generalization Bounds for Adversarially Robust Learning",
    "abstract": " Comments: JMLR camera ready ",
    "url": "https://arxiv.org/abs/1810.02180",
    "authors": [
      "Idan Attias",
      "Aryeh Kontorovich",
      "Yishay Mansour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1911.04254",
    "title": "Kernelized Similarity Learning and Embedding for Dynamic Texture  Synthesis",
    "abstract": " Comments: Accepted to IEEE Transactions on Systems, Man, and Cybernetics: Systems ",
    "url": "https://arxiv.org/abs/1911.04254",
    "authors": [
      "Shiming Chen",
      "Peng Zhang",
      "Guo-Sen Xie",
      "Qinmu Peng",
      "Zehong Cao",
      "Wei Yuan",
      "Xinge You"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2003.05582",
    "title": "$\u03bb_\\infty$ & Maximum Variance Embedding: Measuring and Optimizing  Connectivity of A Graph Metric",
    "abstract": " Title: $\u03bb_\\infty$ & Maximum Variance Embedding: Measuring and Optimizing  Connectivity of A Graph Metric ",
    "url": "https://arxiv.org/abs/2003.05582",
    "authors": [
      "Majid Farhadi",
      "Anand Louis",
      "Mohit Singh",
      "Prasad Tetali"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2006.15574",
    "title": "Community detection and percolation of information in a geometric  setting",
    "abstract": " Comments: 23 pages. Changes to Lemma 16 ",
    "url": "https://arxiv.org/abs/2006.15574",
    "authors": [
      "Ronen Eldan",
      "Dan Mikulincer",
      "Hester Pieters"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2102.03214",
    "title": "Topology-Aware Network Pruning using Multi-stage Graph Embedding and  Reinforcement Learning",
    "abstract": " Comments: Accepted at ICML 2022 Long presentation ",
    "url": "https://arxiv.org/abs/2102.03214",
    "authors": [
      "Sixing Yu",
      "Arya Mazaheri",
      "Ali Jannesari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.13686",
    "title": "Robust subgroup discovery",
    "abstract": " Comments: For associated code, see this https URL ; submitted to Data Mining and Knowledge Discovery Journal ",
    "url": "https://arxiv.org/abs/2103.13686",
    "authors": [
      "Hugo Manuel Proen\u00e7a",
      "Peter Gr\u00fcnwald",
      "Thomas B\u00e4ck",
      "Matthijs van Leeuwen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2104.14818",
    "title": "Traceability Technology Adoption in Supply Chain Networks",
    "abstract": " Title: Traceability Technology Adoption in Supply Chain Networks ",
    "url": "https://arxiv.org/abs/2104.14818",
    "authors": [
      "Philippe Blaettchen",
      "Andre P. Calmon",
      "Georgina Hall"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2105.04156",
    "title": "ReLU Deep Neural Networks from the Hierarchical Basis Perspective",
    "abstract": " Comments: 28 pages ",
    "url": "https://arxiv.org/abs/2105.04156",
    "authors": [
      "Juncai He",
      "Lin Li",
      "Jinchao Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.01813",
    "title": "Identification of diffusively coupled linear networks through structured  polynomial models",
    "abstract": " Title: Identification of diffusively coupled linear networks through structured  polynomial models ",
    "url": "https://arxiv.org/abs/2106.01813",
    "authors": [
      "E.M.M.",
      "Kivits",
      "Paul M.J. Van den Hof"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2107.00932",
    "title": "MSN: Multi-Style Network for Trajectory Prediction",
    "abstract": " Title: MSN: Multi-Style Network for Trajectory Prediction ",
    "url": "https://arxiv.org/abs/2107.00932",
    "authors": [
      "Conghao Wong",
      "Beihao Xia",
      "Qinmu Peng",
      "Wei Yuan",
      "Xinge You"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.02234",
    "title": "Multi-Branch with Attention Network for Hand-Based Person Recognition",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2101.05260 ",
    "url": "https://arxiv.org/abs/2108.02234",
    "authors": [
      "Nathanael L. Baisa",
      "Bryan Williams",
      "Hossein Rahmani",
      "Plamen Angelov",
      "Sue Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.10061",
    "title": "Graph Neural Networks for Graph Drawing",
    "abstract": " Comments: Accepted for publication in IEEE Transaction of Neural Networks and Learning Systems (TNNLS) 2022, Special Issue on Deep Neural Networks for Graphs: Theory, Models, Algorithms and Applications ",
    "url": "https://arxiv.org/abs/2109.10061",
    "authors": [
      "Matteo Tiezzi",
      "Gabriele Ciravegna",
      "Marco Gori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.01509",
    "title": "DeepA2: A Modular Framework for Deep Argument Analysis with Pretrained  Neural Text2Text Language Models",
    "abstract": " Comments: A Demo is available at this https URL , the model can be downloaded from this https URL , and the datasets can be accessed at this https URL ",
    "url": "https://arxiv.org/abs/2110.01509",
    "authors": [
      "Gregor Betz",
      "Kyle Richardson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.11024",
    "title": "Watermarking Graph Neural Networks based on Backdoor Attacks",
    "abstract": " Comments: 13 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2110.11024",
    "authors": [
      "Jing Xu",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2110.15292",
    "title": "Class-wise Thresholding for Robust Out-of-Distribution Detection",
    "abstract": " Comments: 12 pages, 7 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2110.15292",
    "authors": [
      "Matteo Guarrera",
      "Baihong Jin",
      "Tung-Wei Lin",
      "Maria Zuluaga",
      "Yuxin Chen",
      "Alberto Sangiovanni-Vincentelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.02585",
    "title": "InQSS: a speech intelligibility and quality assessment model using a  multi-task learning network",
    "abstract": " Comments: accepted by Insterspeech 2022 ",
    "url": "https://arxiv.org/abs/2111.02585",
    "authors": [
      "Yu-Wen Chen",
      "Yu Tsao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2111.13091",
    "title": "Deadlock Freedom for Asynchronous and Cyclic Process Networks (Extended  Version)",
    "abstract": " Comments: Extended version of arXiv:2110.00146, doi:10.4204/EPTCS.347.3 ",
    "url": "https://arxiv.org/abs/2111.13091",
    "authors": [
      "Bas van den Heuvel",
      "Jorge A. P\u00e9rez"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2111.13300",
    "title": "A Robust Volumetric Transformer for Accurate 3D Tumor Segmentation",
    "abstract": " Title: A Robust Volumetric Transformer for Accurate 3D Tumor Segmentation ",
    "url": "https://arxiv.org/abs/2111.13300",
    "authors": [
      "Himashi Peiris",
      "Munawar Hayat",
      "Zhaolin Chen",
      "Gary Egan",
      "Mehrtash Harandi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.03195",
    "title": "More is Better (Mostly): On the Backdoor Attacks in Federated Graph  Neural Networks",
    "abstract": " Comments: 15 pages, 15 figures ",
    "url": "https://arxiv.org/abs/2202.03195",
    "authors": [
      "Jing Xu",
      "Rui Wang",
      "Stefanos Koffas",
      "Kaitai Liang",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.10806",
    "title": "Stochastic Causal Programming for Bounding Treatment Effects",
    "abstract": " Title: Stochastic Causal Programming for Bounding Treatment Effects ",
    "url": "https://arxiv.org/abs/2202.10806",
    "authors": [
      "Kirtan Padh",
      "Jakob Zeitler",
      "David Watson",
      "Matt Kusner",
      "Ricardo Silva",
      "Niki Kilbertus"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.12197",
    "title": "Situational Graphs for Robot Navigation in Structured Indoor  Environments",
    "abstract": " Comments: 8 pages, 6 figures, RAL/IROS 2022 ",
    "url": "https://arxiv.org/abs/2202.12197",
    "authors": [
      "Hriday Bavle",
      "Jose Luis Sanchez-Lopez",
      "Muhammad Shaheer",
      "Javier Civera",
      "Holger Voos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.04251",
    "title": "End-to-End Semi-Supervised Learning for Video Action Detection",
    "abstract": " Comments: CVPR'22 ",
    "url": "https://arxiv.org/abs/2203.04251",
    "authors": [
      "Akash Kumar",
      "Yogesh Singh Rawat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.14883",
    "title": "TGL: A General Framework for Temporal GNN Training on Billion-Scale  Graphs",
    "abstract": " Comments: VLDB'22 ",
    "url": "https://arxiv.org/abs/2203.14883",
    "authors": [
      "Hongkuan Zhou",
      "Da Zheng",
      "Israt Nisa",
      "Vasileios Ioannidis",
      "Xiang Song",
      "George Karypis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15081",
    "title": "Word Discovery in Visually Grounded, Self-Supervised Speech Models",
    "abstract": " Comments: Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2203.15081",
    "authors": [
      "Puyuan Peng",
      "David Harwath"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2203.16251",
    "title": "Robust Generation Dispatch with Strategic Renewable Power Curtailment  and Decision-Dependent Uncertainty",
    "abstract": " Comments: 14 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2203.16251",
    "authors": [
      "Yue Chen",
      "Wei Wei"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.05183",
    "title": "Building an ASR Error Robust Spoken Virtual Patient System in a Highly  Class-Imbalanced Scenario Without Speech Data",
    "abstract": " Comments: 5 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2204.05183",
    "authors": [
      "Vishal Sunder",
      "Prashant Serai",
      "Eric Fosler-Lussier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.06439",
    "title": "Receptive Field Analysis of Temporal Convolutional Networks for Monaural  Speech Dereverberation",
    "abstract": " Comments: Accepted at EUSIPCO 2022 ",
    "url": "https://arxiv.org/abs/2204.06439",
    "authors": [
      "William Ravenscroft",
      "Stefan Goetze",
      "Thomas Hain"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.12037",
    "title": "Causal Reasoning Meets Visual Representation Learning: A Prospective  Study",
    "abstract": " Comments: 33 pages, 14 figures. This work has been submitted to Machine Intelligence Research ",
    "url": "https://arxiv.org/abs/2204.12037",
    "authors": [
      "Yang Liu",
      "Yushen Wei",
      "Hong Yan",
      "Guanbin Li",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2205.01897",
    "title": "Virtual Analog Modeling of Distortion Circuits Using Neural Ordinary  Differential Equations",
    "abstract": " Comments: 8 pages, 10 figures, accepted for DAFx 2022 conference, for associated audio examples, see this https URL ",
    "url": "https://arxiv.org/abs/2205.01897",
    "authors": [
      "Jan Wilczek",
      "Alec Wright",
      "Vesa V\u00e4lim\u00e4ki",
      "Emanu\u00ebl Habets"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.02592",
    "title": "Investigating molecular transport in the human brain from MRI with  physics-informed neural networks",
    "abstract": " Title: Investigating molecular transport in the human brain from MRI with  physics-informed neural networks ",
    "url": "https://arxiv.org/abs/2205.02592",
    "authors": [
      "Bastian Zapf",
      "Johannes Haubner",
      "Miroslav Kuchta",
      "Geir Ringstad",
      "Per Kristian Eide",
      "Kent-Andre Mardal"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2205.05229",
    "title": "A new approach for the fractional Laplacian via deep neural networks",
    "abstract": " Comments: 55 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2205.05229",
    "authors": [
      "Nicol\u00e1s Valenzuela"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2205.09934",
    "title": "Towards Explanation for Unsupervised Graph-Level Representation Learning",
    "abstract": " Title: Towards Explanation for Unsupervised Graph-Level Representation Learning ",
    "url": "https://arxiv.org/abs/2205.09934",
    "authors": [
      "Qinghua Zheng",
      "Jihong Wang",
      "Minnan Luo",
      "Yaoliang Yu",
      "Jundong Li",
      "Lina Yao",
      "Xiaojun Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10636",
    "title": "AutoLink: Self-supervised Learning of Human Skeletons and Object  Outlines by Linking Keypoints",
    "abstract": " Title: AutoLink: Self-supervised Learning of Human Skeletons and Object  Outlines by Linking Keypoints ",
    "url": "https://arxiv.org/abs/2205.10636",
    "authors": [
      "Xingzhe He",
      "Bastian Wandt",
      "Helge Rhodin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13034",
    "title": "EvoVGM: a Deep Variational Generative Model for Evolutionary Parameter  Estimation",
    "abstract": " Comments: Accepted as a full paper for publication in ACM-BCB 2022 (Camera-ready version) ",
    "url": "https://arxiv.org/abs/2205.13034",
    "authors": [
      "Amine M. Remita",
      "Abdoulaye Banir\u00e9 Diallo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2205.15466",
    "title": "Data Banzhaf: A Data Valuation Framework with Maximal Robustness to  Learning Stochasticity",
    "abstract": " Title: Data Banzhaf: A Data Valuation Framework with Maximal Robustness to  Learning Stochasticity ",
    "url": "https://arxiv.org/abs/2205.15466",
    "authors": [
      "Tianhao Wang",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.07296",
    "title": "Enhanced Knowledge Selection for Grounded Dialogues via Document  Semantic Graphs",
    "abstract": " Comments: NAACL 2022. Please refer to this https URL for code and resources ",
    "url": "https://arxiv.org/abs/2206.07296",
    "authors": [
      "Sha Li",
      "Mahdi Namazifar",
      "Di Jin",
      "Mohit Bansal",
      "Heng Ji",
      "Yang Liu",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.07934",
    "title": "BANet: Motion Forecasting with Boundary Aware Network",
    "abstract": " Title: BANet: Motion Forecasting with Boundary Aware Network ",
    "url": "https://arxiv.org/abs/2206.07934",
    "authors": [
      "Chen Zhang",
      "Honglin Sun",
      "Chen Chen",
      "Yandong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.08545",
    "title": "NU-Wave 2: A General Neural Audio Upsampling Model for Various Sampling  Rates",
    "abstract": " Comments: Accepted to Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2206.08545",
    "authors": [
      "Seungu Han",
      "Junhyeok Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.11023",
    "title": "Heterogeneous Graph Neural Networks for Software Effort Estimation",
    "abstract": " Comments: Accepted in the Technical Papers Track of the 16th International Symposium on Empirical Software Engineering and Measurement, 2022 (ESEM 2022) ",
    "url": "https://arxiv.org/abs/2206.11023",
    "authors": [
      "Hung Phan",
      "Ali Jannesari"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.13108",
    "title": "AdaSparse: Learning Adaptively Sparse Structures for Multi-Domain  Click-Through Rate Prediction",
    "abstract": " Title: AdaSparse: Learning Adaptively Sparse Structures for Multi-Domain  Click-Through Rate Prediction ",
    "url": "https://arxiv.org/abs/2206.13108",
    "authors": [
      "Xuanhua Yang",
      "Xiaoyu Peng",
      "Penghui Wei",
      "Shaoguo Liu",
      "Liang Wang",
      "Bo Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14604",
    "title": "Mining Seasonal Temporal Patterns in Big Time Series",
    "abstract": " Title: Mining Seasonal Temporal Patterns in Big Time Series ",
    "url": "https://arxiv.org/abs/2206.14604",
    "authors": [
      "Van Long Ho",
      "Nguyen Ho",
      "Torben Bach Pedersen"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2206.15067",
    "title": "Language Model-Based Emotion Prediction Methods for Emotional Speech  Synthesis Systems",
    "abstract": " Comments: Accepted by INTERSPEECH2022 ",
    "url": "https://arxiv.org/abs/2206.15067",
    "authors": [
      "Hyun-Wook Yoon",
      "Ohsung Kwon",
      "Hoyeon Lee",
      "Ryuichi Yamamoto",
      "Eunwoo Song",
      "Jae-Min Kim",
      "Min-Jae Hwang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.15101",
    "title": "The maximum capability of a topological feature in link prediction",
    "abstract": " Title: The maximum capability of a topological feature in link prediction ",
    "url": "https://arxiv.org/abs/2206.15101",
    "authors": [
      "Yijun Ran",
      "Xiao-Ke Xu",
      "Tao Jia"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.15129",
    "title": "Personalized Detection of Cognitive Biases in Actions of Users from  Their Logs: Anchoring and Recency Biases",
    "abstract": " Title: Personalized Detection of Cognitive Biases in Actions of Users from  Their Logs: Anchoring and Recency Biases ",
    "url": "https://arxiv.org/abs/2206.15129",
    "authors": [
      "Atanu R Sinha",
      "Navita Goyal",
      "Sunny Dhamnani",
      "Tanay Asija",
      "Raja K Dubey",
      "M V Kaarthik Raja",
      "Georgios Theocharous"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.15398",
    "title": "PolarFormer: Multi-camera 3D Object Detection with Polar Transformers",
    "abstract": " Title: PolarFormer: Multi-camera 3D Object Detection with Polar Transformers ",
    "url": "https://arxiv.org/abs/2206.15398",
    "authors": [
      "Yanqin Jiang",
      "Li Zhang",
      "Zhenwei Miao",
      "Xiatian Zhu",
      "Jin Gao",
      "Weiming Hu",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]