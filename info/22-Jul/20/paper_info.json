[
  {
    "id": "arXiv:2207.08808",
    "title": "Global-Local Stepwise Generative Network for Ultra High-Resolution Image  Restoration",
    "abstract": "While the research on image background restoration from regular size of degraded images has achieved remarkable progress, restoring ultra high-resolution (e.g., 4K) images remains an extremely challenging task due to the explosion of computational complexity and memory usage, as well as the deficiency of annotated data. In this paper we present a novel model for ultra high-resolution image restoration, referred to as the Global-Local Stepwise Generative Network (GLSGN), which employs a stepwise restoring strategy involving four restoring pathways: three local pathways and one global pathway. The local pathways focus on conducting image restoration in a fine-grained manner over local but high-resolution image patches, while the global pathway performs image restoration coarsely on the scale-down but intact image to provide cues for the local pathways in a global view including semantics and noise patterns. To smooth the mutual collaboration between these four pathways, our GLSGN is designed to ensure the inter-pathway consistency in four aspects in terms of low-level content, perceptual attention, restoring intensity and high-level semantics, respectively. As another major contribution of this work, we also introduce the first ultra high-resolution dataset to date for both reflection removal and rain streak removal, comprising 4,670 real-world and synthetic images. Extensive experiments across three typical tasks for image background restoration, including image reflection removal, image rain streak removal and image dehazing, show that our GLSGN consistently outperforms state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2207.08808",
    "authors": [
      "Xin Feng",
      "Haobo Ji",
      "Wenjie Pei",
      "Fanglin Chen",
      "David Zhang",
      "Guangming Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08811",
    "title": "Fusion of Physiological and Behavioural Signals on SPD Manifolds with  Application to Stress and Pain Detection",
    "abstract": "Existing multimodal stress/pain recognition approaches generally extract features from different modalities independently and thus ignore cross-modality correlations. This paper proposes a novel geometric framework for multimodal stress/pain detection utilizing Symmetric Positive Definite (SPD) matrices as a representation that incorporates the correlation relationship of physiological and behavioural signals from covariance and cross-covariance. Considering the non-linearity of the Riemannian manifold of SPD matrices, well-known machine learning techniques are not suited to classify these matrices. Therefore, a tangent space mapping method is adopted to map the derived SPD matrix sequences to the vector sequences in the tangent space where the LSTM-based network can be applied for classification. The proposed framework has been evaluated on two public multimodal datasets, achieving both the state-of-the-art results for stress and pain detection tasks. ",
    "url": "https://arxiv.org/abs/2207.08811",
    "authors": [
      "Yujin WU",
      "Mohamed Daoudi",
      "Ali Amad",
      "Laurent Sparrow",
      "Fabien D'Hondt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.08813",
    "title": "Audio Input Generates Continuous Frames to Synthesize Facial Video Using  Generative Adiversarial Networks",
    "abstract": "This paper presents a simple method for speech videos generation based on audio: given a piece of audio, we can generate a video of the target face speaking this audio. We propose Generative Adversarial Networks (GAN) with cut speech audio input as condition and use Convolutional Gate Recurrent Unit (GRU) in generator and discriminator. Our model is trained by exploiting the short audio and the frames in this duration. For training, we cut the audio and extract the face in the corresponding frames. We designed a simple encoder and compare the generated frames using GAN with and without GRU. We use GRU for temporally coherent frames and the results show that short audio can produce relatively realistic output results. ",
    "url": "https://arxiv.org/abs/2207.08813",
    "authors": [
      "Hanhaodi Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.08814",
    "title": "PBRE: A Rule Extraction Method from Trained Neural Networks Designed for  Smart Home Services",
    "abstract": "Designing smart home services is a complex task when multiple services with a large number of sensors and actuators are deployed simultaneously. It may rely on knowledge-based or data-driven approaches. The former can use rule-based methods to design services statically, and the latter can use learning methods to discover inhabitants' preferences dynamically. However, neither of these approaches is entirely satisfactory because rules cannot cover all possible situations that may change, and learning methods may make decisions that are sometimes incomprehensible to the inhabitant. In this paper, PBRE (Pedagogic Based Rule Extractor) is proposed to extract rules from learning methods to realize dynamic rule generation for smart home systems. The expected advantage is that both the explainability of rule-based methods and the dynamicity of learning methods are adopted. We compare PBRE with an existing rule extraction method, and the results show better performance of PBRE. We also apply PBRE to extract rules from a smart home service represented by an NRL (Neural Network-based Reinforcement Learning). The results show that PBRE can help the NRL-simulated service to make understandable suggestions to the inhabitant. ",
    "url": "https://arxiv.org/abs/2207.08814",
    "authors": [
      "Mingming Qiu",
      "Elie Najm",
      "Remi Sharrock",
      "Bruno Traverson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2207.08817",
    "title": "Research Trends and Applications of Data Augmentation Algorithms",
    "abstract": "In the Machine Learning research community, there is a consensus regarding the relationship between model complexity and the required amount of data and computation power. In real world applications, these computational requirements are not always available, motivating research on regularization methods. In addition, current and past research have shown that simpler classification algorithms can reach state-of-the-art performance on computer vision tasks given a robust method to artificially augment the training dataset. Because of this, data augmentation techniques became a popular research topic in recent years. However, existing data augmentation methods are generally less transferable than other regularization methods. In this paper we identify the main areas of application of data augmentation algorithms, the types of algorithms used, significant research trends, their progression over time and research gaps in data augmentation literature. To do this, the related literature was collected through the Scopus database. Its analysis was done following network science, text mining and exploratory analysis approaches. We expect readers to understand the potential of data augmentation, as well as identify future research directions and open questions within data augmentation research. ",
    "url": "https://arxiv.org/abs/2207.08817",
    "authors": [
      "Joao Fonseca",
      "Fernando Bacao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08821",
    "title": "The Multiple Subnetwork Hypothesis: Enabling Multidomain Learning by  Isolating Task-Specific Subnetworks in Feedforward Neural Networks",
    "abstract": "Neural networks have seen an explosion of usage and research in the past decade, particularly within the domains of computer vision and natural language processing. However, only recently have advancements in neural networks yielded performance improvements beyond narrow applications and translated to expanded multitask models capable of generalizing across multiple data types and modalities. Simultaneously, it has been shown that neural networks are overparameterized to a high degree, and pruning techniques have proved capable of significantly reducing the number of active weights within the network while largely preserving performance. In this work, we identify a methodology and network representational structure which allows a pruned network to employ previously unused weights to learn subsequent tasks. We employ these methodologies on well-known benchmarking datasets for testing purposes and show that networks trained using our approaches are able to learn multiple tasks, which may be related or unrelated, in parallel or in sequence without sacrificing performance on any task or exhibiting catastrophic forgetting. ",
    "url": "https://arxiv.org/abs/2207.08821",
    "authors": [
      "Jacob Renn",
      "Ian Sotnek",
      "Benjamin Harvey",
      "Brian Caffo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.08825",
    "title": "Contrastive Environmental Sound Representation Learning",
    "abstract": "Machine hearing of the environmental sound is one of the important issues in the audio recognition domain. It gives the machine the ability to discriminate between the different input sounds that guides its decision making. In this work we exploit the self-supervised contrastive technique and a shallow 1D CNN to extract the distinctive audio features (audio representations) without using any explicit annotations.We generate representations of a given audio using both its raw audio waveform and spectrogram and evaluate if the proposed learner is agnostic to the type of audio input. We further use canonical correlation analysis (CCA) to fuse representations from the two types of input of a given audio and demonstrate that the fused global feature results in robust representation of the audio signal as compared to the individual representations. The evaluation of the proposed technique is done on both ESC-50 and UrbanSound8K. The results show that the proposed technique is able to extract most features of the environmental audio and gives an improvement of 12.8% and 0.9% on the ESC-50 and UrbanSound8K datasets respectively. ",
    "url": "https://arxiv.org/abs/2207.08825",
    "authors": [
      "Peter Ochieng",
      "Dennis Kaburu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.08859",
    "title": "Prior-Guided Adversarial Initialization for Fast Adversarial Training",
    "abstract": "Fast adversarial training (FAT) effectively improves the efficiency of standard adversarial training (SAT). However, initial FAT encounters catastrophic overfitting, i.e.,the robust accuracy against adversarial attacks suddenly and dramatically decreases. Though several FAT variants spare no effort to prevent overfitting, they sacrifice much calculation cost. In this paper, we explore the difference between the training processes of SAT and FAT and observe that the attack success rate of adversarial examples (AEs) of FAT gets worse gradually in the late training stage, resulting in overfitting. The AEs are generated by the fast gradient sign method (FGSM) with a zero or random initialization. Based on the observation, we propose a prior-guided FGSM initialization method to avoid overfitting after investigating several initialization strategies, improving the quality of the AEs during the whole training process. The initialization is formed by leveraging historically generated AEs without additional calculation cost. We further provide a theoretical analysis for the proposed initialization method. We also propose a simple yet effective regularizer based on the prior-guided initialization,i.e., the currently generated perturbation should not deviate too much from the prior-guided initialization. The regularizer adopts both historical and current adversarial perturbations to guide the model learning. Evaluations on four datasets demonstrate that the proposed method can prevent catastrophic overfitting and outperform state-of-the-art FAT methods. The code is released at https://github.com/jiaxiaojunQAQ/FGSM-PGI. ",
    "url": "https://arxiv.org/abs/2207.08859",
    "authors": [
      "Xiaojun Jia",
      "Yong Zhang",
      "Xingxing Wei",
      "Baoyuan Wu",
      "Ke Ma",
      "Jue Wang",
      "Xiaochun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08865",
    "title": "Romanus: Robust Task Offloading in Modular Multi-Sensor Autonomous  Driving Systems",
    "abstract": "Due to the high performance and safety requirements of self-driving applications, the complexity of modern autonomous driving systems (ADS) has been growing, instigating the need for more sophisticated hardware which could add to the energy footprint of the ADS platform. Addressing this, edge computing is poised to encompass self-driving applications, enabling the compute-intensive autonomy-related tasks to be offloaded for processing at compute-capable edge servers. Nonetheless, the intricate hardware architecture of ADS platforms, in addition to the stringent robustness demands, set forth complications for task offloading which are unique to autonomous driving. Hence, we present $ROMANUS$, a methodology for robust and efficient task offloading for modular ADS platforms with multi-sensor processing pipelines. Our methodology entails two phases: (i) the introduction of efficient offloading points along the execution path of the involved deep learning models, and (ii) the implementation of a runtime solution based on Deep Reinforcement Learning to adapt the operating mode according to variations in the perceived road scene complexity, network connectivity, and server load. Experiments on the object detection use case demonstrated that our approach is 14.99% more energy-efficient than pure local execution while achieving a 77.06% reduction in risky behavior from a robust-agnostic offloading baseline. ",
    "url": "https://arxiv.org/abs/2207.08865",
    "authors": [
      "Luke Chen",
      "Mohanad Odema",
      "Mohammad Abdullah Al Faruque"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08878",
    "title": "A hierarchical semantic segmentation framework for computer vision-based  bridge damage detection",
    "abstract": "Computer vision-based damage detection using remote cameras and unmanned aerial vehicles (UAVs) enables efficient and low-cost bridge health monitoring that reduces labor costs and the needs for sensor installation and maintenance. By leveraging recent semantic image segmentation approaches, we are able to find regions of critical structural components and recognize damage at the pixel level using images as the only input. However, existing methods perform poorly when detecting small damages (e.g., cracks and exposed rebars) and thin objects with limited image samples, especially when the components of interest are highly imbalanced. To this end, this paper introduces a semantic segmentation framework that imposes the hierarchical semantic relationship between component category and damage types. For example, certain concrete cracks only present on bridge columns and therefore the non-column region will be masked out when detecting such damages. In this way, the damage detection model could focus on learning features from possible damaged regions only and avoid the effects of other irrelevant regions. We also utilize multi-scale augmentation that provides views with different scales that preserves contextual information of each image without losing the ability of handling small and thin objects. Furthermore, the proposed framework employs important sampling that repeatedly samples images containing rare components (e.g., railway sleeper and exposed rebars) to provide more data samples, which addresses the imbalanced data challenge. ",
    "url": "https://arxiv.org/abs/2207.08878",
    "authors": [
      "Jingxiao Liu",
      "Yujie Wei",
      "Bingqing Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08890",
    "title": "NeuForm: Adaptive Overfitting for Neural Shape Editing",
    "abstract": "Neural representations are popular for representing shapes, as they can be learned form sensor data and used for data cleanup, model completion, shape editing, and shape synthesis. Current neural representations can be categorized as either overfitting to a single object instance, or representing a collection of objects. However, neither allows accurate editing of neural scene representations: on the one hand, methods that overfit objects achieve highly accurate reconstructions, but do not generalize to unseen object configurations and thus cannot support editing; on the other hand, methods that represent a family of objects with variations do generalize but produce only approximate reconstructions. We propose NEUFORM to combine the advantages of both overfitted and generalizable representations by adaptively using the one most appropriate for each shape region: the overfitted representation where reliable data is available, and the generalizable representation everywhere else. We achieve this with a carefully designed architecture and an approach that blends the network weights of the two representations, avoiding seams and other artifacts. We demonstrate edits that successfully reconfigure parts of human-designed shapes, such as chairs, tables, and lamps, while preserving semantic integrity and the accuracy of an overfitted shape representation. We compare with two state-of-the-art competitors and demonstrate clear improvements in terms of plausibility and fidelity of the resultant edits. ",
    "url": "https://arxiv.org/abs/2207.08890",
    "authors": [
      "Connor Z. Lin",
      "Niloy J. Mitra",
      "Gordon Wetzstein",
      "Leonidas Guibas",
      "Paul Guerrero"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08896",
    "title": "On the Study of Sample Complexity for Polynomial Neural Networks",
    "abstract": "As a general type of machine learning approach, artificial neural networks have established state-of-art benchmarks in many pattern recognition and data analysis tasks. Among various kinds of neural networks architectures, polynomial neural networks (PNNs) have been recently shown to be analyzable by spectrum analysis via neural tangent kernel, and particularly effective at image generation and face recognition. However, acquiring theoretical insight into the computation and sample complexity of PNNs remains an open problem. In this paper, we extend the analysis in previous literature to PNNs and obtain novel results on sample complexity of PNNs, which provides some insights in explaining the generalization ability of PNNs. ",
    "url": "https://arxiv.org/abs/2207.08896",
    "authors": [
      "Chao Pan",
      "Chuanyi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.08913",
    "title": "Robust Factorizations and Colorings of Tensor Graphs",
    "abstract": "Since the seminal result of Karger, Motwani, and Sudan, algorithms for approximate 3-coloring have primarily centered around SDP-based rounding. However, it is likely that important combinatorial or algebraic insights are needed in order to break the $n^{o(1)}$ threshold. One way to develop new understanding in graph coloring is to study special subclasses of graphs. For instance, Blum studied the 3-coloring of random graphs, and Arora and Ge studied the 3-coloring of graphs with low threshold-rank. In this work, we study graphs which arise from a tensor product, which appear to be novel instances of the 3-coloring problem. We consider graphs of the form $H = (V,E)$ with $V =V( K_3 \\times G)$ and $E = E(K_3 \\times G) \\setminus E'$, where $E' \\subseteq E(K_3 \\times G)$ is any edge set such that no vertex has more than an $\\epsilon$ fraction of its edges in $E'$. We show that one can construct $\\widetilde{H} = K_3 \\times \\widetilde{G}$ with $V(\\widetilde{H}) = V(H)$ that is close to $H$. For arbitrary $G$, $\\widetilde{H}$ satisfies $|E(H) \\Delta E(\\widetilde{H})| \\leq O(\\epsilon|E(H)|)$. Additionally when $G$ is a mild expander, we provide a 3-coloring for $H$ in polynomial time. These results partially generalize an exact tensor factorization algorithm of Imrich. On the other hand, without any assumptions on $G$, we show that it is NP-hard to 3-color $H$. ",
    "url": "https://arxiv.org/abs/2207.08913",
    "authors": [
      "Joshua Brakensiek",
      "Sami Davies"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2207.08914",
    "title": "Conditional DETR V2: Efficient Detection Transformer with Box Queries",
    "abstract": "In this paper, we are interested in Detection Transformer (DETR), an end-to-end object detection approach based on a transformer encoder-decoder architecture without hand-crafted postprocessing, such as NMS. Inspired by Conditional DETR, an improved DETR with fast training convergence, that presented box queries (originally called spatial queries) for internal decoder layers, we reformulate the object query into the format of the box query that is a composition of the embeddings of the reference point and the transformation of the box with respect to the reference point. This reformulation indicates the connection between the object query in DETR and the anchor box that is widely studied in Faster R-CNN. Furthermore, we learn the box queries from the image content, further improving the detection quality of Conditional DETR still with fast training convergence. In addition, we adopt the idea of axial self-attention to save the memory cost and accelerate the encoder. The resulting detector, called Conditional DETR V2, achieves better results than Conditional DETR, saves the memory cost and runs more efficiently. For example, for the DC$5$-ResNet-$50$ backbone, our approach achieves $44.8$ AP with $16.4$ FPS on the COCO $val$ set and compared to Conditional DETR, it runs $1.6\\times$ faster, saves $74$\\% of the overall memory cost, and improves $1.0$ AP score. ",
    "url": "https://arxiv.org/abs/2207.08914",
    "authors": [
      "Xiaokang Chen",
      "Fangyun Wei",
      "Gang Zeng",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08937",
    "title": "A Community-Aware Framework for Social Influence Maximization",
    "abstract": "We consider the Influence Maximization (IM) problem: 'if we can try to convince a subset of individuals in a social network to adopt a new product or innovation, and the goal is to trigger a large cascade of further adoptions, which set of individuals should we target'? Formally, it is the task of selecting $k$ seed nodes in a social network such that the expected number of influenced nodes in the network (under some influence propagation model) is maximized. This problem has been widely studied in the literature and several solution approaches have been proposed. However, most simulation-based approaches involve time-consuming Monte-Carlo simulations to compute the influence of the seed nodes in the entire network. This limits the applicability of these methods on large social networks. In the paper, we are interested in solving the problem of influence maximization in a time-efficient manner. We propose a community-aware divide-and-conquer strategy that involves (i) learning the inherent community structure of the social network, (ii) generating candidate solutions by solving the influence maximization problem for each community, and (iii) selecting the final set of individuals from the candidate solutions using a novel progressive budgeting scheme. We provide experiments on real-world social networks, showing that the proposed algorithm outperforms the simulation-based algorithms in terms of empirical run-time and the heuristic algorithms in terms of influence. We also study the effect of the community structure on the performance of our algorithm. Our experiments show that the community structures with higher modularity lead the proposed algorithm to perform better in terms of run-time and influence. ",
    "url": "https://arxiv.org/abs/2207.08937",
    "authors": [
      "Abhishek Kumar Umrawal",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.08943",
    "title": "MRCLens: an MRC Dataset Bias Detection Toolkit",
    "abstract": "Many recent neural models have shown remarkable empirical results in Machine Reading Comprehension, but evidence suggests sometimes the models take advantage of dataset biases to predict and fail to generalize on out-of-sample data. While many other approaches have been proposed to address this issue from the computation perspective such as new architectures or training procedures, we believe a method that allows researchers to discover biases, and adjust the data or the models in an earlier stage will be beneficial. Thus, we introduce MRCLens, a toolkit that detects whether biases exist before users train the full model. For the convenience of introducing the toolkit, we also provide a categorization of common biases in MRC. ",
    "url": "https://arxiv.org/abs/2207.08943",
    "authors": [
      "Yifan Zhong",
      "Haohan Wang",
      "Eric P. Xing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08944",
    "title": "Robustar: Interactive Toolbox Supporting Precise Data Annotation for  Robust Vision Learning",
    "abstract": "We introduce the initial release of our software Robustar, which aims to improve the robustness of vision classification machine learning models through a data-driven perspective. Building upon the recent understanding that the lack of machine learning model's robustness is the tendency of the model's learning of spurious features, we aim to solve this problem from its root at the data perspective by removing the spurious features from the data before training. In particular, we introduce a software that helps the users to better prepare the data for training image classification models by allowing the users to annotate the spurious features at the pixel level of images. To facilitate this process, our software also leverages recent advances to help identify potential images and pixels worthy of attention and to continue the training with newly annotated data. Our software is hosted at the GitHub Repository https://github.com/HaohanWang/Robustar. ",
    "url": "https://arxiv.org/abs/2207.08944",
    "authors": [
      "Chonghan Chen",
      "Haohan Wang",
      "Leyang Hu",
      "Yuhao Zhang",
      "Shuguang Lyu",
      "Jingcheng Wu",
      "Xinnuo Li",
      "Linjing Sun",
      "Eric P. Xing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08948",
    "title": "Multi-step domain adaptation by adversarial attack to $\\mathcal{H}  \u0394\\mathcal{H}$-divergence",
    "abstract": "Adversarial examples are transferable between different models. In our paper, we propose to use this property for multi-step domain adaptation. In unsupervised domain adaptation settings, we demonstrate that replacing the source domain with adversarial examples to $\\mathcal{H} \\Delta \\mathcal{H}$-divergence can improve source classifier accuracy on the target domain. Our method can be connected to most domain adaptation techniques. We conducted a range of experiments and achieved improvement in accuracy on Digits and Office-Home datasets. ",
    "url": "https://arxiv.org/abs/2207.08948",
    "authors": [
      "Arip Asadulaev",
      "Alexander Panfilov",
      "Andrey Filchenkov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08950",
    "title": "Adversarial Training Improves Joint Energy-Based Generative Modelling",
    "abstract": "We propose the novel framework for generative modelling using hybrid energy-based models. In our method we combine the interpretable input gradients of the robust classifier and Langevin Dynamics for sampling. Using the adversarial training we improve not only the training stability, but robustness and generative modelling of the joint energy-based models. ",
    "url": "https://arxiv.org/abs/2207.08950",
    "authors": [
      "Rostislav Korst",
      "Arip Asadulaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08951",
    "title": "MonoIndoor++:Towards Better Practice of Self-Supervised Monocular Depth  Estimation for Indoor Environments",
    "abstract": "Self-supervised monocular depth estimation has seen significant progress in recent years, especially in outdoor environments. However, depth prediction results are not satisfying in indoor scenes where most of the existing data are captured with hand-held devices. As compared to outdoor environments, estimating depth of monocular videos for indoor environments, using self-supervised methods, results in two additional challenges: (i) the depth range of indoor video sequences varies a lot across different frames, making it difficult for the depth network to induce consistent depth cues for training; (ii) the indoor sequences recorded with handheld devices often contain much more rotational motions, which cause difficulties for the pose network to predict accurate relative camera poses. In this work, we propose a novel framework-MonoIndoor++ by giving special considerations to those challenges and consolidating a set of good practices for improving the performance of self-supervised monocular depth estimation for indoor environments. First, a depth factorization module with transformer-based scale regression network is proposed to estimate a global depth scale factor explicitly, and the predicted scale factor can indicate the maximum depth values. Second, rather than using a single-stage pose estimation strategy as in previous methods, we propose to utilize a residual pose estimation module to estimate relative camera poses across consecutive frames iteratively. Third, to incorporate extensive coordinates guidance for our residual pose estimation module, we propose to perform coordinate convolutional encoding directly over the inputs to pose networks. The proposed method is validated on a variety of benchmark indoor datasets, i.e., EuRoC MAV, NYUv2, ScanNet and 7-Scenes, demonstrating the state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2207.08951",
    "authors": [
      "Runze Li",
      "Pan Ji",
      "Yi Xu",
      "Bir Bhanu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08954",
    "title": "Exploiting Unlabeled Data with Vision and Language Models for Object  Detection",
    "abstract": "Building robust and generic object detection frameworks requires scaling to larger label spaces and bigger training datasets. However, it is prohibitively costly to acquire annotations for thousands of categories at a large scale. We propose a novel method that leverages the rich semantics available in recent vision and language models to localize and classify objects in unlabeled images, effectively generating pseudo labels for object detection. Starting with a generic and class-agnostic region proposal mechanism, we use vision and language models to categorize each region of an image into any object category that is required for downstream tasks. We demonstrate the value of the generated pseudo labels in two specific tasks, open-vocabulary detection, where a model needs to generalize to unseen object categories, and semi-supervised object detection, where additional unlabeled images can be used to improve the model. Our empirical evaluation shows the effectiveness of the pseudo labels in both tasks, where we outperform competitive baselines and achieve a novel state-of-the-art for open-vocabulary object detection. Our code is available at https://github.com/xiaofeng94/VL-PLM. ",
    "url": "https://arxiv.org/abs/2207.08954",
    "authors": [
      "Shiyu Zhao",
      "Zhixing Zhang",
      "Samuel Schulter",
      "Long Zhao",
      "Vijay Kumar B.G",
      "Anastasis Stathopoulos",
      "Manmohan Chandraker",
      "Dimitris Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08978",
    "title": "A Security & Privacy Analysis of US-based Contact Tracing Apps",
    "abstract": "With the onset of COVID-19, governments worldwide planned to develop and deploy contact tracing apps to help speed up the contact tracing process. However, experts raised concerns about the long-term privacy and security implications of using these apps. Consequently, several proposals were made to design privacy-preserving contact tracing apps. To this end, Google and Apple developed the Google/Apple Exposure Notification (GAEN) framework to help public health authorities develop privacy-preserving contact tracing apps. In the United States, 26 states used the GAEN framework to develop their contact tracing apps. In this paper, we empirically evaluate the US-based apps to determine 1) the privileges these apps have, 2) if the apps comply with their defined privacy policies, and 3) if they contain known vulnerabilities that can be exploited to compromise privacy. The results show that all apps violate their privacy policies and contain several known vulnerabilities. ",
    "url": "https://arxiv.org/abs/2207.08978",
    "authors": [
      "Joydeep Mitra"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.08979",
    "title": "SelectionConv: Convolutional Neural Networks for Non-rectilinear Image  Data",
    "abstract": "Convolutional Neural Networks have revolutionized vision applications. There are image domains and representations, however, that cannot be handled by standard CNNs (e.g., spherical images, superpixels). Such data are usually processed using networks and algorithms specialized for each type. In this work, we show that it may not always be necessary to use specialized neural networks to operate on such spaces. Instead, we introduce a new structured graph convolution operator that can copy 2D convolution weights, transferring the capabilities of already trained traditional CNNs to our new graph network. This network can then operate on any data that can be represented as a positional graph. By converting non-rectilinear data to a graph, we can apply these convolutions on these irregular image domains without requiring training on large domain-specific datasets. Results of transferring pre-trained image networks for segmentation, stylization, and depth prediction are demonstrated for a variety of such data forms. ",
    "url": "https://arxiv.org/abs/2207.08979",
    "authors": [
      "David Hart",
      "Michael Whitney",
      "Bryan Morse"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08988",
    "title": "Training Large-Vocabulary Neural Language Models by Private Federated  Learning for Resource-Constrained Devices",
    "abstract": "Federated Learning (FL) is a technique to train models using data distributed across devices. Differential Privacy (DP) provides a formal privacy guarantee for sensitive data. Our goal is to train a large neural network language model (NNLM) on compute-constrained devices while preserving privacy using FL and DP. However, the DP-noise introduced to the model increases as the model size grows, which often prevents convergence. We propose Partial Embedding Updates (PEU), a novel technique to decrease noise by decreasing payload size. Furthermore, we adopt Low Rank Adaptation (LoRA) and Noise Contrastive Estimation (NCE) to reduce the memory demands of large models on compute-constrained devices. This combination of techniques makes it possible to train large-vocabulary language models while preserving accuracy and privacy. ",
    "url": "https://arxiv.org/abs/2207.08988",
    "authors": [
      "Mingbin Xu",
      "Congzheng Song",
      "Ye Tian",
      "Neha Agrawal",
      "Filip Granqvist",
      "Rogier van Dalen",
      "Xiao Zhang",
      "Arturo Argueta",
      "Shiyi Han",
      "Yaqiao Deng",
      "Leo Liu",
      "Anmol Walia",
      "Alex Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.08996",
    "title": "Multi-Source AoI-Constrained Resource Minimization under HARQ:  Heterogeneous Sampling Processes",
    "abstract": "We consider a multi-source hybrid automatic repeat request (HARQ) based system, where a transmitter sends status update packets of random arrival (i.e., uncontrollable sampling) and generate-atwill (i.e., controllable sampling) sources to a destination through an error-prone channel. We develop transmission scheduling policies to minimize the average number of transmissions subject to an average age of information (AoI) constraint. First, we consider known environment (i.e., known system statistics) and develop a near-optimal deterministic transmission policy and a low-complexity dynamic transmission (LC-DT) policy. The former policy is derived by casting the main problem into a constrained Markov decision process (CMDP) problem, which is then solved using the Lagrangian relaxation, relative value iteration algorithm, and bisection. The LC-DT policy is developed via the drift-plus-penalty (DPP) method by transforming the main problem into a sequence of per-slot problems. Finally, we consider unknown environment and devise a learning-based transmission policy by relaxing the CMDP problem into an MDP problem using the DPP method and then adopting the deep Q-learning algorithm. Numerical results show that the proposed policies achieve near-optimal performance and illustrate the benefits of HARQ in status updating. ",
    "url": "https://arxiv.org/abs/2207.08996",
    "authors": [
      "Saeid Sadeghi Vilni",
      "Mohammad Moltafet",
      "Markus Leinonen",
      "Marian Codreanu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.09031",
    "title": "Decorrelative Network Architecture for Robust Electrocardiogram  Classification",
    "abstract": "Artificial intelligence has made great progresses in medical data analysis, but the lack of robustness and interpretability has kept these methods from being widely deployed. In particular, data-driven models are vulnerable to adversarial attacks, which are small, targeted perturbations that dramatically degrade model performance. As a recent example, while deep learning has shown impressive performance in electrocardiogram (ECG) classification, Han et al. crafted realistic perturbations that fooled the network 74% of the time [2020]. Current adversarial defense paradigms are computationally intensive and impractical for many high dimensional problems. Previous research indicates that a network vulnerability is related to the features learned during training. We propose a novel approach based on ensemble decorrelation and Fourier partitioning for training parallel network arms into a decorrelated architecture to learn complementary features, significantly reducing the chance of a perturbation fooling all arms of the deep learning model. We test our approach in ECG classification, demonstrating a much-improved 77.2% chance of at least one correct network arm on the strongest adversarial attack tested, in contrast to a 21.7% chance from a comparable ensemble. Our approach does not require expensive optimization with adversarial samples, and thus can be scaled to large problems. These methods can easily be applied to other tasks for improved network robustness. ",
    "url": "https://arxiv.org/abs/2207.09031",
    "authors": [
      "Christopher Wiedeman",
      "Ge Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.09049",
    "title": "RepBNN: towards a precise Binary Neural Network with Enhanced Feature  Map via Repeating",
    "abstract": "Binary neural network (BNN) is an extreme quantization version of convolutional neural networks (CNNs) with all features and weights mapped to just 1-bit. Although BNN saves a lot of memory and computation demand to make CNN applicable on edge or mobile devices, BNN suffers the drop of network performance due to the reduced representation capability after binarization. In this paper, we propose a new replaceable and easy-to-use convolution module RepConv, which enhances feature maps through replicating input or output along channel dimension by $\\beta$ times without extra cost on the number of parameters and convolutional computation. We also define a set of RepTran rules to use RepConv throughout BNN modules like binary convolution, fully connected layer and batch normalization. Experiments demonstrate that after the RepTran transformation, a set of highly cited BNNs have achieved universally better performance than the original BNN versions. For example, the Top-1 accuracy of Rep-ReCU-ResNet-20, i.e., a RepBconv enhanced ReCU-ResNet-20, reaches 88.97% on CIFAR-10, which is 1.47% higher than that of the original network. And Rep-AdamBNN-ReActNet-A achieves 71.342% Top-1 accuracy on ImageNet, a fresh state-of-the-art result of BNNs. Code and models are available at:https://github.com/imfinethanks/Rep_AdamBNN. ",
    "url": "https://arxiv.org/abs/2207.09049",
    "authors": [
      "Xulong Shi",
      "Zhi Qi",
      "Jiaxuan Cai",
      "Keqi Fu",
      "Yaru Zhao",
      "Zan Li",
      "Xuanyu Liu",
      "Hao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09065",
    "title": "Automated Black-Box Boundary Value Detection",
    "abstract": "The input domain of software systems can typically be divided into sub-domains for which the outputs are similar. To ensure high quality it is critical to test the software on the boundaries between these sub-domains. Consequently, boundary value analysis and testing has been part of the toolbox of software testers for long and is typically taught early to students. However, despite its many argued benefits, boundary value analysis for a given specification or piece of software is typically described in abstract terms which allow for variation in how testers apply it. Here we propose an automated, black-box boundary value detection method to support software testers in systematic boundary value analysis with consistent results. The method builds on a metric to quantify the level of boundariness of test inputs: the program derivative. By coupling it with search algorithms we find and rank pairs of inputs as good boundary candidates, i.e. inputs close together but with outputs far apart. We implement our AutoBVA approach and evaluate it on a curated dataset of example programs. Our results indicate that even with a simple and generic program derivative variant in combination with broad sampling over the input space, interesting boundary candidates can be identified. ",
    "url": "https://arxiv.org/abs/2207.09065",
    "authors": [
      "Felix Dobslaw",
      "Robert Feldt",
      "Francisco de Oliveira Neto"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2207.09066",
    "title": "Moment Centralization based Gradient Descent Optimizers for  Convolutional Neural Networks",
    "abstract": "Convolutional neural networks (CNNs) have shown very appealing performance for many computer vision applications. The training of CNNs is generally performed using stochastic gradient descent (SGD) based optimization techniques. The adaptive momentum-based SGD optimizers are the recent trends. However, the existing optimizers are not able to maintain a zero mean in the first-order moment and struggle with optimization. In this paper, we propose a moment centralization-based SGD optimizer for CNNs. Specifically, we impose the zero mean constraints on the first-order moment explicitly. The proposed moment centralization is generic in nature and can be integrated with any of the existing adaptive momentum-based optimizers. The proposed idea is tested with three state-of-the-art optimization techniques, including Adam, Radam, and Adabelief on benchmark CIFAR10, CIFAR100, and TinyImageNet datasets for image classification. The performance of the existing optimizers is generally improved when integrated with the proposed moment centralization. Further, The results of the proposed moment centralization are also better than the existing gradient centralization. The analytical analysis using the toy example shows that the proposed method leads to a shorter and smoother optimization trajectory. The source code is made publicly available at \\url{https://github.com/sumanthsadhu/MC-optimizer}. ",
    "url": "https://arxiv.org/abs/2207.09066",
    "authors": [
      "Sumanth Sadu",
      "Shiv Ram Dubey",
      "SR Sreeja"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09080",
    "title": "MUD-PQFed: Towards Malicious User Detection in Privacy-Preserving  Quantized Federated Learning",
    "abstract": "Federated Learning (FL), a distributed machine learning paradigm, has been adapted to mitigate privacy concerns for customers. Despite their appeal, there are various inference attacks that can exploit shared-plaintext model updates to embed traces of customer private information, leading to serious privacy concerns. To alleviate this privacy issue, cryptographic techniques such as Secure Multi-Party Computation and Homomorphic Encryption have been used for privacy-preserving FL. However, such security issues in privacy-preserving FL are poorly elucidated and underexplored. This work is the first attempt to elucidate the triviality of performing model corruption attacks on privacy-preserving FL based on lightweight secret sharing. We consider scenarios in which model updates are quantized to reduce communication overhead in this case, where an adversary can simply provide local parameters outside the legal range to corrupt the model. We then propose the MUD-PQFed protocol, which can precisely detect malicious clients performing attacks and enforce fair penalties. By removing the contributions of detected malicious clients, the global model utility is preserved to be comparable to the baseline global model without the attack. Extensive experiments validate effectiveness in maintaining baseline accuracy and detecting malicious clients in a fine-grained manner ",
    "url": "https://arxiv.org/abs/2207.09080",
    "authors": [
      "Hua Ma",
      "Qun Li",
      "Yifeng Zheng",
      "Zhi Zhang",
      "Xiaoning Liu",
      "Yansong Gao",
      "Said F. Al-Sarawi",
      "Derek Abbott"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.09081",
    "title": "Generalizing Goal-Conditioned Reinforcement Learning with Variational  Causal Reasoning",
    "abstract": "As a pivotal component to attaining generalizable solutions in human intelligence, reasoning provides great potential for reinforcement learning (RL) agents' generalization towards varied goals by summarizing part-to-whole arguments and discovering cause-and-effect relations. However, how to discover and represent causalities remains a huge gap that hinders the development of causal RL. In this paper, we augment Goal-Conditioned RL (GCRL) with Causal Graph (CG), a structure built upon the relation between objects and events. We novelly formulate the GCRL problem into variational likelihood maximization with CG as latent variables. To optimize the derived objective, we propose a framework with theoretical performance guarantees that alternates between two steps: using interventional data to estimate the posterior of CG; using CG to learn generalizable models and interpretable policies. Due to the lack of public benchmarks that verify generalization capability under reasoning, we design nine tasks and then empirically show the effectiveness of the proposed method against five baselines on these tasks. Further theoretical analysis shows that our performance improvement is attributed to the virtuous cycle of causal discovery, transition modeling, and policy training, which aligns with the experimental evidence in extensive ablation studies. ",
    "url": "https://arxiv.org/abs/2207.09081",
    "authors": [
      "Wenhao Ding",
      "Haohong Lin",
      "Bo Li",
      "Ding Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2207.09087",
    "title": "Is Vertical Logistic Regression Privacy-Preserving? A Comprehensive  Privacy Analysis and Beyond",
    "abstract": "We consider vertical logistic regression (VLR) trained with mini-batch gradient descent -- a setting which has attracted growing interest among industries and proven to be useful in a wide range of applications including finance and medical research. We provide a comprehensive and rigorous privacy analysis of VLR in a class of open-source Federated Learning frameworks, where the protocols might differ between one another, yet a procedure of obtaining local gradients is implicitly shared. We first consider the honest-but-curious threat model, in which the detailed implementation of protocol is neglected and only the shared procedure is assumed, which we abstract as an oracle. We find that even under this general setting, single-dimension feature and label can still be recovered from the other party under suitable constraints of batch size, thus demonstrating the potential vulnerability of all frameworks following the same philosophy. Then we look into a popular instantiation of the protocol based on Homomorphic Encryption (HE). We propose an active attack that significantly weaken the constraints on batch size in the previous analysis via generating and compressing auxiliary ciphertext. To address the privacy leakage within the HE-based protocol, we develop a simple-yet-effective countermeasure based on Differential Privacy (DP), and provide both utility and privacy guarantees for the updated algorithm. Finally, we empirically verify the effectiveness of our attack and defense on benchmark datasets. Altogether, our findings suggest that all vertical federated learning frameworks that solely depend on HE might contain severe privacy risks, and DP, which has already demonstrated its power in horizontal federated learning, can also play a crucial role in the vertical setting, especially when coupled with HE or secure multi-party computation (MPC) techniques. ",
    "url": "https://arxiv.org/abs/2207.09087",
    "authors": [
      "Yuzheng Hu",
      "Tianle Cai",
      "Jinyong Shan",
      "Shange Tang",
      "Chaochao Cai",
      "Ethan Song",
      "Bo Li",
      "Dawn Song"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09088",
    "title": "XG-BoT: An Explainable Deep Graph Neural Network for Botnet Detection  and Forensics",
    "abstract": "In this paper, we proposed XG-BoT, an explainable deep graph neural network model for botnet node detection. The proposed model is mainly composed of a botnet detector and an explainer for automatic forensics. The XG-BoT detector can effectively detect malicious botnet nodes under large-scale networks. Specifically, it utilizes a grouped reversible residual connection with a graph isomorphism network to learn expressive node representations from the botnet communication graphs. The explainer in XG-BoT can perform automatic network forensics by highlighting suspicious network flows and related botnet nodes. We evaluated XG-BoT on real-world, large-scale botnet network graphs. Overall, XG-BoT is able to outperform the state-of-the-art in terms of evaluation metrics. In addition, we show that the XG-BoT explainer can generate useful explanations based on GNNExplainer for automatic network forensics. ",
    "url": "https://arxiv.org/abs/2207.09088",
    "authors": [
      "Wai Weng Lo",
      "Siamak Layeghy",
      "Mohanad Sarhan",
      "Marius Portmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.09092",
    "title": "IoT Anomaly Detection Methods and Applications: A Survey",
    "abstract": "Ongoing research on anomaly detection for the Internet of Things (IoT) is a rapidly expanding field. This growth necessitates an examination of application trends and current gaps. The vast majority of those publications are in areas such as network and infrastructure security, sensor monitoring, smart home, and smart city applications and are extending into even more sectors. Recent advancements in the field have increased the necessity to study the many IoT anomaly detection applications. This paper begins with a summary of the detection methods and applications, accompanied by a discussion of the categorization of IoT anomaly detection algorithms. We then discuss the current publications to identify distinct application domains, examining papers chosen based on our search criteria. The survey considers 64 papers among recent publications published between January 2019 and July 2021. In recent publications, we observed a shortage of IoT anomaly detection methodologies, for example, when dealing with the integration of systems with various sensors, data and concept drifts, and data augmentation where there is a shortage of Ground Truth data. Finally, we discuss the present such challenges and offer new perspectives where further research is required. ",
    "url": "https://arxiv.org/abs/2207.09092",
    "authors": [
      "Ayan Chatterjee",
      "Bestoun S. Ahmed"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2207.09105",
    "title": "DUQIM-Net: Probabilistic Object Hierarchy Representation for Multi-View  Manipulation",
    "abstract": "Object manipulation in cluttered scenes is a difficult and important problem in robotics. To efficiently manipulate objects, it is crucial to understand their surroundings, especially in cases where multiple objects are stacked one on top of the other, preventing effective grasping. We here present DUQIM-Net, a decision-making approach for object manipulation in a setting of stacked objects. In DUQIM-Net, the hierarchical stacking relationship is assessed using Adj-Net, a model that leverages existing Transformer Encoder-Decoder object detectors by adding an adjacency head. The output of this head probabilistically infers the underlying hierarchical structure of the objects in the scene. We utilize the properties of the adjacency matrix in DUQIM-Net to perform decision making and assist with object-grasping tasks. Our experimental results show that Adj-Net surpasses the state-of-the-art in object-relationship inference on the Visual Manipulation Relationship Dataset (VMRD), and that DUQIM-Net outperforms comparable approaches in bin clearing tasks. ",
    "url": "https://arxiv.org/abs/2207.09105",
    "authors": [
      "Vladimir Tchuiev",
      "Yakov Miron",
      "Dotan Di-Castro"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.09107",
    "title": "MONet: Multi-scale Overlap Network for Duplication Detection in  Biomedical Images",
    "abstract": "Manipulation of biomedical images to misrepresent experimental results has plagued the biomedical community for a while. Recent interest in the problem led to the curation of a dataset and associated tasks to promote the development of biomedical forensic methods. Of these, the largest manipulation detection task focuses on the detection of duplicated regions between images. Traditional computer-vision based forensic models trained on natural images are not designed to overcome the challenges presented by biomedical images. We propose a multi-scale overlap detection model to detect duplicated image regions. Our model is structured to find duplication hierarchically, so as to reduce the number of patch operations. It achieves state-of-the-art performance overall and on multiple biomedical image categories. ",
    "url": "https://arxiv.org/abs/2207.09107",
    "authors": [
      "Ekraam Sabir",
      "Soumyaroop Nandi",
      "Wael AbdAlmageed",
      "Prem Natarajan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.09108",
    "title": "eCDT: Event Clustering for Simultaneous Feature Detection and Tracking-",
    "abstract": "Contrary to other standard cameras, event cameras interpret the world in an entirely different manner; as a collection of asynchronous events. Despite event camera's unique data output, many event feature detection and tracking algorithms have shown significant progress by making detours to frame-based data representations. This paper questions the need to do so and proposes a novel event data-friendly method that achieve simultaneous feature detection and tracking, called event Clustering-based Detection and Tracking (eCDT). Our method employs a novel clustering method, named as k-NN Classifier-based Spatial Clustering and Applications with Noise (KCSCAN), to cluster adjacent polarity events to retrieve event trajectories.With the aid of a Head and Tail Descriptor Matching process, event clusters that reappear in a different polarity are continually tracked, elongating the feature tracks. Thanks to our clustering approach in spatio-temporal space, our method automatically solves feature detection and feature tracking simultaneously. Also, eCDT can extract feature tracks at any frequency with an adjustable time window, which does not corrupt the high temporal resolution of the original event data. Our method achieves 30% better feature tracking ages compared with the state-of-the-art approach while also having a low error approximately equal to it. ",
    "url": "https://arxiv.org/abs/2207.09108",
    "authors": [
      "Sumin Hu",
      "Yeeun Kim",
      "Hyungtae Lim",
      "Alex Junho Lee",
      "Hyun Myung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09135",
    "title": "Shrinking the Semantic Gap: Spatial Pooling of Local Moment Invariants  for Copy-Move Forgery Detection",
    "abstract": "Copy-move forgery is a manipulation of copying and pasting specific patches from and to an image, with potentially illegal or unethical uses. Recent advances in the forensic methods for copy-move forgery have shown increasing success in detection accuracy and robustness. However, for images with high self-similarity or strong signal corruption, the existing algorithms often exhibit inefficient processes and unreliable results. This is mainly due to the inherent semantic gap between low-level visual representation and high-level semantic concept. In this paper, we present a very first study of trying to mitigate the semantic gap problem in copy-move forgery detection, with spatial pooling of local moment invariants for midlevel image representation. Our detection method expands the traditional works on two aspects: 1) we introduce the bag-of-visual-words model into this field for the first time, may meaning a new perspective of forensic study; 2) we propose a word-to-phrase feature description and matching pipeline, covering the spatial structure and visual saliency information of digital images. Extensive experimental results show the superior performance of our framework over state-of-the-art algorithms in overcoming the related problems caused by the semantic gap. ",
    "url": "https://arxiv.org/abs/2207.09135",
    "authors": [
      "Chao Wang",
      "Zhiqiu Huang",
      "Shuren Qi",
      "Yaoshen Yu",
      "Guohua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09136",
    "title": "Nonlinear Model Predictive Control Framework For Cooperative Three-Agent  Target Defense Game",
    "abstract": "This paper presents cooperative target defense guidance strategies using nonlinear model predictive control (NMPC) framework for a target-attacker-defender (TAD) game. The TAD game consists of an attacker and a cooperative target-defender pair. The attacker's objective is to capture the target, whereas the target-defender team acts together such that the defender can intercept the attacker and ensure target survival. We assume that the cooperative target-defender pair do not have perfect knowledge of the attacker states, and hence the states are estimated using an Extended Kalman Filter (EKF). The capture analysis based on the Apollonius circles is performed to identify the target survival regions. The efficacy of the NMPC-based solution is evaluated through extensive numerical simulations. The results show that the NMPC-based solution offers robustness to the different unknown attacker models and has better performance than CLOS and A-CLOS based strategies. ",
    "url": "https://arxiv.org/abs/2207.09136",
    "authors": [
      "Amith Manoharan",
      "P.B. Sujit"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.09139",
    "title": "Heterogeneous Treatment Effect with Trained Kernels of the  Nadaraya-Watson Regression",
    "abstract": "A new method for estimating the conditional average treatment effect is proposed in the paper. It is called TNW-CATE (the Trainable Nadaraya-Watson regression for CATE) and based on the assumption that the number of controls is rather large whereas the number of treatments is small. TNW-CATE uses the Nadaraya-Watson regression for predicting outcomes of patients from the control and treatment groups. The main idea behind TNW-CATE is to train kernels of the Nadaraya-Watson regression by using a weight sharing neural network of a specific form. The network is trained on controls, and it replaces standard kernels with a set of neural subnetworks with shared parameters such that every subnetwork implements the trainable kernel, but the whole network implements the Nadaraya-Watson estimator. The network memorizes how the feature vectors are located in the feature space. The proposed approach is similar to the transfer learning when domains of source and target data are similar, but tasks are different. Various numerical simulation experiments illustrate TNW-CATE and compare it with the well-known T-learner, S-learner and X-learner for several types of the control and treatment outcome functions. The code of proposed algorithms implementing TNW-CATE is available in https://github.com/Stasychbr/TNW-CATE. ",
    "url": "https://arxiv.org/abs/2207.09139",
    "authors": [
      "Andrei V. Konstantinov",
      "Stanislav R. Kirpichenko",
      "Lev V. Utkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.09141",
    "title": "Using Neural Networks by Modelling Semi-Active Shock Absorber",
    "abstract": "A permanently increasing number of on-board automotive control systems requires new approaches to their digital mapping that improves functionality in terms of adaptability and robustness as well as enables their easier on-line software update. As it can be concluded from many recent studies, various methods applying neural networks (NN) can be good candidates for relevant digital twin (DT) tools in automotive control system design, for example, for controller parameterization and condition monitoring. However, the NN-based DT has strong requirements to an adequate amount of data to be used in training and design. In this regard, the paper presents an approach, which demonstrates how the regression tasks can be efficiently handled by the modeling of a semi-active shock absorber within the DT framework. The approach is based on the adaptation of time series augmentation techniques to the stationary data that increases the variance of the latter. Such a solution gives a background to elaborate further data engineering methods for the data preparation of sophisticated databases. ",
    "url": "https://arxiv.org/abs/2207.09141",
    "authors": [
      "Moritz Zink",
      "Martin Schiele",
      "Valentin Ivanov"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09142",
    "title": "Existentially Quantified Systems of Equations as an Implicit  Representation of Answers in Logic Programming",
    "abstract": "In this paper we present an alternative approach to formalize the theory of logic programming. In this formalization we allow existential quantified variables and equations in queries. In opposite to standard approaches the role of answer will be played by existentially quantified systems of equations. This allows us to avoid problems when we deal with substitutions. In particular, we need no ''global'' variable separated conditions when new variables are introduced by input clauses. Moreover, this formalization can be regarded as a basis for the theory of concurrent logic languages, since it also includes a wide spectrum of parallel computational methods. Moreover, the parallel composition of answers can be defined directly -- as a consistent conjunction of answers. ",
    "url": "https://arxiv.org/abs/2207.09142",
    "authors": [
      "J\u00e1n Komara"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2207.09143",
    "title": "What Matters for 3D Scene Flow Network",
    "abstract": "3D scene flow estimation from point clouds is a low-level 3D motion perception task in computer vision. Flow embedding is a commonly used technique in scene flow estimation, and it encodes the point motion between two consecutive frames. Thus, it is critical for the flow embeddings to capture the correct overall direction of the motion. However, previous works only search locally to determine a soft correspondence, ignoring the distant points that turn out to be the actual matching ones. In addition, the estimated correspondence is usually from the forward direction of the adjacent point clouds, and may not be consistent with the estimated correspondence acquired from the backward direction. To tackle these problems, we propose a novel all-to-all flow embedding layer with backward reliability validation during the initial scene flow estimation. Besides, we investigate and compare several design choices in key components of the 3D scene flow network, including the point similarity calculation, input elements of predictor, and predictor & refinement level design. After carefully choosing the most effective designs, we are able to present a model that achieves the state-of-the-art performance on FlyingThings3D and KITTI Scene Flow datasets. Our proposed model surpasses all existing methods by at least 38.2% on FlyingThings3D dataset and 24.7% on KITTI Scene Flow dataset for EPE3D metric. We release our codes at https://github.com/IRMVLab/3DFlow. ",
    "url": "https://arxiv.org/abs/2207.09143",
    "authors": [
      "Guangming Wang",
      "Yunzhe Hu",
      "Zhe Liu",
      "Yiyang Zhou",
      "Masayoshi Tomizuka",
      "Wei Zhan",
      "Hesheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09154",
    "title": "On the development of a Bayesian optimisation framework for complex  unknown systems",
    "abstract": "Bayesian optimisation provides an effective method to optimise expensive black box functions. It has recently been applied to problems in fluid dynamics. This paper studies and compares common Bayesian optimisation algorithms empirically on a range of synthetic test functions. It investigates the choice of acquisition function and number of training samples, exact calculation of acquisition functions and Monte Carlo based approaches and both single-point and multi-point optimisation. The test functions considered cover a wide selection of challenges and therefore serve as an ideal test bed to understand the performance of Bayesian optimisation and to identify general situations where Bayesian optimisation performs well and poorly. This knowledge can be utilised in applications, including those in fluid dynamics, where objective functions are unknown. The results of this investigation show that the choices to be made are less relevant for relatively simple functions, while optimistic acquisition functions such as Upper Confidence Bound should be preferred for more complex objective functions. Furthermore, results from the Monte Carlo approach are comparable to results from analytical acquisition functions. In instances where the objective function allows parallel evaluations, the multi-point approach offers a quicker alternative, yet it may potentially require more objective function evaluations. ",
    "url": "https://arxiv.org/abs/2207.09154",
    "authors": [
      "Mike Diessner",
      "Yu Guan",
      "Kevin J. Wilson",
      "Richard D. Whalley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09156",
    "title": "Learning Mutual Modulation for Self-Supervised Cross-Modal  Super-Resolution",
    "abstract": "Self-supervised cross-modal super-resolution (SR) can overcome the difficulty of acquiring paired training data, but is challenging because only low-resolution (LR) source and high-resolution (HR) guide images from different modalities are available. Existing methods utilize pseudo or weak supervision in LR space and thus deliver results that are blurry or not faithful to the source modality. To address this issue, we present a mutual modulation SR (MMSR) model, which tackles the task by a mutual modulation strategy, including a source-to-guide modulation and a guide-to-source modulation. In these modulations, we develop cross-domain adaptive filters to fully exploit cross-modal spatial dependency and help induce the source to emulate the resolution of the guide and induce the guide to mimic the modality characteristics of the source. Moreover, we adopt a cycle consistency constraint to train MMSR in a fully self-supervised manner. Experiments on various tasks demonstrate the state-of-the-art performance of our MMSR. ",
    "url": "https://arxiv.org/abs/2207.09156",
    "authors": [
      "Xiaoyu Dong",
      "Naoto Yokoya",
      "Longguang Wang",
      "Tatsumi Uezato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09179",
    "title": "SCARA: Scalable Graph Neural Networks with Feature-Oriented Optimization",
    "abstract": "Recent advances in data processing have stimulated the demand for learning graphs of very large scales. Graph Neural Networks (GNNs), being an emerging and powerful approach in solving graph learning tasks, are known to be difficult to scale up. Most scalable models apply node-based techniques in simplifying the expensive graph message-passing propagation procedure of GNN. However, we find such acceleration insufficient when applied to million- or even billion-scale graphs. In this work, we propose SCARA, a scalable GNN with feature-oriented optimization for graph computation. SCARA efficiently computes graph embedding from node features, and further selects and reuses feature computation results to reduce overhead. Theoretical analysis indicates that our model achieves sub-linear time complexity with a guaranteed precision in propagation process as well as GNN training and inference. We conduct extensive experiments on various datasets to evaluate the efficacy and efficiency of SCARA. Performance comparison with baselines shows that SCARA can reach up to 100x graph propagation acceleration than current state-of-the-art methods with fast convergence and comparable accuracy. Most notably, it is efficient to process precomputation on the largest available billion-scale GNN dataset Papers100M (111M nodes, 1.6B edges) in 100 seconds. ",
    "url": "https://arxiv.org/abs/2207.09179",
    "authors": [
      "Ningyi Liao",
      "Dingheng Mo",
      "Siqiang Luo",
      "Xiang Li",
      "Pengcheng Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2207.09193",
    "title": "NDF: Neural Deformable Fields for Dynamic Human Modelling",
    "abstract": "We propose Neural Deformable Fields (NDF), a new representation for dynamic human digitization from a multi-view video. Recent works proposed to represent a dynamic human body with shared canonical neural radiance fields which links to the observation space with deformation fields estimations. However, the learned canonical representation is static and the current design of the deformation fields is not able to represent large movements or detailed geometry changes. In this paper, we propose to learn a neural deformable field wrapped around a fitted parametric body model to represent the dynamic human. The NDF is spatially aligned by the underlying reference surface. A neural network is then learned to map pose to the dynamics of NDF. The proposed NDF representation can synthesize the digitized performer with novel views and novel poses with a detailed and reasonable dynamic appearance. Experiments show that our method significantly outperforms recent human synthesis methods. ",
    "url": "https://arxiv.org/abs/2207.09193",
    "authors": [
      "Ruiqi Zhang",
      "Jie Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.09202",
    "title": "Exploring Disentangled Content Information for Face Forgery Detection",
    "abstract": "Convolutional neural network based face forgery detection methods have achieved remarkable results during training, but struggled to maintain comparable performance during testing. We observe that the detector is prone to focus more on content information than artifact traces, suggesting that the detector is sensitive to the intrinsic bias of the dataset, which leads to severe overfitting. Motivated by this key observation, we design an easily embeddable disentanglement framework for content information removal, and further propose a Content Consistency Constraint (C2C) and a Global Representation Contrastive Constraint (GRCC) to enhance the independence of disentangled features. Furthermore, we cleverly construct two unbalanced datasets to investigate the impact of the content bias. Extensive visualizations and experiments demonstrate that our framework can not only ignore the interference of content information, but also guide the detector to mine suspicious artifact traces and achieve competitive performance. ",
    "url": "https://arxiv.org/abs/2207.09202",
    "authors": [
      "Jiahao Liang",
      "Huafeng Shi",
      "Weihong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09204",
    "title": "VoloGAN: Adversarial Domain Adaptation for Synthetic Depth Data",
    "abstract": "We present VoloGAN, an adversarial domain adaptation network that translates synthetic RGB-D images of a high-quality 3D model of a person, into RGB-D images that could be generated with a consumer depth sensor. This system is especially useful to generate high amount training data for single-view 3D reconstruction algorithms replicating the real-world capture conditions, being able to imitate the style of different sensor types, for the same high-end 3D model database. The network uses a CycleGAN framework with a U-Net architecture for the generator and a discriminator inspired by SIV-GAN. We use different optimizers and learning rate schedules to train the generator and the discriminator. We further construct a loss function that considers image channels individually and, among other metrics, evaluates the structural similarity. We demonstrate that CycleGANs can be used to apply adversarial domain adaptation of synthetic 3D data to train a volumetric video generator model having only few training samples. ",
    "url": "https://arxiv.org/abs/2207.09204",
    "authors": [
      "Sascha Kirch",
      "Rafael Pag\u00e9s",
      "Sergio Arnaldo",
      "Sergio Mart\u00edn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.09209",
    "title": "FLDetector: Detecting Malicious Clients in Model Poisoning Attacks to  Federated Learning",
    "abstract": "Federated learning (FL) is vulnerable to model poisoning attacks, in which malicious clients corrupt the global model via sending manipulated model updates to the server. Existing defenses mainly rely on Byzantine-robust FL methods, which aim to learn an accurate global model even if some clients are malicious. However, they can only resist a small number of malicious clients in practice. It is still an open challenge how to defend against model poisoning attacks with a large number of malicious clients. Our FLDetector addresses this challenge via detecting malicious clients. FLDetector aims to detect and remove the majority of the malicious clients such that a Byzantine-robust FL method can learn an accurate global model using the remaining clients. Our key observation is that, in model poisoning attacks, the model updates from a client in multiple iterations are inconsistent. Therefore, FLDetector detects malicious clients via checking their model-updates consistency. Roughly speaking, the server predicts a client's model update in each iteration based on its historical model updates using the Cauchy mean value theorem and L-BFGS, and flags a client as malicious if the received model update from the client and the predicted model update are inconsistent in multiple iterations. Our extensive experiments on three benchmark datasets show that FLDetector can accurately detect malicious clients in multiple state-of-the-art model poisoning attacks. After removing the detected malicious clients, existing Byzantine-robust FL methods can learn accurate global models. ",
    "url": "https://arxiv.org/abs/2207.09209",
    "authors": [
      "Zaixi Zhang",
      "Xiaoyu Cao",
      "Jinayuan Jia",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.09240",
    "title": "IDET: Iterative Difference-Enhanced Transformers for High-Quality Change  Detection",
    "abstract": "Change detection (CD) aims to detect change regions within an image pair captured at different times, playing a significant role for diverse real-world applications. Nevertheless, most of existing works focus on designing advanced network architectures to map the feature difference to the final change map while ignoring the influence of the quality of the feature difference. In this paper, we study the CD from a new perspective, i.e., how to optimize the feature difference to highlight changes and suppress unchanged regions, and propose a novel module denoted as iterative difference-enhanced transformers (IDET). IDET contains three transformers: two transformers for extracting the long-range information of the two images and one transformer for enhancing the feature difference. In contrast to the previous transformers, the third transformer takes the outputs of the first two transformers to guide the enhancement of the feature difference iteratively. To achieve more effective refinement, we further propose the multi-scale IDET-based change detection that uses multi-scale representations of the images for multiple feature difference refinements and proposes a coarse-to-fine fusion strategy to combine all refinements. Our final CD method outperforms seven state-of-the-art methods on six large-scale datasets under diverse application scenarios, which demonstrates the importance of feature difference enhancements and the effectiveness of IDET. ",
    "url": "https://arxiv.org/abs/2207.09240",
    "authors": [
      "Rui Huang",
      "Ruofei Wang",
      "Qing Guo",
      "Yuxiang Zhang",
      "Wei Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09258",
    "title": "EVE: Environmental Adaptive Neural Network Models for Low-power Energy  Harvesting System",
    "abstract": "IoT devices are increasingly being implemented with neural network models to enable smart applications. Energy harvesting (EH) technology that harvests energy from ambient environment is a promising alternative to batteries for powering those devices due to the low maintenance cost and wide availability of the energy sources. However, the power provided by the energy harvester is low and has an intrinsic drawback of instability since it varies with the ambient environment. This paper proposes EVE, an automated machine learning (autoML) co-exploration framework to search for desired multi-models with shared weights for energy harvesting IoT devices. Those shared models incur significantly reduced memory footprint with different levels of model sparsity, latency, and accuracy to adapt to the environmental changes. An efficient on-device implementation architecture is further developed to efficiently execute each model on device. A run-time model extraction algorithm is proposed that retrieves individual model with negligible overhead when a specific model mode is triggered. Experimental results show that the neural networks models generated by EVE is on average 2.5X times faster than the baseline models without pruning and shared weights. ",
    "url": "https://arxiv.org/abs/2207.09258",
    "authors": [
      "Sahidul Islam",
      "Shanglin Zhou",
      "Ran Ran",
      "Yufang Jin",
      "Wujie Wen",
      "Caiwen Ding",
      "Mimi Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2207.09262",
    "title": "Efficient Constructions for the Gy\u0151ri-Lov\u00e1sz Theorem on Almost  Chordal Graphs",
    "abstract": "In the 1970s, Gy\\H{o}ri and Lov\\'{a}sz showed that for a $k$-connected $n$-vertex graph, a given set of terminal vertices $t_1, \\dots, t_k$ and natural numbers $n_1, \\dots, n_k$ satisfying $\\sum_{i=1}^{k} n_i = n$, a connected vertex partition $S_1, \\dots, S_k$ satisfying $t_i \\in S_i$ and $|S_i| = n_i$ exists. However, polynomial algorithms to actually compute such partitions are known so far only for $k \\leq 4$. This motivates us to take a new approach and constrain this problem to particular graph classes instead of restricting the values of $k$. More precisely, we consider $k$-connected chordal graphs and a broader class of graphs related to them. For the first, we give an algorithm with $O(n^2)$ running time that solves the problem exactly, and for the second, an algorithm with $O(n^4)$ running time that deviates on at most one vertex from the given required vertex partition sizes. ",
    "url": "https://arxiv.org/abs/2207.09262",
    "authors": [
      "Katrin Casel",
      "Tobias Friedrich",
      "Davis Issac",
      "Aikaterini Niklanovits",
      "Ziena Zeif"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2207.09302",
    "title": "Deep Semantic Statistics Matching (D2SM) Denoising Network",
    "abstract": "The ultimate aim of image restoration like denoising is to find an exact correlation between the noisy and clear image domains. But the optimization of end-to-end denoising learning like pixel-wise losses is performed in a sample-to-sample manner, which ignores the intrinsic correlation of images, especially semantics. In this paper, we introduce the Deep Semantic Statistics Matching (D2SM) Denoising Network. It exploits semantic features of pretrained classification networks, then it implicitly matches the probabilistic distribution of clear images at the semantic feature space. By learning to preserve the semantic distribution of denoised images, we empirically find our method significantly improves the denoising capabilities of networks, and the denoised results can be better understood by high-level vision tasks. Comprehensive experiments conducted on the noisy Cityscapes dataset demonstrate the superiority of our method on both the denoising performance and semantic segmentation accuracy. Moreover, the performance improvement observed on our extended tasks including super-resolution and dehazing experiments shows its potentiality as a new general plug-and-play component. ",
    "url": "https://arxiv.org/abs/2207.09302",
    "authors": [
      "Kangfu Mei",
      "Vishal M. Patel",
      "Rui Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09303",
    "title": "DH-AUG: DH Forward Kinematics Model Driven Augmentation for 3D Human  Pose Estimation",
    "abstract": "Due to the lack of diversity of datasets, the generalization ability of the pose estimator is poor. To solve this problem, we propose a pose augmentation solution via DH forward kinematics model, which we call DH-AUG. We observe that the previous work is all based on single-frame pose augmentation, if it is directly applied to video pose estimator, there will be several previously ignored problems: (i) angle ambiguity in bone rotation (multiple solutions); (ii) the generated skeleton video lacks movement continuity. To solve these problems, we propose a special generator based on DH forward kinematics model, which is called DH-generator. Extensive experiments demonstrate that DH-AUG can greatly increase the generalization ability of the video pose estimator. In addition, when applied to a single-frame 3D pose estimator, our method outperforms the previous best pose augmentation method. The source code has been released at https://github.com/hlz0606/DH-AUG-DH-Forward-Kinematics-Model-Driven-Augmentation-for-3D-Human-Pose-Estimation. ",
    "url": "https://arxiv.org/abs/2207.09303",
    "authors": [
      "Linzhi Huang",
      "Jiahao Liang",
      "Weihong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09314",
    "title": "Self-Supervised Interactive Object Segmentation Through a  Singulation-and-Grasping Approach",
    "abstract": "Instance segmentation with unseen objects is a challenging problem in unstructured environments. To solve this problem, we propose a robot learning approach to actively interact with novel objects and collect each object's training label for further fine-tuning to improve the segmentation model performance, while avoiding the time-consuming process of manually labeling a dataset. The Singulation-and-Grasping (SaG) policy is trained through end-to-end reinforcement learning. Given a cluttered pile of objects, our approach chooses pushing and grasping motions to break the clutter and conducts object-agnostic grasping for which the SaG policy takes as input the visual observations and imperfect segmentation. We decompose the problem into three subtasks: (1) the object singulation subtask aims to separate the objects from each other, which creates more space that alleviates the difficulty of (2) the collision-free grasping subtask; (3) the mask generation subtask to obtain the self-labeled ground truth masks by using an optical flow-based binary classifier and motion cue post-processing for transfer learning. Our system achieves 70% singulation success rate in simulated cluttered scenes. The interactive segmentation of our system achieves 87.8%, 73.9%, and 69.3% average precision for toy blocks, YCB objects in simulation and real-world novel objects, respectively, which outperforms several baselines. ",
    "url": "https://arxiv.org/abs/2207.09314",
    "authors": [
      "Houjian Yu",
      "Changhyun Choi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09324",
    "title": "Signed Network Embedding with Application to Simultaneous Detection of  Communities and Anomalies",
    "abstract": "Signed networks are frequently observed in real life with additional sign information associated with each edge, yet such information has been largely ignored in existing network models. This paper develops a unified embedding model for signed networks to disentangle the intertwined balance structure and anomaly effect, which can greatly facilitate the downstream analysis, including community detection, anomaly detection, and network inference. The proposed model captures both balance structure and anomaly effect through a low rank plus sparse matrix decomposition, which are jointly estimated via a regularized formulation. Its theoretical guarantees are established in terms of asymptotic consistency and finite-sample probability bounds for network embedding, community detection and anomaly detection. The advantage of the proposed embedding model is also demonstrated through extensive numerical experiments on both synthetic networks and an international relation network. ",
    "url": "https://arxiv.org/abs/2207.09324",
    "authors": [
      "Haoran Zhang",
      "Junhui Wang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.09332",
    "title": "Rethinking IoU-based Optimization for Single-stage 3D Object Detection",
    "abstract": "Since Intersection-over-Union (IoU) based optimization maintains the consistency of the final IoU prediction metric and losses, it has been widely used in both regression and classification branches of single-stage 2D object detectors. Recently, several 3D object detection methods adopt IoU-based optimization and directly replace the 2D IoU with 3D IoU. However, such a direct computation in 3D is very costly due to the complex implementation and inefficient backward operations. Moreover, 3D IoU-based optimization is sub-optimal as it is sensitive to rotation and thus can cause training instability and detection performance deterioration. In this paper, we propose a novel Rotation-Decoupled IoU (RDIoU) method that can mitigate the rotation-sensitivity issue, and produce more efficient optimization objectives compared with 3D IoU during the training stage. Specifically, our RDIoU simplifies the complex interactions of regression parameters by decoupling the rotation variable as an independent term, yet preserving the geometry of 3D IoU. By incorporating RDIoU into both the regression and classification branches, the network is encouraged to learn more precise bounding boxes and concurrently overcome the misalignment issue between classification and regression. Extensive experiments on the benchmark KITTI and Waymo Open Dataset validate that our RDIoU method can bring substantial improvement for the single-stage 3D object detection. ",
    "url": "https://arxiv.org/abs/2207.09332",
    "authors": [
      "Hualian Sheng",
      "Sijia Cai",
      "Na Zhao",
      "Bing Deng",
      "Jianqiang Huang",
      "Xian-Sheng Hua",
      "Min-Jian Zhao",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09339",
    "title": "Visual Representation Learning with Transformer: A Sequence-to-Sequence  Perspective",
    "abstract": "Visual representation learning is the key of solving various vision problems. Relying on the seminal grid structure priors, convolutional neural networks (CNNs) have been the de facto standard architectures of most deep vision models. For instance, classical semantic segmentation methods often adopt a fully-convolutional network (FCN) with an encoder-decoder architecture. The encoder progressively reduces the spatial resolution and learns more abstract visual concepts with larger receptive fields. Since context modeling is critical for segmentation, the latest efforts have been focused on increasing the receptive field, through either dilated (i.e., atrous) convolutions or inserting attention modules. However, the FCN-based architecture remains unchanged. In this paper, we aim to provide an alternative perspective by treating visual representation learning generally as a sequence-to-sequence prediction task. Specifically, we deploy a pure Transformer to encode an image as a sequence of patches, without local convolution and resolution reduction. With the global context modeled in every layer of the Transformer, stronger visual representation can be learned for better tackling vision tasks. In particular, our segmentation model, termed as SEgmentation TRansformer (SETR), excels on ADE20K (50.28% mIoU, the first position in the test leaderboard on the day of submission), Pascal Context (55.83% mIoU) and reaches competitive results on Cityscapes. Further, we formulate a family of Hierarchical Local-Global (HLG) Transformers characterized by local attention within windows and global-attention across windows in a hierarchical and pyramidal architecture. Extensive experiments show that our method achieves appealing performance on a variety of visual recognition tasks (e.g., image classification, object detection and instance segmentation and semantic segmentation). ",
    "url": "https://arxiv.org/abs/2207.09339",
    "authors": [
      "Li Zhang",
      "Sixiao Zheng",
      "Jiachen Lu",
      "Xinxuan Zhao",
      "Xiatian Zhu",
      "Yanwei Fu",
      "Tao Xiang",
      "Jianfeng Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09378",
    "title": "P4TE: PISA Switch Based Traffic Engineering in Fat-Tree Data Center  Networks",
    "abstract": "This work presents P4TE, an in-band traffic monitoring, load-aware packet forwarding, and flow rate controlling mechanism for traffic engineering in fat-tree topology-based data center networks using PISA switches. It achieves sub-RTT reaction time to change in network conditions, improved flow completion time, and balanced link utilization. Unlike the classical probe-based monitoring approach, P4TE uses an in-band monitoring approach to identify traffic events in the data plane. Based on these events, it re-adjusts the priorities of the paths. It uses a heuristic-based load-aware forwarding path selection mechanism to respond to changing network conditions and control the flow rate by sending feedback to the end hosts. It is implementable on emerging v1model.p4 architecture-based programmable switches and capable of maintaining the line-rate performance. Our evaluation shows that P4TE uses a small amount of resources in the PISA pipeline and achieves an improved flow completion time than ECMP and HULA. ",
    "url": "https://arxiv.org/abs/2207.09378",
    "authors": [
      "Debobroto Das Robin",
      "Javed I. Khan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.09390",
    "title": "Neural Greedy Pursuit for Feature Selection",
    "abstract": "We propose a greedy algorithm to select $N$ important features among $P$ input features for a non-linear prediction problem. The features are selected one by one sequentially, in an iterative loss minimization procedure. We use neural networks as predictors in the algorithm to compute the loss and hence, we refer to our method as neural greedy pursuit (NGP). NGP is efficient in selecting $N$ features when $N \\ll P$, and it provides a notion of feature importance in a descending order following the sequential selection procedure. We experimentally show that NGP provides better performance than several feature selection methods such as DeepLIFT and Drop-one-out loss. In addition, we experimentally show a phase transition behavior in which perfect selection of all $N$ features without false positives is possible when the training data size exceeds a threshold. ",
    "url": "https://arxiv.org/abs/2207.09390",
    "authors": [
      "Sandipan Das",
      "Alireza M. Javid",
      "Prakash Borpatra Gohain",
      "Yonina C. Eldar",
      "Saikat Chatterjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.09397",
    "title": "Composition Theorems for Interactive Differential Privacy",
    "abstract": "An interactive mechanism is an algorithm that stores a data set and answers adaptively chosen queries to it. The mechanism is called differentially private, if any adversary cannot distinguish whether a specific individual is in the data set by interacting with the mechanism. We study composition properties of differential privacy in concurrent compositions. In this setting, an adversary interacts with k interactive mechanisms in parallel and can interleave its queries to the mechanisms arbitrarily. Previously, [Vadhan and Wang, TCC 2021] proved an optimal concurrent composition theorem for pure-differential privacy. We significantly generalize and extend their results. Namely, we prove optimal parallel composition properties for several major notions of differential privacy in the literature, including approximate DP, R\\'enyi DP, and zero-concentrated DP. Our results demonstrate that the adversary gains no advantage by interleaving its queries to independently running mechanisms. Hence, interactivity is a feature that differential privacy grants us for free. ",
    "url": "https://arxiv.org/abs/2207.09397",
    "authors": [
      "Xin Lyu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2207.09399",
    "title": "RCLane: Relay Chain Prediction for Lane Detection",
    "abstract": "Lane detection is an important component of many real-world autonomous systems. Despite a wide variety of lane detection approaches have been proposed, reporting steady benchmark improvements over time, lane detection remains a largely unsolved problem. This is because most of the existing lane detection methods either treat the lane detection as a dense prediction or a detection task, few of them consider the unique topologies (Y-shape, Fork-shape, nearly horizontal lane) of the lane markers, which leads to sub-optimal solution. In this paper, we present a new method for lane detection based on relay chain prediction. Specifically, our model predicts a segmentation map to classify the foreground and background region. For each pixel point in the foreground region, we go through the forward branch and backward branch to recover the whole lane. Each branch decodes a transfer map and a distance map to produce the direction moving to the next point, and how many steps to progressively predict a relay station (next point). As such, our model is able to capture the keypoints along the lanes. Despite its simplicity, our strategy allows us to establish new state-of-the-art on four major benchmarks including TuSimple, CULane, CurveLanes and LLAMAS. ",
    "url": "https://arxiv.org/abs/2207.09399",
    "authors": [
      "Shenghua Xu",
      "Xinyue Cai",
      "Bin Zhao",
      "Li Zhang",
      "Hang Xu",
      "Yanwei Fu",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09408",
    "title": "Bounding generalization error with input compression: An empirical study  with infinite-width networks",
    "abstract": "Estimating the Generalization Error (GE) of Deep Neural Networks (DNNs) is an important task that often relies on availability of held-out data. The ability to better predict GE based on a single training set may yield overarching DNN design principles to reduce a reliance on trial-and-error, along with other performance assessment advantages. In search of a quantity relevant to GE, we investigate the Mutual Information (MI) between the input and final layer representations, using the infinite-width DNN limit to bound MI. An existing input compression-based GE bound is used to link MI and GE. To the best of our knowledge, this represents the first empirical study of this bound. In our attempt to empirically falsify the theoretical bound, we find that it is often tight for best-performing models. Furthermore, it detects randomization of training labels in many cases, reflects test-time perturbation robustness, and works well given only few training samples. These results are promising given that input compression is broadly applicable where MI can be estimated with confidence. ",
    "url": "https://arxiv.org/abs/2207.09408",
    "authors": [
      "Angus Galloway",
      "Anna Golubeva",
      "Mahmoud Salem",
      "Mihai Nica",
      "Yani Ioannou",
      "Graham W. Taylor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.09412",
    "title": "Det6D: A Ground-Aware Full-Pose 3D Object Detector for Improving Terrain  Robustness",
    "abstract": "Accurate 3D object detection with LiDAR is critical for autonomous driving. Existing research is all based on the flat-world assumption. However, the actual road can be complex with steep sections, which breaks the premise. Current methods suffer from performance degradation in this case due to difficulty correctly detecting objects on sloped terrain. In this work, we propose Det6D, the first full-degree-of-freedom 3D object detector without spatial and postural limitations, to improve terrain robustness. We choose the point-based framework by founding their capability of detecting objects in the entire spatial range. To predict full-degree poses, including pitch and roll, we design a ground-aware orientation branch that leverages the local ground constraints. Given the difficulty of long-tail non-flat scene data collection and 6D pose annotation, we present Slope-Aug, a data augmentation method for synthesizing non-flat terrain from existing datasets recorded in flat scenes. Experiments on various datasets demonstrate the effectiveness and robustness of our method in different terrains. We further conducted an extended experiment to explore how the network predicts the two extra poses. The proposed modules are plug-and-play for existing point-based frameworks. The code is available at https://github.com/HITSZ-NRSL/De6D. ",
    "url": "https://arxiv.org/abs/2207.09412",
    "authors": [
      "Junyuan Ouyang",
      "Haoyao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09429",
    "title": "Prior-Independent Auctions for Heterogeneous Bidders",
    "abstract": "We study the design of prior-independent auctions in a setting with heterogeneous bidders. In particular, we consider the setting of selling to $n$ bidders whose values are drawn from $n$ independent but not necessarily identical distributions. We work in the robust auction design regime, where we assume the seller has no knowledge of the bidders' value distributions and must design a mechanism that is prior-independent. While there have been many strong results on prior-independent auction design in the i.i.d. setting, not much is known for the heterogeneous setting, even though the latter is of significant practical importance. Unfortunately, no prior-independent mechanism can hope to always guarantee any approximation to Myerson's revenue in the heterogeneous setting; similarly, no prior-independent mechanism can consistently do better than the second-price auction. In light of this, we design a family of (parametrized) randomized auctions which approximates at least one of these benchmarks: For heterogeneous bidders with regular value distributions, our mechanisms either achieve a good approximation of the expected revenue of an optimal mechanism (which knows the bidders' distributions) or exceeds that of the second-price auction by a certain multiplicative factor. The factor in the latter case naturally trades off with the approximation ratio of the former case. We show that our mechanism is optimal for such a trade-off between the two cases by establishing a matching lower bound. Our result extends to selling $k$ identical items to heterogeneous bidders with an additional $O\\big(\\ln^2 k\\big)$-factor in our trade-off between the two cases. ",
    "url": "https://arxiv.org/abs/2207.09429",
    "authors": [
      "Guru Guruganesh",
      "Aranyak Mehta",
      "Di Wang",
      "Kangning Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2207.09432",
    "title": "Deep equilibrium networks are sensitive to initialization statistics",
    "abstract": "Deep equilibrium networks (DEQs) are a promising way to construct models which trade off memory for compute. However, theoretical understanding of these models is still lacking compared to traditional networks, in part because of the repeated application of a single set of weights. We show that DEQs are sensitive to the higher order statistics of the matrix families from which they are initialized. In particular, initializing with orthogonal or symmetric matrices allows for greater stability in training. This gives us a practical prescription for initializations which allow for training with a broader range of initial weight scales. ",
    "url": "https://arxiv.org/abs/2207.09432",
    "authors": [
      "Atish Agarwala",
      "Samuel S. Schoenholz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08824",
    "title": "3D Equivariant Molecular Graph Pretraining",
    "abstract": "Pretraining molecular representation models without labels is fundamental to various applications. Conventional methods mainly process 2D molecular graphs and focus solely on 2D tasks, making their pretrained models incapable of characterizing 3D geometry and thus defective for downstream 3D tasks. In this work, we tackle 3D molecular pretraining in a complete and novel sense. In particular, we first propose to adopt an equivariant energy-based model as the backbone for pretraining, which enjoys the merit of fulfilling the symmetry of 3D space. Then we develop a node-level pretraining loss for force prediction, where we further exploit the Riemann-Gaussian distribution to ensure the loss to be E(3)-invariant, enabling more robustness. Moreover, a graph-level noise scale prediction task is also leveraged to further promote the eventual performance. We evaluate our model pretrained from a large-scale 3D dataset GEOM-QM9 on two challenging 3D benchmarks: MD17 and QM9. The experimental results support the better efficacy of our method against current state-of-the-art pretraining approaches, and verify the validity of our design for each proposed component. ",
    "url": "https://arxiv.org/abs/2207.08824",
    "authors": [
      "Rui Jiao",
      "Jiaqi Han",
      "Wenbing Huang",
      "Yu Rong",
      "Yang Liu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08898",
    "title": "Benchmarking Machine Learning Robustness in Covid-19 Genome Sequence  Classification",
    "abstract": "The rapid spread of the COVID-19 pandemic has resulted in an unprecedented amount of sequence data of the SARS-CoV-2 genome -- millions of sequences and counting. This amount of data, while being orders of magnitude beyond the capacity of traditional approaches to understanding the diversity, dynamics, and evolution of viruses is nonetheless a rich resource for machine learning (ML) approaches as alternatives for extracting such important information from these data. It is of hence utmost importance to design a framework for testing and benchmarking the robustness of these ML models. This paper makes the first effort (to our knowledge) to benchmark the robustness of ML models by simulating biological sequences with errors. In this paper, we introduce several ways to perturb SARS-CoV-2 genome sequences to mimic the error profiles of common sequencing platforms such as Illumina and PacBio. We show from experiments on a wide array of ML models that some simulation-based approaches are more robust (and accurate) than others for specific embedding methods to certain adversarial attacks to the input sequences. Our benchmarking framework may assist researchers in properly assessing different ML models and help them understand the behavior of the SARS-CoV-2 virus or avoid possible future pandemics. ",
    "url": "https://arxiv.org/abs/2207.08898",
    "authors": [
      "Sarwan Ali",
      "Bikram Sahoo",
      "Alexander Zelikovskiy",
      "Pin-Yu Chen",
      "Murray Patterson"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08927",
    "title": "Towards Learning Self-Organized Criticality of Rydberg Atoms using Graph  Neural Networks",
    "abstract": "Self-Organized Criticality (SOC) is a ubiquitous dynamical phenomenon believed to be responsible for the emergence of universal scale-invariant behavior in many, seemingly unrelated systems, such as forest fires, virus spreading or atomic excitation dynamics. SOC describes the buildup of large-scale and long-range spatio-temporal correlations as a result of only local interactions and dissipation. The simulation of SOC dynamics is typically based on Monte-Carlo (MC) methods, which are however numerically expensive and do not scale beyond certain system sizes. We investigate the use of Graph Neural Networks (GNNs) as an effective surrogate model to learn the dynamics operator for a paradigmatic SOC system, inspired by an experimentally accessible physics example: driven Rydberg atoms. To this end, we generalize existing GNN simulation approaches to predict dynamics for the internal state of the node. We show that we can accurately reproduce the MC dynamics as well as generalize along the two important axes of particle number and particle density. This paves the way to model much larger systems beyond the limits of traditional MC methods. While the exact system is inspired by the dynamics of Rydberg atoms, the approach is quite general and can readily be applied to other systems. ",
    "url": "https://arxiv.org/abs/2207.08927",
    "authors": [
      "Simon Ohler",
      "Daniel Brady",
      "Winfried L\u00f6tzsch",
      "Michael Fleischhauer",
      "Johannes S. Otterbach"
    ],
    "subjectives": [
      "Atomic Physics (physics.atom-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09097",
    "title": "Lazy Estimation of Variable Importance for Large Neural Networks",
    "abstract": "As opaque predictive models increasingly impact many areas of modern life, interest in quantifying the importance of a given input variable for making a specific prediction has grown. Recently, there has been a proliferation of model-agnostic methods to measure variable importance (VI) that analyze the difference in predictive power between a full model trained on all variables and a reduced model that excludes the variable(s) of interest. A bottleneck common to these methods is the estimation of the reduced model for each variable (or subset of variables), which is an expensive process that often does not come with theoretical guarantees. In this work, we propose a fast and flexible method for approximating the reduced model with important inferential guarantees. We replace the need for fully retraining a wide neural network by a linearization initialized at the full model parameters. By adding a ridge-like penalty to make the problem convex, we prove that when the ridge penalty parameter is sufficiently large, our method estimates the variable importance measure with an error rate of $O(\\frac{1}{\\sqrt{n}})$ where $n$ is the number of training samples. We also show that our estimator is asymptotically normal, enabling us to provide confidence bounds for the VI estimates. We demonstrate through simulations that our method is fast and accurate under several data-generating regimes, and we demonstrate its real-world applicability on a seasonal climate forecasting example. ",
    "url": "https://arxiv.org/abs/2207.09097",
    "authors": [
      "Yue Gao",
      "Abby Stevens",
      "Rebecca Willet",
      "Garvesh Raskutti"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09389",
    "title": "Image Synthesis with Disentangled Attributes for Chest X-Ray Nodule  Augmentation and Detection",
    "abstract": "Lung nodule detection in chest X-ray (CXR) images is common to early screening of lung cancers. Deep-learning-based Computer-Assisted Diagnosis (CAD) systems can support radiologists for nodule screening in CXR. However, it requires large-scale and diverse medical data with high-quality annotations to train such robust and accurate CADs. To alleviate the limited availability of such datasets, lung nodule synthesis methods are proposed for the sake of data augmentation. Nevertheless, previous methods lack the ability to generate nodules that are realistic with the size attribute desired by the detector. To address this issue, we introduce a novel lung nodule synthesis framework in this paper, which decomposes nodule attributes into three main aspects including shape, size, and texture, respectively. A GAN-based Shape Generator firstly models nodule shapes by generating diverse shape masks. The following Size Modulation then enables quantitative control on the diameters of the generated nodule shapes in pixel-level granularity. A coarse-to-fine gated convolutional Texture Generator finally synthesizes visually plausible nodule textures conditioned on the modulated shape masks. Moreover, we propose to synthesize nodule CXR images by controlling the disentangled nodule attributes for data augmentation, in order to better compensate for the nodules that are easily missed in the detection task. Our experiments demonstrate the enhanced image quality, diversity, and controllability of the proposed lung nodule synthesis framework. We also validate the effectiveness of our data augmentation on greatly improving nodule detection performance. ",
    "url": "https://arxiv.org/abs/2207.09389",
    "authors": [
      "Zhenrong Shen",
      "Xi Ouyang",
      "Bin Xiao",
      "Jie-Zhi Cheng",
      "Qian Wang",
      "Dinggang Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09440",
    "title": "A Convolutional Neural Network Approach to Supernova Time-Series  Classification",
    "abstract": "One of the brightest objects in the universe, supernovae (SNe) are powerful explosions marking the end of a star's lifetime. Supernova (SN) type is defined by spectroscopic emission lines, but obtaining spectroscopy is often logistically unfeasible. Thus, the ability to identify SNe by type using time-series image data alone is crucial, especially in light of the increasing breadth and depth of upcoming telescopes. We present a convolutional neural network method for fast supernova time-series classification, with observed brightness data smoothed in both the wavelength and time directions with Gaussian process regression. We apply this method to full duration and truncated SN time-series, to simulate retrospective as well as real-time classification performance. Retrospective classification is used to differentiate cosmologically useful Type Ia SNe from other SN types, and this method achieves >99% accuracy on this task. We are also able to differentiate between 6 SN types with 60% accuracy given only two nights of data and 98% accuracy retrospectively. ",
    "url": "https://arxiv.org/abs/2207.09440",
    "authors": [
      "Helen Qu",
      "Masao Sako",
      "Anais Moller",
      "Cyrille Doux"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1205.5921",
    "title": "Diabetes prediction using Machine Learning algorithms and ontology",
    "abstract": " Title: Diabetes prediction using Machine Learning algorithms and ontology ",
    "url": "https://arxiv.org/abs/1205.5921",
    "authors": [
      "Hakim El Massari",
      "Zineb Sabouri",
      "Sajida Mhammedi",
      "Noreddine Gherabi"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:1905.11374",
    "title": "A Unifying Causal Framework for Analyzing Dataset Shift-stable Learning  Algorithms",
    "abstract": " Comments: Published in the Journal of Causal Inference ",
    "url": "https://arxiv.org/abs/1905.11374",
    "authors": [
      "Adarsh Subbaswamy",
      "Bryant Chen",
      "Suchi Saria"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2002.07606",
    "title": "Scheduling periodic messages on a shared link",
    "abstract": " Comments: 27 pages, 18 figures ",
    "url": "https://arxiv.org/abs/2002.07606",
    "authors": [
      "Ma\u00ebl Guiraud",
      "Yann Strozecki"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2002.11892",
    "title": "Multi-Robot Path Planning Using Medial-Axis-Based Pebble-Graph Embedding",
    "abstract": " Title: Multi-Robot Path Planning Using Medial-Axis-Based Pebble-Graph Embedding ",
    "url": "https://arxiv.org/abs/2002.11892",
    "authors": [
      "Liang He",
      "Zherong Pan",
      "Kiril Solovey",
      "Biao Jia",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2008.09041",
    "title": "A New Perspective on Stabilizing GANs training: Direct Adversarial  Training",
    "abstract": " Comments: Accepted to IEEE Transactions on Emerging Topics in Computational Intelligence ",
    "url": "https://arxiv.org/abs/2008.09041",
    "authors": [
      "Ziqiang Li",
      "Pengfei Xia",
      "Rentuo Tao",
      "Hongjing Niu",
      "Bin Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2101.11328",
    "title": "Recursive Decoding of Reed-Muller Codes Starting With the Higher-Rate  Constituent Code",
    "abstract": " Comments: Accepted for Publication in IEEE Transactions on Information Theory. This paper has been presented in part at the 2021 IEEE International Symposium on Information Theory (ISIT) ",
    "url": "https://arxiv.org/abs/2101.11328",
    "authors": [
      "Mikhail Kamenev"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2105.02711",
    "title": "SafeDrug: Dual Molecular Graph Encoders for Recommending Effective and  Safe Drug Combinations",
    "abstract": " Comments: Accepted in IJCAI 2021, this is the full version with appendix ",
    "url": "https://arxiv.org/abs/2105.02711",
    "authors": [
      "Chaoqi Yang",
      "Cao Xiao",
      "Fenglong Ma",
      "Lucas Glass",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.08760",
    "title": "Robust outlier detection by de-biasing VAE likelihoods",
    "abstract": " Comments: CVPR 2022. 20 pages and 19 figures ",
    "url": "https://arxiv.org/abs/2108.08760",
    "authors": [
      "Kushal Chauhan",
      "Barath Mohan U",
      "Pradeep Shenoy",
      "Manish Gupta",
      "Devarajan Sridharan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.04538",
    "title": "Focus Your Distribution: Coarse-to-Fine Non-Contrastive Learning for  Anomaly Detection and Localization",
    "abstract": " Comments: ICME2022 oral ",
    "url": "https://arxiv.org/abs/2110.04538",
    "authors": [
      "Ye Zheng",
      "Xiang Wang",
      "Rui Deng",
      "Tianpeng Bao",
      "Rui Zhao",
      "Liwei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.05940",
    "title": "Cycle-tree guided attack of random K-core: Spin glass model and  efficient message-passing algorithm",
    "abstract": " Comments: A label in Figure 3(b) was corrected ",
    "url": "https://arxiv.org/abs/2110.05940",
    "authors": [
      "Hai-Jun Zhou"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2111.03322",
    "title": "Automatic Repair and Deadlock Detection for Parameterized Systems",
    "abstract": " Title: Automatic Repair and Deadlock Detection for Parameterized Systems ",
    "url": "https://arxiv.org/abs/2111.03322",
    "authors": [
      "Swen Jacobs",
      "Mouhammad Sakr",
      "Marcus V\u00f6lp"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2111.07761",
    "title": "EmbAssi: Embedding Assignment Costs for Similarity Search in Large Graph  Databases",
    "abstract": " Comments: Data Min Knowl Disc (2022) ",
    "url": "https://arxiv.org/abs/2111.07761",
    "authors": [
      "Franka Bause",
      "Erich Schubert",
      "Nils M. Kriege"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2111.13579",
    "title": "VL-LTR: Learning Class-wise Visual-Linguistic Representation for  Long-Tailed Visual Recognition",
    "abstract": " Comments: Accepted by ECCV 2022; 14 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2111.13579",
    "authors": [
      "Changyao Tian",
      "Wenhai Wang",
      "Xizhou Zhu",
      "Jifeng Dai",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.00378",
    "title": "$\\ell_\\infty$-Robustness and Beyond: Unleashing Efficient Adversarial  Training",
    "abstract": " Comments: Accepted to the 17th European Conference on Computer Vision (ECCV 2022) ",
    "url": "https://arxiv.org/abs/2112.00378",
    "authors": [
      "Hadi M. Dolatabadi",
      "Sarah Erfani",
      "Christopher Leckie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.04966",
    "title": "CA-SSL: Class-Agnostic Semi-Supervised Learning for Detection and  Segmentation",
    "abstract": " Comments: Appeared in ECCV2022 ",
    "url": "https://arxiv.org/abs/2112.04966",
    "authors": [
      "Lu Qi",
      "Jason Kuen",
      "Zhe Lin",
      "Jiuxiang Gu",
      "Fengyun Rao",
      "Dian Li",
      "Weidong Guo",
      "Zhen Wen",
      "Ming-Hsuan Yang",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.07957",
    "title": "FEAR: Fast, Efficient, Accurate and Robust Visual Tracker",
    "abstract": " Title: FEAR: Fast, Efficient, Accurate and Robust Visual Tracker ",
    "url": "https://arxiv.org/abs/2112.07957",
    "authors": [
      "Vasyl Borsuk",
      "Roman Vei",
      "Orest Kupyn",
      "Tetiana Martyniuk",
      "Igor Krashenyi",
      "Ji\u0159i Matas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.14676",
    "title": "Learning nonlinear dynamics in synchronization of knowledge-based  leader-following networks",
    "abstract": " Title: Learning nonlinear dynamics in synchronization of knowledge-based  leader-following networks ",
    "url": "https://arxiv.org/abs/2112.14676",
    "authors": [
      "Shimin Wang",
      "Xiangyu Meng",
      "Hongwei Zhang",
      "Frank L. Lewis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2202.00211",
    "title": "GNNRank: Learning Global Rankings from Pairwise Comparisons via Directed  Graph Neural Networks",
    "abstract": " Comments: ICML 2022 spotlight; 32 pages (9 pages for main text) ",
    "url": "https://arxiv.org/abs/2202.00211",
    "authors": [
      "Yixuan He",
      "Quan Gan",
      "David Wipf",
      "Gesine Reinert",
      "Junchi Yan",
      "Mihai Cucuringu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.00980",
    "title": "Robust Training of Neural Networks Using Scale Invariant Architectures",
    "abstract": " Comments: 36 pages, 7 figures; ICML 2022 ",
    "url": "https://arxiv.org/abs/2202.00980",
    "authors": [
      "Zhiyuan Li",
      "Srinadh Bhojanapalli",
      "Manzil Zaheer",
      "Sashank J. Reddi",
      "Sanjiv Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.06804",
    "title": "Flexible learning of quantum states with generative query neural  networks",
    "abstract": " Comments: Major improvements in the presentation; new numerical experiments that illustrate the applicability of our neural network to various types of states ",
    "url": "https://arxiv.org/abs/2202.06804",
    "authors": [
      "Yan Zhu",
      "Ya-Dong Wu",
      "Ge Bai",
      "Dong-Sheng Wang",
      "Yuexuan Wang",
      "Giulio Chiribella"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.08146",
    "title": "A Prospective Approach for Human-to-Human Interaction Recognition from  Wi-Fi Channel Data using Attention Bidirectional Gated Recurrent Neural  Network with GUI Application Implementation",
    "abstract": " Comments: 24 Pages. This is the Pre-print version article submitted for Peer-Review to a prestigious journal ",
    "url": "https://arxiv.org/abs/2202.08146",
    "authors": [
      "Md. Mohi Uddin Khan",
      "Abdullah Bin Shams",
      "Md. Mohsin Sarker Raihan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.13538",
    "title": "Algorithm and System Co-design for Efficient Subgraph-based Graph  Representation Learning",
    "abstract": " Comments: This is an extended version of the full paper to appear in PVLDB 15.11(VLDB 2022) ",
    "url": "https://arxiv.org/abs/2202.13538",
    "authors": [
      "Haoteng Yin",
      "Muhan Zhang",
      "Yanbang Wang",
      "Jianguo Wang",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2203.00306",
    "title": "Comprehensive Analysis of the Object Detection Pipeline on UAVs",
    "abstract": " Comments: Submitted WACV23 ",
    "url": "https://arxiv.org/abs/2203.00306",
    "authors": [
      "Leon Amadeus Varga",
      "Sebastian Koch",
      "Andreas Zell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00949",
    "title": "GAP: Differentially Private Graph Neural Networks with Aggregation  Perturbation",
    "abstract": " Title: GAP: Differentially Private Graph Neural Networks with Aggregation  Perturbation ",
    "url": "https://arxiv.org/abs/2203.00949",
    "authors": [
      "Sina Sajadmanesh",
      "Ali Shahin Shamsabadi",
      "Aur\u00e9lien Bellet",
      "Daniel Gatica-Perez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.01386",
    "title": "Exploring Hierarchical Graph Representation for Large-Scale Zero-Shot  Image Classification",
    "abstract": " Comments: ECCV 2022, camera-ready version ",
    "url": "https://arxiv.org/abs/2203.01386",
    "authors": [
      "Kai Yi",
      "Xiaoqian Shen",
      "Yunhao Gou",
      "Mohamed Elhoseiny"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.02378",
    "title": "DiT: Self-supervised Pre-training for Document Image Transformer",
    "abstract": " Comments: ACM Multimedia 2022 ",
    "url": "https://arxiv.org/abs/2203.02378",
    "authors": [
      "Junlong Li",
      "Yiheng Xu",
      "Tengchao Lv",
      "Lei Cui",
      "Cha Zhang",
      "Furu Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.04419",
    "title": "Survival Prediction of Brain Cancer with Incomplete Radiology,  Pathology, Genomics, and Demographic Data",
    "abstract": " Title: Survival Prediction of Brain Cancer with Incomplete Radiology,  Pathology, Genomics, and Demographic Data ",
    "url": "https://arxiv.org/abs/2203.04419",
    "authors": [
      "Can Cui",
      "Han Liu",
      "Quan Liu",
      "Ruining Deng",
      "Zuhayr Asad",
      "Yaohong WangShilin Zhao",
      "Haichun Yang",
      "Bennett A. Landman",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.05625",
    "title": "PETR: Position Embedding Transformation for Multi-View 3D Object  Detection",
    "abstract": " Comments: Accepted by ECCV 2022. Code is available at \\url{this https URL} ",
    "url": "https://arxiv.org/abs/2203.05625",
    "authors": [
      "Yingfei Liu",
      "Tiancai Wang",
      "Xiangyu Zhang",
      "Jian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07724",
    "title": "CODA: A Real-World Road Corner Case Dataset for Object Detection in  Autonomous Driving",
    "abstract": " Comments: Accepted by ECCV 2022 ",
    "url": "https://arxiv.org/abs/2203.07724",
    "authors": [
      "Kaican Li",
      "Kai Chen",
      "Haoyu Wang",
      "Lanqing Hong",
      "Chaoqiang Ye",
      "Jianhua Han",
      "Yukuai Chen",
      "Wei Zhang",
      "Chunjing Xu",
      "Dit-Yan Yeung",
      "Xiaodan Liang",
      "Zhenguo Li",
      "Hang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.11089",
    "title": "PersFormer: 3D Lane Detection via Perspective Transformer and the  OpenLane Benchmark",
    "abstract": " Comments: Accepted by ECCV 2022 (Oral). Project page: this https URL | OpenLane dataset: this https URL ",
    "url": "https://arxiv.org/abs/2203.11089",
    "authors": [
      "Li Chen",
      "Chonghao Sima",
      "Yang Li",
      "Zehan Zheng",
      "Jiajie Xu",
      "Xiangwei Geng",
      "Hongyang Li",
      "Conghui He",
      "Jianping Shi",
      "Yu Qiao",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.00604",
    "title": "Quantized GAN for Complex Music Generation from Dance Videos",
    "abstract": " Comments: Dataset and code at this https URL ",
    "url": "https://arxiv.org/abs/2204.00604",
    "authors": [
      "Ye Zhu",
      "Kyle Olszewski",
      "Yu Wu",
      "Panos Achlioptas",
      "Menglei Chai",
      "Yan Yan",
      "Sergey Tulyakov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.02088",
    "title": "A Mixed supervised Learning Framework for Target Sound Detection",
    "abstract": " Comments: submitted to DCASE workshop ",
    "url": "https://arxiv.org/abs/2204.02088",
    "authors": [
      "Dongchao Yang",
      "Helin Wang",
      "Yuexian Zou",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.04245",
    "title": "Online Emotions During the Storming of the U.S. Capitol: Evidence from  the Social Media Network Parler",
    "abstract": " Comments: Accepted at the International AAAI Conference on Web and Social Media (ICWSM, 2023) ",
    "url": "https://arxiv.org/abs/2204.04245",
    "authors": [
      "Johannes Jakubik",
      "Michael V\u00f6ssing",
      "Dominik B\u00e4r",
      "Nicolas Pr\u00f6llochs",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.05133",
    "title": "On the link between conscious function and general intelligence in  humans and machines",
    "abstract": " Title: On the link between conscious function and general intelligence in  humans and machines ",
    "url": "https://arxiv.org/abs/2204.05133",
    "authors": [
      "Arthur Juliani",
      "Kai Arulkumaran",
      "Shuntaro Sasai",
      "Ryota Kanai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.06508",
    "title": "FactGraph: Evaluating Factuality in Summarization with Semantic Graph  Representations",
    "abstract": " Comments: NAACL 2022 (15 pages) ",
    "url": "https://arxiv.org/abs/2204.06508",
    "authors": [
      "Leonardo F. R. Ribeiro",
      "Mengwen Liu",
      "Iryna Gurevych",
      "Markus Dreyer",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.09443",
    "title": "GIMO: Gaze-Informed Human Motion Prediction in Context",
    "abstract": " Title: GIMO: Gaze-Informed Human Motion Prediction in Context ",
    "url": "https://arxiv.org/abs/2204.09443",
    "authors": [
      "Yang Zheng",
      "Yanchao Yang",
      "Kaichun Mo",
      "Jiaman Li",
      "Tao Yu",
      "Yebin Liu",
      "C. Karen Liu",
      "Leonidas J. Guibas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.13317",
    "title": "MMRotate: A Rotated Object Detection Benchmark using PyTorch",
    "abstract": " Comments: 5 pages, 2 tables, MMRotate is accepted by ACM MM 2022 (OS Track). Yue Zhou and Xue Yang provided equal contribution. The code is publicly released at this https URL ",
    "url": "https://arxiv.org/abs/2204.13317",
    "authors": [
      "Yue Zhou",
      "Xue Yang",
      "Gefan Zhang",
      "Jiabao Wang",
      "Yanyi Liu",
      "Liping Hou",
      "Xue Jiang",
      "Xingzhao Liu",
      "Junchi Yan",
      "Chengqi Lyu",
      "Wenwei Zhang",
      "Kai Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.00705",
    "title": "3D Object Detection with a Self-supervised Lidar Scene Flow Backbone",
    "abstract": " Title: 3D Object Detection with a Self-supervised Lidar Scene Flow Backbone ",
    "url": "https://arxiv.org/abs/2205.00705",
    "authors": [
      "Ekim Yurtsever",
      "Eme\u00e7 Er\u00e7elik",
      "Mingyu Liu",
      "Zhijie Yang",
      "Hanzhen Zhang",
      "P\u0131nar Top\u00e7am",
      "Maximilian Listl",
      "Y\u0131lmaz Kaan \u00c7ayl\u0131",
      "Alois Knoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.08455",
    "title": "Utterance Weighted Multi-Dilation Temporal Convolutional Networks for  Monaural Speech Dereverberation",
    "abstract": " Comments: Accepted at IWAENC 2022 ",
    "url": "https://arxiv.org/abs/2205.08455",
    "authors": [
      "William Ravenscroft",
      "Stefan Goetze",
      "Thomas Hain"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.09219",
    "title": "A Classification of $G$-invariant Shallow Neural Networks",
    "abstract": " Comments: 29 pages, 8 figures; corrected proof of Lemma 20, fixed typos including in the statement of Thm. 5 ",
    "url": "https://arxiv.org/abs/2205.09219",
    "authors": [
      "Devanshu Agrawal",
      "James Ostrowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.10864",
    "title": "Federated Learning Aggregation: New Robust Algorithms with Guarantees",
    "abstract": " Title: Federated Learning Aggregation: New Robust Algorithms with Guarantees ",
    "url": "https://arxiv.org/abs/2205.10864",
    "authors": [
      "Adnan Ben Mansour",
      "Gaia Carenini",
      "Alexandre Duplessis",
      "David Naccache"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.05263",
    "title": "Causal Balancing for Domain Generalization",
    "abstract": " Comments: 16 pages, 3 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2206.05263",
    "authors": [
      "Xinyi Wang",
      "Michael Saxon",
      "Jiachen Li",
      "Hongyang Zhang",
      "Kun Zhang",
      "William Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07990",
    "title": "Patch-level Representation Learning for Self-supervised Vision  Transformers",
    "abstract": " Comments: Accepted to CVPR 2022 (Oral). Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2206.07990",
    "authors": [
      "Sukmin Yun",
      "Hankook Lee",
      "Jaehyung Kim",
      "Jinwoo Shin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00095",
    "title": "End-to-end Learning for Image-based Detection of Molecular Alterations  in Digital Pathology",
    "abstract": " Comments: MICCAI 2022; 8.5 Pages, 4 Figures ",
    "url": "https://arxiv.org/abs/2207.00095",
    "authors": [
      "Marvin Teichmann",
      "Andre Aichert",
      "Hanibal Bohnenberger",
      "Philipp Str\u00f6bel",
      "Tobias Heimann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2207.02192",
    "title": "CEN : Cooperatively Evolving Networks",
    "abstract": " Title: CEN : Cooperatively Evolving Networks ",
    "url": "https://arxiv.org/abs/2207.02192",
    "authors": [
      "Sobhan Babu",
      "Ravindra Guravannavar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.02541",
    "title": "Dense Teacher: Dense Pseudo-Labels for Semi-supervised Object Detection",
    "abstract": " Comments: ECCV2022 ",
    "url": "https://arxiv.org/abs/2207.02541",
    "authors": [
      "Hongyu Zhou",
      "Zheng Ge",
      "Songtao Liu",
      "Weixin Mao",
      "Zeming Li",
      "Haiyan Yu",
      "Jian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04821",
    "title": "Long-term Reproducibility for Neural Architecture Search",
    "abstract": " Comments: 4 pages, LaTeX, Typos corrected ",
    "url": "https://arxiv.org/abs/2207.04821",
    "authors": [
      "David Towers",
      "Matthew Forshaw",
      "Amir Atapour-Abarghouei",
      "Andrew Stephen McGough"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.06918",
    "title": "Interference-Limited Ultra-Reliable and Low-Latency Communications:  Graph Neural Networks or Stochastic Geometry?",
    "abstract": " Comments: Submitted to IEEE journal for possible publication ",
    "url": "https://arxiv.org/abs/2207.06918",
    "authors": [
      "Yuhong Liu",
      "Changyang She",
      "Yi Zhong",
      "Wibowo Hardjawana",
      "Fu-Chun Zheng",
      "Branka Vucetic"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07219",
    "title": "Dynamic 5G Network Slice Management Middleware for Industrial Internet  of Things: Industry Paper",
    "abstract": " Comments: 10 pages, 9 figures, conference ",
    "url": "https://arxiv.org/abs/2207.07219",
    "authors": [
      "Ziran Min",
      "Shashank Shekhar",
      "Charif Mahmoudi",
      "Valerio Formicola",
      "Swapna Gokhale",
      "Aniruddha Gokhale"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.07316",
    "title": "Privacy-Preserving Face Recognition with Learnable Privacy Budgets in  Frequency Domain",
    "abstract": " Comments: ECCV 2022; Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2207.07316",
    "authors": [
      "Jiazhen Ji",
      "Huan Wang",
      "Yuge Huang",
      "Jiaxiang Wu",
      "Xingkun Xu",
      "Shouhong Ding",
      "ShengChuan Zhang",
      "Liujuan Cao",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07783",
    "title": "Learning Long-Term Spatial-Temporal Graphs for Active Speaker Detection",
    "abstract": " Comments: ECCV 2022 camera ready (Supplementary videos: on ECVA soon). This paper supersedes arXiv:2112.01479 ",
    "url": "https://arxiv.org/abs/2207.07783",
    "authors": [
      "Kyle Min",
      "Sourya Roy",
      "Subarna Tripathi",
      "Tanaya Guha",
      "Somdeb Majumdar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07795",
    "title": "RCRN: Real-world Character Image Restoration Network via Skeleton  Extraction",
    "abstract": " Comments: Accepted to ACM MM 2022 ",
    "url": "https://arxiv.org/abs/2207.07795",
    "authors": [
      "Daqian Shi",
      "Xiaolei Diao",
      "Hao Tang",
      "Xiaomin Li",
      "Hao Xing",
      "Hao Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07828",
    "title": "Structural Prior Guided Generative Adversarial Transformers for  Low-Light Image Enhancement",
    "abstract": " Title: Structural Prior Guided Generative Adversarial Transformers for  Low-Light Image Enhancement ",
    "url": "https://arxiv.org/abs/2207.07828",
    "authors": [
      "Cong Wang",
      "Jinshan Pan",
      "Xiao-Ming Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.08455",
    "title": "Open-world Semantic Segmentation via Contrasting and Clustering  Vision-Language Embedding",
    "abstract": " Comments: Accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2207.08455",
    "authors": [
      "Quande Liu",
      "Youpeng Wen",
      "Jianhua Han",
      "Chunjing Xu",
      "Hang Xu",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08485",
    "title": "Hierarchical Feature Alignment Network for Unsupervised Video Object  Segmentation",
    "abstract": " Comments: Accepted by ECCV-2022 ",
    "url": "https://arxiv.org/abs/2207.08485",
    "authors": [
      "Gensheng Pei",
      "Fumin Shen",
      "Yazhou Yao",
      "Guo-Sen Xie",
      "Zhenmin Tang",
      "Jinhui Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08629",
    "title": "Comprehensive Graph Gradual Pruning for Sparse Training in Graph Neural  Networks",
    "abstract": " Comments: 29 pages, 27 figures, submitting to IEEE TNNLS ",
    "url": "https://arxiv.org/abs/2207.08629",
    "authors": [
      "Chuang Liu",
      "Xueqi Ma",
      "Yibing Zhan",
      "Liang Ding",
      "Dapeng Tao",
      "Bo Du",
      "Wenbin Hu",
      "Danilo Mandic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]