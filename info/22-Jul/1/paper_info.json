[
  {
    "id": "arXiv:2206.14841",
    "title": "Causality for Inherently Explainable Transformers: CAT-XPLAIN",
    "abstract": "There have been several post-hoc explanation approaches developed to explain pre-trained black-box neural networks. However, there is still a gap in research efforts toward designing neural networks that are inherently explainable. In this paper, we utilize a recently proposed instance-wise post-hoc causal explanation method to make an existing transformer architecture inherently explainable. Once trained, our model provides an explanation in the form of top-$k$ regions in the input space of the given instance contributing to its decision. We evaluate our method on binary classification tasks using three image datasets: MNIST, FMNIST, and CIFAR. Our results demonstrate that compared to the causality-based post-hoc explainer model, our inherently explainable model achieves better explainability results while eliminating the need of training a separate explainer model. Our code is available at https://github.com/mvrl/CAT-XPLAIN. ",
    "url": "https://arxiv.org/abs/2206.14841",
    "authors": [
      "Subash Khanal",
      "Benjamin Brodie",
      "Xin Xing",
      "Ai-Ling Lin",
      "Nathan Jacobs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14854",
    "title": "Neural Motion Fields: Encoding Grasp Trajectories as Implicit Value  Functions",
    "abstract": "The pipeline of current robotic pick-and-place methods typically consists of several stages: grasp pose detection, finding inverse kinematic solutions for the detected poses, planning a collision-free trajectory, and then executing the open-loop trajectory to the grasp pose with a low-level tracking controller. While these grasping methods have shown good performance on grasping static objects on a table-top, the problem of grasping dynamic objects in constrained environments remains an open problem. We present Neural Motion Fields, a novel object representation which encodes both object point clouds and the relative task trajectories as an implicit value function parameterized by a neural network. This object-centric representation models a continuous distribution over the SE(3) space and allows us to perform grasping reactively by leveraging sampling-based MPC to optimize this value function. ",
    "url": "https://arxiv.org/abs/2206.14854",
    "authors": [
      "Yun-Chun Chen",
      "Adithyavairavan Murali",
      "Balakumar Sundaralingam",
      "Wei Yang",
      "Animesh Garg",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14855",
    "title": "SoK: Content Moderation in Social Media, from Guidelines to Enforcement,  and Research to Practice",
    "abstract": "To counter online abuse and misinformation, social media platforms have been establishing content moderation guidelines and employing various moderation policies. The goal of this paper is to study these community guidelines and moderation practices, as well as the relevant research publications to identify the research gaps, differences in moderation techniques, and challenges that should be tackled by the social media platforms and the research community at large. In this regard, we study and analyze in the US jurisdiction the fourteen most popular social media content moderation guidelines and practices, and consolidate them. We then introduce three taxonomies drawn from this analysis as well as covering over one hundred interdisciplinary research papers about moderation strategies. We identified the differences between the content moderation employed in mainstream social media platforms compared to fringe platforms. We also highlight the implications of Section 230, the need for transparency and opacity in content moderation, why platforms should shift from a one-size-fits-all model to a more inclusive model, and lastly, we highlight why there is a need for a collaborative human-AI system. ",
    "url": "https://arxiv.org/abs/2206.14855",
    "authors": [
      "Mohit Singhal",
      "Chen Ling",
      "Nihal Kumarswamy",
      "Gianluca Stringhini",
      "Shirin Nilizadeh"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.14862",
    "title": "Momentum Diminishes the Effect of Spectral Bias in Physics-Informed  Neural Networks",
    "abstract": "Physics-informed neural network (PINN) algorithms have shown promising results in solving a wide range of problems involving partial differential equations (PDEs). However, they often fail to converge to desirable solutions when the target function contains high-frequency features, due to a phenomenon known as spectral bias. In the present work, we exploit neural tangent kernels (NTKs) to investigate the training dynamics of PINNs evolving under stochastic gradient descent with momentum (SGDM). This demonstrates SGDM significantly reduces the effect of spectral bias. We have also examined why training a model via the Adam optimizer can accelerate the convergence while reducing the spectral bias. Moreover, our numerical experiments have confirmed that wide-enough networks using SGDM still converge to desirable solutions, even in the presence of high-frequency features. In fact, we show that the width of a network plays a critical role in convergence. ",
    "url": "https://arxiv.org/abs/2206.14862",
    "authors": [
      "Ghazal Farhani",
      "Alexander Kazachek",
      "Boyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.14885",
    "title": "Space-Efficient Representation of Entity-centric Query Language Models",
    "abstract": "Virtual assistants make use of automatic speech recognition (ASR) to help users answer entity-centric queries. However, spoken entity recognition is a difficult problem, due to the large number of frequently-changing named entities. In addition, resources available for recognition are constrained when ASR is performed on-device. In this work, we investigate the use of probabilistic grammars as language models within the finite-state transducer (FST) framework. We introduce a deterministic approximation to probabilistic grammars that avoids the explicit expansion of non-terminals at model creation time, integrates directly with the FST framework, and is complementary to n-gram models. We obtain a 10% relative word error rate improvement on long tail entity queries compared to when a similarly-sized n-gram model is used without our method. ",
    "url": "https://arxiv.org/abs/2206.14885",
    "authors": [
      "Christophe Van Gysel",
      "Mirko Hannemann",
      "Ernest Pusateri",
      "Youssef Oualil",
      "Ilya Oparin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.14898",
    "title": "Recognizing Map Graphs of Bounded Treewidth",
    "abstract": "A map graph is a graph admitting a representation in which vertices are nations on a spherical map and edges are shared curve segments or points between nations. We present an explicit fixed-parameter tractable algorithm for recognizing map graphs parameterized by treewidth. The algorithm has time complexity that is linear in the size of the graph and, if the input is a yes-instance, it reports a certificate in the form of a so-called witness. Furthermore, this result is developed within a more general algorithmic framework that allows to test, for any $k$, if the input graph admits a $k$-map (where at most $k$ nations meet at a common point) or a hole-free~$k$-map (where each point of the sphere is covered by at least one nation). We point out that, although bounding the treewidth of the input graph also bounds the size of its largest clique, the latter alone does not seem to be a strong enough structural limitation to obtain an efficient time complexity. In fact, while the largest clique in a $k$-map graph is $\\lfloor 3k/2 \\rfloor$, the recognition of $k$-map graphs is still open for any fixed $k \\ge 5$. ",
    "url": "https://arxiv.org/abs/2206.14898",
    "authors": [
      "Patrizio Angelini",
      "Michael A. Bekos",
      "Giordano Da Lozzo",
      "Martin Gronemann",
      "Fabrizio Montecchiani",
      "Alessandra Tappini"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2206.14909",
    "title": "RAC Drawings of Graphs with Low Degree",
    "abstract": "Motivated by cognitive experiments providing evidence that large crossing-angles do not impair the readability of a graph drawing, RAC (Right Angle Crossing) drawings were introduced to address the problem of producing readable representations of non-planar graphs by supporting the optimal case in which all crossings form 90{\\deg} angles. In this work, we make progress on the problem of finding RAC drawings of graphs of low degree. In this context, a long-standing open question asks whether all degree-3 graphs admit straight-line RAC drawings. This question has been positively answered for the Hamiltonian degree-3 graphs. We improve on this result by extending to the class of 3-edge-colorable degree-3 graphs. When each edge is allowed to have one bend, we prove that degree-4 graphs admit such RAC drawings, a result which was previously known only for degree-3 graphs. Finally, we show that 7-edge-colorable degree-7 graphs admit RAC drawings with two bends per edge. This improves over the previous result on degree-6 graphs. ",
    "url": "https://arxiv.org/abs/2206.14909",
    "authors": [
      "Patrizio Angelini",
      "Michael A. Bekos",
      "Julia Katheder",
      "Michael Kaufmann",
      "Maximilian Pfister"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2206.14925",
    "title": "ComDensE : Combined Dense Embedding of Relation-aware and Common  Features for Knowledge Graph Completion",
    "abstract": "Real-world knowledge graphs (KG) are mostly incomplete. The problem of recovering missing relations, called KG completion, has recently become an active research area. Knowledge graph (KG) embedding, a low-dimensional representation of entities and relations, is the crucial technique for KG completion. Convolutional neural networks in models such as ConvE, SACN, InteractE, and RGCN achieve recent successes. This paper takes a different architectural view and proposes ComDensE which combines relation-aware and common features using dense neural networks. In the relation-aware feature extraction, we attempt to create relational inductive bias by applying an encoding function specific to each relation. In the common feature extraction, we apply the common encoding function to all input embeddings. These encoding functions are implemented using dense layers in ComDensE. ComDensE achieves the state-of-the-art performance in the link prediction in terms of MRR, HIT@1 on FB15k-237 and HIT@1 on WN18RR compared to the previous baseline approaches. We conduct an extensive ablation study to examine the effects of the relation-aware layer and the common layer of the ComDensE. Experimental results illustrate that the combined dense architecture as implemented in ComDensE achieves the best performance. ",
    "url": "https://arxiv.org/abs/2206.14925",
    "authors": [
      "Minsang Kim",
      "Seungjun Baek"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14971",
    "title": "Boosting 3D Object Detection by Simulating Multimodality on Point Clouds",
    "abstract": "This paper presents a new approach to boost a single-modality (LiDAR) 3D object detector by teaching it to simulate features and responses that follow a multi-modality (LiDAR-image) detector. The approach needs LiDAR-image data only when training the single-modality detector, and once well-trained, it only needs LiDAR data at inference. We design a novel framework to realize the approach: response distillation to focus on the crucial response samples and avoid the background samples; sparse-voxel distillation to learn voxel semantics and relations from the estimated crucial voxels; a fine-grained voxel-to-point distillation to better attend to features of small and distant objects; and instance distillation to further enhance the deep-feature consistency. Experimental results on the nuScenes dataset show that our approach outperforms all SOTA LiDAR-only 3D detectors and even surpasses the baseline LiDAR-image detector on the key NDS metric, filling 72% mAP gap between the single- and multi-modality detectors. ",
    "url": "https://arxiv.org/abs/2206.14971",
    "authors": [
      "Wu Zheng",
      "Mingxuan Hong",
      "Li Jiang",
      "Chi-Wing Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14973",
    "title": "Benchmarking the Robustness of Deep Neural Networks to Common  Corruptions in Digital Pathology",
    "abstract": "When designing a diagnostic model for a clinical application, it is crucial to guarantee the robustness of the model with respect to a wide range of image corruptions. Herein, an easy-to-use benchmark is established to evaluate how deep neural networks perform on corrupted pathology images. Specifically, corrupted images are generated by injecting nine types of common corruptions into validation images. Besides, two classification and one ranking metrics are designed to evaluate the prediction and confidence performance under corruption. Evaluated on two resulting benchmark datasets, we find that (1) a variety of deep neural network models suffer from a significant accuracy decrease (double the error on clean images) and the unreliable confidence estimation on corrupted images; (2) A low correlation between the validation and test errors while replacing the validation set with our benchmark can increase the correlation. Our codes are available on https://github.com/superjamessyx/robustness_benchmark. ",
    "url": "https://arxiv.org/abs/2206.14973",
    "authors": [
      "Yunlong Zhang",
      "Yuxuan Sun",
      "Honglin Li",
      "Sunyi Zheng",
      "Chenglu Zhu",
      "Lin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.14976",
    "title": "Semi-Supervised Generative Adversarial Network for Stress Detection  Using Partially Labeled Physiological Data",
    "abstract": "Physiological measurements involves observing variables that attribute to the normative functioning of human systems and subsystems directly or indirectly. The measurements can be used to detect affective states of a person with aims such as improving human-computer interactions. There are several methods of collecting physiological data, but wearable sensors are a common, non-invasive tool for accurate readings. However, valuable information is hard to extract from the raw physiological data, especially for affective state detection. Machine Learning techniques are used to detect the affective state of a person through labeled physiological data. A clear problem with using labeled data is creating accurate labels. An expert is needed to analyze a form of recording of participants and mark sections with different states such as stress and calm. While expensive, this method delivers a complete dataset with labeled data that can be used in any number of supervised algorithms. An interesting question arises from the expensive labeling: how can we reduce the cost while maintaining high accuracy? Semi-Supervised learning (SSL) is a potential solution to this problem. These algorithms allow for machine learning models to be trained with only a small subset of labeled data (unlike unsupervised which use no labels). They provide a way of avoiding expensive labeling. This paper compares a fully supervised algorithm to a SSL on the public WESAD (Wearable Stress and Affect Detection) Dataset for stress detection. This paper shows that Semi-Supervised algorithms are a viable method for inexpensive affective state detection systems with accurate results. ",
    "url": "https://arxiv.org/abs/2206.14976",
    "authors": [
      "Nibraas Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.14996",
    "title": "Cross-domain Federated Object Detection",
    "abstract": "Detection models trained by one party (server) may face severe performance degradation when distributed to other users (clients). For example, in autonomous driving scenarios, different driving environments may bring obvious domain shifts, which lead to biases in model predictions. Federated learning that has emerged in recent years can enable multi-party collaborative training without leaking client data. In this paper, we focus on a special cross-domain scenario where the server contains large-scale data and multiple clients only contain a small amount of data; meanwhile, there exist differences in data distributions among the clients. In this case, traditional federated learning techniques cannot take into account the learning of both the global knowledge of all participants and the personalized knowledge of a specific client. To make up for this limitation, we propose a cross-domain federated object detection framework, named FedOD. In order to learn both the global knowledge and the personalized knowledge in different domains, the proposed framework first performs the federated training to obtain a public global aggregated model through multi-teacher distillation, and sends the aggregated model back to each client for finetuning its personalized local model. After very few rounds of communication, on each client we can perform weighted ensemble inference on the public global model and the personalized local model. With the ensemble, the generalization performance of the client-side model can outperform a single model with the same parameter scale. We establish a federated object detection dataset which has significant background differences and instance differences based on multiple public autonomous driving datasets, and then conduct extensive experiments on the dataset. The experimental results validate the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2206.14996",
    "authors": [
      "Shangchao Su",
      "Bin Li",
      "Chengzhi Zhang",
      "Mingzhao Yang",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14997",
    "title": "Security and Privacy vulnerabilities of 5G/6G and WiFi 6: Survey and  Research Directions from a Coexistence Perspective",
    "abstract": "Spectrum scarcity has been a major concern for achieving the desired quality of experience (QoE) in next-generation (5G/6G and beyond) networks supporting a massive volume of mobile and IoT devices with low-latency and seamless connectivity. Hence, spectrum sharing systems have been considered as a major enabler for next-generation wireless networks in meeting QoE demands. While most current coexistence solutions and standards focus on performance improvement and QoE optimization, the emerging security challenges of such network environments have been ignored in the literature. The security framework of standalone networks (either 5G or WiFi) assumes the ownership of entire network resources from spectrum to core functions. Hence, all accesses to the network shall be authenticated and authorized within the intra-network security system and is deemed illegal otherwise. However, coexistence network environments can lead to unprecedented security vulnerabilities and breaches as the standalone networks shall tolerate unknown and out-of-network accesses, specifically in the medium access. In this paper, for the first time in literature, we review some of the critical and emerging security vulnerabilities in the 5G/WiFi coexistence network environment which have not been observed previously in standalone networks. Specifically, independent medium access control (MAC) protocols and the resulting hidden node issues can result in exploitation such as service blocking, deployment of rogue base-stations, and eavesdropping attacks. We study potential vulnerabilities in the perspective of physical layer authentication, network access security, and cross-layer authentication mechanisms. This study opens a new direction of research in the analysis and design of a security framework that can address the unique challenges of coexistence networks. ",
    "url": "https://arxiv.org/abs/2206.14997",
    "authors": [
      "Keyvan Ramezanpour",
      "Jithin Jagannath",
      "Anu Jagannath"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2206.15002",
    "title": "Spatial Transformer Network with Transfer Learning for Small-scale  Fine-grained Skeleton-based Tai Chi Action Recognition",
    "abstract": "Human action recognition is a quite hugely investigated area where most remarkable action recognition networks usually use large-scale coarse-grained action datasets of daily human actions as inputs to state the superiority of their networks. We intend to recognize our small-scale fine-grained Tai Chi action dataset using neural networks and propose a transfer-learning method using NTU RGB+D dataset to pre-train our network. More specifically, the proposed method first uses a large-scale NTU RGB+D dataset to pre-train the Transformer-based network for action recognition to extract common features among human motion. Then we freeze the network weights except for the fully connected (FC) layer and take our Tai Chi actions as inputs only to train the initialized FC weights. Experimental results show that our general model pipeline can reach a high accuracy of small-scale fine-grained Tai Chi action recognition with even few inputs and demonstrate that our method achieves the state-of-the-art performance compared with previous Tai Chi action recognition methods. ",
    "url": "https://arxiv.org/abs/2206.15002",
    "authors": [
      "Lin Yuan",
      "Zhen He",
      "Qiang Wang",
      "Leiyang Xu",
      "Xiang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.15005",
    "title": "Continuous-Time and Multi-Level Graph Representation Learning for  Origin-Destination Demand Prediction",
    "abstract": "Traffic demand forecasting by deep neural networks has attracted widespread interest in both academia and industry society. Among them, the pairwise Origin-Destination (OD) demand prediction is a valuable but challenging problem due to several factors: (i) the large number of possible OD pairs, (ii) implicitness of spatial dependence, and (iii) complexity of traffic states. To address the above issues, this paper proposes a Continuous-time and Multi-level dynamic graph representation learning method for Origin-Destination demand prediction (CMOD). Firstly, a continuous-time dynamic graph representation learning framework is constructed, which maintains a dynamic state vector for each traffic node (metro stations or taxi zones). The state vectors keep historical transaction information and are continuously updated according to the most recently happened transactions. Secondly, a multi-level structure learning module is proposed to model the spatial dependency of station-level nodes. It can not only exploit relations between nodes adaptively from data, but also share messages and representations via cluster-level and area-level virtual nodes. Lastly, a cross-level fusion module is designed to integrate multi-level memories and generate comprehensive node representations for the final prediction. Extensive experiments are conducted on two real-world datasets from Beijing Subway and New York Taxi, and the results demonstrate the superiority of our model against the state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2206.15005",
    "authors": [
      "Liangzhe Han",
      "Xiaojian Ma",
      "Leilei Sun",
      "Bowen Du",
      "Yanjie Fu",
      "Weifeng Lv",
      "Hui Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.15015",
    "title": "Exploring Temporally Dynamic Data Augmentation for Video Recognition",
    "abstract": "Data augmentation has recently emerged as an essential component of modern training recipes for visual recognition tasks. However, data augmentation for video recognition has been rarely explored despite its effectiveness. Few existing augmentation recipes for video recognition naively extend the image augmentation methods by applying the same operations to the whole video frames. Our main idea is that the magnitude of augmentation operations for each frame needs to be changed over time to capture the real-world video's temporal variations. These variations should be generated as diverse as possible using fewer additional hyper-parameters during training. Through this motivation, we propose a simple yet effective video data augmentation framework, DynaAugment. The magnitude of augmentation operations on each frame is changed by an effective mechanism, Fourier Sampling that parameterizes diverse, smooth, and realistic temporal variations. DynaAugment also includes an extended search space suitable for video for automatic data augmentation methods. DynaAugment experimentally demonstrates that there are additional performance rooms to be improved from static augmentations on diverse video models. Specifically, we show the effectiveness of DynaAugment on various video datasets and tasks: large-scale video recognition (Kinetics-400 and Something-Something-v2), small-scale video recognition (UCF- 101 and HMDB-51), fine-grained video recognition (Diving-48 and FineGym), video action segmentation on Breakfast, video action localization on THUMOS'14, and video object detection on MOT17Det. DynaAugment also enables video models to learn more generalized representation to improve the model robustness on the corrupted videos. ",
    "url": "https://arxiv.org/abs/2206.15015",
    "authors": [
      "Taeoh Kim",
      "Jinhyung Kim",
      "Minho Shim",
      "Sangdoo Yun",
      "Myunggu Kang",
      "Dongyoon Wee",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.15017",
    "title": "Consensus Function from an $L_p^q-$norm Regularization Term for its Use  as Adaptive Activation Functions in Neural Networks",
    "abstract": "The design of a neural network is usually carried out by defining the number of layers, the number of neurons per layer, their connections or synapses, and the activation function that they will execute. The training process tries to optimize the weights assigned to those connections, together with the biases of the neurons, to better fit the training data. However, the definition of the activation functions is, in general, determined in the design process and not modified during the training, meaning that their behavior is unrelated to the training data set. In this paper we propose the definition and utilization of an implicit, parametric, non-linear activation function that adapts its shape during the training process. This fact increases the space of parameters to optimize within the network, but it allows a greater flexibility and generalizes the concept of neural networks. Furthermore, it simplifies the architectural design since the same activation function definition can be employed in each neuron, letting the training process to optimize their parameters and, thus, their behavior. Our proposed activation function comes from the definition of the consensus variable from the optimization of a linear underdetermined problem with an $L_p^q$ regularization term, via the Alternating Direction Method of Multipliers (ADMM). We define the neural networks using this type of activation functions as $pq-$networks. Preliminary results show that the use of these neural networks with this type of adaptive activation functions reduces the error in regression and classification examples, compared to equivalent regular feedforward neural networks with fixed activation functions. ",
    "url": "https://arxiv.org/abs/2206.15017",
    "authors": [
      "Juan Heredia-Juesas",
      "Jos\u00e9 \u00c1. Mart\u00ednez-Lorenzo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.15025",
    "title": "Stochastic Bilevel Distributed Optimization over a Network",
    "abstract": "Bilevel optimization has been applied to a wide variety of machine learning models. Numerous stochastic bilevel optimization algorithms have been developed in recent years. However, most of them restrict their focus on the single-machine setting so that they are incapable of handling the distributed data. To address this issue, under the setting where all participants compose a network and perform the peer-to-peer communication in this network, we developed two novel distributed stochastic bilevel optimization algorithms based on the gradient tracking communication mechanism and two different gradient estimators. Additionally, we show that they can achieve $O(\\frac{1}{\\epsilon^{2}(1-\\lambda)^2})$ and $O(\\frac{1}{\\epsilon^{3/2}(1-\\lambda)^2})$ convergence rate respectively to obtain the $\\epsilon$-accuracy solution, where $1-\\lambda$ denotes the spectral gap of the communication network. To our knowledge, this is the first work achieving these theoretical results. Finally, we applied our algorithms to practical machine learning models, and the experimental results confirmed the efficacy of our algorithms. ",
    "url": "https://arxiv.org/abs/2206.15025",
    "authors": [
      "Hongchang Gao",
      "Bin Gu",
      "My T. Thai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.15027",
    "title": "Interpretable Melody Generation from Lyrics with Discrete-Valued  Adversarial Training",
    "abstract": "Generating melody from lyrics is an interesting yet challenging task in the area of artificial intelligence and music. However, the difficulty of keeping the consistency between input lyrics and generated melody limits the generation quality of previous works. In our proposal, we demonstrate our proposed interpretable lyrics-to-melody generation system which can interact with users to understand the generation process and recreate the desired songs. To improve the reliability of melody generation that matches lyrics, mutual information is exploited to strengthen the consistency between lyrics and generated melodies. Gumbel-Softmax is exploited to solve the non-differentiability problem of generating discrete music attributes by Generative Adversarial Networks (GANs). Moreover, the predicted probabilities output by the generator is utilized to recommend music attributes. Interacting with our lyrics-to-melody generation system, users can listen to the generated AI song as well as recreate a new song by selecting from recommended music attributes. ",
    "url": "https://arxiv.org/abs/2206.15027",
    "authors": [
      "Wei Duan",
      "Zhe Zhang",
      "Yi Yu",
      "Keizo Oyama"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.15031",
    "title": "Timestamp-Supervised Action Segmentation with Graph Convolutional  Networks",
    "abstract": "We introduce a novel approach for temporal activity segmentation with timestamp supervision. Our main contribution is a graph convolutional network, which is learned in an end-to-end manner to exploit both frame features and connections between neighboring frames to generate dense framewise labels from sparse timestamp labels. The generated dense framewise labels can then be used to train the segmentation model. In addition, we propose a framework for alternating learning of both the segmentation model and the graph convolutional model, which first initializes and then iteratively refines the learned models. Detailed experiments on four public datasets, including 50 Salads, GTEA, Breakfast, and Desktop Assembly, show that our method is superior to the multi-layer perceptron baseline, while performing on par with or better than the state of the art in temporal activity segmentation with timestamp supervision. ",
    "url": "https://arxiv.org/abs/2206.15031",
    "authors": [
      "Hamza Khan",
      "Sanjay Haresh",
      "Awais Ahmed",
      "Shakeeb Siddiqui",
      "Andrey Konin",
      "M. Zeeshan Zia",
      "Quoc-Huy Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.15033",
    "title": "Causality-Based Multivariate Time Series Anomaly Detection",
    "abstract": "Anomaly detection in multivariate time series plays an important role in monitoring the behaviors of various real-world systems, e.g., IT system operations or manufacturing industry. Previous approaches model the joint distribution without considering the underlying mechanism of multivariate time series, making them complicated and computationally hungry. In this paper, we formulate the anomaly detection problem from a causal perspective and view anomalies as instances that do not follow the regular causal mechanism to generate the multivariate data. We then propose a causality-based anomaly detection approach, which first learns the causal structure from data and then infers whether an instance is an anomaly relative to the local causal mechanism to generate each variable from its direct causes, whose conditional distribution can be directly estimated from data. In light of the modularity property of causal systems, the original problem is divided into a series of separate low-dimensional anomaly detection problems so that where an anomaly happens can be directly identified. We evaluate our approach with both simulated and public datasets as well as a case study on real-world AIOps applications, showing its efficacy, robustness, and practical feasibility. ",
    "url": "https://arxiv.org/abs/2206.15033",
    "authors": [
      "Wenzhuo Yang",
      "Kun Zhang",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.15036",
    "title": "Brain-like combination of feedforward and recurrent network components  achieves prototype extraction and robust pattern recognition",
    "abstract": "Associative memory has been a prominent candidate for the computation performed by the massively recurrent neocortical networks. Attractor networks implementing associative memory have offered mechanistic explanation for many cognitive phenomena. However, attractor memory models are typically trained using orthogonal or random patterns to avoid interference between memories, which makes them unfeasible for naturally occurring complex correlated stimuli like images. We approach this problem by combining a recurrent attractor network with a feedforward network that learns distributed representations using an unsupervised Hebbian-Bayesian learning rule. The resulting network model incorporates many known biological properties: unsupervised learning, Hebbian plasticity, sparse distributed activations, sparse connectivity, columnar and laminar cortical architecture, etc. We evaluate the synergistic effects of the feedforward and recurrent network components in complex pattern recognition tasks on the MNIST handwritten digits dataset. We demonstrate that the recurrent attractor component implements associative memory when trained on the feedforward-driven internal (hidden) representations. The associative memory is also shown to perform prototype extraction from the training data and make the representations robust to severely distorted input. We argue that several aspects of the proposed integration of feedforward and recurrent computations are particularly attractive from a machine learning perspective. ",
    "url": "https://arxiv.org/abs/2206.15036",
    "authors": [
      "Naresh Balaji Ravichandran",
      "Anders Lansner",
      "Pawel Herman"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.15037",
    "title": "Privacy Research with Marginalized Groups: What We Know, What's Needed,  and What's Next",
    "abstract": "People who are marginalized experience disproportionate harms when their privacy is violated. Meeting their needs is vital for developing equitable and privacy-protective technologies. In response, research at the intersection of privacy and marginalization has acquired newfound urgency in the HCI and social computing community. In this literature review, we set out to understand how researchers have investigated this area of study. What topics have been examined, and how? What are the key findings and recommendations? And, crucially, where do we go from here? Based on a review of papers on privacy and marginalization published between 2010-2020 across HCI, Communication, and Privacy-focused venues, we make three main contributions: (1) we identify key themes in existing work and introduce the Privacy Responses and Costs framework to describe the tensions around protecting privacy in marginalized contexts, (2) we identify understudied research topics (e.g., race) and other avenues for future work, and (3) we characterize trends in research practices, including the under-reporting of important methodological choices, and provide suggestions for establishing shared best practices for this growing research area. ",
    "url": "https://arxiv.org/abs/2206.15037",
    "authors": [
      "Shruti Sannon",
      "Andrea Forte"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2206.15042",
    "title": "Automated Wheat Disease Detection using a ROS-based Autonomous Guided  UAV",
    "abstract": "With the increase in world population, food resources have to be modified to be more productive, resistive, and reliable. Wheat is one of the most important food resources in the world, mainly because of the variety of wheat-based products. Wheat crops are threatened by three main types of diseases which cause large amounts of annual damage in crop yield. These diseases can be eliminated by using pesticides at the right time. While the task of manually spraying pesticides is burdensome and expensive, agricultural robotics can aid farmers by increasing the speed and decreasing the amount of chemicals. In this work, a smart autonomous system has been implemented on an unmanned aerial vehicle to automate the task of monitoring wheat fields. First, an image-based deep learning approach is used to detect and classify disease-infected wheat plants. To find the most optimal method, different approaches have been studied. Because of the lack of a public wheat-disease dataset, a custom dataset has been created and labeled. Second, an efficient mapping and navigation system is presented using a simulation in the robot operating system and Gazebo environments. A 2D simultaneous localization and mapping algorithm is used for mapping the workspace autonomously with the help of a frontier-based exploration method. ",
    "url": "https://arxiv.org/abs/2206.15042",
    "authors": [
      "Behzad Safarijalal",
      "Yousef Alborzi",
      "Esmaeil Najafi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.15051",
    "title": "Group-invariant tensor train networks for supervised learning",
    "abstract": "Invariance has recently proven to be a powerful inductive bias in machine learning models. One such class of predictive or generative models are tensor networks. We introduce a new numerical algorithm to construct a basis of tensors that are invariant under the action of normal matrix representations of an arbitrary discrete group. This method can be up to several orders of magnitude faster than previous approaches. The group-invariant tensors are then combined into a group-invariant tensor train network, which can be used as a supervised machine learning model. We applied this model to a protein binding classification problem, taking into account problem-specific invariances, and obtained prediction accuracy in line with state-of-the-art deep learning approaches. ",
    "url": "https://arxiv.org/abs/2206.15051",
    "authors": [
      "Brent Sprangers",
      "Nick Vannieuwenhoven"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2206.15056",
    "title": "FeaRLESS: Feature Refinement Loss for Ensembling Self-Supervised  Learning Features in Robust End-to-end Speech Recognition",
    "abstract": "Self-supervised learning representations (SSLR) have resulted in robust features for downstream tasks in many fields. Recently, several SSLRs have shown promising results on automatic speech recognition (ASR) benchmark corpora. However, previous studies have only shown performance for solitary SSLRs as an input feature for ASR models. In this study, we propose to investigate the effectiveness of diverse SSLR combinations using various fusion methods within end-to-end (E2E) ASR models. In addition, we will show there are correlations between these extracted SSLRs. As such, we further propose a feature refinement loss for decorrelation to efficiently combine the set of input features. For evaluation, we show that the proposed 'FeaRLESS learning features' perform better than systems without the proposed feature refinement loss for both the WSJ and Fearless Steps Challenge (FSC) corpora. ",
    "url": "https://arxiv.org/abs/2206.15056",
    "authors": [
      "Szu-Jui Chen",
      "Jiamin Xie",
      "John H.L. Hansen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.15058",
    "title": "A note on Linear Bottleneck networks and their Transition to  Multilinearity",
    "abstract": "Randomly initialized wide neural networks transition to linear functions of weights as the width grows, in a ball of radius $O(1)$ around initialization. A necessary condition for this result is that all layers of the network are wide enough, i.e., all widths tend to infinity. However, the transition to linearity breaks down when this infinite width assumption is violated. In this work we show that linear networks with a bottleneck layer learn bilinear functions of the weights, in a ball of radius $O(1)$ around initialization. In general, for $B-1$ bottleneck layers, the network is a degree $B$ multilinear function of weights. Importantly, the degree only depends on the number of bottlenecks and not the total depth of the network. ",
    "url": "https://arxiv.org/abs/2206.15058",
    "authors": [
      "Libin Zhu",
      "Parthe Pandit",
      "Mikhail Belkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.15063",
    "title": "Imputation under Differential Privacy",
    "abstract": "The literature on differential privacy almost invariably assumes that the data to be analyzed are fully observed. In most practical applications this is an unrealistic assumption. A popular strategy to address this problem is imputation, in which missing values are replaced by estimated values given the observed data. In this paper we evaluate various approaches to answering queries on an imputed dataset in a differentially private manner, as well as discuss trade-offs as to where along the pipeline privacy is considered. We show that if imputation is done without consideration to privacy, the sensitivity of certain queries can increase linearly with the number of incomplete records. On the other hand, for a general class of imputation strategies, these worst case scenarios can be greatly reduced by ensuring privacy already during the imputation stage. We use a simulated dataset to demonstrate these results across a number of imputation schemes (both private and non-private) and examine their impact on the utility of a private query on the data. ",
    "url": "https://arxiv.org/abs/2206.15063",
    "authors": [
      "Soumojit Das",
      "Jorg Dreschler",
      "Keith Merrill",
      "Shawn Merrill"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2206.15065",
    "title": "Learning-Based Near-Orthogonal Superposition Code for MIMO Short Message  Transmission",
    "abstract": "Massive machine type communication (mMTC) has attracted new coding schemes optimized for reliable short message transmission. In this paper, a novel deep learning-based near-orthogonal superposition (NOS) coding scheme is proposed to transmit short messages in multiple-input multiple-output (MIMO) channels for mMTC applications. In the proposed MIMO-NOS scheme, a neural network-based encoder is optimized via end-to-end learning with a corresponding neural network-based detector/decoder in a superposition-based auto-encoder framework including a MIMO channel. The proposed MIMO-NOS encoder spreads the information bits to multiple near-orthogonal high dimensional vectors to be combined (superimposed) into a single vector and reshaped for the space-time transmission. For the receiver, we propose a novel looped K-best tree-search algorithm with cyclic redundancy check (CRC) assistance to enhance the error correcting ability in the block-fading MIMO channel. Simulation results show the proposed MIMO-NOS scheme outperforms maximum likelihood (ML) MIMO detection combined with a polar code with CRC-assisted list decoding by 1-2 dB in various MIMO systems for short (32-64 bit) message transmission. ",
    "url": "https://arxiv.org/abs/2206.15065",
    "authors": [
      "Chenghong Bian",
      "Chin-Wei Hsu",
      "Changwoo Lee",
      "Hun-Seok Kim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.15067",
    "title": "Language Model-Based Emotion Prediction Methods for Emotional Speech  Synthesis Systems",
    "abstract": "This paper proposes an effective emotional text-to-speech (TTS) system with a pre-trained language model (LM)-based emotion prediction method. Unlike conventional systems that require auxiliary inputs such as manually defined emotion classes, our system directly estimates emotion-related attributes from the input text. Specifically, we utilize generative pre-trained transformer (GPT)-3 to jointly predict both an emotion class and its strength in representing emotions coarse and fine properties, respectively. Then, these attributes are combined in the emotional embedding space and used as conditional features of the TTS model for generating output speech signals. Consequently, the proposed system can produce emotional speech only from text without any auxiliary inputs. Furthermore, because the GPT-3 enables to capture emotional context among the consecutive sentences, the proposed method can effectively handle the paragraph-level generation of emotional speech. ",
    "url": "https://arxiv.org/abs/2206.15067",
    "authors": [
      "Hyun-Wook Yoon",
      "Ohsung Kwon",
      "Hoyeon Lee",
      "Ryuichi Yamamoto",
      "Eunwoo Song",
      "Jae-Min Kim",
      "Min-Jae Hwang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.15072",
    "title": "Learnable Model-Driven Performance Prediction and Optimization for  Imperfect MIMO System: Framework and Application",
    "abstract": "State-of-the-art schemes for performance analysis and optimization of multiple-input multiple-output systems generally experience degradation or even become invalid in dynamic complex scenarios with unknown interference and channel state information (CSI) uncertainty. To adapt to the challenging settings and better accomplish these network auto-tuning tasks, we propose a generic learnable model-driven framework in this paper. To explain how the proposed framework works, we consider regularized zero-forcing precoding as a usage instance and design a light-weight neural network for refined prediction of sum rate and detection error based on coarse model-driven approximations. Then, we estimate the CSI uncertainty on the learned predictor in an iterative manner and, on this basis, optimize the transmit regularization term and subsequent receive power scaling factors. A deep unfolded projected gradient descent based algorithm is proposed for power scaling, which achieves favorable trade-off between convergence rate and robustness. ",
    "url": "https://arxiv.org/abs/2206.15072",
    "authors": [
      "Fan Meng",
      "Shengheng Liu",
      "Yongming Huang",
      "Zhaohua Lu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.15088",
    "title": "On graphs coverable by k shortest paths",
    "abstract": "We show that if the edges or vertices of an undirected graph $G$ can be covered by $k$ shortest paths, then the pathwidth of $G$ is upper-bounded by a function of $k$. As a corollary, we prove that the problem Isometric Path Cover with Terminals (which, given a graph $G$ and a set of $k$ pairs of vertices called \\emph{terminals}, asks whether $G$ can be covered by $k$ shortest paths, each joining a pair of terminals) is FPT with respect to the number of terminals. The same holds for the similar problem Strong Geodetic Set with Terminals (which, given a graph $G$ and a set of $k$ terminals, asks whether there exist $\\binom{k}{2}$ shortest paths, each joining a distinct pair of terminals such that these paths cover $G$). Moreover, this implies that the related problems Isometric Path Cover and Strong Geodetic Set (defined similarly but where the set of terminals is not part of the input) are in XP with respect to parameter $k$. ",
    "url": "https://arxiv.org/abs/2206.15088",
    "authors": [
      "Ma\u00ebl Dumas",
      "Florent Foucaud",
      "Anthony Perez",
      "Ioan Todinca"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2206.15095",
    "title": "Learning-Aided Beam Prediction in mmWave MU-MIMO Systems for High-Speed  Railway",
    "abstract": "The problem of beam alignment and tracking in high mobility scenarios such as high-speed railway (HSR) becomes extremely challenging, since large overhead cost and significant time delay are introduced for fast time-varying channel estimation. To tackle this challenge, we propose a learning-aided beam prediction scheme for HSR networks, which predicts the beam directions and the channel amplitudes within a period of future time with fine time granularity, using a group of observations. Concretely, we transform the problem of high-dimensional beam prediction into a two-stage task, i.e., a low-dimensional parameter estimation and a cascaded hybrid beamforming operation. In the first stage, the location and speed of a certain terminal are estimated by maximum likelihood criterion, and a data-driven data fusion module is designed to improve the final estimation accuracy and robustness. Then, the probable future beam directions and channel amplitudes are predicted, based on the HSR scenario priors including deterministic trajectory, motion model, and channel model. Furthermore, we incorporate a learnable non-linear mapping module into the overall beam prediction to allow non-linear tracks. Both of the proposed learnable modules are model-based and have a good interpretability. Compared to the existing beam management scheme, the proposed beam prediction has (near) zero overhead cost and time delay. Simulation results verify the effectiveness of the proposed scheme. ",
    "url": "https://arxiv.org/abs/2206.15095",
    "authors": [
      "Fan Meng",
      "Shengheng Liu",
      "Yongming Huang",
      "Zhaohua Lu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.15097",
    "title": "Prefix-free parsing for building large tunnelled Wheeler graphs",
    "abstract": "We propose a new technique for creating a space-efficient index for large repetitive text collections, such as pangenomic databases containing sequences of many individuals from the same species. We combine two recent techniques from this area: Wheeler graphs (Gagie et al., 2017) and prefix-free parsing (PFP, Boucher et al., 2019). Wheeler graphs (WGs) are a general framework encompassing several indexes based on the Burrows-Wheeler transform (BWT), such as the FM-index. Wheeler graphs admit a succinct representation which can be further compacted by employing the idea of tunnelling, which exploits redundancies in the form of parallel, equally-labelled paths called blocks that can be merged into a single path. The problem of finding the optimal set of blocks for tunnelling, i.e. the one that minimizes the size of the resulting WG, is known to be NP-complete and remains the most computationally challenging part of the tunnelling process. To find an adequate set of blocks in less time, we propose a new method based on the prefix-free parsing (PFP). The idea of PFP is to divide the input text into phrases of roughly equal sizes that overlap by a fixed number of characters. The original text is represented by a sequence of phrase ranks (the parse) and a list of all used phrases (the dictionary). In repetitive texts, the PFP of the text is generally much shorter than the original. To speed up the block selection for tunnelling, we apply the PFP to obtain the parse and the dictionary of the text, tunnel the WG of the parse using existing heuristics and subsequently use this tunnelled parse to construct a compact WG of the original text. Compared with constructing a WG from the original text without PFP, our method is much faster and uses less memory on collections of pangenomic sequences. Therefore, our method enables the use of WGs as a pangenomic reference for real-world datasets. ",
    "url": "https://arxiv.org/abs/2206.15097",
    "authors": [
      "Adri\u00e1n Goga",
      "Andrej Bal\u00e1\u017e"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2206.15109",
    "title": "MKIoU Loss: Towards Accurate Oriented Object Detection in Aerial Images",
    "abstract": "Oriented bounding box regression is crucial for oriented object detection. However, regression-based methods often suffer from boundary problems and the inconsistency between loss and evaluation metrics. In this paper, a modulated Kalman IoU loss of approximate SkewIoU is proposed, named MKIoU. To avoid boundary problems, we convert the oriented bounding box to Gaussian distribution, then use the Kalman filter to approximate the intersection area. However, there exists significant difference between the calculated and actual intersection areas. Thus, we propose a modulation factor to adjust the sensitivity of angle deviation and width-height offset to loss variation, making the loss more consistent with the evaluation metric. Furthermore, the Gaussian modeling method avoids the boundary problem but causes the angle confusion of square objects simultaneously. Thus, the Gaussian Angle Loss (GA Loss) is presented to solve this problem by adding a corrected loss for square targets. The proposed GA Loss can be easily extended to other Gaussian-based methods. Experiments on three publicly available aerial image datasets, DOTA, UCAS-AOD, and HRSC2016, show the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2206.15109",
    "authors": [
      "Xinyi Yu",
      "Jiangping Lu",
      "Xinyi Yu",
      "Mi Lin",
      "Linlin Ou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.15128",
    "title": "Detecting and Recovering Adversarial Examples from Extracting Non-robust  and Highly Predictive Adversarial Perturbations",
    "abstract": "Deep neural networks (DNNs) have been shown to be vulnerable against adversarial examples (AEs) which are maliciously designed to fool target models. The normal examples (NEs) added with imperceptible adversarial perturbation, can be a security threat to DNNs. Although the existing AEs detection methods have achieved a high accuracy, they failed to exploit the information of the AEs detected. Thus, based on high-dimension perturbation extraction, we propose a model-free AEs detection method, the whole process of which is free from querying the victim model. Research shows that DNNs are sensitive to the high-dimension features. The adversarial perturbation hiding in the adversarial example belongs to the high-dimension feature which is highly predictive and non-robust. DNNs learn more details from high-dimension data than others. In our method, the perturbation extractor can extract the adversarial perturbation from AEs as high-dimension feature, then the trained AEs discriminator determines whether the input is an AE. Experimental results show that the proposed method can not only detect the adversarial examples with high accuracy, but also detect the specific category of the AEs. Meanwhile, the extracted perturbation can be used to recover the AEs to NEs. ",
    "url": "https://arxiv.org/abs/2206.15128",
    "authors": [
      "Mingyu Dong",
      "Jiahao Chen",
      "Diqun Yan",
      "Jingxing Gao",
      "Li Dong",
      "Rangding Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.15129",
    "title": "Personalized Detection of Cognitive Biases in Actions of Users from  Their Logs: Anchoring and Recency Biases",
    "abstract": "Cognitive biases are mental shortcuts humans use in dealing with information and the environment, and which result in biased actions and behaviors (or, actions), unbeknownst to themselves. Biases take many forms, with cognitive biases occupying a central role that inflicts fairness, accountability, transparency, ethics, law, medicine, and discrimination. Detection of biases is considered a necessary step toward their mitigation. Herein, we focus on two cognitive biases - anchoring and recency. The recognition of cognitive bias in computer science is largely in the domain of information retrieval, and bias is identified at an aggregate level with the help of annotated data. Proposing a different direction for bias detection, we offer a principled approach along with Machine Learning to detect these two cognitive biases from Web logs of users' actions. Our individual user level detection makes it truly personalized, and does not rely on annotated data. Instead, we start with two basic principles established in cognitive psychology, use modified training of an attention network, and interpret attention weights in a novel way according to those principles, to infer and distinguish between these two biases. The personalized approach allows detection for specific users who are susceptible to these biases when performing their tasks, and can help build awareness among them so as to undertake bias mitigation. ",
    "url": "https://arxiv.org/abs/2206.15129",
    "authors": [
      "Atanu R Sinha",
      "Navita Goyal",
      "Sunny Dhamnani",
      "Tanay Asija",
      "Raja K Dubey",
      "M V Kaarthik Raja",
      "Georgios Theocharous"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.15143",
    "title": "Scalable K-FAC Training for Deep Neural Networks with Distributed  Preconditioning",
    "abstract": "The second-order optimization methods, notably the D-KFAC (Distributed Kronecker Factored Approximate Curvature) algorithms, have gained traction on accelerating deep neural network (DNN) training on GPU clusters. However, existing D-KFAC algorithms require to compute and communicate a large volume of second-order information, i.e., Kronecker factors (KFs), before preconditioning gradients, resulting in large computation and communication overheads as well as a high memory footprint. In this paper, we propose DP-KFAC, a novel distributed preconditioning scheme that distributes the KF constructing tasks at different DNN layers to different workers. DP-KFAC not only retains the convergence property of the existing D-KFAC algorithms but also enables three benefits: reduced computation overhead in constructing KFs, no communication of KFs, and low memory footprint. Extensive experiments on a 64-GPU cluster show that DP-KFAC reduces the computation overhead by 1.55x-1.65x, the communication cost by 2.79x-3.15x, and the memory footprint by 1.14x-1.47x in each second-order update compared to the state-of-the-art D-KFAC methods. ",
    "url": "https://arxiv.org/abs/2206.15143",
    "authors": [
      "Lin Zhang",
      "Shaohuai Shi",
      "Wei Wang",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2206.15144",
    "title": "Neural Networks can Learn Representations with Gradient Descent",
    "abstract": "Significant theoretical work has established that in specific regimes, neural networks trained by gradient descent behave like kernel methods. However, in practice, it is known that neural networks strongly outperform their associated kernels. In this work, we explain this gap by demonstrating that there is a large class of functions which cannot be efficiently learned by kernel methods but can be easily learned with gradient descent on a two layer neural network outside the kernel regime by learning representations that are relevant to the target task. We also demonstrate that these representations allow for efficient transfer learning, which is impossible in the kernel regime. Specifically, we consider the problem of learning polynomials which depend on only a few relevant directions, i.e. of the form $f^\\star(x) = g(Ux)$ where $U: \\R^d \\to \\R^r$ with $d \\gg r$. When the degree of $f^\\star$ is $p$, it is known that $n \\asymp d^p$ samples are necessary to learn $f^\\star$ in the kernel regime. Our primary result is that gradient descent learns a representation of the data which depends only on the directions relevant to $f^\\star$. This results in an improved sample complexity of $n\\asymp d^2 r + dr^p$. Furthermore, in a transfer learning setup where the data distributions in the source and target domain share the same representation $U$ but have different polynomial heads we show that a popular heuristic for transfer learning has a target sample complexity independent of $d$. ",
    "url": "https://arxiv.org/abs/2206.15144",
    "authors": [
      "Alex Damian",
      "Jason D. Lee",
      "Mahdi Soltanolkotabi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.15157",
    "title": "HRFuser: A Multi-resolution Sensor Fusion Architecture for 2D Object  Detection",
    "abstract": "Besides standard cameras, autonomous vehicles typically include multiple additional sensors, such as lidars and radars, which help acquire richer information for perceiving the content of the driving scene. While several recent works focus on fusing certain pairs of sensors - such as camera and lidar or camera and radar - by using architectural components specific to the examined setting, a generic and modular sensor fusion architecture is missing from the literature. In this work, we focus on 2D object detection, a fundamental high-level task which is defined on the 2D image domain, and propose HRFuser, a multi-resolution sensor fusion architecture that scales straightforwardly to an arbitrary number of input modalities. The design of HRFuser is based on state-of-the-art high-resolution networks for image-only dense prediction and incorporates a novel multi-window cross-attention block as the means to perform fusion of multiple modalities at multiple resolutions. Even though cameras alone provide very informative features for 2D detection, we demonstrate via extensive experiments on the nuScenes and Seeing Through Fog datasets that our model effectively leverages complementary features from additional modalities, substantially improving upon camera-only performance and consistently outperforming state-of-the-art fusion methods for 2D detection both in normal and adverse conditions. The source code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2206.15157",
    "authors": [
      "Tim Broedermann",
      "Christos Sakaridis",
      "Dengxin Dai",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.15162",
    "title": "Using Person Embedding to Enrich Features and Data Augmentation for  Classification",
    "abstract": "Today, machine learning is applied in almost any field. In machine learning, where there are numerous methods, classification is one of the most basic and crucial ones. Various problems can be solved by classification. The feature selection for model setup is extremely important, and producing new features via feature engineering also has a vital place in the success of the model. In our study, fraud detection classification models are built on a labeled and imbalanced dataset as a case-study. Although it is a natural language processing method, a customer space has been created with word embedding, which has been used in different areas, especially for recommender systems. The customer vectors in the created space are fed to the classification model as a feature. Moreover, to increase the number of positive labels, rows with similar characteristics are re-labeled as positive by using customer similarity determined by embedding. The model in which embedding methods are included in the classification, which provides a better representation of customers, has been compared with other models. Considering the results, it is observed that the customer embedding method had a positive effect on the success of the classification models. ",
    "url": "https://arxiv.org/abs/2206.15162",
    "authors": [
      "Ahmet Tu\u011frul Bayrak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.15174",
    "title": "Graph-Time Convolutional Neural Networks: Architecture and Theoretical  Analysis",
    "abstract": "Devising and analyzing learning models for spatiotemporal network data is of importance for tasks including forecasting, anomaly detection, and multi-agent coordination, among others. Graph Convolutional Neural Networks (GCNNs) are an established approach to learn from time-invariant network data. The graph convolution operation offers a principled approach to aggregate multiresolution information. However, extending the convolution principled learning and respective analysis to the spatiotemporal domain is challenging because spatiotemporal data have more intrinsic dependencies. Hence, a higher flexibility to capture jointly the spatial and the temporal dependencies is required to learn meaningful higher-order representations. Here, we leverage product graphs to represent the spatiotemporal dependencies in the data and introduce Graph-Time Convolutional Neural Networks (GTCNNs) as a principled architecture to aid learning. The proposed approach can work with any type of product graph and we also introduce a parametric product graph to learn also the spatiotemporal coupling. The convolution principle further allows a similar mathematical tractability as for GCNNs. In particular, the stability result shows GTCNNs are stable to spatial perturbations but there is an implicit trade-off between discriminability and robustness; i.e., the more complex the model, the less stable. Extensive numerical results on benchmark datasets corroborate our findings and show the GTCNN compares favorably with state-of-the-art solutions. We anticipate the GTCNN to be a starting point for more sophisticated models that achieve good performance but are also fundamentally grounded. ",
    "url": "https://arxiv.org/abs/2206.15174",
    "authors": [
      "Mohammad Sabbaqi",
      "Elvin Isufi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.15183",
    "title": "Neural Network Assisted Depth Map Packing for Compression Using Standard  Hardware Video Codecs",
    "abstract": "Depth maps are needed by various graphics rendering and processing operations. Depth map streaming is often necessary when such operations are performed in a distributed system and it requires in most cases fast performing compression, which is why video codecs are often used. Hardware implementations of standard video codecs enable relatively high resolution and framerate combinations, even on resource constrained devices, but unfortunately those implementations do not currently support RGB+depth extensions. However, they can be used for depth compression by first packing the depth maps into RGB or YUV frames. We investigate depth map compression using a combination of depth map packing followed by encoding with a standard video codec. We show that the precision at which depth maps are packed has a large and nontrivial impact on the resulting error caused by the combination of the packing scheme and lossy compression when bitrate is constrained. Consequently, we propose a variable precision packing scheme assisted by a neural network model that predicts the optimal precision for each depth map given a bitrate constraint. We demonstrate that the model yields near optimal predictions and that it can be integrated into a game engine with very low overhead using modern hardware. ",
    "url": "https://arxiv.org/abs/2206.15183",
    "authors": [
      "Matti Siekkinen",
      "Teemu K\u00e4m\u00e4r\u00e4inen"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.15186",
    "title": "Out-of-Distribution Detection for Long-tailed and Fine-grained Skin  Lesion Images",
    "abstract": "Recent years have witnessed a rapid development of automated methods for skin lesion diagnosis and classification. Due to an increasing deployment of such systems in clinics, it has become important to develop a more robust system towards various Out-of-Distribution(OOD) samples (unknown skin lesions and conditions). However, the current deep learning models trained for skin lesion classification tend to classify these OOD samples incorrectly into one of their learned skin lesion categories. To address this issue, we propose a simple yet strategic approach that improves the OOD detection performance while maintaining the multi-class classification accuracy for the known categories of skin lesion. To specify, this approach is built upon a realistic scenario of a long-tailed and fine-grained OOD detection task for skin lesion images. Through this approach, 1) First, we target the mixup amongst middle and tail classes to address the long-tail problem. 2) Later, we combine the above mixup strategy with prototype learning to address the fine-grained nature of the dataset. The unique contribution of this paper is two-fold, justified by extensive experiments. First, we present a realistic problem setting of OOD task for skin lesion. Second, we propose an approach to target the long-tailed and fine-grained aspects of the problem setting simultaneously to increase the OOD performance. ",
    "url": "https://arxiv.org/abs/2206.15186",
    "authors": [
      "Deval Mehta",
      "Yaniv Gal",
      "Adrian Bowling",
      "Paul Bonnington",
      "Zongyuan Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.15190",
    "title": "Classification of network topology and dynamics via sequence  characterization",
    "abstract": "Sequences arise in many real-world scenarios; thus, identifying the mechanisms behind symbol generation is essential to understanding many complex systems. This paper analyzes sequences generated by agents walking on a networked topology. Given that in many real scenarios, the underlying processes generating the sequence is hidden, we investigate whether the reconstruction of the network via the co-occurrence method is useful to recover both the network topology and agent dynamics generating sequences. We found that the characterization of reconstructed networks provides valuable information regarding the process and topology used to create the sequences. In a machine learning approach considering 16 combinations of network topology and agent dynamics as classes, we obtained an accuracy of 87% with sequences generated with less than 40% of nodes visited. Larger sequences turned out to generate improved machine learning models. Our findings suggest that the proposed methodology could be extended to classify sequences and understand the mechanisms behind sequence generation. ",
    "url": "https://arxiv.org/abs/2206.15190",
    "authors": [
      "Lucas Guerreiro",
      "Filipi N. Silva",
      "Diego R. Amancio"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.15228",
    "title": "Signed ego network model and its application to Twitter",
    "abstract": "The Ego Network Model (ENM) describes how individuals organise their social relations in concentric circles (typically five) of decreasing intimacy, and it has been found almost ubiquitously in social networks, both offline and online. The ENM gauges the tie strength between peers in terms of interaction frequency, which is easy to measure and provides a good proxy for the time spent nurturing the relationship. However, advances in signed network analysis have shown that positive and negative relations play very different roles in network dynamics. For this reason, this work sets out to investigate the ENM when including signed relations. The main contributions of this paper are twofold: firstly, a novel method of signing relationships between individuals using sentiment analysis and, secondly, an investigation of the properties of Signed Ego Networks (Ego Networks with signed connections). Signed Ego Networks are then extracted for the users of eight different Twitter datasets composed of both specialised users (e.g. journalists) and generic users. We find that negative links are over-represented in the active part of the Ego Networks of all types of users, suggesting that Twitter users tend to engage regularly with negative connections. Further, we observe that negative relationships are overwhelmingly predominant in the Ego Network circles of specialised users, hinting at very polarised online interactions for this category of users. In addition, negative relationships are found disproportionately more at the more intimate levels of the ENM for journalists, while their percentages are stable across the circles of the other Twitter users ",
    "url": "https://arxiv.org/abs/2206.15228",
    "authors": [
      "Jack Tacchi",
      "Chiara Boldrini",
      "Andrea Passarella",
      "Marco Conti"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.15237",
    "title": "Adherence to Misinformation on Social Media Through Socio-Cognitive and  Group-Based Processes",
    "abstract": "Previous work suggests that people's preference for different kinds of information depends on more than just accuracy. This could happen because the messages contained within different pieces of information may either be well-liked or repulsive. Whereas factual information must often convey uncomfortable truths, misinformation can have little regard for veracity and leverage psychological processes which increase its attractiveness and proliferation on social media. In this review, we argue that when misinformation proliferates, this happens because the social media environment enables adherence to misinformation by reducing, rather than increasing, the psychological cost of doing so. We cover how attention may often be shifted away from accuracy and towards other goals, how social and individual cognition is affected by misinformation and the cases under which debunking it is most effective, and how the formation of online groups affects information consumption patterns, often leading to more polarization and radicalization. Throughout, we make the case that polarization and misinformation adherence are closely tied. We identify ways in which the psychological cost of adhering to misinformation can be increased when designing anti-misinformation interventions or resilient affordances, and we outline open research questions that the CSCW community can take up in further understanding this cost. ",
    "url": "https://arxiv.org/abs/2206.15237",
    "authors": [
      "Alexandros Efstratiou",
      "Emiliano De Cristofaro"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.15241",
    "title": "Benchmark Dataset for Precipitation Forecasting by Post-Processing the  Numerical Weather Prediction",
    "abstract": "Precipitation forecasting is an important scientific challenge that has wide-reaching impacts on society. Historically, this challenge has been tackled using numerical weather prediction (NWP) models, grounded on physics-based simulations. Recently, many works have proposed an alternative approach, using end-to-end deep learning (DL) models to replace physics-based NWP. While these DL methods show improved performance and computational efficiency, they exhibit limitations in long-term forecasting and lack the explainability of NWP models. In this work, we present a hybrid NWP-DL workflow to fill the gap between standalone NWP and DL approaches. Under this workflow, the NWP output is fed into a deep model, which post-processes the data to yield a refined precipitation forecast. The deep model is trained with supervision, using Automatic Weather Station (AWS) observations as ground-truth labels. This can achieve the best of both worlds, and can even benefit from future improvements in NWP technology. To facilitate study in this direction, we present a novel dataset focused on the Korean Peninsula, termed KoMet (Korea Meteorological Dataset), comprised of NWP predictions and AWS observations. For NWP, we use the Global Data Assimilation and Prediction Systems-Korea Integrated Model (GDAPS-KIM). ",
    "url": "https://arxiv.org/abs/2206.15241",
    "authors": [
      "Taehyeon Kim",
      "Namgyu Ho",
      "Donggyu Kim",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2206.15242",
    "title": "Secure Heterogeneous Multi-Robot Collaboration and Docking with  Hyperledger Fabric Blockchain",
    "abstract": "In recent years, multi-robot systems have received increasing attention from both industry and academia. Besides the need of accurate and robust estimation of relative localization, security and trust in the system are essential to enable wider adoption. In this paper, we propose a framework using Hyperledger Fabric for multi-robot collaboration in industrial applications. We rely on blockchain identities for the interaction of ground and aerial robots, and use smart contracts for collaborative decision making. The use of ultra-wideband (UWB) localization for both autonomous navigation and robot collaboration extends our previous work in Fabric-based fleet management. We focus on an inventory management application which uses a ground robot and an aerial robot to inspect a warehouse-like environment and store information about the found objects in the blockchain. We measure the impact of adding the blockchain layer, analyze the transaction commit latency and compare the resource utilization of blockchain-related processes to the already running data processing modules. ",
    "url": "https://arxiv.org/abs/2206.15242",
    "authors": [
      "Salma Salimi",
      "Paola Torrico Mor\u00f3n",
      "Jorge Pe\u00f1a Queralta",
      "Tomi Westerlund"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.15255",
    "title": "Neural Rendering for Stereo 3D Reconstruction of Deformable Tissues in  Robotic Surgery",
    "abstract": "Reconstruction of the soft tissues in robotic surgery from endoscopic stereo videos is important for many applications such as intra-operative navigation and image-guided robotic surgery automation. Previous works on this task mainly rely on SLAM-based approaches, which struggle to handle complex surgical scenes. Inspired by recent progress in neural rendering, we present a novel framework for deformable tissue reconstruction from binocular captures in robotic surgery under the single-viewpoint setting. Our framework adopts dynamic neural radiance fields to represent deformable surgical scenes in MLPs and optimize shapes and deformations in a learning-based manner. In addition to non-rigid deformations, tool occlusion and poor 3D clues from a single viewpoint are also particular challenges in soft tissue reconstruction. To overcome these difficulties, we present a series of strategies of tool mask-guided ray casting, stereo depth-cueing ray marching and stereo depth-supervised optimization. With experiments on DaVinci robotic surgery videos, our method significantly outperforms the current state-of-the-art reconstruction method for handling various complex non-rigid deformations. To our best knowledge, this is the first work leveraging neural rendering for surgical scene 3D reconstruction with remarkable potential demonstrated. Code is available at: https://github.com/med-air/EndoNeRF. ",
    "url": "https://arxiv.org/abs/2206.15255",
    "authors": [
      "Yuehao Wang",
      "Yonghao Long",
      "Siu Hin Fan",
      "Qi Dou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.15258",
    "title": "Neural Surface Reconstruction of Dynamic Scenes with Monocular RGB-D  Camera",
    "abstract": "We propose Neural-DynamicReconstruction (NDR), a template-free method to recover high-fidelity geometry and motions of a dynamic scene from a monocular RGB-D camera. In NDR, we adopt the neural implicit function for surface representation and rendering such that the captured color and depth can be fully utilized to jointly optimize the surface and deformations. To represent and constrain the non-rigid deformations, we propose a novel neural invertible deforming network such that the cycle consistency between arbitrary two frames is automatically satisfied. Considering that the surface topology of dynamic scene might change over time, we employ a topology-aware strategy to construct the topology-variant correspondence for the fused frames. NDR also further refines the camera poses in a global optimization manner. Experiments on public datasets and our collected dataset demonstrate that NDR outperforms existing monocular dynamic reconstruction methods. ",
    "url": "https://arxiv.org/abs/2206.15258",
    "authors": [
      "Hongrui Cai",
      "Wanquan Feng",
      "Xuetao Feng",
      "Yan Wang",
      "Juyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2206.15268",
    "title": "Submission to Generic Event Boundary Detection Challenge@CVPR 2022:  Local Context Modeling and Global Boundary Decoding Approach",
    "abstract": "Generic event boundary detection (GEBD) is an important yet challenging task in video understanding, which aims at detecting the moments where humans naturally perceive event boundaries. In this paper, we present a local context modeling and global boundary decoding approach for GEBD task. Local context modeling sub-network is proposed to perceive diverse patterns of generic event boundaries, and it generates powerful video representations and reliable boundary confidence. Based on them, global boundary decoding sub-network is exploited to decode event boundaries from a global view. Our proposed method achieves 85.13% F1-score on Kinetics-GEBD testing set, which achieves a more than 22% F1-score boost compared to the baseline method. The code is available at https://github.com/JackyTown/GEBD_Challenge_CVPR2022. ",
    "url": "https://arxiv.org/abs/2206.15268",
    "authors": [
      "Jiaqi Tang",
      "Zhaoyang Liu",
      "Jing Tan",
      "Chen Qian",
      "Wayne Wu",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.15275",
    "title": "Multiclass-SGCN: Sparse Graph-based Trajectory Prediction with Agent  Class Embedding",
    "abstract": "Trajectory prediction of road users in real-world scenarios is challenging because their movement patterns are stochastic and complex. Previous pedestrian-oriented works have been successful in modelling the complex interactions among pedestrians, but fail in predicting trajectories when other types of road users are involved (e.g., cars, cyclists, etc.), because they ignore user types. Although a few recent works construct densely connected graphs with user label information, they suffer from superfluous spatial interactions and temporal dependencies. To address these issues, we propose Multiclass-SGCN, a sparse graph convolution network based approach for multi-class trajectory prediction that takes into consideration velocity and agent label information and uses a novel interaction mask to adaptively decide the spatial and temporal connections of agents based on their interaction scores. The proposed approach significantly outperformed state-of-the-art approaches on the Stanford Drone Dataset, providing more realistic and plausible trajectory predictions. ",
    "url": "https://arxiv.org/abs/2206.15275",
    "authors": [
      "Ruochen Li",
      "Stamos Katsigiannis",
      "Hubert P. H. Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.15276",
    "title": "R-MelNet: Reduced Mel-Spectral Modeling for Neural TTS",
    "abstract": "This paper introduces R-MelNet, a two-part autoregressive architecture with a frontend based on the first tier of MelNet and a backend WaveRNN-style audio decoder for neural text-to-speech synthesis. Taking as input a mixed sequence of characters and phonemes, with an optional audio priming sequence, this model produces low-resolution mel-spectral features which are interpolated and used by a WaveRNN decoder to produce an audio waveform. Coupled with half precision training, R-MelNet uses under 11 gigabytes of GPU memory on a single commodity GPU (NVIDIA 2080Ti). We detail a number of critical implementation details for stable half precision training, including an approximate, numerically stable mixture of logistics attention. Using a stochastic, multi-sample per step inference scheme, the resulting model generates highly varied audio, while enabling text and audio based controls to modify output waveforms. Qualitative and quantitative evaluations of an R-MelNet system trained on a single speaker TTS dataset demonstrate the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2206.15276",
    "authors": [
      "Kyle Kastner",
      "Aaron Courville"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.15296",
    "title": "Self-SuperFlow: Self-supervised Scene Flow Prediction in Stereo  Sequences",
    "abstract": "In recent years, deep neural networks showed their exceeding capabilities in addressing many computer vision tasks including scene flow prediction. However, most of the advances are dependent on the availability of a vast amount of dense per pixel ground truth annotations, which are very difficult to obtain for real life scenarios. Therefore, synthetic data is often relied upon for supervision, resulting in a representation gap between the training and test data. Even though a great quantity of unlabeled real world data is available, there is a huge lack in self-supervised methods for scene flow prediction. Hence, we explore the extension of a self-supervised loss based on the Census transform and occlusion-aware bidirectional displacements for the problem of scene flow prediction. Regarding the KITTI scene flow benchmark, our method outperforms the corresponding supervised pre-training of the same network and shows improved generalization capabilities while achieving much faster convergence. ",
    "url": "https://arxiv.org/abs/2206.15296",
    "authors": [
      "Katharina Bendig",
      "Ren\u00e9 Schuster",
      "Didier Stricker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.15312",
    "title": "FL-Tuning: Layer Tuning for Feed-Forward Network in Transformer",
    "abstract": "Prompt tuning is an emerging way of adapting pre-trained language models to downstream tasks. However, the existing studies are mainly to add prompts to the input sequence. This way would not work as expected due to the intermediate multi-head self-attention and feed-forward network computation, making model optimization not very smooth. Hence, we propose a novel tuning way called layer tuning, aiming to add learnable parameters in Transformer layers. Specifically, we focus on layer tuning for feed-forward network in the Transformer, namely FL-tuning. It introduces additional units into the hidden layer of each feed-forward network. We conduct extensive experiments on the public CLUE benchmark. The results show that: 1) Our FL-tuning outperforms prompt tuning methods under both full-data and few-shot settings in almost all cases. In particular, it improves accuracy by 17.93% (full-data setting) on WSC 1.0 and F1 by 16.142% (few-shot setting) on CLUENER over P-tuning v2. 2) Our FL-tuning is more stable and converges about 1.17 times faster than P-tuning v2. 3) With only about 3% of Transformer's parameters to be trained, FL-tuning is comparable with fine-tuning on most datasets, and significantly outperforms fine-tuning (e.g., accuracy improved by 12.9% on WSC 1.1) on several datasets. The source codes are available at https://github.com/genggui001/FL-Tuning. ",
    "url": "https://arxiv.org/abs/2206.15312",
    "authors": [
      "Jingping Liu",
      "Yuqiu Song",
      "Kui Xue",
      "Hongli Sun",
      "Chao Wang",
      "Lihan Chen",
      "Haiyun Jiang",
      "Jiaqing Liang",
      "Tong Ruan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.15316",
    "title": "Interpretable Anomaly Detection in Echocardiograms with Dynamic  Variational Trajectory Models",
    "abstract": "We propose a novel anomaly detection method for echocardiogram videos. The introduced method takes advantage of the periodic nature of the heart cycle to learn different variants of a variational latent trajectory model (TVAE). The models are trained on the healthy samples of an in-house dataset of infant echocardiogram videos consisting of multiple chamber views to learn a normative prior of the healthy population. During inference, maximum a posteriori (MAP) based anomaly detection is performed to detect out-of-distribution samples in our dataset. The proposed method reliably identifies severe congenital heart defects, such as Ebstein's Anomaly or Shonecomplex. Moreover, it achieves superior performance over MAP-based anomaly detection with standard variational autoencoders on the task of detecting pulmonary hypertension and right ventricular dilation. Finally, we demonstrate that the proposed method provides interpretable explanations of its output through heatmaps which highlight the regions corresponding to anomalous heart structures. ",
    "url": "https://arxiv.org/abs/2206.15316",
    "authors": [
      "Alain Ryser",
      "Laura Manduchi",
      "Fabian Laumer",
      "Holger Michel",
      "Sven Wellmann",
      "Julia E. Vogt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.15328",
    "title": "Neural Annotation Refinement: Development of a New 3D Dataset for  Adrenal Gland Analysis",
    "abstract": "The human annotations are imperfect, especially when produced by junior practitioners. Multi-expert consensus is usually regarded as golden standard, while this annotation protocol is too expensive to implement in many real-world projects. In this study, we propose a method to refine human annotation, named Neural Annotation Refinement (NeAR). It is based on a learnable implicit function, which decodes a latent vector into represented shape. By integrating the appearance as an input of implicit functions, the appearance-aware NeAR fixes the annotation artefacts. Our method is demonstrated on the application of adrenal gland analysis. We first show that the NeAR can repair distorted golden standards on a public adrenal gland segmentation dataset. Besides, we develop a new Adrenal gLand ANalysis (ALAN) dataset with the proposed NeAR, where each case consists of a 3D shape of adrenal gland and its diagnosis label (normal vs. abnormal) assigned by experts. We show that models trained on the shapes repaired by the NeAR can diagnose adrenal glands better than the original ones. The ALAN dataset will be open-source, with 1,594 shapes for adrenal gland diagnosis, which serves as a new benchmark for medical shape analysis. Code and dataset are available at https://github.com/M3DV/NeAR. ",
    "url": "https://arxiv.org/abs/2206.15328",
    "authors": [
      "Jiancheng Yang",
      "Rui Shi",
      "Udaranga Wickramasinghe",
      "Qikui Zhu",
      "Bingbing Ni",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.15335",
    "title": "Byzantine Agreement with Optimal Resilience via Statistical Fraud  Detection",
    "abstract": "Since the mid-1980s it has been known that Byzantine Agreement can be solved with probability 1 asynchronously, even against an omniscient, computationally unbounded adversary that can adaptively \\emph{corrupt} up to $f<n/3$ parties. Moreover, the problem is insoluble with $f\\geq n/3$ corruptions. However, Bracha's 1984 protocol achieved $f<n/3$ resilience at the cost of exponential expected latency $2^{\\Theta(n)}$, a bound that has never been improved in this model with $f=\\lfloor (n-1)/3 \\rfloor$ corruptions. In this paper we prove that Byzantine Agreement in the asynchronous, full information model can be solved with probability 1 against an adaptive adversary that can corrupt $f<n/3$ parties, while incurring only polynomial latency with high probability. Our protocol follows earlier polynomial latency protocols of King and Saia and Huang, Pettie, and Zhu, which had suboptimal resilience, namely $f \\approx n/10^9$ and $f<n/4$, respectively. Resilience $f=(n-1)/3$ is uniquely difficult as this is the point at which the influence of the Byzantine and honest players are of roughly equal strength. The core technical problem we solve is to design a collective coin-flipping protocol that eventually lets us flip a coin with an unambiguous outcome. In the beginning the influence of the Byzantine players is too powerful to overcome and they can essentially fix the coin's behavior at will. We guarantee that after just a polynomial number of executions of the coin-flipping protocol, either (a) the Byzantine players fail to fix the behavior of the coin (thereby ending the game) or (b) we can ``blacklist'' players such that the blacklisting rate for Byzantine players is at least as large as the blacklisting rate for good players. The blacklisting criterion is based on a simple statistical test of fraud detection. ",
    "url": "https://arxiv.org/abs/2206.15335",
    "authors": [
      "Shang-En Huang",
      "Seth Pettie",
      "Leqi Zhu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2206.15336",
    "title": "Tight Bounds for Online Matching in Bounded-Degree Graphs with Vertex  Capacities",
    "abstract": "We study the $b$-matching problem in bipartite graphs $G=(S,R,E)$. Each vertex $s\\in S$ is a server with individual capacity $b_s$. The vertices $r\\in R$ are requests that arrive online and must be assigned instantly to an eligible server. The goal is to maximize the size of the constructed matching. We assume that $G$ is a $(k,d)$-graph~\\cite{NW}, where $k$ specifies a lower bound on the degree of each server and $d$ is an upper bound on the degree of each request. This setting models matching problems in timely applications. We present tight upper and lower bounds on the performance of deterministic online algorithms. In particular, we develop a new online algorithm via a primal-dual analysis. The optimal competitive ratio tends to~1, for arbitrary $k\\geq d$, as the server capacities increase. Hence, nearly optimal solutions can be computed online. Our results also hold for the vertex-weighted problem extension, and thus for AdWords and auction problems in which each bidder issues individual, equally valued bids. Our bounds improve the previous best competitive ratios. The asymptotic competitiveness of~1 is a significant improvement over the previous factor of $1-1/e^{k/d}$, for the interesting range where $k/d\\geq 1$ is small. Recall that $1-1/e\\approx 0.63$. Matching problems that admit a competitive ratio arbitrarily close to~1 are rare. Prior results rely on randomization or probabilistic input models. ",
    "url": "https://arxiv.org/abs/2206.15336",
    "authors": [
      "Susanne Albers",
      "Sebastian Schubert"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2206.15359",
    "title": "Two-Stage Classifier for COVID-19 Misinformation Detection Using BERT: a  Study on Indonesian Tweets",
    "abstract": "The COVID-19 pandemic has caused globally significant impacts since the beginning of 2020. This brought a lot of confusion to society, especially due to the spread of misinformation through social media. Although there were already several studies related to the detection of misinformation in social media data, most studies focused on the English dataset. Research on COVID-19 misinformation detection in Indonesia is still scarce. Therefore, through this research, we collect and annotate datasets for Indonesian and build prediction models for detecting COVID-19 misinformation by considering the tweet's relevance. The dataset construction is carried out by a team of annotators who labeled the relevance and misinformation of the tweet data. In this study, we propose the two-stage classifier model using IndoBERT pre-trained language model for the Tweet misinformation detection task. We also experiment with several other baseline models for text classification. The experimental results show that the combination of the BERT sequence classifier for relevance prediction and Bi-LSTM for misinformation detection outperformed other machine learning models with an accuracy of 87.02%. Overall, the BERT utilization contributes to the higher performance of most prediction models. We release a high-quality COVID-19 misinformation Tweet corpus in the Indonesian language, indicated by the high inter-annotator agreement. ",
    "url": "https://arxiv.org/abs/2206.15359",
    "authors": [
      "Douglas Raevan Faisal",
      "Rahmad Mahendra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.15362",
    "title": "Quantum gene regulatory networks",
    "abstract": "In this work, we present a quantum circuit model for inferring gene regulatory networks (GRNs). The model is based on the idea of using qubit-qubit entanglement to simulate interactions between genes. We provide preliminary results that suggest our quantum GRN modeling method is competitive and warrants further investigation. Specifically, we present the results derived from the single-cell transcriptomic data of human cell lines, focusing on genes in involving innate immunity regulation. We demonstrate that our quantum circuit model can be used to predict the presence or absence of regulatory interactions between genes and estimate the strength and direction of the interactions, setting the stage for further investigations on how quantum computing finds applications in data-driven life sciences and, more importantly, to invite exploration of quantum algorithm design that takes advantage of the single-cell data. The application of quantum computing on single-cell transcriptomic data likewise contributes to a novel understanding of GRNs, given that the relationship between fully interconnected genes can be approached more effectively by quantum modeling than by statistical correlations. ",
    "url": "https://arxiv.org/abs/2206.15362",
    "authors": [
      "Cristhian Roman-Vicharra",
      "James J. Cai"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Genomics (q-bio.GN)"
    ]
  },
  {
    "id": "arXiv:2206.15374",
    "title": "Verification and search algorithms for causal DAGs",
    "abstract": "We study two problems related to recovering causal graphs from interventional data: (i) $\\textit{verification}$, where the task is to check if a purported causal graph is correct, and (ii) $\\textit{search}$, where the task is to recover the correct causal graph. For both, we wish to minimize the number of interventions performed. For the first problem, we give a characterization of a minimal sized set of atomic interventions that is necessary and sufficient to check the correctness of a claimed causal graph. Our characterization uses the notion of $\\textit{covered edges}$, which enables us to obtain simple proofs and also easily reason about earlier results. We also generalize our results to the settings of bounded size interventions and node-dependent interventional costs. For all the above settings, we provide the first known provable algorithms for efficiently computing (near)-optimal verifying sets on general graphs. For the second problem, we give a simple adaptive algorithm based on graph separators that produces an atomic intervention set which fully orients any essential graph while using $\\mathcal{O}(\\log n)$ times the optimal number of interventions needed to $\\textit{verify}$ (verifying size) the underlying DAG on $n$ vertices. This approximation is tight as $\\textit{any}$ search algorithm on an essential line graph has worst case approximation ratio of $\\Omega(\\log n)$ with respect to the verifying size. With bounded size interventions, each of size $\\leq k$, our algorithm gives an $\\mathcal{O}(\\log n \\cdot \\log \\log k)$ factor approximation. Our result is the first known algorithm that gives a non-trivial approximation guarantee to the verifying size on general unweighted graphs and with bounded size interventions. ",
    "url": "https://arxiv.org/abs/2206.15374",
    "authors": [
      "Davin Choo",
      "Kirankumar Shiragur",
      "Arnab Bhattacharyya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.15398",
    "title": "PolarFormer: Multi-camera 3D Object Detection with Polar Transformer",
    "abstract": "3D object detection in autonomous driving aims to reason \"what\" and \"where\" the objects of interest present in a 3D world. Following the conventional wisdom of previous 2D object detection, existing methods often adopt the canonical Cartesian coordinate system with perpendicular axis. However, we conjugate that this does not fit the nature of the ego car's perspective, as each onboard camera perceives the world in shape of wedge intrinsic to the imaging geometry with radical (non-perpendicular) axis. Hence, in this paper we advocate the exploitation of the Polar coordinate system and propose a new Polar Transformer (PolarFormer) for more accurate 3D object detection in the bird's-eye-view (BEV) taking as input only multi-camera 2D images. Specifically, we design a cross attention based Polar detection head without restriction to the shape of input structure to deal with irregular Polar grids. For tackling the unconstrained object scale variations along Polar's distance dimension, we further introduce a multi-scalePolar representation learning strategy. As a result, our model can make best use of the Polar representation rasterized via attending to the corresponding image observation in a sequence-to-sequence fashion subject to the geometric constraints. Thorough experiments on the nuScenes dataset demonstrate that our PolarFormer outperforms significantly state-of-the-art 3D object detection alternatives, as well as yielding competitive performance on BEV semantic segmentation task. ",
    "url": "https://arxiv.org/abs/2206.15398",
    "authors": [
      "Yanqin Jiang",
      "Li Zhang",
      "Zhenwei Miao",
      "Xiatian Zhu",
      "Jin Gao",
      "Weiming Hu",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.15414",
    "title": "Bounding and computing obstacle numbers of graphs",
    "abstract": "An obstacle representation of a graph $G$ consists of a set of pairwise disjoint simply-connected closed regions and a one-to-one mapping of the vertices of $G$ to points such that two vertices are adjacent in $G$ if and only if the line segment connecting the two corresponding points does not intersect any obstacle. The obstacle number of a graph is the smallest number of obstacles in an obstacle representation of the graph in the plane such that all obstacles are simple polygons. It is known that the obstacle number of each $n$-vertex graph is $O(n \\log n)$ [Balko, Cibulka, and Valtr, 2018] and that there are $n$-vertex graphs whose obstacle number is $\\Omega(n/(\\log\\log n)^2)$ [Dujmovi\\'c and Morin, 2015]. We improve this lower bound to $\\Omega(n/\\log\\log n)$ for simple polygons and to $\\Omega(n)$ for convex polygons. To obtain these stronger bounds, we improve known estimates on the number of $n$-vertex graphs with bounded obstacle number, solving a conjecture by Dujmovi\\'c and Morin. We also show that if the drawing of some $n$-vertex graph is given as part of the input, then for some drawings $\\Omega(n^2)$ obstacles are required to turn them into an obstacle representation of the graph. Our bounds are asymptotically tight in several instances. We complement these combinatorial bounds by two complexity results. First, we show that computing the obstacle number of a graph $G$ is fixed-parameter tractable in the vertex cover number of $G$. Second, we show that, given a graph $G$ and a simple polygon $P$, it is NP-hard to decide whether $G$ admits an obstacle representation using $P$ as the only obstacle. ",
    "url": "https://arxiv.org/abs/2206.15414",
    "authors": [
      "Martin Balko",
      "Steven Chaplick",
      "Robert Ganian",
      "Siddharth Gupta",
      "Michael Hoffmann",
      "Pavel Valtr",
      "Alexander Wolff"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2206.15415",
    "title": "MEAD: A Multi-Armed Approach for Evaluation of Adversarial Examples  Detectors",
    "abstract": "Detection of adversarial examples has been a hot topic in the last years due to its importance for safely deploying machine learning algorithms in critical applications. However, the detection methods are generally validated by assuming a single implicitly known attack strategy, which does not necessarily account for real-life threats. Indeed, this can lead to an overoptimistic assessment of the detectors' performance and may induce some bias in the comparison between competing detection schemes. We propose a novel multi-armed framework, called MEAD, for evaluating detectors based on several attack strategies to overcome this limitation. Among them, we make use of three new objectives to generate attacks. The proposed performance metric is based on the worst-case scenario: detection is successful if and only if all different attacks are correctly recognized. Empirically, we show the effectiveness of our approach. Moreover, the poor performance obtained for state-of-the-art detectors opens a new exciting line of research. ",
    "url": "https://arxiv.org/abs/2206.15415",
    "authors": [
      "Federica Granese",
      "Marine Picot",
      "Marco Romanelli",
      "Francisco Messina",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.15418",
    "title": "Distributed asynchronous convergence detection without detection  protocol",
    "abstract": "In this paper, we address the problem of detecting the moment when an ongoing asynchronous parallel iterative process can be terminated to provide a sufficiently precise solution to a fixed-point problem being solved. Formulating the detection problem as a global solution identification problem, we analyze the snapshot-based approach, which is the only one that allows for exact global residual error computation. From a recently developed approximate snapshot protocol providing a reliable global residual error, we experimentally investigate here, as well, the reliability of a global residual error computed without any prior particular detection mechanism. Results on a single-site supercomputer successfully show that such high-performance computing platforms possibly provide computational environments stable enough to allow for simply resorting to non-blocking reduction operations for computing reliable global residual errors, which provides noticeable time saving, at both implementation and execution levels. ",
    "url": "https://arxiv.org/abs/2206.15418",
    "authors": [
      "Guillaume Gbikpi-Benissan",
      "Frederic Magoules"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2206.15423",
    "title": "Implicit Neural Spatial Filtering for Multichannel Source Separation in  the Waveform Domain",
    "abstract": "We present a single-stage casual waveform-to-waveform multichannel model that can separate moving sound sources based on their broad spatial locations in a dynamic acoustic scene. We divide the scene into two spatial regions containing, respectively, the target and the interfering sound sources. The model is trained end-to-end and performs spatial processing implicitly, without any components based on traditional processing or use of hand-crafted spatial features. We evaluate the proposed model on a real-world dataset and show that the model matches the performance of an oracle beamformer followed by a state-of-the-art single-channel enhancement network. ",
    "url": "https://arxiv.org/abs/2206.15423",
    "authors": [
      "Dejan Markovic",
      "Alexandre Defossez",
      "Alexander Richard"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.15428",
    "title": "Test2Vec: An Execution Trace Embedding for Test Case Prioritization",
    "abstract": "Most automated software testing tasks can benefit from the abstract representation of test cases. Traditionally, this is done by encoding test cases based on their code coverage. Specification-level criteria can replace code coverage to better represent test cases' behavior, but they are often not cost-effective. In this paper, we hypothesize that execution traces of the test cases can be a good alternative to abstract their behavior for automated testing tasks. We propose a novel embedding approach, Test2Vec, that maps test execution traces to a latent space. We evaluate this representation in the test case prioritization (TP) task. Our default TP method is based on the similarity of the embedded vectors to historical failing test vectors. We also study an alternative based on the diversity of test vectors. Finally, we propose a method to decide which TP to choose, for a given test suite. The experiment is based on several real and seeded faults with over a million execution traces. Results show that our proposed TP improves best alternatives by 41.80% in terms of the median normalized rank of the first failing test case (FFR). It outperforms traditional code coverage-based approaches by 25.05% and 59.25% in terms of median APFD and median normalized FFR. ",
    "url": "https://arxiv.org/abs/2206.15428",
    "authors": [
      "Emad Jabbar",
      "Soheila Zangeneh",
      "Hadi Hemmati",
      "Robert Feldt"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.15474",
    "title": "Forecasting Future World Events with Neural Networks",
    "abstract": "Forecasting future world events is a challenging but valuable task. Forecasts of climate, geopolitical conflict, pandemics and economic indicators help shape policy and decision making. In these domains, the judgment of expert humans contributes to the best forecasts. Given advances in language modeling, can these forecasts be automated? To this end, we introduce Autocast, a dataset containing thousands of forecasting questions and an accompanying news corpus. Questions are taken from forecasting tournaments, ensuring high quality, real-world importance, and diversity. The news corpus is organized by date, allowing us to precisely simulate the conditions under which humans made past forecasts (avoiding leakage from the future). Motivated by the difficulty of forecasting numbers across orders of magnitude (e.g. global cases of COVID-19 in 2022), we also curate IntervalQA, a dataset of numerical questions and metrics for calibration. We test language models on our forecasting task and find that performance is far below a human expert baseline. However, performance improves with increased model size and incorporation of relevant information from the news corpus. In sum, Autocast poses a novel challenge for large language models and improved performance could bring large practical benefits. ",
    "url": "https://arxiv.org/abs/2206.15474",
    "authors": [
      "Andy Zou",
      "Tristan Xiao",
      "Ryan Jia",
      "Joe Kwon",
      "Mantas Mazeika",
      "Richard Li",
      "Dawn Song",
      "Jacob Steinhardt",
      "Owain Evans",
      "Dan Hendrycks"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.15475",
    "title": "Causal Machine Learning: A Survey and Open Problems",
    "abstract": "Causal Machine Learning (CausalML) is an umbrella term for machine learning methods that formalize the data-generation process as a structural causal model (SCM). This allows one to reason about the effects of changes to this process (i.e., interventions) and what would have happened in hindsight (i.e., counterfactuals). We categorize work in \\causalml into five groups according to the problems they tackle: (1) causal supervised learning, (2) causal generative modeling, (3) causal explanations, (4) causal fairness, (5) causal reinforcement learning. For each category, we systematically compare its methods and point out open problems. Further, we review modality-specific applications in computer vision, natural language processing, and graph representation learning. Finally, we provide an overview of causal benchmarks and a critical discussion of the state of this nascent field, including recommendations for future work. ",
    "url": "https://arxiv.org/abs/2206.15475",
    "authors": [
      "Jean Kaddour",
      "Aengus Lynch",
      "Qi Liu",
      "Matt J. Kusner",
      "Ricardo Silva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2206.15476",
    "title": "AnoShift: A Distribution Shift Benchmark for Unsupervised Anomaly  Detection",
    "abstract": "Analyzing the distribution shift of data is a growing research direction in nowadays Machine Learning, leading to emerging new benchmarks that focus on providing a suitable scenario for studying the generalization properties of ML models. The existing benchmarks are focused on supervised learning, and to the best of our knowledge, there is none for unsupervised learning. Therefore, we introduce an unsupervised anomaly detection benchmark with data that shifts over time, built over Kyoto-2006+, a traffic dataset for network intrusion detection. This kind of data meets the premise of shifting the input distribution: it covers a large time span ($10$ years), with naturally occurring changes over time (\\eg users modifying their behavior patterns, and software updates). We first highlight the non-stationary nature of the data, using a basic per-feature analysis, t-SNE, and an Optimal Transport approach for measuring the overall distribution distances between years. Next, we propose AnoShift, a protocol splitting the data in IID, NEAR, and FAR testing splits. We validate the performance degradation over time with diverse models (MLM to classical Isolation Forest). Finally, we show that by acknowledging the distribution shift problem and properly addressing it, the performance can be improved compared to the classical IID training (by up to $3\\%$, on average). Dataset and code are available at https://github.com/bit-ml/AnoShift/. ",
    "url": "https://arxiv.org/abs/2206.15476",
    "authors": [
      "Marius Dr\u0103goi",
      "Elena Burceanu",
      "Emanuela Haller",
      "Andrei Manolache",
      "Florin Brad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14820",
    "title": "Strong Lensing Source Reconstruction Using Continuous Neural Fields",
    "abstract": "From the nature of dark matter to the rate of expansion of our Universe, observations of distant galaxies distorted through strong gravitational lensing have the potential to answer some of the major open questions in astrophysics. Modeling galaxy-galaxy strong lensing observations presents a number of challenges as the exact configuration of both the background source and foreground lens galaxy is unknown. A timely call, prompted by a number of upcoming surveys anticipating high-resolution lensing images, demands methods that can efficiently model lenses at their full complexity. In this work, we introduce a method that uses continuous neural fields to non-parametrically reconstruct the complex morphology of a source galaxy while simultaneously inferring a distribution over foreground lens galaxy configurations. We demonstrate the efficacy of our method through experiments on simulated data targeting high-resolution lensing images similar to those anticipated in near-future astrophysical surveys. ",
    "url": "https://arxiv.org/abs/2206.14820",
    "authors": [
      "Siddharth Mishra-Sharma",
      "Ge Yang"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14866",
    "title": "iEmoTTS: Toward Robust Cross-Speaker Emotion Transfer and Control for  Speech Synthesis based on Disentanglement between Prosody and Timbre",
    "abstract": "The capability of generating speech with specific type of emotion is desired for many applications of human-computer interaction. Cross-speaker emotion transfer is a common approach to generating emotional speech when speech with emotion labels from target speakers is not available for model training. This paper presents a novel cross-speaker emotion transfer system, named iEmoTTS. The system is composed of an emotion encoder, a prosody predictor, and a timbre encoder. The emotion encoder extracts the identity of emotion type as well as the respective emotion intensity from the mel-spectrogram of input speech. The emotion intensity is measured by the posterior probability that the input utterance carries that emotion. The prosody predictor is used to provide prosodic features for emotion transfer. The timber encoder provides timbre-related information for the system. Unlike many other studies which focus on disentangling speaker and style factors of speech, the iEmoTTS is designed to achieve cross-speaker emotion transfer via disentanglement between prosody and timbre. Prosody is considered as the main carrier of emotion-related speech characteristics and timbre accounts for the essential characteristics for speaker identification. Zero-shot emotion transfer, meaning that speech of target speakers are not seen in model training, is also realized with iEmoTTS. Extensive experiments of subjective evaluation have been carried out. The results demonstrate the effectiveness of iEmoTTS as compared with other recently proposed systems of cross-speaker emotion transfer. It is shown that iEmoTTS can produce speech with designated emotion type and controllable emotion intensity. With appropriate information bottleneck capacity, iEmoTTS is able to effectively transfer emotion information to a new speaker. Audio samples are publicly available\\footnote{https://patrick-g-zhang.github.io/iemotts/}. ",
    "url": "https://arxiv.org/abs/2206.14866",
    "authors": [
      "Guangyan Zhang",
      "Ying Qin",
      "Wenjie Zhang",
      "Jialun Wu",
      "Mei Li",
      "Yutao Gai",
      "Feijun Jiang",
      "Tan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2206.14896",
    "title": "Threshold for Detecting High Dimensional Geometry in Anisotropic Random  Geometric Graphs",
    "abstract": "In the anisotropic random geometric graph model, vertices correspond to points drawn from a high-dimensional Gaussian distribution and two vertices are connected if their distance is smaller than a specified threshold. We study when it is possible to hypothesis test between such a graph and an Erd\\H{o}s-R\\'enyi graph with the same edge probability. If $n$ is the number of vertices and $\\alpha$ is the vector of eigenvalues, Eldan and Mikulincer show that detection is possible when $n^3 \\gg (\\|\\alpha\\|_2/\\|\\alpha\\|_3)^6$ and impossible when $n^3 \\ll (\\|\\alpha\\|_2/\\|\\alpha\\|_4)^4$. We show detection is impossible when $n^3 \\ll (\\|\\alpha\\|_2/\\|\\alpha\\|_3)^6$, closing this gap and affirmatively resolving the conjecture of Eldan and Mikulincer. ",
    "url": "https://arxiv.org/abs/2206.14896",
    "authors": [
      "Matthew Brennan",
      "Guy Bresler",
      "Brice Huang"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2206.14903",
    "title": "CIRDataset: A large-scale Dataset for Clinically-Interpretable lung  nodule Radiomics and malignancy prediction",
    "abstract": "Spiculations/lobulations, sharp/curved spikes on the surface of lung nodules, are good predictors of lung cancer malignancy and hence, are routinely assessed and reported by radiologists as part of the standardized Lung-RADS clinical scoring criteria. Given the 3D geometry of the nodule and 2D slice-by-slice assessment by radiologists, manual spiculation/lobulation annotation is a tedious task and thus no public datasets exist to date for probing the importance of these clinically-reported features in the SOTA malignancy prediction algorithms. As part of this paper, we release a large-scale Clinically-Interpretable Radiomics Dataset, CIRDataset, containing 956 radiologist QA/QC'ed spiculation/lobulation annotations on segmented lung nodules from two public datasets, LIDC-IDRI (N=883) and LUNGx (N=73). We also present an end-to-end deep learning model based on multi-class Voxel2Mesh extension to segment nodules (while preserving spikes), classify spikes (sharp/spiculation and curved/lobulation), and perform malignancy prediction. Previous methods have performed malignancy prediction for LIDC and LUNGx datasets but without robust attribution to any clinically reported/actionable features (due to known hyperparameter sensitivity issues with general attribution schemes). With the release of this comprehensively-annotated CIRDataset and end-to-end deep learning baseline, we hope that malignancy prediction methods can validate their explanations, benchmark against our baseline, and provide clinically-actionable insights. Dataset, code, pretrained models, and docker containers are available at https://github.com/nadeemlab/CIR. ",
    "url": "https://arxiv.org/abs/2206.14903",
    "authors": [
      "Wookjin Choi",
      "Navdeep Dahiya",
      "Saad Nadeem"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14919",
    "title": "Identifying and Combating Bias in Segmentation Networks by leveraging  multiple resolutions",
    "abstract": "Exploration of bias has significant impact on the transparency and applicability of deep learning pipelines in medical settings, yet is so far woefully understudied. In this paper, we consider two separate groups for which training data is only available at differing image resolutions. For group H, available images and labels are at the preferred high resolution while for group L only deprecated lower resolution data exist. We analyse how this resolution-bias in the data distribution propagates to systematically biased predictions for group L at higher resolutions. Our results demonstrate that single-resolution training settings result in significant loss of volumetric group differences that translate to erroneous segmentations as measured by DSC and subsequent classification failures on the low resolution group. We further explore how training data across resolutions can be used to combat this systematic bias. Specifically, we investigate the effect of image resampling, scale augmentation and resolution independence and demonstrate that biases can effectively be reduced with multi-resolution approaches. ",
    "url": "https://arxiv.org/abs/2206.14919",
    "authors": [
      "Leonie Henschel",
      "David K\u00fcgler",
      "Derek S Andrews",
      "Christine W Nordahl",
      "Martin Reuter"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14951",
    "title": "CLTS-GAN: Color-Lighting-Texture-Specular Reflection Augmentation for  Colonoscopy",
    "abstract": "Automated analysis of optical colonoscopy (OC) video frames (to assist endoscopists during OC) is challenging due to variations in color, lighting, texture, and specular reflections. Previous methods either remove some of these variations via preprocessing (making pipelines cumbersome) or add diverse training data with annotations (but expensive and time-consuming). We present CLTS-GAN, a new deep learning model that gives fine control over color, lighting, texture, and specular reflection synthesis for OC video frames. We show that adding these colonoscopy-specific augmentations to the training data can improve state-of-the-art polyp detection/segmentation methods as well as drive next generation of OC simulators for training medical students. The code and pre-trained models for CLTS-GAN are available on Computational Endoscopy Platform GitHub (https://github.com/nadeemlab/CEP). ",
    "url": "https://arxiv.org/abs/2206.14951",
    "authors": [
      "Shawn Mathew",
      "Saad Nadeem",
      "Arie Kaufman"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14964",
    "title": "Improving Visual Speech Enhancement Network by Learning Audio-visual  Affinity with Multi-head Attention",
    "abstract": "Audio-visual speech enhancement system is regarded as one of promising solutions for isolating and enhancing speech of desired speaker. Typical methods focus on predicting clean speech spectrum via a naive convolution neural network based encoder-decoder architecture, and these methods a) are not adequate to use data fully, b) are unable to effectively balance audio-visual features. The proposed model alleviates these drawbacks by a) applying a model that fuses audio and visual features layer by layer in encoding phase, and that feeds fused audio-visual features to each corresponding decoder layer, and more importantly, b) introducing a 2-stage multi-head cross attention (MHCA) mechanism to infer audio-visual speech enhancement for balancing the fused audio-visual features and eliminating irrelevant features. This paper proposes attentional audio-visual multi-layer feature fusion model, in which MHCA units are applied to feature mapping at every layer of decoder. The proposed model demonstrates the superior performance of the network against the state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2206.14964",
    "authors": [
      "Xinmeng Xu",
      "Yang Wang",
      "Jie Jia",
      "Binbin Chen",
      "Dejun Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2206.14984",
    "title": "TTS-by-TTS 2: Data-selective augmentation for neural speech synthesis  using ranking support vector machine with variational autoencoder",
    "abstract": "Recent advances in synthetic speech quality have enabled us to train text-to-speech (TTS) systems by using synthetic corpora. However, merely increasing the amount of synthetic data is not always advantageous for improving training efficiency. Our aim in this study is to selectively choose synthetic data that are beneficial to the training process. In the proposed method, we first adopt a variational autoencoder whose posterior distribution is utilized to extract latent features representing acoustic similarity between the recorded and synthetic corpora. By using those learned features, we then train a ranking support vector machine (RankSVM) that is well known for effectively ranking relative attributes among binary classes. By setting the recorded and synthetic ones as two opposite classes, RankSVM is used to determine how the synthesized speech is acoustically similar to the recorded data. Then, synthetic TTS data, whose distribution is close to the recorded data, are selected from large-scale synthetic corpora. By using these data for retraining the TTS model, the synthetic quality can be significantly improved. Objective and subjective evaluation results show the superiority of the proposed method over the conventional methods. ",
    "url": "https://arxiv.org/abs/2206.14984",
    "authors": [
      "Eunwoo Song",
      "Ryuichi Yamamoto",
      "Ohsung Kwon",
      "Chan-Ho Song",
      "Min-Jae Hwang",
      "Suhyeon Oh",
      "Hyun-Wook Yoon",
      "Jin-Seob Kim",
      "Jae-Min Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2206.14986",
    "title": "A Hierarchical Robust Control Strategy for Decentralized Signal-Free  Intersection Management",
    "abstract": "The development of connected and automated vehicles (CAVs) is the key to improve urban mobility safety and efficiency. This paper focuses on the cooperative vehicle management at a signal-free intersection with consideration of vehicle modeling uncertainties and sensor measurement disturbances. The problem is approached by a hierarchical robust control strategy (HRCS) in a decentralized traffic coordination framework where optimal control and tube-based robust model predictive control (RMPC) methods are designed to hierarchically solve the optimal crossing order and the velocity trajectories of a group of CAVs in terms of energy consumption and throughput. To capture the energy consumption of each vehicle, their powertrain system is modeled in line with an electric drive system. With a suitable relaxation and spatial modeling approach, the optimization problems in HRCS can be formulated as convex second-order cone programs (SOCPs), which provide unique and computationally efficient solution. A rigorous proof of the equivalence between the convexified and the original problems is also provided. Simulation results illustrate the effectiveness and robustness of HRCS and reveal the impact of traffic density on the control solution. The study of the Pareto optimal solutions for the energy-time objective shows that a minor reduction in journey time can considerably reduce energy consumption, which emphasizes the necessity of optimizing their trade-off. Finally, the numerical comparisons carried out for different prediction horizons and sampling intervals provide insight into the control design. ",
    "url": "https://arxiv.org/abs/2206.14986",
    "authors": [
      "Xiao Pan",
      "Boli Chen",
      "Li Dai",
      "Stelios Timotheou",
      "Simos A. Evangelou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.15073",
    "title": "Custom Pretrainings and Adapted 3D-ConvNeXt Architecture for COVID  Detection and Severity Prediction",
    "abstract": "Since COVID strongly affects the respiratory system, lung CT scans can be used for the analysis of a patients health. We introduce an neural network for the prediction of the severity of lung damage and the detection of infection using three-dimensional CT-scans. Therefore, we adapt the recent ConvNeXt model to process three-dimensional data. Furthermore, we introduce different pretraining methods specifically adjusted to improve the models ability to handle three-dimensional CT-data. In order to test the performance of our model, we participate in the 2nd COV19D Competition for severity prediction and infection detection. ",
    "url": "https://arxiv.org/abs/2206.15073",
    "authors": [
      "Daniel Kienzle",
      "Julian Lorenz",
      "Robin Sch\u00f6n",
      "Katja Ludwig",
      "Rainer Lienhart"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.15079",
    "title": "Prediction of Dilatory Behavior in eLearning: A Comparison of Multiple  Machine Learning Models",
    "abstract": "Procrastination, the irrational delay of tasks, is a common occurrence in online learning. Potential negative consequences include higher risk of drop-outs, increased stress, and reduced mood. Due to the rise of learning management systems and learning analytics, indicators of such behavior can be detected, enabling predictions of future procrastination and other dilatory behavior. However, research focusing on such predictions is scarce. Moreover, studies involving different types of predictors and comparisons between the predictive performance of various methods are virtually non-existent. In this study, we aim to fill these research gaps by analyzing the performance of multiple machine learning algorithms when predicting the delayed or timely submission of online assignments in a higher education setting with two categories of predictors: subjective, questionnaire-based variables and objective, log-data based indicators extracted from a learning management system. The results show that models with objective predictors consistently outperform models with subjective predictors, and a combination of both variable types perform slightly better. For each of these three options, a different approach prevailed (Gradient Boosting Machines for the subjective, Bayesian multilevel models for the objective, and Random Forest for the combined predictors). We conclude that careful attention should be paid to the selection of predictors and algorithms before implementing such models in learning management systems. ",
    "url": "https://arxiv.org/abs/2206.15079",
    "authors": [
      "Christof Imhof",
      "Ioan-Sorin Comsa",
      "Martin Hlosta",
      "Behnam Parsaeifard",
      "Ivan Moser",
      "Per Bergamin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.15092",
    "title": "Treewidth versus clique number. III. Tree-independence number of graphs  with a forbidden structure",
    "abstract": "We continue the study of $(\\mathrm{tw},\\omega)$-bounded graph classes, that is, hereditary graph classes in which the treewidth can only be large due to the presence of a large clique, with the goal of understanding the extent to which this property has useful algorithmic implications for the Independent Set and related problems. In the previous paper of the series [Dallard, Milani\\v{c}, and \\v{S}torgel, Treewidth versus clique number. II. Tree-independence number], we introduced the tree-independence number, a min-max graph invariant related to tree decompositions. Bounded tree-independence number implies both $(\\mathrm{tw},\\omega)$-boundedness and the existence of a polynomial-time algorithm for the Maximum Weight Independent Set problem, provided that the input graph is given together with a tree decomposition with bounded independence number. In this paper, we consider six graph containment relations and for each of them characterize the graphs $H$ for which any graph excluding $H$ with respect to the relation admits a tree decomposition with bounded independence number. The induced minor relation is of particular interest: we show that excluding either a $K_5$ minus an edge or the $4$-wheel implies the existence of a tree decomposition in which every bag is a clique plus at most $3$ vertices, while excluding a complete bipartite graph $K_{2,q}$ implies the existence of a tree decomposition with independence number at most $2(q-1)$. Our constructive proofs are obtained using a variety of tools, including $\\ell$-refined tree decompositions, SPQR trees, and potential maximal cliques. They imply polynomial-time algorithms for the Independent Set and related problems in an infinite family of graph classes; in particular, the results apply to the class of $1$-perfectly orientable graphs, answering a question of Beisegel, Chudnovsky, Gurvich, Milani\\v{c}, and Servatius from 2019. ",
    "url": "https://arxiv.org/abs/2206.15092",
    "authors": [
      "Cl\u00e9ment Dallard",
      "Martin Milani\u010d",
      "Kenny \u0160torgel"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2206.15101",
    "title": "The maximum capability of a topological feature in link prediction",
    "abstract": "Link prediction aims to predict links of a network that are not directly visible, with profound applications in biological and social systems. Despite intensive utilization of the topological feature in this task, it is unclear to what extent a particular feature can be leveraged to infer missing links. Here, we show that the maximum capability of a topological feature follows a simple mathematical expression, which is independent of how an index gauges the feature. Hence, a family of indexes associated with one topological feature shares the same performance limit. A feature's capability is lifted in the supervised prediction, which in general gives rise to better results compared with unsupervised prediction. The universality of the pattern uncovered is empirically verified by 550 structurally diverse networks, which can be applied to feature selection and the analysis of network characteristics associated with a topological feature in link prediction. ",
    "url": "https://arxiv.org/abs/2206.15101",
    "authors": [
      "Ran Yijun",
      "Xu Xiao-Ke",
      "Jia Tao"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.15134",
    "title": "InsMix: Towards Realistic Generative Data Augmentation for Nuclei  Instance Segmentation",
    "abstract": "Nuclei Segmentation from histology images is a fundamental task in digital pathology analysis. However, deep-learning-based nuclei segmentation methods often suffer from limited annotations. This paper proposes a realistic data augmentation method for nuclei segmentation, named InsMix, that follows a Copy-Paste-Smooth principle and performs morphology-constrained generative instance augmentation. Specifically, we propose morphology constraints that enable the augmented images to acquire luxuriant information about nuclei while maintaining their morphology characteristics (e.g., geometry and location). To fully exploit the pixel redundancy of the background and improve the model's robustness, we further propose a background perturbation method, which randomly shuffles the background patches without disordering the original nuclei distribution. To achieve contextual consistency between original and template instances, a smooth-GAN is designed with a foreground similarity encoder (FSE) and a triplet loss. We validated the proposed method on two datasets, i.e., Kumar and CPS datasets. Experimental results demonstrate the effectiveness of each component and the superior performance achieved by our method to the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2206.15134",
    "authors": [
      "Yi Lin",
      "Zeyu Wang",
      "Kwang-Ting Cheng",
      "Hao Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.15182",
    "title": "The (de)biasing effect of GAN-based augmentation methods on skin lesion  images",
    "abstract": "New medical datasets are now more open to the public, allowing for better and more extensive research. Although prepared with the utmost care, new datasets might still be a source of spurious correlations that affect the learning process. Moreover, data collections are usually not large enough and are often unbalanced. One approach to alleviate the data imbalance is using data augmentation with Generative Adversarial Networks (GANs) to extend the dataset with high-quality images. GANs are usually trained on the same biased datasets as the target data, resulting in more biased instances. This work explored unconditional and conditional GANs to compare their bias inheritance and how the synthetic data influenced the models. We provided extensive manual data annotation of possibly biasing artifacts on the well-known ISIC dataset with skin lesions. In addition, we examined classification models trained on both real and synthetic data with counterfactual bias explanations. Our experiments showed that GANs inherited biases and sometimes even amplified them, leading to even stronger spurious correlations. Manual data annotation and synthetic images are publicly available for reproducible scientific research. ",
    "url": "https://arxiv.org/abs/2206.15182",
    "authors": [
      "Agnieszka Miko\u0142ajczyk",
      "Sylwia Majchrowska",
      "Sandra Carrasco Limeros"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.15274",
    "title": "Exposing and addressing the fragility of neural networks in digital  pathology",
    "abstract": "Neural networks have achieved impressive results in many medical imaging tasks but often perform substantially worse on out-of-distribution datasets originating from different medical centres or patient cohorts. Evaluating this lack of ability to generalise and address the underlying problem are the two main challenges in developing neural networks intended for clinical practice. In this study, we develop a new method for evaluating neural network models' ability to generalise by generating a large number of distribution-shifted datasets, which can be used to thoroughly investigate their robustness to variability encountered in clinical practice. Compared to external validation, \\textit{shifted evaluation} can provide explanations for why neural networks fail on a given dataset, thus offering guidance on how to improve model robustness. With shifted evaluation, we demonstrate that neural networks, trained with state-of-the-art methods, are highly fragile to even small distribution shifts from training data, and in some cases lose all discrimination ability. To address this fragility, we develop an augmentation strategy, explicitly designed to increase neural networks' robustness to distribution shifts. \\texttt{StrongAugment} is evaluated with large-scale, heterogeneous histopathology data including five training datasets from two tissue types, 274 distribution-shifted datasets and 20 external datasets from four countries. Neural networks trained with \\texttt{StrongAugment} retain similar performance on all datasets, even with distribution shifts where networks trained with current state-of-the-art methods lose all discrimination ability. We recommend using strong augmentation and shifted evaluation to train and evaluate all neural networks intended for clinical practice. ",
    "url": "https://arxiv.org/abs/2206.15274",
    "authors": [
      "Joona Pohjonen",
      "Carolin St\u00fcrenberg",
      "Atte F\u00f6hr",
      "Esa Pitk\u00e4nen",
      "Antti Rannikko",
      "Tuomas Mirtti"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.15408",
    "title": "Sub-8-Bit Quantization Aware Training for 8-Bit Neural Network  Accelerator with On-Device Speech Recognition",
    "abstract": "We present a novel sub-8-bit quantization-aware training (S8BQAT) scheme for 8-bit neural network accelerators. Our method is inspired from Lloyd-Max compression theory with practical adaptations for a feasible computational overhead during training. With the quantization centroids derived from a 32-bit baseline, we augment training loss with a Multi-Regional Absolute Cosine (MRACos) regularizer that aggregates weights towards their nearest centroid, effectively acting as a pseudo compressor. Additionally, a periodically invoked hard compressor is introduced to improve the convergence rate by emulating runtime model weight quantization. We apply S8BQAT on speech recognition tasks using Recurrent Neural NetworkTransducer (RNN-T) architecture. With S8BQAT, we are able to increase the model parameter size to reduce the word error rate by 4-16% relatively, while still improving latency by 5%. ",
    "url": "https://arxiv.org/abs/2206.15408",
    "authors": [
      "Kai Zhen",
      "Hieu Duy Nguyen",
      "Raviteja Chinta",
      "Nathan Susanj",
      "Athanasios Mouchtaris",
      "Tariq Afzal",
      "Ariya Rastrow"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.15427",
    "title": "Few-Shot Cross-Lingual TTS Using Transferable Phoneme Embedding",
    "abstract": "This paper studies a transferable phoneme embedding framework that aims to deal with the cross-lingual text-to-speech (TTS) problem under the few-shot setting. Transfer learning is a common approach when it comes to few-shot learning since training from scratch on few-shot training data is bound to overfit. Still, we find that the naive transfer learning approach fails to adapt to unseen languages under extremely few-shot settings, where less than 8 minutes of data is provided. We deal with the problem by proposing a framework that consists of a phoneme-based TTS model and a codebook module to project phonemes from different languages into a learned latent space. Furthermore, by utilizing phoneme-level averaged self-supervised learned features, we effectively improve the quality of synthesized speeches. Experiments show that using 4 utterances, which is about 30 seconds of data, is enough to synthesize intelligible speech when adapting to an unseen language using our framework. ",
    "url": "https://arxiv.org/abs/2206.15427",
    "authors": [
      "Wei-Ping Huang",
      "Po-Chun Chen",
      "Sung-Feng Huang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.15445",
    "title": "Asymmetry Disentanglement Network for Interpretable Acute Ischemic  Stroke Infarct Segmentation in Non-Contrast CT Scans",
    "abstract": "Accurate infarct segmentation in non-contrast CT (NCCT) images is a crucial step toward computer-aided acute ischemic stroke (AIS) assessment. In clinical practice, bilateral symmetric comparison of brain hemispheres is usually used to locate pathological abnormalities. Recent research has explored asymmetries to assist with AIS segmentation. However, most previous symmetry-based work mixed different types of asymmetries when evaluating their contribution to AIS. In this paper, we propose a novel Asymmetry Disentanglement Network (ADN) to automatically separate pathological asymmetries and intrinsic anatomical asymmetries in NCCTs for more effective and interpretable AIS segmentation. ADN first performs asymmetry disentanglement based on input NCCTs, which produces different types of 3D asymmetry maps. Then a synthetic, intrinsic-asymmetry-compensated and pathology-asymmetry-salient NCCT volume is generated and later used as input to a segmentation network. The training of ADN incorporates domain knowledge and adopts a tissue-type aware regularization loss function to encourage clinically-meaningful pathological asymmetry extraction. Coupled with an unsupervised 3D transformation network, ADN achieves state-of-the-art AIS segmentation performance on a public NCCT dataset. In addition to the superior performance, we believe the learned clinically-interpretable asymmetry maps can also provide insights towards a better understanding of AIS assessment. Our code is available at https://github.com/nihaomiao/MICCAI22_ADN. ",
    "url": "https://arxiv.org/abs/2206.15445",
    "authors": [
      "Haomiao Ni",
      "Yuan Xue",
      "Kelvin Wong",
      "John Volpi",
      "Stephen T.C. Wong",
      "James Z. Wang",
      "Xiaolei Huang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.15457",
    "title": "PhySRNet: Physics informed super-resolution network for application in  computational solid mechanics",
    "abstract": "Traditional approaches based on finite element analyses have been successfully used to predict the macro-scale behavior of heterogeneous materials (composites, multicomponent alloys, and polycrystals) widely used in industrial applications. However, this necessitates the mesh size to be smaller than the characteristic length scale of the microstructural heterogeneities in the material leading to computationally expensive and time-consuming calculations. The recent advances in deep learning based image super-resolution (SR) algorithms open up a promising avenue to tackle this computational challenge by enabling researchers to enhance the spatio-temporal resolution of data obtained from coarse mesh simulations. However, technical challenges still remain in developing a high-fidelity SR model for application to computational solid mechanics, especially for materials undergoing large deformation. This work aims at developing a physics-informed deep learning based super-resolution framework (PhySRNet) which enables reconstruction of high-resolution deformation fields (displacement and stress) from their low-resolution counterparts without requiring high-resolution labeled data. We design a synthetic case study to illustrate the effectiveness of the proposed framework and demonstrate that the super-resolved fields match the accuracy of an advanced numerical solver running at 400 times the coarse mesh resolution while simultaneously satisfying the (highly nonlinear) governing laws. The approach opens the door to applying machine learning and traditional numerical approaches in tandem to reduce computational complexity accelerate scientific discovery and engineering design. ",
    "url": "https://arxiv.org/abs/2206.15457",
    "authors": [
      "Rajat Arora"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1901.01632",
    "title": "Exploiting Network Loss for Distributed Approximate Computing with  NetApprox",
    "abstract": " Title: Exploiting Network Loss for Distributed Approximate Computing with  NetApprox ",
    "url": "https://arxiv.org/abs/1901.01632",
    "authors": [
      "Ke Liu",
      "Jinmou Li",
      "Shin-Yeh Tsai",
      "Theophilus Benson",
      "Yiying Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2011.02408",
    "title": "Which Minimizer Does My Neural Network Converge To?",
    "abstract": " Title: Which Minimizer Does My Neural Network Converge To? ",
    "url": "https://arxiv.org/abs/2011.02408",
    "authors": [
      "Manuel Nonnenmacher",
      "David Reeb",
      "Ingo Steinwart"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2011.14599",
    "title": "On the Challenges of Detecting Side-Channel Attacks in SGX",
    "abstract": " Title: On the Challenges of Detecting Side-Channel Attacks in SGX ",
    "url": "https://arxiv.org/abs/2011.14599",
    "authors": [
      "Jianyu Jiang",
      "Claudio Soriente",
      "Ghassan Karame"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2101.12602",
    "title": "On the differential privacy of dynamic location obfuscation with  personalized error bounds",
    "abstract": " Comments: 9 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2101.12602",
    "authors": [
      "Zhang Shun",
      "Duan Benfei",
      "Chen Zhili",
      "Zhong Hong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2103.06102",
    "title": "Effectively Counting s-t Simple Paths in Directed Graphs",
    "abstract": " Title: Effectively Counting s-t Simple Paths in Directed Graphs ",
    "url": "https://arxiv.org/abs/2103.06102",
    "authors": [
      "Mostafa Haghir Chehreghani"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2107.04616",
    "title": "A deep convolutional neural network that is invariant to time rescaling",
    "abstract": " Title: A deep convolutional neural network that is invariant to time rescaling ",
    "url": "https://arxiv.org/abs/2107.04616",
    "authors": [
      "Brandon G. Jacques",
      "Zoran Tiganj",
      "Aakash Sarkar",
      "Marc W. Howard",
      "Per B. Sederberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.08094",
    "title": "LAORAM: A Look Ahead ORAM Architecture for Training Large Embedding  Tables",
    "abstract": " Title: LAORAM: A Look Ahead ORAM Architecture for Training Large Embedding  Tables ",
    "url": "https://arxiv.org/abs/2107.08094",
    "authors": [
      "Rachit Rajat",
      "Yongqin Wang",
      "Murali Annavaram"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2111.11707",
    "title": "Boosting Neural Machine Translation with Dependency-Scaled  Self-Attention Network",
    "abstract": " Title: Boosting Neural Machine Translation with Dependency-Scaled  Self-Attention Network ",
    "url": "https://arxiv.org/abs/2111.11707",
    "authors": [
      "Ru Peng",
      "Nankai Lin",
      "Yi Fang",
      "Shengyi Jiang",
      "Tianyong Hao",
      "Boyu Chen",
      "Junbo Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2201.02593",
    "title": "Equalized Focal Loss for Dense Long-Tailed Object Detection",
    "abstract": " Comments: Accepted by the IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR) 2022 ",
    "url": "https://arxiv.org/abs/2201.02593",
    "authors": [
      "Bo Li",
      "Yongqiang Yao",
      "Jingru Tan",
      "Gang Zhang",
      "Fengwei Yu",
      "Jianwei Lu",
      "Ye Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.11726",
    "title": "Search Trajectories Networks of Multiobjective Evolutionary Algorithms",
    "abstract": " Title: Search Trajectories Networks of Multiobjective Evolutionary Algorithms ",
    "url": "https://arxiv.org/abs/2201.11726",
    "authors": [
      "Yuri Lavinas",
      "Claus Aranha",
      "Gabriela Ochoa"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.00789",
    "title": "Team Belief DAG: A Concise Representation for Team-Correlated  Game-Theoretic Decision Making",
    "abstract": " Title: Team Belief DAG: A Concise Representation for Team-Correlated  Game-Theoretic Decision Making ",
    "url": "https://arxiv.org/abs/2202.00789",
    "authors": [
      "Brian Hu Zhang",
      "Gabriele Farina",
      "Tuomas Sandholm"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2202.01855",
    "title": "Self-supervised Learning with Random-projection Quantizer for Speech  Recognition",
    "abstract": " Comments: ICML 2022 ",
    "url": "https://arxiv.org/abs/2202.01855",
    "authors": [
      "Chung-Cheng Chiu",
      "James Qin",
      "Yu Zhang",
      "Jiahui Yu",
      "Yonghui Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2202.02832",
    "title": "Detecting Melanoma Fairly: Skin Tone Detection and Debiasing for Skin  Lesion Classification",
    "abstract": " Comments: 8 pages ",
    "url": "https://arxiv.org/abs/2202.02832",
    "authors": [
      "Peter J. Bevan",
      "Amir Atapour-Abarghouei"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.08070",
    "title": "On Measuring Excess Capacity in Neural Networks",
    "abstract": " Title: On Measuring Excess Capacity in Neural Networks ",
    "url": "https://arxiv.org/abs/2202.08070",
    "authors": [
      "Florian Graf",
      "Sebastian Zeng",
      "Bastian Rieck",
      "Marc Niethammer",
      "Roland Kwitt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.11948",
    "title": "Domain Disentangled Generative Adversarial Network for Zero-Shot  Sketch-Based 3D Shape Retrieval",
    "abstract": " Comments: Accepted by AAAI 2022 ",
    "url": "https://arxiv.org/abs/2202.11948",
    "authors": [
      "Rui Xu",
      "Zongyan Han",
      "Le Hui",
      "Jianjun Qian",
      "Jin Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.04406",
    "title": "Routing with Privacy for Drone Package Delivery Systems",
    "abstract": " Title: Routing with Privacy for Drone Package Delivery Systems ",
    "url": "https://arxiv.org/abs/2203.04406",
    "authors": [
      "Geoffrey Ding",
      "Alex Berke",
      "Karthik Gopalakrishnan",
      "Kwassi H. Degue",
      "Hamsa Balakrishnan",
      "Max Z. Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.07060",
    "title": "MotionSC: Data Set and Network for Real-Time Semantic Mapping in Dynamic  Environments",
    "abstract": " Title: MotionSC: Data Set and Network for Real-Time Semantic Mapping in Dynamic  Environments ",
    "url": "https://arxiv.org/abs/2203.07060",
    "authors": [
      "Joey Wilson",
      "Jingyu Song",
      "Yuewei Fu",
      "Arthur Zhang",
      "Andrew Capodieci",
      "Paramsothy Jayakumar",
      "Kira Barton",
      "Maani Ghaffari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.09180",
    "title": "A Novel End-To-End Network for Reconstruction of Non-Regularly Sampled  Image Data Using Locally Fully Connected Layers",
    "abstract": " Comments: 6 pages, 5 figures, 2 tables, IEEE 23rd International Workshop on Multimedia Signal Processing (MMSP). arXiv admin note: text overlap with arXiv:2203.00336 ",
    "url": "https://arxiv.org/abs/2203.09180",
    "authors": [
      "Simon Grosche",
      "Fabian Brand",
      "Andr\u00e9 Kaup"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10723",
    "title": "An Intermediate-level Attack Framework on The Basis of Linear Regression",
    "abstract": " Comments: Accepted by TPAMI; Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2203.10723",
    "authors": [
      "Yiwen Guo",
      "Qizhang Li",
      "Wangmeng Zuo",
      "Hao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2203.12905",
    "title": "Privileged Attribution Constrained Deep Networks for Facial Expression  Recognition",
    "abstract": " Title: Privileged Attribution Constrained Deep Networks for Facial Expression  Recognition ",
    "url": "https://arxiv.org/abs/2203.12905",
    "authors": [
      "Jules Bonnard",
      "Arnaud Dapogny",
      "Ferdinand Dhombres",
      "K\u00e9vin Bailly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.14416",
    "title": "Bunched LPCNet2: Efficient Neural Vocoders Covering Devices from Cloud  to Edge",
    "abstract": " Comments: Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2203.14416",
    "authors": [
      "Sangjun Park",
      "Kihyun Choo",
      "Joohyung Lee",
      "Anton V. Porov",
      "Konstantin Osipov",
      "June Sig Sung"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2203.16637",
    "title": "Hybrid Handcrafted and Learnable Audio Representation for Analysis of  Speech Under Cognitive and Physical Load",
    "abstract": " Comments: Submitted to InterSpeech 2022 ",
    "url": "https://arxiv.org/abs/2203.16637",
    "authors": [
      "Gasser Elbanna",
      "Alice Biryukov",
      "Neil Scheidwasser-Clow",
      "Lara Orlandic",
      "Pablo Mainar",
      "Mikolaj Kegler",
      "Pierre Beckmann",
      "Milos Cernak"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.00768",
    "title": "VQTTS: High-Fidelity Text-to-Speech Synthesis with Self-Supervised VQ  Acoustic Feature",
    "abstract": " Comments: Accepted to Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2204.00768",
    "authors": [
      "Chenpeng Du",
      "Yiwei Guo",
      "Xie Chen",
      "Kai Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.02967",
    "title": "Enhanced Direct Speech-to-Speech Translation Using Self-supervised  Pre-training and Data Augmentation",
    "abstract": " Comments: Accepted to be published in the Proceedings of Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2204.02967",
    "authors": [
      "Sravya Popuri",
      "Peng-Jen Chen",
      "Changhan Wang",
      "Juan Pino",
      "Yossi Adi",
      "Jiatao Gu",
      "Wei-Ning Hsu",
      "Ann Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.07230",
    "title": "Learning two-phase microstructure evolution using neural operators and  autoencoder architectures",
    "abstract": " Title: Learning two-phase microstructure evolution using neural operators and  autoencoder architectures ",
    "url": "https://arxiv.org/abs/2204.07230",
    "authors": [
      "Vivek Oommen",
      "Khemraj Shukla",
      "Somdatta Goswami",
      "Remi Dingreville",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2204.07763",
    "title": "UFRC: A Unified Framework for Reliable COVID-19 Detection on  Crowdsourced Cough Audio",
    "abstract": " Title: UFRC: A Unified Framework for Reliable COVID-19 Detection on  Crowdsourced Cough Audio ",
    "url": "https://arxiv.org/abs/2204.07763",
    "authors": [
      "Jiangeng Chang",
      "Yucheng Ruan",
      "Cui Shaoze",
      "John Soong Tshon Yit",
      "Mengling Feng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.09381",
    "title": "Exploration strategies for articulatory synthesis of complex syllable  onsets",
    "abstract": " Comments: Accepted at Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2204.09381",
    "authors": [
      "Daniel R. van Niekerk",
      "Anqi Xu",
      "Branislav Gerazov",
      "Paul K. Krug",
      "Peter Birkholz",
      "Yi Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.11582",
    "title": "Graph-DETR3D: Rethinking Overlapping Regions for Multi-View 3D Object  Detection",
    "abstract": " Comments: Accepted to ACM MM 2022 ",
    "url": "https://arxiv.org/abs/2204.11582",
    "authors": [
      "Zehui Chen",
      "Zhenyu Li",
      "Shiquan Zhang",
      "Liangji Fang",
      "Qinhong Jiang",
      "Feng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01897",
    "title": "Virtual Analog Modeling of Distortion Circuits Using Neural Ordinary  Differential Equations",
    "abstract": " Comments: 8 pages, 10 figures, accepted for DAFx 2022 conference, for associated audio examples, see this https URL ",
    "url": "https://arxiv.org/abs/2205.01897",
    "authors": [
      "Jan Wilczek",
      "Alec Wright",
      "Vesa V\u00e4lim\u00e4ki",
      "Emanu\u00ebl Habets"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.04956",
    "title": "Parallel Batch-Dynamic Minimum Spanning Forest and the Efficiency of  Dynamic Agglomerative Graph Clustering",
    "abstract": " Comments: SPAA 2022 ",
    "url": "https://arxiv.org/abs/2205.04956",
    "authors": [
      "Tom Tseng",
      "Laxman Dhulipala",
      "Julian Shun"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2206.01863",
    "title": "Recursive Deformable Image Registration Network with Mutual Attention",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2203.04290 ",
    "url": "https://arxiv.org/abs/2206.01863",
    "authors": [
      "Jian-Qing Zheng",
      "Ziyang Wang",
      "Baoru Huang",
      "Ngee Han Lim",
      "Tonia Vincent",
      "Bartlomiej W. Papiez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.06174",
    "title": "Predicting Corporate Risk by Jointly Modeling Company Networks and  Dialogues in Earnings Conference Calls",
    "abstract": " Title: Predicting Corporate Risk by Jointly Modeling Company Networks and  Dialogues in Earnings Conference Calls ",
    "url": "https://arxiv.org/abs/2206.06174",
    "authors": [
      "Yunxin Sang",
      "Yang Bao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.06986",
    "title": "Exploring Representation of Horn Clauses using GNNs (Extended Technique  Report)",
    "abstract": " Title: Exploring Representation of Horn Clauses using GNNs (Extended Technique  Report) ",
    "url": "https://arxiv.org/abs/2206.06986",
    "authors": [
      "Chencheng Liang",
      "Philipp R\u00fcmmer",
      "Marc Brockschmidt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09677",
    "title": "GraphFramEx: Towards Systematic Evaluation of Explainability Methods for  Graph Neural Networks",
    "abstract": " Comments: Submitted to Neurips 2022 Conference ",
    "url": "https://arxiv.org/abs/2206.09677",
    "authors": [
      "Kenza Amara",
      "Rex Ying",
      "Zitao Zhang",
      "Zhihao Han",
      "Yinan Shan",
      "Ulrik Brandes",
      "Sebastian Schemm",
      "Ce Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.12038",
    "title": "BYOL-S: Learning Self-supervised Speech Representations by Bootstrapping",
    "abstract": " Comments: Submitted to HEAR-PMLR 2021 ",
    "url": "https://arxiv.org/abs/2206.12038",
    "authors": [
      "Gasser Elbanna",
      "Neil Scheidwasser-Clow",
      "Mikolaj Kegler",
      "Pierre Beckmann",
      "Karl El Hajal",
      "Milos Cernak"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.12901",
    "title": "Noise-aware Physics-informed Machine Learning for Robust PDE Discovery",
    "abstract": " Comments: 13 pages, 8 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice ",
    "url": "https://arxiv.org/abs/2206.12901",
    "authors": [
      "Pongpisit Thanasutives",
      "Takeshi Morita",
      "Masayuki Numao",
      "Ken-ichi Fukui"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2206.13318",
    "title": "Key-frame Guided Network for Thyroid Nodule Recognition using Ultrasound  Videos",
    "abstract": " Title: Key-frame Guided Network for Thyroid Nodule Recognition using Ultrasound  Videos ",
    "url": "https://arxiv.org/abs/2206.13318",
    "authors": [
      "Yuchen Wang",
      "Zhongyu Li",
      "Xiangxiang Cui",
      "Liangliang Zhang",
      "Xiang Luo",
      "Meng Yang",
      "Shi Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.13358",
    "title": "FIDO2 With Two Displays$\\unicode{x2013}$Or How to Protect  Security-Critical Web Transactions Against Malware Attacks",
    "abstract": " Title: FIDO2 With Two Displays$\\unicode{x2013}$Or How to Protect  Security-Critical Web Transactions Against Malware Attacks ",
    "url": "https://arxiv.org/abs/2206.13358",
    "authors": [
      "Timon Hackenjos",
      "Benedikt Wagner",
      "Julian Herr",
      "Jochen Rill",
      "Marek Wehmer",
      "Niklas Goerke",
      "Ingmar Baumgart"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.13689",
    "title": "Tiny-Sepformer: A Tiny Time-Domain Transformer Network for Speech  Separation",
    "abstract": " Comments: Accepted by Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2206.13689",
    "authors": [
      "Jian Luo",
      "Jianzong Wang",
      "Ning Cheng",
      "Edward Xiao",
      "Xulong Zhang",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.13737",
    "title": "Adversarial Consistency for Single Domain Generalization in Medical  Image Segmentation",
    "abstract": " Comments: MICCAI2022 accpted ",
    "url": "https://arxiv.org/abs/2206.13737",
    "authors": [
      "Yanwu Xu",
      "Shaoan Xie",
      "Maxwell Reynolds",
      "Matthew Ragoza",
      "Mingming Gong",
      "Kayhan Batmanghelich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14362",
    "title": "Lower Bounds on the Error Probability for Invariant Causal Prediction",
    "abstract": " Comments: Accepted to the 2022 IEEE International Workshop on Machine Learning for Signal Processing (MLSP) ",
    "url": "https://arxiv.org/abs/2206.14362",
    "authors": [
      "Austin Goddard",
      "Yu Xiang",
      "Ilya Soloveychik"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Methodology (stat.ME)"
    ]
  }
]