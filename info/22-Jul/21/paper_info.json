[
  {
    "id": "arXiv:2207.09453",
    "title": "e3nn: Euclidean Neural Networks",
    "abstract": "We present e3nn, a generalized framework for creating E(3) equivariant trainable functions, also known as Euclidean neural networks. e3nn naturally operates on geometry and geometric tensors that describe systems in 3D and transform predictably under a change of coordinate system. The core of e3nn are equivariant operations such as the TensorProduct class or the spherical harmonics functions that can be composed to create more complex modules such as convolutions and attention mechanisms. These core operations of e3nn can be used to efficiently articulate Tensor Field Networks, 3D Steerable CNNs, Clebsch-Gordan Networks, SE(3) Transformers and other E(3) equivariant networks. ",
    "url": "https://arxiv.org/abs/2207.09453",
    "authors": [
      "Mario Geiger",
      "Tess Smidt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2207.09457",
    "title": "A Deep Learning Framework for Wind Turbine Repair Action Prediction  Using Alarm Sequences and Long Short Term Memory Algorithms",
    "abstract": "With an increasing emphasis on driving down the costs of Operations and Maintenance (O$\\&$M) in the Offshore Wind (OSW) sector, comes the requirement to explore new methodology and applications of Deep Learning (DL) to the domain. Condition-based monitoring (CBM) has been at the forefront of recent research developing alarm-based systems and data-driven decision making. This paper provides a brief insight into the research being conducted in this area, with a specific focus on alarm sequence modelling and the associated challenges faced in its implementation. The paper proposes a novel idea to predict a set of relevant repair actions from an input sequence of alarm sequences, comparing Long Short-term Memory (LSTM) and Bidirectional LSTM (biLSTM) models. Achieving training accuracy results of up to 80.23$\\%$, and test accuracy results of up to 76.01$\\%$ with biLSTM gives a strong indication to the potential benefits of the proposed approach that can be furthered in future research. The paper introduces a framework that integrates the proposed approach into O$\\&$M procedures and discusses the potential benefits which include the reduction of a confusing plethora of alarms, as well as unnecessary vessel transfers to the turbines for fault diagnosis and correction. ",
    "url": "https://arxiv.org/abs/2207.09457",
    "authors": [
      "Connor Walker",
      "Callum Rothon",
      "Koorosh Aslansefat",
      "Yiannis Papadopoulos",
      "Nina Dethlefs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.09459",
    "title": "Contaminant source identification in groundwater by means of artificial  neural network",
    "abstract": "In a desired environmental protection system, groundwater may not be excluded. In addition to the problem of over-exploitation, in total disagreement with the concept of sustainable development, another not negligible issue concerns the groundwater contamination. Mainly, this aspect is due to intensive agricultural activities or industrialized areas. In literature, several papers have dealt with transport problem, especially for inverse problems in which the release history or the source location are identified. The innovative aim of the paper is to develop a data-driven model that is able to analyze multiple scenarios, even strongly non-linear, in order to solve forward and inverse transport problems, preserving the reliability of the results and reducing the uncertainty. Furthermore, this tool has the characteristic of providing extremely fast responses, essential to identify remediation strategies immediately. The advantages produced by the model were compared with literature studies. In this regard, a feedforward artificial neural network, which has been trained to handle different cases, represents the data-driven model. Firstly, to identify the concentration of the pollutant at specific observation points in the study area (forward problem); secondly, to deal with inverse problems identifying the release history at known source location; then, in case of one contaminant source, identifying the release history and, at the same time, the location of the source in a specific sub-domain of the investigated area. At last, the observation error is investigated and estimated. The results are satisfactorily achieved, highlighting the capability of the ANN to deal with multiple scenarios by approximating nonlinear functions without the physical point of view that describes the phenomenon, providing reliable results, with very low computational burden and uncertainty. ",
    "url": "https://arxiv.org/abs/2207.09459",
    "authors": [
      "Daniele Secci",
      "Laura Molino",
      "Andrea Zanini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2207.09460",
    "title": "Money and Trust in Metaverses, Bitcoin and Stablecoins in global social  XR",
    "abstract": "We present a state of the art and positioning book, about Web3, Bitcoin, and `Metaverse'; describing the intersections and synergies. A high level overview of Web3 technologies leads to a description of blockchain, and the Bitcoin network is specifically selected for detailed examination. Suitable components of the extended Bitcoin ecosystem are described in more depth. Other mechanisms for native digital value transfer are described, with a focus on `money'. Metaverse technology is over-viewed, primarily from the perspective of Bitcoin and extended reality.\\par Bitcoin is selected as the best contender for value transfer in metaverses because of it's free and open source nature, and network effect. Challenges and risks of this approach are identified. A cloud deployable virtual machine based technology stack deployment guide with a focus on cybersecurity best practice can be downloaded from GitHub to experiment with the technologies. This deployable lab is designed to inform development of secure value transaction, for small and medium sized companies. ",
    "url": "https://arxiv.org/abs/2207.09460",
    "authors": [
      "John Joseph O'Hare",
      "Allen Fairchild",
      "Umran Ali"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.09511",
    "title": "Approximation Power of Deep Neural Networks: an explanatory mathematical  survey",
    "abstract": "The goal of this survey is to present an explanatory review of the approximation properties of deep neural networks. Specifically, we aim at understanding how and why deep neural networks outperform other classical linear and nonlinear approximation methods. This survey consists of three chapters. In Chapter 1 we review the key ideas and concepts underlying deep networks and their compositional nonlinear structure. We formalize the neural network problem by formulating it as an optimization problem when solving regression and classification problems. We briefly discuss the stochastic gradient descent algorithm and the back-propagation formulas used in solving the optimization problem and address a few issues related to the performance of neural networks, including the choice of activation functions, cost functions, overfitting issues, and regularization. In Chapter 2 we shift our focus to the approximation theory of neural networks. We start with an introduction to the concept of density in polynomial approximation and in particular study the Stone-Weierstrass theorem for real-valued continuous functions. Then, within the framework of linear approximation, we review a few classical results on the density and convergence rate of feedforward networks, followed by more recent developments on the complexity of deep networks in approximating Sobolev functions. In Chapter 3, utilizing nonlinear approximation theory, we further elaborate on the power of depth and approximation superiority of deep ReLU networks over other classical methods of nonlinear approximation. ",
    "url": "https://arxiv.org/abs/2207.09511",
    "authors": [
      "Mohammad Motamed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.09524",
    "title": "Identification and characterization of misinformation superspreaders on  social media",
    "abstract": "The world's digital information ecosystem continues to struggle with the spread of misinformation. Prior work has suggested that users who consistently disseminate a disproportionate amount of low-credibility content -- so-called superspreaders -- are at the center of this problem. We quantitatively confirm this hypothesis and introduce simple metrics to predict the top misinformation superspreaders several months into the future. We then conduct a qualitative review to characterize the most prolific superspreaders and analyze their sharing behaviors. Superspreaders include pundits with large followings, low-credibility media outlets, personal accounts affiliated with those media outlets, and a range of influencers. They are primarily political in nature and use more toxic language than the typical user sharing misinformation. We also find concerning evidence suggesting that Twitter may be overlooking prominent superspreaders. We hope this work will further public understanding of bad actors and promote steps to mitigate their negative impacts on healthy digital discourse. ",
    "url": "https://arxiv.org/abs/2207.09524",
    "authors": [
      "Matthew R. DeVerna",
      "Rachith Aiyappa",
      "Diogo Pacheco",
      "John Bryden",
      "Filippo Menczer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2207.09529",
    "title": "COVID-19 Detection from Respiratory Sounds with Hierarchical Spectrogram  Transformers",
    "abstract": "Monitoring of prevalent airborne diseases such as COVID-19 characteristically involve respiratory assessments. While auscultation is a mainstream method for symptomatic monitoring, its diagnostic utility is hampered by the need for dedicated hospital visits. Continual remote monitoring based on recordings of respiratory sounds on portable devices is a promising alternative, which can assist in screening of COVID-19. In this study, we introduce a novel deep learning approach to distinguish patients with COVID-19 from healthy controls given audio recordings of cough or breathing sounds. The proposed approach leverages a novel hierarchical spectrogram transformer (HST) on spectrogram representations of respiratory sounds. HST embodies self-attention mechanisms over local windows in spectrograms, and window size is progressively grown over model stages to capture local to global context. HST is compared against state-of-the-art conventional and deep-learning baselines. Comprehensive demonstrations on a multi-national dataset indicate that HST outperforms competing methods, achieving over 97% area under the receiver operating characteristic curve (AUC) in detecting COVID-19 cases. ",
    "url": "https://arxiv.org/abs/2207.09529",
    "authors": [
      "Idil Aytekin",
      "Onat Dalmaz",
      "Kaan Gonc",
      "Haydar Ankishan",
      "Emine U Saritas",
      "Ulas Bagci",
      "Haydar Celik",
      "Tolga Cukur"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.09530",
    "title": "Knowledge distillation with a class-aware loss for endoscopic disease  detection",
    "abstract": "Prevalence of gastrointestinal (GI) cancer is growing alarmingly every year leading to a substantial increase in the mortality rate. Endoscopic detection is providing crucial diagnostic support, however, subtle lesions in upper and lower GI are quite hard to detect and cause considerable missed detection. In this work, we leverage deep learning to develop a framework to improve the localization of difficult to detect lesions and minimize the missed detection rate. We propose an end to end student-teacher learning setup where class probabilities of a trained teacher model on one class with larger dataset are used to penalize multi-class student network. Our model achieves higher performance in terms of mean average precision (mAP) on both endoscopic disease detection (EDD2020) challenge and Kvasir-SEG datasets. Additionally, we show that using such learning paradigm, our model is generalizable to unseen test set giving higher APs for clinically crucial neoplastic and polyp categories ",
    "url": "https://arxiv.org/abs/2207.09530",
    "authors": [
      "Pedro E. Chavarrias-Solanon",
      "Mansoor Ali-Teevno",
      "Gilberto Ochoa-Ruiz",
      "Sharib Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.09531",
    "title": "A Block-based Convolutional Neural Network for Low-Resolution Image  Classification",
    "abstract": "The success of CNN-based architecture on image classification in learning and extracting features made them so popular these days, but the task of image classification becomes more challenging when we use state of art models to classify noisy and low-quality images. To solve this problem, we proposed a novel image classification architecture that learns subtle details in low-resolution images that are blurred and noisy. In order to build our new blocks, we used the idea of Res Connections and the Inception module ideas. Using the MNIST datasets, we have conducted extensive experiments that show that the introduced architecture is more accurate and faster than other state-of-the-art Convolutional neural networks. As a result of the special characteristics of our model, it can achieve a better result with fewer parameters. ",
    "url": "https://arxiv.org/abs/2207.09531",
    "authors": [
      "Ashkan Ganj",
      "Mohsen Ebadpour",
      "Mahdi Darvish",
      "Hamid Bahador"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09562",
    "title": "QuoteKG: A Multilingual Knowledge Graph of Quotes",
    "abstract": "Quotes of public figures can mark turning points in history. A quote can explain its originator's actions, foreshadowing political or personal decisions and revealing character traits. Impactful quotes cross language barriers and influence the general population's reaction to specific stances, always facing the risk of being misattributed or taken out of context. The provision of a cross-lingual knowledge graph of quotes that establishes the authenticity of quotes and their contexts is of great importance to allow the exploration of the lives of important people as well as topics from the perspective of what was actually said. In this paper, we present QuoteKG, the first multilingual knowledge graph of quotes. We propose the QuoteKG creation pipeline that extracts quotes from Wikiquote, a free and collaboratively created collection of quotes in many languages, and aligns different mentions of the same quote. QuoteKG includes nearly one million quotes in $55$ languages, said by more than $69,000$ people of public interest across a wide range of topics. QuoteKG is publicly available and can be accessed via a SPARQL endpoint. ",
    "url": "https://arxiv.org/abs/2207.09562",
    "authors": [
      "Tin Kuculo",
      "Simon Gottschalk",
      "Elena Demidova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2207.09572",
    "title": "Towards Robust Multivariate Time-Series Forecasting: Adversarial Attacks  and Defense Mechanisms",
    "abstract": "As deep learning models have gradually become the main workhorse of time series forecasting, the potential vulnerability under adversarial attacks to forecasting and decision system accordingly has emerged as a main issue in recent years. Albeit such behaviors and defense mechanisms started to be investigated for the univariate time series forecasting, there are still few studies regarding the multivariate forecasting which is often preferred due to its capacity to encode correlations between different time series. In this work, we study and design adversarial attack on multivariate probabilistic forecasting models, taking into consideration attack budget constraints and the correlation architecture between multiple time series. Specifically, we investigate a sparse indirect attack that hurts the prediction of an item (time series) by only attacking the history of a small number of other items to save attacking cost. In order to combat these attacks, we also develop two defense strategies. First, we adopt randomized smoothing to multivariate time series scenario and verify its effectiveness via empirical experiments. Second, we leverage a sparse attacker to enable end-to-end adversarial training that delivers robust probabilistic forecasters. Extensive experiments on real dataset confirm that our attack schemes are powerful and our defend algorithms are more effective compared with other baseline defense mechanisms. ",
    "url": "https://arxiv.org/abs/2207.09572",
    "authors": [
      "Linbo Liu",
      "Youngsuk Park",
      "Trong Nghia Hoang",
      "Hilaf Hasson",
      "Jun Huan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.09592",
    "title": "Inclusive Privacy Design for Older Adults Living in Ambient Assisted  Living",
    "abstract": "Ambient assisted living (AAL) environments support independence and quality of life of older adults However, in an AAL environment, privacy-related issues (e.g., unawareness, information disclosure, and lack of support) directly impact older adults and bystanders (e.g., caregivers, service providers, etc.). We explore the privacy challenges that both older adults and bystanders face in AAL. We call for inclusive privacy design and recommend following areas of improvement: consent, notification, and consideration for cultural differences. ",
    "url": "https://arxiv.org/abs/2207.09592",
    "authors": [
      "Nyteisha Bookert",
      "May Almousa",
      "Mohd Anwar"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.09593",
    "title": "Privacy Threats on the Internet of Medical Things",
    "abstract": "The Internet of Medical Things (IoMT) is a frequent target of attacks -- compromising both patient data and healthcare infra-structure. While privacy-enhanced technologies and services (PETS) are developed to mitigate traditional privacy concerns, they cannot be applied without identifying specific threat models. Therefore, our position is that the new threat land-scape created by the relatively new and underexplored IoMT domain must be studied. We briefly discuss specific privacy threats and threat actors in IoMT. Furthermore, we argue that the privacy policy gap needs to be identified for the IoMT threat landscape. ",
    "url": "https://arxiv.org/abs/2207.09593",
    "authors": [
      "Nyteisha Bookert",
      "Mohd Anwar"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.09597",
    "title": "Feasible Adversarial Robust Reinforcement Learning for Underspecified  Environments",
    "abstract": "Robust reinforcement learning (RL) considers the problem of learning policies that perform well in the worst case among a set of possible environment parameter values. In real-world environments, choosing the set of possible values for robust RL can be a difficult task. When that set is specified too narrowly, the agent will be left vulnerable to reasonable parameter values unaccounted for. When specified too broadly, the agent will be too cautious. In this paper, we propose Feasible Adversarial Robust RL (FARR), a method for automatically determining the set of environment parameter values over which to be robust. FARR implicitly defines the set of feasible parameter values as those on which an agent could achieve a benchmark reward given enough training resources. By formulating this problem as a two-player zero-sum game, FARR jointly learns an adversarial distribution over parameter values with feasible support and a policy robust over this feasible parameter set. Using the PSRO algorithm to find an approximate Nash equilibrium in this FARR game, we show that an agent trained with FARR is more robust to feasible adversarial parameter selection than with existing minimax, domain-randomization, and regret objectives in a parameterized gridworld and three MuJoCo control environments. ",
    "url": "https://arxiv.org/abs/2207.09597",
    "authors": [
      "JB Lanier",
      "Stephen McAleer",
      "Pierre Baldi",
      "Roy Fox"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2207.09609",
    "title": "Towards Accurate and Robust Classification in Continuously Transitioning  Industrial Sprays with Mixup",
    "abstract": "Image classification with deep neural networks has seen a surge of technological breakthroughs with promising applications in areas such as face recognition, medical imaging, and autonomous driving. In engineering problems, however, such as high-speed imaging of engine fuel injector sprays or body paint sprays, deep neural networks face a fundamental challenge related to the availability of adequate and diverse data. Typically, only thousands or sometimes even hundreds of samples are available for training. In addition, the transition between different spray classes is a continuum and requires a high level of domain expertise to label the images accurately. In this work, we used Mixup as an approach to systematically deal with the data scarcity and ambiguous class boundaries found in industrial spray applications. We show that data augmentation can mitigate the over-fitting problem of large neural networks on small data sets, to a certain level, but cannot fundamentally resolve the issue. We discuss how a convex linear interpolation of different classes naturally aligns with the continuous transition between different classes in our application. Our experiments demonstrate Mixup as a simple yet effective method to train an accurate and robust deep neural network classifier with only a few hundred samples. ",
    "url": "https://arxiv.org/abs/2207.09609",
    "authors": [
      "Hongjiang Li",
      "Huanyi Shui",
      "Alemayehu Admasu",
      "Praveen Narayanan",
      "Devesh Upadhyay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09613",
    "title": "Exploiting Domain Transferability for Collaborative Inter-level Domain  Adaptive Object Detection",
    "abstract": "Domain adaptation for object detection (DAOD) has recently drawn much attention owing to its capability of detecting target objects without any annotations. To tackle the problem, previous works focus on aligning features extracted from partial levels (e.g., image-level, instance-level, RPN-level) in a two-stage detector via adversarial training. However, individual levels in the object detection pipeline are closely related to each other and this inter-level relation is unconsidered yet. To this end, we introduce a novel framework for DAOD with three proposed components: Multi-scale-aware Uncertainty Attention (MUA), Transferable Region Proposal Network (TRPN), and Dynamic Instance Sampling (DIS). With these modules, we seek to reduce the negative transfer effect during training while maximizing transferability as well as discriminability in both domains. Finally, our framework implicitly learns domain invariant regions for object detection via exploiting the transferable information and enhances the complementarity between different detection levels by collaboratively utilizing their domain information. Through ablation studies and experiments, we show that the proposed modules contribute to the performance improvement in a synergic way, demonstrating the effectiveness of our method. Moreover, our model achieves a new state-of-the-art performance on various benchmarks. ",
    "url": "https://arxiv.org/abs/2207.09613",
    "authors": [
      "Mirae Do",
      "Seogkyu Jeon",
      "Pilhyeon Lee",
      "Kibeom Hong",
      "Yu-seung Ma",
      "Hyeran Byun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09616",
    "title": "Towards Transmission-Friendly and Robust CNN Models over Cloud and  Device",
    "abstract": "Deploying deep convolutional neural network (CNN) models on ubiquitous Internet of Things (IoT) devices has attracted much attention from industry and academia since it greatly facilitates our lives by providing various rapid-response services. Due to the limited resources of IoT devices, cloud-assisted training of CNN models has become the mainstream. However, most existing related works suffer from a large amount of model parameter transmission and weak model robustness. To this end, this paper proposes a cloud-assisted CNN training framework with low model parameter transmission and strong model robustness. In the proposed framework, we first introduce MonoCNN, which contains only a few learnable filters, and other filters are nonlearnable. These nonlearnable filter parameters are generated according to certain rules, i.e., the filter generation function (FGF), and can be saved and reproduced by a few random seeds. Thus, the cloud server only needs to send these learnable filters and a few seeds to the IoT device. Compared to transmitting all model parameters, sending several learnable filter parameters and seeds can significantly reduce parameter transmission. Then, we investigate multiple FGFs and enable the IoT device to use the FGF to generate multiple filters and combine them into MonoCNN. Thus, MonoCNN is affected not only by the training data but also by the FGF. The rules of the FGF play a role in regularizing the MonoCNN, thereby improving its robustness. Experimental results show that compared to state-of-the-art methods, our proposed framework can reduce a large amount of model parameter transfer between the cloud server and the IoT device while improving the performance by approximately 2.2% when dealing with corrupted data. The code is available at https://github.com/evoxlos/mono-cnn-pytorch. ",
    "url": "https://arxiv.org/abs/2207.09616",
    "authors": [
      "Chuntao Ding",
      "Zhichao Lu",
      "Felix Juefei Xu",
      "Vishnu Naresh Boddeti",
      "Yidong Li",
      "Jiannong Cao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2207.09634",
    "title": "HyperNet: Self-Supervised Hyperspectral Spatial-Spectral Feature  Understanding Network for Hyperspectral Change Detection",
    "abstract": "The fast development of self-supervised learning lowers the bar learning feature representation from massive unlabeled data and has triggered a series of research on change detection of remote sensing images. Challenges in adapting self-supervised learning from natural images classification to remote sensing images change detection arise from difference between the two tasks. The learned patch-level feature representations are not satisfying for the pixel-level precise change detection. In this paper, we proposed a novel pixel-level self-supervised hyperspectral spatial-spectral understanding network (HyperNet) to accomplish pixel-wise feature representation for effective hyperspectral change detection. Concretely, not patches but the whole images are fed into the network and the multi-temporal spatial-spectral features are compared pixel by pixel. Instead of processing the two-dimensional imaging space and spectral response dimension in hybrid style, a powerful spatial-spectral attention module is put forward to explore the spatial correlation and discriminative spectral features of multi-temporal hyperspectral images (HSIs), separately. Only the positive samples at the same location of bi-temporal HSIs are created and forced to be aligned, aiming at learning the spectral difference-invariant features. Moreover, a new similarity loss function named focal cosine is proposed to solve the problem of imbalanced easy and hard positive samples comparison, where the weights of those hard samples are enlarged and highlighted to promote the network training. Six hyperspectral datasets have been adopted to test the validity and generalization of proposed HyperNet. The extensive experiments demonstrate the superiority of HyperNet over the state-of-the-art algorithms on downstream hyperspectral change detection tasks. ",
    "url": "https://arxiv.org/abs/2207.09634",
    "authors": [
      "Meiqi Hu",
      "Chen Wu",
      "Liangpei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09643",
    "title": "Integrating Linguistic Theory and Neural Language Models",
    "abstract": "Transformer-based language models have recently achieved remarkable results in many natural language tasks. However, performance on leaderboards is generally achieved by leveraging massive amounts of training data, and rarely by encoding explicit linguistic knowledge into neural models. This has led many to question the relevance of linguistics for modern natural language processing. In this dissertation, I present several case studies to illustrate how theoretical linguistics and neural language models are still relevant to each other. First, language models are useful to linguists by providing an objective tool to measure semantic distance, which is difficult to do using traditional methods. On the other hand, linguistic theory contributes to language modelling research by providing frameworks and sources of data to probe our language models for specific aspects of language understanding. This thesis contributes three studies that explore different aspects of the syntax-semantics interface in language models. In the first part of my thesis, I apply language models to the problem of word class flexibility. Using mBERT as a source of semantic distance measurements, I present evidence in favour of analyzing word class flexibility as a directional process. In the second part of my thesis, I propose a method to measure surprisal at intermediate layers of language models. My experiments show that sentences containing morphosyntactic anomalies trigger surprisals earlier in language models than semantic and commonsense anomalies. Finally, in the third part of my thesis, I adapt several psycholinguistic studies to show that language models contain knowledge of argument structure constructions. In summary, my thesis develops new connections between natural language processing, linguistic theory, and psycholinguistics to provide fresh perspectives for the interpretation of language models. ",
    "url": "https://arxiv.org/abs/2207.09643",
    "authors": [
      "Bai Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.09644",
    "title": "Hierarchically Self-Supervised Transformer for Human Skeleton  Representation Learning",
    "abstract": "Despite the success of fully-supervised human skeleton sequence modeling, utilizing self-supervised pre-training for skeleton sequence representation learning has been an active field because acquiring task-specific skeleton annotations at large scales is difficult. Recent studies focus on learning video-level temporal and discriminative information using contrastive learning, but overlook the hierarchical spatial-temporal nature of human skeletons. Different from such superficial supervision at the video level, we propose a self-supervised hierarchical pre-training scheme incorporated into a hierarchical Transformer-based skeleton sequence encoder (Hi-TRS), to explicitly capture spatial, short-term, and long-term temporal dependencies at frame, clip, and video levels, respectively. To evaluate the proposed self-supervised pre-training scheme with Hi-TRS, we conduct extensive experiments covering three skeleton-based downstream tasks including action recognition, action detection, and motion prediction. Under both supervised and semi-supervised evaluation protocols, our method achieves the state-of-the-art performance. Additionally, we demonstrate that the prior knowledge learned by our model in the pre-training stage has strong transfer capability for different downstream tasks. ",
    "url": "https://arxiv.org/abs/2207.09644",
    "authors": [
      "Yuxiao Chen",
      "Long Zhao",
      "Jianbo Yuan",
      "Yu Tian",
      "Zhaoyang Xia",
      "Shijie Geng",
      "Ligong Han",
      "Dimitris N. Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09663",
    "title": "Streamable Neural Fields",
    "abstract": "Neural fields have emerged as a new data representation paradigm and have shown remarkable success in various signal representations. Since they preserve signals in their network parameters, the data transfer by sending and receiving the entire model parameters prevents this emerging technology from being used in many practical scenarios. We propose streamable neural fields, a single model that consists of executable sub-networks of various widths. The proposed architectural and training techniques enable a single network to be streamable over time and reconstruct different qualities and parts of signals. For example, a smaller sub-network produces smooth and low-frequency signals, while a larger sub-network can represent fine details. Experimental results have shown the effectiveness of our method in various domains, such as 2D images, videos, and 3D signed distance functions. Finally, we demonstrate that our proposed method improves training stability, by exploiting parameter sharing. ",
    "url": "https://arxiv.org/abs/2207.09663",
    "authors": [
      "Junwoo Cho",
      "Seungtae Nam",
      "Daniel Rho",
      "Jong Hwan Ko",
      "Eunbyung Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09667",
    "title": "Generalizable and Robust Deep Learning Algorithm for Atrial Fibrillation  Diagnosis Across Ethnicities, Ages and Sexes",
    "abstract": "To drive health innovation that meets the needs of all and democratize healthcare, there is a need to assess the generalization performance of deep learning (DL) algorithms across various distribution shifts to ensure that these algorithms are robust. This retrospective study is, to the best of our knowledge, the first to develop and assess the generalization performance of a deep learning (DL) model for AF events detection from long term beat-to-beat intervals across ethnicities, ages and sexes. The new recurrent DL model, denoted ArNet2, was developed on a large retrospective dataset of 2,147 patients totaling 51,386 hours of continuous electrocardiogram (ECG). The models generalization was evaluated on manually annotated test sets from four centers (USA, Israel, Japan and China) totaling 402 patients. The model was further validated on a retrospective dataset of 1,730 consecutives Holter recordings from the Rambam Hospital Holter clinic, Haifa, Israel. The model outperformed benchmark state-of-the-art models and generalized well across ethnicities, ages and sexes. Performance was higher for female than male and young adults (less than 60 years old) and showed some differences across ethnicities. The main finding explaining these variations was an impairment in performance in groups with a higher prevalence of atrial flutter (AFL). Our findings on the relative performance of ArNet2 across groups may have clinical implications on the choice of the preferred AF examination method to use relative to the group of interest. ",
    "url": "https://arxiv.org/abs/2207.09667",
    "authors": [
      "Shany Biton",
      "Mohsin Aldhafeeri",
      "Erez Marcusohn",
      "Kenta Tsutsui",
      "Tom Szwagier",
      "Adi Elias",
      "Julien Oster",
      "Jean Marc Sellal",
      "Mahmoud Suleiman",
      "Joachim A. Behar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2207.09672",
    "title": "Duplicate Detection as a Service",
    "abstract": "Completeness of a knowledge graph is an important quality dimension and factor on how well an application that makes use of it performs. Completeness can be improved by performing knowledge enrichment. Duplicate detection aims to find identity links between the instances of knowledge graphs and is a fundamental subtask of knowledge enrichment. Current solutions to the problem require expert knowledge of the tool and the knowledge graph they are applied to. Users might not have this expert knowledge. We present our service-based approach to the duplicate detection task that provides an easy-to-use no-code solution that is still competitive with the state-of-the-art and has recently been adopted in an industrial context. The evaluation will be based on several frequently used test scenarios. ",
    "url": "https://arxiv.org/abs/2207.09672",
    "authors": [
      "Juliette Opdenplatz",
      "Umutcan \u015eim\u015fek",
      "Dieter Fensel"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2207.09674",
    "title": "Improving Data Driven Inverse Text Normalization using Data Augmentation",
    "abstract": "Inverse text normalization (ITN) is used to convert the spoken form output of an automatic speech recognition (ASR) system to a written form. Traditional handcrafted ITN rules can be complex to transcribe and maintain. Meanwhile neural modeling approaches require quality large-scale spoken-written pair examples in the same or similar domain as the ASR system (in-domain data), to train. Both these approaches require costly and complex annotations. In this paper, we present a data augmentation technique that effectively generates rich spoken-written numeric pairs from out-of-domain textual data with minimal human annotation. We empirically demonstrate that ITN model trained using our data augmentation technique consistently outperform ITN model trained using only in-domain data across all numeric surfaces like cardinal, currency, and fraction, by an overall accuracy of 14.44%. ",
    "url": "https://arxiv.org/abs/2207.09674",
    "authors": [
      "Laxmi Pandey",
      "Debjyoti Paul",
      "Pooja Chitkara",
      "Yutong Pang",
      "Xuedong Zhang",
      "Kjell Schubert",
      "Mark Chou",
      "Shu Liu",
      "Yatharth Saraf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.09675",
    "title": "ERA: Expert Retrieval and Assembly for Early Action Prediction",
    "abstract": "Early action prediction aims to successfully predict the class label of an action before it is completely performed. This is a challenging task because the beginning stages of different actions can be very similar, with only minor subtle differences for discrimination. In this paper, we propose a novel Expert Retrieval and Assembly (ERA) module that retrieves and assembles a set of experts most specialized at using discriminative subtle differences, to distinguish an input sample from other highly similar samples. To encourage our model to effectively use subtle differences for early action prediction, we push experts to discriminate exclusively between samples that are highly similar, forcing these experts to learn to use subtle differences that exist between those samples. Additionally, we design an effective Expert Learning Rate Optimization method that balances the experts' optimization and leads to better performance. We evaluate our ERA module on four public action datasets and achieve state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2207.09675",
    "authors": [
      "Lin Geng Foo",
      "Tianjiao Li",
      "Hossein Rahmani",
      "Qiuhong Ke",
      "Jun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09679",
    "title": "Explaining Deepfake Detection by Analysing Image Matching",
    "abstract": "This paper aims to interpret how deepfake detection models learn artifact features of images when just supervised by binary labels. To this end, three hypotheses from the perspective of image matching are proposed as follows. 1. Deepfake detection models indicate real/fake images based on visual concepts that are neither source-relevant nor target-relevant, that is, considering such visual concepts as artifact-relevant. 2. Besides the supervision of binary labels, deepfake detection models implicitly learn artifact-relevant visual concepts through the FST-Matching (i.e. the matching fake, source, target images) in the training set. 3. Implicitly learned artifact visual concepts through the FST-Matching in the raw training set are vulnerable to video compression. In experiments, the above hypotheses are verified among various DNNs. Furthermore, based on this understanding, we propose the FST-Matching Deepfake Detection Model to boost the performance of forgery detection on compressed videos. Experiment results show that our method achieves great performance, especially on highly-compressed (e.g. c40) videos. ",
    "url": "https://arxiv.org/abs/2207.09679",
    "authors": [
      "Shichao Dong",
      "Jin Wang",
      "Jiajun Liang",
      "Haoqiang Fan",
      "Renhe Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09686",
    "title": "Object-Compositional Neural Implicit Surfaces",
    "abstract": "The neural implicit representation has shown its effectiveness in novel view synthesis and high-quality 3D reconstruction from multi-view images. However, most approaches focus on holistic scene representation yet ignore individual objects inside it, thus limiting potential downstream applications. In order to learn object-compositional representation, a few works incorporate the 2D semantic map as a cue in training to grasp the difference between objects. But they neglect the strong connections between object geometry and instance semantic information, which leads to inaccurate modeling of individual instance. This paper proposes a novel framework, ObjectSDF, to build an object-compositional neural implicit representation with high fidelity in 3D reconstruction and object representation. Observing the ambiguity of conventional volume rendering pipelines, we model the scene by combining the Signed Distance Functions (SDF) of individual object to exert explicit surface constraint. The key in distinguishing different instances is to revisit the strong association between an individual object's SDF and semantic label. Particularly, we convert the semantic information to a function of object SDF and develop a unified and compact representation for scene and objects. Experimental results show the superiority of ObjectSDF framework in representing both the holistic object-compositional scene and the individual instances. Code can be found at https://qianyiwu.github.io/objectsdf/ ",
    "url": "https://arxiv.org/abs/2207.09686",
    "authors": [
      "Qianyi Wu",
      "Xian Liu",
      "Yuedong Chen",
      "Kejie Li",
      "Chuanxia Zheng",
      "Jianfei Cai",
      "Jianmin Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09691",
    "title": "Efficient Meta-Tuning for Content-aware Neural Video Delivery",
    "abstract": "Recently, Deep Neural Networks (DNNs) are utilized to reduce the bandwidth and improve the quality of Internet video delivery. Existing methods train corresponding content-aware super-resolution (SR) model for each video chunk on the server, and stream low-resolution (LR) video chunks along with SR models to the client. Although they achieve promising results, the huge computational cost of network training limits their practical applications. In this paper, we present a method named Efficient Meta-Tuning (EMT) to reduce the computational cost. Instead of training from scratch, EMT adapts a meta-learned model to the first chunk of the input video. As for the following chunks, it fine-tunes the partial parameters selected by gradient masking of previous adapted model. In order to achieve further speedup for EMT, we propose a novel sampling strategy to extract the most challenging patches from video frames. The proposed strategy is highly efficient and brings negligible additional cost. Our method significantly reduces the computational cost and achieves even better performance, paving the way for applying neural video delivery techniques to practical applications. We conduct extensive experiments based on various efficient SR architectures, including ESPCN, SRCNN, FSRCNN and EDSR-1, demonstrating the generalization ability of our work. The code is released at \\url{https://github.com/Neural-video-delivery/EMT-Pytorch-ECCV2022}. ",
    "url": "https://arxiv.org/abs/2207.09691",
    "authors": [
      "Xiaoqi Li",
      "Jiaming Liu",
      "Shizun Wang",
      "Cheng Lyu",
      "Ming Lu",
      "Yurong Chen",
      "Anbang Yao",
      "Yandong Guo",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.09693",
    "title": "Correntropy-Based Logistic Regression with Automatic Relevance  Determination for Robust Sparse Brain Activity Decoding",
    "abstract": "Recent studies have utilized sparse classifications to predict categorical variables from high-dimensional brain activity signals to expose human's intentions and mental states, selecting the relevant features automatically in the model training process. However, existing sparse classification models will likely be prone to the performance degradation which is caused by noise inherent in the brain recordings. To address this issue, we aim to propose a new robust and sparse classification algorithm in this study. To this end, we introduce the correntropy learning framework into the automatic relevance determination based sparse classification model, proposing a new correntropy-based robust sparse logistic regression algorithm. To demonstrate the superior brain activity decoding performance of the proposed algorithm, we evaluate it on a synthetic dataset, an electroencephalogram (EEG) dataset, and a functional magnetic resonance imaging (fMRI) dataset. The extensive experimental results confirm that not only the proposed method can achieve higher classification accuracy in a noisy and high-dimensional classification task, but also it would select those more informative features for the decoding scenarios. Integrating the correntropy learning approach with the automatic relevance determination technique will significantly improve the robustness with respect to the noise, leading to more adequate robust sparse brain decoding algorithm. It provides a more powerful approach in the real-world brain activity decoding and the brain-computer interfaces. ",
    "url": "https://arxiv.org/abs/2207.09693",
    "authors": [
      "Yuanhao Li",
      "Badong Chen",
      "Yuxi Shi",
      "Natsue Yoshimura",
      "Yasuharu Koike"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2207.09697",
    "title": "Robust Object Detection With Inaccurate Bounding Boxes",
    "abstract": "Learning accurate object detectors often requires large-scale training data with precise object bounding boxes. However, labeling such data is expensive and time-consuming. As the crowd-sourcing labeling process and the ambiguities of the objects may raise noisy bounding box annotations, the object detectors will suffer from the degenerated training data. In this work, we aim to address the challenge of learning robust object detectors with inaccurate bounding boxes. Inspired by the fact that localization precision suffers significantly from inaccurate bounding boxes while classification accuracy is less affected, we propose leveraging classification as a guidance signal for refining localization results. Specifically, by treating an object as a bag of instances, we introduce an Object-Aware Multiple Instance Learning approach (OA-MIL), featured with object-aware instance selection and object-aware instance extension. The former aims to select accurate instances for training, instead of directly using inaccurate box annotations. The latter focuses on generating high-quality instances for selection. Extensive experiments on synthetic noisy datasets (i.e., noisy PASCAL VOC and MS-COCO) and a real noisy wheat head dataset demonstrate the effectiveness of our OA-MIL. Code is available at https://github.com/cxliu0/OA-MIL. ",
    "url": "https://arxiv.org/abs/2207.09697",
    "authors": [
      "Chengxin Liu",
      "Kewei Wang",
      "Hao Lu",
      "Zhiguo Cao",
      "Ziming Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09705",
    "title": "Resolving Copycat Problems in Visual Imitation Learning via Residual  Action Prediction",
    "abstract": "Imitation learning is a widely used policy learning method that enables intelligent agents to acquire complex skills from expert demonstrations. The input to the imitation learning algorithm is usually composed of both the current observation and historical observations since the most recent observation might not contain enough information. This is especially the case with image observations, where a single image only includes one view of the scene, and it suffers from a lack of motion information and object occlusions. In theory, providing multiple observations to the imitation learning agent will lead to better performance. However, surprisingly people find that sometimes imitation from observation histories performs worse than imitation from the most recent observation. In this paper, we explain this phenomenon from the information flow within the neural network perspective. We also propose a novel imitation learning neural network architecture that does not suffer from this issue by design. Furthermore, our method scales to high-dimensional image observations. Finally, we benchmark our approach on two widely used simulators, CARLA and MuJoCo, and it successfully alleviates the copycat problem and surpasses the existing solutions. ",
    "url": "https://arxiv.org/abs/2207.09705",
    "authors": [
      "Chia-Chi Chuang",
      "Donglin Yang",
      "Chuan Wen",
      "Yang Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09710",
    "title": "Learning Sequence Representations by Non-local Recurrent Neural Memory",
    "abstract": "The key challenge of sequence representation learning is to capture the long-range temporal dependencies. Typical methods for supervised sequence representation learning are built upon recurrent neural networks to capture temporal dependencies. One potential limitation of these methods is that they only model one-order information interactions explicitly between adjacent time steps in a sequence, hence the high-order interactions between nonadjacent time steps are not fully exploited. It greatly limits the capability of modeling the long-range temporal dependencies since the temporal features learned by one-order interactions cannot be maintained for a long term due to temporal information dilution and gradient vanishing. To tackle this limitation, we propose the Non-local Recurrent Neural Memory (NRNM) for supervised sequence representation learning, which performs non-local operations \\MR{by means of self-attention mechanism} to learn full-order interactions within a sliding temporal memory block and models global interactions between memory blocks in a gated recurrent manner. Consequently, our model is able to capture long-range dependencies. Besides, the latent high-level features contained in high-order interactions can be distilled by our model. We validate the effectiveness and generalization of our NRNM on three types of sequence applications across different modalities, including sequence classification, step-wise sequential prediction and sequence similarity learning. Our model compares favorably against other state-of-the-art methods specifically designed for each of these sequence applications. ",
    "url": "https://arxiv.org/abs/2207.09710",
    "authors": [
      "Wenjie Pei",
      "Xin Feng",
      "Canmiao Fu",
      "Qiong Cao",
      "Guangming Lu",
      "Yu-Wing Tai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09721",
    "title": "Feature Representation Learning for Unsupervised Cross-domain Image  Retrieval",
    "abstract": "Current supervised cross-domain image retrieval methods can achieve excellent performance. However, the cost of data collection and labeling imposes an intractable barrier to practical deployment in real applications. In this paper, we investigate the unsupervised cross-domain image retrieval task, where class labels and pairing annotations are no longer a prerequisite for training. This is an extremely challenging task because there is no supervision for both in-domain feature representation learning and cross-domain alignment. We address both challenges by introducing: 1) a new cluster-wise contrastive learning mechanism to help extract class semantic-aware features, and 2) a novel distance-of-distance loss to effectively measure and minimize the domain discrepancy without any external supervision. Experiments on the Office-Home and DomainNet datasets consistently show the superior image retrieval accuracies of our framework over state-of-the-art approaches. Our source code can be found at https://github.com/conghuihu/UCDIR. ",
    "url": "https://arxiv.org/abs/2207.09721",
    "authors": [
      "Conghui Hu",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09728",
    "title": "Revisiting data augmentation for subspace clustering",
    "abstract": "Subspace clustering is the classical problem of clustering a collection of data samples that approximately lie around several low-dimensional subspaces. The current state-of-the-art approaches for this problem are based on the self-expressive model which represents the samples as linear combination of other samples. However, these approaches require sufficiently well-spread samples for accurate representation which might not be necessarily accessible in many applications. In this paper, we shed light on this commonly neglected issue and argue that data distribution within each subspace plays a critical role in the success of self-expressive models. Our proposed solution to tackle this issue is motivated by the central role of data augmentation in the generalization power of deep neural networks. We propose two subspace clustering frameworks for both unsupervised and semi-supervised settings that use augmented samples as an enlarged dictionary to improve the quality of the self-expressive representation. We present an automatic augmentation strategy using a few labeled samples for the semi-supervised problem relying on the fact that the data samples lie in the union of multiple linear subspaces. Experimental results confirm the effectiveness of data augmentation, as it significantly improves the performance of general self-expressive models. ",
    "url": "https://arxiv.org/abs/2207.09728",
    "authors": [
      "Maryam Abdolali",
      "Nicolas Gillis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.09744",
    "title": "MLMSA: Multi-Label Multi-Side-Channel-Information enabled Deep Learning  Attacks on APUF Variants",
    "abstract": "To improve the modeling resilience of silicon strong physical unclonable functions (PUFs), in particular, the APUFs, that yield a very large number of challenge response pairs (CRPs), a number of composited APUF variants such as XOR-APUF, interpose-PUF (iPUF), feed-forward APUF (FF-APUF),and OAX-APUF have been devised. When examining their security in terms of modeling resilience, utilizing multiple information sources such as power side channel information (SCI) or/and reliability SCI given a challenge is under-explored, which poses a challenge to their supposed modeling resilience in practice. Building upon multi-label/head deep learning model architecture,this work proposes Multi-Label Multi-Side-channel-information enabled deep learning Attacks (MLMSA) to thoroughly evaluate the modeling resilience of aforementioned APUF variants. Despite its simplicity, MLMSA can successfully break large-scaled APUF variants, which has not previously been achieved. More precisely, the MLMSA breaks 128-stage 30-XOR-APUF, (9, 9)- and (2, 18)-iPUFs, and (2, 2, 30)-OAX-APUF when CRPs, power SCI and reliability SCI are concurrently used. It breaks 128-stage 12-XOR-APUF and (2, 2, 9)-OAX-APUF even when only the easy-to-obtain reliability SCI and CRPs are exploited. The 128-stage six-loop FF-APUF and one-loop 20-XOR-FF-APUF can be broken by simultaneously using reliability SCI and CRPs. All these attacks are normally completed within an hour with a standard personalcomputer. Therefore, MLMSA is a useful technique for evaluating other existing or any emerging strong PUF designs. ",
    "url": "https://arxiv.org/abs/2207.09744",
    "authors": [
      "Yansong Gao",
      "Jianrong Yao",
      "Lihui Pang",
      "Wei Yang",
      "Anmin Fu",
      "Said F. Al-Sarawi",
      "Derek Abbott"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.09746",
    "title": "Can Causal (and Counterfactual) Reasoning improve Privacy Threat  Modelling?",
    "abstract": "Causal questions often permeate in our day-to-day activities. With causal reasoning and counterfactual intuition, privacy threats can not only be alleviated but also prevented. In this paper, we discuss what is causal and counterfactual reasoning and how this can be applied in the field of privacy threat modelling (PTM). We believe that the future of PTM relies on how we can causally and counterfactually imagine cybersecurity threats and incidents. ",
    "url": "https://arxiv.org/abs/2207.09746",
    "authors": [
      "Rakshit Naidu",
      "Navid Kagalwalla"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2207.09750",
    "title": "Fair Context-Aware Privacy Threat Modelling",
    "abstract": "Given the progressive nature of the world today, fairness is a very important social aspect in various areas, and it has long been studied with the advent of technology. To the best of our knowledge, methods of quantifying fairness errors and fairness in privacy threat models have been absent. To this end, in this short paper, we examine notions of fairness in privacy threat modelling due to different causes of privacy threats within a particular situation/context and that across contexts. ",
    "url": "https://arxiv.org/abs/2207.09750",
    "authors": [
      "Saswat Das",
      "Rakshit Naidu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.09769",
    "title": "A Hybrid Convolutional Neural Network with Meta Feature Learning for  Abnormality Detection in Wireless Capsule Endoscopy Images",
    "abstract": "Wireless Capsule Endoscopy is one of the most advanced non-invasive methods for the examination of gastrointestinal tracts. An intelligent computer-aided diagnostic system for detecting gastrointestinal abnormalities like polyp, bleeding, inflammation, etc. is highly exigent in wireless capsule endoscopy image analysis. Abnormalities greatly differ in their shape, size, color, and texture, and some appear to be visually similar to normal regions. This poses a challenge in designing a binary classifier due to intra-class variations. In this study, a hybrid convolutional neural network is proposed for abnormality detection that extracts a rich pool of meaningful features from wireless capsule endoscopy images using a variety of convolution operations. It consists of three parallel convolutional neural networks, each with a distinctive feature learning capability. The first network utilizes depthwise separable convolution, while the second employs cosine normalized convolution operation. A novel meta-feature extraction mechanism is introduced in the third network, to extract patterns from the statistical information drawn over the features generated from the first and second networks and its own previous layer. The network trio effectively handles intra-class variance and efficiently detects gastrointestinal abnormalities. The proposed hybrid convolutional neural network model is trained and tested on two widely used publicly available datasets. The test results demonstrate that the proposed model outperforms six state-of-the-art methods with 97\\% and 98\\% classification accuracy on KID and Kvasir-Capsule datasets respectively. Cross dataset evaluation results also demonstrate the generalization performance of the proposed model. ",
    "url": "https://arxiv.org/abs/2207.09769",
    "authors": [
      "Samir Jain",
      "Ayan Seal",
      "Aparajita Ojha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.09777",
    "title": "AU-Supervised Convolutional Vision Transformers for Synthetic Facial  Expression Recognition",
    "abstract": "The paper describes our proposed methodology for the six basic expression classification track of Affective Behavior Analysis in-the-wild (ABAW) Competition 2022. In Learing from Synthetic Data(LSD) task, facial expression recognition (FER) methods aim to learn the representation of expression from the artificially generated data and generalise to real data. Because of the ambiguous of the synthetic data and the objectivity of the facial Action Unit (AU), we resort to the AU information for performance boosting, and make contributions as follows. First, to adapt the model to synthetic scenarios, we use the knowledge from pre-trained large-scale face recognition data. Second, we propose a conceptually-new framework, termed as AU-Supervised Convolutional Vision Transformers (AU-CVT), which clearly improves the performance of FER by jointly training auxiliary datasets with AU or pseudo AU labels. Our AU-CVT achieved F1 score as $0.6863$, accuracy as $0.7433$ on the validation set. The source code of our work is publicly available online: https://github.com/msy1412/ABAW4 ",
    "url": "https://arxiv.org/abs/2207.09777",
    "authors": [
      "Shuyi Mao",
      "Xinpeng Li",
      "Junyao Chen",
      "Xiaojiang Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09784",
    "title": "Anomaly Detection of Smart Metering System for Power Management with  Battery Storage System/Electric Vehicle",
    "abstract": "A novel smart metering technique capable of anomaly detection was proposed for real-time home power management system. Smart meter data generated in real-time was obtained from 900 households of single apartments. To detect outliers and missing values in smart meter data, a deep learning model, the autoencoder, consisting of a graph convolutional network and bidirectional long short-term memory network, was applied to the smart metering technique. Power management based on the smart metering technique was performed by multi-objective optimization in the presence of a battery storage system and an electric vehicle. The results of the power management employing the proposed smart metering technique indicate a reduction in electricity cost and amount of power supplied by the grid compared to the results of power management without anomaly detection. ",
    "url": "https://arxiv.org/abs/2207.09784",
    "authors": [
      "Sangkeum Lee",
      "Sarvar Hussain Nengroo",
      "Hojun Jin",
      "Yoonmee Doh",
      "Chungho Lee",
      "Taewook Heo",
      "Dongsoo Har"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.09792",
    "title": "Unsupervised Industrial Anomaly Detection via Pattern Generative and  Contrastive Networks",
    "abstract": "It is hard to collect enough flaw images for training deep learning network in industrial production. Therefore, existing industrial anomaly detection methods prefer to use CNN-based unsupervised detection and localization network to achieve this task. However, these methods always fail when there are varieties happened in new signals since traditional end-to-end networks suffer barriers of fitting nonlinear model in high-dimensional space. Moreover, they have a memory library by clustering the feature of normal images essentially, which cause it is not robust to texture change. To this end, we propose the Vision Transformer based (VIT-based) unsupervised anomaly detection network. It utilizes a hierarchical task learning and human experience to enhance its interpretability. Our network consists of pattern generation and comparison networks. Pattern generation network uses two VIT-based encoder modules to extract the feature of two consecutive image patches, then uses VIT-based decoder module to learn the human designed style of these features and predict the third image patch. After this, we use the Siamese-based network to compute the similarity of the generation image patch and original image patch. Finally, we refine the anomaly localization by the bi-directional inference strategy. Comparison experiments on public dataset MVTec dataset show our method achieves 99.8% AUC, which surpasses previous state-of-the-art methods. In addition, we give a qualitative illustration on our own leather and cloth datasets. The accurate segment results strongly prove the accuracy of our method in anomaly detection. ",
    "url": "https://arxiv.org/abs/2207.09792",
    "authors": [
      "Jianfeng Huang",
      "Chenyang Li",
      "Yimin Lin",
      "Shiguo Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.09796",
    "title": "EASNet: Searching Elastic and Accurate Network Architecture for Stereo  Matching",
    "abstract": "Recent advanced studies have spent considerable human efforts on optimizing network architectures for stereo matching but hardly achieved both high accuracy and fast inference speed. To ease the workload in network design, neural architecture search (NAS) has been applied with great success to various sparse prediction tasks, such as image classification and object detection. However, existing NAS studies on the dense prediction task, especially stereo matching, still cannot be efficiently and effectively deployed on devices of different computing capabilities. To this end, we propose to train an elastic and accurate network for stereo matching (EASNet) that supports various 3D architectural settings on devices with different computing capabilities. Given the deployment latency constraint on the target device, we can quickly extract a sub-network from the full EASNet without additional training while the accuracy of the sub-network can still be maintained. Extensive experiments show that our EASNet outperforms both state-of-the-art human-designed and NAS-based architectures on Scene Flow and MPI Sintel datasets in terms of model accuracy and inference speed. Particularly, deployed on an inference GPU, EASNet achieves a new SOTA 0.73 EPE on the Scene Flow dataset with 100 ms, which is 4.5$\\times$ faster than LEAStereo with a better quality model. ",
    "url": "https://arxiv.org/abs/2207.09796",
    "authors": [
      "Qiang Wang",
      "Shaohuai Shi",
      "Kaiyong Zhao",
      "Xiaowen Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.09800",
    "title": "The community structure of collaboration networks in computer science  and its impact on scientific production and consumption",
    "abstract": "Collaboration networks, where nodes represent authors and edges coauthorships among them, are key to understanding the consumption, production, and diffusion of knowledge. Due to social mechanisms, biases, and constraints at play, these networks are organized in tight communities with different levels of segregation. Here, we aim to quantify the extent and impact of segregation in collaboration networks. We study the field of Computer Science via the Semantic Scholar Open Research Corpus. We measure the segregation of communities using the Spectral Segregation Index (SSI) and find three categories: non-segregated, moderately segregated, and highly segregated communities. We focus our attention on non-segregated and highly segregated communities, quantifying and comparing their structural topology and core location. When we consider communities of both categories in the same size range, our results show no differences in density and clustering, but evident variability in their core position. As community size increases, communities are more likely to occupy a core closer to the network nucleus. However, controlling for size, highly segregated communities tend to be located closer to the network periphery than non-segregated communities. Finally, we analyse differences in citations gained by researchers depending on their community segregation level. Interestingly, researchers in highly segregated communities gain more citations per publication when located in the periphery. They have a higher chance of receiving citations from members of their same community in all cores. Researchers in non-segregated communities accrue more citations per publication in intermediary and central cores. To our knowledge, our work is the first to characterise segregated communities in scientific collaboration networks and to investigate their relationship with the impact measured in terms of citations. ",
    "url": "https://arxiv.org/abs/2207.09800",
    "authors": [
      "Ana Maria Jaramillo",
      "Hywel T.P. Williams",
      "Nicola Perra",
      "Ronaldo Menezes"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2207.09805",
    "title": "Multimodal Transformer for Automatic 3D Annotation and Object Detection",
    "abstract": "Despite a growing number of datasets being collected for training 3D object detection models, significant human effort is still required to annotate 3D boxes on LiDAR scans. To automate the annotation and facilitate the production of various customized datasets, we propose an end-to-end multimodal transformer (MTrans) autolabeler, which leverages both LiDAR scans and images to generate precise 3D box annotations from weak 2D bounding boxes. To alleviate the pervasive sparsity problem that hinders existing autolabelers, MTrans densifies the sparse point clouds by generating new 3D points based on 2D image information. With a multi-task design, MTrans segments the foreground/background, densifies LiDAR point clouds, and regresses 3D boxes simultaneously. Experimental results verify the effectiveness of the MTrans for improving the quality of the generated labels. By enriching the sparse point clouds, our method achieves 4.48\\% and 4.03\\% better 3D AP on KITTI moderate and hard samples, respectively, versus the state-of-the-art autolabeler. MTrans can also be extended to improve the accuracy for 3D object detection, resulting in a remarkable 89.45\\% AP on KITTI hard samples. Codes are at \\url{https://github.com/Cliu2/MTrans}. ",
    "url": "https://arxiv.org/abs/2207.09805",
    "authors": [
      "Chang Liu",
      "Xiaoyan Qian",
      "Binxiao Huang",
      "Xiaojuan Qi",
      "Edmund Lam",
      "Siew-Chong Tan",
      "Ngai Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09827",
    "title": "Comparing directed networks via denoising graphlet distributions",
    "abstract": "Network comparison is a widely-used tool for analyzing complex systems, with applications in varied domains including comparison of protein interactions or highlighting changes in structure of trade networks. In recent years, a number of network comparison methodologies based on the distribution of graphlets (small connected network subgraphs) have been introduced. In particular, NetEmd has recently achieved state of the art performance in undirected networks. In this work, we propose an extension of NetEmd to directed networks and deal with the significant increase in complexity of graphlet structure in the directed case by denoising through linear projections. Simulation results show that our framework is able to improve on the performance of a simple translation of the undirected NetEmd algorithm to the directed case, especially when networks differ in size and density. ",
    "url": "https://arxiv.org/abs/2207.09827",
    "authors": [
      "Miguel E. P. Silva",
      "Robert E. Gaunt",
      "Luis Ospina-Forero",
      "Caroline Jay",
      "Thomas House"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2207.09828",
    "title": "${\\mathcal K}$-monotonicity and feedback synthesis for incrementally  stable networks",
    "abstract": "We discuss the role of monotonicity in enabling numerically tractable modular control design for networked nonlinear systems. We first show that the variational systems of monotone systems can be embedded into positive systems. Utilizing this embedding, we show how to solve a network stabilization problem by enforcing monotonicity and exponential dissipativity of the network sub-components. Such modular approach leads to a design algorithm based on a sequence of linear programming problems. ",
    "url": "https://arxiv.org/abs/2207.09828",
    "authors": [
      "Yu Kawano",
      "Fulvio Forni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2207.09830",
    "title": "The Atlas Benchmark: an Automated Evaluation Framework for Human Motion  Prediction",
    "abstract": "Human motion trajectory prediction, an essential task for autonomous systems in many domains, has been on the rise in recent years. With a multitude of new methods proposed by different communities, the lack of standardized benchmarks and objective comparisons is increasingly becoming a major limitation to assess progress and guide further research. Existing benchmarks are limited in their scope and flexibility to conduct relevant experiments and to account for contextual cues of agents and environments. In this paper we present Atlas, a benchmark to systematically evaluate human motion trajectory prediction algorithms in a unified framework. Atlas offers data preprocessing functions, hyperparameter optimization, comes with popular datasets and has the flexibility to setup and conduct underexplored yet relevant experiments to analyze a method's accuracy and robustness. In an example application of Atlas, we compare five popular model- and learning-based predictors and find that, when properly applied, early physics-based approaches are still remarkably competitive. Such results confirm the necessity of benchmarks like Atlas. ",
    "url": "https://arxiv.org/abs/2207.09830",
    "authors": [
      "Andrey Rudenko",
      "Luigi Palmieri",
      "Wanting Huang",
      "Achim J. Lilienthal",
      "Kai O. Arras"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.09835",
    "title": "UNIF: United Neural Implicit Functions for Clothed Human Reconstruction  and Animation",
    "abstract": "We propose united implicit functions (UNIF), a part-based method for clothed human reconstruction and animation with raw scans and skeletons as the input. Previous part-based methods for human reconstruction rely on ground-truth part labels from SMPL and thus are limited to minimal-clothed humans. In contrast, our method learns to separate parts from body motions instead of part supervision, thus can be extended to clothed humans and other articulated objects. Our Partition-from-Motion is achieved by a bone-centered initialization, a bone limit loss, and a section normal loss that ensure stable part division even when the training poses are limited. We also present a minimal perimeter loss for SDF to suppress extra surfaces and part overlapping. Another core of our method is an adjacent part seaming algorithm that produces non-rigid deformations to maintain the connection between parts which significantly relieves the part-based artifacts. Under this algorithm, we further propose \"Competing Parts\", a method that defines blending weights by the relative position of a point to bones instead of the absolute position, avoiding the generalization problem of neural implicit functions with inverse LBS (linear blend skinning). We demonstrate the effectiveness of our method by clothed human body reconstruction and animation on the CAPE and the ClothSeq datasets. ",
    "url": "https://arxiv.org/abs/2207.09835",
    "authors": [
      "Shenhan Qian",
      "Jiale Xu",
      "Ziwei Liu",
      "Liqian Ma",
      "Shenghua Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09851",
    "title": "An Embedded Monocular Vision Approach for Ground-Aware Objects Detection  and Position Estimation",
    "abstract": "In the RoboCup Small Size League (SSL), teams are encouraged to propose solutions for executing basic soccer tasks inside the SSL field using only embedded sensing information. Thus, this work proposes an embedded monocular vision approach for detecting objects and estimating relative positions inside the soccer field. Prior knowledge from the environment is exploited by assuming objects lay on the ground, and the onboard camera has its position fixed on the robot. We implemented the proposed method on an NVIDIA Jetson Nano and employed SSD MobileNet v2 for 2D Object Detection with TensorRT optimization, detecting balls, robots, and goals with distances up to 3.5 meters. Ball localization evaluation shows that the proposed solution overcomes the currently used SSL vision system for positions closer than 1 meter to the onboard camera with a Root Mean Square Error of 14.37 millimeters. In addition, the proposed method achieves real-time performance with an average processing speed of 30 frames per second. ",
    "url": "https://arxiv.org/abs/2207.09851",
    "authors": [
      "Jo\u00e3o G. Melo",
      "Edna Barros"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09854",
    "title": "Auto-active Verification of Graph Algorithms, Written in OCaml",
    "abstract": "Functional programming offers the perfect ground for building correct-by-construction software. Languages of such paradigm normally feature state-of-the-art type systems, good abstraction mechanisms, and well-defined execution models. We claim that all of these make software written in a functional language excellent targets for formal certification. Yet, somehow surprising, techniques such as deductive verification have been seldom applied to large-scale programs, written in mainstream functional languages. In this paper, we wish to address this situation and present the auto-active proof of realistic OCaml implementations. We choose implementations issued from the OCamlgraph library as our target, since this is both a large-scale and widely-used piece of OCaml code. We use Cameleer, a recently proposed tool for the deductive verification of OCaml programs, to conduct the proofs of the selected case studies. The vast majority of such proofs are completed fully-automatically, using SMT solvers, and when needed we can apply lightweight interactive proof inside the Why3 IDE (Cameleer translates an input program into an equivalent WhyML one, the language of the Why3 verification framework). To the best of our knowledge, these are the first mechanized, mostly-automated proofs of graph algorithms written in OCaml. ",
    "url": "https://arxiv.org/abs/2207.09854",
    "authors": [
      "Daniel Castanho",
      "M\u00e1rio Pereira"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2207.09869",
    "title": "A Novel Neural Network Training Method for Autonomous Driving Using  Semi-Pseudo-Labels and 3D Data Augmentations",
    "abstract": "Training neural networks to perform 3D object detection for autonomous driving requires a large amount of diverse annotated data. However, obtaining training data with sufficient quality and quantity is expensive and sometimes impossible due to human and sensor constraints. Therefore, a novel solution is needed for extending current training methods to overcome this limitation and enable accurate 3D object detection. Our solution for the above-mentioned problem combines semi-pseudo-labeling and novel 3D augmentations. For demonstrating the applicability of the proposed method, we have designed a convolutional neural network for 3D object detection which can significantly increase the detection range in comparison with the training data distribution. ",
    "url": "https://arxiv.org/abs/2207.09869",
    "authors": [
      "Tamas Matuszka",
      "Daniel Kozma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09889",
    "title": "When Is TTS Augmentation Through a Pivot Language Useful?",
    "abstract": "Developing Automatic Speech Recognition (ASR) for low-resource languages is a challenge due to the small amount of transcribed audio data. For many such languages, audio and text are available separately, but not audio with transcriptions. Using text, speech can be synthetically produced via text-to-speech (TTS) systems. However, many low-resource languages do not have quality TTS systems either. We propose an alternative: produce synthetic audio by running text from the target language through a trained TTS system for a higher-resource pivot language. We investigate when and how this technique is most effective in low-resource settings. In our experiments, using several thousand synthetic TTS text-speech pairs and duplicating authentic data to balance yields optimal results. Our findings suggest that searching over a set of candidate pivot languages can lead to marginal improvements and that, surprisingly, ASR performance can by harmed by increases in measured TTS quality. Application of these findings improves ASR by 64.5\\% and 45.0\\% character error reduction rate (CERR) respectively for two low-resource languages: Guaran\\'i and Suba. ",
    "url": "https://arxiv.org/abs/2207.09889",
    "authors": [
      "Nathaniel Robinson",
      "Perez Ogayo",
      "Swetha Gangu",
      "David R. Mortensen",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.09897",
    "title": "Successor Representation Active Inference",
    "abstract": "Recent work has uncovered close links between between classical reinforcement learning algorithms, Bayesian filtering, and Active Inference which lets us understand value functions in terms of Bayesian posteriors. An alternative, but less explored, model-free RL algorithm is the successor representation, which expresses the value function in terms of a successor matrix of expected future state occupancies. In this paper, we derive the probabilistic interpretation of the successor representation in terms of Bayesian filtering and thus design a novel active inference agent architecture utilizing successor representations instead of model-based planning. We demonstrate that active inference successor representations have significant advantages over current active inference agents in terms of planning horizon and computational cost. Moreover, we demonstrate how the successor representation agent can generalize to changing reward functions such as variants of the expected free energy. ",
    "url": "https://arxiv.org/abs/2207.09897",
    "authors": [
      "Beren Millidge",
      "Christopher L Buckley"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.09902",
    "title": "Bayesian Hyperparameter Optimization for Deep Neural Network-Based  Network Intrusion Detection",
    "abstract": "Traditional network intrusion detection approaches encounter feasibility and sustainability issues to combat modern, sophisticated, and unpredictable security attacks. Deep neural networks (DNN) have been successfully applied for intrusion detection problems. The optimal use of DNN-based classifiers requires careful tuning of the hyper-parameters. Manually tuning the hyperparameters is tedious, time-consuming, and computationally expensive. Hence, there is a need for an automatic technique to find optimal hyperparameters for the best use of DNN in intrusion detection. This paper proposes a novel Bayesian optimization-based framework for the automatic optimization of hyperparameters, ensuring the best DNN architecture. We evaluated the performance of the proposed framework on NSL-KDD, a benchmark dataset for network intrusion detection. The experimental results show the framework's effectiveness as the resultant DNN architecture demonstrates significantly higher intrusion detection performance than the random search optimization-based approach in terms of accuracy, precision, recall, and f1-score. ",
    "url": "https://arxiv.org/abs/2207.09902",
    "authors": [
      "Mohammad Masum",
      "Hossain Shahriar",
      "Hisham Haddad",
      "Md Jobair Hossain Faruk",
      "Maria Valero",
      "Md Abdullah Khan",
      "Mohammad A. Rahman",
      "Muhaiminul I. Adnan",
      "Alfredo Cuzzocrea"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09908",
    "title": "Integrated Finite Element Neural Network (I-FENN) for non-local  continuum damage mechanics",
    "abstract": "We present a new Integrated Finite Element Neural Network framework (I-FENN), with the objective to accelerate the numerical solution of nonlinear computational mechanics problems. We leverage the swift predictive capability of neural networks (NNs) and we embed them inside the finite element stiffness function, to compute element-level state variables and their derivatives within a nonlinear, iterative numerical solution. This process is conducted jointly with conventional finite element methods that involve shape functions: the NN receives input data that resembles the material point deformation and its output is used to construct element-level field variables such as the element Jacobian matrix and residual vector. Here we introduce I-FENN to the continuum damage analysis of quasi-brittle materials, and we establish a new non-local gradient-based damage framework which operates at the cost of a local damage approach. First, we develop a physics informed neural network (PINN) to resemble the non-local gradient model and then we train the neural network offline. The network learns to predict the non-local equivalent strain at each material point, as well as its derivative with respect to the local strain. Then, the PINN is integrated in the element stiffness definition and conducts the local to non-local strain transformation, whereas the two PINN outputs are used to construct the element Jacobian matrix and residual vector. This process is carried out within the nonlinear solver, until numerical convergence is achieved. The resulting method bears the computational cost of the conventional local damage approach, but ensures mesh-independent results and a diffused non-local strain and damage profile. As a result, the proposed method tackles the vital drawbacks of both the local and non-local gradient method, respectively being the mesh-dependence and additional computational cost. ",
    "url": "https://arxiv.org/abs/2207.09908",
    "authors": [
      "Panos Pantidis",
      "Mostafa E. Mobasher"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Applied Physics (physics.app-ph)"
    ]
  },
  {
    "id": "arXiv:2207.09912",
    "title": "Online Evasion Attacks on Recurrent Models:The Power of Hallucinating  the Future",
    "abstract": "Recurrent models are frequently being used in online tasks such as autonomous driving, and a comprehensive study of their vulnerability is called for. Existing research is limited in generality only addressing application-specific vulnerability or making implausible assumptions such as the knowledge of future input. In this paper, we present a general attack framework for online tasks incorporating the unique constraints of the online setting different from offline tasks. Our framework is versatile in that it covers time-varying adversarial objectives and various optimization constraints, allowing for a comprehensive study of robustness. Using the framework, we also present a novel white-box attack called Predictive Attack that `hallucinates' the future. The attack achieves 98 percent of the performance of the ideal but infeasible clairvoyant attack on average. We validate the effectiveness of the proposed framework and attacks through various experiments. ",
    "url": "https://arxiv.org/abs/2207.09912",
    "authors": [
      "Byunggill Joe",
      "Insik Shin",
      "Jihun Hamm"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09920",
    "title": "DESCN: Deep Entire Space Cross Networks for Individual Treatment Effect  Estimation",
    "abstract": "Causal Inference has wide applications in various areas such as E-commerce and precision medicine, and its performance heavily relies on the accurate estimation of the Individual Treatment Effect (ITE). Conventionally, ITE is predicted by modeling the treated and control response functions separately in their individual sample spaces. However, such an approach usually encounters two issues in practice, i.e. divergent distribution between treated and control groups due to treatment bias, and significant sample imbalance of their population sizes. This paper proposes Deep Entire Space Cross Networks (DESCN) to model treatment effects from an end-to-end perspective. DESCN captures the integrated information of the treatment propensity, the response, and the hidden treatment effect through a cross network in a multi-task learning manner. Our method jointly learns the treatment and response functions in the entire sample space to avoid treatment bias and employs an intermediate pseudo treatment effect prediction network to relieve sample imbalance. Extensive experiments are conducted on a synthetic dataset and a large-scaled production dataset from the E-commerce voucher distribution business. The results indicate that DESCN can successfully enhance the accuracy of ITE estimation and improve the uplift ranking performance. A sample of the production dataset and the source code are released to facilitate future research in the community, which is, to the best of our knowledge, the first large-scale public biased treatment dataset for causal inference. ",
    "url": "https://arxiv.org/abs/2207.09920",
    "authors": [
      "Kailiang Zhong",
      "Fengtong Xiao",
      "Yan Ren",
      "Yaorong Liang",
      "Wenqing Yao",
      "Xiaofeng Yang",
      "Ling Cen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.09927",
    "title": "ViGAT: Bottom-up event recognition and explanation in video using  factorized graph attention network",
    "abstract": "In this paper a pure-attention bottom-up approach, called ViGAT, that utilizes an object detector together with a Vision Transformer (ViT) backbone network to derive object and frame features, and a head network to process these features for the task of event recognition and explanation in video, is proposed. The ViGAT head consists of graph attention network (GAT) blocks factorized along the spatial and temporal dimensions in order to capture effectively both local and long-term dependencies between objects or frames. Moreover, using the weighted in-degrees (WiDs) derived from the adjacency matrices at the various GAT blocks, we show that the proposed architecture can identify the most salient objects and frames that explain the decision of the network. A comprehensive evaluation study is performed, demonstrating that the proposed approach provides state-of-the-art results on three large, publicly available video datasets (FCVID, Mini-Kinetics, ActivityNet). ",
    "url": "https://arxiv.org/abs/2207.09927",
    "authors": [
      "Nikolaos Gkalelis",
      "Dimitrios Daskalakis",
      "Vasileios Mezaris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.09928",
    "title": "Upgrading the protection of children from manipulative and addictive  strategies in online games: Legal and technical solutions beyond privacy  regulation",
    "abstract": "Despite the increasing awareness from academia, civil society and media to the issue of child manipulation online, the current EU regulatory system fails at providing sufficient levels of protection. Given the universality of the issue, there is a need to combine and further these scattered efforts into a unitary, multidisciplinary theory of digital manipulation that identifies causes and effects, systematizes the technical and legal knowledge on manipulative and addictive tactics, and to find effective regulatory mechanisms to fill the legislative gaps. In this paper we discuss manipulative and exploitative strategies in the context of online games for children, suggest a number of possible reasons for the failure of the applicable regulatory system, propose an \"upgrade\" for the regulatory approach to address these risks from the perspective of freedom of thought, and present and discuss technological approaches that allow for the development of games that verifiably protect the privacy and freedoms of players. ",
    "url": "https://arxiv.org/abs/2207.09928",
    "authors": [
      "Tommaso Crepax",
      "Jan Tobias Muehlberg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.09933",
    "title": "Robust Landmark-based Stent Tracking in X-ray Fluoroscopy",
    "abstract": "In clinical procedures of angioplasty (i.e., open clogged coronary arteries), devices such as balloons and stents need to be placed and expanded in arteries under the guidance of X-ray fluoroscopy. Due to the limitation of X-ray dose, the resulting images are often noisy. To check the correct placement of these devices, typically multiple motion-compensated frames are averaged to enhance the view. Therefore, device tracking is a necessary procedure for this purpose. Even though angioplasty devices are designed to have radiopaque markers for the ease of tracking, current methods struggle to deliver satisfactory results due to the small marker size and complex scenes in angioplasty. In this paper, we propose an end-to-end deep learning framework for single stent tracking, which consists of three hierarchical modules: U-Net based landmark detection, ResNet based stent proposal and feature extraction, and graph convolutional neural network (GCN) based stent tracking that temporally aggregates both spatial information and appearance features. The experiments show that our method performs significantly better in detection compared with the state-of-the-art point-based tracking models. In addition, its fast inference speed satisfies clinical requirements. ",
    "url": "https://arxiv.org/abs/2207.09933",
    "authors": [
      "Luojie Huang",
      "Yikang Liu",
      "Li Chen",
      "Eric Z Chen",
      "Xiao Chen",
      "Shanhui Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09936",
    "title": "A Secure Clustering Protocol with Fuzzy Trust Evaluation and Outlier  Detection for Industrial Wireless Sensor Networks",
    "abstract": "Security is one of the major concerns in Industrial Wireless Sensor Networks (IWSNs). To assure the security in clustered IWSNs, this paper presents a secure clustering protocol with fuzzy trust evaluation and outlier detection (SCFTO). Firstly, to deal with the transmission uncertainty in an open wireless medium, an interval type-2 fuzzy logic controller is adopted to estimate the trusts. And then a density based outlier detection mechanism is introduced to acquire an adaptive trust threshold used to isolate the malicious nodes from being cluster heads. Finally, a fuzzy based cluster heads election method is proposed to achieve a balance between energy saving and security assurance, so that a normal sensor node with more residual energy or less confidence on other nodes has higher probability to be the cluster head. Extensive experiments verify that our secure clustering protocol can effectively defend the network against attacks from internal malicious or compromised nodes. ",
    "url": "https://arxiv.org/abs/2207.09936",
    "authors": [
      "Liu Yang",
      "Yinzhi Lu",
      "Simon X. Yang",
      "Tan Guo",
      "Zhifang Liang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.09953",
    "title": "Learning Pedestrian Group Representations for Multi-modal Trajectory  Prediction",
    "abstract": "Modeling the dynamics of people walking is a problem of long-standing interest in computer vision. Many previous works involving pedestrian trajectory prediction define a particular set of individual actions to implicitly model group actions. In this paper, we present a novel architecture named GP-Graph which has collective group representations for effective pedestrian trajectory prediction in crowded environments, and is compatible with all types of existing approaches. A key idea of GP-Graph is to model both individual-wise and group-wise relations as graph representations. To do this, GP-Graph first learns to assign each pedestrian into the most likely behavior group. Using this assignment information, GP-Graph then forms both intra- and inter-group interactions as graphs, accounting for human-human relations within a group and group-group relations, respectively. To be specific, for the intra-group interaction, we mask pedestrian graph edges out of an associated group. We also propose group pooling&unpooling operations to represent a group with multiple pedestrians as one graph node. Lastly, GP-Graph infers a probability map for socially-acceptable future trajectories from the integrated features of both group interactions. Moreover, we introduce a group-level latent vector sampling to ensure collective inferences over a set of possible future trajectories. Extensive experiments are conducted to validate the effectiveness of our architecture, which demonstrates consistent performance improvements with publicly available benchmarks. Code is publicly available at https://github.com/inhwanbae/GPGraph. ",
    "url": "https://arxiv.org/abs/2207.09953",
    "authors": [
      "Inhwan Bae",
      "Jin-Hwi Park",
      "Hae-Gon Jeon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.09955",
    "title": "Operation-Level Performance Benchmarking of Graph Neural Networks for  Scientific Applications",
    "abstract": "As Graph Neural Networks (GNNs) increase in popularity for scientific machine learning, their training and inference efficiency is becoming increasingly critical. Additionally, the deep learning field as a whole is trending towards wider and deeper networks, and ever increasing data sizes, to the point where hard hardware bottlenecks are often encountered. Emerging specialty hardware platforms provide an exciting solution to this problem. In this paper, we systematically profile and select low-level operations pertinent to GNNs for scientific computing implemented in the Pytorch Geometric software framework. These are then rigorously benchmarked on NVIDIA A100 GPUs for several various combinations of input values, including tensor sparsity. We then analyze these results for each operation. At a high level, we conclude that on NVIDIA systems: (1) confounding bottlenecks such as memory inefficiency often dominate runtime costs moreso than data sparsity alone, (2) native Pytorch operations are often as or more competitive than their Pytorch Geometric equivalents, especially at low to moderate levels of input data sparsity, and (3) many operations central to state-of-the-art GNN architectures have little to no optimization for sparsity. We hope that these results serve as a baseline for those developing these operations on specialized hardware and that our subsequent analysis helps to facilitate future software and hardware based optimizations of these operations and thus scalable GNN performance as a whole. ",
    "url": "https://arxiv.org/abs/2207.09955",
    "authors": [
      "Ryien Hosseini",
      "Filippo Simini",
      "Venkatram Vishwanath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2207.09964",
    "title": "On a Generalized Framework for Time-Aware Knowledge Graphs",
    "abstract": "Knowledge graphs have emerged as an effective tool for managing and standardizing semistructured domain knowledge in a human- and machine-interpretable way. In terms of graph-based domain applications, such as embeddings and graph neural networks, current research is increasingly taking into account the time-related evolution of the information encoded within a graph. Algorithms and models for stationary and static knowledge graphs are extended to make them accessible for time-aware domains, where time-awareness can be interpreted in different ways. In particular, a distinction needs to be made between the validity period and the traceability of facts as objectives of time-related knowledge graph extensions. In this context, terms and definitions such as dynamic and temporal are often used inconsistently or interchangeably in the literature. Therefore, with this paper we aim to provide a short but well-defined overview of time-aware knowledge graph extensions and thus faciliate future research in this field as well. ",
    "url": "https://arxiv.org/abs/2207.09964",
    "authors": [
      "Franz Krause",
      "Tobias Weller",
      "Heiko Paulheim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.09965",
    "title": "M2-Net: Multi-stages Specular Highlight Detection and Removal in  Multi-scenes",
    "abstract": "In this paper, we propose a novel uniformity framework for highlight detection and removal in multi-scenes, including synthetic images, face images, natural images, and text images. The framework consists of three main components, highlight feature extractor module, highlight coarse removal module, and highlight refine removal module. Firstly, the highlight feature extractor module can directly separate the highlight feature and non-highlight feature from the original highlight image. Then highlight removal image is obtained using a coarse highlight removal network. To further improve the highlight removal effect, the refined highlight removal image is finally obtained using refine highlight removal module based on contextual highlight attention mechanisms. Extensive experimental results in multiple scenes indicate that the proposed framework can obtain excellent visual effects of highlight removal and achieve state-of-the-art results in several quantitative evaluation metrics. Our algorithm is applied for the first time in video highlight removal with promising results. ",
    "url": "https://arxiv.org/abs/2207.09965",
    "authors": [
      "Zhaoyangfan Huang",
      "Kun Hu",
      "Xingjun Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09978",
    "title": "NeuralBF: Neural Bilateral Filtering for Top-down Instance Segmentation  on Point Clouds",
    "abstract": "We introduce a method for instance proposal generation for 3D point clouds. Existing techniques typically directly regress proposals in a single feed-forward step, leading to inaccurate estimation. We show that this serves as a critical bottleneck, and propose a method based on iterative bilateral filtering with learned kernels. Following the spirit of bilateral filtering, we consider both the deep feature embeddings of each point, as well as their locations in the 3D space. We show via synthetic experiments that our method brings drastic improvements when generating instance proposals for a given point of interest. We further validate our method on the challenging ScanNet benchmark, achieving the best instance segmentation performance amongst the sub-category of top-down methods. ",
    "url": "https://arxiv.org/abs/2207.09978",
    "authors": [
      "Weiwei Sun",
      "Daniel Rebain",
      "Renjie Liao",
      "Vladimir Tankovich",
      "Soroosh Yazdani",
      "Kwang Moo Yi",
      "Andrea Tagliasacchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2207.09988",
    "title": "DecoupleNet: Decoupled Network for Domain Adaptive Semantic Segmentation",
    "abstract": "Unsupervised domain adaptation in semantic segmentation has been raised to alleviate the reliance on expensive pixel-wise annotations. It leverages a labeled source domain dataset as well as unlabeled target domain images to learn a segmentation network. In this paper, we observe two main issues of the existing domain-invariant learning framework. (1) Being distracted by the feature distribution alignment, the network cannot focus on the segmentation task. (2) Fitting source domain data well would compromise the target domain performance. To address these issues, we propose DecoupleNet that alleviates source domain overfitting and enables the final model to focus more on the segmentation task. Furthermore, we put forward Self-Discrimination (SD) and introduce an auxiliary classifier to learn more discriminative target domain features with pseudo labels. Finally, we propose Online Enhanced Self-Training (OEST) to contextually enhance the quality of pseudo labels in an online manner. Experiments show our method outperforms existing state-of-the-art methods, and extensive ablation studies verify the effectiveness of each component. Code is available at https://github.com/dvlab-research/DecoupleNet. ",
    "url": "https://arxiv.org/abs/2207.09988",
    "authors": [
      "Xin Lai",
      "Zhuotao Tian",
      "Xiaogang Xu",
      "Yingcong Chen",
      "Shu Liu",
      "Hengshuang Zhao",
      "Liwei Wang",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09996",
    "title": "Phenomenon-Signal Model: Formalisation, Graph and Application",
    "abstract": "Considering information as the basis of action, it may be of interest to examine the flow and acquisition of information between the actors in traffic. The central question is: Which signals does an automated driving system (which will be referred to as an automaton in the remainder of this paper) in traffic have to receive, decode or send in road traffic in order to act safely and in a manner that is compliant with valid standards. The phenomenon-signal model (PSM) is a method for structuring the problem area and for analysing and describing this very signal flow. The aim of this paper is to explain the basics, the structure and the application of this method. ",
    "url": "https://arxiv.org/abs/2207.09996",
    "authors": [
      "Hans Nikolaus Beck",
      "Nayel Fabian Salem",
      "Veronica Haber",
      "Matthias Rauschenbach",
      "Jan Reich"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.09999",
    "title": "Digital Twin-based Intrusion Detection for Industrial Control Systems",
    "abstract": "Digital twins have recently gained significant interest in simulation, optimization, and predictive maintenance of Industrial Control Systems (ICS). Recent studies discuss the possibility of using digital twins for intrusion detection in industrial systems. Accordingly, this study contributes to a digital twin-based security framework for industrial control systems, extending its capabilities for simulation of attacks and defense mechanisms. Four types of process-aware attack scenarios are implemented on a standalone open-source digital twin of an industrial filling plant: command injection, network Denial of Service (DoS), calculated measurement modification, and naive measurement modification. A stacked ensemble classifier is proposed as the real-time intrusion detection, based on the offline evaluation of eight supervised machine learning algorithms. The designed stacked model outperforms previous methods in terms of F1-Score and accuracy, by combining the predictions of various algorithms, while it can detect and classify intrusions in near real-time (0.1 seconds). This study also discusses the practicality and benefits of the proposed digital twin-based security framework. ",
    "url": "https://arxiv.org/abs/2207.09999",
    "authors": [
      "Seba Anna Varghese",
      "Alireza Dehlaghi Ghadim",
      "Ali Balador",
      "Zahra Alimadadi",
      "Panos Papadimitratos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10008",
    "title": "E-Graph: Minimal Solution for Rigid Rotation with Extensibility Graphs",
    "abstract": "Minimal solutions for relative rotation and translation estimation tasks have been explored in different scenarios, typically relying on the so-called co-visibility graph. However, how to build direct rotation relationships between two frames without overlap is still an open topic, which, if solved, could greatly improve the accuracy of visual odometry. In this paper, a new minimal solution is proposed to solve relative rotation estimation between two images without overlapping areas by exploiting a new graph structure, which we call Extensibility Graph (E-Graph). Differently from a co-visibility graph, high-level landmarks, including vanishing directions and plane normals, are stored in our E-Graph, which are geometrically extensible. Based on E-Graph, the rotation estimation problem becomes simpler and more elegant, as it can deal with pure rotational motion and requires fewer assumptions, e.g. Manhattan/Atlanta World, planar/vertical motion. Finally, we embed our rotation estimation strategy into a complete camera tracking and mapping system which obtains 6-DoF camera poses and a dense 3D mesh model. Extensive experiments on public benchmarks demonstrate that the proposed method achieves state-of-the-art tracking performance. ",
    "url": "https://arxiv.org/abs/2207.10008",
    "authors": [
      "Yanyan Li",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.10025",
    "title": "Learning from Synthetic Data: Facial Expression Classification based on  Ensemble of Multi-task Networks",
    "abstract": "Facial expression in-the-wild is essential for various interactive computing domains. Especially, \"Learning from Synthetic Data\" (LSD) is an important topic in the facial expression recognition task. In this paper, we propose a multi-task learning-based facial expression recognition approach which consists of emotion and appearance learning branches that can share all face information, and present preliminary results for the LSD challenge introduced in the 4th affective behavior analysis in-the-wild (ABAW) competition. Our method achieved the mean F1 score of 0.71. ",
    "url": "https://arxiv.org/abs/2207.10025",
    "authors": [
      "Jae-Yeop Jeong",
      "Yeong-Gi Hong",
      "JiYeon Oh",
      "Sumin Hong",
      "Jin-Woo Jeong",
      "Yuchul Jung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10035",
    "title": "Fully Sparse 3D Object Detection",
    "abstract": "As the perception range of LiDAR increases, LiDAR-based 3D object detection becomes a dominant task in the long-range perception task of autonomous driving. The mainstream 3D object detectors usually build dense feature maps in the network backbone and prediction head. However, the computational and spatial costs on the dense feature map are quadratic to the perception range, which makes them hardly scale up to the long-range setting. To enable efficient long-range LiDAR-based object detection, we build a fully sparse 3D object detector (FSD). The computational and spatial cost of FSD is roughly linear to the number of points and independent of the perception range. FSD is built upon the general sparse voxel encoder and a novel sparse instance recognition (SIR) module. SIR first groups the points into instances and then applies instance-wise feature extraction and prediction. In this way, SIR resolves the issue of center feature missing, which hinders the design of the fully sparse architecture for all center-based or anchor-based detectors. Moreover, SIR avoids the time-consuming neighbor queries in previous point-based methods by grouping points into instances. We conduct extensive experiments on the large-scale Waymo Open Dataset to reveal the working mechanism of FSD, and state-of-the-art performance is reported. To demonstrate the superiority of FSD in long-range detection, we also conduct experiments on Argoverse 2 Dataset, which has a much larger perception range ($200m$) than Waymo Open Dataset ($75m$). On such a large perception range, FSD achieves state-of-the-art performance and is 2.4$\\times$ faster than the dense counterpart.Codes will be released at https://github.com/TuSimple/SST. ",
    "url": "https://arxiv.org/abs/2207.10035",
    "authors": [
      "Lue Fan",
      "Feng Wang",
      "Naiyan Wang",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.10047",
    "title": "Densely Constrained Depth Estimator for Monocular 3D Object Detection",
    "abstract": "Estimating accurate 3D locations of objects from monocular images is a challenging problem because of lacking depth. Previous work shows that utilizing the object's keypoint projection constraints to estimate multiple depth candidates boosts the detection performance. However, the existing methods can only utilize vertical edges as projection constraints for depth estimation. So these methods only use a small number of projection constraints and produce insufficient depth candidates, leading to inaccurate depth estimation. In this paper, we propose a method that utilizes dense projection constraints from edges of any direction. In this way, we employ much more projection constraints and produce considerable depth candidates. Besides, we present a graph matching weighting module to merge the depth candidates. The proposed method DCD (Densely Constrained Detector) achieves state-of-the-art performance on the KITTI and WOD benchmarks. Code is released at https://github.com/BraveGroup/DCD. ",
    "url": "https://arxiv.org/abs/2207.10047",
    "authors": [
      "Yingyan Li",
      "Yunchao Chen",
      "Jiawei He",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10049",
    "title": "Pretraining a Neural Network before Knowing Its Architecture",
    "abstract": "Training large neural networks is possible by training a smaller hypernetwork that predicts parameters for the large ones. A recently released Graph HyperNetwork (GHN) trained this way on one million smaller ImageNet architectures is able to predict parameters for large unseen networks such as ResNet-50. While networks with predicted parameters lose performance on the source task, the predicted parameters have been found useful for fine-tuning on other tasks. We study if fine-tuning based on the same GHN is still useful on novel strong architectures that were published after the GHN had been trained. We found that for recent architectures such as ConvNeXt, GHN initialization becomes less useful than for ResNet-50. One potential reason is the increased distribution shift of novel architectures from those used to train the GHN. We also found that the predicted parameters lack the diversity necessary to successfully fine-tune parameters with gradient descent. We alleviate this limitation by applying simple post-processing techniques to predicted parameters before fine-tuning them on a target task and improve fine-tuning of ResNet-50 and ConvNeXt. ",
    "url": "https://arxiv.org/abs/2207.10049",
    "authors": [
      "Boris Knyazev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10075",
    "title": "Is an Object-Centric Video Representation Beneficial for Transfer?",
    "abstract": "The objective of this work is to learn an object-centric video representation, with the aim of improving transferability to novel tasks, i.e., tasks different from the pre-training task of action classification. To this end, we introduce a new object-centric video recognition model based on a transformer architecture. The model learns a set of object-centric summary vectors for the video, and uses these vectors to fuse the visual and spatio-temporal trajectory `modalities' of the video clip. We also introduce a novel trajectory contrast loss to further enhance objectness in these summary vectors. With experiments on four datasets -- SomethingSomething-V2, SomethingElse, Action Genome and EpicKitchens -- we show that the object-centric model outperforms prior video representations (both object-agnostic and object-aware), when: (1) classifying actions on unseen objects and unseen environments; (2) low-shot learning to novel classes; (3) linear probe to other downstream tasks; as well as (4) for standard action classification. ",
    "url": "https://arxiv.org/abs/2207.10075",
    "authors": [
      "Chuhan Zhang",
      "Ankush Gupta",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10077",
    "title": "Discover and Mitigate Unknown Biases with Debiasing Alternate Networks",
    "abstract": "Deep image classifiers have been found to learn biases from datasets. To mitigate the biases, most previous methods require labels of protected attributes (e.g., age, skin tone) as full-supervision, which has two limitations: 1) it is infeasible when the labels are unavailable; 2) they are incapable of mitigating unknown biases -- biases that humans do not preconceive. To resolve those problems, we propose Debiasing Alternate Networks (DebiAN), which comprises two networks -- a Discoverer and a Classifier. By training in an alternate manner, the discoverer tries to find multiple unknown biases of the classifier without any annotations of biases, and the classifier aims at unlearning the biases identified by the discoverer. While previous works evaluate debiasing results in terms of a single bias, we create Multi-Color MNIST dataset to better benchmark mitigation of multiple biases in a multi-bias setting, which not only reveals the problems in previous methods but also demonstrates the advantage of DebiAN in identifying and mitigating multiple biases simultaneously. We further conduct extensive experiments on real-world datasets, showing that the discoverer in DebiAN can identify unknown biases that may be hard to be found by humans. Regarding debiasing, DebiAN achieves strong bias mitigation performance. ",
    "url": "https://arxiv.org/abs/2207.10077",
    "authors": [
      "Zhiheng Li",
      "Anthony Hoogs",
      "Chenliang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09514",
    "title": "ESPnet-SE++: Speech Enhancement for Robust Speech Recognition,  Translation, and Understanding",
    "abstract": "This paper presents recent progress on integrating speech separation and enhancement (SSE) into the ESPnet toolkit. Compared with the previous ESPnet-SE work, numerous features have been added, including recent state-of-the-art speech enhancement models with their respective training and evaluation recipes. Importantly, a new interface has been designed to flexibly combine speech enhancement front-ends with other tasks, including automatic speech recognition (ASR), speech translation (ST), and spoken language understanding (SLU). To showcase such integration, we performed experiments on carefully designed synthetic datasets for noisy-reverberant multi-channel ST and SLU tasks, which can be used as benchmark corpora for future research. In addition to these new tasks, we also use CHiME-4 and WSJ0-2Mix to benchmark multi- and single-channel SE approaches. Results show that the integration of SE front-ends with back-end tasks is a promising research direction even for tasks besides ASR, especially in the multi-channel scenario. The code is available online at https://github.com/ESPnet/ESPnet. The multi-channel ST and SLU datasets, which are another contribution of this work, are released on HuggingFace. ",
    "url": "https://arxiv.org/abs/2207.09514",
    "authors": [
      "Yen-Ju Lu",
      "Xuankai Chang",
      "Chenda Li",
      "Wangyou Zhang",
      "Samuele Cornell",
      "Zhaoheng Ni",
      "Yoshiki Masuyama",
      "Brian Yan",
      "Robin Scheibler",
      "Zhong-Qiu Wang",
      "Yu Tsao",
      "Yanmin Qian",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2207.09560",
    "title": "Holistic Robust Data-Driven Decisions",
    "abstract": "The design of data-driven formulations for machine learning and decision-making with good out-of-sample performance is a key challenge. The observation that good in-sample performance does not guarantee good out-of-sample performance is generally known as overfitting. Practical overfitting can typically not be attributed to a single cause but instead is caused by several factors all at once. We consider here three overfitting sources: (i) statistical error as a result of working with finite sample data, (ii) data noise which occurs when the data points are measured only with finite precision, and finally (iii) data misspecification in which a small fraction of all data may be wholly corrupted. We argue that although existing data-driven formulations may be robust against one of these three sources in isolation they do not provide holistic protection against all overfitting sources simultaneously. We design a novel data-driven formulation which does guarantee such holistic protection and is furthermore computationally viable. Our distributionally robust optimization formulation can be interpreted as a novel combination of a Kullback-Leibler and Levy-Prokhorov robust optimization formulation. Finally, we show how in the context of classification and regression problems several popular regularized and robust formulations reduce to a particular case of our proposed more general formulation. ",
    "url": "https://arxiv.org/abs/2207.09560",
    "authors": [
      "Amine Bennouna",
      "Bart Van Parys"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09588",
    "title": "New Auction Algorithms for Path Planning, Network Transport, and  Reinforcement Learning",
    "abstract": "We consider some classical optimization problems in path planning and network transport, and we introduce new auction-based algorithms for their optimal and suboptimal solution. The algorithms are based on mathematical ideas that are related to competitive bidding by persons for objects and the attendant market equilibrium, which underlie auction processes. However, the starting point of our algorithms is different, namely weighted and unweighted path construction in directed graphs, rather than assignment of persons to objects. The new algorithms have several potential advantages over existing methods: they are empirically faster in some important contexts, such as max-flow, they are well-suited for on-line replanning, and they can be adapted to distributed asynchronous operation. Moreover, they allow arbitrary initial prices, without complementary slackness restrictions, and thus are better-suited to take advantage of reinforcement learning methods that use off-line training with data, as well as on-line training during real-time operation. The new algorithms may also find use in reinforcement learning contexts involving approximation, such as multistep lookahead and tree search schemes, and/or rollout algorithms. ",
    "url": "https://arxiv.org/abs/2207.09588",
    "authors": [
      "Dimitri Bertsekas"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2207.09665",
    "title": "ExoSGAN and ExoACGAN: Exoplanet Detection using Adversarial Training  Algorithms",
    "abstract": "Exoplanet detection opens the door to the discovery of new habitable worlds and helps us understand how planets were formed. With the objective of finding earth-like habitable planets, NASA launched Kepler space telescope and its follow up mission K2. The advancement of observation capabilities has increased the range of fresh data available for research, and manually handling them is both time-consuming and difficult. Machine learning and deep learning techniques can greatly assist in lowering human efforts to process the vast array of data produced by the modern instruments of these exoplanet programs in an economical and unbiased manner. However, care should be taken to detect all the exoplanets precisely while simultaneously minimizing the misclassification of non-exoplanet stars. In this paper, we utilize two variations of generative adversarial networks, namely semi-supervised generative adversarial networks and auxiliary classifier generative adversarial networks, to detect transiting exoplanets in K2 data. We find that the usage of these models can be helpful for the classification of stars with exoplanets. Both of our techniques are able to categorize the light curves with a recall and precision of 1.00 on the test data. Our semi-supervised technique is beneficial to solve the cumbersome task of creating a labeled dataset. ",
    "url": "https://arxiv.org/abs/2207.09665",
    "authors": [
      "Cicy K Agnes",
      "Akthar Naveed V",
      "Anitha Mary M O Chacko"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09751",
    "title": "Contraction Bidimensionality of Geometric Intersection Graphs",
    "abstract": "Given a graph $G$, we define ${\\bf bcg}(G)$ as the minimum $k$ for which $G$ can be contracted to the uniformly triangulated grid $\\Gamma_{k}$. A graph class ${\\cal G}$ has the SQG${\\bf C}$ property if every graph $G\\in{\\cal G}$ has treewidth $\\mathcal{O}({\\bf bcg}(G)^{c})$ for some $1\\leq c<2$. The SQG${\\bf C}$ property is important for algorithm design as it defines the applicability horizon of a series of meta-algorithmic results, in the framework of bidimensionality theory, related to fast parameterized algorithms, kernelization, and approximation schemes. These results apply to a wide family of problems, namely problems that are contraction-bidimensional. Our main combinatorial result reveals a wide family of graph classes that satisfy the SQG${\\bf C}$ property. This family includes, in particular, bounded-degree string graphs. This considerably extends the applicability of bidimensionality theory for contraction bidimensional problems. ",
    "url": "https://arxiv.org/abs/2207.09751",
    "authors": [
      "Julien Baste",
      "Dimitrios M. Thilikos"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2207.09785",
    "title": "Unsupervised energy disaggregation via convolutional sparse coding",
    "abstract": "In this work, a method for unsupervised energy disaggregation in private households equipped with smart meters is proposed. This method aims to classify power consumption as active or passive, granting the ability to report on the residents' activity and presence without direct interaction. This lays the foundation for applications like non-intrusive health monitoring of private homes. The proposed method is based on minimizing a suitable energy functional, for which the iPALM (inertial proximal alternating linearized minimization) algorithm is employed, demonstrating that various conditions guaranteeing convergence are satisfied. In order to confirm feasibility of the proposed method, experiments on semi-synthetic test data sets and a comparison to existing, supervised methods are provided. ",
    "url": "https://arxiv.org/abs/2207.09785",
    "authors": [
      "Christian Aarset",
      "Andreas Habring",
      "Martin Holler",
      "Mario Mitter"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.09947",
    "title": "Fixed Points of Cone Mapping with the Application to Neural Networks",
    "abstract": "We derive conditions for the existence of fixed points of cone mappings without assuming scalability of functions. Monotonicity and scalability are often inseparable in the literature in the context of searching for fixed points of interference mappings. In applications, such mappings are approximated by non-negative neural networks. It turns out, however, that the process of training non-negative networks requires imposing an artificial constraint on the weights of the model. However, in the case of specific non-negative data, it cannot be said that if the mapping is non-negative, it has only non-negative weights. Therefore, we considered the problem of the existence of fixed points for general neural networks, assuming the conditions of tangency conditions with respect to specific cones. This does not relax the physical assumptions, because even assuming that the input and output are to be non-negative, the weights can have (small, but) less than zero values. Such properties (often found in papers on the interpretability of weights of neural networks) lead to the weakening of the assumptions about the monotonicity or scalability of the mapping associated with the neural network. To the best of our knowledge, this paper is the first to study this phenomenon. ",
    "url": "https://arxiv.org/abs/2207.09947",
    "authors": [
      "Grzegorz Gabor",
      "Krzysztof Rykaczewski"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "General Topology (math.GN)"
    ]
  },
  {
    "id": "arXiv:2207.09971",
    "title": "NeuralNEB -- Neural Networks can find Reaction Paths Fast",
    "abstract": "Machine Learning (ML) models have, in contrast to their usefulness in molecular dynamics studies, had limited success as surrogate potentials for reaction barrier search. It is due to the scarcity of training data in relevant transition state regions of chemical space. Currently, available datasets for training ML models on small molecular systems almost exclusively contain configurations at or near equilibrium. In this work, we present the dataset Transition1x containing 9.6 million Density Functional Theory (DFT) calculations of forces and energies of molecular configurations on and around reaction pathways at the wB97x/6-31G(d) level of theory. The data was generated by running Nudged Elastic Band (NEB) calculations with DFT on 10k reactions while saving intermediate calculations. We train state-of-the-art equivariant graph message-passing neural network models on Transition1x and cross-validate on the popular ANI1x and QM9 datasets. We show that ML models cannot learn features in transition-state regions solely by training on hitherto popular benchmark datasets. Transition1x is a new challenging benchmark that will provide an important step towards developing next-generation ML force fields that also work far away from equilibrium configurations and reactive systems. ",
    "url": "https://arxiv.org/abs/2207.09971",
    "authors": [
      "Mathias Schreiner",
      "Arghya Bhowmik",
      "Tejs Vegge",
      "Ole Winther"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2006.05630",
    "title": "Distributionally Robust Batch Contextual Bandits",
    "abstract": " Comments: The short version has been accepted in ICML 2020 ",
    "url": "https://arxiv.org/abs/2006.05630",
    "authors": [
      "Nian Si",
      "Fan Zhang",
      "Zhengyuan Zhou",
      "Jose Blanchet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2010.13062",
    "title": "Transgender Community Sentiment Analysis from Social Media Data: A  Natural Language Processing Approach",
    "abstract": " Comments: 5 pages, 1 figures ",
    "url": "https://arxiv.org/abs/2010.13062",
    "authors": [
      "Yuqiao Liu",
      "Yudan Wang",
      "Ying Zhao",
      "Zhixiang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2011.10698",
    "title": "Backdoor Attacks on the DNN Interpretation System",
    "abstract": " Comments: Published at the 2022 AAAI Conference on Artificial Intelligence (AAAI), 2022 ",
    "url": "https://arxiv.org/abs/2011.10698",
    "authors": [
      "Shihong Fang",
      "Anna Choromanska"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2102.00311",
    "title": "Fairness through Social Welfare Optimization",
    "abstract": " Comments: 23 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2102.00311",
    "authors": [
      "Violet Xinying Chen",
      "J.N. Hooker"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2102.12369",
    "title": "Neural content-aware collaborative filtering for cold-start music  recommendation",
    "abstract": " Title: Neural content-aware collaborative filtering for cold-start music  recommendation ",
    "url": "https://arxiv.org/abs/2102.12369",
    "authors": [
      "Paul Magron",
      "C\u00e9dric F\u00e9votte"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2103.16554",
    "title": "Pre-training strategies and datasets for facial representation learning",
    "abstract": " Comments: Accepted at ECCV 2022 ",
    "url": "https://arxiv.org/abs/2103.16554",
    "authors": [
      "Adrian Bulat",
      "Shiyang Cheng",
      "Jing Yang",
      "Andrew Garbett",
      "Enrique Sanchez",
      "Georgios Tzimiropoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.05587",
    "title": "A Discontinuity Capturing Shallow Neural Network for Elliptic Interface  Problems",
    "abstract": " Title: A Discontinuity Capturing Shallow Neural Network for Elliptic Interface  Problems ",
    "url": "https://arxiv.org/abs/2106.05587",
    "authors": [
      "Wei-Fan Hu",
      "Te-Sheng Lin",
      "Ming-Chih Lai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.12096",
    "title": "Towards Unbiased Visual Emotion Recognition via Causal Intervention",
    "abstract": " Comments: Accepted to ACM Multimedia 2022, code is available at this https URL ",
    "url": "https://arxiv.org/abs/2107.12096",
    "authors": [
      "Yuedong Chen",
      "Xu Yang",
      "Tat-Jen Cham",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.05698",
    "title": "Detecting Textual Adversarial Examples through Randomized Substitution  and Vote",
    "abstract": " Comments: Accepted by UAI 2022, code is avaliable at this https URL ",
    "url": "https://arxiv.org/abs/2109.05698",
    "authors": [
      "Xiaosen Wang",
      "Yifeng Xiong",
      "Kun He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.08685",
    "title": "Self-supervised learning methods and applications in medical imaging  analysis: A survey",
    "abstract": " Title: Self-supervised learning methods and applications in medical imaging  analysis: A survey ",
    "url": "https://arxiv.org/abs/2109.08685",
    "authors": [
      "Saeed Shurrab",
      "Rehab Duwairi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.09367",
    "title": "Network Clustering by Embedding of Attribute-augmented Graphs",
    "abstract": " Comments: 31 pages, 12 figures, preprint ",
    "url": "https://arxiv.org/abs/2109.09367",
    "authors": [
      "Pasqua D'Ambra",
      "Panayot S. Vassilevski",
      "Luisa Cutillo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2110.04079",
    "title": "A Hybrid Spatial-temporal Deep Learning Architecture for Lane Detection",
    "abstract": " Comments: 18 pages, 5 figures. Published by Computer-Aided Civil and Infrastructure Engineering (CACIE). Open access from this https URL ",
    "url": "https://arxiv.org/abs/2110.04079",
    "authors": [
      "Yongqi Dong",
      "Sandeep Patil",
      "Bart van Arem",
      "Haneen Farah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2111.12990",
    "title": "Learning Algebraic Representation for Systematic Generalization in  Abstract Reasoning",
    "abstract": " Comments: ECCV 2022 paper. Supplementary: this http URL Project: this http URL ",
    "url": "https://arxiv.org/abs/2111.12990",
    "authors": [
      "Chi Zhang",
      "Sirui Xie",
      "Baoxiong Jia",
      "Ying Nian Wu",
      "Song-Chun Zhu",
      "Yixin Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.13844",
    "title": "Adaptive Image Transformations for Transfer-based Adversarial Attack",
    "abstract": " Comments: 34 pages, 7 figures, 11 tables. Accepted by ECCV2022 ",
    "url": "https://arxiv.org/abs/2111.13844",
    "authors": [
      "Zheng Yuan",
      "Jie Zhang",
      "Shiguang Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.13876",
    "title": "Learning Discriminative Shrinkage Deep Networks for Image Deconvolution",
    "abstract": " Title: Learning Discriminative Shrinkage Deep Networks for Image Deconvolution ",
    "url": "https://arxiv.org/abs/2111.13876",
    "authors": [
      "Pin-Hung Kuo",
      "Jinshan Pan",
      "Shao-Yi Chien",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.08684",
    "title": "META: Mimicking Embedding via oThers' Aggregation for Generalizable  Person Re-identification",
    "abstract": " Title: META: Mimicking Embedding via oThers' Aggregation for Generalizable  Person Re-identification ",
    "url": "https://arxiv.org/abs/2112.08684",
    "authors": [
      "Boqiang Xu",
      "Jian Liang",
      "Lingxiao He",
      "Zhenan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.08932",
    "title": "Learning from Guided Play: A Scheduled Hierarchical Approach for  Improving Exploration in Adversarial Imitation Learning",
    "abstract": " Comments: In Proceedings of the Neural Information Processing Systems (NeurIPS'21) Deep Reinforcement Learning Workshop, Sydney, Australia, Dec. 13, 2021 ",
    "url": "https://arxiv.org/abs/2112.08932",
    "authors": [
      "Trevor Ablett",
      "Bryan Chan",
      "Jonathan Kelly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2112.13697",
    "title": "Weakly Supervised Visual-Auditory Human-eye Fixation Prediction with  Multigranularity Perception",
    "abstract": " Title: Weakly Supervised Visual-Auditory Human-eye Fixation Prediction with  Multigranularity Perception ",
    "url": "https://arxiv.org/abs/2112.13697",
    "authors": [
      "Guotao Wang",
      "Chenglizhao Chen",
      "Deng-Ping Fan",
      "Aimin Hao",
      "Hong Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.05889",
    "title": "StolenEncoder: Stealing Pre-trained Encoders in Self-supervised Learning",
    "abstract": " Comments: To appear in ACM Conference on Computer and Communications Security (CCS), 2022 ",
    "url": "https://arxiv.org/abs/2201.05889",
    "authors": [
      "Yupei Liu",
      "Jinyuan Jia",
      "Hongbin Liu",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.13019",
    "title": "On the Robustness of Quality Measures for GANs",
    "abstract": " Comments: Accepted at the European Conference in Computer Vision (ECCV 2022) ",
    "url": "https://arxiv.org/abs/2201.13019",
    "authors": [
      "Motasem Alfarra",
      "Juan C. P\u00e9rez",
      "Anna Fr\u00fchst\u00fcck",
      "Philip H. S. Torr",
      "Peter Wonka",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02650",
    "title": "Efficient Privacy Preserving Logistic Regression for Horizontally  Distributed Data",
    "abstract": " Title: Efficient Privacy Preserving Logistic Regression for Horizontally  Distributed Data ",
    "url": "https://arxiv.org/abs/2202.02650",
    "authors": [
      "Guanhong Miao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)",
      "Other Statistics (stat.OT)"
    ]
  },
  {
    "id": "arXiv:2202.04208",
    "title": "Validating Causal Inference Methods",
    "abstract": " Comments: 5 figures, 13 pages ",
    "url": "https://arxiv.org/abs/2202.04208",
    "authors": [
      "Harsh Parikh",
      "Carlos Varjao",
      "Louise Xu",
      "Eric Tchetgen Tchetgen"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ]
  },
  {
    "id": "arXiv:2202.07261",
    "title": "Exploring the Devil in Graph Spectral Domain for 3D Point Cloud Attacks",
    "abstract": " Title: Exploring the Devil in Graph Spectral Domain for 3D Point Cloud Attacks ",
    "url": "https://arxiv.org/abs/2202.07261",
    "authors": [
      "Qianjiang Hu",
      "Daizong Liu",
      "Wei Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.01325",
    "title": "Self-Supervised Learning for Real-World Super-Resolution from Dual  Zoomed Observations",
    "abstract": " Comments: ECCV 2022 camera ready ",
    "url": "https://arxiv.org/abs/2203.01325",
    "authors": [
      "Zhilu Zhang",
      "Ruohao Wang",
      "Hongzhi Zhang",
      "Yunjin Chen",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03931",
    "title": "PASS: Part-Aware Self-Supervised Pre-Training for Person  Re-Identification",
    "abstract": " Comments: Accepted by ECCV2022. Codes are available at this https URL ",
    "url": "https://arxiv.org/abs/2203.03931",
    "authors": [
      "Kuan Zhu",
      "Haiyun Guo",
      "Tianyi Yan",
      "Yousong Zhu",
      "Jinqiao Wang",
      "Ming Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05203",
    "title": "MORE: Multi-Order RElation Mining for Dense Captioning in 3D Scenes",
    "abstract": " Comments: Accepted by ECCV 2022 ",
    "url": "https://arxiv.org/abs/2203.05203",
    "authors": [
      "Yang Jiao",
      "Shaoxiang Chen",
      "Zequn Jie",
      "Jingjing Chen",
      "Lin Ma",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.06145",
    "title": "Neuromorphic Data Augmentation for Training Spiking Neural Networks",
    "abstract": " Comments: Accepted to the 17th European Conference on Computer Vision (ECCV 2022) ",
    "url": "https://arxiv.org/abs/2203.06145",
    "authors": [
      "Yuhang Li",
      "Youngeun Kim",
      "Hyoungseob Park",
      "Tamar Geller",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.08606",
    "title": "A Reachability Index for Recursive Label-Concatenated Graph Queries",
    "abstract": " Title: A Reachability Index for Recursive Label-Concatenated Graph Queries ",
    "url": "https://arxiv.org/abs/2203.08606",
    "authors": [
      "Chao Zhang",
      "Angela Bonifati",
      "Hugo Kapp",
      "Vlad Ioan Haprian",
      "Jean-Pierre Lozi"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2203.11191",
    "title": "Robust Visual Tracking by Segmentation",
    "abstract": " Comments: Accepted at ECCV 2022. Code and trained models are available at: this https URL ",
    "url": "https://arxiv.org/abs/2203.11191",
    "authors": [
      "Matthieu Paul",
      "Martin Danelljan",
      "Christoph Mayer",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11654",
    "title": "Fine-Grained Scene Graph Generation with Data Transfer",
    "abstract": " Comments: ECCV 2022 (Oral) ",
    "url": "https://arxiv.org/abs/2203.11654",
    "authors": [
      "Ao Zhang",
      "Yuan Yao",
      "Qianyu Chen",
      "Wei Ji",
      "Zhiyuan Liu",
      "Maosong Sun",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.12961",
    "title": "Multilevel Bayesian Deep Neural Networks",
    "abstract": " Title: Multilevel Bayesian Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2203.12961",
    "authors": [
      "Neil K. Chada",
      "Ajay Jasra",
      "Kody J. H. Law",
      "Sumeetpal S. Singh"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.15946",
    "title": "Towards Learning Neural Representations from Shadows",
    "abstract": " Title: Towards Learning Neural Representations from Shadows ",
    "url": "https://arxiv.org/abs/2203.15946",
    "authors": [
      "Kushagra Tiwary",
      "Tzofi Klinghoffer",
      "Ramesh Raskar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.16317",
    "title": "PseCo: Pseudo Labeling and Consistency Training for Semi-Supervised  Object Detection",
    "abstract": " Comments: ECCV 2022 ",
    "url": "https://arxiv.org/abs/2203.16317",
    "authors": [
      "Gang Li",
      "Xiang Li",
      "Yujie Wang",
      "Yichao Wu",
      "Ding Liang",
      "Shanshan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.02804",
    "title": "Federated Self-supervised Speech Representations: Are We There Yet?",
    "abstract": " Title: Federated Self-supervised Speech Representations: Are We There Yet? ",
    "url": "https://arxiv.org/abs/2204.02804",
    "authors": [
      "Yan Gao",
      "Javier Fernandez-Marques",
      "Titouan Parcollet",
      "Abhinav Mehrotra",
      "Nicholas D. Lane"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.05141",
    "title": "Learning Object-Centered Autotelic Behaviors with Graph Neural Networks",
    "abstract": " Comments: 15 pages, 10 figures, published at the Conference on Lifelong Learning Agents COLLAS 2022 ",
    "url": "https://arxiv.org/abs/2204.05141",
    "authors": [
      "Ahmed Akakzia",
      "Olivier Sigaud"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.08682",
    "title": "Investigation of a Data Split Strategy Involving the Time Axis in  Adverse Event Prediction Using Machine Learning",
    "abstract": " Comments: 20 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2204.08682",
    "authors": [
      "Katsuhisa Morita",
      "Tadahaya Mizuno",
      "Hiroyuki Kusuhara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2205.02886",
    "title": "Data Augmentation for Manipulation",
    "abstract": " Comments: Robotics Science and Systems (RSS) 2022 Project Website: this https URL ",
    "url": "https://arxiv.org/abs/2205.02886",
    "authors": [
      "Peter Mitrano",
      "Dmitry Berenson"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.06230",
    "title": "Simple Open-Vocabulary Object Detection with Vision Transformers",
    "abstract": " Comments: ECCV 2022 camera-ready version ",
    "url": "https://arxiv.org/abs/2205.06230",
    "authors": [
      "Matthias Minderer",
      "Alexey Gritsenko",
      "Austin Stone",
      "Maxim Neumann",
      "Dirk Weissenborn",
      "Alexey Dosovitskiy",
      "Aravindh Mahendran",
      "Anurag Arnab",
      "Mostafa Dehghani",
      "Zhuoran Shen",
      "Xiao Wang",
      "Xiaohua Zhai",
      "Thomas Kipf",
      "Neil Houlsby"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.09944",
    "title": "6G Network AI Architecture for Everyone-Centric Customized Services",
    "abstract": " Title: 6G Network AI Architecture for Everyone-Centric Customized Services ",
    "url": "https://arxiv.org/abs/2205.09944",
    "authors": [
      "Yang Yang",
      "Mulei Ma",
      "Hequan Wu",
      "Quan Yu",
      "Ping Zhang",
      "Xiaohu You",
      "Jianjun Wu",
      "Chenghui Peng",
      "Tak-Shing Peter Yum",
      "Sherman Shen",
      "Hamid Aghvami",
      "Geoffrey Y Li",
      "Jiangzhou Wang",
      "Guangyi Liu",
      "Peng Gao",
      "Xiongyan Tang",
      "Chang Cao",
      "John Thompson",
      "Kat-Kit Wong",
      "Shanzhi Chen",
      "Merouane Debbah",
      "Schahram Dustdar",
      "Frank Eliassen",
      "Tao Chen",
      "Xiangyang Duan",
      "Shaohui Sun",
      "Xiaofeng Tao",
      "Qinyu Zhang",
      "Jianwei Huang",
      "Shuguang Cui",
      "Wenjun Zhang",
      "Jie Li",
      "Yue Gao",
      "Honggang Zhang",
      "Xu Chen",
      "Xiaohu Ge",
      "Yong Xiao",
      "Cheng-Xiang Wang",
      "Zaichen Zhang",
      "Song Ci",
      "Guoqiang Mao",
      "Changle Li",
      "Ziyu Shao",
      "Yong Zhou",
      "Junrui Liang",
      "Kai Li",
      "Liantao Wu",
      "Fanglei Sun",
      "Kunlun Wang",
      "Zening Liu",
      "Kun Yang",
      "Jun Wang",
      "Teng Gao",
      "Hongfeng Shu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.12796",
    "title": "Non-rigid Point Cloud Registration with Neural Deformation Pyramid",
    "abstract": " Comments: Code: this https URL ",
    "url": "https://arxiv.org/abs/2205.12796",
    "authors": [
      "Yang Li",
      "Tatsuya Harada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.04397",
    "title": "ESBMC-Jimple: Verifying Kotlin Programs via Jimple Intermediate  Representation",
    "abstract": " Comments: ACM SIGSOFT International Symposium on Software Testing and Analysis 2022 ",
    "url": "https://arxiv.org/abs/2206.04397",
    "authors": [
      "Rafael Menezes",
      "Daniel Moura",
      "Helena Cavalcante",
      "Rosiane de Freitas",
      "Lucas C. Cordeiro"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2206.09628",
    "title": "Diversified Adversarial Attacks based on Conjugate Gradient Method",
    "abstract": " Comments: Proceedings of the 39th International Conference on Machine Learning (ICML 2022) ",
    "url": "https://arxiv.org/abs/2206.09628",
    "authors": [
      "Keiichiro Yamamura",
      "Haruki Sato",
      "Nariaki Tateiwa",
      "Nozomi Hata",
      "Toru Mitsutake",
      "Issa Oe",
      "Hiroki Ishikura",
      "Katsuki Fujisawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.01975",
    "title": "Federated Self-supervised Learning for Video Understanding",
    "abstract": " Title: Federated Self-supervised Learning for Video Understanding ",
    "url": "https://arxiv.org/abs/2207.01975",
    "authors": [
      "Yasar Abbas Ur Rehman",
      "Yan Gao",
      "Jiajun Shen",
      "Pedro Porto Buarque de Gusmao",
      "Nicholas Lane"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.02192",
    "title": "CEN : Cooperatively Evolving Networks",
    "abstract": " Title: CEN : Cooperatively Evolving Networks ",
    "url": "https://arxiv.org/abs/2207.02192",
    "authors": [
      "Ch. Sobhan Babu",
      "Ravindra Guravannavar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05444",
    "title": "Category-Level 6D Object Pose and Size Estimation using Self-Supervised  Deep Prior Deformation Networks",
    "abstract": " Comments: Accepted by ECCV2022 ",
    "url": "https://arxiv.org/abs/2207.05444",
    "authors": [
      "Jiehong Lin",
      "Zewei Wei",
      "Changxing Ding",
      "Kui Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.06819",
    "title": "Anomal-E: A Self-Supervised Network Intrusion Detection System based on  Graph Neural Networks",
    "abstract": " Title: Anomal-E: A Self-Supervised Network Intrusion Detection System based on  Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2207.06819",
    "authors": [
      "Evan Caville",
      "Wai Weng Lo",
      "Siamak Layeghy",
      "Marius Portmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.08017",
    "title": "Is Soccer a lie or simply a complex system?",
    "abstract": " Comments: 15 pages, in Spanish language, 6 Figures ",
    "url": "https://arxiv.org/abs/2207.08017",
    "authors": [
      "Nelson Fernandez",
      "Ricardo Bernal"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2207.08435",
    "title": "Robust Simulation-Based Inference in Cosmology with Bayesian Neural  Networks",
    "abstract": " Comments: 5 pages, 3 figures. Accepted at the ML4Astro Machine Learning for Astrophysics Workshop at the Thirty-ninth International Conference on Machine Learning (ICML 2022) ",
    "url": "https://arxiv.org/abs/2207.08435",
    "authors": [
      "Pablo Lemos",
      "Miles Cranmer",
      "Muntazir Abidi",
      "ChangHoon Hahn",
      "Michael Eickenberg",
      "Elena Massara",
      "David Yallup",
      "Shirley Ho"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08609",
    "title": "ExAgt: Expert-guided Augmentation for Representation Learning of Traffic  Scenarios",
    "abstract": " Comments: Accepted as a conference paper in ITSC 2022, Macau, China ",
    "url": "https://arxiv.org/abs/2207.08609",
    "authors": [
      "Lakshman Balasubramanian",
      "Jonas Wurst",
      "Robin Egolf",
      "Michael Botsch",
      "Wolfgang Utschick",
      "Ke Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08782",
    "title": "Instance-Aware Observer Network for Out-of-Distribution Object  Segmentation",
    "abstract": " Title: Instance-Aware Observer Network for Out-of-Distribution Object  Segmentation ",
    "url": "https://arxiv.org/abs/2207.08782",
    "authors": [
      "Victor Besnier",
      "Andrei Bursuc",
      "David Picard",
      "Alexandre Briot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08824",
    "title": "3D Equivariant Molecular Graph Pretraining",
    "abstract": " Title: 3D Equivariant Molecular Graph Pretraining ",
    "url": "https://arxiv.org/abs/2207.08824",
    "authors": [
      "Rui Jiao",
      "Jiaqi Han",
      "Wenbing Huang",
      "Yu Rong",
      "Yang Liu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08978",
    "title": "A Security & Privacy Analysis of US-based Contact Tracing Apps",
    "abstract": " Title: A Security & Privacy Analysis of US-based Contact Tracing Apps ",
    "url": "https://arxiv.org/abs/2207.08978",
    "authors": [
      "Joydeep Mitra"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.09108",
    "title": "eCDT: Event Clustering for Simultaneous Feature Detection and Tracking-",
    "abstract": " Comments: IROS2022 accepted paper ",
    "url": "https://arxiv.org/abs/2207.09108",
    "authors": [
      "Sumin Hu",
      "Yeeun Kim",
      "Hyungtae Lim",
      "Alex Junho Lee",
      "Hyun Myung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09209",
    "title": "FLDetector: Defending Federated Learning Against Model Poisoning Attacks  via Detecting Malicious Clients",
    "abstract": " Comments: Accepted by KDD 2022 (Research Track) ",
    "url": "https://arxiv.org/abs/2207.09209",
    "authors": [
      "Zaixi Zhang",
      "Xiaoyu Cao",
      "Jinayuan Jia",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.09332",
    "title": "Rethinking IoU-based Optimization for Single-stage 3D Object Detection",
    "abstract": " Comments: Accepted by ECCV2022. The code is available at this https URL ",
    "url": "https://arxiv.org/abs/2207.09332",
    "authors": [
      "Hualian Sheng",
      "Sijia Cai",
      "Na Zhao",
      "Bing Deng",
      "Jianqiang Huang",
      "Xian-Sheng Hua",
      "Min-Jian Zhao",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]