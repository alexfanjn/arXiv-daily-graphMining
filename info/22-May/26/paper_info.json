[
  {
    "id": "arXiv:2205.12260",
    "title": "Releasing survey microdata with exact cluster locations and additional  privacy safeguards",
    "abstract": "Household survey programs around the world publish fine-granular georeferenced microdata to support research on the interdependence of human livelihoods and their surrounding environment. To safeguard the respondents' privacy, micro-level survey data is usually (pseudo)-anonymized through deletion or perturbation procedures such as obfuscating the true location of data collection. This, however, poses a challenge to emerging approaches that augment survey data with auxiliary information on a local level. Here, we propose an alternative microdata dissemination strategy that leverages the utility of the original microdata with additional privacy safeguards through synthetically generated data using generative models. We back our proposal with experiments using data from the 2011 Costa Rican census and satellite-derived auxiliary information. Our strategy reduces the respondents' re-identification risk for any number of disclosed attributes by 60-80\\% even under re-identification attempts. ",
    "url": "https://arxiv.org/abs/2205.12260",
    "authors": [
      "Till Koebe",
      "Alejandra Arias-Salazar"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2205.12262",
    "title": "PINO-MBD: Physics-informed Neural Operator for Solving Coupled ODEs in  Multi-body Dynamics",
    "abstract": "In multi-body dynamics, the motion of a complicated physical object is described as a coupled ordinary differential equation system with multiple unknown solutions. Engineers need to constantly adjust the object to meet requirements at the design stage, where a highly efficient solver is needed. The rise of machine learning-based partial differential equation solvers can meet this need. These solvers can be classified into two categories: approximating the solution function (Physics-informed neural network) and learning the solution operator (Neural operator). The recently proposed physics-informed neural operator (PINO) gains advantages from both categories by embedding physics equations into the loss function of a neural operator. Following this state-of-art concept, we propose the physics-informed neural operator for coupled ODEs in multi-body dynamics (PINO-MBD), which learns the mapping between parameter spaces and solution spaces. Once PINO-MBD is trained, only one forward pass of the network is required to obtain the solutions for a new instance with different parameters. To handle the difficulty that coupled ODEs contain multiple solutions (instead of only one in normal PDE problems), two new physics embedding methods are also proposed. The experimental results on classic vehicle-track coupled dynamics problem show state-of-art performance not only on solutions but also the first and second derivatives of solutions. ",
    "url": "https://arxiv.org/abs/2205.12262",
    "authors": [
      "Wenhao Ding",
      "Qing He",
      "Hanghang Tong",
      "Ping Wang"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2205.12295",
    "title": "lpSpikeCon: Enabling Low-Precision Spiking Neural Network Processing for  Efficient Unsupervised Continual Learning on Autonomous Agents",
    "abstract": "Recent advances have shown that SNN-based systems can efficiently perform unsupervised continual learning due to their bio-plausible learning rule, e.g., Spike-Timing-Dependent Plasticity (STDP). Such learning capabilities are especially beneficial for use cases like autonomous agents (e.g., robots and UAVs) that need to continuously adapt to dynamically changing scenarios/environments, where new data gathered directly from the environment may have novel features that should be learned online. Current state-of-the-art works employ high-precision weights (i.e., 32 bit) for both training and inference phases, which pose high memory and energy costs thereby hindering efficient embedded implementations of such systems for battery-driven mobile autonomous systems. On the other hand, precision reduction may jeopardize the quality of unsupervised continual learning due to information loss. Towards this, we propose lpSpikeCon, a novel methodology to enable low-precision SNN processing for efficient unsupervised continual learning on resource-constrained autonomous agents/systems. Our lpSpikeCon methodology employs the following key steps: (1) analyzing the impacts of training the SNN model under unsupervised continual learning settings with reduced weight precision on the inference accuracy; (2) leveraging this study to identify SNN parameters that have a significant impact on the inference accuracy; and (3) developing an algorithm for searching the respective SNN parameter values that improve the quality of unsupervised continual learning. The experimental results show that our lpSpikeCon can reduce weight memory of the SNN model by 8x (i.e., by judiciously employing 4-bit weights) for performing online training with unsupervised continual learning and achieve no accuracy loss in the inference phase, as compared to the baseline model with 32-bit weights across different network sizes. ",
    "url": "https://arxiv.org/abs/2205.12295",
    "authors": [
      "Rachmad Vidya Wicaksana Putra",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12311",
    "title": "Fast & Furious: Modelling Malware Detection as Evolving Data Streams",
    "abstract": "Malware is a major threat to computer systems and imposes many challenges to cyber security. Targeted threats, such as ransomware, cause millions of dollars in losses every year. The constant increase of malware infections has been motivating popular antiviruses (AVs) to develop dedicated detection strategies, which include meticulously crafted machine learning (ML) pipelines. However, malware developers unceasingly change their samples features to bypass detection. This constant evolution of malware samples causes changes to the data distribution (i.e., concept drifts) that directly affect ML model detection rates. In this work, we evaluate the impact of concept drift on malware classifiers for two Android datasets: DREBIN (~130K apps) and AndroZoo (~350K apps). Android is a ubiquitous operating system for smartphones, which stimulates attackers to regularly create and update malware to the platform. We conducted a longitudinal evaluation by (i) classifying malware samples collected over nine years (2009-2018), (ii) reviewing concept drift detection algorithms to attest its pervasiveness, (iii) comparing distinct ML approaches to mitigate the issue, and (iv) proposing an ML data stream pipeline that outperformed literature approaches. As a result, we observed that updating every component of the pipeline in response to concept drifts allows the classification model to achieve increasing detection rates as the data representation (extracted features) is updated. Furthermore, we discuss the impact of the changes on the classification models by comparing the variations in the extracted features. ",
    "url": "https://arxiv.org/abs/2205.12311",
    "authors": [
      "Fabr\u00edcio Ceschin",
      "Marcus Botacin",
      "Heitor Murilo Gomes",
      "Felipe Pinag\u00e9",
      "Luiz S. Oliveira",
      "Andr\u00e9 Gr\u00e9gio"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12318",
    "title": "ColdGuess: A General and Effective Relational Graph Convolutional  Network to Tackle Cold Start Cases",
    "abstract": "Low-quality listings and bad actor behavior in online retail websites threatens e-commerce business as these result in sub-optimal buying experience and erode customer trust. When a new listing is created, how to tell it has good-quality? Is the method effective, fast, and scalable? Previous approaches often have three limitations/challenges: (1) unable to handle cold start problems where new sellers/listings lack sufficient selling histories. (2) inability of scoring hundreds of millions of listings at scale, or compromise performance for scalability. (3) has space challenges from large-scale graph with giant e-commerce business size. To overcome these limitations/challenges, we proposed ColdGuess, an inductive graph-based risk predictor built upon a heterogeneous seller product graph, which effectively identifies risky seller/product/listings at scale. ColdGuess tackles the large-scale graph by consolidated nodes, and addresses the cold start problems using homogeneous influence1. The evaluation on real data demonstrates that ColdGuess has stable performance as the number of unknown features increases. It outperforms the lightgbm2 by up to 34 pcp ROC-AUC in a cold start case when a new seller sells a new product . The resulting system, ColdGuess, is effective, adaptable to changing risky seller behavior, and is already in production ",
    "url": "https://arxiv.org/abs/2205.12318",
    "authors": [
      "Bo He",
      "Xiang Song",
      "Vincent Gao",
      "Christos Faloutsos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12331",
    "title": "Certified Robustness Against Natural Language Attacks by Causal  Intervention",
    "abstract": "Deep learning models have achieved great success in many fields, yet they are vulnerable to adversarial examples. This paper follows a causal perspective to look into the adversarial vulnerability and proposes Causal Intervention by Semantic Smoothing (CISS), a novel framework towards robustness against natural language attacks. Instead of merely fitting observational data, CISS learns causal effects p(y|do(x)) by smoothing in the latent semantic space to make robust predictions, which scales to deep architectures and avoids tedious construction of noise customized for specific attacks. CISS is provably robust against word substitution attacks, as well as empirically robust even when perturbations are strengthened by unknown attack algorithms. For example, on YELP, CISS surpasses the runner-up by 6.7% in terms of certified robustness against word substitutions, and achieves 79.4% empirical robustness when syntactic attacks are integrated. ",
    "url": "https://arxiv.org/abs/2205.12331",
    "authors": [
      "Haiteng Zhao",
      "Chang Ma",
      "Xinshuai Dong",
      "Anh Tuan Luu",
      "Zhi-Hong Deng",
      "Hanwang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.12358",
    "title": "A Benchmark and Asymmetrical-Similarity Learning for Practical Image  Copy Detection",
    "abstract": "Image copy detection (ICD) aims to determine whether a query image is an edited copy of any image from a reference set. Currently, there are very limited public benchmarks for ICD, while all overlook a critical challenge in real-world applications, i.e., the distraction from hard negative queries. Specifically, some queries are not edited copies but are inherently similar to some reference images. These hard negative queries are easily false recognized as edited copies, significantly compromising the ICD accuracy. This observation motivates us to build the first ICD benchmark featuring this characteristic. Based on existing ICD datasets, this paper constructs a new dataset by additionally adding 100, 000 and 24, 252 hard negative pairs into the training and test set, respectively. Moreover, this paper further reveals a unique difficulty for solving the hard negative problem in ICD, i.e., there is a fundamental conflict between current metric learning and ICD. This conflict is: the metric learning adopts symmetric distance while the edited copy is an asymmetric (unidirectional) process, e.g., a partial crop is close to its holistic reference image and is an edited copy, while the latter cannot be the edited copy of the former (in spite the distance is equally small). This insight results in an Asymmetrical-Similarity Learning (ASL) method, which allows the similarity in two directions (the query <-> the reference image) to be different from each other. Experimental results show that ASL outperforms state-of-the-art methods by a clear margin, confirming that solving the symmetric-asymmetric conflict is critical for ICD. ",
    "url": "https://arxiv.org/abs/2205.12358",
    "authors": [
      "Wenhao Wang",
      "Yifan Sun",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12372",
    "title": "TorchNTK: A Library for Calculation of Neural Tangent Kernels of PyTorch  Models",
    "abstract": "We introduce torchNTK, a python library to calculate the empirical neural tangent kernel (NTK) of neural network models in the PyTorch framework. We provide an efficient method to calculate the NTK of multilayer perceptrons. We compare the explicit differentiation implementation against autodifferentiation implementations, which have the benefit of extending the utility of the library to any architecture supported by PyTorch, such as convolutional networks. A feature of the library is that we expose the user to layerwise NTK components, and show that in some regimes a layerwise calculation is more memory efficient. We conduct preliminary experiments to demonstrate use cases for the software and probe the NTK. ",
    "url": "https://arxiv.org/abs/2205.12372",
    "authors": [
      "Andrew Engel",
      "Zhichao Wang",
      "Anand D. Sarwate",
      "Sutanay Choudhury",
      "Tony Chiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12376",
    "title": "A Comparative Analysis of Ookla Speedtest and Measurement Labs Network  Diagnostic Test (NDT7)",
    "abstract": "Consumers, regulators, and ISPs all use client-based \"speed tests\" to measure network performance, both in single-user settings and in aggregate. Two prevalent speed tests, Ookla's Speedtest and Measurement Lab's Network Diagnostic Test (NDT), are often used for similar purposes, despite having significant differences in both the test design and implementation and in the infrastructure used to conduct measurements. In this paper, we present a comparative evaluation of Ookla and NDT7 (the latest version of NDT), both in controlled and wide-area settings. Our goal is to characterize when, how much and under what circumstances these two speed tests differ, as well as what factors contribute to the differences. To study the effects of the test design, we conduct a series of controlled, in-lab experiments under a variety of network conditions and usage modes (TCP congestion control, native vs. browser client). Our results show that Ookla and NDT7 report similar speeds when the latency between the client and server is low, but that the tools diverge when path latency is high. To characterize the behavior of these tools in wide-area deployment, we collect more than 40,000 pairs of Ookla and NDT7 measurements across six months and 67 households, with a range of ISPs and speed tiers. Our analysis demonstrates various systemic issues, including high variability in NDT7 test results and systematically under-performing servers in the Ookla network. ",
    "url": "https://arxiv.org/abs/2205.12376",
    "authors": [
      "Kyle MacMillan",
      "Tarun Mangla",
      "James Saxon",
      "Nicole P. Marwell",
      "Nick Feamster"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.12379",
    "title": "Imposing Gaussian Pre-Activations in a Neural Network",
    "abstract": "The goal of the present work is to propose a way to modify both the initialization distribution of the weights of a neural network and its activation function, such that all pre-activations are Gaussian. We propose a family of pairs initialization/activation, where the activation functions span a continuum from bounded functions (such as Heaviside or tanh) to the identity function. This work is motivated by the contradiction between existing works dealing with Gaussian pre-activations: on one side, the works in the line of the Neural Tangent Kernels and the Edge of Chaos are assuming it, while on the other side, theoretical and experimental results challenge this hypothesis. The family of pairs initialization/activation we are proposing will help us to answer this hot question: is it desirable to have Gaussian pre-activations in a neural network? ",
    "url": "https://arxiv.org/abs/2205.12379",
    "authors": [
      "Pierre Wolinski",
      "Julyan Arbel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.12382",
    "title": "VoynaSlov: A Data Set of Russian Social Media Activity during the 2022  Ukraine-Russia War",
    "abstract": "In this report, we describe a new data set called VoynaSlov which contains 21M+ Russian-language social media activities (i.e. tweets, posts, comments) made by Russian media outlets and by the general public during the time of war between Ukraine and Russia. We scraped the data from two major platforms that are widely used in Russia: Twitter and VKontakte (VK), a Russian social media platform based in Saint Petersburg commonly referred to as \"Russian Facebook\". We provide descriptions of our data collection process and data statistics that compare state-affiliated and independent Russian media, and also the two platforms, VK and Twitter. The main differences that distinguish our data from previously released data related to the ongoing war are its focus on Russian media and consideration of state-affiliation as well as the inclusion of data from VK, which is more suitable than Twitter for understanding Russian public sentiment considering its wide use within Russia. We hope our data set can facilitate future research on information warfare and ultimately enable the reduction and prevention of disinformation and opinion manipulation campaigns. The data set is available at https://github.com/chan0park/VoynaSlov and will be regularly updated as we continuously collect more data. ",
    "url": "https://arxiv.org/abs/2205.12382",
    "authors": [
      "Chan Young Park",
      "Julia Mendelsohn",
      "Anjalie Field",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.12390",
    "title": "Toxicity Detection with Generative Prompt-based Inference",
    "abstract": "Due to the subtleness, implicity, and different possible interpretations perceived by different people, detecting undesirable content from text is a nuanced difficulty. It is a long-known risk that language models (LMs), once trained on corpus containing undesirable content, have the power to manifest biases and toxicity. However, recent studies imply that, as a remedy, LMs are also capable of identifying toxic content without additional fine-tuning. Prompt-methods have been shown to effectively harvest this surprising self-diagnosing capability. However, existing prompt-based methods usually specify an instruction to a language model in a discriminative way. In this work, we explore the generative variant of zero-shot prompt-based toxicity detection with comprehensive trials on prompt engineering. We evaluate on three datasets with toxicity labels annotated on social media posts. Our analysis highlights the strengths of our generative classification approach both quantitatively and qualitatively. Interesting aspects of self-diagnosis and its ethical implications are discussed. ",
    "url": "https://arxiv.org/abs/2205.12390",
    "authors": [
      "Yau-Shian Wang",
      "Yingshan Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12396",
    "title": "Recipe2Vec: Multi-modal Recipe Representation Learning with Graph Neural  Networks",
    "abstract": "Learning effective recipe representations is essential in food studies. Unlike what has been developed for image-based recipe retrieval or learning structural text embeddings, the combined effect of multi-modal information (i.e., recipe images, text, and relation data) receives less attention. In this paper, we formalize the problem of multi-modal recipe representation learning to integrate the visual, textual, and relational information into recipe embeddings. In particular, we first present Large-RG, a new recipe graph data with over half a million nodes, making it the largest recipe graph to date. We then propose Recipe2Vec, a novel graph neural network based recipe embedding model to capture multi-modal information. Additionally, we introduce an adversarial attack strategy to ensure stable learning and improve performance. Finally, we design a joint objective function of node classification and adversarial learning to optimize the model. Extensive experiments demonstrate that Recipe2Vec outperforms state-of-the-art baselines on two classic food study tasks, i.e., cuisine category classification and region prediction. Dataset and codes are available at https://github.com/meettyj/Recipe2Vec. ",
    "url": "https://arxiv.org/abs/2205.12396",
    "authors": [
      "Yijun Tian",
      "Chuxu Zhang",
      "Zhichun Guo",
      "Yihong Ma",
      "Ronald Metoyer",
      "Nitesh V. Chawla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.12407",
    "title": "Convolutional Neural Processes for Inpainting Satellite Images",
    "abstract": "The widespread availability of satellite images has allowed researchers to model complex systems such as disease dynamics. However, many satellite images have missing values due to measurement defects, which render them unusable without data imputation. For example, the scanline corrector for the LANDSAT 7 satellite broke down in 2003, resulting in a loss of around 20\\% of its data. Inpainting involves predicting what is missing based on the known pixels and is an old problem in image processing, classically based on PDEs or interpolation methods, but recent deep learning approaches have shown promise. However, many of these methods do not explicitly take into account the inherent spatiotemporal structure of satellite images. In this work, we cast satellite image inpainting as a natural meta-learning problem, and propose using convolutional neural processes (ConvNPs) where we frame each satellite image as its own task or 2D regression problem. We show ConvNPs can outperform classical methods and state-of-the-art deep learning inpainting models on a scanline inpainting problem for LANDSAT 7 satellite images, assessed on a variety of in and out-of-distribution images. ",
    "url": "https://arxiv.org/abs/2205.12407",
    "authors": [
      "Alexander Pondaven",
      "M\u00e4rt Bakler",
      "Donghu Guo",
      "Hamzah Hashim",
      "Martin Ignatov",
      "Harrison Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12416",
    "title": "Counterfactual Data Augmentation improves Factuality of Abstractive  Summarization",
    "abstract": "Abstractive summarization systems based on pretrained language models often generate coherent but factually inconsistent sentences. In this paper, we present a counterfactual data augmentation approach where we augment data with perturbed summaries that increase the training data diversity. Specifically, we present three augmentation approaches based on replacing (i) entities from other and the same category and (ii) nouns with their corresponding WordNet hypernyms. We show that augmenting the training data with our approach improves the factual correctness of summaries without significantly affecting the ROUGE score. We show that in two commonly used summarization datasets (CNN/Dailymail and XSum), we improve the factual correctness by about 2.5 points on average ",
    "url": "https://arxiv.org/abs/2205.12416",
    "authors": [
      "Dheeraj Rajagopal",
      "Siamak Shakeri",
      "Cicero Nogueira dos Santos",
      "Eduard Hovy",
      "Chung-Ching Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.12424",
    "title": "VulBERTa: Simplified Source Code Pre-Training for Vulnerability  Detection",
    "abstract": "This paper presents VulBERTa, a deep learning approach to detect security vulnerabilities in source code. Our approach pre-trains a RoBERTa model with a custom tokenisation pipeline on real-world code from open-source C/C++ projects. The model learns a deep knowledge representation of the code syntax and semantics, which we leverage to train vulnerability detection classifiers. We evaluate our approach on binary and multi-class vulnerability detection tasks across several datasets (Vuldeepecker, Draper, REVEAL and muVuldeepecker) and benchmarks (CodeXGLUE and D2A). The evaluation results show that VulBERTa achieves state-of-the-art performance and outperforms existing approaches across different datasets, despite its conceptual simplicity, and limited cost in terms of size of training data and number of model parameters. ",
    "url": "https://arxiv.org/abs/2205.12424",
    "authors": [
      "Hazim Hanif",
      "Sergio Maffeis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12430",
    "title": "Additive Logistic Mechanism for Privacy-Preserving Self-Supervised  Learning",
    "abstract": "We study the privacy risks that are associated with training a neural network's weights with self-supervised learning algorithms. Through empirical evidence, we show that the fine-tuning stage, in which the network weights are updated with an informative and often private dataset, is vulnerable to privacy attacks. To address the vulnerabilities, we design a post-training privacy-protection algorithm that adds noise to the fine-tuned weights and propose a novel differential privacy mechanism that samples noise from the logistic distribution. Compared to the two conventional additive noise mechanisms, namely the Laplace and the Gaussian mechanisms, the proposed mechanism uses a bell-shaped distribution that resembles the distribution of the Gaussian mechanism, and it satisfies pure $\\epsilon$-differential privacy similar to the Laplace mechanism. We apply membership inference attacks on both unprotected and protected models to quantify the trade-off between the models' privacy and performance. We show that the proposed protection algorithm can effectively reduce the attack accuracy to roughly 50\\%-equivalent to random guessing-while maintaining a performance loss below 5\\%. ",
    "url": "https://arxiv.org/abs/2205.12430",
    "authors": [
      "Yunhao Yang",
      "Parham Gohari",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.12452",
    "title": "Sparse*BERT: Sparse Models are Robust",
    "abstract": "Large Language Models have become the core architecture upon which most modern natural language processing (NLP) systems build. These models can consistently deliver impressive accuracy and robustness across tasks and domains, but their high computational overhead can make inference difficult and expensive. To make the usage of these models less costly recent work has explored leveraging structured and unstructured pruning, quantization, and distillation as ways to improve inference speed and decrease size. This paper studies how models pruned using Gradual Unstructured Magnitude Pruning can transfer between domains and tasks. Our experimentation shows that models that are pruned during pretraining using general domain masked language models can transfer to novel domains and tasks without extensive hyperparameter exploration or specialized approaches. We demonstrate that our general sparse model Sparse*BERT can become SparseBioBERT simply by pretraining the compressed architecture on unstructured biomedical text. Moreover, we show that SparseBioBERT can match the quality of BioBERT with only 10\\% of the parameters. ",
    "url": "https://arxiv.org/abs/2205.12452",
    "authors": [
      "Daniel Campos",
      "Alexandre Marques",
      "Tuan Nguyen",
      "Mark Kurtz",
      "ChengXiang Zhai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12454",
    "title": "Recipe for a General, Powerful, Scalable Graph Transformer",
    "abstract": "We propose a recipe on how to build a general, powerful, scalable (GPS) graph Transformer with linear complexity and state-of-the-art results on a diverse set of benchmarks. Graph Transformers (GTs) have gained popularity in the field of graph representation learning with a variety of recent publications but they lack a common foundation about what constitutes a good positional or structural encoding, and what differentiates them. In this paper, we summarize the different types of encodings with a clearer definition and categorize them as being $\\textit{local}$, $\\textit{global}$ or $\\textit{relative}$. Further, GTs remain constrained to small graphs with few hundred nodes, and we propose the first architecture with a complexity linear to the number of nodes and edges $O(N+E)$ by decoupling the local real-edge aggregation from the fully-connected Transformer. We argue that this decoupling does not negatively affect the expressivity, with our architecture being a universal function approximator for graphs. Our GPS recipe consists of choosing 3 main ingredients: (i) positional/structural encoding, (ii) local message-passing mechanism, and (iii) global attention mechanism. We build and open-source a modular framework $\\textit{GraphGPS}$ that supports multiple types of encodings and that provides efficiency and scalability both in small and large graphs. We test our architecture on 11 benchmarks and show very competitive results on all of them, show-casing the empirical benefits gained by the modularity and the combination of different strategies. ",
    "url": "https://arxiv.org/abs/2205.12454",
    "authors": [
      "Ladislav Ramp\u00e1\u0161ek",
      "Mikhail Galkin",
      "Vijay Prakash Dwivedi",
      "Anh Tuan Luu",
      "Guy Wolf",
      "Dominique Beaini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12458",
    "title": "A Lightweight NMS-free Framework for Real-time Visual Fault Detection  System of Freight Trains",
    "abstract": "Real-time vision-based system of fault detection (RVBS-FD) for freight trains is an essential part of ensuring railway transportation safety. Most existing vision-based methods still have high computational costs based on convolutional neural networks. The computational cost is mainly reflected in the backbone, neck, and post-processing, i.e., non-maximum suppression (NMS). In this paper, we propose a lightweight NMS-free framework to achieve real-time detection and high accuracy simultaneously. First, we use a lightweight backbone for feature extraction and design a fault detection pyramid to process features. This fault detection pyramid includes three novel individual modules using attention mechanism, bottleneck, and dilated convolution for feature enhancement and computation reduction. Instead of using NMS, we calculate different loss functions, including classification and location costs in the detection head, to further reduce computation. Experimental results show that our framework achieves over 83 frames per second speed with a smaller model size and higher accuracy than the state-of-the-art detectors. Meanwhile, the hardware resource requirements of our method are low during the training and testing process. ",
    "url": "https://arxiv.org/abs/2205.12458",
    "authors": [
      "Guodong Sun",
      "Yang Zhou",
      "Huilin Pan",
      "Bo Wu",
      "Ye Hu",
      "Yang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.12465",
    "title": "FBNETGEN: Task-aware GNN-based fMRI Analysis via Functional Brain  Network Generation",
    "abstract": "Functional magnetic resonance imaging (fMRI) is one of the most common imaging modalities to investigate brain functions. Recent studies in neuroscience stress the great potential of functional brain networks constructed from fMRI data for clinical predictions. Traditional functional brain networks, however, are noisy and unaware of downstream prediction tasks, while also incompatible with the deep graph neural network (GNN) models. In order to fully unleash the power of GNNs in network-based fMRI analysis, we develop FBNETGEN, a task-aware and interpretable fMRI analysis framework via deep brain network generation. In particular, we formulate (1) prominent region of interest (ROI) features extraction, (2) brain networks generation, and (3) clinical predictions with GNNs, in an end-to-end trainable model under the guidance of particular prediction tasks. Along with the process, the key novel component is the graph generator which learns to transform raw time-series features into task-oriented brain networks. Our learnable graphs also provide unique interpretations by highlighting prediction-related brain regions. Comprehensive experiments on two datasets, i.e., the recently released and currently largest publicly available fMRI dataset Adolescent Brain Cognitive Development (ABCD), and the widely-used fMRI dataset PNC, prove the superior effectiveness and interpretability of FBNETGEN. The implementation is available at https://github.com/Wayfear/FBNETGEN.} ",
    "url": "https://arxiv.org/abs/2205.12465",
    "authors": [
      "Xuan Kan",
      "Hejie Cui",
      "Joshua Lukemire",
      "Ying Guo",
      "Carl Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2205.12467",
    "title": "R2D2: Robust Data-to-Text with Replacement Detection",
    "abstract": "Unfaithful text generation is a common problem for text generation systems. In the case of Data-to-Text (D2T) systems, the factuality of the generated text is particularly crucial for any real-world applications. We introduce R2D2, a training framework that addresses unfaithful Data-to-Text generation by training a system both as a generator and a faithfulness discriminator with additional replacement detection and unlikelihood learning tasks. To facilitate such training, we propose two methods for sampling unfaithful sentences. We argue that the poor entity retrieval capability of D2T systems is one of the primary sources of unfaithfulness, so in addition to the existing metrics, we further propose NER-based metrics to evaluate the fidelity of D2T generations. Our experimental results show that R2D2 systems could effectively mitigate the unfaithful text generation, and they achieve new state-of-the-art results on FeTaQA, LogicNLG, and ToTTo, all with significant improvements. ",
    "url": "https://arxiv.org/abs/2205.12467",
    "authors": [
      "Linyong Nan",
      "Lorenzo Jaime Yu Flores",
      "Yilun Zhao",
      "Yixin Liu",
      "Luke Benson",
      "Weijin Zou",
      "Dragomir Radev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.12474",
    "title": "A Correlation Analysis and Visualization of Climate Change using  Post-Disaster Heterogeneous Datasets",
    "abstract": "There are numerous geo-climatic and human factors that contribute to the occurrence of natural disasters in the real-world scenario. Besides the study of causes and preconditions of such calamities, post-disaster analysis is essential for the efficient management of the disaster situation. This process needs timely and accurate data in light of the increasing frequency and severity of climate change-related extreme weather events. The analysis of disaster data involves the challenging task of integrating multiple heterogeneous sources, data ingestion and visualization. This paper aims at providing a three-dimensional analytical view of disaster data as time-series charts and a statistical model to evaluate the correlation between the occurrence of disasters, climate change and the corresponding economic damages (as a percentage of GDP). Therefore, statistical methodologies are leveraged to play important role in managing disasters, from preparation to recovery and reporting. The graphical representations provide insights on regional trends that follow, related to factors such as the proportion of each type of disaster in the various losses incurred. Therefore, obtaining reliable information about the population, the economy and climate are crucial both for risk management and preparedness and for responding to disasters. The research puts forth a detailed statistical methodology with a spatial dimension to study the impacts on the economy and infrastructure in the aftermath of a disaster thereby ensuring specialized assistance. The inference of the analysis confirmed a positive correlation between climate change and occurrence of natural disasters. Therefore, statistical evidence of an important phenomenon like climate change affecting natural disasters brings awareness among the population in the society to be more environmentally responsible. ",
    "url": "https://arxiv.org/abs/2205.12474",
    "authors": [
      "Sukeerthi Mandyam",
      "Shanmuga Priya",
      "Shalini Suresh",
      "Kavitha Srinivasan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2205.12493",
    "title": "Federated Self-supervised Learning for Heterogeneous Clients",
    "abstract": "Federated Learning has become an important learning paradigm due to its privacy and computational benefits. As the field advances, two key challenges that still remain to be addressed are: (1) system heterogeneity - variability in the compute and/or data resources present on each client, and (2) lack of labeled data in certain federated settings. Several recent developments have tried to overcome these challenges independently. In this work, we propose a unified and systematic framework, \\emph{Heterogeneous Self-supervised Federated Learning} (Hetero-SSFL) for enabling self-supervised learning with federation on heterogeneous clients. The proposed framework allows collaborative representation learning across all the clients without imposing architectural constraints or requiring presence of labeled data. The key idea in Hetero-SSFL is to let each client train its unique self-supervised model and enable the joint learning across clients by aligning the lower dimensional representations on a common dataset. The entire training procedure could be viewed as self and peer-supervised as both the local training and the alignment procedures do not require presence of any labeled data. As in conventional self-supervised learning, the obtained client models are task independent and can be used for varied end-tasks. We provide a convergence guarantee of the proposed framework for non-convex objectives in heterogeneous settings and also empirically demonstrate that our proposed approach outperforms the state of the art methods by a significant margin. ",
    "url": "https://arxiv.org/abs/2205.12493",
    "authors": [
      "Disha Makhija",
      "Nhat Ho",
      "Joydeep Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.12495",
    "title": "ToKen: Task Decomposition and Knowledge Infusion for Few-Shot Hate  Speech Detection",
    "abstract": "Hate speech detection is complex; it relies on commonsense reasoning, knowledge of stereotypes, and an understanding of social nuance that differs from one culture to the next. It is also difficult to collect a large-scale hate speech annotated dataset. In this work, we frame this problem as a few-shot learning task, and show significant gains with decomposing the task into its \"constituent\" parts. In addition, we see that infusing knowledge from reasoning datasets (e.g. Atomic2020) improves the performance even further. Moreover, we observe that the trained models generalize to out-of-distribution datasets, showing the superiority of task decomposition and knowledge infusion compared to previously used methods. Concretely, our method outperforms the baseline by 17.83% absolute gain in the 16-shot case. ",
    "url": "https://arxiv.org/abs/2205.12495",
    "authors": [
      "Badr AlKhamissi",
      "Faisal Ladhak",
      "Srini Iyer",
      "Ves Stoyanov",
      "Zornitsa Kozareva",
      "Xian Li",
      "Pascale Fung",
      "Lambert Mathias",
      "Asli Celikyilmaz",
      "Mona Diab"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.12514",
    "title": "Machine Translation Robustness to Natural Asemantic Variation",
    "abstract": "We introduce and formalize an under-studied linguistic phenomenon we call Natural Asemantic Variation (NAV) and investigate it in the context of Machine Translation (MT) robustness. Standard MT models are shown to be less robust to rarer, nuanced language forms, and current robustness techniques do not account for this kind of perturbation despite their prevalence in \"real world\" data. Experiment results provide more insight into the nature of NAV and we demonstrate strategies to improve performance on NAV. We also show that NAV robustness can be transferred across languages and fine that synthetic perturbations can achieve some but not all of the benefits of human-generated NAV data. ",
    "url": "https://arxiv.org/abs/2205.12514",
    "authors": [
      "Jacob Bremerman",
      "Xiang Ren",
      "Jonathan May"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.12519",
    "title": "Structure Aware and Class Balanced 3D Object Detection on nuScenes  Dataset",
    "abstract": "3-D object detection is pivotal for autonomous driving. Point cloud based methods have become increasingly popular for 3-D object detection, owing to their accurate depth information. NuTonomy's nuScenes dataset greatly extends commonly used datasets such as KITTI in size, sensor modalities, categories, and annotation numbers. However, it suffers from severe class imbalance. The Class-balanced Grouping and Sampling paper addresses this issue and suggests augmentation and sampling strategy. However, the localization precision of this model is affected by the loss of spatial information in the downscaled feature maps. We propose to enhance the performance of the CBGS model by designing an auxiliary network, that makes full use of the structure information of the 3D point cloud, in order to improve the localization accuracy. The detachable auxiliary network is jointly optimized by two point-level supervisions, namely foreground segmentation and center estimation. The auxiliary network does not introduce any extra computation during inference, since it can be detached at test time. ",
    "url": "https://arxiv.org/abs/2205.12519",
    "authors": [
      "Sushruth Nagesh",
      "Asfiya Baig",
      "Savitha Srinivasan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12535",
    "title": "\"Help! Can You Hear Me?\": Understanding How Help-Seeking Posts are  Overwhelmed on Social Media during a Natural Disaster",
    "abstract": "Posting help-seeking requests on social media has been broadly adopted by victims during natural disasters to look for urgent rescue and supplies. The help-seeking requests need to get sufficient public attention and be promptly routed to the intended target(s) for timely responses. However, the huge volume and diverse types of crisis-related posts on social media might limit help-seeking requests to receive adequate engagement and lead to their overwhelm. To understand this problem, this work proposes a mixed-methods approach to figure out the overwhelm situation of help-seeking requests, and individuals' and online communities' strategies to cope. We focused on the 2021 Henan Floods in China and collected 141,674 help-seeking posts with the keyword \"Henan Rainstorm Mutual Aid\" on a popular Chinese social media platform Weibo. The findings indicate that help-seeking posts confront critical challenges of both external overwhelm (i.e., an enormous number of non-help-seeking posts with the help-seeking-related keyword distracting public attention) and internal overwhelm (i.e., attention inequality with 5% help-seeking posts receiving more than 95% likes, comments, and shares). We discover linguistic and non-linguistic help-seeking strategies that could help to prevent the overwhelm, such as including contact information, disclosing situational vulnerabilities, using subjective narratives, and structuring help-seeking posts to a normalized syntax. We also illustrate how community members spontaneously work to prevent the overwhelm with their collective wisdom (e.g., norm development through discussion) and collaborative work (e.g., cross-community support). We reflect on how the findings enrich the literature in crisis informatics and raise design implications that facilitate effective help-seeking on social media during natural disasters. ",
    "url": "https://arxiv.org/abs/2205.12535",
    "authors": [
      "Changyang He",
      "Yue Deng",
      "Wenjie Yang",
      "Bo Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2205.12543",
    "title": "Misleading Deep-Fake Detection with GAN Fingerprints",
    "abstract": "Generative adversarial networks (GANs) have made remarkable progress in synthesizing realistic-looking images that effectively outsmart even humans. Although several detection methods can recognize these deep fakes by checking for image artifacts from the generation process, multiple counterattacks have demonstrated their limitations. These attacks, however, still require certain conditions to hold, such as interacting with the detection method or adjusting the GAN directly. In this paper, we introduce a novel class of simple counterattacks that overcomes these limitations. In particular, we show that an adversary can remove indicative artifacts, the GAN fingerprint, directly from the frequency spectrum of a generated image. We explore different realizations of this removal, ranging from filtering high frequencies to more nuanced frequency-peak cleansing. We evaluate the performance of our attack with different detection methods, GAN architectures, and datasets. Our results show that an adversary can often remove GAN fingerprints and thus evade the detection of generated images. ",
    "url": "https://arxiv.org/abs/2205.12543",
    "authors": [
      "Vera Wesselkamp",
      "Konrad Rieck",
      "Daniel Arp",
      "Erwin Quiring"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.12550",
    "title": "Learning dynamics from partial observations with structured neural ODEs",
    "abstract": "Identifying dynamical systems from experimental data is a notably difficult task. Prior knowledge generally helps, but the extent of this knowledge varies with the application, and customized models are often needed. We propose a flexible framework to incorporate a broad spectrum of physical insight into neural ODE-based system identification, giving physical interpretability to the resulting latent space. This insight is either enforced through hard constraints in the optimization problem or added in its cost function. In order to link the partial and possibly noisy observations to the latent state, we rely on tools from nonlinear observer theory to build a recognition model. We demonstrate the performance of the proposed approach on numerical simulations and on an experimental dataset from a robotic exoskeleton. ",
    "url": "https://arxiv.org/abs/2205.12550",
    "authors": [
      "Mona Buisson-Fenet",
      "Valery Morgenthaler",
      "Sebastian Trimpe",
      "Florent Di Meglio"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12558",
    "title": "Constrained Sampling from Language Models via Langevin Dynamics in  Embedding Spaces",
    "abstract": "Large pre-trained language models are well-established for their ability to generate text seemingly indistinguishable from humans. In this work, we study the problem of constrained sampling from such language models. That is, generating text that satisfies user-defined constraints. Typical decoding strategies which generate samples left-to-right are not always conducive to imposing such constraints globally. Instead, we propose MuCoLa -- a sampling procedure that combines the log-likelihood of the language model with arbitrary differentiable constraints into a single energy function; and generates samples by initializing the entire output sequence with noise and following a Markov chain defined by Langevin Dynamics using the gradients of this energy. We evaluate our approach on different text generation tasks with soft and hard constraints as well as their combinations with competitive results for toxicity avoidance, sentiment control, and keyword-guided generation. ",
    "url": "https://arxiv.org/abs/2205.12558",
    "authors": [
      "Sachin Kumar",
      "Biswajit Paria",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.12559",
    "title": "Envy-Free Cake Cutting with Graph Constraints",
    "abstract": "We study the classic problem of fairly dividing a heterogeneous and divisible resource -- represented by a cake, $[0,1]$ -- among $n$ agents. This work considers an interesting variant of the problem where agents are embedded on a graph. The graphical constraint entails that each agent evaluates her allocated share only against her neighbor's share. Given a graph, the goal is to efficiently find a locally envy-free allocation where every agent values her share to be at least as much as any of her neighbor's share. The best known algorithm (by Aziz and Mackenzie) for finding envy-free cake divisions has a hyper-exponential query complexity. One of the key technical contributions of this work is to identify a non-trivial graph structure -- tree graphs with depth at-most two (Depth2Tree) -- on $n$ agents that admits a query efficient cake-cutting protocol (under the Robertson-Webb query model). In particular, we develop a discrete protocol that finds a locally envy-free allocation among $n$ agents on depth-two trees with at-most $O(n^3 \\log(n))$ cuts on the cake. For the special case of Depth2Tree where every non-root agent is connected to at-most two agents (2-Star), we show that $O(n^2)$ queries suffice. We complement our algorithmic results with establishing a lower bound of $\\Omega(n^2)$ (evaluation) queries for finding a locally envy-free allocation among $n$ agents on a 1-Star graph (under the assumption that the root agent partitions the cake into $n$ connected pieces). ",
    "url": "https://arxiv.org/abs/2205.12559",
    "authors": [
      "Ganesh Ghalme",
      "Xin Huang",
      "Nidhi Rathi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2205.12568",
    "title": "The security of the Coordicide: the implementation and analysis of  possible attack vectors",
    "abstract": "The goal of the thesis is to study and perform an analysis of the possible attack vectors on the Iota network 2.0 version of the protocol. In this work, existing attack vectors on Distributed Ledger Technologies are studied and their applicability to the Iota 2.0 protocol is discussed. A specific attack that targets the capability of honest participants to write to the ledger is presented and analyzed in a network of nodes that run a full node software version. ",
    "url": "https://arxiv.org/abs/2205.12568",
    "authors": [
      "Daria Dziuba\u0142towska"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.12579",
    "title": "From Pedestrian Detection to Crosswalk Estimation: An EM Algorithm and  Analysis on Diverse Datasets",
    "abstract": "In this work, we contribute an EM algorithm for estimation of corner points and linear crossing segments for both marked and unmarked pedestrian crosswalks using the detections of pedestrians from processed LiDAR point clouds or camera images. We demonstrate the algorithmic performance by analyzing three real-world datasets containing multiple periods of data collection for four-corner and two-corner intersections with marked and unmarked crosswalks. Additionally, we include a Python video tool to visualize the crossing parameter estimation, pedestrian trajectories, and phase intervals in our public source code. ",
    "url": "https://arxiv.org/abs/2205.12579",
    "authors": [
      "Ross Greer",
      "Mohan Trivedi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12583",
    "title": "MUG: Multi-human Graph Network for 3D Mesh Reconstruction from 2D Pose",
    "abstract": "Reconstructing multi-human body mesh from a single monocular image is an important but challenging computer vision problem. In addition to the individual body mesh models, we need to estimate relative 3D positions among subjects to generate a coherent representation. In this work, through a single graph neural network, named MUG (Multi-hUman Graph network), we construct coherent multi-human meshes using only multi-human 2D pose as input. Compared with existing methods, which adopt a detection-style pipeline (i.e., extracting image features and then locating human instances and recovering body meshes from that) and suffer from the significant domain gap between lab-collected training datasets and in-the-wild testing datasets, our method benefits from the 2D pose which has a relatively consistent geometric property across datasets. Our method works like the following: First, to model the multi-human environment, it processes multi-human 2D poses and builds a novel heterogeneous graph, where nodes from different people and within one person are connected to capture inter-human interactions and draw the body geometry (i.e., skeleton and mesh structure). Second, it employs a dual-branch graph neural network structure -- one for predicting inter-human depth relation and the other one for predicting root-joint-relative mesh coordinates. Finally, the entire multi-human 3D meshes are constructed by combining the output from both branches. Extensive experiments demonstrate that MUG outperforms previous multi-human mesh estimation methods on standard 3D human benchmarks -- Panoptic, MuPoTS-3D and 3DPW. ",
    "url": "https://arxiv.org/abs/2205.12583",
    "authors": [
      "Chenyan Wu",
      "Yandong Li",
      "Xianfeng Tang",
      "James Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12586",
    "title": "Perturbation Augmentation for Fairer NLP",
    "abstract": "Unwanted and often harmful social biases are becoming ever more salient in NLP research, affecting both models and datasets. In this work, we ask: does training on demographically perturbed data lead to more fair language models? We collect a large dataset of human annotated text perturbations and train an automatic perturber on it, which we show to outperform heuristic alternatives. We find: (i) Language models (LMs) pre-trained on demographically perturbed corpora are more fair, at least, according to our current best metrics for measuring model fairness, and (ii) LMs finetuned on perturbed GLUE datasets exhibit less demographic bias on downstream tasks. We find that improved fairness does not come at the expense of accuracy. Although our findings appear promising, there are still some limitations, as well as outstanding questions about how best to evaluate the (un)fairness of large language models. We hope that this initial exploration of neural demographic perturbation will help drive more improvement towards fairer NLP. ",
    "url": "https://arxiv.org/abs/2205.12586",
    "authors": [
      "Rebecca Qian",
      "Candace Ross",
      "Jude Fernandes",
      "Eric Smith",
      "Douwe Kiela",
      "Adina Williams"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12591",
    "title": "On Secure NOMA-CDRT Systems with Physical Layer Network Coding",
    "abstract": "This paper proposes a new scheme to enhance the secrecy performance of a NOMA-based coordinated direct relay transmission system (NOMA-CDRT) with an untrusted relay. The physical-layer network coding and the non-orthogonal multiple access scheme are combined to improve the spectrum efficiency. Furthermore, inter-user interference and friendly jamming signals are utilized to suppress the eavesdropping ability of the untrusted relay without affecting the acceptance quality of legitimate users. Specifically, the far user in the first slot and the near user in the second slot act as jammers to generate jamming signals to ensure secure transmissions of the confidential signals. We investigate the secrecy performance of the proposed scheme in NOMA-CDRT systems and derive the closed-form expression for the ergodic secrecy sum rate. The asymptotic analysis at high signal-to-noise ratio is performed to obtain more insights. Finally, simulation results are presented to demonstrate the effectiveness of the proposed scheme and the correctness of the theoretical analysis. ",
    "url": "https://arxiv.org/abs/2205.12591",
    "authors": [
      "Hongjiang Lei",
      "Xusheng She",
      "Ki-Hong Park",
      "Imran Shafique Ansari",
      "Zheng Shi",
      "Jing Jiang",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2205.12594",
    "title": "Heterogeneous Reservoir Computing Models for Persian Speech Recognition",
    "abstract": "Over the last decade, deep-learning methods have been gradually incorporated into conventional automatic speech recognition (ASR) frameworks to create acoustic, pronunciation, and language models. Although it led to significant improvements in ASRs' recognition accuracy, due to their hard constraints related to hardware requirements (e.g., computing power and memory usage), it is unclear if such approaches are the most computationally- and energy-efficient options for embedded ASR applications. Reservoir computing (RC) models (e.g., echo state networks (ESNs) and liquid state machines (LSMs)), on the other hand, have been proven inexpensive to train, have vastly fewer parameters, and are compatible with emergent hardware technologies. However, their performance in speech processing tasks is relatively inferior to that of the deep-learning-based models. To enhance the accuracy of the RC in ASR applications, we propose heterogeneous single and multi-layer ESNs to create non-linear transformations of the inputs that capture temporal context at different scales. To test our models, we performed a speech recognition task on the Farsdat Persian dataset. Since, to the best of our knowledge, standard RC has not yet been employed to conduct any Persian ASR tasks, we also trained conventional single-layer and deep ESNs to provide baselines for comparison. Besides, we compared the RC performance with a standard long-short-term memory (LSTM) model. Heterogeneous RC models (1) show improved performance to the standard RC models; (2) perform on par in terms of recognition accuracy with the LSTM, and (3) reduce the training time considerably. ",
    "url": "https://arxiv.org/abs/2205.12594",
    "authors": [
      "Zohreh Ansari",
      "Farzin Pourhoseini",
      "Fatemeh Hadaeghi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.12597",
    "title": "Near-Optimal Leader Election in Population Protocols on Graphs",
    "abstract": "In the stochastic population protocol model, we are given a connected graph with $n$ nodes, and in every time step, a scheduler samples an edge of the graph uniformly at random and the nodes connected by this edge interact. A fundamental task in this model is stable leader election, in which all nodes start in an identical state and the aim is to reach a configuration in which (1) exactly one node is elected as leader and (2) this node remains as the unique leader no matter what sequence of interactions follows. On cliques, the complexity of this problem has recently been settled: time-optimal protocols stabilize in $\\Theta(n \\log n)$ expected steps using $\\Theta(\\log \\log n)$ states, whereas protocols that use $O(1)$ states require $\\Theta(n^2)$ expected steps. In this work, we investigate the complexity of stable leader election on general graphs. We provide the first non-trivial time lower bounds for leader election on general graphs, showing that, when moving beyond cliques, the complexity landscape of leader election becomes very diverse: the time required to elect a leader can range from $O(1)$ to $\\Theta(n^3)$ expected steps. On the upper bound side, we first observe that there exists a protocol that is time-optimal on many graph families, but uses polynomially-many states. In contrast, we give a near-time-optimal protocol that uses only $O(\\log^2n)$ states that is at most a factor $\\log n$ slower. Finally, we show that the constant-state protocol of Beauquier et al. [OPODIS 2013] is at most a factor $n \\log n$ slower than the fast polynomial-state protocol. Moreover, among constant-state protocols, this protocol has near-optimal average case complexity on dense random graphs. ",
    "url": "https://arxiv.org/abs/2205.12597",
    "authors": [
      "Dan Alistarh",
      "Joel Rybicki",
      "Sasha Voitovych"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.12598",
    "title": "RobustLR: Evaluating Robustness to Logical Perturbation in Deductive  Reasoning",
    "abstract": "Transformers have been shown to be able to perform deductive reasoning on a logical rulebase containing rules and statements written in English natural language. While the progress is promising, it is currently unclear if these models indeed perform logical reasoning by understanding the underlying logical semantics in the language. To this end, we propose RobustLR, a suite of evaluation datasets that evaluate the robustness of these models to minimal logical edits in rulebases and some standard logical equivalence conditions. In our experiments with RoBERTa and T5, we find that the models trained in prior works do not perform consistently on the different perturbations in RobustLR, thus showing that the models are not robust to the proposed logical perturbations. Further, we find that the models find it especially hard to learn logical negation and disjunction operators. Overall, using our evaluation sets, we demonstrate some shortcomings of the deductive reasoning-based language models, which can eventually help towards designing better models for logical reasoning over natural language. ",
    "url": "https://arxiv.org/abs/2205.12598",
    "authors": [
      "Soumya Sanyal",
      "Zeyi Liao",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2205.12601",
    "title": "Learning Distributions by Generative Adversarial Networks: Approximation  and Generalization",
    "abstract": "We study how well generative adversarial networks (GAN) learn probability distributions from finite samples by analyzing the convergence rates of these models. Our analysis is based on a new oracle inequality that decomposes the estimation error of GAN into the discriminator and generator approximation errors, generalization error and optimization error. To estimate the discriminator approximation error, we establish error bounds on approximating H\\\"older functions by ReLU neural networks, with explicit upper bounds on the Lipschitz constant of the network or norm constraint on the weights. For generator approximation error, we show that neural network can approximately transform a low-dimensional source distribution to a high-dimensional target distribution and bound such approximation error by the width and depth of neural network. Combining the approximation results with generalization bounds of neural networks from statistical learning theory, we establish the convergence rates of GANs in various settings, when the error is measured by a collection of integral probability metrics defined through H\\\"older classes, including the Wasserstein distance as a special case. In particular, for distributions concentrated around a low-dimensional set, we show that the convergence rates of GANs do not depend on the high ambient dimension, but on the lower intrinsic dimension. ",
    "url": "https://arxiv.org/abs/2205.12601",
    "authors": [
      "Yunfei Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.12604",
    "title": "Intermediate Training on Question Answering Datasets Improves Generative  Data Augmentation",
    "abstract": "Manually annotating datasets requires domain experts to read through many documents and carefully label them, which is often expensive. Recently, pre-trained generative language models (GLMs) have demonstrated exceptional abilities in generating text which motivates to leverage them for generative data augmentation. We improve generative data augmentation by formulating the data generation as context generation task and use question answering (QA) datasets for intermediate training. Specifically, we view QA to be more as a format than of a task and train GLMs as context generators for a given question and its respective answer. Then, we cast downstream tasks into question answering format and adapt the fine-tuned context generators to the target task domain. Finally, we use the fine-tuned GLM to generate relevant contexts, which is further used as synthetic training data for their corresponding tasks. We perform extensive experiments, case studies, and ablation studies on multiple sentiment and topic classification datasets and demonstrate substantial improvements in performance in few-shot, zero-shot settings. Remarkably, on the SST-2 dataset, intermediate training on SocialIQA dataset achieves an improvement of 40% on Macro-F1 score. Through thorough analyses, we observe that QA datasets that requires high-level reasoning abilities (e.g., abstractive and common-sense QA datasets) tend to give the best boost in performance in both few-shot and zero-shot settings. ",
    "url": "https://arxiv.org/abs/2205.12604",
    "authors": [
      "Dheeraj Mekala",
      "Tu Vu",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.12606",
    "title": "ReSmooth: Detecting and Utilizing OOD Samples when Training with Data  Augmentation",
    "abstract": "Data augmentation (DA) is a widely used technique for enhancing the training of deep neural networks. Recent DA techniques which achieve state-of-the-art performance always meet the need for diversity in augmented training samples. However, an augmentation strategy that has a high diversity usually introduces out-of-distribution (OOD) augmented samples and these samples consequently impair the performance. To alleviate this issue, we propose ReSmooth, a framework that firstly detects OOD samples in augmented samples and then leverages them. To be specific, we first use a Gaussian mixture model to fit the loss distribution of both the original and augmented samples and accordingly split these samples into in-distribution (ID) samples and OOD samples. Then we start a new training where ID and OOD samples are incorporated with different smooth labels. By treating ID samples and OOD samples unequally, we can make better use of the diverse augmented data. Further, we incorporate our ReSmooth framework with negative data augmentation strategies. By properly handling their intentionally created ODD samples, the classification performance of negative data augmentations is largely ameliorated. Experiments on several classification benchmarks show that ReSmooth can be easily extended to existing augmentation strategies (such as RandAugment, rotate, and jigsaw) and improve on them. ",
    "url": "https://arxiv.org/abs/2205.12606",
    "authors": [
      "Chenyang Wang",
      "Junjun Jiang",
      "Xiong Zhou",
      "Xianming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12635",
    "title": "MoCoViT: Mobile Convolutional Vision Transformer",
    "abstract": "Recently, Transformer networks have achieved impressive results on a variety of vision tasks. However, most of them are computationally expensive and not suitable for real-world mobile applications. In this work, we present Mobile Convolutional Vision Transformer (MoCoViT), which improves in performance and efficiency by introducing transformer into mobile convolutional networks to leverage the benefits of both architectures. Different from recent works on vision transformer, the mobile transformer block in MoCoViT is carefully designed for mobile devices and is very lightweight, accomplished through two primary modifications: the Mobile Self-Attention (MoSA) module and the Mobile Feed Forward Network (MoFFN). MoSA simplifies the calculation of the attention map through Branch Sharing scheme while MoFFN serves as a mobile version of MLP in the transformer, further reducing the computation by a large margin. Comprehensive experiments verify that our proposed MoCoViT family outperform state-of-the-art portable CNNs and transformer neural architectures on various vision tasks. On ImageNet classification, it achieves 74.5% top-1 accuracy at 147M FLOPs, gaining 1.2% over MobileNetV3 with less computations. And on the COCO object detection task, MoCoViT outperforms GhostNet by 2.1 AP in RetinaNet framework. ",
    "url": "https://arxiv.org/abs/2205.12635",
    "authors": [
      "Hailong Ma",
      "Xin Xia",
      "Xing Wang",
      "Xuefeng Xiao",
      "Jiashi Li",
      "Min Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12646",
    "title": "UniInst: Unique Representation for End-to-End Instance Segmentation",
    "abstract": "Existing instance segmentation methods have achieved impressive performance but still suffer from a common dilemma: redundant representations (e.g., multiple boxes, grids, and anchor points) are inferred for one instance, which leads to multiple duplicated predictions. Thus, mainstream methods usually rely on a hand-designed non-maximum suppression (NMS) post-processing to select the optimal prediction result, which hinders end-to-end training. To address this issue, we propose a box-free and NMS-free end-to-end instance segmentation framework, termed UniInst, that yields only one unique representation for each instance. Specifically, we design an instance-aware one-to-one assignment scheme, namely Only Yield One Representation (OYOR), which dynamically assigns one unique representation to one instance according to the matching quality between predictions and ground truths. Then, a novel prediction re-ranking strategy is elegantly integrated into the framework to address the misalignment between the classification score and the mask quality, enabling the learned representation to be more discriminative. With these techniques, our UniInst, the first FCN-based end-to-end instance segmentation framework, achieves competitive performance, e.g., 39.0 mask AP with ResNet-50-FPN and 40.2 mask AP with ResNet-101-FPN, against mainstream methods on the COCO benchmark. Moreover, the proposed instance-aware method is robust to occlusion scenes, outperforming common baselines by remarkable mask AP on the heavily-occluded OCHuman benchmark. Our codes will be available upon publication. ",
    "url": "https://arxiv.org/abs/2205.12646",
    "authors": [
      "Yimin Ou",
      "Rui Yang",
      "Lufan Ma",
      "Yong Liu",
      "Jiangpeng Yan",
      "Shang Xu",
      "Chengjie Wang",
      "Xiu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12649",
    "title": "Investigating Lexical Replacements for Arabic-English Code-Switched Data  Augmentation",
    "abstract": "Code-switching (CS) poses several challenges to NLP tasks, where data sparsity is a main problem hindering the development of CS NLP systems. In this paper, we investigate data augmentation techniques for synthesizing Dialectal Arabic-English CS text. We perform lexical replacements using parallel corpora and alignments where CS points are either randomly chosen or learnt using a sequence-to-sequence model. We evaluate the effectiveness of data augmentation on language modeling (LM), machine translation (MT), and automatic speech recognition (ASR) tasks. Results show that in the case of using 1-1 alignments, using trained predictive models produces more natural CS sentences, as reflected in perplexity. By relying on grow-diag-final alignments, we then identify aligning segments and perform replacements accordingly. By replacing segments instead of words, the quality of synthesized data is greatly improved. With this improvement, random-based approach outperforms using trained predictive models on all extrinsic tasks. Our best models achieve 33.6% improvement in perplexity, +3.2-5.6 BLEU points on MT task, and 7% relative improvement on WER for ASR task. We also contribute in filling the gap in resources by collecting and publishing the first Arabic English CS-English parallel corpus. ",
    "url": "https://arxiv.org/abs/2205.12649",
    "authors": [
      "Injy Hamed",
      "Nizar Habash",
      "Slim Abdennadher",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.12654",
    "title": "Bitext Mining Using Distilled Sentence Representations for Low-Resource  Languages",
    "abstract": "Scaling multilingual representation learning beyond the hundred most frequent languages is challenging, in particular to cover the long tail of low-resource languages. A promising approach has been to train one-for-all multilingual models capable of cross-lingual transfer, but these models often suffer from insufficient capacity and interference between unrelated languages. Instead, we move away from this approach and focus on training multiple language (family) specific representations, but most prominently enable all languages to still be encoded in the same representational space. To achieve this, we focus on teacher-student training, allowing all encoders to be mutually compatible for bitext mining, and enabling fast learning of new languages. We introduce a new teacher-student training scheme which combines supervised and self-supervised training, allowing encoders to take advantage of monolingual training data, which is valuable in the low-resource setting. Our approach significantly outperforms the original LASER encoder. We study very low-resource languages and handle 50 African languages, many of which are not covered by any other model. For these languages, we train sentence encoders, mine bitexts, and validate the bitexts by training NMT systems. ",
    "url": "https://arxiv.org/abs/2205.12654",
    "authors": [
      "Kevin Heffernan",
      "Onur \u00c7elebi",
      "Holger Schwenk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.12656",
    "title": "Optimizing UAV Recharge Scheduling for Heterogeneous and Persistent  Aerial Service",
    "abstract": "The adoption of UAVs in communication networks is becoming reality thanks to the deployment of advanced solutions for connecting UAVs and using them as communication relays. However, the use of UAVs introduces novel energy constraints and scheduling challenges in the dynamic management of network devices, due to the need to call back and recharge, or substitute, UAVs that run out of energy. In this paper, we design UAV recharging schemes under realistic assumptions on limited flight times and time consuming charging operations. Such schemes are designed to minimize the size of the fleet to be devoted to a persistent service of a set of aerial locations, hence its cost. We consider a fleet of homogeneous UAVs both under homogeneous and heterogeneous service topologies. For UAVs serving aerial locations with homogeneous distances to a recharge station, we design a simple scheduling, that we name HORR, which we prove to be feasible and optimal, in the sense that it uses the minimum possible number of UAVs to guarantee the coverage of the aerial service locations. For the case of non-evenly distributed aerial locations, we demonstrate that the problem becomes NP-hard, and design a lightweight recharging scheduling scheme, PHERR, that extends the operation of HORR to the heterogeneous case, leveraging the partitioning of the set of service locations. We show that PHERR is near-optimal because it approaches the performance limits identified through a lower bound that we formulate on the total fleet size. ",
    "url": "https://arxiv.org/abs/2205.12656",
    "authors": [
      "Edgar Arribas",
      "Vicent Cholvi",
      "Vincenzo Mancuso"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.12660",
    "title": "MAPLE-X: Latency Prediction with Explicit Microprocessor Prior Knowledge",
    "abstract": "Deep neural network (DNN) latency characterization is a time-consuming process and adds significant cost to Neural Architecture Search (NAS) processes when searching for efficient convolutional neural networks for embedded vision applications. DNN Latency is a hardware dependent metric and requires direct measurement or inference on target hardware. A recently introduced latency estimation technique known as MAPLE predicts DNN execution time on previously unseen hardware devices by using hardware performance counters. Leveraging these hardware counters in the form of an implicit prior, MAPLE achieves state-of-the-art performance in latency prediction. Here, we propose MAPLE-X which extends MAPLE by incorporating explicit prior knowledge of hardware devices and DNN architecture latency to better account for model stability and robustness. First, by identifying DNN architectures that exhibit a similar latency to each other, we can generate multiple virtual examples to significantly improve the accuracy over MAPLE. Secondly, the hardware specifications are used to determine the similarity between training and test hardware to emphasize training samples captured from comparable devices (domains) and encourages improved domain alignment. Experimental results using a convolution neural network NAS benchmark across different types of devices, including an Intel processor that is now used for embedded vision applications, demonstrate a 5% improvement over MAPLE and 9% over HELP. Furthermore, we include ablation studies to independently assess the benefits of virtual examples and hardware-based sample importance. ",
    "url": "https://arxiv.org/abs/2205.12660",
    "authors": [
      "Saad Abbasi",
      "Alexander Wong",
      "Mohammad Javad Shafiee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12674",
    "title": "Training Language Models with Memory Augmentation",
    "abstract": "Recent work has improved language models remarkably by equipping them with a non-parametric memory component. However, most existing approaches only introduce memories at testing time, or represent them using a separately trained encoder -- resulting in sub-optimal training of the language model. In this work, we present TRIME, a novel yet simple training approach designed for training language models with memory augmentation. Our approach uses a training objective that directly takes in-batch examples as accessible memory. We also present new methods for memory construction and data batching, which are used for adapting to different sets of memories -- local, long-term, and external memory -- at testing time. We evaluate our approach on multiple language modeling and machine translation benchmarks. We find that simply replacing the vanilla language modeling objective by ours greatly reduces the perplexity, without modifying the model architecture or incorporating extra context (e.g., 18.70 $\\to$ 17.76 on WikiText-103). We further augment language models with long-range contexts and external knowledge and demonstrate significant gains over previous memory-augmented approaches. ",
    "url": "https://arxiv.org/abs/2205.12674",
    "authors": [
      "Zexuan Zhong",
      "Tao Lei",
      "Danqi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12700",
    "title": "Textual Backdoor Attacks with Iterative Trigger Injection",
    "abstract": "The backdoor attack has become an emerging threat for Natural Language Processing (NLP) systems. A victim model trained on poisoned data can be embedded with a \"backdoor\", making it predict the adversary-specified output (e.g., the positive sentiment label) on inputs satisfying the trigger pattern (e.g., containing a certain keyword). In this paper, we demonstrate that it's possible to design an effective and stealthy backdoor attack by iteratively injecting \"triggers\" into a small set of training data. While all triggers are common words that fit into the context, our poisoning process strongly associates them with the target label, forming the model backdoor. Experiments on sentiment analysis and hate speech detection show that our proposed attack is both stealthy and effective, raising alarm on the usage of untrusted training data. We further propose a defense method to combat this threat. ",
    "url": "https://arxiv.org/abs/2205.12700",
    "authors": [
      "Jun Yan",
      "Vansh Gupta",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.12706",
    "title": "Scalable Online Change Detection for High-dimensional Data Streams",
    "abstract": "Detecting changes in data streams is a core objective in their analysis and has applications in, say, predictive maintenance, fraud detection, and medicine. A principled approach to detect changes is to compare distributions observed within the stream to each other. However, data streams often are high-dimensional, and changes can be complex, e.g., only manifest themselves in higher moments. The streaming setting also imposes heavy memory and computation restrictions. We propose an algorithm, Maximum Mean Discrepancy Adaptive Windowing (MMDAW), which leverages the well-known Maximum Mean Discrepancy (MMD) two-sample test, and facilitates its efficient online computation on windows whose size it flexibly adapts. As MMD is sensitive to any change in the underlying distribution, our algorithm is a general-purpose non-parametric change detector that fulfills the requirements imposed by the streaming setting. Our experiments show that MMDAW achieves better detection quality than state-of-the-art competitors. ",
    "url": "https://arxiv.org/abs/2205.12706",
    "authors": [
      "Florian Kalinke",
      "Marco Heyden",
      "Edouard Fouch\u00e9",
      "Klemens B\u00f6hm"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12711",
    "title": "Service Discovery in Social Internet of Things using Graph Neural  Networks",
    "abstract": "Internet-of-Things (IoT) networks intelligently connect thousands of physical entities to provide various services for the community. It is witnessing an exponential expansion, which is complicating the process of discovering IoT devices existing in the network and requesting corresponding services from them. As the highly dynamic nature of the IoT environment hinders the use of traditional solutions of service discovery, we aim, in this paper, to address this issue by proposing a scalable resource allocation neural model adequate for heterogeneous large-scale IoT networks. We devise a Graph Neural Network (GNN) approach that utilizes the social relationships formed between the devices in the IoT network to reduce the search space of any entity lookup and acquire a service from another device in the network. This proposed resource allocation approach surpasses standardization issues and embeds the structure and characteristics of the social IoT graph, by the means of GNNs, for eventual clustering analysis process. Simulation results applied on a real-world dataset illustrate the performance of this solution and its significant efficiency to operate on large-scale IoT networks. ",
    "url": "https://arxiv.org/abs/2205.12711",
    "authors": [
      "Aymen Hamrouni",
      "Hakim Ghazzai",
      "Yehia Massoud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.12713",
    "title": "jTrans: Jump-Aware Transformer for Binary Code Similarity",
    "abstract": "Binary code similarity detection (BCSD) has important applications in various fields such as vulnerability detection, software component analysis, and reverse engineering. Recent studies have shown that deep neural networks (DNNs) can comprehend instructions or control-flow graphs (CFG) of binary code and support BCSD. In this study, we propose a novel Transformer-based approach, namely jTrans, to learn representations of binary code. It is the first solution that embeds control flow information of binary code into Transformer-based language models, by using a novel jump-aware representation of the analyzed binaries and a newly-designed pre-training task. Additionally, we release to the community a newly-created large dataset of binaries, BinaryCorp, which is the most diverse to date. Evaluation results show that jTrans outperforms state-of-the-art (SOTA) approaches on this more challenging dataset by 30.5% (i.e., from 32.0% to 62.5%). In a real-world task of known vulnerability searching, jTrans achieves a recall that is 2X higher than existing SOTA baselines. ",
    "url": "https://arxiv.org/abs/2205.12713",
    "authors": [
      "Hao Wang",
      "Wenjie Qu",
      "Gilad Katz",
      "Wenyu Zhu",
      "Zeyu Gao",
      "Han Qiu",
      "Jianwei Zhuge",
      "Chao Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.12718",
    "title": "DPSNN: A Differentially Private Spiking Neural Network",
    "abstract": "Privacy-preserving is a key problem for the machine learning algorithm. Spiking neural network (SNN) plays an important role in many domains, such as image classification, object detection, and speech recognition, but the study on the privacy protection of SNN is urgently needed. This study combines the differential privacy (DP) algorithm and SNN and proposes differentially private spiking neural network (DPSNN). DP injects noise into the gradient, and SNN transmits information in discrete spike trains so that our differentially private SNN can maintain strong privacy protection while still ensuring high accuracy. We conducted experiments on MNIST, Fashion-MNIST, and the face recognition dataset Extended YaleB. When the privacy protection is improved, the accuracy of the artificial neural network(ANN) drops significantly, but our algorithm shows little change in performance. Meanwhile, we analyzed different factors that affect the privacy protection of SNN. Firstly, the less precise the surrogate gradient is, the better the privacy protection of the SNN. Secondly, the Integrate-And-Fire (IF) neurons perform better than leaky Integrate-And-Fire (LIF) neurons. Thirdly, a large time window contributes more to privacy protection and performance. ",
    "url": "https://arxiv.org/abs/2205.12718",
    "authors": [
      "Jihang Wang",
      "Dongcheng Zhao",
      "Guobin Shen",
      "Qian Zhang",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12723",
    "title": "Interpretable Feature Engineering for Time Series Predictors using  Attention Networks",
    "abstract": "Regression problems with time-series predictors are common in banking and many other areas of application. In this paper, we use multi-head attention networks to develop interpretable features and use them to achieve good predictive performance. The customized attention layer explicitly uses multiplicative interactions and builds feature-engineering heads that capture temporal dynamics in a parsimonious manner. Convolutional layers are used to combine multivariate time series. We also discuss methods for handling static covariates in the modeling process. Visualization and explanation tools are used to interpret the results and explain the relationship between the inputs and the extracted features. Both simulation and real dataset are used to illustrate the usefulness of the methodology. Keyword: Attention heads, Deep neural networks, Interpretable feature engineering ",
    "url": "https://arxiv.org/abs/2205.12723",
    "authors": [
      "Tianjie Wang",
      "Jie Chen",
      "Joel Vaughan",
      "Vijayan N. Nair"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12730",
    "title": "Uncertainty Quantification for Transport in Porous media using  Parameterized Physics Informed neural Networks",
    "abstract": "We present a Parametrization of the Physics Informed Neural Network (P-PINN) approach to tackle the problem of uncertainty quantification in reservoir engineering problems. We demonstrate the approach with the immiscible two phase flow displacement (Buckley-Leverett problem) in heterogeneous porous medium. The reservoir properties (porosity, permeability) are treated as random variables. The distribution of these properties can affect dynamic properties such as the fluids saturation, front propagation speed or breakthrough time. We explore and use to our advantage the ability of networks to interpolate complex high dimensional functions. We observe that the additional dimensions resulting from a stochastic treatment of the partial differential equations tend to produce smoother solutions on quantities of interest (distributions parameters) which is shown to improve the performance of PINNS. We show that provided a proper parameterization of the uncertainty space, PINN can produce solutions that match closely both the ensemble realizations and the stochastic moments. We demonstrate applications for both homogeneous and heterogeneous fields of properties. We are able to solve problems that can be challenging for classical methods. This approach gives rise to trained models that are both more robust to variations in the input space and can compete in performance with traditional stochastic sampling methods. ",
    "url": "https://arxiv.org/abs/2205.12730",
    "authors": [
      "Cedric Fraces Gasmi",
      "Hamdi Tchelepi"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12735",
    "title": "Inductive Learning of Complex Knowledge from Raw Data",
    "abstract": "One of the ultimate goals of Artificial Intelligence is to learn generalised and human-interpretable knowledge from raw data. Neuro-symbolic reasoning approaches partly tackle this problem by improving the training of a neural network using a manually engineered symbolic knowledge base. In the case where symbolic knowledge is learned from raw data, this knowledge lacks the expressivity required to solve complex problems. In this paper, we introduce Neuro-Symbolic Inductive Learner (NSIL), an approach that trains a neural network to extract latent concepts from raw data, whilst learning symbolic knowledge that solves complex problems, defined in terms of these latent concepts. The novelty of our approach is a method for biasing a symbolic learner to learn improved knowledge, based on the in-training performance of both neural and symbolic components. We evaluate NSIL on two problem domains that require learning knowledge with different levels of complexity, and demonstrate that NSIL learns knowledge that is not possible to learn with other neuro-symbolic systems, whilst outperforming baseline models in terms of accuracy and data efficiency. ",
    "url": "https://arxiv.org/abs/2205.12735",
    "authors": [
      "Daniel Cunnington",
      "Mark Law",
      "Jorge Lobo",
      "Alessandra Russo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12737",
    "title": "On the Routing Convergence Delay in the Lightning Network",
    "abstract": "Nodes in the Lightning Network synchronise routing information through a gossip protocol that makes use of a staggered broadcast mechanism. In this work, we show that the convergence delay in the network is larger than what would be expected from the protocol's specification and that payment attempt failures caused by the delay are more frequent, the larger the delay is. To this end, we measure the convergence delay incurred in the network and analyse what its primary causes are. Moreover, we further investigate and confirm our findings through a time-discrete simulation of the Lightning Network gossip protocol. We explore the use of alternative gossip protocols as well as parameter variations of the current protocol and evaluate them by the resulting bandwidth usage and convergence delay. Our research shows that there are multiple ways of lowering the convergence delay, ranging from simple parameter changes to overhauling the entire protocol. ",
    "url": "https://arxiv.org/abs/2205.12737",
    "authors": [
      "Niklas G\u00f6gge",
      "Elias Rohrer",
      "Florian Tschorsch"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.12752",
    "title": "NECA: Network-Embedded Deep Representation Learning for Categorical Data",
    "abstract": "We propose NECA, a deep representation learning method for categorical data. Built upon the foundations of network embedding and deep unsupervised representation learning, NECA deeply embeds the intrinsic relationship among attribute values and explicitly expresses data objects with numeric vector representations. Designed specifically for categorical data, NECA can support important downstream data mining tasks, such as clustering. Extensive experimental analysis demonstrated the effectiveness of NECA. ",
    "url": "https://arxiv.org/abs/2205.12752",
    "authors": [
      "Xiaonan Gao",
      "Sen Wu",
      "Wenjun Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12753",
    "title": "An Empirical Study on Distribution Shift Robustness From the Perspective  of Pre-Training and Data Augmentation",
    "abstract": "The performance of machine learning models under distribution shift has been the focus of the community in recent years. Most of current methods have been proposed to improve the robustness to distribution shift from the algorithmic perspective, i.e., designing better training algorithms to help the generalization in shifted test distributions. This paper studies the distribution shift problem from the perspective of pre-training and data augmentation, two important factors in the practice of deep learning that have not been systematically investigated by existing work. By evaluating seven pre-trained models, including ResNets and ViT's with self-supervision and supervision mode, on five important distribution-shift datasets, from WILDS and DomainBed benchmarks, with five different learning algorithms, we provide the first comprehensive empirical study focusing on pre-training and data augmentation. With our empirical result obtained from 1,330 models, we provide the following main observations: 1) ERM combined with data augmentation can achieve state-of-the-art performance if we choose a proper pre-trained model respecting the data property; 2) specialized algorithms further improve the robustness on top of ERM when handling a specific type of distribution shift, e.g., GroupDRO for spurious correlation and CORAL for large-scale out-of-distribution data; 3) Comparing different pre-training modes, architectures and data sizes, we provide novel observations about pre-training on distribution shift, which sheds light on designing or selecting pre-training strategy for different kinds of distribution shifts. In summary, our empirical study provides a comprehensive baseline for a wide range of pre-training models fine-tuned with data augmentation, which potentially inspires research exploiting the power of pre-training and data augmentation in the future of distribution shift study. ",
    "url": "https://arxiv.org/abs/2205.12753",
    "authors": [
      "Ziquan Liu",
      "Yi Xu",
      "Yuanhong Xu",
      "Qi Qian",
      "Hao Li",
      "Rong Jin",
      "Xiangyang Ji",
      "Antoni B. Chan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12755",
    "title": "An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale  Multitask Learning Systems",
    "abstract": "Multitask learning assumes that models capable of learning from multiple tasks can achieve better quality and efficiency via knowledge transfer, a key feature of human learning. Though, state of the art ML models rely on high customization for each task and leverage size and data scale rather than scaling the number of tasks. Also, continual learning, that adds the temporal aspect to multitask, is often focused to the study of common pitfalls such as catastrophic forgetting instead of being studied at a large scale as a critical component to build the next generation artificial intelligence. We propose an evolutionary method that can generate a large scale multitask model, and can support the dynamic and continuous addition of new tasks. The generated multitask model is sparsely activated and integrates a task-based routing that guarantees bounded compute cost and fewer added parameters per task as the model expands. The proposed method relies on a knowledge compartmentalization technique to achieve immunity against catastrophic forgetting and other common pitfalls such as gradient interference and negative transfer. We empirically show that the proposed method can jointly solve and achieve competitive results on 69image classification tasks, for example achieving the best test accuracy reported fora model trained only on public data for competitive tasks such as cifar10: 99.43%. ",
    "url": "https://arxiv.org/abs/2205.12755",
    "authors": [
      "Andrea Gesmundo",
      "Jeff Dean"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.12764",
    "title": "Square roots of nearly planar graphs",
    "abstract": "We prove that it is NP-hard to decide whether a graph is the square of a 6-apex graph. This shows that the square root problem is not tractable for squares of sparse graphs (or even graphs from proper minor-closed classes). ",
    "url": "https://arxiv.org/abs/2205.12764",
    "authors": [
      "Zden\u011bk Dvo\u0159\u00e1k",
      "Benjamin Moore",
      "Abhiruk Lahari"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2205.12768",
    "title": "Would You Ask it that Way? Measuring and Improving Question Naturalness  for Knowledge Graph Question Answering",
    "abstract": "Knowledge graph question answering (KGQA) facilitates information access by leveraging structured data without requiring formal query language expertise from the user. Instead, users can express their information needs by simply asking their questions in natural language (NL). Datasets used to train KGQA models that would provide such a service are expensive to construct, both in terms of expert and crowdsourced labor. Typically, crowdsourced labor is used to improve template-based pseudo-natural questions generated from formal queries. However, the resulting datasets often fall short of representing genuinely natural and fluent language. In the present work, we investigate ways to characterize and remedy these shortcomings. We create the IQN-KGQA test collection by sampling questions from existing KGQA datasets and evaluating them with regards to five different aspects of naturalness. Then, the questions are rewritten to improve their fluency. Finally, the performance of existing KGQA models is compared on the original and rewritten versions of the NL questions. We find that some KGQA systems fare worse when presented with more realistic formulations of NL questions. The IQN-KGQA test collection is a resource to help evaluate KGQA systems in a more realistic setting. The construction of this test collection also sheds light on the challenges of constructing large-scale KGQA datasets with genuinely NL questions. ",
    "url": "https://arxiv.org/abs/2205.12768",
    "authors": [
      "Trond Linjordet",
      "Krisztian Balog"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.12770",
    "title": "An Experimental Comparison Between Temporal Difference and Residual  Gradient with Neural Network Approximation",
    "abstract": "Gradient descent or its variants are popular in training neural networks. However, in deep Q-learning with neural network approximation, a type of reinforcement learning, gradient descent (also known as Residual Gradient (RG)) is barely used to solve Bellman residual minimization problem. On the contrary, Temporal Difference (TD), an incomplete gradient descent method prevails. In this work, we perform extensive experiments to show that TD outperforms RG, that is, when the training leads to a small Bellman residual error, the solution found by TD has a better policy and is more robust against the perturbation of neural network parameters. We further use experiments to reveal a key difference between reinforcement learning and supervised learning, that is, a small Bellman residual error can correspond to a bad policy in reinforcement learning while the test loss function in supervised learning is a standard index to indicate the performance. We also empirically examine that the missing term in TD is a key reason why RG performs badly. Our work shows that the performance of a deep Q-learning solution is closely related to the training dynamics and how an incomplete gradient descent method can find a good policy is interesting for future study. ",
    "url": "https://arxiv.org/abs/2205.12770",
    "authors": [
      "Shuyu Yin",
      "Tao Luo",
      "Peilin Liu",
      "Zhi-Qin John Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12771",
    "title": "Does Moral Code Have a Moral Code? Probing Delphi's Moral Philosophy",
    "abstract": "In an effort to guarantee that machine learning model outputs conform with human moral values, recent work has begun exploring the possibility of explicitly training models to learn the difference between right and wrong. This is typically done in a bottom-up fashion, by exposing the model to different scenarios, annotated with human moral judgements. One question, however, is whether the trained models actually learn any consistent, higher-level ethical principles from these datasets -- and if so, what? Here, we probe the Allen AI Delphi model with a set of standardized morality questionnaires, and find that, despite some inconsistencies, Delphi tends to mirror the moral principles associated with the demographic groups involved in the annotation process. We question whether this is desirable and discuss how we might move forward with this knowledge. ",
    "url": "https://arxiv.org/abs/2205.12771",
    "authors": [
      "Kathleen C. Fraser",
      "Svetlana Kiritchenko",
      "Esma Balkir"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.12775",
    "title": "Residual-Concatenate Neural Network with Deep Regularization Layers for  Binary Classification",
    "abstract": "Many complex Deep Learning models are used with different variations for various prognostication tasks. The higher learning parameters not necessarily ensure great accuracy. This can be solved by considering changes in very deep models with many regularization based techniques. In this paper we train a deep neural network that uses many regularization layers with residual and concatenation process for best fit with Polycystic Ovary Syndrome Diagnosis prognostication. The network was built with improvements from every step of failure to meet the needs of the data and achieves an accuracy of 99.3% seamlessly. ",
    "url": "https://arxiv.org/abs/2205.12775",
    "authors": [
      "Abhishek Gupta",
      "Sruthi Nair",
      "Raunak Joshi",
      "Vidya Chitre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12781",
    "title": "Ultra-compact Binary Neural Networks for Human Activity Recognition on  RISC-V Processors",
    "abstract": "Human Activity Recognition (HAR) is a relevant inference task in many mobile applications. State-of-the-art HAR at the edge is typically achieved with lightweight machine learning models such as decision trees and Random Forests (RFs), whereas deep learning is less common due to its high computational complexity. In this work, we propose a novel implementation of HAR based on deep neural networks, and precisely on Binary Neural Networks (BNNs), targeting low-power general purpose processors with a RISC-V instruction set. BNNs yield very small memory footprints and low inference complexity, thanks to the replacement of arithmetic operations with bit-wise ones. However, existing BNN implementations on general purpose processors impose constraints tailored to complex computer vision tasks, which result in over-parametrized models for simpler problems like HAR. Therefore, we also introduce a new BNN inference library, which targets ultra-compact models explicitly. With experiments on a single-core RISC-V processor, we show that BNNs trained on two HAR datasets obtain higher classification accuracy compared to a state-of-the-art baseline based on RFs. Furthermore, our BNN reaches the same accuracy of a RF with either less memory (up to 91%) or more energy-efficiency (up to 70%), depending on the complexity of the features extracted by the RF. ",
    "url": "https://arxiv.org/abs/2205.12781",
    "authors": [
      "Francesco Daghero",
      "Chen Xie",
      "Daniele Jahier Pagliari",
      "Alessio Burrello",
      "Marco Castellano",
      "Luca Gandolfi",
      "Andrea Calimera",
      "Enrico Macii",
      "Massimo Poncino"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.12784",
    "title": "TrustGNN: Graph Neural Network based Trust Evaluation via Learnable  Propagative and Composable Nature",
    "abstract": "Trust evaluation is critical for many applications such as cyber security, social communication and recommender systems. Users and trust relationships among them can be seen as a graph. Graph neural networks (GNNs) show their powerful ability for analyzing graph-structural data. Very recently, existing work attempted to introduce the attributes and asymmetry of edges into GNNs for trust evaluation, while failed to capture some essential properties (e.g., the propagative and composable nature) of trust graphs. In this work, we propose a new GNN based trust evaluation method named TrustGNN, which integrates smartly the propagative and composable nature of trust graphs into a GNN framework for better trust evaluation. Specifically, TrustGNN designs specific propagative patterns for different propagative processes of trust, and distinguishes the contribution of different propagative processes to create new trust. Thus, TrustGNN can learn comprehensive node embeddings and predict trust relationships based on these embeddings. Experiments on some widely-used real-world datasets indicate that TrustGNN significantly outperforms the state-of-the-art methods. We further perform analytical experiments to demonstrate the effectiveness of the key designs in TrustGNN. ",
    "url": "https://arxiv.org/abs/2205.12784",
    "authors": [
      "Cuiying Huo",
      "Di Jin",
      "Chundong Liang",
      "Dongxiao He",
      "Tie Qiu",
      "Lingfei Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12785",
    "title": "AO2-DETR: Arbitrary-Oriented Object Detection Transformer",
    "abstract": "Arbitrary-oriented object detection (AOOD) is a challenging task to detect objects in the wild with arbitrary orientations and cluttered arrangements. Existing approaches are mainly based on anchor-based boxes or dense points, which rely on complicated hand-designed processing steps and inductive bias, such as anchor generation, transformation, and non-maximum suppression reasoning. Recently, the emerging transformer-based approaches view object detection as a direct set prediction problem that effectively removes the need for hand-designed components and inductive biases. In this paper, we propose an Arbitrary-Oriented Object DEtection TRansformer framework, termed AO2-DETR, which comprises three dedicated components. More precisely, an oriented proposal generation mechanism is proposed to explicitly generate oriented proposals, which provides better positional priors for pooling features to modulate the cross-attention in the transformer decoder. An adaptive oriented proposal refinement module is introduced to extract rotation-invariant region features and eliminate the misalignment between region features and objects. And a rotation-aware set matching loss is used to ensure the one-to-one matching process for direct set prediction without duplicate predictions. Our method considerably simplifies the overall pipeline and presents a new AOOD paradigm. Comprehensive experiments on several challenging datasets show that our method achieves superior performance on the AOOD task. ",
    "url": "https://arxiv.org/abs/2205.12785",
    "authors": [
      "Linhui Dai",
      "Hong Liu",
      "Hao Tang",
      "Zhiwei Wu",
      "Pinhao Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12796",
    "title": "Non-rigid Point Cloud Registration with Neural Deformation Pyramid",
    "abstract": "Non-rigid point cloud registration is a key component in many computer vision and computer graphics applications. The high complexity of the unknown non-rigid motion make this task a challenging problem. In this paper, we break down this problem via hierarchical motion decomposition. Our method called Neural Deformation Pyramid (NDP) represents non-rigid motion using a pyramid architecture. Each pyramid level, denoted by a Multi-Layer Perception (MLP), takes as input a sinusoidally encoded 3D point and outputs its motion increments from the previous level. The sinusoidal function starts with a low input frequency and gradually increases when the pyramid level goes down. This allows a multi-level rigid to nonrigid motion decomposition and also speeds up the solving by 50 times compared to the existing MLP-based approach. Our method achieves advanced partialto-partial non-rigid point cloud registration results on the 4DMatch/4DLoMatch benchmark under both no-learned and supervised settings. ",
    "url": "https://arxiv.org/abs/2205.12796",
    "authors": [
      "Yang Li",
      "Tatsuya Harada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12816",
    "title": "P4Filter: A two level defensive mechanism against attacks in SDN using  P4",
    "abstract": "The advancements in networking technologies have led to a new paradigm of controlling networks, with data plane programmability as a basis. This facility opens up many advantages, such as flexibility in packet processing and better network management, which leads to better security in the network. However, the current literature lacks network security solutions concerning authentication and preventing unauthorized access. In this work, our goal is to avoid attacks in a two level defense mechanism (P4Filter). The first level is a dynamic firewall logic, which blocks packets generated from an unauthorized source. The second level is an authentication mechanism based on dynamic port knocking. The two security levels were tested in a virtual environment with P4 based switches. The packets arriving at the switch from unknown hosts are sent to the controller. The controller maintains an ACL using which it assigns rules for both the levels to allow or drop the packets. For port knocking a new random sequence is generated for every new host. Hosts can only connect using the correct sequence assigned to them.The tests conducted show this approach performs better than the previous P4 based firewall approaches due to two security levels. Moreover, it is successful in mitigating specific security attacks by blocking unauthorized access to the network. ",
    "url": "https://arxiv.org/abs/2205.12816",
    "authors": [
      "Ananya Saxena",
      "Ritvik Muttreja",
      "Shivam Upadhyay",
      "K. Shiv Kumar",
      "Dr Venkanna U"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.12830",
    "title": "How to Wake Up Your Neighbors: Safe and Nearly Optimal Generic Energy  Conservation in Radio Networks",
    "abstract": "Recent work has shown that it is sometimes feasible to significantly reduce the energy usage of some radio-network algorithms by adaptively powering down the radio receiver when it is not needed. Although past work has focused on modifying specific network algorithms in this way, we now ask the question of whether this problem can be solved in a generic way, treating the algorithm as a kind of black box. We are able to answer this question in the affirmative, presenting a new general way to modify arbitrary radio-network algorithms in an attempt to save energy. At the expense of a small increase in the time complexity, we can provably reduce the energy usage to an extent that is provably nearly optimal within a certain class of general-purpose algorithms. As an application, we show that our algorithm reduces the energy cost of breadth-first search in radio networks from the previous best bound of $2^{O(\\sqrt{\\log n})}$ to $\\mathrm{polylog}(n)$, where $n$ is the number of nodes in the network A key ingredient in our algorithm is hierarchical clustering based on additive Voronoi decomposition done at multiple scales. Similar clustering algorithms have been used in other recent work on energy-aware computation in radio networks, but we believe the specific approach presented here may be of independent interest. ",
    "url": "https://arxiv.org/abs/2205.12830",
    "authors": [
      "Varsha Dani",
      "Thomas P. Hayes"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.12850",
    "title": "A Universal Error Measure for Input Predictions Applied to Online Graph  Problems",
    "abstract": "We introduce a novel measure for quantifying the error in input predictions. The error is based on a minimum-cost hyperedge cover in a suitably defined hypergraph and provides a general template which we apply to online graph problems. The measure captures errors due to absent predicted requests as well as unpredicted actual requests; hence, predicted and actual inputs can be of arbitrary size. We achieve refined performance guarantees for previously studied network design problems in the online-list model, such as Steiner tree and facility location. Further, we initiate the study of learning-augmented algorithms for online routing problems, such as the traveling salesperson problem and dial-a-ride problem, where (transportation) requests arrive over time (online-time model). We provide a general algorithmic framework and we give error-dependent performance bounds that improve upon known worst-case barriers, when given accurate predictions, at the cost of slightly increased worst-case bounds when given predictions of arbitrary quality. ",
    "url": "https://arxiv.org/abs/2205.12850",
    "authors": [
      "Giulia Bernardini",
      "Alexander Lindermayr",
      "Alberto Marchetti-Spaccamela",
      "Nicole Megow",
      "Leen Stougie",
      "Michelle Sweering"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12853",
    "title": "Deep Gradient Learning for Efficient Camouflaged Object Detection",
    "abstract": "This paper introduces DGNet, a novel deep framework that exploits object gradient supervision for camouflaged object detection (COD). It decouples the task into two connected branches, i.e., a context and a texture encoder. The essential connection is the gradient-induced transition, representing a soft grouping between context and texture features. Benefiting from the simple but efficient framework, DGNet outperforms existing state-of-the-art COD models by a large margin. Notably, our efficient version, DGNet-S, runs in real-time (80 fps) and achieves comparable results to the cutting-edge model JCSOD-CVPR$_{21}$ with only 6.82% parameters. Application results also show that the proposed DGNet performs well in polyp segmentation, defect detection, and transparent object segmentation tasks. Codes will be made available at https://github.com/GewelsJI/DGNet. ",
    "url": "https://arxiv.org/abs/2205.12853",
    "authors": [
      "Ge-Peng Ji",
      "Deng-Ping Fan",
      "Yu-Cheng Chou",
      "Dengxin Dai",
      "Alexander Liniger",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12886",
    "title": "You Need to Read Again: Multi-granularity Perception Network for Moment  Retrieval in Videos",
    "abstract": "Moment retrieval in videos is a challenging task that aims to retrieve the most relevant video moment in an untrimmed video given a sentence description. Previous methods tend to perform self-modal learning and cross-modal interaction in a coarse manner, which neglect fine-grained clues contained in video content, query context, and their alignment. To this end, we propose a novel Multi-Granularity Perception Network (MGPN) that perceives intra-modality and inter-modality information at a multi-granularity level. Specifically, we formulate moment retrieval as a multi-choice reading comprehension task and integrate human reading strategies into our framework. A coarse-grained feature encoder and a co-attention mechanism are utilized to obtain a preliminary perception of intra-modality and inter-modality information. Then a fine-grained feature encoder and a conditioned interaction module are introduced to enhance the initial perception inspired by how humans address reading comprehension problems. Moreover, to alleviate the huge computation burden of some existing methods, we further design an efficient choice comparison module and reduce the hidden size with imperceptible quality loss. Extensive experiments on Charades-STA, TACoS, and ActivityNet Captions datasets demonstrate that our solution outperforms existing state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2205.12886",
    "authors": [
      "Xin Sun",
      "Xuan Wang",
      "Jialin Gao",
      "Qiong Liu",
      "Xi Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2205.12888",
    "title": "Robust Reinforcement Learning on Graphs for Logistics optimization",
    "abstract": "Logistics optimization nowadays is becoming one of the hottest areas in the AI community. In the past year, significant advancements in the domain were achieved by representing the problem in a form of graph. Another promising area of research was to apply reinforcement learning algorithms to the above task. In our work, we made advantage of using both approaches and apply reinforcement learning on a graph. To do that, we have analyzed the most recent results in both fields and selected SOTA algorithms both from graph neural networks and reinforcement learning. Then, we combined selected models on the problem of AMOD systems optimization for the transportation network of New York city. Our team compared three algorithms - GAT, Pro-CNN and PTDNet - to bring to the fore the important nodes on a graph representation. Finally, we achieved SOTA results on AMOD systems optimization problem employing PTDNet with GNN and training them in reinforcement fashion. Keywords: Graph Neural Network (GNN), Logistics optimization, Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2205.12888",
    "authors": [
      "Zangir Iklassov",
      "Dmitrii Medvedev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12904",
    "title": "A Neural Tangent Kernel Formula for Ensembles of Soft Trees with  Arbitrary Architectures",
    "abstract": "A soft tree is an actively studied variant of a decision tree that updates splitting rules using the gradient method. Although it can have various tree architectures, the theoretical properties of their impact are not well known. In this paper, we formulate and analyze the Neural Tangent Kernel (NTK) induced by soft tree ensembles for arbitrary tree architectures. This kernel leads to the remarkable finding that only the number of leaves at each depth is relevant for the tree architecture in ensemble learning with infinitely many trees. In other words, if the number of leaves at each depth is fixed, the training behavior in function space and the generalization performance are exactly the same across different tree architectures, even if they are not isomorphic. We also show that the NTK of asymmetric trees like decision lists does not degenerate when they get infinitely deep. This is in contrast to the perfect binary trees, whose NTK is known to degenerate and leads to worse generalization performance for deeper trees. ",
    "url": "https://arxiv.org/abs/2205.12904",
    "authors": [
      "Ryuichi Kanoh",
      "Mahito Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.12918",
    "title": "A Low Memory Footprint Quantized Neural Network for Depth Completion of  Very Sparse Time-of-Flight Depth Maps",
    "abstract": "Sparse active illumination enables precise time-of-flight depth sensing as it maximizes signal-to-noise ratio for low power budgets. However, depth completion is required to produce dense depth maps for 3D perception. We address this task with realistic illumination and sensor resolution constraints by simulating ToF datasets for indoor 3D perception with challenging sparsity levels. We propose a quantized convolutional encoder-decoder network for this task. Our model achieves optimal depth map quality by means of input pre-processing and carefully tuned training with a geometry-preserving loss function. We also achieve low memory footprint for weights and activations by means of mixed precision quantization-at-training techniques. The resulting quantized models are comparable to the state of the art in terms of quality, but they require very low GPU times and achieve up to 14-fold memory size reduction for the weights w.r.t. their floating point counterpart with minimal impact on quality metrics. ",
    "url": "https://arxiv.org/abs/2205.12918",
    "authors": [
      "Xiaowen Jiang",
      "Valerio Cambareri",
      "Gianluca Agresti",
      "Cynthia Ifeyinwa Ugwu",
      "Adriano Simonetto",
      "Fabien Cardinaux",
      "Pietro Zanuttigh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12920",
    "title": "DH-GAN: A Physics-driven Untrained Generative Adversarial Network for 3D  Microscopic Imaging using Digital Holography",
    "abstract": "Digital holography is a 3D imaging technique by emitting a laser beam with a plane wavefront to an object and measuring the intensity of the diffracted waveform, called holograms. The object's 3D shape can be obtained by numerical analysis of the captured holograms and recovering the incurred phase. Recently, deep learning (DL) methods have been used for more accurate holographic processing. However, most supervised methods require large datasets to train the model, which is rarely available in most DH applications due to the scarcity of samples or privacy concerns. A few one-shot DL-based recovery methods exist with no reliance on large datasets of paired images. Still, most of these methods often neglect the underlying physics law that governs wave propagation. These methods offer a black-box operation, which is not explainable, generalizable, and transferrable to other samples and applications. In this work, we propose a new DL architecture based on generative adversarial networks that uses a discriminative network for realizing a semantic measure for reconstruction quality while using a generative network as a function approximator to model the inverse of hologram formation. We impose smoothness on the background part of the recovered image using a progressive masking module powered by simulated annealing to enhance the reconstruction quality. The proposed method is one of its kind that exhibits high transferability to similar samples, which facilitates its fast deployment in time-sensitive applications without the need for retraining the network. The results show a considerable improvement to competitor methods in reconstruction quality (about 5 dB PSNR gain) and robustness to noise (about 50% reduction in PSNR vs noise increase rate). ",
    "url": "https://arxiv.org/abs/2205.12920",
    "authors": [
      "Xiwen Chen",
      "Hao Wang",
      "Abofazl Razi",
      "Michael Kozicki",
      "Christopher Mann"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12923",
    "title": "Domain Adaptation for Object Detection using SE Adaptors and Center Loss",
    "abstract": "Despite growing interest in object detection, very few works address the extremely practical problem of cross-domain robustness especially for automative applications. In order to prevent drops in performance due to domain shift, we introduce an unsupervised domain adaptation method built on the foundation of faster-RCNN with two domain adaptation components addressing the shift at the instance and image levels respectively and apply a consistency regularization between them. We also introduce a family of adaptation layers that leverage the squeeze excitation mechanism called SE Adaptors to improve domain attention and thus improves performance without any prior requirement of knowledge of the new target domain. Finally, we incorporate a center loss in the instance and image level representations to improve the intra-class variance. We report all results with Cityscapes as our source domain and Foggy Cityscapes as the target domain outperforming previous baselines. ",
    "url": "https://arxiv.org/abs/2205.12923",
    "authors": [
      "Sushruth Nagesh",
      "Shreyas Rajesh",
      "Asfiya Baig",
      "Savitha Srinivasan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12934",
    "title": "Amortized Inference for Causal Structure Learning",
    "abstract": "Learning causal structure poses a combinatorial search problem that typically involves evaluating structures using a score or independence test. The resulting search is costly, and designing suitable scores or tests that capture prior knowledge is difficult. In this work, we propose to amortize the process of causal structure learning. Rather than searching over causal structures directly, we train a variational inference model to predict the causal structure from observational/interventional data. Our inference model acquires domain-specific inductive bias for causal discovery solely from data generated by a simulator. This allows us to bypass both the search over graphs and the hand-engineering of suitable score functions. Moreover, the architecture of our inference model is permutation invariant w.r.t. the data points and permutation equivariant w.r.t. the variables, facilitating generalization to significantly larger problem instances than seen during training. On synthetic data and semi-synthetic gene expression data, our models exhibit robust generalization capabilities under substantial distribution shift and significantly outperform existing algorithms, especially in the challenging genomics domain. ",
    "url": "https://arxiv.org/abs/2205.12934",
    "authors": [
      "Lars Lorch",
      "Scott Sussex",
      "Jonas Rothfuss",
      "Andreas Krause",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.12938",
    "title": "Joint Beam Management and Power Allocation in THz-NOMA Networks",
    "abstract": "This paper investigates how to apply non-orthogonal multiple access (NOMA) as an add-on in terahertz (THz) networks. In particular, prior to the implementation of NOMA, it is assumed that there exists a legacy THz system, where spatial beams have already been configured to serve legacy primary users. The aim of this paper is to study how these pre-configured spatial beams can be used as a type of bandwidth resources, on which additional secondary users are served without degrading the performance of the legacy primary users. A joint beam management and power allocation problem is first formulated as a mixed combinatorial non-convex optimization problem, and then solved by two methods with different performance-complexity tradeoffs, one based on the branch and bound method and the other based on successive convex approximation. Both analytical and simulation results are presented to illustrate the new features of beam-based resource allocation in THz-NOMA networks and also demonstrate that those pre-configured spatial beams can be employed to improve the system throughput and connectivity in a spectrally efficient manner. ",
    "url": "https://arxiv.org/abs/2205.12938",
    "authors": [
      "Zhiguo Ding",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.12955",
    "title": "Neural 3D Reconstruction in the Wild",
    "abstract": "We are witnessing an explosion of neural implicit representations in computer vision and graphics. Their applicability has recently expanded beyond tasks such as shape generation and image-based rendering to the fundamental problem of image-based 3D reconstruction. However, existing methods typically assume constrained 3D environments with constant illumination captured by a small set of roughly uniformly distributed cameras. We introduce a new method that enables efficient and accurate surface reconstruction from Internet photo collections in the presence of varying illumination. To achieve this, we propose a hybrid voxel- and surface-guided sampling technique that allows for more efficient ray sampling around surfaces and leads to significant improvements in reconstruction quality. Further, we present a new benchmark and protocol for evaluating reconstruction performance on such in-the-wild scenes. We perform extensive experiments, demonstrating that our approach surpasses both classical and neural reconstruction methods on a wide variety of metrics. ",
    "url": "https://arxiv.org/abs/2205.12955",
    "authors": [
      "Jiaming Sun",
      "Xi Chen",
      "Qianqian Wang",
      "Zhengqi Li",
      "Hadar Averbuch-Elor",
      "Xiaowei Zhou",
      "Noah Snavely"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2205.12127",
    "title": "Privacy and correctness trade-offs for information-theoretically secure  quantum homomorphic encryption",
    "abstract": "Quantum homomorphic encryption, which allows computation by a server directly on encrypted data, is a fundamental primitive out of which more complex quantum cryptography protocols can be built. For such constructions to be possible, quantum homomorphic encryption must satisfy two privacy properties: data privacy which ensures that the input data is private from the server, and circuit privacy which ensures that the ciphertext after the computation does not reveal any additional information about the circuit used to perform it, beyond the output of the computation itself. While circuit privacy is well-studied in classical cryptography and many homomorphic encryption schemes can be equipped with it, its quantum analogue has received little attention. Here we establish a definition of circuit privacy for quantum homomorphic encryption with information-theoretic security. Furthermore, we reduce quantum oblivious transfer to quantum homomorphic encryption. Using this reduction, our work unravels fundamental trade-offs between circuit privacy, data privacy and correctness for a broad family of quantum homomorphic encryption protocols, including schemes that allow only computation of Clifford circuits. ",
    "url": "https://arxiv.org/abs/2205.12127",
    "authors": [
      "Yanglin Hu",
      "Yingkai Ouyang",
      "Marco Tomamichel"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.12338",
    "title": "Hippocluster: an efficient, hippocampus-inspired algorithm for graph  clustering",
    "abstract": "Random walks can reveal communities or clusters in networks, because they are more likely to stay within a cluster than leave it. Thus, one family of community detection algorithms uses random walks to measure distance between pairs of nodes in various ways, and then applies K-Means or other generic clustering methods to these distances. Interestingly, information processing in the brain may suggest a simpler method of learning clusters directly from random walks. Drawing inspiration from the hippocampus, we describe a simple two-layer neural learning framework. Neurons in one layer are associated with graph nodes and simulate random walks. These simulations cause neurons in the second layer to become tuned to graph clusters through simple associative learning. We show that if these neuronal interactions are modelled a particular way, the system is essentially a variant of K-Means clustering applied directly in the walk-space, bypassing the usual step of computing node distances/similarities. The result is an efficient graph clustering method. Biological information processing systems are known for high efficiency and adaptability. In tests on benchmark graphs, our framework demonstrates this high data-efficiency, low memory use, low complexity, and real-time adaptation to graph changes, while still achieving clustering quality comparable to other algorithms. ",
    "url": "https://arxiv.org/abs/2205.12338",
    "authors": [
      "Eric Chalmers",
      "Artur Luczak"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.12354",
    "title": "Optimal Entanglement Distribution using Satellite Based Quantum Networks",
    "abstract": "Recent technological advancements in satellite based quantum communication has made it a promising technology for realizing global scale quantum networks. Due to better loss distance scaling compared to ground based fiber communication, satellite quantum communication can distribute high quality quantum entanglements among ground stations that are geographically separated at very long distances. This work focuses on optimal distribution of bipartite entanglements to a set of pair of ground stations using a constellation of orbiting satellites. In particular, we characterize the optimal satellite-to-ground station transmission scheduling policy with respect to the aggregate entanglement distribution rate subject to various resource constraints at the satellites and ground stations. We cast the optimal transmission scheduling problem as an integer linear programming problem and solve it efficiently for some specific scenarios. Our framework can also be used as a benchmark tool to measure the performance of other potential transmission scheduling policies. ",
    "url": "https://arxiv.org/abs/2205.12354",
    "authors": [
      "Nitish K. Panigrahy",
      "Prajit Dhara",
      "Don Towsley",
      "Saikat Guha",
      "Leandros Tassiulas"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.12429",
    "title": "Interaction of a priori Anatomic Knowledge with Self-Supervised  Contrastive Learning in Cardiac Magnetic Resonance Imaging",
    "abstract": "Training deep learning models on cardiac magnetic resonance imaging (CMR) can be a challenge due to the small amount of expert generated labels and inherent complexity of data source. Self-supervised contrastive learning (SSCL) has recently been shown to boost performance in several medical imaging tasks. However, it is unclear how much the pre-trained representation reflects the primary organ of interest compared to spurious surrounding tissue. In this work, we evaluate the optimal method of incorporating prior knowledge of anatomy into a SSCL training paradigm. Specifically, we evaluate using a segmentation network to explicitly local the heart in CMR images, followed by SSCL pretraining in multiple diagnostic tasks. We find that using a priori knowledge of anatomy can greatly improve the downstream diagnostic performance. Furthermore, SSCL pre-training with in-domain data generally improved downstream performance and more human-like saliency compared to end-to-end training and ImageNet pre-trained networks. However, introducing anatomic knowledge to pre-training generally does not have significant impact. ",
    "url": "https://arxiv.org/abs/2205.12429",
    "authors": [
      "Makiya Nakashima",
      "Inyeop Jang",
      "Ramesh Basnet",
      "Mitchel Benovoy",
      "W.H. Wilson Tang",
      "Christopher Nguyen",
      "Deborah Kwon",
      "Tae Hyun Hwang",
      "David Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12632",
    "title": "Robust Differential Dynamic Programming",
    "abstract": "Differential Dynamic Programming is an optimal control technique often used for trajectory generation. Many variations of this algorithm have been developed in the literature, including algorithms for stochastic dynamics or state and input constraints. In this contribution, we develop a robust version of Differential Dynamic Programming that uses generalized plants and multiplier relaxations for uncertainties. To this end, we study a version of the Bellman principle and use convex relaxations to account for uncertainties in the dynamic program. The resulting algorithm can be seen as a robust trajectory generation tool for nonlinear systems. ",
    "url": "https://arxiv.org/abs/2205.12632",
    "authors": [
      "Dennis Gramlich",
      "Carsten W. Scherer",
      "Christian Ebenbauer"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.12642",
    "title": "On the Interpretability of Regularisation for Neural Networks Through  Model Gradient Similarity",
    "abstract": "Most complex machine learning and modelling techniques are prone to over-fitting and may subsequently generalise poorly to future data. Artificial neural networks are no different in this regard and, despite having a level of implicit regularisation when trained with gradient descent, often require the aid of explicit regularisers. We introduce a new framework, Model Gradient Similarity (MGS), that (1) serves as a metric of regularisation, which can be used to monitor neural network training, (2) adds insight into how explicit regularisers, while derived from widely different principles, operate via the same mechanism underneath by increasing MGS, and (3) provides the basis for a new regularisation scheme which exhibits excellent performance, especially in challenging settings such as high levels of label noise or limited sample sizes. ",
    "url": "https://arxiv.org/abs/2205.12642",
    "authors": [
      "Vincent Szolnoky",
      "Viktor Andersson",
      "Balazs Kulcsar",
      "Rebecka J\u00f6rnsten"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2205.12803",
    "title": "Graph Agnostic Randomized Experimental Design",
    "abstract": "Randomized experiments are widely used to estimate causal effects of proposed \"treatments\" in domains spanning across physical sciences, social sciences, medicine, and technology industries. However, classical approaches to experimental design rely on critical independence assumptions that are violated when the outcome of an individual a may be affected by the treatment of another individual b, referred to as network interference. Under such network interference, naively using popular estimators and randomized experimental designs can result in significant bias and loss of efficiency. We consider a heterogeneous linear outcomes model that can capture network interference that arises from spillover, peer effects, and contagion. Under this model, we characterize the limitations and possibilities for estimating the total treatment effect, average direct treatment effect, and average interference effect. Given access to average historical baseline measurements prior to the experiment, we propose simple estimators and randomized designs that output unbiased estimates with low variance for these three estimands. Furthermore, our solution and statistical guarantees do not require knowledge of the underlying network structure, and thus can be used for scenarios where the network is unknown and complex. We believe our results are poised to impact current randomized experimentation strategies due to its ease of interpretation and implementation, alongside its provable statistical guarantees under heterogeneous network effects. ",
    "url": "https://arxiv.org/abs/2205.12803",
    "authors": [
      "Christina Lee Yu",
      "Edoardo M Airoldi",
      "Christian Borgs",
      "Jennifer T Chayes"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.12857",
    "title": "Structure Unbiased Adversarial Model for Medical Image Segmentation",
    "abstract": "Generative models have been widely proposed in image recognition to generate more images where the distribution is similar to that of the real images. It often introduces a discriminator network to discriminate original real data and generated data. However, such discriminator often considers the distribution of the data and did not pay enough attention to the intrinsic gap due to structure. In this paper, we reformulate a new image to image translation problem to reduce structural gap, in addition to the typical intensity distribution gap. We further propose a simple yet important Structure Unbiased Adversarial Model for Medical Image Segmentation (SUAM) with learnable inverse structural deformation for medical image segmentation. It consists of a structure extractor, an attention diffeomorphic registration and a structure \\& intensity distribution rendering module. The structure extractor aims to extract the dominant structure of the input image. The attention diffeomorphic registration is proposed to reduce the structure gap with an inverse deformation field to warp the prediction masks back to their original form. The structure rendering module is to render the deformed structure to an image with targeted intensity distribution. We apply the proposed SUAM on both optical coherence tomography (OCT), magnetic resonance imaging (MRI) and computerized tomography (CT) data. Experimental results show that the proposed method has the capability to transfer both intensity and structure distributions. ",
    "url": "https://arxiv.org/abs/2205.12857",
    "authors": [
      "Tianyang Zhang",
      "Shaoming Zheng",
      "Jun Cheng",
      "Xi Jia",
      "Joseph Bartlett",
      "Huazhu Fu",
      "Zhaowen Qiu",
      "Jiang Liu",
      "Jinming Duan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12902",
    "title": "RADNet: Ensemble Model for Robust Glaucoma Classification in Color  Fundus Images",
    "abstract": "Glaucoma is one of the most severe eye diseases, characterized by rapid progression and leading to irreversible blindness. It is often the case that pathology diagnostics is carried out when the one's sight has already significantly degraded due to the lack of noticeable symptoms at early stage of the disease. Regular glaucoma screenings of the population shall improve early-stage detection, however the desirable frequency of etymological checkups is often not feasible due to excessive load imposed by manual diagnostics on limited number of specialists. Considering the basic methodology to detect glaucoma is to analyze fundus images for the \\textit{optic-disc-to-optic-cup ratio}, Machine Learning domain can offer sophisticated tooling for image processing and classification. In our work, we propose an advanced image pre-processing technique combined with an ensemble of deep classification networks. Our \\textit{Retinal Auto Detection (RADNet)} model has been successfully tested on Rotterdam EyePACS AIROGS train dataset with AUC of 0.92, and then additionally finetuned and tested on a fraction of RIM-ONE DL dataset with AUC of 0.91. ",
    "url": "https://arxiv.org/abs/2205.12902",
    "authors": [
      "Dmitrii Medvedev",
      "Rand Muhtaseb",
      "Ahmed Al Mahrooqi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12933",
    "title": "Boosting Tail Neural Network for Realtime Custom Keyword Spotting",
    "abstract": "In this paper, we propose a Boosting Tail Neural Network (BTNN) for improving the performance of Realtime Custom Keyword Spotting (RCKS) that is still an industrial challenge for demanding powerful classification ability with limited computation resources. Inspired by Brain Science that a brain is only partly activated for a nerve simulation and numerous machine learning algorithms are developed to use a batch of weak classifiers to resolve arduous problems, which are often proved to be effective. We show that this method is helpful to the RCKS problem. The proposed approach achieve better performances in terms of wakeup rate and false alarm. In our experiments compared with those traditional algorithms that use only one strong classifier, it gets 18\\% relative improvement. We also point out that this approach may be promising in future ASR exploration. ",
    "url": "https://arxiv.org/abs/2205.12933",
    "authors": [
      "Sihao Xue",
      "Qianyao Shen",
      "Guoqing Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2205.12940",
    "title": "Conformal Prediction Intervals with Temporal Dependence",
    "abstract": "Cross-sectional prediction is common in many domains such as healthcare, including forecasting tasks using electronic health records, where different patients form a cross-section. We focus on the task of constructing valid prediction intervals (PIs) in time-series regression with a cross-section. A prediction interval is considered valid if it covers the true response with (a pre-specified) high probability. We first distinguish between two notions of validity in such a setting: cross-sectional and longitudinal. Cross-sectional validity is concerned with validity across the cross-section of the time series data, while longitudinal validity accounts for the temporal dimension. Coverage guarantees along both these dimensions are ideally desirable; however, we show that distribution-free longitudinal validity is theoretically impossible. Despite this limitation, we propose Conformal Prediction with Temporal Dependence (CPTD), a procedure which is able to maintain strict cross-sectional validity while improving longitudinal coverage. CPTD is post-hoc and light-weight, and can easily be used in conjunction with any prediction model as long as a calibration set is available. We focus on neural networks due to their ability to model complicated data such as diagnosis codes for time-series regression, and perform extensive experimental validation to verify the efficacy of our approach. We find that CPTD outperforms baselines on a variety of datasets by improving longitudinal coverage and often providing more efficient (narrower) PIs. ",
    "url": "https://arxiv.org/abs/2205.12940",
    "authors": [
      "Zhen Lin",
      "Shubhendu Trivedi",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:1901.05894",
    "title": "LiSHT: Non-Parametric Linearly Scaled Hyperbolic Tangent Activation  Function for Neural Networks",
    "abstract": " Title: LiSHT: Non-Parametric Linearly Scaled Hyperbolic Tangent Activation  Function for Neural Networks ",
    "url": "https://arxiv.org/abs/1901.05894",
    "authors": [
      "Swalpa Kumar Roy",
      "Suvojit Manna",
      "Shiv Ram Dubey",
      "Bidyut Baran Chaudhuri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1904.07957",
    "title": "Almost-Smooth Histograms and Sliding-Window Graph Algorithms",
    "abstract": " Title: Almost-Smooth Histograms and Sliding-Window Graph Algorithms ",
    "url": "https://arxiv.org/abs/1904.07957",
    "authors": [
      "Robert Krauthgamer",
      "David Reitblat"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2002.03977",
    "title": "Multimodal active speaker detection and virtual cinematography for video  conferencing",
    "abstract": " Title: Multimodal active speaker detection and virtual cinematography for video  conferencing ",
    "url": "https://arxiv.org/abs/2002.03977",
    "authors": [
      "Ross Cutler",
      "Ramin Mehran",
      "Sam Johnson",
      "Cha Zhang",
      "Adam Kirk",
      "Oliver Whyte",
      "Adarsh Kowdle"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2011.01174",
    "title": "Learning to Maximize Speech Quality Directly Using MOS Prediction for  Neural Text-to-Speech",
    "abstract": " Comments: 9 pages, 5 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2011.01174",
    "authors": [
      "Yeunju Choi",
      "Youngmoon Jung",
      "Youngjoo Suh",
      "Hoirin Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2011.12193",
    "title": "xFraud: Explainable Fraud Transaction Detection",
    "abstract": " Comments: This is the extended version of a full paper to appear in PVLDB 15 (3) (VLDB 2022) ",
    "url": "https://arxiv.org/abs/2011.12193",
    "authors": [
      "Susie Xi Rao",
      "Shuai Zhang",
      "Zhichao Han",
      "Zitao Zhang",
      "Wei Min",
      "Zhiyao Chen",
      "Yinan Shan",
      "Yang Zhao",
      "Ce Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2103.01932",
    "title": "Meta-Learning-Based Robust Adaptive Flight Control Under Uncertain Wind  Conditions",
    "abstract": " Comments: 7 pages, 7 figures; this article is an early draft and presents preliminary results; the full method and improved results were published in Science Robotics on May 4th, 2022: doi.org/10.1126/scirobotics.abm6597; arXiv: doi.org/10.48550/arXiv.2205.06908 ",
    "url": "https://arxiv.org/abs/2103.01932",
    "authors": [
      "Michael O'Connell",
      "Guanya Shi",
      "Xichen Shi",
      "Soon-Jo Chung"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2105.08840",
    "title": "Training Heterogeneous Features in Sequence to Sequence Tasks: Latent  Enhanced Multi-filter Seq2Seq Model",
    "abstract": " Comments: Accepted to Intelligent Systems Conference 2022 ",
    "url": "https://arxiv.org/abs/2105.08840",
    "authors": [
      "Yunhao Yang",
      "Zhaokun Xue"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.07548",
    "title": "A scalable multi-step least squares method for network identification  with unknown disturbance topology",
    "abstract": " Comments: 17 pages, 4 figures, accepted and published in Automatica Volume 141, July 2022 ",
    "url": "https://arxiv.org/abs/2106.07548",
    "authors": [
      "Stefanie J.M. Fonken",
      "Karthik R. Ramaswamy",
      "Paul M.J. Van den Hof"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.10823",
    "title": "3D Object Detection for Autonomous Driving: A Survey",
    "abstract": " Comments: The manuscript is accepted by Pattern Recognition on 14 May 2022 ",
    "url": "https://arxiv.org/abs/2106.10823",
    "authors": [
      "Rui Qian",
      "Xin Lai",
      "Xirong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.00946",
    "title": "Online Metro Origin-Destination Prediction via Heterogeneous Information  Aggregation",
    "abstract": " Comments: This paper has been accepted to TPAMI ",
    "url": "https://arxiv.org/abs/2107.00946",
    "authors": [
      "Lingbo Liu",
      "Yuying Zhu",
      "Guanbin Li",
      "Ziyi Wu",
      "Lei Bai",
      "Liang Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.11839",
    "title": "Differential Privacy in the Shuffle Model: A Survey of Separations",
    "abstract": " Comments: 24 May '22 version includes more recent work on sums, histograms, and an appendix comparing the shuffle model with other distributed models ",
    "url": "https://arxiv.org/abs/2107.11839",
    "authors": [
      "Albert Cheu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2108.12947",
    "title": "Learning JPEG Compression Artifacts for Image Manipulation Detection and  Localization",
    "abstract": " Comments: The version of record of this article, published in the International Journal of Computer Vision (IJCV), is available online at Publisher's website: this https URL ; Code is available at: this https URL ",
    "url": "https://arxiv.org/abs/2108.12947",
    "authors": [
      "Myung-Joon Kwon",
      "Seung-Hun Nam",
      "In-Jae Yu",
      "Heung-Kyu Lee",
      "Changick Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2109.06604",
    "title": "Non-Parametric Unsupervised Domain Adaptation for Neural Machine  Translation",
    "abstract": " Comments: Findings of EMNLP 2021 ",
    "url": "https://arxiv.org/abs/2109.06604",
    "authors": [
      "Xin Zheng",
      "Zhirui Zhang",
      "Shujian Huang",
      "Boxing Chen",
      "Jun Xie",
      "Weihua Luo",
      "Jiajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.01174",
    "title": "Deep Kernel Representation for Image Reconstruction in PET",
    "abstract": " Title: Deep Kernel Representation for Image Reconstruction in PET ",
    "url": "https://arxiv.org/abs/2110.01174",
    "authors": [
      "Siqi Li",
      "Guobao Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.07736",
    "title": "Identifying and Mitigating Spurious Correlations for Improving  Robustness in NLP Models",
    "abstract": " Comments: 8 pages, accepted to NAACL 2022 Findings ",
    "url": "https://arxiv.org/abs/2110.07736",
    "authors": [
      "Tianlu Wang",
      "Rohit Sridhar",
      "Diyi Yang",
      "Xuezhi Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2111.04964",
    "title": "On Representation Knowledge Distillation for Graph Neural Networks",
    "abstract": " Title: On Representation Knowledge Distillation for Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2111.04964",
    "authors": [
      "Chaitanya K. Joshi",
      "Fayao Liu",
      "Xu Xun",
      "Jie Lin",
      "Chuan-Sheng Foo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.07006",
    "title": "Optimization Framework for Splitting DNN Inference Jobs over Computing  Networks",
    "abstract": " Comments: Submitted for publication ",
    "url": "https://arxiv.org/abs/2111.07006",
    "authors": [
      "Sehun Jung",
      "Hyang-Won Lee"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2111.11165",
    "title": "Graph-Based Similarity of Neural Network Representations",
    "abstract": " Title: Graph-Based Similarity of Neural Network Representations ",
    "url": "https://arxiv.org/abs/2111.11165",
    "authors": [
      "Zuohui Chen",
      "Yao Lu",
      "Jinxuan Hu",
      "Wen Yang",
      "Qi Xuan",
      "Zhen Wang",
      "Xiaoniu Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.15119",
    "title": "Aerial Images Meet Crowdsourced Trajectories: A New Approach to Robust  Road Extraction",
    "abstract": " Comments: This work has been accepted by IEEE Transactions on Neural Networks and Learning Systems ",
    "url": "https://arxiv.org/abs/2111.15119",
    "authors": [
      "Lingbo Liu",
      "Zewei Yang",
      "Guanbin Li",
      "Kuo Wang",
      "Tianshui Chen",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.03753",
    "title": "Tell me why! Explanations support learning relational and causal  structure",
    "abstract": " Comments: ICML 2022; 23 pages ",
    "url": "https://arxiv.org/abs/2112.03753",
    "authors": [
      "Andrew K. Lampinen",
      "Nicholas A. Roy",
      "Ishita Dasgupta",
      "Stephanie C. Y. Chan",
      "Allison C. Tam",
      "James L. McClelland",
      "Chen Yan",
      "Adam Santoro",
      "Neil C. Rabinowitz",
      "Jane X. Wang",
      "Felix Hill"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.08609",
    "title": "DuQM: A Chinese Dataset of Linguistically Perturbed Natural Questions  for Evaluating the Robustness of Question Matching Models",
    "abstract": " Title: DuQM: A Chinese Dataset of Linguistically Perturbed Natural Questions  for Evaluating the Robustness of Question Matching Models ",
    "url": "https://arxiv.org/abs/2112.08609",
    "authors": [
      "Hongyu Zhu",
      "Yan Chen",
      "Jing Yan",
      "Jing Liu",
      "Yu Hong",
      "Ying Chen",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.13798",
    "title": "PORTFILER: Port-Level Network Profiling for Self-Propagating Malware  Detection",
    "abstract": " Comments: An earlier version is accepted to be published in IEEE Conference on Communications and Network Security (CNS) 2021 ",
    "url": "https://arxiv.org/abs/2112.13798",
    "authors": [
      "Talha Ongun",
      "Oliver Spohngellert",
      "Benjamin Miller",
      "Simona Boboila",
      "Alina Oprea",
      "Tina Eliassi-Rad",
      "Jason Hiser",
      "Alastair Nottingham",
      "Jack Davidson",
      "Malathi Veeraraghavan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.01549",
    "title": "SPT-Code: Sequence-to-Sequence Pre-Training for Learning Source Code  Representations",
    "abstract": " Comments: ICSE 2022: Technical Track ",
    "url": "https://arxiv.org/abs/2201.01549",
    "authors": [
      "Changan Niu",
      "Chuanyi Li",
      "Vincent Ng",
      "Jidong Ge",
      "Liguo Huang",
      "Bin Luo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2201.07070",
    "title": "Attention-based Proposals Refinement for 3D Object Detection",
    "abstract": " Comments: Accepted for IV 2022 ",
    "url": "https://arxiv.org/abs/2201.07070",
    "authors": [
      "Minh-Quan Dao",
      "Elwan H\u00e9ry",
      "Vincent Fr\u00e9mont"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2201.07546",
    "title": "Welfare vs. Representation in Participatory Budgeting",
    "abstract": " Title: Welfare vs. Representation in Participatory Budgeting ",
    "url": "https://arxiv.org/abs/2201.07546",
    "authors": [
      "Roy Fairstein",
      "Reshef Meir",
      "Dan Vilenchik",
      "Kobi Gal"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2202.04579",
    "title": "Neural Sheaf Diffusion: A Topological Perspective on Heterophily and  Oversmoothing in GNNs",
    "abstract": " Comments: 27 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2202.04579",
    "authors": [
      "Cristian Bodnar",
      "Francesco Di Giovanni",
      "Benjamin Paul Chamberlain",
      "Pietro Li\u00f2",
      "Michael M. Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2202.05100",
    "title": "Adaptively Exploiting d-Separators with Causal Bandits",
    "abstract": " Comments: 33 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2202.05100",
    "authors": [
      "Blair Bilodeau",
      "Linbo Wang",
      "Daniel M. Roy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05713",
    "title": "Cross Domain Few-Shot Learning via Meta Adversarial Training",
    "abstract": " Comments: 6 pages including references ",
    "url": "https://arxiv.org/abs/2202.05713",
    "authors": [
      "Jirui Qi",
      "Richong Zhang",
      "Chune Li",
      "Yongyi Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.01137",
    "title": "Self-Supervised Scene Flow Estimation with 4D Automotive Radar",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2203.01137",
    "authors": [
      "Fangqiang Ding",
      "Zhijun Pan",
      "Yimin Deng",
      "Jianning Deng",
      "Chris Xiaoxuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.01451",
    "title": "Label Leakage and Protection from Forward Embedding in Vertical  Federated Learning",
    "abstract": " Title: Label Leakage and Protection from Forward Embedding in Vertical  Federated Learning ",
    "url": "https://arxiv.org/abs/2203.01451",
    "authors": [
      "Jiankai Sun",
      "Xin Yang",
      "Yuanshun Yao",
      "Chong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.05757",
    "title": "A comparative study of non-deep learning, deep learning, and ensemble  learning methods for sunspot number prediction",
    "abstract": " Title: A comparative study of non-deep learning, deep learning, and ensemble  learning methods for sunspot number prediction ",
    "url": "https://arxiv.org/abs/2203.05757",
    "authors": [
      "Yuchen Dang",
      "Ziqi Chen",
      "Heng Li",
      "Hai Shu"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07648",
    "title": "Contrastive Learning of Sociopragmatic Meaning in Social Media",
    "abstract": " Comments: Work in progress ",
    "url": "https://arxiv.org/abs/2203.07648",
    "authors": [
      "Chiyu Zhang",
      "Muhammad Abdul-Mageed",
      "Ganesh Jawahar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.10093",
    "title": "Deep Reinforcement Learning Guided Graph Neural Networks for Brain  Network Analysis",
    "abstract": " Title: Deep Reinforcement Learning Guided Graph Neural Networks for Brain  Network Analysis ",
    "url": "https://arxiv.org/abs/2203.10093",
    "authors": [
      "Xusheng Zhao",
      "Jia Wu",
      "Hao Peng",
      "Amin Beheshti",
      "Jessica Monaghan",
      "David McAlpine",
      "Heivet Hernandez-Perez",
      "Mark Dras",
      "Qiong Dai",
      "Yangyang Li",
      "Philip S. Yu",
      "Lifang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2204.00122",
    "title": "Synthesis of Stabilizing Recurrent Equilibrium Network Controllers",
    "abstract": " Comments: Submitted to IEEE CDC 2022. arXiv admin note: text overlap with arXiv:2109.03861 ",
    "url": "https://arxiv.org/abs/2204.00122",
    "authors": [
      "Neelay Junnarkar",
      "He Yin",
      "Fangda Gu",
      "Murat Arcak",
      "Peter Seiler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.03080",
    "title": "Graph Neural Networks Designed for Different Graph Types: A Survey",
    "abstract": " Title: Graph Neural Networks Designed for Different Graph Types: A Survey ",
    "url": "https://arxiv.org/abs/2204.03080",
    "authors": [
      "Josephine M. Thomas",
      "Alice Moallemy-Oureh",
      "Silvia Beddar-Wiesing",
      "Clara Holzh\u00fcter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.10629",
    "title": "MEKER: Memory Efficient Knowledge Embedding Representation for Link  Prediction and Question Answering",
    "abstract": " Title: MEKER: Memory Efficient Knowledge Embedding Representation for Link  Prediction and Question Answering ",
    "url": "https://arxiv.org/abs/2204.10629",
    "authors": [
      "Viktoriia Chekalina",
      "Anton Razzhigaev",
      "Albert Sayapin",
      "Evgeny Frolov",
      "Alexander Panchenko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.12344",
    "title": "REDCHO: Robust Exact Dynamic Consensus of High Order",
    "abstract": " Comments: This is the preprint version of the accepted Manuscript: Rodrigo Aldana-Lopez, Rosario Aragues, Carlos Sagues, REDCHO: Robust Exact Dynamic Consensus of High Order, Automatica, Volume 141, 2022, ISSN 0005-1098 ",
    "url": "https://arxiv.org/abs/2204.12344",
    "authors": [
      "Rodrigo Aldana-L\u00f3pez",
      "Rosario Arag\u00fc\u00e9s",
      "Carlos Sag\u00fc\u00e9s"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2204.12581",
    "title": "RAMBO-RL: Robust Adversarial Model-Based Offline Reinforcement Learning",
    "abstract": " Title: RAMBO-RL: Robust Adversarial Model-Based Offline Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2204.12581",
    "authors": [
      "Marc Rigter",
      "Bruno Lacerda",
      "Nick Hawes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.00690",
    "title": "From Noisy Prediction to True Label: Noisy Prediction Calibration via  Generative Model",
    "abstract": " Comments: 21 pages, 9 figures. International Conference on Machine Learning (ICML 2022), Baltimore, Jul 17, 2022 ",
    "url": "https://arxiv.org/abs/2205.00690",
    "authors": [
      "HeeSun Bae",
      "Seungjae Shin",
      "Byeonghu Na",
      "JoonHo Jang",
      "Kyungwoo Song",
      "Il-Chul Moon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01681",
    "title": "Growing Isotropic Neural Cellular Automata",
    "abstract": " Title: Growing Isotropic Neural Cellular Automata ",
    "url": "https://arxiv.org/abs/2205.01681",
    "authors": [
      "Alexander Mordvintsev",
      "Ettore Randazzo",
      "Craig Fouts"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Cell Behavior (q-bio.CB)"
    ]
  },
  {
    "id": "arXiv:2205.03915",
    "title": "FOLPETTI: A Novel Multi-Armed Bandit Smart Attack for Wireless Networks",
    "abstract": " Title: FOLPETTI: A Novel Multi-Armed Bandit Smart Attack for Wireless Networks ",
    "url": "https://arxiv.org/abs/2205.03915",
    "authors": [
      "Emilie Bout",
      "Alessandro Brighente",
      "Mauro Conti",
      "Valeria Loscri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.06589",
    "title": "Discrete density comonads and graph parameters",
    "abstract": " Title: Discrete density comonads and graph parameters ",
    "url": "https://arxiv.org/abs/2205.06589",
    "authors": [
      "Samson Abramsky",
      "Tom\u00e1\u0161 Jakl",
      "Thomas Paine"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2205.08304",
    "title": "Bayesian Physics-Informed Neural Networks for real-world nonlinear  dynamical systems",
    "abstract": " Title: Bayesian Physics-Informed Neural Networks for real-world nonlinear  dynamical systems ",
    "url": "https://arxiv.org/abs/2205.08304",
    "authors": [
      "Kevin Linka",
      "Amelie Schafer",
      "Xuhui Meng",
      "Zongren Zou",
      "George Em Karniadakis",
      "Ellen Kuhl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2205.09612",
    "title": "CLCNet: Rethinking of Ensemble Modeling with Classification Confidence  Network",
    "abstract": " Title: CLCNet: Rethinking of Ensemble Modeling with Classification Confidence  Network ",
    "url": "https://arxiv.org/abs/2205.09612",
    "authors": [
      "Yao-Ching Yu",
      "Shi-Jinn Horng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10390",
    "title": "EGR: Equivariant Graph Refinement and Assessment of 3D Protein Complex  Structures",
    "abstract": " Comments: 18 pages, 3 figures, and 8 tables. Under review ",
    "url": "https://arxiv.org/abs/2205.10390",
    "authors": [
      "Alex Morehead",
      "Xiao Chen",
      "Tianqi Wu",
      "Jian Liu",
      "Jianlin Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.10937",
    "title": "muNet: Evolving Pretrained Deep Neural Networks into Scalable  Auto-tuning Multitask Systems",
    "abstract": " Title: muNet: Evolving Pretrained Deep Neural Networks into Scalable  Auto-tuning Multitask Systems ",
    "url": "https://arxiv.org/abs/2205.10937",
    "authors": [
      "Andrea Gesmundo",
      "Jeff Dean"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.11191",
    "title": "NPU-BOLT: A Dataset for Bolt Object Detection in Natural Scene Images",
    "abstract": " Title: NPU-BOLT: A Dataset for Bolt Object Detection in Natural Scene Images ",
    "url": "https://arxiv.org/abs/2205.11191",
    "authors": [
      "Yadian Zhao",
      "Zhenglin Yang",
      "Chao Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11461",
    "title": "Undecidability of Network Coding, Conditional Information Inequalities,  and Conditional Independence Implication",
    "abstract": " Comments: 18 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2205.11461",
    "authors": [
      "Cheuk Ting Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2205.11811",
    "title": "Sensing Performance of Multi-Channel RFID-based Finger Augmentation  Devices for Tactile Internet",
    "abstract": " Comments: Accepted for publication in \"IEEE Journal on Radio Frequency Identification\" ",
    "url": "https://arxiv.org/abs/2205.11811",
    "authors": [
      "Federica Naccarata",
      "Giulio Maria Bianco",
      "Gaetano Marrocco"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.11951",
    "title": "Diffuse Map Guiding Unsupervised Generative Adversarial Network for  SVBRDF Estimation",
    "abstract": " Title: Diffuse Map Guiding Unsupervised Generative Adversarial Network for  SVBRDF Estimation ",
    "url": "https://arxiv.org/abs/2205.11951",
    "authors": [
      "Zhiyao Luo",
      "Hongnan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  }
]