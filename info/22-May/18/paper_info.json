[
  {
    "id": "arXiv:2205.07851",
    "title": "ST-ExpertNet: A Deep Expert Framework for Traffic Prediction",
    "abstract": "Recently, forecasting the crowd flows has become an important research topic, and plentiful technologies have achieved good performances. As we all know, the flow at a citywide level is in a mixed state with several basic patterns (e.g., commuting, working, and commercial) caused by the city area functional distributions (e.g., developed commercial areas, educational areas and parks). However, existing technologies have been criticized for their lack of considering the differences in the flow patterns among regions since they want to build only one comprehensive model to learn the mixed flow tensors. Recognizing this limitation, we present a new perspective on flow prediction and propose an explainable framework named ST-ExpertNet, which can adopt every spatial-temporal model and train a set of functional experts devoted to specific flow patterns. Technically, we train a bunch of experts based on the Mixture of Experts (MoE), which guides each expert to specialize in different kinds of flow patterns in sample spaces by using the gating network. We define several criteria, including comprehensiveness, sparsity, and preciseness, to construct the experts for better interpretability and performances. We conduct experiments on a wide range of real-world taxi and bike datasets in Beijing and NYC. The visualizations of the expert's intermediate results demonstrate that our ST-ExpertNet successfully disentangles the city's mixed flow tensors along with the city layout, e.g., the urban ring road structure. Different network architectures, such as ST-ResNet, ConvLSTM, and CNN, have been adopted into our ST-ExpertNet framework for experiments and the results demonstrates the superiority of our framework in both interpretability and performances. ",
    "url": "https://arxiv.org/abs/2205.07851",
    "authors": [
      "Hongjun Wang",
      "Jiyuan Chen",
      "Zipei Fan",
      "Zhiwen Zhang",
      "Zekun Cai",
      "Xuan Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.07853",
    "title": "Heterogeneous Domain Adaptation with Adversarial Neural Representation  Learning: Experiments on E-Commerce and Cybersecurity",
    "abstract": "Learning predictive models in new domains with scarce training data is a growing challenge in modern supervised learning scenarios. This incentivizes developing domain adaptation methods that leverage the knowledge in known domains (source) and adapt to new domains (target) with a different probability distribution. This becomes more challenging when the source and target domains are in heterogeneous feature spaces, known as heterogeneous domain adaptation (HDA). While most HDA methods utilize mathematical optimization to map source and target data to a common space, they suffer from low transferability. Neural representations have proven to be more transferable; however, they are mainly designed for homogeneous environments. Drawing on the theory of domain adaptation, we propose a novel framework, Heterogeneous Adversarial Neural Domain Adaptation (HANDA), to effectively maximize the transferability in heterogeneous environments. HANDA conducts feature and distribution alignment in a unified neural network architecture and achieves domain invariance through adversarial kernel learning. Three experiments were conducted to evaluate the performance against the state-of-the-art HDA methods on major image and text e-commerce benchmarks. HANDA shows statistically significant improvement in predictive performance. The practical utility of HANDA was shown in real-world dark web online markets. HANDA is an important step towards successful domain adaptation in e-commerce applications. ",
    "url": "https://arxiv.org/abs/2205.07853",
    "authors": [
      "Mohammadreza Ebrahimi",
      "Yidong Chai",
      "Hao Helen Zhang",
      "Hsinchun Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.07854",
    "title": "Functional2Structural: Cross-Modality Brain Networks Representation  Learning",
    "abstract": "MRI-based modeling of brain networks has been widely used to understand functional and structural interactions and connections among brain regions, and factors that affect them, such as brain development and disease. Graph mining on brain networks may facilitate the discovery of novel biomarkers for clinical phenotypes and neurodegenerative diseases. Since brain networks derived from functional and structural MRI describe the brain topology from different perspectives, exploring a representation that combines these cross-modality brain networks is non-trivial. Most current studies aim to extract a fused representation of the two types of brain network by projecting the structural network to the functional counterpart. Since the functional network is dynamic and the structural network is static, mapping a static object to a dynamic object is suboptimal. However, mapping in the opposite direction is not feasible due to the non-negativity requirement of current graph learning techniques. Here, we propose a novel graph learning framework, known as Deep Signed Brain Networks (DSBN), with a signed graph encoder that, from an opposite perspective, learns the cross-modality representations by projecting the functional network to the structural counterpart. We validate our framework on clinical phenotype and neurodegenerative disease prediction tasks using two independent, publicly available datasets (HCP and OASIS). The experimental results clearly demonstrate the advantages of our model compared to several state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2205.07854",
    "authors": [
      "Haoteng Tang",
      "Xiyao Fu",
      "Lei Guo",
      "Yalin Wang",
      "Scott Mackin",
      "Olusola Ajilore",
      "Alex Leow",
      "Paul Thompson",
      "Heng Huang",
      "Liang Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2205.07857",
    "title": "Neural Program Synthesis with Query",
    "abstract": "Aiming to find a program satisfying the user intent given input-output examples, program synthesis has attracted increasing interest in the area of machine learning. Despite the promising performance of existing methods, most of their success comes from the privileged information of well-designed input-output examples. However, providing such input-output examples is unrealistic because it requires the users to have the ability to describe the underlying program with a few input-output examples under the training distribution. In this work, we propose a query-based framework that trains a query neural network to generate informative input-output examples automatically and interactively from a large query space. The quality of the query depends on the amount of the mutual information between the query and the corresponding program, which can guide the optimization of the query framework. To estimate the mutual information more accurately, we introduce the functional space (F-space) which models the relevance between the input-output examples and the programs in a differentiable way. We evaluate the effectiveness and generalization of the proposed query-based framework on the Karel task and the list processing task. Experimental results show that the query-based framework can generate informative input-output examples which achieve and even outperform well-designed input-output examples. ",
    "url": "https://arxiv.org/abs/2205.07857",
    "authors": [
      "Di Huang",
      "Rui Zhang",
      "Xing Hu",
      "Xishan Zhang",
      "Pengwei Jin",
      "Nan Li",
      "Zidong Du",
      "Qi Guo",
      "Yunji Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.07859",
    "title": "Btech thesis report on adversarial attack detection and purification of  adverserially attacked images",
    "abstract": "This is Btech thesis report on detection and purification of adverserially attacked images. A deep learning model is trained on certain training examples for various tasks such as classification, regression etc. By training, weights are adjusted such that the model performs the task well not only on training examples judged by a certain metric but has an excellent ability to generalize on other unseen examples as well which are typically called the test data. Despite the huge success of machine learning models on a wide range of tasks, security has received a lot less attention along the years. Robustness along various potential cyber attacks also should be a metric for the accuracy of the machine learning models. These cyber attacks can potentially lead to a variety of negative impacts in the real world sensitive applications for which machine learning is used such as medical and transportation systems. Hence, it is a necessity to secure the system from such attacks. Int this report, I focus on a class of these cyber attacks called the adversarial attacks in which the original input sample is modified by small perturbations such that they still look visually the same to human beings but the machine learning models are fooled by such inputs. In this report I discuss 2 novel ways to counter the adversarial attack using AutoEncoders, 1) by detecting the presence of adversaries and 2) purifying these adversaries to make target classification models robust against such attacks. ",
    "url": "https://arxiv.org/abs/2205.07859",
    "authors": [
      "Dvij Kalaria"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.07860",
    "title": "AdaCap: Adaptive Capacity control for Feed-Forward Neural Networks",
    "abstract": "The capacity of a ML model refers to the range of functions this model can approximate. It impacts both the complexity of the patterns a model can learn but also memorization, the ability of a model to fit arbitrary labels. We propose Adaptive Capacity (AdaCap), a training scheme for Feed-Forward Neural Networks (FFNN). AdaCap optimizes the capacity of FFNN so it can capture the high-level abstract representations underlying the problem at hand without memorizing the training dataset. AdaCap is the combination of two novel ingredients, the Muddling labels for Regularization (MLR) loss and the Tikhonov operator training scheme. The MLR loss leverages randomly generated labels to quantify the propensity of a model to memorize. We prove that the MLR loss is an accurate in-sample estimator for out-of-sample generalization performance and that it can be used to perform Hyper-Parameter Optimization provided a Signal-to-Noise Ratio condition is met. The Tikhonov operator training scheme modulates the capacity of a FFNN in an adaptive, differentiable and data-dependent manner. We assess the effectiveness of AdaCap in a setting where DNN are typically prone to memorization, small tabular datasets, and benchmark its performance against popular machine learning methods. ",
    "url": "https://arxiv.org/abs/2205.07860",
    "authors": [
      "Katia Meziani",
      "Karim Lounici",
      "Benjamin Riu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.07863",
    "title": "Quality versus speed in energy demand prediction for district heating  systems",
    "abstract": "In this paper, we consider energy demand prediction in district heating systems. Effective energy demand prediction is essential in combined heat power systems when offering electrical energy in competitive electricity markets. To address this problem, we propose two sets of algorithms: (1) a novel extension to the algorithm proposed by E. Dotzauer and (2) an autoregressive predictor based on hour-of-week adjusted linear regression on moving averages of energy consumption. These two methods are compared against state-of-the-art artificial neural networks. Energy demand predictor algorithms have various computational costs and prediction quality. While prediction quality is a widely used measure of predictor superiority, computational costs are less frequently analyzed and their impact is not so extensively studied. When predictor algorithms are constantly updated using new data, some computationally expensive forecasting methods may become inapplicable. The computational costs can be split into training and execution parts. The execution part is the cost paid when the already trained algorithm is applied to predict something. In this paper, we evaluate the above methods with respect to the quality and computational costs, both in the training and in the execution. The comparison is conducted on a real-world dataset from a district heating system in the northwest part of Poland. ",
    "url": "https://arxiv.org/abs/2205.07863",
    "authors": [
      "Witold Andrzejewski",
      "Jedrzej Potoniec",
      "Maciej Drozdowski",
      "Jerzy Stefanowski",
      "Robert Wrembel",
      "Pawe\u0142 Stapf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.07864",
    "title": "Privacy Enhancement for Cloud-Based Few-Shot Learning",
    "abstract": "Requiring less data for accurate models, few-shot learning has shown robustness and generality in many application domains. However, deploying few-shot models in untrusted environments may inflict privacy concerns, e.g., attacks or adversaries that may breach the privacy of user-supplied data. This paper studies the privacy enhancement for the few-shot learning in an untrusted environment, e.g., the cloud, by establishing a novel privacy-preserved embedding space that preserves the privacy of data and maintains the accuracy of the model. We examine the impact of various image privacy methods such as blurring, pixelization, Gaussian noise, and differentially private pixelization (DP-Pix) on few-shot image classification and propose a method that learns privacy-preserved representation through the joint loss. The empirical results show how privacy-performance trade-off can be negotiated for privacy-enhanced few-shot learning. ",
    "url": "https://arxiv.org/abs/2205.07864",
    "authors": [
      "Archit Parnami",
      "Muhammad Usama",
      "Liyue Fan",
      "Minwoo Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.07865",
    "title": "Simple Contrastive Graph Clustering",
    "abstract": "Contrastive learning has recently attracted plenty of attention in deep graph clustering for its promising performance. However, complicated data augmentations and time-consuming graph convolutional operation undermine the efficiency of these methods. To solve this problem, we propose a Simple Contrastive Graph Clustering (SCGC) algorithm to improve the existing methods from the perspectives of network architecture, data augmentation, and objective function. As to the architecture, our network includes two main parts, i.e., pre-processing and network backbone. A simple low-pass denoising operation conducts neighbor information aggregation as an independent pre-processing, and only two multilayer perceptrons (MLPs) are included as the backbone. For data augmentation, instead of introducing complex operations over graphs, we construct two augmented views of the same vertex by designing parameter un-shared siamese encoders and corrupting the node embeddings directly. Finally, as to the objective function, to further improve the clustering performance, a novel cross-view structural consistency objective function is designed to enhance the discriminative capability of the learned network. Extensive experimental results on seven benchmark datasets validate our proposed algorithm's effectiveness and superiority. Significantly, our algorithm outperforms the recent contrastive deep clustering competitors with at least seven times speedup on average. ",
    "url": "https://arxiv.org/abs/2205.07865",
    "authors": [
      "Yue Liu",
      "Xihong Yang",
      "Sihang Zhou",
      "Xinwang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.07868",
    "title": "Minimal Neural Network Models for Permutation Invariant Agents",
    "abstract": "Organisms in nature have evolved to exhibit flexibility in face of changes to the environment and/or to themselves. Artificial neural networks (ANNs) have proven useful for controlling of artificial agents acting in environments. However, most ANN models used for reinforcement learning-type tasks have a rigid structure that does not allow for varying input sizes. Further, they fail catastrophically if inputs are presented in an ordering unseen during optimization. We find that these two ANN inflexibilities can be mitigated and their solutions are simple and highly related. For permutation invariance, no optimized parameters can be tied to a specific index of the input elements. For size invariance, inputs must be projected onto a common space that does not grow with the number of projections. Based on these restrictions, we construct a conceptually simple model that exhibit flexibility most ANNs lack. We demonstrate the model's properties on multiple control problems, and show that it can cope with even very rapid permutations of input indices, as well as changes in input size. Ablation studies show that is possible to achieve these properties with simple feedforward structures, but that it is much easier to optimize recurrent structures. ",
    "url": "https://arxiv.org/abs/2205.07868",
    "authors": [
      "Joachim Winther Pedersen",
      "Sebastian Risi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.07870",
    "title": "Unsupervised Driving Behavior Analysis using Representation Learning and  Exploiting Group-based Training",
    "abstract": "Driving behavior monitoring plays a crucial role in managing road safety and decreasing the risk of traffic accidents. Driving behavior is affected by multiple factors like vehicle characteristics, types of roads, traffic, but, most importantly, the pattern of driving of individuals. Current work performs a robust driving pattern analysis by capturing variations in driving patterns. It forms consistent groups by learning compressed representation of time series (Auto Encoded Compact Sequence) using a multi-layer seq-2-seq autoencoder and exploiting hierarchical clustering along with recommending the choice of best distance measure. Consistent groups aid in identifying variations in driving patterns of individuals captured in the dataset. These groups are generated for both train and hidden test data. The consistent groups formed using train data, are exploited for training multiple instances of the classifier. Obtained choice of best distance measure is used to select the best train-test pair of consistent groups. We have experimented on the publicly available UAH-DriveSet dataset considering the signals captured from IMU sensors (accelerometer and gyroscope) for classifying driving behavior. We observe proposed method, significantly outperforms the benchmark performance. ",
    "url": "https://arxiv.org/abs/2205.07870",
    "authors": [
      "Soma Bandyopadhyay",
      "Anish Datta",
      "Shruti Sachan",
      "Arpan Pal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.07877",
    "title": "A Comprehensive Survey on Model Quantization for Deep Neural Networks",
    "abstract": "Recent advances in machine learning by deep neural networks are significant. But using these networks has been accompanied by a huge number of parameters for storage and computations that leads to an increase in the hardware cost and posing challenges. Therefore, compression approaches have been proposed to design efficient accelerators. One important approach for deep neural network compression is quantization that full-precision values are stored in low bit-width. In this way, in addition to memory saving, the operations will be replaced by simple ones with low cost. Many methods are suggested for DNNs Quantization in recent years, because of flexibility and influence in designing efficient hardware. Therefore, an integrated report is essential for better understanding, analysis, and comparison. In this paper, we provide a comprehensive survey. We describe the quantization concepts and categorize the methods from different perspectives. We discuss using the scale factor to match the quantization levels with the distribution of the full-precision values and describe the clustering-based methods. For the first time, we review the training of a quantized deep neural network and using Straight-Through Estimator comprehensively. Also, we describe the simplicity of operations in quantized deep convolutional neural networks and explain the sensitivity of the different layers in quantization. Finally, we discuss the evaluation of the quantization methods and compare the accuracy of previous methods with various bit-width for weights and activations on CIFAR-10 and the large-scale dataset, ImageNet. ",
    "url": "https://arxiv.org/abs/2205.07877",
    "authors": [
      "Babak Rokh",
      "Ali Azarpeyvand",
      "Alireza Khanteymoori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.07886",
    "title": "An Empirical Investigation of Representation Learning for Imitation",
    "abstract": "Imitation learning often needs a large demonstration set in order to handle the full range of situations that an agent might find itself in during deployment. However, collecting expert demonstrations can be expensive. Recent work in vision, reinforcement learning, and NLP has shown that auxiliary representation learning objectives can reduce the need for large amounts of expensive, task-specific data. Our Empirical Investigation of Representation Learning for Imitation (EIRLI) investigates whether similar benefits apply to imitation learning. We propose a modular framework for constructing representation learning algorithms, then use our framework to evaluate the utility of representation learning for imitation across several environment suites. In the settings we evaluate, we find that existing algorithms for image-based representation learning provide limited value relative to a well-tuned baseline with image augmentations. To explain this result, we investigate differences between imitation learning and other settings where representation learning has provided significant benefit, such as image classification. Finally, we release a well-documented codebase which both replicates our findings and provides a modular framework for creating new representation learning algorithms out of reusable components. ",
    "url": "https://arxiv.org/abs/2205.07886",
    "authors": [
      "Xin Chen",
      "Sam Toyer",
      "Cody Wild",
      "Scott Emmons",
      "Ian Fischer",
      "Kuang-Huei Lee",
      "Neel Alex",
      "Steven H Wang",
      "Ping Luo",
      "Stuart Russell",
      "Pieter Abbeel",
      "Rohin Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.07890",
    "title": "On the Difficulty of Defending Self-Supervised Learning against Model  Extraction",
    "abstract": "Self-Supervised Learning (SSL) is an increasingly popular ML paradigm that trains models to transform complex inputs into representations without relying on explicit labels. These representations encode similarity structures that enable efficient learning of multiple downstream tasks. Recently, ML-as-a-Service providers have commenced offering trained SSL models over inference APIs, which transform user inputs into useful representations for a fee. However, the high cost involved to train these models and their exposure over APIs both make black-box extraction a realistic security threat. We thus explore model stealing attacks against SSL. Unlike traditional model extraction on classifiers that output labels, the victim models here output representations; these representations are of significantly higher dimensionality compared to the low-dimensional prediction scores output by classifiers. We construct several novel attacks and find that approaches that train directly on a victim's stolen representations are query efficient and enable high accuracy for downstream models. We then show that existing defenses against model extraction are inadequate and not easily retrofitted to the specificities of SSL. ",
    "url": "https://arxiv.org/abs/2205.07890",
    "authors": [
      "Adam Dziedzic",
      "Nikita Dhawan",
      "Muhammad Ahmad Kaleem",
      "Jonas Guan",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.07953",
    "title": "Application of multilayer perceptron with data augmentation in nuclear  physics",
    "abstract": "Neural networks have become popular in many fields of science since they serve as reliable and powerful tools. Application of the neural networks to the nuclear physics studies has also become popular in recent years because of their success in the prediction of nuclear properties. In this work, we study the effect of the data augmentation on the predictive power of the neural network models. Even though there are various data augmentation techniques used for classification tasks in the literature, this area is still very limited for regression problems. As predicting the binding energies is statistically defined as a regression problem, in addition to using data augmentation for nuclear physics, this study contributes to this field for regression in general. Using the experimental uncertainties for data augmentation, the size of training data set is artificially boosted and the changes in the root-mean-square error between the model predictions on test set and the experimental data are investigated. As far as we know, this is the first time that data augmentation techniques have been implemented for nuclear physics research. Our results show that the data augmentation decreases the prediction errors, stabilizes the model and prevents overfitting. The extrapolation capabilities of the MLP models with different depths are also tested for newly measured nuclei in AME2020 mass table. ",
    "url": "https://arxiv.org/abs/2205.07953",
    "authors": [
      "H\u00fcseyin Bahtiyar",
      "Derya Soydaner",
      "Esra Y\u00fcksel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Nuclear Theory (nucl-th)"
    ]
  },
  {
    "id": "arXiv:2205.07965",
    "title": "Flexible and curtailable resource activation in three-phase unbalanced  distribution networks",
    "abstract": "The need for flexibility and curtailable resources is crucial for ensuring the healthy operation of future distribution networks (DN). In this work, we propose a network-state driven framework that distribution system operators (DSOs) can utilize for activating flexible and curtailable resources for alleviating network voltage and thermal issues, while accounting for network voltage and current imbalances. This approach assumes the availability of dynamic network state information and uses nodal sensitivities for calculating a flexibility activation signal (FAS). The signal design is motivated by volt-Var and volt-watt inverter control, and thus bounded. The FAS also considers network voltage and current imbalances and incentivizes activation of active and reactive power flexibilities for reducing imbalance in addition to mitigating voltage and thermal imbalances in a three-phase unbalanced distribution network. The FAS design resembles optimal power flow duals, often used as locational marginal prices. The gains associated with the imbalance component of the objective function of three-phase unbalanced resource activation (TPU-RA) is performed using Pareto optimality. A numerical case study is presented showing the efficacy of the proposed framework in avoiding network issues while reducing voltage unbalance factor by more than 80\\%. Further, DN's flexibility needs are quantified for location and time of day. ",
    "url": "https://arxiv.org/abs/2205.07965",
    "authors": [
      "Md Umar Hashmi",
      "Arpan Koirala",
      "Hakan Ergun",
      "Dirk Van Hertem"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2205.07993",
    "title": "Generalizable Task Planning through Representation Pretraining",
    "abstract": "The ability to plan for multi-step manipulation tasks in unseen situations is crucial for future home robots. But collecting sufficient experience data for end-to-end learning is often infeasible in the real world, as deploying robots in many environments can be prohibitively expensive. On the other hand, large-scale scene understanding datasets contain diverse and rich semantic and geometric information. But how to leverage such information for manipulation remains an open problem. In this paper, we propose a learning-to-plan method that can generalize to new object instances by leveraging object-level representations extracted from a synthetic scene understanding dataset. We evaluate our method with a suite of challenging multi-step manipulation tasks inspired by household activities and show that our model achieves measurably better success rate than state-of-the-art end-to-end approaches. Additional information can be found at https://sites.google.com/view/gentp ",
    "url": "https://arxiv.org/abs/2205.07993",
    "authors": [
      "Chen Wang",
      "Danfei Xu",
      "Li Fei-Fei"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.08002",
    "title": "Lost in Compression: the Impact of Lossy Image Compression on Variable  Size Object Detection within Infrared Imagery",
    "abstract": "Lossy image compression strategies allow for more efficient storage and transmission of data by encoding data to a reduced form. This is essential enable training with larger datasets on less storage-equipped environments. However, such compression can cause severe decline in performance of deep Convolution Neural Network (CNN) architectures even when mild compression is applied and the resulting compressed imagery is visually identical. In this work, we apply the lossy JPEG compression method with six discrete levels of increasing compression {95, 75, 50, 15, 10, 5} to infrared band (thermal) imagery. Our study quantitatively evaluates the affect that increasing levels of lossy compression has upon the performance of characteristically diverse object detection architectures (Cascade-RCNN, FSAF and Deformable DETR) with respect to varying sizes of objects present in the dataset. When training and evaluating on uncompressed data as a baseline, we achieve maximal mean Average Precision (mAP) of 0.823 with Cascade R-CNN across the FLIR dataset, outperforming prior work. The impact of the lossy compression is more extreme at higher compression levels (15, 10, 5) across all three CNN architectures. However, re-training models on lossy compressed imagery notably ameliorated performances for all three CNN models with an average increment of ~76% (at higher compression level 5). Additionally, we demonstrate the relative sensitivity of differing object areas {tiny, small, medium, large} with respect to the compression level. We show that tiny and small objects are more sensitive to compression than medium and large objects. Overall, Cascade R-CNN attains the maximal mAP across most of the object area categories. ",
    "url": "https://arxiv.org/abs/2205.08002",
    "authors": [
      "Neelanjan Bhowmik",
      "Jack W. Barker",
      "Yona Falinie A. Gaus",
      "Toby P. Breckon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.08012",
    "title": "CascadER: Cross-Modal Cascading for Knowledge Graph Link Prediction",
    "abstract": "Knowledge graph (KG) link prediction is a fundamental task in artificial intelligence, with applications in natural language processing, information retrieval, and biomedicine. Recently, promising results have been achieved by leveraging cross-modal information in KGs, using ensembles that combine knowledge graph embeddings (KGEs) and contextual language models (LMs). However, existing ensembles are either (1) not consistently effective in terms of ranking accuracy gains or (2) impractically inefficient on larger datasets due to the combinatorial explosion problem of pairwise ranking with deep language models. In this paper, we propose a novel tiered ranking architecture CascadER to maintain the ranking accuracy of full ensembling while improving efficiency considerably. CascadER uses LMs to rerank the outputs of more efficient base KGEs, relying on an adaptive subset selection scheme aimed at invoking the LMs minimally while maximizing accuracy gain over the KGE. Extensive experiments demonstrate that CascadER improves MRR by up to 9 points over KGE baselines, setting new state-of-the-art performance on four benchmarks while improving efficiency by one or more orders of magnitude over competitive cross-modal baselines. Our empirical analyses reveal that diversity of models across modalities and preservation of individual models' confidence signals help explain the effectiveness of CascadER, and suggest promising directions for cross-modal cascaded architectures. Code and pretrained models are available at https://github.com/tsafavi/cascader. ",
    "url": "https://arxiv.org/abs/2205.08012",
    "authors": [
      "Tara Safavi",
      "Doug Downey",
      "Tom Hope"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.08025",
    "title": "The Hamiltonian Path Graph is Connected for Simple $s,t$ Paths in  Rectangular Grid Graphs",
    "abstract": "A \\emph{simple} $s,t$ path $P$ in a rectangular grid graph $\\mathbb{G}$ is a Hamiltonian path from the top-left corner $s$ to the bottom-right corner $t$ such that each \\emph{internal} subpath of $P$ with both endpoints $a$ and $b$ on the boundary of $\\mathbb{G}$ has the minimum number of bends needed to travel from $a$ to $b$ (i.e., $0$, $1$, or $2$ bends, depending on whether $a$ and $b$ are on opposite, adjacent, or the same side of the bounding rectangle). Here, we show that $P$ can be reconfigured to any other simple $s,t$ path of $\\mathbb{G}$ by \\emph{switching $2\\times 2$ squares}, where at most ${5}|\\mathbb{G}|/{4}$ such operations are required. Furthermore, each \\emph{square-switch} is done in $O(1)$ time and keeps the resulting path in the same family of simple $s,t$ paths. Our reconfiguration result proves that the \\emph{Hamiltonian path graph} $\\cal{G}$ for simple $s,t$ paths is connected and has diameter at most ${5}|\\mathbb{G}|/{4}$ which is asymptotically tight. ",
    "url": "https://arxiv.org/abs/2205.08025",
    "authors": [
      "Rahnuma Islam Nishat",
      "Venkatesh Srinivasan",
      "Sue Whitesides"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2205.08028",
    "title": "Browser-based Hyperbolic Visualization of Graphs",
    "abstract": "Hyperbolic geometry offers a natural focus + context for data visualization and has been shown to underlie real-world complex networks. However, current hyperbolic network visualization approaches are limited to special types of networks and do not scale to large datasets. With this in mind, we designed, implemented, and analyzed three methods for hyperbolic visualization of networks in the browser based on inverse projections, generalized force-directed algorithms, and hyperbolic multi-dimensional scaling (H-MDS). A comparison with Euclidean MDS shows that H-MDS produces embeddings with lower distortion for several types of networks. All three methods can handle node-link representations and are available in fully functional web-based systems. ",
    "url": "https://arxiv.org/abs/2205.08028",
    "authors": [
      "Jacob Miller",
      "Stephen Kobourov",
      "Vahan Huroyan"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.08032",
    "title": "On Algebraic Constructions of Neural Networks with Small Weights",
    "abstract": "Neural gates compute functions based on weighted sums of the input variables. The expressive power of neural gates (number of distinct functions it can compute) depends on the weight sizes and, in general, large weights (exponential in the number of inputs) are required. Studying the trade-offs among the weight sizes, circuit size and depth is a well-studied topic both in circuit complexity theory and the practice of neural computation. We propose a new approach for studying these complexity trade-offs by considering a related algebraic framework. Specifically, given a single linear equation with arbitrary coefficients, we would like to express it using a system of linear equations with smaller (even constant) coefficients. The techniques we developed are based on Siegel's Lemma for the bounds, anti-concentration inequalities for the existential results and extensions of Sylvester-type Hadamard matrices for the constructions. We explicitly construct a constant weight, optimal size matrix to compute the EQUALITY function (checking if two integers expressed in binary are equal). Computing EQUALITY with a single linear equation requires exponentially large weights. In addition, we prove the existence of the best-known weight size (linear) matrices to compute the COMPARISON function (comparing between two integers expressed in binary). In the context of the circuit complexity theory, our results improve the upper bounds on the weight sizes for the best-known circuit sizes for EQUALITY and COMPARISON. ",
    "url": "https://arxiv.org/abs/2205.08032",
    "authors": [
      "Kordag Mehmet Kilic",
      "Jin Sima",
      "Jehoshua Bruck"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.08033",
    "title": "Using Embeddings for Causal Estimation of Peer Influence in Social  Networks",
    "abstract": "We address the problem of using observational data to estimate peer contagion effects, the influence of treatments applied to individuals in a network on the outcomes of their neighbors. A main challenge to such estimation is that homophily - the tendency of connected units to share similar latent traits - acts as an unobserved confounder for contagion effects. Informally, it's hard to tell whether your friends have similar outcomes because they were influenced by your treatment, or whether it's due to some common trait that caused you to be friends in the first place. Because these common causes are not usually directly observed, they cannot be simply adjusted for. We describe an approach to perform the required adjustment using node embeddings learned from the network itself. The main aim is to perform this adjustment nonparametrically, without functional form assumptions on either the process that generated the network or the treatment assignment and outcome processes. The key contributions are to nonparametrically formalize the causal effect in a way that accounts for homophily, and to show how embedding methods can be used to identify and estimate this effect. Code is available at https://github.com/IrinaCristali/Peer-Contagion-on-Networks. ",
    "url": "https://arxiv.org/abs/2205.08033",
    "authors": [
      "Irina Cristali",
      "Victor Veitch"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.08041",
    "title": "Detection and Physical Interaction with Deformable Linear Objects",
    "abstract": "Deformable linear objects (e.g., cables, ropes, and threads) commonly appear in our everyday lives. However, perception of these objects and the study of physical interaction with them is still a growing area. There have already been successful methods to model and track deformable linear objects. However, the number of methods that can automatically extract the initial conditions in non-trivial situations for these methods has been limited, and they have been introduced to the community only recently. On the other hand, while physical interaction with these objects has been done with ground manipulators, there have not been any studies on physical interaction and manipulation of the deformable linear object with aerial robots. This workshop describes our recent work on detecting deformable linear objects, which uses the segmentation output of the existing methods to provide the initialization required by the tracking methods automatically. It works with crossings and can fill the gaps and occlusions in the segmentation and output the model desirable for physical interaction and simulation. Then we present our work on using the method for tasks such as routing and manipulation with the ground and aerial robots. We discuss our feasibility analysis on extending the physical interaction with these objects to aerial manipulation applications. ",
    "url": "https://arxiv.org/abs/2205.08041",
    "authors": [
      "Azarakhsh Keipour",
      "Mohammadreza Mousaei",
      "Maryam Bandari",
      "Stefan Schaal",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.08043",
    "title": "Explainable and Optimally Configured Artificial Neural Networks for  Attack Detection in Smart Homes",
    "abstract": "In recent years cybersecurity has become a major concern in adaptation of smart applications. Specially, in smart homes where a large number of IoT devices are used having a secure and trusted mechanisms can provide peace of mind for users. Accurate detection of cyber attacks is crucial, however precise identification of the type of attacks plays a huge role if devising the countermeasure for protecting the system. Artificial Neural Networks (ANN) have provided promising results for detecting any security attacks for smart applications. However, due to complex nature of the model used for this technique it is not easy for normal users to trust ANN based security solutions. Also, selection of right hyperparameters for ANN architecture plays a crucial role in the accurate detection of security attacks, especially when it come to identifying the subcategories of attacks. In this paper, we propose a model that considers both the issues of explainability of ANN model and the hyperparameter selection for this approach to be easily trusted and adapted by users of smart home applications. Also, our approach considers a subset of the dataset for optimal selection of hyperparamters to reduce the overhead of the process of ANN architecture design. Distinctively this paper focuses on configuration, performance and evaluation of ANN architecture for identification of five categorical attacks and nine subcategorical attacks. Using a very recent IoT dataset our approach showed high performance for intrusion detection with 99.9%, 99.7%, and 97.7% accuracy for Binary, Category, and Subcategory level classification of attacks. ",
    "url": "https://arxiv.org/abs/2205.08043",
    "authors": [
      "Shaleeza Sohail",
      "Zongwen Fan",
      "Xin Gu",
      "Fariza Sabrina"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.08048",
    "title": "A Short Introduction to the Koopman Representation of Dynamical Systems",
    "abstract": "The Koopman representation is an infinite dimensional linear representation of linear or nonlinear dynamical systems. It represents the dynamics of output maps (aka observables), which are functions on the state space whose evaluation is interpreted as an output. Conceptually simple derivations and commentary on the Koopman representation are given. We emphasize an important duality between initial conditions and output maps of the original system, and those of the Koopman representation. This duality is an important consideration when this representation is used in data-driven applications such as the Dynamic Mode Decomposition (DMD) and its variants. The adjoint relation between the Koopman representation and the transfer operator of mass transport is also shown. ",
    "url": "https://arxiv.org/abs/2205.08048",
    "authors": [
      "Bassam Bamieh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2205.08067",
    "title": "Robust Perception Architecture Design for Automotive Cyber-Physical  Systems",
    "abstract": "In emerging automotive cyber-physical systems (CPS), accurate environmental perception is critical to achieving safety and performance goals. Enabling robust perception for vehicles requires solving multiple complex problems related to sensor selection/ placement, object detection, and sensor fusion. Current methods address these problems in isolation, which leads to inefficient solutions. We present PASTA, a novel framework for global co-optimization of deep learning and sensing for dependable vehicle perception. Experimental results with the Audi-TT and BMW-Minicooper vehicles show how PASTA can find robust, vehicle-specific perception architecture solutions. ",
    "url": "https://arxiv.org/abs/2205.08067",
    "authors": [
      "Joydeep Dey",
      "Sudeep Pasricha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.08071",
    "title": "How Not to Handle Keys: Timing Attacks on FIDO Authenticator Privacy",
    "abstract": "This paper presents a timing attack on the FIDO2 (Fast IDentity Online) authentication protocol that allows attackers to link user accounts stored in vulnerable authenticators, a serious privacy concern. FIDO2 is a new standard specified by the FIDO industry alliance for secure token online authentication. It complements the W3C WebAuthn specification by providing means to use a USB token or other authenticator as a second factor during the authentication process. From a cryptographic perspective, the protocol is a simple challenge-response where the elliptic curve digital signature algorithm is used to sign challenges. To protect the privacy of the user the token uses unique key pairs per service. To accommodate for small memory, tokens use various techniques that make use of a special parameter called a key handle sent by the service to the token. We identify and analyse a vulnerability in the way the processing of key handles is implemented that allows attackers to remotely link user accounts on multiple services. We show that for vulnerable authenticators there is a difference between the time it takes to process a key handle for a different service but correct authenticator, and for a different authenticator but correct service. This difference can be used to perform a timing attack allowing an adversary to link user's accounts across services. We present several real world examples of adversaries that are in a position to execute our attack and can benefit from linking accounts. We found that two of the eight hardware authenticators we tested were vulnerable despite FIDO level 1 certification. This vulnerability cannot be easily mitigated on authenticators because, for security reasons, they usually do not allow firmware updates. In addition, we show that due to the way existing browsers implement the WebAuthn standard, the attack can be executed remotely. ",
    "url": "https://arxiv.org/abs/2205.08071",
    "authors": [
      "Michal Kepkowski",
      "Lucjan Hanzlik",
      "Ian Wood",
      "Mohamed Ali Kaafar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.08075",
    "title": "Collaborative Attention Memory Network for Video Object Segmentation",
    "abstract": "Semi-supervised video object segmentation is a fundamental yet Challenging task in computer vision. Embedding matching based CFBI series networks have achieved promising results by foreground-background integration approach. Despite its superior performance, these works exhibit distinct shortcomings, especially the false predictions caused by little appearance instances in first frame, even they could easily be recognized by previous frame. Moreover, they suffer from object's occlusion and error drifts. In order to overcome the shortcomings , we propose Collaborative Attention Memory Network with an enhanced segmentation head. We introduce a object context scheme that explicitly enhances the object information, which aims at only gathering the pixels that belong to the same category as a given pixel as its context. Additionally, a segmentation head with Feature Pyramid Attention(FPA) module is adopted to perform spatial pyramid attention structure on high-level output. Furthermore, we propose an ensemble network to combine STM network with all these new refined CFBI network. Finally, we evaluated our approach on the 2021 Youtube-VOS challenge where we obtain 6th place with an overall score of 83.5\\%. ",
    "url": "https://arxiv.org/abs/2205.08075",
    "authors": [
      "Zhixing Huang",
      "Junli Zha",
      "Fei Xie",
      "Yuwei Zheng",
      "Yuandong Zhong",
      "Jinpeng Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.08086",
    "title": "EvoRobogami: Co-designing with Humans in Evolutionary Robotics  Experiments",
    "abstract": "We study the effects of injecting human-generated designs into the initial population of an evolutionary robotics experiment, where subsequent population of robots are optimised via a Genetic Algorithm and MAP-Elites. First, human participants interact via a graphical front-end to explore a directly-parameterised legged robot design space and attempt to produce robots via a combination of intuition and trial-and-error that perform well in a range of environments. Environments are generated whose corresponding high-performance robot designs range from intuitive to complex and hard to grasp. Once the human designs have been collected, their impact on the evolutionary process is assessed by replacing a varying number of designs in the initial population with human designs and subsequently running the evolutionary algorithm. Our results suggest that a balance of random and hand-designed initial solutions provides the best performance for the problems considered, and that human designs are most valuable when the problem is intuitive. The influence of human design in an evolutionary algorithm is a highly understudied area, and the insights in this paper may be valuable to the area of AI-based design more generally. ",
    "url": "https://arxiv.org/abs/2205.08086",
    "authors": [
      "Huang Zonghao",
      "Quinn Wu",
      "David Howard",
      "Cynthia Sung"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.08089",
    "title": "Efficient Stereo Depth Estimation for Pseudo LiDAR: A Self-Supervised  Approach Based on Multi-Input ResNet Encoder",
    "abstract": "Perception and localization are essential for autonomous delivery vehicles, mostly estimated from 3D LiDAR sensors due to their precise distance measurement capability. This paper presents a strategy to obtain the real-time pseudo point cloud instead of the laser sensor from the image sensor. We propose an approach to use different depth estimators to obtain pseudo point clouds like LiDAR to obtain better performance. Moreover, the training and validating strategy of the depth estimator has adopted stereo imagery data to estimate more accurate depth estimation as well as point cloud results. Our approach to generating depth maps outperforms on KITTI benchmark while yielding point clouds significantly faster than other approaches. ",
    "url": "https://arxiv.org/abs/2205.08089",
    "authors": [
      "Sabir Hossain",
      "Xianke Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.08093",
    "title": "Narrowing the LOCAL$\\unicode{x2013}$CONGEST Gaps in Sparse Networks via  Expander Decompositions",
    "abstract": "Many combinatorial optimization problems can be approximated within $(1 \\pm \\epsilon)$ factors in $\\text{poly}(\\log n, 1/\\epsilon)$ rounds in the LOCAL model via network decompositions [Ghaffari, Kuhn, and Maus, STOC 2018]. These approaches require sending messages of unlimited size, so they do not extend to the CONGEST model, which restricts the message size to be $O(\\log n)$ bits. In this paper, we develop a generic framework for obtaining $\\text{poly}(\\log n, 1/\\epsilon)$-round $(1\\pm \\epsilon)$-approximation algorithms for many combinatorial optimization problems, including maximum weighted matching, maximum independent set, and correlation clustering, in graphs excluding a fixed minor in the CONGEST model. This class of graphs covers many sparse network classes that have been studied in the literature, including planar graphs, bounded-genus graphs, and bounded-treewidth graphs. Furthermore, we show that our framework can be applied to give an efficient distributed property testing algorithm for an arbitrary minor-closed graph property that is closed under taking disjoint union, significantly generalizing the previous distributed property testing algorithm for planarity in [Levi, Medina, and Ron, PODC 2018 & Distributed Computing 2021]. Our framework uses distributed expander decomposition algorithms [Chang and Saranurak, FOCS 2020] to decompose the graph into clusters of high conductance. We show that any graph excluding a fixed minor admits small edge separators. Using this result, we show the existence of a high-degree vertex in each cluster in an expander decomposition, which allows the entire graph topology of the cluster to be routed to a vertex. Similar to the use of network decompositions in the LOCAL model, the vertex will be able to perform any local computation on the subgraph induced by the cluster and broadcast the result over the cluster. ",
    "url": "https://arxiv.org/abs/2205.08093",
    "authors": [
      "Yi-Jun Chang",
      "Hsin-Hao Su"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.08096",
    "title": "Can Bad Teaching Induce Forgetting? Unlearning in Deep Networks using an  Incompetent Teacher",
    "abstract": "Machine unlearning has become an important field of research due to an increasing focus on addressing the evolving data privacy rules and regulations into the machine learning (ML) applications. It facilitates the request for removal of certain set or class of data from the already trained ML model without retraining from scratch. Recently, several efforts have been made to perform unlearning in an effective and efficient manner. We propose a novel machine unlearning method by exploring the utility of competent and incompetent teachers in a student-teacher framework to induce forgetfulness. The knowledge from the competent and incompetent teachers is selectively transferred to the student to obtain a model that doesn't contain any information about the forget data. We experimentally show that this method is well generalized, fast, and effective. Furthermore, we introduce a zero retrain forgetting (ZRF) metric to evaluate the unlearning method. Unlike the existing unlearning metrics, the ZRF score does not depend on the availability of the expensive retrained model. This makes it useful for analysis of the unlearned model after deployment as well. The experiments are conducted for random subset forgetting and class forgetting on various deep networks and across different application domains. A use case of forgetting information about the patients' medical records is also presented. ",
    "url": "https://arxiv.org/abs/2205.08096",
    "authors": [
      "Vikram S Chundawat",
      "Ayush K Tarun",
      "Murari Mandal",
      "Mohan Kankanhalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.08099",
    "title": "Dimensionality Reduced Training by Pruning and Freezing Parts of a Deep  Neural Network, a Survey",
    "abstract": "State-of-the-art deep learning models have a parameter count that reaches into the billions. Training, storing and transferring such models is energy and time consuming, thus costly. A big part of these costs is caused by training the network. Model compression lowers storage and transfer costs, and can further make training more efficient by decreasing the number of computations in the forward and/or backward pass. Thus, compressing networks also at training time while maintaining a high performance is an important research topic. This work is a survey on methods which reduce the number of trained weights in deep learning models throughout the training. Most of the introduced methods set network parameters to zero which is called pruning. The presented pruning approaches are categorized into pruning at initialization, lottery tickets and dynamic sparse training. Moreover, we discuss methods that freeze parts of a network at its random initialization. By freezing weights, the number of trainable parameters is shrunken which reduces gradient computations and the dimensionality of the model's optimization space. In this survey we first propose dimensionality reduced training as an underlying mathematical model that covers pruning and freezing during training. Afterwards, we present and discuss different dimensionality reduced training methods. ",
    "url": "https://arxiv.org/abs/2205.08099",
    "authors": [
      "Paul Wimmer",
      "Jens Mehnert",
      "Alexandru Paul Condurache"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.08115",
    "title": "Fast and Provably Convergent Algorithms for Gromov-Wasserstein in Graph  Learning",
    "abstract": "In this paper, we study the design and analysis of a class of efficient algorithms for computing the Gromov-Wasserstein (GW) distance tailored to large-scale graph learning tasks. Armed with the Luo-Tseng error bound condition~\\cite{luo1992error}, two proposed algorithms, called Bregman Alternating Projected Gradient (BAPG) and hybrid Bregman Proximal Gradient (hBPG) are proven to be (linearly) convergent. Upon task-specific properties, our analysis further provides novel theoretical insights to guide how to select the best fit method. As a result, we are able to provide comprehensive experiments to validate the effectiveness of our methods on a host of tasks, including graph alignment, graph partition, and shape matching. In terms of both wall-clock time and modeling performance, the proposed methods achieve state-of-the-art results. ",
    "url": "https://arxiv.org/abs/2205.08115",
    "authors": [
      "Jiajin Li",
      "Jianheng Tang",
      "Lemin Kong",
      "Huikang Liu",
      "Jia Li",
      "Anthony Man-Cho So",
      "Jose Blanchet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.08116",
    "title": "On the Use of Refactoring in Security Vulnerability Fixes: An  Exploratory Study on Maven Libraries",
    "abstract": "Third-party library dependencies are commonplace in today's software development. With the growing threat of security vulnerabilities, applying security fixes in a timely manner is important to protect software systems. As such, the community developed a list of software and hardware weakness known as Common Weakness Enumeration (CWE) to assess vulnerabilities. Prior work has revealed that maintenance activities such as refactoring code potentially correlate with security-related aspects in the source code. In this work, we explore the relationship between refactoring and security by analyzing refactoring actions performed jointly with vulnerability fixes in practice. We conducted a case study to analyze 143 maven libraries in which 351 known vulnerabilities had been detected and fixed. Surprisingly, our exploratory results show that developers incorporate refactoring operations in their fixes, with 31.9% (112 out of 351) of the vulnerabilities paired with refactoring actions. We envision this short paper to open up potential new directions to motivate automated tool support, allowing developers to deliver fixes faster, while maintaining their code. ",
    "url": "https://arxiv.org/abs/2205.08116",
    "authors": [
      "Ayano Ikegami",
      "Raula Gaikovina Kula",
      "Bodin Chinthanet",
      "Vittunyuta Maeprasart",
      "Ali Ouni",
      "Takashi Ishio",
      "Kenichi Matsumoto"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.08119",
    "title": "ShiftAddNAS: Hardware-Inspired Search for More Accurate and Efficient  Neural Networks",
    "abstract": "Neural networks (NNs) with intensive multiplications (e.g., convolutions and transformers) are capable yet power hungry, impeding their more extensive deployment into resource-constrained devices. As such, multiplication-free networks, which follow a common practice in energy-efficient hardware implementation to parameterize NNs with more efficient operators (e.g., bitwise shifts and additions), have gained growing attention. However, multiplication-free networks usually under-perform their vanilla counterparts in terms of the achieved accuracy. To this end, this work advocates hybrid NNs that consist of both powerful yet costly multiplications and efficient yet less powerful operators for marrying the best of both worlds, and proposes ShiftAddNAS, which can automatically search for more accurate and more efficient NNs. Our ShiftAddNAS highlights two enablers. Specifically, it integrates (1) the first hybrid search space that incorporates both multiplication-based and multiplication-free operators for facilitating the development of both accurate and efficient hybrid NNs; and (2) a novel weight sharing strategy that enables effective weight sharing among different operators that follow heterogeneous distributions (e.g., Gaussian for convolutions vs. Laplacian for add operators) and simultaneously leads to a largely reduced supernet size and much better searched networks. Extensive experiments and ablation studies on various models, datasets, and tasks consistently validate the efficacy of ShiftAddNAS, e.g., achieving up to a +7.7% higher accuracy or a +4.9 better BLEU score compared to state-of-the-art NN, while leading to up to 93% or 69% energy and latency savings, respectively. Codes and pretrained models are available at https://github.com/RICE-EIC/ShiftAddNAS. ",
    "url": "https://arxiv.org/abs/2205.08119",
    "authors": [
      "Haoran You",
      "Baopu Li",
      "Huihong Shi",
      "Yonggan Fu",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.08147",
    "title": "Pairwise Comparison Network for Remote Sensing Scene Classification",
    "abstract": "Remote sensing scene classification aims to assign a specific semantic label to a remote sensing image. Recently, convolutional neural networks have greatly improved the performance of remote sensing scene classification. However, some confused images may be easily recognized as the incorrect category, which generally degrade the performance. The differences between image pairs can be used to distinguish image categories. This paper proposed a pairwise comparison network, which contains two main steps: pairwise selection and pairwise representation. The proposed network first selects similar image pairs, and then represents the image pairs with pairwise representations. The self-representation is introduced to highlight the informative parts of each image itself, while the mutual-representation is proposed to capture the subtle differences between image pairs. Comprehensive experimental results on two challenging datasets (AID, NWPU-RESISC45) demonstrate the effectiveness of the proposed network. The code are provided in https://github.com/spectralpublic/PCNet.git. ",
    "url": "https://arxiv.org/abs/2205.08147",
    "authors": [
      "Zhang Yue",
      "Zheng Xiangtao",
      "Lu Xiaoqiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.08152",
    "title": "Dual-mode robust MPC for the tracking control of non-holonomoic mobile  robots",
    "abstract": "In this paper, a novel dual-mode robust model predictive control (MPC) approach is proposed for solving the tracking control problem of non-holonomoic mobile robots with additive bounded disturbance. To reduce the negative effect of disturbance and drive the state of real system closer to the one of nominal system , a robust reference signal is introduced into the cost function of MPC. In order to reduced the computation burden caused by online optimization of MPC and further improve the tracking accuracy, a dual-mode control strucuture consisting of the robust MPC and the local nonlinear robust control is developed, in which the local nonlinear robust control law is applied within a specified terminal region. Finally, simulation results on the non-holonomic mobile robot are presented to show the validity of the proposed control approach. ",
    "url": "https://arxiv.org/abs/2205.08152",
    "authors": [
      "Huan Meng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.08157",
    "title": "Uncertainty-based Network for Few-shot Image Classification",
    "abstract": "The transductive inference is an effective technique in the few-shot learning task, where query sets update prototypes to improve themselves. However, these methods optimize the model by considering only the classification scores of the query instances as confidence while ignoring the uncertainty of these classification scores. In this paper, we propose a novel method called Uncertainty-Based Network, which models the uncertainty of classification results with the help of mutual information. Specifically, we first data augment and classify the query instance and calculate the mutual information of these classification scores. Then, mutual information is used as uncertainty to assign weights to classification scores, and the iterative update strategy based on classification scores and uncertainties assigns the optimal weights to query instances in prototype optimization. Extensive results on four benchmarks show that Uncertainty-Based Network achieves comparable performance in classification accuracy compared to state-of-the-art method. ",
    "url": "https://arxiv.org/abs/2205.08157",
    "authors": [
      "Minglei Yuan",
      "Qian Xu",
      "Chunhao Cai",
      "Yin-Dong Zheng",
      "Tao Wang",
      "Tong Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.08159",
    "title": "SEMI-FND: Stacked Ensemble Based Multimodal Inference For Faster Fake  News Detection",
    "abstract": "Fake News Detection (FND) is an essential field in natural language processing that aims to identify and check the truthfulness of major claims in a news article to decide the news veracity. FND finds its uses in preventing social, political and national damage caused due to misrepresentation of facts which may harm a certain section of society. Further, with the explosive rise in fake news dissemination over social media, including images and text, it has become imperative to identify fake news faster and more accurately. To solve this problem, this work investigates a novel multimodal stacked ensemble-based approach (SEMIFND) to fake news detection. Focus is also kept on ensuring faster performance with fewer parameters. Moreover, to improve multimodal performance, a deep unimodal analysis is done on the image modality to identify NasNet Mobile as the most appropriate model for the task. For text, an ensemble of BERT and ELECTRA is used. The approach was evaluated on two datasets: Twitter MediaEval and Weibo Corpus. The suggested framework offered accuracies of 85.80% and 86.83% on the Twitter and Weibo datasets respectively. These reported metrics are found to be superior when compared to similar recent works. Further, we also report a reduction in the number of parameters used in training when compared to recent relevant works. SEMI-FND offers an overall parameter reduction of at least 20% with unimodal parametric reduction on text being 60%. Therefore, based on the investigations presented, it is concluded that the application of a stacked ensembling significantly improves FND over other approaches while also improving speed. ",
    "url": "https://arxiv.org/abs/2205.08159",
    "authors": [
      "Prabhav Singh",
      "Ridam Srivastava",
      "K.P.S. Rana",
      "Vineet Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.08178",
    "title": "Active learning of causal probability trees",
    "abstract": "The past two decades have seen a growing interest in combining causal information, commonly represented using causal graphs, with machine learning models. Probability trees provide a simple yet powerful alternative representation of causal information. They enable both computation of intervention and counterfactuals, and are strictly more general, since they allow context-dependent causal dependencies. Here we present a Bayesian method for learning probability trees from a combination of interventional and observational data. The method quantifies the expected information gain from an intervention, and selects the interventions with the largest gain. We demonstrate the efficiency of the method on simulated and real data. An effective method for learning probability trees on a limited interventional budget will greatly expand their applicability. ",
    "url": "https://arxiv.org/abs/2205.08178",
    "authors": [
      "Tue Herlau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2205.08180",
    "title": "SAMU-XLSR: Semantically-Aligned Multimodal Utterance-level Cross-Lingual  Speech Representation",
    "abstract": "We propose the SAMU-XLSR: Semantically-Aligned Multimodal Utterance-level Cross-Lingual Speech Representation learning framework. Unlike previous works on speech representation learning, which learns multilingual contextual speech embedding at the resolution of an acoustic frame (10-20ms), this work focuses on learning multimodal (speech-text) multilingual speech embedding at the resolution of a sentence (5-10s) such that the embedding vector space is semantically aligned across different languages. We combine state-of-the-art multilingual acoustic frame-level speech representation learning model XLS-R with the Language Agnostic BERT Sentence Embedding (LaBSE) model to create an utterance-level multimodal multilingual speech encoder SAMU-XLSR. Although we train SAMU-XLSR with only multilingual transcribed speech data, cross-lingual speech-text and speech-speech associations emerge in its learned representation space. To substantiate our claims, we use SAMU-XLSR speech encoder in combination with a pre-trained LaBSE text sentence encoder for cross-lingual speech-to-text translation retrieval, and SAMU-XLSR alone for cross-lingual speech-to-speech translation retrieval. We highlight these applications by performing several cross-lingual text and speech translation retrieval tasks across several datasets. ",
    "url": "https://arxiv.org/abs/2205.08180",
    "authors": [
      "Sameer Khurana",
      "Antoine Laurent",
      "James Glass"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.08199",
    "title": "Sharp asymptotics on the compression of two-layer neural networks",
    "abstract": "In this paper, we study the compression of a target two-layer neural network with N nodes into a compressed network with M < N nodes. More precisely, we consider the setting in which the weights of the target network are i.i.d. sub-Gaussian, and we minimize the population L2 loss between the outputs of the target and of the compressed network, under the assumption of Gaussian inputs. By using tools from high-dimensional probability, we show that this non-convex problem can be simplified when the target network is sufficiently over-parameterized, and provide the error rate of this approximation as a function of the input dimension and N . For a ReLU activation function, we conjecture that the optimum of the simplified optimization problem is achieved by taking weights on the Equiangular Tight Frame (ETF), while the scaling of the weights and the orientation of the ETF depend on the parameters of the target network. Numerical evidence is provided to support this conjecture. ",
    "url": "https://arxiv.org/abs/2205.08199",
    "authors": [
      "Mohammad Hossein Amani",
      "Simone Bombari",
      "Marco Mondelli",
      "Rattana Pukdee",
      "Stefano Rini"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.08240",
    "title": "Scheduling in Wireless Networks using Whittle Index Theory",
    "abstract": "We consider the problem of scheduling packet transmissions in a wireless network of users while minimizing the energy consumed and the transmission delay. A challenge is that transmissions of users that are close to each other mutually interfere, while users that are far apart can transmit simultaneously without much interference. Each user has a queue of packets that are transmitted on a single channel and mutually non interfering users reuse the spectrum. Using the theory of Whittle index for cost minimizing restless bandits, we design four index-based policies and compare their performance with that of the well-known policies: Slotted ALOHA, maximum weight scheduling, quadratic Lyapunov drift, Cella and Cesa Bianchi algorithm, and two Whittle index based policies from a recently published paper. We make the code used to perform our simulations publicly available, so that it can be used for future work by the research community at large. ",
    "url": "https://arxiv.org/abs/2205.08240",
    "authors": [
      "Karthik GVB",
      "Vivek S. Borkar",
      "Gaurav S. Kasbekar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.08247",
    "title": "Monotonicity Regularization: Improved Penalties and Novel Applications  to Disentangled Representation Learning and Robust Classification",
    "abstract": "We study settings where gradient penalties are used alongside risk minimization with the goal of obtaining predictors satisfying different notions of monotonicity. Specifically, we present two sets of contributions. In the first part of the paper, we show that different choices of penalties define the regions of the input space where the property is observed. As such, previous methods result in models that are monotonic only in a small volume of the input space. We thus propose an approach that uses mixtures of training instances and random points to populate the space and enforce the penalty in a much larger region. As a second set of contributions, we introduce regularization strategies that enforce other notions of monotonicity in different settings. In this case, we consider applications, such as image classification and generative modeling, where monotonicity is not a hard constraint but can help improve some aspects of the model. Namely, we show that inducing monotonicity can be beneficial in applications such as: (1) allowing for controllable data generation, (2) defining strategies to detect anomalous data, and (3) generating explanations for predictions. Our proposed approaches do not introduce relevant computational overhead while leading to efficient procedures that provide extra benefits over baseline models. ",
    "url": "https://arxiv.org/abs/2205.08247",
    "authors": [
      "Joao Monteiro",
      "Mohamed Osama Ahmed",
      "Hossein Hajimirsadeghi",
      "Greg Mori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.08249",
    "title": "Learnable Optimal Sequential Grouping for Video Scene Detection",
    "abstract": "Video scene detection is the task of dividing videos into temporal semantic chapters. This is an important preliminary step before attempting to analyze heterogeneous video content. Recently, Optimal Sequential Grouping (OSG) was proposed as a powerful unsupervised solution to solve a formulation of the video scene detection problem. In this work, we extend the capabilities of OSG to the learning regime. By giving the capability to both learn from examples and leverage a robust optimization formulation, we can boost performance and enhance the versatility of the technology. We present a comprehensive analysis of incorporating OSG into deep learning neural networks under various configurations. These configurations include learning an embedding in a straight-forward manner, a tailored loss designed to guide the solution of OSG, and an integrated model where the learning is performed through the OSG pipeline. With thorough evaluation and analysis, we assess the benefits and behavior of the various configurations, and show that our learnable OSG approach exhibits desirable behavior and enhanced performance compared to the state of the art. ",
    "url": "https://arxiv.org/abs/2205.08249",
    "authors": [
      "Daniel Rotman",
      "Yevgeny Yaroker",
      "Elad Amrani",
      "Udi Barzelay",
      "Rami Ben-Ari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.08252",
    "title": "An Empirical Assessment of Security and Privacy Risks of Web  based-Chatbots",
    "abstract": "Web-based chatbots provide website owners with the benefits of increased sales, immediate response to their customers, and insight into customer behaviour. While Web-based chatbots are getting popular, they have not received much scrutiny from security researchers. The benefits to owners come at the cost of users' privacy and security. Vulnerabilities, such as tracking cookies and third-party domains, can be hidden in the chatbot's iFrame script. This paper presents a large-scale analysis of five Web-based chatbots among the top 1-million Alexa websites. Through our crawler tool, we identify the presence of chatbots in these 1-million websites. We discover that 13,515 out of the top 1-million Alexa websites (1.59%) use one of the five analysed chatbots. Our analysis reveals that the top 300k Alexa ranking websites are dominated by Intercom chatbots that embed the least number of third-party domains. LiveChat chatbots dominate the remaining websites and embed the highest samples of third-party domains. We also find that 850 (6.29%) of the chatbots use insecure protocols to transfer users' chats in plain text. Furthermore, some chatbots heavily rely on cookies for tracking and advertisement purposes. More than two-thirds (68.92%) of the identified cookies in chatbot iFrames are used for ads and tracking users. Our results show that, despite the promises for privacy, security, and anonymity given by the majority of the websites, millions of users may unknowingly be subject to poor security guarantees by chatbot service providers ",
    "url": "https://arxiv.org/abs/2205.08252",
    "authors": [
      "Nazar Waheed",
      "Muhammad Ikram",
      "Saad Sajid Hashmi",
      "Xiangjian He",
      "Priyadarsi Nanda"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.08257",
    "title": "Detection Masking for Improved OCR on Noisy Documents",
    "abstract": "Optical Character Recognition (OCR), the task of extracting textual information from scanned documents is a vital and broadly used technology for digitizing and indexing physical documents. Existing technologies perform well for clean documents, but when the document is visually degraded, or when there are non-textual elements, OCR quality can be greatly impacted, specifically due to erroneous detections. In this paper we present an improved detection network with a masking system to improve the quality of OCR performed on documents. By filtering non-textual elements from the image we can utilize document-level OCR to incorporate contextual information to improve OCR results. We perform a unified evaluation on a publicly available dataset demonstrating the usefulness and broad applicability of our method. Additionally, we present and make publicly available our synthetic dataset with a unique hard-negative component specifically tuned to improve detection results, and evaluate the benefits that can be gained from its usage ",
    "url": "https://arxiv.org/abs/2205.08257",
    "authors": [
      "Daniel Rotman",
      "Ophir Azulai",
      "Inbar Shapira",
      "Yevgeny Burshtein",
      "Udi Barzelay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.08285",
    "title": "KGNN: Distributed Framework for Graph Neural Knowledge Representation",
    "abstract": "Knowledge representation learning has been commonly adopted to incorporate knowledge graph (KG) into various online services. Although existing knowledge representation learning methods have achieved considerable performance improvement, they ignore high-order structure and abundant attribute information, resulting unsatisfactory performance on semantics-rich KGs. Moreover, they fail to make prediction in an inductive manner and cannot scale to large industrial graphs. To address these issues, we develop a novel framework called KGNN to take full advantage of knowledge data for representation learning in the distributed learning system. KGNN is equipped with GNN based encoder and knowledge aware decoder, which aim to jointly explore high-order structure and attribute information together in a fine-grained fashion and preserve the relation patterns in KGs, respectively. Extensive experiments on three datasets for link prediction and triplet classification task demonstrate the effectiveness and scalability of KGNN framework. ",
    "url": "https://arxiv.org/abs/2205.08285",
    "authors": [
      "Binbin Hu",
      "Zhiyang Hu",
      "Zhiqiang Zhang",
      "Jun Zhou",
      "Chuan Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.08288",
    "title": "Measuring Alignment Bias in Neural Seq2Seq Semantic Parsers",
    "abstract": "Prior to deep learning the semantic parsing community has been interested in understanding and modeling the range of possible word alignments between natural language sentences and their corresponding meaning representations. Sequence-to-sequence models changed the research landscape suggesting that we no longer need to worry about alignments since they can be learned automatically by means of an attention mechanism. More recently, researchers have started to question such premise. In this work we investigate whether seq2seq models can handle both simple and complex alignments. To answer this question we augment the popular Geo semantic parsing dataset with alignment annotations and create Geo-Aligned. We then study the performance of standard seq2seq models on the examples that can be aligned monotonically versus examples that require more complex alignments. Our empirical study shows that performance is significantly better over monotonic alignments. ",
    "url": "https://arxiv.org/abs/2205.08288",
    "authors": [
      "Davide Locatelli",
      "Ariadna Quattoni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.08304",
    "title": "Bayesian Physics-Informed Neural Networks for real-world nonlinear  dynamical systems",
    "abstract": "Understanding real-world dynamical phenomena remains a challenging task. Across various scientific disciplines, machine learning has advanced as the go-to technology to analyze nonlinear dynamical systems, identify patterns in big data, and make decision around them. Neural networks are now consistently used as universal function approximators for data with underlying mechanisms that are incompletely understood or exceedingly complex. However, neural networks alone ignore the fundamental laws of physics and often fail to make plausible predictions. Here we integrate data, physics, and uncertainties by combining neural networks, physics-informed modeling, and Bayesian inference to improve the predictive potential of traditional neural network models. We embed the physical model of a damped harmonic oscillator into a fully-connected feed-forward neural network to explore a simple and illustrative model system, the outbreak dynamics of COVID-19. Our Physics-Informed Neural Networks can seamlessly integrate data and physics, robustly solve forward and inverse problems, and perform well for both interpolation and extrapolation, even for a small amount of noisy and incomplete data. At only minor additional cost, they can self-adaptively learn the weighting between data and physics. Combined with Bayesian Neural Networks, they can serve as priors in a Bayesian Inference, and provide credible intervals for uncertainty quantification. Our study reveals the inherent advantages and disadvantages of Neural Networks, Bayesian Inference, and a combination of both and provides valuable guidelines for model selection. While we have only demonstrated these approaches for the simple model problem of a seasonal endemic infectious disease, we anticipate that the underlying concepts and trends generalize to more complex disease conditions and, more broadly, to a wide variety of nonlinear dynamical systems. ",
    "url": "https://arxiv.org/abs/2205.08304",
    "authors": [
      "Kevin Linka",
      "Amelie Schafer",
      "Xuhui Meng",
      "Zongren Zou",
      "George Em Karniadakis",
      "Ellen Kuhl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2205.08316",
    "title": "Self-Supervised Learning of Multi-Object Keypoints for Robotic  Manipulation",
    "abstract": "In recent years, policy learning methods using either reinforcement or imitation have made significant progress. However, both techniques still suffer from being computationally expensive and requiring large amounts of training data. This problem is especially prevalent in real-world robotic manipulation tasks, where access to ground truth scene features is not available and policies are instead learned from raw camera observations. In this paper, we demonstrate the efficacy of learning image keypoints via the Dense Correspondence pretext task for downstream policy learning. Extending prior work to challenging multi-object scenes, we show that our model can be trained to deal with important problems in representation learning, primarily scale-invariance and occlusion. We evaluate our approach on diverse robot manipulation tasks, compare it to other visual representation learning approaches, and demonstrate its flexibility and effectiveness for sample-efficient policy learning. ",
    "url": "https://arxiv.org/abs/2205.08316",
    "authors": [
      "Jan Ole von Hartz",
      "Eugenio Chisari",
      "Tim Welschehold",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.08321",
    "title": "Finite Element Method-enhanced Neural Network for Forward and Inverse  Problems",
    "abstract": "We introduce a novel hybrid methodology combining classical finite element methods (FEM) with neural networks to create a well-performing and generalizable surrogate model for forward and inverse problems. The residual from finite element methods and custom loss functions from neural networks are merged to form the algorithm. The Finite Element Method-enhanced Neural Network hybrid model (FEM-NN hybrid) is data-efficient and physics conforming. The proposed methodology can be used for surrogate models in real-time simulation, uncertainty quantification, and optimization in the case of forward problems. It can be used for updating the models in the case of inverse problems. The method is demonstrated with examples, and the accuracy of the results and performance is compared against the conventional way of network training and the classical finite element method. An application of the forward-solving algorithm is demonstrated for the uncertainty quantification of wind effects on a high-rise buildings. The inverse algorithm is demonstrated in the speed-dependent bearing coefficient identification of fluid bearings. The hybrid methodology of this kind will serve as a paradigm shift in the simulation methods currently used. ",
    "url": "https://arxiv.org/abs/2205.08321",
    "authors": [
      "Rishith Ellath Meethal",
      "Birgit Obst",
      "Mohamed Khalil",
      "Aditya Ghantasala",
      "Anoop Kodakkal",
      "Kai-Uwe Bletzinger",
      "Roland W\u00fcchner"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2205.08325",
    "title": "GraphMapper: Efficient Visual Navigation by Scene Graph Generation",
    "abstract": "Understanding the geometric relationships between objects in a scene is a core capability in enabling both humans and autonomous agents to navigate in new environments. A sparse, unified representation of the scene topology will allow agents to act efficiently to move through their environment, communicate the environment state with others, and utilize the representation for diverse downstream tasks. To this end, we propose a method to train an autonomous agent to learn to accumulate a 3D scene graph representation of its environment by simultaneously learning to navigate through said environment. We demonstrate that our approach, GraphMapper, enables the learning of effective navigation policies through fewer interactions with the environment than vision-based systems alone. Further, we show that GraphMapper can act as a modular scene encoder to operate alongside existing Learning-based solutions to not only increase navigational efficiency but also generate intermediate scene representations that are useful for other future tasks. ",
    "url": "https://arxiv.org/abs/2205.08325",
    "authors": [
      "Zachary Seymour",
      "Niluthpol Chowdhury Mithun",
      "Han-Pang Chiu",
      "Supun Samarasekera",
      "Rakesh Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.08329",
    "title": "Fronthaul Compression Control for shared Fronthaul Access Networks",
    "abstract": "There is a widely held belief that future Radio Access Network (RAN) architectures will be characterized by increased levels of virtualization, whereby base station functionalities, traditionally residing at a single location, will be scattered across different logical entities while being interfaced via high-speed fronthaul (FH) links. For the deployment of such FH links, operators are faced with the challenge of maintaining acceptable radio access performance while at the same time keeping deployment costs low. A common practice is to exploit statistical multiplexing by allowing several cells to utilize the same FH link. As a result, in order to cope with the resulting aggregated traffic, different techniques can be used to reduce the required FH data rates. Herein, we focus on FH compression control strategies for multiple-cell/multiple-user scenarios sharing a common FH link. We propose various methods for sounding reference signal (SRS) handling and analyze different FH-aware modulation data compression and scheduling strategies. Considering a full system setup, including the radio and FH access networks, numerical evaluation is conducted using a 5G NR system-level simulator implemented in ns-3. Simulation results show that, under stringent FH capacity constraints, optimized modulation compression strategies provide significant user-perceived throughput gains over baseline strategies (between 5.2x and 6.9x). On top of them, SRS handling methods achieve additional 2% to 41% gains. ",
    "url": "https://arxiv.org/abs/2205.08329",
    "authors": [
      "Sandra Lag\u00e9n",
      "Xavier Gelabert",
      "Andreas Hansson",
      "Manuel Requena",
      "Lorenza Giupponi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.08332",
    "title": "Scalable algorithms for physics-informed neural and graph networks",
    "abstract": "Physics-informed machine learning (PIML) has emerged as a promising new approach for simulating complex physical and biological systems that are governed by complex multiscale processes for which some data are also available. In some instances, the objective is to discover part of the hidden physics from the available data, and PIML has been shown to be particularly effective for such problems for which conventional methods may fail. Unlike commercial machine learning where training of deep neural networks requires big data, in PIML big data are not available. Instead, we can train such networks from additional information obtained by employing the physical laws and evaluating them at random points in the space-time domain. Such physics-informed machine learning integrates multimodality and multifidelity data with mathematical models, and implements them using neural networks or graph networks. Here, we review some of the prevailing trends in embedding physics into machine learning, using physics-informed neural networks (PINNs) based primarily on feed-forward neural networks and automatic differentiation. For more complex systems or systems of systems and unstructured data, graph neural networks (GNNs) present some distinct advantages, and here we review how physics-informed learning can be accomplished with GNNs based on graph exterior calculus to construct differential operators; we refer to these architectures as physics-informed graph networks (PIGNs). We present representative examples for both forward and inverse problems and discuss what advances are needed to scale up PINNs, PIGNs and more broadly GNNs for large-scale engineering problems. ",
    "url": "https://arxiv.org/abs/2205.08332",
    "authors": [
      "Khemraj Shukla",
      "Mengjia Xu",
      "Nathaniel Trask",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Analysis of PDEs (math.AP)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2205.08343",
    "title": "Moving Stuff Around: A study on efficiency of moving documents into  memory for Neural IR models",
    "abstract": "When training neural rankers using Large Language Models, it's expected that a practitioner would make use of multiple GPUs to accelerate the training time. By using more devices, deep learning frameworks, like PyTorch, allow the user to drastically increase the available VRAM pool, making larger batches possible when training, therefore shrinking training time. At the same time, one of the most critical processes, that is generally overlooked when running data-hungry models, is how data is managed between disk, main memory and VRAM. Most open source research implementations overlook this memory hierarchy, and instead resort to loading all documents from disk to main memory and then allowing the framework (e.g., PyTorch) to handle moving data into VRAM. Therefore, with the increasing sizes of datasets dedicated to IR research, a natural question arises: s this the optimal solution for optimizing training time? We here study how three different popular approaches to handling documents for IR datasets behave and how they scale with multiple GPUs. Namely, loading documents directly into memory, reading documents directly from text files with a lookup table and using a library for handling IR datasets (ir_datasets) differ, both in performance (i.e. samples processed per second) and memory footprint. We show that, when using the most popular libraries for neural ranker research (i.e. PyTorch and Hugging Face's Transformers), the practice of loading all documents into main memory is not always the fastest option and is not feasible for setups with more than a couple GPUs. Meanwhile, a good implementation of data streaming from disk can be faster, while being considerably more scalable. We also show how popular techniques for improving loading times, like memory pining, multiple workers, and RAMDISK usage, can reduce the training time further with minor memory overhead. ",
    "url": "https://arxiv.org/abs/2205.08343",
    "authors": [
      "Arthur C\u00e2mara",
      "Claudia Hauff"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2205.08347",
    "title": "Landing AI on Networks: An equipment vendor viewpoint on Autonomous  Driving Networks",
    "abstract": "The tremendous achievements of Artificial Intelligence (AI) in computer vision, natural language processing, games and robotics, has extended the reach of the AI hype to other fields: in telecommunication networks, the long term vision is to let AI fully manage, and autonomously drive, all aspects of network operation. In this industry vision paper, we discuss challenges and opportunities of Autonomous Driving Network (ADN) driven by AI technologies. To understand how AI can be successfully landed in current and future networks, we start by outlining challenges that are specific to the networking domain, putting them in perspective with advances that AI has achieved in other fields. We then present a system view, clarifying how AI can be fitted in the network architecture. We finally discuss current achievements as well as future promises of AI in networks, mentioning a roadmap to avoid bumps in the road that leads to true large-scale deployment of AI technologies in networks. ",
    "url": "https://arxiv.org/abs/2205.08347",
    "authors": [
      "Dario Rossi",
      "Liang Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.08356",
    "title": "DouFu: A Double Fusion Joint Learning Method For Driving Trajectory  Representation",
    "abstract": "Driving trajectory representation learning is of great significance for various location-based services, such as driving pattern mining and route recommendation. However, previous representation generation approaches tend to rarely address three challenges: 1) how to represent the intricate semantic intentions of mobility inexpensively; 2) complex and weak spatial-temporal dependencies due to the sparsity and heterogeneity of the trajectory data; 3) route selection preferences and their correlation to driving behavior. In this paper, we propose a novel multimodal fusion model, DouFu, for trajectory representation joint learning, which applies multimodal learning and attention fusion module to capture the internal characteristics of trajectories. We first design movement, route, and global features generated from the trajectory data and urban functional zones and then analyze them respectively with the attention encoder or feed forward network. The attention fusion module incorporates route features with movement features to create a better spatial-temporal embedding. With the global semantic feature, DouFu produces a comprehensive embedding for each trajectory. We evaluate representations generated by our method and other baseline models on classification and clustering tasks. Empirical results show that DouFu outperforms other models in most of the learning algorithms like the linear regression and the support vector machine by more than 10%. ",
    "url": "https://arxiv.org/abs/2205.08356",
    "authors": [
      "Han Wang",
      "Zhou Huang",
      "Xiao Zhou",
      "Ganmin Yin",
      "Yi Bao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2205.08362",
    "title": "LPC-AD: Fast and Accurate Multivariate Time Series Anomaly Detection via  Latent Predictive Coding",
    "abstract": "This paper proposes LPC-AD, a fast and accurate multivariate time series (MTS) anomaly detection method. LPC-AD is motivated by the ever-increasing needs for fast and accurate MTS anomaly detection methods to support fast troubleshooting in cloud computing, micro-service systems, etc. LPC-AD is fast in the sense that its reduces the training time by as high as 38.2% compared to the state-of-the-art (SOTA) deep learning methods that focus on training speed. LPC-AD is accurate in the sense that it improves the detection accuracy by as high as 18.9% compared to SOTA sophisticated deep learning methods that focus on enhancing detection accuracy. Methodologically, LPC-AD contributes a generic architecture LPC-Reconstruct for one to attain different trade-offs between training speed and detection accuracy. More specifically, LPC-Reconstruct is built on ideas from autoencoder for reducing redundancy in time series, latent predictive coding for capturing temporal dependence in MTS, and randomized perturbation for avoiding overfitting of anomalous dependence in the training data. We present simple instantiations of LPC-Reconstruct to attain fast training speed, where we propose a simple randomized perturbation method. The superior performance of LPC-AD over SOTA methods is validated by extensive experiments on four large real-world datasets. Experiment results also show the necessity and benefit of each component of the LPC-Reconstruct architecture and that LPC-AD is robust to hyper parameters. ",
    "url": "https://arxiv.org/abs/2205.08362",
    "authors": [
      "Zhi Qi",
      "Hong Xie",
      "Ye Li",
      "Jian Tan",
      "FeiFei Li",
      "John C.S. Lui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.08364",
    "title": "Network Gradient Descent Algorithm for Decentralized Federated Learning",
    "abstract": "We study a fully decentralized federated learning algorithm, which is a novel gradient descent algorithm executed on a communication-based network. For convenience, we refer to it as a network gradient descent (NGD) method. In the NGD method, only statistics (e.g., parameter estimates) need to be communicated, minimizing the risk of privacy. Meanwhile, different clients communicate with each other directly according to a carefully designed network structure without a central master. This greatly enhances the reliability of the entire algorithm. Those nice properties inspire us to carefully study the NGD method both theoretically and numerically. Theoretically, we start with a classical linear regression model. We find that both the learning rate and the network structure play significant roles in determining the NGD estimator's statistical efficiency. The resulting NGD estimator can be statistically as efficient as the global estimator, if the learning rate is sufficiently small and the network structure is well balanced, even if the data are distributed heterogeneously. Those interesting findings are then extended to general models and loss functions. Extensive numerical studies are presented to corroborate our theoretical findings. Classical deep learning models are also presented for illustration purpose. ",
    "url": "https://arxiv.org/abs/2205.08364",
    "authors": [
      "Shuyuan Wu",
      "Danyang Huang",
      "Hansheng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.08370",
    "title": "Individualized Risk Assessment of Preoperative Opioid Use by  Interpretable Neural Network Regression",
    "abstract": "Preoperative opioid use has been reported to be associated with higher preoperative opioid demand, worse postoperative outcomes, and increased postoperative healthcare utilization and expenditures. Understanding the risk of preoperative opioid use helps establish patient-centered pain management. In the field of machine learning, deep neural network (DNN) has emerged as a powerful means for risk assessment because of its superb prediction power; however, the blackbox algorithms may make the results less interpretable than statistical models. Bridging the gap between the statistical and machine learning fields, we propose a novel Interpretable Neural Network Regression (INNER), which combines the strengths of statistical and DNN models. We use the proposed INNER to conduct individualized risk assessment of preoperative opioid use. Intensive simulations and an analysis of 34,186 patients expecting surgery in the Analgesic Outcomes Study (AOS) show that the proposed INNER not only can accurately predict the preoperative opioid use using preoperative characteristics as DNN, but also can estimate the patient specific odds of opioid use without pain and the odds ratio of opioid use for a unit increase in the reported overall body pain, leading to more straightforward interpretations of the tendency to use opioids than DNN. Our results identify the patient characteristics that are strongly associated with opioid use and is largely consistent with the previous findings, providing evidence that INNER is a useful tool for individualized risk assessment of preoperative opioid use. ",
    "url": "https://arxiv.org/abs/2205.08370",
    "authors": [
      "Yuming Sun",
      "Jian Kang",
      "Chad Brummett",
      "Yi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2205.08378",
    "title": "Machine learning and atomic layer deposition: predicting saturation  times from reactor growth profiles using artificial neural networks",
    "abstract": "In this work we explore the application of deep neural networks to the optimization of atomic layer deposition processes based on thickness values obtained at different points of an ALD reactor. We introduce a dataset designed to train neural networks to predict saturation times based on the dose time and thickness values measured at different points of the reactor for a single experimental condition. We then explore different artificial neural network configurations, including depth (number of hidden layers) and size (number of neurons in each layers) to better understand the size and complexity that neural networks should have to achieve high predictive accuracy. The results obtained show that trained neural networks can accurately predict saturation times without requiring any prior information on the surface kinetics. This provides a viable approach to minimize the number of experiments required to optimize new ALD processes in a known reactor. However, the datasets and training procedure depend on the reactor geometry. ",
    "url": "https://arxiv.org/abs/2205.08378",
    "authors": [
      "Angel Yanguas-Gil",
      "Jeffrey W. Elam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Applied Physics (physics.app-ph)"
    ]
  },
  {
    "id": "arXiv:2205.08382",
    "title": "Compatible deep neural network framework with financial time series  data, including data preprocessor, neural network model and trading strategy",
    "abstract": "Experience has shown that trading in stock and cryptocurrency markets has the potential to be highly profitable. In this light, considerable effort has been recently devoted to investigate how to apply machine learning and deep learning to interpret and predict market behavior. This research introduces a new deep neural network architecture and a novel idea of how to prepare financial data before feeding them to the model. In the data preparation part, the first step is to generate many features using technical indicators and then apply the XGBoost model for feature engineering. Splitting data into three categories and using separate autoencoders, we extract high-level mixed features at the second step. This data preprocessing is introduced to predict price movements. Regarding modeling, different convolutional layers, an long short-term memory unit, and several fully-connected layers have been designed to perform binary classification. This research also introduces a trading strategy to exploit the trained model outputs. Three different datasets are used to evaluate this method, where results indicate that this framework can provide us with profitable and robust predictions. ",
    "url": "https://arxiv.org/abs/2205.08382",
    "authors": [
      "Mohammadmahdi Ghahramani",
      "Hamid Esmaeili Najafabadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2205.08383",
    "title": "Bias and Fairness on Multimodal Emotion Detection Algorithms",
    "abstract": "Numerous studies have shown that machine learning algorithms can latch onto protected attributes such as race and gender and generate predictions that systematically discriminate against one or more groups. To date the majority of bias and fairness research has been on unimodal models. In this work, we explore the biases that exist in emotion recognition systems in relationship to the modalities utilized, and study how multimodal approaches affect system bias and fairness. We consider audio, text, and video modalities, as well as all possible multimodal combinations of those, and find that text alone has the least bias, and accounts for the majority of the models' performances, raising doubts about the worthiness of multimodal emotion recognition systems when bias and fairness are desired alongside model performance. ",
    "url": "https://arxiv.org/abs/2205.08383",
    "authors": [
      "Matheus Schmitz",
      "Rehan Ahmed",
      "Jimi Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.08395",
    "title": "Subdivisions and Crossroads: Identifying Hidden Community Structures in  a Data Archive's Citation Network",
    "abstract": "Data archives are an important source of high quality data in many fields, making them ideal sites to study data reuse. By studying data reuse through citation networks, we are able to learn how hidden research communities - those that use the same scientific datasets - are organized. This paper analyzes the community structure of an authoritative network of datasets cited in academic publications, which have been collected by a large, social science data archive: the Interuniversity Consortium for Political and Social Research (ICPSR). Through network analysis, we identified communities of social science datasets and fields of research connected through shared data use. We argue that communities of exclusive data reuse form subdivisions that contain valuable disciplinary resources, while datasets at a \"crossroads\" broadly connect research communities. Our research reveals the hidden structure of data reuse and demonstrates how interdisciplinary research communities organize around datasets as shared scientific inputs. These findings contribute new ways of describing scientific communities in order to understand the impacts of research data reuse. ",
    "url": "https://arxiv.org/abs/2205.08395",
    "authors": [
      "Sara Lafia",
      "Lizhou Fan",
      "Andrea Thomer",
      "Libby Hemphill"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2205.08406",
    "title": "Object Detection and Heading Forecasting by fusing Raw Radar Data using  Cross Attention",
    "abstract": "Radar has been believed to be an inevitable sensor for advanced driver assistance systems (ADAS) for decades. Along with providing robust range, angle and velocity measurements, it is also cost-effective. Hence, radar is expected to play a big role in the next generation ADAS. In this paper, we propose a neural network for object detection and heading forecasting based on radar by fusing three raw radar channels with a cross-attention mechanism. We also introduce an improved ground truth augmentation method based on Bivariate norm, which represents the object labels in a more realistic form for radar measurements. Our results show 5% better mAP compared to state-of-the-art methods. To the best of our knowledge, this is the first attempt in the radar field, where cross-attention is utilized for object detection and heading forecasting without the use of object tracking and association. ",
    "url": "https://arxiv.org/abs/2205.08406",
    "authors": [
      "Ravi Kothari",
      "Ali Kariminezhad",
      "Christian Mayr",
      "Haoming Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2205.08412",
    "title": "From mean-field to complex topologies: network effects on the  algorithmic bias model",
    "abstract": "Nowadays, we live in a society where people often form their opinion by accessing and discussing contents shared on social networking websites. While these platforms have fostered information access and diffusion, they represent optimal environments for the proliferation of polluted contents, which is argued to be one of the co-causes of polarization/radicalization. Moreover, recommendation algorithms - intended to enhance platform usage - are likely to augment such phenomena, generating the so called Algorithmic Bias. In this work, we study the impact that different network topologies have on the formation and evolution of opinion in the context of a recent opinion dynamic model which includes bounded confidence and algorithmic bias. Mean-field, scale-free and random topologies, as well as networks generated by the Lancichinetti-Fortunato-Radicchi benchmark, are compared in terms of opinion fragmentation/polarization and time to convergence. ",
    "url": "https://arxiv.org/abs/2205.08412",
    "authors": [
      "Valentina Pansanella",
      "Giulio Rossetti",
      "Letizia Milli"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2205.08430",
    "title": "Towards Resilient Access Equality for 6G Serverless p-LEO Satellite  Networks",
    "abstract": "Low earth orbit (LEO) mega-constellations, integrating government space systems and commercial practices, have emerged as enabling technologies for the sixth generation (6G) networks due to their good merits of global coverage and ubiquitous services for military and civilian use cases. However, convergent LEO-based satellite networking infrastructures still lack leveraging the synergy of space and terrestrial systems. This paper, therefore, extends conventional serverless cloud platforms with serverless edge learning architectures for 6G proliferated LEO (p-LEO) satellite ecosystems and provides a new distributed training design from a networking perspective. The proposed design dynamically orchestrates communications and computation functionalities and resources among heterogeneous physical units to efficiently fulfill multi-agent deep reinforcement learning for service-level agreements. Innovative ecosystem enhancements, including ultrabroadband access, anti-jammed transmissions, resilient networking, and related open challenges, are also investigated for end-to-end connectivity, communications, and learning performance. ",
    "url": "https://arxiv.org/abs/2205.08430",
    "authors": [
      "Lin Shih-Chun",
      "Lin Chia-Hung",
      "Chu Liang C.",
      "Lien Shao-Yu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.08440",
    "title": "Moving Smart Contracts -- A Privacy Preserving Method for Off-Chain Data  Trust",
    "abstract": "Blockchains provide environments where parties can interact transparently and securely peer-to-peer without needing a trusted third party. Parties can trust the integrity and correctness of transactions and the verifiable execution of binary code on the blockchain (smart contracts) inside the system. Including information from outside of the blockchain remains challenging. A challenge is data privacy. In a public system, shared data becomes public and, coming from a single source, often lacks credibility. A private system gives the parties control over their data and sources but trades in positive aspects as transparency. Often, not the data itself is the most critical information but the result of a computation performed on it. An example is research data certification. To keep data private but still prove data provenance, researchers can store a hash value of that data on the blockchain. This hash value is either calculated locally on private data without the chance for validation or is calculated on the blockchain, meaning that data must be published and stored on the blockchain -- a problem of the overall data amount stored on and distributed with the ledger. A system we called moving smart contracts bypasses this problem: Data remain local, but trusted nodes can access them and execute trusted smart contract code stored on the blockchain. This method avoids the system-wide distribution of research data and makes it accessible and verifiable with trusted software. ",
    "url": "https://arxiv.org/abs/2205.08440",
    "authors": [
      "Simon Tschirner",
      "Shashank Shekher Tripathi",
      "Mathias Roeper",
      "Markus M. Becker",
      "Volker Skwarek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.08443",
    "title": "On the Privacy of Decentralized Machine Learning",
    "abstract": "In this work, we carry out the first, in-depth, privacy analysis of Decentralized Learning -- a collaborative machine learning framework aimed at circumventing the main limitations of federated learning. We identify the decentralized learning properties that affect users' privacy and we introduce a suite of novel attacks for both passive and active decentralized adversaries. We demonstrate that, contrary to what is claimed by decentralized learning proposers, decentralized learning does not offer any security advantages over more practical approaches such as federated learning. Rather, it tends to degrade users' privacy by increasing the attack surface and enabling any user in the system to perform powerful privacy attacks such as gradient inversion, and even gain full control over honest users' local model. We also reveal that, given the state of the art in protections, privacy-preserving configurations of decentralized learning require abandoning any possible advantage over the federated setup, completely defeating the objective of the decentralized approach. ",
    "url": "https://arxiv.org/abs/2205.08443",
    "authors": [
      "Dario Pasquini",
      "Mathilde Raynal",
      "Carmela Troncoso"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.08455",
    "title": "Utterance Weighted Multi-Dilation Temporal Convolutional Networks for  Monaural Speech Dereverberation",
    "abstract": "Speech dereverberation is an important stage in many speech technology applications. Recent work in this area has been dominated by deep neural network models. Temporal convolutional networks (TCNs) are deep learning models that have been proposed for sequence modelling in the task of dereverberating speech. In this work a weighted multi-dilation depthwise-separable convolution is proposed to replace standard depthwise-separable convolutions in TCN models. This proposed convolution enables the TCN to dynamically focus on more or less local information in its receptive field at each convolutional block in the network. It is shown that this weighted multi-dilation temporal convolutional network (WD-TCN) consistently outperforms the TCN across various model configurations and using the WD-TCN model is a more parameter efficient method to improve the performance of the model than increasing the number of convolutional blocks. The best performance improvement over the baseline TCN is 0.55 dB scale-invariant signal-to-distortion ratio (SISDR) and the best performing WD-TCN model attains 12.26 dB SISDR on the WHAMR dataset. ",
    "url": "https://arxiv.org/abs/2205.08455",
    "authors": [
      "William Ravenscroft",
      "Stefan Goetze",
      "Thomas Hain"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.08459",
    "title": "Dynamic Recognition of Speakers for Consent Management by Contrastive  Embedding Replay",
    "abstract": "Voice assistants record sound and can overhear conversations. Thus, a consent management mechanism is desirable such that users can express their wish to be recorded or not. Consent management can be implemented using speaker recognition; users that do not give consent enrol their voice and all further recordings of these users is subsequently not processed. Building speaker recognition based consent management is challenging due to the dynamic nature of the problem, required scalability for large number of speakers, and need for fast speaker recognition with high accuracy. This paper describes a speaker recognition based consent management system addressing the aforementioned challenges. A fully supervised batch contrastive learning is applied to learn the underlying speaker equivariance inductive bias during the training on the set of speakers noting recording dissent. Speakers that do not provide consent are grouped in buckets which are trained continuously. The embeddings are contrastively learned for speakers in their buckets during training and act later as a replay buffer for classification. The buckets are progressively registered during training and a novel multi-strided random sampling of the contrastive embedding replay buffer is proposed. Buckets are contrastively trained for a few steps only in each iteration and replayed for classification progressively leading to fast convergence. An algorithm for fast and dynamic registration and removal of speakers in buckets is described. The evaluation results show that the proposed approach provides the desired fast and dynamic solution for consent management and outperforms existing approaches in terms of convergence speed and adaptive capabilities as well as verification performance during inference. ",
    "url": "https://arxiv.org/abs/2205.08459",
    "authors": [
      "Arash Shahmansoori",
      "Utz Roedig"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.08462",
    "title": "Privacy Preserving Machine Learning for Electric Vehicles: A Survey",
    "abstract": "In the recent years, the interest of individual users in modern electric vehicles (EVs) has grown exponentially. An EV has two major components, which make it different from traditional vehicles, first is its environment friendly nature because of being electric, and second is the interconnection ability of these vehicles because of modern information and communication technologies (ICTs). Both of these features are playing a key role in the development of EVs, and both academia and industry personals are working towards development of modern protocols for EV networks. All these interactions, whether from energy perspective or from communication perspective, both are generating a tremendous amount of data every day. In order to get most out of this data collected from EVs, research works have highlighted the use of machine/deep learning techniques for various EV applications. This interaction is quite fruitful, but it also comes with a critical concern of privacy leakage during collection, storage, and training of vehicular data. Therefore, alongside developing machine/deep learning techniques for EVs, it is also critical to ensure that they are resilient to private information leakage and attacks. In this paper, we begin with the discussion about essential background on EVs and privacy preservation techniques, followed by a brief overview of privacy preservation in EVs using machine learning techniques. Particularly, we also focus on an in-depth review of the integration of privacy techniques in EVs and highlighted different application scenarios in EVs. Alongside this, we provide a a very detailed survey of current works on privacy preserving machine/deep learning techniques used for modern EVs. Finally, we present the certain research issues, critical challenges, and future directions of research for researchers working in privacy preservation in EVs. ",
    "url": "https://arxiv.org/abs/2205.08462",
    "authors": [
      "Abdul Rahman Sani",
      "Muneeb Ul Hassan",
      "Jinjun Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.08464",
    "title": "Robust Losses for Learning Value Functions",
    "abstract": "Most value function learning algorithms in reinforcement learning are based on the mean squared (projected) Bellman error. However, squared errors are known to be sensitive to outliers, both skewing the solution of the objective and resulting in high-magnitude and high-variance gradients. To control these high-magnitude updates, typical strategies in RL involve clipping gradients, clipping rewards, rescaling rewards, or clipping errors. While these strategies appear to be related to robust losses -- like the Huber loss -- they are built on semi-gradient update rules which do not minimize a known loss. In this work, we build on recent insights reformulating squared Bellman errors as a saddlepoint optimization problem and propose a saddlepoint reformulation for a Huber Bellman error and Absolute Bellman error. We start from a formalization of robust losses, then derive sound gradient-based approaches to minimize these losses in both the online off-policy prediction and control settings. We characterize the solutions of the robust losses, providing insight into the problem settings where the robust losses define notably better solutions than the mean squared Bellman error. Finally, we show that the resulting gradient-based algorithms are more stable, for both prediction and control, with less sensitivity to meta-parameters. ",
    "url": "https://arxiv.org/abs/2205.08464",
    "authors": [
      "Andrew Patterson",
      "Victor Liao",
      "Martha White"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.08479",
    "title": "Opportunistic Routing in Quantum Networks",
    "abstract": "Unlike classical routing algorithms, quantum routing algorithms make use of entangled states - a type of resources that have a limited lifetime and need to be regenerated after consumption. In a nutshell, quantum routing algorithms have to use these resources efficiently, while optimizing some objectives such as the total waiting time. Current routing algorithms tend to keep a routing request waiting until all of the resources on its path are available. In this paper, we introduce a new way of managing entanglement resources in an opportunistic fashion: a request can move forward along its path as soon as possible (even if some resources on its path are not ready). We show that this opportunistic approach is fundamentally better than conventional approaches. In particular, our results indicate that this new approach achieves a 30-50% improvement in the average total waiting time and average link waiting time compared with several state-of-the-art routing algorithms. As a by-product of this work, we develop a new simulator for quantum routing, which can be used to evaluate various design choices under different scenarios. ",
    "url": "https://arxiv.org/abs/2205.08479",
    "authors": [
      "Ali Farahbakhsh",
      "Chen Feng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.08501",
    "title": "Experimentally realized in situ backpropagation for deep learning in  nanophotonic neural networks",
    "abstract": "Neural networks are widely deployed models across many scientific disciplines and commercial endeavors ranging from edge computing and sensing to large-scale signal processing in data centers. The most efficient and well-entrenched method to train such networks is backpropagation, or reverse-mode automatic differentiation. To counter an exponentially increasing energy budget in the artificial intelligence sector, there has been recent interest in analog implementations of neural networks, specifically nanophotonic neural networks for which no analog backpropagation demonstration exists. We design mass-manufacturable silicon photonic neural networks that alternately cascade our custom designed \"photonic mesh\" accelerator with digitally implemented nonlinearities. These reconfigurable photonic meshes program computationally intensive arbitrary matrix multiplication by setting physical voltages that tune the interference of optically encoded input data propagating through integrated Mach-Zehnder interferometer networks. Here, using our packaged photonic chip, we demonstrate in situ backpropagation for the first time to solve classification tasks and evaluate a new protocol to keep the entire gradient measurement and update of physical device voltages in the analog domain, improving on past theoretical proposals. Our method is made possible by introducing three changes to typical photonic meshes: (1) measurements at optical \"grating tap\" monitors, (2) bidirectional optical signal propagation automated by fiber switch, and (3) universal generation and readout of optical amplitude and phase. After training, our classification achieves accuracies similar to digital equivalents even in presence of systematic error. Our findings suggest a new training paradigm for photonics-accelerated artificial intelligence based entirely on a physical analog of the popular backpropagation technique. ",
    "url": "https://arxiv.org/abs/2205.08501",
    "authors": [
      "Sunil Pai",
      "Zhanghao Sun",
      "Tyler W. Hughes",
      "Taewon Park",
      "Ben Bartlett",
      "Ian A. D. Williamson",
      "Momchil Minkov",
      "Maziyar Milanizadeh",
      "Nathnael Abebe",
      "Francesco Morichetti",
      "Andrea Melloni",
      "Shanhui Fan",
      "Olav Solgaard",
      "David A.B. Miller"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2205.08518",
    "title": "Do Neural Networks Compress Manifolds Optimally?",
    "abstract": "Artificial Neural-Network-based (ANN-based) lossy compressors have recently obtained striking results on several sources. Their success may be ascribed to an ability to identify the structure of low-dimensional manifolds in high-dimensional ambient spaces. Indeed, prior work has shown that ANN-based compressors can achieve the optimal entropy-distortion curve for some such sources. In contrast, we determine the optimal entropy-distortion tradeoffs for two low-dimensional manifolds with circular structure and show that state-of-the-art ANN-based compressors fail to optimally compress the sources, especially at high rates. ",
    "url": "https://arxiv.org/abs/2205.08518",
    "authors": [
      "Sourbh Bhadane",
      "Aaron B. Wagner",
      "Johannes Ball\u00e9"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.08525",
    "title": "Self-supervised Neural Articulated Shape and Appearance Models",
    "abstract": "Learning geometry, motion, and appearance priors of object classes is important for the solution of a large variety of computer vision problems. While the majority of approaches has focused on static objects, dynamic objects, especially with controllable articulation, are less explored. We propose a novel approach for learning a representation of the geometry, appearance, and motion of a class of articulated objects given only a set of color images as input. In a self-supervised manner, our novel representation learns shape, appearance, and articulation codes that enable independent control of these semantic dimensions. Our model is trained end-to-end without requiring any articulation annotations. Experiments show that our approach performs well for different joint types, such as revolute and prismatic joints, as well as different combinations of these joints. Compared to state of the art that uses direct 3D supervision and does not output appearance, we recover more faithful geometry and appearance from 2D observations only. In addition, our representation enables a large variety of applications, such as few-shot reconstruction, the generation of novel articulations, and novel view-synthesis. ",
    "url": "https://arxiv.org/abs/2205.08525",
    "authors": [
      "Fangyin Wei",
      "Rohan Chabra",
      "Lingni Ma",
      "Christoph Lassner",
      "Michael Zollh\u00f6fer",
      "Szymon Rusinkiewicz",
      "Chris Sweeney",
      "Richard Newcombe",
      "Mira Slavcheva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.07869",
    "title": "Near out-of-distribution detection for low-resolution radar  micro-Doppler signatures",
    "abstract": "Near out-of-distribution detection (OOD) aims at discriminating semantically similar data points without the supervision required for classification. This paper puts forward an OOD use case for radar targets detection extensible to other kinds of sensors and detection scenarios. We emphasize the relevance of OOD and its specific supervision requirements for the detection of a multimodal, diverse targets class among other similar radar targets and clutter in real-life critical systems. We propose a comparison of deep and non-deep OOD methods on simulated low-resolution pulse radar micro-Doppler signatures, considering both a spectral and a covariance matrix input representation. The covariance representation aims at estimating whether dedicated second-order processing is appropriate to discriminate signatures. The potential contributions of labeled anomalies in training, self-supervised learning, contrastive learning insights and innovative training losses are discussed, and the impact of training set contamination caused by mislabelling is investigated. ",
    "url": "https://arxiv.org/abs/2205.07869",
    "authors": [
      "Martin Bauw",
      "Santiago Velasco-Forero",
      "Jesus Angulo",
      "Claude Adnet",
      "Olivier Airiau"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.08055",
    "title": "HelixADMET: a robust and endpoint extensible ADMET system incorporating  self-supervised knowledge transfer",
    "abstract": "Accurate ADMET (an abbreviation for \"absorption, distribution, metabolism, excretion, and toxicity\") predictions can efficiently screen out undesirable drug candidates in the early stage of drug discovery. In recent years, multiple comprehensive ADMET systems that adopt advanced machine learning models have been developed, providing services to estimate multiple endpoints. However, those ADMET systems usually suffer from weak extrapolation ability. First, due to the lack of labelled data for each endpoint, typical machine learning models perform frail for the molecules with unobserved scaffolds. Second, most systems only provide fixed built-in endpoints and cannot be customised to satisfy various research requirements. To this end, we develop a robust and endpoint extensible ADMET system, HelixADMET (H-ADMET). H-ADMET incorporates the concept of self-supervised learning to produce a robust pre-trained model. The model is then fine-tuned with a multi-task and multi-stage framework to transfer knowledge between ADMET endpoints, auxiliary tasks, and self-supervised tasks. Our results demonstrate that H-ADMET achieves an overall improvement of 4%, compared with existing ADMET systems on comparable endpoints. Additionally, the pre-trained model provided by H-ADMET can be fine-tuned to generate new and customised ADMET endpoints, meeting various demands of drug research and development requirements. ",
    "url": "https://arxiv.org/abs/2205.08055",
    "authors": [
      "Shanzhuo Zhang",
      "Zhiyuan Yan",
      "Yueyang Huang",
      "Lihang Liu",
      "Donglong He",
      "Wei Wang",
      "Xiaomin Fang",
      "Xiaonan Zhang",
      "Fan Wang",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2205.08059",
    "title": "Natural evolutionary strategies applied to quantum-classical hybrid  neural networks",
    "abstract": "With the rapid development of quantum computers, several applications are being proposed for them. Quantum simulations, simulation of chemical reactions, solution of optimization problems and quantum neural networks are some examples. However, problems such as noise, limited number of qubits and circuit depth, and gradient vanishing must be resolved before we can use them to their full potential. In the field of quantum machine learning, several models have been proposed. In general, in order to train these different models, we use the gradient of a cost function with respect to the model parameters. In order to obtain this gradient, we must compute the derivative of this function with respect to the model parameters. For this we can use the method called parameter-shift rule. This method consists of evaluating the cost function twice for each parameter of the quantum network. A problem with this method is that the number of evaluations grows linearly with the number of parameters. In this work we study an alternative method, called Natural Evolutionary Strategies (NES), which are a family of black box optimization algorithms. An advantage of the NES method is that in using it one can control the number of times the cost function will be evaluated. We apply the NES method to the binary classification task, showing that this method is a viable alternative for training quantum neural networks. ",
    "url": "https://arxiv.org/abs/2205.08059",
    "authors": [
      "Lucas Friedrich",
      "Jonas Maziero"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.08068",
    "title": "A Framework for CSI-Based Indoor Localization with 1D Convolutional  Neural Networks",
    "abstract": "Modern indoor localization techniques are essential to overcome the weak GPS coverage in indoor environments. Recently, considerable progress has been made in Channel State Information (CSI) based indoor localization with signal fingerprints. However, CSI signal patterns can be complicated in the large and highly dynamic indoor spaces with complex interiors, thus a solution for solving this issue is urgently needed to expand the applications of CSI to a broader indoor space. In this paper, we propose an end-to-end solution including data collection, pattern clustering, denoising, calibration and a lightweight one-dimensional convolutional neural network (1D CNN) model with CSI fingerprinting to tackle this problem. We have also created and plan to open source a CSI dataset with a large amount of data collected across complex indoor environments at Colorado State University. Experiments indicate that our approach achieves up to 68.5% improved performance (mean distance error) with minimal number of parameters, compared to the best-known deep machine learning and CSI-based indoor localization works. ",
    "url": "https://arxiv.org/abs/2205.08068",
    "authors": [
      "Liping Wang",
      "Sudeep Pasricha"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.08069",
    "title": "Multi-Head Attention Neural Network for Smartphone Invariant Indoor  Localization",
    "abstract": "Smartphones together with RSSI fingerprinting serve as an efficient approach for delivering a low-cost and high-accuracy indoor localization solution. However, a few critical challenges have prevented the wide-spread proliferation of this technology in the public domain. One such critical challenge is device heterogeneity, i.e., the variation in the RSSI signal characteristics captured across different smartphone devices. In the real-world, the smartphones or IoT devices used to capture RSSI fingerprints typically vary across users of an indoor localization service. Conventional indoor localization solutions may not be able to cope with device-induced variations which can degrade their localization accuracy. We propose a multi-head attention neural network-based indoor localization framework that is resilient to device heterogeneity. An in-depth analysis of our proposed framework across a variety of indoor environments demonstrates up to 35% accuracy improvement compared to state-of-the-art indoor localization techniques. ",
    "url": "https://arxiv.org/abs/2205.08069",
    "authors": [
      "Saideep Tiku",
      "Danish Gufran",
      "Sudeep Pasricha"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.08106",
    "title": "Computerized Tomography Pulmonary Angiography Image Simulation using  Cycle Generative Adversarial Network from Chest CT imaging in Pulmonary  Embolism Patients",
    "abstract": "The purpose of this research is to develop a system that generates simulated computed tomography pulmonary angiography (CTPA) images clinically for pulmonary embolism diagnoses. Nowadays, CTPA images are the gold standard computerized detection method to determine and identify the symptoms of pulmonary embolism (PE), although performing CTPA is harmful for patients and also expensive. Therefore, we aim to detect possible PE patients through CT images. The system will simulate CTPA images with deep learning models for the identification of PE patients' symptoms, providing physicians with another reference for determining PE patients. In this study, the simulated CTPA image generation system uses a generative antagonistic network to enhance the features of pulmonary vessels in the CT images to strengthen the reference value of the images and provide a basis for hospitals to judge PE patients. We used the CT images of 22 patients from National Cheng Kung University Hospital and the corresponding CTPA images as the training data for the task of simulating CTPA images and generated them using two sets of generative countermeasure networks. This study is expected to propose a new approach to the clinical diagnosis of pulmonary embolism, in which a deep learning network is used to assist in the complex screening process and to review the generated simulated CTPA images, allowing physicians to assess whether a patient needs to undergo detailed testing for CTPA, improving the speed of detection of pulmonary embolism and significantly reducing the number of undetected patients. ",
    "url": "https://arxiv.org/abs/2205.08106",
    "authors": [
      "Chia-Hung Yang",
      "Yun-Chien Cheng",
      "Chin Kuo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.08126",
    "title": "The Hamilton compression of highly symmetric graphs",
    "abstract": "We say that a Hamilton cycle $C=(x_1,\\ldots,x_n)$ in a graph $G$ is $k$-symmetric, if the mapping $x_i\\mapsto x_{i+n/k}$ for all $i=1,\\ldots,n$, where indices are considered modulo $n$, is an automorphism of $G$. In other words, if we lay out the vertices $x_1,\\ldots,x_n$ equidistantly on a circle and draw the edges of $G$ as straight lines, then the drawing of $G$ has $k$-fold rotational symmetry, i.e., all information about the graph is compressed into a $360^\\circ/k$ wedge of the drawing. We refer to the maximum $k$ for which there exists a $k$-symmetric Hamilton cycle in $G$ as the Hamilton compression of $G$. We investigate the Hamilton compression of four different families of vertex-transitive graphs, namely hypercubes, Johnson graphs, permutahedra and Cayley graphs of abelian groups. In several cases we determine their Hamilton compression exactly, and in other cases we provide close lower and upper bounds. The cycles we construct have a much higher compression than several classical Gray codes known from the literature. Our constructions also yield Gray codes for bitstrings, combinations and permutations that have few tracks and/or that are balanced. ",
    "url": "https://arxiv.org/abs/2205.08126",
    "authors": [
      "Petr Gregor",
      "Arturo Merino",
      "Torsten M\u00fctze"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2205.08138",
    "title": "Composing General Audio Representation by Fusing Multilayer Features of  a Pre-trained Model",
    "abstract": "Many application studies rely on audio DNN models pre-trained on a large-scale dataset as essential feature extractors, and they extract features from the last layers. In this study, we focus on our finding that the middle layer features of existing supervised pre-trained models are more effective than the late layer features for some tasks. We propose a simple approach to compose features effective for general-purpose applications, consisting of two steps: (1) calculating feature vectors along the time frame from middle/late layer outputs, and (2) fusing them. This approach improves the utility of frequency and channel information in downstream processes, and combines the effectiveness of middle and late layer features for different tasks. As a result, the feature vectors become effective for general purposes. In the experiments using VGGish, PANNs' CNN14, and AST on nine downstream tasks, we first show that each layer output of these models serves different tasks. Then, we demonstrate that the proposed approach significantly improves their performance and brings it to a level comparable to that of the state-of-the-art. In particular, the performance of the non-semantic speech (NOSS) tasks greatly improves, especially on Speech commands V2 with VGGish of +77.1 (14.3% to 91.4%). ",
    "url": "https://arxiv.org/abs/2205.08138",
    "authors": [
      "Daisuke Niizumi",
      "Daiki Takeuchi",
      "Yasunori Ohishi",
      "Noboru Harada",
      "Kunio Kashino"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2205.08181",
    "title": "Coloring circle arrangements: New $4$-chromatic planar graphs",
    "abstract": "Felsner, Hurtado, Noy and Streinu (2000) conjectured that arrangement graphs of simple great-circle arrangements have chromatic number at most $3$. Motivated by this conjecture, we study the colorability of arrangement graphs for different classes of arrangements of (pseudo-)circles. In this paper the conjecture is verified for $\\triangle$-saturated pseudocircle arrangements, i.e., for arrangements where one color class of the 2-coloring of faces consists of triangles only, as well as for further classes of (pseudo-)circle arrangements. These results are complemented by a construction which maps $\\triangle$-saturated arrangements with a pentagonal face to arrangements with 4-chromatic 4-regular arrangement graphs. This \"corona\" construction has similarities with the crowning construction introduced by Koester (1985). Based on exhaustive experiments with small arrangements we propose three strengthenings of the original conjecture. We also investigate fractional colorings. It is shown that the arrangement graph of every arrangement $\\mathcal{A}$ of pairwise intersecting pseudocircles is \"close\" to being $3$-colorable. More precisely, the fractional chromatic number $\\chi_f(\\mathcal{A})$ of the arrangement graph is bounded from above by $\\chi_f(\\mathcal{A}) \\le 3+O(\\frac{1}{n})$, where $n$ is the number of pseudocircles of $\\mathcal{A}$. Furthermore, we construct an infinite family of $4$-edge-critical $4$-regular planar graphs which are fractionally $3$-colorable. This disproves a conjecture of Gimbel, K\\\"{u}ndgen, Li, and Thomassen (2019). ",
    "url": "https://arxiv.org/abs/2205.08181",
    "authors": [
      "Man-Kwun Chiu",
      "Stefan Felsner",
      "Manfred Scheucher",
      "Felix Schr\u00f6der",
      "Raphael Steiner",
      "Birgit Vogtenhuber"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2205.08187",
    "title": "Deep neural networks with dependent weights: Gaussian Process mixture  limit, heavy tails, sparsity and compressibility",
    "abstract": "This article studies the infinite-width limit of deep feedforward neural networks whose weights are dependent, and modelled via a mixture of Gaussian distributions. Each hidden node of the network is assigned a nonnegative random variable that controls the variance of the outgoing weights of that node. We make minimal assumptions on these per-node random variables: they are iid and their sum, in each layer, converges to some finite random variable in the infinite-width limit. Under this model, we show that each layer of the infinite-width neural network can be characterised by two simple quantities: a non-negative scalar parameter and a L\\'evy measure on the positive reals. If the scalar parameters are strictly positive and the L\\'evy measures are trivial at all hidden layers, then one recovers the classical Gaussian process (GP) limit, obtained with iid Gaussian weights. More interestingly, if the L\\'evy measure of at least one layer is non-trivial, we obtain a mixture of Gaussian processes (MoGP) in the large-width limit. The behaviour of the neural network in this regime is very different from the GP regime. One obtains correlated outputs, with non-Gaussian distributions, possibly with heavy tails. Additionally, we show that, in this regime, the weights are compressible, and feature learning is possible. Many sparsity-promoting neural network models can be recast as special cases of our approach, and we discuss their infinite-width limits; we also present an asymptotic analysis of the pruning error. We illustrate some of the benefits of the MoGP regime over the GP regime in terms of representation learning and compressibility on simulated, MNIST and Fashion MNIST datasets. ",
    "url": "https://arxiv.org/abs/2205.08187",
    "authors": [
      "Hoil Lee",
      "Fadhel Ayed",
      "Paul Jung",
      "Juho Lee",
      "Hongseok Yang",
      "Fran\u00e7ois Caron"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2205.08193",
    "title": "The HEP Software Foundation Community",
    "abstract": "The HEP Software Foundation was founded in 2014 to tackle common problems of software development and sustainability for high-energy physics. In this paper we outline the motivation for the founding of the organisation and give a brief history of its development. We describe how the organisation functions today and what challenges remain to be faced in the future. ",
    "url": "https://arxiv.org/abs/2205.08193",
    "authors": [
      "Graeme A Stewart",
      "Peter Elmer",
      "Elizabeth Sexton-Kennedy"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.08349",
    "title": "Topological Signal Processing using the Weighted Ordinal Partition  Network",
    "abstract": "One of the most important problems arising in time series analysis is that of bifurcation, or change point detection. That is, given a collection of time series over a varying parameter, when has the structure of the underlying dynamical system changed? For this task, we turn to the field of topological data analysis (TDA), which encodes information about the shape and structure of data. The idea of utilizing tools from TDA for signal processing tasks, known as topological signal processing (TSP), has gained much attention in recent years, largely through a standard pipeline that computes the persistent homology of the point cloud generated by the Takens' embedding. However, this procedure is limited by computation time since the simplicial complex generated in this case is large, but also has a great deal of redundant data. For this reason, we turn to a more recent method for encoding the structure of the attractor, which constructs an ordinal partition network (OPN) representing information about when the dynamical system has passed between certain regions of state space. The result is a weighted graph whose structure encodes information about the underlying attractor. Our previous work began to find ways to package the information of the OPN in a manner that is amenable to TDA; however, that work only used the network structure and did nothing to encode the additional weighting information. In this paper, we take the next step: building a pipeline to analyze the weighted OPN with TDA and showing that this framework provides more resilience to noise or perturbations in the system and improves the accuracy of the dynamic state detection. ",
    "url": "https://arxiv.org/abs/2205.08349",
    "authors": [
      "Audun Myers",
      "Firas A. Khasawneh",
      "Elizabeth Munch"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.08409",
    "title": "Automated Mobility Context Detection with Inertial Signals",
    "abstract": "Remote monitoring of motor functions is a powerful approach for health assessment, especially among the elderly population or among subjects affected by pathologies that negatively impact their walking capabilities. This is further supported by the continuous development of wearable sensor devices, which are getting progressively smaller, cheaper, and more energy efficient. The external environment and mobility context have an impact on walking performance, hence one of the biggest challenges when remotely analysing gait episodes is the ability to detect the context within which those episodes occurred. The primary goal of this paper is the investigation of context detection for remote monitoring of daily motor functions. We aim to understand whether inertial signals sampled with wearable accelerometers, provide reliable information to classify gait-related activities as either indoor or outdoor. We explore two different approaches to this task: (1) using gait descriptors and features extracted from the input inertial signals sampled during walking episodes, together with classic machine learning algorithms, and (2) treating the input inertial signals as time series data and leveraging end-to-end state-of-the-art time series classifiers. We directly compare the two approaches through a set of experiments based on data collected from 9 healthy individuals. Our results indicate that the indoor/outdoor context can be successfully derived from inertial data streams. We also observe that time series classification models achieve better accuracy than any other feature-based models, while preserving efficiency and ease of use. ",
    "url": "https://arxiv.org/abs/2205.08409",
    "authors": [
      "Antonio Bevilacqua",
      "Lisa Alcock",
      "Brian Caulfield",
      "Eran Gazit",
      "Clint Hansen",
      "Neil Ireson",
      "Georgiana Ifrim"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.08418",
    "title": "Fault Detection for Non-Condensing Boilers using Simulated Building  Automation System Sensor Data",
    "abstract": "Building performance has been shown to degrade significantly after commissioning, resulting in increased energy consumption and associated greenhouse gas emissions. Continuous Commissioning using existing sensor networks and IoT devices has the potential to minimize this waste by continually identifying system degradation and re-tuning control strategies to adapt to real building performance. Due to its significant contribution to greenhouse gas emissions, the performance of gas boiler systems for building heating is critical. A review of boiler performance studies has been used to develop a set of common faults and degraded performance conditions, which have been integrated into a MATLAB/Simulink emulator. This resulted in a labeled dataset with approximately 10,000 simulations of steady-state performance for each of 14 non-condensing boilers. The collected data is used for training and testing fault classification using K-nearest neighbour, Decision tree, Random Forest, and Support Vector Machines. The results show that the Support Vector Machines method gave the best prediction accuracy, consistently exceeding 90%, and generalization across multiple boilers is not possible due to low classification accuracy. ",
    "url": "https://arxiv.org/abs/2205.08418",
    "authors": [
      "Rony Shohet",
      "Mohamed Kandil",
      "J.J. McArthur"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2205.08419",
    "title": "Human Emotion Classification based on EEG Signals Using Recurrent Neural  Network And KNN",
    "abstract": "In human contact, emotion is very crucial. Attributes like words, voice intonation, facial expressions, and kinesics can all be used to portray one's feelings. However, brain-computer interface (BCI) devices have not yet reached the level required for emotion interpretation. With the rapid development of machine learning algorithms, dry electrode techniques, and different real-world applications of the brain-computer interface for normal individuals, emotion categorization from EEG data has recently gotten a lot of attention. Electroencephalogram (EEG) signals are a critical resource for these systems. The primary benefit of employing EEG signals is that they reflect true emotion and are easily resolved by computer systems. In this work, EEG signals associated with good, neutral, and negative emotions were identified using channel selection preprocessing. However, researchers had a limited grasp of the specifics of the link between various emotional states until now. To identify EEG signals, we used discrete wavelet transform and machine learning techniques such as recurrent neural network (RNN) and k-nearest neighbor (kNN) algorithm. Initially, the classifier methods were utilized for channel selection. As a result, final feature vectors were created by integrating the features of EEG segments from these channels. Using the RNN and kNN algorithms, the final feature vectors with connected positive, neutral, and negative emotions were categorized independently. The classification performance of both techniques is computed and compared. Using RNN and kNN, the average overall accuracies were 94.844 % and 93.438 %, respectively. ",
    "url": "https://arxiv.org/abs/2205.08419",
    "authors": [
      "Shashank Joshi",
      "Falak Joshi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.08423",
    "title": "The Deployment of IRS in UAV-Empowered 6G Networks",
    "abstract": "Intelligent reflecting surfaces (IRSs) with the ability to reconfigure inherent electromagnetic reflection and absorption characteristics in real-time provide unparalleled prospects to improve wireless connectivity in adverse circumstances. Unmanned aerial vehicles (UAV)-assisted wireless networks are evolved as a reliable solution to combat non-line of sight (NLoS) scenarios. Thereby, the IRS-empowered UAV-assisted cellular networks will be a significant role-player to improve the coverage and user experiences. The paper aimed to minimize the path loss and maximize the achievable data rate in IRS-UAV-assisted networks. In this context, the work analyzed path loss and achievable rate utilizing millimeter wave (mmWave) carrier considering the conventional UAV model and IRS-empowered UAV communication model. The research obtained that the IRSempowered UAV communications model can significantly minimize path loss and maximize the achievable data rate compared to the conventional UAV-assisted model. ",
    "url": "https://arxiv.org/abs/2205.08423",
    "authors": [
      "Mobasshir Mahbub",
      "Raed M. Shubair"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2205.08467",
    "title": "Application of Graph Based Features in Computer Aided Diagnosis for  Histopathological Image Classification of Gastric Cancer",
    "abstract": "The gold standard for gastric cancer detection is gastric histopathological image analysis, but there are certain drawbacks in the existing histopathological detection and diagnosis. In this paper, based on the study of computer aided diagnosis system, graph based features are applied to gastric cancer histopathology microscopic image analysis, and a classifier is used to classify gastric cancer cells from benign cells. Firstly, image segmentation is performed, and after finding the region, cell nuclei are extracted using the k-means method, the minimum spanning tree (MST) is drawn, and graph based features of the MST are extracted. The graph based features are then put into the classifier for classification. In this study, different segmentation methods are compared in the tissue segmentation stage, among which are Level-Set, Otsu thresholding, watershed, SegNet, U-Net and Trans-U-Net segmentation; Graph based features, Red, Green, Blue features, Grey-Level Co-occurrence Matrix features, Histograms of Oriented Gradient features and Local Binary Patterns features are compared in the feature extraction stage; Radial Basis Function (RBF) Support Vector Machine (SVM), Linear SVM, Artificial Neural Network, Random Forests, k-NearestNeighbor, VGG16, and Inception-V3 are compared in the classifier stage. It is found that using U-Net to segment tissue areas, then extracting graph based features, and finally using RBF SVM classifier gives the optimal results with 94.29%. ",
    "url": "https://arxiv.org/abs/2205.08467",
    "authors": [
      "Haiqing Zhang",
      "Chen Li",
      "Shiliang Ai",
      "Haoyuan Chen",
      "Yuchao Zheng",
      "Yixin Li",
      "Xiaoyan Li",
      "Hongzan Sun",
      "Xinyu Huang",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.08468",
    "title": "Community Detection in networks by Dynamical Optimal Transport  Formulation",
    "abstract": "Detecting communities in networks is important in various domains of applications. While a variety of methods exists to perform this task, recent efforts propose Optimal Transport (OT) principles combined with the geometric notion of Ollivier-Ricci curvature to classify nodes into groups by rigorously comparing the information encoded into nodes' neighborhoods. We present an OT-based approach that exploits recent advances in OT theory to allow tuning for traffic penalization, which enforces different transportation schemes. As a result, our model can flexibly capture different scenarios and thus increase performance accuracy in recovering communities, compared to standard OT-based formulations. We test the performance of our algorithm in both synthetic and real networks, achieving a comparable or better performance than other OT-based methods in the former case, while finding communities more aligned with node metadata in real data. This pushes further our understanding of geometric approaches in their ability to capture patterns in complex networks. ",
    "url": "https://arxiv.org/abs/2205.08468",
    "authors": [
      "Daniela Leite",
      "Diego Baptista",
      "Abdullahi Ibrahim",
      "Enrico Facca",
      "Caterina De Bacco"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.08494",
    "title": "Covariance Estimation: Optimal Dimension-free Guarantees for Adversarial  Corruption and Heavy Tails",
    "abstract": "We provide an estimator of the covariance matrix that achieves the optimal rate of convergence (up to constant factors) in the operator norm under two standard notions of data contamination: We allow the adversary to corrupt an $\\eta$-fraction of the sample arbitrarily, while the distribution of the remaining data points only satisfies that the $L_{p}$-marginal moment with some $p \\ge 4$ is equivalent to the corresponding $L_2$-marginal moment. Despite requiring the existence of only a few moments, our estimator achieves the same tail estimates as if the underlying distribution were Gaussian. As a part of our analysis, we prove a dimension-free Bai-Yin type theorem in the regime $p > 4$. ",
    "url": "https://arxiv.org/abs/2205.08494",
    "authors": [
      "Pedro Abdalla",
      "Nikita Zhivotovskiy"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2007.02938",
    "title": "Causal Feature Selection via Orthogonal Search",
    "abstract": " Title: Causal Feature Selection via Orthogonal Search ",
    "url": "https://arxiv.org/abs/2007.02938",
    "authors": [
      "Ashkan Soleymani",
      "Anant Raj",
      "Stefan Bauer",
      "Michel Besserve",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2009.05673",
    "title": "Applications of Deep Neural Networks with Keras",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:1610.02357, arXiv:1603.05027, arXiv:1801.04381, arXiv:2001.02394, arXiv:1704.04861 by other authors ",
    "url": "https://arxiv.org/abs/2009.05673",
    "authors": [
      "Jeff Heaton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2009.07439",
    "title": "On the Landscape of One-hidden-layer Sparse Networks and Beyond",
    "abstract": " Title: On the Landscape of One-hidden-layer Sparse Networks and Beyond ",
    "url": "https://arxiv.org/abs/2009.07439",
    "authors": [
      "Dachao Lin",
      "Ruoyu Sun",
      "Zhihua Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2010.15745",
    "title": "Reinforcement Learning of Causal Variables Using Mediation Analysis",
    "abstract": " Comments: As accepted at proceedings of the AAAI Conference on Artificial Intelligence (AAAI), AAAI, 2022 ",
    "url": "https://arxiv.org/abs/2010.15745",
    "authors": [
      "Tue Herlau",
      "Rasmus Larsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2104.09350",
    "title": "A speckle filter for Sentinel-1 SAR Ground Range Detected data based on  Residual Convolutional Neural Networks",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2104.09350",
    "authors": [
      "Alessandro Sebastianelli",
      "Maria Pia Del Rosso",
      "Silvia Liberata Ullo",
      "Paolo Gamba"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2105.10882",
    "title": "Weakly-supervised 3D Human Pose Estimation with Cross-view U-shaped  Graph Convolutional Network",
    "abstract": " Comments: Accepted by IEEE Transactions on Multimedia ",
    "url": "https://arxiv.org/abs/2105.10882",
    "authors": [
      "Guoliang Hua",
      "Hong Liu",
      "Wenhao Li",
      "Qian Zhang",
      "Runwei Ding",
      "Xin Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.11225",
    "title": "Distantly-Supervised Long-Tailed Relation Extraction Using Constraint  Graphs",
    "abstract": " Comments: Accepted by TKDE as a regular paper ",
    "url": "https://arxiv.org/abs/2105.11225",
    "authors": [
      "Tianming Liang",
      "Yang Liu",
      "Xiaoyan Liu",
      "Hao Zhang",
      "Gaurav Sharma",
      "Maozu Guo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2105.12120",
    "title": "Sampling random graphs with specified degree sequences",
    "abstract": " Comments: 18 pages, 14 figures, added references and applications, methods substantially improved, results expanded. Code available at this http URL ",
    "url": "https://arxiv.org/abs/2105.12120",
    "authors": [
      "Upasana Dutta",
      "Bailey K. Fosdick",
      "Aaron Clauset"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2107.05556",
    "title": "DebiasedDTA: Improving the Generalizability of Drug-Target Affinity  Prediction Models",
    "abstract": " Title: DebiasedDTA: Improving the Generalizability of Drug-Target Affinity  Prediction Models ",
    "url": "https://arxiv.org/abs/2107.05556",
    "authors": [
      "R\u0131za \u00d6z\u00e7elik",
      "Alperen Ba\u011f",
      "Berk At\u0131l",
      "Melih Barsbey",
      "Arzucan \u00d6zg\u00fcr",
      "Elif \u00d6zk\u0131r\u0131ml\u0131"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.03861",
    "title": "KGAP: Knowledge Graph Augmented Political Perspective Detection in News  Media",
    "abstract": " Title: KGAP: Knowledge Graph Augmented Political Perspective Detection in News  Media ",
    "url": "https://arxiv.org/abs/2108.03861",
    "authors": [
      "Shangbin Feng",
      "Zilong Chen",
      "Wenqian Zhang",
      "Qingyao Li",
      "Qinghua Zheng",
      "Xiaojun Chang",
      "Minnan Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2108.04206",
    "title": "Classification Auto-Encoder based Detector against Diverse Data  Poisoning Attacks",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2108.04206",
    "authors": [
      "Fereshteh Razmi",
      "Li Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.06871",
    "title": "Data Efficient Human Intention Prediction: Leveraging Neural Network  Verification and Expert Guidance",
    "abstract": " Comments: 9 pages, 7 figures. ICML 2021 Workshop of Human in the Loop Learning ",
    "url": "https://arxiv.org/abs/2108.06871",
    "authors": [
      "Ruixuan Liu",
      "Changliu Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2109.07018",
    "title": "Discretization-independent surrogate modeling over complex geometries  using hypernetworks and implicit representations",
    "abstract": " Title: Discretization-independent surrogate modeling over complex geometries  using hypernetworks and implicit representations ",
    "url": "https://arxiv.org/abs/2109.07018",
    "authors": [
      "James Duvall",
      "Karthik Duraisamy",
      "Shaowu Pan"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.01450",
    "title": "Extended dynamic mode decomposition with dictionary learning using  neural ordinary differential equations",
    "abstract": " Comments: Corrigendum: The loss function in Eq. (20) is not what we have used in our code. Please replace the sum of squared error in Eq. (20) with the mean squared error ",
    "url": "https://arxiv.org/abs/2110.01450",
    "authors": [
      "Hiroaki Terao",
      "Sho Shirasaka",
      "Hideyuki Suzuki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Chaotic Dynamics (nlin.CD)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2111.04635",
    "title": "CORE: a COmplex event Recognition Engine",
    "abstract": " Comments: 30 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2111.04635",
    "authors": [
      "Marco Bucchi",
      "Alejandro Grez",
      "Andr\u00e9s Quintana",
      "Cristian Riveros",
      "Stijn Vansummeren"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2111.11430",
    "title": "Class-agnostic Object Detection with Multi-modal Transformer",
    "abstract": " Title: Class-agnostic Object Detection with Multi-modal Transformer ",
    "url": "https://arxiv.org/abs/2111.11430",
    "authors": [
      "Muhammad Maaz",
      "Hanoona Rasheed",
      "Salman Khan",
      "Fahad Shahbaz Khan",
      "Rao Muhammad Anwer",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.12405",
    "title": "An Attack on Facial Soft-biometric Privacy Enhancement",
    "abstract": " Title: An Attack on Facial Soft-biometric Privacy Enhancement ",
    "url": "https://arxiv.org/abs/2111.12405",
    "authors": [
      "Dail\u00e9 Osorio-Roig",
      "Christian Rathgeb",
      "Pawel Drozdowski",
      "Philipp Terh\u00f6rst",
      "Vitomir \u0160truc",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.06751",
    "title": "Role of Human-AI Interaction in Selective Prediction",
    "abstract": " Comments: Published in AAAI 2022; added link to data, small formatting corrections for camera-ready, including small changes to Fig 6-7 that do not change conclusions ",
    "url": "https://arxiv.org/abs/2112.06751",
    "authors": [
      "Elizabeth Bondi",
      "Raphael Koster",
      "Hannah Sheahan",
      "Martin Chadwick",
      "Yoram Bachrach",
      "Taylan Cemgil",
      "Ulrich Paquet",
      "Krishnamurthy Dvijotham"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2112.09245",
    "title": "Automated Deep Learning: Neural Architecture Search Is Not the End",
    "abstract": " Comments: 66 pages, 10 tables, 4 figures, 325 references; improve the old version with community feedback ",
    "url": "https://arxiv.org/abs/2112.09245",
    "authors": [
      "Xuanyi Dong",
      "David Jacob Kedziora",
      "Katarzyna Musial",
      "Bogdan Gabrys"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.13416",
    "title": "Attribute Inference Attack of Speech Emotion Recognition in Federated  Learning Settings",
    "abstract": " Title: Attribute Inference Attack of Speech Emotion Recognition in Federated  Learning Settings ",
    "url": "https://arxiv.org/abs/2112.13416",
    "authors": [
      "Tiantian Feng",
      "Hanieh Hashemi",
      "Rajat Hebbar",
      "Murali Annavaram",
      "Shrikanth S. Narayanan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2201.00323",
    "title": "V-LinkNet: Learning Contextual Inpainting Across Latent Space of  Generative Adversarial Network",
    "abstract": " Comments: 13 pages including references, 9 figures and 4 tables ",
    "url": "https://arxiv.org/abs/2201.00323",
    "authors": [
      "Jireh Jam",
      "Connah Kendrick",
      "Vincent Drouard",
      "Kevin Walker",
      "Moi Hoon Yap"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.07287",
    "title": "Polar Coded Merkle Tree: Improved Detection of Data Availability Attacks  in Blockchain Systems",
    "abstract": " Comments: 9 pages, 4 figures, 2 tables, To appear in IEEE International Symposium on Information Theory (ISIT) 2022 ",
    "url": "https://arxiv.org/abs/2201.07287",
    "authors": [
      "Debarnab Mitra",
      "Lev Tauz",
      "Lara Dolecek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.10110",
    "title": "A Hybrid Quantum-Classical Algorithm for Robust Fitting",
    "abstract": " Comments: IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR) 2022 ",
    "url": "https://arxiv.org/abs/2201.10110",
    "authors": [
      "Anh-Dzung Doan",
      "Michele Sasdelli",
      "David Suter",
      "Tat-Jun Chin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.12898",
    "title": "Clearing Payments in Dynamic Financial Networks",
    "abstract": " Title: Clearing Payments in Dynamic Financial Networks ",
    "url": "https://arxiv.org/abs/2201.12898",
    "authors": [
      "Giuseppe C. Calafiore",
      "Giulia Fracastoro",
      "Anton V. Proskurnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Systems and Control (eess.SY)",
      "Mathematical Finance (q-fin.MF)",
      "Risk Management (q-fin.RM)"
    ]
  },
  {
    "id": "arXiv:2201.13357",
    "title": "DNS: Determinantal Point Process Based Neural Network Sampler for  Ensemble Reinforcement Learning",
    "abstract": " Comments: Accepted for Publication at ICML 2022 ",
    "url": "https://arxiv.org/abs/2201.13357",
    "authors": [
      "Hassam Sheikh",
      "Kizza Frisbee",
      "Mariano Phielipp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01123",
    "title": "An ASP approach for reasoning on neural networks under a finitely  many-valued semantics for weighted conditional knowledge bases",
    "abstract": " Comments: Paper presented at the 38th International Conference on Logic Programming (ICLP 2022), 16 pages ",
    "url": "https://arxiv.org/abs/2202.01123",
    "authors": [
      "Laura Giordano",
      "Daniele Theseider Dupr\u00e9"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.09256",
    "title": "Traffic-Aware Dynamic Functional Split for 5G Cloud Radio Access  Networks",
    "abstract": " Title: Traffic-Aware Dynamic Functional Split for 5G Cloud Radio Access  Networks ",
    "url": "https://arxiv.org/abs/2202.09256",
    "authors": [
      "Himank Gupta",
      "Antony Franklin A",
      "Mayank Kumar",
      "Bheemarjuna Reddy Tamma"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2202.11099",
    "title": "Roto-Translation Equivariant Super-Resolution of Two-Dimensional Flows  Using Convolutional Neural Networks",
    "abstract": " Title: Roto-Translation Equivariant Super-Resolution of Two-Dimensional Flows  Using Convolutional Neural Networks ",
    "url": "https://arxiv.org/abs/2202.11099",
    "authors": [
      "Yuki Yasuda"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2202.12586",
    "title": "Spatio-Temporal Latent Graph Structure Learning for Traffic Forecasting",
    "abstract": " Comments: This paper has been accepted as a full paper at IJCNN 2022 ",
    "url": "https://arxiv.org/abs/2202.12586",
    "authors": [
      "Jiabin Tang",
      "Tang Qian",
      "Shijing Liu",
      "Shengdong Du",
      "Jie Hu",
      "Tianrui Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01910",
    "title": "Efficient Data Structures for Exploiting Sparsity and Structure in  Representation of Polynomial Optimization Problems: Implementation in  SOSTOOLS",
    "abstract": " Title: Efficient Data Structures for Exploiting Sparsity and Structure in  Representation of Polynomial Optimization Problems: Implementation in  SOSTOOLS ",
    "url": "https://arxiv.org/abs/2203.01910",
    "authors": [
      "Declan Jagt",
      "Sachin Shivakumar",
      "Peter Seiler",
      "Matthew Peet"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Mathematical Software (cs.MS)"
    ]
  },
  {
    "id": "arXiv:2203.10183",
    "title": "RoVISQ: Reduction of Video Service Quality via Adversarial Attacks on  Deep Learning-based Video Compression",
    "abstract": " Title: RoVISQ: Reduction of Video Service Quality via Adversarial Attacks on  Deep Learning-based Video Compression ",
    "url": "https://arxiv.org/abs/2203.10183",
    "authors": [
      "Jung-Woo Chang",
      "Mojan Javaheripi",
      "Seira Hidano",
      "Farinaz Koushanfar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.17055",
    "title": "Certified machine learning: A posteriori error estimation for  physics-informed neural networks",
    "abstract": " Title: Certified machine learning: A posteriori error estimation for  physics-informed neural networks ",
    "url": "https://arxiv.org/abs/2203.17055",
    "authors": [
      "Birgit Hillebrecht",
      "Benjamin Unger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2204.02500",
    "title": "User-Level Differential Privacy against Attribute Inference Attack of  Speech Emotion Recognition in Federated Learning",
    "abstract": " Title: User-Level Differential Privacy against Attribute Inference Attack of  Speech Emotion Recognition in Federated Learning ",
    "url": "https://arxiv.org/abs/2204.02500",
    "authors": [
      "Tiantian Feng",
      "Raghuveer Peri",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.06832",
    "title": "Self-Guided Learning to Denoise for Robust Recommendation",
    "abstract": " Comments: Accepted by SIGIR2022 ",
    "url": "https://arxiv.org/abs/2204.06832",
    "authors": [
      "Yunjun Gao",
      "Yuntao Du",
      "Yujia Hu",
      "Lu Chen",
      "Xinjun Zhu",
      "Ziquan Fang",
      "Baihua Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2204.08182",
    "title": "Modality-Balanced Embedding for Video Retrieval",
    "abstract": " Comments: Accepted by SIGIR-2022, short paper ",
    "url": "https://arxiv.org/abs/2204.08182",
    "authors": [
      "Xun Wang",
      "Bingqing Ke",
      "Xuanping Li",
      "Fangyu Liu",
      "Mingyu Zhang",
      "Xiao Liang",
      "Qiushi Xiao",
      "Cheng Luo",
      "Yue Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.13821",
    "title": "A Neural Network-enhanced Reproducing Kernel Particle Method for  Modeling Strain Localization",
    "abstract": " Title: A Neural Network-enhanced Reproducing Kernel Particle Method for  Modeling Strain Localization ",
    "url": "https://arxiv.org/abs/2204.13821",
    "authors": [
      "Jonghyuk Baek",
      "Jiun-Shyan Chen",
      "Kristen Susuki"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2205.04411",
    "title": "Model-Contrastive Learning for Backdoor Defense",
    "abstract": " Title: Model-Contrastive Learning for Backdoor Defense ",
    "url": "https://arxiv.org/abs/2205.04411",
    "authors": [
      "Zhihao Yue",
      "Jun Xia",
      "Zhiwei Ling",
      "Ming Hu",
      "Ting Wang",
      "Xian Wei",
      "Mingsong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.04546",
    "title": "CODEC: Complex Document and Entity Collection",
    "abstract": " Comments: 10 pages, SIGIR 2022 Preprint ",
    "url": "https://arxiv.org/abs/2205.04546",
    "authors": [
      "Iain Mackie",
      "Paul Owoicho",
      "Carlos Gemmell",
      "Sophie Fischer",
      "Sean MacAvaney",
      "Jeffrey Dalton"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2205.06296",
    "title": "Integrating User and Item Reviews in Deep Cooperative Neural Networks  for Movie Recommendation",
    "abstract": " Comments: 13 pages, typos corrected, references added ",
    "url": "https://arxiv.org/abs/2205.06296",
    "authors": [
      "Aristeidis Karras",
      "Christos Karras"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.06401",
    "title": "PoisonedEncoder: Poisoning the Unlabeled Pre-training Data in  Contrastive Learning",
    "abstract": " Comments: To appear in USENIX Security Symposium, 2022 ",
    "url": "https://arxiv.org/abs/2205.06401",
    "authors": [
      "Hongbin Liu",
      "Jinyuan Jia",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.06445",
    "title": "Personalized Adversarial Data Augmentation for Dysarthric and Elderly  Speech Recognition",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2202.10290 ",
    "url": "https://arxiv.org/abs/2205.06445",
    "authors": [
      "Zengrui Jin",
      "Mengzhe Geng",
      "Jiajun Deng",
      "Tianzi Wang",
      "Shujie Hu",
      "Guinan Li",
      "Xunying Liu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.07266",
    "title": "Discovering the Representation Bottleneck of Graph Neural Networks from  Multi-order Interactions",
    "abstract": " Title: Discovering the Representation Bottleneck of Graph Neural Networks from  Multi-order Interactions ",
    "url": "https://arxiv.org/abs/2205.07266",
    "authors": [
      "Fang Wu",
      "Siyuan Li",
      "Lirong Wu",
      "Stan Z. Li",
      "Dragomir Radev",
      "Qiang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.07556",
    "title": "An Effective Transformer-based Solution for RSNA Intracranial Hemorrhage  Detection Competition",
    "abstract": " Title: An Effective Transformer-based Solution for RSNA Intracranial Hemorrhage  Detection Competition ",
    "url": "https://arxiv.org/abs/2205.07556",
    "authors": [
      "Fangxin Shang",
      "Siqi Wang",
      "Yehui Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.07829",
    "title": "Federated Anomaly Detection over Distributed Data Streams",
    "abstract": " Comments: DSAA'2021 Conference - PhD Track ",
    "url": "https://arxiv.org/abs/2205.07829",
    "authors": [
      "Paula Raissa Silva",
      "Jo\u00e3o Vinagre",
      "Jo\u00e3o Gama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  }
]