[
  {
    "id": "arXiv:2205.01094",
    "title": "A Word is Worth A Thousand Dollars: Adversarial Attack on Tweets Fools  Stock Prediction",
    "abstract": "More and more investors and machine learning models rely on social media (e.g., Twitter and Reddit) to gather real-time information and sentiment to predict stock price movements. Although text-based models are known to be vulnerable to adversarial attacks, whether stock prediction models have similar vulnerability is underexplored. In this paper, we experiment with a variety of adversarial attack configurations to fool three stock prediction victim models. We address the task of adversarial generation by solving combinatorial optimization problems with semantics and budget constraints. Our results show that the proposed attack method can achieve consistent success rates and cause significant monetary loss in trading simulation by simply concatenating a perturbed but semantically similar tweet. ",
    "url": "https://arxiv.org/abs/2205.01094",
    "authors": [
      "Yong Xie",
      "Dakuo Wang",
      "Pin-Yu Chen",
      "Jinjun Xiong",
      "Sijia Liu",
      "Sanmi Koyejo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)"
    ]
  },
  {
    "id": "arXiv:2205.01135",
    "title": "D-DPCC: Deep Dynamic Point Cloud Compression via 3D Motion Prediction",
    "abstract": "The non-uniformly distributed nature of the 3D dynamic point cloud (DPC) brings significant challenges to its high-efficient inter-frame compression. This paper proposes a novel 3D sparse convolution-based Deep Dynamic Point Cloud Compression (D-DPCC) network to compensate and compress the DPC geometry with 3D motion estimation and motion compensation in the feature space. In the proposed D-DPCC network, we design a {\\it Multi-scale Motion Fusion} (MMF) module to accurately estimate the 3D optical flow between the feature representations of adjacent point cloud frames. Specifically, we utilize a 3D sparse convolution-based encoder to obtain the latent representation for motion estimation in the feature space and introduce the proposed MMF module for fused 3D motion embedding. Besides, for motion compensation, we propose a 3D {\\it Adaptively Weighted Interpolation} (3DAWI) algorithm with a penalty coefficient to adaptively decrease the impact of distant neighbors. We compress the motion embedding and the residual with a lossy autoencoder-based network. To our knowledge, this paper is the first work proposing an end-to-end deep dynamic point cloud compression framework. The experimental result shows that the proposed D-DPCC framework achieves an average 76\\% BD-Rate (Bjontegaard Delta Rate) gains against state-of-the-art Video-based Point Cloud Compression (V-PCC) v13 in inter mode. ",
    "url": "https://arxiv.org/abs/2205.01135",
    "authors": [
      "Tingyu Fan",
      "Linyao Gao",
      "Yiling Xu",
      "Zhu Li",
      "Dong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.01159",
    "title": "Saliency map using features derived from spiking neural networks of  primate visual cortex",
    "abstract": "We propose a framework inspired by biological vision systems to produce saliency maps of digital images. Well-known computational models for receptive fields of areas in the visual cortex that are specialized for color and orientation perception are used. To model the connectivity between these areas we use the CARLsim library which is a spiking neural network(SNN) simulator. The spikes generated by CARLsim, then serve as extracted features and input to our saliency detection algorithm. This new method of saliency detection is described and applied to benchmark images. ",
    "url": "https://arxiv.org/abs/2205.01159",
    "authors": [
      "Reza Hojjaty Saeedy",
      "Richard A. Messner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01167",
    "title": "3D Convolutional Neural Networks for Dendrite Segmentation Using  Fine-Tuning and Hyperparameter Optimization",
    "abstract": "Dendritic microstructures are ubiquitous in nature and are the primary solidification morphologies in metallic materials. Techniques such as x-ray computed tomography (XCT) have provided new insights into dendritic phase transformation phenomena. However, manual identification of dendritic morphologies in microscopy data can be both labor intensive and potentially ambiguous. The analysis of 3D datasets is particularly challenging due to their large sizes (terabytes) and the presence of artifacts scattered within the imaged volumes. In this study, we trained 3D convolutional neural networks (CNNs) to segment 3D datasets. Three CNN architectures were investigated, including a new 3D version of FCDense. We show that using hyperparameter optimization (HPO) and fine-tuning techniques, both 2D and 3D CNN architectures can be trained to outperform the previous state of the art. The 3D U-Net architecture trained in this study produced the best segmentations according to quantitative metrics (pixel-wise accuracy of 99.84% and a boundary displacement error of 0.58 pixels), while 3D FCDense produced the smoothest boundaries and best segmentations according to visual inspection. The trained 3D CNNs are able to segment entire 852 x 852 x 250 voxel 3D volumes in only ~60 seconds, thus hastening the progress towards a deeper understanding of phase transformation phenomena such as dendritic solidification. ",
    "url": "https://arxiv.org/abs/2205.01167",
    "authors": [
      "Jim James",
      "Nathan Pruyne",
      "Tiberiu Stan",
      "Marcus Schwarting",
      "Jiwon Yeom",
      "Seungbum Hong",
      "Peter Voorhees",
      "Ben Blaiszik",
      "Ian Foster"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.01179",
    "title": "VAE-Loco: Versatile Quadruped Locomotion by Learning a Disentangled Gait  Representation",
    "abstract": "Quadruped locomotion is rapidly maturing to a degree where robots now routinely traverse a variety of unstructured terrains. However, while gaits can be varied typically by selecting from a range of pre-computed styles, current planners are unable to vary key gait parameters continuously while the robot is in motion. The synthesis, on-the-fly, of gaits with unexpected operational characteristics or even the blending of dynamic manoeuvres lies beyond the capabilities of the current state-of-the-art. In this work we address this limitation by learning a latent space capturing the key stance phases constituting a particular gait. This is achieved via a generative model trained on a single trot style, which encourages disentanglement such that application of a drive signal to a single dimension of the latent state induces holistic plans synthesising a continuous variety of trot styles. We demonstrate that specific properties of the drive signal map directly to gait parameters such as cadence, footstep height and full stance duration. Due to the nature of our approach these synthesised gaits are continuously variable online during robot operation and robustly capture a richness of movement significantly exceeding the relatively narrow behaviour seen during training. In addition, the use of a generative model facilitates the detection and mitigation of disturbances to provide a versatile and robust planning framework. We evaluate our approach on two versions of the real ANYmal quadruped robots and demonstrate that our method achieves a continuous blend of dynamic trot styles whilst being robust and reactive to external perturbations. ",
    "url": "https://arxiv.org/abs/2205.01179",
    "authors": [
      "Alexander L. Mitchell",
      "Wolfgang Merkt",
      "Mathieu Geisert",
      "Siddhant Gangapurwala",
      "Martin Engelcke",
      "Oiwi Parker Jones",
      "Ioannis Havoutis",
      "Ingmar Posner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01184",
    "title": "Performance Weighting for Robust Federated Learning Against Corrupted  Sources",
    "abstract": "Federated Learning has emerged as a dominant computational paradigm for distributed machine learning. Its unique data privacy properties allow us to collaboratively train models while offering participating clients certain privacy-preserving guarantees. However, in real-world applications, a federated environment may consist of a mixture of benevolent and malicious clients, with the latter aiming to corrupt and degrade federated model's performance. Different corruption schemes may be applied such as model poisoning and data corruption. Here, we focus on the latter, the susceptibility of federated learning to various data corruption attacks. We show that the standard global aggregation scheme of local weights is inefficient in the presence of corrupted clients. To mitigate this problem, we propose a class of task-oriented performance-based methods computed over a distributed validation dataset with the goal to detect and mitigate corrupted clients. Specifically, we construct a robust weight aggregation scheme based on geometric mean and demonstrate its effectiveness under random label shuffling and targeted label flipping attacks. ",
    "url": "https://arxiv.org/abs/2205.01184",
    "authors": [
      "Dimitris Stripelis",
      "Marcin Abram",
      "Jose Luis Ambite"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.01198",
    "title": "NHA12D: A New Pavement Crack Dataset and a Comparison Study Of Crack  Detection Algorithms",
    "abstract": "Crack detection plays a key role in automated pavement inspection. Although a large number of algorithms have been developed in recent years to further boost performance, there are still remaining challenges in practice, due to the complexity of pavement images. To further accelerate the development and identify the remaining challenges, this paper conducts a comparison study to evaluate the performance of the state of the art crack detection algorithms quantitatively and objectively. A more comprehensive annotated pavement crack dataset (NHA12D) that contains images with different viewpoints and pavements types is proposed. In the comparison study, crack detection algorithms were trained equally on the largest public crack dataset collected and evaluated on the proposed dataset (NHA12D). Overall, the U-Net model with VGG-16 as backbone has the best all-around performance, but models generally fail to distinguish cracks from concrete joints, leading to a high false-positive rate. It also found that detecting cracks from concrete pavement images still has huge room for improvement. Dataset for concrete pavement images is also missing in the literature. Future directions in this area include filling the gap for concrete pavement images and using domain adaptation techniques to enhance the detection results on unseen datasets. ",
    "url": "https://arxiv.org/abs/2205.01198",
    "authors": [
      "Zhening Huang",
      "Weiwei Chen",
      "Abir Al-Tabbaa",
      "Ioannis Brilakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.01202",
    "title": "POCD: Probabilistic Object-Level Change Detection and Volumetric Mapping  in Semi-Static Scenes",
    "abstract": "Maintaining an up-to-date map to reflect recent changes in the scene is very important, particularly in situations involving repeated traversals by a robot operating in an environment over an extended period. Undetected changes may cause a deterioration in map quality, leading to poor localization, inefficient operations, and lost robots. Volumetric methods, such as truncated signed distance functions (TSDFs), have quickly gained traction due to their real-time production of a dense and detailed map, though map updating in scenes that change over time remains a challenge. We propose a framework that introduces a novel probabilistic object state representation to track object pose changes in semi-static scenes. The representation jointly models a stationarity score and a TSDF change measure for each object. A Bayesian update rule that incorporates both geometric and semantic information is derived to achieve consistent online map maintenance. To extensively evaluate our approach alongside the state-of-the-art, we release a novel real-world dataset in a warehouse environment. We also evaluate on the public ToyCar dataset. Our method outperforms state-of-the-art methods on the reconstruction quality of semi-static environments. ",
    "url": "https://arxiv.org/abs/2205.01202",
    "authors": [
      "Jingxing Qian",
      "Veronica Chatrath",
      "Jun Yang",
      "James Servos",
      "Angela P. Schoellig",
      "Steven L. Waslander"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.01204",
    "title": "Multi-Task Text Classification using Graph Convolutional Networks for  Large-Scale Low Resource Language",
    "abstract": "Graph Convolutional Networks (GCN) have achieved state-of-art results on single text classification tasks like sentiment analysis, emotion detection, etc. However, the performance is achieved by testing and reporting on resource-rich languages like English. Applying GCN for multi-task text classification is an unexplored area. Moreover, training a GCN or adopting an English GCN for Indian languages is often limited by data availability, rich morphological variation, syntax, and semantic differences. In this paper, we study the use of GCN for the Telugu language in single and multi-task settings for four natural language processing (NLP) tasks, viz. sentiment analysis (SA), emotion identification (EI), hate-speech (HS), and sarcasm detection (SAR). In order to evaluate the performance of GCN with one of the Indian languages, Telugu, we analyze the GCN based models with extensive experiments on four downstream tasks. In addition, we created an annotated Telugu dataset, TEL-NLP, for the four NLP tasks. Further, we propose a supervised graph reconstruction method, Multi-Task Text GCN (MT-Text GCN) on the Telugu that leverages to simultaneously (i) learn the low-dimensional word and sentence graph embeddings from word-sentence graph reconstruction using graph autoencoder (GAE) and (ii) perform multi-task text classification using these latent sentence graph embeddings. We argue that our proposed MT-Text GCN achieves significant improvements on TEL-NLP over existing Telugu pretrained word embeddings, and multilingual pretrained Transformer models: mBERT, and XLM-R. On TEL-NLP, we achieve a high F1-score for four NLP tasks: SA (0.84), EI (0.55), HS (0.83) and SAR (0.66). Finally, we show our model's quantitative and qualitative analysis on the four NLP tasks in Telugu. ",
    "url": "https://arxiv.org/abs/2205.01204",
    "authors": [
      "Mounika Marreddy",
      "Subba Reddy Oota",
      "Lakshmi Sireesha Vakada",
      "Venkata Charan Chinni",
      "Radhika Mamidi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01214",
    "title": "An improvement to a result about graph isomorphism networks using the  prime factorization theorem",
    "abstract": "The unique prime factorization theorem is used to show the existence of a function on a countable set $\\mathcal{X}$ so that the sum aggregator function is injective on all multisets of $\\mathcal{X}$ of finite size. ",
    "url": "https://arxiv.org/abs/2205.01214",
    "authors": [
      "Rahul Sarkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01225",
    "title": "A Hybrid Defense Method against Adversarial Attacks on Traffic Sign  Classifiers in Autonomous Vehicles",
    "abstract": "Adversarial attacks can make deep neural network (DNN) models predict incorrect output labels, such as misclassified traffic signs, for autonomous vehicle (AV) perception modules. Resilience against adversarial attacks can help AVs navigate safely on the road by avoiding misclassication of signs or objects. This DNN-based study develops a resilient traffic sign classifier for AVs that uses a hybrid defense method. We use transfer learning to retrain the Inception-V3 and Resnet-152 models as traffic sign classifiers. This method also utilizes a combination of three different strategies: random filtering, ensembling, and local feature mapping. We use the random cropping and resizing technique for random filtering, plurality voting as ensembling strategy and an optical character recognition model as a local feature mapper. This DNN-based hybrid defense method has been tested for the no attack scenario and against well-known untargeted adversarial attacks (e.g., Projected Gradient Descent or PGD, Fast Gradient Sign Method or FGSM, Momentum Iterative Method or MIM attack, and Carlini and Wagner or C&W). We find that our hybrid defense method achieves 99% average traffic sign classification accuracy for the no attack scenario and 88% average traffic sign classification accuracy for all attack scenarios. Moreover, the hybrid defense method, presented in this study, improves the accuracy for traffic sign classification compared to the traditional defense methods (i.e., JPEG filtering, feature squeezing, binary filtering, and random filtering) up to 6%, 50%, and 55% for FGSM, MIM, and PGD attacks, respectively. ",
    "url": "https://arxiv.org/abs/2205.01225",
    "authors": [
      "Zadid Khan",
      "Mashrur Chowdhury",
      "Sakib Mahmud Khan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01226",
    "title": "Adversarial attacks on an optical neural network",
    "abstract": "Adversarial attacks have been extensively investigated for machine learning systems including deep learning in the digital domain. However, the adversarial attacks on optical neural networks (ONN) have been seldom considered previously. In this work, we first construct an accurate image classifier with an ONN using a mesh of interconnected Mach-Zehnder interferometers (MZI). Then a corresponding adversarial attack scheme is proposed for the first time. The attacked images are visually very similar to the original ones but the ONN system becomes malfunctioned and generates wrong classification results in most time. The results indicate that adversarial attack is also a significant issue for optical machine learning systems. ",
    "url": "https://arxiv.org/abs/2205.01226",
    "authors": [
      "Shuming Jiao",
      "Ziwei Song",
      "Shuiying Xiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01229",
    "title": "DCoflow: Deadline-Aware Scheduling Algorithm for Coflows in Datacenter  Networks",
    "abstract": "Datacenter networks routinely support the data transfers of distributed computing frameworks in the form of coflows, i.e., sets of concurrent flows related to a common task. The vast majority of the literature has focused on the problem of scheduling coflows for completion time minimization, i.e., to maximize the average rate at which coflows are dispatched in the network fabric. Modern applications, though, may generate coflows dedicated to online services and mission-critical computing tasks which have to comply with specific completion deadlines. In this paper, we introduce $\\mathtt{DCoflow}$, a lightweight deadline-aware scheduler for time-critical coflows in datacenter networks. The algorithm combines an online joint admission control and scheduling logic and returns a $\\sigma$-order schedule which maximizes the number of coflows that attain their deadlines. Extensive numerical results demonstrate that the proposed solution outperforms existing ones. ",
    "url": "https://arxiv.org/abs/2205.01229",
    "authors": [
      "Quang-Trung Luu",
      "Olivier Brun",
      "Rachid El-Azouzi",
      "Francesco De Pellegrini",
      "Balakrishna J. Prabhu",
      "C\u00e9dric Richier"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.01231",
    "title": "ADDAI: Anomaly Detection using Distributed AI",
    "abstract": "When dealing with the Internet of Things (IoT), especially industrial IoT (IIoT), two manifest challenges leap to mind. First is the massive amount of data streaming to and from IoT devices, and second is the fast pace at which these systems must operate. Distributed computing in the form of edge/cloud structure is a popular technique to overcome these two challenges. In this paper, we propose ADDAI (Anomaly Detection using Distributed AI) that can easily span out geographically to cover a large number of IoT sources. Due to its distributed nature, it guarantees critical IIoT requirements such as high speed, robustness against a single point of failure, low communication overhead, privacy, and scalability. Through empirical proof, we show the communication cost is minimized, and the performance improves significantly while maintaining the privacy of raw data at the local layer. ADDAI provides predictions for new random samples with an average success rate of 98.4% while reducing the communication overhead by half compared with the traditional technique of offloading all the raw sensor data to the cloud. ",
    "url": "https://arxiv.org/abs/2205.01231",
    "authors": [
      "Maede Zolanvari",
      "Ali Ghubaish",
      "Raj Jain"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.01234",
    "title": "Scalable Tail Latency Estimation for Data Center Networks",
    "abstract": "In this paper, we consider how to provide fast estimates of flow-level tail latency performance for very large scale data center networks. Network tail latency is often a crucial metric for cloud application performance that can be affected by a wide variety of factors, including network load, inter-rack traffic skew, traffic burstiness, flow size distributions, oversubscription, and topology asymmetry. Network simulators such as ns-3 and OMNeT++ can provide accurate answers, but are very hard to parallelize, taking hours or days to answer what if questions for a single configuration at even moderate scale. Recent work with MimicNet has shown how to use machine learning to improve simulation performance, but at a cost of including a long training step per configuration, and with assumptions about workload and topology uniformity that typically do not hold in practice. We address this gap by developing a set of techniques to provide fast performance estimates for large scale networks with general traffic matrices and topologies. A key step is to decompose the problem into a large number of parallel independent single-link simulations; we carefully combine these link-level simulations to produce accurate estimates of end-to-end flow level performance distributions for the entire network. Like MimicNet, we exploit symmetry where possible to gain additional speedups, but without relying on machine learning, so there is no training delay. On large-scale networks where ns-3 takes 11 to 27 hours to simulate five seconds of network behavior, our techniques run in one to two minutes with 99th percentile accuracy within 9% for flow completion times. ",
    "url": "https://arxiv.org/abs/2205.01234",
    "authors": [
      "Kevin Zhao",
      "Prateesh Goyal",
      "Mohammad Alizadeh",
      "Thomas E. Anderson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.01235",
    "title": "Triangular Dropout: Variable Network Width without Retraining",
    "abstract": "One of the most fundamental design choices in neural networks is layer width: it affects the capacity of what a network can learn and determines the complexity of the solution. This latter property is often exploited when introducing information bottlenecks, forcing a network to learn compressed representations. However, such an architecture decision is typically immutable once training begins; switching to a more compressed architecture requires retraining. In this paper we present a new layer design, called Triangular Dropout, which does not have this limitation. After training, the layer can be arbitrarily reduced in width to exchange performance for narrowness. We demonstrate the construction and potential use cases of such a mechanism in three areas. Firstly, we describe the formulation of Triangular Dropout in autoencoders, creating models with selectable compression after training. Secondly, we add Triangular Dropout to VGG19 on ImageNet, creating a powerful network which, without retraining, can be significantly reduced in parameters. Lastly, we explore the application of Triangular Dropout to reinforcement learning (RL) policies on selected control problems. ",
    "url": "https://arxiv.org/abs/2205.01235",
    "authors": [
      "Edward W. Staley",
      "Jared Markowitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.01240",
    "title": "Using Constraint Programming and Graph Representation Learning for  Generating Interpretable Cloud Security Policies",
    "abstract": "Modern software systems rely on mining insights from business sensitive data stored in public clouds. A data breach usually incurs significant (monetary) loss for a commercial organization. Conceptually, cloud security heavily relies on Identity Access Management (IAM) policies that IT admins need to properly configure and periodically update. Security negligence and human errors often lead to misconfiguring IAM policies which may open a backdoor for attackers. To address these challenges, first, we develop a novel framework that encodes generating optimal IAM policies using constraint programming (CP). We identify reducing dark permissions of cloud users as an optimality criterion, which intuitively implies minimizing unnecessary datastore access permissions. Second, to make IAM policies interpretable, we use graph representation learning applied to historical access patterns of users to augment our CP model with similarity constraints: similar users should be grouped together and share common IAM policies. Third, we describe multiple attack models and show that our optimized IAM policies significantly reduce the impact of security attacks using real data from 8 commercial organizations, and synthetic instances. ",
    "url": "https://arxiv.org/abs/2205.01240",
    "authors": [
      "Mikhail Kazdagli",
      "Mohit Tiwari",
      "Akshat Kumar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.01258",
    "title": "Universal Optimality and Robust Utility Bounds for Metric Differential  Privacy",
    "abstract": "We study the privacy-utility trade-off in the context of metric differential privacy. Ghosh et al. introduced the idea of universal optimality to characterise the best mechanism for a certain query that simultaneously satisfies (a fixed) $\\epsilon$-differential privacy constraint whilst at the same time providing better utility compared to any other $\\epsilon$-differentially private mechanism for the same query. They showed that the Geometric mechanism is \"universally optimal\" for the class of counting queries. On the other hand, Brenner and Nissim showed that outside the space of counting queries, and for the Bayes risk loss function, no such universally optimal mechanisms exist. In this paper we use metric differential privacy and quantitative information flow as the fundamental principle for studying universal optimality. Metric differential privacy is a generalisation of both standard (i.e., central) differential privacy and local differential privacy, and it is increasingly being used in various application domains, for instance in location privacy and in privacy preserving machine learning. Using this framework we are able to clarify Nissim and Brenner's negative results, showing (a) that in fact all privacy types contain optimal mechanisms relative to certain kinds of non-trivial loss functions, and (b) extending and generalising their negative results beyond Bayes risk specifically to a wide class of non-trivial loss functions. We also propose weaker universal benchmarks of utility called \"privacy type capacities\". We show that such capacities always exist and can be computed using a convex optimisation algorithm. ",
    "url": "https://arxiv.org/abs/2205.01258",
    "authors": [
      "Natasha Fernandes",
      "Annabelle McIver",
      "Catuscia Palamidessi",
      "Ming Ding"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.01286",
    "title": "When Multi-Level Meets Multi-Interest: A Multi-Grained Neural Model for  Sequential Recommendation",
    "abstract": "Sequential recommendation aims at identifying the next item that is preferred by a user based on their behavioral history. Compared to conventional sequential models that leverage attention mechanisms and RNNs, recent efforts mainly follow two directions for improvement: multi-interest learning and graph convolutional aggregation. Specifically, multi-interest methods such as ComiRec and MIMN, focus on extracting different interests for a user by performing historical item clustering, while graph convolution methods including TGSRec and SURGE elect to refine user preferences based on multi-level correlations between historical items. Unfortunately, neither of them realizes that these two types of solutions can mutually complement each other, by aggregating multi-level user preference to achieve more precise multi-interest extraction for a better recommendation. To this end, in this paper, we propose a unified multi-grained neural model(named MGNM) via a combination of multi-interest learning and graph convolutional aggregation. Concretely, MGNM first learns the graph structure and information aggregation paths of the historical items for a user. It then performs graph convolution to derive item representations in an iterative fashion, in which the complex preferences at different levels can be well captured. Afterwards, a novel sequential capsule network is proposed to inject the sequential patterns into the multi-interest extraction process, leading to a more precise interest learning in a multi-grained manner. ",
    "url": "https://arxiv.org/abs/2205.01286",
    "authors": [
      "Yu Tian",
      "Jianxin Chang",
      "Yannan Niu",
      "Yang Song",
      "Chenliang Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2205.01287",
    "title": "SemAttack: Natural Textual Attacks via Different Semantic Spaces",
    "abstract": "Recent studies show that pre-trained language models (LMs) are vulnerable to textual adversarial attacks. However, existing attack methods either suffer from low attack success rates or fail to search efficiently in the exponentially large perturbation space. We propose an efficient and effective framework SemAttack to generate natural adversarial text by constructing different semantic perturbation functions. In particular, SemAttack optimizes the generated perturbations constrained on generic semantic spaces, including typo space, knowledge space (e.g., WordNet), contextualized semantic space (e.g., the embedding space of BERT clusterings), or the combination of these spaces. Thus, the generated adversarial texts are more semantically close to the original inputs. Extensive experiments reveal that state-of-the-art (SOTA) large-scale LMs (e.g., DeBERTa-v2) and defense strategies (e.g., FreeLB) are still vulnerable to SemAttack. We further demonstrate that SemAttack is general and able to generate natural adversarial texts for different languages (e.g., English and Chinese) with high attack success rates. Human evaluations also confirm that our generated adversarial texts are natural and barely affect human performance. Our code is publicly available at https://github.com/AI-secure/SemAttack. ",
    "url": "https://arxiv.org/abs/2205.01287",
    "authors": [
      "Boxin Wang",
      "Chejian Xu",
      "Xiangyu Liu",
      "Yu Cheng",
      "Bo Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.01291",
    "title": "Cross Domain Object Detection by Target-Perceived Dual Branch  Distillation",
    "abstract": "Cross domain object detection is a realistic and challenging task in the wild. It suffers from performance degradation due to large shift of data distributions and lack of instance-level annotations in the target domain. Existing approaches mainly focus on either of these two difficulties, even though they are closely coupled in cross domain object detection. To solve this problem, we propose a novel Target-perceived Dual-branch Distillation (TDD) framework. By integrating detection branches of both source and target domains in a unified teacher-student learning scheme, it can reduce domain shift and generate reliable supervision effectively. In particular, we first introduce a distinct Target Proposal Perceiver between two domains. It can adaptively enhance source detector to perceive objects in a target image, by leveraging target proposal contexts from iterative cross-attention. Afterwards, we design a concise Dual Branch Self Distillation strategy for model training, which can progressively integrate complementary object knowledge from different domains via self-distillation in two branches. Finally, we conduct extensive experiments on a number of widely-used scenarios in cross domain object detection. The results show that our TDD significantly outperforms the state-of-the-art methods on all the benchmarks. Our code and model will be available at https://github.com/Feobi1999/TDD. ",
    "url": "https://arxiv.org/abs/2205.01291",
    "authors": [
      "Mengzhe He",
      "Yali Wang",
      "Jiaxi Wu",
      "Yiru Wang",
      "Hanqing Li",
      "Bo Li",
      "Weihao Gan",
      "Wei Wu",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01293",
    "title": "A Survey of Deep Learning Models for Structural Code Understanding",
    "abstract": "In recent years, the rise of deep learning and automation requirements in the software industry has elevated Intelligent Software Engineering to new heights. The number of approaches and applications in code understanding is growing, with deep learning techniques being used in many of them to better capture the information in code data. In this survey, we present a comprehensive overview of the structures formed from code data. We categorize the models for understanding code in recent years into two groups: sequence-based and graph-based models, further make a summary and comparison of them. We also introduce metrics, datasets and the downstream tasks. Finally, we make some suggestions for future research in structural code understanding field. ",
    "url": "https://arxiv.org/abs/2205.01293",
    "authors": [
      "Ruoting Wu",
      "Yuxin Zhang",
      "Qibiao Peng",
      "Liang Chen",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "General Literature (cs.GL)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2205.01297",
    "title": "RU-Net: Regularized Unrolling Network for Scene Graph Generation",
    "abstract": "Scene graph generation (SGG) aims to detect objects and predict the relationships between each pair of objects. Existing SGG methods usually suffer from several issues, including 1) ambiguous object representations, as graph neural network-based message passing (GMP) modules are typically sensitive to spurious inter-node correlations, and 2) low diversity in relationship predictions due to severe class imbalance and a large number of missing annotations. To address both problems, in this paper, we propose a regularized unrolling network (RU-Net). We first study the relation between GMP and graph Laplacian denoising (GLD) from the perspective of the unrolling technique, determining that GMP can be formulated as a solver for GLD. Based on this observation, we propose an unrolled message passing module and introduce an $\\ell_p$-based graph regularization to suppress spurious connections between nodes. Second, we propose a group diversity enhancement module that promotes the prediction diversity of relationships via rank maximization. Systematic experiments demonstrate that RU-Net is effective under a variety of settings and metrics. Furthermore, RU-Net achieves new state-of-the-arts on three popular databases: VG, VRD, and OI. Code is available at https://github.com/siml3/RU-Net. ",
    "url": "https://arxiv.org/abs/2205.01297",
    "authors": [
      "Xin Lin",
      "Changxing Ding",
      "Jing Zhang",
      "Yibing Zhan",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01300",
    "title": "Towards an Ensemble Regressor Model for Anomalous ISP Traffic Prediction",
    "abstract": "Prediction of network traffic behavior is significant for the effective management of modern telecommunication networks. However, the intuitive approach of predicting network traffic using administrative experience and market analysis data is inadequate for an efficient forecast framework. As a result, many different mathematical models have been studied to capture the general trend of the network traffic and predict accordingly. But the comprehensive performance analysis of varying regression models and their ensemble has not been studied before for analyzing real-world anomalous traffic. In this paper, several regression models such as Extra Gradient Boost (XGBoost), Light Gradient Boosting Machine (LightGBM), Stochastic Gradient Descent (SGD), Gradient Boosting Regressor (GBR), and CatBoost Regressor were analyzed to predict real traffic without and with outliers and show the significance of outlier detection in real-world traffic prediction. Also, we showed the outperformance of the ensemble regression model over the individual prediction model. We compared the performance of different regression models based on five different feature sets of lengths 6, 9, 12, 15, and 18. Our ensemble regression model achieved the minimum average gap of 5.04% between actual and predicted traffic with nine outlier-adjusted inputs. In general, our experimental results indicate that the outliers in the data can significantly impact the quality of the prediction. Thus, outlier detection and mitigation assist the regression model in learning the general trend and making better predictions. ",
    "url": "https://arxiv.org/abs/2205.01300",
    "authors": [
      "Sajal Saha",
      "Anwar Haque",
      "Greg Sidebottom"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.01306",
    "title": "CANShield: Signal-based Intrusion Detection for Controller Area Networks",
    "abstract": "Modern vehicles rely on a fleet of electronic control units (ECUs) connected through controller area network (CAN) buses for critical vehicular control. However, with the expansion of advanced connectivity features in automobiles and the elevated risks of internal system exposure, the CAN bus is increasingly prone to intrusions and injection attacks. The ordinary injection attacks disrupt the typical timing properties of the CAN data stream, and the rule-based intrusion detection systems (IDS) can easily detect them. However, advanced attackers can inject false data to the time series sensory data (signal), while looking innocuous by the pattern/frequency of the CAN messages. Such attacks can bypass the rule-based IDS or any anomaly-based IDS built on binary payload data. To make the vehicles robust against such intelligent attacks, we propose CANShield, a signal-based intrusion detection framework for the CAN bus. CANShield consists of three modules: a data preprocessing module that handles the high-dimensional CAN data stream at the signal level and makes them suitable for a deep learning model; a data analyzer module consisting of multiple deep autoencoder (AE) networks, each analyzing the time-series data from a different temporal perspective; and finally an attack detection module that uses an ensemble method to make the final decision. Evaluation results on two high-fidelity signal-based CAN attack datasets show the high accuracy and responsiveness of CANShield in detecting wide-range of advanced intrusion attacks. ",
    "url": "https://arxiv.org/abs/2205.01306",
    "authors": [
      "Md Hasan Shahriar",
      "Yang Xiao",
      "Pablo Moriano",
      "Wenjing Lou",
      "Y. Thomas Hou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01307",
    "title": "Embedding Hallucination for Few-Shot Language Fine-tuning",
    "abstract": "Few-shot language learners adapt knowledge from a pre-trained model to recognize novel classes from a few-labeled sentences. In such settings, fine-tuning a pre-trained language model can cause severe over-fitting. In this paper, we propose an Embedding Hallucination (EmbedHalluc) method, which generates auxiliary embedding-label pairs to expand the fine-tuning dataset. The hallucinator is trained by playing an adversarial game with the discriminator, such that the hallucinated embedding is indiscriminative to the real ones in the fine-tuning dataset. By training with the extended dataset, the language learner effectively learns from the diverse hallucinated embeddings to overcome the over-fitting issue. Experiments demonstrate that our proposed method is effective in a wide range of language tasks, outperforming current fine-tuning methods. Further, we show that EmbedHalluc outperforms other methods that address this over-fitting problem, such as common data augmentation, semi-supervised pseudo-labeling, and regularization. The code will be made available at: https://github.com/yiren-jian/EmbedHalluc. ",
    "url": "https://arxiv.org/abs/2205.01307",
    "authors": [
      "Yiren Jian",
      "Chongyang Gao",
      "Soroush Vosoughi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.01310",
    "title": "FedRN: Exploiting k-Reliable Neighbors Towards Robust Federated Learning",
    "abstract": "Robustness is becoming another important challenge of federated learning in that the data collection process in each client is naturally accompanied by noisy labels. However, it is far more complex and challenging owing to varying levels of data heterogeneity and noise over clients, which exacerbates the client-to-client performance discrepancy. In this work, we propose a robust federated learning method called FedRN, which exploits k-reliable neighbors with high data expertise or similarity. Our method helps mitigate the gap between low- and high-performance clients by training only with a selected set of clean examples, identified by their ensembled mixture models. We demonstrate the superiority of FedRN via extensive evaluations on three real-world or synthetic benchmark datasets. Compared with existing robust training methods, the results show that FedRN significantly improves the test accuracy in the presence of noisy labels. ",
    "url": "https://arxiv.org/abs/2205.01310",
    "authors": [
      "SangMook Kim",
      "Wonyoung Shin",
      "Soohyuk Jang",
      "Hwanjun Song",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01316",
    "title": "HL-Net: Heterophily Learning Network for Scene Graph Generatio",
    "abstract": "Scene graph generation (SGG) aims to detect objects and predict their pairwise relationships within an image. Current SGG methods typically utilize graph neural networks (GNNs) to acquire context information between objects/relationships. Despite their effectiveness, however, current SGG methods only assume scene graph homophily while ignoring heterophily. Accordingly, in this paper, we propose a novel Heterophily Learning Network (HL-Net) to comprehensively explore the homophily and heterophily between objects/relationships in scene graphs. More specifically, HL-Net comprises the following 1) an adaptive reweighting transformer module, which adaptively integrates the information from different layers to exploit both the heterophily and homophily in objects; 2) a relationship feature propagation module that efficiently explores the connections between relationships by considering heterophily in order to refine the relationship representation; 3) a heterophily-aware message-passing scheme to further distinguish the heterophily and homophily between objects/relationships, thereby facilitating improved message passing in graphs. We conducted extensive experiments on two public datasets: Visual Genome (VG) and Open Images (OI). The experimental results demonstrate the superiority of our proposed HL-Net over existing state-of-the-art approaches. In more detail, HL-Net outperforms the second-best competitors by 2.1$\\%$ on the VG dataset for scene graph classification and 1.2$\\%$ on the IO dataset for the final score. Code is available at https://github.com/siml3/HL-Net. ",
    "url": "https://arxiv.org/abs/2205.01316",
    "authors": [
      "Xin Lin",
      "Changxing Ding",
      "Yibing Zhan",
      "Zijian Li",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01331",
    "title": "GRAPHYP: A Scientific Knowledge Graph with Manifold Subnetworks of  Communities. Detection of Scholarly Disputes in Adversarial Information  Routes",
    "abstract": "The cognitive manifold of published content is currently expanding in all areas of science. However, Scientific Knowledge Graphs (SKGs) only provide poor pictures of the adversarial directions and scientific controversies that feed the production of knowledge. In this Article, we tackle the understanding of the design of the information space of a cognitive representation of research activities, and of related bottlenecks that affect search interfaces, in the mapping of structured objects into graphs. We propose, with SKG GRAPHYP, a novel graph designed geometric architecture which optimizes both the detection of the knowledge manifold of \"cognitive communities\", and the representation of alternative paths to adversarial answers to a research question, for instance in the context of academic disputes. With a methodology for designing \"Manifold Subnetworks of Cognitive Communities\", GRAPHYP provides a classification of distinct search paths in a research field. Users are detected from the variety of their search practices and classified in \"Cognitive communities\" from the analysis of the search history of their logs of scientific documentation. The manifold of practices is expressed from metrics of differentiated uses by triplets of nodes shaped into symmetrical graph subnetworks, with the following three parameters: Mass, Intensity, and Variety. ",
    "url": "https://arxiv.org/abs/2205.01331",
    "authors": [
      "Renaud Fabre",
      "Otmane Azeroual",
      "Patrice Bellot",
      "Joachim Sch\u00f6pfel",
      "Daniel Egret"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.01338",
    "title": "MMSE Signal Detection for MIMO Systems based on Ordinary Differential  Equation",
    "abstract": "Motivated by emerging technologies for energy efficient analog computing and continuous-time processing, this paper proposes continuous-time minimum mean squared error estimation for multiple-input multiple-output (MIMO) systems based on an ordinary differential equation. Mean squared error (MSE) is a principal detection performance measure of estimation methods for MIMO systems. We derive an analytical MSE formula that indicates the MSE at any time. The MSE of the proposed method depends on a regularization parameter which affects the convergence property of the MSE. Furthermore, we extend the proposed method by using a time-dependent regularization parameter to achieve better convergence performance. Numerical experiments indicated excellent agreement with the theoretical values and improvement in the convergence performance owing to the use of the time-dependent parameter. ",
    "url": "https://arxiv.org/abs/2205.01338",
    "authors": [
      "Ayano Nakai-Kasai",
      "Tadashi Wadayama"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.01351",
    "title": "Tooling for Time- and Space-efficient git Repository Mining",
    "abstract": "Software projects under version control grow with each commit, accumulating up to hundreds of thousands of commits per repository. Especially for such large projects, the traversal of a repository and data extraction for static source code analysis poses a trade-off between granularity and speed. We showcase the command-line tool pyrepositoryminer that combines a set of optimization approaches for efficient traversal and data extraction from git repositories while being adaptable to third-party and custom software metrics and data extractions. The tool is written in Python and combines bare repository access, in-memory storage, parallelization, caching, change-based analysis, and optimized communication between the traversal and custom data extraction components. The tool allows for both metrics written in Python and external programs for data extraction. A single-thread performance evaluation based on a basic mining use case shows a mean speedup of 15.6x to other freely available tools across four mid-sized open source projects. A multi-threaded execution allows for load distribution among cores and, thus, a mean speedup up to 86.9x using 12 threads. ",
    "url": "https://arxiv.org/abs/2205.01351",
    "authors": [
      "Fabian Heseding",
      "Willy Scheibel",
      "J\u00fcrgen D\u00f6llner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.01355",
    "title": "Predicting Loose-Fitting Garment Deformations Using Bone-Driven Motion  Networks",
    "abstract": "We present a learning algorithm that uses bone-driven motion networks to predict the deformation of loose-fitting garment meshes at interactive rates. Given a garment, we generate a simulation database and extract virtual bones from simulated mesh sequences using skin decomposition. At runtime, we separately compute low- and high-frequency deformations in a sequential manner. The low-frequency deformations are predicted by transferring body motions to virtual bones' motions, and the high-frequency deformations are estimated leveraging the global information of virtual bones' motions and local information extracted from low-frequency meshes. In addition, our method can estimate garment deformations caused by variations of the simulation parameters (e.g., fabric's bending stiffness) using an RBF kernel ensembling trained networks for different sets of simulation parameters. Through extensive comparisons, we show that our method outperforms state-of-the-art methods in terms of prediction accuracy of mesh deformations by about 20% in RMSE and 10% in Hausdorff distance and STED. The code and data are available at https://github.com/non-void/VirtualBones. ",
    "url": "https://arxiv.org/abs/2205.01355",
    "authors": [
      "Xiaoyu Pan",
      "Jiaming Mai",
      "Xinwei Jiang",
      "Dongxue Tang",
      "Jingxiang Li",
      "Tianjia Shao",
      "Kun Zhou",
      "Xiaogang Jin",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01356",
    "title": "Neural Combinatorial Optimization: a New Player in the Field",
    "abstract": "Neural Combinatorial Optimization attempts to learn good heuristics for solving a set of problems using Neural Network models and Reinforcement Learning. Recently, its good performance has encouraged many practitioners to develop neural architectures for a wide variety of combinatorial problems. However, the incorporation of such algorithms in the conventional optimization framework has raised many questions related to their performance and the experimental comparison with other methods such as exact algorithms, heuristics and metaheuristics. This paper presents a critical analysis on the incorporation of algorithms based on neural networks into the classical combinatorial optimization framework. Subsequently, a comprehensive study is carried out to analyse the fundamental aspects of such algorithms, including performance, transferability, computational cost and generalization to larger-sized instances. To that end, we select the Linear Ordering Problem as a case of study, an NP-hard problem, and develop a Neural Combinatorial Optimization model to optimize it. Finally, we discuss how the analysed aspects apply to a general learning framework, and suggest new directions for future work in the area of Neural Combinatorial Optimization algorithms. ",
    "url": "https://arxiv.org/abs/2205.01356",
    "authors": [
      "Andoni I. Garmendia",
      "Josu Ceberio",
      "Alexander Mendiburu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2205.01362",
    "title": "TracInAD: Measuring Influence for Anomaly Detection",
    "abstract": "As with many other tasks, neural networks prove very effective for anomaly detection purposes. However, very few deep-learning models are suited for detecting anomalies on tabular datasets. This paper proposes a novel methodology to flag anomalies based on TracIn, an influence measure initially introduced for explicability purposes. The proposed methods can serve to augment any unsupervised deep anomaly detection method. We test our approach using Variational Autoencoders and show that the average influence of a subsample of training points on a test point can serve as a proxy for abnormality. Our model proves to be competitive in comparison with state-of-the-art approaches: it achieves comparable or better performance in terms of detection accuracy on medical and cyber-security tabular benchmark data. ",
    "url": "https://arxiv.org/abs/2205.01362",
    "authors": [
      "Hugo Thimonier",
      "Fabrice Popineau",
      "Arpad Rimmel",
      "Bich-Li\u00ean Doan",
      "Fabrice Daniel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01374",
    "title": "Hidden behind the obvious: misleading keywords and implicitly abusive  language on social media",
    "abstract": "While social media offers freedom of self-expression, abusive language carry significant negative social impact. Driven by the importance of the issue, research in the automated detection of abusive language has witnessed growth and improvement. However, these detection models display a reliance on strongly indicative keywords, such as slurs and profanity. This means that they can falsely (1a) miss abuse without such keywords or (1b) flag non-abuse with such keywords, and that (2) they perform poorly on unseen data. Despite the recognition of these problems, gaps and inconsistencies remain in the literature. In this study, we analyse the impact of keywords from dataset construction to model behaviour in detail, with a focus on how models make mistakes on (1a) and (1b), and how (1a) and (1b) interact with (2). Through the analysis, we provide suggestions for future research to address all three problems. ",
    "url": "https://arxiv.org/abs/2205.01374",
    "authors": [
      "Wenjie Yin",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.01389",
    "title": "Sampling-free obstacle gradients and reactive planning in Neural  Radiance Fields (NeRF)",
    "abstract": "This work investigates the use of Neural implicit representations, specifically Neural Radiance Fields (NeRF), for geometrical queries and motion planning. We show that by adding the capacity to infer occupancy in a radius to a pre-trained NeRF, we are effectively learning an approximation to a Euclidean Signed Distance Field (ESDF). Using backward differentiation of the augmented network, we obtain an obstacle gradient that is integrated into an obstacle avoidance policy based on the Riemannian Motion Policies (RMP) framework. Thus, our findings allow for very fast sampling-free obstacle avoidance planning in the implicit representation. ",
    "url": "https://arxiv.org/abs/2205.01389",
    "authors": [
      "Michael Pantic",
      "Cesar Cadena",
      "Roland Siegwart",
      "Lionel Ott"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01397",
    "title": "Data Determines Distributional Robustness in Contrastive Language Image  Pre-training (CLIP)",
    "abstract": "Contrastively trained image-text models such as CLIP, ALIGN, and BASIC have demonstrated unprecedented robustness to multiple challenging natural distribution shifts. Since these image-text models differ from previous training approaches in several ways, an important question is what causes the large robustness gains. We answer this question via a systematic experimental investigation. Concretely, we study five different possible causes for the robustness gains: (i) the training set size, (ii) the training distribution, (iii) language supervision at training time, (iv) language supervision at test time, and (v) the contrastive loss function. Our experiments show that the more diverse training distribution is the main cause for the robustness gains, with the other factors contributing little to no robustness. Beyond our experimental results, we also introduce ImageNet-Captions, a version of ImageNet with original text annotations from Flickr, to enable further controlled experiments of language-image training. ",
    "url": "https://arxiv.org/abs/2205.01397",
    "authors": [
      "Alex Fang",
      "Gabriel Ilharco",
      "Mitchell Wortsman",
      "Yuhao Wan",
      "Vaishaal Shankar",
      "Achal Dave",
      "Ludwig Schmidt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01398",
    "title": "Neural language models for network configuration: Opportunities and  reality check",
    "abstract": "Boosted by deep learning, natural language processing (NLP) techniques have recently seen spectacular progress, mainly fueled by breakthroughs both in representation learning with word embeddings (e.g. word2vec) as well as novel architectures (e.g. transformers). This success quickly invited researchers to explore the use of NLP techniques to other field, such as computer programming languages, with the promise to automate tasks in software programming (bug detection, code synthesis, code repair, cross language translation etc.). By extension, NLP has potential for application to network configuration languages as well, for instance considering tasks such as network configuration verification, synthesis, and cross-vendor translation. In this paper, we survey recent advances in deep learning applied to programming languages, for the purpose of code verification, synthesis and translation: in particularly, we review their training requirements and expected performance, and qualitatively assess whether similar techniques can benefit corresponding use-cases in networking. ",
    "url": "https://arxiv.org/abs/2205.01398",
    "authors": [
      "Zied Ben Houidi",
      "Dario Rossi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.01404",
    "title": "Neural Language Taskonomy: Which NLP Tasks are the most Predictive of  fMRI Brain Activity?",
    "abstract": "Several popular Transformer based language models have been found to be successful for text-driven brain encoding. However, existing literature leverages only pretrained text Transformer models and has not explored the efficacy of task-specific learned Transformer representations. In this work, we explore transfer learning from representations learned for ten popular natural language processing tasks (two syntactic and eight semantic) for predicting brain responses from two diverse datasets: Pereira (subjects reading sentences from paragraphs) and Narratives (subjects listening to the spoken stories). Encoding models based on task features are used to predict activity in different regions across the whole brain. Features from coreference resolution, NER, and shallow syntax parsing explain greater variance for the reading activity. On the other hand, for the listening activity, tasks such as paraphrase generation, summarization, and natural language inference show better encoding performance. Experiments across all 10 task representations provide the following cognitive insights: (i) language left hemisphere has higher predictive brain activity versus language right hemisphere, (ii) posterior medial cortex, temporo-parieto-occipital junction, dorsal frontal lobe have higher correlation versus early auditory and auditory association cortex, (iii) syntactic and semantic tasks display a good predictive performance across brain regions for reading and listening stimuli resp. ",
    "url": "https://arxiv.org/abs/2205.01404",
    "authors": [
      "Subba Reddy Oota",
      "Jashn Arora",
      "Veeral Agarwal",
      "Mounika Marreddy",
      "Manish Gupta",
      "Bapi Raju Surampudi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2205.01411",
    "title": "On the Utility of Prediction Sets in Human-AI Teams",
    "abstract": "Research on human-AI teams usually provides experts with a single label, which ignores the uncertainty in a model's recommendation. Conformal prediction (CP) is a well established line of research that focuses on building a theoretically grounded, calibrated prediction set, which may contain multiple labels. We explore how such prediction sets impact expert decision-making in human-AI teams. Our evaluation on human subjects finds that set valued predictions positively impact experts. However, we notice that the predictive sets provided by CP can be very large, which leads to unhelpful AI assistants. To mitigate this, we introduce D-CP, a method to perform CP on some examples and defer to experts. We prove that D-CP can reduce the prediction set size of non-deferred examples. We show how D-CP performs in quantitative and in human subject experiments ($n=120$). Our results suggest that CP prediction sets improve human-AI team performance over showing the top-1 prediction alone, and that experts find D-CP prediction sets are more useful than CP prediction sets. ",
    "url": "https://arxiv.org/abs/2205.01411",
    "authors": [
      "Varun Babbar",
      "Umang Bhatt",
      "Adrian Weller"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2205.01414",
    "title": "Multimodal Detection of Unknown Objects on Roads for Autonomous Driving",
    "abstract": "Tremendous progress in deep learning over the last years has led towards a future with autonomous vehicles on our roads. Nevertheless, the performance of their perception systems is strongly dependent on the quality of the utilized training data. As these usually only cover a fraction of all object classes an autonomous driving system will face, such systems struggle with handling the unexpected. In order to safely operate on public roads, the identification of objects from unknown classes remains a crucial task. In this paper, we propose a novel pipeline to detect unknown objects. Instead of focusing on a single sensor modality, we make use of lidar and camera data by combining state-of-the art detection models in a sequential manner. We evaluate our approach on the Waymo Open Perception Dataset and point out current research gaps in anomaly detection. ",
    "url": "https://arxiv.org/abs/2205.01414",
    "authors": [
      "Daniel Bogdoll",
      "Enrico Eisen",
      "Maximilian Nitsche",
      "Christin Scheib",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.01415",
    "title": "Robust Subset Selection by Greedy and Evolutionary Pareto Optimization",
    "abstract": "Subset selection, which aims to select a subset from a ground set to maximize some objective function, arises in various applications such as influence maximization and sensor placement. In real-world scenarios, however, one often needs to find a subset which is robust against (i.e., is good over) a number of possible objective functions due to uncertainty, resulting in the problem of robust subset selection. This paper considers robust subset selection with monotone objective functions, relaxing the submodular property required by previous studies. We first show that the greedy algorithm can obtain an approximation ratio of $1-e^{-\\beta\\opgamma}$, where $\\beta$ and $\\opgamma$ are the correlation and submodularity ratios of the objective functions, respectively; and then propose EPORSS, an evolutionary Pareto optimization algorithm that can utilize more time to find better subsets. We prove that EPORSS can also be theoretically grounded, achieving a similar approximation guarantee to the greedy algorithm. In addition, we derive the lower bound of $\\beta$ for the application of robust influence maximization, and further conduct experiments to validate the performance of the greedy algorithm and EPORSS. ",
    "url": "https://arxiv.org/abs/2205.01415",
    "authors": [
      "Chao Bian",
      "Yawen Zhou",
      "Chao Qian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2205.01420",
    "title": "Bridging Causal Consistent and Time Reversibility: A Stochastic Process  Algebraic Approach",
    "abstract": "Causal consistent reversibility blends causality and reversibility. For a concurrent system, it says that an action can be undone provided that this has no consequences, thereby making it possible to bring the system back to a past consistent state. Time reversibility is instead considered in the performance evaluation field, mostly for efficient analysis purposes. A continuous-time Markov chain is time reversible if its stochastic behavior remains the same when the direction of time is reversed. We study how to bridge these two theories of reversibility by showing the conditions under which both causal consistent reversibility and time reversibility can be ensured by construction. This is done in the setting of a stochastic process calculus, which is then equipped with a notion of stochastic bisimilarity accounting for both forward and backward directions. ",
    "url": "https://arxiv.org/abs/2205.01420",
    "authors": [
      "Marco Bernardo",
      "Claudio Antares Mezzina"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2205.01421",
    "title": "A Falsificationist Account of Artificial Neural Networks",
    "abstract": "Machine learning operates at the intersection of statistics and computer science. This raises the question as to its underlying methodology. While much emphasis has been put on the close link between the process of learning from data and induction, the falsificationist component of machine learning has received minor attention. In this paper, we argue that the idea of falsification is central to the methodology of machine learning. It is commonly thought that machine learning algorithms infer general prediction rules from past observations. This is akin to a statistical procedure by which estimates are obtained from a sample of data. But machine learning algorithms can also be described as choosing one prediction rule from an entire class of functions. In particular, the algorithm that determines the weights of an artificial neural network operates by empirical risk minimization and rejects prediction rules that lack empirical adequacy. It also exhibits a behavior of implicit regularization that pushes hypothesis choice toward simpler prediction rules. We argue that taking both aspects together gives rise to a falsificationist account of artificial neural networks. ",
    "url": "https://arxiv.org/abs/2205.01421",
    "authors": [
      "Oliver Buchholz",
      "Eric Raidl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.01432",
    "title": "ARCADE: Adversarially Regularized Convolutional Autoencoder for Network  Anomaly Detection",
    "abstract": "As the number of heterogenous IP-connected devices and traffic volume increase, so does the potential for security breaches. The undetected exploitation of these breaches can bring severe cybersecurity and privacy risks. In this paper, we present a practical unsupervised anomaly-based deep learning detection system called ARCADE (Adversarially Regularized Convolutional Autoencoder for unsupervised network anomaly DEtection). ARCADE exploits the property of 1D Convolutional Neural Networks (CNNs) and Generative Adversarial Networks (GAN) to automatically build a profile of the normal traffic based on a subset of raw bytes of a few initial packets of network flows so that potential network anomalies and intrusions can be effectively detected before they could cause any more damage to the network. A convolutional Autoencoder (AE) is proposed that suits online detection in resource-constrained environments, and can be easily improved for environments with higher computational capabilities. An adversarial training strategy is proposed to regularize and decrease the AE's capabilities to reconstruct network flows that are out of the normal distribution, and thereby improve its anomaly detection capabilities. The proposed approach is more effective than existing state-of-the-art deep learning approaches for network anomaly detection and significantly reduces detection time. The evaluation results show that the proposed approach is suitable for anomaly detection on resource-constrained hardware platforms such as Raspberry Pi. ",
    "url": "https://arxiv.org/abs/2205.01432",
    "authors": [
      "Willian T. Lunardi",
      "Martin Andreoni Lopez",
      "Jean-Pierre Giacalone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.01435",
    "title": "RLFlow: Optimising Neural Network Subgraph Transformation with World  Models",
    "abstract": "We explored the use of reinforcement learning (RL) agents that can learn to perform neural network subgraph transformations, without the need of expertly designed heuristics to achieve a high level of performance. Reducing compute requirements of deep learning models is a focus of extensive research and many systems, optimisations and just-in-time (JIT) compilers have been proposed to decrease runtime. Recent work has aimed to apply reinforcement learning to computer systems with some success, especially using model-free RL techniques. Model-based reinforcement learning methods have seen an increased focus in research as they can be used to learn the transition dynamics of the environment; this can be leveraged to train an agent using the hallucinogenic environment, thereby increasing sample efficiency compared to model-free approaches. Furthermore, when using a world model as a simulated environment, batch rollouts can occur safely in parallel and, especially in systems environments, it overcomes the latency impact of updating system environments that can take orders of magnitude longer to perform an action compared to simple emulators for video games. We propose a design for a model-based agent which learns to optimise the architecture of neural networks by performing a sequence of subgraph transformations to reduce model runtime. We show our approach can match the performance of state of the art on common convolutional networks and outperform those by up to 5% on transformer-style architectures. ",
    "url": "https://arxiv.org/abs/2205.01435",
    "authors": [
      "Sean Parker",
      "Sami Alabed",
      "Eiko Yoneki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01480",
    "title": "Residual Graph Convolutional Recurrent Networks For Multi-step Traffic  Flow Forecasting",
    "abstract": "Traffic flow forecasting is essential for traffic planning, control and management. The main challenge of traffic forecasting tasks is accurately capturing traffic networks' spatial and temporal correlation. Although there are many traffic forecasting methods, most of them still have limitations in capturing spatial and temporal correlations. To improve traffic forecasting accuracy, we propose a new Spatial-temporal forecasting model, namely the Residual Graph Convolutional Recurrent Network (RGCRN). The model uses our proposed Residual Graph Convolutional Network (ResGCN) to capture the fine-grained spatial correlation of the traffic road network and then uses a Bi-directional Gated Recurrent Unit (BiGRU) to model time series with spatial information and obtains the temporal correlation by analysing the change in information transfer between the forward and reverse neurons of the time series data. Our comparative experimental results on two real datasets show that RGCRN improves on average by 20.66% compared to the best baseline model. You can get our source code and data through https://github.com/zhangshqii/RGCRN. ",
    "url": "https://arxiv.org/abs/2205.01480",
    "authors": [
      "Wei Zhao",
      "Shiqi Zhang",
      "Bing Zhou",
      "Bei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.01491",
    "title": "A Comprehensive Survey of Image Augmentation Techniques for Deep  Learning",
    "abstract": "Deep learning has been achieving decent performance in computer vision requiring a large volume of images, however, collecting images is expensive and difficult in many scenarios. To alleviate this issue, many image augmentation algorithms have been proposed as effective and efficient strategies. Understanding current algorithms is essential to find suitable methods or develop novel techniques for given tasks. In this paper, we perform a comprehensive survey on image augmentation for deep learning with a novel informative taxonomy. To get the basic idea why we need image augmentation, we introduce the challenges in computer vision tasks and vicinity distribution. Then, the algorithms are split into three categories; model-free, model-based, and optimizing policy-based. The model-free category employs image processing methods while the model-based method leverages trainable image generation models. In contrast, the optimizing policy-based approach aims to find the optimal operations or their combinations. Furthermore, we discuss the current trend of common applications with two more active topics, leveraging different ways to understand image augmentation, such as group and kernel theory, and deploying image augmentation for unsupervised learning. Based on the analysis, we believe that our survey gives a better understanding helpful to choose suitable methods or design novel algorithms for practical applications. ",
    "url": "https://arxiv.org/abs/2205.01491",
    "authors": [
      "Mingle Xu",
      "Sook Yoon",
      "Alvaro Fuentes",
      "Dong Sun Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01492",
    "title": "A unified view on Self-Organizing Maps (SOMs) and Stochastic Neighbor  Embedding (SNE)",
    "abstract": "We propose a unified view on two widely used data visualization techniques: Self-Organizing Maps (SOMs) and Stochastic Neighbor Embedding (SNE). We show that they can both be derived from a common mathematical framework. Leveraging this formulation, we propose to compare SOM and SNE quantitatively on two datasets, and discuss possible avenues for future work to take advantage of both approaches. ",
    "url": "https://arxiv.org/abs/2205.01492",
    "authors": [
      "Thibaut Kulak",
      "Anthony Fillion",
      "Fran\u00e7ois Blayo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.01493",
    "title": "On the uncertainty principle of neural networks",
    "abstract": "Despite the successes in many fields, it is found that neural networks are vulnerability and difficult to be both accurate and robust (robust means that the prediction of the trained network stays unchanged for inputs with non-random perturbations introduced by adversarial attacks). Various empirical and analytic studies have suggested that there is more or less a trade-off between the accuracy and robustness of neural networks. If the trade-off is inherent, applications based on the neural networks are vulnerable with untrustworthy predictions. It is then essential to ask whether the trade-off is an inherent property or not. Here, we show that the accuracy-robustness trade-off is an intrinsic property whose underlying mechanism is deeply related to the uncertainty principle in quantum mechanics. We find that for a neural network to be both accurate and robust, it needs to resolve the features of the two conjugated parts $x$ (the inputs) and $\\Delta$ (the derivatives of the normalized loss function $J$ with respect to $x$), respectively. Analogous to the position-momentum conjugation in quantum mechanics, we show that the inputs and their conjugates cannot be resolved by a neural network simultaneously. ",
    "url": "https://arxiv.org/abs/2205.01493",
    "authors": [
      "Jun-Jie Zhang",
      "Dong-Xiao Zhang",
      "Jian-Nan Chen",
      "Long-Gang Pang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2205.01508",
    "title": "Compact Neural Networks via Stacking Designed Basic Units",
    "abstract": "Unstructured pruning has the limitation of dealing with the sparse and irregular weights. By contrast, structured pruning can help eliminate this drawback but it requires complex criterion to determine which components to be pruned. To this end, this paper presents a new method termed TissueNet, which directly constructs compact neural networks with fewer weight parameters by independently stacking designed basic units, without requiring additional judgement criteria anymore. Given the basic units of various architectures, they are combined and stacked in a certain form to build up compact neural networks. We formulate TissueNet in diverse popular backbones for comparison with the state-of-the-art pruning methods on different benchmark datasets. Moreover, two new metrics are proposed to evaluate compression performance. Experiment results show that TissueNet can achieve comparable classification accuracy while saving up to around 80% FLOPs and 89.7% parameters. That is, stacking basic units provides a new promising way for network compression. ",
    "url": "https://arxiv.org/abs/2205.01508",
    "authors": [
      "Weichao Lan",
      "Yiu-ming Cheung",
      "Juyong Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01510",
    "title": "ExSpliNet: An interpretable and expressive spline-based neural network",
    "abstract": "In this paper we present ExSpliNet, an interpretable and expressive neural network model. The model combines ideas of Kolmogorov neural networks, ensembles of probabilistic trees, and multivariate B-spline representations. We give a probabilistic interpretation of the model and show its universal approximation properties. We also discuss how it can be efficiently encoded by exploiting B-spline properties. Finally, we test the effectiveness of the proposed model on synthetic approximation problems and classical machine learning benchmark datasets. ",
    "url": "https://arxiv.org/abs/2205.01510",
    "authors": [
      "Daniele Fakhoury",
      "Emanuele Fakhoury",
      "Hendrik Speleers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2205.01515",
    "title": "Multitask Network for Joint Object Detection, Semantic Segmentation and  Human Pose Estimation in Vehicle Occupancy Monitoring",
    "abstract": "In order to ensure safe autonomous driving, precise information about the conditions in and around the vehicle must be available. Accordingly, the monitoring of occupants and objects inside the vehicle is crucial. In the state-of-the-art, single or multiple deep neural networks are used for either object recognition, semantic segmentation, or human pose estimation. In contrast, we propose our Multitask Detection, Segmentation and Pose Estimation Network (MDSP) -- the first multitask network solving all these three tasks jointly in the area of occupancy monitoring. Due to the shared architecture, memory and computing costs can be saved while achieving higher accuracy. Furthermore, our architecture allows a flexible combination of the three mentioned tasks during a simple end-to-end training. We perform comprehensive evaluations on the public datasets SVIRO and TiCaM in order to demonstrate the superior performance. ",
    "url": "https://arxiv.org/abs/2205.01515",
    "authors": [
      "Nikolas Ebert",
      "Patrick Mangat",
      "Oliver Wasenm\u00fcller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01550",
    "title": "Multi Scale Sparse Convolution Point Cloud Semantic Segmentation Neural  Network",
    "abstract": "Point clouds have the characteristics of disorder, unstructured and sparseness.Aiming at the problem of the non-structural nature of point clouds, thanks to the excellent performance of convolutional neural networks in image processing, one of the solutions is to extract features from point clouds based on two-dimensional convolutional neural networks. The three-dimensional information carried in the point cloud can be converted to two-dimensional, and then processed by a two-dimensional convolutional neural network, and finally back-projected to three-dimensional.In the process of projecting 3D information to 2D and back-projection, certain information loss will inevitably be caused to the point cloud and category inconsistency will be introduced in the back-projection stage;Another solution is the voxel-based point cloud segmentation method, which divides the point cloud into small grids one by one.However, the point cloud is sparse, and the direct use of 3D convolutional neural network inevitably wastes computing resources. In this paper, we propose a feature extraction module based on multi-scale ultra-sparse convolution and a feature selection module based on channel attention, and build a point cloud segmentation network framework based on this.By introducing multi-scale sparse convolution, network could capture richer feature information based on convolution kernels of different sizes, improving the segmentation result of point cloud segmentation. ",
    "url": "https://arxiv.org/abs/2205.01550",
    "authors": [
      "Yunzheng Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.01556",
    "title": "Privacy Amplification via Random Participation in Federated Learning",
    "abstract": "Running a randomized algorithm on a subsampled dataset instead of the entire dataset amplifies differential privacy guarantees. In this work, in a federated setting, we consider random participation of the clients in addition to subsampling their local datasets. Since such random participation of the clients creates correlation among the samples of the same client in their subsampling, we analyze the corresponding privacy amplification via non-uniform subsampling. We show that when the size of the local datasets is small, the privacy guarantees via random participation is close to those of the centralized setting, in which the entire dataset is located in a single host and subsampled. On the other hand, when the local datasets are large, observing the output of the algorithm may disclose the identities of the sampled clients with high confidence. Our analysis reveals that, even in this case, privacy guarantees via random participation outperform those via only local subsampling. ",
    "url": "https://arxiv.org/abs/2205.01556",
    "authors": [
      "Burak Hasircioglu",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.01568",
    "title": "RAFT-MSF: Self-Supervised Monocular Scene Flow using Recurrent Optimizer",
    "abstract": "Learning scene flow from a monocular camera still remains a challenging task due to its ill-posedness as well as lack of annotated data. Self-supervised methods demonstrate learning scene flow estimation from unlabeled data, yet their accuracy lags behind (semi-)supervised methods. In this paper, we introduce a self-supervised monocular scene flow method that substantially improves the accuracy over the previous approaches. Based on RAFT, a state-of-the-art optical flow model, we design a new decoder to iteratively update 3D motion fields and disparity maps simultaneously. Furthermore, we propose an enhanced upsampling layer and a disparity initialization technique, which overall further improves accuracy up to 7.2%. Our method achieves state-of-the-art accuracy among all self-supervised monocular scene flow methods, improving accuracy by 34.2%. Our fine-tuned model outperforms the best previous semi-supervised method with 228 times faster runtime. Code will be publicly available. ",
    "url": "https://arxiv.org/abs/2205.01568",
    "authors": [
      "Bayram Bayramli",
      "Junhwa Hur",
      "Hongtao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.01571",
    "title": "A Real Time 1280x720 Object Detection Chip With 585MB/s Memory Traffic",
    "abstract": "Memory bandwidth has become the real-time bottleneck of current deep learning accelerators (DLA), particularly for high definition (HD) object detection. Under resource constraints, this paper proposes a low memory traffic DLA chip with joint hardware and software optimization. To maximize hardware utilization under memory bandwidth, we morph and fuse the object detection model into a group fusion-ready model to reduce intermediate data access. This reduces the YOLOv2's feature memory traffic from 2.9 GB/s to 0.15 GB/s. To support group fusion, our previous DLA based hardware employes a unified buffer with write-masking for simple layer-by-layer processing in a fusion group. When compared to our previous DLA with the same PE numbers, the chip implemented in a TSMC 40nm process supports 1280x720@30FPS object detection and consumes 7.9X less external DRAM access energy, from 2607 mJ to 327.6 mJ. ",
    "url": "https://arxiv.org/abs/2205.01571",
    "authors": [
      "Kuo-Wei Chang",
      "Hsu-Tung Shih",
      "Tian-Sheuan Chang",
      "Shang-Hong Tsai",
      "Chih-Chyau Yang",
      "Chien-Ming Wu",
      "Chun-Ming Huang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01590",
    "title": "An Empirical Study on Internet Traffic Prediction Using Statistical  Rolling Model",
    "abstract": "Real-world IP network traffic is susceptible to external and internal factors such as new internet service integration, traffic migration, internet application, etc. Due to these factors, the actual internet traffic is non-linear and challenging to analyze using a statistical model for future prediction. In this paper, we investigated and evaluated the performance of different statistical prediction models for real IP network traffic; and showed a significant improvement in prediction using the rolling prediction technique. Initially, a set of best hyper-parameters for the corresponding prediction model is identified by analyzing the traffic characteristics and implementing a grid search algorithm based on the minimum Akaike Information Criterion (AIC). Then, we performed a comparative performance analysis among AutoRegressive Integrated Moving Average (ARIMA), Seasonal ARIMA (SARIMA), SARIMA with eXogenous factors (SARIMAX), and Holt-Winter for single-step prediction. The seasonality of our traffic has been explicitly modeled using SARIMA, which reduces the rolling prediction Mean Average Percentage Error (MAPE) by more than 4% compared to ARIMA (incapable of handling the seasonality). We further improved traffic prediction using SARIMAX to learn different exogenous factors extracted from the original traffic, which yielded the best rolling prediction results with a MAPE of 6.83%. Finally, we applied the exponential smoothing technique to handle the variability in traffic following the Holt-Winter model, which exhibited a better prediction than ARIMA (around 1.5% less MAPE). The rolling prediction technique reduced prediction error using real Internet Service Provider (ISP) traffic data by more than 50\\% compared to the standard prediction method. ",
    "url": "https://arxiv.org/abs/2205.01590",
    "authors": [
      "Sajal Saha",
      "Anwar Haque",
      "Greg Sidebottom"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01595",
    "title": "A Bidirectional Conversion Network for Cross-Spectral Face Recognition",
    "abstract": "Face recognition in the infrared (IR) band has become an important supplement to visible light face recognition due to its advantages of independent background light, strong penetration, ability of imaging under harsh environments such as nighttime, rain and fog. However, cross-spectral face recognition (i.e., VIS to IR) is very challenging due to the dramatic difference between the visible light and IR imageries as well as the lack of paired training data. This paper proposes a framework of bidirectional cross-spectral conversion (BCSC-GAN) between the heterogeneous face images, and designs an adaptive weighted fusion mechanism based on information fusion theory. The network reduces the cross-spectral recognition problem into an intra-spectral problem, and improves performance by fusing bidirectional information. Specifically, a face identity retaining module (IRM) is introduced with the ability to preserve identity features, and a new composite loss function is designed to overcome the modal differences caused by different spectral characteristics. Two datasets of TINDERS and CASIA were tested, where performance metrics of FID, recognition rate, equal error rate and normalized distance were compared. Results show that our proposed network is superior than other state-of-the-art methods. Additionally, the proposed rule of Self Adaptive Weighted Fusion (SAWF) is better than the recognition results of the unfused case and other traditional fusion rules that are commonly used, which further justifies the effectiveness and superiority of the proposed bidirectional conversion approach. ",
    "url": "https://arxiv.org/abs/2205.01595",
    "authors": [
      "Zhicheng Cao",
      "Jiaxuan Zhang",
      "Liaojun Pang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01620",
    "title": "OmniKnight: Multilingual Neural Machine Translation with  Language-Specific Self-Distillation",
    "abstract": "Although all-in-one-model multilingual neural machine translation (MNMT) has achieved remarkable progress in recent years, its selected best overall checkpoint fails to achieve the best performance simultaneously in all language pairs. It is because that the best checkpoints for each individual language pair (i.e., language-specific best checkpoints) scatter in different epochs. In this paper, we present a novel training strategy dubbed Language-Specific Self-Distillation (LSSD) for bridging the gap between language-specific best checkpoints and the overall best checkpoint. In detail, we regard each language-specific best checkpoint as a teacher to distill the overall best checkpoint. Moreover, we systematically explore three variants of our LSSD, which perform distillation statically, selectively, and adaptively. Experimental results on two widely-used benchmarks show that LSSD obtains consistent improvements towards all language pairs and achieves the state-of-the-art ",
    "url": "https://arxiv.org/abs/2205.01620",
    "authors": [
      "Yichong Huang",
      "Xiaocheng Feng",
      "Xinwei Geng",
      "Bing Qin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.01624",
    "title": "Practical Saccade Prediction for Head-Mounted Displays: Towards a  Comprehensive Model",
    "abstract": "Eye-tracking technology is an integral component of new display devices such as virtual and augmented reality headsets. Applications of gaze information range from new interaction techniques exploiting eye patterns to gaze-contingent digital content creation. However, system latency is still a significant issue in many of these applications because it breaks the synchronization between the current and measured gaze positions. Consequently, it may lead to unwanted visual artifacts and degradation of user experience. In this work, we focus on foveated rendering applications where the quality of an image is reduced towards the periphery for computational savings. In foveated rendering, the presence of latency leads to delayed updates to the rendered frame, making the quality degradation visible to the user. To address this issue and to combat system latency, recent work proposes to use saccade landing position prediction to extrapolate the gaze information from delayed eye-tracking samples. While the benefits of such a strategy have already been demonstrated, the solutions range from simple and efficient ones, which make several assumptions about the saccadic eye movements, to more complex and costly ones, which use machine learning techniques. Yet, it is unclear to what extent the prediction can benefit from accounting for additional factors. \\revcorr{This paper presents a series of experiments investigating the importance of different factors for saccades prediction in common virtual and augmented reality applications. In particular, we investigate the effects of saccade orientation in 3D space and smooth pursuit eye-motion (SPEM) and how their influence compares to the variability across users. We also present a simple yet efficient correction method that adapts the existing saccade prediction methods to handle these factors without performing extensive data collection. ",
    "url": "https://arxiv.org/abs/2205.01624",
    "authors": [
      "Elena Arabadzhiyska",
      "Cara Tursun",
      "Hans-Peter Seidel",
      "Piotr Didyk"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2205.01625",
    "title": "Toward Robust Spiking Neural Network Against Adversarial Perturbation",
    "abstract": "As spiking neural networks (SNNs) are deployed increasingly in real-world efficiency critical applications, the security concerns in SNNs attract more attention. Currently, researchers have already demonstrated an SNN can be attacked with adversarial examples. How to build a robust SNN becomes an urgent issue. Recently, many studies apply certified training in artificial neural networks (ANNs), which can improve the robustness of an NN model promisely. However, existing certifications cannot transfer to SNNs directly because of the distinct neuron behavior and input formats for SNNs. In this work, we first design S-IBP and S-CROWN that tackle the non-linear functions in SNNs' neuron modeling. Then, we formalize the boundaries for both digital and spike inputs. Finally, we demonstrate the efficiency of our proposed robust training method in different datasets and model architectures. Based on our experiment, we can achieve a maximum $37.7\\%$ attack error reduction with $3.7\\%$ original accuracy loss. To the best of our knowledge, this is the first analysis on robust training of SNNs. ",
    "url": "https://arxiv.org/abs/2205.01625",
    "authors": [
      "Ling Liang",
      "Kaidi Xu",
      "Xing Hu",
      "Lei Deng",
      "Yuan Xie"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01629",
    "title": "AutoFi: Towards Automatic WiFi Human Sensing via Geometric  Self-Supervised Learning",
    "abstract": "WiFi sensing technology has shown superiority in smart homes among various sensors for its cost-effective and privacy-preserving merits. It is empowered by Channel State Information (CSI) extracted from WiFi signals and advanced machine learning models to analyze motion patterns in CSI. Many learning-based models have been proposed for kinds of applications, but they severely suffer from environmental dependency. Though domain adaptation methods have been proposed to tackle this issue, it is not practical to collect high-quality, well-segmented and balanced CSI samples in a new environment for adaptation algorithms, but randomly captured CSI samples can be easily collected. In this paper, we firstly explore how to learn a robust model from these low-quality CSI samples, and propose AutoFi, an automatic WiFi sensing model based on a novel geometric self-supervised learning algorithm. The AutoFi fully utilizes unlabeled low-quality CSI samples that are captured randomly, and then transfers the knowledge to specific tasks defined by users, which is the first work to achieve cross-task transfer in WiFi sensing. The AutoFi is implemented on a pair of Atheros WiFi APs for evaluation. The AutoFi transfers knowledge from randomly collected CSI samples into human gait recognition and achieves state-of-the-art performance. Furthermore, we simulate cross-task transfer using public datasets to further demonstrate its capacity for cross-task learning. For the UT-HAR and Widar datasets, the AutoFi achieves satisfactory results on activity recognition and gesture recognition without any prior training. We believe that the AutoFi takes a huge step toward automatic WiFi sensing without any developer engagement while overcoming the cross-site issue. ",
    "url": "https://arxiv.org/abs/2205.01629",
    "authors": [
      "Jianfei Yang",
      "Xinyan Chen",
      "Han Zou",
      "Dazhuo Wang",
      "Lihua Xie"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.01631",
    "title": "A general approach to deriving diagnosability results of interconnection  networks",
    "abstract": "We generalize an approach to deriving diagnosability results of various interconnection networks in terms of the popular $g$-good-neighbor and $g$-extra fault-tolerant models, as well as mainstream diagnostic models such as the PMC and the MM* models. As demonstrative examples, we show how to follow this constructive, and effective, process to derive the $g$-extra diagnosabilities of the hypercube, the $(n, k)$-star, and the arrangement graph. These results agree with those achieved individually, without duplicating structure independent technical details. Some of them come with a larger applicable range than those already known, and the result for the arrangement graph in terms of the MM* model is new. ",
    "url": "https://arxiv.org/abs/2205.01631",
    "authors": [
      "Eddie Cheng",
      "Yaping Mao",
      "Ke Qiu",
      "Zhizhang Shen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2205.01643",
    "title": "Cross-Domain Object Detection with Mean-Teacher Transformer",
    "abstract": "Recently, DEtection TRansformer (DETR), an end-to-end object detection pipeline, has achieved promising performance. However, it requires large-scale labeled data and suffers from domain shift, especially when no labeled data is available in the target domain. To solve this problem, we propose an end-to-end cross-domain detection transformer based on the mean teacher knowledge transfer (MTKT), which transfers knowledge between domains via pseudo labels. To improve the quality of pseudo labels in the target domain, which is a crucial factor for better domain adaptation, we design three levels of source-target feature alignment strategies based on the architecture of the Transformer, including domain query-based feature alignment (DQFA), bi-level-graph-based prototype alignment (BGPA), and token-wise image feature alignment (TIFA). These three levels of feature alignment match the global, local, and instance features between source and target, respectively. With these strategies, more accurate pseudo labels can be obtained, and knowledge can be better transferred from source to target, thus improving the cross-domain capability of the detection transformer. Extensive experiments demonstrate that our proposed method achieves state-of-the-art performance on three domain adaptation scenarios, especially the result of Sim10k to Cityscapes scenario is remarkably improved from 52.6 mAP to 57.9 mAP. Code will be released. ",
    "url": "https://arxiv.org/abs/2205.01643",
    "authors": [
      "Jinze Yu",
      "Jiaming Liu",
      "Xiaobao Wei",
      "Haoyi Zhou",
      "Yohei Nakata",
      "Denis Gudovskiy",
      "Tomoyuki Okuno",
      "Jianxin Li",
      "Kurt Keutzer",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01646",
    "title": "Implementation of an efficient, portable and platform-agnostic  cryptocurrency mining algorithm for Internet of Things devices",
    "abstract": "Recently, there has been a remarkable amount of research being done in both, the fields of Blockchain and Internet of Things (IoT). Blockchain technology synergises well with IoT, solving key problems such as privacy, concerns with interoperability and security. However, the consensus mechanisms that allows trustless parties to maintain an agreement, the same algorithms that underpins cryptocurrency mining, are usually extremely computationally expensive, making implementation on low-power IoT devices difficult. More importantly, mining requires downloading and synchronizing hundred of gigabytes worth of blocks which is far beyond the capabilities of most IoT devices. In this paper, we present an efficient, portable and platform-agnostic cryptocurrency mining algorithm using the Stratum protocol to avoid downloading the entire blockchain. We implement the algorithm in four different platforms- PC, ESP32, an emulator and an old PlayStation Portable (PSP) to demonstrate that it is indeed possible for any device to mine cryptocurrencies with no assumptions except the ability to connect to the internet. To make sure of ease of portability on any platform and for reproducibility of the reported results we make the implementation publicly available with detailed instructions at: https://anonymous.4open.science/r/cryptominer. ",
    "url": "https://arxiv.org/abs/2205.01646",
    "authors": [
      "Kinshuk Dua"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.01656",
    "title": "GeoRefine: Self-Supervised Online Depth Refinement for Accurate Dense  Mapping",
    "abstract": "We present a robust and accurate depth refinement system, named GeoRefine, for geometrically-consistent dense mapping from monocular sequences. GeoRefine consists of three modules: a hybrid SLAM module using learning-based priors, an online depth refinement module leveraging self-supervision, and a global mapping module via TSDF fusion. The proposed system is online by design and achieves great robustness and accuracy via: (i) a robustified hybrid SLAM that incorporates learning-based optical flow and/or depth; (ii) self-supervised losses that leverage SLAM outputs and enforce long-term geometric consistency; (iii) careful system design that avoids degenerate cases in online depth refinement. We extensively evaluate GeoRefine on multiple public datasets and reach as low as $5\\%$ absolute relative depth errors. ",
    "url": "https://arxiv.org/abs/2205.01656",
    "authors": [
      "Pan Ji",
      "Qingan Yan",
      "Yuxin Ma",
      "Yi Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01657",
    "title": "Cross-modal Representation Learning for Zero-shot Action Recognition",
    "abstract": "We present a cross-modal Transformer-based framework, which jointly encodes video data and text labels for zero-shot action recognition (ZSAR). Our model employs a conceptually new pipeline by which visual representations are learned in conjunction with visual-semantic associations in an end-to-end manner. The model design provides a natural mechanism for visual and semantic representations to be learned in a shared knowledge space, whereby it encourages the learned visual embedding to be discriminative and more semantically consistent. In zero-shot inference, we devise a simple semantic transfer scheme that embeds semantic relatedness information between seen and unseen classes to composite unseen visual prototypes. Accordingly, the discriminative features in the visual structure could be preserved and exploited to alleviate the typical zero-shot issues of information loss, semantic gap, and the hubness problem. Under a rigorous zero-shot setting of not pre-training on additional datasets, the experiment results show our model considerably improves upon the state of the arts in ZSAR, reaching encouraging top-1 accuracy on UCF101, HMDB51, and ActivityNet benchmark datasets. Code will be made available. ",
    "url": "https://arxiv.org/abs/2205.01657",
    "authors": [
      "Chung-Ching Lin",
      "Kevin Lin",
      "Linjie Li",
      "Lijuan Wang",
      "Zicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01663",
    "title": "Adversarial Training for High-Stakes Reliability",
    "abstract": "In the future, powerful AI systems may be deployed in high-stakes settings, where a single failure could be catastrophic. One technique for improving AI safety in high-stakes settings is adversarial training, which uses an adversary to generate examples to train on in order to achieve better worst-case performance. In this work, we used a language generation task as a testbed for achieving high reliability through adversarial training. We created a series of adversarial training techniques -- including a tool that assists human adversaries -- to find and eliminate failures in a classifier that filters text completions suggested by a generator. In our simple \"avoid injuries\" task, we determined that we can set very conservative classifier thresholds without significantly impacting the quality of the filtered outputs. With our chosen thresholds, filtering with our baseline classifier decreases the rate of unsafe completions from about 2.4% to 0.003% on in-distribution data, which is near the limit of our ability to measure. We found that adversarial training significantly increased robustness to the adversarial attacks that we trained on, without affecting in-distribution performance. We hope to see further work in the high-stakes reliability setting, including more powerful tools for enhancing human adversaries and better ways to measure high levels of reliability, until we can confidently rule out the possibility of catastrophic deployment-time failures of powerful models. ",
    "url": "https://arxiv.org/abs/2205.01663",
    "authors": [
      "Daniel M. Ziegler",
      "Seraphina Nix",
      "Lawrence Chan",
      "Tim Bauman",
      "Peter Schmidt-Nielsen",
      "Tao Lin",
      "Adam Scherlis",
      "Noa Nabeshima",
      "Ben Weinstein-Raun",
      "Daniel de Haas",
      "Buck Shlegeris",
      "Nate Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.01666",
    "title": "DANBO: Disentangled Articulated Neural Body Representations via Graph  Neural Networks",
    "abstract": "Deep learning greatly improved the realism of animatable human models by learning geometry and appearance from collections of 3D scans, template meshes, and multi-view imagery. High-resolution models enable photo-realistic avatars but at the cost of requiring studio settings not available to end users. Our goal is to create avatars directly from raw images without relying on expensive studio setups and surface tracking. While a few such approaches exist, those have limited generalization capabilities and are prone to learning spurious (chance) correlations between irrelevant body parts, resulting in implausible deformations and missing body parts on unseen poses. We introduce a three-stage method that induces two inductive biases to better disentangled pose-dependent deformation. First, we model correlations of body parts explicitly with a graph neural network. Second, to further reduce the effect of chance correlations, we introduce localized per-bone features that use a factorized volumetric representation and a new aggregation function. We demonstrate that our model produces realistic body shapes under challenging unseen poses and shows high-quality image synthesis. Our proposed representation strikes a better trade-off between model capacity, expressiveness, and robustness than competing methods. Project website: https://lemonatsu.github.io/danbo. ",
    "url": "https://arxiv.org/abs/2205.01666",
    "authors": [
      "Shih-Yang Su",
      "Timur Bagautdinov",
      "Helge Rhodin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01191",
    "title": "Taming graphs with no large creatures and skinny ladders",
    "abstract": "We confirm a conjecture of Gartland and Lokshtanov [arXiv:2007.08761]: if for a hereditary graph class $\\mathcal{G}$ there exists a constant $k$ such that no member of $\\mathcal{G}$ contains a $k$-creature as an induced subgraph or a $k$-skinny-ladder as an induced minor, then there exists a polynomial $p$ such that every $G \\in \\mathcal{G}$ contains at most $p(|V(G)|)$ minimal separators. By a result of Fomin, Todinca, and Villanger [SIAM J. Comput. 2015] the latter entails the existence of polynomial-time algorithms for Maximum Weight Independent Set, Feedback Vertex Set and many other problems, when restricted to an input graph from $\\mathcal{G}$. Furthermore, as shown by Gartland and Lokshtanov, our result implies a full dichotomy of hereditary graph classes defined by a finite set of forbidden induced subgraphs into tame (admitting a polynomial bound of the number of minimal separators) and feral (containing infinitely many graphs with exponential number of minimal separators). ",
    "url": "https://arxiv.org/abs/2205.01191",
    "authors": [
      "Jakub Gajarsk\u00fd",
      "Lars Jaffke",
      "Paloma T. Lima",
      "Jana Novotn\u00e1",
      "Marcin Pilipczuk",
      "Pawe\u0142 Rz\u0105\u017cewski",
      "U\u00e9verton S. Souza"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2205.01222",
    "title": "Leveraging Stochastic Predictions of Bayesian Neural Networks for Fluid  Simulations",
    "abstract": "We investigate uncertainty estimation and multimodality via the non-deterministic predictions of Bayesian neural networks (BNNs) in fluid simulations. To this end, we deploy BNNs in three challenging experimental test-cases of increasing complexity: We show that BNNs, when used as surrogate models for steady-state fluid flow predictions, provide accurate physical predictions together with sensible estimates of uncertainty. Further, we experiment with perturbed temporal sequences from Navier-Stokes simulations and evaluate the capabilities of BNNs to capture multimodal evolutions. While our findings indicate that this is problematic for large perturbations, our results show that the networks learn to correctly predict high uncertainties in such situations. Finally, we study BNNs in the context of solver interactions with turbulent plasma flows. We find that BNN-based corrector networks can stabilize coarse-grained simulations and successfully create multimodal trajectories. ",
    "url": "https://arxiv.org/abs/2205.01222",
    "authors": [
      "Maximilian Mueller",
      "Robin Greif",
      "Frank Jenko",
      "Nils Thuerey"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01304",
    "title": "Efficient dynamic filter for robust and low computational feature  extraction",
    "abstract": "Unseen noise signal which is not considered in a model training process is difficult to anticipate and would lead to performance degradation. Various methods have been investigated to mitigate unseen noise. In our previous work, an Instance-level Dynamic Filter (IDF) and a Pixel Dynamic Filter (PDF) were proposed to extract noise-robust features. However, the performance of the dynamic filter might be degraded since simple feature pooling is used to reduce the computational resource in the IDF part. In this paper, we propose an efficient dynamic filter to enhance the performance of the dynamic filter. Instead of utilizing the simple feature mean, we separate Time-Frequency (T-F) features as non-overlapping chunks, and separable convolutions are carried out for each feature direction (inter chunks and intra chunks). Additionally, we propose Dynamic Attention Pooling that maps high dimensional features as low dimensional feature embeddings. These methods are applied to the IDF for keyword spotting and speaker verification tasks. We confirm that our proposed method performs better in unseen environments (unseen noise and unseen speakers) than state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2205.01304",
    "authors": [
      "Donghyeon Kim",
      "Gwantae Kim",
      "Bokyeung Lee",
      "Jeong-gi Kwak",
      "David K. Han",
      "Hanseok Ko"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2205.01445",
    "title": "High-dimensional Asymptotics of Feature Learning: How One Gradient Step  Improves the Representation",
    "abstract": "We study the first gradient descent step on the first-layer parameters $\\boldsymbol{W}$ in a two-layer neural network: $f(\\boldsymbol{x}) = \\frac{1}{\\sqrt{N}}\\boldsymbol{a}^\\top\\sigma(\\boldsymbol{W}^\\top\\boldsymbol{x})$, where $\\boldsymbol{W}\\in\\mathbb{R}^{d\\times N}, \\boldsymbol{a}\\in\\mathbb{R}^{N}$ are randomly initialized, and the training objective is the empirical MSE loss: $\\frac{1}{n}\\sum_{i=1}^n (f(\\boldsymbol{x}_i)-y_i)^2$. In the proportional asymptotic limit where $n,d,N\\to\\infty$ at the same rate, and an idealized student-teacher setting, we show that the first gradient update contains a rank-1 \"spike\", which results in an alignment between the first-layer weights and the linear component of the teacher model $f^*$. To characterize the impact of this alignment, we compute the prediction risk of ridge regression on the conjugate kernel after one gradient step on $\\boldsymbol{W}$ with learning rate $\\eta$, when $f^*$ is a single-index model. We consider two scalings of the first step learning rate $\\eta$. For small $\\eta$, we establish a Gaussian equivalence property for the trained feature map, and prove that the learned kernel improves upon the initial random features model, but cannot defeat the best linear model on the input. Whereas for sufficiently large $\\eta$, we prove that for certain $f^*$, the same ridge estimator on trained features can go beyond this \"linear regime\" and outperform a wide range of random features and rotationally invariant kernels. Our results demonstrate that even one gradient step can lead to a considerable advantage over random features, and highlight the role of learning rate scaling in the initial phase of training. ",
    "url": "https://arxiv.org/abs/2205.01445",
    "authors": [
      "Jimmy Ba",
      "Murat A. Erdogdu",
      "Taiji Suzuki",
      "Zhichao Wang",
      "Denny Wu",
      "Greg Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2205.01478",
    "title": "Eigenvector centrality for multilayer networks with dependent node  importance",
    "abstract": "We present an approach for computing eigenvector centrality for multilayer networks with interlayer constraints on node importance. Specifically, we consider a multilayer network defined by multiple edge-weighted, potentially directed, graphs over the same set of nodes with each graph representing one layer of the network. In this scenario, edges between layers are not allowed. As in the standard eigenvector centrality construction, the importance each node in a given layer is based on the weighted sum of the importance of adjacent nodes in that same layer. Unlike standard eigenvector centrality, we assume that the adjacency relationship and the importance of adjacent nodes may be based on distinct layers. This form of centrality constraint between the layers leads to eigenvector centrality values defined by a system of interdependent eigenvalue problems, whose solution can be efficiently realized using an interleaved power iteration algorithm. ",
    "url": "https://arxiv.org/abs/2205.01478",
    "authors": [
      "H. Robert Frost"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2205.01639",
    "title": "Dynamic and Context-Dependent Stock Price Prediction Using Attention  Modules and News Sentiment",
    "abstract": "The growth of machine-readable data in finance, such as alternative data, requires new modeling techniques that can handle non-stationary and non-parametric data. Due to the underlying causal dependence and the size and complexity of the data, we propose a new modeling approach for financial time series data, the $\\alpha_{t}$-RIM (recurrent independent mechanism). This architecture makes use of key-value attention to integrate top-down and bottom-up information in a context-dependent and dynamic way. To model the data in such a dynamic manner, the $\\alpha_{t}$-RIM utilizes an exponentially smoothed recurrent neural network, which can model non-stationary times series data, combined with a modular and independent recurrent structure. We apply our approach to the closing prices of three selected stocks of the S\\&P 500 universe as well as their news sentiment score. The results suggest that the $\\alpha_{t}$-RIM is capable of reflecting the causal structure between stock prices and news sentiment, as well as the seasonality and trends. Consequently, this modeling approach markedly improves the generalization performance, that is, the prediction of unseen data, and outperforms state-of-the-art networks such as long short-term memory models. ",
    "url": "https://arxiv.org/abs/2205.01639",
    "authors": [
      "Nicole Koenigstein"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1901.03409",
    "title": "Graph embeddings into Hamming spaces",
    "abstract": " Comments: 3 pages ",
    "url": "https://arxiv.org/abs/1901.03409",
    "authors": [
      "Dominic van der Zypen"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:1910.01099",
    "title": "Graph modification for edge-coloured and signed graph homomorphism  problems: parameterized and classical complexity",
    "abstract": " Comments: 17 pages, 9 figures, 2 tables ",
    "url": "https://arxiv.org/abs/1910.01099",
    "authors": [
      "Florent Foucaud",
      "Herv\u00e9 Hocquard",
      "Dimitri Lajou",
      "Valia Mitsou",
      "Th\u00e9o Pierron"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:1912.10905",
    "title": "Acoustic Scene Analysis using Analog Spiking Neural Network",
    "abstract": " Comments: 21 pages, Journal ",
    "url": "https://arxiv.org/abs/1912.10905",
    "authors": [
      "Anand Kumar Mukhopadhyay",
      "Naligala Moses Prabhakar",
      "Divya Lakshmi Duggisetty",
      "Indrajit Chakrabarti",
      "Mrigank Sharad"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2006.07776",
    "title": "Domain Adaptation and Image Classification via Deep Conditional  Adaptation Network",
    "abstract": " Title: Domain Adaptation and Image Classification via Deep Conditional  Adaptation Network ",
    "url": "https://arxiv.org/abs/2006.07776",
    "authors": [
      "Pengfei Ge",
      "Chuan-Xian Ren",
      "Dao-Qing Dai",
      "Hong Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2011.14619",
    "title": "DeepCloth: Neural Garment Representation for Shape and Style Editing",
    "abstract": " Title: DeepCloth: Neural Garment Representation for Shape and Style Editing ",
    "url": "https://arxiv.org/abs/2011.14619",
    "authors": [
      "Zhaoqi Su",
      "Tao Yu",
      "Yangang Wang",
      "Yebin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2012.11073",
    "title": "Regularization in network optimization via trimmed stochastic gradient  descent with noisy label",
    "abstract": " Title: Regularization in network optimization via trimmed stochastic gradient  descent with noisy label ",
    "url": "https://arxiv.org/abs/2012.11073",
    "authors": [
      "Kensuke Nakamura",
      "Bong-Soo Sohn",
      "Kyoung-Jae Won",
      "Byung-Woo Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.02597",
    "title": "Neural 3D Video Synthesis from Multi-view Video",
    "abstract": " Comments: Accepted as an oral presentation for CVPR 2022. Project website: this https URL ",
    "url": "https://arxiv.org/abs/2103.02597",
    "authors": [
      "Tianye Li",
      "Mira Slavcheva",
      "Michael Zollhoefer",
      "Simon Green",
      "Christoph Lassner",
      "Changil Kim",
      "Tanner Schmidt",
      "Steven Lovegrove",
      "Michael Goesele",
      "Richard Newcombe",
      "Zhaoyang Lv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2104.11172",
    "title": "Inference in Opinion Dynamics under Social Pressure",
    "abstract": " Title: Inference in Opinion Dynamics under Social Pressure ",
    "url": "https://arxiv.org/abs/2104.11172",
    "authors": [
      "Ali Jadbabaie",
      "Anuran Makur",
      "Elchanan Mossel",
      "Rabih Salhab"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2104.12278",
    "title": "Causal Learning for Socially Responsible AI",
    "abstract": " Comments: 8 pages, 3 figures, accepted at IJCAI21 survey track ",
    "url": "https://arxiv.org/abs/2104.12278",
    "authors": [
      "Lu Cheng",
      "Ahmadreza Mosallanezhad",
      "Paras Sheth",
      "Huan Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2105.03155",
    "title": "Diffusion Mechanism in Residual Neural Network: Theory and Applications",
    "abstract": " Title: Diffusion Mechanism in Residual Neural Network: Theory and Applications ",
    "url": "https://arxiv.org/abs/2105.03155",
    "authors": [
      "Tangjun Wang",
      "Zehao Dou",
      "Chenglong Bao",
      "Zuoqiang Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.13086",
    "title": "Partial Maximum Correntropy Regression for Robust Trajectory Decoding  from Noisy Epidural Electrocorticographic Signals",
    "abstract": " Title: Partial Maximum Correntropy Regression for Robust Trajectory Decoding  from Noisy Epidural Electrocorticographic Signals ",
    "url": "https://arxiv.org/abs/2106.13086",
    "authors": [
      "Yuanhao Li",
      "Badong Chen",
      "Gang Wang",
      "Natsue Yoshimura",
      "Yasuharu Koike"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.15419",
    "title": "Convergent and Efficient Deep Q Network Algorithm",
    "abstract": " Title: Convergent and Efficient Deep Q Network Algorithm ",
    "url": "https://arxiv.org/abs/2106.15419",
    "authors": [
      "Zhikang T. Wang",
      "Masahito Ueda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2109.06980",
    "title": "Explainable Identification of Dementia from Transcripts using  Transformer Networks",
    "abstract": " Comments: IEEE Journal of Biomedical and Health Informatics (Accepted) ",
    "url": "https://arxiv.org/abs/2109.06980",
    "authors": [
      "Loukas Ilias",
      "Dimitris Askounis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.12249",
    "title": "A general alternating-direction implicit framework with Gaussian process  regression parameter prediction for large sparse linear systems",
    "abstract": " Title: A general alternating-direction implicit framework with Gaussian process  regression parameter prediction for large sparse linear systems ",
    "url": "https://arxiv.org/abs/2109.12249",
    "authors": [
      "Kai Jiang",
      "Xuehong Su",
      "Juan Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2109.12813",
    "title": "An optimised deep spiking neural network architecture without gradients",
    "abstract": " Comments: 18 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2109.12813",
    "authors": [
      "Yeshwanth Bethi",
      "Ying Xu",
      "Gregory Cohen",
      "Andre van Schaik",
      "Saeed Afshar"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.06123",
    "title": "COVID-19 Diagnosis from Cough Acoustics using ConvNets and Data  Augmentation",
    "abstract": " Comments: DiCOVA, top 1st, This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2110.06123",
    "authors": [
      "Saranga Kingkor Mahanta",
      "Darsh Kaushik",
      "Shubham Jain",
      "Hoang Van Truong",
      "Koushik Guha"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2110.11867",
    "title": "CeyMo: See More on Roads -- A Novel Benchmark Dataset for Road Marking  Detection",
    "abstract": " Comments: Accepted to 2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2022) ",
    "url": "https://arxiv.org/abs/2110.11867",
    "authors": [
      "Oshada Jayasinghe",
      "Sahan Hemachandra",
      "Damith Anhettigama",
      "Shenali Kariyawasam",
      "Ranga Rodrigo",
      "Peshala Jayasekara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.01221",
    "title": "Robust Federated Learning via Over-The-Air Computation",
    "abstract": " Title: Robust Federated Learning via Over-The-Air Computation ",
    "url": "https://arxiv.org/abs/2111.01221",
    "authors": [
      "Houssem Sifaou",
      "Geoffrey Ye Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.04637",
    "title": "A hemispheric two-channel code accounts for binaural unmasking in humans",
    "abstract": " Title: A hemispheric two-channel code accounts for binaural unmasking in humans ",
    "url": "https://arxiv.org/abs/2111.04637",
    "authors": [
      "J\u00f6rg Encke",
      "Mathias Dietz"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2111.10541",
    "title": "Retrieve-then-extract Based Knowledge Graph Querying Using Graph Neural  Networks",
    "abstract": " Title: Retrieve-then-extract Based Knowledge Graph Querying Using Graph Neural  Networks ",
    "url": "https://arxiv.org/abs/2111.10541",
    "authors": [
      "Hanning Gao",
      "Lingfei Wu",
      "Po Hu",
      "Zhihua Wei",
      "Fangli Xu",
      "Bo Long"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.01156",
    "title": "A Unified Framework for Adversarial Attack and Defense in Constrained  Feature Space",
    "abstract": " Title: A Unified Framework for Adversarial Attack and Defense in Constrained  Feature Space ",
    "url": "https://arxiv.org/abs/2112.01156",
    "authors": [
      "Thibault Simonetto",
      "Salijona Dyrmishi",
      "Salah Ghamizi",
      "Maxime Cordy",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.04764",
    "title": "3D-VField: Adversarial Augmentation of Point Clouds for Domain  Generalization in 3D Object Detection",
    "abstract": " Comments: CVPR 2022. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2112.04764",
    "authors": [
      "Alexander Lehner",
      "Stefano Gasperini",
      "Alvaro Marcos-Ramiro",
      "Michael Schmidt",
      "Mohammad-Ali Nikouei Mahani",
      "Nassir Navab",
      "Benjamin Busam",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2112.05787",
    "title": "Representation Learning for Conversational Data using Discourse Mutual  Information Maximization",
    "abstract": " Comments: Preprint, 15 pages, To appear in NAACL 2022 (Main) ",
    "url": "https://arxiv.org/abs/2112.05787",
    "authors": [
      "Bishal Santra",
      "Sumegh Roychowdhury",
      "Aishik Mandal",
      "Vasu Gurram",
      "Atharva Naik",
      "Manish Gupta",
      "Pawan Goyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.10166",
    "title": "FedNI: Federated Graph Learning with Network Inpainting for  Population-Based Disease Prediction",
    "abstract": " Title: FedNI: Federated Graph Learning with Network Inpainting for  Population-Based Disease Prediction ",
    "url": "https://arxiv.org/abs/2112.10166",
    "authors": [
      "Liang Peng",
      "Nan Wang",
      "Nicha Dvornek",
      "Xiaofeng Zhu",
      "Xiaoxiao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2201.00989",
    "title": "DigNet: Digging Clues from Local-Global Interactive Graph for  Aspect-level Sentiment Classification",
    "abstract": " Comments: submitted to Journal of Artificial Intelligence Research (JAIR) ",
    "url": "https://arxiv.org/abs/2201.00989",
    "authors": [
      "Bowen Xing",
      "Ivor Tsang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2201.06665",
    "title": "Text characterization based on recurrence networks",
    "abstract": " Title: Text characterization based on recurrence networks ",
    "url": "https://arxiv.org/abs/2201.06665",
    "authors": [
      "B\u00e1rbara C. e Souza",
      "Filipi N. Silva",
      "Henrique F. de Arruda",
      "Giovana D. da Silva",
      "Luciano da F. Costa",
      "Diego R. Amancio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2201.12158",
    "title": "Stagnation Detection Meets Fast Mutation",
    "abstract": " Comments: 28 pages. Full version of a paper appearing at EvoCOP 2022 ",
    "url": "https://arxiv.org/abs/2201.12158",
    "authors": [
      "Benjamin Doerr",
      "Amirhossein Rajabi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2201.13402",
    "title": "Privacy Limitations Of Interest-based Advertising On The Web: A  Post-mortem Empirical Analysis Of Google's FLoC",
    "abstract": " Title: Privacy Limitations Of Interest-based Advertising On The Web: A  Post-mortem Empirical Analysis Of Google's FLoC ",
    "url": "https://arxiv.org/abs/2201.13402",
    "authors": [
      "Alex Berke",
      "Dan Calacci"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2202.05628",
    "title": "Artemis: Articulated Neural Pets with Appearance and Motion synthesis",
    "abstract": " Title: Artemis: Articulated Neural Pets with Appearance and Motion synthesis ",
    "url": "https://arxiv.org/abs/2202.05628",
    "authors": [
      "Haimin Luo",
      "Teng Xu",
      "Yuheng Jiang",
      "Chenglin Zhou",
      "Qiwei Qiu",
      "Yingliang Zhang",
      "Wei Yang",
      "Lan Xu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00274",
    "title": "TableFormer: Robust Transformer Modeling for Table-Text Encoding",
    "abstract": " Comments: ACL 2022, 10 pages ",
    "url": "https://arxiv.org/abs/2203.00274",
    "authors": [
      "Jingfeng Yang",
      "Aditya Gupta",
      "Shyam Upadhyay",
      "Luheng He",
      "Rahul Goel",
      "Shachi Paul"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.02628",
    "title": "Target Network and Truncation Overcome The Deadly Triad in $Q$-Learning",
    "abstract": " Title: Target Network and Truncation Overcome The Deadly Triad in $Q$-Learning ",
    "url": "https://arxiv.org/abs/2203.02628",
    "authors": [
      "Zaiwei Chen",
      "John Paul Clarke",
      "Siva Theja Maguluri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.09509",
    "title": "ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and  Implicit Hate Speech Detection",
    "abstract": " Title: ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and  Implicit Hate Speech Detection ",
    "url": "https://arxiv.org/abs/2203.09509",
    "authors": [
      "Thomas Hartvigsen",
      "Saadia Gabriel",
      "Hamid Palangi",
      "Maarten Sap",
      "Dipankar Ray",
      "Ece Kamar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.09678",
    "title": "Self-Ensemble Adversarial Training for Improved Robustness",
    "abstract": " Comments: 18 pages, 3 figures, ICLR 2022 ",
    "url": "https://arxiv.org/abs/2203.09678",
    "authors": [
      "Hongjun Wang",
      "Yisen Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2204.04796",
    "title": "SOS! Self-supervised Learning Over Sets Of Handled Objects In Egocentric  Action Recognition",
    "abstract": " Title: SOS! Self-supervised Learning Over Sets Of Handled Objects In Egocentric  Action Recognition ",
    "url": "https://arxiv.org/abs/2204.04796",
    "authors": [
      "Victor Escorcia",
      "Ricardo Guerrero",
      "Xiatian Zhu",
      "Brais Martinez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07497",
    "title": "Helicity-conservative Physics-informed Neural Network Model for  Navier-Stokes Equations",
    "abstract": " Comments: 17 pages, 9 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2204.07497",
    "authors": [
      "Jiwei Jia",
      "Young Ju Lee",
      "Ziqian Li",
      "Zheng Lu",
      "Ran Zhang"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2204.09183",
    "title": "Robustness Testing of Data and Knowledge Driven Anomaly Detection in  Cyber-Physical Systems",
    "abstract": " Comments: 8 pages, 10 figures, to appear in the 5th IEEE/IFIP DSN Workshop on Dependable and Secure Machine Learning (DSN-DSML) ",
    "url": "https://arxiv.org/abs/2204.09183",
    "authors": [
      "Xugui Zhou",
      "Maxfield Kouzel",
      "Homa Alemzadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.12371",
    "title": "Social learning spontaneously emerges by searching optimal heuristics  with deep reinforcement learning",
    "abstract": " Comments: Main manuscript : 11 pages, 6 figures. Supplementary information : 7 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2204.12371",
    "authors": [
      "Seungwoong Ha",
      "Hawoong Jeong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.13653",
    "title": "GRIT: General Robust Image Task Benchmark",
    "abstract": " Title: GRIT: General Robust Image Task Benchmark ",
    "url": "https://arxiv.org/abs/2204.13653",
    "authors": [
      "Tanmay Gupta",
      "Ryan Marten",
      "Aniruddha Kembhavi",
      "Derek Hoiem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.00771",
    "title": "Local Differential Privacy Meets Computational Social Choice --  Resilience under Voter Deletion",
    "abstract": " Title: Local Differential Privacy Meets Computational Social Choice --  Resilience under Voter Deletion ",
    "url": "https://arxiv.org/abs/2205.00771",
    "authors": [
      "Liangde Tao",
      "Lin Chen",
      "Lei Xu",
      "Weidong Shi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2205.01005",
    "title": "What Factors Should Paper-Reviewer Assignments Rely On? Community  Perspectives on Issues and Ideals in Conference Peer-Review",
    "abstract": " Comments: NAACL 2022 camera-ready Replacement note: formatting mistake on pages 4-5 ",
    "url": "https://arxiv.org/abs/2205.01005",
    "authors": [
      "Terne Sasha Thorn Jakobsen",
      "Anna Rogers"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.01054",
    "title": "A Change Dynamic Model for the Online Detection of Gradual Change",
    "abstract": " Title: A Change Dynamic Model for the Online Detection of Gradual Change ",
    "url": "https://arxiv.org/abs/2205.01054",
    "authors": [
      "Chris Browne"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  }
]