[
  {
    "id": "arXiv:2205.11519",
    "title": "FedSA: Accelerating Intrusion Detection in Collaborative Environments  with Federated Simulated Annealing",
    "abstract": "Fast identification of new network attack patterns is crucial for improving network security. Nevertheless, identifying an ongoing attack in a heterogeneous network is a non-trivial task. Federated learning emerges as a solution to collaborative training for an Intrusion Detection System (IDS). The federated learning-based IDS trains a global model using local machine learning models provided by federated participants without sharing local data. However, optimization challenges are intrinsic to federated learning. This paper proposes the Federated Simulated Annealing (FedSA) metaheuristic to select the hyperparameters and a subset of participants for each aggregation round in federated learning. FedSA optimizes hyperparameters linked to the global model convergence. The proposal reduces aggregation rounds and speeds up convergence. Thus, FedSA accelerates learning extraction from local models, requiring fewer IDS updates. The proposal assessment shows that the FedSA global model converges in less than ten communication rounds. The proposal requires up to 50% fewer aggregation rounds to achieve approximately 97% accuracy in attack detection than the conventional aggregation approach. ",
    "url": "https://arxiv.org/abs/2205.11519",
    "authors": [
      "Helio N. Cunha Neto",
      "Ivana Dusparic",
      "Diogo M. F. Mattos",
      "Natalia C. Fernandes"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11551",
    "title": "Learning to Ignore Adversarial Attacks",
    "abstract": "Despite the strong performance of current NLP models, they can be brittle against adversarial attacks. To enable effective learning against adversarial inputs, we introduce the use of rationale models that can explicitly learn to ignore attack tokens. We find that the rationale models can successfully ignore over 90\\% of attack tokens. This approach leads to consistent sizable improvements ($\\sim$10\\%) over baseline models in robustness on three datasets for both BERT and RoBERTa, and also reliably outperforms data augmentation with adversarial examples alone. In many cases, we find that our method is able to close the gap between model performance on a clean test set and an attacked test set and hence reduce the effect of adversarial attacks. ",
    "url": "https://arxiv.org/abs/2205.11551",
    "authors": [
      "Yiming Zhang",
      "Yangqiaoyu Zhou",
      "Samuel Carton",
      "Chenhao Tan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11566",
    "title": "A network compression approach for quantifying the importance of  temporal contact chronology",
    "abstract": "Studies of dynamics on temporal networks often look at the overall impact of temporal structural changes, falling back on static networks when the changes are slow, or on average annealed networks when the changes are fast. In between these limits, we propose a method to quantify the importance of chronology in temporal network data by using an epidemic spreading approach and looking at the commutative property of consecutive snapshots. We use this method to reduce the number of snapshots in real sequences of contact data by algorithmically compressing consecutive snapshots. We find that the framework succeeds in mimicking the fully temporal dynamics, and can also be used to assess the sensitivity of the data to temporal variations. ",
    "url": "https://arxiv.org/abs/2205.11566",
    "authors": [
      "Andrea J. Allen",
      "Cristopher Moore",
      "Laurent H\u00e9bert-Dufresne"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2205.11589",
    "title": "Explaining Causal Models with Argumentation: the Case of Bi-variate  Reinforcement",
    "abstract": "Causal models are playing an increasingly important role in machine learning, particularly in the realm of explainable AI. We introduce a conceptualisation for generating argumentation frameworks (AFs) from causal models for the purpose of forging explanations for the models' outputs. The conceptualisation is based on reinterpreting desirable properties of semantics of AFs as explanation moulds, which are means for characterising the relations in the causal model argumentatively. We demonstrate our methodology by reinterpreting the property of bi-variate reinforcement as an explanation mould to forge bipolar AFs as explanations for the outputs of causal models. We perform a theoretical evaluation of these argumentative explanations, examining whether they satisfy a range of desirable explanatory and argumentative properties. ",
    "url": "https://arxiv.org/abs/2205.11589",
    "authors": [
      "Antonio Rago",
      "Pietro Baroni",
      "Francesca Toni"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11597",
    "title": "Wiser: Increasing Throughput in Payment Channel Networks with  Transaction Aggregation",
    "abstract": "Payment channel networks (PCNs) are one of the most prominent solutions to the limited transaction throughput of blockchains. Nevertheless, PCNs suffer themselves from a throughput limitation due to the capital constraints of their channels. A similar dependence on high capital is also found in inter-bank payment settlements, where the so-called netting technique is used to mitigate liquidity demands. In this work, we alleviate this limitation by introducing the notion of transaction aggregation: instead of executing transactions sequentially through a PCN, we enable senders to aggregate multiple transactions and execute them simultaneously to benefit from several amounts that may \"cancel out\". Two direct advantages of our proposal is the decrease in intermediary fees paid by senders as well as the obfuscation of the transaction data from the intermediaries. We formulate the transaction aggregation as a computational problem, a generalization of the Bank Clearing Problem. We present a generic framework for the transaction aggregation execution, and thereafter we propose Wiser as an implementation of this framework in a specific hub-based setting. To overcome the NP-hardness of the transaction aggregation problem, in Wiser we propose a fixed-parameter linear algorithm for a special case of transaction aggregation as well as the Bank Clearing Problem. Wiser can also be seen as a modern variant of the Hawala money transfer system, as well as a decentralized implementation of the overseas remittance service of Wise. ",
    "url": "https://arxiv.org/abs/2205.11597",
    "authors": [
      "Samarth Tiwari",
      "Michelle Yeo",
      "Zeta Avarikioti",
      "Iosif Salem",
      "Krzysztof Pietrzak",
      "Stefan Schmid"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.11603",
    "title": "Improving language models fine-tuning with representation consistency  targets",
    "abstract": "Fine-tuning contextualized representations learned by pre-trained language models has become a standard practice in the NLP field. However, pre-trained representations are prone to degradation (also known as representation collapse) during fine-tuning, which leads to instability, suboptimal performance, and weak generalization. In this paper, we propose a novel fine-tuning method that avoids representation collapse during fine-tuning by discouraging undesirable changes in the representations. We show that our approach matches or exceeds the performance of the existing regularization-based fine-tuning methods across 13 language understanding tasks (GLUE benchmark and six additional datasets). We also demonstrate its effectiveness in low-data settings and robustness to label perturbation. Furthermore, we extend previous studies of representation collapse and propose several metrics to quantify it. Using these metrics and previously proposed experiments, we show that our approach obtains significant improvements in retaining the expressive power of representations. ",
    "url": "https://arxiv.org/abs/2205.11603",
    "authors": [
      "Anastasia Razdaibiedina",
      "Vivek Madan",
      "Zohar Karnin",
      "Ashish Khetan",
      "Vishaal Kapoor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.11605",
    "title": "On Measuring Social Biases in Prompt-Based Multi-Task Learning",
    "abstract": "Large language models trained on a mixture of NLP tasks that are converted into a text-to-text format using prompts, can generalize into novel forms of language and handle novel tasks. A large body of work within prompt engineering attempts to understand the effects of input forms and prompts in achieving superior performance. We consider an alternative measure and inquire whether the way in which an input is encoded affects social biases promoted in outputs. In this paper, we study T0, a large-scale multi-task text-to-text language model trained using prompt-based learning. We consider two different forms of semantically equivalent inputs: question-answer format and premise-hypothesis format. We use an existing bias benchmark for the former BBQ and create the first bias benchmark in natural language inference BBNLI with hand-written hypotheses while also converting each benchmark into the other form. The results on two benchmarks suggest that given two different formulations of essentially the same input, T0 conspicuously acts more biased in question answering form, which is seen during training, compared to premise-hypothesis form which is unlike its training examples. Code and data are released under https://github.com/feyzaakyurek/bbnli. ",
    "url": "https://arxiv.org/abs/2205.11605",
    "authors": [
      "Afra Feyza Aky\u00fcrek",
      "Sejin Paik",
      "Muhammed Yusuf Kocyigit",
      "Seda Akbiyik",
      "\u015eerife Leman Runyun",
      "Derry Wijaya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2205.11607",
    "title": "Low-Complexity Block Coordinate Descend Based Multiuser Detection for  Uplink Grant-Free NOMA",
    "abstract": "Grant-free non-orthogonal multiple access (NOMA) scheme is considered as a promising candidate for the enabling of massive connectivity and reduced signalling overhead for Internet of Things (IoT) applications in massive machine-type communication (mMTC) networks. Exploiting the inherent nature of sporadic transmissions in the grant-free NOMA systems, compressed sensing based multiuser detection (CS-MUD) has been deemed as a powerful solution to user activity detection (UAD) and data detection (DD). In this paper, block coordinate descend (BCD) method is employed in CS-MUD to reduce the computational complexity. We propose two modified BCD based algorithms, called enhanced BCD (EBCD) and complexity reduction enhanced BCD (CR-EBCD), respectively. To be specific, by incorporating a novel candidate set pruning mechanism into the original BCD framework, our proposed EBCD algorithm achieves remarkable CS-MUD performance improvement. In addition, the proposed CR-EBCD algorithm further ameliorates the proposed EBCD by eliminating the redundant matrix multiplications during the iteration process. As a consequence, compared with the proposed EBCD algorithm, our proposed CR-EBCD algorithm enjoys two orders of magnitude complexity saving without any CS-MUD performance degradation, rendering it a viable solution for future mMTC scenarios. Extensive simulation results demonstrate the bound-approaching performance as well as ultra-low computational complexity. ",
    "url": "https://arxiv.org/abs/2205.11607",
    "authors": [
      "Pengyu Gao",
      "Zilong Liu",
      "Pei Xiao",
      "Chuan Heng Foh",
      "Jing Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.11610",
    "title": "uGLAD: Sparse graph recovery by optimizing deep unrolled networks",
    "abstract": "Probabilistic Graphical Models (PGMs) are generative models of complex systems. They rely on conditional independence assumptions between variables to learn sparse representations which can be visualized in a form of a graph. Such models are used for domain exploration and structure discovery in poorly understood domains. This work introduces a novel technique to perform sparse graph recovery by optimizing deep unrolled networks. Assuming that the input data $X\\in\\mathbb{R}^{M\\times D}$ comes from an underlying multivariate Gaussian distribution, we apply a deep model on $X$ that outputs the precision matrix $\\Theta$, which can also be interpreted as the adjacency matrix. Our model, uGLAD, builds upon and extends the state-of-the-art model GLAD to the unsupervised setting. The key benefits of our model are (1) uGLAD automatically optimizes sparsity-related regularization parameters leading to better performance than existing algorithms. (2) We introduce multi-task learning based `consensus' strategy for robust handling of missing data in an unsupervised setting. We evaluate model results on synthetic Gaussian data, non-Gaussian data generated from Gene Regulatory Networks, and present a case study in anaerobic digestion. ",
    "url": "https://arxiv.org/abs/2205.11610",
    "authors": [
      "Harsh Shrivastava",
      "Urszula Chajewska",
      "Robin Abraham",
      "Xinshi Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.11611",
    "title": "A Contrario multi-scale anomaly detection method for industrial quality  inspection",
    "abstract": "Anomalies can be defined as any non-random structure which deviates from normality. Anomaly detection methods reported in the literature are numerous and diverse, as what is considered anomalous usually varies depending on particular scenarios and applications. In this work we propose an a contrario framework to detect anomalies in images applying statistical analysis to feature maps obtained via convolutions. We evaluate filters learned from the image under analysis via patch PCA, Gabor filters and the feature maps obtained from a pre-trained deep neural network (Resnet). The proposed method is multi-scale and fully unsupervised and is able to detect anomalies in a wide variety of scenarios. While the end goal of this work is the detection of subtle defects in leather samples for the automotive industry, we show that the same algorithm achieves state-of-the-art results in public anomalies datasets. ",
    "url": "https://arxiv.org/abs/2205.11611",
    "authors": [
      "Mat\u00edas Tailanian",
      "Pablo Mus\u00e9",
      "\u00c1lvaro Pardo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11616",
    "title": "Utilizing Language-Image Pretraining for Efficient and Robust Bilingual  Word Alignment",
    "abstract": "Word translation without parallel corpora has become feasible, rivaling the performance of supervised methods. Recent findings have shown that the accuracy and robustness of unsupervised word translation (UWT) can be improved by making use of visual observations, which are universal representations across languages. In this work, we investigate the potential of using not only visual observations but also pretrained language-image models for enabling a more efficient and robust UWT. Specifically, we develop a novel UWT method dubbed Word Alignment using Language-Image Pretraining (WALIP), which leverages visual observations via the shared embedding space of images and texts provided by CLIP models (Radford et al., 2021). WALIP has a two-step procedure. First, we retrieve word pairs with high confidences of similarity, computed using our proposed image-based fingerprints, which define the initial pivot for the word alignment. Second, we apply our robust Procrustes algorithm to estimate the linear mapping between two embedding spaces, which iteratively corrects and refines the estimated alignment. Our extensive experiments show that WALIP improves upon the state-of-the-art performance of bilingual word alignment for a few language pairs across different word embeddings and displays great robustness to the dissimilarity of language pairs or training corpora for two word embeddings. ",
    "url": "https://arxiv.org/abs/2205.11616",
    "authors": [
      "Tuan Dinh",
      "Jy-yong Sohn",
      "Shashank Rajput",
      "Timothy Ossowski",
      "Yifei Ming",
      "Junjie Hu",
      "Dimitris Papailiopoulos",
      "Kangwook Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11631",
    "title": "Towards Opening the Black Box of Neural Machine Translation: Source and  Target Interpretations of the Transformer",
    "abstract": "In Neural Machine Translation (NMT), each token prediction is conditioned on the source sentence and the target prefix (what has been previously translated at a decoding step). However, previous work on interpretability in NMT has focused solely on source sentence tokens attributions. Therefore, we lack a full understanding of the influences of every input token (source sentence and target prefix) in the model predictions. In this work, we propose an interpretability method that tracks complete input token attributions. Our method, which can be extended to any encoder-decoder Transformer-based model, allows us to better comprehend the inner workings of current NMT models. We apply the proposed method to both bilingual and multilingual Transformers and present insights into their behaviour. ",
    "url": "https://arxiv.org/abs/2205.11631",
    "authors": [
      "Javier Ferrando",
      "Gerard I. G\u00e1llego",
      "Belen Alastruey",
      "Carlos Escolano",
      "Marta R. Costa-juss\u00e0"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.11664",
    "title": "Towards Model Generalization for Monocular 3D Object Detection",
    "abstract": "Monocular 3D object detection (Mono3D) has achieved tremendous improvements with emerging large-scale autonomous driving datasets and the rapid development of deep learning techniques. However, caused by severe domain gaps (e.g., the field of view (FOV), pixel size, and object size among datasets), Mono3D detectors have difficulty in generalization, leading to drastic performance degradation on unseen domains. To solve these issues, we combine the position-invariant transform and multi-scale training with the pixel-size depth strategy to construct an effective unified camera-generalized paradigm (CGP). It fully considers discrepancies in the FOV and pixel size of images captured by different cameras. Moreover, we further investigate the obstacle in quantitative metrics when cross-dataset inference through an exhaustive systematic study. We discern that the size bias of prediction leads to a colossal failure. Hence, we propose the 2D-3D geometry-consistent object scaling strategy (GCOS) to bridge the gap via an instance-level augment. Our method called DGMono3D achieves remarkable performance on all evaluated datasets and surpasses the SoTA unsupervised domain adaptation scheme even without utilizing data on the target domain. ",
    "url": "https://arxiv.org/abs/2205.11664",
    "authors": [
      "Zhenyu Li",
      "Zehui Chen",
      "Ang Li",
      "Liangji Fang",
      "Qinhong Jiang",
      "Xianming Liu",
      "Junjun Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11668",
    "title": "TIC como apoyo del soporte social al enfermo cr\u00f3nico y su cuidador :  Aproximaci\u00f3n al estado del Arte",
    "abstract": "The current approach is carried out in order to have an overview of the level of inclusion and the participation of ICTs in social support and support for vulnerable populations suffering from chronic diseases. The inclusion was made through a bibliographic review, this being the basis for the collection of data and pertinent information. The argumentative study that was carried out clearly and concisely identified the advantages and disadvantages of the use of ICT in social support from a psychoeducational and engineering point of view. The regions were characterized by the highest concentration of ICT use in the social support literature, based on previously studied content and analyzing the results of this use. ",
    "url": "https://arxiv.org/abs/2205.11668",
    "authors": [
      "Benjamin A. Huerfano Z.",
      "Andres F Ardila",
      "Pedro L Cifuentes"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2205.11678",
    "title": "Compressing Deep Graph Neural Networks via Adversarial Knowledge  Distillation",
    "abstract": "Deep graph neural networks (GNNs) have been shown to be expressive for modeling graph-structured data. Nevertheless, the over-stacked architecture of deep graph models makes it difficult to deploy and rapidly test on mobile or embedded systems. To compress over-stacked GNNs, knowledge distillation via a teacher-student architecture turns out to be an effective technique, where the key step is to measure the discrepancy between teacher and student networks with predefined distance functions. However, using the same distance for graphs of various structures may be unfit, and the optimal distance formulation is hard to determine. To tackle these problems, we propose a novel Adversarial Knowledge Distillation framework for graph models named GraphAKD, which adversarially trains a discriminator and a generator to adaptively detect and decrease the discrepancy. Specifically, noticing that the well-captured inter-node and inter-class correlations favor the success of deep GNNs, we propose to criticize the inherited knowledge from node-level and class-level views with a trainable discriminator. The discriminator distinguishes between teacher knowledge and what the student inherits, while the student GNN works as a generator and aims to fool the discriminator. To our best knowledge, GraphAKD is the first to introduce adversarial training to knowledge distillation in graph domains. Experiments on node-level and graph-level classification benchmarks demonstrate that GraphAKD improves the student performance by a large margin. The results imply that GraphAKD can precisely transfer knowledge from a complicated teacher GNN to a compact student GNN. ",
    "url": "https://arxiv.org/abs/2205.11678",
    "authors": [
      "Huarui He",
      "Jie Wang",
      "Zhanqiu Zhang",
      "Feng Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11680",
    "title": "HiPAL: A Deep Framework for Physician Burnout Prediction Using Activity  Logs in Electronic Health Records",
    "abstract": "Burnout is a significant public health concern affecting nearly half of the healthcare workforce. This paper presents the first end-to-end deep learning framework for predicting physician burnout based on clinician activity logs, digital traces of their work activities, available in any electronic health record (EHR) system. In contrast to prior approaches that exclusively relied on surveys for burnout measurement, our framework directly learns deep workload representations from large-scale clinician activity logs to predict burnout. We propose the Hierarchical burnout Prediction based on Activity Logs (HiPAL), featuring a pre-trained time-dependent activity embedding mechanism tailored for activity logs and a hierarchical predictive model, which mirrors the natural hierarchical structure of clinician activity logs and captures physician's evolving workload patterns at both short-term and long-term levels. To utilize the large amount of unlabeled activity logs, we propose a semi-supervised framework that learns to transfer knowledge extracted from unlabeled clinician activities to the HiPAL-based prediction model. The experiment on over 15 million clinician activity logs collected from the EHR at a large academic medical center demonstrates the advantages of our proposed framework in predictive performance of physician burnout and training efficiency over state of the art approaches. ",
    "url": "https://arxiv.org/abs/2205.11680",
    "authors": [
      "Hanyang Liu",
      "Sunny S. Lou",
      "Benjamin C. Warner",
      "Derek R. Harford",
      "Thomas Kannampallil",
      "Chenyang Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11691",
    "title": "High-Order Pooling for Graph Neural Networks with Tensor Decomposition",
    "abstract": "Graph Neural Networks (GNNs) are attracting growing attention due to their effectiveness and flexibility in modeling a variety of graph-structured data. Exiting GNN architectures usually adopt simple pooling operations (e.g., sum, average, max) when aggregating messages from a local neighborhood for updating node representation or pooling node representations from the entire graph to compute the graph representation. Though simple and effective, these linear operations do not model high-order non-linear interactions among nodes. We propose the Tensorized Graph Neural Network (tGNN), a highly expressive GNN architecture relying on tensor decomposition to model high-order non-linear node interactions. tGNN leverages the symmetric CP decomposition to efficiently parameterize permutation-invariant multilinear maps for modeling node interactions. Theoretical and empirical analysis on both node and graph classification tasks show the superiority of tGNN over competitive baselines. In particular, tGNN achieves state-of-the-art results on two OGB node classification datasets and one OGB graph classification dataset. ",
    "url": "https://arxiv.org/abs/2205.11691",
    "authors": [
      "Chenqing Hua",
      "Guillaume Rabusseau",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11702",
    "title": "Functional Network: A Novel Framework for Interpretability of Deep  Neural Networks",
    "abstract": "The layered structure of deep neural networks hinders the use of numerous analysis tools and thus the development of its interpretability. Inspired by the success of functional brain networks, we propose a novel framework for interpretability of deep neural networks, that is, the functional network. We construct the functional network of fully connected networks and explore its small-worldness. In our experiments, the mechanisms of regularization methods, namely, batch normalization and dropout, are revealed using graph theoretical analysis and topological data analysis. Our empirical analysis shows the following: (1) Batch normalization enhances model performance by increasing the global e ciency and the number of loops but reduces adversarial robustness by lowering the fault tolerance. (2) Dropout improves generalization and robustness of models by improving the functional specialization and fault tolerance. (3) The models with dierent regularizations can be clustered correctly according to their functional topological dierences, re ecting the great potential of the functional network and topological data analysis in interpretability. ",
    "url": "https://arxiv.org/abs/2205.11702",
    "authors": [
      "Ben Zhang",
      "Zhetong Dong",
      "Junsong Zhang",
      "Hongwei Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11707",
    "title": "A Complex Java Code Generator for ACL2 Based on a Shallow Embedding of  ACL2 in Java",
    "abstract": "This paper describes a code generator that translates ACL2 constructs to corresponding Java constructs, according to a shallow embedding of ACL2 in Java. Starting from purely functional ACL2 code, the generated Java code exhibits imperative and object-oriented features like destructive updates, loops, and overloading. The overall translation from ACL2 to Java is fairly elaborate, consisting of several ACL2-to-ACL2 pre-translation steps, an ACL2-to-Java proper translation step, and several Java-to-Java post-translation steps. Experiments suggest that the generated Java code is not much slower than the ACL2 code. The code generator can also recognize, and translate to Java, ACL2 representations of certain Java constructs, forerunning a code generation approach based on a shallow embedding of Java in ACL2 (i.e. going the other way). This code generator builds upon, and significantly extends, a simple Java code generator for ACL2 based on a deep embedding of ACL2 in Java. ",
    "url": "https://arxiv.org/abs/2205.11707",
    "authors": [
      "Alessandro Coglio"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.11708",
    "title": "A Proof-Generating C Code Generator for ACL2 Based on a Shallow  Embedding of C in ACL2",
    "abstract": "This paper describes a C code generator for ACL2 that recognizes ACL2 representations of C constructs, according to a shallow embedding of C in ACL2, and translates those representations to the represented C constructs. The code generator also generates ACL2 theorems asserting the correctness of the C code with respect to the ACL2 code. The code generator currently supports a limited but growing subset of C that already suffices for some interesting programs. This paper also offers a general perspective on language embedding and code generation. ",
    "url": "https://arxiv.org/abs/2205.11708",
    "authors": [
      "Alessandro Coglio"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.11710",
    "title": "SCVRL: Shuffled Contrastive Video Representation Learning",
    "abstract": "We propose SCVRL, a novel contrastive-based framework for self-supervised learning for videos. Differently from previous contrast learning based methods that mostly focus on learning visual semantics (e.g., CVRL), SCVRL is capable of learning both semantic and motion patterns. For that, we reformulate the popular shuffling pretext task within a modern contrastive learning paradigm. We show that our transformer-based network has a natural capacity to learn motion in self-supervised settings and achieves strong performance, outperforming CVRL on four benchmarks. ",
    "url": "https://arxiv.org/abs/2205.11710",
    "authors": [
      "Michael Dorkenwald",
      "Fanyi Xiao",
      "Biagio Brattoli",
      "Joseph Tighe",
      "Davide Modolo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11716",
    "title": "Randomly Initialized One-Layer Neural Networks Make Data Linearly  Separable",
    "abstract": "Recently, neural networks have been shown to perform exceptionally well in transforming two arbitrary sets into two linearly separable sets. Doing this with a randomly initialized neural network is of immense interest because the associated computation is cheaper than using fully trained networks. In this paper, we show that, with sufficient width, a randomly initialized one-layer neural network transforms two sets into two linearly separable sets with high probability. Furthermore, we provide explicit bounds on the required width of the neural network for this to occur. Our first bound is exponential in the input dimension and polynomial in all other parameters, while our second bound is independent of the input dimension, thereby overcoming the curse of dimensionality. We also perform an experimental study comparing the separation capacity of randomly initialized one-layer and two-layer neural networks. With correctly chosen biases, our study shows for low-dimensional data, the two-layer neural network outperforms the one-layer network. However, the opposite is observed for higher-dimensional data. ",
    "url": "https://arxiv.org/abs/2205.11716",
    "authors": [
      "Promit Ghosal",
      "Srinath Mahankali",
      "Yihang Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.11718",
    "title": "Semi-Parametric Deep Neural Networks in Linear Time and Memory",
    "abstract": "Recent advances in deep learning have been driven by large-scale parametric models, which can be computationally expensive and lack interpretability. Semi-parametric methods query the training set at inference time and can be more compact, although they typically have quadratic computational complexity. Here, we introduce SPIN, a general-purpose semi-parametric neural architecture whose computational cost is linear in the size and dimensionality of the data. Our architecture is inspired by inducing point methods and relies on a novel application of cross-attention between datapoints. At inference time, its computational cost is constant in the training set size as the data gets distilled into a fixed number of inducing points. We find that our method reduces the computational requirements of existing semi-parametric models by up to an order of magnitude across a range of datasets and improves state-of-the-art performance on an important practical problem, genotype imputation. ",
    "url": "https://arxiv.org/abs/2205.11718",
    "authors": [
      "Richa Rastogi",
      "Yuntian Deng",
      "Ian Lee",
      "Mert R. Sabuncu",
      "Volodymyr Kuleshov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11720",
    "title": "Embedding Neighborhoods Simultaneously t-SNE (ENS-t-SNE)",
    "abstract": "We propose an algorithm for visualizing a dataset by embedding it in 3-dimensional Euclidean space based on various given distances between the same pairs of datapoints. Its aim is to find an Embedding which preserves Neighborhoods Simultaneously for all given distances by generalizing the t-Stochastic Neighborhood Embedding approach (ENS-t-SNE). We illustrate the utility of ENS-t-SNE by demonstrating its use in three applications. First, to visualize different notions of clusters and groups within the same high-dimensional dataset with one 3-dimensional embedding, as opposed to providing different embeddings of the same data and trying to match the corresponding points. Second, to illustrate the effects of different hyper-parameters of the classical t-SNE. Third, by considering multiple different notions of clustering in data, ENS-t-SNE can generate an alternative embedding than the classic t-SNE. We provide an extensive quantitative evaluation with real-world and synthetic datasets of different sizes and using different numbers of projections. ",
    "url": "https://arxiv.org/abs/2205.11720",
    "authors": [
      "Vahan Huroyan",
      "Raymundo Navarrete",
      "Md Iqbal Hossain",
      "Stephen Kobourov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2205.11725",
    "title": "A Survey on Neural Open Information Extraction: Current Status and  Future Directions",
    "abstract": "Open Information Extraction (OpenIE) facilitates domain-independent discovery of relational facts from large corpora. The technique well suits many open-world natural language understanding scenarios, such as automatic knowledge base construction, open-domain question answering, and explicit reasoning. Thanks to the rapid development in deep learning technologies, numerous neural OpenIE architectures have been proposed and achieve considerable performance improvement. In this survey, we provide an extensive overview of the-state-of-the-art neural OpenIE models, their key design decisions, strengths and weakness. Then, we discuss limitations of current solutions and the open issues in OpenIE problem itself. Finally we list recent trends that could help expand its scope and applicability, setting up promising directions for future research in OpenIE. To our best knowledge, this paper is the first review on this specific topic. ",
    "url": "https://arxiv.org/abs/2205.11725",
    "authors": [
      "Shaowen Zhou",
      "Bowen Yu",
      "Aixin Sun",
      "Cheng Long",
      "Jingyang Li",
      "Jian Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.11736",
    "title": "Towards a Defense against Backdoor Attacks in Continual Federated  Learning",
    "abstract": "Backdoor attacks are a major concern in federated learning (FL) pipelines where training data is sourced from untrusted clients over long periods of time (i.e., continual learning). Preventing such attacks is difficult because defenders in FL do not have access to raw training data. Moreover, in a phenomenon we call backdoor leakage, models trained continuously eventually suffer from backdoors due to cumulative errors in backdoor defense mechanisms. We propose a novel framework for defending against backdoor attacks in the federated continual learning setting. Our framework trains two models in parallel: a backbone model and a shadow model. The backbone is trained without any defense mechanism to obtain good performance on the main task. The shadow model combines recent ideas from robust covariance estimation-based filters with early-stopping to control the attack success rate even as the data distribution changes. We provide theoretical motivation for this design and show experimentally that our framework significantly improves upon existing defenses against backdoor attacks. ",
    "url": "https://arxiv.org/abs/2205.11736",
    "authors": [
      "Shuaiqi Wang",
      "Jonathan Hayase",
      "Giulia Fanti",
      "Sewoong Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.11738",
    "title": "Adaptive Few-Shot Learning Algorithm for Rare Sound Event Detection",
    "abstract": "Sound event detection is to infer the event by understanding the surrounding environmental sounds. Due to the scarcity of rare sound events, it becomes challenging for the well-trained detectors which have learned too much prior knowledge. Meanwhile, few-shot learning methods promise a good generalization ability when facing a new limited-data task. Recent approaches have achieved promising results in this field. However, these approaches treat each support example independently, ignoring the information of other examples from the whole task. Because of this, most of previous methods are constrained to generate a same feature embedding for all test-time tasks, which is not adaptive to each inputted data. In this work, we propose a novel task-adaptive module which is easy to plant into any metric-based few-shot learning frameworks. The module could identify the task-relevant feature dimension. Incorporating our module improves the performance considerably on two datasets over baseline methods, especially for the transductive propagation network. Such as +6.8% for 5-way 1-shot accuracy on ESC-50, and +5.9% on noiseESC-50. We investigate our approach in the domain-mismatch setting and also achieve better results than previous methods. ",
    "url": "https://arxiv.org/abs/2205.11738",
    "authors": [
      "Chendong Zhao",
      "Jianzong Wang",
      "Leilai Li",
      "Xiaoyang Qu",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.11739",
    "title": "Deep Learning Meets Software Engineering: A Survey on Pre-Trained Models  of Source Code",
    "abstract": "Recent years have seen the successful application of deep learning to software engineering (SE). In particular, the development and use of pre-trained models of source code has enabled state-of-the-art results to be achieved on a wide variety of SE tasks. This paper provides an overview of this rapidly advancing field of research and reflects on future research directions. ",
    "url": "https://arxiv.org/abs/2205.11739",
    "authors": [
      "Changan Niu",
      "Chuanyi Li",
      "Bin Luo",
      "Vincent Ng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11744",
    "title": "Alleviating Robust Overfitting of Adversarial Training With Consistency  Regularization",
    "abstract": "Adversarial training (AT) has proven to be one of the most effective ways to defend Deep Neural Networks (DNNs) against adversarial attacks. However, the phenomenon of robust overfitting, i.e., the robustness will drop sharply at a certain stage, always exists during AT. It is of great importance to decrease this robust generalization gap in order to obtain a robust model. In this paper, we present an in-depth study towards the robust overfitting from a new angle. We observe that consistency regularization, a popular technique in semi-supervised learning, has a similar goal as AT and can be used to alleviate robust overfitting. We empirically validate this observation, and find a majority of prior solutions have implicit connections to consistency regularization. Motivated by this, we introduce a new AT solution, which integrates the consistency regularization and Mean Teacher (MT) strategy into AT. Specifically, we introduce a teacher model, coming from the average weights of the student models over the training steps. Then we design a consistency loss function to make the prediction distribution of the student models over adversarial examples consistent with that of the teacher model over clean samples. Experiments show that our proposed method can effectively alleviate robust overfitting and improve the robustness of DNN models against common adversarial attacks. ",
    "url": "https://arxiv.org/abs/2205.11744",
    "authors": [
      "Shudong Zhang",
      "Haichang Gao",
      "Tianwei Zhang",
      "Yunyi Zhou",
      "Zihui Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11755",
    "title": "MOSPAT: AutoML based Model Selection and Parameter Tuning for Time  Series Anomaly Detection",
    "abstract": "Organizations leverage anomaly and changepoint detection algorithms to detect changes in user behavior or service availability and performance. Many off-the-shelf detection algorithms, though effective, cannot readily be used in large organizations where thousands of users monitor millions of use cases and metrics with varied time series characteristics and anomaly patterns. The selection of algorithm and parameters needs to be precise for each use case: manual tuning does not scale, and automated tuning requires ground truth, which is rarely available. In this paper, we explore MOSPAT, an end-to-end automated machine learning based approach for model and parameter selection, combined with a generative model to produce labeled data. Our scalable end-to-end system allows individual users in large organizations to tailor time-series monitoring to their specific use case and data characteristics, without expert knowledge of anomaly detection algorithms or laborious manual labeling. Our extensive experiments on real and synthetic data demonstrate that this method consistently outperforms using any single algorithm. ",
    "url": "https://arxiv.org/abs/2205.11755",
    "authors": [
      "Sourav Chatterjee",
      "Rohan Bopardikar",
      "Marius Guerard",
      "Uttam Thakore",
      "Xiaodong Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11756",
    "title": "UMSNet: An Universal Multi-sensor Network for Human Activity Recognition",
    "abstract": "Human activity recognition (HAR) based on multimodal sensors has become a rapidly growing branch of biometric recognition and artificial intelligence. However, how to fully mine multimodal time series data and effectively learn accurate behavioral features has always been a hot topic in this field. Practical applications also require a well-generalized framework that can quickly process a variety of raw sensor data and learn better feature representations. This paper proposes a universal multi-sensor network (UMSNet) for human activity recognition. In particular, we propose a new lightweight sensor residual block (called LSR block), which improves the performance by reducing the number of activation function and normalization layers, and adding inverted bottleneck structure and grouping convolution. Then, the Transformer is used to extract the relationship of series features to realize the classification and recognition of human activities. Our framework has a clear structure and can be directly applied to various types of multi-modal Time Series Classification (TSC) tasks after simple specialization. Extensive experiments show that the proposed UMSNet outperforms other state-of-the-art methods on two popular multi-sensor human activity recognition datasets (i.e. HHAR dataset and MHEALTH dataset). ",
    "url": "https://arxiv.org/abs/2205.11756",
    "authors": [
      "Jialiang Wang",
      "Haotian Wei",
      "Yi Wang",
      "Shu Yang",
      "Chi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11765",
    "title": "Byzantine-Robust Federated Learning with Optimal Statistical Rates and  Privacy Guarantees",
    "abstract": "We propose Byzantine-robust federated learning protocols with nearly optimal statistical rates. In contrast to prior work, our proposed protocols improve the dimension dependence and achieve a tight statistical rate in terms of all the parameters for strongly convex losses. We benchmark against competing protocols and show the empirical superiority of the proposed protocols. Finally, we remark that our protocols with bucketing can be naturally combined with privacy-guaranteeing procedures to introduce security against a semi-honest server. The code for evaluation is provided in https://github.com/wanglun1996/secure-robust-federated-learning. ",
    "url": "https://arxiv.org/abs/2205.11765",
    "authors": [
      "Banghua Zhu",
      "Lun Wang",
      "Qi Pang",
      "Shuai Wang",
      "Jiantao Jiao",
      "Dawn Song",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.11771",
    "title": "Learning Context-Aware Service Representation for Service Recommendation  in Workflow Composition",
    "abstract": "As increasingly more software services have been published onto the Internet, it remains a significant challenge to recommend suitable services to facilitate scientific workflow composition. This paper proposes a novel NLP-inspired approach to recommending services throughout a workflow development process, based on incrementally learning latent service representation from workflow provenance. A workflow composition process is formalized as a step-wise, context-aware service generation procedure, which is mapped to next-word prediction in a natural language sentence. Historical service dependencies are extracted from workflow provenance to build and enrich a knowledge graph. Each path in the knowledge graph reflects a scenario in a data analytics experiment, which is analogous to a sentence in a conversation. All paths are thus formalized as composable service sequences and are mined, using various patterns, from the established knowledge graph to construct a corpus. Service embeddings are then learned by applying deep learning model from the NLP field. Extensive experiments on the real-world dataset demonstrate the effectiveness and efficiency of the approach. ",
    "url": "https://arxiv.org/abs/2205.11771",
    "authors": [
      "Xihao Xie",
      "Jia Zhang",
      "Rahul Ramachandran",
      "Tsengdar J. Lee",
      "Seungwon Lee"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11772",
    "title": "Multi-Augmentation for Efficient Visual Representation Learning for  Self-supervised Pre-training",
    "abstract": "In recent years, self-supervised learning has been studied to deal with the limitation of available labeled-dataset. Among the major components of self-supervised learning, the data augmentation pipeline is one key factor in enhancing the resulting performance. However, most researchers manually designed the augmentation pipeline, and the limited collections of transformation may cause the lack of robustness of the learned feature representation. In this work, we proposed Multi-Augmentations for Self-Supervised Representation Learning (MA-SSRL), which fully searched for various augmentation policies to build the entire pipeline to improve the robustness of the learned feature representation. MA-SSRL successfully learns the invariant feature representation and presents an efficient, effective, and adaptable data augmentation pipeline for self-supervised pre-training on different distribution and domain datasets. MA-SSRL outperforms the previous state-of-the-art methods on transfer and semi-supervised benchmarks while requiring fewer training epochs. ",
    "url": "https://arxiv.org/abs/2205.11772",
    "authors": [
      "Van-Nhiem Tran",
      "Chi-En Huang",
      "Shen-Hsuan Liu",
      "Kai-Lin Yang",
      "Timothy Ko",
      "Yung-Hui Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11775",
    "title": "Constrained Monotonic Neural Networks",
    "abstract": "Deep neural networks are becoming increasingly popular in approximating arbitrary functions from noisy data. But wider adoption is being hindered by the need to explain such models and to impose additional constraints on them. Monotonicity constraint is one of the most requested properties in real-world scenarios and is the focus of this paper. One of the oldest ways to construct a monotonic fully connected neural network is to constrain its weights to be non-negative while employing a monotonic activation function. Unfortunately, this construction does not work with popular non-saturated activation functions such as ReLU, ELU, SELU etc, as it can only approximate convex functions. We show this shortcoming can be fixed by employing the original activation function for a part of the neurons in the layer, and employing its point reflection for the other part. Our experiments show this approach of building monotonic deep neural networks have matching or better accuracy when compared to other state-of-the-art methods such as deep lattice networks or monotonic networks obtained by heuristic regularization. This method is the simplest one in the sense of having the least number of parameters, not requiring any modifications to the learning procedure or steps post-learning steps. ",
    "url": "https://arxiv.org/abs/2205.11775",
    "authors": [
      "Davor Runje",
      "Sharath M. Shankaranarayana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11782",
    "title": "Fine-grained Poisoning Attacks to Local Differential Privacy Protocols  for Mean and Variance Estimation",
    "abstract": "Local differential privacy (LDP) protects individual data contributors against privacy-probing data aggregation and analytics. Recent work has shown that LDP for some specific data types is vulnerable to data poisoning attacks, which enable the attacker to alter analytical results by injecting carefully-crafted bogus data. In this work, we focus on applying data poisoning attack to unexplored statistical tasks, i.e. mean and variance estimations. In contrast to prior work that aims for overall LDP performance degradation or straightforward attack gain maximization, our attacker can fine-tune the LDP estimated mean/variance to the desired target values and simultaneously manipulate them. To accomplish this goal, we propose two types of data poisoning attacks: input poisoning attack (IPA) and output poisoning attack (OPA). The former is independent of LDP while the latter utilizes the characteristics of LDP, thus being more effective. More intriguingly, we observe a security-privacy consistency where a small $\\epsilon$ enhances the security of LDP contrary to the previous conclusion of a security-privacy trade-off. We further study the consistency and reveal a more holistic view of the threat landscape of LDP in the presence of data poisoning attacks. We comprehensively evaluate the attacks on three real-world datasets and report their effectiveness for achieving the target values. We also explore defense mechanisms and provide insights into the secure LDP design. ",
    "url": "https://arxiv.org/abs/2205.11782",
    "authors": [
      "Xiaoguang Li",
      "Neil Zhenqiang Gong",
      "Ninghui Li",
      "Wenhai Sun",
      "Hui Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.11783",
    "title": "Smart Grid: Cyber Attacks, Critical Defense Approaches, and Digital Twin",
    "abstract": "As a national critical infrastructure, the smart grid has attracted widespread attention for its cybersecurity issues. The development towards an intelligent, digital, and Internetconnected smart grid has attracted external adversaries for malicious activities. It is necessary to enhance its cybersecurity by either improving the existing defense approaches or introducing novel developed technologies to the smart grid context. As an emerging technology, digital twin (DT) is considered as an enabler for enhanced security. However, the practical implementation is quite challenging. This is due to the knowledge barriers among smart grid designers, security experts, and DT developers. Each single domain is a complicated system covering various components and technologies. As a result, works are needed to sort out relevant contents so that DT can be better embedded in the security architecture design of smart grid. In order to meet this demand, our paper covers the above three domains, i.e., smart grid, cybersecurity, and DT. Specifically, the paper i) introduces the background of the smart grid; ii) reviews external cyber attacks from attack incidents and attack methods; iii) introduces critical defense approaches in industrial cyber systems, which include device identification, vulnerability discovery, intrusion detection systems (IDSs), honeypots, attribution, and threat intelligence (TI); iv) reviews the relevant content of DT, including its basic concepts, applications in the smart grid, and how DT enhances the security. In the end, the paper puts forward our security considerations on the future development of DT-based smart grid. The survey is expected to help developers break knowledge barriers among smart grid, cybersecurity, and DT, and provide guidelines for future security design of DT-based smart grid. ",
    "url": "https://arxiv.org/abs/2205.11783",
    "authors": [
      "Tianming Zheng",
      "Ming Liu",
      "Deepak Puthal",
      "Ping Yi",
      "Yue Wu",
      "Xiangjian He"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.11784",
    "title": "LOCUS 2.0: Robust and Computationally Efficient Lidar Odometry for  Real-Time Underground 3D Mapping",
    "abstract": "Lidar odometry has attracted considerable attention as a robust localization method for autonomous robots operating in complex GNSS-denied environments. However, achieving reliable and efficient performance on heterogeneous platforms in large-scale environments remains an open challenge due to the limitations of onboard computation and memory resources needed for autonomous operation. In this work, we present LOCUS 2.0, a robust and computationally-efficient \\lidar odometry system for real-time underground 3D mapping. LOCUS 2.0 includes a novel normals-based \\morrell{Generalized Iterative Closest Point (GICP)} formulation that reduces the computation time of point cloud alignment, an adaptive voxel grid filter that maintains the desired computation load regardless of the environment's geometry, and a sliding-window map approach that bounds the memory consumption. The proposed approach is shown to be suitable to be deployed on heterogeneous robotic platforms involved in large-scale explorations under severe computation and memory constraints. We demonstrate LOCUS 2.0, a key element of the CoSTAR team's entry in the DARPA Subterranean Challenge, across various underground scenarios. We release LOCUS 2.0 as an open-source library and also release a \\lidar-based odometry dataset in challenging and large-scale underground environments. The dataset features legged and wheeled platforms in multiple environments including fog, dust, darkness, and geometrically degenerate surroundings with a total of $11~h$ of operations and $16~km$ of distance traveled. ",
    "url": "https://arxiv.org/abs/2205.11784",
    "authors": [
      "Andrzej Reinke",
      "Matteo Palieri",
      "Benjamin Morrell",
      "Yun Chang",
      "Kamak Ebadi",
      "Luca Carlone",
      "Ali-akbar Agha-mohammadi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.11785",
    "title": "AFNet-M: Adaptive Fusion Network with Masks for 2D+3D Facial Expression  Recognition",
    "abstract": "2D+3D facial expression recognition (FER) can effectively cope with illumination changes and pose variations by simultaneously merging 2D texture and more robust 3D depth information. Most deep learning-based approaches employ the simple fusion strategy that concatenates the multimodal features directly after fully-connected layers, without considering the different degrees of significance for each modality. Meanwhile, how to focus on both 2D and 3D local features in salient regions is still a great challenge. In this letter, we propose the adaptive fusion network with masks (AFNet-M) for 2D+3D FER. To enhance 2D and 3D local features, we take the masks annotating salient regions of the face as prior knowledge and design the mask attention module (MA) which can automatically learn two modulation vectors to adjust the feature maps. Moreover, we introduce a novel fusion strategy that can perform adaptive fusion at convolutional layers through the designed importance weights computing module (IWC). Experimental results demonstrate that our AFNet-M achieves the state-of-the-art performance on BU-3DFE and Bosphorus datasets and requires fewer parameters in comparison with other models. ",
    "url": "https://arxiv.org/abs/2205.11785",
    "authors": [
      "Mingzhe Sui",
      "Hanting Li",
      "Zhaoqing Zhu",
      "Feng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11786",
    "title": "Transition to Linearity of General Neural Networks with Directed Acyclic  Graph Architecture",
    "abstract": "In this paper we show that feedforward neural networks corresponding to arbitrary directed acyclic graphs undergo transition to linearity as their \"width\" approaches infinity. The width of these general networks is characterized by the minimum in-degree of their neurons, except for the input and first layers. Our results identify the mathematical structure underlying transition to linearity and generalize a number of recent works aimed at characterizing transition to linearity or constancy of the Neural Tangent Kernel for standard architectures. ",
    "url": "https://arxiv.org/abs/2205.11786",
    "authors": [
      "Libin Zhu",
      "Chaoyue Liu",
      "Mikhail Belkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11787",
    "title": "Quadratic models for understanding neural network dynamics",
    "abstract": "In this work, we propose using a quadratic model as a tool for understanding properties of wide neural networks in both optimization and generalization. We show analytically that certain deep learning phenomena such as the \"catapult phase\" from [Lewkowycz et al. 2020], which cannot be captured by linear models, are manifested in the quadratic model for shallow ReLU networks. Furthermore, our empirical results indicate that the behaviour of quadratic models parallels that of neural networks in generalization, especially in the large learning rate regime. We expect that quadratic models will serve as a useful tool for analysis of neural networks. ",
    "url": "https://arxiv.org/abs/2205.11787",
    "authors": [
      "Libin Zhu",
      "Chaoyue Liu",
      "Adityanarayanan Radhakrishnan",
      "Mikhail Belkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11796",
    "title": "G-Rep: Gaussian Representation for Arbitrary-Oriented Object Detection",
    "abstract": "Arbitrary-oriented object representations contain the oriented bounding box (OBB), quadrilateral bounding box (QBB), and point set (PointSet). Each representation encounters problems that correspond to its characteristics, such as the boundary discontinuity, square-like problem, representation ambiguity, and isolated points, which lead to inaccurate detection. Although many effective strategies have been proposed for various representations, there is still no unified solution. Current detection methods based on Gaussian modeling have demonstrated the possibility of breaking this dilemma; however, they remain limited to OBB. To go further, in this paper, we propose a unified Gaussian representation called G-Rep to construct Gaussian distributions for OBB, QBB, and PointSet, which achieves a unified solution to various representations and problems. Specifically, PointSet or QBB-based objects are converted into Gaussian distributions, and their parameters are optimized using the maximum likelihood estimation algorithm. Then, three optional Gaussian metrics are explored to optimize the regression loss of the detector because of their excellent parameter optimization mechanisms. Furthermore, we also use Gaussian metrics for sampling to align label assignment and regression loss. Experimental results on several public available datasets, DOTA, HRSC2016, UCAS-AOD, and ICDAR2015 show the excellent performance of the proposed method for arbitrary-oriented object detection. The code has been open sourced at https://github.com/open-mmlab/mmrotate. ",
    "url": "https://arxiv.org/abs/2205.11796",
    "authors": [
      "Liping Hou",
      "Ke Lu",
      "Xue Yang",
      "Yuqiu Li",
      "Jian Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11803",
    "title": "WeDef: Weakly Supervised Backdoor Defense for Text Classification",
    "abstract": "Existing backdoor defense methods are only effective for limited trigger types. To defend different trigger types at once, we start from the class-irrelevant nature of the poisoning process and propose a novel weakly supervised backdoor defense framework WeDef. Recent advances in weak supervision make it possible to train a reasonably accurate text classifier using only a small number of user-provided, class-indicative seed words. Such seed words shall be considered independent of the triggers. Therefore, a weakly supervised text classifier trained by only the poisoned documents without their labels will likely have no backdoor. Inspired by this observation, in WeDef, we define the reliability of samples based on whether the predictions of the weak classifier agree with their labels in the poisoned training set. We further improve the results through a two-phase sanitization: (1) iteratively refine the weak classifier based on the reliable samples and (2) train a binary poison classifier by distinguishing the most unreliable samples from the most reliable samples. Finally, we train the sanitized model on the samples that the poison classifier predicts as benign. Extensive experiments show that WeDefis effective against popular trigger-based attacks (e.g., words, sentences, and paraphrases), outperforming existing defense methods. ",
    "url": "https://arxiv.org/abs/2205.11803",
    "authors": [
      "Lesheng Jin",
      "Zihan Wang",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11804",
    "title": "Package Theft Detection from Smart Home Security Cameras",
    "abstract": "Package theft detection has been a challenging task mainly due to lack of training data and a wide variety of package theft cases in reality. In this paper, we propose a new Global and Local Fusion Package Theft Detection Embedding (GLF-PTDE) framework to generate package theft scores for each segment within a video to fulfill the real-world requirements on package theft detection. Moreover, we construct a novel Package Theft Detection dataset to facilitate the research on this task. Our method achieves 80% AUC performance on the newly proposed dataset, showing the effectiveness of the proposed GLF-PTDE framework and its robustness in different real scenes for package theft detection. ",
    "url": "https://arxiv.org/abs/2205.11804",
    "authors": [
      "Hung-Min Hsu",
      "Xinyu Yuan",
      "Baohua Zhu",
      "Zhongwei Cheng",
      "Lin Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11807",
    "title": "NFL: Robust Learned Index via Distribution Transformation",
    "abstract": "Recent works on learned index open a new direction for the indexing field. The key insight of the learned index is to approximate the mapping between keys and positions with piece-wise linear functions. Such methods require partitioning key space for a better approximation. Although lots of heuristics are proposed to improve the approximation quality, the bottleneck is that the segmentation overheads could hinder the overall performance. This paper tackles the approximation problem by applying a \\textit{distribution transformation} to the keys before constructing the learned index. A two-stage Normalizing-Flow-based Learned index framework (NFL) is proposed, which first transforms the original complex key distribution into a near-uniform distribution, then builds a learned index leveraging the transformed keys. For effective distribution transformation, we propose a Numerical Normalizing Flow (Numerical NF). Based on the characteristics of the transformed keys, we propose a robust After-Flow Learned Index (AFLI). To validate the performance, comprehensive evaluations are conducted on both synthetic and real-world workloads, which shows that the proposed NFL produces the highest throughput and the lowest tail latency compared to the state-of-the-art learned indexes. ",
    "url": "https://arxiv.org/abs/2205.11807",
    "authors": [
      "Shangyu Wu",
      "Yufei Cui",
      "Jinghuan Yu",
      "Xuan Sun",
      "Tei-Wei Kuo",
      "Chun Jason Xue"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11808",
    "title": "Increasing Cellular Network Energy Efficiency for Railway Corridors",
    "abstract": "Modern trains act as Faraday cages making it challenging to provide high cellular data capacities to passengers. A solution is the deployment of linear cells along railway tracks, forming a cellular corridor. To provide a sufficiently high data capacity, many cell sites need to be installed at regular distances. However, such cellular corridors with high power sites in short distance intervals are not sustainable due to the infrastructure power consumption. To render railway connectivity more sustainable, we propose to deploy fewer high-power radio units with intermediate low-power support repeater nodes. We show that these repeaters consume only 5 % of the energy of a regular cell site and help to maintain the same data capacity in the trains. In a further step, we introduce a sleep mode for the repeater nodes that enables autonomous solar powering and even eases installation because no cables to the relays are needed. ",
    "url": "https://arxiv.org/abs/2205.11808",
    "authors": [
      "Adrian Schumacher",
      "Ruben Merz",
      "Andreas Burg"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.11811",
    "title": "Sensing Performance of Multi-Channel RFID-based Finger Augmentation  Devices for Tactile Internet",
    "abstract": "Radiofrequency finger augmentation devices (R-FADs) are a recently introduced class of epidermal radiofrequency identification (RFID) sensor-tags attached to the fingers, communicating with a body-worn reader. These devices are promising candidates to enable Tactile Internet (TI) applications in the short term. R-FAD based on auto-tuning RFID microchips can be used as dielectric probes for the material of touched objects. However, due to the nearly unpredictable intrinsic variability of finger-object interaction, a single sensorized finger (single-channel device) is not enough to guarantee reliable data sampling. These limitations can be overcome by exploiting a multi-channel R-FAD sensorizing multiple fingers of the hand. In this paper, the dielectric-sensing performance of a multi-channel R-FAD, composed of sensors encapsulated into soft elastomers, is numerically and experimentally characterized, involving a set of volunteers. The inter-sensor coupling is negligible, thus enabling simultaneous independent dielectric measurements. The multi-sensor configuration allows for 100% reliability of the on-hand communication link for touched objects in a wide range of permittivity. Experiments moreover demonstrate that multi-channel measurements can halve the measurement uncertainty of the single-channel case. The achievable precision is suitable to discriminate among low-, medium-, and high-permittivity materials. ",
    "url": "https://arxiv.org/abs/2205.11811",
    "authors": [
      "Federica Naccarata",
      "Giulio Maria Bianco",
      "Gaetano Marrocco"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.11812",
    "title": "HoSIM: Higher-order Structural Importance based Method for Multiple  Local Community Detection",
    "abstract": "Local community detection has attracted much research attention recently, and many methods have been proposed for the single local community detection that finds a community containing the given set of query nodes. However, nodes may belong to several communities in the network, and detecting all the communities for the query node set, termed as the multiple local community detection (MLCD), is more important as it could uncover more potential information. MLCD is also more challenging because when a query node belongs to multiple communities, it always locates in the complicated overlapping region and the marginal region of communities. Accordingly, detecting multiple communities for such nodes by applying seed expansion methods is insufficient. In this work, we address the MLCD based on higher-order structural importance (HoSI). First, to effectively estimate the influence of higher-order structures, we propose a new variant of random walk called Active Random Walk to measure the HoSI score between nodes. Then, we propose two new metrics to evaluate the HoSI score of a subgraph to a node and the HoSI score of a node, respectively. Based on the proposed metrics, we present a novel algorithm called HoSIM to detect multiple local communities for a single query node. HoSIM enforces a three-stage processing, namely subgraph sampling, core member identification, and local community detection. The key idea is utilizing HoSI to find and identify the core members of communities relevant to the query node and optimize the generated communities. Extensive experiments illustrate the effectiveness of HoSIM. ",
    "url": "https://arxiv.org/abs/2205.11812",
    "authors": [
      "Boyu Li",
      "Meng Wang",
      "John E. Hopcroft",
      "Kun He"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.11819",
    "title": "Quarantine: Sparsity Can Uncover the Trojan Attack Trigger for Free",
    "abstract": "Trojan attacks threaten deep neural networks (DNNs) by poisoning them to behave normally on most samples, yet to produce manipulated results for inputs attached with a particular trigger. Several works attempt to detect whether a given DNN has been injected with a specific trigger during the training. In a parallel line of research, the lottery ticket hypothesis reveals the existence of sparse subnetworks which are capable of reaching competitive performance as the dense network after independent training. Connecting these two dots, we investigate the problem of Trojan DNN detection from the brand new lens of sparsity, even when no clean training data is available. Our crucial observation is that the Trojan features are significantly more stable to network pruning than benign features. Leveraging that, we propose a novel Trojan network detection regime: first locating a \"winning Trojan lottery ticket\" which preserves nearly full Trojan information yet only chance-level performance on clean inputs; then recovering the trigger embedded in this already isolated subnetwork. Extensive experiments on various datasets, i.e., CIFAR-10, CIFAR-100, and ImageNet, with different network architectures, i.e., VGG-16, ResNet-18, ResNet-20s, and DenseNet-100 demonstrate the effectiveness of our proposal. Codes are available at https://github.com/VITA-Group/Backdoor-LTH. ",
    "url": "https://arxiv.org/abs/2205.11819",
    "authors": [
      "Tianlong Chen",
      "Zhenyu Zhang",
      "Yihua Zhang",
      "Shiyu Chang",
      "Sijia Liu",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.11823",
    "title": "Thunder: Thumbnail based Fast Lightweight Image Denoising Network",
    "abstract": "To achieve promising results on removing noise from real-world images, most of existing denoising networks are formulated with complex network structure, making them impractical for deployment. Some attempts focused on reducing the number of filters and feature channels but suffered from large performance loss, and a more practical and lightweight denoising network with fast inference speed is of high demand. To this end, a \\textbf{Thu}mb\\textbf{n}ail based \\textbf{D}\\textbf{e}noising Netwo\\textbf{r}k dubbed Thunder, is proposed and implemented as a lightweight structure for fast restoration without comprising the denoising capabilities. Specifically, the Thunder model contains two newly-established modules: (1) a wavelet-based Thumbnail Subspace Encoder (TSE) which can leverage sub-bands correlation to provide an approximate thumbnail based on the low-frequent feature; (2) a Subspace Projection based Refine Module (SPR) which can restore the details for thumbnail progressively based on the subspace projection approach. Extensive experiments have been carried out on two real-world denoising benchmarks, demonstrating that the proposed Thunder outperforms the existing lightweight models and achieves competitive performance on PSNR and SSIM when compared with the complex designs. ",
    "url": "https://arxiv.org/abs/2205.11823",
    "authors": [
      "Yifeng Zhou",
      "Xing Xu",
      "Shuaicheng Liu",
      "Guoqing Wang",
      "Huimin Lu",
      "Heng Tao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.11830",
    "title": "TraCon: A novel dataset for real-time traffic cones detection using deep  learning",
    "abstract": "Substantial progress has been made in the field of object detection in road scenes. However, it is mainly focused on vehicles and pedestrians. To this end, we investigate traffic cone detection, an object category crucial for road effects and maintenance. In this work, the YOLOv5 algorithm is employed, in order to find a solution for the efficient and fast detection of traffic cones. The YOLOv5 can achieve a high detection accuracy with the score of IoU up to 91.31%. The proposed method is been applied to an RGB roadwork image dataset, collected from various sources. ",
    "url": "https://arxiv.org/abs/2205.11830",
    "authors": [
      "Iason Katsamenis",
      "Eleni Eirini Karolou",
      "Agapi Davradou",
      "Eftychios Protopapadakis",
      "Anastasios Doulamis",
      "Nikolaos Doulamis",
      "Dimitris Kalogeras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11843",
    "title": "Beam Aware Stochastic Multihop Routing for Flying Ad-hoc Networks",
    "abstract": "Routing is a crucial component in the design of Flying Ad-Hoc Networks (FANETs). State of the art routing solutions exploit the position of Unmanned Aerial Vehicles (UAVs) and their mobility information to determine the existence of links between them, but this information is often unreliable, as the topology of FANETs can change quickly and unpredictably. In order to improve the tracking performance, the uncertainty introduced by imperfect measurements and tracking algorithms needs to be accounted for in the routing. Another important element to consider is beamforming, which can reduce interference, but requires accurate channel and position information to work. In this work, we present the Beam Aware Stochastic Multihop Routing for FANETs (BA-SMURF), a Software-Defined Networking (SDN) routing scheme that takes into account the positioning uncertainty and beamforming design to find the most reliable routes in a FANET. Our simulation results show that joint consideration of the beamforming and routing can provide a 5% throughput improvement with respect to the state of the art. ",
    "url": "https://arxiv.org/abs/2205.11843",
    "authors": [
      "Anay Ajit Deshpande",
      "Roberto Pereira",
      "Federico Chiariotti",
      "Adriano Pastore",
      "Xavier Mestre",
      "Andrea Zanella"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.11849",
    "title": "Collaborative 3D Object Detection for Automatic Vehicle Systems via  Learnable Communications",
    "abstract": "Accurate detection of objects in 3D point clouds is a key problem in autonomous driving systems. Collaborative perception can incorporate information from spatially diverse sensors and provide significant benefits for improving the perception accuracy of autonomous driving systems. In this work, we consider that the autonomous vehicle uses local point cloud data and combines information from neighboring infrastructures through wireless links for cooperative 3D object detection. However, information sharing among vehicle and infrastructures in predefined communication schemes may result in communication congestion and/or bring limited performance improvement. To this end, we propose a novel collaborative 3D object detection framework that consists of three components: feature learning networks that map point clouds into feature maps; an efficient communication block that propagates compact and fine-grained query feature maps from vehicle to support infrastructures and optimizes attention weights between query and key to refine support feature maps; a region proposal network that fuses local feature maps and weighted support feature maps for 3D object detection. We evaluate the performance of the proposed framework using a synthetic cooperative dataset created in two complex driving scenarios: a roundabout and a T-junction. Experiment results and bandwidth usage analysis demonstrate that our approach can save communication and computation costs and significantly improve detection performance under different detection difficulties in all scenarios. ",
    "url": "https://arxiv.org/abs/2205.11849",
    "authors": [
      "Junyong Wang",
      "Yuan Zeng",
      "Yi Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11850",
    "title": "Faithful Explanations for Deep Graph Models",
    "abstract": "This paper studies faithful explanations for Graph Neural Networks (GNNs). First, we provide a new and general method for formally characterizing the faithfulness of explanations for GNNs. It applies to existing explanation methods, including feature attributions and subgraph explanations. Second, our analytical and empirical results demonstrate that feature attribution methods cannot capture the nonlinear effect of edge features, while existing subgraph explanation methods are not faithful. Third, we introduce \\emph{k-hop Explanation with a Convolutional Core} (KEC), a new explanation method that provably maximizes faithfulness to the original GNN by leveraging information about the graph structure in its adjacency matrix and its \\emph{k-th} power. Lastly, our empirical results over both synthetic and real-world datasets for classification and anomaly detection tasks with GNNs demonstrate the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2205.11850",
    "authors": [
      "Zifan Wang",
      "Yuhang Yao",
      "Chaoran Zhang",
      "Han Zhang",
      "Youjie Kang",
      "Carlee Joe-Wong",
      "Matt Fredrikson",
      "Anupam Datta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11857",
    "title": "Comprehensive Privacy Analysis on Federated Recommender System against  Attribute Inference Attacks",
    "abstract": "In recent years, recommender systems are crucially important for the delivery of personalized services that satisfy users' preferences. With personalized recommendation services, users can enjoy a variety of recommendations such as movies, books, ads, restaurants, and more. Despite the great benefits, personalized recommendations typically require the collection of personal data for user modelling and analysis, which can make users susceptible to attribute inference attacks. Specifically, the vulnerability of existing centralized recommenders under attribute inference attacks leaves malicious attackers a backdoor to infer users' private attributes, as the systems remember information of their training data (i.e., interaction data and side information). An emerging practice is to implement recommender systems in the federated setting, which enables all user devices to collaboratively learn a shared global recommender while keeping all the training data on device. However, the privacy issues in federated recommender systems have been rarely explored. In this paper, we first design a novel attribute inference attacker to perform a comprehensive privacy analysis of the state-of-the-art federated recommender models. The experimental results show that the vulnerability of each model component against attribute inference attack is varied, highlighting the need for new defense approaches. Therefore, we propose a novel adaptive privacy-preserving approach to protect users' sensitive data in the presence of attribute inference attacks and meanwhile maximize the recommendation accuracy. Extensive experimental results on two real-world datasets validate the superior performance of our model on both recommendation effectiveness and resistance to inference attacks. ",
    "url": "https://arxiv.org/abs/2205.11857",
    "authors": [
      "Shijie Zhang",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2205.11859",
    "title": "Stability in data-driven MPC: an inherent robustness perspective",
    "abstract": "Data-driven model predictive control (DD-MPC) based on Willems' Fundamental Lemma has received much attention in recent years, allowing to control systems directly based on an implicit data-dependent system description. The literature contains many successful practical applications as well as theoretical results on closed-loop stability and robustness. In this paper, we provide a tutorial introduction to DD-MPC for unknown linear time-invariant (LTI) systems with focus on (robust) closed-loop stability. We first address the scenario of noise-free data, for which we present a DD-MPC scheme with terminal equality constraints and derive closed-loop properties. In case of noisy data, we introduce a simple yet powerful approach to analyze robust stability of DD-MPC by combining continuity of DD-MPC w.r.t. noise with inherent robustness of model-based MPC, i.e., robustness of nominal MPC w.r.t. small disturbances. Moreover, we discuss how the presented proof technique allows to show closed-loop stability of a variety of DD-MPC schemes with noisy data, as long as the corresponding model-based MPC is inherently robust. ",
    "url": "https://arxiv.org/abs/2205.11859",
    "authors": [
      "Julian Berberich",
      "Johannes K\u00f6hler",
      "Matthias A. M\u00fcller",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2205.11874",
    "title": "Approximation speed of quantized vs. unquantized ReLU neural networks  and beyond",
    "abstract": "We consider general approximation families encompassing ReLU neural networks. On the one hand, we introduce a new property, that we call $\\infty$-encodability, which lays a framework that we use (i) to guarantee that ReLU networks can be uniformly quantized and still have approximation speeds comparable to unquantized ones, and (ii) to prove that ReLU networks share a common limitation with many other approximation families: the approximation speed of a set C is bounded from above by an encoding complexity of C (a complexity well-known for many C's). The property of $\\infty$-encodability allows us to unify and generalize known results in which it was implicitly used. On the other hand, we give lower and upper bounds on the Lipschitz constant of the mapping that associates the weights of a network to the function they represent in L^p. It is given in terms of the width, the depth of the network and a bound on the weight's norm, and it is based on well-known upper bounds on the Lipschitz constants of the functions represented by ReLU networks. This allows us to recover known results, to establish new bounds on covering numbers, and to characterize the accuracy of naive uniform quantization of ReLU networks. ",
    "url": "https://arxiv.org/abs/2205.11874",
    "authors": [
      "Antoine Gonon",
      "Nicolas Brisebarre",
      "R\u00e9mi Gribonval",
      "Elisa Riccietti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.11912",
    "title": "Physics-Embedded Neural Networks:  $\\boldsymbol{\\mathrm{E}(n)}$-Equivariant Graph Neural PDE Solvers",
    "abstract": "Graph neural network (GNN) is a promising approach to learning and predicting physical phenomena described in boundary value problems, such as partial differential equations (PDEs) with boundary conditions. However, existing models inadequately treat boundary conditions essential for the reliable prediction of such problems. In addition, because of the locally connected nature of GNNs, it is difficult to accurately predict the state after a long time, where interaction between vertices tends to be global. We present our approach termed physics-embedded neural networks that considers boundary conditions and predicts the state after a long time using an implicit method. It is built based on an $\\mathrm{E}(n)$-equivariant GNN, resulting in high generalization performance on various shapes. We demonstrate that our model learns flow phenomena in complex shapes and outperforms a well-optimized classical solver and a state-of-the-art machine learning model in speed-accuracy trade-off. Therefore, our model can be a useful standard for realizing reliable, fast, and accurate GNN-based PDE solvers. ",
    "url": "https://arxiv.org/abs/2205.11912",
    "authors": [
      "Masanobu Horie",
      "Naoto Mitsume"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2205.11917",
    "title": "Community Question Answering Entity Linking via Leveraging Auxiliary  Data",
    "abstract": "Community Question Answering (CQA) platforms contain plenty of CQA texts (i.e., questions and answers corresponding to the question) where named entities appear ubiquitously. In this paper, we define a new task of CQA entity linking (CQAEL) as linking the textual entity mentions detected from CQA texts with their corresponding entities in a knowledge base. This task can facilitate many downstream applications including expert finding and knowledge base enrichment. Traditional entity linking methods mainly focus on linking entities in news documents, and are suboptimal over this new task of CQAEL since they cannot effectively leverage various informative auxiliary data involved in the CQA platform to aid entity linking, such as parallel answers and two types of meta-data (i.e., topic tags and users). To remedy this crucial issue, we propose a novel transformer-based framework to effectively harness the knowledge delivered by different kinds of auxiliary data to promote the linking performance. We validate the superiority of our framework through extensive experiments over a newly released CQAEL data set against state-of-the-art entity linking methods. ",
    "url": "https://arxiv.org/abs/2205.11917",
    "authors": [
      "Yuhan Li",
      "Wei Shen",
      "Jianbo Gao",
      "Yadong Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11921",
    "title": "Compression-aware Training of Neural Networks using Frank-Wolfe",
    "abstract": "Many existing Neural Network pruning approaches either rely on retraining to compensate for pruning-caused performance degradation or they induce strong biases to converge to a specific sparse solution throughout training. A third paradigm obtains a wide range of compression ratios from a single dense training run while also avoiding retraining. Recent work of Pokutta et al. (2020) and Miao et al. (2022) suggests that the Stochastic Frank-Wolfe (SFW) algorithm is particularly suited for training state-of-the-art models that are robust to compression. We propose leveraging $k$-support norm ball constraints and demonstrate significant improvements over the results of Miao et al. (2022) in the case of unstructured pruning. We also extend these ideas to the structured pruning domain and propose novel approaches to both ensure robustness to the pruning of convolutional filters as well as to low-rank tensor decompositions of convolutional layers. In the latter case, our approach performs on-par with nuclear-norm regularization baselines while requiring only half of the computational resources. Our findings also indicate that the robustness of SFW-trained models largely depends on the gradient rescaling of the learning rate and we establish a theoretical foundation for that practice. ",
    "url": "https://arxiv.org/abs/2205.11921",
    "authors": [
      "Max Zimmer",
      "Christoph Spiegel",
      "Sebastian Pokutta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2205.11925",
    "title": "Robust 3D Object Detection in Cold Weather Conditions",
    "abstract": "Adverse weather conditions can negatively affect LiDAR-based object detectors. In this work, we focus on the phenomenon of vehicle gas exhaust condensation in cold weather conditions. This everyday effect can influence the estimation of object sizes, orientations and introduce ghost object detections, compromising the reliability of the state of the art object detectors. We propose to solve this problem by using data augmentation and a novel training loss term. To effectively train deep neural networks, a large set of labeled data is needed. In case of adverse weather conditions, this process can be extremely laborious and expensive. We address this issue in two steps: First, we present a gas exhaust data generation method based on 3D surface reconstruction and sampling which allows us to generate large sets of gas exhaust clouds from a small pool of labeled data. Second, we introduce a point cloud augmentation process that can be used to add gas exhaust to datasets recorded in good weather conditions. Finally, we formulate a new training loss term that leverages the augmented point cloud to increase object detection robustness by penalizing predictions that include noise. In contrast to other works, our method can be used with both grid-based and point-based detectors. Moreover, since our approach does not require any network architecture changes, inference times remain unchanged. Experimental results on real data show that our proposed method greatly increases robustness to gas exhaust and noisy data. ",
    "url": "https://arxiv.org/abs/2205.11925",
    "authors": [
      "Aldi Piroli",
      "Vinzenz Dallabetta",
      "Marc Walessa",
      "Daniel Meissner",
      "Johannes Kopp",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11947",
    "title": "Causal Influences Decouple From Their Underlying Network Structure In  Echo State Networks",
    "abstract": "Echo State Networks (ESN) are versatile recurrent neural network models in which the hidden layer remains unaltered during training. Interactions among nodes of this static backbone produce diverse representations of the given stimuli that are harnessed by a read-out mechanism to perform computations needed for solving a given task. ESNs are accessible models of neuronal circuits, since they are relatively inexpensive to train. Therefore, ESNs have become attractive for neuroscientists studying the relationship between neural structure, function, and behavior. For instance, it is not yet clear how distinctive connectivity patterns of brain networks support effective interactions among their nodes and how these patterns of interactions give rise to computation. To address this question, we employed an ESN with a biologically inspired structure and used a systematic multi-site lesioning framework to quantify the causal contribution of each node to the network's output, thus providing a causal link between network structure and behavior. We then focused on the structure-function relationship and decomposed the causal influence of each node on all other nodes, using the same lesioning framework. We found that nodes in a properly engineered ESN interact largely irrespective of the network's underlying structure. However, in a network with the same topology and a non-optimal parameter set, the underlying connectivity patterns determine the node interactions. Our results suggest that causal structure-function relations in ESNs can be decomposed into two components, direct and indirect interactions. The former are based on influences relying on structural connections. The latter describe the effective communication between any two nodes through other intermediate nodes. These widely distributed indirect interactions may crucially contribute to the efficient performance of ESNs. ",
    "url": "https://arxiv.org/abs/2205.11947",
    "authors": [
      "Kayson Fakhar",
      "Fatemeh Hadaeghi",
      "Claus C. Hilgetag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2205.11951",
    "title": "Diffuse Map Guiding Unsupervised Generative Adversarial Network for  SVBRDF Estimation",
    "abstract": "Reconstructing materials in the real world has always been a difficult problem in computer graphics. Accurately reconstructing the material in the real world is critical in the field of realistic rendering. Traditionally, materials in computer graphics are mapped by an artist, then mapped onto a geometric model by coordinate transformation, and finally rendered with a rendering engine to get realistic materials. For opaque objects, the industry commonly uses physical-based bidirectional reflectance distribution function (BRDF) rendering models for material modeling. The commonly used physical-based rendering models are Cook-Torrance BRDF, Disney BRDF. In this paper, we use the Cook-Torrance model to reconstruct the materials. The SVBRDF material parameters include Normal, Diffuse, Specular and Roughness. This paper presents a Diffuse map guiding material estimation method based on the Generative Adversarial Network(GAN). This method can predict plausible SVBRDF maps with global features using only a few pictures taken by the mobile phone. The main contributions of this paper are: 1) We preprocess a small number of input pictures to produce a large number of non-repeating pictures for training to reduce over-fitting. 2) We use a novel method to directly obtain the guessed diffuse map with global characteristics, which provides more prior information for the training process. 3) We improve the network architecture of the generator so that it can generate fine details of normal maps and reduce the possibility to generate over-flat normal maps. The method used in this paper can obtain prior knowledge without using dataset training, which greatly reduces the difficulty of material reconstruction and saves a lot of time to generate and calibrate datasets. ",
    "url": "https://arxiv.org/abs/2205.11951",
    "authors": [
      "Zhiyao Luo",
      "Hongnan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2205.11962",
    "title": "A Wireless-Vision Dataset for Privacy Preserving Human Activity  Recognition",
    "abstract": "Human Activity Recognition (HAR) has recently received remarkable attention in numerous applications such as assisted living and remote monitoring. Existing solutions based on sensors and vision technologies have obtained achievements but still suffering from considerable limitations in the environmental requirement. Wireless signals like WiFi-based sensing have emerged as a new paradigm since it is convenient and not restricted in the environment. In this paper, a new WiFi-based and video-based neural network (WiNN) is proposed to improve the robustness of activity recognition where the synchronized video serves as the supplement for the wireless data. Moreover, a wireless-vision benchmark (WiVi) is collected for 9 class actions recognition in three different visual conditions, including the scenes without occlusion, with partial occlusion, and with full occlusion. Both machine learning methods - support vector machine (SVM) as well as deep learning methods are used for the accuracy verification of the data set. Our results show that WiVi data set satisfies the primary demand and all three branches in the proposed pipeline keep more than $80\\%$ of activity recognition accuracy over multiple action segmentation from 1s to 3s. In particular, WiNN is the most robust method in terms of all the actions on three action segmentation compared to the others. ",
    "url": "https://arxiv.org/abs/2205.11962",
    "authors": [
      "Yanling Hao",
      "Zhiyuan Shi",
      "Yuanwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.11981",
    "title": "OPOM: Customized Invisible Cloak towards Face Privacy Protection",
    "abstract": "While convenient in daily life, face recognition technologies also raise privacy concerns for regular users on the social media since they could be used to analyze face images and videos, efficiently and surreptitiously without any security restrictions. In this paper, we investigate the face privacy protection from a technology standpoint based on a new type of customized cloak, which can be applied to all the images of a regular user, to prevent malicious face recognition systems from uncovering their identity. Specifically, we propose a new method, named one person one mask (OPOM), to generate person-specific (class-wise) universal masks by optimizing each training sample in the direction away from the feature subspace of the source identity. To make full use of the limited training images, we investigate several modeling methods, including affine hulls, class centers, and convex hulls, to obtain a better description of the feature subspace of source identities. The effectiveness of the proposed method is evaluated on both common and celebrity datasets against black-box face recognition models with different loss functions and network architectures. In addition, we discuss the advantages and potential problems of the proposed method. In particular, we conduct an application study on the privacy protection of a video dataset, Sherlock, to demonstrate the potential practical usage of the proposed method. Datasets and code are available at https://github.com/zhongyy/OPOM. ",
    "url": "https://arxiv.org/abs/2205.11981",
    "authors": [
      "Yaoyao Zhong",
      "Weihong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11987",
    "title": "Word-order typology in Multilingual BERT: A case study in  subordinate-clause detection",
    "abstract": "The capabilities and limitations of BERT and similar models are still unclear when it comes to learning syntactic abstractions, in particular across languages. In this paper, we use the task of subordinate-clause detection within and across languages to probe these properties. We show that this task is deceptively simple, with easy gains offset by a long tail of harder cases, and that BERT's zero-shot performance is dominated by word-order effects, mirroring the SVO/VSO/SOV typology. ",
    "url": "https://arxiv.org/abs/2205.11987",
    "authors": [
      "Dmitry Nikolaev",
      "Sebastian Pad\u00f3"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.12009",
    "title": "Graph Convolutional Reinforcement Learning for Collaborative Queuing  Agents",
    "abstract": "In this paper, we explore the use of multi-agent deep learning as well as learning to cooperate principles to meet stringent service level agreements, in terms of throughput and end-to-end delay, for a set of classified network flows. We consider agents built on top of a weighted fair queuing algorithm that continuously set weights for three flow groups: gold, silver, and bronze. We rely on a novel graph-convolution based, multi-agent reinforcement learning approach known as DGN. As benchmarks, we propose centralized and distributed deep Q-network approaches and evaluate their performances in different network, traffic, and routing scenarios, highlighting the effectiveness of our proposals and the importance of agent cooperation. We show that our DGN-based approach meets stringent throughput and delay requirements across all scenarios. ",
    "url": "https://arxiv.org/abs/2205.12009",
    "authors": [
      "Hassan Fawaz",
      "Julien Lesca",
      "Pham Tran Anh Quang",
      "J\u00e9r\u00e9mie Leguay",
      "Djamal Zeghlache",
      "Paolo Medagliani"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12010",
    "title": "SFace: Sigmoid-Constrained Hypersphere Loss for Robust Face Recognition",
    "abstract": "Deep face recognition has achieved great success due to large-scale training databases and rapidly developing loss functions. The existing algorithms devote to realizing an ideal idea: minimizing the intra-class distance and maximizing the inter-class distance. However, they may neglect that there are also low quality training images which should not be optimized in this strict way. Considering the imperfection of training databases, we propose that intra-class and inter-class objectives can be optimized in a moderate way to mitigate overfitting problem, and further propose a novel loss function, named sigmoid-constrained hypersphere loss (SFace). Specifically, SFace imposes intra-class and inter-class constraints on a hypersphere manifold, which are controlled by two sigmoid gradient re-scale functions respectively. The sigmoid curves precisely re-scale the intra-class and inter-class gradients so that training samples can be optimized to some degree. Therefore, SFace can make a better balance between decreasing the intra-class distances for clean examples and preventing overfitting to the label noise, and contributes more robust deep face recognition models. Extensive experiments of models trained on CASIA-WebFace, VGGFace2, and MS-Celeb-1M databases, and evaluated on several face recognition benchmarks, such as LFW, MegaFace and IJB-C databases, have demonstrated the superiority of SFace. ",
    "url": "https://arxiv.org/abs/2205.12010",
    "authors": [
      "Yaoyao Zhong",
      "Weihong Deng",
      "Jiani Hu",
      "Dongyue Zhao",
      "Xian Li",
      "Dongchao Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12019",
    "title": "Economic Topology Optimization of District Heating Networks using a  SIMP-like Multi-Material Penalization Approach",
    "abstract": "In the presented study, a multi-material 'Solid Isotropic Material with Penalization' (SIMP)-like penalization approach for the economic topology optimization of District Heating Networks is proposed. For District Heating Networks, an important technology for carbon-neutral space heating, the upfront investment is a crucial factor for the rollout of this technology. Today, the pipe routing is usually designed relying on a linearization of the underlying heat transport problem. This study proposes to solve the optimal pipe routing problem as a non-linear topology optimization problem, drawing inspiration from PDE-constrained topology optimization. The optimization problem is formulated around a non-linear heat transport model and minimizes a detailed net present value representation of the heating network cost. A discrete network topology and near-discrete pipe design is achieved by using a pipe penalization strategy. For a realistic test case, the proposed algorithm achieves a discrete network topology and near-discrete pipe design that outperforms simple post-processing steps. ",
    "url": "https://arxiv.org/abs/2205.12019",
    "authors": [
      "Yannick Wack",
      "Martine Baelmans",
      "Robbe Salenbien",
      "Maarten Blommaert"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2205.12050",
    "title": "Training Efficient CNNS: Tweaking the Nuts and Bolts of Neural Networks  for Lighter, Faster and Robust Models",
    "abstract": "Deep Learning has revolutionized the fields of computer vision, natural language understanding, speech recognition, information retrieval and more. Many techniques have evolved over the past decade that made models lighter, faster, and robust with better generalization. However, many deep learning practitioners persist with pre-trained models and architectures trained mostly on standard datasets such as Imagenet, MS-COCO, IMDB-Wiki Dataset, and Kinetics-700 and are either hesitant or unaware of redesigning the architecture from scratch that will lead to better performance. This scenario leads to inefficient models that are not suitable on various devices such as mobile, edge, and fog. In addition, these conventional training methods are of concern as they consume a lot of computing power. In this paper, we revisit various SOTA techniques that deal with architecture efficiency (Global Average Pooling, depth-wise convolutions & squeeze and excitation, Blurpool), learning rate (Cyclical Learning Rate), data augmentation (Mixup, Cutout), label manipulation (label smoothing), weight space manipulation (stochastic weight averaging), and optimizer (sharpness aware minimization). We demonstrate how an efficient deep convolution network can be built in a phased manner by sequentially reducing the number of training parameters and using the techniques mentioned above. We achieved a SOTA accuracy of 99.2% on MNIST data with just 1500 parameters and an accuracy of 86.01% with just over 140K parameters on the CIFAR-10 dataset. ",
    "url": "https://arxiv.org/abs/2205.12050",
    "authors": [
      "Sabeesh Ethiraj",
      "Bharath Kumar Bolla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12054",
    "title": "EventMix: An Efficient Augmentation Strategy for Event-Based Data",
    "abstract": "High-quality and challenging event stream datasets play an important role in the design of an efficient event-driven mechanism that mimics the brain. Although event cameras can provide high dynamic range and low-energy event stream data, the scale is smaller and more difficult to obtain than traditional frame-based data, which restricts the development of neuromorphic computing. Data augmentation can improve the quantity and quality of the original data by processing more representations from the original data. This paper proposes an efficient data augmentation strategy for event stream data: EventMix. We carefully design the mixing of different event streams by Gaussian Mixture Model to generate random 3D masks and achieve arbitrary shape mixing of event streams in the spatio-temporal dimension. By computing the relative distances of event streams, we propose a more reasonable way to assign labels to the mixed samples. The experimental results on multiple neuromorphic datasets have shown that our strategy can improve its performance on neuromorphic datasets both for ANNs and SNNs, and we have achieved state-of-the-art performance on DVS-CIFAR10, N-Caltech101, N-CARS, and DVS-Gesture datasets. ",
    "url": "https://arxiv.org/abs/2205.12054",
    "authors": [
      "Guobin Shen",
      "Dongcheng Zhao",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.12064",
    "title": "Process Mining Algorithm for Online Intrusion Detection System",
    "abstract": "In this paper, we consider the applications of process mining in intrusion detection. We propose a novel process mining inspired algorithm to be used to preprocess data in intrusion detection systems (IDS). The algorithm is designed to process the network packet data and it works well in online mode for online intrusion detection. To test our algorithm, we used the CSE-CIC-IDS2018 dataset which contains several common attacks. The packet data was preprocessed with this algorithm and then fed into the detectors. We report on the experiments using the algorithm with different machine learning (ML) models as classifiers to verify that our algorithm works as expected; we tested the performance on anomaly detection methods as well and reported on the existing preprocessing tool CICFlowMeter for the comparison of performance. ",
    "url": "https://arxiv.org/abs/2205.12064",
    "authors": [
      "Yinzheng Zhong",
      "John Y. Goulermas",
      "Alexei Lisitsa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.12066",
    "title": "Context Attention Network for Skeleton Extraction",
    "abstract": "Skeleton extraction is a task focused on providing a simple representation of an object by extracting the skeleton from the given binary or RGB image. In recent years many attractive works in skeleton extraction have been made. But as far as we know, there is little research on how to utilize the context information in the binary shape of objects. In this paper, we propose an attention-based model called Context Attention Network (CANet), which integrates the context extraction module in a UNet architecture and can effectively improve the ability of network to extract the skeleton pixels. Meanwhile, we also use some novel techniques including distance transform, weight focal loss to achieve good results on the given dataset. Finally, without model ensemble and with only 80% of the training images, our method achieves 0.822 F1 score during the development phase and 0.8507 F1 score during the final phase of the Pixel SkelNetOn Competition, ranking 1st place on the leaderboard. ",
    "url": "https://arxiv.org/abs/2205.12066",
    "authors": [
      "Zixuan Huang",
      "Yunfeng Wang",
      "Zhiwen Chen",
      "Xin Gao",
      "Ruili Feng",
      "Xiaobo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12076",
    "title": "Ensemble Multi-Relational Graph Neural Networks",
    "abstract": "It is well established that graph neural networks (GNNs) can be interpreted and designed from the perspective of optimization objective. With this clear optimization objective, the deduced GNNs architecture has sound theoretical foundation, which is able to flexibly remedy the weakness of GNNs. However, this optimization objective is only proved for GNNs with single-relational graph. Can we infer a new type of GNNs for multi-relational graphs by extending this optimization objective, so as to simultaneously solve the issues in previous multi-relational GNNs, e.g., over-parameterization? In this paper, we propose a novel ensemble multi-relational GNNs by designing an ensemble multi-relational (EMR) optimization objective. This EMR optimization objective is able to derive an iterative updating rule, which can be formalized as an ensemble message passing (EnMP) layer with multi-relations. We further analyze the nice properties of EnMP layer, e.g., the relationship with multi-relational personalized PageRank. Finally, a new multi-relational GNNs which well alleviate the over-smoothing and over-parameterization issues are proposed. Extensive experiments conducted on four benchmark datasets well demonstrate the effectiveness of the proposed model. ",
    "url": "https://arxiv.org/abs/2205.12076",
    "authors": [
      "Yuling Wang",
      "Hao Xu",
      "Yanhua Yu",
      "Mengdi Zhang",
      "Zhenhao Li",
      "Yuji Yang",
      "Wei Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.12078",
    "title": "GraphQ IR: Unifying Semantic Parsing of Graph Query Language with  Intermediate Representation",
    "abstract": "Subject to the semantic gap lying between natural and formal language, neural semantic parsing is typically bottlenecked by the paucity and imbalance of data. In this paper, we propose a unified intermediate representation (IR) for graph query languages, namely GraphQ IR. With the IR's natural-language-like representation that bridges the semantic gap and its formally defined syntax that maintains the graph structure, neural semantic parser can more effectively convert user queries into our GraphQ IR, which can be later automatically compiled into different downstream graph query languages. Extensive experiments show that our approach can consistently achieve state-of-the-art performance on benchmarks KQA Pro, Overnight and MetaQA. Evaluations under compositional generalization and few-shot learning settings also validate the promising generalization ability of GraphQ IR with at most 11% accuracy improvement. ",
    "url": "https://arxiv.org/abs/2205.12078",
    "authors": [
      "Lunyiu Nie",
      "Shulin Cao",
      "Jiaxin Shi",
      "Qi Tian",
      "Lei Hou",
      "Juanzi Li",
      "Jidong Zhai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2205.12095",
    "title": "DNNAbacus: Toward Accurate Computational Cost Prediction for Deep Neural  Networks",
    "abstract": "Deep learning is attracting interest across a variety of domains, including natural language processing, speech recognition, and computer vision. However, model training is time-consuming and requires huge computational resources. Existing works on the performance prediction of deep neural networks, which mostly focus on the training time prediction of a few models, rely on analytical models and result in high relative errors. %Optimizing task scheduling and reducing job failures in data centers are essential to improve resource utilization and reduce carbon emissions. This paper investigates the computational resource demands of 29 classical deep neural networks and builds accurate models for predicting computational costs. We first analyze the profiling results of typical networks and demonstrate that the computational resource demands of models with different inputs and hyperparameters are not obvious and intuitive. We then propose a lightweight prediction approach DNNAbacus with a novel network structural matrix for network representation. DNNAbacus can accurately predict both memory and time cost for PyTorch and TensorFlow models, which is also generalized to different hardware architectures and can have zero-shot capability for unseen networks. Our experimental results show that the mean relative error (MRE) is 0.9% with respect to time and 2.8% with respect to memory for 29 classic models, which is much lower than the state-of-the-art works. ",
    "url": "https://arxiv.org/abs/2205.12095",
    "authors": [
      "Lu Bai",
      "Weixing Ji",
      "Qinyuan Li",
      "Xilai Yao",
      "Wei Xin",
      "Wanyi Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2205.12101",
    "title": "Empirical Phase Diagram for Three-layer Neural Networks with Infinite  Width",
    "abstract": "Substantial work indicates that the dynamics of neural networks (NNs) is closely related to their initialization of parameters. Inspired by the phase diagram for two-layer ReLU NNs with infinite width (Luo et al., 2021), we make a step towards drawing a phase diagram for three-layer ReLU NNs with infinite width. First, we derive a normalized gradient flow for three-layer ReLU NNs and obtain two key independent quantities to distinguish different dynamical regimes for common initialization methods. With carefully designed experiments and a large computation cost, for both synthetic datasets and real datasets, we find that the dynamics of each layer also could be divided into a linear regime and a condensed regime, separated by a critical regime. The criteria is the relative change of input weights (the input weight of a hidden neuron consists of the weight from its input layer to the hidden neuron and its bias term) as the width approaches infinity during the training, which tends to $0$, $+\\infty$ and $O(1)$, respectively. In addition, we also demonstrate that different layers can lie in different dynamical regimes in a training process within a deep NN. In the condensed regime, we also observe the condensation of weights in isolated orientations with low complexity. Through experiments under three-layer condition, our phase diagram suggests a complicated dynamical regimes consisting of three possible regimes, together with their mixture, for deep NNs and provides a guidance for studying deep NNs in different initialization regimes, which reveals the possibility of completely different dynamics emerging within a deep NN for its different layers. ",
    "url": "https://arxiv.org/abs/2205.12101",
    "authors": [
      "Hanxu Zhou",
      "Qixuan Zhou",
      "Zhenyuan Jin",
      "Tao Luo",
      "Yaoyu Zhang",
      "Zhi-Qin John Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12102",
    "title": "KQGC: Knowledge Graph Embedding with Smoothing Effects of Graph  Convolutions for Recommendation",
    "abstract": "Leveraging graphs on recommender systems has gained popularity with the development of graph representation learning (GRL). In particular, knowledge graph embedding (KGE) and graph neural networks (GNNs) are representative GRL approaches, which have achieved the state-of-the-art performance on several recommendation tasks. Furthermore, combination of KGE and GNNs (KG-GNNs) has been explored and found effective in many academic literatures. One of the main characteristics of GNNs is their ability to retain structural properties among neighbors in the resulting dense representation, which is usually coined as smoothing. The smoothing is specially desired in the presence of homophilic graphs, such as the ones we find on recommender systems. In this paper, we propose a new model for recommender systems named Knowledge Query-based Graph Convolution (KQGC). In contrast to exisiting KG-GNNs, KQGC focuses on the smoothing, and leverages a simple linear graph convolution for smoothing KGE. A pre-trained KGE is fed into KQGC, and it is smoothed by aggregating neighbor knowledge queries, which allow entity-embeddings to be aligned on appropriate vector points for smoothing KGE effectively. We apply the proposed KQGC to a recommendation task that aims prospective users for specific products. Extensive experiments on a real E-commerce dataset demonstrate the effectiveness of KQGC. ",
    "url": "https://arxiv.org/abs/2205.12102",
    "authors": [
      "Daisuke Kikuta",
      "Toyotaro Suzumura",
      "Md Mostafizur Rahman",
      "Yu Hirate",
      "Satyen Abrol",
      "Manoj Kondapaka",
      "Takuma Ebisu",
      "Pablo Loyola"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12124",
    "title": "Memory based neural networks for end-to-end autonomous driving",
    "abstract": "Recent works in end-to-end control for autonomous driving have investigated the use of vision-based exteroceptive perception. Inspired by such results, we propose a new end-to-end memory-based neural architecture for robot steering and throttle control. We describe and compare this architecture with previous approaches using fundamental error metrics (MAE, MSE) and several external metrics based on their performance on simulated test circuits. The presented work demonstrates the advantages of using internal memory for better generalization capabilities of the model and allowing it to drive in a broader amount of circuits/situations. We analyze the algorithm in a wide range of environments and conclude that the proposed pipeline is robust to varying camera configurations. All the present work, including datasets, network models architectures, weights, simulator, and comparison software, is open source and easy to replicate and extend. ",
    "url": "https://arxiv.org/abs/2205.12124",
    "authors": [
      "Sergio Paniego Blanco",
      "Sakshay Mahna",
      "Utkarsh A. Mishra",
      "JoseMaria Canas"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.12134",
    "title": "Adversarial Attack on Attackers: Post-Process to Mitigate Black-Box  Score-Based Query Attacks",
    "abstract": "The score-based query attacks (SQAs) pose practical threats to deep neural networks by crafting adversarial perturbations within dozens of queries, only using the model's output scores. Nonetheless, we note that if the loss trend of the outputs is slightly perturbed, SQAs could be easily misled and thereby become much less effective. Following this idea, we propose a novel defense, namely Adversarial Attack on Attackers (AAA), to confound SQAs towards incorrect attack directions by slightly modifying the output logits. In this way, (1) SQAs are prevented regardless of the model's worst-case robustness; (2) the original model predictions are hardly changed, i.e., no degradation on clean accuracy; (3) the calibration of confidence scores can be improved simultaneously. Extensive experiments are provided to verify the above advantages. For example, by setting $\\ell_\\infty=8/255$ on CIFAR-10, our proposed AAA helps WideResNet-28 secure $80.59\\%$ accuracy under Square attack ($2500$ queries), while the best prior defense (i.e., adversarial training) only attains $67.44\\%$. Since AAA attacks SQA's general greedy strategy, such advantages of AAA over 8 defenses can be consistently observed on 8 CIFAR-10/ImageNet models under 6 SQAs, using different attack targets and bounds. Moreover, AAA calibrates better without hurting the accuracy. Our code would be released. ",
    "url": "https://arxiv.org/abs/2205.12134",
    "authors": [
      "Sizhe Chen",
      "Zhehao Huang",
      "Qinghua Tao",
      "Yingwen Wu",
      "Cihang Xie",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.12139",
    "title": "Extending the Network Calculus Algorithmic Toolbox for Ultimately  Pseudo-Periodic Functions: Pseudo-Inverse and Composition",
    "abstract": "Network Calculus (NC) is an algebraic theory that represents traffic and service guarantees as curves in a Cartesian plane, in order to compute performance guarantees for flows traversing a network. NC uses transformation operations, e.g., min-plus convolution of two curves, to model how the traffic profile changes with the traversal of network nodes. Such operations, while mathematically well-defined, can quickly become unmanageable to compute using simple pen and paper for any non-trivial case, hence the need for algorithmic descriptions. Previous work identified the class of piecewise affine functions which are ultimately pseudo-periodic (UPP) as being closed under the main NC operations and able to be described finitely. Algorithms that embody NC operations taking as operands UPP curves have been defined and proved correct, thus enabling software implementations of these operations. However, recent advancements in NC make use of operations, namely the lower pseudo-inverse, upper pseudo-inverse, and composition, that are well defined from an algebraic standpoint, but whose algorithmic aspects have not been addressed yet. In this paper, we introduce algorithms for the above operations when operands are UPP curves, thus extending the available algorithmic toolbox for NC. We discuss the algorithmic properties of these operations, providing formal proofs of correctness. ",
    "url": "https://arxiv.org/abs/2205.12139",
    "authors": [
      "Raffaele Zippo",
      "Paul Nikolaus",
      "Giovanni Stea"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2205.12141",
    "title": "One-Pixel Shortcut: on the Learning Preference of Deep Neural Networks",
    "abstract": "Unlearnable examples (ULEs) aim to protect data from unauthorized usage for training DNNs. Error-minimizing noise, which is injected to clean data, is one of the most successful methods for preventing DNNs from giving correct predictions on incoming new data. Nonetheless, under specific training strategies such as adversarial training, the unlearnability of error-minimizing noise will severely degrade. In addition, the transferability of error-minimizing noise is inherently limited by the mismatch between the generator model and the targeted learner model. In this paper, we investigate the mechanism of unlearnable examples and propose a novel model-free method, named \\emph{One-Pixel Shortcut}, which only perturbs a single pixel of each image and makes the dataset unlearnable. Our method needs much less computational cost and obtains stronger transferability and thus can protect data from a wide range of different models. Based on this, we further introduce the first unlearnable dataset called CIFAR-10-S, which is indistinguishable from normal CIFAR-10 by human observers and can serve as a benchmark for different models or training strategies to evaluate their abilities to extract critical features from the disturbance of non-semantic representations. The original error-minimizing ULEs will lose efficiency under adversarial training, where the model can get over 83\\% clean test accuracy. Meanwhile, even if adversarial training and strong data augmentation like RandAugment are applied together, the model trained on CIFAR-10-S cannot get over 50\\% clean test accuracy. ",
    "url": "https://arxiv.org/abs/2205.12141",
    "authors": [
      "Shutong Wu",
      "Sizhe Chen",
      "Cihang Xie",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.12177",
    "title": "Reliability Assessment of Neural Networks in GPUs: A Framework For  Permanent Faults Injections",
    "abstract": "Currently, Deep learning and especially Convolutional Neural Networks (CNNs) have become a fundamental computational approach applied in a wide range of domains, including some safety-critical applications (e.g., automotive, robotics, and healthcare equipment). Therefore, the reliability evaluation of those computational systems is mandatory. The reliability evaluation of CNNs is performed by fault injection campaigns at different levels of abstraction, from the application level down to the hardware level. Many works have focused on evaluating the reliability of neural networks in the presence of transient faults. However, the effects of permanent faults have been investigated at the application level, only, e.g., targeting the parameters of the network. This paper intends to propose a framework, resorting to a binary instrumentation tool to perform fault injection campaigns, targeting different components inside the GPU, such as the register files and the functional units. This environment allows for the first time assessing the reliability of CNNs deployed on a GPU considering the presence of permanent faults. ",
    "url": "https://arxiv.org/abs/2205.12177",
    "authors": [
      "Juan-David Guerrero-Balaguera",
      "Luigi Galasso",
      "Robert Limas Sierra",
      "Matteo Sonza Reorda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.12179",
    "title": "Evidential Temporal-aware Graph-based Social Event Detection via  Dempster-Shafer Theory",
    "abstract": "The rising popularity of online social network services has attracted lots of research on mining social media data, especially on mining social events. Social event detection, due to its wide applications, has now become a trivial task. State-of-the-art approaches exploiting Graph Neural Networks (GNNs) usually follow a two-step strategy: 1) constructing text graphs based on various views (\\textit{co-user}, \\textit{co-entities} and \\textit{co-hashtags}); and 2) learning a unified text representation by a specific GNN model. Generally, the results heavily rely on the quality of the constructed graphs and the specific message passing scheme. However, existing methods have deficiencies in both aspects: 1) They fail to recognize the noisy information induced by unreliable views. 2) Temporal information which works as a vital indicator of events is neglected in most works. To this end, we propose ETGNN, a novel Evidential Temporal-aware Graph Neural Network. Specifically, we construct view-specific graphs whose nodes are the texts and edges are determined by several types of shared elements respectively. To incorporate temporal information into the message passing scheme, we introduce a novel temporal-aware aggregator which assigns weights to neighbours according to an adaptive time exponential decay formula. Considering the view-specific uncertainty, the representations of all views are converted into mass functions through evidential deep learning (EDL) neural networks, and further combined via Dempster-Shafer theory (DST) to make the final detection. Experimental results on three real-world datasets demonstrate the effectiveness of ETGNN in accuracy, reliability and robustness in social event detection. ",
    "url": "https://arxiv.org/abs/2205.12179",
    "authors": [
      "Jiaqian Ren",
      "Lei Jiang",
      "Hao Peng",
      "Zhiwei Liu",
      "Jia Wu",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12215",
    "title": "DivEMT: Neural Machine Translation Post-Editing Effort Across  Typologically Diverse Languages",
    "abstract": "We introduce DivEMT, the first publicly available post-editing study of Neural Machine Translation (NMT) over a typologically diverse set of target languages. Using a strictly controlled setup, 18 professional translators were instructed to translate or post-edit the same set of English documents into Arabic, Dutch, Italian, Turkish, Ukrainian, and Vietnamese. During the process, their edits, keystrokes, editing times, pauses, and perceived effort were recorded, enabling an in-depth, cross-lingual evaluation of NMT quality and its post-editing process. Using this new dataset, we assess the impact on translation productivity of two state-of-the-art NMT systems, namely: Google Translate and the open-source multilingual model mBART50. We find that, while post-editing is consistently faster than translation from scratch, the magnitude of its contribution varies largely across systems and languages, ranging from doubled productivity in Dutch and Italian to marginal gains in Arabic, Turkish and Ukrainian, for some of the evaluated modalities. Moreover, the observed cross-language variability appears to partly reflect source-target relatedness and type of target morphology, while remaining hard to predict even based on state-of-the-art automatic MT quality metrics. We publicly release the complete dataset, including all collected behavioural data, to foster new research on the ability of state-of-the-art NMT systems to generate text in typologically diverse languages. ",
    "url": "https://arxiv.org/abs/2205.12215",
    "authors": [
      "Gabriele Sarti",
      "Arianna Bisazza",
      "Ana Guerberof Arenas",
      "Antonio Toral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.12225",
    "title": "Psychotic Relapse Prediction in Schizophrenia Patients using A Mobile  Sensing-based Supervised Deep Learning Model",
    "abstract": "Mobile sensing-based modeling of behavioral changes could predict an oncoming psychotic relapse in schizophrenia patients for timely interventions. Deep learning models could complement existing non-deep learning models for relapse prediction by modeling latent behavioral features relevant to the prediction. However, given the inter-individual behavioral differences, model personalization might be required for a predictive model. In this work, we propose RelapsePredNet, a Long Short-Term Memory (LSTM) neural network-based model for relapse prediction. The model is personalized for a particular patient by training using data from patients most similar to the given patient. Several demographics and baseline mental health scores were considered as personalization metrics to define patient similarity. We investigated the effect of personalization on training dataset characteristics, learned embeddings, and relapse prediction performance. We compared RelapsePredNet with a deep learning-based anomaly detection model for relapse prediction. Further, we investigated if RelapsePredNet could complement ClusterRFModel (a random forest model leveraging clustering and template features proposed in prior work) in a fusion model, by identifying latent behavioral features relevant for relapse prediction. The CrossCheck dataset consisting of continuous mobile sensing data obtained from 63 schizophrenia patients, each monitored for up to a year, was used for our evaluations. The proposed RelapsePredNet outperformed the deep learning-based anomaly detection model for relapse prediction. The F2 score for prediction were 0.21 and 0.52 in the full test set and the Relapse Test Set (consisting of data from patients who have had relapse only), respectively. These corresponded to a 29.4% and 38.8% improvement compared to the existing deep learning-based model for relapse prediction. ",
    "url": "https://arxiv.org/abs/2205.12225",
    "authors": [
      "Bishal Lamichhane",
      "Joanne Zhou",
      "Akane Sano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.12245",
    "title": "Asynchronous Neural Networks for Learning in Graphs",
    "abstract": "This paper studies asynchronous message passing (AMP), a new paradigm for applying neural network based learning to graphs. Existing graph neural networks use the synchronous distributed computing model and aggregate their neighbors in each round, which causes problems such as oversmoothing and limits their expressiveness. On the other hand, AMP is based on the asynchronous model, where nodes react to messages of their neighbors individually. We prove that (i) AMP can simulate synchronous GNNs and that (ii) AMP can theoretically distinguish any pair of graphs. We experimentally validate AMP's expressiveness. Further, we show that AMP might be better suited to propagate messages over large distances in graphs and performs well on several graph classification benchmarks. ",
    "url": "https://arxiv.org/abs/2205.12245",
    "authors": [
      "Lukas Faber",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12248",
    "title": "RevUp: Revise and Update Information Bottleneck for Event Representation",
    "abstract": "In machine learning, latent variables play a key role to capture the underlying structure of data, but they are often unsupervised. When we have side knowledge that already has high-level information about the input data, we can use that source to guide latent variables and capture the available background information in a process called \"parameter injection.\" In that regard, we propose a semi-supervised information bottleneck-based model that enables the use of side knowledge, even if it is noisy and imperfect, to direct the learning of discrete latent variables. Fundamentally, we introduce an auxiliary continuous latent variable as a way to reparameterize the model's discrete variables with a light-weight hierarchical structure. With this reparameterization, the model's discrete latent variables are learned to minimize the mutual information between the observed data and optional side knowledge that is not already captured by the new, auxiliary variables. We theoretically show that our approach generalizes an existing method of parameter injection, and perform an empirical case study of our approach on language-based event modeling. We corroborate our theoretical results with strong empirical experiments, showing that the proposed method outperforms previous proposed approaches on multiple datasets. ",
    "url": "https://arxiv.org/abs/2205.12248",
    "authors": [
      "Mehdi Rezaee",
      "Francis Ferraro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.12250",
    "title": "Taming the sign problem of explicitly antisymmetrized neural networks  via rough activation functions",
    "abstract": "Explicit antisymmetrization of a two-layer neural network is a potential candidate for a universal function approximator for generic antisymmetric functions, which are ubiquitous in quantum physics. However, this strategy suffers from a sign problem, namely, due to near exact cancellation of positive and negative contributions, the magnitude of the antisymmetrized function may be significantly smaller than that before antisymmetrization. We prove that the severity of the sign problem is directly related to the smoothness of the activation function. For smooth activation functions (e.g., $\\tanh$), the sign problem of the explicitly antisymmetrized two-layer neural network deteriorates super-polynomially with respect to the system size. On the other hand, for rough activation functions (e.g., ReLU), the deterioration rate of the sign problem can be tamed to be at most polynomial with respect to the system size. Finally, the cost of a direct implementation of antisymmetrized two-layer neural network scales factorially with respect to the system size. We describe an efficient algorithm for approximate evaluation of such a network, of which the cost scales polynomially with respect to the system size and inverse precision. ",
    "url": "https://arxiv.org/abs/2205.12250",
    "authors": [
      "Nilin Abrahamsen",
      "Lin Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2205.12259",
    "title": "Policy Compliance Detection via Expression Tree Inference",
    "abstract": "Policy Compliance Detection (PCD) is a task we encounter when reasoning over texts, e.g. legal frameworks. Previous work to address PCD relies heavily on modeling the task as a special case of Recognizing Textual Entailment. Entailment is applicable to the problem of PCD, however viewing the policy as a single proposition, as opposed to multiple interlinked propositions, yields poor performance and lacks explainability. To address this challenge, more recent proposals for PCD have argued for decomposing policies into expression trees consisting of questions connected with logic operators. Question answering is used to obtain answers to these questions with respect to a scenario. Finally, the expression tree is evaluated in order to arrive at an overall solution. However, this work assumes expression trees are provided by experts, thus limiting its applicability to new policies. In this work, we learn how to infer expression trees automatically from policy texts. We ensure the validity of the inferred trees by introducing constrained decoding using a finite state automaton to ensure the generation of valid trees. We determine through automatic evaluation that 63% of the expression trees generated by our constrained generation model are logically equivalent to gold trees. Human evaluation shows that 88% of trees generated by our model are correct. ",
    "url": "https://arxiv.org/abs/2205.12259",
    "authors": [
      "Neema Kotonya",
      "Andreas Vlachos",
      "Majid Yazdani",
      "Lambert Mathias",
      "Marzieh Saeidi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11515",
    "title": "Cardiomegaly Detection using Deep Convolutional Neural Network with  U-Net",
    "abstract": "Cardiomegaly is indeed a medical disease in which the heart is enlarged. Cardiomegaly is better to handle if caught early, so early detection is critical. The chest X-ray, being one of the most often used radiography examinations, has been used to detect and visualize abnormalities of human organs for decades. X-ray is also a significant medical diagnosis tool for cardiomegaly. Even for domain experts, distinguishing the many types of diseases from the X-ray is a difficult and time-consuming task. Deep learning models are also most effective when used on huge data sets, yet due to privacy concerns, large datasets are rarely available inside the medical industry. A Deep learning-based customized retrained U-Net model for detecting Cardiomegaly disease is presented in this research. In the training phase, chest X-ray images from the \"ChestX-ray8\" open source real dataset are used. To reduce computing time, this model performs data preprocessing, picture improvement, image compression, and classification before moving on to the training step. The work used a chest x-ray image dataset to simulate and produced a diagnostic accuracy of 94%, a sensitivity of 96.2 percent, and a specificity of 92.5 percent, which beats prior pre-trained model findings for identifying Cardiomegaly disease. ",
    "url": "https://arxiv.org/abs/2205.11515",
    "authors": [
      "Soham S.Sarpotdar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11649",
    "title": "A Variational Bayesian Perspective on Massive MIMO Detection",
    "abstract": "Optimal data detection in massive multiple-input multiple-output (MIMO) systems requires prohibitive computational complexity. A variety of detection algorithms have been proposed in the literature, offering different trade-offs between complexity and detection performance. In this paper, we build upon variational Bayes (VB) inference to design low-complexity multiuser detection algorithms for massive MIMO systems. We first examine the massive MIMO detection problem with perfect channel state information at the receiver (CSIR) and show that a conventional VB method with known noise variance yields poor detection performance. To address this limitation, we devise two new VB algorithms that use the noise variance and covariance matrix postulated by the algorithms themselves. We further develop the VB framework for massive MIMO detection with imperfect CSIR. Simulation results show that the proposed VB methods achieve significantly lower detection errors compared with existing schemes for a wide range of channel models. ",
    "url": "https://arxiv.org/abs/2205.11649",
    "authors": [
      "Duy H. N. Nguyen",
      "Italo Atzeni",
      "Antti T\u00f6lli",
      "A. Lee Swindlehurst"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2205.11989",
    "title": "Realization Theory Of Recurrent Neural ODEs Using Polynomial System  Embeddings",
    "abstract": "In this paper we show that neural ODE analogs of recurrent (ODE-RNN) and Long Short-Term Memory (ODE-LSTM) networks can be algorithmically embeddeded into the class of polynomial systems. This embedding preserves input-output behavior and can suitably be extended to other neural DE architectures. We then use realization theory of polynomial systems to provide necessary conditions for an input-output map to be realizable by an ODE-LSTM and sufficient conditions for minimality of such systems. These results represent the first steps towards realization theory of recurrent neural ODE architectures, which is is expected be useful for model reduction and learning algorithm analysis of recurrent neural ODEs. ",
    "url": "https://arxiv.org/abs/2205.11989",
    "authors": [
      "Martin Gonzalez",
      "Thibault Defourneau",
      "Hatem Hajri",
      "Mihaly Petreczky"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12006",
    "title": "Neur2SP: Neural Two-Stage Stochastic Programming",
    "abstract": "Stochastic programming is a powerful modeling framework for decision-making under uncertainty. In this work, we tackle two-stage stochastic programs (2SPs), the most widely applied and studied class of stochastic programming models. Solving 2SPs exactly requires evaluation of an expected value function that is computationally intractable. Additionally, having a mixed-integer linear program (MIP) or a nonlinear program (NLP) in the second stage further aggravates the problem difficulty. In such cases, solving them can be prohibitively expensive even if specialized algorithms that exploit problem structure are employed. Finding high-quality (first-stage) solutions -- without leveraging problem structure -- can be crucial in such settings. We develop Neur2SP, a new method that approximates the expected value function via a neural network to obtain a surrogate model that can be solved more efficiently than the traditional extensive formulation approach. Moreover, Neur2SP makes no assumptions about the problem structure, in particular about the second-stage problem, and can be implemented using an off-the-shelf solver and open-source libraries. Our extensive computational experiments on benchmark 2SP datasets from four problem classes with different structures (containing MIP and NLP second-stage problems) show the efficiency (time) and efficacy (solution quality) of Neur2SP. Specifically, the proposed method takes less than 1.66 seconds across all problems, achieving high-quality solutions even as the number of scenarios increases, an ideal property that is difficult to have for traditional 2SP solution techniques. Namely, the most generic baseline method typically requires minutes to hours to find solutions of comparable quality. ",
    "url": "https://arxiv.org/abs/2205.12006",
    "authors": [
      "Justin Dumouchelle",
      "Rahul Patel",
      "Elias B. Khalil",
      "Merve Bodur"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12032",
    "title": "Defending a Music Recommender Against Hubness-Based Adversarial Attacks",
    "abstract": "Adversarial attacks can drastically degrade performance of recommenders and other machine learning systems, resulting in an increased demand for defence mechanisms. We present a new line of defence against attacks which exploit a vulnerability of recommenders that operate in high dimensional data spaces (the so-called hubness problem). We use a global data scaling method, namely Mutual Proximity (MP), to defend a real-world music recommender which previously was susceptible to attacks that inflated the number of times a particular song was recommended. We find that using MP as a defence greatly increases robustness of the recommender against a range of attacks, with success rates of attacks around 44% (before defence) dropping to less than 6% (after defence). Additionally, adversarial examples still able to fool the defended system do so at the price of noticeably lower audio quality as shown by a decreased average SNR. ",
    "url": "https://arxiv.org/abs/2205.12032",
    "authors": [
      "Katharina Hoedt",
      "Arthur Flexer",
      "Gerhard Widmer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2205.12156",
    "title": "Not too little, not too much: a theoretical analysis of graph  (over)smoothing",
    "abstract": "We analyze graph smoothing with \\emph{mean aggregation}, where each node successively receives the average of the features of its neighbors. Indeed, it has quickly been observed that Graph Neural Networks (GNNs), which generally follow some variant of Message-Passing (MP) with repeated aggregation, may be subject to the \\emph{oversmoothing} phenomenon: by performing too many rounds of MP, the node features tend to converge to a non-informative limit. In the case of mean aggregation, for connected graphs, the node features become constant across the whole graph. At the other end of the spectrum, it is intuitively obvious that \\emph{some} MP rounds are necessary, but existing analyses do not exhibit both phenomena at once: beneficial ``finite'' smoothing and oversmoothing in the limit. In this paper, we consider simplified linear GNNs, and rigorously analyze two examples for which a finite number of mean aggregation steps provably improves the learning performance, before oversmoothing kicks in. We consider a latent space random graph model, where node features are partial observations of the latent variables and the graph contains pairwise relationships between them. We show that graph smoothing restores some of the lost information, up to a certain point, by two phenomenon: graph smoothing shrinks non-principal directions in the data faster than principal ones, which is useful for regression, and shrinks nodes within communities faster than they collapse together, which improves classification. ",
    "url": "https://arxiv.org/abs/2205.12156",
    "authors": [
      "Nicolas Keriven"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1908.00467",
    "title": "On the existence of paradoxical motions of generically rigid graphs on  the sphere",
    "abstract": " Comments: 42 pages. This is the accepted version of the manuscript; the final version of this work is this https URL ",
    "url": "https://arxiv.org/abs/1908.00467",
    "authors": [
      "Matteo Gallet",
      "Georg Grasegger",
      "Jan Legersk\u00fd",
      "Josef Schicho"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Robotics (cs.RO)",
      "Algebraic Geometry (math.AG)",
      "Metric Geometry (math.MG)"
    ]
  },
  {
    "id": "arXiv:1909.03862",
    "title": "Out-of-domain Detection for Natural Language Understanding in Dialog  Systems",
    "abstract": " Comments: Accepted by TASLP, Code available at this https URL ",
    "url": "https://arxiv.org/abs/1909.03862",
    "authors": [
      "Yinhe Zheng",
      "Guanyi Chen",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2002.00287",
    "title": "Efficient and Robust Algorithms for Adversarial Linear Contextual  Bandits",
    "abstract": " Title: Efficient and Robust Algorithms for Adversarial Linear Contextual  Bandits ",
    "url": "https://arxiv.org/abs/2002.00287",
    "authors": [
      "Gergely Neu",
      "Julia Olkhovskaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2007.10731",
    "title": "MAGMA: Inference and Prediction with Multi-Task Gaussian Processes",
    "abstract": " Title: MAGMA: Inference and Prediction with Multi-Task Gaussian Processes ",
    "url": "https://arxiv.org/abs/2007.10731",
    "authors": [
      "Arthur Leroy",
      "Pierre Latouche",
      "Benjamin Guedj",
      "Servane Gey"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2007.11972",
    "title": "DeepKriging: Spatially Dependent Deep Neural Networks for Spatial  Prediction",
    "abstract": " Title: DeepKriging: Spatially Dependent Deep Neural Networks for Spatial  Prediction ",
    "url": "https://arxiv.org/abs/2007.11972",
    "authors": [
      "Wanfang Chen",
      "Yuxiao Li",
      "Brian J Reich",
      "Ying Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2010.12138",
    "title": "Rethinking the competition between detection and ReID in Multi-Object  Tracking",
    "abstract": " Comments: Accepted by TIP ",
    "url": "https://arxiv.org/abs/2010.12138",
    "authors": [
      "Chao Liang",
      "Zhipeng Zhang",
      "Xue Zhou",
      "Bing Li",
      "Shuyuan Zhu",
      "Weiming Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2103.06460",
    "title": "Recent Advances on Neural Network Pruning at Initialization",
    "abstract": " Comments: Accepted in IJCAI'22 Survey Track. Code base: this https URL ",
    "url": "https://arxiv.org/abs/2103.06460",
    "authors": [
      "Huan Wang",
      "Can Qin",
      "Yue Bai",
      "Yulun Zhang",
      "Yun Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2105.05004",
    "title": "Smart Name Lookup for NDN Forwarding Plane via Neural Networks",
    "abstract": " Comments: This paper has been published in IEEE/ACM Transactions on Networking. The final version can be accessed from IEEE Xplore ",
    "url": "https://arxiv.org/abs/2105.05004",
    "authors": [
      "Zhuo Li",
      "Jindian Liu",
      "Liu Yan",
      "Beichuan Zhang",
      "Peng Luo",
      "Kaihua Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2106.01100",
    "title": "Prediction of the Position of External Markers Using a Recurrent Neural  Network Trained With Unbiased Online Recurrent Optimization for Safe Lung  Cancer Radiotherapy",
    "abstract": " Comments: 24 pages, 16 figures; Fig. 2 and acknowledgments section added, abstract, introduction, section 3.2, and conclusion section updated, formatting issues solved, English language and scientific unit mistakes corrected; accepted manuscript version ",
    "url": "https://arxiv.org/abs/2106.01100",
    "authors": [
      "Michel Pohl",
      "Mitsuru Uesaka",
      "Hiroyuki Takahashi",
      "Kazuyuki Demachi",
      "Ritu Bhusal Chhatkuli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2106.02797",
    "title": "Neural Distributed Source Coding",
    "abstract": " Title: Neural Distributed Source Coding ",
    "url": "https://arxiv.org/abs/2106.02797",
    "authors": [
      "Jay Whang",
      "Anish Acharya",
      "Hyeji Kim",
      "Alexandros G. Dimakis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.10823",
    "title": "3D Object Detection for Autonomous Driving: A Survey",
    "abstract": " Comments: The manuscript is accepted by Pattern Recognition on 14 May 2022 ",
    "url": "https://arxiv.org/abs/2106.10823",
    "authors": [
      "Rui Qian",
      "Xin Lai",
      "Xirong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.03220",
    "title": "Joint Embedding of Structural and Functional Brain Networks with Graph  Neural Networks for Mental Illness Diagnosis",
    "abstract": " Comments: Formal version accepted to IEEE EMBC 2022; previously presented at ICML 2021 Workshop on Computational Approaches to Mental Health (no proceedings) ",
    "url": "https://arxiv.org/abs/2107.03220",
    "authors": [
      "Yanqiao Zhu",
      "Hejie Cui",
      "Lifang He",
      "Lichao Sun",
      "Carl Yang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2107.07610",
    "title": "Self-Supervised Contrastive Learning with Adversarial Perturbations for  Defending Word Substitution-based Attacks",
    "abstract": " Comments: In Findings of NAACL 2022 ",
    "url": "https://arxiv.org/abs/2107.07610",
    "authors": [
      "Zhao Meng",
      "Yihan Dong",
      "Mrinmaya Sachan",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2107.13260",
    "title": "Deep learning based cough detection camera using enhanced features",
    "abstract": " Comments: 28 pages, 20 figures, and 14 tables ",
    "url": "https://arxiv.org/abs/2107.13260",
    "authors": [
      "Gyeong-Tae Lee",
      "Hyeonuk Nam",
      "Seong-Hu Kim",
      "Sang-Min Choi",
      "Youngkey Kim",
      "Yong-Hwa Park"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2109.11523",
    "title": "How much human-like visual experience do current self-supervised  learning algorithms need in order to achieve human-level object recognition?",
    "abstract": " Comments: v3 adds DINO + robustness scaling experiments ",
    "url": "https://arxiv.org/abs/2109.11523",
    "authors": [
      "A. Emin Orhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2110.04126",
    "title": "3D Infomax improves GNNs for Molecular Property Prediction",
    "abstract": " Comments: 39th International Conference on Machine Learning (ICML 2022). Also accepted at NeurIPS 2021 ML4PH, AI4S, and SSL workshops and as oral at ELLIS ML4Molecules. 23 pages, 7 figures, 18 tables ",
    "url": "https://arxiv.org/abs/2110.04126",
    "authors": [
      "Hannes St\u00e4rk",
      "Dominique Beaini",
      "Gabriele Corso",
      "Prudencio Tossou",
      "Christian Dallago",
      "Stephan G\u00fcnnemann",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2110.06920",
    "title": "Semantics-aware Attention Improves Neural Machine Translation",
    "abstract": " Comments: Accepted to *SEM 2022 ",
    "url": "https://arxiv.org/abs/2110.06920",
    "authors": [
      "Aviv Slobodkin",
      "Leshem Choshen",
      "Omri Abend"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2110.11017",
    "title": "Learning Time-Varying Graphs from Online Data",
    "abstract": " Comments: To appear on IEEE Open Journal of Signal Processing ",
    "url": "https://arxiv.org/abs/2110.11017",
    "authors": [
      "Alberto Natali",
      "Elvin Isufi",
      "Mario Coutino",
      "Geert Leus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2110.15037",
    "title": "Learning Deep Representation with Energy-Based Self-Expressiveness for  Subspace Clustering",
    "abstract": " Comments: There are some errors in Table 1 ",
    "url": "https://arxiv.org/abs/2110.15037",
    "authors": [
      "Yanming Li",
      "Changsheng Li",
      "Shiye Wang",
      "Ye Yuan",
      "Guoren Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.09954",
    "title": "MS-nowcasting: Operational Precipitation Nowcasting with Convolutional  LSTMs at Microsoft Weather",
    "abstract": " Comments: Minor updates to reflect final submission to NeurIPS workshop ",
    "url": "https://arxiv.org/abs/2111.09954",
    "authors": [
      "Sylwester Klocek",
      "Haiyu Dong",
      "Matthew Dixon",
      "Panashe Kanengoni",
      "Najeeb Kazmi",
      "Pete Luferenko",
      "Zhongjian Lv",
      "Shikhar Sharma",
      "Jonathan Weyn",
      "Siqi Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2112.08544",
    "title": "NewsClaims: A New Benchmark for Claim Detection from News with Attribute  Knowledge",
    "abstract": " Comments: Preprint ",
    "url": "https://arxiv.org/abs/2112.08544",
    "authors": [
      "Revanth Gangi Reddy",
      "Sai Chetan",
      "Zhenhailong Wang",
      "Yi R. Fung",
      "Kathryn Conger",
      "Ahmed Elsayed",
      "Martha Palmer",
      "Preslav Nakov",
      "Eduard Hovy",
      "Kevin Small",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.00565",
    "title": "Swift and Sure: Hardness-aware Contrastive Learning for Low-dimensional  Knowledge Graph Embeddings",
    "abstract": " Comments: 11 pages, accepted by the Web Conference 2022 ",
    "url": "https://arxiv.org/abs/2201.00565",
    "authors": [
      "Kai Wang",
      "Yu Liu",
      "Quan Z. Sheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.00719",
    "title": "PowerGraph: Using neural networks and principal components to determine  multivariate statistical power trade-offs",
    "abstract": " Comments: Submitted to AI4Science (ICML workshop). Not published yet ",
    "url": "https://arxiv.org/abs/2201.00719",
    "authors": [
      "Ajinkya K Mulay",
      "Sean Lane",
      "Erin Hennes"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.06543",
    "title": "The Power Word Problem in Graph Products",
    "abstract": " Title: The Power Word Problem in Graph Products ",
    "url": "https://arxiv.org/abs/2201.06543",
    "authors": [
      "Florian Stober",
      "Armin Wei\u00df"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2201.07546",
    "title": "Welfare vs. Representation in Participatory Budgeting",
    "abstract": " Title: Welfare vs. Representation in Participatory Budgeting ",
    "url": "https://arxiv.org/abs/2201.07546",
    "authors": [
      "Roy Fairstein",
      "Reshef Meir",
      "Dan Vilenchik",
      "Kobi Gal"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2201.09686",
    "title": "Balanced Graph Structure Learning for Multivariate Time Series  Forecasting",
    "abstract": " Comments: 16 pages, in submission to ECML-PKDD2022 ",
    "url": "https://arxiv.org/abs/2201.09686",
    "authors": [
      "Weijun Chen",
      "Yanze Wang",
      "Chengshuo Du",
      "Zhenglong Jia",
      "Feng Liu",
      "Ran Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11104",
    "title": "Combining optimal path search with task-dependent learning in a neural  network",
    "abstract": " Title: Combining optimal path search with task-dependent learning in a neural  network ",
    "url": "https://arxiv.org/abs/2201.11104",
    "authors": [
      "Tomas Kulvicius",
      "Minija Tamosiunaite",
      "Florentin W\u00f6rg\u00f6tter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.12724",
    "title": "Stochastic Neural Networks with Infinite Width are Deterministic",
    "abstract": " Title: Stochastic Neural Networks with Infinite Width are Deterministic ",
    "url": "https://arxiv.org/abs/2201.12724",
    "authors": [
      "Liu Ziyin",
      "Hanlin Zhang",
      "Xiangming Meng",
      "Yuting Lu",
      "Eric Xing",
      "Masahito Ueda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.13329",
    "title": "Can Adversarial Training Be Manipulated By Non-Robust Features?",
    "abstract": " Title: Can Adversarial Training Be Manipulated By Non-Robust Features? ",
    "url": "https://arxiv.org/abs/2201.13329",
    "authors": [
      "Lue Tao",
      "Lei Feng",
      "Hongxin Wei",
      "Jinfeng Yi",
      "Sheng-Jun Huang",
      "Songcan Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.03580",
    "title": "Convolutional Neural Networks on Graphs with Chebyshev Approximation,  Revisited",
    "abstract": " Comments: 18 pages ",
    "url": "https://arxiv.org/abs/2202.03580",
    "authors": [
      "Mingguo He",
      "Zhewei Wei",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.07626",
    "title": "Random Feature Amplification: Feature Learning and Generalization in  Neural Networks",
    "abstract": " Comments: 41 pages; updated references and presentation ",
    "url": "https://arxiv.org/abs/2202.07626",
    "authors": [
      "Spencer Frei",
      "Niladri S. Chatterji",
      "Peter L. Bartlett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.09587",
    "title": "Evaluation of Open-source Tools for Differential Privacy",
    "abstract": " Title: Evaluation of Open-source Tools for Differential Privacy ",
    "url": "https://arxiv.org/abs/2202.09587",
    "authors": [
      "Shiliang Zhang",
      "Anton Hagermalm",
      "Sanjin Slavnic",
      "Elad Michael Schiller",
      "Magnus Almgren"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.13758",
    "title": "Logical Fallacy Detection",
    "abstract": " Title: Logical Fallacy Detection ",
    "url": "https://arxiv.org/abs/2202.13758",
    "authors": [
      "Zhijing Jin",
      "Abhinav Lalwani",
      "Tejas Vaidhya",
      "Xiaoyu Shen",
      "Yiwen Ding",
      "Zhiheng Lyu",
      "Mrinmaya Sachan",
      "Rada Mihalcea",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2203.08118",
    "title": "Representation Learning for Resource-Constrained Keyphrase Generation",
    "abstract": " Title: Representation Learning for Resource-Constrained Keyphrase Generation ",
    "url": "https://arxiv.org/abs/2203.08118",
    "authors": [
      "Di Wu",
      "Wasi Uddin Ahmad",
      "Sunipa Dev",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.12369",
    "title": "MetricGAN+/-: Increasing Robustness of Noise Reduction on Unseen Data",
    "abstract": " Comments: 5 pages, 4 figures, Accepted to EUSIPCO 2022 ",
    "url": "https://arxiv.org/abs/2203.12369",
    "authors": [
      "George Close",
      "Thomas Hain",
      "Stefan Goetze"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.12821",
    "title": "On Understanding and Mitigating the Dimensional Collapse of Graph  Contrastive Learning: a Non-Maximum Removal Approach",
    "abstract": " Title: On Understanding and Mitigating the Dimensional Collapse of Graph  Contrastive Learning: a Non-Maximum Removal Approach ",
    "url": "https://arxiv.org/abs/2203.12821",
    "authors": [
      "Jiawei Sun",
      "Ruoxin Chen",
      "Jie Li",
      "Chentao Wu",
      "Yue Ding",
      "Junchi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.13436",
    "title": "Frame-level Prediction of Facial Expressions, Valence, Arousal and  Action Units for Mobile Devices",
    "abstract": " Comments: accepted at CVPR Workshop ABAW3, 8 pages, 2 figures, 6 tables ",
    "url": "https://arxiv.org/abs/2203.13436",
    "authors": [
      "Andrey V. Savchenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.16338",
    "title": "Stack operation of tensor networks",
    "abstract": " Comments: 9 pages, 10 figures, close to the online published version, for the code on Github, see this this https URL ",
    "url": "https://arxiv.org/abs/2203.16338",
    "authors": [
      "Tianning Zhang",
      "Tianqi Chen",
      "Erping Li",
      "Bo Yang",
      "L. K. Ang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2204.10762",
    "title": "Dite-HRNet: Dynamic Lightweight High-Resolution Network for Human Pose  Estimation",
    "abstract": " Comments: Accepted by IJCAI-ECAI 2022 ",
    "url": "https://arxiv.org/abs/2204.10762",
    "authors": [
      "Qun Li",
      "Ziyi Zhang",
      "Fu Xiao",
      "Feng Zhang",
      "Bir Bhanu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.00664",
    "title": "Simple Techniques Work Surprisingly Well for Neural Network Test  Prioritization and Active Learning (Replicability Study)",
    "abstract": " Comments: Accepted at ISSTA 2022 ",
    "url": "https://arxiv.org/abs/2205.00664",
    "authors": [
      "Michael Weiss",
      "Paolo Tonella"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.01550",
    "title": "Point Cloud Semantic Segmentation using Multi Scale Sparse Convolution  Neural Network",
    "abstract": " Title: Point Cloud Semantic Segmentation using Multi Scale Sparse Convolution  Neural Network ",
    "url": "https://arxiv.org/abs/2205.01550",
    "authors": [
      "Yunzheng Su",
      "Lei Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.06947",
    "title": "BronchusNet: Region and Structure Prior Embedded Representation Learning  for Bronchus Segmentation and Classification",
    "abstract": " Title: BronchusNet: Region and Structure Prior Embedded Representation Learning  for Bronchus Segmentation and Classification ",
    "url": "https://arxiv.org/abs/2205.06947",
    "authors": [
      "Wenhao Huang",
      "Haifan Gong",
      "Huan Zhang",
      "Yu Wang",
      "Haofeng Li",
      "Guanbin Li",
      "Hong Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10583",
    "title": "Improving automatically generated code from Codex via Automated Program  Repair",
    "abstract": " Comments: 12 pages ",
    "url": "https://arxiv.org/abs/2205.10583",
    "authors": [
      "Zhiyu Fan",
      "Xiang Gao",
      "Abhik Roychoudhury",
      "Shin Hwei Tan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.10710",
    "title": "Phrase-level Textual Adversarial Attack with Label Preservation",
    "abstract": " Comments: NAACL-HLT 2022 Findings (Long), 9 pages + 2 pages references + 8 pages appendix ",
    "url": "https://arxiv.org/abs/2205.10710",
    "authors": [
      "Yibin Lei",
      "Yu Cao",
      "Dianqi Li",
      "Tianyi Zhou",
      "Meng Fang",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10756",
    "title": "Real Time Detection Free Tracking of Multiple Objects Via Equilibrium  Optimizer",
    "abstract": " Title: Real Time Detection Free Tracking of Multiple Objects Via Equilibrium  Optimizer ",
    "url": "https://arxiv.org/abs/2205.10756",
    "authors": [
      "Djemai Charef-Khodja",
      "Toumi Abida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.10803",
    "title": "GraphMAE: Self-Supervised Masked Graph Autoencoders",
    "abstract": " Comments: 11 pages; Accepted to KDD'22 ",
    "url": "https://arxiv.org/abs/2205.10803",
    "authors": [
      "Zhenyu Hou",
      "Xiao Liu",
      "Yukuo Cen",
      "Yuxiao Dong",
      "Hongxia Yang",
      "Chunjie Wang",
      "Jie Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10852",
    "title": "Relphormer: Relational Graph Transformer for Knowledge Graph  Representation",
    "abstract": " Comments: Work in progress ",
    "url": "https://arxiv.org/abs/2205.10852",
    "authors": [
      "Zhen Bi",
      "Siyuan Cheng",
      "Ningyu Zhang",
      "Xiaozhuan Liang",
      "Feiyu Xiong",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.11232",
    "title": "Deep Neural Network approaches for Analysing Videos of Music  Performances",
    "abstract": " Title: Deep Neural Network approaches for Analysing Videos of Music  Performances ",
    "url": "https://arxiv.org/abs/2205.11232",
    "authors": [
      "Foteini Simistira Liwicki",
      "Richa Upadhyay",
      "Prakash Chandra Chhipa",
      "Killian Murphy",
      "Federico Visi",
      "Stefan \u00d6stersj\u00f6",
      "Marcus Liwicki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2205.11343",
    "title": "Heterogeneous Graph Neural Network for Personalized Session-Based  Recommendation with User-Session Constraints",
    "abstract": " Title: Heterogeneous Graph Neural Network for Personalized Session-Based  Recommendation with User-Session Constraints ",
    "url": "https://arxiv.org/abs/2205.11343",
    "authors": [
      "Minjae Park"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]