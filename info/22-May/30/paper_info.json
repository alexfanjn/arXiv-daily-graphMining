[
  {
    "id": "arXiv:2205.13571",
    "title": "Low-rank lottery tickets: finding efficient low-rank neural networks via  matrix differential equations",
    "abstract": "Neural networks have achieved tremendous success in a large variety of applications. However, their memory footprint and computational demand can render them impractical in application settings with limited hardware or energy resources. In this work, we propose a novel algorithm to find efficient low-rank subnetworks. Remarkably, these subnetworks are determined and adapted already during the training phase and the overall time and memory resources required by both training and evaluating them is significantly reduced. The main idea is to restrict the weight matrices to a low-rank manifold and to update the low-rank factors rather than the full matrix during training. To derive training updates that are restricted to the prescribed manifold, we employ techniques from dynamic model order reduction for matrix differential equations. Moreover, our method automatically and dynamically adapts the ranks during training to achieve a desired approximation accuracy. The efficiency of the proposed method is demonstrated through a variety of numerical experiments on fully-connected and convolutional networks. ",
    "url": "https://arxiv.org/abs/2205.13571",
    "authors": [
      "Steffen Schotth\u00f6fer",
      "Emanuele Zangrando",
      "Jonas Kusch",
      "Gianluca Ceruti",
      "Francesco Tudisco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.13578",
    "title": "Dynamic Network Reconfiguration for Entropy Maximization using Deep  Reinforcement Learning",
    "abstract": "A key problem in network theory is how to reconfigure a graph in order to optimize a quantifiable objective. Given the ubiquity of networked systems, such work has broad practical applications in a variety of situations, ranging from drug and material design to telecommunications. The large decision space of possible reconfigurations, however, makes this problem computationally intensive. In this paper, we cast the problem of network rewiring for optimizing a specified structural property as a Markov Decision Process (MDP), in which a decision-maker is given a budget of modifications that are performed sequentially. We then propose a general approach based on the Deep Q-Network (DQN) algorithm and graph neural networks (GNNs) that can efficiently learn strategies for rewiring networks. We then discuss a cybersecurity case study, i.e., an application to the computer network reconfiguration problem for intrusion protection. In a typical scenario, an attacker might have a (partial) map of the system they plan to penetrate; if the network is effectively \"scrambled\", they would not be able to navigate it since their prior knowledge would become obsolete. This can be viewed as an entropy maximization problem, in which the goal is to increase the surprise of the network. Indeed, entropy acts as a proxy measurement of the difficulty of navigating the network topology. We demonstrate the general ability of the proposed method to obtain better entropy gains than random rewiring on synthetic and real-world graphs while being computationally inexpensive, as well as being able to generalize to larger graphs than those seen during training. Simulations of attack scenarios confirm the effectiveness of the learned rewiring strategies. ",
    "url": "https://arxiv.org/abs/2205.13578",
    "authors": [
      "Christoffel Doorman",
      "Victor-Alexandru Darvariu",
      "Stephen Hailes",
      "Mirco Musolesi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2205.13585",
    "title": "Learning in Feedback-driven Recurrent Spiking Neural Networks using  full-FORCE Training",
    "abstract": "Feedback-driven recurrent spiking neural networks (RSNNs) are powerful computational models that can mimic dynamical systems. However, the presence of a feedback loop from the readout to the recurrent layer de-stabilizes the learning mechanism and prevents it from converging. Here, we propose a supervised training procedure for RSNNs, where a second network is introduced only during the training, to provide hint for the target dynamics. The proposed training procedure consists of generating targets for both recurrent and readout layers (i.e., for a full RSNN system). It uses the recursive least square-based First-Order and Reduced Control Error (FORCE) algorithm to fit the activity of each layer to its target. The proposed full-FORCE training procedure reduces the amount of modifications needed to keep the error between the output and target close to zero. These modifications control the feedback loop, which causes the training to converge. We demonstrate the improved performance and noise robustness of the proposed full-FORCE training procedure to model 8 dynamical systems using RSNNs with leaky integrate and fire (LIF) neurons and rate coding. For energy-efficient hardware implementation, an alternative time-to-first-spike (TTFS) coding is implemented for the full- FORCE training procedure. Compared to rate coding, full-FORCE with TTFS coding generates fewer spikes and facilitates faster convergence to the target dynamics. ",
    "url": "https://arxiv.org/abs/2205.13585",
    "authors": [
      "Ankita Paul",
      "Stefan Wagner",
      "Anup Das"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.13586",
    "title": "Comparing the Digital Annealer with Classical Evolutionary Algorithm",
    "abstract": "In more recent years, there has been increasing research interest in exploiting the use of application specific hardware for solving optimisation problems. Examples of solvers that use specialised hardware are IBM's Quantum System One and D-wave's Quantum Annealer (QA) and Fujitsu's Digital Annealer (DA). These solvers have been developed to optimise problems faster than traditional meta-heuristics implemented on general purpose machines. Previous research has shown that these solvers (can optimise many problems much quicker than exact solvers such as GUROBI and CPLEX. Such conclusions have not been made when comparing hardware solvers with classical evolutionary algorithms. Making a fair comparison between traditional evolutionary algorithms, such as Genetic Algorithm (GA), and the DA (or other similar solvers) is challenging because the later benefits from the use of application specific hardware while evolutionary algorithms are often implemented on generation purpose machines. Moreover, quantum or quantum-inspired solvers are limited to solving problems in a specific format. A common formulation used is Quadratic Unconstrained Binary Optimisation (QUBO). Many optimisation problems are however constrained and have natural representations that are non-binary. Converting such problems to QUBO can lead to more problem difficulty and/or larger search space. The question addressed in this paper is whether quantum or quantum-inspired solvers can optimise QUBO transformations of combinatorial optimisation problems faster than classical evolutionary algorithms applied to the same problems in their natural representations. We show that the DA often presents better average objective function values than GA on Travelling Salesman, Quadratic Assignment and Multi-dimensional Knapsack Problem instances. ",
    "url": "https://arxiv.org/abs/2205.13586",
    "authors": [
      "Mayowa Ayodele"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13587",
    "title": "Evolution of beliefs in social networks",
    "abstract": "Evolution of beliefs of a society are a product of interactions between people (horizontal transmission) in the society over generations (vertical transmission). Researchers have studied both horizontal and vertical transmission separately. Extending prior work, we propose a new theoretical framework which allows application of tools from Markov chain theory to the analysis of belief evolution via horizontal and vertical transmission. We analyze three cases: static network, randomly changing network, and homophily-based dynamic network. Whereas the former two assume network structure is independent of beliefs, the latter assumes that people tend to communicate with those who have similar beliefs. We prove under general conditions that both static and randomly changing networks converge to a single set of beliefs among all individuals along with the rate of convergence. We prove that homophily-based network structures do not in general converge to a single set of beliefs shared by all and prove lower bounds on the number of different limiting beliefs as a function of initial beliefs. We conclude by discussing implications for prior theories and directions for future work. ",
    "url": "https://arxiv.org/abs/2205.13587",
    "authors": [
      "Pushpi Paranamana",
      "Pei Wang",
      "Patrick Shafto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.13607",
    "title": "Self-supervised Pretraining and Transfer Learning Enable Flu and  COVID-19 Predictions in Small Mobile Sensing Datasets",
    "abstract": "Detailed mobile sensing data from phones, watches, and fitness trackers offer an unparalleled opportunity to quantify and act upon previously unmeasurable behavioral changes in order to improve individual health and accelerate responses to emerging diseases. Unlike in natural language processing and computer vision, deep representation learning has yet to broadly impact this domain, in which the vast majority of research and clinical applications still rely on manually defined features and boosted tree models or even forgo predictive modeling altogether due to insufficient accuracy. This is due to unique challenges in the behavioral health domain, including very small datasets (~10^1 participants), which frequently contain missing data, consist of long time series with critical long-range dependencies (length>10^4), and extreme class imbalances (>10^3:1). ",
    "url": "https://arxiv.org/abs/2205.13607",
    "authors": [
      "Mike A. Merrill",
      "Tim Althoff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2205.13613",
    "title": "Circumventing Backdoor Defenses That Are Based on Latent Separability",
    "abstract": "Deep learning models are vulnerable to backdoor poisoning attacks. In particular, adversaries can embed hidden backdoors into a model by only modifying a very small portion of its training data. On the other hand, it has also been commonly observed that backdoor poisoning attacks tend to leave a tangible signature in the latent space of the backdoored model i.e. poison samples and clean samples form two separable clusters in the latent space. These observations give rise to the popularity of latent separability assumption, which states that the backdoored DNN models will learn separable latent representations for poison and clean populations. A number of popular defenses (e.g. Spectral Signature, Activation Clustering, SCAn, etc.) are exactly built upon this assumption. However, in this paper, we show that the latent separation can be significantly suppressed via designing adaptive backdoor poisoning attacks with more sophisticated poison strategies, which consequently render state-of-the-art defenses based on this assumption less effective (and often completely fail). More interestingly, we find that our adaptive attacks can even evade some other typical backdoor defenses that do not explicitly build on this separability assumption. Our results show that adaptive backdoor poisoning attacks that can breach the latent separability assumption should be seriously considered for evaluating existing and future defenses. ",
    "url": "https://arxiv.org/abs/2205.13613",
    "authors": [
      "Xiangyu Qi",
      "Tinghao Xie",
      "Saeed Mahloujifar",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13616",
    "title": "Fight Poison with Poison: Detecting Backdoor Poison Samples via  Decoupling Benign Correlations",
    "abstract": "In this work, we study poison samples detection for defending against backdoor poisoning attacks on deep neural networks (DNNs). A principled idea underlying prior arts on this problem is to utilize the backdoored models' distinguishable behaviors on poison and clean populations to distinguish between these two different populations themselves and remove the identified poison. Many prior arts build their detectors upon a latent separability assumption, which states that backdoored models trained on the poisoned dataset will learn separable latent representations for backdoor and clean samples. Although such separation behaviors empirically exist for many existing attacks, there is no control on the separability and the extent of separation can vary a lot across different poison strategies, datasets, as well as the training configurations of backdoored models. Worse still, recent adaptive poison strategies can greatly reduce the \"distinguishable behaviors\" and consequently render most prior arts less effective (or completely fail). We point out that these limitations directly come from the passive reliance on some distinguishable behaviors that are not controlled by defenders. To mitigate such limitations, in this work, we propose the idea of active defense -- rather than passively assuming backdoored models will have certain distinguishable behaviors on poison and clean samples, we propose to actively enforce the trained models to behave differently on these two different populations. Specifically, we introduce confusion training as a concrete instance of active defense. ",
    "url": "https://arxiv.org/abs/2205.13616",
    "authors": [
      "Xiangyu Qi",
      "Tinghao Xie",
      "Saeed Mahloujifar",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13618",
    "title": "Denial-of-Service Attack on Object Detection Model Using Universal  Adversarial Perturbation",
    "abstract": "Adversarial attacks against deep learning-based object detectors have been studied extensively in the past few years. The proposed attacks aimed solely at compromising the models' integrity (i.e., trustworthiness of the model's prediction), while adversarial attacks targeting the models' availability, a critical aspect in safety-critical domains such as autonomous driving, have not been explored by the machine learning research community. In this paper, we propose NMS-Sponge, a novel approach that negatively affects the decision latency of YOLO, a state-of-the-art object detector, and compromises the model's availability by applying a universal adversarial perturbation (UAP). In our experiments, we demonstrate that the proposed UAP is able to increase the processing time of individual frames by adding \"phantom\" objects while preserving the detection of the original objects. ",
    "url": "https://arxiv.org/abs/2205.13618",
    "authors": [
      "Avishag Shapira",
      "Alon Zolfi",
      "Luca Demetrio",
      "Battista Biggio",
      "Asaf Shabtai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13623",
    "title": "A Hybrid Neural Autoencoder for Sensory Neuroprostheses and Its  Applications in Bionic Vision",
    "abstract": "Sensory neuroprostheses are emerging as a promising technology to restore lost sensory function or augment human capacities. However, sensations elicited by current devices often appear artificial and distorted. Although current models can often predict the neural or perceptual response to an electrical stimulus, an optimal stimulation strategy solves the inverse problem: what is the required stimulus to produce a desired response? Here we frame this as an end-to-end optimization problem, where a deep neural network encoder is trained to invert a known, fixed forward model that approximates the underlying biological system. As a proof of concept, we demonstrate the effectiveness of our hybrid neural autoencoder (HNA) on the use case of visual neuroprostheses. We found that HNA is able to produce high-fidelity stimuli from the MNIST and COCO datasets that outperform conventional encoding strategies and surrogate techniques across all tested conditions. Overall this is an important step towards the long-standing challenge of restoring high-quality vision to people living with incurable blindness and may prove a promising solution for a variety of neuroprosthetic technologies. ",
    "url": "https://arxiv.org/abs/2205.13623",
    "authors": [
      "Jacob Granley",
      "Lucas Relic",
      "Michael Beyeler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13624",
    "title": "Faster Optimization on Sparse Graphs via Neural Reparametrization",
    "abstract": "In mathematical optimization, second-order Newton's methods generally converge faster than first-order methods, but they require the inverse of the Hessian, hence are computationally expensive. However, we discover that on sparse graphs, graph neural networks (GNN) can implement an efficient Quasi-Newton method that can speed up optimization by a factor of 10-100x. Our method, neural reparametrization, modifies the optimization parameters as the output of a GNN to reshape the optimization landscape. Using a precomputed Hessian as the propagation rule, the GNN can effectively utilize the second-order information, reaching a similar effect as adaptive gradient methods. As our method solves optimization through architecture design, it can be used in conjunction with any optimizers such as Adam and RMSProp. We show the application of our method on scientifically relevant problems including heat diffusion, synchronization and persistent homology. ",
    "url": "https://arxiv.org/abs/2205.13624",
    "authors": [
      "Nima Dehmamy",
      "Csaba Both",
      "Jianzhi Long",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2205.13629",
    "title": "Deep Sensor Fusion with Pyramid Fusion Networks for 3D Semantic  Segmentation",
    "abstract": "Robust environment perception for autonomous vehicles is a tremendous challenge, which makes a diverse sensor set with e.g. camera, lidar and radar crucial. In the process of understanding the recorded sensor data, 3D semantic segmentation plays an important role. Therefore, this work presents a pyramid-based deep fusion architecture for lidar and camera to improve 3D semantic segmentation of traffic scenes. Individual sensor backbones extract feature maps of camera images and lidar point clouds. A novel Pyramid Fusion Backbone fuses these feature maps at different scales and combines the multimodal features in a feature pyramid to compute valuable multimodal, multi-scale features. The Pyramid Fusion Head aggregates these pyramid features and further refines them in a late fusion step, incorporating the final features of the sensor backbones. The approach is evaluated on two challenging outdoor datasets and different fusion strategies and setups are investigated. It outperforms recent range view based lidar approaches as well as all so far proposed fusion strategies and architectures. ",
    "url": "https://arxiv.org/abs/2205.13629",
    "authors": [
      "Hannah Schieber",
      "Fabian Duerr",
      "Torsten Schoen",
      "J\u00fcrgen Beyerer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.13634",
    "title": "BagFlip: A Certified Defense against Data Poisoning",
    "abstract": "Machine learning models are vulnerable to data-poisoning attacks, in which an attacker maliciously modifies the training set to change the prediction of a learned model. In a trigger-less attack, the attacker can modify the training set but not the test inputs, while in a backdoor attack the attacker can also modify test inputs. Existing model-agnostic defense approaches either cannot handle backdoor attacks or do not provide effective certificates (i.e., a proof of a defense). We present BagFlip, a model-agnostic certified approach that can effectively defend against both trigger-less and backdoor attacks. We evaluate BagFlip on image classification and malware detection datasets. BagFlip is equal to or more effective than the state-of-the-art approaches for trigger-less attacks and more effective than the state-of-the-art approaches for backdoor attacks. ",
    "url": "https://arxiv.org/abs/2205.13634",
    "authors": [
      "Yuhao Zhang",
      "Aws Albarghouthi",
      "Loris D'Antoni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13635",
    "title": "RIGID: Robust Linear Regression with Missing Data",
    "abstract": "We present a robust framework to perform linear regression with missing entries in the features. By considering an elliptical data distribution, and specifically a multivariate normal model, we are able to conditionally formulate a distribution for the missing entries and present a robust framework, which minimizes the worst case error caused by the uncertainty about the missing data. We show that the proposed formulation, which naturally takes into account the dependency between different variables, ultimately reduces to a convex program, for which a customized and scalable solver can be delivered. In addition to a detailed analysis to deliver such solver, we also asymptoticly analyze the behavior of the proposed framework, and present technical discussions to estimate the required input parameters. We complement our analysis with experiments performed on synthetic, semi-synthetic, and real data, and show how the proposed formulation improves the prediction accuracy and robustness, and outperforms the competing techniques. ",
    "url": "https://arxiv.org/abs/2205.13635",
    "authors": [
      "Alireza Aghasi",
      "MohammadJavad Feizollahi",
      "Saeed Ghadimi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2205.13639",
    "title": "A Model Predictive Control Functional Continuous Time Bayesian Network  for Self-Management of Multiple Chronic Conditions",
    "abstract": "Multiple chronic conditions (MCC) are one of the biggest challenges of modern times. The evolution of MCC follows a complex stochastic process that is influenced by a variety of risk factors, ranging from pre-existing conditions to modifiable lifestyle behavioral factors (e.g. diet, exercise habits, tobacco use, alcohol use, etc.) to non-modifiable socio-demographic factors (e.g., age, gender, education, marital status, etc.). People with MCC are at an increased risk of new chronic conditions and mortality. This paper proposes a model predictive control functional continuous time Bayesian network, an online recursive method to examine the impact of various lifestyle behavioral changes on the emergence trajectories of MCC and generate strategies to minimize the risk of progression of chronic conditions in individual patients. The proposed method is validated based on the Cameron county Hispanic cohort (CCHC) dataset, which has a total of 385 patients. The dataset examines the emergence of 5 chronic conditions (diabetes, obesity, cognitive impairment, hyperlipidemia, and hypertension) based on four modifiable risk factors representing lifestyle behaviors (diet, exercise habits, tobacco use, alcohol use) and four non-modifiable risk factors, including socio-demographic information (age, gender, education, marital status). The proposed method is tested under different scenarios (e.g., age group, the prior existence of MCC), demonstrating the effective intervention strategies for improving the lifestyle behavioral risk factors to offset MCC evolution. ",
    "url": "https://arxiv.org/abs/2205.13639",
    "authors": [
      "Syed Hasib Akhter Faruqui",
      "Adel Alaeddini",
      "Jing Wang",
      "Susan P Fisher-Hoch",
      "Joseph B Mccormick",
      "Julian Carvajal Rico"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2205.13647",
    "title": "Learning to Reason with Neural Networks: Generalization, Unseen Data and  Boolean Measures",
    "abstract": "This paper considers the Pointer Value Retrieval (PVR) benchmark introduced in [ZRKB21], where a 'reasoning' function acts on a string of digits to produce the label. More generally, the paper considers the learning of logical functions with gradient descent (GD) on neural networks. It is first shown that in order to learn logical functions with gradient descent on symmetric neural networks, the generalization error can be lower-bounded in terms of the noise-stability of the target function, supporting a conjecture made in [ZRKB21]. It is then shown that in the distribution shift setting, when the data withholding corresponds to freezing a single feature (referred to as canonical holdout), the generalization error of gradient descent admits a tight characterization in terms of the Boolean influence for several relevant architectures. This is shown on linear models and supported experimentally on other models such as MLPs and Transformers. In particular, this puts forward the hypothesis that for such architectures and for learning logical functions such as PVR functions, GD tends to have an implicit bias towards low-degree representations, which in turn gives the Boolean influence for the generalization error under quadratic loss. ",
    "url": "https://arxiv.org/abs/2205.13647",
    "authors": [
      "Emmanuel Abbe",
      "Samy Bengio",
      "Elisabetta Cornacchia",
      "Jon Kleinberg",
      "Aryo Lotfi",
      "Maithra Raghu",
      "Chiyuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.13658",
    "title": "On the Effect of Triadic Closure on Network Segregation",
    "abstract": "The tendency for individuals to form social ties with others who are similar to themselves, known as homophily, is one of the most robust sociological principles. Since this phenomenon can lead to patterns of interactions that segregate people along different demographic dimensions, it can also lead to inequalities in access to information, resources, and opportunities. As we consider potential interventions that might alleviate the effects of segregation, we face the challenge that homophily constitutes a pervasive and organic force that is difficult to push back against. Designing effective interventions can therefore benefit from identifying counterbalancing social processes that might be harnessed to work in opposition to segregation. In this work, we show that triadic closure -- another common phenomenon that posits that individuals with a mutual connection are more likely to be connected to one another -- can be one such process. In doing so, we challenge a long-held belief that triadic closure and homophily work in tandem. By analyzing several fundamental network models using popular integration measures, we demonstrate the desegregating potential of triadic closure. We further empirically investigate this effect on real-world dynamic networks, surfacing observations that mirror our theoretical findings. We leverage these insights to discuss simple interventions that can help reduce segregation in settings that exhibit an interplay between triadic closure and homophily. We conclude with a discussion on qualitative implications for the design of interventions in settings where individuals arrive in an online fashion, and the designer can influence the initial set of connections. ",
    "url": "https://arxiv.org/abs/2205.13658",
    "authors": [
      "Rediet Abebe",
      "Nicole Immorlica",
      "Jon Kleinberg",
      "Brendan Lucier",
      "Ali Shirali"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Theoretical Economics (econ.TH)"
    ]
  },
  {
    "id": "arXiv:2205.13660",
    "title": "Contextual Adapters for Personalized Speech Recognition in Neural  Transducers",
    "abstract": "Personal rare word recognition in end-to-end Automatic Speech Recognition (E2E ASR) models is a challenge due to the lack of training data. A standard way to address this issue is with shallow fusion methods at inference time. However, due to their dependence on external language models and the deterministic approach to weight boosting, their performance is limited. In this paper, we propose training neural contextual adapters for personalization in neural transducer based ASR models. Our approach can not only bias towards user-defined words, but also has the flexibility to work with pretrained ASR models. Using an in-house dataset, we demonstrate that contextual adapters can be applied to any general purpose pretrained ASR model to improve personalization. Our method outperforms shallow fusion, while retaining functionality of the pretrained models by not altering any of the model weights. We further show that the adapter style training is superior to full-fine-tuning of the ASR models on datasets with user-defined content. ",
    "url": "https://arxiv.org/abs/2205.13660",
    "authors": [
      "Kanthashree Mysore Sathyendra",
      "Thejaswi Muniyappa",
      "Feng-Ju Chang",
      "Jing Liu",
      "Jinru Su",
      "Grant P. Strimel",
      "Athanasios Mouchtaris",
      "Siegfried Kunzmann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13673",
    "title": "Diffusion of Community Fact-Checked Misinformation on Twitter",
    "abstract": "The spread of misinformation on social media is a pressing societal problem that platforms, policymakers, and researchers continue to grapple with. As a countermeasure, recent works have proposed to employ non-expert fact-checkers in the crowd to fact-check social media content. While experimental studies suggest that crowds might be able to accurately assess the veracity of social media content, an understanding of how crowd fact-checked (mis-)information spreads is missing. In this work, we empirically analyze the spread of misleading vs. not misleading community fact-checked posts on social media. For this purpose, we employ a unique dataset of community-created fact-checks from Twitter's \"Birdwatch\" platform and map them to resharing cascades on Twitter. Different from earlier studies analyzing the spread of misinformation listed on third-party fact-checking websites (e.g., snopes.com), we find that community fact-checked misinformation is less viral than the truth. Specifically, misleading posts are estimated to receive 36.85% fewer retweets than not misleading posts. A possible explanation lies in differences in the fact-checking targets: community fact-checkers tend to fact-check posts from influential user accounts with many followers, while expert fact-checks tend to target posts that are shared by less influential users. We further demonstrate that there are significant differences in virality across different sub-types of misinformation (e.g., factual errors, missing context, manipulated media). Altogether, our findings offer insights into how misleading vs. not misleading posts spread and highlight the crucial role of sample selection when studying misinformation on social media. ",
    "url": "https://arxiv.org/abs/2205.13673",
    "authors": [
      "Chiara Drolsbach",
      "Nicolas Pr\u00f6llochs"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.13679",
    "title": "SeedGNN: Graph Neural Networks for Supervised Seeded Graph Matching",
    "abstract": "Recently, there have been significant interests in designing Graph Neural Networks (GNNs) for seeded graph matching, which aims to match two (unlabeled) graphs using only topological information and a small set of seeds. However, most previous GNN architectures for seeded graph matching employ a semi-supervised approach, which learns from only the seed set in a single pair of graphs, and therefore does not attempt to learn from many training examples/graphs to best match future unseen graphs. In contrast, this paper is the first to propose a supervised approach for seeded graph matching, which had so far only been used for seedless graph matching. Our proposed SeedGNN architecture employs a number of novel design choices that are inspired by theoretical studies of seeded graph matching. First, SeedGNN can easily learn the capability of counting and using witnesses of different hops, in a way that can be generalized to graphs with different sizes. Second, SeedGNN can use easily-matched pairs as new seeds to percolate and match other nodes. We evaluate SeedGNN on both synthetic and real graphs, and demonstrate significant performance improvement over both non-learning and learning algorithms in the existing literature. Further, our experiments confirm that the knowledge learned by SeedGNN from training graphs can be generalized to test graphs with different sizes and categories. ",
    "url": "https://arxiv.org/abs/2205.13679",
    "authors": [
      "Liren Yu",
      "Jiaming Xu",
      "Xiaojun Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13680",
    "title": "Membership Inference Attack Using Self Influence Functions",
    "abstract": "Member inference (MI) attacks aim to determine if a specific data sample was used to train a machine learning model. Thus, MI is a major privacy threat to models trained on private sensitive data, such as medical records. In MI attacks one may consider the black-box settings, where the model's parameters and activations are hidden from the adversary, or the white-box case where they are available to the attacker. In this work, we focus on the latter and present a novel MI attack for it that employs influence functions, or more specifically the samples' self-influence scores, to perform the MI prediction. We evaluate our attack on CIFAR-10, CIFAR-100, and Tiny ImageNet datasets, using versatile architectures such as AlexNet, ResNet, and DenseNet. Our attack method achieves new state-of-the-art results for both training with and without data augmentations. Code is available at https://github.com/giladcohen/sif_mi_attack. ",
    "url": "https://arxiv.org/abs/2205.13680",
    "authors": [
      "Gilad Cohen",
      "Raja Giryes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13682",
    "title": "ANISE: Assembly-based Neural Implicit Surface rEconstruction",
    "abstract": "We present ANISE, a method that reconstructs a 3D shape from partial observations (images or sparse point clouds) using a part-aware neural implicit shape representation. It is formulated as an assembly of neural implicit functions, each representing a different shape part. In contrast to previous approaches, the prediction of this representation proceeds in a coarse-to-fine manner. Our network first predicts part transformations which are associated with part neural implicit functions conditioned on those transformations. The part implicit functions can then be combined into a single, coherent shape, enabling part-aware shape reconstructions from images and point clouds. Those reconstructions can be obtained in two ways: (i) by directly decoding combining the refined part implicit functions; or (ii) by using part latents to query similar parts in a part database and assembling them in a single shape. We demonstrate that, when performing reconstruction by decoding part representations into implicit functions, our method achieves state-of-the-art part-aware reconstruction results from both images and sparse point clouds. When reconstructing shapes by assembling parts queried from a dataset, our approach significantly outperforms traditional shape retrieval methods even when significantly restricting the size of the shape database. We present our results in well-known sparse point cloud reconstruction and single-view reconstruction benchmarks. ",
    "url": "https://arxiv.org/abs/2205.13682",
    "authors": [
      "Dmitry Petrov",
      "Matheus Gadelha",
      "Radomir Mech",
      "Evangelos Kalogerakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2205.13685",
    "title": "Adversarial attacks and defenses in Speaker Recognition Systems: A  survey",
    "abstract": "Speaker recognition has become very popular in many application scenarios, such as smart homes and smart assistants, due to ease of use for remote control and economic-friendly features. The rapid development of SRSs is inseparable from the advancement of machine learning, especially neural networks. However, previous work has shown that machine learning models are vulnerable to adversarial attacks in the image domain, which inspired researchers to explore adversarial attacks and defenses in Speaker Recognition Systems (SRS). Unfortunately, existing literature lacks a thorough review of this topic. In this paper, we fill this gap by performing a comprehensive survey on adversarial attacks and defenses in SRSs. We first introduce the basics of SRSs and concepts related to adversarial attacks. Then, we propose two sets of criteria to evaluate the performance of attack methods and defense methods in SRSs, respectively. After that, we provide taxonomies of existing attack methods and defense methods, and further review them by employing our proposed criteria. Finally, based on our review, we find some open issues and further specify a number of future directions to motivate the research of SRSs security. ",
    "url": "https://arxiv.org/abs/2205.13685",
    "authors": [
      "Jiahe Lan",
      "Rui Zhang",
      "Zheng Yan",
      "Jie Wang",
      "Yu Chen",
      "Ronghui Hou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.13689",
    "title": "Safety Aware Changepoint Detection for Piecewise i.i.d. Bandits",
    "abstract": "In this paper, we consider the setting of piecewise i.i.d. bandits under a safety constraint. In this piecewise i.i.d. setting, there exists a finite number of changepoints where the mean of some or all arms change simultaneously. We introduce the safety constraint studied in \\citet{wu2016conservative} to this setting such that at any round the cumulative reward is above a constant factor of the default action reward. We propose two actively adaptive algorithms for this setting that satisfy the safety constraint, detect changepoints, and restart without the knowledge of the number of changepoints or their locations. We provide regret bounds for our algorithms and show that the bounds are comparable to their counterparts from the safe bandit and piecewise i.i.d. bandit literature. We also provide the first matching lower bounds for this setting. Empirically, we show that our safety-aware algorithms perform similarly to the state-of-the-art actively adaptive algorithms that do not satisfy the safety constraint. ",
    "url": "https://arxiv.org/abs/2205.13689",
    "authors": [
      "Subhojyoti Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13692",
    "title": "FedAvg with Fine Tuning: Local Updates Lead to Representation Learning",
    "abstract": "The Federated Averaging (FedAvg) algorithm, which consists of alternating between a few local stochastic gradient updates at client nodes, followed by a model averaging update at the server, is perhaps the most commonly used method in Federated Learning. Notwithstanding its simplicity, several empirical studies have illustrated that the output model of FedAvg, after a few fine-tuning steps, leads to a model that generalizes well to new unseen tasks. This surprising performance of such a simple method, however, is not fully understood from a theoretical point of view. In this paper, we formally investigate this phenomenon in the multi-task linear representation setting. We show that the reason behind generalizability of the FedAvg's output is its power in learning the common data representation among the clients' tasks, by leveraging the diversity among client data distributions via local updates. We formally establish the iteration complexity required by the clients for proving such result in the setting where the underlying shared representation is a linear map. To the best of our knowledge, this is the first such result for any setting. We also provide empirical evidence demonstrating FedAvg's representation learning ability in federated image classification with heterogeneous data. ",
    "url": "https://arxiv.org/abs/2205.13692",
    "authors": [
      "Liam Collins",
      "Hamed Hassani",
      "Aryan Mokhtari",
      "Sanjay Shakkottai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13700",
    "title": "ES-GNN: Generalizing Graph Neural Networks Beyond Homophily with Edge  Splitting",
    "abstract": "Graph Neural Networks (GNNs) have achieved enormous success in tackling analytical problems on graph data. Most GNNs interpret nearly all the node connections as inductive bias with feature smoothness, and implicitly assume strong homophily on the observed graph. However, real-world networks are not always homophilic, but sometimes exhibit heterophilic patterns where adjacent nodes share dissimilar attributes and distinct labels. Therefore,GNNs smoothing the node proximity holistically may aggregate inconsistent information arising from both task-relevant and irrelevant connections. In this paper, we propose a novel edge splitting GNN (ES-GNN) framework, which generalizes GNNs beyond homophily by jointly partitioning network topology and disentangling node features. Specifically, the proposed framework employs an interpretable operation to adaptively split the set of edges of the original graph into two exclusive sets indicating respectively the task-relevant and irrelevant relations among nodes. The node features are then aggregated separately on these two partial edge sets to produce disentangled representations, based on which a more accurate edge splitting can be attained later. Theoretically, we show that our ES-GNN can be regarded as a solution to a graph denoising problem with a disentangled smoothness assumption, which further illustrates our motivations and interprets the improved generalization. Extensive experiments over 8 benchmark and 1 synthetic datasets demonstrate that ES-GNN not only outperforms the state-of-the-arts (including 8 GNN baselines), but also can be more robust to adversarial graphs and alleviate the over-smoothing problem. ",
    "url": "https://arxiv.org/abs/2205.13700",
    "authors": [
      "Jingwei Guo",
      "Kaizhu Huang",
      "Xinping Yi",
      "Rui Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13702",
    "title": "R-HTDetector: Robust Hardware-Trojan Detection Based on Adversarial  Training",
    "abstract": "Hardware Trojans (HTs) have become a serious problem, and extermination of them is strongly required for enhancing the security and safety of integrated circuits. An effective solution is to identify HTs at the gate level via machine learning techniques. However, machine learning has specific vulnerabilities, such as adversarial examples. In reality, it has been reported that adversarial modified HTs greatly degrade the performance of a machine learning-based HT detection method. Therefore, we propose a robust HT detection method using adversarial training (R-HTDetector). We formally describe the robustness of R-HTDetector in modifying HTs. Our work gives the world-first adversarial training for HT detection with theoretical backgrounds. We show through experiments with Trust-HUB benchmarks that R-HTDetector overcomes adversarial examples while maintaining its original accuracy. ",
    "url": "https://arxiv.org/abs/2205.13702",
    "authors": [
      "Kento Hasegawa",
      "Seira Hidano",
      "Kohei Nozawa",
      "Shinsaku Kiyomoto",
      "Nozomu Togawa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.13705",
    "title": "A Decentralized Collaborative Learning Framework Across Heterogeneous  Devices for Personalized Predictive Analytics",
    "abstract": "In this paper, we propose a Similarity-based Decentralized Knowledge Distillation (SD-Dist) framework for collaboratively learning heterogeneous deep models on decentralized devices. By introducing a preloaded reference dataset, SD-Dist enables all participant devices to identify similar users and distil knowledge from them without any assumptions on a fixed model architecture. In addition, none of these operations will reveal any sensitive information like personal data and model parameters. Extensive experimental results on three real-life datasets show that SD-Dist can achieve competitive performance with less compute resources, while ensuring model heterogeneity and privacy. As revealed in our experiments, our framework also enhances the resultant models' robustness when users' data is sparse and diverse. ",
    "url": "https://arxiv.org/abs/2205.13705",
    "authors": [
      "Guanhua Ye",
      "Hongzhi Yin",
      "Tong Chen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.13710",
    "title": "Privacy of Noisy Stochastic Gradient Descent: More Iterations without  More Privacy Loss",
    "abstract": "A central issue in machine learning is how to train models on sensitive user data. Industry has widely adopted a simple algorithm: Stochastic Gradient Descent with noise (a.k.a. Stochastic Gradient Langevin Dynamics). However, foundational theoretical questions about this algorithm's privacy loss remain open -- even in the seemingly simple setting of smooth convex losses over a bounded domain. Our main result resolves these questions: for a large range of parameters, we characterize the differential privacy up to a constant factor. This result reveals that all previous analyses for this setting have the wrong qualitative behavior. Specifically, while previous privacy analyses increase ad infinitum in the number of iterations, we show that after a small burn-in period, running SGD longer leaks no further privacy. Our analysis departs completely from previous approaches based on fast mixing, instead using techniques based on optimal transport (namely, Privacy Amplification by Iteration) and the Sampled Gaussian Mechanism (namely, Privacy Amplification by Sampling). Our techniques readily extend to other settings, e.g., strongly convex losses, non-uniform stepsizes, arbitrary batch sizes, and random or cyclic choice of batches. ",
    "url": "https://arxiv.org/abs/2205.13710",
    "authors": [
      "Jason M. Altschuler",
      "Kunal Talwar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.13711",
    "title": "Incorporating the Barzilai-Borwein Adaptive Step Size into Sugradient  Methods for Deep Network Training",
    "abstract": "In this paper, we incorporate the Barzilai-Borwein step size into gradient descent methods used to train deep networks. This allows us to adapt the learning rate using a two-point approximation to the secant equation which quasi-Newton methods are based upon. Moreover, the adaptive learning rate method presented here is quite general in nature and can be applied to widely used gradient descent approaches such as Adagrad and RMSprop. We evaluate our method using standard example network architectures on widely available datasets and compare against alternatives elsewhere in the literature. In our experiments, our adaptive learning rate shows a smoother and faster convergence than that exhibited by the alternatives, with better or comparable performance. ",
    "url": "https://arxiv.org/abs/2205.13711",
    "authors": [
      "Antonio Robles-Kelly",
      "Asef Nazari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13714",
    "title": "Distributed Gaussian Process Based Cooperative Visual Pursuit Control  for Drone Networks",
    "abstract": "In this paper, we propose a control law for camera-equipped drone networks to pursue a target rigid body with unknown motion based on distributed Gaussian process. First, we consider the situation where each drone has its own dataset, and learned the unknown target motion in a distributed manner. Second, we propose a control law using the distributed Gaussian processes, and show that the estimation and control errors are ultimately bounded. Furthermore, the effectiveness of the proposed method is verified by using simulations and experiments with actual drones. ",
    "url": "https://arxiv.org/abs/2205.13714",
    "authors": [
      "Makoto Saito",
      "Junya Yamauchi",
      "Tesshu Fujinami",
      "Marco Omainska",
      "Masayuki Fujita"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.13720",
    "title": "Effective Abstract Reasoning with Dual-Contrast Network",
    "abstract": "As a step towards improving the abstract reasoning capability of machines, we aim to solve Raven's Progressive Matrices (RPM) with neural networks, since solving RPM puzzles is highly correlated with human intelligence. Unlike previous methods that use auxiliary annotations or assume hidden rules to produce appropriate feature representation, we only use the ground truth answer of each question for model learning, aiming for an intelligent agent to have a strong learning capability with a small amount of supervision. Based on the RPM problem formulation, the correct answer filled into the missing entry of the third row/column has to best satisfy the same rules shared between the first two rows/columns. Thus we design a simple yet effective Dual-Contrast Network (DCNet) to exploit the inherent structure of RPM puzzles. Specifically, a rule contrast module is designed to compare the latent rules between the filled row/column and the first two rows/columns; a choice contrast module is designed to increase the relative differences between candidate choices. Experimental results on the RAVEN and PGM datasets show that DCNet outperforms the state-of-the-art methods by a large margin of 5.77%. Further experiments on few training samples and model generalization also show the effectiveness of DCNet. Code is available at https://github.com/visiontao/dcnet. ",
    "url": "https://arxiv.org/abs/2205.13720",
    "authors": [
      "Tao Zhuo",
      "Mohan Kankanhalli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13733",
    "title": "On Consistency in Graph Neural Network Interpretation",
    "abstract": "Uncovering rationales behind predictions of graph neural networks (GNNs) has received increasing attention over recent years. Instance-level GNN explanation aims to discover critical input elements, like nodes or edges, that the target GNN relies upon for making predictions. These identified sub-structures can provide interpretations of GNN's behavior. Though various algorithms are proposed, most of them formalize this task by searching the minimal subgraph which can preserve original predictions. An inductive bias is deep-rooted in this framework: the same output cannot guarantee that two inputs are processed under the same rationale. Consequently, they have the danger of providing spurious explanations and fail to provide consistent explanations. Applying them to explain weakly-performed GNNs would further amplify these issues. To address the issues, we propose to obtain more faithful and consistent explanations of GNNs. After a close examination on predictions of GNNs from the causality perspective, we attribute spurious explanations to two typical reasons: confounding effect of latent variables like distribution shift, and causal factors distinct from the original input. Motivated by the observation that both confounding effects and diverse causal rationales are encoded in internal representations, we propose a simple yet effective countermeasure by aligning embeddings. This new objective can be incorporated into existing GNN explanation algorithms with no effort. We implement both a simplified version based on absolute distance and a distribution-aware version based on anchors. Experiments on $5$ datasets validate its effectiveness, and theoretical analysis shows that it is in effect optimizing a more faithful explanation objective in design, which further justifies the proposed approach. ",
    "url": "https://arxiv.org/abs/2205.13733",
    "authors": [
      "Tianxiang Zhao",
      "Dongsheng Luo",
      "Xiang Zhang",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.13738",
    "title": "Image Reconstruction of Multi Branch Feature Multiplexing Fusion Network  with Mixed Multi-layer Attention",
    "abstract": "Image super-resolution reconstruction achieves better results than traditional methods with the help of the powerful nonlinear representation ability of convolution neural network. However, some existing algorithms also have some problems, such as insufficient utilization of phased features, ignoring the importance of early phased feature fusion to improve network performance, and the inability of the network to pay more attention to high-frequency information in the reconstruction process. To solve these problems, we propose a multi-branch feature multiplexing fusion network with mixed multi-layer attention (MBMFN), which realizes the multiple utilization of features and the multistage fusion of different levels of features. To further improve the networks performance, we propose a lightweight enhanced residual channel attention (LERCA), which can not only effectively avoid the loss of channel information but also make the network pay more attention to the key channel information and benefit from it. Finally, the attention mechanism is introduced into the reconstruction process to strengthen the restoration of edge texture and other details. A large number of experiments on several benchmark sets show that, compared with other advanced reconstruction algorithms, our algorithm produces highly competitive objective indicators and restores more image detail texture information. ",
    "url": "https://arxiv.org/abs/2205.13738",
    "authors": [
      "Yuxi Cai",
      "Huicheng Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.13744",
    "title": "Learning Instance Representation Banks for Aerial Scene Classification",
    "abstract": "Aerial scenes are more complicated in terms of object distribution and spatial arrangement than natural scenes due to the bird view, and thus remain challenging to learn discriminative scene representation. Recent solutions design \\textit{local semantic descriptors} so that region of interests (RoIs) can be properly highlighted. However, each local descriptor has limited description capability and the overall scene representation remains to be refined. In this paper, we solve this problem by designing a novel representation set named \\textit{instance representation bank} (IRB), which unifies multiple local descriptors under the multiple instance learning (MIL) formulation. This unified framework is not trivial as all the local semantic descriptors can be aligned to the same scene scheme, enhancing the scene representation capability. Specifically, our IRB learning framework consists of a backbone, an instance representation bank, a semantic fusion module and a scene scheme alignment loss function. All the components are organized in an end-to-end manner. Extensive experiments on three aerial scene benchmarks demonstrate that our proposed method outperforms the state-of-the-art approaches by a large margin. ",
    "url": "https://arxiv.org/abs/2205.13744",
    "authors": [
      "Jingjun Yi",
      "Beichen Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13748",
    "title": "Auto-PINN: Understanding and Optimizing Physics-Informed Neural  Architecture",
    "abstract": "Physics-informed neural networks (PINNs) are revolutionizing science and engineering practice by bringing together the power of deep learning to bear on scientific computation. In forward modeling problems, PINNs are meshless partial differential equation (PDE) solvers that can handle irregular, high-dimensional physical domains. Naturally, the neural architecture hyperparameters have a large impact on the efficiency and accuracy of the PINN solver. However, this remains an open and challenging problem because of the large search space and the difficulty of identifying a proper search objective for PDEs. Here, we propose Auto-PINN, the first systematic, automated hyperparameter optimization approach for PINNs, which employs Neural Architecture Search (NAS) techniques to PINN design. Auto-PINN avoids manually or exhaustively searching the hyperparameter space associated with PINNs. A comprehensive set of pre-experiments using standard PDE benchmarks allows us to probe the structure-performance relationship in PINNs. We find that the different hyperparameters can be decoupled, and that the training loss function of PINNs is a good search objective. Comparison experiments with baseline methods demonstrate that Auto-PINN produces neural architectures with superior stability and accuracy over alternative baselines. ",
    "url": "https://arxiv.org/abs/2205.13748",
    "authors": [
      "Yicheng Wang",
      "Xiaotian Han",
      "Chia-Yuan Chang",
      "Daochen Zha",
      "Ulisses Braga-Neto",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13750",
    "title": "Attention Awareness Multiple Instance Neural Network",
    "abstract": "Multiple instance learning is qualified for many pattern recognition tasks with weakly annotated data. The combination of artificial neural network and multiple instance learning offers an end-to-end solution and has been widely utilized. However, challenges remain in two-folds. Firstly, current MIL pooling operators are usually pre-defined and lack flexibility to mine key instances. Secondly, in current solutions, the bag-level representation can be inaccurate or inaccessible. To this end, we propose an attention awareness multiple instance neural network framework in this paper. It consists of an instance-level classifier, a trainable MIL pooling operator based on spatial attention and a bag-level classification layer. Exhaustive experiments on a series of pattern recognition tasks demonstrate that our framework outperforms many state-of-the-art MIL methods and validates the effectiveness of our proposed attention MIL pooling operators. ",
    "url": "https://arxiv.org/abs/2205.13750",
    "authors": [
      "Jingjun Yi",
      "Beichen Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13760",
    "title": "Tranception: protein fitness prediction with autoregressive transformers  and inference-time retrieval",
    "abstract": "The ability to accurately model the fitness landscape of protein sequences is critical to a wide range of applications, from quantifying the effects of human variants on disease likelihood, to predicting immune-escape mutations in viruses and designing novel biotherapeutic proteins. Deep generative models of protein sequences trained on multiple sequence alignments have been the most successful approaches so far to address these tasks. The performance of these methods is however contingent on the availability of sufficiently deep and diverse alignments for reliable training. Their potential scope is thus limited by the fact many protein families are hard, if not impossible, to align. Large language models trained on massive quantities of non-aligned protein sequences from diverse families address these problems and show potential to eventually bridge the performance gap. We introduce Tranception, a novel transformer architecture leveraging autoregressive predictions and retrieval of homologous sequences at inference to achieve state-of-the-art fitness prediction performance. Given its markedly higher performance on multiple mutants, robustness to shallow alignments and ability to score indels, our approach offers significant gain of scope over existing approaches. To enable more rigorous model testing across a broader range of protein families, we develop ProteinGym -- an extensive set of multiplexed assays of variant effects, substantially increasing both the number and diversity of assays compared to existing benchmarks. ",
    "url": "https://arxiv.org/abs/2205.13760",
    "authors": [
      "Pascal Notin",
      "Mafalda Dias",
      "Jonathan Frazer",
      "Javier Marchena-Hurtado",
      "Aidan Gomez",
      "Debora S. Marks",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13763",
    "title": "Tutorial on Course-of-Action (COA) Attack Search Methods in Computer  Networks",
    "abstract": "In the literature of modern network security research, deriving effective and efficient course-of-action (COA) attach search methods are of interests in industry and academia. As the network size grows, the traditional COA attack search methods can suffer from the limitations to computing and communication resources. Therefore, various methods have been developed to solve these problems, and reinforcement learning (RL)-based intelligent algorithms are one of the most effective solutions. Therefore, we review the RL-based COA attack search methods for network attack scenarios in terms of the trends and their contrib ",
    "url": "https://arxiv.org/abs/2205.13763",
    "authors": [
      "Seok Bin Son",
      "Soohyun Park",
      "Haemin Lee",
      "Joongheon Kim",
      "Soyi Jung",
      "Donghwa Kim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13764",
    "title": "Fully Convolutional One-Stage 3D Object Detection on LiDAR Range Images",
    "abstract": "We present a simple yet effective fully convolutional one-stage 3D object detector for LiDAR point clouds of autonomous driving scenes, termed FCOS-LiDAR. Unlike the dominant methods that use the bird-eye view (BEV), our proposed detector detects objects from the range view (RV, a.k.a. range image) of the LiDAR points. Due to the range view's compactness and compatibility with the LiDAR sensors' sampling process on self-driving cars, the range view-based object detector can be realized by solely exploiting the vanilla 2D convolutions, departing from the BEV-based methods which often involve complicated voxelization operations and sparse convolutions. For the first time, we show that an RV-based 3D detector with standard 2D convolutions alone can achieve comparable performance to state-of-the-art BEV-based detectors while being significantly faster and simpler. More importantly, almost all previous range view-based detectors only focus on single-frame point clouds, since it is challenging to fuse multi-frame point clouds into a single range view. In this work, we tackle this challenging issue with a novel range view projection mechanism, and for the first time demonstrate the benefits of fusing multi-frame point clouds for a range-view based detector. Extensive experiments on nuScenes show the superiority of our proposed method and we believe that our work can be strong evidence that an RV-based 3D detector can compare favourably with the current mainstream BEV-based detectors. ",
    "url": "https://arxiv.org/abs/2205.13764",
    "authors": [
      "Zhi Tian",
      "Xiangxiang Chu",
      "Xiaoming Wang",
      "Xiaolin Wei",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13765",
    "title": "Machine Learning-based Ransomware Detection Using Low-level Memory  Access Patterns Obtained From Live-forensic Hypervisor",
    "abstract": "Since modern anti-virus software mainly depends on a signature-based static analysis, they are not suitable for coping with the rapid increase in malware variants. Moreover, even worse, many vulnerabilities of operating systems enable attackers to evade such protection mechanisms. We, therefore, developed a thin and lightweight live-forensic hypervisor to create an additional protection layer under a conventional protection layer of operating systems with supporting ransomware detection using dynamic behavioral features. The developed live-forensic hypervisor collects low-level memory access patterns instead of high-level information such as process IDs and API calls that modern Virtual Machine Introspection techniques have employed. We then created the low-level memory access patterns dataset of three ransomware samples, one wiper malware sample, and four benign applications. We confirmed that our best machine learning classifier using only low-level memory access patterns achieved an $F_1$ score of 0.95 in detecting ransomware and wiper malware. ",
    "url": "https://arxiv.org/abs/2205.13765",
    "authors": [
      "Manabu Hirano",
      "Ryotaro Kobayashi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.13769",
    "title": "Semantic-aware Dense Representation Learning for Remote Sensing Image  Change Detection",
    "abstract": "Training deep learning-based change detection (CD) model heavily depends on labeled data. Contemporary transfer learning-based methods to alleviate the CD label insufficiency mainly upon ImageNet pre-training. A recent trend is using remote sensing (RS) data to obtain in-domain representations via supervised or self-supervised learning (SSL). Here, different from traditional supervised pre-training that learns the mapping from image to label, we leverage semantic supervision in a contrastive manner. There are typically multiple objects of interest (e.g., buildings) distributed in varying locations in RS images. We propose dense semantic-aware pre-training for RS image CD via sampling multiple class-balanced points. Instead of manipulating image-level representations that lack spatial information, we constrain pixel-level cross-view consistency and cross-semantic discrimination to learn spatially-sensitive features, thus benefiting downstream dense CD. Apart from learning illumination invariant features, we fulfill consistent foreground features insensitive to irrelevant background changes via a synthetic view using background swapping. We additionally achieve discriminative representations to distinguish foreground land-covers and others. We collect large-scale image-mask pairs freely available in the RS community for pre-training. Extensive experiments on three CD datasets verify the effectiveness of our method. Ours significantly outperforms ImageNet, in-domain supervision, and several SSL methods. Empirical results indicate ours well alleviates data insufficiency in CD. Notably, we achieve competitive results using only 20% training data than baseline (random) using 100% data. Both quantitative and qualitative results demonstrate the generalization ability of our pre-trained model to downstream images even remaining domain gaps with the pre-training data. Our Code will make public. ",
    "url": "https://arxiv.org/abs/2205.13769",
    "authors": [
      "Hao Chen",
      "Wenyuan Li",
      "Song Chen",
      "Zhenwei Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13770",
    "title": "LEAF + AIO: Edge-Assisted Energy-Aware Object Detection for Mobile  Augmented Reality",
    "abstract": "Today very few deep learning-based mobile augmented reality (MAR) applications are applied in mobile devices because they are significantly energy-guzzling. In this paper, we design an edge-based energy-aware MAR system that enables MAR devices to dynamically change their configurations, such as CPU frequency, computation model size, and image offloading frequency based on user preferences, camera sampling rates, and available radio resources. Our proposed dynamic MAR configuration adaptations can minimize the per frame energy consumption of multiple MAR clients without degrading their preferred MAR performance metrics, such as latency and detection accuracy. To thoroughly analyze the interactions among MAR configurations, user preferences, camera sampling rate, and energy consumption, we propose, to the best of our knowledge, the first comprehensive analytical energy model for MAR devices. Based on the proposed analytical model, we design a LEAF optimization algorithm to guide the MAR configuration adaptation and server radio resource allocation. An image offloading frequency orchestrator, coordinating with the LEAF, is developed to adaptively regulate the edge-based object detection invocations and to further improve the energy efficiency of MAR devices. Extensive evaluations are conducted to validate the performance of the proposed analytical model and algorithms. ",
    "url": "https://arxiv.org/abs/2205.13770",
    "authors": [
      "Haoxin Wang",
      "BaekGyu Kim",
      "Jiang Xie",
      "Zhu Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.13780",
    "title": "Text-Based Automatic Personality Prediction Using KGrAt-Net; A Knowledge  Graph Attention Network Classifier",
    "abstract": "Nowadays, a tremendous amount of human communications take place on the Internet-based communication infrastructures, like social networks, email, forums, organizational communication platforms, etc. Indeed, the automatic prediction or assessment of individuals' personalities through their written or exchanged text would be advantageous to ameliorate the relationships among them. To this end, this paper aims to propose KGrAt-Net which is a Knowledge Graph Attention Network text classifier. For the first time, it applies the knowledge graph attention network to perform Automatic Personality Prediction (APP), according to the Big Five personality traits. After performing some preprocessing activities, first, it tries to acquire a knowingful representation of the knowledge behind the concepts in the input text through building its equivalent knowledge graph. A knowledge graph is a graph-based data model that formally represents the semantics of the existing concepts in the input text and models the knowledge behind them. Then, applying the attention mechanism, it efforts to pay attention to the most relevant parts of the graph to predict the personality traits of the input text. The results demonstrated that KGrAt-Net considerably improved the personality prediction accuracies. Furthermore, KGrAt-Net also uses the knowledge graphs' embeddings to enrich the classification, which makes it even more accurate in APP. ",
    "url": "https://arxiv.org/abs/2205.13780",
    "authors": [
      "Majid Ramezani",
      "Mohammad-Reza Feizi-Derakhshi",
      "Mohammad-Ali Balafar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13790",
    "title": "BEVFusion: A Simple and Robust LiDAR-Camera Fusion Framework",
    "abstract": "Fusing the camera and LiDAR information has become a de-facto standard for 3D object detection tasks. Current methods rely on point clouds from the LiDAR sensor as queries to leverage the feature from the image space. However, people discover that this underlying assumption makes the current fusion framework infeasible to produce any prediction when there is a LiDAR malfunction, regardless of minor or major. This fundamentally limits the deployment capability to realistic autonomous driving scenarios. In contrast, we propose a surprisingly simple yet novel fusion framework, dubbed BEVFusion, whose camera stream does not depend on the input of LiDAR data, thus addressing the downside of previous methods. We empirically show that our framework surpasses the state-of-the-art methods under the normal training settings. Under the robustness training settings that simulate various LiDAR malfunctions, our framework significantly surpasses the state-of-the-art methods by 15.7% to 28.9% mAP. To the best of our knowledge, we are the first to handle realistic LiDAR malfunction and can be deployed to realistic scenarios without any post-processing procedure. The code is available at https://github.com/ADLab-AutoDrive/BEVFusion. ",
    "url": "https://arxiv.org/abs/2205.13790",
    "authors": [
      "Tingting Liang",
      "Hongwei Xie",
      "Kaicheng Yu",
      "Zhongyu Xia",
      "Zhiwei Lin",
      "Yongtao Wang",
      "Tao Tang",
      "Bing Wang",
      "Zhi Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13807",
    "title": "fakeWeather: Adversarial Attacks for Deep Neural Networks Emulating  Weather Conditions on the Camera Lens of Autonomous Systems",
    "abstract": "Recently, Deep Neural Networks (DNNs) have achieved remarkable performances in many applications, while several studies have enhanced their vulnerabilities to malicious attacks. In this paper, we emulate the effects of natural weather conditions to introduce plausible perturbations that mislead the DNNs. By observing the effects of such atmospheric perturbations on the camera lenses, we model the patterns to create different masks that fake the effects of rain, snow, and hail. Even though the perturbations introduced by our attacks are visible, their presence remains unnoticed due to their association with natural events, which can be especially catastrophic for fully-autonomous and unmanned vehicles. We test our proposed fakeWeather attacks on multiple Convolutional Neural Network and Capsule Network models, and report noticeable accuracy drops in the presence of such adversarial perturbations. Our work introduces a new security threat for DNNs, which is especially severe for safety-critical applications and autonomous systems. ",
    "url": "https://arxiv.org/abs/2205.13807",
    "authors": [
      "Alberto Marchisio",
      "Giovanni Caramia",
      "Maurizio Martina",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.13808",
    "title": "Hide and Seek -- Preserving Location Privacy and Utility in the Remote  Identification of Unmanned Aerial Vehicles",
    "abstract": "Due to the frequent unauthorized access by commercial drones to Critical Infrastructures (CIs) such as airports and oil refineries, the US-based Federal Avionics Administration (FAA) recently published a new specification, namely RemoteID. The aforementioned rule mandates that all Unmanned Aerial Vehicles (UAVs) have to broadcast information about their identity and location wirelessly to allow for immediate invasion attribution. However, the enforcement of such a rule poses severe concerns on UAV operators, especially in terms of location privacy and tracking threats, to name a few. Indeed, by simply eavesdropping on the wireless channel, an adversary could know the precise location of the UAV and track it, as well as obtaining sensitive information on path source and destination of the UAV. In this paper, we investigate the trade-off between location privacy and data utility that can be provided to UAVs when obfuscating the broadcasted location through differential privacy techniques. Leveraging the concept of Geo-Indistinguishability (Geo-Ind), already adopted in the context of Location-Based Services (LBS), we show that it is possible to enhance the privacy of the UAVs without preventing CI operators to timely detect unauthorized invasions. In particular, our experiments showed that when the location of an UAV is obfuscated with an average distance of 1.959 km, a carefully designed UAV detection system can detect 97.9% of invasions, with an average detection delay of 303.97 msec. The UAVs have to trade-off such enhanced location privacy with a non-negligible probability of false positives, i.e., being detected as invading while not really invading the no-fly zone. UAVs and CI operators can solve such ambiguous situations later on through the help of the FAA, being this latter the only one that can unveil the actual location of the UAV. ",
    "url": "https://arxiv.org/abs/2205.13808",
    "authors": [
      "Alessandro Brighente",
      "Mauro Conti",
      "Savio Sciancalepore"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.13821",
    "title": "A Look at Improving Robustness in Visual-inertial SLAM by Moment  Matching",
    "abstract": "The fusion of camera sensor and inertial data is a leading method for ego-motion tracking in autonomous and smart devices. State estimation techniques that rely on non-linear filtering are a strong paradigm for solving the associated information fusion task. The de facto inference method in this space is the celebrated extended Kalman filter (EKF), which relies on first-order linearizations of both the dynamical and measurement model. This paper takes a critical look at the practical implications and limitations posed by the EKF, especially under faulty visual feature associations and the presence of strong confounding noise. As an alternative, we revisit the assumed density formulation of Bayesian filtering and employ a moment matching (unscented Kalman filtering) approach to both visual-inertial odometry and visual SLAM. Our results highlight important aspects in robustness both in dynamics propagation and visual measurement updates, and we show state-of-the-art results on EuRoC MAV drone data benchmark. ",
    "url": "https://arxiv.org/abs/2205.13821",
    "authors": [
      "Arno Solin",
      "Rui Li",
      "Andrea Pilzer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13836",
    "title": "Feudal Multi-Agent Reinforcement Learning with Adaptive Network  Partition for Traffic Signal Control",
    "abstract": "Multi-agent reinforcement learning (MARL) has been applied and shown great potential in multi-intersections traffic signal control, where multiple agents, one for each intersection, must cooperate together to optimize traffic flow. To encourage global cooperation, previous work partitions the traffic network into several regions and learns policies for agents in a feudal structure. However, static network partition fails to adapt to dynamic traffic flow, which will changes frequently over time. To address this, we propose a novel feudal MARL approach with adaptive network partition. Specifically, we first partition the network into several regions according to the traffic flow. To do this, we propose two approaches: one is directly to use graph neural network (GNN) to generate the network partition, and the other is to use Monte-Carlo tree search (MCTS) to find the best partition with criteria computed by GNN. Then, we design a variant of Qmix using GNN to handle various dimensions of input, given by the dynamic network partition. Finally, we use a feudal hierarchy to manage agents in each partition and promote global cooperation. By doing so, agents are able to adapt to the traffic flow as required in practice. We empirically evaluate our method both in a synthetic traffic grid and real-world traffic networks of three cities, widely used in the literature. Our experimental results confirm that our method can achieve better performance, in terms of average travel time and queue length, than several leading methods for traffic signal control. ",
    "url": "https://arxiv.org/abs/2205.13836",
    "authors": [
      "Jinming Ma",
      "Feng Wu"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13845",
    "title": "Raising the Bar in Graph-level Anomaly Detection",
    "abstract": "Graph-level anomaly detection has become a critical topic in diverse areas, such as financial fraud detection and detecting anomalous activities in social networks. While most research has focused on anomaly detection for visual data such as images, where high detection accuracies have been obtained, existing deep learning approaches for graphs currently show considerably worse performance. This paper raises the bar on graph-level anomaly detection, i.e., the task of detecting abnormal graphs in a set of graphs. By drawing on ideas from self-supervised learning and transformation learning, we present a new deep learning approach that significantly improves existing deep one-class approaches by fixing some of their known problems, including hypersphere collapse and performance flip. Experiments on nine real-world data sets involving nine techniques reveal that our method achieves an average performance improvement of 11.8% AUC compared to the best existing approach. ",
    "url": "https://arxiv.org/abs/2205.13845",
    "authors": [
      "Chen Qiu",
      "Marius Kloft",
      "Stephan Mandt",
      "Maja Rudolph"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13863",
    "title": "Why Robust Generalization in Deep Learning is Difficult: Perspective of  Expressive Power",
    "abstract": "It is well-known that modern neural networks are vulnerable to adversarial examples. To mitigate this problem, a series of robust learning algorithms have been proposed. However, although the robust training error can be near zero via some methods, all existing algorithms lead to a high robust generalization error. In this paper, we provide a theoretical understanding of this puzzling phenomenon from the perspective of expressive power for deep neural networks. Specifically, for binary classification problems with well-separated data, we show that, for ReLU networks, while mild over-parameterization is sufficient for high robust training accuracy, there exists a constant robust generalization gap unless the size of the neural network is exponential in the data dimension $d$. Even if the data is linear separable, which means achieving low clean generalization error is easy, we can still prove an $\\exp({\\Omega}(d))$ lower bound for robust generalization. Moreover, we establish an improved upper bound of $\\exp({\\mathcal{O}}(k))$ for the network size to achieve low robust generalization error when the data lies on a manifold with intrinsic dimension $k$ ($k \\ll d$). Nonetheless, we also have a lower bound that grows exponentially with respect to $k$ -- the curse of dimensionality is inevitable. By demonstrating an exponential separation between the network size for achieving low robust training and generalization error, our results reveal that the hardness of robust generalization may stem from the expressive power of practical models. ",
    "url": "https://arxiv.org/abs/2205.13863",
    "authors": [
      "Binghui Li",
      "Jikai Jin",
      "Han Zhong",
      "John E. Hopcroft",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.13866",
    "title": "Task Offloading with Multi-Tier Computing Resources in Next Generation  Wireless Networks",
    "abstract": "With the development of next-generation wireless networks, the Internet of Things (IoT) is evolving towards the intelligent IoT (iIoT), where intelligent applications usually have stringent delay and jitter requirements. In order to provide low-latency services to heterogeneous users in the emerging iIoT, multi-tier computing was proposed by effectively combining edge computing and fog computing. More specifically, multi-tier computing systems compensate for cloud computing through task offloading and dispersing computing tasks to multi-tier nodes along the continuum from the cloud to things. In this paper, we investigate key techniques and directions for wireless communications and resource allocation approaches to enable task offloading in multi-tier computing systems. A multi-tier computing model, with its main functionality and optimization methods, is presented in details. We hope that this paper will serve as a valuable reference and guide to the theoretical, algorithmic, and systematic opportunities of multi-tier computing towards next-generation wireless networks. ",
    "url": "https://arxiv.org/abs/2205.13866",
    "authors": [
      "Kunlun Wang",
      "Jiong Jin",
      "Yang Yang",
      "Tao Zhang",
      "Arumugam Nallanathan",
      "Chintha Tellambura",
      "Bijan Jabbari"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.13869",
    "title": "MissDAG: Causal Discovery in the Presence of Missing Data with  Continuous Additive Noise Models",
    "abstract": "State-of-the-art causal discovery methods usually assume that the observational data is complete. However, the missing data problem is pervasive in many practical scenarios such as clinical trials, economics, and biology. One straightforward way to address the missing data problem is first to impute the data using off-the-shelf imputation methods and then apply existing causal discovery methods. However, such a two-step method may suffer from suboptimality, as the imputation algorithm is unaware of the causal discovery step. In this paper, we develop a general method, which we call MissDAG, to perform causal discovery from data with incomplete observations. Focusing mainly on the assumptions of ignorable missingness and the identifiable additive noise models (ANMs), MissDAG maximizes the expected likelihood of the visible part of observations under the expectation-maximization (EM) framework. In the E-step, in cases where computing the posterior distributions of parameters in closed-form is not feasible, Monte Carlo EM is leveraged to approximate the likelihood. In the M-step, MissDAG leverages the density transformation to model the noise distributions with simpler and specific formulations by virtue of the ANMs and uses a likelihood-based causal discovery algorithm with directed acyclic graph prior as an inductive bias. We demonstrate the flexibility of MissDAG for incorporating various causal discovery algorithms and its efficacy through extensive simulations and real data experiments. ",
    "url": "https://arxiv.org/abs/2205.13869",
    "authors": [
      "Erdun Gao",
      "Ignavier Ng",
      "Mingming Gong",
      "Li Shen",
      "Wei Huang",
      "Tongliang Liu",
      "Kun Zhang",
      "Howard Bondell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.13883",
    "title": "Efficient Semantic Summary Graphs for Querying Large Knowledge Graphs",
    "abstract": "Knowledge Graphs (KGs) integrate heterogeneous data, but one challenge is the development of efficient tools for allowing end users to extract useful insights from these sources of knowledge. In such a context, reducing the size of a Resource Description Framework (RDF) graph while preserving all information can speed up query engines by limiting data shuffle, especially in a distributed setting. This paper presents two algorithms for RDF graph summarization: Grouping Based Summarization (GBS) and Query Based Summarization (QBS). The latter is an optimized and lossless approach for the former method. We empirically study the effectiveness of the proposed lossless RDF graph summarization to retrieve complete data, by rewriting an RDF Query Language called SPARQL query with fewer triple patterns using a semantic similarity. We conduct our experimental study in instances of four datasets with different sizes. Compared with the state-of-the-art query engine Sparklify executed over the original RDF graphs as a baseline, QBS query execution time is reduced by up to 80% and the summarized RDF graph is decreased by up to 99%. ",
    "url": "https://arxiv.org/abs/2205.13883",
    "authors": [
      "Emetis Niazmand",
      "Gezim Sejdiu",
      "Damien Graux",
      "Maria-Esther Vidal"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2205.13892",
    "title": "EvenNet: Ignoring Odd-Hop Neighbors Improves Robustness of Graph Neural  Networks",
    "abstract": "Graph Neural Networks (GNNs) have received extensive research attention for their promising performance in graph machine learning. Despite their extraordinary predictive accuracy, existing approaches, such as GCN and GPRGNN, are not robust in the face of homophily changes on test graphs, rendering these models vulnerable to graph structural attacks and with limited capacity in generalizing to graphs of varied homophily levels. Although many methods have been proposed to improve the robustness of GNN models, most of these techniques are restricted to the spatial domain and employ complicated defense mechanisms, such as learning new graph structures or calculating edge attentions. In this paper, we study the problem of designing simple and robust GNN models in the spectral domain. We propose EvenNet, a spectral GNN corresponding to an even-polynomial graph filter. Based on our theoretical analysis in both spatial and spectral domains, we demonstrate that EvenNet outperforms full-order models in generalizing across homophilic and heterophilic graphs, implying that ignoring odd-hop neighbors improves the robustness of GNNs. We conduct experiments on both synthetic and real-world datasets to demonstrate the effectiveness of EvenNet. Notably, EvenNet outperforms existing defense models against structural attacks without introducing additional computational costs and maintains competitiveness in traditional node classification tasks on homophilic and heterophilic graphs. ",
    "url": "https://arxiv.org/abs/2205.13892",
    "authors": [
      "Runlin Lei",
      "Zhen Wang",
      "Yaliang Li",
      "Bolin Ding",
      "Zhewei Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13900",
    "title": "How Tempering Fixes Data Augmentation in Bayesian Neural Networks",
    "abstract": "While Bayesian neural networks (BNNs) provide a sound and principled alternative to standard neural networks, an artificial sharpening of the posterior usually needs to be applied to reach comparable performance. This is in stark contrast to theory, dictating that given an adequate prior and a well-specified model, the untempered Bayesian posterior should achieve optimal performance. Despite the community's extensive efforts, the observed gains in performance still remain disputed with several plausible causes pointing at its origin. While data augmentation has been empirically recognized as one of the main drivers of this effect, a theoretical account of its role, on the other hand, is largely missing. In this work we identify two interlaced factors concurrently influencing the strength of the cold posterior effect, namely the correlated nature of augmentations and the degree of invariance of the employed model to such transformations. By theoretically analyzing simplified settings, we prove that tempering implicitly reduces the misspecification arising from modeling augmentations as i.i.d. data. The temperature mimics the role of the effective sample size, reflecting the gain in information provided by the augmentations. We corroborate our theoretical findings with extensive empirical evaluations, scaling to realistic BNNs. By relying on the framework of group convolutions, we experiment with models of varying inherent degree of invariance, confirming its hypothesized relationship with the optimal temperature. ",
    "url": "https://arxiv.org/abs/2205.13900",
    "authors": [
      "Gregor Bachmann",
      "Lorenzo Noci",
      "Thomas Hofmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.13901",
    "title": "Bias Reduction via Cooperative Bargaining in Synthetic Graph Dataset  Generation",
    "abstract": "In general, to draw robust conclusions from a dataset, all the analyzed population must be represented on said dataset. Having a dataset that does not fulfill this condition normally leads to selection bias. Additionally, graphs have been used to model a wide variety of problems. Although synthetic graphs can be used to augment available real graph datasets to overcome selection bias, the generation of unbiased synthetic datasets is complex with current tools. In this work, we propose a method to find a synthetic graph dataset that has an even representation of graphs with different metrics. The resulting dataset can then be used, among others, for benchmarking graph processing techniques as the accuracy of different Graph Neural Network (GNN) models or the speedups obtained by different graph processing acceleration frameworks. ",
    "url": "https://arxiv.org/abs/2205.13901",
    "authors": [
      "Axel Wassington",
      "Sergi Abadal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13904",
    "title": "Secrecy Capacity Maximization for a Hybrid Relay-RIS Scheme in mmWave  MIMO Networks",
    "abstract": "The hybrid relay-reflecting intelligent surface (HR-RIS) has been recently introduced as an efficient solution to overcome the double path loss and limited beamforming diversity of the conventional fully passive reflecting surface. This motivates us to investigate the application of the HR-RIS in improving the secrecy capacity of millimeter wave multiple-input-multiple-output (MIMO) systems with the presence of multi-antenna eavesdropper. The joint optimization of the transmit beamformer and the relay-reflecting coefficients at RIS is tackled via alternating optimization. In the proposed solution, a closed-form expression for the optimal transmit beamformer at the transmitter is derived, and a metaheuristic solution based on particle swarm optimization is proposed to optimize the active and passive elements at the HR-RIS. The simulation results verify that under various scenarios, the HR-RIS provides significant improvement in the secrecy capacity with respect to the conventional passive reflecting surface. ",
    "url": "https://arxiv.org/abs/2205.13904",
    "authors": [
      "Edson Nobuyuki Egashira",
      "Diana Pamela Moya Osorio",
      "Nhan Thanh Nguyen",
      "Markku Juntti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2205.13919",
    "title": "Fast Causal Orientation Learning in Directed Acyclic Graphs",
    "abstract": "Causal relationships among a set of variables are commonly represented by a directed acyclic graph. The orientations of some edges in the causal DAG can be discovered from observational/interventional data. Further edges can be oriented by iteratively applying so-called Meek rules. Inferring edges' orientations from some previously oriented edges, which we call Causal Orientation Learning (COL), is a common problem in various causal discovery tasks. In these tasks, it is often required to solve multiple COL problems and therefore applying Meek rules could be time-consuming. Motivated by Meek rules, we introduce Meek functions that can be utilized in solving COL problems. In particular, we show that these functions have some desirable properties, enabling us to speed up the process of applying Meek rules. In particular, we propose a dynamic programming (DP) based method to apply Meek functions. Moreover, based on the proposed DP method, we present a lower bound on the number of edges that can be oriented as a result of intervention. We also propose a method to check whether some oriented edges belong to a causal DAG. Experimental results show that the proposed methods can outperform previous work in several causal discovery tasks in terms of running-time. ",
    "url": "https://arxiv.org/abs/2205.13919",
    "authors": [
      "Ramin Safaeian",
      "Saber Salehkaleybar",
      "Mahmoud Tabandeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2205.13933",
    "title": "Standalone Neural ODEs with Sensitivity Analysis",
    "abstract": "This paper presents the Standalone Neural ODE (sNODE), a continuous-depth neural ODE model capable of describing a full deep neural network. This uses a novel nonlinear conjugate gradient (NCG) descent optimization scheme for training, where the Sobolev gradient can be incorporated to improve smoothness of model weights. We also present a general formulation of the neural sensitivity problem and show how it is used in the NCG training. The sensitivity analysis provides a reliable measure of uncertainty propagation throughout a network, and can be used to study model robustness and to generate adversarial attacks. Our evaluations demonstrate that our novel formulations lead to increased robustness and performance as compared to ResNet models, and that it opens up for new opportunities for designing and developing machine learning with improved explainability. ",
    "url": "https://arxiv.org/abs/2205.13933",
    "authors": [
      "Rym Jaroudi",
      "Luk\u00e1\u0161 Mal\u00fd",
      "Gabriel Eilertsen",
      "Tomas B. Johansson",
      "Jonas Unger",
      "George Baravdish"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2205.13941",
    "title": "Auditing Differential Privacy in High Dimensions with the Kernel Quantum  R\u00e9nyi Divergence",
    "abstract": "Differential privacy (DP) is the de facto standard for private data release and private machine learning. Auditing black-box DP algorithms and mechanisms to certify whether they satisfy a certain DP guarantee is challenging, especially in high dimension. We propose relaxations of differential privacy based on new divergences on probability distributions: the kernel R\\'enyi divergence and its regularized version. We show that the regularized kernel R\\'enyi divergence can be estimated from samples even in high dimensions, giving rise to auditing procedures for $\\varepsilon$-DP, $(\\varepsilon,\\delta)$-DP and $(\\alpha,\\varepsilon)$-R\\'enyi DP. ",
    "url": "https://arxiv.org/abs/2205.13941",
    "authors": [
      "Carles Domingo-Enrich",
      "Youssef Mroueh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.13947",
    "title": "Spatio-Temporal Graph Few-Shot Learning with Cross-City Knowledge  Transfer",
    "abstract": "Spatio-temporal graph learning is a key method for urban computing tasks, such as traffic flow, taxi demand and air quality forecasting. Due to the high cost of data collection, some developing cities have few available data, which makes it infeasible to train a well-performed model. To address this challenge, cross-city knowledge transfer has shown its promise, where the model learned from data-sufficient cities is leveraged to benefit the learning process of data-scarce cities. However, the spatio-temporal graphs among different cities show irregular structures and varied features, which limits the feasibility of existing Few-Shot Learning (\\emph{FSL}) methods. Therefore, we propose a model-agnostic few-shot learning framework for spatio-temporal graph called ST-GFSL. Specifically, to enhance feature extraction by transfering cross-city knowledge, ST-GFSL proposes to generate non-shared parameters based on node-level meta knowledge. The nodes in target city transfer the knowledge via parameter matching, retrieving from similar spatio-temporal characteristics. Furthermore, we propose to reconstruct the graph structure during meta-learning. The graph reconstruction loss is defined to guide structure-aware learning, avoiding structure deviation among different datasets. We conduct comprehensive experiments on four traffic speed prediction benchmarks and the results demonstrate the effectiveness of ST-GFSL compared with state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2205.13947",
    "authors": [
      "Bin Lu",
      "Xiaoying Gan",
      "Weinan Zhang",
      "Huaxiu Yao",
      "Luoyi Fu",
      "Xinbing Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13954",
    "title": "Geometer: Graph Few-Shot Class-Incremental Learning via Prototype  Representation",
    "abstract": "With the tremendous expansion of graphs data, node classification shows its great importance in many real-world applications. Existing graph neural network based methods mainly focus on classifying unlabeled nodes within fixed classes with abundant labeling. However, in many practical scenarios, graph evolves with emergence of new nodes and edges. Novel classes appear incrementally along with few labeling due to its newly emergence or lack of exploration. In this paper, we focus on this challenging but practical graph few-shot class-incremental learning (GFSCIL) problem and propose a novel method called Geometer. Instead of replacing and retraining the fully connected neural network classifer, Geometer predicts the label of a node by finding the nearest class prototype. Prototype is a vector representing a class in the metric space. With the pop-up of novel classes, Geometer learns and adjusts the attention-based prototypes by observing the geometric proximity, uniformity and separability. Teacher-student knowledge distillation and biased sampling are further introduced to mitigate catastrophic forgetting and unbalanced labeling problem respectively. Experimental results on four public datasets demonstrate that Geometer achieves a substantial improvement of 9.46% to 27.60% over state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2205.13954",
    "authors": [
      "Bin Lu",
      "Xiaoying Gan",
      "Lina Yang",
      "Weinan Zhang",
      "Luoyi Fu",
      "Xinbing Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13957",
    "title": "Cycle Label-Consistent Networks for Unsupervised Domain Adaptation",
    "abstract": "Domain adaptation aims to leverage a labeled source domain to learn a classifier for the unlabeled target domain with a different distribution. Previous methods mostly match the distribution between two domains by global or class alignment. However, global alignment methods cannot achieve a fine-grained class-to-class overlap; class alignment methods supervised by pseudo-labels cannot guarantee their reliability. In this paper, we propose a simple yet efficient domain adaptation method, i.e. Cycle Label-Consistent Network (CLCN), by exploiting the cycle consistency of classification label, which applies dual cross-domain nearest centroid classification procedures to generate a reliable self-supervised signal for the discrimination in the target domain. The cycle label-consistent loss reinforces the consistency between ground-truth labels and pseudo-labels of source samples leading to statistically similar latent representations between source and target domains. This new loss can easily be added to any existing classification network with almost no computational overhead. We demonstrate the effectiveness of our approach on MNIST-USPS-SVHN, Office-31, Office-Home and Image CLEF-DA benchmarks. Results validate that the proposed method can alleviate the negative influence of falsely-labeled samples and learn more discriminative features, leading to the absolute improvement over source-only model by 9.4% on Office-31 and 6.3% on Image CLEF-DA. ",
    "url": "https://arxiv.org/abs/2205.13957",
    "authors": [
      "Mei Wang",
      "Weihong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13958",
    "title": "Machine Learning-Based User Scheduling in Integrated  Satellite-HAPS-Ground Networks",
    "abstract": "Integrated space-air-ground networks promise to offer a valuable solution space for empowering next generation of communication networks (6G), particularly in the context of connecting the unconnected and ultraconnecting the connected. Such digital inclusion thrive makes the resource management problem of particular interest. However, the classical model-based optimization methods cannot meet the real-time processing and user's QoS needs, due to the high heterogeneity of the space-air-ground networks and the complexity of its associated resource allocation problems. Given the premises of artificial intelligence at automating wireless networks design, this paper focuses on showcasing the prospects of machine learning in the context of user scheduling in integrated space-air-ground communications. The paper first overviews the most relevant state-of-the art in the context of machine learning applications to the resource allocation problems in integrated space-air-ground networks. The paper then proposes, and shows the benefit of, one specific use-case that adopts ensembling deep neural network for optimizing the user scheduling policies in space-high altitude platform station (HAPS)-ground networks. Finally, the paper presents some challenges and sheds light on several open issues in the context of machine learning applications in space-air-ground networks, namely, power limit, imperfect channel state information, multi-HAPSs scenarios and flying taxis-empowered systems. ",
    "url": "https://arxiv.org/abs/2205.13958",
    "authors": [
      "Shasha Liu",
      "Hayssam Dahrouj",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13959",
    "title": "Robust Stutter Bisimulation for Abstraction and Controller Synthesis  with Disturbance: Proofs",
    "abstract": "This paper proposes a method to synthesise controllers for cyber-physical systems such that the controlled systems satisfy specifications given as linear temporal logic formulas. The focus is on systems with disturbance, where future states cannot be predicted exactly due to uncertainty in the environment. The approach used to solve this problem is to first construct a finite-state abstraction of the original system and then synthesise a controller for the abstract system. For this approach, the robust stutter bisimulation relation is introduced, which preserves the existence of controllers for any given linear temporal logic formula. States are related by the robust stutter bisimulation relation if the same target sets can be guaranteed to be reached or avoided under control of some controllers, thereby ensuring that disturbances have similar effect on paths that start in related states. This paper presents an algorithm to construct the corresponding robust stutter bisimulation quotient to solve the abstraction problem, and it is shown, by explicit construction, that there exists a controller enforcing a linear temporal logic formula for the original system if and only if a corresponding controller exists for the quotient system. Lastly, the result of the algorithm and the controller construction are demonstrated by application to an example of robot navigation. ",
    "url": "https://arxiv.org/abs/2205.13959",
    "authors": [
      "Jonas Krook",
      "Robi Malik",
      "Sahar Mohajerani",
      "Martin Fabian"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.13972",
    "title": "Counterfactual Fairness with Partially Known Causal Graph",
    "abstract": "Fair machine learning aims to avoid treating individuals or sub-populations unfavourably based on \\textit{sensitive attributes}, such as gender and race. Those methods in fair machine learning that are built on causal inference ascertain discrimination and bias through causal effects. Though causality-based fair learning is attracting increasing attention, current methods assume the true causal graph is fully known. This paper proposes a general method to achieve the notion of counterfactual fairness when the true causal graph is unknown. To be able to select features that lead to counterfactual fairness, we derive the conditions and algorithms to identify ancestral relations between variables on a \\textit{Partially Directed Acyclic Graph (PDAG)}, specifically, a class of causal DAGs that can be learned from observational data combined with domain knowledge. Interestingly, we find that counterfactual fairness can be achieved as if the true causal graph were fully known, when specific background knowledge is provided: the sensitive attributes do not have ancestors in the causal graph. Results on both simulated and real-world datasets demonstrate the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2205.13972",
    "authors": [
      "Aoqi Zuo",
      "Susan Wei",
      "Tongliang Liu",
      "Bo Han",
      "Kun Zhang",
      "Mingming Gong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13977",
    "title": "Robust Distributed Control within a Curve Virtual Tube for a Robotic  Swarm under Self-Localization Drift and Precise Relative Navigation",
    "abstract": "To guide the movement of a robotic swarm in a corridor-like environment, a curve virtual tube with no obstacle inside is designed in our previous work. This paper generalizes the controller design to the condition that all robots have self-localization drifts and precise relative navigation, where the flocking algorithm is introduced to reduce the negative impact of the self-localization drift. It is shown that the cohesion behavior and the velocity alignment behavior are able to reduce the influence of the position measurement drift and the velocity measurement error, respectively. For the convenience in practical use, a modified vector field controller with five control terms is put forward. Finally, the effectiveness of the proposed method is validated by numerical simulations and real experiments. ",
    "url": "https://arxiv.org/abs/2205.13977",
    "authors": [
      "Yan Gao",
      "Chenggang Bai",
      "Quan Quan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.13980",
    "title": "The Structure of Online Social Networks Mirror Those in the Offline  World",
    "abstract": "We use data on frequencies of bi-directional posts to define edges (or relationships) in two Facebook datasets and a Twitter dataset and use these to create ego-centric social networks. We explore the internal structure of these networks to determine whether they have the same kind of layered structure as has been found in offline face-to-face networks (which have a distinctively scaled structure with successively inclusive layers at 5, 15, 50 and 150 alters). The two Facebook datasets are best described by a four-layer structure and the Twitter dataset by a five-layer structure. The absolute sizes of these layers and the mean frequencies of contact with alters within each layer match very closely the observed values from offline networks. In addition, all three datasets reveal the existence of an innermost network layer at ~1.5 alters. Our analyses thus confirm the existence of the layered structure of ego-centric social networks with a very much larger sample (in total, >185,000 egos) than those previously used to describe them, as well as identifying the existence of an additional network layer whose existence was only hypothesised in offline social networks. In addition, our analyses indicate that online communities have very similar structural characteristics to offline face-to-face networks. ",
    "url": "https://arxiv.org/abs/2205.13980",
    "authors": [
      "R.I.M. Dunbar",
      "Valerio Arnaboldi",
      "Marco Conti",
      "Andrea Passarella"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.13988",
    "title": "Deep Ensembles for Graphs with Higher-order Dependencies",
    "abstract": "Graph neural networks (GNNs) continue to achieve state-of-the-art performance on many graph learning tasks, but rely on the assumption that a given graph is a sufficient approximation of the true neighborhood structure. In the presence of higher-order sequential dependencies, we show that the tendency of traditional graph representations to underfit each node's neighborhood causes existing GNNs to generalize poorly. To address this, we propose a novel Deep Graph Ensemble (DGE), which captures neighborhood variance by training an ensemble of GNNs on different neighborhood subspaces of the same node within a higher-order network structure. We show that DGE consistently outperforms existing GNNs on semisupervised and supervised tasks on four real-world data sets with known higher-order dependencies, even under a similar parameter budget. We demonstrate that learning diverse and accurate base classifiers is central to DGE's success, and discuss the implications of these findings for future work on GNNs. ",
    "url": "https://arxiv.org/abs/2205.13988",
    "authors": [
      "Steven J. Krieg",
      "William C. Burgis",
      "Patrick M. Soga",
      "Nitesh V. Chawla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13994",
    "title": "A framework for robotic arm pose estimation and movement prediction  based on deep and extreme learning models",
    "abstract": "Human-robot collaboration has gained a notable prominence in Industry 4.0, as the use of collaborative robots increases efficiency and productivity in the automation process. However, it is necessary to consider the use of mechanisms that increase security in these environments, as the literature reports that risk situations may exist in the context of human-robot collaboration. One of the strategies that can be adopted is the visual recognition of the collaboration environment using machine learning techniques, which can automatically identify what is happening in the scene and what may happen in the future. In this work, we are proposing a new framework that is capable of detecting robotic arm keypoints commonly used in Industry 4.0. In addition to detecting, the proposed framework is able to predict the future movement of these robotic arms, thus providing relevant information that can be considered in the recognition of the human-robot collaboration scenario. The proposed framework is based on deep and extreme learning machine techniques. Results show that the proposed framework is capable of detecting and predicting with low error, contributing to the mitigation of risks in human-robot collaboration. ",
    "url": "https://arxiv.org/abs/2205.13994",
    "authors": [
      "Iago Richard Rodrigues",
      "Marrone Dantas",
      "Assis Oliveira Filho",
      "Gibson Barbosa",
      "Daniel Bezerra",
      "Ricardo Souza",
      "Maria Val\u00e9ria Marquezini",
      "Patricia Takako Endo",
      "Judith Kelner",
      "Djamel H. Sadok"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.14005",
    "title": "RecipeRec: A Heterogeneous Graph Learning Model for Recipe  Recommendation",
    "abstract": "Recipe recommendation systems play an essential role in helping people decide what to eat. Existing recipe recommendation systems typically focused on content-based or collaborative filtering approaches, ignoring the higher-order collaborative signal such as relational structure information among users, recipes and food items. In this paper, we formalize the problem of recipe recommendation with graphs to incorporate the collaborative signal into recipe recommendation through graph modeling. In particular, we first present URI-Graph, a new and large-scale user-recipe-ingredient graph. We then propose RecipeRec, a novel heterogeneous graph learning model for recipe recommendation. The proposed model can capture recipe content and collaborative signal through a heterogeneous graph neural network with hierarchical attention and an ingredient set transformer. We also introduce a graph contrastive augmentation strategy to extract informative graph knowledge in a self-supervised manner. Finally, we design a joint objective function of recommendation and contrastive learning to optimize the model. Extensive experiments demonstrate that RecipeRec outperforms state-of-the-art methods for recipe recommendation. Dataset and codes are available at https://github.com/meettyj/RecipeRec. ",
    "url": "https://arxiv.org/abs/2205.14005",
    "authors": [
      "Yijun Tian",
      "Chuxu Zhang",
      "Zhichun Guo",
      "Chao Huang",
      "Ronald Metoyer",
      "Nitesh V. Chawla"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14014",
    "title": "What Dense Graph Do You Need for Self-Attention?",
    "abstract": "Transformers have made progress in miscellaneous tasks, but suffer from quadratic computational and memory complexities. Recent works propose sparse Transformers with attention on sparse graphs to reduce complexity and remain strong performance. While effective, the crucial parts of how dense a graph needs to be to perform well are not fully explored. In this paper, we propose Normalized Information Payload (NIP), a graph scoring function measuring information transfer on graph, which provides an analysis tool for trade-offs between performance and complexity. Guided by this theoretical analysis, we present Hypercube Transformer, a sparse Transformer that models token interactions in a hypercube and shows comparable or even better results with vanilla Transformer while yielding $O(N\\log N)$ complexity with sequence length $N$. Experiments on tasks requiring various sequence lengths lay validation for our graph function well. ",
    "url": "https://arxiv.org/abs/2205.14014",
    "authors": [
      "Yuxing Wang",
      "Chu-Tak Lee",
      "Qipeng Guo",
      "Zhangyue Yin",
      "Yunhua Zhou",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.14036",
    "title": "StereoKG: Data-Driven Knowledge Graph Construction for Cultural  Knowledge and Stereotypes",
    "abstract": "Analyzing ethnic or religious bias is important for improving fairness, accountability, and transparency of natural language processing models. However, many techniques rely on human-compiled lists of bias terms, which are expensive to create and are limited in coverage. In this study, we present a fully data-driven pipeline for generating a knowledge graph (KG) of cultural knowledge and stereotypes. Our resulting KG covers 5 religious groups and 5 nationalities and can easily be extended to include more entities. Our human evaluation shows that the majority (59.2%) of non-singleton entries are coherent and complete stereotypes. We further show that performing intermediate masked language model training on the verbalized KG leads to a higher level of cultural awareness in the model and has the potential to increase classification performance on knowledge-crucial samples on a related task, i.e., hate speech detection. ",
    "url": "https://arxiv.org/abs/2205.14036",
    "authors": [
      "Awantee Deshpande",
      "Dana Ruiter",
      "Marius Mosbach",
      "Dietrich Klakow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.14041",
    "title": "Double Deep Q Networks for Sensor Management in Space Situational  Awareness",
    "abstract": "We present a novel Double Deep Q Network (DDQN) application to a sensor management problem in space situational awareness (SSA). Frequent launches of satellites into Earth orbit pose a significant sensor management challenge, whereby a limited number of sensors are required to detect and track an increasing number of objects. In this paper, we demonstrate the use of reinforcement learning to develop a sensor management policy for SSA. We simulate a controllable Earth-based telescope, which is trained to maximise the number of satellites tracked using an extended Kalman filter. The estimated state covariance matrices for satellites observed under the DDQN policy are greatly reduced compared to those generated by an alternate (random) policy. This work provides the basis for further advancements and motivates the use of reinforcement learning for SSA. ",
    "url": "https://arxiv.org/abs/2205.14041",
    "authors": [
      "Benedict Oakes",
      "Dominic Richards",
      "Jordi Barr",
      "Jason F. Ralph"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14054",
    "title": "Contrastive Siamese Network for Semi-supervised Speech Recognition",
    "abstract": "This paper introduces contrastive siamese (c-siam) network, an architecture for leveraging unlabeled acoustic data in speech recognition. c-siam is the first network that extracts high-level linguistic information from speech by matching outputs of two identical transformer encoders. It contains augmented and target branches which are trained by: (1) masking inputs and matching outputs with a contrastive loss, (2) incorporating a stop gradient operation on the target branch, (3) using an extra learnable transformation on the augmented branch, (4) introducing new temporal augment functions to prevent the shortcut learning problem. We use the Libri-light 60k unsupervised data and the LibriSpeech 100hrs/960hrs supervised data to compare c-siam and other best-performing systems. Our experiments show that c-siam provides 20% relative word error rate improvement over wav2vec baselines. A c-siam network with 450M parameters achieves competitive results compared to the state-of-the-art networks with 600M parameters. ",
    "url": "https://arxiv.org/abs/2205.14054",
    "authors": [
      "Soheil Khorram",
      "Jaeyoung Kim",
      "Anshuman Tripathi",
      "Han Lu",
      "Qian Zhang",
      "Hasim Sak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14056",
    "title": "Dual Convexified Convolutional Neural Networks",
    "abstract": "We propose the framework of dual convexified convolutional neural networks (DCCNNs). In this framework, we first introduce a primal learning problem motivated from convexified convolutional neural networks (CCNNs), and then construct the dual convex training program through careful analysis of the Karush-Kuhn-Tucker (KKT) conditions and Fenchel conjugates. Our approach reduces the memory overhead of constructing a large kernel matrix and eliminates the ambiguity of factorizing the matrix. Due to the low-rank structure in CCNNs and the related subdifferential of nuclear norms, there is no closed-form expression to recover the primal solution from the dual solution. To overcome this, we propose a highly novel weight recovery algorithm, which takes the dual solution and the kernel information as the input, and recovers the linear and convolutional weights of a CCNN. Furthermore, our recovery algorithm exploits the low-rank structure and imposes a small number of filters indirectly, which reduces the parameter size. As a result, DCCNNs inherit all the statistical benefits of CCNNs, while enjoying a more formal and efficient workflow. ",
    "url": "https://arxiv.org/abs/2205.14056",
    "authors": [
      "Site Bai",
      "Chuyang Ke",
      "Jean Honorio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.14065",
    "title": "Simple Unsupervised Object-Centric Learning for Complex and Naturalistic  Videos",
    "abstract": "Unsupervised object-centric learning aims to represent the modular, compositional, and causal structure of a scene as a set of object representations and thereby promises to resolve many critical limitations of traditional single-vector representations such as poor systematic generalization. Although there have been many remarkable advances in recent years, one of the most critical problems in this direction has been that previous methods work only with simple and synthetic scenes but not with complex and naturalistic images or videos. In this paper, we propose STEVE, an unsupervised model for object-centric learning in videos. Our proposed model makes a significant advancement by demonstrating its effectiveness on various complex and naturalistic videos unprecedented in this line of research. Interestingly, this is achieved by neither adding complexity to the model architecture nor introducing a new objective or weak supervision. Rather, it is achieved by a surprisingly simple architecture that uses a transformer-based image decoder conditioned on slots and the learning objective is simply to reconstruct the observation. Our experiment results on various complex and naturalistic videos show significant improvements compared to the previous state-of-the-art. ",
    "url": "https://arxiv.org/abs/2205.14065",
    "authors": [
      "Gautam Singh",
      "Yi-Fu Wu",
      "Sungjin Ahn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14079",
    "title": "Haptic Shared Control Improves Neural Efficiency During Myoelectric  Prosthesis Use",
    "abstract": "Clinical myoelectric prostheses lack the sensory feedback and sufficient dexterity required to complete activities of daily living efficiently and accurately. Providing haptic feedback of relevant environmental cues to the user or imbuing the prosthesis with autonomous control authority have been separately shown to improve prosthesis utility. Few studies, however, have investigated the effect of combining these two approaches in a shared control paradigm, and none have evaluated such an approach from the perspective of neural efficiency (the relationship between task performance and mental effort measured directly from the brain). In this work, we analyzed the neural efficiency of 30 non-amputee participants in a grasp-and-lift task of a brittle object. Here, a myoelectric prosthesis featuring vibrotactile feedback of grip force and autonomous control of grasping was compared with a standard myoelectric prosthesis with and without vibrotactile feedback. As a measure of mental effort, we captured the prefrontal cortex activity changes using functional near infrared spectroscopy during the experiment. Results showed that only the haptic shared control system enabled users to achieve high neural efficiency, and that vibrotactile feedback was important for grasping with the appropriate grip force. These results indicate that the haptic shared control system synergistically combines the benefits of haptic feedback and autonomous controllers, and is well-poised to inform such hybrid advancements in myoelectric prosthesis technology. ",
    "url": "https://arxiv.org/abs/2205.14079",
    "authors": [
      "Neha Thomas",
      "Alexandra J. Miller",
      "Hasan Ayaz",
      "Jeremy D. Brown"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.14084",
    "title": "UAlberta at SemEval 2022 Task 2: Leveraging Glosses and Translations for  Multilingual Idiomaticity Detection",
    "abstract": "We describe the University of Alberta systems for the SemEval-2022 Task 2 on multilingual idiomaticity detection. Working under the assumption that idiomatic expressions are noncompositional, our first method integrates information on the meanings of the individual words of an expression into a binary classifier. Further hypothesizing that literal and idiomatic expressions translate differently, our second method translates an expression in context, and uses a lexical knowledge base to determine if the translation is literal. Our approaches are grounded in linguistic phenomena, and leverage existing sources of lexical knowledge. Our results offer support for both approaches, particularly the former. ",
    "url": "https://arxiv.org/abs/2205.14084",
    "authors": [
      "Bradley Hauer",
      "Seeratpal Jaura",
      "Talgat Omarov",
      "Grzegorz Kondrak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.14091",
    "title": "Measuring Equality and Hierarchical Mobility on Abstract Complex  Networks",
    "abstract": "The centrality of a node within a network, however it is measured, is a vital proxy for the importance or influence of that node, and the differences in node centrality generate hierarchies and inequalities. If the network is evolving in time, the influence of each node changes in time as well, and the corresponding hierarchies are modified accordingly. However, there is still a lack of systematic study into the ways in which the centrality of a node evolves when a graph changes. In this paper we introduce a taxonomy of metrics of equality and hierarchical mobility in networks that evolve in time. We propose an indicator of equality based on the classical Gini Coefficient from economics, and we quantify the hierarchical mobility of nodes, that is, how and to what extent the centrality of a node and its neighbourhood change over time. These measures are applied to a corpus of thirty time evolving network data sets from different domains. We show that the proposed taxonomy measures can discriminate between networks from different fields. We also investigate correlations between different taxonomy measures, and demonstrate that some of them have consistently strong correlations (or anti-correlations) across the entire corpus. The mobility and equality measures developed here constitute a useful toolbox for investigating the nature of network evolution, and also for discriminating between different artificial models hypothesised to explain that evolution. ",
    "url": "https://arxiv.org/abs/2205.14091",
    "authors": [
      "Matthew Russell Barnes",
      "Vincenzo Nicosia",
      "Richard G. Clegg"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2205.14092",
    "title": "Capturing Graphs with Hypo-Elliptic Diffusions",
    "abstract": "Convolutional layers within graph neural networks operate by aggregating information about local neighbourhood structures; one common way to encode such substructures is through random walks. The distribution of these random walks evolves according to a diffusion equation defined using the graph Laplacian. We extend this approach by leveraging classic mathematical results about hypo-elliptic diffusions. This results in a novel tensor-valued graph operator, which we call the hypo-elliptic graph Laplacian. We provide theoretical guarantees and efficient low-rank approximation algorithms. In particular, this gives a structured approach to capture long-range dependencies on graphs that is robust to pooling. Besides the attractive theoretical properties, our experiments show that this method competes with graph transformers on datasets requiring long-range reasoning but scales only linearly in the number of edges as opposed to quadratically in nodes. ",
    "url": "https://arxiv.org/abs/2205.14092",
    "authors": [
      "Csaba Toth",
      "Darrick Lee",
      "Celia Hacker",
      "Harald Oberhauser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2205.14094",
    "title": "Failure Detection in Medical Image Classification: A Reality Check and  Benchmarking Testbed",
    "abstract": "Failure detection in automated image classification is a critical safeguard for clinical deployment. Detected failure cases can be referred to human assessment, ensuring patient safety in computer-aided clinical decision making. Despite its paramount importance, there is insufficient evidence about the ability of state-of-the-art confidence scoring methods to detect test-time failures of classification models in the context of medical imaging. This paper provides a reality check, establishing the performance of in-domain misclassification detection methods, benchmarking 9 confidence scores on 6 medical imaging datasets with different imaging modalities, in multiclass and binary classification settings. Our experiments show that the problem of failure detection is far from being solved. We found that none of the benchmarked advanced methods proposed in the computer vision and machine learning literature can consistently outperform a simple softmax baseline. Our developed testbed facilitates future work in this important area. ",
    "url": "https://arxiv.org/abs/2205.14094",
    "authors": [
      "Melanie Bernhardt",
      "Fabio De Sousa Ribeiro",
      "Ben Glocker"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.14105",
    "title": "Learning to Solve Combinatorial Graph Partitioning Problems via  Efficient Exploration",
    "abstract": "From logistics to the natural sciences, combinatorial optimisation on graphs underpins numerous real-world applications. Reinforcement learning (RL) has shown particular promise in this setting as it can adapt to specific problem structures and does not require pre-solved instances for these, often NP-hard, problems. However, state-of-the-art (SOTA) approaches typically suffer from severe scalability issues, primarily due to their reliance on expensive graph neural networks (GNNs) at each decision step. We introduce ECORD; a novel RL algorithm that alleviates this expense by restricting the GNN to a single pre-processing step, before entering a fast-acting exploratory phase directed by a recurrent unit. Experimentally, ECORD achieves a new SOTA for RL algorithms on the Maximum Cut problem, whilst also providing orders of magnitude improvement in speed and scalability. Compared to the nearest competitor, ECORD reduces the optimality gap by up to 73% on 500 vertex graphs with a decreased wall-clock time. Moreover, ECORD retains strong performance when generalising to larger graphs with up to 10000 vertices. ",
    "url": "https://arxiv.org/abs/2205.14105",
    "authors": [
      "Thomas D. Barrett",
      "Christopher W.F. Parsonson",
      "Alexandre Laterre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.14109",
    "title": "Bayesian Robust Graph Contrastive Learning",
    "abstract": "Graph Neural Networks (GNNs) have been widely used to learn node representations and with outstanding performance on various tasks such as node classification. However, noise, which inevitably exists in real-world graph data, would considerably degrade the performance of GNNs as the noise is easily propagated via the graph structure. In this work, we propose a novel and robust method, Bayesian Robust Graph Contrastive Learning (BRGCL), which trains a GNN encoder to learn robust node representations. The BRGCL encoder is a completely unsupervised encoder. Two steps are iteratively executed at each epoch of training the BRGCL encoder: (1) estimating confident nodes and computing robust cluster prototypes of node representations through a novel Bayesian nonparametric method; (2) prototypical contrastive learning between the node representations and the robust cluster prototypes. Experiments on public and large-scale benchmarks demonstrate the superior performance of BRGCL and the robustness of the learned node representations. The code of BRGCL is available at \\url{https://github.com/BRGCL-code/BRGCL-code}. ",
    "url": "https://arxiv.org/abs/2205.14109",
    "authors": [
      "Yancheng Wang",
      "Yingzhen Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14116",
    "title": "Robust Counterfactual Explanations for Random Forests",
    "abstract": "Counterfactual explanations describe how to modify a feature vector in order to flip the outcome of a trained classifier. Several heuristic and optimal methods have been proposed to generate these explanations. However, the robustness of counterfactual explanations when the classifier is re-trained has yet to be studied. Our goal is to obtain counterfactual explanations for random forests that are robust to algorithmic uncertainty. We study the link between the robustness of ensemble models and the robustness of base learners and frame the generation of robust counterfactual explanations as a chance-constrained optimization problem. We develop a practical method with good empirical performance and provide finite-sample and asymptotic guarantees for simple random forests of stumps. We show that existing methods give surprisingly low robustness: the validity of naive counterfactuals is below $50\\%$ on most data sets and can fall to $20\\%$ on large problem instances with many features. Even with high plausibility, counterfactual explanations often exhibit low robustness to algorithmic uncertainty. In contrast, our method achieves high robustness with only a small increase in the distance from counterfactual explanations to their initial observations. Furthermore, we highlight the connection between the robustness of counterfactual explanations and the predictive importance of features. ",
    "url": "https://arxiv.org/abs/2205.14116",
    "authors": [
      "Alexandre Forel",
      "Axel Parmentier",
      "Thibaut Vidal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2205.14118",
    "title": "Efficient textual explanations for complex road and traffic scenarios  based on semantic segmentation",
    "abstract": "The complex driving environment brings great challenges to the visual perception of autonomous vehicles. The accuracy of visual perception drops off sharply under diverse weather conditions and uncertain traffic flow. Black box model makes it difficult to interpret the mechanisms of visual perception. To enhance the user acceptance and reliability of the visual perception system, a textual explanation of the scene evolvement is essential. It analyzes the geometry and topology structure in the complex environment and offers clues to decision and control. However, the existing scene explanation has been implemented as a separate model. It cannot detect comprehensive textual information and requires a high computational load and time consumption. Thus, this study proposed a comprehensive and efficient textual explanation model for complex road and traffic scenarios. From 336k video frames of the driving environment, critical images of complex road and traffic scenarios were selected into a dataset. Through transfer learning, this study established an accurate and efficient segmentation model to gain semantic information. Based on the XGBoost algorithm, a comprehensive model was developed. The model obtained textual information including road types, the motion of conflict objects, and scenario complexity. The approach was verified on the real-world road. It improved the perception accuracy of critical traffic elements to 78.8%. The time consumption reached 13 minutes for each epoch, which was 11.5 times more efficient compared with the pre-trained network. The textual information analyzed from the model was also accordant with reality. The findings explain how autonomous vehicle detects the driving environment, which lays a foundation for subsequent decision and control. It can improve the perception ability by enriching the prior knowledge and judgments for complex traffic situations. ",
    "url": "https://arxiv.org/abs/2205.14118",
    "authors": [
      "Yiyue Zhao",
      "Xinyu Yun",
      "Chen Chai",
      "Zhiyu Liu",
      "Wenxuan Fan",
      "Xiao Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14120",
    "title": "Neural Basis Models for Interpretability",
    "abstract": "Due to the widespread use of complex machine learning models in real-world applications, it is becoming critical to explain model predictions. However, these models are typically black-box deep neural networks, explained post-hoc via methods with known faithfulness limitations. Generalized Additive Models (GAMs) are an inherently interpretable class of models that address this limitation by learning a non-linear shape function for each feature separately, followed by a linear model on top. However, these models are typically difficult to train, require numerous parameters, and are difficult to scale. We propose an entirely new subfamily of GAMs that utilizes basis decomposition of shape functions. A small number of basis functions are shared among all features, and are learned jointly for a given task, thus making our model scale much better to large-scale data with high-dimensional features, especially when features are sparse. We propose an architecture denoted as the Neural Basis Model (NBM) which uses a single neural network to learn these bases. On a variety of tabular and image datasets, we demonstrate that for interpretable machine learning, NBMs are the state-of-the-art in accuracy, model size, and, throughput and can easily model all higher-order feature interactions. ",
    "url": "https://arxiv.org/abs/2205.14120",
    "authors": [
      "Filip Radenovic",
      "Abhimanyu Dubey",
      "Dhruv Mahajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14128",
    "title": "Meta-Learning Adversarial Bandits",
    "abstract": "We study online learning with bandit feedback across multiple tasks, with the goal of improving average performance across tasks if they are similar according to some natural task-similarity measure. As the first to target the adversarial setting, we design a unified meta-algorithm that yields setting-specific guarantees for two important cases: multi-armed bandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-algorithm tunes the initialization, step-size, and entropy parameter of the Tsallis-entropy generalization of the well-known Exp3 method, with the task-averaged regret provably improving if the entropy of the distribution over estimated optima-in-hindsight is small. For BLO, we learn the initialization, step-size, and boundary-offset of online mirror descent (OMD) with self-concordant barrier regularizers, showing that task-averaged regret varies directly with a measure induced by these functions on the interior of the action space. Our adaptive guarantees rely on proving that unregularized follow-the-leader combined with multiplicative weights is enough to online learn a non-smooth and non-convex sequence of affine functions of Bregman divergences that upper-bound the regret of OMD. ",
    "url": "https://arxiv.org/abs/2205.14128",
    "authors": [
      "Maria-Florina Balcan",
      "Keegan Harris",
      "Mikhail Khodak",
      "Zhiwei Steven Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.14140",
    "title": "CEBaB: Estimating the Causal Effects of Real-World Concepts on NLP Model  Behavior",
    "abstract": "The increasing size and complexity of modern ML systems has improved their predictive capabilities but made their behavior harder to explain. Many techniques for model explanation have been developed in response, but we lack clear criteria for assessing these techniques. In this paper, we cast model explanation as the causal inference problem of estimating causal effects of real-world concepts on the output behavior of ML models given actual input data. We introduce CEBaB, a new benchmark dataset for assessing concept-based explanation methods in Natural Language Processing (NLP). CEBaB consists of short restaurant reviews with human-generated counterfactual reviews in which an aspect (food, noise, ambiance, service) of the dining experience was modified. Original and counterfactual reviews are annotated with multiply-validated sentiment ratings at the aspect-level and review-level. The rich structure of CEBaB allows us to go beyond input features to study the effects of abstract, real-world concepts on model behavior. We use CEBaB to compare the quality of a range of concept-based explanation methods covering different assumptions and conceptions of the problem, and we seek to establish natural metrics for comparative assessments of these methods. ",
    "url": "https://arxiv.org/abs/2205.14140",
    "authors": [
      "Eldar David Abraham",
      "Karel D'Oosterlinck",
      "Amir Feder",
      "Yair Ori Gat",
      "Atticus Geiger",
      "Christopher Potts",
      "Roi Reichart",
      "Zhengxuan Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.13614",
    "title": "Emergent organization of receptive fields in networks of excitatory and  inhibitory neurons",
    "abstract": "Local patterns of excitation and inhibition that can generate neural waves are studied as a computational mechanism underlying the organization of neuronal tunings. Sparse coding algorithms based on networks of excitatory and inhibitory neurons are proposed that exhibit topographic maps as the receptive fields are adapted to input stimuli. Motivated by a leaky integrate-and-fire model of neural waves, we propose an activation model that is more typical of artificial neural networks. Computational experiments with the activation model using both natural images and natural language text are presented. In the case of images, familiar \"pinwheel\" patterns of oriented edge detectors emerge; in the case of text, the resulting topographic maps exhibit a 2-dimensional representation of granular word semantics. Experiments with a synthetic model of somatosensory input are used to investigate how the network dynamics may affect plasticity of neuronal maps under changes to the inputs. ",
    "url": "https://arxiv.org/abs/2205.13614",
    "authors": [
      "Leon Lufkin",
      "Ashish Puri",
      "Ganlin Song",
      "Xinyi Zhong",
      "John Lafferty"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13757",
    "title": "Representing Polymers as Periodic Graphs with Learned Descriptors for  Accurate Polymer Property Predictions",
    "abstract": "One of the grand challenges of utilizing machine learning for the discovery of innovative new polymers lies in the difficulty of accurately representing the complex structures of polymeric materials. Although a wide array of hand-designed polymer representations have been explored, there has yet to be an ideal solution for how to capture the periodicity of polymer structures, and how to develop polymer descriptors without the need for human feature design. In this work, we tackle these problems through the development of our periodic polymer graph representation. Our pipeline for polymer property predictions is comprised of our polymer graph representation that naturally accounts for the periodicity of polymers, followed by a message-passing neural network (MPNN) that leverages the power of graph deep learning to automatically learn chemically-relevant polymer descriptors. Across a diverse dataset of 10 polymer properties, we find that this polymer graph representation consistently outperforms hand-designed representations with a 20% average reduction in prediction error. Our results illustrate how the incorporation of chemical intuition through directly encoding periodicity into our polymer graph representation leads to a considerable improvement in the accuracy and reliability of polymer property predictions. We also demonstrate how combining polymer graph representations with message-passing neural network architectures can automatically extract meaningful polymer features that are consistent with human intuition, while outperforming human-derived features. This work highlights the advancement in predictive capability that is possible if using chemical descriptors that are specifically optimized for capturing the unique chemical structure of polymers. ",
    "url": "https://arxiv.org/abs/2205.13757",
    "authors": [
      "Evan R. Antoniuk",
      "Peggy Li",
      "Bhavya Kailkhura",
      "Anna M. Hiszpanski"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13816",
    "title": "Prune and distill: similar reformatting of image information along rat  visual cortex and deep neural networks",
    "abstract": "Visual object recognition has been extensively studied in both neuroscience and computer vision. Recently, the most popular class of artificial systems for this task, deep convolutional neural networks (CNNs), has been shown to provide excellent models for its functional analogue in the brain, the ventral stream in visual cortex. This has prompted questions on what, if any, are the common principles underlying the reformatting of visual information as it flows through a CNN or the ventral stream. Here we consider some prominent statistical patterns that are known to exist in the internal representations of either CNNs or the visual cortex and look for them in the other system. We show that intrinsic dimensionality (ID) of object representations along the rat homologue of the ventral stream presents two distinct expansion-contraction phases, as previously shown for CNNs. Conversely, in CNNs, we show that training results in both distillation and active pruning (mirroring the increase in ID) of low- to middle-level image information in single units, as representations gain the ability to support invariant discrimination, in agreement with previous observations in rat visual cortex. Taken together, our findings suggest that CNNs and visual cortex share a similarly tight relationship between dimensionality expansion/reduction of object representations and reformatting of image information. ",
    "url": "https://arxiv.org/abs/2205.13816",
    "authors": [
      "Paolo Muratore",
      "Sina Tafazoli",
      "Eugenio Piasini",
      "Alessandro Laio",
      "Davide Zoccolan"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13983",
    "title": "Quantum Augmented Dual Attack",
    "abstract": "We present a quantum augmented variant of the dual lattice attack on the Learning with Errors (LWE) problem, using classical memory with quantum random access (QRACM). Applying our results to lattice parameters from the literature, we find that our algorithm outperforms previous algorithms, assuming unit cost access to a QRACM. On a technical level, we show how to obtain a quantum speedup on the search for Fast Fourier Transform (FFT) coefficients above a given threshold by leveraging the relative sparseness of the FFT and using quantum amplitude estimation. We also discuss the applicability of the Quantum Fourier Transform in this context. Furthermore, we give a more rigorous analysis of the classical and quantum expected complexity of guessing part of the secret vector where coefficients follow a discrete Gaussian (mod \\(q\\)). ",
    "url": "https://arxiv.org/abs/2205.13983",
    "authors": [
      "Martin R. Albrecht",
      "Yixin Shen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2009.03561",
    "title": "Local and Central Differential Privacy for Robustness and Privacy in  Federated Learning",
    "abstract": " Title: Local and Central Differential Privacy for Robustness and Privacy in  Federated Learning ",
    "url": "https://arxiv.org/abs/2009.03561",
    "authors": [
      "Mohammad Naseri",
      "Jamie Hayes",
      "Emiliano De Cristofaro"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2102.11707",
    "title": "Deep ReLU neural networks overcome the curse of dimensionality for  partial integrodifferential equations",
    "abstract": " Title: Deep ReLU neural networks overcome the curse of dimensionality for  partial integrodifferential equations ",
    "url": "https://arxiv.org/abs/2102.11707",
    "authors": [
      "Lukas Gonon",
      "Christoph Schwab"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2104.09124",
    "title": "DisCo: Remedy Self-supervised Learning on Lightweight Models with  Distilled Contrastive Learning",
    "abstract": " Title: DisCo: Remedy Self-supervised Learning on Lightweight Models with  Distilled Contrastive Learning ",
    "url": "https://arxiv.org/abs/2104.09124",
    "authors": [
      "Yuting Gao",
      "Jia-Xin Zhuang",
      "Shaohui Lin",
      "Hao Cheng",
      "Xing Sun",
      "Ke Li",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2104.10034",
    "title": "On Generating and Labeling Network Traffic with Realistic,  Self-Propagating Malware",
    "abstract": " Comments: 4+2 pages, 3 figures, 1 table, for AI4CS-SDM21 ",
    "url": "https://arxiv.org/abs/2104.10034",
    "authors": [
      "Molly Buchanan",
      "Jeffrey W. Collyer",
      "Jack W. Davidson",
      "Saikat Dey",
      "Mark Gardner",
      "Jason D. Hiser",
      "Jeffry Lang",
      "Alastair Nottingham",
      "Alina Oprea"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2104.12710",
    "title": "Optimal Algorithm Allocation for Robotic Network Cloud Systems",
    "abstract": " Comments: This work is accepted for publication in the Elsevier Journal of Robotics and Autonomous Systems. Personal use of this material is permitted. Permission from Elsevier must be obtained for all other uses ",
    "url": "https://arxiv.org/abs/2104.12710",
    "authors": [
      "Saeid Alirezazadeh",
      "Andr\u00e9 Correia",
      "Lu\u00eds A. Alexandre"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2105.12537",
    "title": "Networks of climate change: Connecting causes and consequences",
    "abstract": " Title: Networks of climate change: Connecting causes and consequences ",
    "url": "https://arxiv.org/abs/2105.12537",
    "authors": [
      "Petter Holme",
      "Juan C. Rocha"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2105.13856",
    "title": "Lightweight Cross-Lingual Sentence Representation Learning",
    "abstract": " Comments: ACL 2021 main conference; modified Eq. (2) ",
    "url": "https://arxiv.org/abs/2105.13856",
    "authors": [
      "Zhuoyuan Mao",
      "Prakhar Gupta",
      "Pei Wang",
      "Chenhui Chu",
      "Martin Jaggi",
      "Sadao Kurohashi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2108.01724",
    "title": "Approximating the Manifold Structure of Attributed Incentive Salience  from Large Scale Behavioural Data. A Representation Learning Approach Based  on Artificial Neural Networks",
    "abstract": " Title: Approximating the Manifold Structure of Attributed Incentive Salience  from Large Scale Behavioural Data. A Representation Learning Approach Based  on Artificial Neural Networks ",
    "url": "https://arxiv.org/abs/2108.01724",
    "authors": [
      "Valerio Bonometti",
      "Mathieu J. Ruiz",
      "Anders Drachen",
      "Alex Wade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2108.11926",
    "title": "Re-using Adversarial Mask Discriminators for Test-time Training under  Distribution Shifts",
    "abstract": " Comments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) this https URL ",
    "url": "https://arxiv.org/abs/2108.11926",
    "authors": [
      "Gabriele Valvano",
      "Andrea Leo",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2109.07934",
    "title": "Fast and Secure Routing Algorithms for Quantum Key Distribution Networks",
    "abstract": " Title: Fast and Secure Routing Algorithms for Quantum Key Distribution Networks ",
    "url": "https://arxiv.org/abs/2109.07934",
    "authors": [
      "Shahbaz Akhtar",
      "Krishnakumar G",
      "Vishnu B",
      "Abhishek Sinha"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2109.08844",
    "title": "Near-Minimax Optimal Estimation With Shallow ReLU Neural Networks",
    "abstract": " Title: Near-Minimax Optimal Estimation With Shallow ReLU Neural Networks ",
    "url": "https://arxiv.org/abs/2109.08844",
    "authors": [
      "Rahul Parhi",
      "Robert D. Nowak"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2110.01822",
    "title": "Verified eigenvalue and eigenvector computations using complex moments  and the Rayleigh$\\unicode{x2013}$Ritz procedure for generalized Hermitian  eigenvalue problems",
    "abstract": " Comments: 22 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2110.01822",
    "authors": [
      "Akira Imakura",
      "Keiichi Morikuni",
      "Akitoshi Takayasu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2110.13674",
    "title": "C$^2$SP-Net: Joint Compression and Classification Network for Epilepsy  Seizure Prediction",
    "abstract": " Title: C$^2$SP-Net: Joint Compression and Classification Network for Epilepsy  Seizure Prediction ",
    "url": "https://arxiv.org/abs/2110.13674",
    "authors": [
      "Di Wu",
      "Yi Shi",
      "Ziyu Wang",
      "Jie Yang",
      "Mohamad Sawan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.04635",
    "title": "CORE: a Complex Event Recognition Engine",
    "abstract": " Comments: 30 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2111.04635",
    "authors": [
      "Marco Bucchi",
      "Alejandro Grez",
      "Andr\u00e9s Quintana",
      "Cristian Riveros",
      "Stijn Vansummeren"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2111.11798",
    "title": "Composing Partial Differential Equations with Physics-Aware Neural  Networks",
    "abstract": " Comments: Accepted at ICML2022. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2111.11798",
    "authors": [
      "Matthias Karlbauer",
      "Timothy Praditia",
      "Sebastian Otte",
      "Sergey Oladyshkin",
      "Wolfgang Nowak",
      "Martin V. Butz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.12965",
    "title": "Towards Practical Deployment-Stage Backdoor Attack on Deep Neural  Networks",
    "abstract": " Title: Towards Practical Deployment-Stage Backdoor Attack on Deep Neural  Networks ",
    "url": "https://arxiv.org/abs/2111.12965",
    "authors": [
      "Xiangyu Qi",
      "Tinghao Xie",
      "Ruizhe Pan",
      "Jifeng Zhu",
      "Yong Yang",
      "Kai Bu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.08217",
    "title": "Probabilistic Forecasting with Generative Networks via Scoring Rule  Minimization",
    "abstract": " Title: Probabilistic Forecasting with Generative Networks via Scoring Rule  Minimization ",
    "url": "https://arxiv.org/abs/2112.08217",
    "authors": [
      "Lorenzo Pacchiardi",
      "Rilwan Adewoyin",
      "Peter Dueben",
      "Ritabrata Dutta"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.11937",
    "title": "Adversarial Deep Reinforcement Learning for Improving the Robustness of  Multi-agent Autonomous Driving Policies",
    "abstract": " Title: Adversarial Deep Reinforcement Learning for Improving the Robustness of  Multi-agent Autonomous Driving Policies ",
    "url": "https://arxiv.org/abs/2112.11937",
    "authors": [
      "Aizaz Sharif",
      "Dusica Marijan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.11947",
    "title": "Evaluating the Robustness of Deep Reinforcement Learning for Autonomous  and Adversarial Policies in a Multi-agent Urban Driving Environment",
    "abstract": " Title: Evaluating the Robustness of Deep Reinforcement Learning for Autonomous  and Adversarial Policies in a Multi-agent Urban Driving Environment ",
    "url": "https://arxiv.org/abs/2112.11947",
    "authors": [
      "Aizaz Sharif",
      "Dusica Marijan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2112.15139",
    "title": "Finding the Task-Optimal Low-Bit Sub-Distribution in Deep Neural  Networks",
    "abstract": " Comments: Accepted at ICML 2022 ",
    "url": "https://arxiv.org/abs/2112.15139",
    "authors": [
      "Runpei Dong",
      "Zhanhong Tan",
      "Mengdi Wu",
      "Linfeng Zhang",
      "Kaisheng Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.02143",
    "title": "Classification of Long Sequential Data using Circular Dilated  Convolutional Neural Networks",
    "abstract": " Title: Classification of Long Sequential Data using Circular Dilated  Convolutional Neural Networks ",
    "url": "https://arxiv.org/abs/2201.02143",
    "authors": [
      "Lei Cheng",
      "Ruslan Khalitov",
      "Tong Yu",
      "Zhirong Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.03812",
    "title": "Bootstrapping Informative Graph Augmentation via A Meta Learning  Approach",
    "abstract": " Comments: Accepted by International Joint Conference on Artificial Intelligence (IJCAI) 2022 ",
    "url": "https://arxiv.org/abs/2201.03812",
    "authors": [
      "Hang Gao",
      "Jiangmeng Li",
      "Wenwen Qiang",
      "Lingyu Si",
      "Fuchun Sun",
      "Changwen Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.11860",
    "title": "On the Anonymity of Peer-To-Peer Network Anonymity Schemes Used by  Cryptocurrencies",
    "abstract": " Title: On the Anonymity of Peer-To-Peer Network Anonymity Schemes Used by  Cryptocurrencies ",
    "url": "https://arxiv.org/abs/2201.11860",
    "authors": [
      "Piyush Kumar Sharma",
      "Devashish Gosain",
      "Claudia Diaz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.01336",
    "title": "Exploring Transformer Backbones for Heterogeneous Treatment Effect  Estimation",
    "abstract": " Title: Exploring Transformer Backbones for Heterogeneous Treatment Effect  Estimation ",
    "url": "https://arxiv.org/abs/2202.01336",
    "authors": [
      "Yi-Fan Zhang",
      "Hanlin Zhang",
      "Zachary C. Lipton",
      "Li Erran Li",
      "Eric P. Xing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02444",
    "title": "Spelunking the Deep: Guaranteed Queries on General Neural Implicit  Surfaces via Range Analysis",
    "abstract": " Comments: appearing in ACM Transactions on Graphics / SIGGRAPH 2022 Journal Papers ",
    "url": "https://arxiv.org/abs/2202.02444",
    "authors": [
      "Nicholas Sharp",
      "Alec Jacobson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02684",
    "title": "On the Multi-View Information Bottleneck Representation",
    "abstract": " Title: On the Multi-View Information Bottleneck Representation ",
    "url": "https://arxiv.org/abs/2202.02684",
    "authors": [
      "Teng-Hui Huang",
      "Aly El Gamal",
      "Hesham El Gamal"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.07453",
    "title": "Random Walks for Adversarial Meshes",
    "abstract": " Title: Random Walks for Adversarial Meshes ",
    "url": "https://arxiv.org/abs/2202.07453",
    "authors": [
      "Amir Belder",
      "Gal Yefet",
      "Ran Ben Izhak",
      "Ayellet Tal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01216",
    "title": "A Simple and Universal Rotation Equivariant Point-cloud Network",
    "abstract": " Title: A Simple and Universal Rotation Equivariant Point-cloud Network ",
    "url": "https://arxiv.org/abs/2203.01216",
    "authors": [
      "Ben Finkelshtein",
      "Chaim Baskin",
      "Haggai Maron",
      "Nadav Dym"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01414",
    "title": "ICARUS: A Specialized Architecture for Neural Radiance Field Rendering",
    "abstract": " Title: ICARUS: A Specialized Architecture for Neural Radiance Field Rendering ",
    "url": "https://arxiv.org/abs/2203.01414",
    "authors": [
      "Chaolin Rao",
      "Huangjie Yu",
      "Haochuan Wan",
      "Jindong Zhou",
      "Yueyang Zheng",
      "Yu Ma",
      "Anpei Chen",
      "Minye Wu",
      "Binzhe Yuan",
      "Pingqiang Zhou",
      "Xin Lou",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2203.02128",
    "title": "Distributionally Robust Bayesian Optimization with $\u03c6$-divergences",
    "abstract": " Comments: 19 pages ",
    "url": "https://arxiv.org/abs/2203.02128",
    "authors": [
      "Hisham Husain",
      "Vu Nguyen",
      "Anton van den Hengel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.03397",
    "title": "OverlapTransformer: An Efficient and Rotation-Invariant Transformer  Network for LiDAR-Based Place Recognition",
    "abstract": " Comments: Accepted by RAL/IROS 2022 ",
    "url": "https://arxiv.org/abs/2203.03397",
    "authors": [
      "Junyi Ma",
      "Jun Zhang",
      "Jintao Xu",
      "Rui Ai",
      "Weihao Gu",
      "Xieyuanli Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.06649",
    "title": "Joint rotational invariance and adversarial training of a dual-stream  Transformer yields state of the art Brain-Score for Area V4",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2203.06649",
    "authors": [
      "William Berrios",
      "Arturo Deza"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2203.11207",
    "title": "Hybrid training of optical neural networks",
    "abstract": " Title: Hybrid training of optical neural networks ",
    "url": "https://arxiv.org/abs/2203.11207",
    "authors": [
      "James Spall",
      "Xianxin Guo",
      "A. I. Lvovsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Emerging Technologies (cs.ET)",
      "Image and Video Processing (eess.IV)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2203.13207",
    "title": "Supervised Training of Siamese Spiking Neural Networks with Earth  Mover's Distance",
    "abstract": " Comments: Revised paper accepted for presentation at 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) ",
    "url": "https://arxiv.org/abs/2203.13207",
    "authors": [
      "Mateusz Pabian",
      "Dominik Rzepka",
      "Miros\u0142aw Pawlak"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13457",
    "title": "Chaos is a Ladder: A New Theoretical Understanding of Contrastive  Learning via Augmentation Overlap",
    "abstract": " Comments: Accepeted by ICLR 2022 ",
    "url": "https://arxiv.org/abs/2203.13457",
    "authors": [
      "Yifei Wang",
      "Qi Zhang",
      "Yisen Wang",
      "Jiansheng Yang",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.01102",
    "title": "Formal Privacy for Partially Private Data",
    "abstract": " Comments: 24 pages, 5 figures; submitted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2204.01102",
    "authors": [
      "Jeremy Seeman",
      "Matthew Reimherr",
      "Aleksandra Slavkovic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2204.02128",
    "title": "Computing in Anonymous Dynamic Networks Is Linear",
    "abstract": " Comments: 31 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2204.02128",
    "authors": [
      "Giuseppe A. Di Luna",
      "Giovanni Viglietta"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2204.07615",
    "title": "TabNAS: Rejection Sampling for Neural Architecture Search on Tabular  Datasets",
    "abstract": " Comments: 29 pages, 15 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2204.07615",
    "authors": [
      "Chengrun Yang",
      "Gabriel Bender",
      "Hanxiao Liu",
      "Pieter-Jan Kindermans",
      "Madeleine Udell",
      "Yifeng Lu",
      "Quoc Le",
      "Da Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.10586",
    "title": "Efficient Training of Neural Transducer for Speech Recognition",
    "abstract": " Comments: submitted to Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2204.10586",
    "authors": [
      "Wei Zhou",
      "Wilfried Michel",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.11127",
    "title": "U-NO: U-shaped Neural Operators",
    "abstract": " Title: U-NO: U-shaped Neural Operators ",
    "url": "https://arxiv.org/abs/2204.11127",
    "authors": [
      "Md Ashiqur Rahman",
      "Zachary E. Ross",
      "Kamyar Azizzadenesheli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.14057",
    "title": "Unsupervised Voice-Face Representation Learning by Cross-Modal Prototype  Contrast",
    "abstract": " Comments: 8 pages, 4 figures. Accepted by IJCAI-2022 ",
    "url": "https://arxiv.org/abs/2204.14057",
    "authors": [
      "Boqing Zhu",
      "Kele Xu",
      "Changjian Wang",
      "Zheng Qin",
      "Tao Sun",
      "Huaimin Wang",
      "Yuxing Peng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.05167",
    "title": "Robustness of Humans and Machines on Object Recognition with Extreme  Image Transformations",
    "abstract": " Comments: Accepted at CVPR NeuroVision Workshop ",
    "url": "https://arxiv.org/abs/2205.05167",
    "authors": [
      "Dakarai Crowder",
      "Girik Malik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.05980",
    "title": "\"Teaching Independent Parts Separately\" (TIPSy-GAN) : Improving Accuracy  and Stability in Unsupervised Adversarial 2D to 3D Pose Estimation",
    "abstract": " Title: \"Teaching Independent Parts Separately\" (TIPSy-GAN) : Improving Accuracy  and Stability in Unsupervised Adversarial 2D to 3D Pose Estimation ",
    "url": "https://arxiv.org/abs/2205.05980",
    "authors": [
      "Peter Hardy",
      "Srinandan Dasmahapatra",
      "Hansung Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.06440",
    "title": "Exploiting Variational Domain-Invariant User Embedding for Partially  Overlapped Cross Domain Recommendation",
    "abstract": " Title: Exploiting Variational Domain-Invariant User Embedding for Partially  Overlapped Cross Domain Recommendation ",
    "url": "https://arxiv.org/abs/2205.06440",
    "authors": [
      "Weiming Liu",
      "Xiaolin Zheng",
      "Mengling Hu",
      "Chaochao Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2205.09702",
    "title": "Parallel and Distributed Graph Neural Networks: An In-Depth Concurrency  Analysis",
    "abstract": " Title: Parallel and Distributed Graph Neural Networks: An In-Depth Concurrency  Analysis ",
    "url": "https://arxiv.org/abs/2205.09702",
    "authors": [
      "Maciej Besta",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.13326",
    "title": "SHREC 2022: pothole and crack detection in the road pavement using  images and RGB-D data",
    "abstract": " Title: SHREC 2022: pothole and crack detection in the road pavement using  images and RGB-D data ",
    "url": "https://arxiv.org/abs/2205.13326",
    "authors": [
      "Elia Moscoso Thompson",
      "Andrea Ranieri",
      "Silvia Biasotti",
      "Miguel Chicchon",
      "Ivan Sipiran",
      "Minh-Khoi Pham",
      "Thang-Long Nguyen-Ho",
      "Hai-Dang Nguyen",
      "Minh-Triet Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2205.13462",
    "title": "FedAug: Reducing the Local Learning Bias Improves Federated Learning on  Heterogeneous Data",
    "abstract": " Title: FedAug: Reducing the Local Learning Bias Improves Federated Learning on  Heterogeneous Data ",
    "url": "https://arxiv.org/abs/2205.13462",
    "authors": [
      "Yongxin Guo",
      "Tao Lin",
      "Xiaoying Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  }
]