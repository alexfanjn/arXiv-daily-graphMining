[
  {
    "id": "arXiv:2205.09140",
    "title": "Relational representation learning with spike trains",
    "abstract": "Relational representation learning has lately received an increase in interest due to its flexibility in modeling a variety of systems like interacting particles, materials and industrial projects for, e.g., the design of spacecraft. A prominent method for dealing with relational data are knowledge graph embedding algorithms, where entities and relations of a knowledge graph are mapped to a low-dimensional vector space while preserving its semantic structure. Recently, a graph embedding method has been proposed that maps graph elements to the temporal domain of spiking neural networks. However, it relies on encoding graph elements through populations of neurons that only spike once. Here, we present a model that allows us to learn spike train-based embeddings of knowledge graphs, requiring only one neuron per graph element by fully utilizing the temporal domain of spike patterns. This coding scheme can be implemented with arbitrary spiking neuron models as long as gradients with respect to spike times can be calculated, which we demonstrate for the integrate-and-fire neuron model. In general, the presented results show how relational knowledge can be integrated into spike-based systems, opening up the possibility of merging event-based computing and relational data to build powerful and energy efficient artificial intelligence applications and reasoning systems. ",
    "url": "https://arxiv.org/abs/2205.09140",
    "authors": [
      "Dominik Dold"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2205.09167",
    "title": "Backdoor Attacks on Bayesian Neural Networks using Reverse Distribution",
    "abstract": "Due to cost and time-to-market constraints, many industries outsource the training process of machine learning models (ML) to third-party cloud service providers, popularly known as ML-asa-Service (MLaaS). MLaaS creates opportunity for an adversary to provide users with backdoored ML models to produce incorrect predictions only in extremely rare (attacker-chosen) scenarios. Bayesian neural networks (BNN) are inherently immune against backdoor attacks since the weights are designed to be marginal distributions to quantify the uncertainty. In this paper, we propose a novel backdoor attack based on effective learning and targeted utilization of reverse distribution. This paper makes three important contributions. (1) To the best of our knowledge, this is the first backdoor attack that can effectively break the robustness of BNNs. (2) We produce reverse distributions to cancel the original distributions when the trigger is activated. (3) We propose an efficient solution for merging probability distributions in BNNs. Experimental results on diverse benchmark datasets demonstrate that our proposed attack can achieve the attack success rate (ASR) of 100%, while the ASR of the state-of-the-art attacks is lower than 60%. ",
    "url": "https://arxiv.org/abs/2205.09167",
    "authors": [
      "Zhixin Pan",
      "Prabhat Mishra"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.09170",
    "title": "Adaptive Hybrid Heterogeneous IDS for 6LoWPAN",
    "abstract": "IPv6 over Low-powered Wireless Personal Area Networks (6LoWPAN) have grown in importance in recent years, with the Routing Protocol for Low Power and Lossy Networks (RPL) emerging as a major enabler. However, RPL can be subject to attack, with severe consequences. Most proposed IDSs have been limited to specific RPL attacks and typically assume a stationary environment. In this article, we propose the first adaptive hybrid IDS to efficiently detect and identify a wide range of RPL attacks (including DIO Suppression, Increase Rank, and Worst Parent attacks, which have been overlooked in the literature) in evolving data environments. We apply our framework to networks under various levels of node mobility and maliciousness. We experiment with several incremental machine learning (ML) approaches and various 'concept-drift detection' mechanisms (e.g. ADWIN, DDM, and EDDM) to determine the best underlying settings for the proposed scheme. ",
    "url": "https://arxiv.org/abs/2205.09170",
    "authors": [
      "Aryan Mohammadi Pasikhani",
      "John A Clark",
      "Prosanta Gope"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.09182",
    "title": "Computing the ensemble spread from deterministic weather predictions  using conditional generative adversarial networks",
    "abstract": "Ensemble prediction systems are an invaluable tool for weather forecasting. Practically, ensemble predictions are obtained by running several perturbations of the deterministic control forecast. However, ensemble prediction is associated with a high computational cost and often involves statistical post-processing steps to improve its quality. Here we propose to use deep-learning-based algorithms to learn the statistical properties of an ensemble prediction system, the ensemble spread, given only the deterministic control forecast. Thus, once trained, the costly ensemble prediction system will not be needed anymore to obtain future ensemble forecasts, and the statistical properties of the ensemble can be derived from a single deterministic forecast. We adapt the classical pix2pix architecture to a three-dimensional model and also experiment with a shared latent space encoder-decoder model, and train them against several years of operational (ensemble) weather forecasts for the 500 hPa geopotential height. The results demonstrate that the trained models indeed allow obtaining a highly accurate ensemble spread from the control forecast only. ",
    "url": "https://arxiv.org/abs/2205.09182",
    "authors": [
      "R\u00fcdiger Brecht",
      "Alex Bihlo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2205.09199",
    "title": "A False Sense of Security? Revisiting the State of Machine  Learning-Based Industrial Intrusion Detection",
    "abstract": "Anomaly-based intrusion detection promises to detect novel or unknown attacks on industrial control systems by modeling expected system behavior and raising corresponding alarms for any deviations.As manually creating these behavioral models is tedious and error-prone, research focuses on machine learning to train them automatically, achieving detection rates upwards of 99%. However, these approaches are typically trained not only on benign traffic but also on attacks and then evaluated against the same type of attack used for training. Hence, their actual, real-world performance on unknown (not trained on) attacks remains unclear. In turn, the reported near-perfect detection rates of machine learning-based intrusion detection might create a false sense of security. To assess this situation and clarify the real potential of machine learning-based industrial intrusion detection, we develop an evaluation methodology and examine multiple approaches from literature for their performance on unknown attacks (excluded from training). Our results highlight an ineffectiveness in detecting unknown attacks, with detection rates dropping to between 3.2% and 14.7% for some types of attacks. Moving forward, we derive recommendations for further research on machine learning-based approaches to ensure clarity on their ability to detect unknown attacks. ",
    "url": "https://arxiv.org/abs/2205.09199",
    "authors": [
      "Dominik Kus",
      "Eric Wagner",
      "Jan Pennekamp",
      "Konrad Wolsing",
      "Ina Berenice Fink",
      "Markus Dahlmanns",
      "Klaus Wehrle",
      "Martin Henze"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09219",
    "title": "A Classification of $G$-invariant Shallow Neural Networks",
    "abstract": "When trying to fit a deep neural network (DNN) to a $G$-invariant target function with respect to a group $G$, it only makes sense to constrain the DNN to be $G$-invariant as well. However, there can be many different ways to do this, thus raising the problem of \"$G$-invariant neural architecture design\": What is the optimal $G$-invariant architecture for a given problem? Before we can consider the optimization problem itself, we must understand the search space, the architectures in it, and how they relate to one another. In this paper, we take a first step towards this goal; we prove a theorem that gives a classification of all $G$-invariant single-hidden-layer or \"shallow\" neural network ($G$-SNN) architectures with ReLU activation for any finite orthogonal group $G$. The proof is based on a correspondence of every $G$-SNN to a signed permutation representation of $G$ acting on the hidden neurons. The classification is equivalently given in terms of the first cohomology classes of $G$, thus admitting a topological interpretation. Based on a code implementation, we enumerate the $G$-SNN architectures for some example groups $G$ and visualize their structure. We draw the network morphisms between the enumerated architectures that can be leveraged during neural architecture search (NAS). Finally, we prove that architectures corresponding to inequivalent cohomology classes in a given cohomology ring coincide in function space only when their weight matrices are zero, and we discuss the implications of this in the context of NAS. ",
    "url": "https://arxiv.org/abs/2205.09219",
    "authors": [
      "Devanshu Agrawal",
      "James Ostrowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.09226",
    "title": "Modeling Multi-hop Question Answering as Single Sequence Prediction",
    "abstract": "Fusion-in-decoder (Fid) (Izacard and Grave, 2020) is a generative question answering (QA) model that leverages passage retrieval with a pre-trained transformer and pushed the state of the art on single-hop QA. However, the complexity of multi-hop QA hinders the effectiveness of the generative QA approach. In this work, we propose a simple generative approach (PathFid) that extends the task beyond just answer generation by explicitly modeling the reasoning process to resolve the answer for multi-hop questions. By linearizing the hierarchical reasoning path of supporting passages, their key sentences, and finally the factoid answer, we cast the problem as a single sequence prediction task. To facilitate complex reasoning with multiple clues, we further extend the unified flat representation of multiple input documents by encoding cross-passage interactions. Our extensive experiments demonstrate that PathFid leads to strong performance gains on two multi-hop QA datasets: HotpotQA and IIRC. Besides the performance gains, PathFid is more interpretable, which in turn yields answers that are more faithfully grounded to the supporting passages and facts compared to the baseline Fid model. ",
    "url": "https://arxiv.org/abs/2205.09226",
    "authors": [
      "Semih Yavuz",
      "Kazuma Hashimoto",
      "Yingbo Zhou",
      "Nitish Shirish Keskar",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.09228",
    "title": "Scalable Multi-view Clustering with Graph Filtering",
    "abstract": "With the explosive growth of multi-source data, multi-view clustering has attracted great attention in recent years. Most existing multi-view methods operate in raw feature space and heavily depend on the quality of original feature representation. Moreover, they are often designed for feature data and ignore the rich topology structure information. Accordingly, in this paper, we propose a generic framework to cluster both attribute and graph data with heterogeneous features. It is capable of exploring the interplay between feature and structure. Specifically, we first adopt graph filtering technique to eliminate high-frequency noise to achieve a clustering-friendly smooth representation. To handle the scalability challenge, we develop a novel sampling strategy to improve the quality of anchors. Extensive experiments on attribute and graph benchmarks demonstrate the superiority of our approach with respect to state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2205.09228",
    "authors": [
      "Liang Liu",
      "Peng Chen",
      "Guangchun Luo",
      "Zhao Kang",
      "Yonggang Luo",
      "Sanchu Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.09229",
    "title": "PromptDA: Label-guided Data Augmentation for Prompt-based Few Shot  Learners",
    "abstract": "Recent advances on large pre-trained language models (PLMs) lead impressive gains on natural language understanding (NLU) tasks with task-specific fine-tuning. However, direct fine-tuning PLMs heavily relies on large amount of labeled instances, which are expensive and time-consuming to obtain. Prompt-based tuning on PLMs has proven valuable for few shot tasks. Existing works studying prompt-based tuning for few-shot NLU mainly focus on deriving proper label words with a verbalizer or generating prompt templates for eliciting semantics from PLMs. In addition, conventional data augmentation methods have also been verified useful for few-shot tasks. However, there currently are few data augmentation methods designed for the prompt-based tuning paradigm. Therefore, we study a new problem of data augmentation for prompt-based few shot learners. Since label semantics are helpful in prompt-based tuning, we propose a novel label-guided data augmentation method PromptDA which exploits the enriched label semantic information for data augmentation. Experimental results on several few shot text classification tasks show that our proposed framework achieves superior performance by effectively leveraging label semantics and data augmentation in language understanding. ",
    "url": "https://arxiv.org/abs/2205.09229",
    "authors": [
      "Canyu Chen",
      "Kai Shu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.09240",
    "title": "Debiasing Neural Retrieval via In-batch Balancing Regularization",
    "abstract": "People frequently interact with information retrieval (IR) systems, however, IR models exhibit biases and discrimination towards various demographics. The in-processing fair ranking methods provide a trade-offs between accuracy and fairness through adding a fairness-related regularization term in the loss function. However, there haven't been intuitive objective functions that depend on the click probability and user engagement to directly optimize towards this. In this work, we propose the In-Batch Balancing Regularization (IBBR) to mitigate the ranking disparity among subgroups. In particular, we develop a differentiable \\textit{normed Pairwise Ranking Fairness} (nPRF) and leverage the T-statistics on top of nPRF over subgroups as a regularization to improve fairness. Empirical results with the BERT-based neural rankers on the MS MARCO Passage Retrieval dataset with the human-annotated non-gendered queries benchmark \\citep{rekabsaz2020neural} show that our IBBR method with nPRF achieves significantly less bias with minimal degradation in ranking performance compared with the baseline. ",
    "url": "https://arxiv.org/abs/2205.09240",
    "authors": [
      "Yuantong Li",
      "Xiaokai Wei",
      "Zijian Wang",
      "Shen Wang",
      "Parminder Bhatia",
      "Xiaofei Ma",
      "Andrew Arnold"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2205.09248",
    "title": "MESH2IR: Neural Acoustic Impulse Response Generator for Complex 3D  Scenes",
    "abstract": "We propose a mesh-based neural network (MESH2IR) to generate acoustic impulse responses (IRs) for indoor 3D scenes represented using a mesh. The IRs are used to create a high-quality sound experience in interactive applications and audio processing. Our method can handle input triangular meshes with arbitrary topologies (2K - 3M triangles). We present a novel training technique to train MESH2IR using energy decay relief and highlight its benefits. We also show that training MESH2IR on IRs preprocessed using our proposed technique significantly improves the accuracy of IR generation. We reduce the non-linearity in the mesh space by transforming 3D scene meshes to latent space using a graph convolution network. Our MESH2IR is more than 200 times faster than a geometric acoustic algorithm on a CPU and can generate more than 10,000 IRs per second on an NVIDIA GeForce RTX 2080 Ti GPU for a given furnished indoor 3D scene. The acoustic metrics are used to characterize the acoustic environment. We show that the acoustic metrics of the IRs predicted from our MESH2IR match the ground truth with less than 10% error. We also highlight the benefits of MESH2IR on audio and speech processing applications such as speech dereverberation and speech separation. To the best of our knowledge, ours is the first neural-network-based approach to predict IRs from a given 3D scene mesh in real-time. ",
    "url": "https://arxiv.org/abs/2205.09248",
    "authors": [
      "Anton Ratnarajah",
      "Zhenyu Tang",
      "Rohith Chandrashekar Aralikatti",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.09250",
    "title": "Bayesian Convolutional Neural Networks for Limited Data Hyperspectral  Remote Sensing Image Classification",
    "abstract": "Employing deep neural networks for Hyper-spectral remote sensing (HSRS) image classification is a challenging task. HSRS images have high dimensionality and a large number of channels with substantial redundancy between channels. In addition, the training data for classifying HSRS images is limited and the amount of available training data is much smaller compared to other classification tasks. These factors complicate the training process of deep neural networks with many parameters and cause them to not perform well even compared to conventional models. Moreover, convolutional neural networks produce over-confident predictions, which is highly undesirable considering the aforementioned problem. In this work, we use a special class of deep neural networks, namely Bayesian neural network, to classify HSRS images. To the extent of our knowledge, this is the first time that this class of neural networks has been used in HSRS image classification. Bayesian neural networks provide an inherent tool for measuring uncertainty. We show that a Bayesian network can outperform a similarly-constructed non-Bayesian convolutional neural network (CNN) and an off-the-shelf Random Forest (RF). Moreover, experimental results for the Pavia Centre, Salinas, and Botswana datasets show that the Bayesian network is more stable and robust to model pruning. Furthermore, we analyze the prediction uncertainty of the Bayesian model and show that the prediction uncertainty metric can provide information about the model predictions and has a positive correlation with the prediction error. ",
    "url": "https://arxiv.org/abs/2205.09250",
    "authors": [
      "Mohammad Joshaghani",
      "Amirabbas Davari",
      "Faezeh Nejati Hatamian",
      "Andreas Maier",
      "Christian Riess"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.09257",
    "title": "Mining Observation and Cognitive Behavior Process Patterns of Bridge  Inspector",
    "abstract": "In bridge inspection, engineers should diagnose the observed bridge defects by identifying the factors underlying those defects. Traditionally, engineers search and organize structural condition-related information based on visual inspections. Even following the same qualitative inspection standards, experienced engineers tend to find the critical defects and predict the underlying reasons more reliably than less experienced ones. Unique bridge and site conditions, quality of available data, and personal skills and knowledge collectively influence such a subjective nature of data-driven bridge diagnosis. Unfortunately, the lack of detailed data about how experienced engineers observe bridge defects and identify failure modes makes it hard to comprehend what engineers' behaviors form the best practice of producing reliable bridge inspection. Besides, even experienced engineers could sometimes fail to notice critical defects, thereby producing inconsistent, conflicting condition assessments. Therefore, a detailed cognitive behavior analysis of bridge inspectors is critical for enabling a proactive inspector coaching system that uses inspectors' behavior histories to complement personal limitations. This paper presents a computational framework for revealing engineers' observation and cognitive-behavioral processes to identify bridge defects and produce diagnosis conclusions. The authors designed a bridge inspection game consisting of FEM simulation data and inspection reports to capture and analyze experienced and inexperienced engineers' diagnosis behaviors. Mining these behavioral logs have revealed reusable behavioral process patterns that map critical bridge defects and diagnosis conclusions. The results indicate that the proposed method can proactively share inspection experiences and improve inspection processes' explainability and reliability. ",
    "url": "https://arxiv.org/abs/2205.09257",
    "authors": [
      "Pengkun Liu",
      "Ruoxin Xiong",
      "Pingbo Tang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2205.09263",
    "title": "A Mutually Exciting Latent Space Hawkes Process Model for  Continuous-time Networks",
    "abstract": "Networks and temporal point processes serve as fundamental building blocks for modeling complex dynamic relational data in various domains. We propose the latent space Hawkes (LSH) model, a novel generative model for continuous-time networks of relational events, using a latent space representation for nodes. We model relational events between nodes using mutually exciting Hawkes processes with baseline intensities dependent upon the distances between the nodes in the latent space and sender and receiver specific effects. We propose an alternating minimization algorithm to jointly estimate the latent positions of the nodes and other model parameters. We demonstrate that our proposed LSH model can replicate many features observed in real temporal networks including reciprocity and transitivity, while also achieves superior prediction accuracy and provides more interpretability compared to existing models. ",
    "url": "https://arxiv.org/abs/2205.09263",
    "authors": [
      "Zhipeng Huang",
      "Hadeel Soliman",
      "Subhadeep Paul",
      "Kevin S. Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.09281",
    "title": "Causal Inference from Small High-dimensional Datasets",
    "abstract": "Many methods have been proposed to estimate treatment effects with observational data. Often, the choice of the method considers the application's characteristics, such as type of treatment and outcome, confounding effect, and the complexity of the data. These methods implicitly assume that the sample size is large enough to train such models, especially the neural network-based estimators. What if this is not the case? In this work, we propose Causal-Batle, a methodology to estimate treatment effects in small high-dimensional datasets in the presence of another high-dimensional dataset in the same feature space. We adopt an approach that brings transfer learning techniques into causal inference. Our experiments show that such an approach helps to bring stability to neural network-based methods and improve the treatment effect estimates in small high-dimensional datasets. ",
    "url": "https://arxiv.org/abs/2205.09281",
    "authors": [
      "Raquel Aoki",
      "Martin Ester"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.09299",
    "title": "3DConvCaps: 3DUnet with Convolutional Capsule Encoder for Medical Image  Segmentation",
    "abstract": "Convolutional Neural Networks (CNNs) have achieved promising results in medical image segmentation. However, CNNs require lots of training data and are incapable of handling pose and deformation of objects. Furthermore, their pooling layers tend to discard important information such as positions as well as CNNs are sensitive to rotation and affine transformation. Capsule network is a recent new architecture that has achieved better robustness in part-whole representation learning by replacing pooling layers with dynamic routing and convolutional strides, which has shown potential results on popular tasks such as digit classification and object segmentation. In this paper, we propose a 3D encoder-decoder network with Convolutional Capsule Encoder (called 3DConvCaps) to learn lower-level features (short-range attention) with convolutional layers while modeling the higher-level features (long-range dependence) with capsule layers. Our experiments on multiple datasets including iSeg-2017, Hippocampus, and Cardiac demonstrate that our 3D 3DConvCaps network considerably outperforms previous capsule networks and 3D-UNets. We further conduct ablation studies of network efficiency and segmentation performance under various configurations of convolution layers and capsule layers at both contracting and expanding paths. ",
    "url": "https://arxiv.org/abs/2205.09299",
    "authors": [
      "Minh Tran",
      "Viet-Khoa Vo-Ho",
      "Ngan T.H. Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.09307",
    "title": "Support-set based Multi-modal Representation Enhancement for Video  Captioning",
    "abstract": "Video captioning is a challenging task that necessitates a thorough comprehension of visual scenes. Existing methods follow a typical one-to-one mapping, which concentrates on a limited sample space while ignoring the intrinsic semantic associations between samples, resulting in rigid and uninformative expressions. To address this issue, we propose a novel and flexible framework, namely Support-set based Multi-modal Representation Enhancement (SMRE) model, to mine rich information in a semantic subspace shared between samples. Specifically, we propose a Support-set Construction (SC) module to construct a support-set to learn underlying connections between samples and obtain semantic-related visual elements. During this process, we design a Semantic Space Transformation (SST) module to constrain relative distance and administrate multi-modal interactions in a self-supervised way. Extensive experiments on MSVD and MSR-VTT datasets demonstrate that our SMRE achieves state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2205.09307",
    "authors": [
      "Xiaoya Chen",
      "Jingkuan Song",
      "Pengpeng Zeng",
      "Lianli Gao",
      "Heng Tao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.09310",
    "title": "Mitigating Neural Network Overconfidence with Logit Normalization",
    "abstract": "Detecting out-of-distribution inputs is critical for safe deployment of machine learning models in the real world. However, neural networks are known to suffer from the overconfidence issue, where they produce abnormally high confidence for both in- and out-of-distribution inputs. In this work, we show that this issue can be mitigated through Logit Normalization (LogitNorm) -- a simple fix to the cross-entropy loss -- by enforcing a constant vector norm on the logits in training. Our method is motivated by the analysis that the norm of the logit keeps increasing during training, leading to overconfident output. Our key idea behind LogitNorm is thus to decouple the influence of output's norm during network optimization. Trained with LogitNorm, neural networks produce highly distinguishable confidence scores between in- and out-of-distribution data. Extensive experiments demonstrate the superiority of LogitNorm, reducing the average FPR95 by up to 42.30% on common benchmarks. ",
    "url": "https://arxiv.org/abs/2205.09310",
    "authors": [
      "Hongxin Wei",
      "Renchunzi Xie",
      "Hao Cheng",
      "Lei Feng",
      "Bo An",
      "Yixuan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09314",
    "title": "Target-Guided Dialogue Response Generation Using Commonsense and Data  Augmentation",
    "abstract": "Target-guided response generation enables dialogue systems to smoothly transition a conversation from a dialogue context toward a target sentence. Such control is useful for designing dialogue systems that direct a conversation toward specific goals, such as creating non-obtrusive recommendations or introducing new topics in the conversation. In this paper, we introduce a new technique for target-guided response generation, which first finds a bridging path of commonsense knowledge concepts between the source and the target, and then uses the identified bridging path to generate transition responses. Additionally, we propose techniques to re-purpose existing dialogue datasets for target-guided generation. Experiments reveal that the proposed techniques outperform various baselines on this task. Finally, we observe that the existing automated metrics for this task correlate poorly with human judgement ratings. We propose a novel evaluation metric that we demonstrate is more reliable for target-guided response evaluation. Our work generally enables dialogue system designers to exercise more control over the conversations that their systems produce. ",
    "url": "https://arxiv.org/abs/2205.09314",
    "authors": [
      "Prakhar Gupta",
      "Harsh Jhamtani",
      "Jeffrey P. Bigham"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.09330",
    "title": "CHARLES: Channel-Quality-Adaptive Over-the-Air Federated Learning over  Wireless Networks",
    "abstract": "Over-the-air federated learning (OTA-FL) has emerged as an efficient mechanism that exploits the superposition property of the wireless medium and performs model aggregation for federated learning in the air. OTA-FL is naturally sensitive to wireless channel fading, which could significantly diminish its learning accuracy. To address this challenge, in this paper, we propose an OTA-FL algorithm called CHARLES (channel-quality-aware over-the-air local estimating and scaling). Our CHARLES algorithm performs channel state information (CSI) estimation and adaptive scaling to mitigate the impacts of wireless channel fading. We establish the theoretical convergence rate performance of CHARLES and analyze the impacts of CSI error on the convergence of CHARLES. We show that the adaptive channel inversion scaling scheme in CHARLES is robust under imperfect CSI scenarios. We also demonstrate through numerical results that CHARLES outperforms existing OTA-FL algorithms with heterogeneous data under imperfect CSI. ",
    "url": "https://arxiv.org/abs/2205.09330",
    "authors": [
      "Jiayu Mao",
      "Haibo Yang",
      "Peiwen Qiu",
      "Jia Liu",
      "Aylin Yener"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.09332",
    "title": "Accelerated Training of Physics Informed Neural Networks (PINNs) using  Meshless Discretizations",
    "abstract": "We present a new technique for the accelerated training of physics-informed neural networks (PINNs): discretely-trained PINNs (DT-PINNs). The repeated computation of partial derivative terms in the PINN loss functions via automatic differentiation during training is known to be computationally expensive, especially for higher-order derivatives. DT-PINNs are trained by replacing these exact spatial derivatives with high-order accurate numerical discretizations computed using meshless radial basis function-finite differences (RBF-FD) and applied via sparse-matrix vector multiplication. The use of RBF-FD allows for DT-PINNs to be trained even on point cloud samples placed on irregular domain geometries. Additionally, though traditional PINNs (vanilla-PINNs) are typically stored and trained in 32-bit floating-point (fp32) on the GPU, we show that for DT-PINNs, using fp64 on the GPU leads to significantly faster training times than fp32 vanilla-PINNs with comparable accuracy. We demonstrate the efficiency and accuracy of DT-PINNs via a series of experiments. First, we explore the effect of network depth on both numerical and automatic differentiation of a neural network with random weights and show that RBF-FD approximations of third-order accuracy and above are more efficient while being sufficiently accurate. We then compare the DT-PINNs to vanilla-PINNs on both linear and nonlinear Poisson equations and show that DT-PINNs achieve similar losses with 2-4x faster training times on a consumer GPU. Finally, we also demonstrate that similar results can be obtained for the PINN solution to the heat equation (a space-time problem) by discretizing the spatial derivatives using RBF-FD and using automatic differentiation for the temporal derivative. Our results show that fp64 DT-PINNs offer a superior cost-accuracy profile to fp32 vanilla-PINNs. ",
    "url": "https://arxiv.org/abs/2205.09332",
    "authors": [
      "Ramansh Sharma",
      "Varun Shankar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09335",
    "title": "A Simple Yet Effective SVD-GCN for Directed Graphs",
    "abstract": "In this paper, we propose a simple yet effective graph neural network for directed graphs (digraph) based on the classic Singular Value Decomposition (SVD), named SVD-GCN. The new graph neural network is built upon the graph SVD-framelet to better decompose graph signals on the SVD ``frequency'' bands. Further the new framelet SVD-GCN is also scaled up for larger scale graphs via using Chebyshev polynomial approximation. Through empirical experiments conducted on several node classification datasets, we have found that SVD-GCN has remarkable improvements in a variety of graph node learning tasks and it outperforms GCN and many other state-of-the-art graph neural networks for digraphs. Moreover, we empirically demonstate that the SVD-GCN has great denoising capability and robustness to high level graph data attacks. The theoretical and experimental results prove that the SVD-GCN is effective on a variant of graph datasets, meanwhile maintaining stable and even better performance than the state-of-the-arts. ",
    "url": "https://arxiv.org/abs/2205.09335",
    "authors": [
      "Chunya Zou",
      "Andi Han",
      "Lequan Lin",
      "Junbin Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.09348",
    "title": "Analyzing Echo-state Networks Using Fractal Dimension",
    "abstract": "This work joins aspects of reservoir optimization, information-theoretic optimal encoding, and at its center fractal analysis. We build on the observation that, due to the recursive nature of recurrent neural networks, input sequences appear as fractal patterns in their hidden state representation. These patterns have a fractal dimension that is lower than the number of units in the reservoir. We show potential usage of this fractal dimension with regard to optimization of recurrent neural network initialization. We connect the idea of `ideal' reservoirs to lossless optimal encoding using arithmetic encoders. Our investigation suggests that the fractal dimension of the mapping from input to hidden state shall be close to the number of units in the network. This connection between fractal dimension and network connectivity is an interesting new direction for recurrent neural network initialization and reservoir computing. ",
    "url": "https://arxiv.org/abs/2205.09348",
    "authors": [
      "Norbert Michael Mayer",
      "Oliver Obst"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.09350",
    "title": "Cross-lingual Inflection as a Data Augmentation Method for Parsing",
    "abstract": "We propose a morphology-based method for low-resource (LR) dependency parsing. We train a morphological inflector for target LR languages, and apply it to related rich-resource (RR) treebanks to create cross-lingual (x-inflected) treebanks that resemble the target LR language. We use such inflected treebanks to train parsers in zero- (training on x-inflected treebanks) and few-shot (training on x-inflected and target language treebanks) setups. The results show that the method sometimes improves the baselines, but not consistently. ",
    "url": "https://arxiv.org/abs/2205.09350",
    "authors": [
      "Alberto Mu\u00f1oz Ortiz",
      "Carlos G\u00f3mez-Rodr\u00edguez",
      "David Vilares"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.09351",
    "title": "Mip-NeRF RGB-D: Depth Assisted Fast Neural Radiance Fields",
    "abstract": "Neural scene representations, such as neural radiance fields (NeRF), are based on training a multilayer perceptron (MLP) using a set of color images with known poses. An increasing number of devices now produce RGB-D information, which has been shown to be very important for a wide range of tasks. Therefore, the aim of this paper is to investigate what improvements can be made to these promising implicit representations by incorporating depth information with the color images. In particular, the recently proposed Mip-NeRF approach, which uses conical frustums instead of rays for volume rendering, allows one to account for the varying area of a pixel with distance from the camera center. The proposed method additionally models depth uncertainty. This allows to address major limitations of NeRF-based approaches including improving the accuracy of geometry, reduced artifacts, faster training time, and shortened prediction time. Experiments are performed on well-known benchmark scenes, and comparisons show improved accuracy in scene geometry and photometric reconstruction, while reducing the training time by 3 - 5 times. ",
    "url": "https://arxiv.org/abs/2205.09351",
    "authors": [
      "Arnab Dey",
      "Yassine Ahmine",
      "Andrew I. Comport"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.09353",
    "title": "Physics Informed LSTM Network for Flexibility Identification in  Evaporative Cooling Systems",
    "abstract": "In energy intensive industrial systems, an evaporative cooling process may introduce operational flexibility. Such flexibility refers to a systems ability to deviate from its scheduled energy consumption. Identifying the flexibility, and therefore, designing control that ensures efficient and reliable operation presents a great challenge due to the inherently complex dynamics of industrial systems. Recently, machine learning models have attracted attention for identifying flexibility, due to their ability to model complex nonlinear behavior. This research presents machine learning based methods that integrate system dynamics into the machine learning models (e.g., Neural Networks) for better adherence to physical constraints. We define and evaluate physics informed long-short term memory networks (PhyLSTM) and physics informed neural networks (PhyNN) for the identification of flexibility in the evaporative cooling process. These physics informed networks approximate the time-dependent relationship between control input and system response while enforcing the dynamics of the process in the neural network architecture. Our proposed PhyLSTM provides less than 2% system response estimation error, converges in less than half iterations compared to a baseline Neural Network (NN), and accurately estimates the defined flexibility metrics. We include a detailed analysis of the impact of training data size on the performance and optimization of our proposed models. ",
    "url": "https://arxiv.org/abs/2205.09353",
    "authors": [
      "Manu Lahariya",
      "Farzaneh Karami",
      "Chris Develder",
      "Guillaume Crevecoeur"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.09362",
    "title": "Sparse Adversarial Attack in Multi-agent Reinforcement Learning",
    "abstract": "Cooperative multi-agent reinforcement learning (cMARL) has many real applications, but the policy trained by existing cMARL algorithms is not robust enough when deployed. There exist also many methods about adversarial attacks on the RL system, which implies that the RL system can suffer from adversarial attacks, but most of them focused on single agent RL. In this paper, we propose a \\textit{sparse adversarial attack} on cMARL systems. We use (MA)RL with regularization to train the attack policy. Our experiments show that the policy trained by the current cMARL algorithm can obtain poor performance when only one or a few agents in the team (e.g., 1 of 8 or 5 of 25) were attacked at a few timesteps (e.g., attack 3 of total 40 timesteps). ",
    "url": "https://arxiv.org/abs/2205.09362",
    "authors": [
      "Yizheng Hu",
      "Zhihua Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.09370",
    "title": "TC-Driver: Trajectory Conditioned Driving for Robust Autonomous Racing  -- A Reinforcement Learning Approach",
    "abstract": "Autonomous racing is becoming popular for academic and industry researchers as a test for general autonomous driving by pushing perception, planning, and control algorithms to their limits. While traditional control methods such as MPC are capable of generating an optimal control sequence at the edge of the vehicles physical controllability, these methods are sensitive to the accuracy of the modeling parameters. This paper presents TC-Driver, a RL approach for robust control in autonomous racing. In particular, the TC-Driver agent is conditioned by a trajectory generated by any arbitrary traditional high-level planner. The proposed TC-Driver addresses the tire parameter modeling inaccuracies by exploiting the heuristic nature of RL while leveraging the reliability of traditional planning methods in a hierarchical control structure. We train the agent under varying tire conditions, allowing it to generalize to different model parameters, aiming to increase the racing capabilities of the system in practice. The proposed RL method outperforms a non-learning-based MPC with a 2.7 lower crash ratio in a model mismatch setting, underlining robustness to parameter discrepancies. In addition, the average RL inference duration is 0.25 ms compared to the average MPC solving time of 11.5 ms, yielding a nearly 40-fold speedup, allowing for complex control deployment in computationally constrained devices. Lastly, we show that the frequently utilized end-to-end RL architecture, as a control policy directly learned from sensory input, is not well suited to model mismatch robustness nor track generalization. Our realistic simulations show that TC-Driver achieves a 6.7 and 3-fold lower crash ratio under model mismatch and track generalization settings, while simultaneously achieving lower lap times than an end-to-end approach, demonstrating the viability of TC-driver to robust autonomous racing. ",
    "url": "https://arxiv.org/abs/2205.09370",
    "authors": [
      "Edoardo Ghignone",
      "Nicolas Baumann",
      "Mike Boss",
      "Michele Magno"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.09373",
    "title": "Diversity Matters: Fully Exploiting Depth Clues for Reliable Monocular  3D Object Detection",
    "abstract": "As an inherently ill-posed problem, depth estimation from single images is the most challenging part of monocular 3D object detection (M3OD). Many existing methods rely on preconceived assumptions to bridge the missing spatial information in monocular images, and predict a sole depth value for every object of interest. However, these assumptions do not always hold in practical applications. To tackle this problem, we propose a depth solving system that fully explores the visual clues from the subtasks in M3OD and generates multiple estimations for the depth of each target. Since the depth estimations rely on different assumptions in essence, they present diverse distributions. Even if some assumptions collapse, the estimations established on the remaining assumptions are still reliable. In addition, we develop a depth selection and combination strategy. This strategy is able to remove abnormal estimations caused by collapsed assumptions, and adaptively combine the remaining estimations into a single one. In this way, our depth solving system becomes more precise and robust. Exploiting the clues from multiple subtasks of M3OD and without introducing any extra information, our method surpasses the current best method by more than 20% relatively on the Moderate level of test split in the KITTI 3D object detection benchmark, while still maintaining real-time efficiency. ",
    "url": "https://arxiv.org/abs/2205.09373",
    "authors": [
      "Zhuoling Li",
      "Zhan Qu",
      "Yang Zhou",
      "Jianzhuang Liu",
      "Haoqian Wang",
      "Lihui Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.09378",
    "title": "Sum-Rate Optimal Relay Selection and Power Control in Multi-Hop Networks",
    "abstract": "In this paper, we focus on the achievable sum-rate optimization problem of a multi-user, multi-hop relay network. We analyze the joint relay selection and power control in the presence of interference such that the achievable sum-rate is maximized. First, we evaluate the achievable sum-rate under five relay selection strategies when the transmit power is fixed. We show that the dynamic programming based max-min relay selection with the objective of maximizing the minimum signal-to-noise-ratio results in the highest achievable sum-rate gain for larger networks. Next, we combine the relay selection problem using the max-min relay selection and the power control problem using a tight lower bound approximation and propose a novel iterative algorithm, which maximizes the achievable sum-rate. We also provide a comprehensive comparison of the proposed algorithm with respect to existing resource allocation techniques, and observe that our proposed algorithm provides significant sum-rate gains. Finally, we prove that for the special case of two-user networks, binary power allocation is optimum for at least two transmitting nodes. Extensive numerical examples are provided to illustrate the accuracy of our results. ",
    "url": "https://arxiv.org/abs/2205.09378",
    "authors": [
      "Shalanika Dayarathna",
      "Rajitha Senanayake",
      "Jamie Evans"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.09389",
    "title": "Simplifying Node Classification on Heterophilous Graphs with Compatible  Label Propagation",
    "abstract": "Graph Neural Networks (GNNs) have been predominant for graph learning tasks; however, recent studies showed that a well-known graph algorithm, Label Propagation (LP), combined with a shallow neural network can achieve comparable performance to GNNs in semi-supervised node classification on graphs with high homophily. In this paper, we show that this approach falls short on graphs with low homophily, where nodes often connect to the nodes of the opposite classes. To overcome this, we carefully design a combination of a base predictor with LP algorithm that enjoys a closed-form solution as well as convergence guarantees. Our algorithm first learns the class compatibility matrix and then aggregates label predictions using LP algorithm weighted by class compatibilities. On a wide variety of benchmarks, we show that our approach achieves the leading performance on graphs with various levels of homophily. Meanwhile, it has orders of magnitude fewer parameters and requires less execution time. Empirical evaluations demonstrate that simple adaptations of LP can be competitive in semi-supervised node classification in both homophily and heterophily regimes. ",
    "url": "https://arxiv.org/abs/2205.09389",
    "authors": [
      "Zhiqiang Zhong",
      "Sergey Ivanov",
      "Jun Pang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.09391",
    "title": "Transformers as Neural Augmentors: Class Conditional Sentence Generation  via Variational Bayes",
    "abstract": "Data augmentation methods for Natural Language Processing tasks are explored in recent years, however they are limited and it is hard to capture the diversity on sentence level. Besides, it is not always possible to perform data augmentation on supervised tasks. To address those problems, we propose a neural data augmentation method, which is a combination of Conditional Variational Autoencoder and encoder-decoder Transformer model. While encoding and decoding the input sentence, our model captures the syntactic and semantic representation of the input language with its class condition. Following the developments in the past years on pre-trained language models, we train and evaluate our models on several benchmarks to strengthen the downstream tasks. We compare our method with 3 different augmentation techniques. The presented results show that, our model increases the performance of current models compared to other data augmentation techniques with a small amount of computation power. ",
    "url": "https://arxiv.org/abs/2205.09391",
    "authors": [
      "M. \u015eafak Bilici",
      "Mehmet Fatih Amasyali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09418",
    "title": "Leveraging Dynamic Objects for Relative Localization COrrection in a  Connected Autonomous Vehicle Network",
    "abstract": "High-accurate localization is crucial for the safety and reliability of autonomous driving, especially for the information fusion of collective perception that aims to further improve road safety by sharing information in a communication network of ConnectedAutonomous Vehicles (CAV). In this scenario, small localization errors can impose additional difficulty on fusing the information from different CAVs. In this paper, we propose a RANSAC-based (RANdom SAmple Consensus) method to correct the relative localization errors between two CAVs in order to ease the information fusion among the CAVs. Different from previous LiDAR-based localization algorithms that only take the static environmental information into consideration, this method also leverages the dynamic objects for localization thanks to the real-time data sharing between CAVs. Specifically, in addition to the static objects like poles, fences, and facades, the object centers of the detected dynamic vehicles are also used as keypoints for the matching of two point sets. The experiments on the synthetic dataset COMAP show that the proposed method can greatly decrease the relative localization error between two CAVs to less than 20cmas far as there are enough vehicles and poles are correctly detected by bothCAVs. Besides, our proposed method is also highly efficient in runtime and can be used in real-time scenarios of autonomous driving. ",
    "url": "https://arxiv.org/abs/2205.09418",
    "authors": [
      "Yunshuang Yuan",
      "Monika Sester"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.09422",
    "title": "Inferring extended summary causal graphs from observational time series",
    "abstract": "This study addresses the problem of learning an extended summary causal graph on time series. The algorithms we propose fit within the well-known constraint-based framework for causal discovery and make use of information-theoretic measures to determine (in)dependencies between time series. We first introduce generalizations of the causation entropy measure to any lagged or instantaneous relations, prior to using this measure to construct extended summary causal graphs by adapting two well-known algorithms, namely PC and FCI. The behavior of our methods is illustrated through several experiments run on simulated and real datasets. ",
    "url": "https://arxiv.org/abs/2205.09422",
    "authors": [
      "Charles K. Assaad",
      "Emilie Devijver",
      "Eric Gaussier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.09428",
    "title": "Which bugs are missed in code reviews: An empirical study on SmartSHARK  dataset",
    "abstract": "In pull-based development systems, code reviews and pull request comments play important roles in improving code quality. In such systems, reviewers attempt to carefully check a piece of code by different unit tests. Unfortunately, sometimes they miss bugs in their review of pull requests, which lead to quality degradations of the systems. In other words, disastrous consequences occur when bugs are observed after merging the pull requests. The lack of a concrete understanding of these bugs led us to investigate and categorize them. In this research, we try to identify missed bugs in pull requests of SmartSHARK dataset projects. Our contribution is twofold. First, we hypothesized merged pull requests that have code reviews, code review comments, or pull request comments after merging, may have missed bugs after the code review. We considered these merged pull requests as candidate pull requests having missed bugs. Based on our assumption, we obtained 3,261 candidate pull requests from 77 open-source GitHub projects. After two rounds of restrictive manual analysis, we found 187 bugs missed in 173 pull requests. In the first step, we found 224 buggy pull requests containing missed bugs after merging the pull requests. Secondly, we defined and finalized a taxonomy that is appropriate for the bugs that we found and then found the distribution of bug categories after analysing those pull requests all over again. The categories of missed bugs in pull requests and their distributions are: semantic (51.34%), build (15.5%), analysis checks (9.09%), compatibility (7.49%), concurrency (4.28%), configuration (4.28%), GUI (2.14%), API (2.14%), security (2.14%), and memory (1.6%). ",
    "url": "https://arxiv.org/abs/2205.09428",
    "authors": [
      "F. Khoshnoud",
      "A. Rezaei Nasab",
      "Z. Toudeji",
      "A. Sami"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.09430",
    "title": "Action Conditioned Tactile Prediction: a case study on slip prediction",
    "abstract": "Tactile predictive models can be useful across several robotic manipulation tasks, e.g. robotic pushing, robotic grasping, slip avoidance, and in-hand manipulation. However, available tactile prediction models are mostly studied for image-based tactile sensors and there is no comparison study indicating the best performing models. In this paper, we presented two novel data-driven action-conditioned models for predicting tactile signals during real-world physical robot interaction tasks (1) action condition tactile prediction and (2) action conditioned tactile-video prediction models. We use a magnetic-based tactile sensor that is challenging to analyse and test state-of-the-art predictive models and the only existing bespoke tactile prediction model. We compare the performance of these models with those of our proposed models. We perform the comparison study using our novel tactile enabled dataset containing 51,000 tactile frames of a real-world robotic manipulation task with 11 flat-surfaced household objects. Our experimental results demonstrate the superiority of our proposed tactile prediction models in terms of qualitative, quantitative and slip prediction scores. ",
    "url": "https://arxiv.org/abs/2205.09430",
    "authors": [
      "Willow Mandil",
      "Kiyanoush Nazari",
      "Amir Ghalamzan E"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09448",
    "title": "Image Augmentation Based Momentum Memory Intrinsic Reward for Sparse  Reward Visual Scenes",
    "abstract": "Many scenes in real life can be abstracted to the sparse reward visual scenes, where it is difficult for an agent to tackle the task under the condition of only accepting images and sparse rewards. We propose to decompose this problem into two sub-problems: the visual representation and the sparse reward. To address them, a novel framework IAMMIR combining the self-supervised representation learning with the intrinsic motivation is presented. For visual representation, a representation driven by a combination of the imageaugmented forward dynamics and the reward is acquired. For sparse rewards, a new type of intrinsic reward is designed, the Momentum Memory Intrinsic Reward (MMIR). It utilizes the difference of the outputs from the current model (online network) and the historical model (target network) to present the agent's state familiarity. Our method is evaluated on the visual navigation task with sparse rewards in Vizdoom. Experiments demonstrate that our method achieves the state of the art performance in sample efficiency, at least 2 times faster than the existing methods reaching 100% success rate. ",
    "url": "https://arxiv.org/abs/2205.09448",
    "authors": [
      "Zheng Fang",
      "Biao Zhao",
      "Guizhong Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.09452",
    "title": "Learning-based AC-OPF Solvers on Realistic Network and Realistic Loads",
    "abstract": "Deep learning approaches for the Alternating Current-Optimal Power Flow (AC-OPF) problem are under active research in recent years. A common shortcoming in this area of research is the lack of a dataset that includes both a realistic power network topology and the corresponding realistic loads. To address this issue, we construct an AC-OPF formulation-ready dataset called TAS-97 that contains realistic network information and realistic bus loads from Tasmania's electricity network. We found that the realistic loads in Tasmania are correlated between buses and they show signs of an underlying multivariate normal distribution. Feasibility-optimized end-to-end deep neural network models are trained and tested on the constructed dataset. Trained on samples with bus loads generated from a fitted multivariate normal distribution, our learning-based AC-OPF solver achieves 0.13% cost optimality gap, 99.73% feasibility rate, and 38.62 times of speedup on realistic testing samples when compared to PYPOWER. ",
    "url": "https://arxiv.org/abs/2205.09452",
    "authors": [
      "Tsun Ho Aaron Cheung",
      "Min Zhou",
      "Minghua Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.09456",
    "title": "Insights on Neural Representations for End-to-End Speech Recognition",
    "abstract": "End-to-end automatic speech recognition (ASR) models aim to learn a generalised speech representation. However, there are limited tools available to understand the internal functions and the effect of hierarchical dependencies within the model architecture. It is crucial to understand the correlations between the layer-wise representations, to derive insights on the relationship between neural representations and performance. Previous investigations of network similarities using correlation analysis techniques have not been explored for End-to-End ASR models. This paper analyses and explores the internal dynamics between layers during training with CNN, LSTM and Transformer based approaches using Canonical correlation analysis (CCA) and centered kernel alignment (CKA) for the experiments. It was found that neural representations within CNN layers exhibit hierarchical correlation dependencies as layer depth increases but this is mostly limited to cases where neural representation correlates more closely. This behaviour is not observed in LSTM architecture, however there is a bottom-up pattern observed across the training process, while Transformer encoder layers exhibit irregular coefficiency correlation as neural depth increases. Altogether, these results provide new insights into the role that neural architectures have upon speech recognition performance. More specifically, these techniques can be used as indicators to build better performing speech recognition models. ",
    "url": "https://arxiv.org/abs/2205.09456",
    "authors": [
      "Anna Ollerenshaw",
      "Md Asif Jalal",
      "Thomas Hain"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.09459",
    "title": "Neural Network Architecture Beyond Width and Depth",
    "abstract": "This paper proposes a new neural network architecture by introducing an additional dimension called height beyond width and depth. Neural network architectures with height, width, and depth as hyperparameters are called three-dimensional architectures. It is shown that neural networks with three-dimensional architectures are significantly more expressive than the ones with two-dimensional architectures (those with only width and depth as hyperparameters), e.g., standard fully connected networks. The new network architecture is constructed recursively via a nested structure, and hence we call a network with the new architecture nested network (NestNet). A NestNet of height $s$ is built with each hidden neuron activated by a NestNet of height $\\le s-1$. When $s=1$, a NestNet degenerates to a standard network with a two-dimensional architecture. It is proved by construction that height-$s$ ReLU NestNets with $\\mathcal{O}(n)$ parameters can approximate Lipschitz continuous functions on $[0,1]^d$ with an error $\\mathcal{O}(n^{-(s+1)/d})$, while the optimal approximation error of standard ReLU networks with $\\mathcal{O}(n)$ parameters is $\\mathcal{O}(n^{-2/d})$. Furthermore, such a result is extended to generic continuous functions on $[0,1]^d$ with the approximation error characterized by the modulus of continuity. Finally, a numerical example is provided to explore the advantages of the super approximation power of ReLU NestNets. ",
    "url": "https://arxiv.org/abs/2205.09459",
    "authors": [
      "Zuowei Shen",
      "Haizhao Yang",
      "Shijun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.09465",
    "title": "Parallel bi-objective evolutionary algorithms for scalable feature  subset selection via migration strategy under Spark",
    "abstract": "Feature subset selection (FSS) for classification is inherently a bi-objective optimization problem, where the task is to obtain a feature subset which yields the maximum possible area under the receiver operator characteristic curve (AUC) with minimum cardinality of the feature subset. In todays world, a humungous amount of data is generated in all activities of humans. To mine such voluminous data, which is often high-dimensional, there is a need to develop parallel and scalable frameworks. In the first-of-its-kind study, we propose and develop an iterative MapReduce-based framework for bi-objective evolutionary algorithms (EAs) based wrappers under Apache spark with the migration strategy. In order to accomplish this, we parallelized the non-dominated sorting based algorithms namely non dominated sorting algorithm (NSGA-II), and non-dominated sorting particle swarm optimization (NSPSO), also the decomposition-based algorithm, namely the multi-objective evolutionary algorithm based on decomposition (MOEA-D), and named them P-NSGA-II-IS, P-NSPSO-IS, P-MOEA-D-IS, respectively. We proposed a modified MOEA-D by incorporating the non-dominated sorting principle while parallelizing it. Throughout the study, AUC is computed by logistic regression (LR). We test the effectiveness of the proposed methodology on various datasets. It is noteworthy that the P-NSGA-II turns out to be statistically significant by being in the top 2 positions on most datasets. We also reported the empirical attainment plots, speed up analysis, and mean AUC obtained by the most repeated feature subset and the least cardinal feature subset with the highest AUC, and diversity analysis using hypervolume. ",
    "url": "https://arxiv.org/abs/2205.09465",
    "authors": [
      "Yelleti Vivek",
      "Vadlamani Ravi",
      "P. Radha Krishna"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.09479",
    "title": "Neural ODEs with Irregular and Noisy Data",
    "abstract": "Measurement noise is an integral part while collecting data of a physical process. Thus, noise removal is necessary to draw conclusions from these data, and it often becomes essential to construct dynamical models using these data. We discuss a methodology to learn differential equation(s) using noisy and irregular sampled measurements. In our methodology, the main innovation can be seen in the integration of deep neural networks with the neural ordinary differential equations (ODEs) approach. Precisely, we aim at learning a neural network that provides (approximately) an implicit representation of the data and an additional neural network that models the vector fields of the dependent variables. We combine these two networks by constraining using neural ODEs. The proposed framework to learn a model describing the vector field is highly effective under noisy measurements. The approach can handle scenarios where dependent variables are not available at the same temporal grid. Moreover, a particular structure, e.g., second-order with respect to time, can easily be incorporated. We demonstrate the effectiveness of the proposed method for learning models using data obtained from various differential equations and present a comparison with the neural ODE method that does not make any special treatment to noise. ",
    "url": "https://arxiv.org/abs/2205.09479",
    "authors": [
      "Pawan Goyal",
      "Peter Benner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2205.09489",
    "title": "Spatial Autoregressive Coding for Graph Neural Recommendation",
    "abstract": "Graph embedding methods including traditional shallow models and deep Graph Neural Networks (GNNs) have led to promising applications in recommendation. Nevertheless, shallow models especially random-walk-based algorithms fail to adequately exploit neighbor proximity in sampled subgraphs or sequences due to their optimization paradigm. GNN-based algorithms suffer from the insufficient utilization of high-order information and easily cause over-smoothing problems when stacking too much layers, which may deteriorate the recommendations of low-degree (long-tail) items, limiting the expressiveness and scalability. In this paper, we propose a novel framework SAC, namely Spatial Autoregressive Coding, to solve the above problems in a unified way. To adequately leverage neighbor proximity and high-order information, we design a novel spatial autoregressive paradigm. Specifically, we first randomly mask multi-hop neighbors and embed the target node by integrating all other surrounding neighbors with an explicit multi-hop attention. Then we reinforce the model to learn a neighbor-predictive coding for the target node by contrasting the coding and the masked neighbors' embedding, equipped with a new hard negative sampling strategy. To learn the minimal sufficient representation for the target-to-neighbor prediction task and remove the redundancy of neighbors, we devise Neighbor Information Bottleneck by maximizing the mutual information between target predictive coding and the masked neighbors' embedding, and simultaneously constraining those between the coding and surrounding neighbors' embedding. Experimental results on both public recommendation datasets and a real scenario web-scale dataset Douyin-Friend-Recommendation demonstrate the superiority of SAC compared with state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2205.09489",
    "authors": [
      "Jiayi Zheng",
      "Ling Yang",
      "Heyuan Wang",
      "Cheng Yang",
      "Yinghong Li",
      "Xiaowei Hu",
      "Shenda Hong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09497",
    "title": "Psychiatric Scale Guided Risky Post Screening for Early Detection of  Depression",
    "abstract": "Depression is a prominent health challenge to the world, and early risk detection (ERD) of depression from online posts can be a promising technique for combating the threat. Early depression detection faces the challenge of efficiently tackling streaming data, balancing the tradeoff between timeliness, accuracy and explainability. To tackle these challenges, we propose a psychiatric scale guided risky post screening method that can capture risky posts related to the dimensions defined in clinical depression scales, and providing interpretable diagnostic basis. A Hierarchical Attentional Network equipped with BERT (HAN-BERT) is proposed to further advance explainable predictions. For ERD, we propose an online algorithm based on an evolving queue of risky posts that can significantly reduce the number of model inferences to boost efficiency. Experiments show that our method outperforms the competitive feature-based and neural models under conventional depression detection settings, and achieves simultaneous improvement in both efficacy and efficiency for ERD. ",
    "url": "https://arxiv.org/abs/2205.09497",
    "authors": [
      "Zhiling Zhang",
      "Siyuan Chen",
      "Mengyue Wu",
      "Kenny Q. Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.09518",
    "title": "Enhancing the Transferability of Adversarial Examples via a Few Queries",
    "abstract": "Due to the vulnerability of deep neural networks, the black-box attack has drawn great attention from the community. Though transferable priors decrease the query number of the black-box query attacks in recent efforts, the average number of queries is still larger than 100, which is easily affected by the number of queries limit policy. In this work, we propose a novel method called query prior-based method to enhance the family of fast gradient sign methods and improve their attack transferability by using a few queries. Specifically, for the untargeted attack, we find that the successful attacked adversarial examples prefer to be classified as the wrong categories with higher probability by the victim model. Therefore, the weighted augmented cross-entropy loss is proposed to reduce the gradient angle between the surrogate model and the victim model for enhancing the transferability of the adversarial examples. Theoretical analysis and extensive experiments demonstrate that our method could significantly improve the transferability of gradient-based adversarial attacks on CIFAR10/100 and ImageNet and outperform the black-box query attack with the same few queries. ",
    "url": "https://arxiv.org/abs/2205.09518",
    "authors": [
      "Xiangyuan Yang",
      "Jie Lin",
      "Hanlin Zhang",
      "Xinyu Yang",
      "Peng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.09522",
    "title": "Defending Against Adversarial Attacks by Energy Storage Facility",
    "abstract": "Adversarial attacks on data-driven algorithms applied in pow-er system will be a new type of threat on grid security. Litera-ture has demonstrated the adversarial attack on deep-neural network can significantly misleading the load forecast of a power system. However, it is unclear how the new type of at-tack impact on the operation of grid system. In this research, we manifest that the adversarial algorithm attack induces a significant cost-increase risk which will be exacerbated by the growing penetration of intermittent renewable energy. In Texas, a 5% adversarial attack can increase the total generation cost by 17% in a quarter, which account for around 20 million dollars. When wind-energy penetration increases to over 40%, the 5% adver-sarial attack will inflate the generation cost by 23%. Our re-search discovers a novel approach of defending against the adversarial attack: investing on energy-storage system. All current literature focuses on developing algorithm to defending against adversarial attack. We are the first research revealing the capability of using facility in physical system to defending against the adversarial algorithm attack in a system of Internet of Thing, such as smart grid system. ",
    "url": "https://arxiv.org/abs/2205.09522",
    "authors": [
      "Jiawei Li",
      "Jianxiao Wang",
      "Lin Chen",
      "Yang Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.09524",
    "title": "Security Analysis of DeFi: Vulnerabilities, Attacks and Advances",
    "abstract": "Decentralized finance (DeFi) in Ethereum is a financial ecosystem built on the blockchain that has locked over 200 billion USD until April 2022. All transaction information is transparent and open when transacting through the DeFi protocol, which has led to a series of attacks. Several studies have attempted to optimize it from both economic and technical perspectives. However, few works analyze the vulnerabilities and optimizations of the entire DeFi system. In this paper, we first systematically analyze vulnerabilities related to DeFi in Ethereum at several levels, then we investigate real-world attacks. Finally, we summarize the achievements of DeFi optimization and provide some future directions. ",
    "url": "https://arxiv.org/abs/2205.09524",
    "authors": [
      "Wenkai Li",
      "Jiuyang Bu",
      "Xiaoqi Li",
      "Xianyi Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.09539",
    "title": "Data-driven prediction of Air Traffic Controllers reactions to resolving  conflicts",
    "abstract": "With the aim to enhance automation in conflict detection and resolution (CD&R) tasks in the Air Traffic Management domain, in this paper we propose deep learning techniques (DL) that can learn models of Air Traffic Controllers' (ATCO) reactions in resolving conflicts that can violate separation minimum constraints among aircraft trajectories: This implies learning when the ATCO will react towards resolving a conflict, and how he/she will react. Timely reactions, to which this paper aims, focus on when do reactions happen, aiming to predict the trajectory points, as the trajectory evolves, that the ATCO issues a conflict resolution action, while also predicting the type of resolution action (if any). Towards this goal, the paper formulates the ATCO reactions prediction problem for CD&R, and presents DL methods that can model ATCO timely reactions and evaluates these methods in real-world data sets, showing their efficacy in prediction with very high accuracy. ",
    "url": "https://arxiv.org/abs/2205.09539",
    "authors": [
      "Alevizos Bastas",
      "George A. Vouros"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09556",
    "title": "Neural Networks in Imandra: Matrix Representation as a Verification  Choice",
    "abstract": "The demand for formal verification tools for neural networks has increased as neural networks have been deployed in a growing number of safety-critical applications. Matrices are a data structure essential to formalising neural networks. Functional programming languages encourage diverse approaches to matrix definitions. This feature has already been successfully exploited in different applications. The question we ask is whether, and how, these ideas can be applied in neural network verification. A functional programming language Imandra combines the syntax of a functional programming language and the power of an automated theorem prover. Using these two key features of Imandra, we explore how different implementations of matrices can influence automation of neural network verification. ",
    "url": "https://arxiv.org/abs/2205.09556",
    "authors": [
      "Remi Desmartin",
      "Grant Passmore",
      "Ekaterina Komendantskaya"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2205.09564",
    "title": "Automatic Spoken Language Identification using a Time-Delay Neural  Network",
    "abstract": "Closed-set spoken language identification is the task of recognizing the language being spoken in a recorded audio clip from a set of known languages. In this study, a language identification system was built and trained to distinguish between Arabic, Spanish, French, and Turkish based on nothing more than recorded speech. A pre-existing multilingual dataset was used to train a series of acoustic models based on the Tedlium TDNN model to perform automatic speech recognition. The system was provided with a custom multilingual language model and a specialized pronunciation lexicon with language names prepended to phones. The trained model was used to generate phone alignments to test data from all four languages, and languages were predicted based on a voting scheme choosing the most common language prepend in an utterance. Accuracy was measured by comparing predicted languages to known languages, and was determined to be very high in identifying Spanish and Arabic, and somewhat lower in identifying Turkish and French. ",
    "url": "https://arxiv.org/abs/2205.09564",
    "authors": [
      "Benjamin Kepecs",
      "Homayoon Beigi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.09573",
    "title": "Jacobian Granger Causal Neural Networks for Analysis of Stationary and  Nonstationary Data",
    "abstract": "Granger causality is a commonly used method for uncovering information flow and dependencies in a time series. Here we introduce JGC (Jacobian Granger Causality), a neural network-based approach to Granger causality using the Jacobian as a measure of variable importance, and propose a thresholding procedure for inferring Granger causal variables using this measure. The resulting approach performs consistently well compared to other approaches in identifying Granger causal variables, the associated time lags, as well as interaction signs. Lastly, through the inclusion of a time variable, we show that this approach is able to learn the temporal dependencies for nonstationary systems whose Granger causal structures change in time. ",
    "url": "https://arxiv.org/abs/2205.09573",
    "authors": [
      "Suryadi",
      "Yew-Soon Ong",
      "Lock Yue Chew"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09575",
    "title": "Learning Graph Structure from Convolutional Mixtures",
    "abstract": "Machine learning frameworks such as graph neural networks typically rely on a given, fixed graph to exploit relational inductive biases and thus effectively learn from network data. However, when said graphs are (partially) unobserved, noisy, or dynamic, the problem of inferring graph structure from data becomes relevant. In this paper, we postulate a graph convolutional relationship between the observed and latent graphs, and formulate the graph learning task as a network inverse (deconvolution) problem. In lieu of eigendecomposition-based spectral methods or iterative optimization solutions, we unroll and truncate proximal gradient iterations to arrive at a parameterized neural network architecture that we call a Graph Deconvolution Network (GDN). GDNs can learn a distribution of graphs in a supervised fashion, perform link prediction or edge-weight regression tasks by adapting the loss function, and they are inherently inductive. We corroborate GDN's superior graph recovery performance and its generalization to larger graphs using synthetic data in supervised settings. Furthermore, we demonstrate the robustness and representation power of GDNs on real world neuroimaging and social network datasets. ",
    "url": "https://arxiv.org/abs/2205.09575",
    "authors": [
      "Max Wasserman",
      "Saurabh Sihag",
      "Gonzalo Mateos",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.09576",
    "title": "Discovering Dynamic Functional Brain Networks via Spatial and  Channel-wise Attention",
    "abstract": "Using deep learning models to recognize functional brain networks (FBNs) in functional magnetic resonance imaging (fMRI) has been attracting increasing interest recently. However, most existing work focuses on detecting static FBNs from entire fMRI signals, such as correlation-based functional connectivity. Sliding-window is a widely used strategy to capture the dynamics of FBNs, but it is still limited in representing intrinsic functional interactive dynamics at each time step. And the number of FBNs usually need to be set manually. More over, due to the complexity of dynamic interactions in brain, traditional linear and shallow models are insufficient in identifying complex and spatially overlapped FBNs across each time step. In this paper, we propose a novel Spatial and Channel-wise Attention Autoencoder (SCAAE) for discovering FBNs dynamically. The core idea of SCAAE is to apply attention mechanism to FBNs construction. Specifically, we designed two attention modules: 1) spatial-wise attention (SA) module to discover FBNs in the spatial domain and 2) a channel-wise attention (CA) module to weigh the channels for selecting the FBNs automatically. We evaluated our approach on ADHD200 dataset and our results indicate that the proposed SCAAE method can effectively recover the dynamic changes of the FBNs at each fMRI time step, without using sliding windows. More importantly, our proposed hybrid attention modules (SA and CA) do not enforce assumptions of linearity and independence as previous methods, and thus provide a novel approach to better understanding dynamic functional brain networks. ",
    "url": "https://arxiv.org/abs/2205.09576",
    "authors": [
      "Yiheng Liu",
      "Enjie Ge",
      "Mengshen He",
      "Zhengliang Liu",
      "Shijie Zhao",
      "Xintao Hu",
      "Dajiang Zhu",
      "Tianming Liu",
      "Bao Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.09586",
    "title": "On Trace of PGD-Like Adversarial Attacks",
    "abstract": "Adversarial attacks pose safety and security concerns for deep learning applications. Yet largely imperceptible, a strong PGD-like attack may leave strong trace in the adversarial example. Since attack triggers the local linearity of a network, we speculate network behaves in different extents of linearity for benign examples and adversarial examples. Thus, we construct Adversarial Response Characteristics (ARC) features to reflect the model's gradient consistency around the input to indicate the extent of linearity. Under certain conditions, it shows a gradually varying pattern from benign example to adversarial example, as the later leads to Sequel Attack Effect (SAE). ARC feature can be used for informed attack detection (perturbation magnitude is known) with binary classifier, or uninformed attack detection (perturbation magnitude is unknown) with ordinal regression. Due to the uniqueness of SAE to PGD-like attacks, ARC is also capable of inferring other attack details such as loss function, or the ground-truth label as a post-processing defense. Qualitative and quantitative evaluations manifest the effectiveness of ARC feature on CIFAR-10 w/ ResNet-18 and ImageNet w/ ResNet-152 and SwinT-B-IN1K with considerable generalization among PGD-like attacks despite domain shift. Our method is intuitive, light-weighted, non-intrusive, and data-undemanding. ",
    "url": "https://arxiv.org/abs/2205.09586",
    "authors": [
      "Mo Zhou",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.09589",
    "title": "Learning Energy Networks with Generalized Fenchel-Young Losses",
    "abstract": "Energy-based models, a.k.a. energy networks, perform inference by optimizing an energy function, typically parametrized by a neural network. This allows one to capture potentially complex relationships between inputs and outputs. To learn the parameters of the energy function, the solution to that optimization problem is typically fed into a loss function. The key challenge for training energy networks lies in computing loss gradients, as this typically requires argmin/argmax differentiation. In this paper, building upon a generalized notion of conjugate function, which replaces the usual bilinear pairing with a general energy function, we propose generalized Fenchel-Young losses, a natural loss construction for learning energy networks. Our losses enjoy many desirable properties and their gradients can be computed efficiently without argmin/argmax differentiation. We also prove the calibration of their excess risk in the case of linear-concave energies. We demonstrate our losses on multilabel classification and imitation learning tasks. ",
    "url": "https://arxiv.org/abs/2205.09589",
    "authors": [
      "Mathieu Blondel",
      "Felipe Llinares-L\u00f3pez",
      "Robert Dadashi",
      "L\u00e9onard Hussenot",
      "Matthieu Geist"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.09592",
    "title": "Transferable Physical Attack against Object Detection with Separable  Attention",
    "abstract": "Transferable adversarial attack is always in the spotlight since deep learning models have been demonstrated to be vulnerable to adversarial samples. However, existing physical attack methods do not pay enough attention on transferability to unseen models, thus leading to the poor performance of black-box attack.In this paper, we put forward a novel method of generating physically realizable adversarial camouflage to achieve transferable attack against detection models. More specifically, we first introduce multi-scale attention maps based on detection models to capture features of objects with various resolutions. Meanwhile, we adopt a sequence of composite transformations to obtain the averaged attention maps, which could curb model-specific noise in the attention and thus further boost transferability. Unlike the general visualization interpretation methods where model attention should be put on the foreground object as much as possible, we carry out attack on separable attention from the opposite perspective, i.e. suppressing attention of the foreground and enhancing that of the background. Consequently, transferable adversarial camouflage could be yielded efficiently with our novel attention-based loss function. Extensive comparison experiments verify the superiority of our method to state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2205.09592",
    "authors": [
      "Yu Zhang",
      "Zhiqiang Gong",
      "Yichuang Zhang",
      "YongQian Li",
      "Kangcheng Bin",
      "Jiahao Qi",
      "Wei Xue",
      "Ping Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.09607",
    "title": "LAGr: Label Aligned Graphs for Better Systematic Generalization in  Semantic Parsing",
    "abstract": "Semantic parsing is the task of producing structured meaning representations for natural language sentences. Recent research has pointed out that the commonly-used sequence-to-sequence (seq2seq) semantic parsers struggle to generalize systematically, i.e. to handle examples that require recombining known knowledge in novel settings. In this work, we show that better systematic generalization can be achieved by producing the meaning representation directly as a graph and not as a sequence. To this end we propose LAGr (Label Aligned Graphs), a general framework to produce semantic parses by independently predicting node and edge labels for a complete multi-layer input-aligned graph. The strongly-supervised LAGr algorithm requires aligned graphs as inputs, whereas weakly-supervised LAGr infers alignments for originally unaligned target graphs using approximate maximum-a-posteriori inference. Experiments demonstrate that LAGr achieves significant improvements in systematic generalization upon the baseline seq2seq parsers in both strongly- and weakly-supervised settings. ",
    "url": "https://arxiv.org/abs/2205.09607",
    "authors": [
      "Dora Jambor",
      "Dzmitry Bahdanau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.09612",
    "title": "CLCNet: Rethinking of Ensemble Modeling with Classification Confidence  Network",
    "abstract": "In this paper, we propose a Classification Confidence Network (CLCNet) that can determine whether the classification model classifies input samples correctly. It can take a classification result in the form of vector in any dimension, and return a confidence score as output, which represents the probability of an instance being classified correctly. We can utilize CLCNet in a simple cascade structure system consisting of several SOTA (state-of-the-art) classification models, and our experiments show that the system can achieve the following advantages: 1. The system can customize the average computation requirement (FLOPs) per image while inference. 2. Under the same computation requirement, the performance of the system can exceed any model that has identical structure with the model in the system, but different in size. In fact, this is a new type of ensemble modeling. Like general ensemble modeling, it can achieve higher performance than single classification model, yet our system requires much less computation than general ensemble modeling. We have uploaded our code to a github repository: https://github.com/yaoching0/CLCNet-Rethinking-of-Ensemble-Modeling. ",
    "url": "https://arxiv.org/abs/2205.09612",
    "authors": [
      "Yao-Ching Yu",
      "Shi-Jinn Horng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.09613",
    "title": "Integral Migrating Pre-trained Transformer Encoder-decoders for Visual  Object Detection",
    "abstract": "Modern object detectors have taken the advantages of pre-trained vision transformers by using them as backbone networks. However, except for the backbone networks, other detector components, such as the detector head and the feature pyramid network, remain randomly initialized, which hinders the consistency between detectors and pre-trained models. In this study, we propose to integrally migrate the pre-trained transformer encoder-decoders (imTED) for object detection, constructing a feature extraction-operation path that is not only \"fully pre-trained\" but also consistent with pre-trained models. The essential improvements of imTED over existing transformer-based detectors are twofold: (1) it embeds the pre-trained transformer decoder to the detector head; and (2) it removes the feature pyramid network from the feature extraction path. Such improvements significantly reduce the proportion of randomly initialized parameters and enhance the generation capability of detectors. Experiments on MS COCO dataset demonstrate that imTED consistently outperforms its counterparts by ~2.8% AP. Without bells and whistles, imTED improves the state-of-the-art of few-shot object detection by up to 7.6% AP, demonstrating significantly higher generalization capability. Code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2205.09613",
    "authors": [
      "Xiaosong Zhang",
      "Feng Liu",
      "Zhiliang Peng",
      "Zonghao Guo",
      "Fang Wan",
      "Xiangyang Ji",
      "Qixiang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.09618",
    "title": "Eco-driving Trajectory Planning of a Heterogeneous Platoon in Urban  Environments",
    "abstract": "Given the increasing popularity and demand for connected and autonomous vehicles (CAVs), Eco-driving and platooning in highways and urban areas to increase the efficiency of the traffic system is becoming a possibility. This paper presents Eco-driving trajectory planning for a platoon of heterogeneous electric vehicles (EVs) in urban environments. The proposed control strategy for the platoon considers energy consumption, mobility and passenger comfort, with which vehicles may pass signalized intersections with no stops. For a given urban route, first, the platoon's leader vehicle employs dynamic programming (DP) to plan a trajectory for the anticipated path with the aim of balancing energy consumption, mobility and passenger comfort. Then, every other following CAV in the platoon either follows its preceding vehicle using a PID-based cooperative adaptive cruise control or plans its own trajectory by checking whether it can pass the next intersection without stopping. Furthermore, a heavy-duty vehicle that cannot efficiently follow a light-weight vehicle would instead employ the DP-based trajectory planner. Simulation studies demonstrate the efficacy of the proposed control strategy with which the platoon's energy consumption is shown to reduce while the mobility is not compromised. ",
    "url": "https://arxiv.org/abs/2205.09618",
    "authors": [
      "Hao Zhen",
      "Sahand Mosharafian",
      "Jidong J. Yang",
      "Javad Mohammadpour Velni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.09619",
    "title": "Improving Robustness against Real-World and Worst-Case Distribution  Shifts through Decision Region Quantification",
    "abstract": "The reliability of neural networks is essential for their use in safety-critical applications. Existing approaches generally aim at improving the robustness of neural networks to either real-world distribution shifts (e.g., common corruptions and perturbations, spatial transformations, and natural adversarial examples) or worst-case distribution shifts (e.g., optimized adversarial examples). In this work, we propose the Decision Region Quantification (DRQ) algorithm to improve the robustness of any differentiable pre-trained model against both real-world and worst-case distribution shifts in the data. DRQ analyzes the robustness of local decision regions in the vicinity of a given data point to make more reliable predictions. We theoretically motivate the DRQ algorithm by showing that it effectively smooths spurious local extrema in the decision surface. Furthermore, we propose an implementation using targeted and untargeted adversarial attacks. An extensive empirical evaluation shows that DRQ increases the robustness of adversarially and non-adversarially trained models against real-world and worst-case distribution shifts on several computer vision benchmark datasets. ",
    "url": "https://arxiv.org/abs/2205.09619",
    "authors": [
      "Leo Schwinn",
      "Leon Bungert",
      "An Nguyen",
      "Ren\u00e9 Raab",
      "Falk Pulsmeyer",
      "Doina Precup",
      "Bj\u00f6rn Eskofier",
      "Dario Zanca"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09624",
    "title": "Focused Adversarial Attacks",
    "abstract": "Recent advances in machine learning show that neural models are vulnerable to minimally perturbed inputs, or adversarial examples. Adversarial algorithms are optimization problems that minimize the accuracy of ML models by perturbing inputs, often using a model's loss function to craft such perturbations. State-of-the-art object detection models are characterized by very large output manifolds due to the number of possible locations and sizes of objects in an image. This leads to their outputs being sparse and optimization problems that use them incur a lot of unnecessary computation. We propose to use a very limited subset of a model's learned manifold to compute adversarial examples. Our \\textit{Focused Adversarial Attacks} (FA) algorithm identifies a small subset of sensitive regions to perform gradient-based adversarial attacks. FA is significantly faster than other gradient-based attacks when a model's manifold is sparsely activated. Also, its perturbations are more efficient than other methods under the same perturbation constraints. We evaluate FA on the COCO 2017 and Pascal VOC 2007 detection datasets. ",
    "url": "https://arxiv.org/abs/2205.09624",
    "authors": [
      "Thomas Cilloni",
      "Charles Walter",
      "Charles Fleming"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.09641",
    "title": "SNaC: Coherence Error Detection for Narrative Summarization",
    "abstract": "Progress in summarizing long texts is inhibited by the lack of appropriate evaluation frameworks. When a long summary must be produced to appropriately cover the facets of that text, that summary needs to present a coherent narrative to be understandable by a reader, but current automatic and human evaluation methods fail to identify gaps in coherence. In this work, we introduce SNaC, a narrative coherence evaluation framework rooted in fine-grained annotations for long summaries. We develop a taxonomy of coherence errors in generated narrative summaries and collect span-level annotations for 6.6k sentences across 150 book and movie screenplay summaries. Our work provides the first characterization of coherence errors generated by state-of-the-art summarization models and a protocol for eliciting coherence judgments from crowd annotators. Furthermore, we show that the collected annotations allow us to train a strong classifier for automatically localizing coherence errors in generated summaries as well as benchmarking past work in coherence modeling. Finally, our SNaC framework can support future work in long document summarization and coherence evaluation, including improved summarization modeling and post-hoc summary correction. ",
    "url": "https://arxiv.org/abs/2205.09641",
    "authors": [
      "Tanya Goyal",
      "Junyi Jessy Li",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.09648",
    "title": "Are Graph Representation Learning Methods Robust to Graph Sparsity and  Asymmetric Node Information?",
    "abstract": "The growing popularity of Graph Representation Learning (GRL) methods has resulted in the development of a large number of models applied to a miscellany of domains. Behind this diversity of domains, there is a strong heterogeneity of graphs, making it difficult to estimate the expected performance of a model on a new graph, especially when the graph has distinctive characteristics that have not been encountered in the benchmark yet. To address this, we have developed an experimental pipeline, to assess the impact of a given property on the models performances. In this paper, we use this pipeline to study the effect of two specificities encountered on banks transactional graphs resulting from the partial view a bank has on all the individuals and transactions carried out on the market. These specific features are graph sparsity and asymmetric node information. This study demonstrates the robustness of GRL methods to these distinctive characteristics. We believe that this work can ease the evaluation of GRL methods to specific characteristics and foster the development of such methods on transactional graphs. ",
    "url": "https://arxiv.org/abs/2205.09648",
    "authors": [
      "Pierre Sevestre",
      "Marine Neyret"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.09663",
    "title": "Collision Detection Accelerated: An Optimization Perspective",
    "abstract": "Collision detection between two convex shapes is an essential feature of any physics engine or robot motion planner. It has often been tackled as a computational geometry problem, with the Gilbert, Johnson and Keerthi (GJK) algorithm being the most common approach today. In this work we leverage the fact that collision detection is fundamentally a convex optimization problem. In particular, we establish that the GJK algorithm is a specific sub-case of the well-established Frank-Wolfe (FW) algorithm in convex optimization. We introduce a new collision detection algorithm by adapting recent works linking Nesterov acceleration and Frank-Wolfe methods. We benchmark the proposed accelerated collision detection method on two datasets composed of strictly convex and non-strictly convex shapes. Our results show that our approach significantly reduces the number of iterations to solve collision detection problems compared to the state-of-the-art GJK algorithm, leading to up to two times faster computation times. ",
    "url": "https://arxiv.org/abs/2205.09663",
    "authors": [
      "Louis Montaut",
      "Quentin Le Lidec",
      "Josef Sivic",
      "Justin Carpentier"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.09667",
    "title": "The AI Mechanic: Acoustic Vehicle Characterization Neural Networks",
    "abstract": "In a world increasingly dependent on road-based transportation, it is essential to understand vehicles. We introduce the AI mechanic, an acoustic vehicle characterization deep learning system, as an integrated approach using sound captured from mobile devices to enhance transparency and understanding of vehicles and their condition for non-expert users. We develop and implement novel cascading architectures for vehicle understanding, which we define as sequential, conditional, multi-level networks that process raw audio to extract highly-granular insights. To showcase the viability of cascading architectures, we build a multi-task convolutional neural network that predicts and cascades vehicle attributes to enhance fault detection. We train and test these models on a synthesized dataset reflecting more than 40 hours of augmented audio and achieve >92% validation set accuracy on attributes (fuel type, engine configuration, cylinder count and aspiration type). Our cascading architecture additionally achieved 93.6% validation and 86.8% test set accuracy on misfire fault prediction, demonstrating margins of 16.4% / 7.8% and 4.2% / 1.5% improvement over na\\\"ive and parallel baselines. We explore experimental studies focused on acoustic features, data augmentation, feature fusion, and data reliability. Finally, we conclude with a discussion of broader implications, future directions, and application areas for this work. ",
    "url": "https://arxiv.org/abs/2205.09667",
    "authors": [
      "Adam M. Terwilliger",
      "Joshua E. Siegel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.09669",
    "title": "Semi-WTC: A Practical Semi-supervised Framework for Attack  Categorization through Weight-Task Consistency",
    "abstract": "Supervised learning has been widely used for attack detection, which requires large amounts of high-quality data and labels. However, the data is often imbalanced and sufficient annotations are difficult to obtain. Moreover, these supervised models are subject to real-world deployment issues, such as defending against unseen artificial attacks. We propose a semi-supervised fine-grained attack categorization framework consisting of an encoder and a two-branch structure to integrate information from labeled and unlabeled data to tackle these practical challenges. This framework can be generalized to different supervised models. The multilayer perceptron with residual connection and batch normalization is used as the encoder to extract features and reduce the complexity. The Recurrent Prototype Module (RPM) is proposed to train the encoder effectively in a semi-supervised manner. To alleviate the problem of data imbalance, we introduce the Weight-Task Consistency (WTC) into the iterative process of RPM by assigning larger weights to classes with fewer samples in the loss function. In addition, to cope with new attacks in real-world deployment, we further propose an Active Adaption Resampling (AAR) method, which can better discover the distribution of the unseen sample data and adapt the parameters of the encoder. Experimental results show that our model outperforms the state-of-the-art semi-supervised attack detection methods with a general 5% improvement in classification accuracy and a 90% reduction in training time. ",
    "url": "https://arxiv.org/abs/2205.09669",
    "authors": [
      "Zihan Li",
      "Wentao Chen",
      "Zhiqing Wei",
      "Xingqi Luo",
      "Bing Su"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09670",
    "title": "A Unified Collaborative Representation Learning for Neural-Network based  Recommender Systems",
    "abstract": "Most NN-RSs focus on accuracy by building representations from the direct user-item interactions (e.g., user-item rating matrix), while ignoring the underlying relatedness between users and items (e.g., users who rate the same ratings for the same items should be embedded into similar representations), which is an ideological disadvantage. On the other hand, ME models directly employ inner products as a default loss function metric that cannot project users and items into a proper latent space, which is a methodological disadvantage. In this paper, we propose a supervised collaborative representation learning model - Magnetic Metric Learning (MML) - to map users and items into a unified latent vector space, enhancing the representation learning for NN-RSs. Firstly, MML utilizes dual triplets to model not only the observed relationships between users and items, but also the underlying relationships between users as well as items to overcome the ideological disadvantage. Specifically, a modified metric-based dual loss function is proposed in MML to gather similar entities and disperse the dissimilar ones. With MML, we can easily compare all the relationships (user to user, item to item, user to item) according to the weighted metric, which overcomes the methodological disadvantage. We conduct extensive experiments on four real-world datasets with large item space. The results demonstrate that MML can learn a proper unified latent space for representations from the user-item matrix with high accuracy and effectiveness, and lead to a performance gain over the state-of-the-art RS models by an average of 17%. ",
    "url": "https://arxiv.org/abs/2205.09670",
    "authors": [
      "Yuanbo Xu",
      "En Wang",
      "Yongjian Yang",
      "Yi Chang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2205.09678",
    "title": "Semi-Supervised Learning for Image Classification using Compact Networks  in the BioMedical Context",
    "abstract": "The development of mobile and on the edge applications that embed deep convolutional neural models has the potential to revolutionise biomedicine. However, most deep learning models require computational resources that are not available in smartphones or edge devices; an issue that can be faced by means of compact models. The problem with such models is that they are, at least usually, less accurate than bigger models. In this work, we study how this limitation can be addressed with the application of semi-supervised learning techniques. We conduct several statistical analyses to compare performance of deep compact architectures when trained using semi-supervised learning methods for tackling image classification tasks in the biomedical context. In particular, we explore three families of compact networks, and two families of semi-supervised learning techniques for 10 biomedical tasks. By combining semi-supervised learning methods with compact networks, it is possible to obtain a similar performance to standard size networks. In general, the best results are obtained when combining data distillation with MixNet, and plain distillation with ResNet-18. Also, in general, NAS networks obtain better results than manually designed networks and quantized networks. The work presented in this paper shows the benefits of apply semi-supervised methods to compact networks; this allow us to create compact models that are not only as accurate as standard size models, but also faster and lighter. Finally, we have developed a library that simplifies the construction of compact models using semi-supervised learning methods. ",
    "url": "https://arxiv.org/abs/2205.09678",
    "authors": [
      "Adri\u00e1n In\u00e9s",
      "Andr\u00e9s D\u00edaz-Pinto",
      "C\u00e9sar Dom\u00ednguez",
      "J\u00f3nathan Heras",
      "Eloy Mata",
      "Vico Pascual"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09682",
    "title": "Comparing single-node and multi-node performance of an important fusion  HPC code benchmark",
    "abstract": "Fusion simulations have traditionally required the use of leadership scale High Performance Computing (HPC) resources in order to produce advances in physics. The impressive improvements in compute and memory capacity of many-GPU compute nodes are now allowing for some problems that once required a multi-node setup to be also solvable on a single node. When possible, the increased interconnect bandwidth can result in order of magnitude higher science throughput, especially for communication-heavy applications. In this paper we analyze the performance of the fusion simulation tool CGYRO, an Eulerian gyrokinetic turbulence solver designed and optimized for collisional, electromagnetic, multiscale simulation, which is widely used in the fusion research community. Due to the nature of the problem, the application has to work on a large multi-dimensional computational mesh as a whole, requiring frequent exchange of large amounts of data between the compute processes. In particular, we show that the average-scale nl03 benchmark CGYRO simulation can be run at an acceptable speed on a single Google Cloud instance with 16 A100 GPUs, outperforming 8 NERSC Perlmutter Phase1 nodes, 16 ORNL Summit nodes and 256 NERSC Cori nodes. Moving from a multi-node to a single-node GPU setup we get comparable simulation times using less than half the number of GPUs. Larger benchmark problems, however, still require a multi-node HPC setup due to GPU memory capacity needs, since at the time of writing no vendor offers nodes with a sufficient GPU memory setup. The upcoming external NVSWITCH does however promise to deliver an almost equivalent solution for up to 256 NVIDIA GPUs. ",
    "url": "https://arxiv.org/abs/2205.09682",
    "authors": [
      "Emily A. Belli",
      "Jeff Candy",
      "Igor Sfiligoi",
      "Frank W\u00fcrthwein"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Plasma Physics (physics.plasm-ph)"
    ]
  },
  {
    "id": "arXiv:2205.09683",
    "title": "Dexterous Robotic Manipulation using Deep Reinforcement Learning and  Knowledge Transfer for Complex Sparse Reward-based Tasks",
    "abstract": "This paper describes a deep reinforcement learning (DRL) approach that won Phase 1 of the Real Robot Challenge (RRC) 2021, and then extends this method to a more difficult manipulation task. The RRC consisted of using a TriFinger robot to manipulate a cube along a specified positional trajectory, but with no requirement for the cube to have any specific orientation. We used a relatively simple reward function, a combination of goal-based sparse reward and distance reward, in conjunction with Hindsight Experience Replay (HER) to guide the learning of the DRL agent (Deep Deterministic Policy Gradient (DDPG)). Our approach allowed our agents to acquire dexterous robotic manipulation strategies in simulation. These strategies were then applied to the real robot and outperformed all other competition submissions, including those using more traditional robotic control techniques, in the final evaluation stage of the RRC. Here we extend this method, by modifying the task of Phase 1 of the RRC to require the robot to maintain the cube in a particular orientation, while the cube is moved along the required positional trajectory. The requirement to also orient the cube makes the agent unable to learn the task through blind exploration due to increased problem complexity. To circumvent this issue, we make novel use of a Knowledge Transfer (KT) technique that allows the strategies learned by the agent in the original task (which was agnostic to cube orientation) to be transferred to this task (where orientation matters). KT allowed the agent to learn and perform the extended task in the simulator, which improved the average positional deviation from 0.134 m to 0.02 m, and average orientation deviation from 142{\\deg} to 76{\\deg} during evaluation. This KT concept shows good generalisation properties and could be applied to any actor-critic learning algorithm. ",
    "url": "https://arxiv.org/abs/2205.09683",
    "authors": [
      "Qiang Wang",
      "Francisco Roldan Sanchez",
      "Robert McCarthy",
      "David Cordova Bulens",
      "Kevin McGuinness",
      "Noel O'Connor",
      "Manuel W\u00fcthrich",
      "Felix Widmaier",
      "Stefan Bauer",
      "Stephen J. Redmond"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09701",
    "title": "Homophily and Incentive Effects in Use of Algorithms",
    "abstract": "As algorithmic tools increasingly aid experts in making consequential decisions, the need to understand the precise factors that mediate their influence has grown commensurately. In this paper, we present a crowdsourcing vignette study designed to assess the impacts of two plausible factors on AI-informed decision-making. First, we examine homophily -- do people defer more to models that tend to agree with them? -- by manipulating the agreement during training between participants and the algorithmic tool. Second, we considered incentives -- how do people incorporate a (known) cost structure in the hybrid decision-making setting? -- by varying rewards associated with true positives vs. true negatives. Surprisingly, we found limited influence of either homophily and no evidence of incentive effects, despite participants performing similarly to previous studies. Higher levels of agreement between the participant and the AI tool yielded more confident predictions, but only when outcome feedback was absent. These results highlight the complexity of characterizing human-algorithm interactions, and suggest that findings from social psychology may require re-examination when humans interact with algorithms. ",
    "url": "https://arxiv.org/abs/2205.09701",
    "authors": [
      "Riccardo Fogliato",
      "Sina Fazelpour",
      "Shantanu Gupta",
      "Zachary Lipton",
      "David Danks"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2205.09702",
    "title": "Parallel and Distributed Graph Neural Networks: An In-Depth Concurrency  Analysis",
    "abstract": "Graph neural networks (GNNs) are among the most powerful tools in deep learning. They routinely solve complex problems on unstructured networks, such as node classification, graph classification, or link prediction, with high accuracy. However, both inference and training of GNNs are complex, and they uniquely combine the features of irregular graph processing with dense and regular computations. This complexity makes it very challenging to execute GNNs efficiently on modern massively parallel architectures. To alleviate this, we first design a taxonomy of parallelism in GNNs, considering data and model parallelism, and different forms of pipelining. Then, we use this taxonomy to investigate the amount of parallelism in numerous GNN models, GNN-driven machine learning tasks, software frameworks, or hardware accelerators. We use the work-depth model, and we also assess communication volume and synchronization. We specifically focus on the sparsity/density of the associated tensors, in order to understand how to effectively apply techniques such as vectorization. We also formally analyze GNN pipelining, and we generalize the established Message-Passing class of GNN models to cover arbitrary pipeline depths, facilitating future optimizations. Finally, we investigate different forms of asynchronicity, navigating the path for future asynchronous parallel GNN pipelines. The outcomes of our analysis are synthesized in a set of insights that help to maximize GNN performance, and a comprehensive list of challenges and opportunities for further research into efficient GNN computations. Our work will help to advance the design of future GNNs. ",
    "url": "https://arxiv.org/abs/2205.09702",
    "authors": [
      "Maciej Besta",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.09705",
    "title": "Distributed Multi-Agent Deep Reinforcement Learning for Robust  Coordination against Noise",
    "abstract": "In multi-agent systems, noise reduction techniques are important for improving the overall system reliability as agents are required to rely on limited environmental information to develop cooperative and coordinated behaviors with the surrounding agents. However, previous studies have often applied centralized noise reduction methods to build robust and versatile coordination in noisy multi-agent environments, while distributed and decentralized autonomous agents are more plausible for real-world application. In this paper, we introduce a \\emph{distributed attentional actor architecture model for a multi-agent system} (DA3-X), using which we demonstrate that agents with DA3-X can selectively learn the noisy environment and behave cooperatively. We experimentally evaluate the effectiveness of DA3-X by comparing learning methods with and without DA3-X and show that agents with DA3-X can achieve better performance than baseline agents. Furthermore, we visualize heatmaps of \\emph{attentional weights} from the DA3-X to analyze how the decision-making process and coordinated behavior are influenced by noise. ",
    "url": "https://arxiv.org/abs/2205.09705",
    "authors": [
      "Yoshinari Motokawa",
      "Toshiharu Sugawara"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.09722",
    "title": "Light In The Black: An Evaluation of Data Augmentation Techniques for  COVID-19 CT's Semantic Segmentation",
    "abstract": "With the COVID-19 global pandemic, computer-assisted diagnoses of medical images have gained much attention, and robust methods of Semantic Segmentation of Computed Tomography (CT) became highly desirable. Semantic Segmentation of CT is one of many research fields of automatic detection of COVID-19 and has been widely explored since the COVID-19 outbreak. In this work, we propose an extensive analysis of how different data augmentation techniques improve the training of encoder-decoder neural networks on this problem. Twenty different data augmentation techniques were evaluated on five different datasets. Each dataset was validated through a five-fold cross-validation strategy, thus resulting in over 3,000 experiments. Our findings show that spatial level transformations are the most promising to improve the learning of neural networks on this problem. ",
    "url": "https://arxiv.org/abs/2205.09722",
    "authors": [
      "Bruno A. Krinski",
      "Daniel V. Ruiz",
      "Eduardo Todt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.09723",
    "title": "Robust and Efficient Medical Imaging with Self-Supervision",
    "abstract": "Recent progress in Medical Artificial Intelligence (AI) has delivered systems that can reach clinical expert level performance. However, such systems tend to demonstrate sub-optimal \"out-of-distribution\" performance when evaluated in clinical settings different from the training environment. A common mitigation strategy is to develop separate systems for each clinical setting using site-specific data [1]. However, this quickly becomes impractical as medical data is time-consuming to acquire and expensive to annotate [2]. Thus, the problem of \"data-efficient generalization\" presents an ongoing difficulty for Medical AI development. Although progress in representation learning shows promise, their benefits have not been rigorously studied, specifically for out-of-distribution settings. To meet these challenges, we present REMEDIS, a unified representation learning strategy to improve robustness and data-efficiency of medical imaging AI. REMEDIS uses a generic combination of large-scale supervised transfer learning with self-supervised learning and requires little task-specific customization. We study a diverse range of medical imaging tasks and simulate three realistic application scenarios using retrospective data. REMEDIS exhibits significantly improved in-distribution performance with up to 11.5% relative improvement in diagnostic accuracy over a strong supervised baseline. More importantly, our strategy leads to strong data-efficient generalization of medical imaging AI, matching strong supervised baselines using between 1% to 33% of retraining data across tasks. These results suggest that REMEDIS can significantly accelerate the life-cycle of medical imaging AI development thereby presenting an important step forward for medical imaging AI to deliver broad impact. ",
    "url": "https://arxiv.org/abs/2205.09723",
    "authors": [
      "Shekoofeh Azizi",
      "Laura Culp",
      "Jan Freyberg",
      "Basil Mustafa",
      "Sebastien Baur",
      "Simon Kornblith",
      "Ting Chen",
      "Patricia MacWilliams",
      "S. Sara Mahdavi",
      "Ellery Wulczyn",
      "Boris Babenko",
      "Megan Wilson",
      "Aaron Loh",
      "Po-Hsuan Cameron Chen",
      "Yuan Liu",
      "Pinal Bavishi",
      "Scott Mayer McKinney",
      "Jim Winkens",
      "Abhijit Guha Roy",
      "Zach Beaver",
      "Fiona Ryan",
      "Justin Krogue",
      "Mozziyar Etemadi",
      "Umesh Telang",
      "Yun Liu",
      "Lily Peng",
      "Greg S. Corrado",
      "Dale R. Webster",
      "David Fleet",
      "Geoffrey Hinton",
      "Neil Houlsby",
      "Alan Karthikesalingam",
      "Mohammad Norouzi",
      "Vivek Natarajan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09730",
    "title": "Dissemination Control in Dynamic Data Clustering For Dense IIoT Against  False Data Injection Attack",
    "abstract": "The IoT has made possible the development of increasingly driven services, like industrial IIoT services, that often deal with massive amounts of data. Meantime, as IIoT networks grow, the threats are even greater, and false data injection attacks (FDI) stand out as being one of the most aggressive. The majority of current solutions to handle this attack do not take into account the data validation, especially on the data clustering service. Aiming to advance on the issue, this work introduces CONFINIT, an intrusion detection system for mitigating FDI attacks on the data dissemination service performing in dense IIoT networks. CONFINIT combines watchdog surveillance and collaborative consensus strategies for assertively excluding various FDI attacks. The simulations showed that CONFINIT compared to DDFC increased by up to 35% - 40% the number of clusters without attackers in a gas pressure IIoT environment. CONFINIT achieved attack detection rates of 99%, accuracy of 90 and F1 score of 0.81 in multiple IIoT scenarios, with only up to 3.2% and 3.6% of false negatives and positives rates, respectively. Moreover, under two variants of FDI attacks, called Churn and Sensitive attacks, CONFINIT achieved detection rates of 100%, accuracy of 99 and F1 of 0.93 with less than 2% of false positives and negatives rates. ",
    "url": "https://arxiv.org/abs/2205.09730",
    "authors": [
      "Carlos Pedroso",
      "Aldri Santos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.09743",
    "title": "BEVerse: Unified Perception and Prediction in Birds-Eye-View for  Vision-Centric Autonomous Driving",
    "abstract": "In this paper, we present BEVerse, a unified framework for 3D perception and prediction based on multi-camera systems. Unlike existing studies focusing on the improvement of single-task approaches, BEVerse features in producing spatio-temporal Birds-Eye-View (BEV) representations from multi-camera videos and jointly reasoning about multiple tasks for vision-centric autonomous driving. Specifically, BEVerse first performs shared feature extraction and lifting to generate 4D BEV representations from multi-timestamp and multi-view images. After the ego-motion alignment, the spatio-temporal encoder is utilized for further feature extraction in BEV. Finally, multiple task decoders are attached for joint reasoning and prediction. Within the decoders, we propose the grid sampler to generate BEV features with different ranges and granularities for different tasks. Also, we design the method of iterative flow for memory-efficient future prediction. We show that the temporal information improves 3D object detection and semantic map construction, while the multi-task learning can implicitly benefit motion prediction. With extensive experiments on the nuScenes dataset, we show that the multi-task BEVerse outperforms existing single-task methods on 3D object detection, semantic map construction, and motion prediction. Compared with the sequential paradigm, BEVerse also favors in significantly improved efficiency. The code and trained models will be released at https://github.com/zhangyp15/BEVerse. ",
    "url": "https://arxiv.org/abs/2205.09743",
    "authors": [
      "Yunpeng Zhang",
      "Zheng Zhu",
      "Wenzhao Zheng",
      "Junjie Huang",
      "Guan Huang",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.09169",
    "title": "Anonymous conference key agreement in linear quantum networks",
    "abstract": "Sharing multi-partite quantum entanglement between parties allows for diverse secure communication tasks to be performed. Among them, conference key agreement (CKA), an extension of key distribution to multiple parties, has received much attention recently. Interestingly, CKA can also be performed in a way that protects the identities of the participating parties, therefore providing anonymity. In this work, we propose an anonymous CKA protocol for three parties that is implemented in a highly practical network setting. Specifically, a line of quantum repeater nodes is used to build a linear cluster state among all nodes, which is then used to anonymously establish a secret key between any three of them. The nodes need only share maximally entangled pairs with their neighbours, therefore avoiding the necessity of a central server sharing entangled states. This repeater setup makes our protocol an excellent candidate for implementation in future quantum networks. We explicitly prove that our protocol protects the identities of the participants from one another and perform an analysis of the key rate in the finite regime, contributing to the quest of identifying feasible quantum communication tasks for network architectures beyond point-to-point. ",
    "url": "https://arxiv.org/abs/2205.09169",
    "authors": [
      "Jarn de Jong",
      "Frederik Hahn",
      "Jens Eisert",
      "Nathan Walk",
      "Anna Pappa"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.09235",
    "title": "Constraint-Based Causal Structure Learning from Undersampled Graphs",
    "abstract": "Graphical structures estimated by causal learning algorithms from time series data can provide highly misleading causal information if the causal timescale of the generating process fails to match the measurement timescale of the data. Although this problem has been recently recognized, practitioners have limited resources to respond to it, and so must continue using models that they know are likely misleading. Existing methods either (a) require that the difference between causal and measurement timescales is known; or (b) can handle only very small number of random variables when the timescale difference is unknown; or (c) apply to only pairs of variables, though with fewer assumptions about prior knowledge; or (d) return impractically too many solutions. This paper addresses all four challenges. We combine constraint programming with both theoretical insights into the problem structure and prior information about admissible causal interactions. The resulting system provides a practical approach that scales to significantly larger sets (>100) of random variables, does not require precise knowledge of the timescale difference, supports edge misidentification and parametric connection strengths, and can provide the optimum choice among many possible solutions. The cumulative impact of these improvements is gain of multiple orders of magnitude in speed and informativeness. ",
    "url": "https://arxiv.org/abs/2205.09235",
    "authors": [
      "Mohammadsajad Abavisani",
      "David Danks",
      "Sergey Plis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09241",
    "title": "Neural ODE Control for Trajectory Approximation of Continuity Equation",
    "abstract": "We consider the controllability problem for the continuity equation, corresponding to neural ordinary differential equations (ODEs), which describes how a probability measure is pushedforward by the flow. We show that the controlled continuity equation has very strong controllability properties. Particularly, a given solution of the continuity equation corresponding to a bounded Lipschitz vector field defines a trajectory on the set of probability measures. For this trajectory, we show that there exist piecewise constant training weights for a neural ODE such that the solution of the continuity equation corresponding to the neural ODE is arbitrarily close to it. As a corollary to this result, we establish that the continuity equation of the neural ODE is approximately controllable on the set of compactly supported probability measures that are absolutely continuous with respect to the Lebesgue measure. ",
    "url": "https://arxiv.org/abs/2205.09241",
    "authors": [
      "Karthik Elamvazhuthi",
      "Bahman Gharesifard",
      "Andrea Bertozzi",
      "Stanley Osher"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.09317",
    "title": "Odd coloring of two subclasses of planar graphs",
    "abstract": "A proper coloring of a graph is odd if every non-isolated vertex has some color that appears an odd number of times on its neighborhood. Petru\\v{s}evski and \\v{S}krekovski conjectured in 2021 that every planar graph admits an odd $5$-coloring. We confirm this conjecture for outer-1-planar graphs and 2-boundary planar graphs, which are two subclasses of planar graphs. ",
    "url": "https://arxiv.org/abs/2205.09317",
    "authors": [
      "Mengke Qi",
      "Xin Zhang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2205.09382",
    "title": "BabyNet: Residual Transformer Module for Birth Weight Prediction on  Fetal Ultrasound Video",
    "abstract": "Predicting fetal weight at birth is an important aspect of perinatal care, particularly in the context of antenatal management, which includes the planned timing and the mode of delivery. Accurate prediction of weight using prenatal ultrasound is challenging as it requires images of specific fetal body parts during advanced pregnancy which is difficult to capture due to poor quality of images caused by the lack of amniotic fluid. As a consequence, predictions which rely on standard methods often suffer from significant errors. In this paper we propose the Residual Transformer Module which extends a 3D ResNet-based network for analysis of 2D+t spatio-temporal ultrasound video scans. Our end-to-end method, called BabyNet, automatically predicts fetal birth weight based on fetal ultrasound video scans. We evaluate BabyNet using a dedicated clinical set comprising 225 2D fetal ultrasound videos of pregnancies from 75 patients performed one day prior to delivery. Experimental results show that BabyNet outperforms several state-of-the-art methods and estimates the weight at birth with accuracy comparable to human experts. Furthermore, combining estimates provided by human experts with those computed by BabyNet yields the best results, outperforming either of other methods by a significant margin. The source code of BabyNet is available at https://github.com/SanoScience/BabyNet. ",
    "url": "https://arxiv.org/abs/2205.09382",
    "authors": [
      "Szymon P\u0142otka",
      "Micha\u0142 K. Grzeszczyk",
      "Robert Brawura-Biskupski-Samaha",
      "Pawe\u0142 Gutaj",
      "Micha\u0142 Lipa",
      "Tomasz Trzci\u0144ski",
      "Arkadiusz Sitek"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09401",
    "title": "Bias Analysis of Spatial Coherence-Based RTF Vector Estimation for  Acoustic Sensor Networks in a Diffuse Sound Field",
    "abstract": "In many multi-microphone algorithms, an estimate of the relative transfer functions (RTFs) of the desired speaker is required. Recently, a computationally efficient RTF vector estimation method was proposed for acoustic sensor networks, assuming that the spatial coherence (SC) of the noise component between a local microphone array and multiple external microphones is low. Aiming at optimizing the output signal-to-noise ratio (SNR), this method linearly combines multiple RTF vector estimates, where the complex-valued weights are computed using a generalized eigenvalue decomposition (GEVD). In this paper, we perform a theoretical bias analysis for the SC-based RTF vector estimation method with multiple external microphones. Assuming a certain model for the noise field, we derive an analytical expression for the weights, showing that the optimal model-based weights are real-valued and only depend on the input SNR in the external microphones. Simulations with real-world recordings show a good accordance of the GEVD-based and the model-based weights. Nevertheless, the results also indicate that in practice, estimation errors occur which the model-based weights cannot account for. ",
    "url": "https://arxiv.org/abs/2205.09401",
    "authors": [
      "Wiebke Middelberg",
      "Simon Doclo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.09508",
    "title": "Practical Skills Demand Forecasting via Representation Learning of  Temporal Dynamics",
    "abstract": "Rapid technological innovation threatens to leave much of the global workforce behind. Today's economy juxtaposes white-hot demand for skilled labor against stagnant employment prospects for workers unprepared to participate in a digital economy. It is a moment of peril and opportunity for every country, with outcomes measured in long-term capital allocation and the life satisfaction of billions of workers. To meet the moment, governments and markets must find ways to quicken the rate at which the supply of skills reacts to changes in demand. More fully and quickly understanding labor market intelligence is one route. In this work, we explore the utility of time series forecasts to enhance the value of skill demand data gathered from online job advertisements. This paper presents a pipeline which makes one-shot multi-step forecasts into the future using a decade of monthly skill demand observations based on a set of recurrent neural network methods. We compare the performance of a multivariate model versus a univariate one, analyze how correlation between skills can influence multivariate model results, and present predictions of demand for a selection of skills practiced by workers in the information technology industry. ",
    "url": "https://arxiv.org/abs/2205.09508",
    "authors": [
      "Maysa M. Garcia de Macedo",
      "Wyatt Clarke",
      "Eli Lucherini",
      "Tyler Baldwin",
      "Dilermando Queiroz Neto",
      "Rogerio de Paula",
      "Subhro Das"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09533",
    "title": "Estimating the ultrasound attenuation coefficient using convolutional  neural networks -- a feasibility study",
    "abstract": "Attenuation coefficient (AC) is a fundamental measure of tissue acoustical properties, which can be used in medical diagnostics. In this work, we investigate the feasibility of using convolutional neural networks (CNNs) to directly estimate AC from radio-frequency (RF) ultrasound signals. To develop the CNNs we used RF signals collected from tissue mimicking numerical phantoms for the AC values in a range from 0.1 to 1.5 dB/(MHz*cm). The models were trained based on 1-D patches of RF data. We obtained mean absolute AC estimation errors of 0.08, 0.12, 0.20, 0.25 for the patch lengths: 10 mm, 5 mm, 2 mm and 1 mm, respectively. We explain the performance of the model by visualizing the frequency content associated with convolutional filters. Our study presents that the AC can be calculated using deep learning, and the weights of the CNNs can have physical interpretation. ",
    "url": "https://arxiv.org/abs/2205.09533",
    "authors": [
      "Piotr Jarosik",
      "Michal Byra",
      "Marcin Lewandowski",
      "Ziemowit Klimonda"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.09644",
    "title": "Neural network for multi-exponential sound energy decay analysis",
    "abstract": "An established model for sound energy decay functions (EDFs) is the superposition of multiple exponentials and a noise term. This work proposes a neural-network-based approach for estimating the model parameters from EDFs. The network is trained on synthetic EDFs and evaluated on two large datasets of over 20000 EDF measurements conducted in various acoustic environments. The evaluation shows that the proposed neural network architecture robustly estimates the model parameters from large datasets of measured EDFs, while being lightweight and computationally efficient. An implementation of the proposed neural network is publicly available. ",
    "url": "https://arxiv.org/abs/2205.09644",
    "authors": [
      "Georg G\u00f6tz",
      "Ricardo Falc\u00f3n P\u00e9rez",
      "Sebastian J. Schlecht",
      "Ville Pulkki"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2205.09653",
    "title": "Self-Consistent Dynamical Field Theory of Kernel Evolution in Wide  Neural Networks",
    "abstract": "We analyze feature learning in infinite width neural networks trained with gradient flow through a self-consistent dynamical field theory. We construct a collection of deterministic dynamical order parameters which are inner-product kernels for hidden unit activations and gradients in each layer at pairs of time points, providing a reduced description of network activity through training. These kernel order parameters collectively define the hidden layer activation distribution, the evolution of the neural tangent kernel, and consequently output predictions. For deep linear networks, these kernels satisfy a set of algebraic matrix equations. For nonlinear networks, we provide an alternating sampling procedure to self-consistently solve for the kernel order parameters. We provide comparisons of the self-consistent solution to various approximation schemes including the static NTK approximation, gradient independence assumption, and leading order perturbation theory, showing that each of these approximations can break down in regimes where general self-consistent solutions still provide an accurate description. Lastly, we provide experiments in more realistic settings which demonstrate that the loss and kernel dynamics of CNNs at fixed feature learning strength is preserved across different widths on a CIFAR classification task. ",
    "url": "https://arxiv.org/abs/2205.09653",
    "authors": [
      "Blake Bordelon",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09679",
    "title": "Dynamic Pricing Provides Robust Equilibria in Stochastic Ridesharing  Networks",
    "abstract": "Ridesharing markets are complex: drivers are strategic, rider demand and driver availability are stochastic, and complex city-scale phenomena like weather induce large scale correlation across space and time. At the same time, past work has focused on a subset of these challenges. We propose a model of ridesharing networks with strategic drivers, spatiotemporal dynamics, and stochasticity. Supporting both computational tractability and better modeling flexibility than classical fluid limits, we use a two-level stochastic model that allows correlated shocks caused by weather or large public events. Using this model, we propose a novel pricing mechanism: stochastic spatiotemporal pricing (SSP). We show that the SSP mechanism is asymptotically incentive-compatible and that all (approximate) equilibria of the resulting game are asymptotically welfare-maximizing when the market is large enough. The SSP mechanism iteratively recomputes prices based on realized demand and supply, and in this sense prices dynamically. We show that this is critical: while a static variant of the SSP mechanism (whose prices vary with the market-level stochastic scenario but not individual rider and driver decisions) has a sequence of asymptotically welfare-optimal approximate equilibria, we demonstrate that it also has other equilibria producing extremely low social welfare. Thus, we argue that dynamic pricing is important for ensuring robustness in stochastic ride-sharing networks. ",
    "url": "https://arxiv.org/abs/2205.09679",
    "authors": [
      "J. Massey Cashore",
      "Peter I. Frazier",
      "Eva Tardos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2205.09699",
    "title": "Neural network topological snake models for locating general phase  diagrams",
    "abstract": "Machine learning for locating phase diagram has received intensive research interest in recent years. However, its application in automatically locating phase diagram is limited to single closed phase boundary. In this paper, in order to locate phase diagrams with multiple phases and complex boundaries, we introduce (i) a network-shaped snake model and (ii) a topologically transformable snake with discriminative cooperative networks, respectively. The phase diagrams of both quantum and classical spin-1 model are obtained. Our method is flexible to determine the phase diagram with just snapshots of configurations from the cold-atom or other experiments. ",
    "url": "https://arxiv.org/abs/2205.09699",
    "authors": [
      "Wanzhou Zhang",
      "Huijiong Yang",
      "Nan Wu"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Quantum Gases (cond-mat.quant-gas)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09724",
    "title": "Chemotactically induced search and defense strategies in a tritrophic  system",
    "abstract": "In this paper we study the question of the survival of a predator which in a static scenario vanishes. we analyze the role of migration on the coexistence of three species interacting through a intraguild relationship. ",
    "url": "https://arxiv.org/abs/2205.09724",
    "authors": [
      "Nestor Anaya",
      "Manuel Falconi",
      "Guilmer Gonz\u00e1lez"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:1806.04884",
    "title": "Spurious Local Minima of Deep ReLU Neural Networks in the Neural Tangent  Kernel Regime",
    "abstract": " Comments: 12 pages, 6 figures. We relocated the results obtained in the previous version into the NTK regime, and changed the paper title ",
    "url": "https://arxiv.org/abs/1806.04884",
    "authors": [
      "Tohru Nitta"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2006.06926",
    "title": "Bayesian Network Structure Learning using Digital Annealer",
    "abstract": " Comments: 11 pages, 2 tables, 3 figures, NeurIPS 2022 (under review) ",
    "url": "https://arxiv.org/abs/2006.06926",
    "authors": [
      "Yuta Shikuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2009.12494",
    "title": "SEMI: Self-supervised Exploration via Multisensory Incongruity",
    "abstract": " Comments: Accepted at ICRA 2022 ",
    "url": "https://arxiv.org/abs/2009.12494",
    "authors": [
      "Jianren Wang",
      "Ziwen Zhuang",
      "Hang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2011.12815",
    "title": "Learning Multiscale Convolutional Dictionaries for Image Reconstruction",
    "abstract": " Title: Learning Multiscale Convolutional Dictionaries for Image Reconstruction ",
    "url": "https://arxiv.org/abs/2011.12815",
    "authors": [
      "Tianlin Liu",
      "Anadi Chaman",
      "David Belius",
      "Ivan Dokmani\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2012.01821",
    "title": "D-Unet: A Dual-encoder U-Net for Image Splicing Forgery Detection and  Localization",
    "abstract": " Comments: 13 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2012.01821",
    "authors": [
      "Xiuli Bi",
      "Ranglei Wu",
      "Bin Xiao",
      "Weisheng Li",
      "Guoyin Wang",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2012.03389",
    "title": "Traffic Assignment Problem for Footpath Networks with Bidirectional  Links",
    "abstract": " Title: Traffic Assignment Problem for Footpath Networks with Bidirectional  Links ",
    "url": "https://arxiv.org/abs/2012.03389",
    "authors": [
      "Tanapon Lilasathapornkit",
      "David Rey",
      "Wei Liu",
      "Meead Saberi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2104.02230",
    "title": "Achieving Domain Generalization in Underwater Object Detection by Domain  Mixup and Contrastive Learning",
    "abstract": " Title: Achieving Domain Generalization in Underwater Object Detection by Domain  Mixup and Contrastive Learning ",
    "url": "https://arxiv.org/abs/2104.02230",
    "authors": [
      "Pinhao Song",
      "Linhui Dai",
      "Peipei Yuan",
      "Hong Liu",
      "Runwei Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.10699",
    "title": "Denoising Noisy Neural Networks: A Bayesian Approach with Compensation",
    "abstract": " Comments: Keywords: Noisy neural network, denoiser, wireless transmission of neural networks, federated edge learning, analog device. 18 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2105.10699",
    "authors": [
      "Yulin Shao",
      "Soung Chang Liew",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2105.14139",
    "title": "On a class of data-driven mixed-integer programming problems under  uncertainty: a distributionally robust approach",
    "abstract": " Comments: The paper has been substantially revised with respect to the definition of weak and strong optimality as well as the related theoretical results (Theorems 1-4). Furthermore, some additional results for the unweighted knapsack problem are provided ",
    "url": "https://arxiv.org/abs/2105.14139",
    "authors": [
      "Sergey S. Ketkov",
      "Andrei S. Shilov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2106.10595",
    "title": "Heterogeneous Multi-task Learning with Expert Diversity",
    "abstract": " Comments: 10 pages, 7 figures, BIOKDD, IEEE/ACM ",
    "url": "https://arxiv.org/abs/2106.10595",
    "authors": [
      "Raquel Aoki",
      "Frederick Tung",
      "Gabriel L. Oliveira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.02772",
    "title": "A Causal Bandit Approach to Learning Good Atomic Interventions in  Presence of Unobserved Confounders",
    "abstract": " Comments: 36 pages; metadata changed ",
    "url": "https://arxiv.org/abs/2107.02772",
    "authors": [
      "Aurghya Maiti",
      "Vineet Nair",
      "Gaurav Sinha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2107.06048",
    "title": "A Graph Data Augmentation Strategy with Entropy Preservation",
    "abstract": " Title: A Graph Data Augmentation Strategy with Entropy Preservation ",
    "url": "https://arxiv.org/abs/2107.06048",
    "authors": [
      "Xue Liu",
      "Dan Sun",
      "Wei Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2108.03443",
    "title": "NODEO: A Neural Ordinary Differential Equation Based Optimization  Framework for Deformable Image Registration",
    "abstract": " Title: NODEO: A Neural Ordinary Differential Equation Based Optimization  Framework for Deformable Image Registration ",
    "url": "https://arxiv.org/abs/2108.03443",
    "authors": [
      "Yifan Wu",
      "Tom Z. Jiahao",
      "Jiancong Wang",
      "Paul A. Yushkevich",
      "M. Ani Hsieh",
      "James C. Gee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.05018",
    "title": "Are Neural Ranking Models Robust?",
    "abstract": " Comments: Accepted by TOIS ",
    "url": "https://arxiv.org/abs/2108.05018",
    "authors": [
      "Chen Wu",
      "Ruqing Zhang",
      "Jiafeng Guo",
      "Yixing Fan",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2108.08735",
    "title": "SiReN: Sign-Aware Recommendation Using Graph Neural Networks",
    "abstract": " Comments: 15 pages, 5 figures, 3 tables; to appear in the IEEE Transactions on Neural Networks and Learning Systems (Special Issue on Deep Neural Networks for Graphs: Theory, Models, Algorithms and Applications) (Please cite our journal version that will appear in an upcoming issue.) ",
    "url": "https://arxiv.org/abs/2108.08735",
    "authors": [
      "Changwon Seo",
      "Kyeong-Joong Jeong",
      "Sungsu Lim",
      "Won-Yong Shin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2109.03748",
    "title": "A robust approach for deep neural networks in presence of label noise:  relabelling and filtering instances during training",
    "abstract": " Comments: 24 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2109.03748",
    "authors": [
      "Anabel G\u00f3mez-R\u00edos",
      "Juli\u00e1n Luengo",
      "Francisco Herrera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2109.11094",
    "title": "PredictionNet: Real-Time Joint Probabilistic Traffic Prediction for  Planning, Control, and Simulation",
    "abstract": " Comments: 7 pages, 7 figures, accepted to ICRA 2022 conference, for associated video file, see this https URL ",
    "url": "https://arxiv.org/abs/2109.11094",
    "authors": [
      "Alexey Kamenev",
      "Lirui Wang",
      "Ollin Boer Bohan",
      "Ishwar Kulkarni",
      "Bilal Kartal",
      "Artem Molchanov",
      "Stan Birchfield",
      "David Nist\u00e9r",
      "Nikolai Smolyanskiy"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.13046",
    "title": "The Spread of Propaganda by Coordinated Communities on Social Media",
    "abstract": " Comments: The 14th ACM Web Science Conference 2022 (WebSci '22) ",
    "url": "https://arxiv.org/abs/2109.13046",
    "authors": [
      "Kristina Hristakieva",
      "Stefano Cresci",
      "Giovanni Da San Martino",
      "Mauro Conti",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2110.01276",
    "title": "Characterizing Omega-Regularity through Finite-Memory Determinacy of  Games on Infinite Graphs",
    "abstract": " Comments: Full version of STACS 2022 conference paper. 41 pages, 14 figures ",
    "url": "https://arxiv.org/abs/2110.01276",
    "authors": [
      "Patricia Bouyer",
      "Mickael Randour",
      "Pierre Vandenhove"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2110.03905",
    "title": "COVID-19 Monitoring System using Social Distancing and Face Mask  Detection on Surveillance video datasets",
    "abstract": " Title: COVID-19 Monitoring System using Social Distancing and Face Mask  Detection on Surveillance video datasets ",
    "url": "https://arxiv.org/abs/2110.03905",
    "authors": [
      "Sahana Srinivasan",
      "Rujula Singh R",
      "Ruchita Biradar",
      "Nikhil Nayak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.09473",
    "title": "DBSegment: Fast and robust segmentation of deep brain structures --  Evaluation of transportability across acquisition domains",
    "abstract": " Comments: The data used have mistakes. No one has time to correct the data and add a new version, that is why we would like to retract it. Once we have the correct version we will resubmit to arxiv ",
    "url": "https://arxiv.org/abs/2110.09473",
    "authors": [
      "Mehri Baniasadi",
      "Mikkel V. Petersen",
      "Jorge Goncalves",
      "Andreas Horn",
      "Vanja Vlasov",
      "Frank Hertel",
      "Andreas Husch"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2111.05070",
    "title": "Universal Lower Bound for Learning Causal DAGs with Atomic Interventions",
    "abstract": " Comments: Extended version of AISTATS 2022 paper. Added results for multi-node interventions, and shortened title ",
    "url": "https://arxiv.org/abs/2111.05070",
    "authors": [
      "Vibhor Porwal",
      "Piyush Srivastava",
      "Gaurav Sinha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.04564",
    "title": "CoSSL: Co-Learning of Representation and Classifier for Imbalanced  Semi-Supervised Learning",
    "abstract": " Comments: Published at CVPR 2022 as a conference paper. Code at this https URL ",
    "url": "https://arxiv.org/abs/2112.04564",
    "authors": [
      "Yue Fan",
      "Dengxin Dai",
      "Anna Kukleva",
      "Bernt Schiele"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.09436",
    "title": "Privacy preserving n-party scalar product protocol",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2112.09436",
    "authors": [
      "Florian van Daalen",
      "Inigo Bermejo",
      "Lianne Ippel",
      "Andre Dekkers"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.09990",
    "title": "FlowPool: Pooling Graph Representations with Wasserstein Gradient Flows",
    "abstract": " Title: FlowPool: Pooling Graph Representations with Wasserstein Gradient Flows ",
    "url": "https://arxiv.org/abs/2112.09990",
    "authors": [
      "Effrosyni Simou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04929",
    "title": "Improving VAE based molecular representations for compound property  prediction",
    "abstract": " Title: Improving VAE based molecular representations for compound property  prediction ",
    "url": "https://arxiv.org/abs/2201.04929",
    "authors": [
      "A. Tevosyan",
      "L. Khondkaryan",
      "H. Khachatrian",
      "G. Tadevosyan",
      "L. Apresyan",
      "N. Babayan",
      "H. Stopper",
      "Z. Navoyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.10737",
    "title": "Class-Aware Generative Adversarial Transformers for Medical Image  Segmentation",
    "abstract": " Title: Class-Aware Generative Adversarial Transformers for Medical Image  Segmentation ",
    "url": "https://arxiv.org/abs/2201.10737",
    "authors": [
      "Chenyu You",
      "Ruihan Zhao",
      "Fenglin Liu",
      "Siyuan Dong",
      "Sandeep Chinchali",
      "Ufuk Topcu",
      "Lawrence Staib",
      "James S. Duncan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2202.00645",
    "title": "Generalization Analysis of Message Passing Neural Networks on Large  Random Graphs",
    "abstract": " Comments: Preprint in Review ",
    "url": "https://arxiv.org/abs/2202.00645",
    "authors": [
      "Sohir Maskey",
      "Ron Levie",
      "Yunseok Lee",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2202.03609",
    "title": "Backdoor Detection in Reinforcement Learning",
    "abstract": " Title: Backdoor Detection in Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2202.03609",
    "authors": [
      "Junfeng Guo",
      "Ang Li",
      "Cong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.03918",
    "title": "Network Coding Multicast Key-Capacity",
    "abstract": " Title: Network Coding Multicast Key-Capacity ",
    "url": "https://arxiv.org/abs/2202.03918",
    "authors": [
      "Michael Langberg",
      "Michelle Effros"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.05267",
    "title": "On Real-time Image Reconstruction with Neural Networks for MRI-guided  Radiotherapy",
    "abstract": " Comments: 12 pages, 6 figures, 1 table. v2 has a typo in eqn 1 corrected and references added to the discussion ",
    "url": "https://arxiv.org/abs/2202.05267",
    "authors": [
      "David E. J. Waddington",
      "Nicholas Hindley",
      "Neha Koonjoo",
      "Christopher Chiu",
      "Tess Reynolds",
      "Paul Z. Y. Liu",
      "Bo Zhu",
      "Danyal Bhutto",
      "Chiara Paganelli",
      "Paul J. Keall",
      "Matthew S. Rosen"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.00213",
    "title": "Optimal Routing for Multi-user Multi-hop Relay Networks via Dynamic  Programming",
    "abstract": " Comments: Extended Version, Accepted to IEEE Wireless Communications Letters ",
    "url": "https://arxiv.org/abs/2203.00213",
    "authors": [
      "Shalanika Dayarathna",
      "Rajitha Senanayake",
      "Jamie Evans"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.05241",
    "title": "Theory of Network Wave",
    "abstract": " Title: Theory of Network Wave ",
    "url": "https://arxiv.org/abs/2203.05241",
    "authors": [
      "Bo Li",
      "Mao Yang",
      "Zhongjiang Yan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.09185",
    "title": "Phase Optimization for Massive IRS-aided Two-way Relay Network",
    "abstract": " Comments: 9 pages,10 figures ",
    "url": "https://arxiv.org/abs/2203.09185",
    "authors": [
      "Peng Zhang",
      "Xuehui Wang",
      "Siling Feng",
      "Zhongwen Sun",
      "Feng Shu",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.12481",
    "title": "Prompt-based System for Personality and Interpersonal Reactivity  Prediction",
    "abstract": " Comments: Published in Software Impacts ",
    "url": "https://arxiv.org/abs/2203.12481",
    "authors": [
      "Bin Li",
      "Yixuan Weng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.13544",
    "title": "Performance evaluation of switching between WiFi and LiFi under a common  virtual network interface",
    "abstract": " Comments: 6 pages, 12 figures (including subfigures), 2 tables, conference paper ",
    "url": "https://arxiv.org/abs/2203.13544",
    "authors": [
      "Loreto Pescosolido",
      "Emilio Ancillotti",
      "Andrea Passarella"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.16662",
    "title": "Overcoming challenges in leveraging GANs for few-shot data augmentation",
    "abstract": " Comments: v2 of the paper, updated with better figures and with semi-supervised results ",
    "url": "https://arxiv.org/abs/2203.16662",
    "authors": [
      "Christopher Beckham",
      "Issam Laradji",
      "Pau Rodriguez",
      "David Vazquez",
      "Derek Nowrouzezahrai",
      "Christopher Pal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.17066",
    "title": "Cross-modal Learning of Graph Representations using Radar Point Cloud  for Long-Range Gesture Recognition",
    "abstract": " Comments: Accepted by IEEE Sensor Array and Multichannel Signal Processing Workshop (SAM 2022) ",
    "url": "https://arxiv.org/abs/2203.17066",
    "authors": [
      "Souvik Hazra",
      "Hao Feng",
      "Gamze Naz Kiprit",
      "Michael Stephan",
      "Lorenzo Servadei",
      "Robert Wille",
      "Robert Weigel",
      "Avik Santra"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.02964",
    "title": "Unleashing Vanilla Vision Transformer with Masked Image Modeling for  Object Detection",
    "abstract": " Comments: v2: more analysis & stronger results. Preprint. Work in progress. Code and pre-trained models are available at this https URL ",
    "url": "https://arxiv.org/abs/2204.02964",
    "authors": [
      "Yuxin Fang",
      "Shusheng Yang",
      "Shijie Wang",
      "Yixiao Ge",
      "Ying Shan",
      "Xinggang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.07539",
    "title": "Stability and Robustness of a Hybrid Control Law for the Half-bridge  Inverter",
    "abstract": " Title: Stability and Robustness of a Hybrid Control Law for the Half-bridge  Inverter ",
    "url": "https://arxiv.org/abs/2204.07539",
    "authors": [
      "Gabriel E. Col\u00f3n-Reyes",
      "Kaylene C. Stocking",
      "Duncan S. Callaway",
      "Claire J. Tomlin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.09803",
    "title": "GUARD: Graph Universal Adversarial Defense",
    "abstract": " Comments: Preprint. Code is publicly available at this https URL ",
    "url": "https://arxiv.org/abs/2204.09803",
    "authors": [
      "Jintang Li",
      "Jie Liao",
      "Ruofan Wu",
      "Liang Chen",
      "Jiawang Dan",
      "Changhua Meng",
      "Zibin Zheng",
      "Weiqiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2204.11887",
    "title": "Evolutionary latent space search for driving human portrait generation",
    "abstract": " Comments: This paper was accepted and presented during the 2021 IEEE Latin American Conference on Computational Intelligence (LA-CCI) ",
    "url": "https://arxiv.org/abs/2204.11887",
    "authors": [
      "Benjam\u00edn Mach\u00edn",
      "Sergio Nesmachnow",
      "Jamal Toutouh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.02162",
    "title": "UnrealNAS: Can We Search Neural Architectures with Unreal Data?",
    "abstract": " Title: UnrealNAS: Can We Search Neural Architectures with Unreal Data? ",
    "url": "https://arxiv.org/abs/2205.02162",
    "authors": [
      "Zhen Dong",
      "Kaicheng Zhou",
      "Guohao Li",
      "Qiang Zhou",
      "Mingfei Guo",
      "Bernard Ghanem",
      "Kurt Keutzer",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.02260",
    "title": "Multivariate Prediction Intervals for Random Forests",
    "abstract": " Comments: 9 pages, 4 figures. Submitted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.02260",
    "authors": [
      "Brendan Folie",
      "Maxwell Hutchinson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.02517",
    "title": "A Simple Contrastive Learning Objective for Alleviating Neural Text  Degeneration",
    "abstract": " Comments: 22 pages, 11 figures, 8 tables ",
    "url": "https://arxiv.org/abs/2205.02517",
    "authors": [
      "Shaojie Jiang",
      "Ruqing Zhang",
      "Svitlana Vakulenko",
      "Maarten de Rijke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.04042",
    "title": "Incremental-DETR: Incremental Few-Shot Object Detection via  Self-Supervised Learning",
    "abstract": " Comments: 11 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2205.04042",
    "authors": [
      "Na Dong",
      "Yongqiang Zhang",
      "Mingli Ding",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.04051",
    "title": "Unsupervised Learning of Rydberg Atom Array Phase Diagram with Siamese  Neural Networks",
    "abstract": " Title: Unsupervised Learning of Rydberg Atom Array Phase Diagram with Siamese  Neural Networks ",
    "url": "https://arxiv.org/abs/2205.04051",
    "authors": [
      "Zakaria Patel",
      "Ejaaz Merali",
      "Sebastian J. Wetzel"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Quantum Gases (cond-mat.quant-gas)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2205.05874",
    "title": "Distinction Maximization Loss: Efficiently Improving Classification  Accuracy, Uncertainty Estimation, and Out-of-Distribution Detection Simply  Replacing the Loss and Calibrating",
    "abstract": " Title: Distinction Maximization Loss: Efficiently Improving Classification  Accuracy, Uncertainty Estimation, and Out-of-Distribution Detection Simply  Replacing the Loss and Calibrating ",
    "url": "https://arxiv.org/abs/2205.05874",
    "authors": [
      "David Mac\u00eado",
      "Cleber Zanchettin",
      "Teresa Ludermir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.06296",
    "title": "Integrating User and Item Reviews in Deep Cooperative Neural Networks  for Movie Ranking Prediction",
    "abstract": " Comments: 13 pages, typos corrected, references added ",
    "url": "https://arxiv.org/abs/2205.06296",
    "authors": [
      "Aristeidis Karras",
      "Christos Karras"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.07403",
    "title": "PillarNet: Real-Time and High-Performance Pillar-based 3D Object  Detection",
    "abstract": " Title: PillarNet: Real-Time and High-Performance Pillar-based 3D Object  Detection ",
    "url": "https://arxiv.org/abs/2205.07403",
    "authors": [
      "Guangsheng Shi",
      "Ruifeng Li",
      "Chao Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.07422",
    "title": "PrEF: Percolation-based Evolutionary Framework for the  diffusion-source-localization problem in large networks",
    "abstract": " Title: PrEF: Percolation-based Evolutionary Framework for the  diffusion-source-localization problem in large networks ",
    "url": "https://arxiv.org/abs/2205.07422",
    "authors": [
      "Yang Liu",
      "Xiaoqi Wang",
      "Xi Wang",
      "Zhen Wang",
      "J\u00fcrgen Kurths"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2205.08565",
    "title": "Text Detection & Recognition in the Wild for Robot Localization",
    "abstract": " Comments: 6 papged, VI section, typos corrected, revison changes, no result changes ",
    "url": "https://arxiv.org/abs/2205.08565",
    "authors": [
      "Zobeir Raisi",
      "John Zelek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.08689",
    "title": "Spatial-Temporal Interactive Dynamic Graph Convolution Network for  Traffic Forecasting",
    "abstract": " Title: Spatial-Temporal Interactive Dynamic Graph Convolution Network for  Traffic Forecasting ",
    "url": "https://arxiv.org/abs/2205.08689",
    "authors": [
      "Aoyu Liu",
      "Yaying Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.08924",
    "title": "Financial Time Series Data Augmentation with Generative Adversarial  Networks and Extended Intertemporal Return Plots",
    "abstract": " Title: Financial Time Series Data Augmentation with Generative Adversarial  Networks and Extended Intertemporal Return Plots ",
    "url": "https://arxiv.org/abs/2205.08924",
    "authors": [
      "Justin Hellermann",
      "Qinzhuan Qian",
      "Ankit Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]