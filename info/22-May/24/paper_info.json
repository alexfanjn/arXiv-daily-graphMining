[
  {
    "id": "arXiv:2205.10358",
    "title": "A Hardware-Aware Framework for Accelerating Neural Architecture Search  Across Modalities",
    "abstract": "Recent advances in Neural Architecture Search (NAS) such as one-shot NAS offer the ability to extract specialized hardware-aware sub-network configurations from a task-specific super-network. While considerable effort has been employed towards improving the first stage, namely, the training of the super-network, the search for derivative high-performing sub-networks is still under-explored. Popular methods decouple the super-network training from the sub-network search and use performance predictors to reduce the computational burden of searching on different hardware platforms. We propose a flexible search framework that automatically and efficiently finds optimal sub-networks that are optimized for different performance metrics and hardware configurations. Specifically, we show how evolutionary algorithms can be paired with lightly trained objective predictors in an iterative cycle to accelerate architecture search in a multi-objective setting for various modalities including machine translation and image classification. ",
    "url": "https://arxiv.org/abs/2205.10358",
    "authors": [
      "Daniel Cummings",
      "Anthony Sarah",
      "Sharath Nittur Sridhar",
      "Maciej Szankin",
      "Juan Pablo Munoz",
      "Sairam Sundaresan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10363",
    "title": "Robust Task-Oriented Dialogue Generation with Contrastive Pre-training  and Adversarial Filtering",
    "abstract": "Data artifacts incentivize machine learning models to learn non-transferable generalizations by taking advantage of shortcuts in the data, and there is growing evidence that data artifacts play a role for the strong results that deep learning models achieve in recent natural language processing benchmarks. In this paper, we focus on task-oriented dialogue and investigate whether popular datasets such as MultiWOZ contain such data artifacts. We found that by only keeping frequent phrases in the training examples, state-of-the-art models perform similarly compared to the variant trained with full data, suggesting they exploit these spurious correlations to solve the task. Motivated by this, we propose a contrastive learning based framework to encourage the model to ignore these cues and focus on learning generalisable patterns. We also experiment with adversarial filtering to remove \"easy\" training instances so that the model would focus on learning from the \"harder\" instances. We conduct a number of generalization experiments -- e.g., cross-domain/dataset and adversarial tests -- to assess the robustness of our approach and found that it works exceptionally well. ",
    "url": "https://arxiv.org/abs/2205.10363",
    "authors": [
      "Shiquan Yang",
      "Xinting Huang",
      "Jey Han Lau",
      "Sarah Erfani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.10365",
    "title": "A Correlation Information-based Spatiotemporal Network for Traffic Flow  Forecasting",
    "abstract": "With the growth of transport modes, high traffic forecasting precision is required in intelligent transportation systems. Most previous works utilize the transformer architecture based on graph neural networks and attention mechanisms to discover spatiotemporal dependencies and dynamic relationships. The correlation information among spatiotemporal sequences, however, has not been thoroughly considered. In this paper, we present two elaborate spatiotemporal representations, spatial correlation information (SCorr) and temporal correlation information (TCorr), among spatiotemporal sequences based on the maximal information coefficient. Using SCorr, we propose a novel correlation information-based spatiotemporal network (CorrSTN), including a dynamic graph neural network component incorporating correlation information into the spatial structure effectively and a multi-head attention component utilizing spatial correlation information to extract dynamic temporal dependencies accurately. Using TCorr, we further explore the correlation pattern among different periodic data and then propose a novel data selection scheme to identify the most relevant data. The experimental results on the highway traffic flow (PEMS07 and PEMS08) and metro crowd flow (HZME inflow and outflow) datasets demonstrate that CorrSTN outperforms the state-of-the-art methods in terms of predictive performance. In particular, on the HZME (outflow) dataset, our model makes significant improvements compared with the latest model ASTGNN by 12.7%, 14.4% and 27.4% in the metrics of MAE, RMSE and MAPE, respectively. ",
    "url": "https://arxiv.org/abs/2205.10365",
    "authors": [
      "Weiguo Zhu",
      "Yongqi Sun",
      "Xintong Yi",
      "Yan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10386",
    "title": "A Dynamic Weighted Tabular Method for Convolutional Neural Networks",
    "abstract": "Traditional Machine Learning (ML) models like Support Vector Machine, Random Forest, and Logistic Regression are generally preferred for classification tasks on tabular datasets. Tabular data consists of rows and columns corresponding to instances and features, respectively. Past studies indicate that traditional classifiers often produce unsatisfactory results in complex tabular datasets. Hence, researchers attempt to use the powerful Convolutional Neural Networks (CNN) for tabular datasets. Recent studies propose several techniques like SuperTML, Conditional GAN (CTGAN), and Tabular Convolution (TAC) for applying Convolutional Neural Networks (CNN) on tabular data. These models outperform the traditional classifiers and substantially improve the performance on tabular data. This study introduces a novel technique, namely, Dynamic Weighted Tabular Method (DWTM), that uses feature weights dynamically based on statistical techniques to apply CNNs on tabular datasets. The method assigns weights dynamically to each feature based on their strength of associativity to the class labels. Each data point is converted into images and fed to a CNN model. The features are allocated image canvas space based on their weights. The DWTM is an improvement on the previously mentioned methods as it dynamically implements the entire experimental setting rather than using the static configuration provided in the previous methods. Furthermore, it uses the novel idea of using feature weights to create image canvas space. In this paper, the DWTM is applied to six benchmarked tabular datasets and it achieves outstanding performance (i.e., average accuracy = 95%) on all of them. ",
    "url": "https://arxiv.org/abs/2205.10386",
    "authors": [
      "Md Ifraham Iqbal",
      "Md. Saddam Hossain Mukta",
      "Ahmed Rafi Hasan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10390",
    "title": "EGR: Equivariant Graph Refinement and Assessment of 3D Protein Complex  Structures",
    "abstract": "Protein complexes are macromolecules essential to the functioning and well-being of all living organisms. As the structure of a protein complex, in particular its region of interaction between multiple protein subunits (i.e., chains), has a notable influence on the biological function of the complex, computational methods that can quickly and effectively be used to refine and assess the quality of a protein complex's 3D structure can directly be used within a drug discovery pipeline to accelerate the development of new therapeutics and improve the efficacy of future vaccines. In this work, we introduce the Equivariant Graph Refiner (EGR), a novel E(3)-equivariant graph neural network (GNN) for multi-task structure refinement and assessment of protein complexes. Our experiments on new, diverse protein complex datasets, all of which we make publicly available in this work, demonstrate the state-of-the-art effectiveness of EGR for atomistic refinement and assessment of protein complexes and outline directions for future work in the field. In doing so, we establish a baseline for future studies in macromolecular refinement and structure analysis. ",
    "url": "https://arxiv.org/abs/2205.10390",
    "authors": [
      "Alex Morehead",
      "Xiao Chen",
      "Tianqi Wu",
      "Jian Liu",
      "Jianlin Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.10400",
    "title": "Multi2WOZ: A Robust Multilingual Dataset and Conversational Pretraining  for Task-Oriented Dialog",
    "abstract": "Research on (multi-domain) task-oriented dialog (TOD) has predominantly focused on the English language, primarily due to the shortage of robust TOD datasets in other languages, preventing the systematic investigation of cross-lingual transfer for this crucial NLP application area. In this work, we introduce Multi2WOZ, a new multilingual multi-domain TOD dataset, derived from the well-established English dataset MultiWOZ, that spans four typologically diverse languages: Chinese, German, Arabic, and Russian. In contrast to concurrent efforts, Multi2WOZ contains gold-standard dialogs in target languages that are directly comparable with development and test portions of the English dataset, enabling reliable and comparative estimates of cross-lingual transfer performance for TOD. We then introduce a new framework for multilingual conversational specialization of pretrained language models (PrLMs) that aims to facilitate cross-lingual transfer for arbitrary downstream TOD tasks. Using such conversational PrLMs specialized for concrete target languages, we systematically benchmark a number of zero-shot and few-shot cross-lingual transfer approaches on two standard TOD tasks: Dialog State Tracking and Response Retrieval. Our experiments show that, in most setups, the best performance entails the combination of (I) conversational specialization in the target language and (ii) few-shot transfer for the concrete TOD task. Most importantly, we show that our conversational specialization in the target language allows for an exceptionally sample-efficient few-shot transfer for downstream TOD tasks. ",
    "url": "https://arxiv.org/abs/2205.10400",
    "authors": [
      "Chia-Chien Hung",
      "Anne Lauscher",
      "Ivan Vuli\u0107",
      "Simone Paolo Ponzetto",
      "Goran Glava\u0161"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.10403",
    "title": "Tackling Provably Hard Representative Selection via Graph Neural  Networks",
    "abstract": "Representative selection (RS) is the problem of finding a small subset of exemplars from an unlabeled dataset, and has numerous applications in summarization, active learning, data compression and many other domains. In this paper, we focus on finding representatives that optimize the accuracy of a model trained on the selected representatives. We study RS for data represented as attributed graphs. We develop RS-GNN, a representation learning-based RS model based on Graph Neural Networks. Empirically, we demonstrate the effectiveness of RS-GNN on problems with predefined graph structures as well as problems with graphs induced from node feature similarities, by showing that RS-GNN achieves significant improvements over established baselines that optimize surrogate functions. Theoretically, we establish a new hardness result for RS by proving that RS is hard to approximate in polynomial time within any reasonable factor, which implies a significant gap between the optimum solution of widely-used surrogate functions and the actual accuracy of the model, and provides justification for the superiority of representation learning-based approaches such as RS-GNN over surrogate functions. ",
    "url": "https://arxiv.org/abs/2205.10403",
    "authors": [
      "Seyed Mehran Kazemi",
      "Anton Tsitsulin",
      "Hossein Esfandiari",
      "MohammadHossein Bateni",
      "Deepak Ramachandran",
      "Bryan Perozzi",
      "Vahab Mirrokni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2205.10405",
    "title": "Demo: A Transparent Antenna System for In-Building Networks",
    "abstract": "For in-building networks, the potential of transparent antennas, which are used as windows of a building, is presented in this paper. In this scenario, a transparent window antenna communicates with outdoor devices or base stations, and the indoor repeaters act as relay stations of the transparent window antenna for indoor devices. At indoor, back lobe waves of the transparent window antenna are defined as interference to in-building networks. Hence, we analyze different SIR and SINR results according to the location of an indoor repeater through 3D ray tracing system-level simulation. Furthermore, a link-level simulation through a full-duplex software-defined radio platform with the fabricated transparent antenna is presented to examine the feasibility of the transparent antenna. ",
    "url": "https://arxiv.org/abs/2205.10405",
    "authors": [
      "Sang-Hyun Park",
      "Soo-Min Kim",
      "Seonghoon Kim",
      "HongIl Yoo",
      "Byoungnam Kim",
      "Chan-Byoung Chae"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.10406",
    "title": "Combining Contrastive and Supervised Learning for Video Super-Resolution  Detection",
    "abstract": "Upscaled video detection is a helpful tool in multimedia forensics, but it is a challenging task that involves various upscaling and compression algorithms. There are many resolution-enhancement methods, including interpolation and deep-learning-based super-resolution, and they leave unique traces. In this work, we propose a new upscaled-resolution-detection method based on learning of visual representations using contrastive and cross-entropy losses. To explain how the method detects videos, we systematically review the major components of our framework - in particular, we show that most data-augmentation approaches hinder the learning of the method. Through extensive experiments on various datasets, we demonstrate that our method effectively detects upscaling even in compressed videos and outperforms the state-of-the-art alternatives. The code and models are publicly available at https://github.com/msu-video-group/SRDM ",
    "url": "https://arxiv.org/abs/2205.10406",
    "authors": [
      "Viacheslav Meshchaninov",
      "Ivan Molodetskikh",
      "Dmitriy Vatolin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10408",
    "title": "Forecasting COVID-19 Caseloads Using Unsupervised Embedding Clusters of  Social Media Posts",
    "abstract": "We present a novel approach incorporating transformer-based language models into infectious disease modelling. Text-derived features are quantified by tracking high-density clusters of sentence-level representations of Reddit posts within specific US states' COVID-19 subreddits. We benchmark these clustered embedding features against features extracted from other high-quality datasets. In a threshold-classification task, we show that they outperform all other feature types at predicting upward trend signals, a significant result for infectious disease modelling in areas where epidemiological data is unreliable. Subsequently, in a time-series forecasting task we fully utilise the predictive power of the caseload and compare the relative strengths of using different supplementary datasets as covariate feature sets in a transformer-based time-series model. ",
    "url": "https://arxiv.org/abs/2205.10408",
    "authors": [
      "Felix Drinkall",
      "Stefan Zohren",
      "Janet B. Pierrehumbert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.10439",
    "title": "How Useful are Gradients for OOD Detection Really?",
    "abstract": "One critical challenge in deploying highly performant machine learning models in real-life applications is out of distribution (OOD) detection. Given a predictive model which is accurate on in distribution (ID) data, an OOD detection system will further equip the model with the option to defer prediction when the input is novel and the model has little confidence in prediction. There has been some recent interest in utilizing the gradient information in pre-trained models for OOD detection. While these methods have shown competitive performance, there are misconceptions about the true mechanism underlying them, which conflate their performance with the necessity of gradients. In this work, we provide an in-depth analysis and comparison of gradient based methods and elucidate the key components that warrant their OOD detection performance. We further propose a general, non-gradient based method of OOD detection which improves over previous baselines in both performance and computational efficiency. ",
    "url": "https://arxiv.org/abs/2205.10439",
    "authors": [
      "Conor Igoe",
      "Youngseog Chung",
      "Ian Char",
      "Jeff Schneider"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10450",
    "title": "Temporally Precise Action Spotting in Soccer Videos Using Dense  Detection Anchors",
    "abstract": "We present a model for temporally precise action spotting in videos, which uses a dense set of detection anchors, predicting a detection confidence and corresponding fine-grained temporal displacement for each anchor. We experiment with two trunk architectures, both of which are able to incorporate large temporal contexts while preserving the smaller-scale features required for precise localization: a one-dimensional version of a u-net, and a Transformer encoder (TE). We also suggest best practices for training models of this kind, by applying Sharpness-Aware Minimization (SAM) and mixup data augmentation. We achieve a new state-of-the-art on SoccerNet-v2, the largest soccer video dataset of its kind, with marked improvements in temporal localization. Additionally, our ablations show: the importance of predicting the temporal displacements; the trade-offs between the u-net and TE trunks; and the benefits of training with SAM and mixup. ",
    "url": "https://arxiv.org/abs/2205.10450",
    "authors": [
      "Jo\u00e3o V. B. Soares",
      "Avijit Shah",
      "Topojoy Biswas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10456",
    "title": "PSO-Convolutional Neural Networks with Heterogeneous Learning Rate",
    "abstract": "Convolutional Neural Networks (ConvNets) have been candidly deployed in the scope of computer vision and related fields. Nevertheless, the dynamics of training of these neural networks lie still elusive: it is hard and computationally expensive to train them. A myriad of architectures and training strategies have been proposed to overcome this challenge and address several problems in image processing such as speech, image and action recognition as well as object detection. In this article, we propose a novel Particle Swarm Optimization (PSO) based training for ConvNets. In such framework, the vector of weights of each ConvNet is typically cast as the position of a particle in phase space whereby PSO collaborative dynamics intertwines with Stochastic Gradient Descent (SGD) in order to boost training performance and generalization. Our approach goes as follows: i) [warm-up phase] each ConvNet is trained independently via SGD; ii) [collaborative phase] ConvNets share among themselves their current vector of weights (or particle-position) along with their gradient estimates of the Loss function. Distinct step sizes are coined by distinct ConvNets. By properly blending ConvNets with large (possibly random) step-sizes along with more conservative ones, we propose an algorithm with competitive performance with respect to other PSO-based approaches on Cifar-10 (accuracy of 98.31%). These accuracy levels are obtained by resorting to only four ConvNets -- such results are expected to scale with the number of collaborative ConvNets accordingly. We make our source codes available for download https://github.com/leonlha/PSO-ConvNet-Dynamics. ",
    "url": "https://arxiv.org/abs/2205.10456",
    "authors": [
      "Nguyen Huu Phong",
      "Augusto Santos",
      "Bernardete Ribeiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.10457",
    "title": "Robust Sensible Adversarial Learning of Deep Neural Networks for Image  Classification",
    "abstract": "The idea of robustness is central and critical to modern statistical analysis. However, despite the recent advances of deep neural networks (DNNs), many studies have shown that DNNs are vulnerable to adversarial attacks. Making imperceptible changes to an image can cause DNN models to make the wrong classification with high confidence, such as classifying a benign mole as a malignant tumor and a stop sign as a speed limit sign. The trade-off between robustness and standard accuracy is common for DNN models. In this paper, we introduce sensible adversarial learning and demonstrate the synergistic effect between pursuits of standard natural accuracy and robustness. Specifically, we define a sensible adversary which is useful for learning a robust model while keeping high natural accuracy. We theoretically establish that the Bayes classifier is the most robust multi-class classifier with the 0-1 loss under sensible adversarial learning. We propose a novel and efficient algorithm that trains a robust model using implicit loss truncation. We apply sensible adversarial learning for large-scale image classification to a handwritten digital image dataset called MNIST and an object recognition colored image dataset called CIFAR10. We have performed an extensive comparative study to compare our method with other competitive methods. Our experiments empirically demonstrate that our method is not sensitive to its hyperparameter and does not collapse even with a small model capacity while promoting robustness against various attacks and keeping high natural accuracy. ",
    "url": "https://arxiv.org/abs/2205.10457",
    "authors": [
      "Jungeum Kim",
      "Xiao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.10459",
    "title": "Multi-stage Resilience Management of Smart Power Distribution Systems: A  Stochastic Robust Optimization Model",
    "abstract": "Significant outages from weather and climate extremes have highlighted the critical need for resilience-centered risk management of the grid. This paper proposes a multi-stage stochastic robust optimization (SRO) model that advances the existing planning frameworks on two main fronts. First, it captures interactions of operational measures with hardening decisions. Second, it properly treats the multitude of uncertainties in planning. The SRO model coordinates hardening and system operational measures for smart power distribution systems equipped with distributed generation units and switches. To capture the uncertainty in the incurred damage by extreme events, an uncertainty set is developed by integrating probabilistic information of hurricanes with the performance of overhead structures. A novel probabilistic model for the repair time of damaged lines is derived to account for the uncertainty in the recovery process. A solution strategy based on the integration of a differential evolution algorithm and a mixed-integer solver is designed to solve the resilience maximization model. The proposed approach is applied to a modified IEEE 33-bus system with 485 utility poles and a 118-bus system with 1841 poles. The systems are mapped on the Harris County, TX, U.S. Results reveal that optimal hardening decisions can be significantly influenced by resilience operational measures. ",
    "url": "https://arxiv.org/abs/2205.10459",
    "authors": [
      "Nariman L. Dehghani",
      "Abdollah Shafieezadeh"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2205.10475",
    "title": "DeepStruct: Pretraining of Language Models for Structure Prediction",
    "abstract": "We introduce a method for improving the structural understanding abilities of language models. Unlike previous approaches that finetune the models with task-specific augmentation, we pretrain language models on a collection of task-agnostic corpora to generate structures from text. Our structure pretraining enables zero-shot transfer of the learned knowledge that models have about the structure tasks. We study the performance of this approach on 28 datasets, spanning 10 structure prediction tasks including open information extraction, joint entity and relation extraction, named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, factual probe, intent detection, and dialogue state tracking. We further enhance the pretraining with the task-specific training sets. We show that a 10B parameter language model transfers non-trivially to most tasks and obtains state-of-the-art performance on 21 of 28 datasets that we evaluate. ",
    "url": "https://arxiv.org/abs/2205.10475",
    "authors": [
      "Chenguang Wang",
      "Xiao Liu",
      "Zui Chen",
      "Haoyun Hong",
      "Jie Tang",
      "Dawn Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10479",
    "title": "DKG: A Descriptive Knowledge Graph for Explaining Relationships between  Entities",
    "abstract": "In this paper, we propose Descriptive Knowledge Graph (DKG) - an open and interpretable form of modeling relationships between entities. In DKGs, relationships between entities are represented by relation descriptions. For instance, the relationship between entities of machine learning and algorithm can be described as \"Machine learning explores the study and construction of algorithms that can learn from and make predictions on data.\" To construct DKGs, we propose a self-supervised learning method to extract relation descriptions with the analysis of dependency patterns and a transformer-based relation description synthesizing model to generate relation descriptions. Experiments demonstrate that our system can extract and generate high-quality relation descriptions for explaining entity relationships. ",
    "url": "https://arxiv.org/abs/2205.10479",
    "authors": [
      "Jie Huang",
      "Kerui Zhu",
      "Kevin Chen-Chuan Chang",
      "Jinjun Xiong",
      "Wen-mei Hwu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10481",
    "title": "Semi-Supervised Subspace Clustering via Tensor Low-Rank Representation",
    "abstract": "In this letter, we propose a novel semi-supervised subspace clustering method, which is able to simultaneously augment the initial supervisory information and construct a discriminative affinity matrix. By representing the limited amount of supervisory information as a pairwise constraint matrix, we observe that the ideal affinity matrix for clustering shares the same low-rank structure as the ideal pairwise constraint matrix. Thus, we stack the two matrices into a 3-D tensor, where a global low-rank constraint is imposed to promote the affinity matrix construction and augment the initial pairwise constraints synchronously. Besides, we use the local geometry structure of input samples to complement the global low-rank prior to achieve better affinity matrix learning. The proposed model is formulated as a Laplacian graph regularized convex low-rank tensor representation problem, which is further solved with an alternative iterative algorithm. In addition, we propose to refine the affinity matrix with the augmented pairwise constraints. Comprehensive experimental results on six commonly-used benchmark datasets demonstrate the superiority of our method over state-of-the-art methods. The code is publicly available at https://github.com/GuanxingLu/Subspace-Clustering. ",
    "url": "https://arxiv.org/abs/2205.10481",
    "authors": [
      "Guanxing Lu",
      "Yuheng Jia",
      "Junhui Hou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10489",
    "title": "Social Fragmentation Transitions in Large-Scale Adaptive Social Network  Simulations",
    "abstract": "Social fragmentation transition is a transition of social states between many disconnected communities with distinct opinions and a well-connected single network with homogeneous opinions. This is a timely research topic with high relevance to various current societal issues. We had previously studied this problem using numerical simulations of adaptive social network models and found that two individual behavioral traits, homophily and attention to novelty, had the most statistically significant impact on the outcomes of social network evolution. However, our previous study was limited in terms of the range of parameter values examined, and possible interactions between multiple behavioral traits were largely ignored. In this study, we conducted a substantially larger-scale numerical simulation experiment of the same model with an expanded parameter sweep range by an order of magnitude in each parameter dimension, resulting in a total of 116,640 simulation runs. To capture nontrivial interactions among behavioral parameters, we modeled and visualized the dependence of outcome measures on the model parameters using artificial neural networks. Results show that, while the competition between homophily and attention to novelty is still the primary determinant of social fragmentation, another transition plane emerges when individuals have strong social conformity behavior, which was not previously known. This implies that social fragmentation transition can also occur in the homophily-social conformity trade-off, the two behavioral traits that have very similar microscopic individual-level effects but produce very different macroscopic collective-level outcomes, illustrating the nontrivial macroscopic dynamics of complex collective systems. ",
    "url": "https://arxiv.org/abs/2205.10489",
    "authors": [
      "Hiroki Sayama"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2205.10495",
    "title": "Enriched Robust Multi-View Kernel Subspace Clustering",
    "abstract": "Subspace clustering is to find underlying low-dimensional subspaces and cluster the data points correctly. In this paper, we propose a novel multi-view subspace clustering method. Most existing methods suffer from two critical issues. First, they usually adopt a two-stage framework and isolate the processes of affinity learning, multi-view information fusion and clustering. Second, they assume the data lies in a linear subspace which may fail in practice as most real-world datasets may have non-linearity structures. To address the above issues, in this paper we propose a novel Enriched Robust Multi-View Kernel Subspace Clustering framework where the consensus affinity matrix is learned from both multi-view data and spectral clustering. Due to the objective and constraints which is difficult to optimize, we propose an iterative optimization method which is easy to implement and can yield closed solution in each step. Extensive experiments have validated the superiority of our method over state-of-the-art clustering methods. ",
    "url": "https://arxiv.org/abs/2205.10495",
    "authors": [
      "Mengyuan Zhang",
      "Kai Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10497",
    "title": "eBIM-GNN : Fast and Scalable energy analysis through BIMs and Graph  Neural Networks",
    "abstract": "Building Information Modeling has been used to analyze as well as increase the energy efficiency of the buildings. It has shown significant promise in existing buildings by deconstruction and retrofitting. Current cities which were built without the knowledge of energy savings are now demanding better ways to become smart in energy utilization. However, the existing methods of generating BIMs work on building basis. Hence they are slow and expensive when we scale to a larger community or even entire towns or cities. In this paper, we propose a method to creation of prototype buildings that enable us to match and generate statistics very efficiently. Our method suggests better energy efficient prototypes for the existing buildings. The existing buildings are identified and located in the 3D point cloud. We perform experiments on synthetic dataset to demonstrate the working of our approach. ",
    "url": "https://arxiv.org/abs/2205.10497",
    "authors": [
      "Rucha Bhalchandra Joshi",
      "Annada Prasad Behera",
      "Subhankar Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10507",
    "title": "Travel Time, Distance and Costs Optimization for Paratransit Operations  using Graph Convolutional Neural Network",
    "abstract": "The provision of paratransit services is one option to meet the transportation needs of Vulnerable Road Users (VRUs). Like any other means of transportation, paratransit has obstacles such as high operational costs and longer trip times. As a result, customers are dissatisfied, and paratransit operators have a low approval rating. Researchers have undertaken various studies over the years to better understand the travel behaviors of paratransit customers and how they are operated. According to the findings of these researches, paratransit operators confront the challenge of determining the optimal route for their trips in order to save travel time. Depending on the nature of the challenge, most research used different optimization techniques to solve these routing problems. As a result, the goal of this study is to use Graph Convolutional Neural Networks (GCNs) to assist paratransit operators in researching various operational scenarios in a strategic setting in order to optimize routing, minimize operating costs and minimize their users' travel time. The study was carried out by using a randomized simulated dataset to help determine the decision to make in terms of fleet composition and capacity under different situations. For the various scenarios investigated, the GCN assisted in determining the minimum optimal gap. ",
    "url": "https://arxiv.org/abs/2205.10507",
    "authors": [
      "Kelvin Kwakye",
      "Younho Seong",
      "Sun Yi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10511",
    "title": "Improving Long Tailed Document-Level Relation Extraction via Easy  Relation Augmentation and Contrastive Learning",
    "abstract": "Towards real-world information extraction scenario, research of relation extraction is advancing to document-level relation extraction(DocRE). Existing approaches for DocRE aim to extract relation by encoding various information sources in the long context by novel model architectures. However, the inherent long-tailed distribution problem of DocRE is overlooked by prior work. We argue that mitigating the long-tailed distribution problem is crucial for DocRE in the real-world scenario. Motivated by the long-tailed distribution problem, we propose an Easy Relation Augmentation(ERA) method for improving DocRE by enhancing the performance of tailed relations. In addition, we further propose a novel contrastive learning framework based on our ERA, i.e., ERACL, which can further improve the model performance on tailed relations and achieve competitive overall DocRE performance compared to the state-of-arts. ",
    "url": "https://arxiv.org/abs/2205.10511",
    "authors": [
      "Yangkai Du",
      "Tengfei Ma",
      "Lingfei Wu",
      "Yiming Wu",
      "Xuhong Zhang",
      "Bo Long",
      "Shouling Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10528",
    "title": "Point is a Vector: A Feature Representation in Point Analysis",
    "abstract": "The irregularity and disorder of point clouds bring many challenges to point cloud analysis. PointMLP suggests that geometric information is not the only critical point in point cloud analysis. It achieves promising result based on a simple multi-layer perception (MLP) structure with geometric affine module. However, these MLP-like structures aggregate features only with fixed weights, while differences in the semantic information of different point features are ignored. So we propose a novel Point-Vector Representation of the point feature to improve feature aggregation by using inductive bias. The direction of the introduced vector representation can dynamically modulate the aggregation of two point features according to the semantic relationship. Based on it, we design a novel Point2Vector MLP architecture. Experiments show that it achieves state-of-the-art performance on the classification task of ScanObjectNN dataset, with 1% increase, compared with the previous best method. We hope our method can help people better understand the role of semantic information in point cloud analysis and lead to explore more and better feature representations or other ways. ",
    "url": "https://arxiv.org/abs/2205.10528",
    "authors": [
      "Xin Deng",
      "WengYu Zhang",
      "Qing Ding",
      "XinMing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10539",
    "title": "On the Feasibility and Generality of Patch-based Adversarial Attacks on  Semantic Segmentation Problems",
    "abstract": "Deep neural networks were applied with success in a myriad of applications, but in safety critical use cases adversarial attacks still pose a significant threat. These attacks were demonstrated on various classification and detection tasks and are usually considered general in a sense that arbitrary network outputs can be generated by them. In this paper we will demonstrate through simple case studies both in simulation and in real-life, that patch based attacks can be utilised to alter the output of segmentation networks. Through a few examples and the investigation of network complexity, we will also demonstrate that the number of possible output maps which can be generated via patch-based attacks of a given size is typically smaller than the area they effect or areas which should be attacked in case of practical applications. We will prove that based on these results most patch-based attacks cannot be general in practice, namely they can not generate arbitrary output maps or if they could, they are spatially limited and this limit is significantly smaller than the receptive field of the patches. ",
    "url": "https://arxiv.org/abs/2205.10539",
    "authors": [
      "Soma Kontar",
      "Andras Horvath"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10546",
    "title": "Improvements to Self-Supervised Representation Learning for Masked Image  Modeling",
    "abstract": "This paper explores improvements to the masked image modeling (MIM) paradigm. The MIM paradigm enables the model to learn the main object features of the image by masking the input image and predicting the masked part by the unmasked part. We found the following three main directions for MIM to be improved. First, since both encoders and decoders contribute to representation learning, MIM uses only encoders for downstream tasks, which ignores the impact of decoders on representation learning. Although the MIM paradigm already employs small decoders with asymmetric structures, we believe that continued reduction of decoder parameters is beneficial to improve the representational learning capability of the encoder . Second, MIM solves the image prediction task by training the encoder and decoder together , and does not design a separate task for the encoder . To further enhance the performance of the encoder when performing downstream tasks, we designed the encoder for the tasks of comparative learning and token position prediction. Third, since the input image may contain background and other objects, and the proportion of each object in the image varies, reconstructing the tokens related to the background or to other objects is not meaningful for MIM to understand the main object representations. Therefore we use ContrastiveCrop to crop the input image so that the input image contains as much as possible only the main objects. Based on the above three improvements to MIM, we propose a new model, Contrastive Masked AutoEncoders (CMAE). We achieved a Top-1 accuracy of 65.84% on tinyimagenet using the ViT-B backbone, which is +2.89 outperforming the MAE of competing methods when all conditions are equal. Code will be made available. ",
    "url": "https://arxiv.org/abs/2205.10546",
    "authors": [
      "Jiawei Mao",
      "Xuesong Yin",
      "Yuanqi Chang",
      "Honggu Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10550",
    "title": "KGNN: Harnessing Kernel-based Networks for Semi-supervised Graph  Classification",
    "abstract": "This paper studies semi-supervised graph classification, which is an important problem with various applications in social network analysis and bioinformatics. This problem is typically solved by using graph neural networks (GNNs), which yet rely on a large number of labeled graphs for training and are unable to leverage unlabeled graphs. We address the limitations by proposing the Kernel-based Graph Neural Network (KGNN). A KGNN consists of a GNN-based network as well as a kernel-based network parameterized by a memory network. The GNN-based network performs classification through learning graph representations to implicitly capture the similarity between query graphs and labeled graphs, while the kernel-based network uses graph kernels to explicitly compare each query graph with all the labeled graphs stored in a memory for prediction. The two networks are motivated from complementary perspectives, and thus combing them allows KGNN to use labeled graphs more effectively. We jointly train the two networks by maximizing their agreement on unlabeled graphs via posterior regularization, so that the unlabeled graphs serve as a bridge to let both networks mutually enhance each other. Experiments on a range of well-known benchmark datasets demonstrate that KGNN achieves impressive performance over competitive baselines. ",
    "url": "https://arxiv.org/abs/2205.10550",
    "authors": [
      "Wei Ju",
      "Junwei Yang",
      "Meng Qu",
      "Weiping Song",
      "Jianhao Shen",
      "Ming Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2205.10568",
    "title": "Secure and Efficient Decentralized Federated Learning with Data  Representation Protection",
    "abstract": "Federated learning (FL) is a promising technical support to the vision of ubiquitous artificial intelligence in the sixth generation (6G) wireless communication network. However, traditional FL heavily relies on a trusted centralized server. Besides, FL is vulnerable to poisoning attacks, and the global aggregation of model updates makes the private training data under the risk of being reconstructed. What's more, FL suffers from efficiency problem due to heavy communication cost. Although decentralized FL eliminates the problem of the central dependence of traditional FL, it makes other problems more serious. In this paper, we propose BlockDFL, an efficient fully peer-to-peer (P2P) framework for decentralized FL. It integrates gradient compression and our designed voting mechanism with blockchain to efficiently coordinate multiple peer participants without mutual trust to carry out decentralized FL, while preventing data from being reconstructed according to transmitted model updates. Extensive experiments conducted on two real-world datasets exhibit that BlockDFL obtains competitive accuracy compared to centralized FL and can defend against poisoning attacks while achieving efficiency and scalability. Especially when the proportion of malicious participants is as high as 40 percent, BlockDFL can still preserve the accuracy of FL, which outperforms existing fully decentralized FL frameworks. ",
    "url": "https://arxiv.org/abs/2205.10568",
    "authors": [
      "Zhen Qin",
      "Shuiguang Deng",
      "Xueqiang Yan",
      "Schahram Dustdar",
      "Albert Y. Zomaya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.10573",
    "title": "Spectral Neural Operators",
    "abstract": "A plentitude of applications in scientific computing requires the approximation of mappings between Banach spaces. Recently introduced Fourier Neural Operator (FNO) and Deep Operator Network (DeepONet) can provide this functionality. For both of these neural operators, the input function is sampled on a given grid (uniform for FNO), and the output function is parametrized by a neural network. We argue that this parametrization leads to 1) opaque output that is hard to analyze and 2) systematic bias caused by aliasing errors in the case of FNO. The alternative, advocated in this article, is to use Chebyshev and Fourier series for both domain and codomain. The resulting Spectral Neural Operator (SNO) has transparent output, never suffers from aliasing, and may include many exact (lossless) operations on functions. The functionality is based on well-developed fast, and stable algorithms from spectral methods. The implementation requires only standard numerical linear algebra. Our benchmarks show that for many operators, SNO is superior to FNO and DeepONet. ",
    "url": "https://arxiv.org/abs/2205.10573",
    "authors": [
      "V. Fanaskov",
      "I. Oseledets"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2205.10574",
    "title": "A graphical representation of binary linear codes",
    "abstract": "A binary $[n,k]$-linear code $\\mathcal{C}$ is a $k$-dimensional subspace of $\\mathbb{F}_2^n$. For $\\boldsymbol{x}\\in \\mathbb{F}_2^n$, the set $\\boldsymbol{x}+\\mathcal{C}$ is a coset of $\\mathcal{C}$. In this work we study a partial ordering on the set of cosets of a binary linear code $\\mathcal{C}$ of length $n$ and we construct a graph using the orphan structure of this code. ",
    "url": "https://arxiv.org/abs/2205.10574",
    "authors": [
      "Lisbeth Danyeli Delgado Ordo\u00f1ez",
      "John H. Castillo",
      "Alexander Holgu\u00edn-Villa"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2205.10577",
    "title": "Non-Autoregressive Neural Machine Translation: A Call for Clarity",
    "abstract": "Non-autoregressive approaches aim to improve the inference speed of translation models by only requiring a single forward pass to generate the output sequence instead of iteratively producing each predicted token. Consequently, their translation quality still tends to be inferior to their autoregressive counterparts due to several issues involving output token interdependence. In this work, we take a step back and revisit several techniques that have been proposed for improving non-autoregressive translation models and compare their combined translation quality and speed implications under third-party testing environments. We provide novel insights for establishing strong baselines using length prediction or CTC-based architecture variants and contribute standardized BLEU, chrF++, and TER scores using sacreBLEU on four translation tasks, which crucially have been missing as inconsistencies in the use of tokenized BLEU lead to deviations of up to 1.7 BLEU points. Our open-sourced code is integrated into fairseq for reproducibility. ",
    "url": "https://arxiv.org/abs/2205.10577",
    "authors": [
      "Robin M. Schmidt",
      "Telmo Pires",
      "Stephan Peitz",
      "Jonas L\u00f6\u00f6f"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10579",
    "title": "Boosting Camouflaged Object Detection with Dual-Task Interactive  Transformer",
    "abstract": "Camouflaged object detection intends to discover the concealed objects hidden in the surroundings. Existing methods follow the bio-inspired framework, which first locates the object and second refines the boundary. We argue that the discovery of camouflaged objects depends on the recurrent search for the object and the boundary. The recurrent processing makes the human tired and helpless, but it is just the advantage of the transformer with global search ability. Therefore, a dual-task interactive transformer is proposed to detect both accurate position of the camouflaged object and its detailed boundary. The boundary feature is considered as Query to improve the camouflaged object detection, and meanwhile the object feature is considered as Query to improve the boundary detection. The camouflaged object detection and the boundary detection are fully interacted by multi-head self-attention. Besides, to obtain the initial object feature and boundary feature, transformer-based backbones are adopted to extract the foreground and background. The foreground is just object, while foreground minus background is considered as boundary. Here, the boundary feature can be obtained from blurry boundary region of the foreground and background. Supervised by the object, the background and the boundary ground truth, the proposed model achieves state-of-the-art performance in public datasets. https://github.com/liuzywen/COD ",
    "url": "https://arxiv.org/abs/2205.10579",
    "authors": [
      "Zhengyi Liu",
      "Zhili Zhang",
      "Wei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10583",
    "title": "Improving automatically generated code from Codex via Automated Program  Repair",
    "abstract": "Large language models, e.g., Codex and AlphaCode, have shown capability in producing working code for many programming tasks. However, the success rate of existing models remains low, especially for complex programming tasks. One of the reasons is that language models lack awareness of program semantics (e.g., type information), resulting in incorrect programs (or even programs which do not compile). In this paper, we systematically study whether automated program repair (APR) techniques can fix the incorrect solutions produced by language models in LeetCode contests. The goal is to study whether APR techniques can enhance confidence in the code produced by language models. Our study revealed that: (1) automatically generated codes share some common programming mistakes with human-crafted solutions, indicating existing APR tools have the potential to fix auto-generated code; (2) TBar and Recoder, two well-known Java APR tools based on templates and learning respectively, increase the number of solved tasks from 37 to 42 on 60 easy level tasks, while increase from 5 to 9 on 53 medium-level programming tasks; (3) given bug location information provided by a statistical fault localization approach, the newly released Codex edit mode, which supports changing existing code, may outperform existing APR tools in fixing incorrect solutions. By analyzing the experimental results generated by these tools, we provide several suggestions on how to improve current APR tools. ",
    "url": "https://arxiv.org/abs/2205.10583",
    "authors": [
      "Zhiyu Fan",
      "Xiang Gao",
      "Abhik Roychoudhury",
      "Shin Hwei Tan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.10587",
    "title": "A comprehensive survey on semantic facial attribute editing using  generative adversarial networks",
    "abstract": "Generating random photo-realistic images has experienced tremendous growth during the past few years due to the advances of the deep convolutional neural networks and generative models. Among different domains, face photos have received a great deal of attention and a large number of face generation and manipulation models have been proposed. Semantic facial attribute editing is the process of varying the values of one or more attributes of a face image while the other attributes of the image are not affected. The requested modifications are provided as an attribute vector or in the form of driving face image and the whole process is performed by the corresponding models. In this paper, we survey the recent works and advances in semantic facial attribute editing. We cover all related aspects of these models including the related definitions and concepts, architectures, loss functions, datasets, evaluation metrics, and applications. Based on their architectures, the state-of-the-art models are categorized and studied as encoder-decoder, image-to-image, and photo-guided models. The challenges and restrictions of the current state-of-the-art methods are discussed as well. ",
    "url": "https://arxiv.org/abs/2205.10587",
    "authors": [
      "Ahmad Nickabadi",
      "Maryam Saeedi Fard",
      "Nastaran Moradzadeh Farid",
      "Najmeh Mohammadbagheri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10588",
    "title": "Micro-video recommendation model based on graph neural network and  attention mechanism",
    "abstract": "With the rapid development of Internet technology and the comprehensive popularity of Internet applications, online activities have gradually become an indispensable part of people's daily life. The original recommendation learning algorithm is mainly based on user-microvideo interaction for learning, modeling the user-micro-video connection relationship, which is difficult to capture the more complex relationships between nodes. To address the above problems, we propose a personalized recommendation model based on graph neural network, which utilizes the feature that graph neural network can tap deep information of graph data more effectively, and transforms the input user rating information and item side information into graph structure, for effective feature extraction, based on the importance sampling strategy. The importance-based sampling strategy measures the importance of neighbor nodes to the central node by calculating the relationship tightness between the neighbor nodes and the central node, and selects the neighbor nodes for recommendation tasks based on the importance level, which can be more targeted to select the sampling neighbors with more influence on the target micro-video nodes. The pooling aggregation strategy, on the other hand, trains the aggregation weights by inputting the neighborhood node features into the fully connected layer before aggregating the neighborhood features, and then introduces the pooling layer for feature aggregation, and finally aggregates the obtained neighborhood aggregation features with the target node itself, which directly introduces a symmetric trainable function to fuse the neighborhood weight training into the model to better capture the different neighborhood nodes' differential features in a learnable manner to allow for a more accurate representation of the current node features. ",
    "url": "https://arxiv.org/abs/2205.10588",
    "authors": [
      "Chan Ching Ting",
      "Mathew Bowles",
      "Ibrahim Idewu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2205.10599",
    "title": "Networks of international football: communities, evolution and  globalization of the game",
    "abstract": "As the most popular sport around the globe, the game of football has recently intrigued much research interest to explore and distill useful and appealing information from the sport. Network science and graph-centric methods have been previously applied to study the importance of football players and teams. In this paper, for the first time we study the macroscopic evolution of the football society from a complex network point of view. Football game records within a time window of over a century were collected and expressed in a graph format, where participant teams are represented by graph nodes and the games between them are the graph edges. We carry out community detection and temporal analysis to reveal the dynamic features and the community structures embedded within the football network, offering the evidence of a continuously expanding football society. Spatio-temporal analysis is also implemented to unveil the temporal states that represent distinct development stages in the football history. Our analysis suggests that the evolution of the game receives considerable impact not only from major sport events, but also from multiple social and political incidents. The game of football and its evolution reflect significant historical transitions and turning points, and can provide a novel perspective for the study of the worldwide globalization process. ",
    "url": "https://arxiv.org/abs/2205.10599",
    "authors": [
      "Yang Li",
      "Gonzalo Mateos"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.10617",
    "title": "Gradient Concealment: Free Lunch for Defending Adversarial Attacks",
    "abstract": "Recent studies show that the deep neural networks (DNNs) have achieved great success in various tasks. However, even the \\emph{state-of-the-art} deep learning based classifiers are extremely vulnerable to adversarial examples, resulting in sharp decay of discrimination accuracy in the presence of enormous unknown attacks. Given the fact that neural networks are widely used in the open world scenario which can be safety-critical situations, mitigating the adversarial effects of deep learning methods has become an urgent need. Generally, conventional DNNs can be attacked with a dramatically high success rate since their gradient is exposed thoroughly in the white-box scenario, making it effortless to ruin a well trained classifier with only imperceptible perturbations in the raw data space. For tackling this problem, we propose a plug-and-play layer that is training-free, termed as \\textbf{G}radient \\textbf{C}oncealment \\textbf{M}odule (GCM), concealing the vulnerable direction of gradient while guaranteeing the classification accuracy during the inference time. GCM reports superior defense results on the ImageNet classification benchmark, improving up to 63.41\\% top-1 attack robustness (AR) when faced with adversarial inputs compared to the vanilla DNNs. Moreover, we use GCM in the CVPR 2022 Robust Classification Challenge, currently achieving \\textbf{2nd} place in Phase II with only a tiny version of ConvNext. The code will be made available. ",
    "url": "https://arxiv.org/abs/2205.10617",
    "authors": [
      "Sen Pei",
      "Jiaxi Sun",
      "Xiaopeng Zhang",
      "Gaofeng Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10620",
    "title": "Graph Neural Network Enhanced Approximate Message Passing for MIMO  Detection",
    "abstract": "Efficient multiple-input multiple-output (MIMO) detection algorithms with satisfactory performance and low complexity are critical for future multi-antenna systems to meet the high throughput and ultra-low latency requirements in 5G and beyond communications. In this paper, we propose a low complexity graph neural network (GNN) enhanced approximate message passing (AMP) algorithm, AMP-GNN, for MIMO detection. The structure of the neural network is customized by unfolding the AMP algorithm and introducing the GNN module to address the inaccuracy of the Gaussian approximation for multiuser interference cancellation. Numerical results will show that the proposed AMP-GNN significantly improves the performance of the AMP detector and achieves comparable performance as the state-of-the-art deep learning-based MIMO detectors but with reduced computational complexity. ",
    "url": "https://arxiv.org/abs/2205.10620",
    "authors": [
      "Hengtao He",
      "Alva Kosasihy",
      "Xianghao Yu",
      "Jun Zhang",
      "S.H. Song",
      "Wibowo Hardjawanay",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.10621",
    "title": "Learning Meta Representations of One-shot Relations for Temporal  Knowledge Graph Link Prediction",
    "abstract": "Few-shot relational learning for static knowledge graphs (KGs) has drawn greater interest in recent years, while few-shot learning for temporal knowledge graphs (TKGs) has hardly been studied. Compared to KGs, TKGs contain rich temporal information, thus requiring temporal reasoning techniques for modeling. This poses a greater challenge in learning few-shot relations in the temporal context. In this paper, we revisit the previous work related to few-shot relational learning in KGs and extend two existing TKG reasoning tasks, i.e., interpolated and extrapolated link prediction, to the one-shot setting. We propose four new large-scale benchmark datasets and develop a TKG reasoning model for learning one-shot relations in TKGs. Experimental results show that our model can achieve superior performance on all datasets in both interpolation and extrapolation tasks. ",
    "url": "https://arxiv.org/abs/2205.10621",
    "authors": [
      "Zifeng Ding",
      "Bailan He",
      "Yunpu Ma",
      "Zhen Han",
      "Volker Tresp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10624",
    "title": "CEP3: Community Event Prediction with Neural Point Process on Graph",
    "abstract": "Many real world applications can be formulated as event forecasting on Continuous Time Dynamic Graphs (CTDGs) where the occurrence of a timed event between two entities is represented as an edge along with its occurrence timestamp in the graphs.However, most previous works approach the problem in compromised settings, either formulating it as a link prediction task on the graph given the event time or a time prediction problem given which event will happen next. In this paper, we propose a novel model combining Graph Neural Networks and Marked Temporal Point Process (MTPP) that jointly forecasts multiple link events and their timestamps on communities over a CTDG. Moreover, to scale our model to large graphs, we factorize the jointly event prediction problem into three easier conditional probability modeling problems.To evaluate the effectiveness of our model and the rationale behind such a decomposition, we establish a set of benchmarks and evaluation metrics for this event forecasting task. Our experiments demonstrate the superior performance of our model in terms of both model accuracy and training efficiency. ",
    "url": "https://arxiv.org/abs/2205.10624",
    "authors": [
      "Xuhong Wang",
      "Sirui Chen",
      "Yixuan He",
      "Minjie Wang",
      "Quan Gan",
      "Yupu Yang",
      "Junchi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10625",
    "title": "Least-to-Most Prompting Enables Complex Reasoning in Large Language  Models",
    "abstract": "We propose a novel prompting strategy, least-to-most prompting, that enables large language models to better perform multi-step reasoning tasks. Least-to-most prompting first reduces a complex problem into a list of subproblems, and then sequentially solves the subproblems, whereby solving a given subproblem is facilitated by the model's answers to previously solved subproblems. Experiments on symbolic manipulation, compositional generalization and numerical reasoning demonstrate that least-to-most prompting can generalize to examples that are harder than those seen in the prompt context, outperforming other prompting-based approaches by a large margin. A notable empirical result is that the GPT-3 code-davinci-002 model with least-to-most-prompting can solve the SCAN benchmark with an accuracy of 99.7% using 14 examples. As a comparison, the neural-symbolic models in the literature specialized for solving SCAN are trained with the full training set of more than 15,000 examples. ",
    "url": "https://arxiv.org/abs/2205.10625",
    "authors": [
      "Denny Zhou",
      "Nathanael Sch\u00e4rli",
      "Le Hou",
      "Jason Wei",
      "Nathan Scales",
      "Xuezhi Wang",
      "Dale Schuurmans",
      "Olivier Bousquet",
      "Quoc Le",
      "Ed Chi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.10627",
    "title": "DProQ: A Gated-Graph Transformer for Protein Complex Structure  Assessment",
    "abstract": "Proteins interact to form complexes to carry out essential biological functions. Computational methods have been developed to predict the structures of protein complexes. However, an important challenge in protein complex structure prediction is to estimate the quality of predicted protein complex structures without any knowledge of the corresponding native structures. Such estimations can then be used to select high-quality predicted complex structures to facilitate biomedical research such as protein function analysis and drug discovery. We challenge this significant task with DProQ, which introduces a gated neighborhood-modulating Graph Transformer (GGT) designed to predict the quality of 3D protein complex structures. Notably, we incorporate node and edge gates within a novel Graph Transformer framework to control information flow during graph message passing. We train and evaluate DProQ on four newly-developed datasets that we make publicly available in this work. Our rigorous experiments demonstrate that DProQ achieves state-of-the-art performance in ranking protein complex structures. ",
    "url": "https://arxiv.org/abs/2205.10627",
    "authors": [
      "Xiao Chen",
      "Alex Morehead",
      "Jian Liu",
      "Jianlin Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2205.10635",
    "title": "SplitPlace: AI Augmented Splitting and Placement of Large-Scale Neural  Networks in Mobile Edge Environments",
    "abstract": "In recent years, deep learning models have become ubiquitous in industry and academia alike. Deep neural networks can solve some of the most complex pattern-recognition problems today, but come with the price of massive compute and memory requirements. This makes the problem of deploying such large-scale neural networks challenging in resource-constrained mobile edge computing platforms, specifically in mission-critical domains like surveillance and healthcare. To solve this, a promising solution is to split resource-hungry neural networks into lightweight disjoint smaller components for pipelined distributed processing. At present, there are two main approaches to do this: semantic and layer-wise splitting. The former partitions a neural network into parallel disjoint models that produce a part of the result, whereas the latter partitions into sequential models that produce intermediate results. However, there is no intelligent algorithm that decides which splitting strategy to use and places such modular splits to edge nodes for optimal performance. To combat this, this work proposes a novel AI-driven online policy, SplitPlace, that uses Multi-Armed-Bandits to intelligently decide between layer and semantic splitting strategies based on the input task's service deadline demands. SplitPlace places such neural network split fragments on mobile edge devices using decision-aware reinforcement learning for efficient and scalable computing. Moreover, SplitPlace fine-tunes its placement engine to adapt to volatile environments. Our experiments on physical mobile-edge environments with real-world workloads show that SplitPlace can significantly improve the state-of-the-art in terms of average response time, deadline violation rate, inference accuracy, and total reward by up to 46, 69, 3 and 12 percent respectively. ",
    "url": "https://arxiv.org/abs/2205.10635",
    "authors": [
      "Shreshth Tuli",
      "Giuliano Casale",
      "Nicholas R. Jennings"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2205.10636",
    "title": "AutoLink: Self-supervised Learning of Human Skeletons and Object  Outlines by Linking Keypoints",
    "abstract": "Structured representations such as keypoints are widely used in pose transfer, conditional image generation, animation, and 3D reconstruction. However, their supervised learning requires expensive annotation for each target domain. We propose a self-supervised method that learns to disentangle object structure from the appearance with a graph of 2D keypoints linked by straight edges. Both the keypoint location and their pairwise edge weights are learned, given only a collection of images depicting the same object class. The graph is interpretable, for example, AutoLink recovers the human skeleton topology when applied to images showing people. Our key ingredients are i) an encoder that predicts keypoint locations in an input image, ii) a shared graph as a latent variable that links the same pairs of keypoints in every image, iii) an intermediate edge map that combines the latent graph edge weights and keypoint locations in a soft, differentiable manner, and iv) an inpainting objective on randomly masked images. Although simpler, AutoLink outperforms existing self-supervised methods on the established keypoint and pose estimation benchmarks and paves the way for structure-conditioned generative models on more diverse datasets. ",
    "url": "https://arxiv.org/abs/2205.10636",
    "authors": [
      "Xingzhe He",
      "Bastian Wandt",
      "Helge Rhodin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10643",
    "title": "Self-Supervised Speech Representation Learning: A Review",
    "abstract": "Although supervised deep learning has revolutionized speech and audio processing, it has necessitated the building of specialist models for individual tasks and application scenarios. It is likewise difficult to apply this to dialects and languages for which only limited labeled data is available. Self-supervised representation learning methods promise a single universal model that would benefit a wide variety of tasks and domains. Such methods have shown success in natural language processing and computer vision domains, achieving new levels of performance while reducing the number of labels required for many downstream scenarios. Speech representation learning is experiencing similar progress in three main categories: generative, contrastive, and predictive methods. Other approaches rely on multi-modal data for pre-training, mixing text or visual data streams with speech. Although self-supervised speech representation is still a nascent research area, it is closely related to acoustic word embedding and learning with zero lexical resources, both of which have seen active research for many years. This review presents approaches for self-supervised speech representation learning and their connection to other research areas. Since many current methods focus solely on automatic speech recognition as a downstream task, we review recent efforts on benchmarking learned representations to extend the application beyond speech recognition. ",
    "url": "https://arxiv.org/abs/2205.10643",
    "authors": [
      "Abdelrahman Mohamed",
      "Hung-yi Lee",
      "Lasse Borgholt",
      "Jakob D. Havtorn",
      "Joakim Edin",
      "Christian Igel",
      "Katrin Kirchhoff",
      "Shang-Wen Li",
      "Karen Livescu",
      "Lars Maal\u00f8e",
      "Tara N. Sainath",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.10650",
    "title": "Transformer-based out-of-distribution detection for clinically safe  segmentation",
    "abstract": "In a clinical setting it is essential that deployed image processing systems are robust to the full range of inputs they might encounter and, in particular, do not make confidently wrong predictions. The most popular approach to safe processing is to train networks that can provide a measure of their uncertainty, but these tend to fail for inputs that are far outside the training data distribution. Recently, generative modelling approaches have been proposed as an alternative; these can quantify the likelihood of a data sample explicitly, filtering out any out-of-distribution (OOD) samples before further processing is performed. In this work, we focus on image segmentation and evaluate several approaches to network uncertainty in the far-OOD and near-OOD cases for the task of segmenting haemorrhages in head CTs. We find all of these approaches are unsuitable for safe segmentation as they provide confidently wrong predictions when operating OOD. We propose performing full 3D OOD detection using a VQ-GAN to provide a compressed latent representation of the image and a transformer to estimate the data likelihood. Our approach successfully identifies images in both the far- and near-OOD cases. We find a strong relationship between image likelihood and the quality of a model's segmentation, making this approach viable for filtering images unsuitable for segmentation. To our knowledge, this is the first time transformers have been applied to perform OOD detection on 3D image data. ",
    "url": "https://arxiv.org/abs/2205.10650",
    "authors": [
      "Mark S Graham",
      "Petru-Daniel Tudosiu",
      "Paul Wright",
      "Walter Hugo Lopez Pinaya",
      "U Jean-Marie",
      "Yee Mah",
      "James Teo",
      "Rolf H J\u00e4ger",
      "David Werring",
      "Parashkev Nachev",
      "Sebastien Ourselin",
      "M Jorge Cardoso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10652",
    "title": "Are Graph Neural Networks Really Helpful for Knowledge Graph Completion?",
    "abstract": "Knowledge graphs (KGs) facilitate a wide variety of applications due to their ability to store relational knowledge applicable to many areas. Despite great efforts invested in creation and maintenance, even the largest KGs are far from complete. Hence, KG completion (KGC) has become one of the most crucial tasks for KG research. Recently, considerable literature in this space has centered around the use of Graph Neural Networks (GNNs) to learn powerful embeddings which leverage topological structures in the KGs. Specifically, dedicated efforts have been made to extend GNNs, which are commonly designed for simple homogeneous and uni-relational graphs, to the KG context which has diverse and multi-relational connections between entities, by designing more complex aggregation schemes over neighboring nodes (crucial to GNN performance) to appropriately leverage multi-relational information. The success of these methods is naturally attributed to the use of GNNs over simpler multi-layer perceptron (MLP) models, owing to their additional aggregation functionality. In this work, we find that surprisingly, simple MLP models are able to achieve comparable performance to GNNs, suggesting that aggregation may not be as crucial as previously believed. With further exploration, we show careful scoring function and loss function design has a much stronger influence on KGC model performance, and aggregation is not practically required. This suggests a conflation of scoring function design, loss function design, and aggregation in prior work, with promising insights regarding the scalability of state-of-the-art KGC methods today, as well as careful attention to more suitable aggregation designs for KGC tasks tomorrow. ",
    "url": "https://arxiv.org/abs/2205.10652",
    "authors": [
      "Juanhui Li",
      "Harry Shomer",
      "Jiayuan Ding",
      "Yiqi Wang",
      "Yao Ma",
      "Neil Shah",
      "Jiliang Tang",
      "Dawei Yin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10661",
    "title": "An Empirical Investigation of Commonsense Self-Supervision with  Knowledge Graphs",
    "abstract": "Self-supervision based on the information extracted from large knowledge graphs has been shown to improve the generalization of language models, in zero-shot evaluation on various downstream language reasoning tasks. Since these improvements are reported in aggregate, however, little is known about (i) how to select the appropriate knowledge for solid performance across tasks, (ii) how to combine this knowledge with neural language models, and (iii) how these pairings affect granular task performance. In this paper, we study the effect of knowledge sampling strategies and sizes that can be used to generate synthetic data for adapting language models. We study the effect of different synthetic datasets on language models with various architectures and sizes. The resulting models are evaluated against four task properties: domain overlap, answer similarity, vocabulary overlap, and answer length. Our experiments show that encoder-decoder models benefit from more data to learn from, whereas sampling strategies that balance across different aspects yield best performance. Most of the improvement occurs on questions with short answers and dissimilar answer candidates, which corresponds to the characteristics of the data used for pre-training. ",
    "url": "https://arxiv.org/abs/2205.10661",
    "authors": [
      "Jiarui Zhang",
      "Filip Ilievski",
      "Kaixin Ma",
      "Jonathan Francis",
      "Alessandro Oltramari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10662",
    "title": "Equivariant Mesh Attention Networks",
    "abstract": "Equivariance to symmetries has proven to be a powerful inductive bias in deep learning research. Recent works on mesh processing have concentrated on various kinds of natural symmetries, including translations, rotations, scaling, node permutations, and gauge transformations. To date, no existing architecture is equivariant to all of these transformations. Moreover, previous implementations have not always applied these symmetry transformations to the test dataset. This inhibits the ability to determine whether the model attains the claimed equivariance properties. In this paper, we present an attention-based architecture for mesh data that is provably equivariant to all transformations mentioned above. We carry out experiments on the FAUST and TOSCA datasets, and apply the mentioned symmetries to the test set only. Our results confirm that our proposed architecture is equivariant, and therefore robust, to these local/global transformations. ",
    "url": "https://arxiv.org/abs/2205.10662",
    "authors": [
      "Sourya Basu",
      "Jose Gallego-Posada",
      "Francesco Vigan\u00f2",
      "James Rowbottom",
      "Taco Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.10664",
    "title": "Temporal Domain Generalization with Drift-Aware Dynamic Neural Network",
    "abstract": "Temporal domain generalization is a promising yet extremely challenging area where the goal is to learn models under temporally changing data distributions and generalize to unseen data distributions following the trends of the change. The advancement of this area is challenged by: 1) characterizing data distribution drift and its impacts on models, 2) expressiveness in tracking the model dynamics, and 3) theoretical guarantee on the performance. To address them, we propose a Temporal Domain Generalization with Drift-Aware Dynamic Neural Network (DRAIN) framework. Specifically, we formulate the problem into a Bayesian framework that jointly models the relation between data and model dynamics. We then build a recurrent graph generation scenario to characterize the dynamic graph-structured neural networks learned across different time points. It captures the temporal drift of model parameters and data distributions and can predict models in the future without the presence of future data. In addition, we explore theoretical guarantees of the model performance under the challenging temporal DG setting and provide theoretical analysis, including uncertainty and generalization error. Finally, extensive experiments on several real-world benchmarks with temporal drift demonstrate the effectiveness and efficiency of the proposed method. ",
    "url": "https://arxiv.org/abs/2205.10664",
    "authors": [
      "Guangji Bai",
      "Ling Chen",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10666",
    "title": "MultiBiSage: A Web-Scale Recommendation System Using Multiple Bipartite  Graphs at Pinterest",
    "abstract": "Graph Convolutional Networks (GCN) can efficiently integrate graph structure and node features to learn high-quality node embeddings. These embeddings can then be used for several tasks such as recommendation and search. At Pinterest, we have developed and deployed PinSage, a data-efficient GCN that learns pin embeddings from the Pin-Board graph. The Pin-Board graph contains pin and board entities and the graph captures the pin belongs to a board interaction. However, there exist several entities at Pinterest such as users, idea pins, creators, and there exist heterogeneous interactions among these entities such as add-to-cart, follow, long-click. In this work, we show that training deep learning models on graphs that captures these diverse interactions would result in learning higher-quality pin embeddings than training PinSage on only the Pin-Board graph. To that end, we model the diverse entities and their diverse interactions through multiple bipartite graphs and propose a novel data-efficient MultiBiSage model. MultiBiSage can capture the graph structure of multiple bipartite graphs to learn high-quality pin embeddings. We take this pragmatic approach as it allows us to utilize the existing infrastructure developed at Pinterest -- such as Pixie system that can perform optimized random-walks on billion node graphs, along with existing training and deployment workflows. We train MultiBiSage on six bipartite graphs including our Pin-Board graph. Our offline metrics show that MultiBiSage significantly outperforms the deployed latest version of PinSage on multiple user engagement metrics. ",
    "url": "https://arxiv.org/abs/2205.10666",
    "authors": [
      "Saket Gurukar",
      "Nikil Pancha",
      "Andrew Zhai",
      "Eric Kim",
      "Samson Hu",
      "Srinivasan Parthasarathy",
      "Charles Rosenberg",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.10674",
    "title": "NS3: Neuro-Symbolic Semantic Code Search",
    "abstract": "Semantic code search is the task of retrieving a code snippet given a textual description of its functionality. Recent work has been focused on using similarity metrics between neural embeddings of text and code. However, current language models are known to struggle with longer, compositional text, and multi-step reasoning. To overcome this limitation, we propose supplementing the query sentence with a layout of its semantic structure. The semantic layout is used to break down the final reasoning decision into a series of lower-level decisions. We use a Neural Module Network architecture to implement this idea. We compare our model - NS3 (Neuro-Symbolic Semantic Search) - to a number of baselines, including state-of-the-art semantic code retrieval methods, and evaluate on two datasets - CodeSearchNet and Code Search and Question Answering. We demonstrate that our approach results in more precise code retrieval, and we study the effectiveness of our modular design when handling compositional queries. ",
    "url": "https://arxiv.org/abs/2205.10674",
    "authors": [
      "Shushan Arakelyan",
      "Anna Hakhverdyan",
      "Miltiadis Allamanis",
      "Christophe Hauser",
      "Luis Garcia",
      "Xiang Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10682",
    "title": "A Novel Markov Model for Near-Term Railway Delay Prediction",
    "abstract": "Predicting the near-future delay with accuracy for trains is momentous for railway operations and passengers' traveling experience. This work aims to design prediction models for train delays based on Netherlands Railway data. We first develop a chi-square test to show that the delay evolution over stations follows a first-order Markov chain. We then propose a delay prediction model based on non-homogeneous Markov chains. To deal with the sparsity of the transition matrices of the Markov chains, we propose a novel matrix recovery approach that relies on Gaussian kernel density estimation. Our numerical tests show that this recovery approach outperforms other heuristic approaches in prediction accuracy. The Markov chain model we propose also shows to be better than other widely-used time series models with respect to both interpretability and prediction accuracy. Moreover, our proposed model does not require a complicated training process, which is capable of handling large-scale forecasting problems. ",
    "url": "https://arxiv.org/abs/2205.10682",
    "authors": [
      "Jin Xu",
      "Weiqi Wang",
      "Zheming Gao",
      "Haochen Luo",
      "Qian Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.10683",
    "title": "Scalable and Efficient Training of Large Convolutional Neural Networks  with Differential Privacy",
    "abstract": "Large convolutional neural networks (CNN) can be difficult to train in the differentially private (DP) regime, since the optimization algorithms require a computationally expensive operation, known as the per-sample gradient clipping. We propose an efficient and scalable implementation of this clipping on convolutional layers, termed as the mixed ghost clipping, that significantly eases the private training in terms of both time and space complexities, without affecting the accuracy. The improvement in efficiency is rigorously studied through the first complexity analysis for the mixed ghost clipping and existing DP training algorithms. Extensive experiments on vision classification tasks, with large ResNet, VGG, and Vision Transformers, demonstrate that DP training with mixed ghost clipping adds $1\\sim 10\\%$ memory overhead and $<2\\times$ slowdown to the standard non-private training. Specifically, when training VGG19 on CIFAR10, the mixed ghost clipping is $3\\times$ faster than state-of-the-art Opacus library with $18\\times$ larger maximum batch size. To emphasize the significance of efficient DP training on convolutional layers, we achieve 96.7\\% accuracy on CIFAR10 and 83.0\\% on CIFAR100 at $\\epsilon=1$ using BEiT, while the previous best results are 94.8\\% and 67.4\\%, respectively. We open-source a privacy engine (\\url{https://github.com/JialinMao/private_CNN}) that implements DP training of CNN with a few lines of code. ",
    "url": "https://arxiv.org/abs/2205.10683",
    "authors": [
      "Zhiqi Bu",
      "Jialin Mao",
      "Shiyun Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10684",
    "title": "Neural Augmented Min-Sum Decoding of Short Block Codes for Fading  Channels",
    "abstract": "In the decoding of linear block codes, it was shown that noticeable gains in terms of bit error rate can be achieved by introducing learnable parameters to the Belief Propagation (BP) decoder. Despite the success of these methods, there are two key open problems. The first is the lack of analysis for channels other than AWGN. The second is the interpretation of the weights learned and their effect on the reliability of the BP decoder. In this work, we aim to bridge this gap by looking at non-AWGN channels such as Extended Typical Urban (ETU) channel. We study the effect of entangling the weights and how the performance holds across different channel settings for the min-sum version of BP decoder. We show that while entanglement has little degradation in the AWGN channel, a significant loss is observed in more complex channels. We also provide insights into the weights learned and their connection to the structure of the underlying code. Finally, we evaluate our algorithm on the over-the-air channels using Software Defined Radios. ",
    "url": "https://arxiv.org/abs/2205.10684",
    "authors": [
      "Sravan Kumar Ankireddy",
      "Hyeji Kim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10686",
    "title": "Post-breach Recovery: Protection against White-box Adversarial Examples  for Leaked DNN Models",
    "abstract": "Server breaches are an unfortunate reality on today's Internet. In the context of deep neural network (DNN) models, they are particularly harmful, because a leaked model gives an attacker \"white-box\" access to generate adversarial examples, a threat model that has no practical robust defenses. For practitioners who have invested years and millions into proprietary DNNs, e.g. medical imaging, this seems like an inevitable disaster looming on the horizon. In this paper, we consider the problem of post-breach recovery for DNN models. We propose Neo, a new system that creates new versions of leaked models, alongside an inference time filter that detects and removes adversarial examples generated on previously leaked models. The classification surfaces of different model versions are slightly offset (by introducing hidden distributions), and Neo detects the overfitting of attacks to the leaked model used in its generation. We show that across a variety of tasks and attack methods, Neo is able to filter out attacks from leaked models with very high accuracy, and provides strong protection (7--10 recoveries) against attackers who repeatedly breach the server. Neo performs well against a variety of strong adaptive attacks, dropping slightly in # of breaches recoverable, and demonstrates potential as a complement to DNN defenses in the wild. ",
    "url": "https://arxiv.org/abs/2205.10686",
    "authors": [
      "Shawn Shan",
      "Wenxin Ding",
      "Emily Wenger",
      "Haitao Zheng",
      "Ben Y. Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.10688",
    "title": "Co-design of Embodied Neural Intelligence via Constrained Evolution",
    "abstract": "We introduce a novel co-design method for autonomous moving agents' shape attributes and locomotion by combining deep reinforcement learning and evolution with user control. Our main inspiration comes from evolution, which has led to wide variability and adaptation in Nature and has the potential to significantly improve design and behavior simultaneously. Our method takes an input agent with optional simple constraints such as leg parts that should not evolve or allowed ranges of changes. It uses physics-based simulation to determine its locomotion and finds a behavior policy for the input design, later used as a baseline for comparison. The agent is then randomly modified within the allowed ranges creating a new generation of several hundred agents. The generation is trained by transferring the previous policy, which significantly speeds up the training. The best-performing agents are selected, and a new generation is formed using their crossover and mutations. The next generations are then trained until satisfactory results are reached. We show a wide variety of evolved agents, and our results show that even with only 10% of changes, the overall performance of the evolved agents improves 50%. If more significant changes to the initial design are allowed, our experiments' performance improves even more to 150%. Contrary to related work, our co-design works on a single GPU and provides satisfactory results by training thousands of agents within one hour. ",
    "url": "https://arxiv.org/abs/2205.10688",
    "authors": [
      "Zhiquan Wang",
      "Bedrich Benes",
      "Ahmed H. Qureshi",
      "Christos Mousas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.10689",
    "title": "Diversity Preference-Aware Link Recommendation for Online Social  Networks",
    "abstract": "Link recommendation, which recommends links to connect unlinked online social network users, is a fundamental social network analytics problem with ample business implications. Existing link recommendation methods tend to recommend similar friends to a user but overlook the user's diversity preference, although social psychology theories suggest the criticality of diversity preference to link recommendation performance. In recommender systems, a field related to link recommendation, a number of diversification methods have been proposed to improve the diversity of recommended items. Nevertheless, diversity preference is distinct from diversity studied by diversification methods. To address these research gaps, we define and operationalize the concept of diversity preference for link recommendation and propose a new link recommendation problem: the diversity preference-aware link recommendation problem. We then analyze key properties of the new link recommendation problem and develop a novel link recommendation method to solve the problem. Using two large-scale online social network data sets, we conduct extensive empirical evaluations to demonstrate the superior performance of our method over representative diversification methods adapted for link recommendation as well as state-of-the-art link recommendation methods. ",
    "url": "https://arxiv.org/abs/2205.10689",
    "authors": [
      "Kexin Yin",
      "Xiao Fang",
      "Bintong Chen",
      "Olivia Sheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10692",
    "title": "All You Need Is Logs: Improving Code Completion by Learning from  Anonymous IDE Usage Logs",
    "abstract": "Integrated Development Environments (IDE) are designed to make users more productive, as well as to make their work more comfortable. To achieve this, a lot of diverse tools are embedded into IDEs, and the developers of IDEs can employ anonymous usage logs to collect the data about how they are being used to improve them. A particularly important component that this can be applied to is code completion, since improving code completion using statistical learning techniques is a well-established research area. In this work, we propose an approach for collecting completion usage logs from the users in an IDE and using them to train a machine learning based model for ranking completion candidates. We developed a set of features that describe completion candidates and their context, and deployed their anonymized collection in the Early Access Program of IntelliJ-based IDEs. We used the logs to collect a dataset of code completions from users, and employed it to train a ranking CatBoost model. Then, we evaluated it in two settings: on a held-out set of the collected completions and in a separate A/B test on two different groups of users in the IDE. Our evaluation shows that using a simple ranking model trained on the past user behavior logs significantly improved code completion experience. Compared to the default heuristics-based ranking, our model demonstrated a decrease in the number of typing actions necessary to perform the completion in the IDE from 2.073 to 1.832. The approach adheres to privacy requirements and legal constraints, since it does not require collecting personal information, performing all the necessary anonymization on the client's side. Importantly, it can be improved continuously: implementing new features, collecting new data, and evaluating new models - this way, we have been using it in production since the end of 2020. ",
    "url": "https://arxiv.org/abs/2205.10692",
    "authors": [
      "Vitaliy Bibaev",
      "Alexey Kalina",
      "Vadim Lomshakov",
      "Yaroslav Golubev",
      "Alexander Bezzubov",
      "Nikita Povarov",
      "Timofey Bryksin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10706",
    "title": "GL-RG: Global-Local Representation Granularity for Video Captioning",
    "abstract": "Video captioning is a challenging task as it needs to accurately transform visual understanding into natural language description. To date, state-of-the-art methods inadequately model global-local representation across video frames for caption generation, leaving plenty of room for improvement. In this work, we approach the video captioning task from a new perspective and propose a GL-RG framework for video captioning, namely a \\textbf{G}lobal-\\textbf{L}ocal \\textbf{R}epresentation \\textbf{G}ranularity. Our GL-RG demonstrates three advantages over the prior efforts: 1) we explicitly exploit extensive visual representations from different video ranges to improve linguistic expression; 2) we devise a novel global-local encoder to produce rich semantic vocabulary to obtain a descriptive granularity of video contents across frames; 3) we develop an incremental training strategy which organizes model learning in an incremental fashion to incur an optimal captioning behavior. Experimental results on the challenging MSR-VTT and MSVD datasets show that our DL-RG outperforms recent state-of-the-art methods by a significant margin. Code is available at \\url{https://github.com/ylqi/GL-RG}. ",
    "url": "https://arxiv.org/abs/2205.10706",
    "authors": [
      "Liqi Yan",
      "Qifan Wang",
      "Yiming Cui",
      "Fuli Feng",
      "Xiaojun Quan",
      "Xiangyu Zhang",
      "Dongfang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10710",
    "title": "Phrase-level Textual Adversarial Attack with Label Preservation",
    "abstract": "Generating high-quality textual adversarial examples is critical for investigating the pitfalls of natural language processing (NLP) models and further promoting their robustness. Existing attacks are usually realized through word-level or sentence-level perturbations, which either limit the perturbation space or sacrifice fluency and textual quality, both affecting the attack effectiveness. In this paper, we propose Phrase-Level Textual Adversarial aTtack (PLAT) that generates adversarial samples through phrase-level perturbations. PLAT first extracts the vulnerable phrases as attack targets by a syntactic parser, and then perturbs them by a pre-trained blank-infilling model. Such flexible perturbation design substantially expands the search space for more effective attacks without introducing too many modifications, and meanwhile maintaining the textual fluency and grammaticality via contextualized generation using surrounding texts. Moreover, we develop a label-preservation filter leveraging the likelihoods of language models fine-tuned on each class, rather than textual similarity, to rule out those perturbations that potentially alter the original class label for humans. Extensive experiments and human evaluation demonstrate that PLAT has a superior attack effectiveness as well as a better label consistency than strong baselines. ",
    "url": "https://arxiv.org/abs/2205.10710",
    "authors": [
      "Yibin Lei",
      "Yu Cao",
      "Dianqi Li",
      "Tianyi Zhou",
      "Meng Fang",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10726",
    "title": "TWEET-FID: An Annotated Dataset for Multiple Foodborne Illness Detection  Tasks",
    "abstract": "Foodborne illness is a serious but preventable public health problem -- with delays in detecting the associated outbreaks resulting in productivity loss, expensive recalls, public safety hazards, and even loss of life. While social media is a promising source for identifying unreported foodborne illnesses, there is a dearth of labeled datasets for developing effective outbreak detection models. To accelerate the development of machine learning-based models for foodborne outbreak detection, we thus present TWEET-FID (TWEET-Foodborne Illness Detection), the first publicly available annotated dataset for multiple foodborne illness incident detection tasks. TWEET-FID collected from Twitter is annotated with three facets: tweet class, entity type, and slot type, with labels produced by experts as well as by crowdsource workers. We introduce several domain tasks leveraging these three facets: text relevance classification (TRC), entity mention detection (EMD), and slot filling (SF). We describe the end-to-end methodology for dataset design, creation, and labeling for supporting model development for these tasks. A comprehensive set of results for these tasks leveraging state-of-the-art single- and multi-task deep learning methods on the TWEET-FID dataset are provided. This dataset opens opportunities for future research in foodborne outbreak detection. ",
    "url": "https://arxiv.org/abs/2205.10726",
    "authors": [
      "Ruofan Hu",
      "Dongyu Zhang",
      "Dandan Tao",
      "Thomas Hartvigsen",
      "Hao Feng",
      "Elke Rundensteiner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10728",
    "title": "Neural Lyapunov Differentiable Predictive Control",
    "abstract": "We present a learning-based predictive control methodology using the differentiable programming framework with probabilistic Lyapunov-based stability guarantees. The neural Lyapunov differentiable predictive control (NLDPC) learns the policy by constructing a computational graph encompassing the system dynamics, state and input constraints, and the necessary Lyapunov certification constraints, and thereafter using the automatic differentiation to update the neural policy parameters. In conjunction, our approach jointly learns a Lyapunov function that certifies the regions of state-space with stable dynamics. We also provide a sampling-based statistical guarantee for the training of NLDPC from the distribution of initial conditions. Our offline training approach provides a computationally efficient and scalable alternative to classical explicit model predictive control solutions. We substantiate the advantages of the proposed approach with simulations to stabilize the double integrator model and on an example of controlling an aircraft model. ",
    "url": "https://arxiv.org/abs/2205.10728",
    "authors": [
      "Sayak Mukherjee",
      "J\u00e1n Drgo\u0148a",
      "Aaron Tuor",
      "Mahantesh Halappanavar",
      "Draguna Vrabie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10734",
    "title": "Limit Cycles Analysis and Control of Evolutionary Game Dynamics with  Environmental Feedback",
    "abstract": "Recently, an evolutionary game dynamics model taking into account the environmental feedback has been proposed to describe the co-evolution of strategic actions of a population of individuals and the state of the surrounding environment; correspondingly a range of interesting dynamic behaviors have been reported. In this paper, we provide new theoretical insight into such behaviors and discuss control options. Instead of the standard replicator dynamics, we use a more realistic and comprehensive model of replicator-mutator dynamics, to describe the strategic evolution of the population. After integrating the environment feedback, we study the effect of mutations on the resulting closed-loop system dynamics. We prove the conditions for two types of bifurcations, Hopf bifurcation and Heteroclinic bifurcation, both of which result in stable limit cycles. These limit cycles have not been identified in existing works, and we further prove that such limit cycles are in fact persistent in a large parameter space and are almost globally stable. In the end, an intuitive control policy based on incentives is applied, and the effectiveness of this control policy is examined by analysis and simulations. ",
    "url": "https://arxiv.org/abs/2205.10734",
    "authors": [
      "Lulu Gong",
      "Weijia Yao",
      "Jian Gao",
      "Ming Cao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2205.10743",
    "title": "Do Deep Learning Models and News Headlines Outperform Conventional  Prediction Techniques on Forex Data?",
    "abstract": "Foreign Exchange (FOREX) is a decentralised global market for exchanging currencies. The Forex market is enormous, and it operates 24 hours a day. Along with country-specific factors, Forex trading is influenced by cross-country ties and a variety of global events. Recent pandemic scenarios such as COVID19 and local elections can also have a significant impact on market pricing. We tested and compared various predictions with external elements such as news items in this work. Additionally, we compared classical machine learning methods to deep learning algorithms. We also added sentiment features from news headlines using NLP-based word embeddings and compared the performance. Our results indicate that simple regression model like linear, SGD, and Bagged performed better than deep learning models such as LSTM and RNN for single-step forecasting like the next two hours, the next day, and seven days. Surprisingly, news articles failed to improve the predictions indicating domain-based and relevant information only adds value. Among the text vectorization techniques, Word2Vec and SentenceBERT perform better. ",
    "url": "https://arxiv.org/abs/2205.10743",
    "authors": [
      "Sucharita Atha",
      "Bharath Kumar Bolla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10750",
    "title": "Multi-Agent Feedback Enabled Neural Networks for Intelligent  Communications",
    "abstract": "In the intelligent communication field, deep learning (DL) has attracted much attention due to its strong fitting ability and data-driven learning capability. Compared with the typical DL feedforward network structures, an enhancement structure with direct data feedback have been studied and proved to have better performance than the feedfoward networks. However, due to the above simple feedback methods lack sufficient analysis and learning ability on the feedback data, it is inadequate to deal with more complicated nonlinear systems and therefore the performance is limited for further improvement. In this paper, a novel multi-agent feedback enabled neural network (MAFENN) framework is proposed, which make the framework have stronger feedback learning capabilities and more intelligence on feature abstraction, denoising or generation, etc. Furthermore, the MAFENN framework is theoretically formulated into a three-player Feedback Stackelberg game, and the game is proved to converge to the Feedback Stackelberg equilibrium. The design of MAFENN framework and algorithm are dedicated to enhance the learning capability of the feedfoward DL networks or their variations with the simple data feedback. To verify the MAFENN framework's feasibility in wireless communications, a multi-agent MAFENN based equalizer (MAFENN-E) is developed for wireless fading channels with inter-symbol interference (ISI). Experimental results show that when the quadrature phase-shift keying (QPSK) modulation scheme is adopted, the SER performance of our proposed method outperforms that of the traditional equalizers by about 2 dB in linear channels. When in nonlinear channels, the SER performance of our proposed method outperforms that of either traditional or DL based equalizers more significantly, which shows the effectiveness and robustness of our proposal in the complex channel environment. ",
    "url": "https://arxiv.org/abs/2205.10750",
    "authors": [
      "Fanglei Sun",
      "Yang Li",
      "Ying Wen",
      "Jingchen Hu",
      "Jun Wang",
      "Yang Yang",
      "Kai Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10756",
    "title": "Real Time Detection Free Tracking of Multiple Objects Via Equilibrium  Optimizer",
    "abstract": "Multiple objects tracking (MOT) is a difficult task, as it usually requires special hardware and higher computation complexity. In this work, we present a new framework of MOT by using of equilibrium optimizer (EO) algorithm and reducing the resolution of the bounding boxes of the objects to solve such problems in the detection free framework. First, in the first frame the target objects are initialized and its size is computed, then its resolution is reduced if it is higher than a threshold, and then modeled by their kernel color histogram to establish a feature model. The Bhattacharya distances between the histogram of object models and other candidates are used as the fitness function to be optimized. Multiple agents are generated by EO, according to the number of the target objects to be tracked. EO algorithm is used because of its efficiency and lower computation cost compared to other algorithms in global optimization. Experimental results confirm that EO multi-object tracker achieves satisfying tracking results then other trackers. ",
    "url": "https://arxiv.org/abs/2205.10756",
    "authors": [
      "Djemai Charef-Khodja",
      "Toumi Abida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.10762",
    "title": "How sensitive are translation systems to extra contexts? Mitigating  gender bias in Neural Machine Translation models through relevant contexts",
    "abstract": "Neural Machine Translation systems built on top of Transformer-based architectures are routinely improving the state-of-the-art in translation quality according to word-overlap metrics. However, a growing number of studies also highlight the inherent gender bias that these models incorporate during training, which reflects poorly in their translations. In this work, we investigate whether these models can be instructed to fix their bias during inference using targeted, guided instructions as contexts. By translating relevant contextual sentences during inference along with the input, we observe large improvements in reducing the gender bias in translations, across three popular test suites (WinoMT, BUG, SimpleGen). We further propose a novel metric to assess several large pretrained models (OPUS-MT, M2M-100) on their sensitivity towards using contexts during translation to correct their biases. Our approach requires no fine-tuning, and thus can be used easily in production systems to de-bias translations from stereotypical gender-occupation bias. We hope our method, along with our metric, can be used to build better, bias-free translation systems. ",
    "url": "https://arxiv.org/abs/2205.10762",
    "authors": [
      "Shanya Sharma",
      "Manan Dey",
      "Koustuv Sinha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10766",
    "title": "Recent Advances in Embedding Methods for Multi-Object Tracking: A Survey",
    "abstract": "Multi-object tracking (MOT) aims to associate target objects across video frames in order to obtain entire moving trajectories. With the advancement of deep neural networks and the increasing demand for intelligent video analysis, MOT has gained significantly increased interest in the computer vision community. Embedding methods play an essential role in object location estimation and temporal identity association in MOT. Unlike other computer vision tasks, such as image classification, object detection, re-identification, and segmentation, embedding methods in MOT have large variations, and they have never been systematically analyzed and summarized. In this survey, we first conduct a comprehensive overview with in-depth analysis for embedding methods in MOT from seven different perspectives, including patch-level embedding, single-frame embedding, cross-frame joint embedding, correlation embedding, sequential embedding, tracklet embedding, and cross-track relational embedding. We further summarize the existing widely used MOT datasets and analyze the advantages of existing state-of-the-art methods according to their embedding strategies. Finally, some critical yet under-investigated areas and future research directions are discussed. ",
    "url": "https://arxiv.org/abs/2205.10766",
    "authors": [
      "Gaoang Wang",
      "Mingli Song",
      "Jenq-Neng Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10773",
    "title": "A Domain-adaptive Pre-training Approach for Language Bias Detection in  News",
    "abstract": "Media bias is a multi-faceted construct influencing individual behavior and collective decision-making. Slanted news reporting is the result of one-sided and polarized writing which can occur in various forms. In this work, we focus on an important form of media bias, i.e. bias by word choice. Detecting biased word choices is a challenging task due to its linguistic complexity and the lack of representative gold-standard corpora. We present DA-RoBERTa, a new state-of-the-art transformer-based model adapted to the media bias domain which identifies sentence-level bias with an F1 score of 0.814. In addition, we also train, DA-BERT and DA-BART, two more transformer models adapted to the bias domain. Our proposed domain-adapted models outperform prior bias detection approaches on the same data. ",
    "url": "https://arxiv.org/abs/2205.10773",
    "authors": [
      "Jan-David Krieger",
      "Timo Spinde",
      "Terry Ruas",
      "Juhi Kulshrestha",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10780",
    "title": "Data-aided Active User Detection with a User Activity Extraction Network  for Grant-free SCMA Systems",
    "abstract": "In grant-free sparse code multiple access system, joint optimization of contention resources for users and active user detection (AUD) at the receiver is a complex combinatorial problem. To this end, we propose a deep learning-based data-aided AUD scheme which extracts a priori user activity information via a novel user activity extraction network (UAEN). This is enabled by an end-to-end training of an autoencoder (AE), which simultaneously optimizes the contention resources, i.e., preamble sequences, each associated with one of the codebooks, and extraction of user activity information from both preamble and data transmission. Furthermore, we propose self-supervised pre-training scheme for the UAEN, which ensures the convergence of offline end-to-end training. Simulation results demonstrated that the proposed AUD scheme achieved 3 to 5dB gain at a target activity detection error rate of ${{10}^{-3}}$ compared to the state-of-the-art DL-based AUD schemes. ",
    "url": "https://arxiv.org/abs/2205.10780",
    "authors": [
      "Minsig Han",
      "Ameha T. Abebe",
      "Chung G. Kang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10787",
    "title": "A Dirichlet Process Mixture of Robust Task Models for Scalable Lifelong  Reinforcement Learning",
    "abstract": "While reinforcement learning (RL) algorithms are achieving state-of-the-art performance in various challenging tasks, they can easily encounter catastrophic forgetting or interference when faced with lifelong streaming information. In the paper, we propose a scalable lifelong RL method that dynamically expands the network capacity to accommodate new knowledge while preventing past memories from being perturbed. We use a Dirichlet process mixture to model the non-stationary task distribution, which captures task relatedness by estimating the likelihood of task-to-cluster assignments and clusters the task models in a latent space. We formulate the prior distribution of the mixture as a Chinese restaurant process (CRP) that instantiates new mixture components as needed. The update and expansion of the mixture are governed by the Bayesian non-parametric framework with an expectation maximization (EM) procedure, which dynamically adapts the model complexity without explicit task boundaries or heuristics. Moreover, we use the domain randomization technique to train robust prior parameters for the initialization of each task model in the mixture, thus the resulting model can better generalize and adapt to unseen tasks. With extensive experiments conducted on robot navigation and locomotion domains, we show that our method successfully facilitates scalable lifelong RL and outperforms relevant existing methods. ",
    "url": "https://arxiv.org/abs/2205.10787",
    "authors": [
      "Zhi Wang",
      "Chunlin Chen",
      "Daoyi Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10791",
    "title": "Federated Spectrum Learning for Reconfigurable Intelligent  Surfaces-Aided Wireless Edge Networks",
    "abstract": "Increasing concerns on intelligent spectrum sensing call for efficient training and inference technologies. In this paper, we propose a novel federated learning (FL) framework, dubbed federated spectrum learning (FSL), which exploits the benefits of reconfigurable intelligent surfaces (RISs) and overcomes the unfavorable impact of deep fading channels. Distinguishingly, we endow conventional RISs with spectrum learning capabilities by leveraging a fully-trained convolutional neural network (CNN) model at each RIS controller, thereby helping the base station to cooperatively infer the users who request to participate in FL at the beginning of each training iteration. To fully exploit the potential of FL and RISs, we address three technical challenges: RISs phase shifts configuration, user-RIS association, and wireless bandwidth allocation. The resulting joint learning, wireless resource allocation, and user-RIS association design is formulated as an optimization problem whose objective is to maximize the system utility while considering the impact of FL prediction accuracy. In this context, the accuracy of FL prediction interplays with the performance of resource optimization. In particular, if the accuracy of the trained CNN model deteriorates, the performance of resource allocation worsens. The proposed FSL framework is tested by using real radio frequency (RF) traces and numerical results demonstrate its advantages in terms of spectrum prediction accuracy and system utility: a better CNN prediction accuracy and FL system utility can be achieved with a larger number of RISs and reflecting elements. ",
    "url": "https://arxiv.org/abs/2205.10791",
    "authors": [
      "Bo Yang",
      "Xuelin Cao",
      "Chongwen Huang",
      "Chau Yuen",
      "Marco Di Renzo",
      "Yong Liang Guan",
      "Dusit Niyato",
      "Lijun Qian",
      "Merouane Debbah"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.10798",
    "title": "PAC-Wrap: Semi-Supervised PAC Anomaly Detection",
    "abstract": "Anomaly detection is essential for preventing hazardous outcomes for safety-critical applications like autonomous driving. Given their safety-criticality, these applications benefit from provable bounds on various errors in anomaly detection. To achieve this goal in the semi-supervised setting, we propose to provide Probably Approximately Correct (PAC) guarantees on the false negative and false positive detection rates for anomaly detection algorithms. Our method (PAC-Wrap) can wrap around virtually any existing semi-supervised and unsupervised anomaly detection method, endowing it with rigorous guarantees. Our experiments with various anomaly detectors and datasets indicate that PAC-Wrap is broadly effective. ",
    "url": "https://arxiv.org/abs/2205.10798",
    "authors": [
      "Shuo Li",
      "Xiayan Ji",
      "Edgar Dobriban",
      "Oleg Sokolsky",
      "Insup Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.10802",
    "title": "Inverse-Inverse Reinforcement Learning. How to Hide Strategy from an  Adversarial Inverse Reinforcement Learner",
    "abstract": "Inverse reinforcement learning (IRL) deals with estimating an agent's utility function from its actions. In this paper, we consider how an agent can hide its strategy and mitigate an adversarial IRL attack; we call this inverse IRL (I-IRL). How should the decision maker choose its response to ensure a poor reconstruction of its strategy by an adversary performing IRL to estimate the agent's strategy? This paper comprises four results: First, we present an adversarial IRL algorithm that estimates the agent's strategy while controlling the agent's utility function. Our second result for I-IRL result spoofs the IRL algorithm used by the adversary. Our I-IRL results are based on revealed preference theory in micro-economics. The key idea is for the agent to deliberately choose sub-optimal responses that sufficiently masks its true strategy. Third, we give a sample complexity result for our main I-IRL result when the agent has noisy estimates of the adversary specified utility function. Finally, we illustrate our I-IRL scheme in a radar problem where a meta-cognitive radar is trying to mitigate an adversarial target. ",
    "url": "https://arxiv.org/abs/2205.10802",
    "authors": [
      "Kunal Pattanayak",
      "Vikram Krishnamurthy",
      "Christopher Berry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.10803",
    "title": "GraphMAE: Self-Supervised Masked Graph Autoencoders",
    "abstract": "Self-supervised learning (SSL) has been extensively explored in recent years. Particularly, generative SSL has seen emerging success in natural language processing and other fields, such as the wide adoption of BERT and GPT. Despite this, contrastive learning-which heavily relies on structural data augmentation and complicated training strategies-has been the dominant approach in graph SSL, while the progress of generative SSL on graphs, especially graph autoencoders (GAEs), has thus far not reached the potential as promised in other fields. In this paper, we identify and examine the issues that negatively impact the development of GAEs, including their reconstruction objective, training robustness, and error metric. We present a masked graph autoencoder GraphMAE that mitigates these issues for generative self-supervised graph learning. Instead of reconstructing structures, we propose to focus on feature reconstruction with both a masking strategy and scaled cosine error that benefit the robust training of GraphMAE. We conduct extensive experiments on 21 public datasets for three different graph learning tasks. The results manifest that GraphMAE-a simple graph autoencoder with our careful designs-can consistently generate outperformance over both contrastive and generative state-of-the-art baselines. This study provides an understanding of graph autoencoders and demonstrates the potential of generative self-supervised learning on graphs. ",
    "url": "https://arxiv.org/abs/2205.10803",
    "authors": [
      "Zhenyu Hou",
      "Xiao Liu",
      "Yuxiao Dong",
      "Hongxia yang",
      "Chunjie Wang",
      "Jie Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10822",
    "title": "A Graph Enhanced BERT Model for Event Prediction",
    "abstract": "Predicting the subsequent event for an existing event context is an important but challenging task, as it requires understanding the underlying relationship between events. Previous methods propose to retrieve relational features from event graph to enhance the modeling of event correlation. However, the sparsity of event graph may restrict the acquisition of relevant graph information, and hence influence the model performance. To address this issue, we consider automatically building of event graph using a BERT model. To this end, we incorporate an additional structured variable into BERT to learn to predict the event connections in the training process. Hence, in the test process, the connection relationship for unseen events can be predicted by the structured variable. Results on two event prediction tasks: script event prediction and story ending prediction, show that our approach can outperform state-of-the-art baseline methods. ",
    "url": "https://arxiv.org/abs/2205.10822",
    "authors": [
      "Li Du",
      "Xiao Ding",
      "Yue Zhang",
      "Kai Xiong",
      "Ting Liu",
      "Bing Qin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10825",
    "title": "A Convolutional Dispersion Relation Preserving Scheme for the Acoustic  Wave Equation",
    "abstract": "We propose an accurate numerical scheme for approximating the solution of the two dimensional acoustic wave problem. We use machine learning to find a stencil suitable even in the presence of high wavenumbers. The proposed scheme incorporates physically informed elements from the field of optimized numerical schemes into a convolutional optimization machine learning algorithm. ",
    "url": "https://arxiv.org/abs/2205.10825",
    "authors": [
      "Oded Ovadia",
      "Adar Kahana",
      "Eli Turkel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2205.10830",
    "title": "A review on Deep Neural Network for Computer Network Traffic  Classification",
    "abstract": "Focus on Deep Neural Network based malicious and normal computer Network Traffic classification. (such as attacks, phishing, any other illegal activity and normal traffic identification). In this paper, the main idea is to review, existed Neural Network based network traffic classification. Which indicates intrusion activity classification and detection. It is very important to classify network traffic to safeguard any system, connected to computer network. There are a variety of NN architecture for it, with different rate of accuracy. On this paper we will do relative compression among them. Index Terms-Computer Network, Network traffic, Packet, Intrusion, DOS (Denial-of-service), unauthorized access, IDS (Intrusion Detection System), IPS (Intrusion Prevention Systems), R2L (Remote to Local Attack), Probing, U2R (User to Root Attack), DNN (Deep Neural Network), CRNN (Convolutional Recurrent Neural Network), RPROP (Resilient propagation). ",
    "url": "https://arxiv.org/abs/2205.10830",
    "authors": [
      "Md. Ariful Haque",
      "Dr. Rajesh Palit"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.10837",
    "title": "Neural Inverse Kinematics",
    "abstract": "Inverse kinematic (IK) methods recover the parameters of the joints, given the desired position of selected elements in the kinematic chain. While the problem is well-defined and low-dimensional, it has to be solved rapidly, accounting for multiple possible solutions. In this work, we propose a neural IK method that employs the hierarchical structure of the problem to sequentially sample valid joint angles conditioned on the desired position and on the preceding joints along the chain. In our solution, a hypernetwork $f$ recovers the parameters of multiple primary networks {$g_1,g_2,\\dots,g_N$, where $N$ is the number of joints}, such that each $g_i$ outputs a distribution of possible joint angles, and is conditioned on the sampled values obtained from the previous primary networks $g_j, j<i$. The hypernetwork can be trained on readily available pairs of matching joint angles and positions, without observing multiple solutions. At test time, a high-variance joint distribution is presented, by sampling sequentially from the primary networks. We demonstrate the advantage of the proposed method both in comparison to other IK methods for isolated instances of IK and with regard to following the path of the end effector in Cartesian space. ",
    "url": "https://arxiv.org/abs/2205.10837",
    "authors": [
      "Raphael Bensadoun",
      "Shir Gur",
      "Nitsan Blau",
      "Tom Shenkar",
      "Lior Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.10840",
    "title": "Self-supervised U-net for few-shot learning of object segmentation in  microscopy images",
    "abstract": "State-of-the-art segmentation performances are achieved by deep neural networks. Training these networks from only a few training examples is challenging while producing annotated images that provide supervision is tedious. Recently, self-supervision, i.e. designing a neural pipeline providing synthetic or indirect supervision, has proved to significantly increase generalization performances of models trained on few shots. This paper introduces one such neural pipeline in the context of microscopic image segmentation. By leveraging the rather simple content of these images a trainee network can be mentored by a referee network which has been previously trained on synthetically generated pairs of corrupted/correct region masks. ",
    "url": "https://arxiv.org/abs/2205.10840",
    "authors": [
      "Arnaud Deleruyelle",
      "Cristian Versari",
      "John Klein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10841",
    "title": "Robust Modeling and Controls for Racing on the Edge",
    "abstract": "Race cars are routinely driven to the edge of their handling limits in dynamic scenarios well above 200mph. Similar challenges are posed in autonomous racing, where a software stack, instead of a human driver, interacts within a multi-agent environment. For an Autonomous Racing Vehicle (ARV), operating at the edge of handling limits and acting safely in these dynamic environments is still an unsolved problem. In this paper, we present a baseline controls stack for an ARV capable of operating safely up to 140mph. Additionally, limitations in the current approach are discussed to highlight the need for improved dynamics modeling and learning. ",
    "url": "https://arxiv.org/abs/2205.10841",
    "authors": [
      "Joshua Spisak",
      "Andrew Saba",
      "Nayana Suvarna",
      "Brian Mao",
      "Chuan Tian Zhang",
      "Chris Chang",
      "Sebastian Scherer",
      "Deva Ramanan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.10848",
    "title": "Robust Quantity-Aware Aggregation for Federated Learning",
    "abstract": "Federated learning (FL) enables multiple clients to collaboratively train models without sharing their local data, and becomes an important privacy-preserving machine learning framework. However, classical FL faces serious security and robustness problem, e.g., malicious clients can poison model updates and at the same time claim large quantities to amplify the impact of their model updates in the model aggregation. Existing defense methods for FL, while all handling malicious model updates, either treat all quantities benign or simply ignore/truncate the quantities of all clients. The former is vulnerable to quantity-enhanced attack, while the latter leads to sub-optimal performance since the local data on different clients is usually in significantly different sizes. In this paper, we propose a robust quantity-aware aggregation algorithm for federated learning, called FedRA, to perform the aggregation with awareness of local data quantities while being able to defend against quantity-enhanced attacks. More specifically, we propose a method to filter malicious clients by jointly considering the uploaded model updates and data quantities from different clients, and performing quantity-aware weighted averaging on model updates from remaining clients. Moreover, as the number of malicious clients participating in the federated learning may dynamically change in different rounds, we also propose a malicious client number estimator to predict how many suspicious clients should be filtered in each round. Experiments on four public datasets demonstrate the effectiveness of our FedRA method in defending FL against quantity-enhanced attacks. ",
    "url": "https://arxiv.org/abs/2205.10848",
    "authors": [
      "Jingwei Yi",
      "Fangzhao Wu",
      "Huishuai Zhang",
      "Bin Zhu",
      "Tao Qi",
      "Guangzhong Sun",
      "Xing Xie"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10850",
    "title": "AFEC: A Knowledge Graph Capturing Social Intelligence in Casual  Conversations",
    "abstract": "This paper introduces AFEC, an automatically curated knowledge graph based on people's day-to-day casual conversations. The knowledge captured in this graph bears potential for conversational systems to understand how people offer acknowledgement, consoling, and a wide range of empathetic responses in social conversations. For this body of knowledge to be comprehensive and meaningful, we curated a large-scale corpus from the r/CasualConversation SubReddit. After taking the first two turns of all conversations, we obtained 134K speaker nodes and 666K listener nodes. To demonstrate how a chatbot can converse in social settings, we built a retrieval-based chatbot and compared it with existing empathetic dialog models. Experiments show that our model is capable of generating much more diverse responses (at least 15% higher diversity scores in human evaluation), while still outperforming two out of the four baselines in terms of response quality. ",
    "url": "https://arxiv.org/abs/2205.10850",
    "authors": [
      "Yubo Xie",
      "Junze Li",
      "Pearl Pu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.10851",
    "title": "Vision-based Anti-UAV Detection and Tracking",
    "abstract": "Unmanned aerial vehicles (UAV) have been widely used in various fields, and their invasion of security and privacy has aroused social concern. Several detection and tracking systems for UAVs have been introduced in recent years, but most of them are based on radio frequency, radar, and other media. We assume that the field of computer vision is mature enough to detect and track invading UAVs. Thus we propose a visible light mode dataset called Dalian University of Technology Anti-UAV dataset, DUT Anti-UAV for short. It contains a detection dataset with a total of 10,000 images and a tracking dataset with 20 videos that include short-term and long-term sequences. All frames and images are manually annotated precisely. We use this dataset to train several existing detection algorithms and evaluate the algorithms' performance. Several tracking methods are also tested on our tracking dataset. Furthermore, we propose a clear and simple tracking algorithm combined with detection that inherits the detector's high precision. Extensive experiments show that the tracking performance is improved considerably after fusing detection, thus providing a new attempt at UAV tracking using our dataset.The datasets and results are publicly available at: https://github.com/wangdongdut/DUT-Anti-UAV ",
    "url": "https://arxiv.org/abs/2205.10851",
    "authors": [
      "Jie Zhao",
      "Jingshu Zhang",
      "Dongdong Li",
      "Dong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10852",
    "title": "Relphormer: Relational Graph Transformer for Knowledge Graph  Representation",
    "abstract": "Transformers have achieved remarkable performance in widespread fields, including natural language processing, computer vision and graph mining. However, in the knowledge graph representation, where translational distance paradigm dominates this area, vanilla Transformer architectures have not yielded promising improvements. Note that vanilla Transformer architectures struggle to capture the intrinsically semantic and structural information of knowledge graphs and can hardly scale to long-distance neighbors due to quadratic dependency. To this end, we propose a new variant of Transformer for knowledge graph representation dubbed Relphormer. Specifically, we introduce Triple2Seq which can dynamically sample contextualized sub-graph sequences as the input of the Transformer to alleviate the scalability issue. We then propose a novel structure-enhanced self-attention mechanism to encode the relational information and keep the globally semantic information among sub-graphs. Moreover, we propose masked knowledge modeling as a new paradigm for knowledge graph representation learning to unify different link prediction tasks. Experimental results show that our approach can obtain better performance on benchmark datasets compared with baselines. ",
    "url": "https://arxiv.org/abs/2205.10852",
    "authors": [
      "Zhen Bi",
      "Siyuan Cheng",
      "Ningyu Zhang",
      "Xiaozhuan Liang",
      "Feiyu Xiong",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.10866",
    "title": "Blackbird's language matrices (BLMs): a new benchmark to investigate  disentangled generalisation in neural networks",
    "abstract": "Current successes of machine learning architectures are based on computationally expensive algorithms and prohibitively large amounts of data. We need to develop tasks and data to train networks to reach more complex and more compositional skills. In this paper, we illustrate Blackbird's language matrices (BLMs), a novel grammatical dataset developed to test a linguistic variant of Raven's progressive matrices, an intelligence test usually based on visual stimuli. The dataset consists of 44800 sentences, generatively constructed to support investigations of current models' linguistic mastery of grammatical agreement rules and their ability to generalise them. We present the logic of the dataset, the method to automatically construct data on a large scale and the architecture to learn them. Through error analysis and several experiments on variations of the dataset, we demonstrate that this language task and the data that instantiate it provide a new challenging testbed to understand generalisation and abstraction. ",
    "url": "https://arxiv.org/abs/2205.10866",
    "authors": [
      "Paola Merlo",
      "Aixiu An",
      "Maria A. Rodriguez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.10879",
    "title": "Fast Gaussian Process Posterior Mean Prediction via Local Cross  Validation and Precomputation",
    "abstract": "Gaussian processes (GPs) are Bayesian non-parametric models useful in a myriad of applications. Despite their popularity, the cost of GP predictions (quadratic storage and cubic complexity with respect to the number of training points) remains a hurdle in applying GPs to large data. We present a fast posterior mean prediction algorithm called FastMuyGPs to address this shortcoming. FastMuyGPs is based upon the MuyGPs hyperparameter estimation algorithm and utilizes a combination of leave-one-out cross-validation, batching, nearest neighbors sparsification, and precomputation to provide scalable, fast GP prediction. We demonstrate several benchmarks wherein FastMuyGPs prediction attains superior accuracy and competitive or superior runtime to both deep neural networks and state-of-the-art scalable GP algorithms. ",
    "url": "https://arxiv.org/abs/2205.10879",
    "authors": [
      "Alec M. Dunton",
      "Benjamin W. Priest",
      "Amanda Muyskens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.10900",
    "title": "Visual Explanations from Deep Networks via Riemann-Stieltjes Integrated  Gradient-based Localization",
    "abstract": "Neural networks are becoming increasingly better at tasks that involve classifying and recognizing images. At the same time techniques intended to explain the network output have been proposed. One such technique is the Gradient-based Class Activation Map (Grad-CAM), which is able to locate features of an input image at various levels of a convolutional neural network (CNN), but is sensitive to the vanishing gradients problem. There are techniques such as Integrated Gradients (IG), that are not affected by that problem, but its use is limited to the input layer of a network. Here we introduce a new technique to produce visual explanations for the predictions of a CNN. Like Grad-CAM, our method can be applied to any layer of the network, and like Integrated Gradients it is not affected by the problem of vanishing gradients. For efficiency, gradient integration is performed numerically at the layer level using a Riemann-Stieltjes sum approximation. Compared to Grad-CAM, heatmaps produced by our algorithm are better focused in the areas of interest, and their numerical computation is more stable. Our code is available at https://github.com/mlerma54/RSIGradCAM ",
    "url": "https://arxiv.org/abs/2205.10900",
    "authors": [
      "Mirtha Lucas",
      "Miguel Lerma",
      "Jacob Furst",
      "Daniela Raicu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10906",
    "title": "Monitoring of Perception Systems: Deterministic, Probabilistic, and  Learning-based Fault Detection and Identification",
    "abstract": "This paper investigates runtime monitoring of perception systems. Perception is a critical component of high-integrity applications of robotics and autonomous systems, such as self-driving cars. In these applications, failure of perception systems may put human life at risk, and a broad adoption of these technologies requires the development of methodologies to guarantee and monitor safe operation. Despite the paramount importance of perception, currently there is no formal approach for system-level perception monitoring. In this paper, we formalize the problem of runtime fault detection and identification in perception systems and present a framework to model diagnostic information using a diagnostic graph. We then provide a set of deterministic, probabilistic, and learning-based algorithms that use diagnostic graphs to perform fault detection and identification. Moreover, we investigate fundamental limits and provide deterministic and probabilistic guarantees on the fault detection and identification results. We conclude the paper with an extensive experimental evaluation, which recreates several realistic failure modes in the LGSVL open-source autonomous driving simulator, and applies the proposed system monitors to a state-of-the-art autonomous driving software stack (Baidu's Apollo Auto). The results show that the proposed system monitors outperform baselines, have the potential of preventing accidents in realistic autonomous driving scenarios, and incur a negligible computational overhead. ",
    "url": "https://arxiv.org/abs/2205.10906",
    "authors": [
      "Pasquale Antonante",
      "Heath Nilsen",
      "Luca Carlone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10920",
    "title": "Test-Time Robust Personalization for Federated Learning",
    "abstract": "Federated Learning (FL) is a machine learning paradigm where many clients collaboratively learn a shared global model with decentralized training data. Personalization on FL model additionally adapts the global model to different clients, achieving promising results on consistent local training & test distributions. However, for real-world personalized FL applications, it is crucial to go one step further: robustifying FL models under evolving local test set during deployment, where various types of distribution shifts can arise. In this work, we identify the pitfalls of existing works under test-time distribution shifts and propose a novel test-time robust personalization method, namely Federated Test-time Head Ensemble plus tuning (FedTHE+). We illustrate the advancement of FedTHE+ (and its degraded computationally efficient variant FedTHE) over strong competitors, for training various neural architectures (CNN, ResNet, and Transformer) on CIFAR10 and ImageNet and evaluating on diverse test distributions. Along with this, we build a benchmark for assessing performance and robustness of personalized FL methods during deployment. ",
    "url": "https://arxiv.org/abs/2205.10920",
    "authors": [
      "Liangze Jiang",
      "Tao Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10933",
    "title": "AutoJoin: Efficient Adversarial Training for Robust Maneuvering via  Denoising Autoencoder and Joint Learning",
    "abstract": "As a result of increasingly adopted machine learning algorithms and ubiquitous sensors, many 'perception-to-control' systems have been deployed in various settings. For these systems to be trustworthy, we need to improve their robustness with adversarial training being one approach. In this work, we propose a gradient-free adversarial training technique, called AutoJoin. AutoJoin is a very simple yet effective and efficient approach to produce robust models for imaged-based autonomous maneuvering. Compared to other SOTA methods with testing on over 5M perturbed and clean images, AutoJoin achieves significant performance increases up to the 40% range under perturbed datasets while improving on clean performance for almost every dataset tested. In particular, AutoJoin can triple the clean performance improvement compared to the SOTA work by Shen et al. Regarding efficiency, AutoJoin demonstrates strong advantages over other SOTA techniques by saving up to 83% time per training epoch and 90% training data. The core idea of AutoJoin is to use a decoder attachment to the original regression model creating a denoising autoencoder within the architecture. This allows the tasks 'steering' and 'denoising sensor input' to be jointly learnt and enable the two tasks to reinforce each other's performance. ",
    "url": "https://arxiv.org/abs/2205.10933",
    "authors": [
      "Michael Villarreal",
      "Bibek Poudel",
      "Ryan Wickman",
      "Yu Shen",
      "Weizi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.10937",
    "title": "muNet: Evolving Pretrained Deep Neural Networks into Scalable  Auto-tuning Multitask Systems",
    "abstract": "Most uses of machine learning today involve training a model from scratch for a particular task, or sometimes starting with a model pretrained on a related task and then fine-tuning on a downstream task. Both approaches offer limited knowledge transfer between different tasks, time-consuming human-driven customization to individual tasks and high computational costs especially when starting from randomly initialized models. We propose a method that uses the layers of a pretrained deep neural network as building blocks to construct an ML system that can jointly solve an arbitrary number of tasks. The resulting system can leverage cross tasks knowledge transfer, while being immune from common drawbacks of multitask approaches such as catastrophic forgetting, gradients interference and negative transfer. We define an evolutionary approach designed to jointly select the prior knowledge relevant for each task, choose the subset of the model parameters to train and dynamically auto-tune its hyperparameters. Furthermore, a novel scale control method is employed to achieve quality/size trade-offs that outperform common fine-tuning techniques. Compared with standard fine-tuning on a benchmark of 10 diverse image classification tasks, the proposed model improves the average accuracy by 2.39% while using 47% less parameters per task. ",
    "url": "https://arxiv.org/abs/2205.10937",
    "authors": [
      "Andrea Gesmundo",
      "Jeff Dean"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.10940",
    "title": "Toward smart composites: small-scale, untethered prediction and control  for soft sensor/actuator systems",
    "abstract": "We present a suite of algorithms and tools for model-predictive control of sensor/actuator systems with embedded microcontroller units (MCU). These MCUs can be colocated with sensors and actuators, thereby enabling a new class of smart composites capable of autonomous behavior that does not require an external computer. In this approach, kinematics are learned using a neural network model from offline data and compiled into MCU code using nn4mc, an open-source tool. Online Newton-Raphson optimization solves for the control input. Shallow neural network models applied to 1D sensor signals allow for reduced model sizes and increased control loop frequencies. We validate this approach on a simulated mass-spring-damper system and two experimental setups with different sensing, actuation, and computational hardware: a tendon-based platform with embedded optical lace sensors and a HASEL-based platform with magnetic sensors. Experimental results indicate effective high-bandwidth tracking of reference paths (120 Hz and higher) with a small memory footprint (less than or equal to 6.4% of available flash). The measured path following error does not exceed 2 mm in the tendon-based platform, and the predicted path following error does not exceed 1 mm in the HASEL-based platform. This controller code's mean power consumption in an ARM Cortex-M4 computer is 45.4 mW. This control approach is also compatible with Tensorflow Lite models and equivalent compilers. Embedded intelligence in composite materials enables a new class of composites that infuse intelligence into structures and systems, making them capable of responding to environmental stimuli using their proprioception. ",
    "url": "https://arxiv.org/abs/2205.10940",
    "authors": [
      "Sarah Aguasvivas Manzano",
      "Vani Sundaram",
      "Artemis Xu",
      "Khoi Ly",
      "Mark Rentschler",
      "Robert Shepherd",
      "Nikolaus Correll"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10952",
    "title": "Analysis of functional neural codes of deep learning models",
    "abstract": "Deep neural networks (DNNs), the agents of deep learning (DL), require a massive number of parallel/sequential operations. This makes it extremely challenging to comprehend DNNs' operations and hinders proper diagnosis. Consequently, DNNs cannot be readily used in high-stakes domains, in which incorrect decisions can lead to catastrophic failures. Therefore, to build more reliable DNNs/DL to be deployed in high-stakes real-world problems, it is imperative that we develop proper analysis tools that will allow us to better understand DNNs' internal operations underlying their decision-making. Here, we used the self-organizing map (SOM) to analyze internal codes of DL models associated with their decision-making. Our analyses suggest that hidden layer activation patterns can be mapped onto a finite number of patterns and are correlated with DL predictions, raising the possibility that they could serve as functional codes of DL models. Encouraged by this observation, we further used SOM to estimate input features coded in hidden layers, analyzed the effects of adversarial inputs to better understand characterized internal representations' evolution and adversarial perturbations' propagation in DL models. ",
    "url": "https://arxiv.org/abs/2205.10952",
    "authors": [
      "Jung Hoon Lee",
      "Sujith Vijayan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10970",
    "title": "Neural Subgraph Explorer: Reducing Noisy Information via Target-Oriented  Syntax Graph Pruning",
    "abstract": "Recent years have witnessed the emerging success of leveraging syntax graphs for the target sentiment classification task. However, we discover that existing syntax-based models suffer from two issues: noisy information aggregation and loss of distant correlations. In this paper, we propose a novel model termed Neural Subgraph Explorer, which (1) reduces the noisy information via pruning target-irrelevant nodes on the syntax graph; (2) introduces beneficial first-order connections between the target and its related words into the obtained graph. Specifically, we design a multi-hop actions score estimator to evaluate the value of each word regarding the specific target. The discrete action sequence is sampled through Gumble-Softmax and then used for both of the syntax graph and the self-attention graph. To introduce the first-order connections between the target and its relevant words, the two pruned graphs are merged. Finally, graph convolution is conducted on the obtained unified graph to update the hidden states. And this process is stacked with multiple layers. To our knowledge, this is the first attempt of target-oriented syntax graph pruning in this task. Experimental results demonstrate the superiority of our model, which achieves new state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2205.10970",
    "authors": [
      "Bowen Xing",
      "Ivor W. Tsang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10990",
    "title": "Multiple Domain Cyberspace Attack and Defense Game Based on Reward  Randomization Reinforcement Learning",
    "abstract": "The existing network attack and defense method can be regarded as game, but most of the game only involves network domain, not multiple domain cyberspace. To address this challenge, this paper proposed a multiple domain cyberspace attack and defense game model based on reinforcement learning. We define the multiple domain cyberspace include physical domain, network domain and digital domain. By establishing two agents, representing the attacker and the defender respectively, defender will select the multiple domain actions in the multiple domain cyberspace to obtain defender's optimal reward by reinforcement learning. In order to improve the defense ability of defender, a game model based on reward randomization reinforcement learning is proposed. When the defender takes the multiple domain defense action, the reward is randomly given and subject to linear distribution, so as to find the better defense policy and improve defense success rate. The experimental results show that the game model can effectively simulate the attack and defense state of multiple domain cyberspace, and the proposed method has a higher defense success rate than DDPG and DQN. ",
    "url": "https://arxiv.org/abs/2205.10990",
    "authors": [
      "Lei Zhang",
      "Yu Pan",
      "Yi Liu",
      "Qibin Zheng",
      "Zhisong Pan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11008",
    "title": "Calibrate and Refine! A Novel and Agile Framework for ASR-error Robust  Intent Detection",
    "abstract": "The past ten years have witnessed the rapid development of text-based intent detection, whose benchmark performances have already been taken to a remarkable level by deep learning techniques. However, automatic speech recognition (ASR) errors are inevitable in real-world applications due to the environment noise, unique speech patterns and etc, leading to sharp performance drop in state-of-the-art text-based intent detection models. Essentially, this phenomenon is caused by the semantic drift brought by ASR errors and most existing works tend to focus on designing new model structures to reduce its impact, which is at the expense of versatility and flexibility. Different from previous one-piece model, in this paper, we propose a novel and agile framework called CR-ID for ASR error robust intent detection with two plug-and-play modules, namely semantic drift calibration module (SDCM) and phonemic refinement module (PRM), which are both model-agnostic and thus could be easily integrated to any existing intent detection models without modifying their structures. Experimental results on SNIPS dataset show that, our proposed CR-ID framework achieves competitive performance and outperform all the baseline methods on ASR outputs, which verifies that CR-ID can effectively alleviate the semantic drift caused by ASR errors. ",
    "url": "https://arxiv.org/abs/2205.11008",
    "authors": [
      "Peilin Zhou",
      "Dading Chong",
      "Helin Wang",
      "Qingcheng Zeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.11023",
    "title": "AdaptivePaste: Code Adaptation through Learning Semantics-aware Variable  Usage Representations",
    "abstract": "In software development, it is common for programmers to copy-paste code snippets and then adapt them to their use case. This scenario motivates \\textit{code adaptation} task -- a variant of program repair which aims to adapt all variable identifiers in a pasted snippet of code to the surrounding, preexisting source code. Nevertheless, no existing approach have been shown to effectively address this task. In this paper, we introduce AdaptivePaste, a learning-based approach to source code adaptation, based on the transformer model and a dedicated dataflow-aware deobfuscation pre-training task to learn meaningful representations of variable usage patterns. We evaluate AdaptivePaste on a dataset of code snippets in Python. Evaluation results suggest that our model can learn to adapt copy-pasted code with 79.8\\% accuracy. ",
    "url": "https://arxiv.org/abs/2205.11023",
    "authors": [
      "Xiaoyu Liu",
      "Jinu Jang",
      "Neel Sundaresan",
      "Miltiadis Allamanis",
      "Alexey Svyatkovskiy"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.11031",
    "title": "Body Composition Estimation Based on Multimodal Multi-task Deep Neural  Network",
    "abstract": "In addition to body weight and Body Mass Index (BMI), body composition is an essential data point that allows people to understand their overall health and body fitness. However, body composition is largely made up of muscle, fat, bones, and water, which makes estimation not as easy and straightforward as measuring body weight. In this paper, we introduce a multimodal multi-task deep neural network to estimate body fat percentage and skeletal muscle mass by analyzing facial images in addition to a person's height, gender, age, and weight information. Using a dataset representative of demographics in Japan, we confirmed that the proposed approach performed better compared to the existing methods. Moreover, the multi-task approach implemented in this study is also able to grasp the negative correlation between body fat percentage and skeletal muscle mass gain/loss. ",
    "url": "https://arxiv.org/abs/2205.11031",
    "authors": [
      "Subas Chhatkuli",
      "Iris Jiang",
      "Kyohei Kamiyama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11039",
    "title": "FLEX: Feature-Logic Embedding Framework for CompleX Knowledge Graph  Reasoning",
    "abstract": "Current best performing models for knowledge graph reasoning (KGR) are based on complex distribution or geometry objects to embed entities and first-order logical (FOL) queries in low-dimensional spaces. They can be summarized as a center-size framework (point/box/cone, Beta/Gaussian distribution, etc.) whose logical reasoning ability is limited by the expressiveness of the relevant mathematical concepts. Because too deeply the center and the size depend on each other, it is difficult to integrate the logical reasoning ability with other models. To address these challenges, we instead propose a novel KGR framework named Feature-Logic Embedding framework, FLEX, which is the first KGR framework that can not only TRULY handle all FOL operations including conjunction, disjunction, negation and so on, but also support various feature spaces. Specifically, the logic part of feature-logic framework is based on vector logic, which naturally models all FOL operations. Experiments demonstrate that FLEX significantly outperforms existing state-of-the-art methods on benchmark datasets. ",
    "url": "https://arxiv.org/abs/2205.11039",
    "authors": [
      "Xueyuan Lin",
      "Haihong E",
      "Gengxian Zhou",
      "Tianyi Hu",
      "Li Ningyuan",
      "Mingzhi Sun",
      "Haoran Luo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11057",
    "title": "Falsification of Multiple Requirements for Cyber-Physical Systems Using  Online Generative Adversarial Networks and Multi-Armed Bandits",
    "abstract": "We consider the problem of falsifying safety requirements of Cyber-Physical Systems expressed in signal temporal logic (STL). This problem can be turned into an optimization problem via STL robustness functions. In this paper, our focus is in falsifying systems with multiple requirements. We propose to solve such conjunctive requirements using online generative adversarial networks (GANs) as test generators. Our main contribution is an algorithm which falsifies a conjunctive requirement $\\varphi_1 \\land \\cdots \\land \\varphi_n$ by using a GAN for each requirement $\\varphi_i$ separately. Using ideas from multi-armed bandit algorithms, our algorithm only trains a single GAN at every step, which saves resources. Our experiments indicate that, in addition to saving resources, this multi-armed bandit algorithm can falsify requirements with fewer number of executions on the system under test when compared to (i) an algorithm training a single GAN for the complete conjunctive requirement and (ii) an algorithm always training $n$ GANs at each step. ",
    "url": "https://arxiv.org/abs/2205.11057",
    "authors": [
      "Jarkko Peltom\u00e4ki",
      "Ivan Porres"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.11060",
    "title": "Wasserstein Generative Adversarial Networks for Online Test Generation  for Cyber Physical Systems",
    "abstract": "We propose a novel online test generation algorithm WOGAN based on Wasserstein Generative Adversarial Networks. WOGAN is a general-purpose black-box test generator applicable to any system under test having a fitness function for determining failing tests. As a proof of concept, we evaluate WOGAN by generating roads such that a lane assistance system of a car fails to stay on the designated lane. We find that our algorithm has a competitive performance respect to previously published algorithms. ",
    "url": "https://arxiv.org/abs/2205.11060",
    "authors": [
      "Jarkko Peltom\u00e4ki",
      "Frankie Spencer",
      "Ivan Porres"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.11083",
    "title": "MonoFormer: Towards Generalization of self-supervised monocular depth  estimation with Transformers",
    "abstract": "Self-supervised monocular depth estimation has been widely studied recently. Most of the work has focused on improving performance on benchmark datasets, such as KITTI, but has offered a few experiments on generalization performance. In this paper, we investigate the backbone networks (e.g. CNNs, Transformers, and CNN-Transformer hybrid models) toward the generalization of monocular depth estimation. We first evaluate state-of-the-art models on diverse public datasets, which have never been seen during the network training. Next, we investigate the effects of texture-biased and shape-biased representations using the various texture-shifted datasets that we generated. We observe that Transformers exhibit a strong shape bias and CNNs do a strong texture-bias. We also find that shape-biased models show better generalization performance for monocular depth estimation compared to texture-biased models. Based on these observations, we newly design a CNN-Transformer hybrid network with a multi-level adaptive feature fusion module, called MonoFormer. The design intuition behind MonoFormer is to increase shape bias by employing Transformers while compensating for the weak locality bias of Transformers by adaptively fusing multi-level representations. Extensive experiments show that the proposed method achieves state-of-the-art performance with various public datasets. Our method also shows the best generalization ability among the competitive methods. ",
    "url": "https://arxiv.org/abs/2205.11083",
    "authors": [
      "Jinwoo Bae",
      "Sungho Moon",
      "Sunghoon Im"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11097",
    "title": "A Fine-grained Interpretability Evaluation Benchmark for Neural NLP",
    "abstract": "While there is increasing concern about the interpretability of neural models, the evaluation of interpretability remains an open problem, due to the lack of proper evaluation datasets and metrics. In this paper, we present a novel benchmark to evaluate the interpretability of both neural models and saliency methods. This benchmark covers three representative NLP tasks: sentiment analysis, textual similarity and reading comprehension, each provided with both English and Chinese annotated data. In order to precisely evaluate the interpretability, we provide token-level rationales that are carefully annotated to be sufficient, compact and comprehensive. We also design a new metric, i.e., the consistency between the rationales before and after perturbations, to uniformly evaluate the interpretability of models and saliency methods on different tasks. Based on this benchmark, we conduct experiments on three typical models with three saliency methods, and unveil their strengths and weakness in terms of interpretability. We will release this benchmark at \\url{https://xyz} and hope it can facilitate the research in building trustworthy systems. ",
    "url": "https://arxiv.org/abs/2205.11097",
    "authors": [
      "Lijie Wang",
      "Yaozong Shen",
      "Shuyuan Peng",
      "Shuai Zhang",
      "Xinyan Xiao",
      "Hao Liu",
      "Hongxuan Tang",
      "Ying Chen",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.11098",
    "title": "PointDistiller: Structured Knowledge Distillation Towards Efficient and  Compact 3D Detection",
    "abstract": "The remarkable breakthroughs in point cloud representation learning have boosted their usage in real-world applications such as self-driving cars and virtual reality. However, these applications usually have an urgent requirement for not only accurate but also efficient 3D object detection. Recently, knowledge distillation has been proposed as an effective model compression technique, which transfers the knowledge from an over-parameterized teacher to a lightweight student and achieves consistent effectiveness in 2D vision. However, due to point clouds' sparsity and irregularity, directly applying previous image-based knowledge distillation methods to point cloud detectors usually leads to unsatisfactory performance. To fill the gap, this paper proposes PointDistiller, a structured knowledge distillation framework for point clouds-based 3D detection. Concretely, PointDistiller includes local distillation which extracts and distills the local geometric structure of point clouds with dynamic graph convolution and reweighted learning strategy, which highlights student learning on the crucial points or voxels to improve knowledge distillation efficiency. Extensive experiments on both voxels-based and raw points-based detectors have demonstrated the effectiveness of our method over seven previous knowledge distillation methods. For instance, our 4X compressed PointPillars student achieves 2.8 and 3.4 mAP improvements on BEV and 3D object detection, outperforming its teacher by 0.9 and 1.8 mAP, respectively. Codes have been released at https://github.com/RunpeiDong/PointDistiller. ",
    "url": "https://arxiv.org/abs/2205.11098",
    "authors": [
      "Linfeng Zhang",
      "Runpei Dong",
      "Hung-Shuo Tai",
      "Kaisheng Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11121",
    "title": "A normal approximation for joint frequency estimatation under Local  Differential Privacy",
    "abstract": "In the recent years, Local Differential Privacy (LDP) has been one of the corner stone of privacy preserving data analysis. However, many challenges still opposes its widespread application. One of these problems is the scalability of LDP to high dimensional data, in particular for estimating joint-distributions. In this paper, we develop an approximate estimator for category frequency joint-distribution under so-called pure LDP protocols. ",
    "url": "https://arxiv.org/abs/2205.11121",
    "authors": [
      "Thomas Carette"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2205.11124",
    "title": "ConvPoseCNN2: Prediction and Refinement of Dense 6D Object Poses",
    "abstract": "Object pose estimation is a key perceptual capability in robotics. We propose a fully-convolutional extension of the PoseCNN method, which densely predicts object translations and orientations. This has several advantages such as improving the spatial resolution of the orientation predictions -- useful in highly-cluttered arrangements, significant reduction in parameters by avoiding full connectivity, and fast inference. We propose and discuss several aggregation methods for dense orientation predictions that can be applied as a post-processing step, such as averaging and clustering techniques. We demonstrate that our method achieves the same accuracy as PoseCNN on the challenging YCB-Video dataset and provide a detailed ablation study of several variants of our method. Finally, we demonstrate that the model can be further improved by inserting an iterative refinement module into the middle of the network, which enforces consistency of the prediction. ",
    "url": "https://arxiv.org/abs/2205.11124",
    "authors": [
      "Arul Selvam Periyasamy",
      "Catherine Capellen",
      "Max Schwarz",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11131",
    "title": "Heterogeneous Semantic Transfer for Multi-label Recognition with Partial  Labels",
    "abstract": "Multi-label image recognition with partial labels (MLR-PL), in which some labels are known while others are unknown for each image, may greatly reduce the cost of annotation and thus facilitate large-scale MLR. We find that strong semantic correlations exist within each image and across different images, and these correlations can help transfer the knowledge possessed by the known labels to retrieve the unknown labels and thus improve the performance of the MLR-PL task (see Figure 1). In this work, we propose a novel heterogeneous semantic transfer (HST) framework that consists of two complementary transfer modules that explore both within-image and cross-image semantic correlations to transfer the knowledge possessed by known labels to generate pseudo labels for the unknown labels. Specifically, an intra-image semantic transfer (IST) module learns an image-specific label co-occurrence matrix for each image and maps the known labels to complement the unknown labels based on these matrices. Additionally, a cross-image transfer (CST) module learns category-specific feature-prototype similarities and then helps complement the unknown labels that have high degrees of similarity with the corresponding prototypes. Finally, both the known and generated pseudo labels are used to train MLR models. Extensive experiments conducted on the Microsoft COCO, Visual Genome, and Pascal VOC 2007 datasets show that the proposed HST framework achieves superior performance to that of current state-of-the-art algorithms. Specifically, it obtains mean average precision (mAP) improvements of 1.4%, 3.3%, and 0.4% on the three datasets over the results of the best-performing previously developed algorithm. ",
    "url": "https://arxiv.org/abs/2205.11131",
    "authors": [
      "Tianshui Chen",
      "Tao Pu",
      "Lingbo Liu",
      "Yukai Shi",
      "Zhijing Yang",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11139",
    "title": "GraphAD: A Graph Neural Network for Entity-Wise Multivariate Time-Series  Anomaly Detection",
    "abstract": "In recent years, the emergence and development of third-party platforms have greatly facilitated the growth of the Online to Offline (O2O) business. However, the large amount of transaction data raises new challenges for retailers, especially anomaly detection in operating conditions. Thus, platforms begin to develop intelligent business assistants with embedded anomaly detection methods to reduce the management burden on retailers. Traditional time-series anomaly detection methods capture underlying patterns from the perspectives of time and attributes, ignoring the difference between retailers in this scenario. Besides, similar transaction patterns extracted by the platforms can also provide guidance to individual retailers and enrich their available information without privacy issues. In this paper, we pose an entity-wise multivariate time-series anomaly detection problem that considers the time-series of each unique entity. To address this challenge, we propose GraphAD, a novel multivariate time-series anomaly detection model based on the graph neural network. GraphAD decomposes the Key Performance Indicator (KPI) into stable and volatility components and extracts their patterns in terms of attributes, entities and temporal perspectives via graph neural networks. We also construct a real-world entity-wise multivariate time-series dataset from the business data of Ele.me. The experimental results on this dataset show that GraphAD significantly outperforms existing anomaly detection methods. ",
    "url": "https://arxiv.org/abs/2205.11139",
    "authors": [
      "Xu Chen",
      "Qiu Qiu",
      "Changshan Li",
      "Kunqing Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2205.11141",
    "title": "OPQ: Compressing Deep Neural Networks with One-shot Pruning-Quantization",
    "abstract": "As Deep Neural Networks (DNNs) usually are overparameterized and have millions of weight parameters, it is challenging to deploy these large DNN models on resource-constrained hardware platforms, e.g., smartphones. Numerous network compression methods such as pruning and quantization are proposed to reduce the model size significantly, of which the key is to find suitable compression allocation (e.g., pruning sparsity and quantization codebook) of each layer. Existing solutions obtain the compression allocation in an iterative/manual fashion while finetuning the compressed model, thus suffering from the efficiency issue. Different from the prior art, we propose a novel One-shot Pruning-Quantization (OPQ) in this paper, which analytically solves the compression allocation with pre-trained weight parameters only. During finetuning, the compression module is fixed and only weight parameters are updated. To our knowledge, OPQ is the first work that reveals pre-trained model is sufficient for solving pruning and quantization simultaneously, without any complex iterative/manual optimization at the finetuning stage. Furthermore, we propose a unified channel-wise quantization method that enforces all channels of each layer to share a common codebook, which leads to low bit-rate allocation without introducing extra overhead brought by traditional channel-wise quantization. Comprehensive experiments on ImageNet with AlexNet/MobileNet-V1/ResNet-50 show that our method improves accuracy and training efficiency while obtains significantly higher compression rates compared to the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2205.11141",
    "authors": [
      "Peng Hu",
      "Xi Peng",
      "Hongyuan Zhu",
      "Mohamed M. Sabry Aly",
      "Jie Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11148",
    "title": "Distributed Computations in Fully-Defective Networks",
    "abstract": "We address fully-defective asynchronous networks, in which all links are subject to an unlimited number of alteration errors, implying that all messages in the network may be completely corrupted. Despite the possible intuition that such a setting is too harsh for any reliable communication, we show how to simulate any algorithm for a noiseless setting over any fully-defective setting, given that the network is 2-edge connected. We prove that if the network is not 2-edge connected, no non-trivial computation in the fully-defective setting is possible. The key structural property of 2-edge-connected graphs that we leverage is the existence of an oriented (non-simple) cycle that goes through all nodes [Robbins, 1939]. The core of our technical contribution is presenting a construction of such a Robbins cycle in fully-defective networks, and showing how to communicate over it despite total message corruption. These are obtained in a content-oblivious manner, since nodes must ignore the content of received messages. ",
    "url": "https://arxiv.org/abs/2205.11148",
    "authors": [
      "Keren Censor-Hillel",
      "Shir Cohen",
      "Ran Gelles",
      "Gal Sela"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.11156",
    "title": "Collaborative Adversarial Training",
    "abstract": "The vulnerability of deep neural networks (DNNs) to adversarial examples has attracted great attention in the machine learning community. The problem is related to local non-smoothness and steepness of normally obtained loss landscapes. Training augmented with adversarial examples (a.k.a., adversarial training) is considered as an effective remedy. In this paper, we highlight that some collaborative examples, nearly perceptually indistinguishable from both adversarial and benign examples yet show extremely lower prediction loss, can be utilized to enhance adversarial training. A novel method called collaborative adversarial training (CoAT) is thus proposed to achieve new state-of-the-arts. ",
    "url": "https://arxiv.org/abs/2205.11156",
    "authors": [
      "Qizhang Li",
      "Yiwen Guo",
      "Wangmeng Zuo",
      "Hao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11164",
    "title": "Time-series Transformer Generative Adversarial Networks",
    "abstract": "Many real-world tasks are plagued by limitations on data: in some instances very little data is available and in others, data is protected by privacy enforcing regulations (e.g. GDPR). We consider limitations posed specifically on time-series data and present a model that can generate synthetic time-series which can be used in place of real data. A model that generates synthetic time-series data has two objectives: 1) to capture the stepwise conditional distribution of real sequences, and 2) to faithfully model the joint distribution of entire real sequences. Autoregressive models trained via maximum likelihood estimation can be used in a system where previous predictions are fed back in and used to predict future ones; in such models, errors can accrue over time. Furthermore, a plausible initial value is required making MLE based models not really generative. Many downstream tasks learn to model conditional distributions of the time-series, hence, synthetic data drawn from a generative model must satisfy 1) in addition to performing 2). We present TsT-GAN, a framework that capitalises on the Transformer architecture to satisfy the desiderata and compare its performance against five state-of-the-art models on five datasets and show that TsT-GAN achieves higher predictive performance on all datasets. ",
    "url": "https://arxiv.org/abs/2205.11164",
    "authors": [
      "Padmanaba Srinivasan",
      "William J. Knottenbelt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11172",
    "title": "How Powerful are Spectral Graph Neural Networks",
    "abstract": "Spectral Graph Neural Network is a kind of Graph Neural Network (GNN) based on graph signal filters, and some models able to learn arbitrary spectral filters have emerged recently. However, few works analyze the expressive power of spectral GNNs. This paper studies spectral GNNs' expressive power theoretically. We first prove that even spectral GNNs without nonlinearity can produce arbitrary graph signals and give two conditions for reaching universality. They are: 1) no multiple eigenvalues of graph Laplacian, and 2) no missing frequency components in node features. We also establish a connection between the expressive power of spectral GNNs and Graph Isomorphism (GI) testing which is often used to characterize spatial GNNs' expressive power. Moreover, we study the difference in empirical performance among different spectral GNNs with the same expressive power from an optimization perspective, and motivate the use of an orthogonal basis whose weight function corresponds to the graph signal density in the spectrum. Inspired by the analysis, we propose JacobiConv, which uses Jacobi polynomial basis due to their orthogonality and flexibility to adapt to a wide range of weight functions. JacobiConv deserts nonlinearity while outperforming all baselines on both synthetic and real-world datasets. ",
    "url": "https://arxiv.org/abs/2205.11172",
    "authors": [
      "Xiyuan Wang",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11181",
    "title": "Lotaru: Locally Estimating Runtimes of Scientific Workflow Tasks in  Heterogeneous Clusters",
    "abstract": "Many scientific workflow scheduling algorithms need to be informed about task runtimes a-priori to conduct efficient scheduling. In heterogeneous cluster infrastructures, this problem becomes aggravated because these runtimes are required for each task-node pair. Using historical data is often not feasible as logs are typically not retained indefinitely and workloads as well as infrastructure changes. In contrast, online methods, which predict task runtimes on specific nodes while the workflow is running, have to cope with the lack of example runs, especially during the start-up. In this paper, we present Lotaru, a novel online method for locally estimating task runtimes in scientific workflows on heterogeneous clusters. Lotaru first profiles all nodes of a cluster with a set of short-running and uniform microbenchmarks. Next, it runs the workflow to be scheduled on the user's local machine with drastically reduced data to determine important task characteristics. Based on these measurements, Lotaru learns a Bayesian linear regression model to predict a task's runtime given the input size and finally adjusts the predicted runtime specifically for each task-node pair in the cluster based on the micro-benchmark results. Due to its Bayesian approach, Lotaru can also compute robust uncertainty estimates and provides them as an input for advanced scheduling methods. Our evaluation with five real-world scientific workflows and different datasets shows that Lotaru significantly outperforms the baselines in terms of prediction errors for homogeneous and heterogeneous clusters. ",
    "url": "https://arxiv.org/abs/2205.11181",
    "authors": [
      "Jonathan Bader",
      "Fabian Lehmann",
      "Lauritz Thamsen",
      "Jonathan Will",
      "Ulf Leser",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.11191",
    "title": "NPU-BOLT: A Dataset for Bolt Object Detection in Natural Scene Images",
    "abstract": "Bolt joints are very common and important in engineering structures. Due to extreme service environment and load factors, bolts often get loose or even disengaged. To real-time or timely detect the loosed or disengaged bolts is an urgent need in practical engineering, which is critical to keep structural safety and service life. In recent years, many bolt loosening detection methods using deep learning and machine learning techniques have been proposed and are attracting more and more attention. However, most of these studies use bolt images captured in laboratory for deep leaning model training. The images are obtained in a well-controlled light, distance, and view angle conditions. Also, the bolted structures are well designed experimental structures with brand new bolts and the bolts are exposed without any shelter nearby. It is noted that in practical engineering, the above well controlled lab conditions are not easy realized and the real bolt images often have blur edges, oblique perspective, partial occlusion and indistinguishable colors etc., which make the trained models obtained in laboratory conditions loss their accuracy or fails. Therefore, the aim of this study is to develop a dataset named NPU-BOLT for bolt object detection in natural scene images and open it to researchers for public use and further development. In the first version of the dataset, it contains 337 samples of bolt joints images mainly in the natural environment, with image data sizes ranging from 400*400 to 6000*4000, totaling approximately 1275 bolt targets. The bolt targets are annotated into four categories named blur bolt, bolt head, bolt nut and bolt side. The dataset is tested with advanced object detection models including yolov5, Faster-RCNN and CenterNet. The effectiveness of the dataset is validated. ",
    "url": "https://arxiv.org/abs/2205.11191",
    "authors": [
      "Yadian Zhao",
      "Zhenglin Yang",
      "Chao Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11195",
    "title": "Deep Image Retrieval is not Robust to Label Noise",
    "abstract": "Large-scale datasets are essential for the success of deep learning in image retrieval. However, manual assessment errors and semi-supervised annotation techniques can lead to label noise even in popular datasets. As previous works primarily studied annotation quality in image classification tasks, it is still unclear how label noise affects deep learning approaches to image retrieval. In this work, we show that image retrieval methods are less robust to label noise than image classification ones. Furthermore, we, for the first time, investigate different types of label noise specific to image retrieval tasks and study their effect on model performance. ",
    "url": "https://arxiv.org/abs/2205.11195",
    "authors": [
      "Stanislav Dereka",
      "Ivan Karpukhin",
      "Sergey Kolesnikov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11219",
    "title": "Higher-order causal theories are models of BV-logic",
    "abstract": "The Caus[-] construction takes a compact closed category of basic processes and yields a *-autonomous category of higher-order processes obeying certain signalling/causality constraints, as dictated by the type system in the resulting category. This paper looks at instances where the base category C satisfies additional properties yielding an affine-linear structure on Caus[C] and a substantially richer internal logic. While the original construction only gave multiplicative linear logic, here we additionally obtain additives and a non-commutative, self-dual sequential product yielding a model of Guglielmi's BV logic. Furthermore, we obtain a natural interpretation for the sequential product as \"A can signal to B, but not vice-versa\", which sits as expected between the non-signalling tensor and the fully-signalling (i.e. unconstrained) par. Fixing matrices of positive numbers for C recovers the BV category structure of probabilistic coherence spaces identified by Blute, Panangaden, and Slavnov, restricted to normalised maps. On the other hand, fixing the category of completely positive maps gives an entirely new model of BV consisting of higher order quantum channels, encompassing recent work in the study of quantum and indefinite causal structures. ",
    "url": "https://arxiv.org/abs/2205.11219",
    "authors": [
      "Will Simmons",
      "Aleks Kissinger"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2205.11229",
    "title": "Exploration of the possibility of infusing Social Media Trends into  generating NFT Recommendations",
    "abstract": "Recommendations Systems have been identified to be one of the integral elements of driving sales in e-commerce sites. The utilization of opinion mining data extracted from trends has been attempted to improve the recommendations that can be provided by baseline methods in this research when user-click data is lacking or is difficult to be collected due to privacy concerns. Utilizing social trends to influence the recommendations generated for a set of unique items has been explored with the use of a suggested scoring mechanism. Embracing concepts from decentralized networks that are expected to change how users interact via the internet over the next couple of decades, the suggested Recommendations System attempts to make use of multiple sources of information, applying coherent information retrieval techniques to extract probable trending items. The proposed Recommendations Architecture in the research presents a method to integrate social trends with recommendations to produce promising outputs. ",
    "url": "https://arxiv.org/abs/2205.11229",
    "authors": [
      "Dinuka Ravijaya Piyadigama",
      "Guhanathan Poravi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.11231",
    "title": "SUGER: A Subgraph-based Graph Convolutional Network Method for Bundle  Recommendation",
    "abstract": "Bundle recommendation is an emerging research direction in the recommender system with the focus on recommending customized bundles of items for users. Although Graph Neural Networks (GNNs) have been applied in this problem and achieve superior performance, existing methods underexplore the graph-level GNN methods, which exhibit great potential in traditional recommender system. Furthermore, they usually lack the transferability from one domain with sufficient supervision to another domain which might suffer from the label scarcity issue. In this work, we propose a subgraph-based Graph Neural Network model, SUGER, for bundle recommendation to handle these limitations. SUGER generates heterogeneous subgraphs around the user-bundle pairs, and then maps those subgraphs to the users' preference predictions via neural relational graph propagation. Experimental results show that SUGER significantly outperforms the state-of-the-art baselines in both the basic and the transfer bundle recommendation problems. ",
    "url": "https://arxiv.org/abs/2205.11231",
    "authors": [
      "Zhenning Zhang",
      "Boxin Du",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2205.11232",
    "title": "Deep Neural Network approaches for Analysing Videos of Music  Performances",
    "abstract": "This paper presents a framework to automate the labelling process for gestures in musical performance videos with a 3D Convolutional Neural Network (CNN). While this idea was proposed in a previous study, this paper introduces several novelties: (i) Presents a novel method to overcome the class imbalance challenge and make learning possible for co-existent gestures by batch balancing approach and spatial-temporal representations of gestures. (ii) Performs a detailed study on 7 and 18 categories of gestures generated during the performance (guitar play) of musical pieces that have been video-recorded. (iii) Investigates the possibility to use audio features. (iv) Extends the analysis to multiple videos. The novel methods significantly improve the performance of gesture identification by 12 %, when compared to the previous work (51 % in this study over 39 % in previous work). We successfully validate the proposed methods on 7 super classes (72 %), an ensemble of the 18 gestures/classes, and additional videos (75 %). ",
    "url": "https://arxiv.org/abs/2205.11232",
    "authors": [
      "Foteini Simistira Liwicki",
      "Richa Upadhya",
      "Prakash Chandra Chhipa",
      "Killian Murphy",
      "Federico Visi",
      "Stefan \u00d6stersj\u00f6",
      "Marcus Liwicki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2205.11233",
    "title": "Poincar\u00e9 Heterogeneous Graph Neural Networks for Sequential  Recommendation",
    "abstract": "Sequential recommendation (SR) learns users' preferences by capturing the sequential patterns from users' behaviors evolution. As discussed in many works, user-item interactions of SR generally present the intrinsic power-law distribution, which can be ascended to hierarchy-like structures. Previous methods usually handle such hierarchical information by making user-item sectionalization empirically under Euclidean space, which may cause distortion of user-item representation in real online scenarios. In this paper, we propose a Poincar\\'{e}-based heterogeneous graph neural network named PHGR to model the sequential pattern information as well as hierarchical information contained in the data of SR scenarios simultaneously. Specifically, for the purpose of explicitly capturing the hierarchical information, we first construct a weighted user-item heterogeneous graph by aliening all the user-item interactions to improve the perception domain of each user from a global view. Then the output of the global representation would be used to complement the local directed item-item homogeneous graph convolution. By defining a novel hyperbolic inner product operator, the global and local graph representation learning are directly conducted in Poincar\\'{e} ball instead of commonly used projection operation between Poincar\\'{e} ball and Euclidean space, which could alleviate the cumulative error issue of general bidirectional translation process. Moreover, for the purpose of explicitly capturing the sequential dependency information, we design two types of temporal attention operations under Poincar\\'{e} ball space. Empirical evaluations on datasets from the public and financial industry show that PHGR outperforms several comparison methods. ",
    "url": "https://arxiv.org/abs/2205.11233",
    "authors": [
      "Naicheng Guo",
      "Xiaolei Liu",
      "Shaoshuai Li",
      "Qiongxu Ma",
      "Kaixin Gao",
      "Bing Han",
      "Lin Zheng",
      "Xiaobo Guo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11237",
    "title": "Hyperspectral Image Classification With Contrastive Graph Convolutional  Network",
    "abstract": "Recently, Graph Convolutional Network (GCN) has been widely used in Hyperspectral Image (HSI) classification due to its satisfactory performance. However, the number of labeled pixels is very limited in HSI, and thus the available supervision information is usually insufficient, which will inevitably degrade the representation ability of most existing GCN-based methods. To enhance the feature representation ability, in this paper, a GCN model with contrastive learning is proposed to explore the supervision signals contained in both spectral information and spatial relations, which is termed Contrastive Graph Convolutional Network (ConGCN), for HSI classification. First, in order to mine sufficient supervision signals from spectral information, a semi-supervised contrastive loss function is utilized to maximize the agreement between different views of the same node or the nodes from the same land cover category. Second, to extract the precious yet implicit spatial relations in HSI, a graph generative loss function is leveraged to explore supplementary supervision signals contained in the graph topology. In addition, an adaptive graph augmentation technique is designed to flexibly incorporate the spectral-spatial priors of HSI, which helps facilitate the subsequent contrastive representation learning. The extensive experimental results on four typical benchmark datasets firmly demonstrate the effectiveness of the proposed ConGCN in both qualitative and quantitative aspects. ",
    "url": "https://arxiv.org/abs/2205.11237",
    "authors": [
      "Wentao Yu",
      "Sheng Wan",
      "Guangyu Li",
      "Jian Yang",
      "Chen Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11240",
    "title": "A Novel Face-Anti Spoofing Neural Network Model For Face Recognition And  Detection",
    "abstract": "Face Recognition (FR) systems are being used in a variety of applications, including road crossings, banking, and mobile banking. The widespread use of FR systems has raised concerns about the safety of face biometrics against spoofing attacks, which use the use of a photo or video of a legitimate user's face to gain illegal access to the resources or activities. Despite the development of several FAS or liveness detection methods (which determine whether a face is live or spoofed at the time of acquisition), the problem remains unsolved due to the difficulty of identifying discrimination and operationally reasonably priced spoof characteristics but also approaches. Additionally, certain facial portions are frequently repeated or correlate to image clutter, resulting in poor performance overall. This research proposes a face-anti-spoofing neural network model that outperforms existing models and has an efficiency of 0.89 percent. ",
    "url": "https://arxiv.org/abs/2205.11240",
    "authors": [
      "Soham S. Sarpotdar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11242",
    "title": "Fusing Multiscale Texture and Residual Descriptors for Multilevel 2D  Barcode Rebroadcasting Detection",
    "abstract": "Nowadays, 2D barcodes have been widely used for advertisement, mobile payment, and product authentication. However, in applications related to product authentication, an authentic 2D barcode can be illegally copied and attached to a counterfeited product in such a way to bypass the authentication scheme. In this paper, we employ a proprietary 2D barcode pattern and use multimedia forensics methods to analyse the scanning and printing artefacts resulting from the copy (rebroadcasting) attack. A diverse and complementary feature set is proposed to quantify the barcode texture distortions introduced during the illegal copying process. The proposed features are composed of global and local descriptors, which characterize the multi-scale texture appearance and the points of interest distribution, respectively. The proposed descriptors are compared against some existing texture descriptors and deep learning-based approaches under various scenarios, such as cross-datasets and cross-size. Experimental results highlight the practicality of the proposed method in real-world settings. ",
    "url": "https://arxiv.org/abs/2205.11242",
    "authors": [
      "Anselmo Ferreira",
      "Changcheng Chen",
      "Mauro Barni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.11244",
    "title": "A Silicon Photonic Accelerator for Convolutional Neural Networks with  Heterogeneous Quantization",
    "abstract": "Parameter quantization in convolutional neural networks (CNNs) can help generate efficient models with lower memory footprint and computational complexity. But, homogeneous quantization can result in significant degradation of CNN model accuracy. In contrast, heterogeneous quantization represents a promising approach to realize compact, quantized models with higher inference accuracies. In this paper, we propose HQNNA, a CNN accelerator based on non-coherent silicon photonics that can accelerate both homogeneously quantized and heterogeneously quantized CNN models. Our analyses show that HQNNA achieves up to 73.8x better energy-per-bit and 159.5x better throughput-energy efficiency than state-of-the-art photonic CNN accelerators. ",
    "url": "https://arxiv.org/abs/2205.11244",
    "authors": [
      "Febin Sunny",
      "Mahdi Nikdast",
      "Sudeep Pasricha"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11255",
    "title": "A Template-based Method for Constrained Neural Machine Translation",
    "abstract": "Machine translation systems are expected to cope with various types of constraints in many practical scenarios. While neural machine translation (NMT) has achieved strong performance in unconstrained cases, it is non-trivial to impose pre-specified constraints into the translation process of NMT models. Although many approaches have been proposed to address this issue, most existing methods can not satisfy the following three desiderata at the same time: (1) high translation quality, (2) high match accuracy, and (3) low latency. In this work, we propose a template-based method that can yield results with high translation quality and match accuracy while keeping the decoding speed. Our basic idea is to rearrange the generation of constrained and unconstrained tokens through a template. The generation and derivation of the template can be learned through one sequence-to-sequence training framework. Thus our method does not require any changes in the model architecture and the decoding algorithm, making it easy to apply. Experimental results show that the proposed template-based methods can outperform several representative baselines in lexically and structurally constrained translation tasks. ",
    "url": "https://arxiv.org/abs/2205.11255",
    "authors": [
      "Shuo Wang",
      "Peng Li",
      "Zhixing Tan",
      "Zhaopeng Tu",
      "Maosong Sun",
      "Yang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.11257",
    "title": "Manifold-aligned Neighbor Embedding",
    "abstract": "In this paper, we introduce a neighbor embedding framework for manifold alignment. We demonstrate the efficacy of the framework using a manifold-aligned version of the uniform manifold approximation and projection algorithm. We show that our algorithm can learn an aligned manifold that is visually competitive to embedding of the whole dataset. ",
    "url": "https://arxiv.org/abs/2205.11257",
    "authors": [
      "Mohammad Tariqul Islam",
      "Jason W. Fleischer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11258",
    "title": "Neuro-Symbolic Regex Synthesis Framework via Neural Example Splitting",
    "abstract": "Due to the practical importance of regular expressions (regexes, for short), there has been a lot of research to automatically generate regexes from positive and negative string examples. We tackle the problem of learning regexes faster from positive and negative strings by relying on a novel approach called `neural example splitting'. Our approach essentially split up each example string into multiple parts using a neural network trained to group similar substrings from positive strings. This helps to learn a regex faster and, thus, more accurately since we now learn from several short-length strings. We propose an effective regex synthesis framework called `SplitRegex' that synthesizes subregexes from `split' positive substrings and produces the final regex by concatenating the synthesized subregexes. For the negative sample, we exploit pre-generated subregexes during the subregex synthesis process and perform the matching against negative strings. Then the final regex becomes consistent with all negative strings. SplitRegex is a divided-and-conquer framework for learning target regexes; split (=divide) positive strings and infer partial regexes for multiple parts, which is much more accurate than the whole string inferring, and concatenate (=conquer) inferred regexes while satisfying negative strings. We empirically demonstrate that the proposed SplitRegex framework substantially improves the previous regex synthesis approaches over four benchmark datasets. ",
    "url": "https://arxiv.org/abs/2205.11258",
    "authors": [
      "Su-Hyeon Kim",
      "Hyunjoon Cheon",
      "Yo-Sub Han",
      "Sang-Ki Ko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2205.11276",
    "title": "Memory-enriched computation and learning in spiking neural networks  through Hebbian plasticity",
    "abstract": "Memory is a key component of biological neural systems that enables the retention of information over a huge range of temporal scales, ranging from hundreds of milliseconds up to years. While Hebbian plasticity is believed to play a pivotal role in biological memory, it has so far been analyzed mostly in the context of pattern completion and unsupervised learning. Here, we propose that Hebbian plasticity is fundamental for computations in biological neural systems. We introduce a novel spiking neural network architecture that is enriched by Hebbian synaptic plasticity. We show that Hebbian enrichment renders spiking neural networks surprisingly versatile in terms of their computational as well as learning capabilities. It improves their abilities for out-of-distribution generalization, one-shot learning, cross-modal generative association, language processing, and reward-based learning. As spiking neural networks are the basis for energy-efficient neuromorphic hardware, this also suggests that powerful cognitive neuromorphic systems can be build based on this principle. ",
    "url": "https://arxiv.org/abs/2205.11276",
    "authors": [
      "Thomas Limbacher",
      "Ozan \u00d6zdenizci",
      "Robert Legenstein"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2205.11279",
    "title": "Tyger: Task-Type-Generic Active Learning for Molecular Property  Prediction",
    "abstract": "How to accurately predict the properties of molecules is an essential problem in AI-driven drug discovery, which generally requires a large amount of annotation for training deep learning models. Annotating molecules, however, is quite costly because it requires lab experiments conducted by experts. To reduce annotation cost, deep Active Learning (AL) methods are developed to select only the most representative and informative data for annotating. However, existing best deep AL methods are mostly developed for a single type of learning task (e.g., single-label classification), and hence may not perform well in molecular property prediction that involves various task types. In this paper, we propose a Task-type-generic active learning framework (termed Tyger) that is able to handle different types of learning tasks in a unified manner. The key is to learn a chemically-meaningful embedding space and perform active selection fully based on the embeddings, instead of relying on task-type-specific heuristics (e.g., class-wise prediction probability) as done in existing works. Specifically, for learning the embedding space, we instantiate a querying module that learns to translate molecule graphs into corresponding SMILES strings. Furthermore, to ensure that samples selected from the space are both representative and informative, we propose to shape the embedding space by two learning objectives, one based on domain knowledge and the other leveraging feedback from the task learner (i.e., model that performs the learning task at hand). We conduct extensive experiments on benchmark datasets of different task types. Experimental results show that Tyger consistently achieves high AL performance on molecular property prediction, outperforming baselines by a large margin. We also perform ablative experiments to verify the effectiveness of each component in Tyger. ",
    "url": "https://arxiv.org/abs/2205.11279",
    "authors": [
      "Kuangqi Zhou",
      "Kaixin Wang",
      "Jiashi Feng",
      "Jian Tang",
      "Tingyang Xu",
      "Xinchao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2205.11283",
    "title": "SelfReformer: Self-Refined Network with Transformer for Salient Object  Detection",
    "abstract": "The global and local contexts significantly contribute to the integrity of predictions in Salient Object Detection (SOD). Unfortunately, existing methods still struggle to generate complete predictions with fine details. There are two major problems in conventional approaches: first, for global context, high-level CNN-based encoder features cannot effectively catch long-range dependencies, resulting in incomplete predictions. Second, downsampling the ground truth to fit the size of predictions will introduce inaccuracy as the ground truth details are lost during interpolation or pooling. Thus, in this work, we developed a Transformer-based network and framed a supervised task for a branch to learn the global context information explicitly. Besides, we adopt Pixel Shuffle from Super-Resolution (SR) to reshape the predictions back to the size of ground truth instead of the reverse. Thus details in the ground truth are untouched. In addition, we developed a two-stage Context Refinement Module (CRM) to fuse global context and automatically locate and refine the local details in the predictions. The proposed network can guide and correct itself based on the global and local context generated, thus is named, Self-Refined Transformer (SelfReformer). Extensive experiments and evaluation results on five benchmark datasets demonstrate the outstanding performance of the network, and we achieved the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2205.11283",
    "authors": [
      "Yi Ke Yun",
      "Weisi Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11299",
    "title": "Multiple Offsets Multilateration: a new paradigm for sensor network  calibration with unsynchronized reference nodes",
    "abstract": "Positioning using wave signal measurements is used in several applications, such as GPS systems, structure from sound and Wifi based positioning. Mathematically, such problems require the computation of the positions of receivers and/or transmitters as well as time offsets if the devices are unsynchronized. In this paper, we expand the previous state-of-the-art on positioning formulations by introducing Multiple Offsets Multilateration (MOM), a new mathematical framework to compute the receivers positions with pseudoranges from unsynchronized reference transmitters at known positions. This could be applied in several scenarios, for example structure from sound and positioning with LEO satellites. We mathematically describe MOM, determining how many receivers and transmitters are needed for the network to be solvable, a study on the number of possible distinct solutions is presented and stable solvers based on homotopy continuation are derived. The solvers are shown to be efficient and robust to noise both for synthetic and real audio data. ",
    "url": "https://arxiv.org/abs/2205.11299",
    "authors": [
      "Luca Ferranti",
      "Kalle \u00c5str\u00f6m",
      "Magnus Oskarsson",
      "Jani Boutellier",
      "Juho Kannala"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.11306",
    "title": "Sample Efficient Approaches for Idiomaticity Detection",
    "abstract": "Deep neural models, in particular Transformer-based pre-trained language models, require a significant amount of data to train. This need for data tends to lead to problems when dealing with idiomatic multiword expressions (MWEs), which are inherently less frequent in natural text. As such, this work explores sample efficient methods of idiomaticity detection. In particular we study the impact of Pattern Exploit Training (PET), a few-shot method of classification, and BERTRAM, an efficient method of creating contextual embeddings, on the task of idiomaticity detection. In addition, to further explore generalisability, we focus on the identification of MWEs not present in the training data. Our experiments show that while these methods improve performance on English, they are much less effective on Portuguese and Galician, leading to an overall performance about on par with vanilla mBERT. Regardless, we believe sample efficient methods for both identifying and representing potentially idiomatic MWEs are very encouraging and hold significant potential for future exploration. ",
    "url": "https://arxiv.org/abs/2205.11306",
    "authors": [
      "Dylan Phelps",
      "Xuan-Rui Fan",
      "Edward Gow-Smith",
      "Harish Tayyar Madabushi",
      "Carolina Scarton",
      "Aline Villavicencio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.11308",
    "title": "Symptom Identification for Interpretable Detection of Multiple Mental  Disorders",
    "abstract": "Mental disease detection (MDD) from social media has suffered from poor generalizability and interpretability, due to lack of symptom modeling. This paper introduces PsySym, the first annotated symptom identification corpus of multiple psychiatric disorders, to facilitate further research progress. PsySym is annotated according to a knowledge graph of the 38 symptom classes related to 7 mental diseases complied from established clinical manuals and scales, and a novel annotation framework for diversity and quality. Experiments show that symptom-assisted MDD enabled by PsySym can outperform strong pure-text baselines. We also exhibit the convincing MDD explanations provided by symptom predictions with case studies, and point to their further potential applications. ",
    "url": "https://arxiv.org/abs/2205.11308",
    "authors": [
      "Zhiling Zhang",
      "Siyuan Chen",
      "Mengyue Wu",
      "Kenny Q. Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.11319",
    "title": "Continual Barlow Twins: continual self-supervised learning for remote  sensing semantic segmentation",
    "abstract": "In the field of Earth Observation (EO), Continual Learning (CL) algorithms have been proposed to deal with large datasets by decomposing them into several subsets and processing them incrementally. The majority of these algorithms assume that data is (a) coming from a single source, and (b) fully labeled. Real-world EO datasets are instead characterized by a large heterogeneity (e.g., coming from aerial, satellite, or drone scenarios), and for the most part they are unlabeled, meaning they can be fully exploited only through the emerging Self-Supervised Learning (SSL) paradigm. For these reasons, in this paper we propose a new algorithm for merging SSL and CL for remote sensing applications, that we call Continual Barlow Twins (CBT). It combines the advantages of one of the simplest self-supervision techniques, i.e., Barlow Twins, with the Elastic Weight Consolidation method to avoid catastrophic forgetting. In addition, for the first time we evaluate SSL methods on a highly heterogeneous EO dataset, showing the effectiveness of these strategies on a novel combination of three almost non-overlapping domains datasets (airborne Potsdam dataset, satellite US3D dataset, and drone UAVid dataset), on a crucial downstream task in EO, i.e., semantic segmentation. Encouraging results show the superiority of SSL in this setting, and the effectiveness of creating an incremental effective pretrained feature extractor, based on ResNet50, without the need of relying on the complete availability of all the data, with a valuable saving of time and resources. ",
    "url": "https://arxiv.org/abs/2205.11319",
    "authors": [
      "Valerio Marsocci",
      "Simone Scardapane"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11322",
    "title": "Learning heterophilious edge to drop: A general framework for boosting  graph neural networks",
    "abstract": "Graph Neural Networks (GNNs) aim at integrating node contents with graph structure to learn nodes/graph representations. Nevertheless, it is found that most of existing GNNs do not work well on data with high heterophily level that accounts for a large proportion of edges between different class labels. Recently, many efforts to tackle this problem focus on optimizing the way of feature learning. From another angle, this work aims at mitigating the negative impacts of heterophily by optimizing graph structure for the first time. Specifically, on assumption that graph smoothing along heterophilious edges can hurt prediction performance, we propose a structure learning method called LHE to identify heterophilious edges to drop. A big advantage of this solution is that it can boost GNNs without careful modification of feature learning strategy. Extensive experiments demonstrate the remarkable performance improvement of GNNs with \\emph{LHE} on multiple datasets across full spectrum of homophily level. ",
    "url": "https://arxiv.org/abs/2205.11322",
    "authors": [
      "Jincheng Huang",
      "Ping Li",
      "Rui Huang",
      "Chen Na"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11324",
    "title": "Towards automatic detection of wildlife trade using machine vision  models",
    "abstract": "Unsustainable trade in wildlife is one of the major threats affecting the global biodiversity crisis. An important part of the trade now occurs on the internet, especially on digital marketplaces and social media. Automated methods to identify trade posts are needed as resources for conservation are limited. Here, we developed machine vision models based on Deep Neural Networks with the aim to automatically identify images of exotic pet animals for sale. A new training dataset representing exotic pet animals advertised for sale on the web was generated for this purpose. We trained 24 neural-net models spanning a combination of five different architectures, three methods of training and two types of datasets. Specifically, model generalisation improved after setting a portion of the training images to represent negative features. Models were evaluated on both within and out of distribution data to test wider model applicability. The top performing models achieved an f-score of over 0.95 on within distribution evaluation and between 0.75 to 0.87 on the two out of distribution datasets. Notably, feature visualisation indicated that models performed well in detecting the surrounding context (e.g. a cage) in which an animal was located, therefore helping to automatically detect images of animals in non-natural environments. The proposed methods can help investigate the online wildlife trade, but can also be adapted to study other types of people-nature interactions from digital platforms. Future studies can use these findings to build robust machine learning models and new data collection pipelines for more taxonomic groups. ",
    "url": "https://arxiv.org/abs/2205.11324",
    "authors": [
      "Ritwik Kulkarni",
      "Enrico Di Minin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11331",
    "title": "Networked Sensing with AI-Empowered Environment Estimation: Exploiting  Macro-Diversity and Array Gain in Perceptive Mobile Networks",
    "abstract": "Sensing will be an important service for future wireless networks to assist innovative applications like autonomous driving and environment monitoring. This paper considers the design of perceptive mobile networks (PMNs) where target monitoring terminals (TMTs) are deployed over the traditional cellular networks for jointly sensing the targets in the presence of environment clutter. Different from traditional radar, the cellular structure of PMNs offers multiple perspectives for target sensing (TS), but the joint processing among distributed sensing nodes also causes heavy computation and communication workload over the network. In this paper, we first propose a two-stage protocol where communication signals are utilized for environment estimation (EE) and TS in two consecutive time periods, respectively. A \\textit{networked} sensing detector is then derived to exploit the perspectives provided by multiple TMTs for sensing the same target. The macro-diversity from multiple TMTs and the array gain from multiple receive antennas at each TMT are analyzed to reveal the benefit of networked sensing. Furthermore, we derive the sufficient condition that one TMT's contribution to the networked sensing is positive, based on which a TMT selection algorithm is proposed. To reduce the computation burden and efficiently estimate the environment, we propose a model-driven deep-learning algorithm that utilizes partially-sampled data for EE. Simulation results confirm the benefits of networked sensing and validate the higher efficiency of the proposed EE algorithm than existing methods. ",
    "url": "https://arxiv.org/abs/2205.11331",
    "authors": [
      "Lei Xie",
      "S.H. Song"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.11332",
    "title": "ImGCL: Revisiting Graph Contrastive Learning on Imbalanced Node  Classification",
    "abstract": "Graph contrastive learning (GCL) has attracted a surge of attention due to its superior performance for learning node/graph representations without labels. However, in practice, unlabeled nodes for the given graph usually follow an implicit imbalanced class distribution, where the majority of nodes belong to a small fraction of classes (a.k.a., head class) and the rest classes occupy only a few samples (a.k.a., tail classes). This highly imbalanced class distribution inevitably deteriorates the quality of learned node representations in GCL. Indeed, we empirically find that most state-of-the-art GCL methods exhibit poor performance on imbalanced node classification. Motivated by this observation, we propose a principled GCL framework on Imbalanced node classification (ImGCL), which automatically and adaptively balances the representation learned from GCL without knowing the labels. Our main inspiration is drawn from the recent progressively balanced sampling (PBS) method in the computer vision domain. We first introduce online clustering based PBS, which balances the training sets based on pseudo-labels obtained from learned representations. We then develop the node centrality based PBS method to better preserve the intrinsic structure of graphs, which highlight the important nodes of the given graph. Besides, we theoretically consolidate our method by proving that the classifier learned by balanced sampling without labels on an imbalanced dataset can converge to the optimal balanced classifier with a linear rate. Extensive experiments on multiple imbalanced graph datasets and imbalance settings verify the effectiveness of our proposed framework, which significantly improves the performance of the recent state-of-the-art GCL methods. Further experimental ablations and analysis show that the ImGCL framework remarkably improves the representations of nodes in tail classes. ",
    "url": "https://arxiv.org/abs/2205.11332",
    "authors": [
      "Liang Zeng",
      "Lanqing Li",
      "Ziqi Gao",
      "Peilin Zhao",
      "Jian Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11333",
    "title": "Towards Deeper Understanding of Camouflaged Object Detection",
    "abstract": "Preys in the wild evolve to be camouflaged to avoid being recognized by predators. In this way, camouflage acts as a key defence mechanism across species that is critical to survival. To detect and segment the whole scope of a camouflaged object, camouflaged object detection (COD) is introduced as a binary segmentation task, with the binary ground truth camouflage map indicating the exact regions of the camouflaged objects. In this paper, we revisit this task and argue that the binary segmentation setting fails to fully understand the concept of camouflage. We find that explicitly modeling the conspicuousness of camouflaged objects against their particular backgrounds can not only lead to a better understanding about camouflage, but also provide guidance to designing more sophisticated camouflage techniques. Furthermore, we observe that it is some specific parts of camouflaged objects that make them detectable by predators. With the above understanding about camouflaged objects, we present the first triple-task learning framework to simultaneously localize, segment and rank camouflaged objects, indicating the conspicuousness level of camouflage. As no corresponding datasets exist for either the localization model or the ranking model, we generate localization maps with an eye tracker, which are then processed according to the instance level labels to generate our ranking-based training and testing dataset. We also contribute the largest COD testing set to comprehensively analyse performance of the camouflaged object detection models. Experimental results show that our triple-task learning framework achieves new state-of-the-art, leading to a more explainable camouflaged object detection network. Our code, data and results are available at: https://github.com/JingZhang617/COD-Rank-Localize-and-Segment. ",
    "url": "https://arxiv.org/abs/2205.11333",
    "authors": [
      "Yunqiu Lv",
      "Jing Zhang",
      "Yuchao Dai",
      "Aixuan Li",
      "Nick Barnes",
      "Deng-Ping Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11338",
    "title": "Temporal Network Analysis Using Zigzag Persistence",
    "abstract": "This work presents a framework for studying temporal networks using zigzag persistence, a tool from the field of Topological Data Analysis (TDA). The resulting approach is general and applicable to a wide variety of time-varying graphs. For example, these graphs may correspond to a system modeled as a network with edges whose weights are functions of time, or they may represent a time series of a complex dynamical system. We use simplicial complexes to represent snapshots of the temporal networks that can then be analyzed using zigzag persistence. We show two applications of our method to dynamic networks: an analysis of commuting trends on multiple temporal scales, e.g., daily and weekly, in the Great Britain transportation network, and the detection of periodic/chaotic transitions due to intermittency in dynamical systems represented by temporal ordinal partition networks. Our findings show that the resulting zero- and one-dimensional zigzag persistence diagrams can detect changes in the networks' shapes that are missed by traditional connectivity and centrality graph statistics. ",
    "url": "https://arxiv.org/abs/2205.11338",
    "authors": [
      "Audun Myers",
      "Firas Khasawneh",
      "Elizabeth Munch"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2205.11343",
    "title": "Heterogeneous Graph Neural Network for Session-Based Recommendation with  User-Session Constraint",
    "abstract": "The recommendation system provides users with an appropriate limit of recent online large amounts of information. Session-based recommendation, a sub-area of recommender systems, attempts to recommend items by interpreting sessions that consist of sequences of items. Recently, research to include user information in these sessions is progress. However, it is difficult to generate high-quality user information that includes session information generated by user. In this paper, we consider various relationships in graph created by sessions through HAN. Constraints also force user information to take into account information from the session. It seeks to increase performance through additional optimization in the training process. The proposed model outperformed other methods on various real-world data sets. ",
    "url": "https://arxiv.org/abs/2205.11343",
    "authors": [
      "Minjae Park"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11344",
    "title": "Cyclic Redundancy Checks and Error Detection",
    "abstract": "This study investigates the capabilities of Cyclic Redundancy Checks(CRCs) to detect burst and random errors. Researchers have favored these error detection codes throughout the evolution of computing and have implemented them in communication protocols worldwide. CRCs are integrated into almost every device, in software and hardware. CRCs play a critical role in ensuring that our digital communication systems are efficient and erroneous packets are detected. Because the quantity of data generated and transmitted has increased over the last twenty years, we are more likely to encounter errors. It is important that the tools and methodologies used to ensure the integrity of digital communication systems are evaluated to handle higher frequencies of information. In this study, we explore the need to improve the capabilities of error-detecting codes to handle higher quantities of data by testing the error detection properties of CRC's in a restricted domain. ",
    "url": "https://arxiv.org/abs/2205.11344",
    "authors": [
      "Waylon Jepsen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.11387",
    "title": "Robust Constrained Multi-objective Evolutionary Algorithm based on  Polynomial Chaos Expansion for Trajectory Optimization",
    "abstract": "An integrated optimization method based on the constrained multi-objective evolutionary algorithm (MOEA) and non-intrusive polynomial chaos expansion (PCE) is proposed, which solves robust multi-objective optimization problems under time-series dynamics. The constraints in such problems are difficult to handle, not only because the number of the dynamic constraints is multiplied by the discretized time steps but also because each of them is probabilistic. The proposed method rewrites a robust formulation into a deterministic problem via the PCE, and then sequentially processes the generated constraints in population generation, trajectory generation, and evaluation by the MOEA. As a case study, the landing trajectory design of supersonic transport (SST) with wind uncertainty is optimized. Results demonstrate the quantitative influence of the constraint values over the optimized solution sets and corresponding trajectories, proposing robust flight controls. ",
    "url": "https://arxiv.org/abs/2205.11387",
    "authors": [
      "Yuji Takubo",
      "Masahiro Kanazaki"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.11394",
    "title": "Detection of Fights in Videos: A Comparison Study of Anomaly Detection  and Action Recognition",
    "abstract": "Detection of fights is an important surveillance application in videos. Most existing methods use supervised binary action recognition. Since frame-level annotations are very hard to get for anomaly detection, weakly supervised learning using multiple instance learning is widely used. This paper explores the detection of fights in videos as one special type of anomaly detection and as binary action recognition. We use the UBI-Fight and NTU-CCTV-Fight datasets for most of the study since they have frame-level annotations. We find that the anomaly detection has similar or even better performance than the action recognition. Furthermore, we study to use anomaly detection as a toolbox to generate training datasets for action recognition in an iterative way conditioned on the performance of the anomaly detection. Experiment results should show that we achieve state-of-the-art performance on three fight detection datasets. ",
    "url": "https://arxiv.org/abs/2205.11394",
    "authors": [
      "Weijun Tan",
      "Jingfeng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11395",
    "title": "Multi-Temporal Spatial-Spectral Comparison Network for Hyperspectral  Anomalous Change Detection",
    "abstract": "Hyperspectral anomalous change detection has been a challenging task for its emphasis on the dynamics of small and rare objects against the prevalent changes. In this paper, we have proposed a Multi-Temporal spatial-spectral Comparison Network for hyperspectral anomalous change detection (MTC-NET). The whole model is a deep siamese network, aiming at learning the prevalent spectral difference resulting from the complex imaging conditions from the hyperspectral images by contrastive learning. A three-dimensional spatial spectral attention module is designed to effectively extract the spatial semantic information and the key spectral differences. Then the gaps between the multi-temporal features are minimized, boosting the alignment of the semantic and spectral features and the suppression of the multi-temporal background spectral difference. The experiments on the \"Viareggio 2013\" datasets demonstrate the effectiveness of proposed MTC-NET. ",
    "url": "https://arxiv.org/abs/2205.11395",
    "authors": [
      "Meiqi Hu",
      "Chen Wu",
      "Bo Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11402",
    "title": "Causal Machine Learning for Healthcare and Precision Medicine",
    "abstract": "Causal machine learning (CML) has experienced increasing popularity in healthcare. Beyond the inherent capabilities of adding domain knowledge into learning systems, CML provides a complete toolset for investigating how a system would react to an intervention (e.g.\\ outcome given a treatment). Quantifying effects of interventions allows actionable decisions to be made whilst maintaining robustness in the presence of confounders. Here, we explore how causal inference can be incorporated into different aspects of clinical decision support (CDS) systems by using recent advances in machine learning. Throughout this paper, we use Alzheimer's disease (AD) to create examples for illustrating how CML can be advantageous in clinical scenarios. Furthermore, we discuss important challenges present in healthcare applications such as processing high-dimensional and unstructured data, generalisation to out-of-distribution samples, and temporal relationships, that despite the great effort from the research community remain to be solved. Finally, we review lines of research within causal representation learning, causal discovery and causal reasoning which offer the potential towards addressing the aforementioned challenges. ",
    "url": "https://arxiv.org/abs/2205.11402",
    "authors": [
      "Pedro Sanchez",
      "Jeremy P. Voisey",
      "Tian Xia",
      "Hannah I. Watson",
      "Alison Q. ONeil",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11404",
    "title": "Variable-Input Deep Operator Networks",
    "abstract": "Existing architectures for operator learning require that the number and locations of sensors (where the input functions are evaluated) remain the same across all training and test samples, significantly restricting the range of their applicability. We address this issue by proposing a novel operator learning framework, termed Variable-Input Deep Operator Network (VIDON), which allows for random sensors whose number and locations can vary across samples. VIDON is invariant to permutations of sensor locations and is proved to be universal in approximating a class of continuous operators. We also prove that VIDON can efficiently approximate operators arising in PDEs. Numerical experiments with a diverse set of PDEs are presented to illustrate the robust performance of VIDON in learning operators. ",
    "url": "https://arxiv.org/abs/2205.11404",
    "authors": [
      "Michael Prasthofer",
      "Tim De Ryck",
      "Siddhartha Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.11432",
    "title": "Logical Reasoning with Span Predictions: Span-level Logical Atoms for  Interpretable and Robust NLI Models",
    "abstract": "Current Natural Language Inference (NLI) models achieve impressive results, sometimes outperforming humans when evaluating on in-distribution test sets. However, as these models are known to learn from annotation artefacts and dataset biases, it is unclear to what extent the models are learning the task of NLI instead of learning from shallow heuristics in their training data. We address this issue by introducing a logical reasoning framework for NLI, creating highly transparent model decisions that are based on logical rules. Unlike prior work, we show that the improved interpretability can be achieved without decreasing the predictive accuracy. We almost fully retain performance on SNLI while identifying the exact hypothesis spans that are responsible for each model prediction. Using the e-SNLI human explanations, we also verify that our model makes sensible decisions at a span level, despite not using any span-level labels during training. We can further improve model performance and the span-level decisions by using the e-SNLI explanations during training. Finally, our model outperforms its baseline in a reduced data setting. When training with only 100 examples, in-distribution performance improves by 18%, while out-of-distribution performance improves on SNLI-hard, MNLI-mismatched, MNLI-matched and SICK by 11%, 26%, 22%, and 21% respectively. ",
    "url": "https://arxiv.org/abs/2205.11432",
    "authors": [
      "Joe Stacey",
      "Pasquale Minervini",
      "Haim Dubossarsky",
      "Marek Rei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11438",
    "title": "Contrastive Representation Learning for Cross-Document Coreference  Resolution of Events and Entities",
    "abstract": "Identifying related entities and events within and across documents is fundamental to natural language understanding. We present an approach to entity and event coreference resolution utilizing contrastive representation learning. Earlier state-of-the-art methods have formulated this problem as a binary classification problem and leveraged large transformers in a cross-encoder architecture to achieve their results. For large collections of documents and corresponding set of $n$ mentions, the necessity of performing $n^{2}$ transformer computations in these earlier approaches can be computationally intensive. We show that it is possible to reduce this burden by applying contrastive learning techniques that only require $n$ transformer computations at inference time. Our method achieves state-of-the-art results on a number of key metrics on the ECB+ corpus and is competitive on others. ",
    "url": "https://arxiv.org/abs/2205.11438",
    "authors": [
      "Benjamin Hsu",
      "Graham Horwood"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.11448",
    "title": "Data augmentation for efficient learning from parametric experts",
    "abstract": "We present a simple, yet powerful data-augmentation technique to enable data-efficient learning from parametric experts for reinforcement and imitation learning. We focus on what we call the policy cloning setting, in which we use online or offline queries of an expert or expert policy to inform the behavior of a student policy. This setting arises naturally in a number of problems, for instance as variants of behavior cloning, or as a component of other algorithms such as DAGGER, policy distillation or KL-regularized RL. Our approach, augmented policy cloning (APC), uses synthetic states to induce feedback-sensitivity in a region around sampled trajectories, thus dramatically reducing the environment interactions required for successful cloning of the expert. We achieve highly data-efficient transfer of behavior from an expert to a student policy for high-degrees-of-freedom control problems. We demonstrate the benefit of our method in the context of several existing and widely used algorithms that include policy cloning as a constituent part. Moreover, we highlight the benefits of our approach in two practically relevant settings (a) expert compression, i.e. transfer to a student with fewer parameters; and (b) transfer from privileged experts, i.e. where the expert has a different observation space than the student, usually including access to privileged information. ",
    "url": "https://arxiv.org/abs/2205.11448",
    "authors": [
      "Alexandre Galashov",
      "Josh Merel",
      "Nicolas Heess"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11449",
    "title": "Nancy: an efficient parallel Network Calculus library",
    "abstract": "This paper describes Nancy, a Network Calculus (NC) library that allows users to perform complex min-plus and max-plus algebra operations efficiently. To the best of our knowledge, Nancy is the only open-source library that implements operators working on arbitrary piecewise-linear functions (as opposed to only concave/convex ones), as well as to implement some of them (e.g. sub-additive closure and function composition). Nancy allows researchers to compute NC results using a straightforward syntax, which matches the algebraic one. Moreover, it is designed having computational efficiency in mind: it exploits clever data representation, it uses inheritance to allow for faster algorithms when they are available (e.g., for specific subclasses of functions), and it is natively parallel, thus reaping the benefit of multicore hardware. This makes it usable to solve NC problems which were previously considered beyond the realm of tractable. ",
    "url": "https://arxiv.org/abs/2205.11449",
    "authors": [
      "Raffaele Zippo",
      "Giovanni Stea"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.11459",
    "title": "CELEST: Federated Learning for Globally Coordinated Threat Detection",
    "abstract": "The cyber-threat landscape has evolved tremendously in recent years, with new threat variants emerging daily, and large-scale coordinated campaigns becoming more prevalent. In this study, we propose CELEST (CollaborativE LEarning for Scalable Threat detection), a federated machine learning framework for global threat detection over HTTP, which is one of the most commonly used protocols for malware dissemination and communication. CELEST leverages federated learning in order to collaboratively train a global model across multiple clients who keep their data locally, thus providing increased privacy and confidentiality assurances. Through a novel active learning component integrated with the federated learning technique, our system continuously discovers and learns the behavior of new, evolving, and globally-coordinated cyber threats. We show that CELEST is able to expose attacks that are largely invisible to individual organizations. For instance, in one challenging attack scenario with data exfiltration malware, the global model achieves a three-fold increase in Precision-Recall AUC compared to the local model. We deploy CELEST on two university networks and show that it is able to detect the malicious HTTP communication with high precision and low false positive rates. Furthermore, during its deployment, CELEST detected a set of previously unknown 42 malicious URLs and 20 malicious domains in one day, which were confirmed to be malicious by VirusTotal. ",
    "url": "https://arxiv.org/abs/2205.11459",
    "authors": [
      "Talha Ongun",
      "Simona Boboila",
      "Alina Oprea",
      "Tina Eliassi-Rad",
      "Jason Hiser",
      "Jack Davidson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11460",
    "title": "Graph-theoretical approach to robust 3D normal extraction of LiDAR data",
    "abstract": "Low dimensional primitive feature extraction from LiDAR point clouds (such as planes) forms the basis of majority of LiDAR data processing tasks. A major challenge in LiDAR data analysis arises from the irregular nature of LiDAR data that forces practitioners to either regularize the data using some form of gridding or utilize a triangular mesh such as triangulated irregular network (TIN). While there have been a handful applications using LiDAR data as a connected graph, a principled treatment of utilizing graph-theoretical approach for LiDAR data modelling is still lacking. In this paper, we try to bridge this gap by utilizing graphical approach for normal estimation from LiDAR point clouds. We formulate the normal estimation problem in an optimization framework, where we find the corresponding normal vector for each LiDAR point by utilizing its nearest neighbors and simultaneously enforcing a graph smoothness assumption based on point samples. This is a non-linear constrained convex optimization problem which can then be solved using projected conjugate gradient descent to yield an unique solution. As an enhancement to our optimization problem, we also provide different weighted solutions based on the dot product of the normals and Euclidean distance between the points. In order to assess the performance of our proposed normal extraction method and weighting strategies, we first provide a detailed analysis on repeated randomly generated datasets with four different noise levels and four different tuning parameters. Finally, we benchmark our proposed method against existing state-of-the-art approaches on a large scale synthetic plane extraction dataset. The code for the proposed approach along with the simulations and benchmarking is available at https://github.com/arpan-kusari/graph-plane-extraction-simulation. ",
    "url": "https://arxiv.org/abs/2205.11460",
    "authors": [
      "Arpan Kusari",
      "Wenbo Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2205.11461",
    "title": "The Undecidability of Network Coding, Conditional Information  Inequalities, and Conditional Independence Implication",
    "abstract": "We resolve three long-standing open problems, namely the (algorithmic) decidability of network coding, the decidability of conditional information inequalities, and the decidability of conditional independence implication among random variables, by showing that these problems are undecidable. The proof is composed of a construction inspired by Herrmann's arguments on embedded multivalued database dependencies, together with a novel construction called the Fano-non-Fano network based on the Fano matroid and the non-Fano matroid. ",
    "url": "https://arxiv.org/abs/2205.11461",
    "authors": [
      "Cheuk Ting Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2205.11463",
    "title": "Context Limitations Make Neural Language Models More Human-Like",
    "abstract": "Do modern natural language processing (NLP) models exhibit human-like language processing? How can they be made more human-like? These questions are motivated by psycholinguistic studies for understanding human language processing as well as engineering efforts. In this study, we demonstrate the discrepancies in context access between modern neural language models (LMs) and humans in incremental sentence processing. Additional context limitation was needed to make LMs better simulate human reading behavior. Our analyses also showed that human-LM gaps in memory access are associated with specific syntactic constructions; incorporating additional syntactic factors into LMs' context access could enhance their cognitive plausibility. ",
    "url": "https://arxiv.org/abs/2205.11463",
    "authors": [
      "Tatsuki Kuribayashi",
      "Yohei Oseki",
      "Ana Brassard",
      "Kentaro Inui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.11472",
    "title": "On the Effect of Sample and Topic Sizes for Argument Mining Datasets",
    "abstract": "The task of Argument Mining, that is extracting argumentative sentences for a specific topic from large document sources, is an inherently difficult task for machine learning models and humans alike, as large datasets are rare and recognition of argumentative sentences requires expert knowledge. The task becomes even more difficult when it also involves stance detection of retrieved arguments. Recent datasets for the task tend to grow evermore large and hence more costly. In this work, we inquire whether it is necessary for acceptable performance of argument mining to have datasets growing in size or, if not, how smaller datasets have to be composed for optimal performance. We also publish a newly created dataset for future benchmarking. ",
    "url": "https://arxiv.org/abs/2205.11472",
    "authors": [
      "Benjamin Schiller",
      "Johannes Daxenberger",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.11490",
    "title": "Local Byte Fusion for Neural Machine Translation",
    "abstract": "Subword tokenization schemes are the dominant technique used in current NLP models. However, such schemes can be rigid and tokenizers built on one corpus do not adapt well to other parallel corpora. It has also been observed that in multilingual corpora, subword tokenization schemes over-segment low-resource languages leading to a drop in translation performance. A simple alternative to subword tokenizers is byte-based methods i.e. tokenization into byte sequences using encoding schemes such as UTF-8. Byte tokens often represent inputs at a sub-character granularity i.e. one character can be represented by a sequence of multiple byte tokens. This results in byte sequences that are significantly longer than character sequences. Enforcing aggregation of local information in the lower layers can guide the model to build higher-level semantic information. We propose a Local Byte Fusion (LOBEF) method for byte-based machine translation -- utilizing byte $n$-gram and word boundaries -- to aggregate local semantic information. Extensive experiments on multilingual translation, zero-shot cross-lingual transfer, and domain adaptation reveal a consistent improvement over traditional byte-based models and even over subword techniques. Further analysis also indicates that our byte-based models are parameter-efficient and can be trained faster than subword models. ",
    "url": "https://arxiv.org/abs/2205.11490",
    "authors": [
      "Makesh Narsimhan Sreedhar",
      "Xiangpeng Wan",
      "Yu Cheng",
      "Junjie Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11491",
    "title": "HyperTree Proof Search for Neural Theorem Proving",
    "abstract": "We propose an online training procedure for a transformer-based automated theorem prover. Our approach leverages a new search algorithm, HyperTree Proof Search (HTPS), inspired by the recent success of AlphaZero. Our model learns from previous proof searches through online training, allowing it to generalize to domains far from the training distribution. We report detailed ablations of our pipeline's main components by studying performance on three environments of increasing complexity. In particular, we show that with HTPS alone, a model trained on annotated proofs manages to prove 65.4% of a held-out set of Metamath theorems, significantly outperforming the previous state of the art of 56.5% by GPT-f. Online training on these unproved theorems increases accuracy to 82.6%. With a similar computational budget, we improve the state of the art on the Lean-based miniF2F-curriculum dataset from 31% to 42% proving accuracy. ",
    "url": "https://arxiv.org/abs/2205.11491",
    "authors": [
      "Guillaume Lample",
      "Marie-Anne Lachaux",
      "Thibaut Lavril",
      "Xavier Martinet",
      "Amaury Hayat",
      "Gabriel Ebner",
      "Aur\u00e9lien Rodriguez",
      "Timoth\u00e9e Lacroix"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11501",
    "title": "VQA-GNN: Reasoning with Multimodal Semantic Graph for Visual Question  Answering",
    "abstract": "Visual understanding requires seamless integration between recognition and reasoning: beyond image-level recognition (e.g., detecting objects), systems must perform concept-level reasoning (e.g., inferring the context of objects and intents of people). However, existing methods only model the image-level features, and do not ground them and reason with background concepts such as knowledge graphs (KGs). In this work, we propose a novel visual question answering method, VQA-GNN, which unifies the image-level information and conceptual knowledge to perform joint reasoning of the scene. Specifically, given a question-image pair, we build a scene graph from the image, retrieve a relevant linguistic subgraph from ConceptNet and visual subgraph from VisualGenome, and unify these three graphs and the question into one joint graph, multimodal semantic graph. Our VQA-GNN then learns to aggregate messages and reason across different modalities captured by the multimodal semantic graph. In the evaluation on the VCR task, our method outperforms the previous scene graph-based Trans-VL models by over 4%, and VQA-GNN-Large, our model that fuses a Trans-VL further improves the state of the art by 2%, attaining the top of the VCR leaderboard at the time of submission. This result suggests the efficacy of our model in performing conceptual reasoning beyond image-level recognition for visual understanding. Finally, we demonstrate that our model is the first work to provide interpretability across visual and textual knowledge domains for the VQA task. ",
    "url": "https://arxiv.org/abs/2205.11501",
    "authors": [
      "Yanan Wang",
      "Michihiro Yasunaga",
      "Hongyu Ren",
      "Shinya Wada",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.11508",
    "title": "Contrastive and Non-Contrastive Self-Supervised Learning Recover Global  and Local Spectral Embedding Methods",
    "abstract": "Self-Supervised Learning (SSL) surmises that inputs and pairwise positive relationships are enough to learn meaningful representations. Although SSL has recently reached a milestone: outperforming supervised methods in many modalities... the theoretical foundations are limited, method-specific, and fail to provide principled design guidelines to practitioners. In this paper, we propose a unifying framework under the helm of spectral manifold learning to address those limitations. Through the course of this study, we will rigorously demonstrate that VICReg, SimCLR, BarlowTwins et al. correspond to eponymous spectral methods such as Laplacian Eigenmaps, Multidimensional Scaling et al. This unification will then allow us to obtain (i) the closed-form optimal representation for each method, (ii) the closed-form optimal network parameters in the linear regime for each method, (iii) the impact of the pairwise relations used during training on each of those quantities and on downstream task performances, and most importantly, (iv) the first theoretical bridge between contrastive and non-contrastive methods towards global and local spectral embedding methods respectively, hinting at the benefits and limitations of each. For example, (a) if the pairwise relation is aligned with the downstream task, any SSL method can be employed successfully and will recover the supervised method, but in the low data regime, SimCLR or VICReg with high invariance hyper-parameter should be preferred; (b) if the pairwise relation is misaligned with the downstream task, BarlowTwins or VICReg with small invariance hyper-parameter should be preferred. ",
    "url": "https://arxiv.org/abs/2205.11508",
    "authors": [
      "Randall Balestriero",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Spectral Theory (math.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.10354",
    "title": "Prediction of stent under-expansion in calcified coronary arteries using  machine-learning on intravascular optical coherence tomography",
    "abstract": "BACKGROUND Careful evaluation of the risk of stent under-expansions before the intervention will aid treatment planning, including the application of a pre-stent plaque modification strategy. OBJECTIVES It remains challenging to achieve a proper stent expansion in the presence of severely calcified coronary lesions. Building on our work in deep learning segmentation, we created an automated machine learning approach that uses lesion attributes to predict stent under-expansion from pre-stent images, suggesting the need for plaque modification. METHODS Pre- and post-stent intravascular optical coherence tomography image data were obtained from 110 coronary lesions. Lumen and calcifications in pre-stent images were segmented using deep learning, and numerous features per lesion were extracted. We analyzed stent expansion along the lesion, enabling frame, segmental, and whole-lesion analyses. We trained regression models to predict the poststent lumen area and then to compute the stent expansion index (SEI). Stents with an SEI < or >/= 80% were classified as \"under-expanded\" and \"well-expanded,\" respectively. RESULTS Best performance (root-mean-square-error = 0.04+/-0.02 mm2, r = 0.94+/-0.04, p < 0.0001) was achieved when we used features from both the lumen and calcification to train a Gaussian regression model for a segmental analysis over a segment length of 31 frames. Under-expansion classification results (AUC=0.85+/-0.02) were significantly improved over other approaches. CONCLUSIONS We used calcifications and lumen features to identify lesions at risk of stent under-expansion. Results suggest that the use of pre-stent images can inform physicians of the need to apply plaque modification approaches. ",
    "url": "https://arxiv.org/abs/2205.10354",
    "authors": [
      "Yazan Gharaibeh",
      "Juhwan Lee",
      "Vladislav N. Zimin",
      "Chaitanya Kolluru",
      "Luis A. P. Dallan",
      "Gabriel T. R. Pereira",
      "Armando Vergara-Martel",
      "Justin N. Kim",
      "Ammar Hoori",
      "Pengfei Dong",
      "Peshala T. Gamage",
      "Linxia Gu",
      "Hiram G. Bezerra",
      "Sadeer Al-Kindi",
      "David L. Wilson"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10367",
    "title": "Nonlinear motion separation via untrained generator networks with  disentangled latent space variables and applications to cardiac MRI",
    "abstract": "In this paper, a nonlinear approach to separate different motion types in video data is proposed. This is particularly relevant in dynamic medical imaging (e.g. PET, MRI), where patient motion poses a significant challenge due to its effects on the image reconstruction as well as for its subsequent interpretation. Here, a new method is proposed where dynamic images are represented as the forward mapping of a sequence of latent variables via a generator neural network. The latent variables are structured so that temporal variations in the data are represented via dynamic latent variables, which are independent of static latent variables characterizing the general structure of the frames. In particular, different kinds of motion are also characterized independently of each other via latent space disentanglement using one-dimensional prior information on all but one of the motion types. This representation allows to freeze any selection of motion types, and to obtain accurate independent representations of other dynamics of interest. Moreover, the proposed algorithm is training-free, i.e., all the network parameters are learned directly from a single video. We illustrate the performance of this method on phantom and real-data MRI examples, where we successfully separate respiratory and cardiac motion. ",
    "url": "https://arxiv.org/abs/2205.10367",
    "authors": [
      "Abdullah",
      "Martin Holler",
      "Karl Kunisch",
      "Malena Sabate Landman"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2205.10401",
    "title": "NeuralEcho: A Self-Attentive Recurrent Neural Network For Unified  Acoustic Echo Suppression And Speech Enhancement",
    "abstract": "Acoustic echo cancellation (AEC) plays an important role in the full-duplex speech communication as well as the front-end speech enhancement for recognition in the conditions when the loudspeaker plays back. In this paper, we present an all-deep-learning framework that implicitly estimates the second order statistics of echo/noise and target speech, and jointly solves echo and noise suppression through an attention based recurrent neural network. The proposed model outperforms the state-of-the-art joint echo cancellation and speech enhancement method F-T-LSTM in terms of objective speech quality metrics, speech recognition accuracy and model complexity. We show that this model can work with speaker embedding for better target speech enhancement and furthermore develop a branch for automatic gain control (AGC) task to form an all-in-one front-end speech enhancement system. ",
    "url": "https://arxiv.org/abs/2205.10401",
    "authors": [
      "Meng Yu",
      "Yong Xu",
      "Chunlei Zhang",
      "Shi-Xiong Zhang",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2205.10499",
    "title": "Towards Balanced Three-phase Charging: Phase Optimization in Adaptive  Charging Networks",
    "abstract": "We study the problem of phase optimization for electric-vehicle (EV) charging. We formulate our problem as a non-convex mixed-integer programming problem whose objective is to minimize the charging loss. Despite the hardness of directly solving this non-convex problem, we solve a relaxation of the original problem by proposing the PXA algorithm where \"P\", \"X\", and \"A\" stand for three variable matrices in the formed phase optimization problems. We show that under certain conditions, the solution is given by the PXA precisely converges to the global optimum. In addition, using the idea of model predictive control (MPC), we design the {PXA-MPC}, which is an online implementation of the PXA. Compared to other empirical phase balancing strategies, the PXA algorithm significantly improves the charging performance by maximizing energy delivery, minimizing charging price, and assisting future energy planning. The efficacy of our algorithm is demonstrated using data collected from a real-world adaptive EV charging network (ACN). ",
    "url": "https://arxiv.org/abs/2205.10499",
    "authors": [
      "Zixin Ye",
      "Tongxin Li",
      "Steven H. Low"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.10515",
    "title": "Visualizing CoAtNet Predictions for Aiding Melanoma Detection",
    "abstract": "Melanoma is considered to be the most aggressive form of skin cancer. Due to the similar shape of malignant and benign cancerous lesions, doctors spend considerably more time when diagnosing these findings. At present, the evaluation of malignancy is performed primarily by invasive histological examination of the suspicious lesion. Developing an accurate classifier for early and efficient detection can minimize and monitor the harmful effects of skin cancer and increase patient survival rates. This paper proposes a multi-class classification task using the CoAtNet architecture, a hybrid model that combines the depthwise convolution matrix operation of traditional convolutional neural networks with the strengths of Transformer models and self-attention mechanics to achieve better generalization and capacity. The proposed multi-class classifier achieves an overall precision of 0.901, recall 0.895, and AP 0.923, indicating high performance compared to other state-of-the-art networks. ",
    "url": "https://arxiv.org/abs/2205.10515",
    "authors": [
      "Daniel Kvak"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10541",
    "title": "Neuroevolutionary Feature Representations for Causal Inference",
    "abstract": "Within the field of causal inference, we consider the problem of estimating heterogeneous treatment effects from data. We propose and validate a novel approach for learning feature representations to aid the estimation of the conditional average treatment effect or CATE. Our method focuses on an intermediate layer in a neural network trained to predict the outcome from the features. In contrast to previous approaches that encourage the distribution of representations to be treatment-invariant, we leverage a genetic algorithm that optimizes over representations useful for predicting the outcome to select those less useful for predicting the treatment. This allows us to retain information within the features useful for predicting outcome even if that information may be related to treatment assignment. We validate our method on synthetic examples and illustrate its use on a real life dataset. ",
    "url": "https://arxiv.org/abs/2205.10541",
    "authors": [
      "Michael C. Burkhart",
      "Gabriel Ruiz"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10663",
    "title": "Transformer based Generative Adversarial Network for Liver Segmentation",
    "abstract": "Automated liver segmentation from radiology scans (CT, MRI) can improve surgery and therapy planning and follow-up assessment in addition to conventional use for diagnosis and prognosis. Although convolutional neural networks (CNNs) have become the standard image segmentation tasks, more recently this has started to change towards Transformers based architectures because Transformers are taking advantage of capturing long range dependence modeling capability in signals, so called attention mechanism. In this study, we propose a new segmentation approach using a hybrid approach combining the Transformer(s) with the Generative Adversarial Network (GAN) approach. The premise behind this choice is that the self-attention mechanism of the Transformers allows the network to aggregate the high dimensional feature and provide global information modeling. This mechanism provides better segmentation performance compared with traditional methods. Furthermore, we encode this generator into the GAN based architecture so that the discriminator network in the GAN can classify the credibility of the generated segmentation masks compared with the real masks coming from human (expert) annotations. This allows us to extract the high dimensional topology information in the mask for biomedical image segmentation and provide more reliable segmentation results. Our model achieved a high dice coefficient of 0.9433, recall of 0.9515, and precision of 0.9376 and outperformed other Transformer based approaches. ",
    "url": "https://arxiv.org/abs/2205.10663",
    "authors": [
      "Ugur Demir",
      "Zheyuan Zhang",
      "Bin Wang",
      "Matthew Antalek",
      "Elif Keles",
      "Debesh Jha",
      "Amir Borhani",
      "Daniela Ladner",
      "Ulas Bagci"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10691",
    "title": "Producing Histopathology Phantom Images using Generative Adversarial  Networks to improve Tumor Detection",
    "abstract": "Advance in medical imaging is an important part in deep learning research. One of the goals of computer vision is development of a holistic, comprehensive model which can identify tumors from histology slides obtained via biopsies. A major problem that stands in the way is lack of data for a few cancer-types. In this paper, we ascertain that data augmentation using GANs can be a viable solution to reduce the unevenness in the distribution of different cancer types in our dataset. Our demonstration showed that a dataset augmented to a 50% increase causes an increase in tumor detection from 80% to 87.5% ",
    "url": "https://arxiv.org/abs/2205.10691",
    "authors": [
      "Vidit Gautam"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10732",
    "title": "Robust Flow-based Conformal Inference (FCI) with Statistical Guarantee",
    "abstract": "Conformal prediction aims to determine precise levels of confidence in predictions for new objects using past experience. However, the commonly used exchangeable assumptions between the training data and testing data limit its usage in dealing with contaminated testing sets. In this paper, we develop a series of conformal inference methods, including building predictive sets and inferring outliers for complex and high-dimensional data. We leverage ideas from adversarial flow to transfer the input data to a random vector with known distributions, which enable us to construct a non-conformity score for uncertainty quantification. We can further learn the distribution of input data in each class directly through the learned transformation. Therefore, our approach is applicable and more robust when the test data is contaminated. We evaluate our method, robust flow-based conformal inference, on benchmark datasets. We find that it produces effective prediction sets and accurate outlier detection and is more powerful relative to competing approaches. ",
    "url": "https://arxiv.org/abs/2205.10732",
    "authors": [
      "Youhui Ye",
      "Meimei Liu",
      "Xin Xing"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10757",
    "title": "Deep Feature Fusion via Graph Convolutional Network for Intracranial  Artery Labeling",
    "abstract": "Intracranial arteries are critical blood vessels that supply the brain with oxygenated blood. Intracranial artery labels provide valuable guidance and navigation to numerous clinical applications and disease diagnoses. Various machine learning algorithms have been carried out for automation in the anatomical labeling of cerebral arteries. However, the task remains challenging because of the high complexity and variations of intracranial arteries. This study investigates a novel graph convolutional neural network with deep feature fusion for cerebral artery labeling. We introduce stacked graph convolutions in an encoder-core-decoder architecture, extracting high-level representations from graph nodes and their neighbors. Furthermore, we efficiently aggregate intermediate features from different hierarchies to enhance the proposed model's representation capability and labeling performance. We perform extensive experiments on public datasets, in which the results prove the superiority of our approach over baselines by a clear margin. ",
    "url": "https://arxiv.org/abs/2205.10757",
    "authors": [
      "Yaxin Zhu",
      "Peisheng Qian",
      "Ziyuan Zhao",
      "Zeng Zeng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10758",
    "title": "Residual Channel Attention Network for Brain Glioma Segmentation",
    "abstract": "A glioma is a malignant brain tumor that seriously affects cognitive functions and lowers patients' life quality. Segmentation of brain glioma is challenging because of interclass ambiguities in tumor regions. Recently, deep learning approaches have achieved outstanding performance in the automatic segmentation of brain glioma. However, existing algorithms fail to exploit channel-wise feature interdependence to select semantic attributes for glioma segmentation. In this study, we implement a novel deep neural network that integrates residual channel attention modules to calibrate intermediate features for glioma segmentation. The proposed channel attention mechanism adaptively weights feature channel-wise to optimize the latent representation of gliomas. We evaluate our method on the established dataset BraTS2017. Experimental results indicate the superiority of our method. ",
    "url": "https://arxiv.org/abs/2205.10758",
    "authors": [
      "Yiming Yao",
      "Peisheng Qian",
      "Ziyuan Zhao",
      "Zeng Zeng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10864",
    "title": "Federated Learning Aggregation: New Robust Algorithms with Guarantees",
    "abstract": "Federated Learning has been recently proposed for distributed model training at the edge. The principle of this approach is to aggregate models learned on distributed clients to obtain a new more general \"average\" model (FedAvg). The resulting model is then redistributed to clients for further training. To date, the most popular federated learning algorithm uses coordinate-wise averaging of the model parameters for aggregation. In this paper, we carry out a complete general mathematical convergence analysis to evaluate aggregation strategies in a federated learning framework. From this, we derive novel aggregation algorithms which are able to modify their model architecture by differentiating client contributions according to the value of their losses. Moreover, we go beyond the assumptions introduced in theory, by evaluating the performance of these strategies and by comparing them with the one of FedAvg in classification tasks in both the IID and the Non-IID framework without additional hypothesis. ",
    "url": "https://arxiv.org/abs/2205.10864",
    "authors": [
      "Adnan Ben Mansour",
      "Gaia Carenini",
      "Alexandre Duplessis",
      "David Naccache"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10972",
    "title": "Global Extreme Heat Forecasting Using Neural Weather Models",
    "abstract": "Heat waves are projected to increase in frequency and severity with global warming. Improved warning systems would help reduce the associated loss of lives, wildfires, power disruptions, and reduction in crop yields. In this work, we explore the potential for deep learning systems trained on historical data to forecast extreme heat on short, medium and subseasonal timescales. To this purpose, we train a set of neural weather models (NWMs) with convolutional architectures to forecast surface temperature anomalies globally, 1 to 28 days ahead, at $\\sim200~\\mathrm{km}$ resolution and on the cubed sphere. The NWMs are trained using the ERA5 reanalysis product and a set of candidate loss functions, including the mean squared error and exponential losses targeting extremes. We find that training models to minimize custom losses tailored to emphasize extremes leads to significant skill improvements in the heat wave prediction task, compared to NWMs trained on the mean squared error loss. This improvement is accomplished with almost no skill reduction in the general temperature prediction task, and it can be efficiently realized through transfer learning, by re-training NWMs with the custom losses for a few epochs. In addition, we find that the use of a symmetric exponential loss reduces the smoothing of NWM forecasts with lead time. Our best NWM is able to outperform persistence in a regressive sense for all lead times and temperature anomaly thresholds considered, and shows positive regressive skill compared to the ECMWF subseasonal-to-seasonal control forecast within the first two forecast days and after two weeks. ",
    "url": "https://arxiv.org/abs/2205.10972",
    "authors": [
      "Ignacio Lopez-Gomez",
      "Amy McGovern",
      "Shreya Agrawal",
      "Jason Hickey"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11106",
    "title": "An improved neural network model for treatment effect estimation",
    "abstract": "Nowadays, in many scientific and industrial fields there is an increasing need for estimating treatment effects and answering causal questions. The key for addressing these problems is the wealth of observational data and the processes for leveraging this data. In this work, we propose a new model for predicting the potential outcomes and the propensity score, which is based on a neural network architecture. The proposed model exploits the covariates as well as the outcomes of neighboring instances in training data. Numerical experiments illustrate that the proposed model reports better treatment effect estimation performance compared to state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2205.11106",
    "authors": [
      "Niki Kiriakidou",
      "Christos Diou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11145",
    "title": "A Coupling Enhancement Algorithm for ZrO2 Ceramic Bearing Ball Surface  Defect Detection Based on Cartoon-texture Decomposition Model and Multi-Scale  Filtering Method",
    "abstract": "This study aimed to improve the surface defect detection accuracy of ZrO2 ceramic bearing balls. Combined with the noise damage of the image samples, a surface defect detection method for ZrO2 ceramic bearing balls based on cartoon-texture decomposition model was proposed. Building a ZrO2 ceramic bearing ball surface defect detection system. The ZrO2 ceramic bearing ball surface defect image was decomposed by using the Gaussian curvature model and the decomposed image layer was filtered by using Winner filter and wavelet value domain filter. Then they were fused into a clear and undamaged ZrO2 ceramic bearing ball surface defect image and detected. The experimental results show that the image denoising method of ZrO2 ceramic bearing ball surface defect based on cartoon-texture decomposition model can denoise while retaining the image details. The PSNR of image is 34.1 dB, the SSIM is 0.9476, the detection accuracy is 95.8%, and the detection speed of a single defect image is 191ms / img. This method can effectively improve the efficiency and accuracy of ZrO2 ceramic bearing ball surface defect detection. ",
    "url": "https://arxiv.org/abs/2205.11145",
    "authors": [
      "Wei Wang",
      "Xin Zhang",
      "Jiaqi Yi",
      "Xianqi Liao",
      "Wenjie Li",
      "Zhenhong Li"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11151",
    "title": "Split personalities in Bayesian Neural Networks: the case for full  marginalisation",
    "abstract": "The true posterior distribution of a Bayesian neural network is massively multimodal. Whilst most of these modes are functionally equivalent, we demonstrate that there remains a level of real multimodality that manifests in even the simplest neural network setups. It is only by fully marginalising over all posterior modes, using appropriate Bayesian sampling tools, that we can capture the split personalities of the network. The ability of a network trained in this manner to reason between multiple candidate solutions dramatically improves the generalisability of the model, a feature we contend is not consistently captured by alternative approaches to the training of Bayesian neural networks. We provide a concise minimal example of this, which can provide lessons and a future path forward for correctly utilising the explainability and interpretability of Bayesian neural networks. ",
    "url": "https://arxiv.org/abs/2205.11151",
    "authors": [
      "David Yallup",
      "Will Handley",
      "Mike Hobson",
      "Anthony Lasenby",
      "Pablo Lemos"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11346",
    "title": "Arbitrary Reduction of MRI Slice Spacing Based on Local-Aware Implicit  Representation",
    "abstract": "Magnetic resonance (MR) images are often acquired in 2D settings for real clinical applications. The 3D volumes reconstructed by stacking multiple 2D slices have large inter-slice spacing, resulting in lower inter-slice resolution than intra-slice resolution. Super-resolution is a powerful tool to reduce the inter-slice spacing of 3D images to facilitate subsequent visualization and computation tasks. However, most existing works train the super-resolution network at a fixed ratio, which is inconvenient in clinical scenes due to the heterogeneous parameters in MR scanning. In this paper, we propose a single super-resolution network to reduce the inter-slice spacing of MR images at an arbitrarily adjustable ratio. Specifically, we view the input image as a continuous implicit function of coordinates. The intermediate slices of different spacing ratios could be constructed according to the implicit representation up-sampled in the continuous domain. We particularly propose a novel local-aware spatial attention mechanism and long-range residual learning to boost the quality of the output image. The experimental results demonstrate the superiority of our proposed method, even compared to the models trained at a fixed ratio. ",
    "url": "https://arxiv.org/abs/2205.11346",
    "authors": [
      "Xin Wang",
      "Kai Xuan",
      "Sheng Wang",
      "Honglin Xiong",
      "Lichi Zhang",
      "Qian Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11407",
    "title": "Deep-learning-based prediction of nanoparticle phase transitions during  in situ transmission electron microscopy",
    "abstract": "We develop the machine learning capability to predict a time sequence of in-situ transmission electron microscopy (TEM) video frames based on the combined long-short-term-memory (LSTM) algorithm and the features de-entanglement method. We train deep learning models to predict a sequence of future video frames based on the input of a sequence of previous frames. This unique capability provides insight into size dependent structural changes in Au nanoparticles under dynamic reaction condition using in-situ environmental TEM data, informing models of morphological evolution and catalytic properties. The model performance and achieved accuracy of predictions are desirable based on, for scientific data characteristic, based on limited size of training data sets. The model convergence and values for the loss function mean square error show dependence on the training strategy, and structural similarity measure between predicted structure images and ground truth reaches the value of about 0.7. This computed structural similarity is smaller than values obtained when the deep learning architecture is trained using much larger benchmark data sets, it is sufficient to show the structural transition of Au nanoparticles. While performance parameters of our model applied to scientific data fall short of those achieved for the non-scientific big data sets, we demonstrate model ability to predict the evolution, even including the particle structural phase transformation, of Au nano particles as catalyst for CO oxidation under the chemical reaction conditions. Using this approach, it may be possible to anticipate the next steps of a chemical reaction for emerging automated experimentation platforms. ",
    "url": "https://arxiv.org/abs/2205.11407",
    "authors": [
      "Wenkai Fu",
      "Steven R. Spurgeon",
      "Chongmin Wang",
      "Yuyan Shao",
      "Wei Wang",
      "Amra Peles"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11440",
    "title": "Federated Distillation based Indoor Localization for IoT Networks",
    "abstract": "Federated distillation (FD) paradigm has been recently proposed as a promising alternative to federated learning (FL) especially in wireless sensor networks with limited communication resources. However, all state-of-the art FD algorithms are designed for only classification tasks and less attention has been given to regression tasks. In this work, we propose an FD framework that properly operates on regression learning problems. Afterwards, we present a use-case implementation by proposing an indoor localization system that shows a good trade-off communication load vs. accuracy compared to federated learning (FL) based indoor localization. With our proposed framework, we reduce the number of transmitted bits by up to 98%. Moreover, we show that the proposed framework is much more scalable than FL, thus more likely to cope with the expansion of wireless networks. ",
    "url": "https://arxiv.org/abs/2205.11440",
    "authors": [
      "Yaya Etiabi",
      "Marwa Chafii",
      "El Mehdi Amhoud"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.11486",
    "title": "Robust and Agnostic Learning of Conditional Distributional Treatment  Effects",
    "abstract": "The conditional average treatment effect (CATE) is the best point prediction of individual causal effects given individual baseline covariates and can help personalize treatments. However, as CATE only reflects the (conditional) average, it can wash out potential risks and tail events, which are crucially relevant to treatment choice. In aggregate analyses, this is usually addressed by measuring distributional treatment effect (DTE), such as differences in quantiles or tail expectations between treatment groups. Hypothetically, one can similarly fit covariate-conditional quantile regressions in each treatment group and take their difference, but this would not be robust to misspecification or provide agnostic best-in-class predictions. We provide a new robust and model-agnostic methodology for learning the conditional DTE (CDTE) for a wide class of problems that includes conditional quantile treatment effects, conditional super-quantile treatment effects, and conditional treatment effects on coherent risk measures given by $f$-divergences. Our method is based on constructing a special pseudo-outcome and regressing it on baseline covariates using any given regression learner. Our method is model-agnostic in the sense that it can provide the best projection of CDTE onto the regression model class. Our method is robust in the sense that even if we learn these nuisances nonparametrically at very slow rates, we can still learn CDTEs at rates that depend on the class complexity and even conduct inferences on linear projections of CDTEs. We investigate the performance of our proposal in simulation studies, and we demonstrate its use in a case study of 401(k) eligibility effects on wealth. ",
    "url": "https://arxiv.org/abs/2205.11486",
    "authors": [
      "Nathan Kallus",
      "Miruna Oprescu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:1905.04325",
    "title": "Seeding with Costly Network Information",
    "abstract": " Title: Seeding with Costly Network Information ",
    "url": "https://arxiv.org/abs/1905.04325",
    "authors": [
      "Dean Eckles",
      "Hossein Esfandiari",
      "Elchanan Mossel",
      "M. Amin Rahimian"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computational Complexity (cs.CC)",
      "Probability (math.PR)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:1908.00894",
    "title": "Pothole Detection Based on Disparity Transformation and Road Surface  Modeling",
    "abstract": " Comments: 12 pages, 15 figures, IEEE Transactions on Image Processing ",
    "url": "https://arxiv.org/abs/1908.00894",
    "authors": [
      "Rui Fan",
      "Umar Ozgunalp",
      "Brett Hosking",
      "Ming Liu",
      "Ioannis Pitas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:1910.07779",
    "title": "Achieving Robustness to Aleatoric Uncertainty with Heteroscedastic  Bayesian Optimisation",
    "abstract": " Comments: Published in Machine Learning: Science and Technology 2021 (this https URL) Earlier version accepted to the 2019 NeurIPS Workshop on Safety and Robustness in Decision Making ",
    "url": "https://arxiv.org/abs/1910.07779",
    "authors": [
      "Ryan-Rhys Griffiths",
      "Alexander A. Aldrick",
      "Miguel Garcia-Ortegon",
      "Vidhi R. Lalchand",
      "Alpha A. Lee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2004.04371",
    "title": "MDCNN-SID: Multi-scale Dilated Convolution Network for Singer  Identification",
    "abstract": " Comments: Accepted by IJCNN2022 (The 2022 International Joint Conference on Neural Networks) ",
    "url": "https://arxiv.org/abs/2004.04371",
    "authors": [
      "Xulong Zhang",
      "Jianzong Wang",
      "Ning Cheng",
      "Jing Xiao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2006.03568",
    "title": "Graph Layer Security: Encrypting Information via Common Networked  Physics",
    "abstract": " Title: Graph Layer Security: Encrypting Information via Common Networked  Physics ",
    "url": "https://arxiv.org/abs/2006.03568",
    "authors": [
      "Zhuangkun Wei",
      "Liang Wang",
      "Schyler Chengyao Sun",
      "Bin Li",
      "Weisi Guo"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2007.14245",
    "title": "Bayesian Multi Scale Neural Network for Crowd Counting",
    "abstract": " Comments: This work makes assumptions which were found wrong later by the author ",
    "url": "https://arxiv.org/abs/2007.14245",
    "authors": [
      "Abhinav Sagar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2008.04891",
    "title": "Semantic Clone Detection via Probabilistic Software Modeling",
    "abstract": " Comments: 22 pages, 3 pages of references, 4 listings, 2 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2008.04891",
    "authors": [
      "Hannes Thaller",
      "Lukas Linsbauer",
      "Alexander Egyed"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2008.13763",
    "title": "Anomaly Detection by Recombining Gated Unsupervised Experts",
    "abstract": " Comments: Accepted at IJCNN 2022 ",
    "url": "https://arxiv.org/abs/2008.13763",
    "authors": [
      "J.-P. Schulze",
      "P. Sperl",
      "K. B\u00f6ttinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2010.08311",
    "title": "Formal Verification of Robustness and Resilience of Learning-Enabled  State Estimation Systems for Robotics",
    "abstract": " Title: Formal Verification of Robustness and Resilience of Learning-Enabled  State Estimation Systems for Robotics ",
    "url": "https://arxiv.org/abs/2010.08311",
    "authors": [
      "Wei Huang",
      "Yifan Zhou",
      "Gaojie Jin",
      "Youcheng Sun",
      "Alec Banks",
      "Jie Meng",
      "James Sharp",
      "Simon Maskell",
      "Xiaowei Huang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2012.01821",
    "title": "D-Unet: A Dual-encoder U-Net for Image Splicing Forgery Detection and  Localization",
    "abstract": " Comments: 13 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2012.01821",
    "authors": [
      "Bo Liu",
      "Ranglei Wu",
      "Xiuli Bi",
      "Bin Xiao",
      "Weisheng Li",
      "Guoyin Wang",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2012.11070",
    "title": "Energy Efficient Federated Learning over Heterogeneous Mobile Devices  via Joint Design of Weight Quantization and Wireless Transmission",
    "abstract": " Comments: 14 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2012.11070",
    "authors": [
      "Rui Chen",
      "Liang Li",
      "Kaiping Xue",
      "Chi Zhang",
      "Miao Pan",
      "Yuguang Fang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.13619",
    "title": "On self-supervised multi-modal representation learning: An application  to Alzheimer's disease",
    "abstract": " Title: On self-supervised multi-modal representation learning: An application  to Alzheimer's disease ",
    "url": "https://arxiv.org/abs/2012.13619",
    "authors": [
      "Alex Fedorov",
      "Lei Wu",
      "Tristan Sylvain",
      "Margaux Luck",
      "Thomas P. DeRamus",
      "Dmitry Bleklov",
      "Sergey M. Plis",
      "Vince D. Calhoun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2101.03778",
    "title": "Revisiting Mahalanobis Distance for Transformer-Based Out-of-Domain  Detection",
    "abstract": " Comments: AAAI 2021 ",
    "url": "https://arxiv.org/abs/2101.03778",
    "authors": [
      "Alexander Podolskiy",
      "Dmitry Lipin",
      "Andrey Bout",
      "Ekaterina Artemova",
      "Irina Piontkovskaya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2101.04645",
    "title": "Double-Adversarial Activation Anomaly Detection: Adversarial  Autoencoders are Anomaly Generators",
    "abstract": " Comments: Accepted at IJCNN 2022 ",
    "url": "https://arxiv.org/abs/2101.04645",
    "authors": [
      "J.-P. Schulze",
      "P. Sperl",
      "K. B\u00f6ttinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2101.05975",
    "title": "Multi-layer Feature Fusion Convolution Network for Audio-visual Speech  Enhancement",
    "abstract": " Title: Multi-layer Feature Fusion Convolution Network for Audio-visual Speech  Enhancement ",
    "url": "https://arxiv.org/abs/2101.05975",
    "authors": [
      "Xinmeng Xu",
      "Jianjun Hao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2102.08501",
    "title": "DEUP: Direct Epistemic Uncertainty Prediction",
    "abstract": " Title: DEUP: Direct Epistemic Uncertainty Prediction ",
    "url": "https://arxiv.org/abs/2102.08501",
    "authors": [
      "Salem Lahlou",
      "Moksh Jain",
      "Hadi Nekoei",
      "Victor Butoi",
      "Paul Bertin",
      "Jarrid Rector-Brooks",
      "Maksym Korablyov",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2102.10287",
    "title": "Deep Structured Feature Networks for Table Detection and Tabular Data  Extraction from Scanned Financial Document Images",
    "abstract": " Comments: Works need further review ",
    "url": "https://arxiv.org/abs/2102.10287",
    "authors": [
      "Siwen Luo",
      "Mengting Wu",
      "Yiwen Gong",
      "Wanying Zhou",
      "Josiah Poon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2103.14620",
    "title": "LiGCN: Label-interpretable Graph Convolutional Networks for Multi-label  Text Classification",
    "abstract": " Comments: 8 tables, 3 figures ",
    "url": "https://arxiv.org/abs/2103.14620",
    "authors": [
      "Irene Li",
      "Aosong Feng",
      "Hao Wu",
      "Tianxiao Li",
      "Toyotaro Suzumura",
      "Ruihai Dong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2103.15914",
    "title": "Tasting the cake: evaluating self-supervised generalization on  out-of-distribution multimodal MRI data",
    "abstract": " Comments: Presented as a RobustML workshop paper at ICLR 2021 ",
    "url": "https://arxiv.org/abs/2103.15914",
    "authors": [
      "Alex Fedorov",
      "Eloy Geenjaar",
      "Lei Wu",
      "Thomas P. DeRamus",
      "Vince D. Calhoun",
      "Sergey M. Plis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.01231",
    "title": "Diverse Gaussian Noise Consistency Regularization for Robustness and  Uncertainty Calibration",
    "abstract": " Comments: Under review. Preliminary version accepted to ICML 2021 Uncertainty & Robustness in Deep Learning Workshop ",
    "url": "https://arxiv.org/abs/2104.01231",
    "authors": [
      "Theodoros Tsiligkaridis",
      "Athanasios Tsiligkaridis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.02230",
    "title": "Achieving Domain Generalization in Underwater Object Detection by Domain  Mixup and Contrastive Learning",
    "abstract": " Title: Achieving Domain Generalization in Underwater Object Detection by Domain  Mixup and Contrastive Learning ",
    "url": "https://arxiv.org/abs/2104.02230",
    "authors": [
      "Pinhao Song",
      "Hong Liu",
      "Linhui Dai",
      "Peipei Yuan",
      "Runwei Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.03414",
    "title": "PrivateSNN: Privacy-Preserving Spiking Neural Networks",
    "abstract": " Comments: Accepted to AAAI2022 ",
    "url": "https://arxiv.org/abs/2104.03414",
    "authors": [
      "Youngeun Kim",
      "Yeshwanth Venkatesha",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2104.05858",
    "title": "Exploring Geometric Consistency for Monocular 3D Object Detection",
    "abstract": " Title: Exploring Geometric Consistency for Monocular 3D Object Detection ",
    "url": "https://arxiv.org/abs/2104.05858",
    "authors": [
      "Qing Lian",
      "Botao Ye",
      "Ruijia Xu",
      "Weilong Yao",
      "Tong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.08811",
    "title": "Human Schema Curation via Causal Association Rule Mining",
    "abstract": " Comments: 12 pages, 6 figures, 6 tables ",
    "url": "https://arxiv.org/abs/2104.08811",
    "authors": [
      "Noah Weber",
      "Anton Belyy",
      "Nils Holzenberger",
      "Rachel Rudinger",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2105.07654",
    "title": "Dependency Parsing as MRC-based Span-Span Prediction",
    "abstract": " Comments: Accepted by ACL 2022 Main Conference ",
    "url": "https://arxiv.org/abs/2105.07654",
    "authors": [
      "Leilei Gan",
      "Yuxian Meng",
      "Kun Kuang",
      "Xiaofei Sun",
      "Chun Fan",
      "Fei Wu",
      "Jiwei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2105.07926",
    "title": "Towards Robust Vision Transformer",
    "abstract": " Comments: Accepted to CVPR 2022, this https URL ",
    "url": "https://arxiv.org/abs/2105.07926",
    "authors": [
      "Xiaofeng Mao",
      "Gege Qi",
      "Yuefeng Chen",
      "Xiaodan Li",
      "Ranjie Duan",
      "Shaokai Ye",
      "Yuan He",
      "Hui Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.10488",
    "title": "Understanding the Performance of Knowledge Graph Embeddings in Drug  Discovery",
    "abstract": " Title: Understanding the Performance of Knowledge Graph Embeddings in Drug  Discovery ",
    "url": "https://arxiv.org/abs/2105.10488",
    "authors": [
      "Stephen Bonner",
      "Ian P Barrett",
      "Cheng Ye",
      "Rowan Swiers",
      "Ola Engkvist",
      "Charles Tapley Hoyt",
      "William L Hamilton"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.11686",
    "title": "Towards Understanding the Condensation of Neural Networks at Initial  Training",
    "abstract": " Title: Towards Understanding the Condensation of Neural Networks at Initial  Training ",
    "url": "https://arxiv.org/abs/2105.11686",
    "authors": [
      "Hanxu Zhou",
      "Qixuan Zhou",
      "Tao Luo",
      "Yaoyu Zhang",
      "Zhi-Qin John Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.00761",
    "title": "Motif Prediction with Graph Neural Networks",
    "abstract": " Title: Motif Prediction with Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2106.00761",
    "authors": [
      "Maciej Besta",
      "Raphael Grob",
      "Cesare Miglioli",
      "Nicola Bernold",
      "Grzegorz Kwasniewski",
      "Gabriel Gjini",
      "Raghavendra Kanakagiri",
      "Saleh Ashkboos",
      "Lukas Gianinazzi",
      "Nikoli Dryden",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.07202",
    "title": "Optimal transport in multilayer networks for traffic flow optimization",
    "abstract": " Comments: 11 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2106.07202",
    "authors": [
      "Abdullahi Adinoyi Ibrahim",
      "Alessandro Lonardi",
      "Caterina De Bacco"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2107.00637",
    "title": "Generalization and Robustness Implications in Object-Centric Learning",
    "abstract": " Comments: Published at ICML 2022 ",
    "url": "https://arxiv.org/abs/2107.00637",
    "authors": [
      "Andrea Dittadi",
      "Samuele Papa",
      "Michele De Vita",
      "Bernhard Sch\u00f6lkopf",
      "Ole Winther",
      "Francesco Locatello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2108.00103",
    "title": "Anomaly Detection with Neural Parsers That Never Reject",
    "abstract": " Comments: 10 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2108.00103",
    "authors": [
      "Alexander Grushin",
      "Walt Woods"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2108.00406",
    "title": "Discovering Distinctive \"Semantics\" in Super-Resolution Networks",
    "abstract": " Comments: discovering and interpreting deep degradation representations (DDR) in super-resolution networks ",
    "url": "https://arxiv.org/abs/2108.00406",
    "authors": [
      "Yihao Liu",
      "Anran Liu",
      "Jinjin Gu",
      "Zhipeng Zhang",
      "Wenhao Wu",
      "Yu Qiao",
      "Chao Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.02234",
    "title": "Multi-Branch with Attention Network for Hand-Based Person Recognition",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2101.05260 ",
    "url": "https://arxiv.org/abs/2108.02234",
    "authors": [
      "Nathanael L. Baisa",
      "Bryan Williams",
      "Hossein Rahmani",
      "Plamen Angelov",
      "Sue Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.02642",
    "title": "Robust interior penalty discontinuous Galerkin methods",
    "abstract": " Title: Robust interior penalty discontinuous Galerkin methods ",
    "url": "https://arxiv.org/abs/2108.02642",
    "authors": [
      "Zhaonan Dong",
      "Emmanuil H. Georgoulis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2108.13178",
    "title": "Modular Meta-Learning for Power Control via Random Edge Graph Neural  Networks",
    "abstract": " Comments: Submitted for publication ",
    "url": "https://arxiv.org/abs/2108.13178",
    "authors": [
      "Ivana Nikoloska",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.01904",
    "title": "Estimating Categorical Counterfactuals via Deep Twin Networks",
    "abstract": " Comments: 8 pages + appendix ",
    "url": "https://arxiv.org/abs/2109.01904",
    "authors": [
      "Athanasios Vlontzos",
      "Bernhard Kainz",
      "Ciaran M. Gilligan-Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2109.04374",
    "title": "IFBiD: Inference-Free Bias Detection",
    "abstract": " Comments: AAAI Workshop on Artificial Intelligence Safety (SafeAI) ",
    "url": "https://arxiv.org/abs/2109.04374",
    "authors": [
      "Ignacio Serna",
      "Daniel DeAlcala",
      "Aythami Morales",
      "Julian Fierrez",
      "Javier Ortega-Garcia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.05623",
    "title": "Sequential Detection and Estimation of Multipath Channel Parameters  Using Belief Propagation",
    "abstract": " Comments: 20 pages (two column), 10 figures, IEEE Transaction on Wireless Communications ",
    "url": "https://arxiv.org/abs/2109.05623",
    "authors": [
      "Xuhong Li",
      "Erik Leitinger",
      "Alexander Venus",
      "Fredrik Tufvesson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2109.13046",
    "title": "The Spread of Propaganda by Coordinated Communities on Social Media",
    "abstract": " Comments: The 14th ACM Web Science Conference 2022 (WebSci '22) ",
    "url": "https://arxiv.org/abs/2109.13046",
    "authors": [
      "Kristina Hristakieva",
      "Stefano Cresci",
      "Giovanni Da San Martino",
      "Mauro Conti",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2109.14860",
    "title": "Physics and Equality Constrained Artificial Neural Networks: Application  to Forward and Inverse Problems with Multi-fidelity Data Fusion",
    "abstract": " Title: Physics and Equality Constrained Artificial Neural Networks: Application  to Forward and Inverse Problems with Multi-fidelity Data Fusion ",
    "url": "https://arxiv.org/abs/2109.14860",
    "authors": [
      "Shamsulhaq Basir",
      "Inanc Senocak"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2110.03744",
    "title": "Voice Reenactment with F0 and timing constraints and adversarial  learning of conversions",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2107.12346 ",
    "url": "https://arxiv.org/abs/2110.03744",
    "authors": [
      "Frederik Bous",
      "Laurent Benaroya",
      "Nicolas Obin",
      "Axel Roebel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2110.04598",
    "title": "Self-explaining Neural Network with Concept-based Explanations for ICU  Mortality Prediction",
    "abstract": " Comments: ACM Conference on Bioinformatics, Computational Biology, and Health Informatics (ACM BCB) 14 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2110.04598",
    "authors": [
      "Sayantan Kumar",
      "Sean C. Yu",
      "Thomas Kannampallil",
      "Zachary Abrams",
      "Andrew Michelson",
      "Philip R.O. Payne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.05025",
    "title": "Self-supervised Learning is More Robust to Dataset Imbalance",
    "abstract": " Title: Self-supervised Learning is More Robust to Dataset Imbalance ",
    "url": "https://arxiv.org/abs/2110.05025",
    "authors": [
      "Hong Liu",
      "Jeff Z. HaoChen",
      "Adrien Gaidon",
      "Tengyu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.09035",
    "title": "Edge Rewiring Goes Neural: Boosting Network Resilience without Rich  Features",
    "abstract": " Comments: Code: this https URL ",
    "url": "https://arxiv.org/abs/2110.09035",
    "authors": [
      "Shanchao Yang",
      "Kaili Ma",
      "Baoxiang Wang",
      "Tianshu Yu",
      "Hongyuan Zha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2110.11749",
    "title": "Feature Learning and Signal Propagation in Deep Neural Networks",
    "abstract": " Comments: 35 pages ",
    "url": "https://arxiv.org/abs/2110.11749",
    "authors": [
      "Yizhang Lou",
      "Chris Mingard",
      "Yoonsoo Nam",
      "Soufiane Hayou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.13400",
    "title": "Scale-Free Adversarial Multi-Armed Bandit with Arbitrary Feedback Delays",
    "abstract": " Title: Scale-Free Adversarial Multi-Armed Bandit with Arbitrary Feedback Delays ",
    "url": "https://arxiv.org/abs/2110.13400",
    "authors": [
      "Jiatai Huang",
      "Yan Dai",
      "Longbo Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.14636",
    "title": "Pay attention to emoji: Feature Fusion Network with EmoGraph2vec Model  for Sentiment Analysis",
    "abstract": " Comments: Camera-ready verison accepted by ICPR 2022 ",
    "url": "https://arxiv.org/abs/2110.14636",
    "authors": [
      "Xiaowei Yuan",
      "Jingyuan Hu",
      "Xiaodan Zhang",
      "Honglei Lv"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2111.01022",
    "title": "Dropout in Training Neural Networks: Flatness of Solution and Noise  Structure",
    "abstract": " Title: Dropout in Training Neural Networks: Flatness of Solution and Noise  Structure ",
    "url": "https://arxiv.org/abs/2111.01022",
    "authors": [
      "Zhongwang Zhang",
      "Hanxu Zhou",
      "Zhi-Qin John Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.12128",
    "title": "On the Unreasonable Effectiveness of Feature propagation in Learning on  Graphs with Missing Node Features",
    "abstract": " Title: On the Unreasonable Effectiveness of Feature propagation in Learning on  Graphs with Missing Node Features ",
    "url": "https://arxiv.org/abs/2111.12128",
    "authors": [
      "Emanuele Rossi",
      "Henry Kenlay",
      "Maria I. Gorinova",
      "Benjamin Paul Chamberlain",
      "Xiaowen Dong",
      "Michael Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.01336",
    "title": "Simultaneously Transmitting and Reflecting Reconfigurable Intelligent  Surface Assisted NOMA Networks",
    "abstract": " Comments: 15 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2112.01336",
    "authors": [
      "Xinwei Yue",
      "Jin Xie",
      "Yuanwei Liu",
      "Zhihao Han",
      "Rongke Liu",
      "Zhiguo Ding"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2112.06351",
    "title": "Neural Point Process for Learning Spatiotemporal Event Dynamics",
    "abstract": " Title: Neural Point Process for Learning Spatiotemporal Event Dynamics ",
    "url": "https://arxiv.org/abs/2112.06351",
    "authors": [
      "Zihao Zhou",
      "Xingyi Yang",
      "Ryan Rossi",
      "Handong Zhao",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.14834",
    "title": "Training Quantized Deep Neural Networks via Cooperative Coevolution",
    "abstract": " Comments: 13 pages, 4 figures, accepted for publication of ICSI ",
    "url": "https://arxiv.org/abs/2112.14834",
    "authors": [
      "Fu Peng",
      "Shengcai Liu",
      "Ning Lu",
      "Ke Tang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04543",
    "title": "Eigenvalue Distribution of Large Random Matrices Arising in Deep Neural  Networks: Orthogonal Case",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2011.11439 ",
    "url": "https://arxiv.org/abs/2201.04543",
    "authors": [
      "Leonid Pastur"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2201.05098",
    "title": "Neural Koopman Lyapunov Control",
    "abstract": " Title: Neural Koopman Lyapunov Control ",
    "url": "https://arxiv.org/abs/2201.05098",
    "authors": [
      "Vrushabh Zinage",
      "Efstathios Bakolas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2201.09332",
    "title": "Investigating Expressiveness of Transformer in Spectral Domain for  Graphs",
    "abstract": " Comments: Corrections and minor updates ",
    "url": "https://arxiv.org/abs/2201.09332",
    "authors": [
      "Anson Bastos",
      "Abhishek Nadgeri",
      "Kuldeep Singh",
      "Hiroki Kanezashi",
      "Toyotaro Suzumura",
      "Isaiah Onando Mulang'"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.10326",
    "title": "ShapeFormer: Transformer-based Shape Completion via Sparse  Representation",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2201.10326",
    "authors": [
      "Xingguang Yan",
      "Liqiang Lin",
      "Niloy J. Mitra",
      "Dani Lischinski",
      "Daniel Cohen-Or",
      "Hui Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12006",
    "title": "Provably Improving Expert Predictions with Prediction Sets",
    "abstract": " Title: Provably Improving Expert Predictions with Prediction Sets ",
    "url": "https://arxiv.org/abs/2201.12006",
    "authors": [
      "Eleni Straitouri",
      "Lequn Wang",
      "Nastaran Okati",
      "Manuel Gomez Rodriguez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.12380",
    "title": "Explaining Graph Neural Networks with Structure-Aware Cooperative Games",
    "abstract": " Title: Explaining Graph Neural Networks with Structure-Aware Cooperative Games ",
    "url": "https://arxiv.org/abs/2201.12380",
    "authors": [
      "Shichang Zhang",
      "Neil Shah",
      "Yozen Liu",
      "Yizhou Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01263",
    "title": "NoisyMix: Boosting Model Robustness to Common Corruptions",
    "abstract": " Title: NoisyMix: Boosting Model Robustness to Common Corruptions ",
    "url": "https://arxiv.org/abs/2202.01263",
    "authors": [
      "N. Benjamin Erichson",
      "Soon Hoe Lim",
      "Winnie Xu",
      "Francisco Utrera",
      "Ziang Cao",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.01664",
    "title": "Removing Distortion Effects in Music Using Deep Neural Networks",
    "abstract": " Comments: Audio clips available at this https URL; 10 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2202.01664",
    "authors": [
      "Johannes Imort",
      "Giorgio Fabbro",
      "Marco A. Mart\u00ednez Ram\u00edrez",
      "Stefan Uhlich",
      "Yuichiro Koyama",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2202.03338",
    "title": "Robust Semantic Communications Against Semantic Noise",
    "abstract": " Comments: 7 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2202.03338",
    "authors": [
      "Qiyu Hu",
      "Guangyi Zhang",
      "Zhijin Qin",
      "Yunlong Cai",
      "Guanding Yu",
      "Geoffrey Ye Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03874",
    "title": "Bankruptcy Prediction via Mixing Intra-Risk and Conductive-Risk",
    "abstract": " Comments: 12 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2202.03874",
    "authors": [
      "Yu Zhao",
      "Shaopeng Wei",
      "Yu Guo",
      "Qing Yang",
      "Qing Li",
      "Fuzhen Zhuang",
      "Ji Liu",
      "Gang Kou"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04777",
    "title": "Exact Solutions of a Deep Linear Network",
    "abstract": " Comments: theorem 3 fixed and minor changes ",
    "url": "https://arxiv.org/abs/2202.04777",
    "authors": [
      "Liu Ziyin",
      "Botao Li",
      "Xiangming Meng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05306",
    "title": "Characterizing and overcoming the greedy nature of learning in  multi-modal deep neural networks",
    "abstract": " Title: Characterizing and overcoming the greedy nature of learning in  multi-modal deep neural networks ",
    "url": "https://arxiv.org/abs/2202.05306",
    "authors": [
      "Nan Wu",
      "Stanis\u0142aw Jastrz\u0119bski",
      "Kyunghyun Cho",
      "Krzysztof J. Geras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07549",
    "title": "Robust Multi-Objective Bayesian Optimization Under Input Noise",
    "abstract": " Comments: To appear at ICML 2022. 35 pages. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2202.07549",
    "authors": [
      "Samuel Daulton",
      "Sait Cakmak",
      "Maximilian Balandat",
      "Michael A. Osborne",
      "Enlu Zhou",
      "Eytan Bakshy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.09407",
    "title": "Blockchain Driven Privacy Preserving Contact Tracing Framework in  Pandemics",
    "abstract": " Title: Blockchain Driven Privacy Preserving Contact Tracing Framework in  Pandemics ",
    "url": "https://arxiv.org/abs/2202.09407",
    "authors": [
      "Xiao Li",
      "Weili Wu",
      "Tiantian Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2202.09661",
    "title": "Detection of Stealthy Adversaries for Networked Unmanned Aerial  Vehicles*",
    "abstract": " Comments: to appear at the 2022 Int'l Conference on Unmanned Aircraft Systems (ICUAS) ",
    "url": "https://arxiv.org/abs/2202.09661",
    "authors": [
      "Mohammad Bahrami",
      "Hamidreza Jafarnejadsani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.11911",
    "title": "When Transformer Meets Robotic Grasping: Exploits Context for Efficient  Grasp Detection",
    "abstract": " Title: When Transformer Meets Robotic Grasping: Exploits Context for Efficient  Grasp Detection ",
    "url": "https://arxiv.org/abs/2202.11911",
    "authors": [
      "Shaochen Wang",
      "Zhangli Zhou",
      "Zhen Kan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.13013",
    "title": "Sign and Basis Invariant Networks for Spectral Graph Representation  Learning",
    "abstract": " Comments: 40 pages. New experiments ",
    "url": "https://arxiv.org/abs/2202.13013",
    "authors": [
      "Derek Lim",
      "Joshua Robinson",
      "Lingxiao Zhao",
      "Tess Smidt",
      "Suvrit Sra",
      "Haggai Maron",
      "Stefanie Jegelka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.02721",
    "title": "Consistent Representation Learning for Continual Relation Extraction",
    "abstract": " Comments: Accepted to Findings of ACL 2022 ",
    "url": "https://arxiv.org/abs/2203.02721",
    "authors": [
      "Kang Zhao",
      "Hua Xu",
      "Jiangong Yang",
      "Kai Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.06125",
    "title": "Protein Representation Learning by Geometric Structure Pretraining",
    "abstract": " Title: Protein Representation Learning by Geometric Structure Pretraining ",
    "url": "https://arxiv.org/abs/2203.06125",
    "authors": [
      "Zuobai Zhang",
      "Minghao Xu",
      "Arian Jamasb",
      "Vijil Chenthamarakshan",
      "Aurelie Lozano",
      "Payel Das",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07172",
    "title": "RED-ACE: Robust Error Detection for ASR using Confidence Embeddings",
    "abstract": " Title: RED-ACE: Robust Error Detection for ASR using Confidence Embeddings ",
    "url": "https://arxiv.org/abs/2203.07172",
    "authors": [
      "Zorik Gekhman",
      "Dina Zverinski",
      "Jonathan Mallinson",
      "Genady Beryozkin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.11437",
    "title": "Self-Supervised Representation Learning as Multimodal Variational  Inference",
    "abstract": " Comments: 12 pages, 9 figures, work in progress ",
    "url": "https://arxiv.org/abs/2203.11437",
    "authors": [
      "Hiroki Nakamura",
      "Masashi Okada",
      "Tadahiro Taniguchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13712",
    "title": "Effective and Efficient Core Computation in Signed Networks",
    "abstract": " Title: Effective and Efficient Core Computation in Signed Networks ",
    "url": "https://arxiv.org/abs/2203.13712",
    "authors": [
      "Junghoon Kim",
      "Sungsu Lim",
      "Jungeun Kim"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.13778",
    "title": "L3Cube-MahaHate: A Tweet-based Marathi Hate Speech Detection Dataset and  BERT models",
    "abstract": " Title: L3Cube-MahaHate: A Tweet-based Marathi Hate Speech Detection Dataset and  BERT models ",
    "url": "https://arxiv.org/abs/2203.13778",
    "authors": [
      "Abhishek Velankar",
      "Hrushikesh Patil",
      "Amol Gore",
      "Shubham Salunke",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.01205",
    "title": "Model-Parallel Fourier Neural Operators as Learned Surrogates for  Large-Scale Parametric PDEs",
    "abstract": " Title: Model-Parallel Fourier Neural Operators as Learned Surrogates for  Large-Scale Parametric PDEs ",
    "url": "https://arxiv.org/abs/2204.01205",
    "authors": [
      "Thomas J. Grady II",
      "Rishi Khan",
      "Mathias Louboutin",
      "Ziyi Yin",
      "Philipp A. Witte",
      "Ranveer Chandra",
      "Russell J. Hewett",
      "Felix J. Herrmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2204.01321",
    "title": "PRADA: Practical Black-Box Adversarial Attacks against Neural Ranking  Models",
    "abstract": " Title: PRADA: Practical Black-Box Adversarial Attacks against Neural Ranking  Models ",
    "url": "https://arxiv.org/abs/2204.01321",
    "authors": [
      "Chen Wu",
      "Ruqing Zhang",
      "Jiafeng Guo",
      "Maarten de Rijke",
      "Yixing Fan",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2204.02461",
    "title": "Less is More: Fairness in Wide-Area Proof-of-Work Blockchain Networks",
    "abstract": " Title: Less is More: Fairness in Wide-Area Proof-of-Work Blockchain Networks ",
    "url": "https://arxiv.org/abs/2204.02461",
    "authors": [
      "Yifan Mao",
      "Shaileshh Bojja Venkatakrishnan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2204.03197",
    "title": "MDA GAN: Adversarial-Learning-based 3-D Seismic Data Interpolation and  Reconstruction for Complex Missing",
    "abstract": " Comments: This work has been submitted to journal for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2204.03197",
    "authors": [
      "Yimin Dou",
      "Kewen Li",
      "Hongjie Duan",
      "Timing Li",
      "Lin Dong",
      "Zongchao Huang"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.03410",
    "title": "Incremental Prototype Prompt-tuning with Pre-trained Representation for  Class Incremental Learning",
    "abstract": " Title: Incremental Prototype Prompt-tuning with Pre-trained Representation for  Class Incremental Learning ",
    "url": "https://arxiv.org/abs/2204.03410",
    "authors": [
      "Jieren Deng",
      "Jianhua Hu",
      "Haojian Zhang",
      "Yunkuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04090",
    "title": "Neural Tangent Generalization Attacks",
    "abstract": " Title: Neural Tangent Generalization Attacks ",
    "url": "https://arxiv.org/abs/2204.04090",
    "authors": [
      "Chia-Hung Yuan",
      "Shan-Hung Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07050",
    "title": "Recent Advances and New Frontiers in Spiking Neural Networks",
    "abstract": " Comments: Accepted at IJCAI2022 ",
    "url": "https://arxiv.org/abs/2204.07050",
    "authors": [
      "Duzhen Zhang",
      "Tielin Zhang",
      "Shuncheng Jia",
      "Qingyu Wang",
      "Bo Xu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.09655",
    "title": "Syntax-informed Question Answering with Heterogeneous Graph Transformer",
    "abstract": " Title: Syntax-informed Question Answering with Heterogeneous Graph Transformer ",
    "url": "https://arxiv.org/abs/2204.09655",
    "authors": [
      "Fangyi Zhu",
      "Lok You Tan",
      "See-Kiong Ng",
      "St\u00e9phane Bressan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.10011",
    "title": "MedFACT: Modeling Medical Feature Correlations in Patient Health  Representation Learning via Feature Clustering",
    "abstract": " Title: MedFACT: Modeling Medical Feature Correlations in Patient Health  Representation Learning via Feature Clustering ",
    "url": "https://arxiv.org/abs/2204.10011",
    "authors": [
      "Xinyu Ma",
      "Xu Chu",
      "Yasha Wang",
      "Hailong Yu",
      "Liantao Ma",
      "Wen Tang",
      "Junfeng Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.10085",
    "title": "Forgetting Prevention for Cross-regional Fraud Detection with  Heterogeneous Trade Graph",
    "abstract": " Title: Forgetting Prevention for Cross-regional Fraud Detection with  Heterogeneous Trade Graph ",
    "url": "https://arxiv.org/abs/2204.10085",
    "authors": [
      "Yujie Li",
      "Yuxuan Yang",
      "Xin Yang",
      "Qiang Gao",
      "Fan Zhou"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2204.12150",
    "title": "Where and What: Driver Attention-based Object Detection",
    "abstract": " Comments: 22 pages ",
    "url": "https://arxiv.org/abs/2204.12150",
    "authors": [
      "Yao Rong",
      "Naemi-Rebecca Kassautzki",
      "Wolfgang Fuhl",
      "Enkelejda Kasneci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2204.13599",
    "title": "Signal Recovery with Non-Expansive Generative Network Priors",
    "abstract": " Title: Signal Recovery with Non-Expansive Generative Network Priors ",
    "url": "https://arxiv.org/abs/2204.13599",
    "authors": [
      "Jorio Cocola"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.14000",
    "title": "Robust Solutions for Multi-Defender Stackelberg Security Games",
    "abstract": " Title: Robust Solutions for Multi-Defender Stackelberg Security Games ",
    "url": "https://arxiv.org/abs/2204.14000",
    "authors": [
      "Dolev Mutzari",
      "Yonatan Aumann",
      "Sarit Kraus"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.00208",
    "title": "Security and Privacy in Virtual Reality - A Literature Survey",
    "abstract": " Comments: 15 pages, 3 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2205.00208",
    "authors": [
      "Alberto Giaretta"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.00242",
    "title": "Approximating Permutations with Neural Network Components for Travelling  Photographer Problem",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2205.00242",
    "authors": [
      "Sue Sin Chong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.00904",
    "title": "Positive-Unlabeled Learning with Adversarial Data Augmentation for  Knowledge Graph Completion",
    "abstract": " Comments: Accepted by IJCAI 2022 ",
    "url": "https://arxiv.org/abs/2205.00904",
    "authors": [
      "Zhenwei Tang",
      "Shichao Pei",
      "Zhao Zhang",
      "Yongchun Zhu",
      "Fuzhen Zhuang",
      "Robert Hoehndorf",
      "Xiangliang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.00976",
    "title": "Knowledge Graph Contrastive Learning for Recommendation",
    "abstract": " Comments: This paper has been published as a full paper at SIGIR 2022 ",
    "url": "https://arxiv.org/abs/2205.00976",
    "authors": [
      "Yuhao Yang",
      "Chao Huang",
      "Lianghao Xia",
      "Chenliang Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.01550",
    "title": "Point Cloud Semantic Segmentation using Multi Scale Sparse Convolution  Neural Network",
    "abstract": " Title: Point Cloud Semantic Segmentation using Multi Scale Sparse Convolution  Neural Network ",
    "url": "https://arxiv.org/abs/2205.01550",
    "authors": [
      "Yunzheng Su",
      "Lei Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.02490",
    "title": "FastRE: Towards Fast Relation Extraction with Convolutional Encoder and  Improved Cascade Binary Tagging Framework",
    "abstract": " Comments: Accepted to IJCAI-ECAI 2022 ",
    "url": "https://arxiv.org/abs/2205.02490",
    "authors": [
      "Guozheng Li",
      "Xu Chen",
      "Peng Wang",
      "Jiafeng Xie",
      "Qiqing Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.03835",
    "title": "On the Use of BERT for Automated Essay Scoring: Joint Learning of  Multi-Scale Essay Representation",
    "abstract": " Comments: Accepted to NAACL 2022 as a long paper ",
    "url": "https://arxiv.org/abs/2205.03835",
    "authors": [
      "Yongjie Wang",
      "Chuan Wang",
      "Ruobing Li",
      "Hui Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.06090",
    "title": "NeuralTree: A 256-Channel 0.227uJ/class Versatile Neural Activity  Classification and Closed-Loop Neuromodulation SoC",
    "abstract": " Title: NeuralTree: A 256-Channel 0.227uJ/class Versatile Neural Activity  Classification and Closed-Loop Neuromodulation SoC ",
    "url": "https://arxiv.org/abs/2205.06090",
    "authors": [
      "Uisub Shin",
      "Cong Ding",
      "Bingzhao Zhu",
      "Yashwanth Vyza",
      "Alix Trouillet",
      "Emilie C. M. Revol",
      "St\u00e9phanie P. Lacour",
      "Mahsa Shoaran"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.06837",
    "title": "Strategic Latency Reduction in Blockchain Peer-to-Peer Networks",
    "abstract": " Title: Strategic Latency Reduction in Blockchain Peer-to-Peer Networks ",
    "url": "https://arxiv.org/abs/2205.06837",
    "authors": [
      "Weizhao Tang",
      "Lucianna Kiffer",
      "Giulia Fanti",
      "Ari Juels"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.07050",
    "title": "Generalization error bounds for DECONET: a deep unfolding network for  analysis Compressive Sensing",
    "abstract": " Title: Generalization error bounds for DECONET: a deep unfolding network for  analysis Compressive Sensing ",
    "url": "https://arxiv.org/abs/2205.07050",
    "authors": [
      "Vasiliki Kouni"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.07154",
    "title": "Evaluating Generalizability of Fine-Tuned Models for Fake News Detection",
    "abstract": " Title: Evaluating Generalizability of Fine-Tuned Models for Fake News Detection ",
    "url": "https://arxiv.org/abs/2205.07154",
    "authors": [
      "Abhijit Suprem",
      "Calton Pu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.07266",
    "title": "Discovering the Representation Bottleneck of Graph Neural Networks from  Multi-order Interactions",
    "abstract": " Title: Discovering the Representation Bottleneck of Graph Neural Networks from  Multi-order Interactions ",
    "url": "https://arxiv.org/abs/2205.07266",
    "authors": [
      "Fang Wu",
      "Siyuan Li",
      "Lirong Wu",
      "Dragomir Radev",
      "Qiang Zhang",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.08075",
    "title": "Collaborative Attention Memory Network for Video Object Segmentation",
    "abstract": " Comments: Technical Report. Proposed systems attain 6th in YouTube-VOS challenge 2021 ",
    "url": "https://arxiv.org/abs/2205.08075",
    "authors": [
      "Zhixing Huang",
      "Junli Zha",
      "Fei Xie",
      "Yuwei Zheng",
      "Yuandong Zhong",
      "Jinpeng Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.08147",
    "title": "Pairwise Comparison Network for Remote Sensing Scene Classification",
    "abstract": " Comments: 6 pages, 4 figures, published to GRSL ",
    "url": "https://arxiv.org/abs/2205.08147",
    "authors": [
      "Zhang Yue",
      "Zheng Xiangtao",
      "Lu Xiaoqiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.09048",
    "title": "Global Contrast Masked Autoencoders Are Powerful Pathological  Representation Learners",
    "abstract": " Title: Global Contrast Masked Autoencoders Are Powerful Pathological  Representation Learners ",
    "url": "https://arxiv.org/abs/2205.09048",
    "authors": [
      "Hao Quan",
      "Xingyu Li",
      "Weixing Chen",
      "Qun Bai",
      "Mingchen Zou",
      "Ruijie Yang",
      "Tingting Zheng",
      "Ruiqun Qi",
      "Xinghua Gao",
      "Xiaoyu Cui"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.09054",
    "title": "Position Aided Beam Prediction in the Real World: How Useful GPS  Locations Actually Are?",
    "abstract": " Comments: Submitted to IEEE. Datasets and code files are available on the DeepSense website: this https URL ",
    "url": "https://arxiv.org/abs/2205.09054",
    "authors": [
      "Jo\u00e3o Morais",
      "Arash Behboodi",
      "Hamed Pezeshki",
      "Ahmed Alkhateeb"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09787",
    "title": "Causal Discovery and Injection for Feed-Forward Neural Networks",
    "abstract": " Title: Causal Discovery and Injection for Feed-Forward Neural Networks ",
    "url": "https://arxiv.org/abs/2205.09787",
    "authors": [
      "Fabrizio Russo",
      "Francesca Toni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.09884",
    "title": "Time Series Anomaly Detection via Reinforcement Learning-Based Model  Selection",
    "abstract": " Comments: 6 pages, 3 figures, submitted to IEEE Canadian Conference on Electrical and Computer Engineering (CCECE) 2022 ",
    "url": "https://arxiv.org/abs/2205.09884",
    "authors": [
      "Jiuqi Elise Zhang",
      "Di Wu",
      "Benoit Boulet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09940",
    "title": "Conformal Prediction with Temporal Quantile Adjustments",
    "abstract": " Comments: 12 pages (main paper, including references) + 11 pages (supplementary material) ",
    "url": "https://arxiv.org/abs/2205.09940",
    "authors": [
      "Zhen Lin",
      "Shubhendu Trivedi",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2205.10014",
    "title": "A Survey of Trustworthy Graph Learning: Reliability, Explainability, and  Privacy Protection",
    "abstract": " Comments: Preprint; Work in progress. arXiv admin note: substantial text overlap with arXiv:2202.07114 ",
    "url": "https://arxiv.org/abs/2205.10014",
    "authors": [
      "Bingzhe Wu",
      "Jintang Li",
      "Junchi Yu",
      "Yatao Bian",
      "Hengtong Zhang",
      "CHaochao Chen",
      "Chengbin Hou",
      "Guoji Fu",
      "Liang Chen",
      "Tingyang Xu",
      "Yu Rong",
      "Xiaolin Zheng",
      "Junzhou Huang",
      "Ran He",
      "Baoyuan Wu",
      "GUangyu Sun",
      "Peng Cui",
      "Zibin Zheng",
      "Zhe Liu",
      "Peilin Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]