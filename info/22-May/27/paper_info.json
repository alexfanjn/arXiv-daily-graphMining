[
  {
    "id": "arXiv:2205.12960",
    "title": "Towards Symbolic Time Series Representation Improved by Kernel Density  Estimators",
    "abstract": "This paper deals with symbolic time series representation. It builds up on the popular mapping technique Symbolic Aggregate approXimation algorithm (SAX), which is extensively utilized in sequence classification, pattern mining, anomaly detection, time series indexing and other data mining tasks. However, the disadvantage of this method is, that it works reliably only for time series with Gaussian-like distribution. In our previous work we have proposed an improvement of SAX, called dwSAX, which can deal with Gaussian as well as non-Gaussian data distribution. Recently we have made further progress in our solution - edwSAX. Our goal was to optimally cover the information space by means of sufficient alphabet utilization; and to satisfy lower bounding criterion as tight as possible. We describe here our approach, including evaluation on commonly employed tasks such as time series reconstruction error and Euclidean distance lower bounding with promising improvements over SAX. ",
    "url": "https://arxiv.org/abs/2205.12960",
    "authors": [
      "Matej Kloska",
      "Viera Rozinajova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12961",
    "title": "Towards Green AI with tensor networks -- Sustainability and innovation  enabled by efficient algorithms",
    "abstract": "The current standard to compare the performance of AI algorithms is mainly based on one criterion: the model's accuracy. In this context, algorithms with a higher accuracy (or similar measures) are considered as better. To achieve new state-of-the-art results, algorithmic development is accompanied by an exponentially increasing amount of compute. While this has enabled AI research to achieve remarkable results, AI progress comes at a cost: it is unsustainable. In this paper, we present a promising tool for sustainable and thus Green AI: tensor networks (TNs). Being an established tool from multilinear algebra, TNs have the capability to improve efficiency without compromising accuracy. Since they can reduce compute significantly, we would like to highlight their potential for Green AI. We elaborate in both a kernel machine and deep learning setting how efficiency gains can be achieved with TNs. Furthermore, we argue that better algorithms should be evaluated in terms of both accuracy and efficiency. To that end, we discuss different efficiency criteria and analyze efficiency in an exemplifying experimental setting for kernel ridge regression. With this paper, we want to raise awareness about Green AI and showcase its positive impact on sustainability and AI research. Our key contribution is to demonstrate that TNs enable efficient algorithms and therefore contribute towards Green AI. In this sense, TNs pave the way for better algorithms in AI. ",
    "url": "https://arxiv.org/abs/2205.12961",
    "authors": [
      "Eva Memmel",
      "Clara Menzen",
      "Jetze Schuurmans",
      "Frederiek Wesel",
      "Kim Batselier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13005",
    "title": "QGNN: Value Function Factorisation with Graph Neural Networks",
    "abstract": "In multi-agent reinforcement learning, the use of a global objective is a powerful tool for incentivising cooperation. Unfortunately, it is not sample-efficient to train individual agents with a global reward, because it does not necessarily correlate with an agent's individual actions. This problem can be solved by factorising the global value function into local value functions. Early work in this domain performed factorisation by conditioning local value functions purely on local information. Recently, it has been shown that providing both local information and an encoding of the global state can promote cooperative behaviour. In this paper we propose QGNN, the first value factorisation method to use a graph neural network (GNN) based model. The multi-layer message passing architecture of QGNN provides more representational complexity than models in prior work, allowing it to produce a more effective factorisation. QGNN also introduces a permutation invariant mixer which is able to match the performance of other methods, even with significantly fewer parameters. We evaluate our method against several baselines, including QMIX-Att, GraphMIX, QMIX, VDN, and hybrid architectures. Our experiments include Starcraft, the standard benchmark for credit assignment; Estimate Game, a custom environment that explicitly models inter-agent dependencies; and Coalition Structure Generation, a foundational problem with real-world applications. The results show that QGNN outperforms state-of-the-art value factorisation baselines consistently. ",
    "url": "https://arxiv.org/abs/2205.13005",
    "authors": [
      "Ryan Kortvelesy",
      "Amanda Prorok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13012",
    "title": "TSEM: Temporally Weighted Spatiotemporal Explainable Neural Network for  Multivariate Time Series",
    "abstract": "Deep learning has become a one-size-fits-all solution for technical and business domains thanks to its flexibility and adaptability. It is implemented using opaque models, which unfortunately undermines the outcome trustworthiness. In order to have a better understanding of the behavior of a system, particularly one driven by time series, a look inside a deep learning model so-called posthoc eXplainable Artificial Intelligence (XAI) approaches, is important. There are two major types of XAI for time series data, namely model-agnostic and model-specific. Model-specific approach is considered in this work. While other approaches employ either Class Activation Mapping (CAM) or Attention Mechanism, we merge the two strategies into a single system, simply called the Temporally Weighted Spatiotemporal Explainable Neural Network for Multivariate Time Series (TSEM). TSEM combines the capabilities of RNN and CNN models in such a way that RNN hidden units are employed as attention weights for the CNN feature maps temporal axis. The result shows that TSEM outperforms XCM. It is similar to STAM in terms of accuracy, while also satisfying a number of interpretability criteria, including causality, fidelity, and spatiotemporality. ",
    "url": "https://arxiv.org/abs/2205.13012",
    "authors": [
      "Anh-Duy Pham",
      "Anastassia Kuestenmacher",
      "Paul G. Ploeger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13018",
    "title": "On the Reliability of Computing-in-Memory Accelerators for Deep Neural  Networks",
    "abstract": "Computing-in-memory with emerging non-volatile memory (nvCiM) is shown to be a promising candidate for accelerating deep neural networks (DNNs) with high energy efficiency. However, most non-volatile memory (NVM) devices suffer from reliability issues, resulting in a difference between actual data involved in the nvCiM computation and the weight value trained in the data center. Thus, models actually deployed on nvCiM platforms achieve lower accuracy than their counterparts trained on the conventional hardware (e.g., GPUs). In this chapter, we first offer a brief introduction to the opportunities and challenges of nvCiM DNN accelerators and then show the properties of different types of NVM devices. We then introduce the general architecture of nvCiM DNN accelerators. After that, we discuss the source of unreliability and how to efficiently model their impact. Finally, we introduce representative works that mitigate the impact of device variations. ",
    "url": "https://arxiv.org/abs/2205.13018",
    "authors": [
      "Zheyu Yan",
      "Xiaobo Sharon Hu",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2205.13022",
    "title": "Towards Using Data-Centric Approach for Better Code Representation  Learning",
    "abstract": "Despite the recent trend of creating source code models and applying them to software engineering tasks, the quality of such models is insufficient for real-world application. In this work, we focus on improving existing code learning models from the data-centric perspective instead of designing new source code models. We shed some light on this direction by using a so-called data-influence method to identify noisy samples of pre-trained code learning models. The data-influence method is to assess the similarity of a target sample to the correct samples to determine whether or not such the target sample is noisy. The results of our evaluation show that data-influence methods can identify noisy samples for the code classification and defection prediction tasks. We envision that the data-centric approach will be a key driver for developing source code models that are useful in practice. ",
    "url": "https://arxiv.org/abs/2205.13022",
    "authors": [
      "Anh Dau",
      "Thang Nguyen-Duc",
      "Hoang Thanh-Tung",
      "Nghi Bui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2205.13033",
    "title": "Concurrent Neural Tree and Data Preprocessing AutoML for Image  Classification",
    "abstract": "Deep Neural Networks (DNN's) are a widely-used solution for a variety of machine learning problems. However, it is often necessary to invest a significant amount of a data scientist's time to pre-process input data, test different neural network architectures, and tune hyper-parameters for optimal performance. Automated machine learning (autoML) methods automatically search the architecture and hyper-parameter space for optimal neural networks. However, current state-of-the-art (SOTA) methods do not include traditional methods for manipulating input data as part of the algorithmic search space. We adapt the Evolutionary Multi-objective Algorithm Design Engine (EMADE), a multi-objective evolutionary search framework for traditional machine learning methods, to perform neural architecture search. We also integrate EMADE's signal processing and image processing primitives. These primitives allow EMADE to manipulate input data before ingestion into the simultaneously evolved DNN. We show that including these methods as part of the search space shows potential to provide benefits to performance on the CIFAR-10 image classification benchmark dataset. ",
    "url": "https://arxiv.org/abs/2205.13033",
    "authors": [
      "Anish Thite",
      "Mohan Dodda",
      "Pulak Agarwal",
      "Jason Zutty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.13034",
    "title": "EvoVGM: A Deep Variational Generative Model for Evolutionary Parameter  Estimation",
    "abstract": "Most evolutionary-oriented deep generative models do not explicitly consider the underlying evolutionary dynamics of biological sequences as it is performed within the Bayesian phylogenetic inference framework. In this study, we propose a method for a deep variational Bayesian generative model that jointly approximates the true posterior of local biological evolutionary parameters and generates sequence alignments. Moreover, it is instantiated and tuned for continuous-time Markov chain substitution models such as JC69 and GTR. We train the model via a low-variance variational objective function and a gradient ascent algorithm. Here, we show the consistency and effectiveness of the method on synthetic sequence alignments simulated with several evolutionary scenarios and on a real virus sequence alignment. ",
    "url": "https://arxiv.org/abs/2205.13034",
    "authors": [
      "Amine M. Remita",
      "Abdoulaye Banir\u00e9 Diallo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2205.13038",
    "title": "Improving Subgraph Representation Learning via Multi-View Augmentation",
    "abstract": "Subgraph representation learning based on Graph Neural Network (GNN) has broad applications in chemistry and biology, such as molecule property prediction and gene collaborative function prediction. On the other hand, graph augmentation techniques have shown promising results in improving graph-based and node-based classification tasks but are rarely explored in the GNN-based subgraph representation learning literature. In this work, we developed a novel multiview augmentation mechanism to improve subgraph representation learning and thus the accuracy of downstream prediction tasks. The augmentation technique creates multiple variants of subgraphs and embeds these variants into the original graph to achieve both high training efficiency, scalability, and improved accuracy. Experiments on several real-world subgraph benchmarks demonstrate the superiority of our proposed multi-view augmentation techniques. ",
    "url": "https://arxiv.org/abs/2205.13038",
    "authors": [
      "Yili Shen",
      "Jiaxu Yan",
      "Cheng-Wei Ju",
      "Jun Yi",
      "Zhou Lin",
      "Hui Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13060",
    "title": "Designing an Efficient End-to-end Machine Learning Pipeline for  Real-time Empty-shelf Detection",
    "abstract": "On-Shelf Availability (OSA) of products in retail stores is a critical business criterion in the fast moving consumer goods and retails sector. When a product is out-of-stock (OOS) and a customer cannot find it on its designed shelf, this causes a negative impact on the customer's behaviors and future demands. Several methods are being adopted by retailers today to detect empty shelves and ensure high OSA of products; however, such methods are generally ineffective and infeasible since they are either manual, expensive or less accurate. Recently machine learning based solutions have been proposed, but they suffer from high computation cost and low accuracy problem due to lack of large annotated datasets of on-shelf products. Here, we present an elegant approach for designing an end-to-end machine learning (ML) pipeline for real-time empty shelf detection. Considering the strong dependency between the quality of ML models and the quality of data, we focus on the importance of proper data collection, cleaning and correct data annotation before delving into modeling. Since an empty-shelf detection solution should be computationally-efficient for real-time predictions, we explore different run-time optimizations to improve the model performance. Our dataset contains 1000 images, collected and annotated by following well-defined guidelines. Our low-latency model achieves a mean average F1-score of 68.5%, and can process up to 67 images/s on Intel Xeon Gold and up to 860 images/s on an A100 GPU. Our annotated dataset is publicly available along with our optimized models. ",
    "url": "https://arxiv.org/abs/2205.13060",
    "authors": [
      "Dipendra Jha",
      "Ata Mahjoubfar",
      "Anupama Joshi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13061",
    "title": "RENs: Relevance Encoding Networks",
    "abstract": "The manifold assumption for high-dimensional data assumes that the data is generated by varying a set of parameters obtained from a low-dimensional latent space. Deep generative models (DGMs) are widely used to learn data representations in an unsupervised way. DGMs parameterize the underlying low-dimensional manifold in the data space using bottleneck architectures such as variational autoencoders (VAEs). The bottleneck dimension for VAEs is treated as a hyperparameter that depends on the dataset and is fixed at design time after extensive tuning. As the intrinsic dimensionality of most real-world datasets is unknown, often, there is a mismatch between the intrinsic dimensionality and the latent dimensionality chosen as a hyperparameter. This mismatch can negatively contribute to the model performance for representation learning and sample generation tasks. This paper proposes relevance encoding networks (RENs): a novel probabilistic VAE-based framework that uses the automatic relevance determination (ARD) prior in the latent space to learn the data-specific bottleneck dimensionality. The relevance of each latent dimension is directly learned from the data along with the other model parameters using stochastic gradient descent and a reparameterization trick adapted to non-Gaussian priors. We leverage the concept of DeepSets to capture permutation invariant statistical properties in both data and latent spaces for relevance determination. The proposed framework is general and flexible and can be used for the state-of-the-art VAE models that leverage regularizers to impose specific characteristics in the latent space (e.g., disentanglement). With extensive experimentation on synthetic and public image datasets, we show that the proposed model learns the relevant latent bottleneck dimensionality without compromising the representation and generation quality of the samples. ",
    "url": "https://arxiv.org/abs/2205.13061",
    "authors": [
      "Krithika Iyer",
      "Riddhish Bhalodia",
      "Shireen Elhabian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13071",
    "title": "Exploring Map-based Features for Efficient Attention-based Vehicle  Motion Prediction",
    "abstract": "Motion prediction (MP) of multiple agents is a crucial task in arbitrarily complex environments, from social robots to self-driving cars. Current approaches tackle this problem using end-to-end networks, where the input data is usually a rendered top-view of the scene and the past trajectories of all the agents; leveraging this information is a must to obtain optimal performance. In that sense, a reliable Autonomous Driving (AD) system must produce reasonable predictions on time, however, despite many of these approaches use simple ConvNets and LSTMs, models might not be efficient enough for real-time applications when using both sources of information (map and trajectory history). Moreover, the performance of these models highly depends on the amount of training data, which can be expensive (particularly the annotated HD maps). In this work, we explore how to achieve competitive performance on the Argoverse 1.0 Benchmark using efficient attention-based models, which take as input the past trajectories and map-based features from minimal map information to ensure efficient and reliable MP. These features represent interpretable information as the driveable area and plausible goal points, in opposition to black-box CNN-based methods for map processing. ",
    "url": "https://arxiv.org/abs/2205.13071",
    "authors": [
      "Carlos G\u00f3mez-Hu\u00e9lamo",
      "Marcos V. Conde",
      "Miguel Ortiz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13076",
    "title": "Entropy Maximization with Depth: A Variational Principle for Random  Neural Networks",
    "abstract": "To understand the essential role of depth in neural networks, we investigate a variational principle for depth: Does increasing depth perform an implicit optimization for the representations in neural networks? We prove that random neural networks equipped with batch normalization maximize the differential entropy of representations with depth up to constant factors, assuming that the representations are contractive. Thus, representations inherently obey the \\textit{principle of maximum entropy} at initialization, in the absence of information about the learning task. Our variational formulation for neural representations characterizes the interplay between representation entropy and architectural components, including depth, width, and non-linear activations, thereby potentially inspiring the design of neural architectures. ",
    "url": "https://arxiv.org/abs/2205.13076",
    "authors": [
      "Amir Joudaki",
      "Hadi Daneshmand",
      "Francis Bach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2205.13084",
    "title": "BRIGHT -- Graph Neural Networks in Real-Time Fraud Detection",
    "abstract": "Detecting fraudulent transactions is an essential component to control risk in e-commerce marketplaces. Apart from rule-based and machine learning filters that are already deployed in production, we want to enable efficient real-time inference with graph neural networks (GNNs), which is useful to catch multihop risk propagation in a transaction graph. However, two challenges arise in the implementation of GNNs in production. First, future information in a dynamic graph should not be considered in message passing to predict the past. Second, the latency of graph query and GNN model inference is usually up to hundreds of milliseconds, which is costly for some critical online services. To tackle these challenges, we propose a Batch and Real-time Inception GrapH Topology (BRIGHT) framework to conduct an end-to-end GNN learning that allows efficient online real-time inference. BRIGHT framework consists of a graph transformation module (Two-Stage Directed Graph) and a corresponding GNN architecture (Lambda Neural Network). The Two-Stage Directed Graph guarantees that the information passed through neighbors is only from the historical payment transactions. It consists of two subgraphs representing historical relationships and real-time links, respectively. The Lambda Neural Network decouples inference into two stages: batch inference of entity embeddings and real-time inference of transaction prediction. Our experiments show that BRIGHT outperforms the baseline models by >2\\% in average w.r.t.~precision. Furthermore, BRIGHT is computationally efficient for real-time fraud detection. Regarding end-to-end performance (including neighbor query and inference), BRIGHT can reduce the P99 latency by >75\\%. For the inference stage, our speedup is on average 7.8$\\times$ compared to the traditional GNN. ",
    "url": "https://arxiv.org/abs/2205.13084",
    "authors": [
      "Mingxuan Lu",
      "Zhichao Han",
      "Susie Xi Rao",
      "Zitao Zhang",
      "Yang Zhao",
      "Yinan Shan",
      "Ramesh Raghunathan",
      "Ce Zhang",
      "Jiawei Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13092",
    "title": "Semantic-Aware Representation Blending for Multi-Label Image Recognition  with Partial Labels",
    "abstract": "Despite achieving impressive progress, current multi-label image recognition (MLR) algorithms heavily depend on large-scale datasets with complete labels, making collecting large-scale datasets extremely time-consuming and labor-intensive. Training the multi-label image recognition models with partial labels (MLR-PL) is an alternative way to address this issue, in which merely some labels are known while others are unknown for each image (see Figure 1). However, current MLP-PL algorithms mainly rely on the pre-trained image classification or similarity models to generate pseudo labels for the unknown labels. Thus, they depend on a certain amount of data annotations and inevitably suffer from obvious performance drops, especially when the known label proportion is low. To address this dilemma, we propose a unified semantic-aware representation blending (SARB) that consists of two crucial modules to blend multi-granularity category-specific semantic representation across different images to transfer information of known labels to complement unknown labels. Extensive experiments on the MS-COCO, Visual Genome, and Pascal VOC 2007 datasets show that the proposed SARB consistently outperforms current state-of-the-art algorithms on all known label proportion settings. Concretely, it obtain the average mAP improvement of 1.9%, 4.5%, 1.0% on the three benchmark datasets compared with the second-best algorithm. ",
    "url": "https://arxiv.org/abs/2205.13092",
    "authors": [
      "Tao Pu",
      "Tianshui Chen",
      "Hefeng Wu",
      "Yongyi Lu",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13094",
    "title": "Undersampling is a Minimax Optimal Robustness Intervention in  Nonparametric Classification",
    "abstract": "While a broad range of techniques have been proposed to tackle distribution shift, the simple baseline of training on an $\\textit{undersampled}$ dataset often achieves close to state-of-the-art-accuracy across several popular benchmarks. This is rather surprising, since undersampling algorithms discard excess majority group data. To understand this phenomenon, we ask if learning is fundamentally constrained by a lack of minority group samples. We prove that this is indeed the case in the setting of nonparametric binary classification. Our results show that in the worst case, an algorithm cannot outperform undersampling unless there is a high degree of overlap between the train and test distributions (which is unlikely to be the case in real-world datasets), or if the algorithm leverages additional structure about the distribution shift. In particular, in the case of label shift we show that there is always an undersampling algorithm that is minimax optimal. While in the case of group-covariate shift we show that there is an undersampling algorithm that is minimax optimal when the overlap between the group distributions is small. We also perform an experimental case study on a label shift dataset and find that in line with our theory the test accuracy of robust neural network classifiers is constrained by the number of minority samples. ",
    "url": "https://arxiv.org/abs/2205.13094",
    "authors": [
      "Niladri S. Chatterji",
      "Saminul Haque",
      "Tatsunori Hashimoto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.13098",
    "title": "Optimal Neural Network Approximation of Wasserstein Gradient Direction  via Convex Optimization",
    "abstract": "The computation of Wasserstein gradient direction is essential for posterior sampling problems and scientific computing. The approximation of the Wasserstein gradient with finite samples requires solving a variational problem. We study the variational problem in the family of two-layer networks with squared-ReLU activations, towards which we derive a semi-definite programming (SDP) relaxation. This SDP can be viewed as an approximation of the Wasserstein gradient in a broader function family including two-layer networks. By solving the convex SDP, we obtain the optimal approximation of the Wasserstein gradient direction in this class of functions. Numerical experiments including PDE-constrained Bayesian inference and parameter estimation in COVID-19 modeling demonstrate the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2205.13098",
    "authors": [
      "Yifei Wang",
      "Peng Chen",
      "Mert Pilanci",
      "Wuchen Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.13108",
    "title": "Unsupervised Abstractive Dialogue Summarization with Word Graphs and POV  Conversion",
    "abstract": "We advance the state-of-the-art in unsupervised abstractive dialogue summarization by utilizing multi-sentence compression graphs. Starting from well-founded assumptions about word graphs, we present simple but reliable path-reranking and topic segmentation schemes. Robustness of our method is demonstrated on datasets across multiple domains, including meetings, interviews, movie scripts, and day-to-day conversations. We also identify possible avenues to augment our heuristic-based system with deep learning. We open-source our code, to provide a strong, reproducible baseline for future research into unsupervised dialogue summarization. ",
    "url": "https://arxiv.org/abs/2205.13108",
    "authors": [
      "Seongmin Park",
      "Jihwa Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13109",
    "title": "Learning to segment with limited annotations: Self-supervised  pretraining with regression and contrastive loss in MRI",
    "abstract": "Obtaining manual annotations for large datasets for supervised training of deep learning (DL) models is challenging. The availability of large unlabeled datasets compared to labeled ones motivate the use of self-supervised pretraining to initialize DL models for subsequent segmentation tasks. In this work, we consider two pre-training approaches for driving a DL model to learn different representations using: a) regression loss that exploits spatial dependencies within an image and b) contrastive loss that exploits semantic similarity between pairs of images. The effect of pretraining techniques is evaluated in two downstream segmentation applications using Magnetic Resonance (MR) images: a) liver segmentation in abdominal T2-weighted MR images and b) prostate segmentation in T2-weighted MR images of the prostate. We observed that DL models pretrained using self-supervision can be finetuned for comparable performance with fewer labeled datasets. Additionally, we also observed that initializing the DL model using contrastive loss based pretraining performed better than the regression loss. ",
    "url": "https://arxiv.org/abs/2205.13109",
    "authors": [
      "Lavanya Umapathy",
      "Zhiyang Fu",
      "Rohit Philip",
      "Diego Martin",
      "Maria Altbach",
      "Ali Bilgin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.13116",
    "title": "GraphPMU: Event Clustering via Graph Representation Learning Using  Locationally-Scarce Distribution-Level Fundamental and Harmonic PMU  Measurements",
    "abstract": "This paper is concerned with the complex task of identifying the type and cause of the events that are captured by distribution-level phasor measurement units (D-PMUs) in order to enhance situational awareness in power distribution systems. Our goal is to address two fundamental challenges in this field: a) scarcity in measurement locations due to the high cost of purchasing, installing, and streaming data from D-PMUs; b) limited prior knowledge about the event signatures due to the fact that the events are diverse, infrequent, and inherently unscheduled. To tackle these challenges, we propose an unsupervised graph-representation learning method, called GraphPMU, to significantly improve the performance in event clustering under locationally-scarce data availability by proposing the following two new directions: 1) using the topological information about the relative location of the few available phasor measurement units on the graph of the power distribution network; 2) utilizing not only the commonly used fundamental phasor measurements, bus also the less explored harmonic phasor measurements in the process of analyzing the signatures of various events. Through a detailed analysis of several case studies, we show that GraphPMU can highly outperform the prevalent methods in the literature. ",
    "url": "https://arxiv.org/abs/2205.13116",
    "authors": [
      "Armin Aligholian",
      "Hamed Mohsenian-Rad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.13128",
    "title": "Cascading Residual Graph Convolutional Network for Multi-Behavior  Recommendation",
    "abstract": "Multi-behavior recommendation exploits multiple types of user-item interactions to alleviate the data sparsity problem faced by the traditional models that often utilize only one type of interaction for recommendation. In real scenarios, users often take a sequence of actions to interact with an item, in order to get more information about the item and thus accurately evaluate whether an item fits personal preference. Those interaction behaviors often obey a certain order, and different behaviors reveal different information or aspects of user preferences towards the target item. Most existing multi-behavior recommendation methods take the strategy to first extract information from different behaviors separately and then fuse them for final prediction. However, they have not exploited the connections between different behaviors to learn user preferences. Besides, they often introduce complex model structures and more parameters to model multiple behaviors, largely increasing the space and time complexity. In this work, we propose a lightweight multi-behavior recommendation model named Cascading Residual Graph Convolutional Network (CRGCN for short), which can explicitly exploit the connections between different behaviors into the embedding learning process without introducing any additional parameters. In particular, we design a cascading residual graph convolutional network structure, which enables our model to learn user preferences by continuously refining user embeddings across different types of behaviors. The multi-task learning method is adopted to jointly optimize our model based on different behaviors. Extensive experimental results on two real-world benchmark datasets show that CRGCN can substantially outperform state-of-the-art methods. Further studies also analyze the effects of leveraging multi-behaviors in different numbers and orders on the final performance. ",
    "url": "https://arxiv.org/abs/2205.13128",
    "authors": [
      "Mingshi Yan",
      "Zhiyong Cheng",
      "Chen Gao",
      "Jing Sun",
      "Fan Liu",
      "Fuming Sun",
      "Haojie Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2205.13135",
    "title": "LAMP 2.0: A Robust Multi-Robot SLAM System for Operation in Challenging  Large-Scale Underground Environments",
    "abstract": "Search and rescue with a team of heterogeneous mobile robots in unknown and large-scale underground environments requires high-precision localization and mapping. This crucial requirement is faced with many challenges in complex and perceptually-degraded subterranean environments, as the onboard perception system is required to operate in off-nominal conditions (poor visibility due to darkness and dust, rugged and muddy terrain, and the presence of self-similar and ambiguous scenes). In a disaster response scenario and in the absence of prior information about the environment, robots must rely on noisy sensor data and perform Simultaneous Localization and Mapping (SLAM) to build a 3D map of the environment and localize themselves and potential survivors. To that end, this paper reports on a multi-robot SLAM system developed by team CoSTAR in the context of the DARPA Subterranean Challenge. We extend our previous work, LAMP, by incorporating a single-robot front-end interface that is adaptable to different odometry sources and lidar configurations, a scalable multi-robot front-end to support inter- and intra-robot loop closure detection for large scale environments and multi-robot teams, and a robust back-end equipped with an outlier-resilient pose graph optimization based on Graduated Non-Convexity. We provide a detailed ablation study on the multi-robot front-end and back-end, and assess the overall system performance in challenging real-world datasets collected across mines, power plants, and caves in the United States. We also release our multi-robot back-end datasets (and the corresponding ground truth), which can serve as challenging benchmarks for large-scale underground SLAM. ",
    "url": "https://arxiv.org/abs/2205.13135",
    "authors": [
      "Yun Chang",
      "Kamak Ebadi",
      "Christopher E. Denniston",
      "Muhammad Fadhil Ginting",
      "Antoni Rosinol",
      "Andrzej Reinke",
      "Matteo Palieri",
      "Jingnan Shi",
      "Arghya Chatterjee",
      "Benjamin Morrell",
      "Ali-akbar Agha-mohammadi",
      "Luca Carlone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2205.13137",
    "title": "MixMIM: Mixed and Masked Image Modeling for Efficient Visual  Representation Learning",
    "abstract": "In this study, we propose Mixed and Masked Image Modeling (MixMIM), a simple but efficient MIM method that is applicable to various hierarchical Vision Transformers. Existing MIM methods replace a random subset of input tokens with a special MASK symbol and aim at reconstructing original image tokens from the corrupted image. However, we find that using the MASK symbol greatly slows down the training and causes training-finetuning inconsistency, due to the large masking ratio (e.g., 40% in BEiT). In contrast, we replace the masked tokens of one image with visible tokens of another image, i.e., creating a mixed image. We then conduct dual reconstruction to reconstruct the original two images from the mixed input, which significantly improves efficiency. While MixMIM can be applied to various architectures, this paper explores a simpler but stronger hierarchical Transformer, and scales with MixMIM-B, -L, and -H. Empirical results demonstrate that MixMIM can learn high-quality visual representations efficiently. Notably, MixMIM-B with 88M parameters achieves 85.1% top-1 accuracy on ImageNet-1K by pretraining for 600 epochs, setting a new record for neural networks with comparable model sizes (e.g., ViT-B) among MIM methods. Besides, its transferring performances on the other 6 datasets show MixMIM has better FLOPs / performance tradeoff than previous MIM methods. Code is available at https://github.com/Sense-X/MixMIM. ",
    "url": "https://arxiv.org/abs/2205.13137",
    "authors": [
      "Jihao Liu",
      "Xin Huang",
      "Yu Liu",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13148",
    "title": "Grammar Detection for Sentiment Analysis through Improved Viterbi  Algorithm",
    "abstract": "Grammar Detection, also referred to as Parts of Speech Tagging of raw text, is considered an underlying building block of the various Natural Language Processing pipelines like named entity recognition, question answering, and sentiment analysis. In short, forgiven a sentence, Parts of Speech tagging is the task of specifying and tagging each word of a sentence with nouns, verbs, adjectives, adverbs, and more. Sentiment Analysis may well be a procedure accustomed to determining if a given sentence's emotional tone is neutral, positive or negative. To assign polarity scores to the thesis or entities within phrase, in-text analysis and analytics, machine learning and natural language processing, approaches are incorporated. This Sentiment Analysis using POS tagger helps us urge a summary of the broader public over a specific topic. For this, we are using the Viterbi algorithm, Hidden Markov Model, Constraint based Viterbi algorithm for POS tagging. By comparing the accuracies, we select the foremost accurate result of the model for Sentiment Analysis for determining the character of the sentence. ",
    "url": "https://arxiv.org/abs/2205.13148",
    "authors": [
      "Surya Teja Chavali",
      "Charan Tej Kandavalli",
      "Sugash T M"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13152",
    "title": "Transferable Adversarial Attack based on Integrated Gradients",
    "abstract": "The vulnerability of deep neural networks to adversarial examples has drawn tremendous attention from the community. Three approaches, optimizing standard objective functions, exploiting attention maps, and smoothing decision surfaces, are commonly used to craft adversarial examples. By tightly integrating the three approaches, we propose a new and simple algorithm named Transferable Attack based on Integrated Gradients (TAIG) in this paper, which can find highly transferable adversarial examples for black-box attacks. Unlike previous methods using multiple computational terms or combining with other methods, TAIG integrates the three approaches into one single term. Two versions of TAIG that compute their integrated gradients on a straight-line path and a random piecewise linear path are studied. Both versions offer strong transferability and can seamlessly work together with the previous methods. Experimental results demonstrate that TAIG outperforms the state-of-the-art methods. The code will available at https://github.com/yihuang2016/TAIG ",
    "url": "https://arxiv.org/abs/2205.13152",
    "authors": [
      "Yi Huang",
      "Adams Wai-Kin Kong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13159",
    "title": "HIRL: A General Framework for Hierarchical Image Representation Learning",
    "abstract": "Learning self-supervised image representations has been broadly studied to boost various visual understanding tasks. Existing methods typically learn a single level of image semantics like pairwise semantic similarity or image clustering patterns. However, these methods can hardly capture multiple levels of semantic information that naturally exists in an image dataset, e.g., the semantic hierarchy of \"Persian cat to cat to mammal\" encoded in an image database for species. It is thus unknown whether an arbitrary image self-supervised learning (SSL) approach can benefit from learning such hierarchical semantics. To answer this question, we propose a general framework for Hierarchical Image Representation Learning (HIRL). This framework aims to learn multiple semantic representations for each image, and these representations are structured to encode image semantics from fine-grained to coarse-grained. Based on a probabilistic factorization, HIRL learns the most fine-grained semantics by an off-the-shelf image SSL approach and learns multiple coarse-grained semantics by a novel semantic path discrimination scheme. We adopt six representative image SSL methods as baselines and study how they perform under HIRL. By rigorous fair comparison, performance gain is observed on all the six methods for diverse downstream tasks, which, for the first time, verifies the general effectiveness of learning hierarchical image semantics. All source code and model weights are available at https://github.com/hirl-team/HIRL ",
    "url": "https://arxiv.org/abs/2205.13159",
    "authors": [
      "Minghao Xu",
      "Yuanfan Guo",
      "Xuanyu Zhu",
      "Jiawen Li",
      "Zhenbang Sun",
      "Jian Tang",
      "Yi Xu",
      "Bingbing Ni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13163",
    "title": "Cost-efficient Gaussian Tensor Network Embeddings for Tensor-structured  Inputs",
    "abstract": "This work discusses tensor network embeddings, which are random matrices ($S$) with tensor network structure. These embeddings have been used to perform dimensionality reduction of tensor network structured inputs $x$ and accelerate applications such as tensor decomposition and kernel regression. Existing works have designed embeddings for inputs $x$ with specific structures, such that the computational cost for calculating $Sx$ is efficient. We provide a systematic way to design tensor network embeddings consisting of Gaussian random tensors, such that for inputs with more general tensor network structures, both the sketch size (row size of $S$) and the sketching computational cost are low. We analyze general tensor network embeddings that can be reduced to a sequence of sketching matrices. We provide a sufficient condition to quantify the accuracy of such embeddings and derive sketching asymptotic cost lower bounds using embeddings that satisfy this condition and have a sketch size lower than any input dimension. We then provide an algorithm to efficiently sketch input data using such embeddings. The sketch size of the embedding used in the algorithm has a linear dependence on the number of sketching dimensions of the input. Assuming tensor contractions are performed with classical dense matrix multiplication algorithms, this algorithm achieves asymptotic cost within a factor of $O(\\sqrt{m})$ of our cost lower bound, where $m$ is the sketch size. Further, when each tensor in the input has a dimension that needs to be sketched, this algorithm yields the optimal sketching asymptotic cost. We apply our sketching analysis to inexact tensor decomposition optimization algorithms. We provide a sketching algorithm for CP decomposition that is asymptotically faster than existing work in multiple regimes, and show optimality of an existing algorithm for tensor train rounding. ",
    "url": "https://arxiv.org/abs/2205.13163",
    "authors": [
      "Linjian Ma",
      "Edgar Solomonik"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13164",
    "title": "Leveraging Dependency Grammar for Fine-Grained Offensive Language  Detection using Graph Convolutional Networks",
    "abstract": "The last few years have witnessed an exponential rise in the propagation of offensive text on social media. Identification of this text with high precision is crucial for the well-being of society. Most of the existing approaches tend to give high toxicity scores to innocuous statements (e.g., \"I am a gay man\"). These false positives result from over-generalization on the training data where specific terms in the statement may have been used in a pejorative sense (e.g., \"gay\"). Emphasis on such words alone can lead to discrimination against the classes these systems are designed to protect. In this paper, we address the problem of offensive language detection on Twitter, while also detecting the type and the target of the offence. We propose a novel approach called SyLSTM, which integrates syntactic features in the form of the dependency parse tree of a sentence and semantic features in the form of word embeddings into a deep learning architecture using a Graph Convolutional Network. Results show that the proposed approach significantly outperforms the state-of-the-art BERT model with orders of magnitude fewer number of parameters. ",
    "url": "https://arxiv.org/abs/2205.13164",
    "authors": [
      "Divyam Goel",
      "Raksha Sharma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13176",
    "title": "On Collective Robustness of Bagging Against Data Poisoning",
    "abstract": "Bootstrap aggregating (bagging) is an effective ensemble protocol, which is believed can enhance robustness by its majority voting mechanism. Recent works further prove the sample-wise robustness certificates for certain forms of bagging (e.g. partition aggregation). Beyond these particular forms, in this paper, \\emph{we propose the first collective certification for general bagging to compute the tight robustness against the global poisoning attack}. Specifically, we compute the maximum number of simultaneously changed predictions via solving a binary integer linear programming (BILP) problem. Then we analyze the robustness of vanilla bagging and give the upper bound of the tolerable poison budget. Based on this analysis, \\emph{we propose hash bagging} to improve the robustness of vanilla bagging almost for free. This is achieved by modifying the random subsampling in vanilla bagging to a hash-based deterministic subsampling, as a way of controlling the influence scope for each poisoning sample universally. Our extensive experiments show the notable advantage in terms of applicability and robustness. ",
    "url": "https://arxiv.org/abs/2205.13176",
    "authors": [
      "Ruoxin Chen",
      "Zenan Li",
      "Jie Li",
      "Chentao Wu",
      "Junchi Yan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.13189",
    "title": "AI for Porosity and Permeability Prediction from Geologic Core X-Ray  Micro-Tomography",
    "abstract": "Geologic cores are rock samples that are extracted from deep under the ground during the well drilling process. They are used for petroleum reservoirs' performance characterization. Traditionally, physical studies of cores are carried out by the means of manual time-consuming experiments. With the development of deep learning, scientists actively started working on developing machine-learning-based approaches to identify physical properties without any manual experiments. Several previous works used machine learning to determine the porosity and permeability of the rocks, but either method was inaccurate or computationally expensive. We are proposing to use self-supervised pretraining of the very small CNN-transformer-based model to predict the physical properties of the rocks with high accuracy in a time-efficient manner. We show that this technique prevents overfitting even for extremely small datasets. ",
    "url": "https://arxiv.org/abs/2205.13189",
    "authors": [
      "Zangir Iklassov",
      "Dmitrii Medvedev",
      "Otabek Nazarov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13191",
    "title": "Orthogonal Stochastic Configuration Networks with Adaptive Construction  Parameter for Data Analytics",
    "abstract": "As a randomized learner model, SCNs are remarkable that the random weights and biases are assigned employing a supervisory mechanism to ensure universal approximation and fast learning. However, the randomness makes SCNs more likely to generate approximate linear correlative nodes that are redundant and low quality, thereby resulting in non-compact network structure. In the light of a fundamental principle in machine learning, that is, a model with fewer parameters holds improved generalization. This paper proposes orthogonal SCN, termed OSCN, to filtrate out the low-quality hidden nodes for network structure reduction by incorporating Gram-Schmidt orthogonalization technology. The universal approximation property of OSCN and an adaptive setting for the key construction parameters have been presented in details. In addition, an incremental updating scheme is developed to dynamically determine the output weights, contributing to improved computational efficiency. Finally, experimental results on two numerical examples and several real-world regression and classification datasets substantiate the effectiveness and feasibility of the proposed approach. ",
    "url": "https://arxiv.org/abs/2205.13191",
    "authors": [
      "Wei Dai",
      "Chuanfeng Ning",
      "Shiyu Pei",
      "Song Zhu",
      "Xuesong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13198",
    "title": "Constellation Design for Non-Coherent Fast-Forward Relays to Mitigate  Full-Duplex Jamming Attacks",
    "abstract": "With potential applications to short-packet communication, we address communication of low-latency messages in fast-fading channels under the presence of a reactive jammer. Unlike a traditional jammer, we assume a full-duplex (FD) jammer capable of detecting pre-existing countermeasures and subsequently changing the target frequency band. To facilitate reliable communication amidst a strong adversary, we propose non-coherent fast-forward full-duplex relaying scheme wherein the victim uses a helper in its vicinity to fast-forward its messages to the base station, in addition to ensuring that the countermeasures are undetected by the FD adversary. Towards designing the constellations for the proposed scheme, we identify that existing non-coherent constellation for fast-fading channels are not applicable owing to the cooperative nature of the fast-forward scheme. As a result, we formulate an optimization problem of designing the non-coherent constellations at the victim and the helper such that the symbol-error-probability at the base station is minimized. We theoretically analyze the optimization problem and propose several strategies to compute near-optimal constellations based on the helper's data-rate and fast-forwarding abilities. We show that the proposed constellations provide near-optimal error performance and help the victim evade jamming. Finally, we also prove the scheme's efficacy in deceiving the countermeasure detectors at the jammer. ",
    "url": "https://arxiv.org/abs/2205.13198",
    "authors": [
      "Vivek Chaudhary",
      "J. Harshan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2205.13199",
    "title": "Decoupled Pyramid Correlation Network for Liver Tumor Segmentation from  CT images",
    "abstract": "Purpose: Automated liver tumor segmentation from Computed Tomography (CT) images is a necessary prerequisite in the interventions of hepatic abnormalities and surgery planning. However, accurate liver tumor segmentation remains challenging due to the large variability of tumor sizes and inhomogeneous texture. Recent advances based on Fully Convolutional Network (FCN) for medical image segmentation drew on the success of learning discriminative pyramid features. In this paper, we propose a Decoupled Pyramid Correlation Network (DPC-Net) that exploits attention mechanisms to fully leverage both low- and high-level features embedded in FCN to segment liver tumor. Methods: We first design a powerful Pyramid Feature Encoder (PFE) to extract multi-level features from input images. Then we decouple the characteristics of features concerning spatial dimension (i.e., height, width, depth) and semantic dimension (i.e., channel). On top of that, we present two types of attention modules, Spatial Correlation (SpaCor) and Semantic Correlation (SemCor) modules, to recursively measure the correlation of multi-level features. The former selectively emphasizes global semantic information in low-level features with the guidance of high-level ones. The latter adaptively enhance spatial details in high-level features with the guidance of low-level ones. Results: We evaluate the DPC-Net on MICCAI 2017 LiTS Liver Tumor Segmentation (LiTS) challenge dataset. Dice Similarity Coefficient (DSC) and Average Symmetric Surface Distance (ASSD) are employed for evaluation. The proposed method obtains a DSC of 76.4% and an ASSD of 0.838 mm for liver tumor segmentation, outperforming the state-of-the-art methods. It also achieves a competitive results with a DSC of 96.0% and an ASSD of 1.636 mm for liver segmentation. ",
    "url": "https://arxiv.org/abs/2205.13199",
    "authors": [
      "Yao Zhang",
      "Jiawei Yang",
      "Yang Liu",
      "Jiang Tian",
      "Siyun Wang",
      "Cheng Zhong",
      "Zhongchao Shi",
      "Yang Zhang",
      "Zhiqiang He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13205",
    "title": "$O(N^2)$ Universal Antisymmetry in Fermionic Neural Networks",
    "abstract": "Fermionic neural network (FermiNet) is a recently proposed wavefunction Ansatz, which is used in variational Monte Carlo (VMC) methods to solve the many-electron Schr\\\"odinger equation. FermiNet proposes permutation-equivariant architectures, on which a Slater determinant is applied to induce antisymmetry. FermiNet is proved to have universal approximation capability with a single determinant, namely, it suffices to represent any antisymmetric function given sufficient parameters. However, the asymptotic computational bottleneck comes from the Slater determinant, which scales with $O(N^3)$ for $N$ electrons. In this paper, we substitute the Slater determinant with a pairwise antisymmetry construction, which is easy to implement and can reduce the computational cost to $O(N^2)$. Furthermore, we formally prove that the pairwise construction built upon permutation-equivariant architectures can universally represent any antisymmetric function. ",
    "url": "https://arxiv.org/abs/2205.13205",
    "authors": [
      "Tianyu Pang",
      "Shuicheng Yan",
      "Min Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2205.13209",
    "title": "Sym-NCO: Leveraging Symmetricity for Neural Combinatorial Optimization",
    "abstract": "Deep reinforcement learning (DRL)-based combinatorial optimization (CO) methods (i.e., DRL-NCO) have shown significant merit over the conventional CO solvers as DRL-NCO is capable of learning CO solvers without supervised labels attained from the verified solver. This paper presents a novel training scheme, Sym-NCO, that achieves significant performance increments to existing DRL-NCO methods. Sym-NCO is a regularizer-based training scheme that leverages universal symmetricities in various CO problems and solutions. Imposing symmetricities such as rotational and reflectional invariance can greatly improve generalization capability of DRL-NCO as symmetricities are invariant features shared by certain CO tasks. Our experimental results verify that our Sym-NCO greatly improves the performance of DRL-NCO methods in four CO tasks, including traveling salesman problem (TSP), capacitated vehicle routing problem (CVRP), prize collecting TSP (PCTSP), and orienteering problem (OP), without employing problem-specific techniques. Remarkably, Sym-NCO outperformed not only the existing DRL-NCO methods but also a competitive conventional solver, the iterative local search (ILS), in PCTSP at 240 times faster speed. ",
    "url": "https://arxiv.org/abs/2205.13209",
    "authors": [
      "Minsu Kim",
      "Junyoung Park",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.13219",
    "title": "Penalizing Proposals using Classifiers for Semi-Supervised Object  Detection",
    "abstract": "Obtaining gold standard annotated data for object detection is often costly, involving human-level effort. Semi-supervised object detection algorithms solve the problem with a small amount of gold-standard labels and a large unlabelled dataset used to generate silver-standard labels. But training on the silver standard labels does not produce good results, because they are machine-generated annotations. In this work, we design a modified loss function to train on large silver standard annotated sets generated by a weak annotator. We include a confidence metric associated with the annotation as an additional term in the loss function, signifying the quality of the annotation. We test the effectiveness of our approach on various test sets and use numerous variations to compare the results with some of the current approaches to object detection. In comparison with the baseline where no confidence metric is used, we achieved a 4\\% gain in mAP with 25\\% labeled data and 10\\% gain in mAP with 50\\% labeled data by using the proposed confidence metric. ",
    "url": "https://arxiv.org/abs/2205.13219",
    "authors": [
      "Somnath Hazra",
      "Pallab Dasgupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13220",
    "title": "DGSVis: Visual Analysis of Hierarchical Snapshots in Dynamic Graph",
    "abstract": "Dynamic graph visualization attracts researchers' concentration as it represents time-varying relationships between entities in multiple domains (e.g., social media analysis, academic cooperation analysis, team sports analysis). Integrating visual analytic methods is consequential in presenting, comparing, and reviewing dynamic graphs. Even though dynamic graph visualization is developed for many years, how to effectively visualize large-scale and time-intensive dynamic graph data with subtle changes is still challenging for researchers. To provide an effective analysis method for this type of dynamic graph data, we propose a snapshot generation algorithm involving Human-In-Loop to help users divide the dynamic graphs into multi-granularity and hierarchical snapshots for further analysis. In addition, we design a visual analysis prototype system (DGSVis) to assist users in accessing the dynamic graph insights effectively. DGSVis integrates a graphical operation interface to help users generate snapshots visually and interactively. It is equipped with the overview and details for visualizing hierarchical snapshots of the dynamic graph data. To illustrate the usability and efficiency of our proposed methods for this type of dynamic graph data, we introduce two case studies based on basketball player networks in a competition. In addition, we conduct an evaluation and receive exciting feedback from experienced visualization experts. ",
    "url": "https://arxiv.org/abs/2205.13220",
    "authors": [
      "Baofeng Chang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13226",
    "title": "Censor-aware Semi-supervised Learning for Survival Time Prediction from  Medical Images",
    "abstract": "Survival time prediction from medical images is important for treatment planning, where accurate estimations can improve healthcare quality. One issue affecting the training of survival models is censored data. Most of the current survival prediction approaches are based on Cox models that can deal with censored data, but their application scope is limited because they output a hazard function instead of a survival time. On the other hand, methods that predict survival time usually ignore censored data, resulting in an under-utilization of the training set. In this work, we propose a new training method that predicts survival time using all censored and uncensored data. We propose to treat censored data as samples with a lower-bound time to death and estimate pseudo labels to semi-supervise a censor-aware survival time regressor. We evaluate our method on pathology and x-ray images from the TCGA-GM and NLST datasets. Our results establish the state-of-the-art survival prediction accuracy on both datasets. ",
    "url": "https://arxiv.org/abs/2205.13226",
    "authors": [
      "Renato Hermoza",
      "Gabriel Maicas",
      "Jacinto C. Nascimento",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13229",
    "title": "Symbiotic Child Emotional Support with Social Robots and Temporal  Knowledge Graphs",
    "abstract": "In current youth-care programs, children with needs (mental health, family issues, learning disabilities, and autism) receive support from youth and family experts as one-to-one assistance at schools or hospitals. Occasionally, social robots have featured in such settings as support roles in a one-to-one interaction with the child. In this paper, we suggest the development of a symbiotic framework for real-time Emotional Support (ES) with social robots Knowledge Graphs (KG). By augmenting a domain-specific corpus from the literature on ES for children (between the age of 8 and 12) and providing scenario-driven context including the history of events, we suggest developing an experimental knowledge-aware ES framework. The framework both guides the social robot in providing ES statements to the child and assists the expert in tracking and interpreting the child's emotional state and related events over time. ",
    "url": "https://arxiv.org/abs/2205.13229",
    "authors": [
      "Isabella Saccardi",
      "Duygu Sezen Islakoglu",
      "Anouk Neerincx",
      "Federica Lucia Vinella"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2205.13234",
    "title": "DT+GNN: A Fully Explainable Graph Neural Network using Decision Trees",
    "abstract": "We propose the fully explainable Decision Tree Graph Neural Network (DT+GNN) architecture. In contrast to existing black-box GNNs and post-hoc explanation methods, the reasoning of DT+GNN can be inspected at every step. To achieve this, we first construct a differentiable GNN layer, which uses a categorical state space for nodes and messages. This allows us to convert the trained MLPs in the GNN into decision trees. These trees are pruned using our newly proposed method to ensure they are small and easy to interpret. We can also use the decision trees to compute traditional explanations. We demonstrate on both real-world datasets and synthetic GNN explainability benchmarks that this architecture works as well as traditional GNNs. Furthermore, we leverage the explainability of DT+GNNs to find interesting insights into many of these datasets, with some surprising results. We also provide an interactive web tool to inspect DT+GNN's decision making. ",
    "url": "https://arxiv.org/abs/2205.13234",
    "authors": [
      "Peter M\u00fcller",
      "Lukas Faber",
      "Karolis Martinkus",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13253",
    "title": "Denial-of-Service Attacks on Learned Image Compression",
    "abstract": "Deep learning techniques have shown promising results in image compression, with competitive bitrate and image reconstruction quality from compressed latent. However, while image compression has progressed towards higher peak signal-to-noise ratio (PSNR) and fewer bits per pixel (bpp), their robustness to corner-case images has never received deliberation. In this work, we, for the first time, investigate the robustness of image compression systems where imperceptible perturbation of input images can precipitate a significant increase in the bitrate of their compressed latent. To characterize the robustness of state-of-the-art learned image compression, we mount white and black-box attacks. Our results on several image compression models with various bitrate qualities show that they are surprisingly fragile, where the white-box attack achieves up to 56.326x and black-box 1.947x bpp change. To improve robustness, we propose a novel model which incorporates attention modules and a basic factorized entropy model, resulting in a promising trade-off between the PSNR/bpp ratio and robustness to adversarial attacks that surpasses existing learned image compressors. ",
    "url": "https://arxiv.org/abs/2205.13253",
    "authors": [
      "Kang Liu",
      "Di Wu",
      "Yiru Wang",
      "Dan Feng",
      "Benjamin Tan",
      "Siddharth Garg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13256",
    "title": "A DLT enabled smart mask system to enable social compliance",
    "abstract": "As Covid-19 remains a cause of concern, especially due to its mutations, wearing masks correctly and efficiently remains a priority in order to limit the spread of the disease. In this paper we present a wearable smart-mask prototype using concepts from Internet of Things, Control Theory and Distributed Ledger Technologies. Its purpose is to encourage people to comply with social distancing norms, through the use of incentives. The smart mask is designed to monitor Carbon Dioxide and Total Volatile Organic Compounds concentrations. The detected data is appended to a DAG-based DLT, named the IOTA Tangle. The IOTA Tangle ensures that the data is secure and immutable and acts as a communication backbone for the incentive mechanism. A hardware-in-the-loop simulation, based on indoor positioning, is developed to validate the effectiveness of the designed prototype. ",
    "url": "https://arxiv.org/abs/2205.13256",
    "authors": [
      "Lianna Zhao",
      "Pietro Ferraro",
      "Robert Shorten"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2205.13265",
    "title": "Privacy-Preserving Wavelet Wavelet Neural Network with Fully Homomorphic  Encryption",
    "abstract": "The main aim of Privacy-Preserving Machine Learning (PPML) is to protect the privacy and provide security to the data used in building Machine Learning models. There are various techniques in PPML such as Secure Multi-Party Computation, Differential Privacy, and Homomorphic Encryption (HE). The techniques are combined with various Machine Learning models and even Deep Learning Networks to protect the data privacy as well as the identity of the user. In this paper, we propose a fully homomorphic encrypted wavelet neural network to protect privacy and at the same time not compromise on the efficiency of the model. We tested the effectiveness of the proposed method on seven datasets taken from the finance and healthcare domains. The results show that our proposed model performs similarly to the unencrypted model. ",
    "url": "https://arxiv.org/abs/2205.13265",
    "authors": [
      "Syed Imtiaz Ahamed",
      "Vadlamani Ravi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13267",
    "title": "Task-Customized Self-Supervised Pre-training with Scalable Dynamic  Routing",
    "abstract": "Self-supervised learning (SSL), especially contrastive methods, has raised attraction recently as it learns effective transferable representations without semantic annotations. A common practice for self-supervised pre-training is to use as much data as possible. For a specific downstream task, however, involving irrelevant data in pre-training may degenerate the downstream performance, observed from our extensive experiments. On the other hand, for existing SSL methods, it is burdensome and infeasible to use different downstream-task-customized datasets in pre-training for different tasks. To address this issue, we propose a novel SSL paradigm called Scalable Dynamic Routing (SDR), which can be trained once and deployed efficiently to different downstream tasks with task-customized pre-trained models. Specifically, we construct the SDRnet with various sub-nets and train each sub-net with only one subset of the data by data-aware progressive training. When a downstream task arrives, we route among all the pre-trained sub-nets to get the best along with its corresponding weights. Experiment results show that our SDR can train 256 sub-nets on ImageNet simultaneously, which provides better transfer performance than a unified model trained on the full ImageNet, achieving state-of-the-art (SOTA) averaged accuracy over 11 downstream classification tasks and AP on PASCAL VOC detection task. ",
    "url": "https://arxiv.org/abs/2205.13267",
    "authors": [
      "Zhili Liu",
      "Jianhua Han",
      "Lanqing Hong",
      "Hang Xu",
      "Kai Chen",
      "Chunjing Xu",
      "Zhenguo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13268",
    "title": "MemeTector: Enforcing deep focus for meme detection",
    "abstract": "Image memes and specifically their widely-known variation image macros, is a special new media type that combines text with images and is used in social media to playfully or subtly express humour, irony, sarcasm and even hate. It is important to accurately retrieve image memes from social media to better capture the cultural and social aspects of online phenomena and detect potential issues (hate-speech, disinformation). Essentially, the background image of an image macro is a regular image easily recognized as such by humans but cumbersome for the machine to do so due to feature map similarity with the complete image macro. Hence, accumulating suitable feature maps in such cases can lead to deep understanding of the notion of image memes. To this end, we propose a methodology that utilizes the visual part of image memes as instances of the regular image class and the initial image memes as instances of the image meme class to force the model to concentrate on the critical parts that characterize an image meme. Additionally, we employ a trainable attention mechanism on top of a standard ViT architecture to enhance the model's ability to focus on these critical parts and make the predictions interpretable. Several training and test scenarios involving web-scraped regular images of controlled text presence are considered in terms of model robustness and accuracy. The findings indicate that light visual part utilization combined with sufficient text presence during training provides the best and most robust model, surpassing state of the art. ",
    "url": "https://arxiv.org/abs/2205.13268",
    "authors": [
      "Christos Koutlis",
      "Manos Schinas",
      "Symeon Papadopoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13273",
    "title": "Acute Lymphoblastic Leukemia Detection Using Hypercomplex-Valued  Convolutional Neural Networks",
    "abstract": "This paper features convolutional neural networks defined on hypercomplex algebras applied to classify lymphocytes in blood smear digital microscopic images. Such classification is helpful for the diagnosis of acute lymphoblast leukemia (ALL), a type of blood cancer. We perform the classification task using eight hypercomplex-valued convolutional neural networks (HvCNNs) along with real-valued convolutional networks. Our results show that HvCNNs perform better than the real-valued model, showcasing higher accuracy with a much smaller number of parameters. Moreover, we found that HvCNNs based on Clifford algebras processing HSV-encoded images attained the highest observed accuracies. Precisely, our HvCNN yielded an average accuracy rate of 96.6% using the ALL-IDB2 dataset with a 50% train-test split, a value extremely close to the state-of-the-art models but using a much simpler architecture with significantly fewer parameters. ",
    "url": "https://arxiv.org/abs/2205.13273",
    "authors": [
      "Guilherme Vieira",
      "Marcos Eduardo Valle"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.13279",
    "title": "Triangular Contrastive Learning on Molecular Graphs",
    "abstract": "Recent contrastive learning methods have shown to be effective in various tasks, learning generalizable representations invariant to data augmentation thereby leading to state of the art performances. Regarding the multifaceted nature of large unlabeled data used in self-supervised learning while majority of real-word downstream tasks use single format of data, a multimodal framework that can train single modality to learn diverse perspectives from other modalities is an important challenge. In this paper, we propose TriCL (Triangular Contrastive Learning), a universal framework for trimodal contrastive learning. TriCL takes advantage of Triangular Area Loss, a novel intermodal contrastive loss that learns the angular geometry of the embedding space through simultaneously contrasting the area of positive and negative triplets. Systematic observation on embedding space in terms of alignment and uniformity showed that Triangular Area Loss can address the line-collapsing problem by discriminating modalities by angle. Our experimental results also demonstrate the outperformance of TriCL on downstream task of molecular property prediction which implies that the advantages of the embedding space indeed benefits the performance on downstream tasks. ",
    "url": "https://arxiv.org/abs/2205.13279",
    "authors": [
      "MinGyu Choi",
      "Wonseok Shin",
      "Yijingxiu Lu",
      "Sun Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13280",
    "title": "Objects Matter: Learning Object Relation Graph for Robust Camera  Relocalization",
    "abstract": "Visual relocalization aims to estimate the pose of a camera from one or more images. In recent years deep learning based pose regression methods have attracted many attentions. They feature predicting the absolute poses without relying on any prior built maps or stored images, making the relocalization very efficient. However, robust relocalization under environments with complex appearance changes and real dynamics remains very challenging. In this paper, we propose to enhance the distinctiveness of the image features by extracting the deep relationship among objects. In particular, we extract objects in the image and construct a deep object relation graph (ORG) to incorporate the semantic connections and relative spatial clues of the objects. We integrate our ORG module into several popular pose regression models. Extensive experiments on various public indoor and outdoor datasets demonstrate that our method improves the performance significantly and outperforms the previous approaches. ",
    "url": "https://arxiv.org/abs/2205.13280",
    "authors": [
      "Chengyu Qiao",
      "Zhiyu Xiang",
      "Xinglu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13283",
    "title": "Embedding Principle in Depth for the Loss Landscape Analysis of Deep  Neural Networks",
    "abstract": "Unraveling the general structure underlying the loss landscapes of deep neural networks (DNNs) is important for the theoretical study of deep learning. Inspired by the embedding principle of DNN loss landscape, we prove in this work an embedding principle in depth that loss landscape of an NN \"contains\" all critical points of the loss landscapes for shallower NNs. Specifically, we propose a critical lifting operator that any critical point of a shallower network can be lifted to a critical manifold of the target network while preserving the outputs. Through lifting, local minimum of an NN can become a strict saddle point of a deeper NN, which can be easily escaped by first-order methods. The embedding principle in depth reveals a large family of critical points in which layer linearization happens, i.e., computation of certain layers is effectively linear for the training inputs. We empirically demonstrate that, through suppressing layer linearization, batch normalization helps avoid the lifted critical manifolds, resulting in a faster decay of loss. We also demonstrate that increasing training data reduces the lifted critical manifold thus could accelerate the training. Overall, the embedding principle in depth well complements the embedding principle (in width), resulting in a complete characterization of the hierarchical structure of critical points/manifolds of a DNN loss landscape. ",
    "url": "https://arxiv.org/abs/2205.13283",
    "authors": [
      "Zhiwei Bai",
      "Tao Luo",
      "Zhi-Qin John Xu",
      "Yaoyu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13296",
    "title": "Social Interpretable Tree for Pedestrian Trajectory Prediction",
    "abstract": "Understanding the multiple socially-acceptable future behaviors is an essential task for many vision applications. In this paper, we propose a tree-based method, termed as Social Interpretable Tree (SIT), to address this multi-modal prediction task, where a hand-crafted tree is built depending on the prior information of observed trajectory to model multiple future trajectories. Specifically, a path in the tree from the root to leaf represents an individual possible future trajectory. SIT employs a coarse-to-fine optimization strategy, in which the tree is first built by high-order velocity to balance the complexity and coverage of the tree and then optimized greedily to encourage multimodality. Finally, a teacher-forcing refining operation is used to predict the final fine trajectory. Compared with prior methods which leverage implicit latent variables to represent possible future trajectories, the path in the tree can explicitly explain the rough moving behaviors (e.g., go straight and then turn right), and thus provides better interpretability. Despite the hand-crafted tree, the experimental results on ETH-UCY and Stanford Drone datasets demonstrate that our method is capable of matching or exceeding the performance of state-of-the-art methods. Interestingly, the experiments show that the raw built tree without training outperforms many prior deep neural network based approaches. Meanwhile, our method presents sufficient flexibility in long-term prediction and different best-of-$K$ predictions. ",
    "url": "https://arxiv.org/abs/2205.13296",
    "authors": [
      "Liushuai Shi",
      "Le Wang",
      "Chengjiang Long",
      "Sanping Zhou",
      "Fang Zheng",
      "Nanning Zheng",
      "Gang Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13299",
    "title": "Federated Split BERT for Heterogeneous Text Classification",
    "abstract": "Pre-trained BERT models have achieved impressive performance in many natural language processing (NLP) tasks. However, in many real-world situations, textual data are usually decentralized over many clients and unable to be uploaded to a central server due to privacy protection and regulations. Federated learning (FL) enables multiple clients collaboratively to train a global model while keeping the local data privacy. A few researches have investigated BERT in federated learning setting, but the problem of performance loss caused by heterogeneous (e.g., non-IID) data over clients remain under-explored. To address this issue, we propose a framework, FedSplitBERT, which handles heterogeneous data and decreases the communication cost by splitting the BERT encoder layers into local part and global part. The local part parameters are trained by the local client only while the global part parameters are trained by aggregating gradients of multiple clients. Due to the sheer size of BERT, we explore a quantization method to further reduce the communication cost with minimal performance loss. Our framework is ready-to-use and compatible to many existing federated learning algorithms, including FedAvg, FedProx and FedAdam. Our experiments verify the effectiveness of the proposed framework, which outperforms baseline methods by a significant margin, while FedSplitBERT with quantization can reduce the communication cost by $11.9\\times$. ",
    "url": "https://arxiv.org/abs/2205.13299",
    "authors": [
      "Zhengyang Li",
      "Shijing Si",
      "Jianzong Wang",
      "Jing Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13313",
    "title": "Cross-Architecture Self-supervised Video Representation Learning",
    "abstract": "In this paper, we present a new cross-architecture contrastive learning (CACL) framework for self-supervised video representation learning. CACL consists of a 3D CNN and a video transformer which are used in parallel to generate diverse positive pairs for contrastive learning. This allows the model to learn strong representations from such diverse yet meaningful pairs. Furthermore, we introduce a temporal self-supervised learning module able to predict an Edit distance explicitly between two video sequences in the temporal order. This enables the model to learn a rich temporal representation that compensates strongly to the video-level representation learned by the CACL. We evaluate our method on the tasks of video retrieval and action recognition on UCF101 and HMDB51 datasets, where our method achieves excellent performance, surpassing the state-of-the-art methods such as VideoMoCo and MoCo+BE by a large margin. The code is made available at https://github.com/guoshengcv/CACL. ",
    "url": "https://arxiv.org/abs/2205.13313",
    "authors": [
      "Sheng Guo",
      "Zihua Xiong",
      "Yujie Zhong",
      "Limin Wang",
      "Xiaobo Guo",
      "Bing Han",
      "Weilin Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13316",
    "title": "Fair Representation Learning through Implicit Path Alignment",
    "abstract": "We consider a fair representation learning perspective, where optimal predictors, on top of the data representation, are ensured to be invariant with respect to different sub-groups. Specifically, we formulate this intuition as a bi-level optimization, where the representation is learned in the outer-loop, and invariant optimal group predictors are updated in the inner-loop. Moreover, the proposed bi-level objective is demonstrated to fulfill the sufficiency rule, which is desirable in various practical scenarios but was not commonly studied in the fair learning. Besides, to avoid the high computational and memory cost of differentiating in the inner-loop of bi-level objective, we propose an implicit path alignment algorithm, which only relies on the solution of inner optimization and the implicit differentiation rather than the exact optimization path. We further analyze the error gap of the implicit approach and empirically validate the proposed method in both classification and regression settings. Experimental results show the consistently better trade-off in prediction performance and fairness measurement. ",
    "url": "https://arxiv.org/abs/2205.13316",
    "authors": [
      "Changjian Shui",
      "Qi Chen",
      "Jiaqi Li",
      "Boyu Wang",
      "Christian Gagn\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.13322",
    "title": "DoS Attacks on Blockchain Ecosystem",
    "abstract": "Denial of Service (DoS) attacks are a growing threat in network services. The frequency and intensity of DoS attacks are rapidly increasing day by day. The immense financial potential of the Cryptocurrency market is a prevalent target of the DoS attack. The DoS attack events are kept on happening in cryptocurrencies and the blockchain ecosystem. To the best of our knowledge, there has not been any study on the DoS attack on the blockchain ecosystem. In this paper, we identify ten entities in the blockchain ecosystem and we scrutinize the DoS attacks on them. We also present the DoS mitigation techniques applicable to the blockchain services. Additionally, we propose a DoS mitigation technique by the use of verifiable delay function (VDF). ",
    "url": "https://arxiv.org/abs/2205.13322",
    "authors": [
      "Mayank Raikwar",
      "Danilo Gligoroski"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.13326",
    "title": "SHREC 2022: pothole and crack detection in the road pavement using  images and RGB-D data",
    "abstract": "This paper describes the methods submitted for evaluation to the SHREC 2022 track on pothole and crack detection in the road pavement. A total of 7 different runs for the semantic segmentation of the road surface are compared, 6 from the participants plus a baseline method. All methods exploit Deep Learning techniques and their performance is tested using the same environment (i.e.: a single Jupyter notebook). A training set, composed of 3836 semantic segmentation image/mask pairs and 797 RGB-D video clips collected with the latest depth cameras was made available to the participants. The methods are then evaluated on the 496 image/mask pairs in the validation set, on the 504 pairs in the test set and finally on 8 video clips. The analysis of the results is based on quantitative metrics for image segmentation and qualitative analysis of the video clips. The participation and the results show that the scenario is of great interest and that the use of RGB-D data is still challenging in this context. ",
    "url": "https://arxiv.org/abs/2205.13326",
    "authors": [
      "Elia Moscoso Thompson",
      "Andrea Ranieri",
      "Silvia Biasotti",
      "Miguel Chicchon",
      "Ivan Sipiran",
      "Minh-Khoi Pham",
      "Thang-Long Nguyen-Ho",
      "Hai-Dang Nguyen",
      "Minh-Triet Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2205.13328",
    "title": "How Powerful are K-hop Message Passing Graph Neural Networks",
    "abstract": "The most popular design paradigm for Graph Neural Networks (GNNs) is 1-hop message passing -- aggregating features from 1-hop neighbors repeatedly. However, the expressive power of 1-hop message passing is bounded by the Weisfeiler-Lehman (1-WL) test. Recently, researchers extended 1-hop message passing to K-hop message passing by aggregating information from K-hop neighbors of nodes simultaneously. However, there is no work on analyzing the expressive power of K-hop message passing. In this work, we theoretically characterize the expressive power of K-hop message passing. Specifically, we first formally differentiate two kinds of kernels of K-hop message passing which are often misused in previous works. We then characterize the expressive power of K-hop message passing by showing that it is more powerful than 1-hop message passing. Despite the higher expressive power, we show that K-hop message passing still cannot distinguish some simple regular graphs. To further enhance its expressive power, we introduce a KP-GNN framework, which improves K-hop message passing by leveraging the peripheral subgraph information in each hop. We prove that KP-GNN can distinguish almost all regular graphs including some distance regular graphs which could not be distinguished by previous distance encoding methods. Experimental results verify the expressive power and effectiveness of KP-GNN. KP-GNN achieves competitive results across all benchmark datasets. ",
    "url": "https://arxiv.org/abs/2205.13328",
    "authors": [
      "Jiarui Feng",
      "Yixin Chen",
      "Fuhai Li",
      "Anindya Sarkar",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13342",
    "title": "Leveraging Causal Inference for Explainable Automatic Program Repair",
    "abstract": "Deep learning models have made significant progress in automatic program repair. However, the black-box nature of these methods has restricted their practical applications. To address this challenge, this paper presents an interpretable approach for program repair based on sequence-to-sequence models with causal inference and our method is called CPR, short for causal program repair. Our CPR can generate explanations in the process of decision making, which consists of groups of causally related input-output tokens. Firstly, our method infers these relations by querying the model with inputs disturbed by data augmentation. Secondly, it generates a graph over tokens from the responses and solves a partitioning problem to select the most relevant components. The experiments on four programming languages (Java, C, Python, and JavaScript) show that CPR can generate causal graphs for reasonable interpretations and boost the performance of bug fixing in automatic program repair. ",
    "url": "https://arxiv.org/abs/2205.13342",
    "authors": [
      "Jianzong Wang",
      "Shijing Si",
      "Zhitao Zhu",
      "Xiaoyang Qu",
      "Zhenhou Hong",
      "Jing Xiao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.13343",
    "title": "Sliding mode control with a neural network compensation scheme for  electro-hydraulic systems",
    "abstract": "Electro-hydraulic servo-systems are widely employed in industrial applications such as robotic manipulators, active suspensions, precision machine tools and aerospace systems. They provide many advantages over electric motors, including high force to weight ratio, fast response time and compact size. However, precise control of electro-hydraulic systems, due to their inherent nonlinear characteristics, cannot be easily obtained with conventional linear controllers. Most flow control valves can also exhibit some hard nonlinearities such as dead-zone due to valve spool overlap. This work describes the development of a sliding mode controller with a neural network compensation scheme for electro-hydraulic systems subject to an unknown dead-zone input. The boundedness and convergence properties of the closed-loop signals are proven using Lyapunov stability theory. Numerical results are presented in order to demonstrate the control system performance. ",
    "url": "https://arxiv.org/abs/2205.13343",
    "authors": [
      "Josiane Maria de Macedo Fernandes",
      "Marcelo Costa Tanaka",
      "Wallace Moreira Bessa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2205.13344",
    "title": "A neural network based controller for underwater robotic vehicles",
    "abstract": "Due to the enormous technological improvements obtained in the last decades it is possible to use robotic vehicles for underwater exploration. This work describes the development of a dynamic positioning system for remotely operated underwater vehicles based. The adopted approach is developed using Lyapunov Stability Theory and enhanced by a neural network based algorithm for uncertainty and disturbance compensation. The performance of the proposed control scheme is evaluated by means of numerical simulations. ",
    "url": "https://arxiv.org/abs/2205.13344",
    "authors": [
      "Josiane Maria Macedo Fernandes",
      "Marcelo Costa Tanaka",
      "Raimundo Carlos Silv\u00e9rio Freire J\u00fanior",
      "Wallace Moreira Bessa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.13359",
    "title": "Feature Forgetting in Continual Representation Learning",
    "abstract": "In continual and lifelong learning, good representation learning can help increase performance and reduce sample complexity when learning new tasks. There is evidence that representations do not suffer from \"catastrophic forgetting\" even in plain continual learning, but little further fact is known about its characteristics. In this paper, we aim to gain more understanding about representation learning in continual learning, especially on the feature forgetting problem. We devise a protocol for evaluating representation in continual learning, and then use it to present an overview of the basic trends of continual representation learning, showing its consistent deficiency and potential issues. To study the feature forgetting problem, we create a synthetic dataset to identify and visualize the prevalence of feature forgetting in neural networks. Finally, we propose a simple technique using gating adapters to mitigate feature forgetting. We conclude by discussing that improving representation learning benefits both old and new tasks in continual learning. ",
    "url": "https://arxiv.org/abs/2205.13359",
    "authors": [
      "Xiao Zhang",
      "Dejing Dou",
      "Ji Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13366",
    "title": "Minimization of THD in Nine Level Cascaded H-Bridge Inverter Using  Artificial Neural Network",
    "abstract": "Multilevel inverter converts different level DC voltage to AC voltage. It has wide interest in power industry especially in high power applications. In power electronic equipment the major drawback is the harmonics. Several control strategies are available to reduce the harmonic content and the most widely used measure of Total Harmonic Distortion (THD). In this project, the comparison has been made for the open loop and closed loop PI controller and neural network that predict the switching angle in order to reduce the harmonics. The mapping between Modulation Index and Switching angles are plotted for the forward neural network. After the prediction of switching angles the neural network topologies are executed for better result. This technique is applied for any type of multilevel inverter, Cascaded H-Bridge multilevel inverter is chosen. A nine level Cascaded H-Bridge multilevel inverter power circuit is simulated in MATLAB 8.3 simulink with sinusoidal PWM technique. The comparison results reveal that the THD is reduced to about 3% with neural network control compared to open loop control. The results are presented and analyzed. ",
    "url": "https://arxiv.org/abs/2205.13366",
    "authors": [
      "Manoj Mathews",
      "B. Ramesh",
      "T. Sreedhar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Instrumentation and Detectors (physics.ins-det)"
    ]
  },
  {
    "id": "arXiv:2205.13371",
    "title": "A Rotated Hyperbolic Wrapped Normal Distribution for Hierarchical  Representation Learning",
    "abstract": "We present a rotated hyperbolic wrapped normal distribution (RoWN), a simple yet effective alteration of a hyperbolic wrapped normal distribution (HWN). The HWN expands the domain of probabilistic modeling from Euclidean to hyperbolic space, where a tree can be embedded with arbitrary low distortion in theory. In this work, we analyze the geometric properties of the diagonal HWN, a standard choice of distribution in probabilistic modeling. The analysis shows that the distribution is inappropriate to represent the data points at the same hierarchy level through their angular distance with the same norm in the Poincar\\'e disk model. We then empirically verify the presence of limitations of HWN, and show how RoWN, the newly proposed distribution, can alleviate the limitations on various hierarchical datasets, including noisy synthetic binary tree, WordNet, and Atari 2600 Breakout. ",
    "url": "https://arxiv.org/abs/2205.13371",
    "authors": [
      "Seunghyuk Cho",
      "Juyong Lee",
      "Jaesik Park",
      "Dongwoo Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13383",
    "title": "BppAttack: Stealthy and Efficient Trojan Attacks against Deep Neural  Networks via Image Quantization and Contrastive Adversarial Learning",
    "abstract": "Deep neural networks are vulnerable to Trojan attacks. Existing attacks use visible patterns (e.g., a patch or image transformations) as triggers, which are vulnerable to human inspection. In this paper, we propose stealthy and efficient Trojan attacks, BppAttack. Based on existing biology literature on human visual systems, we propose to use image quantization and dithering as the Trojan trigger, making imperceptible changes. It is a stealthy and efficient attack without training auxiliary models. Due to the small changes made to images, it is hard to inject such triggers during training. To alleviate this problem, we propose a contrastive learning based approach that leverages adversarial attacks to generate negative sample pairs so that the learned trigger is precise and accurate. The proposed method achieves high attack success rates on four benchmark datasets, including MNIST, CIFAR-10, GTSRB, and CelebA. It also effectively bypasses existing Trojan defenses and human inspection. Our code can be found in https://github.com/RU-System-Software-and-Security/BppAttack. ",
    "url": "https://arxiv.org/abs/2205.13383",
    "authors": [
      "Zhenting Wang",
      "Juan Zhai",
      "Shiqing Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13384",
    "title": "Continual Learning for Visual Search with Backward Consistent Feature  Embedding",
    "abstract": "In visual search, the gallery set could be incrementally growing and added to the database in practice. However, existing methods rely on the model trained on the entire dataset, ignoring the continual updating of the model. Besides, as the model updates, the new model must re-extract features for the entire gallery set to maintain compatible feature space, imposing a high computational cost for a large gallery set. To address the issues of long-term visual search, we introduce a continual learning (CL) approach that can handle the incrementally growing gallery set with backward embedding consistency. We enforce the losses of inter-session data coherence, neighbor-session model coherence, and intra-session discrimination to conduct a continual learner. In addition to the disjoint setup, our CL solution also tackles the situation of increasingly adding new classes for the blurry boundary without assuming all categories known in the beginning and during model update. To our knowledge, this is the first CL method both tackling the issue of backward-consistent feature embedding and allowing novel classes to occur in the new sessions. Extensive experiments on various benchmarks show the efficacy of our approach under a wide range of setups. ",
    "url": "https://arxiv.org/abs/2205.13384",
    "authors": [
      "Timmy S. T. Wan",
      "Jun-Cheng Chen",
      "Tzer-Yi Wu",
      "Chu-Song Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13411",
    "title": "Exponential Random Graph Models for Dynamic Signed Networks: An  Application to International Relations",
    "abstract": "Substantive research in the Social Sciences regularly investigates signed networks, where edges between actors are either positive or negative. For instance, schoolchildren can be friends or rivals, just as countries can cooperate or fight each other. This research often builds on structural balance theory, one of the earliest and most prominent network theories, making signed networks one of the most frequently studied matters in social network analysis. While the theorization and description of signed networks have thus made significant progress, the inferential study of tie formation within them remains limited in the absence of appropriate statistical models. In this paper we fill this gap by proposing the Signed Exponential Random Graph Model (SERGM), extending the well-known Exponential Random Graph Model (ERGM) to networks where ties are not binary but negative or positive if a tie exists. Since most networks are dynamically evolving systems, we specify the model for both cross-sectional and dynamic networks. Based on structural hypotheses derived from structural balance theory, we formulate interpretable signed network statistics, capturing dynamics such as \"the enemy of my enemy is my friend\". In our empirical application, we use the SERGM to analyze cooperation and conflict between countries within the international state system. ",
    "url": "https://arxiv.org/abs/2205.13411",
    "authors": [
      "Cornelius Fritz",
      "Marius Mehrl",
      "Paul W. Thurner",
      "G\u00f6ran kauermann"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2205.13412",
    "title": "A Physical-World Adversarial Attack Against 3D Face Recognition",
    "abstract": "3D face recognition systems have been widely employed in intelligent terminals, among which structured light imaging is a common method to measure the 3D shape. However, this method could be easily attacked, leading to inaccurate 3D face recognition. In this paper, we propose a novel, physically-achievable attack on the fringe structured light system, named structured light attack. The attack utilizes a projector to project optical adversarial fringes on faces to generate point clouds with well-designed noises. We firstly propose a 3D transform-invariant loss function to enhance the robustness of 3D adversarial examples in the physical-world attack. Then we reverse the 3D adversarial examples to the projector's input to place noises on phase-shift images, which models the process of structured light imaging. A real-world structured light system is constructed for the attack and several state-of-the-art 3D face recognition neural networks are tested. Experiments show that our method can attack the physical system successfully and only needs minor modifications of projected images. ",
    "url": "https://arxiv.org/abs/2205.13412",
    "authors": [
      "Yanjie Li",
      "Yiquan Li",
      "Bin Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.13426",
    "title": "AntiBenford Subgraphs: Unsupervised Anomaly Detection in Financial  Networks",
    "abstract": "Benford's law describes the distribution of the first digit of numbers appearing in a wide variety of numerical data, including tax records, and election outcomes, and has been used to raise \"red flags\" about potential anomalies in the data such as tax evasion. In this work, we ask the following novel question: given a large transaction or financial graph, how do we find a set of nodes that perform many transactions among each other that also deviate significantly from Benford's law? We propose the AntiBenford subgraph framework that is founded on well-established statistical principles. Furthermore, we design an efficient algorithm that finds AntiBenford subgraphs in near-linear time on real data. We evaluate our framework on both real and synthetic data against a variety of competitors. We show empirically that our proposed framework enables the detection of anomalous subgraphs in cryptocurrency transaction networks that go undetected by state-of-the-art graph-based anomaly detection methods. Our empirical findings show that our \\ab framework is able to mine anomalous subgraphs, and provide novel insights into financial transaction data. The code and the datasets are available at \\url{https://github.com/tsourakakis-lab/antibenford-subgraphs}. ",
    "url": "https://arxiv.org/abs/2205.13426",
    "authors": [
      "Tianyi Chen",
      "Charalampos E. Tsourakakis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2205.13431",
    "title": "Sub-Rate Linear Network Coding",
    "abstract": "Increasing network utilization is often considered as the holy grail of communications. In this article, the concept of sub-rate coding and decoding in the framework of linear network coding (LNC) is discussed for single-source multiple-sinks finite acyclic networks. Sub-rate coding offers an add-on to existing LNC. It allows sinks whose max-flow is smaller than the source message-rate, termed \\emph{sub-rate sinks}, to decode a portion of the transmitted message without degrading the maximum achievable rate of LNC sinks whose max-flow is equal (or greater) than the rate of the source node. The article studies theoretical aspects of sub-rate coding by formulating the conditions a node (and indeed the network) must fulfill so as to qualify as a legitimate sub-rate sink. ",
    "url": "https://arxiv.org/abs/2205.13431",
    "authors": [
      "Ben Grinboim",
      "Itay Shrem",
      "Ofer Amrani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.13447",
    "title": "Probabilistic failure mechanisms via Monte Carlo simulations of complex  microstructures",
    "abstract": "A probabilistic approach to phase-field brittle and ductile fracture with random material and geometric properties is proposed within this work. In the macroscopic failure mechanics, materials properties and exactness of spatial quantities (of different phases in the geometrical domain) are assumed to be homogeneous and deterministic. This is unlike the lower-scale with strong fluctuation in the material and geometrical properties. Such a response is approximated through some uncertainty in the model problem. The presented contribution is devoted to providing a mathematical framework for modeling uncertainty through stochastic analysis of a microstructure undergoing brittle/ductile failure. Hereby, the proposed model employs various representative volume elements with random distribution of stiff-inclusions and voids within the composite structure. We develop an allocating strategy to allocate the heterogeneities and generate the corresponding meshes in two- and three-dimensional cases. Then the Monte Carlo finite element technique is employed for solving the stochastic PDE-based model and approximate the expectation and the variance of the solution field of brittle/ductile failure by evaluating a large number of samples. For the prediction of failure mechanisms, we rely on the phase-field approach which is a widely adopted framework for modeling and computing the fracture phenomena in solids. Incremental perturbed minimization principles for a class of gradient-type dissipative materials are used to derive the perturbed governing equations. This analysis enables us to study the highly heterogeneous microstructure and monitor the uncertainty in failure mechanics. Several numerical examples are given to examine the efficiency of the proposed method. ",
    "url": "https://arxiv.org/abs/2205.13447",
    "authors": [
      "Nima Noii",
      "Amirreza Khodadadian",
      "Fadi Aldakheel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2205.13451",
    "title": "Follow-the-Perturbed-Leader for Adversarial Markov Decision Processes  with Bandit Feedback",
    "abstract": "We consider regret minimization for Adversarial Markov Decision Processes (AMDPs), where the loss functions are changing over time and adversarially chosen, and the learner only observes the losses for the visited state-action pairs (i.e., bandit feedback). While there has been a surge of studies on this problem using Online-Mirror-Descent (OMD) methods, very little is known about the Follow-the-Perturbed-Leader (FTPL) methods, which are usually computationally more efficient and also easier to implement since it only requires solving an offline planning problem. Motivated by this, we take a closer look at FTPL for learning AMDPs, starting from the standard episodic finite-horizon setting. We find some unique and intriguing difficulties in the analysis and propose a workaround to eventually show that FTPL is also able to achieve near-optimal regret bounds in this case. More importantly, we then find two significant applications: First, the analysis of FTPL turns out to be readily generalizable to delayed bandit feedback with order-optimal regret, while OMD methods exhibit extra difficulties (Jin et al., 2022). Second, using FTPL, we also develop the first no-regret algorithm for learning communicating AMDPs in the infinite-horizon setting with bandit feedback and stochastic transitions. Our algorithm is efficient assuming access to an offline planning oracle, while even for the easier full-information setting, the only existing algorithm (Chandrasekaran and Tewari, 2021) is computationally inefficient. ",
    "url": "https://arxiv.org/abs/2205.13451",
    "authors": [
      "Yan Dai",
      "Haipeng Luo",
      "Liyu Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.13462",
    "title": "FedAug: Reducing the Local Learning Bias Improves Federated Learning on  Heterogeneous Data",
    "abstract": "Federated Learning (FL) is a machine learning paradigm that learns from data kept locally to safeguard the privacy of clients, whereas local SGD is typically employed on the clients' devices to improve communication efficiency. However, such a scheme is currently constrained by the slow and unstable convergence induced by clients' heterogeneous data. In this work, we identify three under-explored phenomena of the biased local learning that may explain these challenges caused by local updates in supervised FL. As a remedy, we propose FedAug, a novel unified algorithm that reduces the local learning bias on features and classifiers to tackle these challenges. FedAug consists of two components: AugMean and AugCA. AugMean alleviates the bias in the local classifiers by balancing the output distribution of models. AugCA learns client invariant features that are close to global features but considerably distinct from those learned from other input distributions. In a series of experiments, we show that FedAug consistently outperforms other SOTA FL and domain generalization (DG) baselines, in which both two components (i.e., AugMean and AugCA) have individual performance gains. ",
    "url": "https://arxiv.org/abs/2205.13462",
    "authors": [
      "Yongxin Guo",
      "Tao Lin",
      "Xiaoying Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13474",
    "title": "2D versus 3D Convolutional Spiking Neural Networks Trained with  Unsupervised STDP for Human Action Recognition",
    "abstract": "Current advances in technology have highlighted the importance of video analysis in the domain of computer vision. However, video analysis has considerably high computational costs with traditional artificial neural networks (ANNs). Spiking neural networks (SNNs) are third generation biologically plausible models that process the information in the form of spikes. Unsupervised learning with SNNs using the spike timing dependent plasticity (STDP) rule has the potential to overcome some bottlenecks of regular artificial neural networks, but STDP-based SNNs are still immature and their performance is far behind that of ANNs. In this work, we study the performance of SNNs when challenged with the task of human action recognition, because this task has many real-time applications in computer vision, such as video surveillance. In this paper we introduce a multi-layered 3D convolutional SNN model trained with unsupervised STDP. We compare the performance of this model to those of a 2D STDP-based SNN when challenged with the KTH and Weizmann datasets. We also compare single-layer and multi-layer versions of these models in order to get an accurate assessment of their performance. We show that STDP-based convolutional SNNs can learn motion patterns using 3D kernels, thus enabling motion-based recognition from videos. Finally, we give evidence that 3D convolution is superior to 2D convolution with STDP-based SNNs, especially when dealing with long video sequences. ",
    "url": "https://arxiv.org/abs/2205.13474",
    "authors": [
      "Mireille El-Assal",
      "Pierre Tirilly",
      "Ioan Marius Bilasco"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13476",
    "title": "Embed to Control Partially Observed Systems: Representation Learning  with Provable Sample Efficiency",
    "abstract": "Reinforcement learning in partially observed Markov decision processes (POMDPs) faces two challenges. (i) It often takes the full history to predict the future, which induces a sample complexity that scales exponentially with the horizon. (ii) The observation and state spaces are often continuous, which induces a sample complexity that scales exponentially with the extrinsic dimension. Addressing such challenges requires learning a minimal but sufficient representation of the observation and state histories by exploiting the structure of the POMDP. To this end, we propose a reinforcement learning algorithm named Embed to Control (ETC), which learns the representation at two levels while optimizing the policy.~(i) For each step, ETC learns to represent the state with a low-dimensional feature, which factorizes the transition kernel. (ii) Across multiple steps, ETC learns to represent the full history with a low-dimensional embedding, which assembles the per-step feature. We integrate (i) and (ii) in a unified framework that allows a variety of estimators (including maximum likelihood estimators and generative adversarial networks). For a class of POMDPs with a low-rank structure in the transition kernel, ETC attains an $O(1/\\epsilon^2)$ sample complexity that scales polynomially with the horizon and the intrinsic dimension (that is, the rank). Here $\\epsilon$ is the optimality gap. To our best knowledge, ETC is the first sample-efficient algorithm that bridges representation learning and policy optimization in POMDPs with infinite observation and state spaces. ",
    "url": "https://arxiv.org/abs/2205.13476",
    "authors": [
      "Lingxiao Wang",
      "Qi Cai",
      "Zhuoran Yang",
      "Zhaoran Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.13479",
    "title": "Learning to Reconstruct Missing Data from Spatiotemporal Graphs with  Sparse Observations",
    "abstract": "Modeling multivariate time series as temporal signals over a (possibly dynamic) graph is an effective representational framework that allows for developing models for time series analysis. In fact, discrete sequences of graphs can be processed by autoregressive graph neural networks to recursively learn representations at each discrete point in time and space. Spatiotemporal graphs are often highly sparse, with time series characterized by multiple, concurrent, and even long sequences of missing data, e.g., due to the unreliable underlying sensor network. In this context, autoregressive models can be brittle and exhibit unstable learning dynamics. The objective of this paper is, then, to tackle the problem of learning effective models to reconstruct, i.e., impute, missing data points by conditioning the reconstruction only on the available observations. In particular, we propose a novel class of attention-based architectures that, given a set of highly sparse discrete observations, learn a representation for points in time and space by exploiting a spatiotemporal diffusion architecture aligned with the imputation task. Representations are trained end-to-end to reconstruct observations w.r.t. the corresponding sensor and its neighboring nodes. Compared to the state of the art, our model handles sparse data without propagating prediction errors or requiring a bidirectional model to encode forward and backward time dependencies. Empirical results on representative benchmarks show the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2205.13479",
    "authors": [
      "Ivan Marisca",
      "Andrea Cini",
      "Cesare Alippi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13481",
    "title": "DeepJoint: Robust Survival Modelling Under Clinical Presence Shift",
    "abstract": "Observational data in medicine arise as a result of the complex interaction between patients and the healthcare system. The sampling process is often highly irregular and itself constitutes an informative process. When using such data to develop prediction models, this phenomenon is often ignored, leading to sub-optimal performance and generalisability of models when practices evolve. We propose a multi-task recurrent neural network which models three clinical presence dimensions -- namely the longitudinal, the inter-observation and the missingness processes -- in parallel to the survival outcome. On a prediction task using MIMIC III laboratory tests, explicit modelling of these three processes showed improved performance in comparison to state-of-the-art predictive models (C-index at 1 day horizon: 0.878). More importantly, the proposed approach was more robust to change in the clinical presence setting, demonstrated by performance comparison between patients admitted on weekdays and weekends. This analysis demonstrates the importance of studying and leveraging clinical presence to improve performance and create more transportable clinical models. ",
    "url": "https://arxiv.org/abs/2205.13481",
    "authors": [
      "Vincent Jeanselme",
      "Glen Martin",
      "Niels Peek",
      "Matthew Sperrin",
      "Brian Tom",
      "Jessica Barrett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13492",
    "title": "Sparse Graph Learning for Spatiotemporal Time Series",
    "abstract": "Outstanding achievements of graph neural networks for spatiotemporal time series prediction show that relational constraints introduce a positive inductive bias into neural forecasting architectures. Often, however, the relational information characterizing the underlying data generating process is unavailable; the practitioner is then left with the problem of inferring from data which relational graph to use in the subsequent processing stages. We propose novel, principled -- yet practical -- probabilistic methods that learn the relational dependencies by modeling distributions over graphs while maximizing, at the same time, end-to-end the forecasting accuracy. Our novel graph learning approach, based on consolidated variance reduction techniques for Monte Carlo score-based gradient estimation, is theoretically grounded and effective. We show that tailoring the gradient estimators to the graph learning problem allows us also for achieving state-of-the-art forecasting performance while controlling, at the same time, both the sparsity of the learned graph and the computational burden. We empirically assess the effectiveness of the proposed method on synthetic and real-world benchmarks, showing that the proposed solution can be used as a stand-alone graph identification procedure as well as a learned component of an end-to-end forecasting architecture. ",
    "url": "https://arxiv.org/abs/2205.13492",
    "authors": [
      "Andrea Cini",
      "Daniele Zambon",
      "Cesare Alippi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13502",
    "title": "An Analytic Framework for Robust Training of Artificial Neural Networks",
    "abstract": "The reliability of a learning model is key to the successful deployment of machine learning in various industries. Creating a robust model, particularly one unaffected by adversarial attacks, requires a comprehensive understanding of the adversarial examples phenomenon. However, it is difficult to describe the phenomenon due to the complicated nature of the problems in machine learning. Consequently, many studies investigate the phenomenon by proposing a simplified model of how adversarial examples occur and validate it by predicting some aspect of the phenomenon. While these studies cover many different characteristics of the adversarial examples, they have not reached a holistic approach to the geometric and analytic modeling of the phenomenon. This paper propose a formal framework to study the phenomenon in learning theory and make use of complex analysis and holomorphicity to offer a robust learning rule for artificial neural networks. With the help of complex analysis, we can effortlessly move between geometric and analytic perspectives of the phenomenon and offer further insights on the phenomenon by revealing its connection with harmonic functions. Using our model, we can explain some of the most intriguing characteristics of adversarial examples, including transferability of adversarial examples, and pave the way for novel approaches to mitigate the effects of the phenomenon. ",
    "url": "https://arxiv.org/abs/2205.13502",
    "authors": [
      "Ramin Barati",
      "Reza Safabakhsh",
      "Mohammad Rahmati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13503",
    "title": "Multi-layer State Evolution Under Random Convolutional Design",
    "abstract": "Signal recovery under generative neural network priors has emerged as a promising direction in statistical inference and computational imaging. Theoretical analysis of reconstruction algorithms under generative priors is, however, challenging. For generative priors with fully connected layers and Gaussian i.i.d. weights, this was achieved by the multi-layer approximate message (ML-AMP) algorithm via a rigorous state evolution. However, practical generative priors are typically convolutional, allowing for computational benefits and inductive biases, and so the Gaussian i.i.d. weight assumption is very limiting. In this paper, we overcome this limitation and establish the state evolution of ML-AMP for random convolutional layers. We prove in particular that random convolutional layers belong to the same universality class as Gaussian matrices. Our proof technique is of an independent interest as it establishes a mapping between convolutional matrices and spatially coupled sensing matrices used in coding theory. ",
    "url": "https://arxiv.org/abs/2205.13503",
    "authors": [
      "Max Daniels",
      "C\u00e9dric Gerbelot",
      "Florent Krzakala",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2205.13522",
    "title": "Dynamically Relative Position Encoding-Based Transformer for Automatic  Code Edit",
    "abstract": "Adapting Deep Learning (DL) techniques to automate non-trivial coding activities, such as code documentation and defect detection, has been intensively studied recently. Learning to predict code changes is one of the popular and essential investigations. Prior studies have shown that DL techniques such as Neural Machine Translation (NMT) can benefit meaningful code changes, including bug fixing and code refactoring. However, NMT models may encounter bottleneck when modeling long sequences, thus are limited in accurately predicting code changes. In this work, we design a Transformer-based approach, considering that Transformer has proven effective in capturing long-term dependencies. Specifically, we propose a novel model named DTrans. For better incorporating the local structure of code, i.e., statement-level information in this paper, DTrans is designed with dynamically relative position encoding in the multi-head attention of Transformer. Experiments on benchmark datasets demonstrate that DTrans can more accurately generate patches than the state-of-the-art methods, increasing the performance by at least 5.45\\%-46.57\\% in terms of the exact match metric on different datasets. Moreover, DTrans can locate the lines to change with 1.75\\%-24.21\\% higher accuracy than the existing methods. ",
    "url": "https://arxiv.org/abs/2205.13522",
    "authors": [
      "Shiyi Qi",
      "Yaoxian Li",
      "Cuiyun Gao",
      "Xiaohong Su",
      "Shuzheng Gao",
      "Zibin Zheng",
      "Chuanyi Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.13523",
    "title": "PerDoor: Persistent Non-Uniform Backdoors in Federated Learning using  Adversarial Perturbations",
    "abstract": "Federated Learning (FL) enables numerous participants to train deep learning models collaboratively without exposing their personal, potentially sensitive data, making it a promising solution for data privacy in collaborative training. The distributed nature of FL and unvetted data, however, makes it inherently vulnerable to backdoor attacks: In this scenario, an adversary injects backdoor functionality into the centralized model during training, which can be triggered to cause the desired misclassification for a specific adversary-chosen input. A range of prior work establishes successful backdoor injection in an FL system; however, these backdoors are not demonstrated to be long-lasting. The backdoor functionality does not remain in the system if the adversary is removed from the training process since the centralized model parameters continuously mutate during successive FL training rounds. Therefore, in this work, we propose PerDoor, a persistent-by-construction backdoor injection technique for FL, driven by adversarial perturbation and targeting parameters of the centralized model that deviate less in successive FL rounds and contribute the least to the main task accuracy. An exhaustive evaluation considering an image classification scenario portrays on average $10.5\\times$ persistence over multiple FL rounds compared to traditional backdoor attacks. Through experiments, we further exhibit the potency of PerDoor in the presence of state-of-the-art backdoor prevention techniques in an FL system. Additionally, the operation of adversarial perturbation also assists PerDoor in developing non-uniform trigger patterns for backdoor inputs compared to uniform triggers (with fixed patterns and locations) of existing backdoor techniques, which are prone to be easily mitigated. ",
    "url": "https://arxiv.org/abs/2205.13523",
    "authors": [
      "Manaar Alam",
      "Esha Sarkar",
      "Michail Maniatakos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.13524",
    "title": "PREF: Phasorial Embedding Fields for Compact Neural Representations",
    "abstract": "We present a phasorial embedding field \\emph{PREF} as a compact representation to facilitate neural signal modeling and reconstruction tasks. Pure multi-layer perceptron (MLP) based neural techniques are biased towards low frequency signals and have relied on deep layers or Fourier encoding to avoid losing details. PREF instead employs a compact and physically explainable encoding field based on the phasor formulation of the Fourier embedding space. We conduct a comprehensive theoretical analysis to demonstrate the advantages of PREF over the latest spatial embedding techniques. We then develop a highly efficient frequency learning framework using an approximated inverse Fourier transform scheme for PREF along with a novel Parseval regularizer. Extensive experiments show our compact PREF-based neural signal processing technique is on par with the state-of-the-art in 2D image completion, 3D SDF surface regression, and 5D radiance field reconstruction. ",
    "url": "https://arxiv.org/abs/2205.13524",
    "authors": [
      "Binbin Huang",
      "Xinhao Yan",
      "Anpei Chen",
      "Shenghua Gao",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2205.13531",
    "title": "Training ReLU networks to high uniform accuracy is intractable",
    "abstract": "Statistical learning theory provides bounds on the necessary number of training samples needed to reach a prescribed accuracy in a learning problem formulated over a given target class. This accuracy is typically measured in terms of a generalization error, that is, an expected value of a given loss function. However, for several applications -- for example in a security-critical context or for problems in the computational sciences -- accuracy in this sense is not sufficient. In such cases, one would like to have guarantees for high accuracy on every input value, that is, with respect to the uniform norm. In this paper we precisely quantify the number of training samples needed for any conceivable training algorithm to guarantee a given uniform accuracy on any learning problem formulated over target classes containing (or consisting of) ReLU neural networks of a prescribed architecture. We prove that, under very general assumptions, the minimal number of training samples for this task scales exponentially both in the depth and the input dimension of the network architecture. As a corollary we conclude that the training of ReLU neural networks to high uniform accuracy is intractable. In a security-critical context this points to the fact that deep learning based systems are prone to being fooled by a possible adversary. We corroborate our theoretical findings by numerical results. ",
    "url": "https://arxiv.org/abs/2205.13531",
    "authors": [
      "Julius Berner",
      "Philipp Grohs",
      "Felix Voigtlaender"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.13532",
    "title": "Selective Classification Via Neural Network Training Dynamics",
    "abstract": "Selective classification is the task of rejecting inputs a model would predict incorrectly on through a trade-off between input space coverage and model accuracy. Current methods for selective classification impose constraints on either the model architecture or the loss function; this inhibits their usage in practice. In contrast to prior work, we show that state-of-the-art selective classification performance can be attained solely from studying the (discretized) training dynamics of a model. We propose a general framework that, for a given test input, monitors metrics capturing the disagreement with the final predicted label over intermediate models obtained during training; we then reject data points exhibiting too much disagreement at late stages in training. In particular, we instantiate a method that tracks when the label predicted during training stops disagreeing with the final predicted label. Our experimental evaluation shows that our method achieves state-of-the-art accuracy/coverage trade-offs on typical selective classification benchmarks. For example, we improve coverage on CIFAR-10/SVHN by 10.1%/1.5% respectively at a fixed target error of 0.5%. ",
    "url": "https://arxiv.org/abs/2205.13532",
    "authors": [
      "Stephan Rabanser",
      "Anvith Thudi",
      "Kimia Hamidieh",
      "Adam Dziedzic",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.13542",
    "title": "BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird's-Eye View  Representation",
    "abstract": "Multi-sensor fusion is essential for an accurate and reliable autonomous driving system. Recent approaches are based on point-level fusion: augmenting the LiDAR point cloud with camera features. However, the camera-to-LiDAR projection throws away the semantic density of camera features, hindering the effectiveness of such methods, especially for semantic-oriented tasks (such as 3D scene segmentation). In this paper, we break this deeply-rooted convention with BEVFusion, an efficient and generic multi-task multi-sensor fusion framework. It unifies multi-modal features in the shared bird's-eye view (BEV) representation space, which nicely preserves both geometric and semantic information. To achieve this, we diagnose and lift key efficiency bottlenecks in the view transformation with optimized BEV pooling, reducing latency by more than 40x. BEVFusion is fundamentally task-agnostic and seamlessly supports different 3D perception tasks with almost no architectural changes. It establishes the new state of the art on nuScenes, achieving 1.3% higher mAP and NDS on 3D object detection and 13.6% higher mIoU on BEV map segmentation, with 1.9x lower computation cost. ",
    "url": "https://arxiv.org/abs/2205.13542",
    "authors": [
      "Zhijian Liu",
      "Haotian Tang",
      "Alexander Amini",
      "Xinyu Yang",
      "Huizi Mao",
      "Daniela Rus",
      "Song Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13270",
    "title": "Computing homomorphisms in hereditary graph classes: the peculiar case  of the 5-wheel and graphs with no long claws",
    "abstract": "For graphs $G$ and $H$, an $H$-coloring of $G$ is an edge-preserving mapping from $V(G)$ to $V(H)$. In the $H$-Coloring problem the graph $H$ is fixed and we ask whether an instance graph $G$ admits an $H$-coloring. A generalization of this problem is $H$-ColoringExt, where some vertices of $G$ are already mapped to vertices of $H$ and we ask if this partial mapping can be extended to an $H$-coloring. We study the complexity of variants of $H$-Coloring in $F$-free graphs, i.e., graphs excluding a fixed graph $F$ as an induced subgraph. For integers $a,b,c \\geq 1$, by $S_{a,b,c}$ we denote the graph obtained by identifying one endvertex of three paths on $a+1$, $b+1$, and $c+1$ vertices, respectively. For odd $k \\geq 5$, by $W_k$ we denote the graph obtained from the $k$-cycle by adding a universal vertex. As our main algorithmic result we show that $W_5$-ColoringExt is polynomial-time solvable in $S_{2,1,1}$-free graphs. This result exhibits an interesting non-monotonicity of $H$-ColoringExt with respect to taking induced subgraphs of $H$. Indeed, $W_5$ contains a triangle, and $K_3$-Coloring, i.e., classical 3-coloring, is NP-hard already in claw-free (i.e., $S_{1,1,1}$-free) graphs. Our algorithm is based on two main observations: 1. $W_5$-ColoringExt in $S_{2,1,1}$-free graphs can be in polynomial time reduced to a variant of the problem of finding an independent set intersecting all triangles, and 2. the latter problem can be solved in polynomial time in $S_{2,1,1}$-free graphs. We complement this algorithmic result with several negative ones. In particular, we show that $W_5$-ColoringExt is NP-hard in $S_{3,3,3}$-free graphs. This is again uncommon, as usually problems that are NP-hard in $S_{a,b,c}$-free graphs for some constant $a,b,c$ are already hard in claw-free graphs. ",
    "url": "https://arxiv.org/abs/2205.13270",
    "authors": [
      "Micha\u0142 D\u0119bski",
      "Zbigniew Lonc",
      "Karolina Okrasa",
      "Marta Piecyk",
      "Pawe\u0142 Rz\u0105\u017cewski"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2205.13285",
    "title": "The Babylonian Graph",
    "abstract": "The Babylonian graph B has the positive integers as vertices and connects two if they define a Pythagorean triple. Triangular subgraphs correspond to Euler bricks. What are the properties of this graph? Are there tetrahedral subgraphs corresponding to Euler tesseracts? Is there only one infinite connected component? Are there two Euler bricks in the graph that are disconnected? Do the number of edges or triangles in the subgraph generated by the first n vertices grow like of the order n W(n), where n is the product log? We prove here some first results like the threshold where B(n) becomes non-planar. In an appendix, we include handout from a talk on Euler cuboids given in the year 2009. ",
    "url": "https://arxiv.org/abs/2205.13285",
    "authors": [
      "Oliver Knill"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Number Theory (math.NT)"
    ]
  },
  {
    "id": "arXiv:2205.13293",
    "title": "Joint Training of Speech Enhancement and Self-supervised Model for  Noise-robust ASR",
    "abstract": "Speech enhancement (SE) is usually required as a front end to improve the speech quality in noisy environments, while the enhanced speech might not be optimal for automatic speech recognition (ASR) systems due to speech distortion. On the other hand, it was shown that self-supervised pre-training enables the utilization of a large amount of unlabeled noisy data, which is rather beneficial for the noise robustness of ASR. However, the potential of the (optimal) integration of SE and self-supervised pre-training still remains unclear. In order to find an appropriate combination and reduce the impact of speech distortion caused by SE, in this paper we therefore propose a joint pre-training approach for the SE module and the self-supervised model. First, in the pre-training phase the original noisy waveform or the waveform obtained by SE is fed into the self-supervised model to learn the contextual representation, where the quantified clean speech acts as the target. Second, we propose a dual-attention fusion method to fuse the features of noisy and enhanced speeches, which can compensate the information loss caused by separately using individual modules. Due to the flexible exploitation of clean/noisy/enhanced branches, the proposed method turns out to be a generalization of some existing noise-robust ASR models, e.g., enhanced wav2vec2.0. Finally, experimental results on both synthetic and real noisy datasets show that the proposed joint training approach can improve the ASR performance under various noisy settings, leading to a stronger noise robustness. ",
    "url": "https://arxiv.org/abs/2205.13293",
    "authors": [
      "Qiu-Shi Zhu",
      "Jie Zhang",
      "Zi-Qiang Zhang",
      "Li-Rong Dai"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2205.13418",
    "title": "Avoiding Barren Plateaus with Classical Deep Neural Networks",
    "abstract": "Variational quantum algorithms (VQAs) are among the most promising algorithms in the era of Noisy Intermediate Scale Quantum Devices. The VQAs are applied to a variety of tasks, such as in chemistry simulations, optimization problems, and quantum neural networks. Such algorithms are constructed using a parameterization U($\\pmb{\\theta}$) with a classical optimizer that updates the parameters $\\pmb{\\theta}$ in order to minimize a cost function $C$. For this task, in general the gradient descent method, or one of its variants, is used. This is a method where the circuit parameters are updated iteratively using the cost function gradient. However, several works in the literature have shown that this method suffers from a phenomenon known as the Barren Plateaus (BP). This phenomenon is characterized by the exponentially flattening of the cost function landscape, so that the number of times the function must be evaluated to perform the optimization grows exponentially as the number of qubits and parameterization depth increase. In this article, we report on how the use of a classical neural networks in the VQAs input parameters can alleviate the BP phenomenon. ",
    "url": "https://arxiv.org/abs/2205.13418",
    "authors": [
      "Lucas Friedrich",
      "Jonas Maziero"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13496",
    "title": "Censored Quantile Regression Neural Networks",
    "abstract": "This paper considers doing quantile regression on censored data using neural networks (NNs). This adds to the survival analysis toolkit by allowing direct prediction of the target variable, along with a distribution-free characterisation of uncertainty, using a flexible function approximator. We begin by showing how an algorithm popular in linear models can be applied to NNs. However, the resulting procedure is inefficient, requiring sequential optimisation of an individual NN at each desired quantile. Our major contribution is a novel algorithm that simultaneously optimises a grid of quantiles output by a single NN. To offer theoretical insight into our algorithm, we show firstly that it can be interpreted as a form of expectation-maximisation, and secondly that it exhibits a desirable `self-correcting' property. Experimentally, the algorithm produces quantiles that are better calibrated than existing methods on 10 out of 12 real datasets. ",
    "url": "https://arxiv.org/abs/2205.13496",
    "authors": [
      "Tim Pearce",
      "Jong-Hyeon Jeong",
      "Yichen Jia",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2006.12963",
    "title": "PFGDF: Pruning Filter via Gaussian Distribution Feature for Deep Neural  Networks Acceleration",
    "abstract": " Title: PFGDF: Pruning Filter via Gaussian Distribution Feature for Deep Neural  Networks Acceleration ",
    "url": "https://arxiv.org/abs/2006.12963",
    "authors": [
      "Jianrong Xu",
      "Boyu Diao",
      "Bifeng Cui",
      "Kang Yang",
      "Chao Li",
      "Yongjun Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2011.13307",
    "title": "Polygon-free: Unconstrained Scene Text Detection with Box Annotations",
    "abstract": " Title: Polygon-free: Unconstrained Scene Text Detection with Box Annotations ",
    "url": "https://arxiv.org/abs/2011.13307",
    "authors": [
      "Weijia Wu",
      "Enze Xie",
      "Ruimao Zhang",
      "Wenhai Wang",
      "Hong Zhou",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2012.15643",
    "title": "CoCoLM: COmplex COmmonsense Enhanced Language Model with Discourse  Relations",
    "abstract": " Title: CoCoLM: COmplex COmmonsense Enhanced Language Model with Discourse  Relations ",
    "url": "https://arxiv.org/abs/2012.15643",
    "authors": [
      "Changlong Yu",
      "Hongming Zhang",
      "Yangqiu Song",
      "Wilfred Ng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2102.05013",
    "title": "Spherical Message Passing for 3D Graph Networks",
    "abstract": " Comments: The paper has been accepted by ICLR 2022. The updated title is \"Spherical Message Passing for 3D Molecular Graphs\". You can also cite the conference version ",
    "url": "https://arxiv.org/abs/2102.05013",
    "authors": [
      "Yi Liu",
      "Limei Wang",
      "Meng Liu",
      "Xuan Zhang",
      "Bora Oztekin",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.00944",
    "title": "A Little Energy Goes a Long Way: Build an Energy-Efficient, Accurate  Spiking Neural Network from Convolutional Neural Network",
    "abstract": " Title: A Little Energy Goes a Long Way: Build an Energy-Efficient, Accurate  Spiking Neural Network from Convolutional Neural Network ",
    "url": "https://arxiv.org/abs/2103.00944",
    "authors": [
      "Dengyu Wu",
      "Xinping Yi",
      "Xiaowei Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.14108",
    "title": "Efficient and robust multi-task learning in the brain with modular  latent primitives",
    "abstract": " Comments: *Shared senior authorship ",
    "url": "https://arxiv.org/abs/2105.14108",
    "authors": [
      "Christian David M\u00e1rton",
      "L\u00e9o Gagnon",
      "Guillaume Lajoie",
      "Kanaka Rajan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2106.03374",
    "title": "MixR: Data Mixing Augmentation for Regression",
    "abstract": " Comments: 13 pages, 8 figures, 8 tables ",
    "url": "https://arxiv.org/abs/2106.03374",
    "authors": [
      "Seong-Hyeon Hwang",
      "Steven Euijong Whang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.08924",
    "title": "Epistemic Neural Networks",
    "abstract": " Title: Epistemic Neural Networks ",
    "url": "https://arxiv.org/abs/2107.08924",
    "authors": [
      "Ian Osband",
      "Zheng Wen",
      "Seyed Mohammad Asghari",
      "Vikranth Dwaracherla",
      "Morteza Ibrahimi",
      "Xiuyuan Lu",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2108.00505",
    "title": "DeepTrack: Lightweight Deep Learning for Vehicle Path Prediction in  Highways",
    "abstract": " Comments: Published in IEEE Transactions on Intelligent Transportation Systems ",
    "url": "https://arxiv.org/abs/2108.00505",
    "authors": [
      "Vinit Katariya",
      "Mohammadreza Baharani",
      "Nichole Morris",
      "Omidreza Shoghli",
      "Hamed Tabkhi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2108.11489",
    "title": "The Interplay Between Implicit Bias and Benign Overfitting in Two-Layer  Linear Networks",
    "abstract": " Title: The Interplay Between Implicit Bias and Benign Overfitting in Two-Layer  Linear Networks ",
    "url": "https://arxiv.org/abs/2108.11489",
    "authors": [
      "Niladri S. Chatterji",
      "Philip M. Long",
      "Peter L. Bartlett"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2110.04629",
    "title": "The Neural Testbed: Evaluating Joint Predictions",
    "abstract": " Title: The Neural Testbed: Evaluating Joint Predictions ",
    "url": "https://arxiv.org/abs/2110.04629",
    "authors": [
      "Ian Osband",
      "Zheng Wen",
      "Seyed Mohammad Asghari",
      "Vikranth Dwaracherla",
      "Botao Hao",
      "Morteza Ibrahimi",
      "Dieterich Lawson",
      "Xiuyuan Lu",
      "Brendan O'Donoghue",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.07514",
    "title": "Advances in Scaling Community Discovery Methods for Signed Graph  Networks",
    "abstract": " Comments: 42 pages, 14 figures, 13 tables ",
    "url": "https://arxiv.org/abs/2110.07514",
    "authors": [
      "Maria Tomasso",
      "Lucas Rusnak",
      "Jelena Te\u0161i\u0107"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2110.08750",
    "title": "TIP: Task-Informed Motion Prediction for Intelligent Vehicles",
    "abstract": " Comments: 9 pages, 5 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2110.08750",
    "authors": [
      "Xin Huang",
      "Guy Rosman",
      "Ashkan Jasour",
      "Stephen G. McGill",
      "John J. Leonard",
      "Brian C. Williams"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.00743",
    "title": "Towards the Generalization of Contrastive Self-Supervised Learning",
    "abstract": " Title: Towards the Generalization of Contrastive Self-Supervised Learning ",
    "url": "https://arxiv.org/abs/2111.00743",
    "authors": [
      "Weiran Huang",
      "Mingyang Yi",
      "Xuyang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.03199",
    "title": "Concurrent multiscale analysis without meshing: Microscale  representation with CutFEM and micro/macro model blending",
    "abstract": " Title: Concurrent multiscale analysis without meshing: Microscale  representation with CutFEM and micro/macro model blending ",
    "url": "https://arxiv.org/abs/2111.03199",
    "authors": [
      "Ehsan Mikaeili",
      "Susanne Claus",
      "Pierre Kerfriden"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2111.04699",
    "title": "Automated pharyngeal phase detection and bolus localization in  videofluoroscopic swallowing study: Killing two birds with one stone?",
    "abstract": " Title: Automated pharyngeal phase detection and bolus localization in  videofluoroscopic swallowing study: Killing two birds with one stone? ",
    "url": "https://arxiv.org/abs/2111.04699",
    "authors": [
      "Andrea Bandini",
      "Sana Smaoui",
      "Catriona M. Steele"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.07183",
    "title": "Reliably-stabilizing piecewise-affine neural network controllers",
    "abstract": " Title: Reliably-stabilizing piecewise-affine neural network controllers ",
    "url": "https://arxiv.org/abs/2111.07183",
    "authors": [
      "Filippo Fabiani",
      "Paul J. Goulart"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2111.14655",
    "title": "FedHM: Efficient Federated Learning for Heterogeneous Models via  Low-rank Factorization",
    "abstract": " Title: FedHM: Efficient Federated Learning for Heterogeneous Models via  Low-rank Factorization ",
    "url": "https://arxiv.org/abs/2111.14655",
    "authors": [
      "Dezhong Yao",
      "Wanning Pan",
      "Michael J O'Neill",
      "Yutong Dai",
      "Yao Wan",
      "Hai Jin",
      "Lichao Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2112.04684",
    "title": "Trajectory-Constrained Deep Latent Visual Attention for Improved Local  Planning in Presence of Heterogeneous Terrain",
    "abstract": " Comments: Published in International Conference on Intelligent Robots and Systems (IROS) 2021 proceedings. Project website: this https URL ",
    "url": "https://arxiv.org/abs/2112.04684",
    "authors": [
      "Stefan Wapnick",
      "Travis Manderson",
      "David Meger",
      "Gregory Dudek"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.07995",
    "title": "Domain-informed neural networks for interaction localization within  astroparticle experiments",
    "abstract": " Comments: 18 pages, 10 figures. Updated to the published version ",
    "url": "https://arxiv.org/abs/2112.07995",
    "authors": [
      "Shixiao Liang",
      "Aaron Higuera",
      "Christina Peters",
      "Venkat Roy",
      "Waheed U. Bajwa",
      "Hagit Shatkay",
      "Christopher D. Tunnell"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.15085",
    "title": "Feature Extraction, Classification and Prediction for Hand Hygiene  Gestures with KNN Algorithm",
    "abstract": " Title: Feature Extraction, Classification and Prediction for Hand Hygiene  Gestures with KNN Algorithm ",
    "url": "https://arxiv.org/abs/2112.15085",
    "authors": [
      "Rashmi Bakshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.01080",
    "title": "Towards Understanding and Harnessing the Effect of Image Transformation  in Adversarial Detection",
    "abstract": " Title: Towards Understanding and Harnessing the Effect of Image Transformation  in Adversarial Detection ",
    "url": "https://arxiv.org/abs/2201.01080",
    "authors": [
      "Hui Liu",
      "Bo Zhao",
      "Yuefeng Peng",
      "Weidong Li",
      "Peng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.01601",
    "title": "FedBalancer: Data and Pace Control for Efficient Federated Learning on  Heterogeneous Clients",
    "abstract": " Comments: Accepted to the 20th ACM International Conference on Mobile Systems, Applications, and Services (MobiSys 2022) ",
    "url": "https://arxiv.org/abs/2201.01601",
    "authors": [
      "Jaemin Shin",
      "Yuanchun Li",
      "Yunxin Liu",
      "Sung-Ju Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.06993",
    "title": "Spiker: an FPGA-optimized Hardware acceleration for Spiking Neural  Networks",
    "abstract": " Comments: 6 pages, 3 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2201.06993",
    "authors": [
      "Alessio Carpegna",
      "Alessandro Savino",
      "Stefano Di Carlo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.12825",
    "title": "Lorentzian Fully Hyperbolic Generative Adversarial Network",
    "abstract": " Title: Lorentzian Fully Hyperbolic Generative Adversarial Network ",
    "url": "https://arxiv.org/abs/2201.12825",
    "authors": [
      "Eric Qu",
      "Dongmian Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.00645",
    "title": "Generalization Analysis of Message Passing Neural Networks on Large  Random Graphs",
    "abstract": " Comments: Preprint in Review ",
    "url": "https://arxiv.org/abs/2202.00645",
    "authors": [
      "Sohir Maskey",
      "Ron Levie",
      "Yunseok Lee",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2202.05564",
    "title": "A Partial Reciprocity-based Channel Prediction Framework for FDD Massive  MIMO with High Mobility",
    "abstract": " Comments: 9 figures, 15 pages, to appear in IEEE Transactions on Wireless Communications ",
    "url": "https://arxiv.org/abs/2202.05564",
    "authors": [
      "Ziao Qin",
      "Haifan Yin",
      "Yandi Cao",
      "Weidong Li",
      "David Gesbert"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.06775",
    "title": "A structure-preserving finite element approximation of surface diffusion  for curve networks and surface clusters",
    "abstract": " Comments: 29 figures ",
    "url": "https://arxiv.org/abs/2202.06775",
    "authors": [
      "Weizhu Bao",
      "Harald Garcke",
      "Robert N\u00fcrnberg",
      "Quan Zhao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2202.09745",
    "title": "RDP-Net: Region Detail Preserving Network for Change Detection",
    "abstract": " Comments: 9 pages, 10 figures, 46 references ",
    "url": "https://arxiv.org/abs/2202.09745",
    "authors": [
      "Hongjia Chen",
      "Fangling Pu",
      "Rui Yang",
      "Rui Tang",
      "Xin Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.12595",
    "title": "Evolutionary scheduling of university activities based on consumption  forecasts to minimise electricity costs",
    "abstract": " Comments: Accepted to the 2022 IEEE Congress on Evolutionary Computation ",
    "url": "https://arxiv.org/abs/2202.12595",
    "authors": [
      "Julian Ruddick",
      "Evgenii Genov",
      "Luis Ramirez Camargo",
      "Thierry Coosemans",
      "Maarten Messagie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2203.05291",
    "title": "On Robustness in Optimization-Based Constrained Iterative Learning  Control",
    "abstract": " Title: On Robustness in Optimization-Based Constrained Iterative Learning  Control ",
    "url": "https://arxiv.org/abs/2203.05291",
    "authors": [
      "Dominic Liao-McPherson",
      "Efe C. Balta",
      "Alisa Rupenyan",
      "John Lygeros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.05184",
    "title": "Domain Adversarial Graph Convolutional Network Based on RSSI and  Crowdsensing for Indoor Localization",
    "abstract": " Title: Domain Adversarial Graph Convolutional Network Based on RSSI and  Crowdsensing for Indoor Localization ",
    "url": "https://arxiv.org/abs/2204.05184",
    "authors": [
      "Mingxin Zhang",
      "Zipei Fan",
      "Ryosuke Shibasaki",
      "Xuan Song"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2204.11032",
    "title": "Heterogeneous Separation Consistency Training for Adaptation of  Unsupervised Speech Separation",
    "abstract": " Title: Heterogeneous Separation Consistency Training for Adaptation of  Unsupervised Speech Separation ",
    "url": "https://arxiv.org/abs/2204.11032",
    "authors": [
      "Jiangyu Han",
      "Yanhua Long"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2205.00690",
    "title": "From Noisy Prediction to True Label: Noisy Prediction Calibration via  Generative Model",
    "abstract": " Comments: 21 pages, 9 figures. International Conference on Machine Learning (ICML 2022), Baltimore, Jul 17, 2022 ",
    "url": "https://arxiv.org/abs/2205.00690",
    "authors": [
      "HeeSun Bae",
      "Seungjae Shin",
      "Byeonghu Na",
      "JoonHo Jang",
      "Kyungwoo Song",
      "Il-Chul Moon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01411",
    "title": "On the Utility of Prediction Sets in Human-AI Teams",
    "abstract": " Comments: Accepted at IJCAI 2022 ",
    "url": "https://arxiv.org/abs/2205.01411",
    "authors": [
      "Varun Babbar",
      "Umang Bhatt",
      "Adrian Weller"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2205.06854",
    "title": "An Approach for Automatic Construction of an Algorithmic Knowledge Graph  from Textual Resources",
    "abstract": " Comments: 12 pages, 7 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2205.06854",
    "authors": [
      "Jyotima Patel",
      "Biswanath Dutta"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.06918",
    "title": "Representation learning with function call graph transformations for  malware open set recognition",
    "abstract": " Title: Representation learning with function call graph transformations for  malware open set recognition ",
    "url": "https://arxiv.org/abs/2205.06918",
    "authors": [
      "Jingyun Jia",
      "Philip K. Chan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09348",
    "title": "Analyzing Echo-state Networks Using Fractal Dimension",
    "abstract": " Comments: IEEE WCCI 2022, Padua. Copyright is with IEEE ",
    "url": "https://arxiv.org/abs/2205.09348",
    "authors": [
      "Norbert Michael Mayer",
      "Oliver Obst"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.11508",
    "title": "Contrastive and Non-Contrastive Self-Supervised Learning Recover Global  and Local Spectral Embedding Methods",
    "abstract": " Title: Contrastive and Non-Contrastive Self-Supervised Learning Recover Global  and Local Spectral Embedding Methods ",
    "url": "https://arxiv.org/abs/2205.11508",
    "authors": [
      "Randall Balestriero",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Spectral Theory (math.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.11736",
    "title": "Towards a Defense against Backdoor Attacks in Continual Federated  Learning",
    "abstract": " Title: Towards a Defense against Backdoor Attacks in Continual Federated  Learning ",
    "url": "https://arxiv.org/abs/2205.11736",
    "authors": [
      "Shuaiqi Wang",
      "Jonathan Hayase",
      "Giulia Fanti",
      "Sewoong Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.11738",
    "title": "Adaptive Few-Shot Learning Algorithm for Rare Sound Event Detection",
    "abstract": " Comments: Accepted to IJCNN 2022 ",
    "url": "https://arxiv.org/abs/2205.11738",
    "authors": [
      "Chendong Zhao",
      "Jianzong Wang",
      "Leilai Li",
      "Xiaoyang Qu",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.12318",
    "title": "ColdGuess: A General and Effective Relational Graph Convolutional  Network to Tackle Cold Start Cases",
    "abstract": " Title: ColdGuess: A General and Effective Relational Graph Convolutional  Network to Tackle Cold Start Cases ",
    "url": "https://arxiv.org/abs/2205.12318",
    "authors": [
      "Bo He",
      "Xiang Song",
      "Vincent Gao",
      "Christos Faloutsos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12331",
    "title": "Certified Robustness Against Natural Language Attacks by Causal  Intervention",
    "abstract": " Title: Certified Robustness Against Natural Language Attacks by Causal  Intervention ",
    "url": "https://arxiv.org/abs/2205.12331",
    "authors": [
      "Haiteng Zhao",
      "Chang Ma*",
      "Xinshuai Dong",
      "Anh Tuan Luu",
      "Zhi-Hong Deng",
      "Hanwang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.12354",
    "title": "Optimal Entanglement Distribution using Satellite Based Quantum Networks",
    "abstract": " Title: Optimal Entanglement Distribution using Satellite Based Quantum Networks ",
    "url": "https://arxiv.org/abs/2205.12354",
    "authors": [
      "Nitish K. Panigrahy",
      "Prajit Dhara",
      "Don Towsley",
      "Saikat Guha",
      "Leandros Tassiulas"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.12493",
    "title": "Federated Self-supervised Learning for Heterogeneous Clients",
    "abstract": " Title: Federated Self-supervised Learning for Heterogeneous Clients ",
    "url": "https://arxiv.org/abs/2205.12493",
    "authors": [
      "Disha Makhija",
      "Nhat Ho",
      "Joydeep Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.12635",
    "title": "MoCoViT: Mobile Convolutional Vision Transformer",
    "abstract": " Comments: After evaluation, the relevant technical details are temporarily inconvenient to be disclosed, so the manuscript is temporarily withdrawn. We will wait for the right time to reopen ",
    "url": "https://arxiv.org/abs/2205.12635",
    "authors": [
      "Hailong Ma",
      "Xin Xia",
      "Xing Wang",
      "Xuefeng Xiao",
      "Jiashi Li",
      "Min Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12646",
    "title": "UniInst: Unique Representation for End-to-End Instance Segmentation",
    "abstract": " Comments: This work is in the revision phase of the journal Neurocomputing. Codes will be available upon publication ",
    "url": "https://arxiv.org/abs/2205.12646",
    "authors": [
      "Yimin Ou",
      "Rui Yang",
      "Lufan Ma",
      "Yong Liu",
      "Jiangpeng Yan",
      "Shang Xu",
      "Chengjie Wang",
      "Xiu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12857",
    "title": "Structure Unbiased Adversarial Model for Medical Image Segmentation",
    "abstract": " Comments: Will revise the paper and resubmit ",
    "url": "https://arxiv.org/abs/2205.12857",
    "authors": [
      "Tianyang Zhang",
      "Shaoming Zheng",
      "Jun Cheng",
      "Xi Jia",
      "Joseph Bartlett",
      "Huazhu Fu",
      "Zhaowen Qiu",
      "Jiang Liu",
      "Jinming Duan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12940",
    "title": "Conformal Prediction Intervals with Temporal Dependence",
    "abstract": " Comments: 15 pages (main paper, including references) + 4 pages (supplementary material) ",
    "url": "https://arxiv.org/abs/2205.12940",
    "authors": [
      "Zhen Lin",
      "Shubhendu Trivedi",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  }
]