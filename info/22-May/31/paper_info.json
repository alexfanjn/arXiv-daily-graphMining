[
  {
    "id": "arXiv:2205.14148",
    "title": "Enhanced physics-informed neural networks for hyperelasticity",
    "abstract": "Physics-informed neural networks have gained growing interest. Specifically, they are used to solve partial differential equations governing several physical phenomena. However, physics-informed neural network models suffer from several issues and can fail to provide accurate solutions in many scenarios. We discuss a few of these challenges and the techniques, such as the use of Fourier transform, that can be used to resolve these issues. This paper proposes and develops a physics-informed neural network model that combines the residuals of the strong form and the potential energy, yielding many loss terms contributing to the definition of the loss function to be minimized. Hence, we propose using the coefficient of variation weighting scheme to dynamically and adaptively assign the weight for each loss term in the loss function. The developed PINN model is standalone and meshfree. In other words, it can accurately capture the mechanical response without requiring any labeled data. Although the framework can be used for many solid mechanics problems, we focus on three-dimensional (3D) hyperelasticity, where we consider two hyperelastic models. Once the model is trained, the response can be obtained almost instantly at any point in the physical domain, given its spatial coordinates. We demonstrate the framework's performance by solving different problems with various boundary conditions. ",
    "url": "https://arxiv.org/abs/2205.14148",
    "authors": [
      "Diab W. Abueidda",
      "Seid Koric",
      "Erman Guleryuz",
      "Nahil A. Sobh"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2205.14151",
    "title": "Interactive and Robust Mesh Booleans",
    "abstract": "Boolean operations are among the most used paradigms to create and edit digital shapes. Despite being conceptually simple, the computation of mesh Booleans is notoriously challenging. Main issues come from numerical approximations that make the detection and processing of intersection points inconsistent and unreliable, exposing implementations based on floating point arithmetic to many kinds of degeneracy and failure. Numerical methods based on rational numbers or exact geometric predicates have the needed robustness guarantees, that are achieved at the cost of increased computation times that, as of today, has always restricted the use of robust mesh Booleans to offline applications. We introduce the first algorithm for Boolean operations with robustness guarantees that is capable of operating at interactive frame rates on meshes with up to 200K triangles. We evaluate our tool thoroughly, considering not only interactive applications but also batch processing of large collections of meshes, processing of huge meshes containing millions of elements and variadic Booleans of hundreds of shapes altogether. In all these experiments, we consistently outperform prior art by at least one order of magnitude. ",
    "url": "https://arxiv.org/abs/2205.14151",
    "authors": [
      "Gianmarco Cherchi",
      "Fabio Pellacini",
      "Marco Attene",
      "Marco Livesu"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2205.14181",
    "title": "Direction and Trajectory Tracking Control for Nonholonomic Spherical  Robot by Combining Sliding Mode Controller and Model Prediction Controller",
    "abstract": "Spherical robot is a nonlinear, nonholonomic and unstable system which increases the difficulty of the direction and trajectory tracking problem. In this study, we propose a new direction controller HTSMC, an instruction planning controller MPC, and a trajectory tracking framework MHH. The HTSMC is designed by integrating a fast terminal algorithm, a hierarchical method, the motion features of a spherical robot, and its dynamics. In addition, the new direction controller has an excellent control effect with a quick response speed and strong stability. MPC can obtain optimal commands that are then transmitted to the velocity and direction controller. Since the two torque controllers in MHH are all Lyapunov-based sliding mode controllers, the MHH framework may achieve optimal control performance while assuring stability. Finally, the two controllers eliminate the requirement for MPC's stability and dynamic constraints. Finally, hardware experiments demonstrate the efficacy of the HTSMC, MPC, and MHH. ",
    "url": "https://arxiv.org/abs/2205.14181",
    "authors": [
      "Yifan Liu",
      "Yixu Wang",
      "Xiaoqing Guan",
      "Tao Hu",
      "Ziang Zhang",
      "Song Jin",
      "You Wang",
      "Jie Hao",
      "Guang Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.14195",
    "title": "Unsupervised learning of features and object boundaries from local  prediction",
    "abstract": "A visual system has to learn both which features to extract from images and how to group locations into (proto-)objects. Those two aspects are usually dealt with separately, although predictability is discussed as a cue for both. To incorporate features and boundaries into the same model, we model a layer of feature maps with a pairwise Markov random field model in which each factor is paired with an additional binary variable, which switches the factor on or off. Using one of two contrastive learning objectives, we can learn both the features and the parameters of the Markov random field factors from images without further supervision signals. The features learned by shallow neural networks based on this loss are local averages, opponent colors, and Gabor-like stripe patterns. Furthermore, we can infer connectivity between locations by inferring the switch variables. Contours inferred from this connectivity perform quite well on the Berkeley segmentation database (BSDS500) without any training on contours. Thus, computing predictions across space aids both segmentation and feature learning, and models trained to optimize these predictions show similarities to the human visual system. We speculate that retinotopic visual cortex might implement such predictions over space through lateral connections. ",
    "url": "https://arxiv.org/abs/2205.14195",
    "authors": [
      "Heiko H. Sch\u00fctt",
      "Wei Ji Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2205.14196",
    "title": "FadMan: Federated Anomaly Detection across Multiple Attributed Networks",
    "abstract": "Anomaly subgraph detection has been widely used in various applications, ranging from cyber attack in computer networks to malicious activities in social networks. Despite an increasing need for federated anomaly detection across multiple attributed networks, only a limited number of approaches are available for this problem. Federated anomaly detection faces two major challenges. One is that isolated data in most industries are restricted share with others for data privacy and security. The other is most of the centralized approaches training based on data integration. The main idea of federated anomaly detection is aligning private anomalies from local data owners on the public anomalies from the attributed network in the server through public anomalies to federate local anomalies. In each private attributed network, the detected anomaly subgraph is aligned with an anomaly subgraph in the public attributed network. The significant public anomaly subgraphs are selected for federated private anomalies while preventing local private data leakage. The proposed algorithm FadMan is a vertical federated learning framework for public node aligned with many private nodes of different features, and is validated on two tasks correlated anomaly detection on multiple attributed networks and anomaly detection on an attributeless network using five real-world datasets. In the first scenario, FadMan outperforms competitive methods by at least 12% accuracy at 10% noise level. In the second scenario, by analyzing the distribution of abnormal nodes, we find that the nodes of traffic anomalies are associated with the event of postgraduate entrance examination on the same day. ",
    "url": "https://arxiv.org/abs/2205.14196",
    "authors": [
      "Nannan Wu",
      "Ning Zhang",
      "Wenjun Wang",
      "Lixin Fan",
      "Qiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.14206",
    "title": "Network Digital Twin: Context, Enabling Technologies and Opportunities",
    "abstract": "The proliferation of emergent network applications (e.g., telesurgery, metaverse) is increasing the difficulty of managing modern communication networks. These applications entail stringent network requirements (e.g., ultra-low deterministic latency), which hinders network operators to manage their resources efficiently. In this article, we introduce the network digital twin (NDT), a renovated concept of classical network modeling tools whose goal is to build accurate data-driven network models that can operate in real-time. We describe the general architecture of the NDT and argue that modern machine learning (ML) technologies enable building some of its core components. Then, we present a case study that leverages a ML-based NDT for network performance evaluation and apply it to routing optimization in a QoS-aware use case. Lastly, we describe some key open challenges and research opportunities yet to be explored to achieve effective deployment of NDTs in real-world networks. ",
    "url": "https://arxiv.org/abs/2205.14206",
    "authors": [
      "Paul Almasan",
      "Miquel Ferriol-Galm\u00e9s",
      "Jordi Paillisse",
      "Jos\u00e9 Su\u00e1rez-Varela",
      "Diego Perino",
      "Diego L\u00f3pez",
      "Antonio Agustin Pastor Perales",
      "Paul Harvey",
      "Laurent Ciavaglia",
      "Leon Wong",
      "Vishnu Ram",
      "Shihan Xiao",
      "Xiang Shi",
      "Xiangle Cheng",
      "Albert Cabellos-Aparicio",
      "Pere Barlet-Ros"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.14209",
    "title": "StarGraph: A Coarse-to-Fine Representation Method for Large-Scale  Knowledge Graph",
    "abstract": "Conventional representation learning algorithms for knowledge graphs (KG) map each entity to a unique embedding vector, ignoring the rich information contained in neighbor entities. We propose a method named StarGraph, which gives a novel way to utilize the neighborhood information for large-scale knowledge graphs to get better entity representations. The core idea is to divide the neighborhood information into different levels for sampling and processing, where the generalized coarse-grained information and unique fine-grained information are combined to generate an efficient subgraph for each node. In addition, a self-attention network is proposed to process the subgraphs and get the entity representations, which are used to replace the entity embeddings in conventional methods. The proposed method achieves the best results on the ogbl-wikikg2 dataset, which validates the effectiveness of it. The code is now available at https://github.com/hzli-ucas/StarGraph ",
    "url": "https://arxiv.org/abs/2205.14209",
    "authors": [
      "Hongzhu Li",
      "Xiangrui Gao",
      "Yafeng Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14230",
    "title": "Semi-supervised Semantics-guided Adversarial Training for Trajectory  Prediction",
    "abstract": "Predicting the trajectories of surrounding objects is a critical task in self-driving and many other autonomous systems. Recent works demonstrate that adversarial attacks on trajectory prediction, where small crafted perturbations are introduced to history trajectories, may significantly mislead the prediction of future trajectories and ultimately induce unsafe planning. However, few works have addressed enhancing the robustness of this important safety-critical task. In this paper, we present the first adversarial training method for trajectory prediction. Compared with typical adversarial training on image tasks, our work is challenged by more random inputs with rich context, and a lack of class labels. To address these challenges, we propose a method based on a semi-supervised adversarial autoencoder that models disentangled semantic features with domain knowledge and provides additional latent labels for the adversarial training. Extensive experiments with different types of attacks demonstrate that our semi-supervised semantics-guided adversarial training method can effectively mitigate the impact of adversarial attacks and generally improve the system's adversarial robustness to a variety of attacks, including unseen ones. We believe that such semantics-guided architecture and advancement in robust generalization is an important step for developing robust prediction models and enabling safe decision making. ",
    "url": "https://arxiv.org/abs/2205.14230",
    "authors": [
      "Ruochen Jiao",
      "Xiangguo Liu",
      "Takami Sato",
      "Qi Alfred Chen",
      "Qi Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.14246",
    "title": "Defending Against Stealthy Backdoor Attacks",
    "abstract": "Defenses against security threats have been an interest of recent studies. Recent works have shown that it is not difficult to attack a natural language processing (NLP) model while defending against them is still a cat-mouse game. Backdoor attacks are one such attack where a neural network is made to perform in a certain way on specific samples containing some triggers while achieving normal results on other samples. In this work, we present a few defense strategies that can be useful to counter against such an attack. We show that our defense methodologies significantly decrease the performance on the attacked inputs while maintaining similar performance on benign inputs. We also show that some of our defenses have very less runtime and also maintain similarity with the original inputs. ",
    "url": "https://arxiv.org/abs/2205.14246",
    "authors": [
      "Sangeet Sagar",
      "Abhinav Bhatt",
      "Abhijith Srinivas Bidaralli"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.14252",
    "title": "Self-supervised models of audio effectively explain human cortical  responses to speech",
    "abstract": "Self-supervised language models are very effective at predicting high-level cortical responses during language comprehension. However, the best current models of lower-level auditory processing in the human brain rely on either hand-constructed acoustic filters or representations from supervised audio neural networks. In this work, we capitalize on the progress of self-supervised speech representation learning (SSL) to create new state-of-the-art models of the human auditory system. Compared against acoustic baselines, phonemic features, and supervised models, representations from the middle layers of self-supervised models (APC, wav2vec, wav2vec 2.0, and HuBERT) consistently yield the best prediction performance for fMRI recordings within the auditory cortex (AC). Brain areas involved in low-level auditory processing exhibit a preference for earlier SSL model layers, whereas higher-level semantic areas prefer later layers. We show that these trends are due to the models' ability to encode information at multiple linguistic levels (acoustic, phonetic, and lexical) along their representation depth. Overall, these results show that self-supervised models effectively capture the hierarchy of information relevant to different stages of speech processing in human cortex. ",
    "url": "https://arxiv.org/abs/2205.14252",
    "authors": [
      "Aditya R. Vaidya",
      "Shailee Jain",
      "Alexander G. Huth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.14259",
    "title": "Personalized PageRank Graph Attention Networks",
    "abstract": "There has been a rising interest in graph neural networks (GNNs) for representation learning over the past few years. GNNs provide a general and efficient framework to learn from graph-structured data. However, GNNs typically only use the information of a very limited neighborhood for each node to avoid over-smoothing. A larger neighborhood would be desirable to provide the model with more information. In this work, we incorporate the limit distribution of Personalized PageRank (PPR) into graph attention networks (GATs) to reflect the larger neighbor information without introducing over-smoothing. Intuitively, message aggregation based on Personalized PageRank corresponds to infinitely many neighborhood aggregation layers. We show that our models outperform a variety of baseline models for four widely used benchmark datasets. Our implementation is publicly available online. ",
    "url": "https://arxiv.org/abs/2205.14259",
    "authors": [
      "Julie Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14268",
    "title": "NeuPSL: Neural Probabilistic Soft Logic",
    "abstract": "We present Neural Probabilistic Soft Logic (NeuPSL), a novel neuro-symbolic (NeSy) framework that unites state-of-the-art symbolic reasoning with the low-level perception of deep neural networks. To explicitly model the boundary between neural and symbolic representations, we introduce NeSy Energy-Based Models, a general family of energy-based models that combine neural and symbolic reasoning. Using this framework, we show how to seamlessly integrate neural and symbolic parameter learning and inference. We perform an extensive empirical evaluation and show that NeuPSL outperforms existing methods on joint inference and has significantly lower variance in almost all settings. ",
    "url": "https://arxiv.org/abs/2205.14268",
    "authors": [
      "Connor Pryor",
      "Charles Dickens",
      "Eriq Augustine",
      "Alon Albalak",
      "William Wang",
      "Lise Getoor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14269",
    "title": "Temporal graph patterns by timed automata",
    "abstract": "Temporal graphs represent graph evolution over time, and have been receiving considerable research attention. Work on expressing temporal graph patterns or discovering temporal motifs typically assumes relatively simple temporal constraints, such as journeys or, more generally, existential constraints, possibly with finite delays. In this paper we propose to use timed automata to express temporal constraints, leading to a general and powerful notion of temporal basic graph pattern (BGP). The new difficulty is the evaluation of the temporal constraint on a large set of matchings. An important benefit of timed automata is that they support an iterative state assignment, which can be useful for early detection of matches and pruning of non-matches. We introduce algorithms to retrieve all instances of a temporal BGP match in a graph, and present results of an extensive experimental evaluation, demonstrating interesting performance trade-offs. We show that an on-demand algorithm that processes total matchings incrementally over time is preferable when dealing with cyclic patterns on sparse graphs. On acyclic patterns or dense graphs, and when connectivity of partial matchings can be guaranteed, the best performance is achieved by maintaining partial matchings over time and allowing automaton evaluation to be fully incremental. ",
    "url": "https://arxiv.org/abs/2205.14269",
    "authors": [
      "Amir Pouya Aghasadeghi",
      "Jan Van den Bussche",
      "Julia Stoyanovich"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2205.14271",
    "title": "Towards Communication-Learning Trade-off for Federated Learning at the  Network Edge",
    "abstract": "In this letter, we study a wireless federated learning (FL) system where network pruning is applied to local users with limited resources. Although pruning is beneficial to reduce FL latency, it also deteriorates learning performance due to the information loss. Thus, a trade-off problem between communication and learning is raised. To address this challenge, we quantify the effects of network pruning and packet error on the learning performance by deriving the convergence rate of FL with a non-convex loss function. Then, closed-form solutions for pruning control and bandwidth allocation are proposed to minimize the weighted sum of FL latency and FL performance. Finally, numerical results demonstrate that 1) our proposed solution can outperform benchmarks in terms of cost reduction and accuracy guarantee, and 2) a higher pruning rate would bring less communication overhead but also worsen FL accuracy, which is consistent with our theoretical analysis. ",
    "url": "https://arxiv.org/abs/2205.14271",
    "authors": [
      "Jianyang Ren",
      "Wanli Ni",
      "Hui Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.14275",
    "title": "Image Keypoint Matching using Graph Neural Networks",
    "abstract": "Image matching is a key component of many tasks in computer vision and its main objective is to find correspondences between features extracted from different natural images. When images are represented as graphs, image matching boils down to the problem of graph matching which has been studied intensively in the past. In recent years, graph neural networks have shown great potential in the graph matching task, and have also been applied to image matching. In this paper, we propose a graph neural network for the problem of image matching. The proposed method first generates initial soft correspondences between keypoints using localized node embeddings and then iteratively refines the initial correspondences using a series of graph neural network layers. We evaluate our method on natural image datasets with keypoint annotations and show that, in comparison to a state-of-the-art model, our method speeds up inference times without sacrificing prediction accuracy. ",
    "url": "https://arxiv.org/abs/2205.14275",
    "authors": [
      "Nancy Xu",
      "Giannis Nikolentzos",
      "Michalis Vazirgiannis",
      "Henrik Bostr\u00f6m"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14289",
    "title": "Contrastive Learning for Multi-Modal Automatic Code Review",
    "abstract": "Automatic code review (ACR), aiming to relieve manual inspection costs, is an indispensable and essential task in software engineering. The existing works only use the source code fragments to predict the results, missing the exploitation of developer's comments. Thus, we present a Multi-Modal Apache Automatic Code Review dataset (MACR) for the Multi-Modal ACR task. The release of this dataset would push forward the research in this field. Based on it, we propose a Contrastive Learning based Multi-Modal Network (CLMN) to deal with the Multi-Modal ACR task. Concretely, our model consists of a code encoding module and a text encoding module. For each module, we use the dropout operation as minimal data augmentation. Then, the contrastive learning method is adopted to pre-train the module parameters. Finally, we combine the two encoders to fine-tune the CLMN to decide the results of Multi-Modal ACR. Experimental results on the MACR dataset illustrate that our proposed model outperforms the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2205.14289",
    "authors": [
      "Bingting Wu",
      "Xiaofang Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.14296",
    "title": "On the Complexity of Maximizing Social Welfare within Fair Allocations  of Indivisible Goods",
    "abstract": "Fair division is a classical topic studied in various disciplines and captures many real applications. One important issue in fair division is to cope with (economic) efficiency and fairness. A natural question along this direction that receives considerable attention is: How to obtain the most efficient allocations among all the fair allocations? In this paper, we study the complexity of maximizing social welfare within envy-free up to one item (EF1) allocations of indivisible goods for both normalized and unnormalized valuations. With two agents, we show a fully polynomial time approximation scheme (FPTAS) and complement this positive result with the NP-hardness result where the latter resolves an open problem raised by the previous work. Further, when the number of agents $n$ is a constant, we provide a bi-criteria algorithm that finds the optimal social welfare while relaxing EF1 by a factor arbitrarily close to 1. We complement this by providing several strong inapproximability results if EF1 is not allowed to relax. In particular, we demonstrate that the inapproximability becomes stronger as $n$ increases. Last, we consider the case with general number of agents. In this case, we give a variant of the round-robin algorithm with an approximation ratio of $1/n$ for unnormalized valuations and provide inapproximability results of $n^{1/3-\\varepsilon}$ and $m^{1/2-\\varepsilon}$ for normalized valuations. In addition, we show that our results of bi-criteria optimization for constant $n$ cannot be extended to the setting here, unless P=NP. ",
    "url": "https://arxiv.org/abs/2205.14296",
    "authors": [
      "Xiaolin Bu",
      "Zihao Li",
      "Shengxin Liu",
      "Jiaxin Song",
      "Biaoshuai Tao"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2205.14297",
    "title": "Fake It Till You Make It: Near-Distribution Novelty Detection by  Score-Based Generative Models",
    "abstract": "We aim for image-based novelty detection. Despite considerable progress, existing models either fail or face a dramatic drop under the so-called ``near-distribution\" setting, where the differences between normal and anomalous samples are subtle. We first demonstrate existing methods experience up to 20\\% decrease in performance in the near-distribution setting. Next, we propose to exploit a score-based generative model to produce synthetic near-distribution anomalous data. Our model is then fine-tuned to distinguish such data from the normal samples. We provide a quantitative as well as qualitative evaluation of this strategy, and compare the results with a variety of GAN-based models. Effectiveness of our method for both the near-distribution and standard novelty detection is assessed through extensive experiments on datasets in diverse applications such as medical images, object classification, and quality control. This reveals that our method considerably improves over existing models, and consistently decreases the gap between the near-distribution and standard novelty detection performance. Overall, our method improves the near-distribution novelty detection by 6% and passes the state-of-the-art by 1% to 5% across nine novelty detection benchmarks. The code repository is available at https://github.com/rohban-lab/FITYMI ",
    "url": "https://arxiv.org/abs/2205.14297",
    "authors": [
      "Hossein Mirzaei",
      "Mohammadreza Salehi",
      "Sajjad Shahabi",
      "Efstratios Gavves",
      "Cees G. M. Snoek",
      "Mohammad Sabokrou",
      "Mohammad Hossein Rohban"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14300",
    "title": "A Quadrature Perspective on Frequency Bias in Neural Network Training  with Nonuniform Data",
    "abstract": "Small generalization errors of over-parameterized neural networks (NNs) can be partially explained by the frequency biasing phenomenon, where gradient-based algorithms minimize the low-frequency misfit before reducing the high-frequency residuals. Using the Neural Tangent Kernel (NTK), one can provide a theoretically rigorous analysis for training where data are drawn from constant or piecewise-constant probability densities. Since most training data sets are not drawn from such distributions, we use the NTK model and a data-dependent quadrature rule to theoretically quantify the frequency biasing of NN training given fully nonuniform data. By replacing the loss function with a carefully selected Sobolev norm, we can further amplify, dampen, counterbalance, or reverse the intrinsic frequency biasing in NN training. ",
    "url": "https://arxiv.org/abs/2205.14300",
    "authors": [
      "Annan Yu",
      "Yunan Yang",
      "Alex Townsend"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14303",
    "title": "Deep Embedded Clustering with Distribution Consistency Preservation for  Attributed Networks",
    "abstract": "Many complex systems in the real world can be characterized by attributed networks. To mine the potential information in these networks, deep embedded clustering, which obtains node representations and clusters simultaneously, has been paid much attention in recent years. Under the assumption of consistency for data in different views, the cluster structure of network topology and that of node attributes should be consistent for an attributed network. However, many existing methods ignore this property, even though they separately encode node representations from network topology and node attributes meanwhile clustering nodes on representation vectors learnt from one of the views. Therefore, in this study, we propose an end-to-end deep embedded clustering model for attributed networks. It utilizes graph autoencoder and node attribute autoencoder to respectively learn node representations and cluster assignments. In addition, a distribution consistency constraint is introduced to maintain the latent consistency of cluster distributions of two views. Extensive experiments on several datasets demonstrate that the proposed model achieves significantly better or competitive performance compared with the state-of-the-art methods. The source code can be found at https://github.com/Zhengymm/DCP. ",
    "url": "https://arxiv.org/abs/2205.14303",
    "authors": [
      "Yimei Zheng",
      "Caiyan Jia",
      "Jian Yu",
      "Xuanya Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.14304",
    "title": "Multimodal Fake News Detection via CLIP-Guided Learning",
    "abstract": "Multimodal fake news detection has attracted many research interests in social forensics. Many existing approaches introduce tailored attention mechanisms to guide the fusion of unimodal features. However, how the similarity of these features is calculated and how it will affect the decision-making process in FND are still open questions. Besides, the potential of pretrained multi-modal feature learning models in fake news detection has not been well exploited. This paper proposes a FND-CLIP framework, i.e., a multimodal Fake News Detection network based on Contrastive Language-Image Pretraining (CLIP). Given a targeted multimodal news, we extract the deep representations from the image and text using a ResNet-based encoder, a BERT-based encoder and two pair-wise CLIP encoders. The multimodal feature is a concatenation of the CLIP-generated features weighted by the standardized cross-modal similarity of the two modalities. The extracted features are further processed for redundancy reduction before feeding them into the final classifier. We introduce a modality-wise attention module to adaptively reweight and aggregate the features. We have conducted extensive experiments on typical fake news datasets. The results indicate that the proposed framework has a better capability in mining crucial features for fake news detection. The proposed FND-CLIP can achieve better performances than previous works, i.e., 0.7\\%, 6.8\\% and 1.3\\% improvements in overall accuracy on Weibo, Politifact and Gossipcop, respectively. Besides, we justify that CLIP-based learning can allow better flexibility on multimodal feature selection. ",
    "url": "https://arxiv.org/abs/2205.14304",
    "authors": [
      "Yangming Zhou",
      "Qichao Ying",
      "Zhenxing Qian",
      "Sheng Li",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14305",
    "title": "Ensemble2: Anomaly Detection via EVT-Ensemble Framework for Seasonal  KPIs in Communication Network",
    "abstract": "KPI anomaly detection is one important function of network management system. Traditional methods either require prior knowledge or manually set thresholds. To overcome these shortcomings, we propose the Ensemble2 framework, which applies ensemble learning to improve exogenous capabilities. Meanwhile, automatically adjusts thresholds based on extreme value theory. The model is tested on production datasets to verify its effectiveness. We further optimize the model using online learning, and finally running at a speed of ~10 pts/s on an Intel i5 platform. ",
    "url": "https://arxiv.org/abs/2205.14305",
    "authors": [
      "Shi-Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14307",
    "title": "TFLEX: Temporal Feature-Logic Embedding Framework for Complex Reasoning  over Temporal Knowledge Graph",
    "abstract": "Multi-hop logical reasoning over knowledge graph (KG) plays a fundamental role in many artificial intelligence tasks. Recent complex query embedding (CQE) methods for reasoning focus on static KGs, while temporal knowledge graphs (TKGs) have not been fully explored. Reasoning over TKGs has two challenges: 1. The query should answer entities or timestamps; 2. The operators should consider both set logic on entity set and temporal logic on timestamp set. To bridge this gap, we define the multi-hop logical reasoning problem on TKGs. With generated three datasets, we propose the first temporal CQE named Temporal Feature-Logic Embedding framework (TFLEX) to answer the temporal complex queries. We utilize vector logic to compute the logic part of Temporal Feature-Logic embeddings, thus naturally modeling all First-Order Logic (FOL) operations on entity set. In addition, our framework extends vector logic on timestamp set to cope with three extra temporal operators (After, Before and Between). Experiments on numerous query patterns demonstrate the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2205.14307",
    "authors": [
      "Xueyuan Lin",
      "Chengjin Xu",
      "Haihong E",
      "Fenglong Su",
      "Gengxian Zhou",
      "Tianyi Hu",
      "Ningyuan Li",
      "Mingzhi Sun",
      "Haoran Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14309",
    "title": "Federated Neural Bandit",
    "abstract": "Recent works on neural contextual bandit have achieved compelling performances thanks to their ability to leverage the strong representation power of neural networks (NNs) for reward prediction. Many applications of contextual bandit involve multiple agents who collaborate without sharing raw observations, giving rise to the setting of federated contextual bandit. Existing works on federated contextual bandit rely on linear or kernelized bandit, which may fall short when modeling complicated real-world reward functions. In this regard, we introduce the federated neural-upper confidence bound (FN-UCB) algorithm. To better exploit the federated setting, we adopt a weighted combination of two UCBs: $\\text{UCB}^{a}$ allows every agent to additionally use the observations from the other agents to accelerate exploration (without sharing raw observations); $\\text{UCB}^{b}$ uses an NN with aggregated parameters for reward prediction in a similar way as federated averaging for supervised learning. Notably, the weight between the two UCBs required by our theoretical analysis is amenable to an interesting interpretation, which emphasizes $\\text{UCB}^{a}$ initially for accelerated exploration and relies more on $\\text{UCB}^{b}$ later after enough observations have been collected to train the NNs for accurate reward prediction (i.e., reliable exploitation). We prove sub-linear upper bounds on both the cumulative regret and the number of communication rounds of FN-UCB, and use empirical experiments to demonstrate its competitive performances. ",
    "url": "https://arxiv.org/abs/2205.14309",
    "authors": [
      "Zhongxiang Dai",
      "Yao Shu",
      "Arun Verma",
      "Flint Xiaofeng Fan",
      "Bryan Kian Hsiang Low",
      "Patrick Jaillet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.14310",
    "title": "Approximate Conditional Coverage via Neural Model Approximations",
    "abstract": "Constructing reliable prediction sets is an obstacle for applications of neural models: Distribution-free conditional coverage is theoretically impossible, and the exchangeability assumption underpinning the coverage guarantees of standard split-conformal approaches is violated on domain shifts. Given these challenges, we propose and analyze a data-driven procedure for obtaining empirically reliable approximate conditional coverage, calculating unique quantile thresholds for each label for each test point. We achieve this via the strong signals for prediction reliability from KNN-based model approximations over the training set and approximations over constrained samples from the held-out calibration set. We demonstrate the potential for substantial (and otherwise unknowable) under-coverage with split-conformal alternatives with marginal coverage guarantees when not taking these distances and constraints into account with protein secondary structure prediction, grammatical error detection, sentiment classification, and fact verification, covering supervised sequence labeling, zero-shot sequence labeling (i.e., feature detection), document classification (with sparsity/interpretability constraints), and retrieval-classification, including class-imbalanced and domain-shifted settings. ",
    "url": "https://arxiv.org/abs/2205.14310",
    "authors": [
      "Allen Schmaltz",
      "Danielle Rasooly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.14311",
    "title": "Robust Molecular Image Recognition: A Graph Generation Approach",
    "abstract": "Molecular image recognition is a fundamental task in information extraction from chemistry literature. Previous data-driven models formulate it as an image-to-sequence task, to generate a sequential representation of the molecule (e.g. SMILES string) from its graphical representation. Although they perform adequately on certain benchmarks, these models are not robust in real-world situations, where molecular images differ in style, quality, and chemical patterns. In this paper, we propose a novel graph generation approach that explicitly predicts atoms and bonds, along with their geometric layouts, to construct the molecular graph. We develop data augmentation strategies for molecules and images to increase the robustness of our model against domain shifts. Our model is flexible to incorporate chemistry constraints, and produces more interpretable predictions than SMILES. In experiments on both synthetic and realistic molecular images, our model significantly outperforms previous models, achieving 84-93% accuracy on five benchmarks. We also conduct human evaluation and show that our model reduces the time for a chemist to extract molecular structures from images by roughly 50%. ",
    "url": "https://arxiv.org/abs/2205.14311",
    "authors": [
      "Yujie Qian",
      "Zhengkai Tu",
      "Jiang Guo",
      "Connor W. Coley",
      "Regina Barzilay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.14315",
    "title": "Efficient Federated Learning with Spike Neural Networks for Traffic Sign  Recognition",
    "abstract": "With the gradual popularization of self-driving, it is becoming increasingly important for vehicles to smartly make the right driving decisions and autonomously obey traffic rules by correctly recognizing traffic signs. However, for machine learning-based traffic sign recognition on the Internet of Vehicles (IoV), a large amount of traffic sign data from distributed vehicles is needed to be gathered in a centralized server for model training, which brings serious privacy leakage risk because of traffic sign data containing lots of location privacy information. To address this issue, we first exploit privacy-preserving federated learning to perform collaborative training for accurate recognition models without sharing raw traffic sign data. Nevertheless, due to the limited computing and energy resources of most devices, it is hard for vehicles to continuously undertake complex artificial intelligence tasks. Therefore, we introduce powerful Spike Neural Networks (SNNs) into traffic sign recognition for energy-efficient and fast model training, which is the next generation of neural networks and is practical and well-fitted to IoV scenarios. Furthermore, we design a novel encoding scheme for SNNs based on neuron receptive fields to extract information from the pixel and spatial dimensions of traffic signs to achieve high-accuracy training. Numerical results indicate that the proposed federated SNN outperforms traditional federated convolutional neural networks in terms of accuracy, noise immunity, and energy efficiency as well. ",
    "url": "https://arxiv.org/abs/2205.14315",
    "authors": [
      "Kan Xie",
      "Zhe Zhang",
      "Bo Li",
      "Jiawen Kang",
      "Dusit Niyato",
      "Shengli Xie",
      "Yi Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14326",
    "title": "Adaptive Activation Network For Low Resource Multilingual Speech  Recognition",
    "abstract": "Low resource automatic speech recognition (ASR) is a useful but thorny task, since deep learning ASR models usually need huge amounts of training data. The existing models mostly established a bottleneck (BN) layer by pre-training on a large source language, and transferring to the low resource target language. In this work, we introduced an adaptive activation network to the upper layers of ASR model, and applied different activation functions to different languages. We also proposed two approaches to train the model: (1) cross-lingual learning, replacing the activation function from source language to target language, (2) multilingual learning, jointly training the Connectionist Temporal Classification (CTC) loss of each language and the relevance of different languages. Our experiments on IARPA Babel datasets demonstrated that our approaches outperform the from-scratch training and traditional bottleneck feature based methods. In addition, combining the cross-lingual learning and multilingual learning together could further improve the performance of multilingual speech recognition. ",
    "url": "https://arxiv.org/abs/2205.14326",
    "authors": [
      "Jian Luo",
      "Jianzong Wang",
      "Ning Cheng",
      "Zhenpeng Zheng",
      "Jing Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.14327",
    "title": "Efficient Policy Iteration for Robust Markov Decision Processes via  Regularization",
    "abstract": "Robust Markov decision processes (MDPs) provide a general framework to model decision problems where the system dynamics are changing or only partially known. Recent work established the equivalence between \\texttt{s} rectangular $L_p$ robust MDPs and regularized MDPs, and derived a regularized policy iteration scheme that enjoys the same level of efficiency as standard MDPs. However, there lacks a clear understanding of the policy improvement step. For example, we know the greedy policy can be stochastic but have little clue how each action affects this greedy policy. In this work, we focus on the policy improvement step and derive concrete forms for the greedy policy and the optimal robust Bellman operators. We find that the greedy policy is closely related to some combination of the top $k$ actions, which provides a novel characterization of its stochasticity. The exact nature of the combination depends on the shape of the uncertainty set. Furthermore, our results allow us to efficiently compute the policy improvement step by a simple binary search, without turning to an external optimization subroutine. Moreover, for $L_1, L_2$, and $L_\\infty$ robust MDPs, we can even get rid of the binary search and evaluate the optimal robust Bellman operators exactly. Our work greatly extends existing results on solving \\texttt{s}-rectangular $L_p$ robust MDPs via regularized policy iteration and can be readily adapted to sample-based model-free algorithms. ",
    "url": "https://arxiv.org/abs/2205.14327",
    "authors": [
      "Navdeep Kumar",
      "Kfir Levy",
      "Kaixin Wang",
      "Shie Mannor"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.14328",
    "title": "Point RCNN: An Angle-Free Framework for Rotated Object Detection",
    "abstract": "Rotated object detection in aerial images is still challenging due to arbitrary orientations, large scale and aspect ratio variations, and extreme density of objects. Existing state-of-the-art rotated object detection methods mainly rely on angle-based detectors. However, angle regression can easily suffer from the long-standing boundary problem. To tackle this problem, we propose a purely angle-free framework for rotated object detection, called Point RCNN, which mainly consists of PointRPN and PointReg. In particular, PointRPN generates accurate rotated RoIs (RRoIs) by converting the learned representative points with a coarse-to-fine manner, which is motivated by RepPoints. Based on the learned RRoIs, PointReg performs corner points refinement for more accurate detection. In addition, aerial images are often severely unbalanced in categories, and existing methods almost ignore this issue. In this paper, we also experimentally verify that re-sampling the images of the rare categories will stabilize training and further improve the detection performance. Experiments demonstrate that our Point RCNN achieves the new state-of-the-art detection performance on commonly used aerial datasets, including DOTA-v1.0, DOTA-v1.5, and HRSC2016. ",
    "url": "https://arxiv.org/abs/2205.14328",
    "authors": [
      "Qiang Zhou",
      "Chaohui Yu",
      "Zhibin Wang",
      "Hao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14329",
    "title": "Speech Augmentation Based Unsupervised Learning for Keyword Spotting",
    "abstract": "In this paper, we investigated a speech augmentation based unsupervised learning approach for keyword spotting (KWS) task. KWS is a useful speech application, yet also heavily depends on the labeled data. We designed a CNN-Attention architecture to conduct the KWS task. CNN layers focus on the local acoustic features, and attention layers model the long-time dependency. To improve the robustness of KWS model, we also proposed an unsupervised learning method. The unsupervised loss is based on the similarity between the original and augmented speech features, as well as the audio reconstructing information. Two speech augmentation methods are explored in the unsupervised learning: speed and intensity. The experiments on Google Speech Commands V2 Dataset demonstrated that our CNN-Attention model has competitive results. Moreover, the augmentation based unsupervised learning could further improve the classification accuracy of KWS task. In our experiments, with augmentation based unsupervised learning, our KWS model achieves better performance than other unsupervised methods, such as CPC, APC, and MPC. ",
    "url": "https://arxiv.org/abs/2205.14329",
    "authors": [
      "Jian Luo",
      "Jianzong Wang",
      "Ning Cheng",
      "Haobin Tang",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.14344",
    "title": "Data-Driven Evolutionary Multi-Objective Optimization Based on  Multiple-Gradient Descent for Disconnected Pareto Fronts",
    "abstract": "Data-driven evolutionary multi-objective optimization (EMO) has been recognized as an effective approach for multi-objective optimization problems with expensive objective functions. The current research is mainly developed for problems with a 'regular' triangle-like Pareto-optimal front (PF), whereas the performance can significantly deteriorate when the PF consists of disconnected segments. Furthermore, the offspring reproduction in the current data-driven EMO does not fully leverage the latent information of the surrogate model. Bearing these considerations in mind, this paper proposes a data-driven EMO algorithm based on multiple-gradient descent. By leveraging the regularity information provided by the up-to-date surrogate model, it is able to progressively probe a set of well distributed candidate solutions with a convergence guarantee. In addition, its infill criterion recommends a batch of promising candidate solutions to conduct expensive objective function evaluations. Experiments on $33$ benchmark test problem instances with disconnected PFs fully demonstrate the effectiveness of our proposed method against four selected peer algorithms. ",
    "url": "https://arxiv.org/abs/2205.14344",
    "authors": [
      "Renzhi Chen",
      "Ke Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.14349",
    "title": "Do We Really Need to Use Constraint Violation in Constrained  Evolutionary Multi-Objective Optimization?",
    "abstract": "Constraint violation has been a building block to design evolutionary multi-objective optimization algorithms for solving constrained multi-objective optimization problems. However, it is not uncommon that the constraint violation is hardly approachable in real-world black-box optimization scenarios. It is unclear that whether the existing constrained evolutionary multi-objective optimization algorithms, whose environmental selection mechanism are built upon the constraint violation, can still work or not when the formulations of the constraint functions are unknown. Bearing this consideration in mind, this paper picks up four widely used constrained evolutionary multi-objective optimization algorithms as the baseline and develop the corresponding variants that replace the constraint violation by a crisp value. From our experiments on both synthetic and real-world benchmark test problems, we find that the performance of the selected algorithms have not been significantly influenced when the constraint violation is not used to guide the environmental selection. ",
    "url": "https://arxiv.org/abs/2205.14349",
    "authors": [
      "Shuang Li",
      "Ke Li",
      "Wei Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.14354",
    "title": "Multi-Task Learning with Multi-query Transformer for Dense Prediction",
    "abstract": "Previous multi-task dense prediction studies developed complex pipelines such as multi-modal distillations in multiple stages or searching for task relational contexts for each task. The core insight beyond these methods is to maximize the mutual effects between each task. Inspired by the recent query-based Transformers, we propose a simpler pipeline named Multi-Query Transformer (MQTransformer) that is equipped with multiple queries from different tasks to facilitate the reasoning among multiple tasks and simplify the cross task pipeline. Instead of modeling the dense per-pixel context among different tasks, we seek a task-specific proxy to perform cross-task reasoning via multiple queries where each query encodes the task-related context. The MQTransformer is composed of three key components: shared encoder, cross task attention and shared decoder. We first model each task with a task-relevant and scale-aware query, and then both the image feature output by the feature extractor and the task-relevant query feature are fed into the shared encoder, thus encoding the query feature from the image feature. Secondly, we design a cross task attention module to reason the dependencies among multiple tasks and feature scales from two perspectives including different tasks of the same scale and different scales of the same task. Then we use a shared decoder to gradually refine the image features with the reasoned query features from different tasks. Extensive experiment results on two dense prediction datasets (NYUD-v2 and PASCAL-Context) show that the proposed method is an effective approach and achieves the state-of-the-art result. Code will be available. ",
    "url": "https://arxiv.org/abs/2205.14354",
    "authors": [
      "Yangyang Xu",
      "Xiangtai Li",
      "Haobo Yuan",
      "Yibo Yang",
      "Jing Zhang",
      "Yunhai Tong",
      "Lefei Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14368",
    "title": "Going Deeper into Permutation-Sensitive Graph Neural Networks",
    "abstract": "The invariance to permutations of the adjacency matrix, i.e., graph isomorphism, is an overarching requirement for Graph Neural Networks (GNNs). Conventionally, this prerequisite can be satisfied by the invariant operations over node permutations when aggregating messages. However, such an invariant manner may ignore the relationships among neighboring nodes, thereby hindering the expressivity of GNNs. In this work, we devise an efficient permutation-sensitive aggregation mechanism via permutation groups, capturing pairwise correlations between neighboring nodes. We prove that our approach is strictly more powerful than the 2-dimensional Weisfeiler-Lehman (2-WL) graph isomorphism test and not less powerful than the 3-WL test. Moreover, we prove that our approach achieves the linear sampling complexity. Comprehensive experiments on multiple synthetic and real-world datasets demonstrate the superiority of our model. ",
    "url": "https://arxiv.org/abs/2205.14368",
    "authors": [
      "Zhongyu Huang",
      "Yingheng Wang",
      "Chaozhuo Li",
      "Huiguang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.14371",
    "title": "GLITCH: an Intermediate-Representation-Based Security Analysis for  Infrastructure as Code Scripts",
    "abstract": "Infrastructure as Code (IaC) is the process of managing IT infrastructure via programmable configuration files (also called IaC scripts). Like other software artifacts, IaC scripts may contain security smells, which are coding patterns that can result in security weaknesses. Automated analysis tools to detect security smells in IaC scripts exist, but they focus on specific technologies such as Puppet, Ansible, or Chef. This means that when the detection of a new smell is implemented in one of the tools, it is not immediately available for the technologies supported by the other tools -- the only option is to duplicate the effort. This paper presents GLITCH, a new technology-agnostic framework that enables automated polyglot smell detection by transforming IaC scripts into an intermediate representation, on which different security smell detectors can be defined. GLITCH currently supports the detection of nine different security smells in scripts written in Puppet, Ansible, or Chef. We compare GLITCH with state-of-the-art security smell detectors. The results obtained not only show that GLITCH can reduce the effort of writing security smell analyses for multiple IaC technologies, but also that it has higher precision and recall than the current state-of-the-art tools. ",
    "url": "https://arxiv.org/abs/2205.14371",
    "authors": [
      "Nuno Saavedra",
      "Jo\u00e3o F. Ferreira"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.14374",
    "title": "Syntax-Guided Program Reduction for Understanding Neural Code  Intelligence Models",
    "abstract": "Neural code intelligence (CI) models are opaque black-boxes and offer little insight on the features they use in making predictions. This opacity may lead to distrust in their prediction and hamper their wider adoption in safety-critical applications. Recently, input program reduction techniques have been proposed to identify key features in the input programs to improve the transparency of CI models. However, this approach is syntax-unaware and does not consider the grammar of the programming language. In this paper, we apply a syntax-guided program reduction technique that considers the grammar of the input programs during reduction. Our experiments on multiple models across different types of input programs show that the syntax-guided program reduction technique is faster and provides smaller sets of key tokens in reduced programs. We also show that the key tokens could be used in generating adversarial examples for up to 65% of the input programs. ",
    "url": "https://arxiv.org/abs/2205.14374",
    "authors": [
      "Md Rafiqul Islam Rabin",
      "Aftab Hussain",
      "Mohammad Amin Alipour"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2205.14375",
    "title": "WaveMix-Lite: A Resource-efficient Neural Network for Image Analysis",
    "abstract": "Gains in the ability to generalize on image analysis tasks for neural networks have come at the cost of increased number of parameters and layers, dataset sizes, training and test computations, and GPU RAM. We introduce a new architecture -- WaveMix-Lite -- that can generalize on par with contemporary transformers and convolutional neural networks (CNNs) while needing fewer resources. WaveMix-Lite uses 2D-discrete wavelet transform to efficiently mix spatial information from pixels. WaveMix-Lite seems to be a versatile and scalable architectural framework that can be used for multiple vision tasks, such as image classification and semantic segmentation, without requiring significant architectural changes, unlike transformers and CNNs. It is able to meet or exceed several accuracy benchmarks while training on a single GPU. For instance, it achieves state-of-the-art accuracy on five EMNIST datasets, outperforms CNNs and transformers in ImageNet-1K (64$\\times$64 images), and achieves an mIoU of 75.32 % on Cityscapes validation set, while using less than one-fifth the number parameters and half the GPU RAM of comparable CNNs or transformers. Our experiments show that while the convolutional elements of neural architectures exploit the shift-invariance property of images, new types of layers (e.g., wavelet transform) can exploit additional properties of images, such as scale-invariance and finite spatial extents of objects. ",
    "url": "https://arxiv.org/abs/2205.14375",
    "authors": [
      "Pranav Jeevan",
      "Kavitha Viswanathan",
      "Amit Sethi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14380",
    "title": "Deep Deconfounded Content-based Tag Recommendation for UGC with Causal  Intervention",
    "abstract": "Traditional content-based tag recommender systems directly learn the association between user-generated content (UGC) and tags based on collected UGC-tag pairs. However, since a UGC uploader simultaneously creates the UGC and selects the corresponding tags, her personal preference inevitably biases the tag selections, which prevents these recommenders from learning the causal influence of UGCs' content features on tags. In this paper, we propose a deep deconfounded content-based tag recommender system, namely, DecTag, to address the above issues. We first establish a causal graph to represent the relations among uploader, UGC, and tag, where the uploaders are identified as confounders that spuriously correlate UGC and tag selections. Specifically, to eliminate the confounding bias, causal intervention is conducted on the UGC node in the graph via backdoor adjustment, where uploaders' influence on tags leaked through backdoor paths can be eliminated for causal effect estimation. Observing that adjusting the causal graph with do-calculus requires integrating the entire uploader space, which is infeasible, we design a novel Monte Carlo (MC)-based estimator with bootstrap, which can achieve asymptotic unbiasedness provided that uploaders for the collected UGCs are i.i.d. samples from the population. In addition, the MC estimator has the intuition of substituting the biased uploaders with a hypothetical random uploader from the population in the training phase, where deconfounding can be achieved in an interpretable manner. Finally, we establish a YT-8M-Causal dataset based on the widely used YouTube-8M dataset with causal intervention and propose an evaluation strategy accordingly to unbiasedly evaluate causal tag recommenders. Extensive experiments show that DecTag is more robust to confounding bias than state-of-the-art causal recommenders. ",
    "url": "https://arxiv.org/abs/2205.14380",
    "authors": [
      "Yaochen Zhu",
      "Xubin Ren",
      "Jing Yi",
      "Zhenzhong Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2205.14398",
    "title": "Deep neural networks overcome the curse of dimensionality in the  numerical approximation of semilinear partial differential equations",
    "abstract": "We prove that deep neural networks are capable of approximating solutions of semilinear Kolmogorov PDE in the case of gradient-independent, Lipschitz-continuous nonlinearities, while the required number of parameters in the networks grow at most polynomially in both dimension $d \\in \\mathbb{N}$ and prescribed reciprocal accuracy $\\varepsilon$. Previously, this has only been proven in the case of semilinear heat equations. ",
    "url": "https://arxiv.org/abs/2205.14398",
    "authors": [
      "Petru A. Cioica-Licht",
      "Martin Hutzenthaler",
      "P. Tobias Werner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2205.14403",
    "title": "Rethinking the Setting of Semi-supervised Learning on Graphs",
    "abstract": "We argue that the present setting of semisupervised learning on graphs may result in unfair comparisons, due to its potential risk of over-tuning hyper-parameters for models. In this paper, we highlight the significant influence of tuning hyper-parameters, which leverages the label information in the validation set to improve the performance. To explore the limit of over-tuning hyperparameters, we propose ValidUtil, an approach to fully utilize the label information in the validation set through an extra group of hyper-parameters. With ValidUtil, even GCN can easily get high accuracy of 85.8% on Cora. To avoid over-tuning, we merge the training set and the validation set and construct an i.i.d. graph benchmark (IGB) consisting of 4 datasets. Each dataset contains 100 i.i.d. graphs sampled from a large graph to reduce the evaluation variance. Our experiments suggest that IGB is a more stable benchmark than previous datasets for semisupervised learning on graphs. ",
    "url": "https://arxiv.org/abs/2205.14403",
    "authors": [
      "Ziang Li",
      "Ming Ding",
      "Weikai Li",
      "Zihan Wang",
      "Ziyu Zeng",
      "Yukuo Cen",
      "Jie Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14411",
    "title": "Feature Pyramid Attention based Residual Neural Network for  Environmental Sound Classification",
    "abstract": "Environmental sound classification (ESC) is a challenging problem due to the unstructured spatial-temporal relations that exist in the sound signals. Recently, many studies have focused on abstracting features from convolutional neural networks while the learning of semantically relevant frames of sound signals has been overlooked. To this end, we present an end-to-end framework, namely feature pyramid attention network (FPAM), focusing on abstracting the semantically relevant features for ESC. We first extract the feature maps of the preprocessed spectrogram of the sound waveform by a backbone network. Then, to build multi-scale hierarchical features of sound spectrograms, we construct a feature pyramid representation of the sound spectrograms by aggregating the feature maps from multi-scale layers, where the temporal frames and spatial locations of semantically relevant frames are localized by FPAM. Specifically, the multiple features are first processed by a dimension alignment module. Afterward, the pyramid spatial attention module (PSA) is attached to localize the important frequency regions spatially with a spatial attention module (SAM). Last, the processed feature maps are refined by a pyramid channel attention (PCA) to localize the important temporal frames. To justify the effectiveness of the proposed FPAM, visualization of attention maps on the spectrograms has been presented. The visualization results show that FPAM can focus more on the semantic relevant regions while neglecting the noises. The effectiveness of the proposed methods is validated on two widely used ESC datasets: the ESC-50 and ESC-10 datasets. The experimental results show that the FPAM yields comparable performance to state-of-the-art methods. A substantial performance increase has been achieved by FPAM compared with the baseline methods. ",
    "url": "https://arxiv.org/abs/2205.14411",
    "authors": [
      "Liguang Zhou",
      "Yuhongze Zhou",
      "Xiaonan Qi",
      "Junjie Hu",
      "Tin Lun Lam",
      "Yangsheng Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.14413",
    "title": "Discrimination-Based Double Auction for Maximizing Social Welfare in the  Electricity and Heating Market Considering Privacy Preservation",
    "abstract": "This paper proposes a doubled-sided auction mechanism with price discrimination for social welfare (SW) maximization in the electricity and heating market. In this mechanism, energy service providers (ESPs) submit offers and load aggregators (LAs) submit bids to an energy trading center (ETC) to maximize their utility; in turn, the selfless ETC as an auctioneer leverages dis-criminatory price weights to regulate the behaviors of ESPs and LAs, which combines the individual benefits of each stakeholder with the overall social welfare to achieve the global optimum. Nash games are employed to describe the interactions between players with the same market role. Theoretically, we first prove the existence and uniqueness of the Nash equilibrium; then, considering the requirement of game players to preserve privacy, a distributed algorithm based on the alternating direction method of multipliers is developed to implement distributed bidding and analytical target cascading algorithm is applied to reach the balance of demand and supply. We validated the proposed mechanism using case studies on a city-level distribution system. The results indicated that the achieved SW improved by 4%-15% compared with other mechanisms, and also verified the effectiveness of the distributed algorithm. ",
    "url": "https://arxiv.org/abs/2205.14413",
    "authors": [
      "Lu Wang",
      "Wei Gu",
      "Shuai Lu",
      "Haifeng Qiu",
      "Zhi Wu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2205.14418",
    "title": "Data Generation for Satellite Image Classification Using Self-Supervised  Representation Learning",
    "abstract": "Supervised deep neural networks are the-state-of-the-art for many tasks in the remote sensing domain, against the fact that such techniques require the dataset consisting of pairs of input and label, which are rare and expensive to collect in term of both manpower and resources. On the other hand, there are abundance of raw satellite images available both for commercial and academic purposes. Hence, in this work, we tackle the insufficient labeled data problem in satellite image classification task by introducing the process based on the self-supervised learning technique to create the synthetic labels for satellite image patches. These synthetic labels can be used as the training dataset for the existing supervised learning techniques. In our experiments, we show that the models trained on the synthetic labels give similar performance to the models trained on the real labels. And in the process of creating the synthetic labels, we also obtain the visual representation vectors that are versatile and knowledge transferable. ",
    "url": "https://arxiv.org/abs/2205.14418",
    "authors": [
      "Sarun Gulyanon",
      "Wasit Limprasert",
      "Pokpong Songmuang",
      "Rachada Kongkachandra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14421",
    "title": "Approximation of Functionals by Neural Network without Curse of  Dimensionality",
    "abstract": "In this paper, we establish a neural network to approximate functionals, which are maps from infinite dimensional spaces to finite dimensional spaces. The approximation error of the neural network is $O(1/\\sqrt{m})$ where $m$ is the size of networks, which overcomes the curse of dimensionality. The key idea of the approximation is to define a Barron space of functionals. ",
    "url": "https://arxiv.org/abs/2205.14421",
    "authors": [
      "Yahong Yang",
      "Yang Xiang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2205.14428",
    "title": "Go Beyond Multiple Instance Neural Networks: Deep-learning Models based  on Local Pattern Aggregation",
    "abstract": "Deep convolutional neural networks (CNNs) have brought breakthroughs in processing clinical electrocardiograms (ECGs), speaker-independent speech and complex images. However, typical CNNs require a fixed input size while it is common to process variable-size data in practical use. Recurrent networks such as long short-term memory (LSTM) are capable of eliminating the restriction, but suffer from high computational complexity. In this paper, we propose local pattern aggregation-based deep-learning models to effectively deal with both problems. The novel network structure, called LPANet, has cropping and aggregation operations embedded into it. With these new features, LPANet can reduce the difficulty of tuning model parameters and thus tend to improve generalization performance. To demonstrate the effectiveness, we applied it to the problem of premature ventricular contraction detection and the experimental results shows that our proposed method has certain advantages compared to classical network models, such as CNN and LSTM. ",
    "url": "https://arxiv.org/abs/2205.14428",
    "authors": [
      "Linpeng Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14433",
    "title": "Discovery and capabilities of guard proxies for CoRE networks",
    "abstract": "Constrained RESTful Environments tolerate and even benefit from proxy services. We explore the concept of proxies installed at entry points to constrained networks without any unified management. We sketch proxies of different levels of intrusiveness into applications, their announcement and discovery, and compare their theoretical capabilities in mitigating the effects of undesired traffic that can otherwise exhaust the environment's constrained resources. ",
    "url": "https://arxiv.org/abs/2205.14433",
    "authors": [
      "Christian Ams\u00fcss"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.14439",
    "title": "Laplace HypoPINN: Physics-Informed Neural Network for hypocenter  localization and its predictive uncertainty",
    "abstract": "Several techniques have been proposed over the years for automatic hypocenter localization. While those techniques have pros and cons that trade-off computational efficiency and the susceptibility of getting trapped in local minima, an alternate approach is needed that allows robust localization performance and holds the potential to make the elusive goal of real-time microseismic monitoring possible. Physics-informed neural networks (PINNs) have appeared on the scene as a flexible and versatile framework for solving partial differential equations (PDEs) along with the associated initial or boundary conditions. We develop HypoPINN -- a PINN-based inversion framework for hypocenter localization and introduce an approximate Bayesian framework for estimating its predictive uncertainties. This work focuses on predicting the hypocenter locations using HypoPINN and investigates the propagation of uncertainties from the random realizations of HypoPINN's weights and biases using the Laplace approximation. We train HypoPINN to obtain the optimized weights for predicting hypocenter location. Next, we approximate the covariance matrix at the optimized HypoPINN's weights for posterior sampling with the Laplace approximation. The posterior samples represent various realizations of HypoPINN's weights. Finally, we predict the locations of the hypocenter associated with those weights' realizations to investigate the uncertainty propagation that comes from those realisations. We demonstrate the features of this methodology through several numerical examples, including using the Otway velocity model based on the Otway project in Australia. ",
    "url": "https://arxiv.org/abs/2205.14439",
    "authors": [
      "Muhammad Izzatullah",
      "Isa Eren Yildirim",
      "Umair Bin Waheed",
      "Tariq Alkhalifah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2205.14440",
    "title": "Large-Scale Privacy-Preserving Network Embedding against Private Link  Inference Attacks",
    "abstract": "Network embedding represents network nodes by a low-dimensional informative vector. While it is generally effective for various downstream tasks, it may leak some private information of networks, such as hidden private links. In this work, we address a novel problem of privacy-preserving network embedding against private link inference attacks. Basically, we propose to perturb the original network by adding or removing links, and expect the embedding generated on the perturbed network can leak little information about private links but hold high utility for various downstream tasks. Towards this goal, we first propose general measurements to quantify privacy gain and utility loss incurred by candidate network perturbations; we then design a PPNE framework to identify the optimal perturbation solution with the best privacy-utility trade-off in an iterative way. Furthermore, we propose many techniques to accelerate PPNE and ensure its scalability. For instance, as the skip-gram embedding methods including DeepWalk and LINE can be seen as matrix factorization with closed form embedding results, we devise efficient privacy gain and utility loss approximation methods to avoid the repetitive time-consuming embedding training for every candidate network perturbation in each iteration. Experiments on real-life network datasets (with up to millions of nodes) verify that PPNE outperforms baselines by sacrificing less utility and obtaining higher privacy protection. ",
    "url": "https://arxiv.org/abs/2205.14440",
    "authors": [
      "Xiao Han",
      "Leye Wang",
      "Junjie Wu",
      "Yuncong Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.14443",
    "title": "A Closer Look at Self-supervised Lightweight Vision Transformers",
    "abstract": "Self-supervised learning on large-scale Vision Transformers (ViTs) as pre-training methods has achieved promising downstream performance. Yet, how such pre-training paradigms promote lightweight ViTs' performance is considerably less studied. In this work, we mainly produce recipes for pre-training high-performance lightweight ViTs using masked-image-modeling-based MAE, namely MAE-lite, which achieves 78.4% top-1 accuracy on ImageNet with ViT-Tiny (5.7M). Furthermore, we develop and benchmark other fully-supervised and self-supervised pre-training counterparts, e.g., contrastive-learning-based MoCo-v3, on both ImageNet and other classification tasks. We analyze and clearly show the effect of such pre-training, and reveal that properly-learned lower layers of the pre-trained models matter more than higher ones in data-sufficient downstream tasks. Finally, by further comparing with the pre-trained representations of the up-scaled models, a distillation strategy during pre-training is developed to improve the pre-trained representations as well, leading to further downstream performance improvement. The code and models will be made publicly available. ",
    "url": "https://arxiv.org/abs/2205.14443",
    "authors": [
      "Shaoru Wang",
      "Jin Gao",
      "Zeming Li",
      "Jian Sun",
      "Weiming Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14444",
    "title": "Visual Superordinate Abstraction for Robust Concept Learning",
    "abstract": "Concept learning constructs visual representations that are connected to linguistic semantics, which is fundamental to vision-language tasks. Although promising progress has been made, existing concept learners are still vulnerable to attribute perturbations and out-of-distribution compositions during inference. We ascribe the bottleneck to a failure of exploring the intrinsic semantic hierarchy of visual concepts, e.g. \\{red, blue,...\\} $\\in$ `color' subspace yet cube $\\in$ `shape'. In this paper, we propose a visual superordinate abstraction framework for explicitly modeling semantic-aware visual subspaces (i.e. visual superordinates). With only natural visual question answering data, our model first acquires the semantic hierarchy from a linguistic view, and then explores mutually exclusive visual superordinates under the guidance of linguistic hierarchy. In addition, a quasi-center visual concept clustering and a superordinate shortcut learning schemes are proposed to enhance the discrimination and independence of concepts within each visual superordinate. Experiments demonstrate the superiority of the proposed framework under diverse settings, which increases the overall answering accuracy relatively by 7.5\\% on reasoning with perturbations and 15.6\\% on compositional generalization tests. ",
    "url": "https://arxiv.org/abs/2205.14444",
    "authors": [
      "Qi Zheng",
      "Chaoyue Wang",
      "Dadong Wang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14449",
    "title": "Controller-Aware Dynamic Network Management for Industry 4.0",
    "abstract": "In this paper, we consider a cyber-physical manufacturing system (CPMS) scenario containing physical components (robots, sensors, and actuators), operating in a digitally connected, constrained environment to perform industrial tasks. The CPMS has a centralized control plane with digital twins (DTs) of the physical resources, computational resources, and a network manager that allocates network resources. Existing approaches for allocation of network resources are typically fixed with respect to controller-dependent run-time specifications, which may impact the performance of physical processes. We propose a dynamic network management framework, where the network resource allocation schemes are controller-aware. The information about the controllers of the physical resources is implemented at the DT level, and metrics, such as regret bounds, take the process performance measures into account. The proposed network management schemes optimize physical system performance by balancing the shared resources between the physical assets on the plant floor, and by considering their control requirements, providing a new perspective for dynamic resource allocation. A simulation study is provided to illustrate the performance of the proposed network management approaches and compare their efficiencies. ",
    "url": "https://arxiv.org/abs/2205.14449",
    "authors": [
      "Efe C. Balta",
      "Mohammad H. Mamduhi",
      "John Lygeros",
      "Alisa Rupenyan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.14460",
    "title": "Visual Perception of Building and Household Vulnerability from Streets",
    "abstract": "In developing countries, building codes often are outdated or not enforced. As a result, a large portion of the housing stock is substandard and vulnerable to natural hazards and climate related events. Assessing housing quality is key to inform public policies and private investments. Standard assessment methods are typically carried out only on a sample / pilot basis due to its high costs or, when complete, tend to be obsolete due to the lack of compliance with recommended updating standards or not accessible to most users with the level of detail needed to take key policy or business decisions. Thus, we propose an evaluation framework that is cost-efficient for first capture and future updates, and is reliable at the block level. The framework complements existing work of using street view imagery combined with deep learning to automatically extract building information to assist the identification of housing characteristics. We then check its potential for scalability and higher level reliability. For that purpose, we create an index, which synthesises the highest possible level of granularity of data at the housing unit and at the household level at the block level, and assess whether the predictions made by our model could be used to approximate vulnerability conditions with a lower budget and in selected areas. Our results indicated that the predictions from the images are clearly correlated with the index. ",
    "url": "https://arxiv.org/abs/2205.14460",
    "authors": [
      "Chaofeng Wang",
      "Sarah Elizabeth Antos",
      "Jessica Grayson Gosling Goldsmith",
      "Luis Miguel Triveno"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14492",
    "title": "A New High-Performance Approach to Approximate Pattern-Matching for  Plagiarism Detection in Blockchain-Based Non-Fungible Tokens (NFTs)",
    "abstract": "We are presenting a fast and innovative approach to performing approximate pattern-matching for plagiarism detection, using an NDFA-based approach that significantly enhances performance compared to other existing similarity measures. We outline the advantages of our approach in the context of blockchain-based non-fungible tokens (NFTs). We present, formalize, discuss and test our proposed approach in several real-world scenarios and with different similarity measures commonly used in plagiarism detection, and observe significant throughput enhancements throughout the entire spectrum of tests, with little to no compromises on the accuracy of the detection process overall. We conclude that our approach is suitable and adequate to perform approximate pattern-matching for plagiarism detection, and outline research directions for future improvements. ",
    "url": "https://arxiv.org/abs/2205.14492",
    "authors": [
      "Ciprian Pungila",
      "Darius Galis",
      "Viorel Negru"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14497",
    "title": "BadDet: Backdoor Attacks on Object Detection",
    "abstract": "Deep learning models have been deployed in numerous real-world applications such as autonomous driving and surveillance. However, these models are vulnerable in adversarial environments. Backdoor attack is emerging as a severe security threat which injects a backdoor trigger into a small portion of training data such that the trained model behaves normally on benign inputs but gives incorrect predictions when the specific trigger appears. While most research in backdoor attacks focuses on image classification, backdoor attacks on object detection have not been explored but are of equal importance. Object detection has been adopted as an important module in various security-sensitive applications such as autonomous driving. Therefore, backdoor attacks on object detection could pose severe threats to human lives and properties. We propose four kinds of backdoor attacks for object detection task: 1) Object Generation Attack: a trigger can falsely generate an object of the target class; 2) Regional Misclassification Attack: a trigger can change the prediction of a surrounding object to the target class; 3) Global Misclassification Attack: a single trigger can change the predictions of all objects in an image to the target class; and 4) Object Disappearance Attack: a trigger can make the detector fail to detect the object of the target class. We develop appropriate metrics to evaluate the four backdoor attacks on object detection. We perform experiments using two typical object detection models -- Faster-RCNN and YOLOv3 on different datasets. More crucially, we demonstrate that even fine-tuning on another benign dataset cannot remove the backdoor hidden in the object detection model. To defend against these backdoor attacks, we propose Detector Cleanse, an entropy-based run-time detection framework to identify poisoned testing samples for any deployed object detector. ",
    "url": "https://arxiv.org/abs/2205.14497",
    "authors": [
      "Shih-Han Chan",
      "Yinpeng Dong",
      "Jun Zhu",
      "Xiaolu Zhang",
      "Jun Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.14503",
    "title": "Towards Distributed 2-Approximation Steiner Minimal Trees in  Billion-edge Graphs",
    "abstract": "Given an edge-weighted graph and a set of known seed vertices, a network scientist often desires to understand the graph relationships to explain connections between the seed vertices. When the seed set is 3 or larger Steiner minimal tree - min-weight acyclic connected subgraph (of the input graph) that contains all the seed vertices - is an attractive generalization of shortest weighted paths. In general, computing a Steiner minimal tree is NP-hard, but several polynomial-time algorithms have been designed and proven to yield Steiner trees whose total weight is bounded within 2 times the Steiner minimal tree. In this paper, we present a parallel 2-approximation Steiner minimal tree algorithm and its MPI-based distributed implementation. In place of distance computation between all pairs of seed vertices, an expensive phase in many algorithms, our solution exploits Voronoi cell computation. Also, this approach has higher parallel efficiency than others that involve minimum spanning tree computation on the entire graph. Furthermore, our distributed design exploits asynchronous processing and a message prioritization scheme to accelerate convergence of distance computation, and harnesses both vertex and edge centric processing to offer fast time-to-solution. We demonstrate scalability and performance of our solution using real-world graphs with up to 128 billion edges and 512 compute nodes (8K processes). We compare our solution with the state-of-the-art exact Steiner minimal tree solver, SCIP-Jack, and two serial algorithms. Our solution comfortably outperforms these related works on graphs with 10s million edges and offers decent strong scaling - up to 90% efficient. We empirically show that, on average, the total distance of the Steiner tree identified by our solution is 1.0527 times greater than the Steiner minimal tree - well within the theoretical bound of less than equal to 2. ",
    "url": "https://arxiv.org/abs/2205.14503",
    "authors": [
      "Tahsin Reza",
      "Geoffrey Sanders",
      "Roger Pearce"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.14526",
    "title": "Group-wise Reinforcement Feature Generation for Optimal and Explainable  Representation Space Reconstruction",
    "abstract": "Representation (feature) space is an environment where data points are vectorized, distances are computed, patterns are characterized, and geometric structures are embedded. Extracting a good representation space is critical to address the curse of dimensionality, improve model generalization, overcome data sparsity, and increase the availability of classic models. Existing literature, such as feature engineering and representation learning, is limited in achieving full automation (e.g., over heavy reliance on intensive labor and empirical experiences), explainable explicitness (e.g., traceable reconstruction process and explainable new features), and flexible optimal (e.g., optimal feature space reconstruction is not embedded into downstream tasks). Can we simultaneously address the automation, explicitness, and optimal challenges in representation space reconstruction for a machine learning task? To answer this question, we propose a group-wise reinforcement generation perspective. We reformulate representation space reconstruction into an interactive process of nested feature generation and selection, where feature generation is to generate new meaningful and explicit features, and feature selection is to eliminate redundant features to control feature sizes. We develop a cascading reinforcement learning method that leverages three cascading Markov Decision Processes to learn optimal generation policies to automate the selection of features and operations and the feature crossing. We design a group-wise generation strategy to cross a feature group, an operation, and another feature group to generate new features and find the strategy that can enhance exploration efficiency and augment reward signals of cascading agents. Finally, we present extensive experiments to demonstrate the effectiveness, efficiency, traceability, and explicitness of our system. ",
    "url": "https://arxiv.org/abs/2205.14526",
    "authors": [
      "Dongjie Wang",
      "Yanjie Fu",
      "Kunpeng Liu",
      "Xiaolin Li",
      "Yan Solihin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.14548",
    "title": "Image Super-resolution with An Enhanced Group Convolutional Neural  Network",
    "abstract": "CNNs with strong learning abilities are widely chosen to resolve super-resolution problem. However, CNNs depend on deeper network architectures to improve performance of image super-resolution, which may increase computational cost in general. In this paper, we present an enhanced super-resolution group CNN (ESRGCNN) with a shallow architecture by fully fusing deep and wide channel features to extract more accurate low-frequency information in terms of correlations of different channels in single image super-resolution (SISR). Also, a signal enhancement operation in the ESRGCNN is useful to inherit more long-distance contextual information for resolving long-term dependency. An adaptive up-sampling operation is gathered into a CNN to obtain an image super-resolution model with low-resolution images of different sizes. Extensive experiments report that our ESRGCNN surpasses the state-of-the-arts in terms of SISR performance, complexity, execution speed, image quality evaluation and visual effect in SISR. Code is found at https://github.com/hellloxiaotian/ESRGCNN. ",
    "url": "https://arxiv.org/abs/2205.14548",
    "authors": [
      "Chunwei Tian",
      "Yixuan Yuan",
      "Shichao Zhang",
      "Chia-Wen Lin",
      "Wangmeng Zuo",
      "David Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.14549",
    "title": "Asymmetric Local Information Privacy and the Watchdog Mechanism",
    "abstract": "This paper proposes a novel watchdog privatization scheme by generalizing local information privacy (LIP) to enhance data utility. To protect the sensitive features $S$ correlated with some useful data $X$, LIP restricts the lift, the ratio of the posterior belief to the prior on $S$ after and before accessing $X$. For each $x$, both maximum and minimum lift over sensitive features are measures of the privacy risk of publishing this symbol and should be restricted for the privacy-preserving purpose. Previous works enforce the same bound for both max-lift and min-lift. However, empirical observations show that the min-lift is usually much smaller than the max-lift. In this work, we generalize the LIP definition to consider the unequal values of max and min lift, i.e., considering different bounds for max-lift and min-lift. This new definition is applied to the watchdog privacy mechanism. We demonstrate that the utility is enhanced under a given privacy constraint on local differential privacy. At the same time, the resulting max-lift is lower and, therefore, tightly restricts other privacy leakages, e.g., mutual information, maximal leakage, and $\\alpha$-leakage. ",
    "url": "https://arxiv.org/abs/2205.14549",
    "authors": [
      "Mohammad Amin Zarrabian",
      "Ni Ding",
      "Parastoo Sadeghi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2205.14557",
    "title": "Representation Gap in Deep Reinforcement Learning",
    "abstract": "Deep reinforcement learning gives the promise that an agent learns good policy from high-dimensional information. Whereas representation learning removes irrelevant and redundant information and retains pertinent information. We consider the representation capacity of action value function and theoretically reveal its inherent property, \\textit{representation gap} with its target action value function. This representation gap is favorable. However, through illustrative experiments, we show that the representation of action value function grows similarly compared with its target value function, i.e. the undesirable inactivity of the representation gap (\\textit{representation overlap}). Representation overlap results in a loss of representation capacity, which further leads to sub-optimal learning performance. To activate the representation gap, we propose a simple but effective framework \\underline{P}olicy \\underline{O}ptimization from \\underline{P}reventing \\underline{R}epresentation \\underline{O}verlaps (POPRO), which regularizes the policy evaluation phase through differing the representation of action value function from its target. We also provide the convergence rate guarantee of POPRO. We evaluate POPRO on gym continuous control suites. The empirical results show that POPRO using pixel inputs outperforms or parallels the sample-efficiency of methods that use state-based features. ",
    "url": "https://arxiv.org/abs/2205.14557",
    "authors": [
      "Qiang He",
      "Huangyuan Su",
      "Jieyu Zhang",
      "Xinwen Hou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.14573",
    "title": "ComplexGen: CAD Reconstruction by B-Rep Chain Complex Generation",
    "abstract": "We view the reconstruction of CAD models in the boundary representation (B-Rep) as the detection of geometric primitives of different orders, i.e. vertices, edges and surface patches, and the correspondence of primitives, which are holistically modeled as a chain complex, and show that by modeling such comprehensive structures more complete and regularized reconstructions can be achieved. We solve the complex generation problem in two steps. First, we propose a novel neural framework that consists of a sparse CNN encoder for input point cloud processing and a tri-path transformer decoder for generating geometric primitives and their mutual relationships with estimated probabilities. Second, given the probabilistic structure predicted by the neural network, we recover a definite B-Rep chain complex by solving a global optimization maximizing the likelihood under structural validness constraints and applying geometric refinements. Extensive tests on large scale CAD datasets demonstrate that the modeling of B-Rep chain complex structure enables more accurate detection for learning and more constrained reconstruction for optimization, leading to structurally more faithful and complete CAD B-Rep models than previous results. ",
    "url": "https://arxiv.org/abs/2205.14573",
    "authors": [
      "Haoxiang Guo",
      "Shilin Liu",
      "Hao Pan",
      "Yang Liu",
      "Xin Tong",
      "Baining Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2205.14576",
    "title": "Problem-Space Evasion Attacks in the Android OS: a Survey",
    "abstract": "Android is the most popular OS worldwide. Therefore, it is a target for various kinds of malware. As a countermeasure, the security community works day and night to develop appropriate Android malware detection systems, with ML-based or DL-based systems considered as some of the most common types. Against these detection systems, intelligent adversaries develop a wide set of evasion attacks, in which an attacker slightly modifies a malware sample to evade its target detection system. In this survey, we address problem-space evasion attacks in the Android OS, where attackers manipulate actual APKs, rather than their extracted feature vector. We aim to explore this kind of attacks, frequently overlooked by the research community due to a lack of knowledge of the Android domain, or due to focusing on general mathematical evasion attacks - i.e., feature-space evasion attacks. We discuss the different aspects of problem-space evasion attacks, using a new taxonomy, which focuses on key ingredients of each problem-space attack, such as the attacker model, the attacker's mode of operation, and the functional assessment of post-attack applications. ",
    "url": "https://arxiv.org/abs/2205.14576",
    "authors": [
      "Harel Berger",
      "Dr. Chen Hajaj",
      "Dr. Amit Dvir"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.14591",
    "title": "Joint Abductive and Inductive Neural Logical Reasoning",
    "abstract": "Neural logical reasoning (NLR) is a fundamental task in knowledge discovery and artificial intelligence. NLR aims at answering multi-hop queries with logical operations on structured knowledge bases based on distributed representations of queries and answers. While previous neural logical reasoners can give specific entity-level answers, i.e., perform inductive reasoning from the perspective of logic theory, they are not able to provide descriptive concept-level answers, i.e., perform abductive reasoning, where each concept is a summary of a set of entities. In particular, the abductive reasoning task attempts to infer the explanations of each query with descriptive concepts, which make answers comprehensible to users and is of great usefulness in the field of applied ontology. In this work, we formulate the problem of the joint abductive and inductive neural logical reasoning (AI-NLR), solving which needs to address challenges in incorporating, representing, and operating on concepts. We propose an original solution named ABIN for AI-NLR. Firstly, we incorporate description logic-based ontological axioms to provide the source of concepts. Then, we represent concepts and queries as fuzzy sets, i.e., sets whose elements have degrees of membership, to bridge concepts and queries with entities. Moreover, we design operators involving concepts on top of the fuzzy set representation of concepts and queries for optimization and inference. Extensive experimental results on two real-world datasets demonstrate the effectiveness of ABIN for AI-NLR. ",
    "url": "https://arxiv.org/abs/2205.14591",
    "authors": [
      "Zhenwei Tang",
      "Shichao Pei",
      "Xi Peng",
      "Fuzhen Zhuang",
      "Xiangliang Zhang",
      "Robert Hoehndorf"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2205.14593",
    "title": "Dynamic Graph Learning Based on Hierarchical Memory for  Origin-Destination Demand Prediction",
    "abstract": "Recent years have witnessed a rapid growth of applying deep spatiotemporal methods in traffic forecasting. However, the prediction of origin-destination (OD) demands is still a challenging problem since the number of OD pairs is usually quadratic to the number of stations. In this case, most of the existing spatiotemporal methods fail to handle spatial relations on such a large scale. To address this problem, this paper provides a dynamic graph representation learning framework for OD demands prediction. In particular, a hierarchical memory updater is first proposed to maintain a time-aware representation for each node, and the representations are updated according to the most recently observed OD trips in continuous-time and multiple discrete-time ways. Second, a spatiotemporal propagation mechanism is provided to aggregate representations of neighbor nodes along a random spatiotemporal route which treats origin and destination as two different semantic entities. Last, an objective function is designed to derive the future OD demands according to the most recent node representations, and also to tackle the data sparsity problem in OD prediction. Extensive experiments have been conducted on two real-world datasets, and the experimental results demonstrate the superiority of the proposed method. The code and data are available at https://github.com/Rising0321/HMOD. ",
    "url": "https://arxiv.org/abs/2205.14593",
    "authors": [
      "Ruixing Zhang",
      "Liangzhe Han",
      "Boyi Liu",
      "Jiayuan Zeng",
      "Leilei Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14606",
    "title": "A General Multiple Data Augmentation Based Framework for Training Deep  Neural Networks",
    "abstract": "Deep neural networks (DNNs) often rely on massive labelled data for training, which is inaccessible in many applications. Data augmentation (DA) tackles data scarcity by creating new labelled data from available ones. Different DA methods have different mechanisms and therefore using their generated labelled data for DNN training may help improving DNN's generalisation to different degrees. Combining multiple DA methods, namely multi-DA, for DNN training, provides a way to boost generalisation. Among existing multi-DA based DNN training methods, those relying on knowledge distillation (KD) have received great attention. They leverage knowledge transfer to utilise the labelled data sets created by multiple DA methods instead of directly combining them for training DNNs. However, existing KD-based methods can only utilise certain types of DA methods, incapable of utilising the advantages of arbitrary DA methods. We propose a general multi-DA based DNN training framework capable to use arbitrary DA methods. To train a DNN, our framework replicates a certain portion in the latter part of the DNN into multiple copies, leading to multiple DNNs with shared blocks in their former parts and independent blocks in their latter parts. Each of these DNNs is associated with a unique DA and a newly devised loss that allows comprehensively learning from the data generated by all DA methods and the outputs from all DNNs in an online and adaptive way. The overall loss, i.e., the sum of each DNN's loss, is used for training the DNN. Eventually, one of the DNNs with the best validation performance is chosen for inference. We implement the proposed framework by using three distinct DA methods and apply it for training representative DNNs. Experiments on the popular benchmarks of image classification demonstrate the superiority of our method to several existing single-DA and multi-DA based training methods. ",
    "url": "https://arxiv.org/abs/2205.14606",
    "authors": [
      "Binyan Hu",
      "Yu Sun",
      "A. K. Qin"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14612",
    "title": "Do Residual Neural Networks discretize Neural Ordinary Differential  Equations?",
    "abstract": "Neural Ordinary Differential Equations (Neural ODEs) are the continuous analog of Residual Neural Networks (ResNets). We investigate whether the discrete dynamics defined by a ResNet are close to the continuous one of a Neural ODE. We first quantify the distance between the ResNet's hidden state trajectory and the solution of its corresponding Neural ODE. Our bound is tight and, on the negative side, does not go to 0 with depth N if the residual functions are not smooth with depth. On the positive side, we show that this smoothness is preserved by gradient descent for a ResNet with linear residual functions and small enough initial loss. It ensures an implicit regularization towards a limit Neural ODE at rate 1 over N, uniformly with depth and optimization time. As a byproduct of our analysis, we consider the use of a memory-free discrete adjoint method to train a ResNet by recovering the activations on the fly through a backward pass of the network, and show that this method theoretically succeeds at large depth if the residual functions are Lipschitz with the input. We then show that Heun's method, a second order ODE integration scheme, allows for better gradient estimation with the adjoint method when the residual functions are smooth with depth. We experimentally validate that our adjoint method succeeds at large depth, and that Heun method needs fewer layers to succeed. We finally use the adjoint method successfully for fine-tuning very deep ResNets without memory consumption in the residual layers. ",
    "url": "https://arxiv.org/abs/2205.14612",
    "authors": [
      "Michael E. Sander",
      "Pierre Ablin",
      "Gabriel Peyr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.14619",
    "title": "Graph Structure Based Data Augmentation Method",
    "abstract": "In this paper, we propose a novel graph-based data augmentation method that can generally be applied to medical waveform data with graph structures. In the process of recording medical waveform data, such as electrocardiogram (ECG) or electroencephalogram (EEG), angular perturbations between the measurement leads exist due to discrepancies in lead positions. The data samples with large angular perturbations often cause inaccuracy in algorithmic prediction tasks. We design a graph-based data augmentation technique that exploits the inherent graph structures within the medical waveform data to improve both performance and robustness. In addition, we show that the performance gain from graph augmentation results from robustness by testing against adversarial attacks. Since the bases of performance gain are orthogonal, the graph augmentation can be used in conjunction with existing data augmentation techniques to further improve the final performance. We believe that our graph augmentation method opens up new possibilities to explore in data augmentation. ",
    "url": "https://arxiv.org/abs/2205.14619",
    "authors": [
      "Kyung Geun Kim",
      "Byeong Tak Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14620",
    "title": "IFRNet: Intermediate Feature Refine Network for Efficient Frame  Interpolation",
    "abstract": "Prevailing video frame interpolation algorithms, that generate the intermediate frames from consecutive inputs, typically rely on complex model architectures with heavy parameters or large delay, hindering them from diverse real-time applications. In this work, we devise an efficient encoder-decoder based network, termed IFRNet, for fast intermediate frame synthesizing. It first extracts pyramid features from given inputs, and then refines the bilateral intermediate flow fields together with a powerful intermediate feature until generating the desired output. The gradually refined intermediate feature can not only facilitate intermediate flow estimation, but also compensate for contextual details, making IFRNet do not need additional synthesis or refinement module. To fully release its potential, we further propose a novel task-oriented optical flow distillation loss to focus on learning the useful teacher knowledge towards frame synthesizing. Meanwhile, a new geometry consistency regularization term is imposed on the gradually refined intermediate features to keep better structure layout. Experiments on various benchmarks demonstrate the excellent performance and fast inference speed of proposed approaches. Code is available at https://github.com/ltkong218/IFRNet. ",
    "url": "https://arxiv.org/abs/2205.14620",
    "authors": [
      "Lingtong Kong",
      "Boyuan Jiang",
      "Donghao Luo",
      "Wenqing Chu",
      "Xiaoming Huang",
      "Ying Tai",
      "Chengjie Wang",
      "Jie Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14625",
    "title": "Cervical Glandular Cell Detection from Whole Slide Image with  Out-Of-Distribution Data",
    "abstract": "Cervical glandular cell (GC) detection is a key step in computer-aided diagnosis for cervical adenocarcinomas screening. It is challenging to accurately recognize GCs in cervical smears in which squamous cells are the major. Widely existing Out-Of-Distribution (OOD) data in the entire smear leads decreasing reliability of machine learning system for GC detection. Although, the State-Of-The-Art (SOTA) deep learning model can outperform pathologists in preselected regions of interest, the mass False Positive (FP) prediction with high probability is still unsolved when facing such gigapixel whole slide image. This paper proposed a novel PolarNet based on the morphological prior knowledge of GC trying to solve the FP problem via a self-attention mechanism in eight-neighbor. It estimates the polar orientation of nucleus of GC. As a plugin module, PolarNet can guide the deep feature and predicted confidence of general object detection models. In experiments, we discovered that general models based on four different frameworks can reject FP in small image set and increase the mean of average precision (mAP) by $\\text{0.007}\\sim\\text{0.015}$ in average, where the highest exceeds the recent cervical cell detection model 0.037. By plugging PolarNet, the deployed C++ program improved by 8.8\\% on accuracy of top-20 GC detection from external WSIs, while sacrificing 14.4 s of computational time. Code is available in \\href{https://github.com/Chrisa142857/PolarNet-GCdet}{https://github.com/Chrisa142857/PolarNet-GCdet}. ",
    "url": "https://arxiv.org/abs/2205.14625",
    "authors": [
      "Ziquan Wei",
      "Shenghua Cheng",
      "Xiuli Liu",
      "Shaoqun Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14629",
    "title": "Superclass Adversarial Attack",
    "abstract": "Adversarial attacks have only focused on changing the predictions of the classifier, but their danger greatly depends on how the class is mistaken. For example, when an automatic driving system mistakes a Persian cat for a Siamese cat, it is hardly a problem. However, if it mistakes a cat for a 120km/h minimum speed sign, serious problems can arise. As a stepping stone to more threatening adversarial attacks, we consider the superclass adversarial attack, which causes misclassification of not only fine classes, but also superclasses. We conducted the first comprehensive analysis of superclass adversarial attacks (an existing and 19 new methods) in terms of accuracy, speed, and stability, and identified several strategies to achieve better performance. Although this study is aimed at superclass misclassification, the findings can be applied to other problem settings involving multiple classes, such as top-k and multi-label classification attacks. ",
    "url": "https://arxiv.org/abs/2205.14629",
    "authors": [
      "Soichiro Kumano",
      "Hiroshi Kera",
      "Toshihiko Yamasaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14630",
    "title": "Physical Activation Functions (PAFs): An Approach for More Efficient  Induction of Physics into Physics-Informed Neural Networks (PINNs)",
    "abstract": "In recent years, the gap between Deep Learning (DL) methods and analytical or numerical approaches in scientific computing is tried to be filled by the evolution of Physics-Informed Neural Networks (PINNs). However, still, there are many complications in the training of PINNs and optimal interleaving of physical models. Here, we introduced the concept of Physical Activation Functions (PAFs). This concept offers that instead of using general activation functions (AFs) such as ReLU, tanh, and sigmoid for all the neurons, one can use generic AFs that their mathematical expression is inherited from the physical laws of the investigating phenomena. The formula of PAFs may be inspired by the terms in the analytical solution of the problem. We showed that the PAFs can be inspired by any mathematical formula related to the investigating phenomena such as the initial or boundary conditions of the PDE system. We validated the advantages of PAFs for several PDEs including the harmonic oscillations, Burgers, Advection-Convection equation, and the heterogeneous diffusion equations. The main advantage of PAFs was in the more efficient constraining and interleaving of PINNs with the investigating physical phenomena and their underlying mathematical models. This added constraint significantly improved the predictions of PINNs for the testing data that was out-of-training distribution. Furthermore, the application of PAFs reduced the size of the PINNs up to 75% in different cases. Also, the value of loss terms was reduced by 1 to 2 orders of magnitude in some cases which is noteworthy for upgrading the training of the PINNs. The iterations required for finding the optimum values were also significantly reduced. It is concluded that using the PAFs helps in generating PINNs with less complexity and much more validity for longer ranges of prediction. ",
    "url": "https://arxiv.org/abs/2205.14630",
    "authors": [
      "Jassem Abbasi",
      "P\u00e5l \u00d8steb\u00f8 Andersen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14643",
    "title": "Micro-Expression Recognition Based on Attribute Information Embedding  and Cross-modal Contrastive Learning",
    "abstract": "Facial micro-expressions recognition has attracted much attention recently. Micro-expressions have the characteristics of short duration and low intensity, and it is difficult to train a high-performance classifier with the limited number of existing micro-expressions. Therefore, recognizing micro-expressions is a challenge task. In this paper, we propose a micro-expression recognition method based on attribute information embedding and cross-modal contrastive learning. We use 3D CNN to extract RGB features and FLOW features of micro-expression sequences and fuse them, and use BERT network to extract text information in Facial Action Coding System. Through cross-modal contrastive loss, we embed attribute information in the visual network, thereby improving the representation ability of micro-expression recognition in the case of limited samples. We conduct extensive experiments in CASME II and MMEW databases, and the accuracy is 77.82% and 71.04%, respectively. The comparative experiments show that this method has better recognition effect than other methods for micro-expression recognition. ",
    "url": "https://arxiv.org/abs/2205.14643",
    "authors": [
      "Yanxin Song",
      "Jianzong Wang",
      "Tianbo Wu",
      "Zhangcheng Huang",
      "Jing Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14651",
    "title": "Contributions to Representation Learning with Graph Autoencoders and  Applications to Music Recommendation",
    "abstract": "Graph autoencoders (GAE) and variational graph autoencoders (VGAE) emerged as two powerful groups of unsupervised node embedding methods, with various applications to graph-based machine learning problems such as link prediction and community detection. Nonetheless, at the beginning of this Ph.D. project, GAE and VGAE models were also suffering from key limitations, preventing them from being adopted in the industry. In this thesis, we present several contributions to improve these models, with the general aim of facilitating their use to address industrial-level problems involving graph representations. Firstly, we propose two strategies to overcome the scalability issues of previous GAE and VGAE models, permitting to effectively train these models on large graphs with millions of nodes and edges. These strategies leverage graph degeneracy and stochastic subgraph decoding techniques, respectively. Besides, we introduce Gravity-Inspired GAE and VGAE, providing the first extensions of these models for directed graphs, that are ubiquitous in industrial applications. We also consider extensions of GAE and VGAE models for dynamic graphs. Furthermore, we argue that GAE and VGAE models are often unnecessarily complex, and we propose to simplify them by leveraging linear encoders. Lastly, we introduce Modularity-Aware GAE and VGAE to improve community detection on graphs, while jointly preserving good performances on link prediction. In the last part of this thesis, we evaluate our methods on several graphs extracted from the music streaming service Deezer. We put the emphasis on graph-based music recommendation problems. In particular, we show that our methods can improve the detection of communities of similar musical items to recommend to users, that they can effectively rank similar artists in a cold start setting, and that they permit modeling the music genre perception across cultures. ",
    "url": "https://arxiv.org/abs/2205.14651",
    "authors": [
      "Guillaume Salha-Galvan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.14655",
    "title": "Network Decoding",
    "abstract": "We consider the problem of error control in a coded, multicast network, focusing on the scenario where the errors can occur only on a proper subset of the network edges. We model this problem via an adversarial noise, presenting a formal framework and a series of techniques to obtain upper and lower bounds on the network's (1-shot) capacity, improving on the best currently known results. In particular, we show that traditional cut-set bounds are not tight in general in the presence of a restricted adversary, and that the non-tightness of these is caused precisely by the restrictions imposed on the noise (and not, as one may expect, by the alphabet size). We also show that, in sharp contrast with the typical situation within network coding, capacity cannot be achieved in general by combining linear network coding with end-to-end channel coding, not even when the underlying network has a single source and a single terminal. We finally illustrate how network decoding techniques are necessary to achieve capacity in the scenarios we examine, exhibiting capacity-achieving schemes and lower bounds for various classes of networks. ",
    "url": "https://arxiv.org/abs/2205.14655",
    "authors": [
      "Allison Beemer",
      "Altan Berdan Kilic",
      "Alberto Ravagnani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2205.14664",
    "title": "Heterogeneous Data-Centric Architectures for Modern Data-Intensive  Applications: Case Studies in Machine Learning and Databases",
    "abstract": "Today's computing systems require moving data back-and-forth between computing resources (e.g., CPUs, GPUs, accelerators) and off-chip main memory so that computation can take place on the data. Unfortunately, this data movement is a major bottleneck for system performance and energy consumption. One promising execution paradigm that alleviates the data movement bottleneck in modern and emerging applications is processing-in-memory (PIM), where the cost of data movement to/from main memory is reduced by placing computation capabilities close to memory. Naively employing PIM to accelerate data-intensive workloads can lead to sub-optimal performance due to the many design constraints PIM substrates impose. Therefore, many recent works co-design specialized PIM accelerators and algorithms to improve performance and reduce the energy consumption of (i) applications from various application domains; and (ii) various computing environments, including cloud systems, mobile systems, and edge devices. We showcase the benefits of co-designing algorithms and hardware in a way that efficiently takes advantage of the PIM paradigm for two modern data-intensive applications: (1) machine learning inference models for edge devices and (2) hybrid transactional/analytical processing databases for cloud systems. We follow a two-step approach in our system design. In the first step, we extensively analyze the computation and memory access patterns of each application to gain insights into its hardware/software requirements and major sources of performance and energy bottlenecks in processor-centric systems. In the second step, we leverage the insights from the first step to co-design algorithms and hardware accelerators to enable high-performance and energy-efficient data-centric architectures for each application. ",
    "url": "https://arxiv.org/abs/2205.14664",
    "authors": [
      "Geraldo F. Oliveira",
      "Amirali Boroumand",
      "Saugata Ghose",
      "Juan G\u00f3mez-Luna",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14665",
    "title": "Multi-Domain Virtual Network Embedding Algorithm based on Horizontal  Federated Learning",
    "abstract": "Network Virtualization (NV) is an emerging network dynamic planning technique to overcome network rigidity. As its necessary challenge, Virtual Network Embedding (VNE) enhances the scalability and flexibility of the network by decoupling the resources and services of the underlying physical network. For the future multi-domain physical network modeling with the characteristics of dynamics, heterogeneity, privacy, and real-time, the existing related works perform satisfactorily. Federated learning (FL) jointly optimizes the network by sharing parameters among multiple parties and is widely employed in disputes over data privacy and data silos. Aiming at the NV challenge of multi-domain physical networks, this work is the first to propose using FL to model VNE, and presents a VNE architecture based on Horizontal Federated Learning (HFL) (HFL-VNE). Specifically, combined with the distributed training paradigm of FL, we deploy local servers in each physical domain, which can effectively focus on local features and reduce resource fragmentation. A global server is deployed to aggregate and share training parameters, which enhances local data privacy and significantly improves learning efficiency. Furthermore, we deploy the Deep Reinforcement Learning (DRL) model in each server to dynamically adjust and optimize the resource allocation of the multi-domain physical network. In DRL-assisted FL, HFL-VNE jointly optimizes decision-making through specific local and federated reward mechanisms and loss functions. Finally, the superiority of HFL-VNE is proved by combining simulation experiments and comparing it with related works. ",
    "url": "https://arxiv.org/abs/2205.14665",
    "authors": [
      "Peiying Zhang",
      "Ning Chen",
      "Shibao Li",
      "Kim-Kwang Raymond Choo",
      "Chunxiao Jiang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.14676",
    "title": "Diminishing Empirical Risk Minimization for Unsupervised Anomaly  Detection",
    "abstract": "Unsupervised anomaly detection (AD) is a challenging task in realistic applications. Recently, there is an increasing trend to detect anomalies with deep neural networks (DNN). However, most popular deep AD detectors cannot protect the network from learning contaminated information brought by anomalous data, resulting in unsatisfactory detection performance and overfitting issues. In this work, we identify one reason that hinders most existing DNN-based anomaly detection methods from performing is the wide adoption of the Empirical Risk Minimization (ERM). ERM assumes that the performance of an algorithm on an unknown distribution can be approximated by averaging losses on the known training set. This averaging scheme thus ignores the distinctions between normal and anomalous instances. To break through the limitations of ERM, we propose a novel Diminishing Empirical Risk Minimization (DERM) framework. Specifically, DERM adaptively adjusts the impact of individual losses through a well-devised aggregation strategy. Theoretically, our proposed DERM can directly modify the gradient contribution of each individual loss in the optimization process to suppress the influence of outliers, leading to a robust anomaly detector. Empirically, DERM outperformed the state-of-the-art on the unsupervised AD benchmark consisting of 18 datasets. ",
    "url": "https://arxiv.org/abs/2205.14676",
    "authors": [
      "Shaoshen Wang",
      "Yanbin Liu",
      "Ling Chen",
      "Chengqi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14686",
    "title": "Saliency Map Based Data Augmentation",
    "abstract": "Data augmentation is a commonly applied technique with two seemingly related advantages. With this method one can increase the size of the training set generating new samples and also increase the invariance of the network against the applied transformations. Unfortunately all images contain both relevant and irrelevant features for classification therefore this invariance has to be class specific. In this paper we will present a new method which uses saliency maps to restrict the invariance of neural networks to certain regions, providing higher test accuracy in classification tasks. ",
    "url": "https://arxiv.org/abs/2205.14686",
    "authors": [
      "Jalal Al-afandi",
      "B\u00e1lint Magyar",
      "Andr\u00e1s Horv\u00e1th"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.14690",
    "title": "CoNT: Contrastive Neural Text Generation",
    "abstract": "Recently, contrastive learning attracts increasing interests in neural text generation as a new solution to alleviate the exposure bias problem. It introduces a sequence-level training signal which is crucial to generation tasks that always rely on auto-regressive decoding. However, previous methods using contrastive learning in neural text generation usually lead to inferior performance. In this paper, we analyse the underlying reasons and propose a new Contrastive Neural Text generation framework, CoNT. CoNT addresses bottlenecks that prevent contrastive learning from being widely adopted in generation tasks from three aspects -- the construction of contrastive examples, the choice of the contrastive loss, and the strategy in decoding. We validate CoNT on five generation tasks with ten benchmarks, including machine translation, summarization, code comment generation, data-to-text generation and commonsense generation. Experimental results show that CoNT clearly outperforms the conventional training framework on all the ten benchmarks with a convincing margin. Especially, CoNT surpasses previous the most competitive contrastive learning method for text generation, by 1.50 BLEU on machine translation and 1.77 ROUGE-1 on summarization, respectively. It achieves new state-of-the-art on summarization, code comment generation (without external data) and data-to-text generation. ",
    "url": "https://arxiv.org/abs/2205.14690",
    "authors": [
      "Chenxin An",
      "Jiangtao Feng",
      "Kai Lv",
      "Lingpeng Kong",
      "Xipeng Qiu",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.14691",
    "title": "On the Robustness of Safe Reinforcement Learning under Observational  Perturbations",
    "abstract": "Safe reinforcement learning (RL) trains a policy to maximize the task reward while satisfying safety constraints. While prior works focus on the performance optimality, we find that the optimal solutions of many safe RL problems are not robust and safe against carefully designed observational perturbations. We formally analyze the unique properties of designing effective state adversarial attackers in the safe RL setting. We show that baseline adversarial attack techniques for standard RL tasks are not always effective for safe RL and proposed two new approaches - one maximizes the cost and the other maximizes the reward. One interesting and counter-intuitive finding is that the maximum reward attack is strong, as it can both induce unsafe behaviors and make the attack stealthy by maintaining the reward. We further propose a more effective adversarial training framework for safe RL and evaluate it via comprehensive experiments. This work sheds light on the inherited connection between observational robustness and safety in RL and provides a pioneer work for future safe RL studies. ",
    "url": "https://arxiv.org/abs/2205.14691",
    "authors": [
      "Zuxin Liu",
      "Zijian Guo",
      "Zhepeng Cen",
      "Huan Zhang",
      "Jie Tan",
      "Bo Li",
      "Ding Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.14697",
    "title": "Evaluating Automated Driving Planner Robustness against Adversarial  Influence",
    "abstract": "Evaluating the robustness of automated driving planners is a critical and challenging task. Although methodologies to evaluate vehicles are well established, they do not yet account for a reality in which vehicles with autonomous components share the road with adversarial agents. Our approach, based on probabilistic trust models, aims to help researchers assess the robustness of protections for machine learning-enabled planners against adversarial influence. In contrast with established practices that evaluate safety using the same evaluation dataset for all vehicles, we argue that adversarial evaluation fundamentally requires a process that seeks to defeat a specific protection. Hence, we propose that evaluations be based on estimating the difficulty for an adversary to determine conditions that effectively induce unsafe behavior. This type of inference requires precise statements about threats, protections, and aspects of planning decisions to be guarded. We demonstrate our approach by evaluating protections for planners relying on camera-based object detectors. ",
    "url": "https://arxiv.org/abs/2205.14697",
    "authors": [
      "Andres Molina-Markham",
      "Silvia G. Ionescu",
      "Erin Lanus",
      "Derek Ng",
      "Sam Sommerer",
      "Joseph J. Rushanan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14705",
    "title": "Evaluating the Socioeconomic Status of a Large Social Event Attendees",
    "abstract": "In this study, Call Detail Records (CDRs) from downtown Budapest were analysed, focusing on a large-scale event in August 2014. The attendees of the main event of the Hungarian State Foundation Day have been analysed based on their Socioeconomic Status (SES). This paper proposes an approach to estimating SES by the price and age of the subscribers' phones, obtained by fusing a mobile phone property database with the CDRs. We have found some tendencies between the attendees based on the location, from where they watched the fireworks. However, the results do not show significant differences in this geographical granularity. ",
    "url": "https://arxiv.org/abs/2205.14705",
    "authors": [
      "Kerecsen Szab\u00f3",
      "Gerg\u0151 Pint\u00e9r",
      "Imre Felde"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.14716",
    "title": "Vision-Assisted User Clustering for Robust mmWave-NOMA Systems",
    "abstract": "NOMA is an emerging paradigm for B5G systems to support a large number and variety of connected users, simultaneously. When operated in the mmWave band and higher bands, user channels get highly correlated which can be exploited in mmWave-NOMA systems to cluster a set of correlated users together and serve them in one beam in the same time slot. Identifying the set of users to cluster together greatly affects the viability of NOMA systems. Typically, only CSI is used to make these clustering decisions. When any problem arises in accessing up-to-date and accurate CSI, user clustering will not properly function due to its hard-dependency on CSI, and obviously, this will negatively affect the robustness of these NOMA systems. To improve the robustness of the NOMA systems, in this paper, we propose to utilize emerging trends such as location-aware and camera-equipped base stations (CBSs) which do not require any extra radio frequency resource consumption. Specifically, we explore three different dimensions of feedback that a CBS can benefit from to solve the user clustering problem, namely CSI-based feedback and non-CSI-based feedback, comprised of UE location and the CBS camera feed. We first investigate how the vision assistance of a CBS can be used in conjunction with other dimensions of feedback to make clustering decisions in various scenarios. Later, we provide a simple user case study to illustrate how to implement vision-assisted user clustering in mmWave-NOMA systems to improve robustness, in which a DL beam selection algorithm is trained on the images captured by the CBS to perform NOMA clustering. We demonstrate that the user clustering without CSI can achieve comparable performance to accurate CSI-based user clustering solutions, and user clustering can continue to function without much performance loss even in the scenarios where CSI is severely outdated or not available at all. ",
    "url": "https://arxiv.org/abs/2205.14716",
    "authors": [
      "Aditya S. Rajasekaran",
      "Hamza U. Sokun",
      "Omar Maraqa",
      "Halim Yanikomeroglu",
      "Saad Al-Ahmadi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2205.14725",
    "title": "What are People Talking about in #BackLivesMatter and #StopAsianHate?  Exploring and Categorizing Twitter Topics Emerging in Online Social Movements  through the Latent Dirichlet Allocation Model",
    "abstract": "Minority groups have been using social media to organize social movements that create profound social impacts. Black Lives Matter (BLM) and Stop Asian Hate (SAH) are two successful social movements that have spread on Twitter that promote protests and activities against racism and increase the public's awareness of other social challenges that minority groups face. However, previous studies have mostly conducted qualitative analyses of tweets or interviews with users, which may not comprehensively and validly represent all tweets. Very few studies have explored the Twitter topics within BLM and SAH dialogs in a rigorous, quantified and data-centered approach. Therefore, in this research, we adopted a mixed-methods approach to comprehensively analyze BLM and SAH Twitter topics. We implemented (1) the latent Dirichlet allocation model to understand the top high-level words and topics and (2) open-coding analysis to identify specific themes across the tweets. We collected more than one million tweets with the #blacklivesmatter and #stopasianhate hashtags and compared their topics. Our findings revealed that the tweets discussed a variety of influential topics in depth, and social justice, social movements, and emotional sentiments were common topics in both movements, though with unique subtopics for each movement. Our study contributes to the topic analysis of social movements on social media platforms in particular and the literature on the interplay of AI, ethics, and society in general. ",
    "url": "https://arxiv.org/abs/2205.14725",
    "authors": [
      "Xin Tong",
      "Yixuan Li",
      "Jiayi Li",
      "Rongqi Bei",
      "Luyao Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.14735",
    "title": "Dynamic Control of Data-Intensive Services over Edge Computing Networks",
    "abstract": "Next-generation distributed computing networks (e.g., edge and fog computing) enable the efficient delivery of delay-sensitive, compute-intensive applications by facilitating access to computation resources in close proximity to end users. Many of these applications (e.g., augmented/virtual reality) are also data-intensive: in addition to user-specific (live) data streams, they require access to (static) digital objects (e.g., image database) to complete the required processing tasks. When required objects are not available at the servers hosting the associated service functions, they must be fetched from other edge locations, incurring additional communication cost and latency. In such settings, overall service delivery performance shall benefit from jointly optimized decisions around (i) routing paths and processing locations for live data streams, together with (ii) cache selection and distribution paths for associated digital objects. In this paper, we address the problem of dynamic control of data-intensive services over edge cloud networks. We characterize the network stability region and design the first throughput-optimal control policy that coordinates processing and routing decisions for both live and static data-streams. Numerical results demonstrate the superior performance (e.g., throughput, delay, and resource consumption) obtained via the novel multi-pipeline flow control mechanism of the proposed policy, compared with state-of-the-art algorithms that lack integrated stream processing and data distribution control. ",
    "url": "https://arxiv.org/abs/2205.14735",
    "authors": [
      "Yang Cai",
      "Jaime Llorca",
      "Antonia M. Tulino",
      "Andreas F. Molisch"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.14740",
    "title": "Investigating Participation Mechanisms in EU Code Week",
    "abstract": "Digital competence (DC) is a broad set of skills, attitudes, and knowledge for confident, critical and responsible use of digital technologies in every aspect of life. DC is fundamental to all people in conducting a productive and fulfilling life in an increasingly digital world. However, prejudices, misconceptions, and lack of awareness reduce the diffusion of DC, hindering digital transformation and preventing countries and people from realising their full potential. Teaching Informatics in the curriculum is increasingly supported by the institutions but faces serious challenges, such as teacher upskilling and support, and will require several years to observe sizeable outcomes. In response, grassroots movements promoting computing literacy in an informal setting have grown, including EU Code Week, whose vision is to develop computing skills while promoting diversity and raising awareness of the importance of digital skills. Code Week participation is a form of public engagement that could be affected by socio-economic and demographic factors, as any other form of participation. The aim of the manuscript is twofold: first, to offer a detailed and comprehensive statistical description of Code Week's participation in the EU Member States in terms of penetration, retention, demographic composition, and spatial distribution in order to inform more effective awareness-raising campaigns; second, to investigate the impact of socio-economic factors on Code Week involvement. The study identifies a strong negative correlation between participation and income at different geographical scales. It also suggests underlying mechanisms driving participation that are coherent with the \"psychosocial\" and the \"resource\" views, i.e. the two most widely accepted explanations of the effect of income on public engagement. ",
    "url": "https://arxiv.org/abs/2205.14740",
    "authors": [
      "Christel Sirocchi",
      "Annika Ostergren Pofantis",
      "Alessandro Bogliolo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2205.14759",
    "title": "Radial Spike and Slab Bayesian Neural Networks for Sparse Data in  Ransomware Attacks",
    "abstract": "Ransomware attacks are increasing at an alarming rate, leading to large financial losses, unrecoverable encrypted data, data leakage, and privacy concerns. The prompt detection of ransomware attacks is required to minimize further damage, particularly during the encryption stage. However, the frequency and structure of the observed ransomware attack data makes this task difficult to accomplish in practice. The data corresponding to ransomware attacks represents temporal, high-dimensional sparse signals, with limited records and very imbalanced classes. While traditional deep learning models have been able to achieve state-of-the-art results in a wide variety of domains, Bayesian Neural Networks, which are a class of probabilistic models, are better suited to the issues of the ransomware data. These models combine ideas from Bayesian statistics with the rich expressive power of neural networks. In this paper, we propose the Radial Spike and Slab Bayesian Neural Network, which is a new type of Bayesian Neural network that includes a new form of the approximate posterior distribution. The model scales well to large architectures and recovers the sparse structure of target functions. We provide a theoretical justification for using this type of distribution, as well as a computationally efficient method to perform variational inference. We demonstrate the performance of our model on a real dataset of ransomware attacks and show improvement over a large number of baselines, including state-of-the-art models such as Neural ODEs (ordinary differential equations). In addition, we propose to represent low-level events as MITRE ATT\\&CK tactics, techniques, and procedures (TTPs) which allows the model to better generalize to unseen ransomware attacks. ",
    "url": "https://arxiv.org/abs/2205.14759",
    "authors": [
      "Jurijs Nazarovs",
      "Jack W. Stokes",
      "Melissa Turcotte",
      "Justin Carroll",
      "Itai Grady"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14762",
    "title": "Rapid Regression Detection in Software Deployments through Sequential  Testing",
    "abstract": "The practice of continuous deployment has enabled companies to reduce time-to-market by increasing the rate at which software can be deployed. However, deploying more frequently bears the risk that occasionally defective changes are released. For Internet companies, this has the potential to degrade the user experience and increase user abandonment. Therefore, quality control gates are an important component of the software delivery process. These are used to build confidence in the reliability of a release or change. Towards this end, a common approach is to perform a canary test to evaluate new software under production workloads. Detecting defects as early as possible is necessary to reduce exposure and to provide immediate feedback to the developer. We present a statistical framework for rapidly detecting regressions in software deployments. Our approach is based on sequential tests of stochastic order and of equality in distribution. This enables canary tests to be continuously monitored, permitting regressions to be rapidly detected while strictly controlling the false detection probability throughout. The utility of this approach is demonstrated based on two case studies at Netflix. ",
    "url": "https://arxiv.org/abs/2205.14762",
    "authors": [
      "Michael Lindon",
      "Chris Sanden",
      "Vach\u00e9 Shirikian"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2205.14769",
    "title": "UPB at SemEval-2022 Task 5: Enhancing UNITER with Image Sentiment and  Graph Convolutional Networks for Multimedia Automatic Misogyny Identification",
    "abstract": "In recent times, the detection of hate-speech, offensive, or abusive language in online media has become an important topic in NLP research due to the exponential growth of social media and the propagation of such messages, as well as their impact. Misogyny detection, even though it plays an important part in hate-speech detection, has not received the same attention. In this paper, we describe our classification systems submitted to the SemEval-2022 Task 5: MAMI - Multimedia Automatic Misogyny Identification. The shared task aimed to identify misogynous content in a multi-modal setting by analysing meme images together with their textual captions. To this end, we propose two models based on the pre-trained UNITER model, one enhanced with an image sentiment classifier, whereas the second leverages a Vocabulary Graph Convolutional Network (VGCN). Additionally, we explore an ensemble using the aforementioned models. Our best model reaches an F1-score of 71.4% in Sub-task A and 67.3% for Sub-task B positioning our team in the upper third of the leaderboard. We release the code and experiments for our models on GitHub ",
    "url": "https://arxiv.org/abs/2205.14769",
    "authors": [
      "Andrei Paraschiv",
      "Mihai Dascalu",
      "Dumitru-Clementin Cercel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.14778",
    "title": "TransforMAP: Transformer for Memory Access Prediction",
    "abstract": "Data Prefetching is a technique that can hide memory latency by fetching data before it is needed by a program. Prefetching relies on accurate memory access prediction, to which task machine learning based methods are increasingly applied. Unlike previous approaches that learn from deltas or offsets and perform one access prediction, we develop TransforMAP, based on the powerful Transformer model, that can learn from the whole address space and perform multiple cache line predictions. We propose to use the binary of memory addresses as model input, which avoids information loss and saves a token table in hardware. We design a block index bitmap to collect unordered future page offsets under the current page address as learning labels. As a result, our model can learn temporal patterns as well as spatial patterns within a page. In a practical implementation, this approach has the potential to hide prediction latency because it prefetches multiple cache lines likely to be used in a long horizon. We show that our approach achieves 35.67% MPKI improvement and 20.55% IPC improvement in simulation, higher than state-of-the-art Best-Offset prefetcher and ISB prefetcher. ",
    "url": "https://arxiv.org/abs/2205.14778",
    "authors": [
      "Pengmiao Zhang",
      "Ajitesh Srivastava",
      "Anant V. Nori",
      "Rajgopal Kannan",
      "Viktor K. Prasanna"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14781",
    "title": "COVID-19 Literature Mining and Retrieval using Text Mining Approaches",
    "abstract": "The novel coronavirus disease (COVID-19) began in Wuhan, China, in late 2019 and to date has infected over 148M people worldwide, resulting in 3.12M deaths. On March 10, 2020, the World Health Organisation (WHO) declared it as a global pandemic. Many academicians and researchers started to publish papers describing the latest discoveries on covid-19. The large influx of publications made it hard for other researchers to go through a large amount of data and find the appropriate one that helps their research. So, the proposed model attempts to extract relavent titles from the large corpus of research publications which makes the job easy for the researchers. Allen Institute for AI released the CORD-19 dataset, which consists of 2,00,000 journal articles related to coronavirus-related research publications from PubMed's PMC, WHO (World Health Organization), bioRxiv, and medRxiv pre-prints. Along with this document corpus, they have also provided a topics dataset named topics-rnd3 consisting of a list of topics. Each topic has three types of representations like query, question, and narrative. These Datasets are made open for research, and also they released a TREC-COVID competition on Kaggle. Using these topics like queries, our goal is to find out the relevant documents in the CORD-19 dataset. In this research, relevant documents should be recognized for the posed topics in topics-rnd3 data set. The proposed model uses Natural Language Processing(NLP) techniques like Bag-of-Words, Average Word-2-Vec, Average BERT Base model and Tf-Idf weighted Word2Vec model to fabricate vectors for query, question, narrative, and combinations of them. Similarly, fabricate vectors for titles in the CORD-19 dataset. After fabricating vectors, cosine similarity is used for finding similarities between every two vectors. Cosine similarity helps us to find relevant documents for the given topic. ",
    "url": "https://arxiv.org/abs/2205.14781",
    "authors": [
      "Sanku Satya Uday",
      "Satti Thanuja Pavani",
      "T. Jaya Lakshmi",
      "Rohit Chivukula"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.14814",
    "title": "Your Contrastive Learning Is Secretly Doing Stochastic Neighbor  Embedding",
    "abstract": "Contrastive learning, especially Self-Supervised Contrastive Learning (SSCL), has achieved great success in extracting powerful features from unlabeled data, enabling comparable performance to the supervised counterpart. In this work, we contribute to the theoretical understanding of SSCL and uncover its connection to the classic data visualization method, Stochastic Neighbor Embedding (SNE). In the perspective of SNE, whose goal is matching pairwise distance, SSCL can be viewed as a special case with the input space pairwise distance specified by constructed \"positive\" pairs from data augmentation. The established correspondence facilitates deeper theoretical understandings of learned features of SSCL, as well as methodological guidelines for practical improvement. Specifically, through the lens of SNE, not only can we re-derive the alignment and uniformity principle, but also provide novel analysis on domain-agnostic augmentations and implicit bias. To illustrate the practical advantage, we demonstrate that the modifications from SNE to $t$-SNE can also be adopted in the SSCL setting, achieving significant improvement in both in-distribution and out-of-distribution generalization. ",
    "url": "https://arxiv.org/abs/2205.14814",
    "authors": [
      "Tianyang Hu",
      "Zhili Liu",
      "Fengwei Zhou",
      "Wenjia Wang",
      "Weiran Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14819",
    "title": "Universality of group convolutional neural networks based on ridgelet  analysis on groups",
    "abstract": "We investigate the approximation property of group convolutional neural networks (GCNNs) based on the ridgelet theory. We regard a group convolution as a matrix element of a group representation, and formulate a versatile GCNN as a nonlinear mapping between group representations, which covers typical GCNN literatures such as a cyclic convolution on a multi-channel image, permutation-invariant datasets (Deep Sets), and $\\mathrm{E}(n)$-equivariant convolutions. The ridgelet transform is an analysis operator of a depth-2 network, namely, it maps an arbitrary given target function $f$ to the weight $\\gamma$ of a network $S[\\gamma]$ so that the network represents the function as $S[\\gamma]=f$. It has been known only for fully-connected networks, and this study is the first to present the ridgelet transform for (G)CNNs. Since the ridgelet transform is given as a closed-form integral operator, it provides a constructive proof of the $cc$-universality of GCNNs. Unlike previous universality arguments on CNNs, we do not need to convert/modify the networks into other universal approximators such as invariant polynomials and fully-connected networks. ",
    "url": "https://arxiv.org/abs/2205.14819",
    "authors": [
      "Sho Sonoda",
      "Isao Ishikawa",
      "Masahiro Ikeda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Representation Theory (math.RT)"
    ]
  },
  {
    "id": "arXiv:2205.14825",
    "title": "Bayesian Low-Rank Interpolative Decomposition for Complex Datasets",
    "abstract": "In this paper, we introduce a probabilistic model for learning interpolative decomposition (ID), which is commonly used for feature selection, low-rank approximation, and identifying hidden patterns in data, where the matrix factors are latent variables associated with each data dimension. Prior densities with support on the specified subspace are used to address the constraint for the magnitude of the factored component of the observed matrix. Bayesian inference procedure based on Gibbs sampling is employed. We evaluate the model on a variety of real-world datasets including CCLE EC50, CCLE IC50, CTRP EC50,and MovieLens 100K datasets with different sizes, and dimensions, and show that the proposed Bayesian ID GBT and GBTN models lead to smaller reconstructive errors compared to existing randomized approaches. ",
    "url": "https://arxiv.org/abs/2205.14825",
    "authors": [
      "Jun Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2205.14826",
    "title": "Robust Weight Perturbation for Adversarial Training",
    "abstract": "Overfitting widely exists in adversarial robust training of deep networks. An effective remedy is adversarial weight perturbation, which injects the worst-case weight perturbation during network training by maximizing the classification loss on adversarial examples. Adversarial weight perturbation helps reduce the robust generalization gap; however, it also undermines the robustness improvement. A criterion that regulates the weight perturbation is therefore crucial for adversarial training. In this paper, we propose such a criterion, namely Loss Stationary Condition (LSC) for constrained perturbation. With LSC, we find that it is essential to conduct weight perturbation on adversarial data with small classification loss to eliminate robust overfitting. Weight perturbation on adversarial data with large classification loss is not necessary and may even lead to poor robustness. Based on these observations, we propose a robust perturbation strategy to constrain the extent of weight perturbation. The perturbation strategy prevents deep networks from overfitting while avoiding the side effect of excessive weight perturbation, significantly improving the robustness of adversarial training. Extensive experiments demonstrate the superiority of the proposed method over the state-of-the-art adversarial training methods. ",
    "url": "https://arxiv.org/abs/2205.14826",
    "authors": [
      "Chaojian Yu",
      "Bo Han",
      "Mingming Gong",
      "Li Shen",
      "Shiming Ge",
      "Bo Du",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14831",
    "title": "Temporal Multiresolution Graph Neural Networks For Epidemic Prediction",
    "abstract": "In this paper, we introduce Temporal Multiresolution Graph Neural Networks (TMGNN), the first architecture that both learns to construct the multiscale and multiresolution graph structures and incorporates the time-series signals to capture the temporal changes of the dynamic graphs. We have applied our proposed model to the task of predicting future spreading of epidemic and pandemic based on the historical time-series data collected from the actual COVID-19 pandemic and chickenpox epidemic in several European countries, and have obtained competitive results in comparison to other previous state-of-the-art temporal architectures and graph learning algorithms. We have shown that capturing the multiscale and multiresolution structures of graphs is important to extract either local or global information that play a critical role in understanding the dynamic of a global pandemic such as COVID-19 which started from a local city and spread to the whole world. Our work brings a promising research direction in forecasting and mitigating future epidemics and pandemics. ",
    "url": "https://arxiv.org/abs/2205.14831",
    "authors": [
      "Truong Son Hy",
      "Viet Bach Nguyen",
      "Long Tran-Thanh",
      "Risi Kondor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2205.14834",
    "title": "GraMeR: Graph Meta Reinforcement Learning for Multi-Objective Influence  Maximization",
    "abstract": "Influence maximization (IM) is a combinatorial problem of identifying a subset of nodes called the seed nodes in a network (graph), which when activated, provide a maximal spread of influence in the network for a given diffusion model and a budget for seed set size. IM has numerous applications such as viral marketing, epidemic control, sensor placement and other network-related tasks. However, the uses are limited due to the computational complexity of current algorithms. Recently, learning heuristics for IM have been explored to ease the computational burden. However, there are serious limitations in current approaches such as: (1) IM formulations only consider influence via spread and ignore self activation; (2) scalability to large graphs; (3) generalizability across graph families; (4) low computational efficiency with a large running time to identify seed sets for every test network. In this work, we address each of these limitations through a unique approach that involves (1) formulating a generic IM problem as a Markov decision process that handles both intrinsic and influence activations; (2) employing double Q learning to estimate seed nodes; (3) ensuring scalability via sub-graph based representations; and (4) incorporating generalizability via meta-learning across graph families. Extensive experiments are carried out in various standard networks to validate performance of the proposed Graph Meta Reinforcement learning (GraMeR) framework. The results indicate that GraMeR is multiple orders faster and generic than conventional approaches. ",
    "url": "https://arxiv.org/abs/2205.14834",
    "authors": [
      "Sai Munikoti",
      "Balasubramaniam Natarajan",
      "Mahantesh Halappanavar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.14837",
    "title": "Enhancing Sequential Recommendation with Graph Contrastive Learning",
    "abstract": "The sequential recommendation systems capture users' dynamic behavior patterns to predict their next interaction behaviors. Most existing sequential recommendation methods only exploit the local context information of an individual interaction sequence and learn model parameters solely based on the item prediction loss. Thus, they usually fail to learn appropriate sequence representations. This paper proposes a novel recommendation framework, namely Graph Contrastive Learning for Sequential Recommendation (GCL4SR). Specifically, GCL4SR employs a Weighted Item Transition Graph (WITG), built based on interaction sequences of all users, to provide global context information for each interaction and weaken the noise information in the sequence data. Moreover, GCL4SR uses subgraphs of WITG to augment the representation of each interaction sequence. Two auxiliary learning objectives have also been proposed to maximize the consistency between augmented representations induced by the same interaction sequence on WITG, and minimize the difference between the representations augmented by the global context on WITG and the local representation of the original sequence. Extensive experiments on real-world datasets demonstrate that GCL4SR consistently outperforms state-of-the-art sequential recommendation methods. ",
    "url": "https://arxiv.org/abs/2205.14837",
    "authors": [
      "Yixin Zhang",
      "Yong Liu",
      "Yonghui Xu",
      "Hao Xiong",
      "Chenyi Lei",
      "Wei He",
      "Lizhen Cui",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.14839",
    "title": "Adversarial Bandits Robust to $S$-Switch Regret",
    "abstract": "We study the adversarial bandit problem under $S$ number of switching best arms for unknown $S$. For handling this problem, we adopt the master-base framework using the online mirror descent method (OMD). We first provide a master-base algorithm with basic OMD, achieving $\\tilde{O}(S^{1/2}K^{1/3}T^{2/3})$. For improving the regret bound with respect to $T$, we propose to use adaptive learning rates for OMD to control variance of loss estimators, and achieve $\\tilde{O}(\\min\\{\\mathbb{E}[\\sqrt{SKT\\rho_T(h^\\dagger)}],S\\sqrt{KT}\\})$, where $\\rho_T(h^\\dagger)$ is a variance term for loss estimators. ",
    "url": "https://arxiv.org/abs/2205.14839",
    "authors": [
      "Jung-hun Kim",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.14842",
    "title": "Efficient Reward Poisoning Attacks on Online Deep Reinforcement Learning",
    "abstract": "We study data poisoning attacks on online deep reinforcement learning (DRL) where the attacker is oblivious to the learning algorithm used by the agent and does not necessarily have full knowledge of the environment. We demonstrate the intrinsic vulnerability of state-of-the-art DRL algorithms by designing a general reward poisoning framework called adversarial MDP attacks. We instantiate our framework to construct several new attacks which only corrupt the rewards for a small fraction of the total training timesteps and make the agent learn a low-performing policy. Our key insight is that the state-of-the-art DRL algorithms strategically explore the environment to find a high-performing policy. Our attacks leverage this insight to construct a corrupted environment for misleading the agent towards learning low-performing policies with a limited attack budget. We provide a theoretical analysis of the efficiency of our attack and perform an extensive evaluation. Our results show that our attacks efficiently poison agents learning with a variety of state-of-the-art DRL algorithms, such as DQN, PPO, SAC, etc. under several popular classical control and MuJoCo environments. ",
    "url": "https://arxiv.org/abs/2205.14842",
    "authors": [
      "Yinglun Xu",
      "Qi Zeng",
      "Gagandeep Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.14851",
    "title": "Exposing Fine-grained Adversarial Vulnerability of Face Anti-spoofing  Models",
    "abstract": "Adversarial attacks seriously threaten the high accuracy of face anti-spoofing models. Little adversarial noise can perturb their classification of live and spoofing. The existing adversarial attacks fail to figure out which part of the target face anti-spoofing model is vulnerable, making adversarial analysis tricky. So we propose fine-grained attacks for exposing adversarial vulnerability of face anti-spoofing models. Firstly, we propose Semantic Feature Augmentation (SFA) module, which makes adversarial noise semantic-aware to live and spoofing features. SFA considers the contrastive classes of data and texture bias of models in the context of face anti-spoofing, increasing the attack success rate by nearly 40% on average. Secondly, we generate fine-grained adversarial examples based on SFA and the multitask network with auxiliary information. We evaluate three annotations (facial attributes, spoofing types and illumination) and two geometric maps (depth and reflection), on four backbone networks (VGG, Resnet, Densenet and Swin Transformer). We find that facial attributes annotation and state-of-art networks fail to guarantee that models are robust to adversarial attacks. Such adversarial attacks can be generalized to more auxiliary information and backbone networks, to help our community handle the trade-off between accuracy and adversarial robustness. ",
    "url": "https://arxiv.org/abs/2205.14851",
    "authors": [
      "Songlin Yang",
      "Wei Wang",
      "Chenye Xu",
      "Bo Peng",
      "Jing Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14852",
    "title": "Benchmarking Unsupervised Anomaly Detection and Localization",
    "abstract": "Unsupervised anomaly detection and localization, as of one the most practical and challenging problems in computer vision, has received great attention in recent years. From the time the MVTec AD dataset was proposed to the present, new research methods that are constantly being proposed push its precision to saturation. It is the time to conduct a comprehensive comparison of existing methods to inspire further research. This paper extensively compares 13 papers in terms of the performance in unsupervised anomaly detection and localization tasks, and adds a comparison of inference efficiency previously ignored by the community. Meanwhile, analysis of the MVTec AD dataset are also given, especially the label ambiguity that affects the model fails to achieve full marks. Moreover, considering the proposal of the new MVTec 3D-AD dataset, this paper also conducts experiments using the existing state-of-the-art 2D methods on this new dataset, and reports the corresponding results with analysis. ",
    "url": "https://arxiv.org/abs/2205.14852",
    "authors": [
      "Ye Zheng",
      "Xiang Wang",
      "Yu Qi",
      "Wei Li",
      "Liwei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14879",
    "title": "Easter2.0: Improving convolutional models for handwritten text  recognition",
    "abstract": "Convolutional Neural Networks (CNN) have shown promising results for the task of Handwritten Text Recognition (HTR) but they still fall behind Recurrent Neural Networks (RNNs)/Transformer based models in terms of performance. In this paper, we propose a CNN based architecture that bridges this gap. Our work, Easter2.0, is composed of multiple layers of 1D Convolution, Batch Normalization, ReLU, Dropout, Dense Residual connection, Squeeze-and-Excitation module and make use of Connectionist Temporal Classification (CTC) loss. In addition to the Easter2.0 architecture, we propose a simple and effective data augmentation technique 'Tiling and Corruption (TACO)' relevant for the task of HTR/OCR. Our work achieves state-of-the-art results on IAM handwriting database when trained using only publicly available training data. In our experiments, we also present the impact of TACO augmentations and Squeeze-and-Excitation (SE) on text recognition accuracy. We further show that Easter2.0 is suitable for few-shot learning tasks and outperforms current best methods including Transformers when trained on limited amount of annotated data. Code and model is available at: https://github.com/kartikgill/Easter2 ",
    "url": "https://arxiv.org/abs/2205.14879",
    "authors": [
      "Kartik Chaudhary",
      "Raghav Bali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.14882",
    "title": "Time3D: End-to-End Joint Monocular 3D Object Detection and Tracking for  Autonomous Driving",
    "abstract": "While separately leveraging monocular 3D object detection and 2D multi-object tracking can be straightforwardly applied to sequence images in a frame-by-frame fashion, stand-alone tracker cuts off the transmission of the uncertainty from the 3D detector to tracking while cannot pass tracking error differentials back to the 3D detector. In this work, we propose jointly training 3D detection and 3D tracking from only monocular videos in an end-to-end manner. The key component is a novel spatial-temporal information flow module that aggregates geometric and appearance features to predict robust similarity scores across all objects in current and past frames. Specifically, we leverage the attention mechanism of the transformer, in which self-attention aggregates the spatial information in a specific frame, and cross-attention exploits relation and affinities of all objects in the temporal domain of sequence frames. The affinities are then supervised to estimate the trajectory and guide the flow of information between corresponding 3D objects. In addition, we propose a temporal -consistency loss that explicitly involves 3D target motion modeling into the learning, making the 3D trajectory smooth in the world coordinate system. Time3D achieves 21.4\\% AMOTA, 13.6\\% AMOTP on the nuScenes 3D tracking benchmark, surpassing all published competitors, and running at 38 FPS, while Time3D achieves 31.2\\% mAP, 39.4\\% NDS on the nuScenes 3D detection benchmark. ",
    "url": "https://arxiv.org/abs/2205.14882",
    "authors": [
      "Peixuan Li",
      "Jieyu Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14886",
    "title": "Neural Shape Mating: Self-Supervised Object Assembly with Adversarial  Shape Priors",
    "abstract": "Learning to autonomously assemble shapes is a crucial skill for many robotic applications. While the majority of existing part assembly methods focus on correctly posing semantic parts to recreate a whole object, we interpret assembly more literally: as mating geometric parts together to achieve a snug fit. By focusing on shape alignment rather than semantic cues, we can achieve across-category generalization. In this paper, we introduce a novel task, pairwise 3D geometric shape mating, and propose Neural Shape Mating (NSM) to tackle this problem. Given the point clouds of two object parts of an unknown category, NSM learns to reason about the fit of the two parts and predict a pair of 3D poses that tightly mate them together. We couple the training of NSM with an implicit shape reconstruction task to make NSM more robust to imperfect point cloud observations. To train NSM, we present a self-supervised data collection pipeline that generates pairwise shape mating data with ground truth by randomly cutting an object mesh into two parts, resulting in a dataset that consists of 200K shape mating pairs from numerous object meshes with diverse cut types. We train NSM on the collected dataset and compare it with several point cloud registration methods and one part assembly baseline. Extensive experimental results and ablation studies under various settings demonstrate the effectiveness of the proposed algorithm. Additional material is available at: https://neural-shape-mating.github.io/ ",
    "url": "https://arxiv.org/abs/2205.14886",
    "authors": [
      "Yun-Chun Chen",
      "Haoda Li",
      "Dylan Turpin",
      "Alec Jacobson",
      "Animesh Garg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.14887",
    "title": "Deep Posterior Distribution-based Embedding for Hyperspectral Image  Super-resolution",
    "abstract": "In this paper, we investigate the problem of hyperspectral (HS) image spatial super-resolution via deep learning. Particularly, we focus on how to embed the high-dimensional spatial-spectral information of HS images efficiently and effectively. Specifically, in contrast to existing methods adopting empirically-designed network modules, we formulate HS embedding as an approximation of the posterior distribution of a set of carefully-defined HS embedding events, including layer-wise spatial-spectral feature extraction and network-level feature aggregation. Then, we incorporate the proposed feature embedding scheme into a source-consistent super-resolution framework that is physically-interpretable, producing lightweight PDE-Net, in which high-resolution (HR) HS images are iteratively refined from the residuals between input low-resolution (LR) HS images and pseudo-LR-HS images degenerated from reconstructed HR-HS images via probability-inspired HS embedding. Extensive experiments over three common benchmark datasets demonstrate that PDE-Net achieves superior performance over state-of-the-art methods. Besides, the probabilistic characteristic of this kind of networks can provide the epistemic uncertainty of the network outputs, which may bring additional benefits when used for other HS image-based applications. The code will be publicly available at https://github.com/jinnh/PDE-Net. ",
    "url": "https://arxiv.org/abs/2205.14887",
    "authors": [
      "Jinhui Hou",
      "Zhiyu Zhu",
      "Junhui Hou",
      "Huanqiang Zeng",
      "Jinjian Wu",
      "Jiantao Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.14888",
    "title": "Giant Components in Random Temporal Graphs",
    "abstract": "A temporal graph is a graph whose edges appear only at certain points in time. In these graphs, reachability among the nodes relies on paths that traverse edges in chronological order (temporal paths). Unlike standard paths, these paths are not always composable, thus the reachability relation is intransitive and connected components do not form equivalence classes. We investigate the properties of reachability and connected components in random temporal graphs, using a simple model that consists of permuting uniformly at random the edges of an Erd\\\"os-R\\'enyi graph and interpreting the position in this permutation as presence times. This model was introduced in [Casteigts et al., FOCS 2021], where thresholds for various reachability properties were identified; for example, sharp threshold for temporal connectivity (all-to-all reachability) is $p=3 \\log n / n$. We generalize several techniques from the above paper in order to characterize the emergence of a giant connected component, which answers an open question from that paper. The growth of a giant component turns out to be quite different from the static case, where a component of size $n^{2/3}$ emerges at $p_0=1/n$ and subsequently absorbs a constant fraction of all vertices, with this fraction gradually approaching 1. In contrast, in temporal graphs, we show that the size of a giant connected component transitions abruptly from $o(n)$ nodes to $n - o(n)$ nodes at $p = \\log n / n$. ",
    "url": "https://arxiv.org/abs/2205.14888",
    "authors": [
      "Ruben Becker",
      "Arnaud Casteigts",
      "Pierluigi Crescenzi",
      "Bojana Kodric",
      "Malte Renken",
      "Michael Raskin",
      "Viktor Zamaraev"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2205.14893",
    "title": "Hybrid Numerical Modeling of Ballistic Clay under Low-Speed Impact using  Artificial Neural Networks",
    "abstract": "Roma Plastilina No. 1 clay has been widely used as a conservative boundary condition in bulletproof vests, namely to play the role of a human body. Interestingly, the effect of this boundary condition on the ballistic performance of the vests is indiscernible. Moreover, back face deformation should be characterized by measuring the indentation in the deformed clay, which is important for determining the lethality of gunshots. Therefore, several studies have focused on modeling not only bulletproof vests but also the clay backing material. Despite various attempts to develop a suitable numerical model, determining the appropriate physical parameters that can capture the high-strain-rate behavior of clay is still challenging. In this study, we predicted indentation depth in clay using an artificial neural network (ANN) and determined the optimal material parameters required for a finite element method (FEM)-based model using an inverse tracking method. Our ANN-FEM hybrid model successfully optimized high-strain-rate material parameters without the need for any independent mechanical tests. The proposed novel model achieved a high prediction accuracy of over 98% referring impact cases. ",
    "url": "https://arxiv.org/abs/2205.14893",
    "authors": [
      "YeonSu Kim",
      "Yoon A Kim",
      "Seo Hwee Park",
      "YunHo Kim"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2205.14895",
    "title": "From Representation to Reasoning: Towards both Evidence and Commonsense  Reasoning for Video Question-Answering",
    "abstract": "Video understanding has achieved great success in representation learning, such as video caption, video object grounding, and video descriptive question-answer. However, current methods still struggle on video reasoning, including evidence reasoning and commonsense reasoning. To facilitate deeper video understanding towards video reasoning, we present the task of Causal-VidQA, which includes four types of questions ranging from scene description (description) to evidence reasoning (explanation) and commonsense reasoning (prediction and counterfactual). For commonsense reasoning, we set up a two-step solution by answering the question and providing a proper reason. Through extensive experiments on existing VideoQA methods, we find that the state-of-the-art methods are strong in descriptions but weak in reasoning. We hope that Causal-VidQA can guide the research of video understanding from representation learning to deeper reasoning. The dataset and related resources are available at \\url{https://github.com/bcmi/Causal-VidQA.git}. ",
    "url": "https://arxiv.org/abs/2205.14895",
    "authors": [
      "Jiangtong Li",
      "Li Niu",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2205.14897",
    "title": "Fully Polynomial-Time Distributed Computation in Low-Treewidth Graphs",
    "abstract": "We consider global problems, i.e. problems that take at least diameter time, even when the bandwidth is not restricted. We show that all problems considered admit efficient solutions in low-treewidth graphs. By ``efficient'' we mean that the running time has polynomial dependence on the treewidth, a linear dependence on the diameter (which is unavoidable), and only a polylogarithmic dependence on $n$, the number of nodes in the graph. We present the algorithms solving the following problems in the CONGEST model which all attain $\\tilde{O(\\tau^{O(1)}D)}$-round complexity (where $\\tau$ and $D$ denote the treewidth and diameter of the graph, respectively): (1) Exact single-source shortest paths (actually, the more general problem of computing a distance labeling scheme) for weighted and directed graphs, (2) exact bipartite unweighted maximum matching, and (3) the weighted girth for both directed and undirected graphs. We derive all of our results using a single unified framework, which consists of two novel technical ingredients, The first is a fully polynomial-time distributed tree decomposition algorithm, which outputs a decomposition of width $O(\\tau^2\\log n)$ in $\\tilde{O}(\\tau^{O(1)}D)$ rounds (where $n$ is the number of nodes in the graph). The second ingredient, and the technical highlight of this paper, is the novel concept of a \\emph{stateful walk constraint}, which naturally defines a set of feasible walks in the input graph based on their local properties (e.g., augmenting paths). Given a stateful walk constraint, the constrained version of the shortest paths problem (or distance labeling) requires the algorithm to output the shortest \\emph{constrained} walk (or its distance) for a given source and sink vertices. We show that this problem can be efficiently solved in the CONGEST model by reducing it to an \\emph{unconstrained} version of the problem. ",
    "url": "https://arxiv.org/abs/2205.14897",
    "authors": [
      "Taisuke Izumi",
      "Naoki Kitamura",
      "Takamasa Naruse",
      "Gregory Schwartzman"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2205.14900",
    "title": "FRAug: Tackling Federated Learning with Non-IID Features via  Representation Augmentation",
    "abstract": "Federated Learning (FL) is a decentralized learning paradigm in which multiple clients collaboratively train deep learning models without centralizing their local data and hence preserve data privacy. Real-world applications usually involve a distribution shift across the datasets of the different clients, which hurts the generalization ability of the clients to unseen samples from their respective data distributions. In this work, we address the recently proposed feature shift problem where the clients have different feature distributions while the label distribution is the same. We propose Federated Representation Augmentation (FRAug) to tackle this practical and challenging problem. Our approach generates synthetic client-specific samples in the embedding space to augment the usually small client datasets. For that, we train a shared generative model to fuse the clients' knowledge, learned from different feature distributions, to synthesize client-agnostic embeddings, which are then locally transformed into client-specific embeddings by Representation Transformation Networks (RTNets). By transferring knowledge across the clients, the generated embeddings act as a regularizer for the client models and reduce overfitting to the local original datasets, hence improving generalization. Our empirical evaluation on multiple benchmark datasets demonstrates the effectiveness of the proposed method, which substantially outperforms the current state-of-the-art FL methods for non-IID features, including PartialFed and FedBN. ",
    "url": "https://arxiv.org/abs/2205.14900",
    "authors": [
      "Haokun Chen",
      "Ahmed Frikha",
      "Denis Krompass",
      "Volker Tresp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.14919",
    "title": "A Deep Learning Approach for Automatic Detection of Qualitative Features  of Lecturing",
    "abstract": "Artificial Intelligence in higher education opens new possibilities for improving the lecturing process, such as enriching didactic materials, helping in assessing students' works or even providing directions to the teachers on how to enhance the lectures. We follow this research path, and in this work, we explore how an academic lecture can be assessed automatically by quantitative features. First, we prepare a set of qualitative features based on teaching practices and then annotate the dataset of academic lecture videos collected for this purpose. We then show how these features could be detected automatically using machine learning and computer vision techniques. Our results show the potential usefulness of our work. ",
    "url": "https://arxiv.org/abs/2205.14919",
    "authors": [
      "Anna Wroblewska",
      "Jozef Jasek",
      "Bogdan Jastrzebski",
      "Stanislaw Pawlak",
      "Anna Grzywacz",
      "Cheong Siew Ann",
      "Tan Seng Chee",
      "Tomasz Trzcinski",
      "Janusz Holyst"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2205.14922",
    "title": "ACIL: Analytic Class-Incremental Learning with Absolute Memorization and  Privacy Protection",
    "abstract": "Class-incremental learning (CIL) learns a classification model with training data of different classes arising progressively. Existing CIL either suffers from serious accuracy loss due to catastrophic forgetting, or invades data privacy by revisiting used exemplars. Inspired by linear learning formulations, we propose an analytic class-incremental learning (ACIL) with absolute memorization of past knowledge while avoiding breaching of data privacy (i.e., without storing historical data). The absolute memorization is demonstrated in the sense that class-incremental learning using ACIL given present data would give identical results to that from its joint-learning counterpart which consumes both present and historical samples. This equality is theoretically validated. Data privacy is ensured since no historical data are involved during the learning process. Empirical validations demonstrate ACIL's competitive accuracy performance with near-identical results for various incremental task settings (e.g., 5-50 phases). This also allows ACIL to outperform the state-of-the-art methods for large-phase scenarios (e.g., 25 and 50 phases). ",
    "url": "https://arxiv.org/abs/2205.14922",
    "authors": [
      "Huiping Zhuang",
      "Zhenyu Weng",
      "Renchunzi Xie",
      "Kar-Ann Toh",
      "Zhiping Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14926",
    "title": "CalFAT: Calibrated Federated Adversarial Training with Label Skewness",
    "abstract": "Recent studies have shown that, like traditional machine learning, federated learning (FL) is also vulnerable to adversarial attacks. To improve the adversarial robustness of FL, few federated adversarial training (FAT) methods have been proposed to apply adversarial training locally before global aggregation. Although these methods demonstrate promising results on independent identically distributed (IID) data, they suffer from training instability issues on non-IID data with label skewness, resulting in much degraded natural accuracy. This tends to hinder the application of FAT in real-world applications where the label distribution across the clients is often skewed. In this paper, we study the problem of FAT under label skewness, and firstly reveal one root cause of the training instability and natural accuracy degradation issues: skewed labels lead to non-identical class probabilities and heterogeneous local models. We then propose a Calibrated FAT (CalFAT) approach to tackle the instability issue by calibrating the logits adaptively to balance the classes. We show both theoretically and empirically that the optimization of CalFAT leads to homogeneous local models across the clients and much improved convergence rate and final performance. ",
    "url": "https://arxiv.org/abs/2205.14926",
    "authors": [
      "Chen Chen",
      "Yuchen Liu",
      "Xingjun Ma",
      "Lingjuan Lyu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.14927",
    "title": "Passively Measuring IPFS Churn and Network Size",
    "abstract": "The InterPlanetary File System~(IPFS) is a popular decentralized peer-to-peer network for exchanging data. While there are many use cases for IPFS, the success of these use cases depends on the network. In this paper, we provide a passive measurement study of the IPFS network, investigating peer dynamics and curiosities of the network. With the help of our measurement, we estimate the network size and confirm the results of previous active measurement studies. ",
    "url": "https://arxiv.org/abs/2205.14927",
    "authors": [
      "Erik Daniel",
      "Florian Tschorsch"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.14929",
    "title": "Neural Volumetric Object Selection",
    "abstract": "We introduce an approach for selecting objects in neural volumetric 3D representations, such as multi-plane images (MPI) and neural radiance fields (NeRF). Our approach takes a set of foreground and background 2D user scribbles in one view and automatically estimates a 3D segmentation of the desired object, which can be rendered into novel views. To achieve this result, we propose a novel voxel feature embedding that incorporates the neural volumetric 3D representation and multi-view image features from all input views. To evaluate our approach, we introduce a new dataset of human-provided segmentation masks for depicted objects in real-world multi-view scene captures. We show that our approach out-performs strong baselines, including 2D segmentation and 3D segmentation approaches adapted to our task. ",
    "url": "https://arxiv.org/abs/2205.14929",
    "authors": [
      "Zhongzheng Ren",
      "Aseem Agarwala",
      "Bryan Russell",
      "Alexander G. Schwing",
      "Oliver Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14931",
    "title": "A multimedia recommendation model based on collaborative graph",
    "abstract": "As one of the main solutions to the information overload problem, recommender systems are widely used in daily life. In the recent emerging micro-video recommendation scenario, micro-videos contain rich multimedia information, involving text, image, video and other multimodal data, and these rich multimodal information conceals users' deep interest in the items. Most of the current recommendation algorithms based on multimodal data use multimodal information to expand the information on the item side, but ignore the different preferences of users for different modal information, and lack the fine-grained mining of the internal connection of multimodal information. To investigate the problems in the micro-video recommendr system mentioned above, we design a hybrid recommendation model based on multimodal information, introduces multimodal information and user-side auxiliary information in the network structure, fully explores the deep interest of users, measures the importance of each dimension of user and item feature representation in the scoring prediction task, makes the application of graph neural network in the recommendation system is improved by using an attention mechanism to fuse the multi-layer state output information, allowing the shallow structural features provided by the intermediate layer to better participate in the prediction task. The recommendation accuracy is improved compared with the traditional recommendation algorithm on different data sets, and the feasibility and effectiveness of our model is verified. ",
    "url": "https://arxiv.org/abs/2205.14931",
    "authors": [
      "Breda Lim",
      "Shubhi Bansal",
      "Ahmed Buru",
      "Kayla Manthey"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2205.14942",
    "title": "Edge YOLO: Real-Time Intelligent Object Detection System Based on  Edge-Cloud Cooperation in Autonomous Vehicles",
    "abstract": "Driven by the ever-increasing requirements of autonomous vehicles, such as traffic monitoring and driving assistant, deep learning-based object detection (DL-OD) has been increasingly attractive in intelligent transportation systems. However, it is difficult for the existing DL-OD schemes to realize the responsible, cost-saving, and energy-efficient autonomous vehicle systems due to low their inherent defects of low timeliness and high energy consumption. In this paper, we propose an object detection (OD) system based on edge-cloud cooperation and reconstructive convolutional neural networks, which is called Edge YOLO. This system can effectively avoid the excessive dependence on computing power and uneven distribution of cloud computing resources. Specifically, it is a lightweight OD framework realized by combining pruning feature extraction network and compression feature fusion network to enhance the efficiency of multi-scale prediction to the largest extent. In addition, we developed an autonomous driving platform equipped with NVIDIA Jetson for system-level verification. We experimentally demonstrate the reliability and efficiency of Edge YOLO on COCO2017 and KITTI data sets, respectively. According to COCO2017 standard datasets with a speed of 26.6 frames per second (FPS), the results show that the number of parameters in the entire network is only 25.67 MB, while the accuracy (mAP) is up to 47.3%. ",
    "url": "https://arxiv.org/abs/2205.14942",
    "authors": [
      "Siyuan Liang",
      "Hao Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14950",
    "title": "QB-II for Evaluating the Reliability of Binary-State Networks",
    "abstract": "Current real-life applications of various networks such as utility (gas, water, electric, 4G/5G) networks, the Internet of Things, social networks, and supply chains. Reliability is one of the most popular tools for evaluating network performance. The fundamental structure of these networks is a binary state network. Distinctive methods have been proposed to efficiently assess binary-state network reliability. A new algorithm called QB-II (quick binary-addition tree algorithm II) is proposed to improve the efficiency of quick BAT, which is based on BAT and outperforms many algorithms. The proposed QB-II implements the shortest minimum cuts (MCs) to separate the entire BAT into main-BAT and sub-BATs, and the source-target matrix convolution products to connect these subgraphs intelligently to improve the efficiency. Twenty benchmark problems were used to validate the performance of the QB-II. ",
    "url": "https://arxiv.org/abs/2205.14950",
    "authors": [
      "Wei-Chang Yeh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2205.14951",
    "title": "Benchmarking the Robustness of LiDAR-Camera Fusion for 3D Object  Detection",
    "abstract": "There are two critical sensors for 3D perception in autonomous driving, the camera and the LiDAR. The camera provides rich semantic information such as color, texture, and the LiDAR reflects the 3D shape and locations of surrounding objects. People discover that fusing these two modalities can significantly boost the performance of 3D perception models as each modality has complementary information to the other. However, we observe that current datasets are captured from expensive vehicles that are explicitly designed for data collection purposes, and cannot truly reflect the realistic data distribution due to various reasons. To this end, we collect a series of real-world cases with noisy data distribution, and systematically formulate a robustness benchmark toolkit, that simulates these cases on any clean autonomous driving datasets. We showcase the effectiveness of our toolkit by establishing the robustness benchmark on two widely-adopted autonomous driving datasets, nuScenes and Waymo, then, to the best of our knowledge, holistically benchmark the state-of-the-art fusion methods for the first time. We observe that: i) most fusion methods, when solely developed on these data, tend to fail inevitably when there is a disruption to the LiDAR input; ii) the improvement of the camera input is significantly inferior to the LiDAR one. We further propose an efficient robust training strategy to improve the robustness of the current fusion method. The benchmark and code are available at https://github.com/kcyu2014/lidar-camera-robust-benchmark ",
    "url": "https://arxiv.org/abs/2205.14951",
    "authors": [
      "Kaicheng Yu",
      "Tang Tao",
      "Hongwei Xie",
      "Zhiwei Lin",
      "Zhongwei Wu",
      "Zhongyu Xia",
      "Tingting Liang",
      "Haiyang Sun",
      "Jiong Deng",
      "Dayang Hao",
      "Yongtao Wang",
      "Xiaodan Liang",
      "Bing Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14962",
    "title": "Sampling-free Inference for Ab-Initio Potential Energy Surface Networks",
    "abstract": "Obtaining the energy of molecular systems typically requires solving the associated Schr\\\"odinger equation. Unfortunately, analytical solutions only exist for single-electron systems, and accurate approximate solutions are expensive. In recent work, the potential energy surface network (PESNet) has been proposed to reduce training time by solving the Schr\\\"odinger equation for many geometries simultaneously. While training significantly faster, inference still required numerical integration limiting the evaluation to a few geometries. Here, we address the inference shortcomings by proposing the Potential learning from ab-initio Networks (PlaNet) framework to simultaneously train a surrogate model that avoids expensive Monte-Carlo integration and, thus, reduces inference time from minutes or even hours to milliseconds. In this way, we can accurately model high-resolution multi-dimensional energy surfaces that previously would have been unobtainable via neural wave functions. Finally, we present PESNet++, an architectural improvement to PESNet, that reduces errors by up to 39% and provides new state-of-the-art results for neural wave functions across all systems evaluated. ",
    "url": "https://arxiv.org/abs/2205.14962",
    "authors": [
      "Nicholas Gao",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2205.14969",
    "title": "Guided Diffusion Model for Adversarial Purification",
    "abstract": "With wider application of deep neural networks (DNNs) in various algorithms and frameworks, security threats have become one of the concerns. Adversarial attacks disturb DNN-based image classifiers, in which attackers can intentionally add imperceptible adversarial perturbations on input images to fool the classifiers. In this paper, we propose a novel purification approach, referred to as guided diffusion model for purification (GDMP), to help protect classifiers from adversarial attacks. The core of our approach is to embed purification into the diffusion denoising process of a Denoised Diffusion Probabilistic Model (DDPM), so that its diffusion process could submerge the adversarial perturbations with gradually added Gaussian noises, and both of these noises can be simultaneously removed following a guided denoising process. On our comprehensive experiments across various datasets, the proposed GDMP is shown to reduce the perturbations raised by adversarial attacks to a shallow range, thereby significantly improving the correctness of classification. GDMP improves the robust accuracy by 5%, obtaining 90.1% under PGD attack on the CIFAR10 dataset. Moreover, GDMP achieves 70.94% robustness on the challenging ImageNet dataset. ",
    "url": "https://arxiv.org/abs/2205.14969",
    "authors": [
      "Jinyi Wang",
      "Zhaoyang Lyu",
      "Dahua Lin",
      "Bo Dai",
      "Hongfei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.14981",
    "title": "ZusammenQA: Data Augmentation with Specialized Models for Cross-lingual  Open-retrieval Question Answering System",
    "abstract": "This paper introduces our proposed system for the MIA Shared Task on Cross-lingual Open-retrieval Question Answering (COQA). In this challenging scenario, given an input question the system has to gather evidence documents from a multilingual pool and generate from them an answer in the language of the question. We devised several approaches combining different model variants for three main components: Data Augmentation, Passage Retrieval, and Answer Generation. For passage retrieval, we evaluated the monolingual BM25 ranker against the ensemble of re-rankers based on multilingual pretrained language models (PLMs) and also variants of the shared task baseline, re-training it from scratch using a recently introduced contrastive loss that maintains a strong gradient signal throughout training by means of mixed negative samples. For answer generation, we focused on language- and domain-specialization by means of continued language model (LM) pretraining of existing multilingual encoders. Additionally, for both passage retrieval and answer generation, we augmented the training data provided by the task organizers with automatically generated question-answer pairs created from Wikipedia passages to mitigate the issue of data scarcity, particularly for the low-resource languages for which no training data were provided. Our results show that language- and domain-specialization as well as data augmentation help, especially for low-resource languages. ",
    "url": "https://arxiv.org/abs/2205.14981",
    "authors": [
      "Chia-Chien Hung",
      "Tommaso Green",
      "Robert Litschko",
      "Tornike Tsereteli",
      "Sotaro Takeshita",
      "Marco Bombieri",
      "Goran Glava\u0161",
      "Simone Paolo Ponzetto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.15016",
    "title": "A Fundamental Probabilistic Fuzzy Logic Framework Suitable for Causal  Reasoning",
    "abstract": "In this paper, we introduce a fundamental framework to create a bridge between Probability Theory and Fuzzy Logic. Indeed, our theory formulates a random experiment of selecting crisp elements with the criterion of having a certain fuzzy attribute. To do so, we associate some specific crisp random variables to the random experiment. Then, several formulas are presented, which make it easier to compute different conditional probabilities and expected values of these random variables. Also, we provide measure theoretical basis for our probabilistic fuzzy logic framework. Note that in our theory, the probability density functions of continuous distributions which come from the aforementioned random variables include the Dirac delta function as a term. Further, we introduce an application of our theory in Causal Inference. ",
    "url": "https://arxiv.org/abs/2205.15016",
    "authors": [
      "Amir Saki",
      "Usef Faghihi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2205.15031",
    "title": "Neural Copula: A unified framework for estimating generic  high-dimensional Copula functions",
    "abstract": "The Copula is widely used to describe the relationship between the marginal distribution and joint distribution of random variables. The estimation of high-dimensional Copula is difficult, and most existing solutions rely either on simplified assumptions or on complicating recursive decompositions. Therefore, people still hope to obtain a generic Copula estimation method with both universality and simplicity. To reach this goal, a novel neural network-based method (named Neural Copula) is proposed in this paper. In this method, a hierarchical unsupervised neural network is constructed to estimate the marginal distribution function and the Copula function by solving differential equations. In the training program, various constraints are imposed on both the neural network and its derivatives. The Copula estimated by the proposed method is smooth and has an analytic expression. The effectiveness of the proposed method is evaluated on both real-world datasets and complex numerical simulations. Experimental results show that Neural Copula's fitting quality for complex distributions is much better than classical methods. The relevant code for the experiments is available on GitHub. (We encourage the reader to run the program for a better understanding of the proposed method). ",
    "url": "https://arxiv.org/abs/2205.15031",
    "authors": [
      "Zhi Zeng",
      "Ting Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.15053",
    "title": "Deblurring Photographs of Characters Using Deep Neural Networks",
    "abstract": "In this paper, we present our approach for the Helsinki Deblur Challenge (HDC2021). The task of this challenge is to deblur images of characters without knowing the point spread function (PSF). The organizers provided a dataset of pairs of sharp and blurred images. Our method consists of three steps: First, we estimate a warping transformation of the images to align the sharp images with the blurred ones. Next, we estimate the PSF using a quasi-Newton method. The estimated PSF allows to generate additional pairs of sharp and blurred images. Finally, we train a deep convolutional neural network to reconstruct the sharp images from the blurred images. Our method is able to successfully reconstruct images from the first 10 stages of the HDC 2021 data. Our code is available at \\url{https://github.com/hhu-machine-learning/hdc2021-psfnn}. ",
    "url": "https://arxiv.org/abs/2205.15053",
    "authors": [
      "Thomas Germer",
      "Tobias Uelwer",
      "Stefan Harmeling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.15063",
    "title": "A Personalized Recommender System for Pervasive Social Networks",
    "abstract": "The current availability of interconnected portable devices, and the advent of the Web 2.0, raise the problem of supporting anywhere and anytime access to a huge amount of content, generated and shared by mobile users. In this work we propose a novel framework for pervasive social networks, called Pervasive PLIERS (pPLIERS), able to discover and select, in a highly personalized way, contents of interest for single mobile users. pPLIERS exploits the recently proposed PLIERS tag based recommender system as context a reasoning tool able to adapt recommendations to heterogeneous interest profiles of different users. pPLIERS effectively operates also when limited knowledge about the network is maintained. It is implemented in a completely decentralized environment, in which new contents are continuously generated and diffused through the network, and it relies only on the exchange of single nodes knowledge during proximity contacts and through device to device communications. We evaluated pPLIERS by simulating its behaviour in three different scenarios: a big event (Expo 2015), a conference venue (ACM KDD 2015), and a working day in the city of Helsinki. For each scenario, we used real or synthetic mobility traces and we extracted real datasets from Twitter interactions to characterise the generation and sharing of user contents. ",
    "url": "https://arxiv.org/abs/2205.15063",
    "authors": [
      "Valerio Arnaboldi",
      "Mattia G. Campana",
      "Franca Delmastro",
      "Elena Pagani"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.15066",
    "title": "On the External Validity of Average-Case Analyses of Graph Algorithms",
    "abstract": "The number one criticism of average-case analysis is that we do not actually know the probability distribution of real-world inputs. Thus, analyzing an algorithm on some random model has no implications for practical performance. At its core, this criticism doubts the existence of external validity, i.e., it assumes that algorithmic behavior on the somewhat simple and clean models does not translate beyond the models to practical performance real-world input. With this paper, we provide a first step towards studying the question of external validity systematically. To this end, we evaluate the performance of six graph algorithms on a collection of 2751 sparse real-world networks depending on two properties; the heterogeneity (variance in the degree distribution) and locality (tendency of edges to connect vertices that are already close). We compare this with the performance on generated networks with varying locality and heterogeneity. We find that the performance in the idealized setting of network models translates surprisingly well to real-world networks. Moreover, heterogeneity and locality appear to be the core properties impacting the performance of many graph algorithms. ",
    "url": "https://arxiv.org/abs/2205.15066",
    "authors": [
      "Thomas Bl\u00e4sius",
      "Philipp Fischbeck"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.15068",
    "title": "Embedding Graphs on Grassmann Manifold",
    "abstract": "Learning efficient graph representation is the key to favorably addressing downstream tasks on graphs, such as node or graph property prediction. Given the non-Euclidean structural property of graphs, preserving the original graph data's similarity relationship in the embedded space needs specific tools and a similarity metric. This paper develops a new graph representation learning scheme, namely EGG, which embeds approximated second-order graph characteristics into a Grassmann manifold. The proposed strategy leverages graph convolutions to learn hidden representations of the corresponding subspace of the graph, which is then mapped to a Grassmann point of a low dimensional manifold through truncated singular value decomposition (SVD). The established graph embedding approximates denoised correlationship of node attributes, as implemented in the form of a symmetric matrix space for Euclidean calculation. The effectiveness of EGG is demonstrated using both clustering and classification tasks at the node level and graph level. It outperforms baseline models on various benchmarks. ",
    "url": "https://arxiv.org/abs/2205.15068",
    "authors": [
      "Bingxin Zhou",
      "Xuebin Zheng",
      "Yu Guang Wang",
      "Ming Li",
      "Junbin Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.15076",
    "title": "Improved Algorithms for Bandit with Graph Feedback via Regret  Decomposition",
    "abstract": "The problem of bandit with graph feedback generalizes both the multi-armed bandit (MAB) problem and the learning with expert advice problem by encoding in a directed graph how the loss vector can be observed in each round of the game. The mini-max regret is closely related to the structure of the feedback graph and their connection is far from being fully understood. We propose a new algorithmic framework for the problem based on a partition of the feedback graph. Our analysis reveals the interplay between various parts of the graph by decomposing the regret to the sum of the regret caused by small parts and the regret caused by their interaction. As a result, our algorithm can be viewed as an interpolation and generalization of the optimal algorithms for MAB and learning with expert advice. Our framework unifies previous algorithms for both strongly observable graphs and weakly observable graphs, resulting in improved and optimal regret bounds on a wide range of graph families including graphs of bounded degree and strongly observable graphs with a few corrupted arms. ",
    "url": "https://arxiv.org/abs/2205.15076",
    "authors": [
      "Yuchen He",
      "Chihao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.15077",
    "title": "On the Value of Retransmissions for Age of Information in Random Access  Networks without Feedback",
    "abstract": "We focus on a slotted ALOHA system without feedback, in which nodes transmit time-stamped updates to a common gateway. Departing from the classical generate-at-will model, we assume that each transmitter may not always have fresh information to deliver, and tackle the fundamental question of whether sending stale packets can be beneficial from an age-of-information (AoI) standpoint. Leaning on a signal-flow-graph analysis of Markov processes the study reveals that, when packets can be lost due to channel impairments, retransmissions can indeed lower AoI for low generation rates of new information, although at a cost in terms of throughput. ",
    "url": "https://arxiv.org/abs/2205.15077",
    "authors": [
      "Andrea Munari"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.15083",
    "title": "CGMN: A Contrastive Graph Matching Network for Self-Supervised Graph  Similarity Learning",
    "abstract": "Graph similarity learning refers to calculating the similarity score between two graphs, which is required in many realistic applications, such as visual tracking, graph classification, and collaborative filtering. As most of the existing graph neural networks yield effective graph representations of a single graph, little effort has been made for jointly learning two graph representations and calculating their similarity score. In addition, existing unsupervised graph similarity learning methods are mainly clustering-based, which ignores the valuable information embodied in graph pairs. To this end, we propose a contrastive graph matching network (CGMN) for self-supervised graph similarity learning in order to calculate the similarity between any two input graph objects. Specifically, we generate two augmented views for each graph in a pair respectively. Then, we employ two strategies, namely cross-view interaction and cross-graph interaction, for effective node representation learning. The former is resorted to strengthen the consistency of node representations in two views. The latter is utilized to identify node differences between different graphs. Finally, we transform node representations into graph-level representations via pooling operations for graph similarity computation. We have evaluated CGMN on eight real-world datasets, and the experiment results show that the proposed new approach is superior to the state-of-the-art methods in graph similarity learning downstream tasks. ",
    "url": "https://arxiv.org/abs/2205.15083",
    "authors": [
      "Di Jin",
      "Luzhi Wang",
      "Yizhen Zheng",
      "Xiang Li",
      "Fei Jiang",
      "Wei Lin",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.15100",
    "title": "Meta Representation Learning with Contextual Linear Bandits",
    "abstract": "Meta-learning seeks to build algorithms that rapidly learn how to solve new learning problems based on previous experience. In this paper we investigate meta-learning in the setting of stochastic linear bandit tasks. We assume that the tasks share a low dimensional representation, which has been partially acquired from previous learning tasks. We aim to leverage this information in order to learn a new downstream bandit task, which shares the same representation. Our principal contribution is to show that if the learned representation estimates well the unknown one, then the downstream task can be efficiently learned by a greedy policy that we propose in this work. We derive an upper bound on the regret of this policy, which is, up to logarithmic factors, of order $r\\sqrt{N}(1\\vee \\sqrt{d/T})$, where $N$ is the horizon of the downstream task, $T$ is the number of training tasks, $d$ the ambient dimension and $r \\ll d$ the dimension of the representation. We highlight that our strategy does not need to know $r$. We note that if $T> d$ our bound achieves the same rate of optimal minimax bandit algorithms using the true underlying representation. Our analysis is inspired and builds in part upon previous work on meta-learning in the i.i.d. full information setting \\citep{tripuraneni2021provable,boursier2022trace}. As a separate contribution we show how to relax certain assumptions in those works, thereby improving their representation learning and risk analysis. ",
    "url": "https://arxiv.org/abs/2205.15100",
    "authors": [
      "Leonardo Cella",
      "Karim Lounici",
      "Massimiliano Pontil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.15104",
    "title": "FLICU: A Federated Learning Workflow for Intensive Care Unit Mortality  Prediction",
    "abstract": "Although Machine Learning (ML) can be seen as a promising tool to improve clinical decision-making for supporting the improvement of medication plans, clinical procedures, diagnoses, or medication prescriptions, it remains limited by access to healthcare data. Healthcare data is sensitive, requiring strict privacy practices, and typically stored in data silos, making traditional machine learning challenging. Federated learning can counteract those limitations by training machine learning models over data silos while keeping the sensitive data localized. This study proposes a federated learning workflow for ICU mortality prediction. Hereby, the applicability of federated learning as an alternative to centralized machine learning and local machine learning is investigated by introducing federated learning to the binary classification problem of predicting ICU mortality. We extract multivariate time series data from the MIMIC-III database (lab values and vital signs), and benchmark the predictive performance of four deep sequential classifiers (FRNN, LSTM, GRU, and 1DCNN) varying the patient history window lengths (8h, 16h, 24h, 48h) and the number of FL clients (2, 4, 8). The experiments demonstrate that both centralized machine learning and federated learning are comparable in terms of AUPRC and F1-score. Furthermore, the federated approach shows superior performance over local machine learning. Thus, the federated approach can be seen as a valid and privacy-preserving alternative to centralized machine learning for classifying ICU mortality when sharing sensitive patient data between hospitals is not possible. ",
    "url": "https://arxiv.org/abs/2205.15104",
    "authors": [
      "Lena Mondrejevski",
      "Ioanna Miliou",
      "Annaclaudia Montanino",
      "David Pitts",
      "Jaakko Hollm\u00e9n",
      "Panagiotis Papapetrou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.15112",
    "title": "Robotic grasp detection based on Transformer",
    "abstract": "Grasp detection in a cluttered environment is still a great challenge for robots. Currently, the Transformer mechanism has been successfully applied to visual tasks, and its excellent ability of global context information extraction provides a feasible way to improve the performance of robotic grasp detection in cluttered scenes. However, the insufficient inductive bias ability of the original Transformer model requires large-scale datasets training, which is difficult to obtain for grasp detection. In this paper, we propose a grasp detection model based on encoder-decoder structure. The encoder uses a Transformer network to extract global context information. The decoder uses a fully convolutional neural network to improve the inductive bias capability of the model and combine features extracted by the encoder to predict the final grasp configuration. Experiments on the VMRD dataset demonstrate that our model performs much better in overlapping object scenes. Meanwhile, on the Cornell Grasp dataset, our approach achieves an accuracy of 98.1%, which is comparable with state-of-the-art algorithms. ",
    "url": "https://arxiv.org/abs/2205.15112",
    "authors": [
      "Mingshuai Dong",
      "Xiuli Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.15117",
    "title": "OOD Link Prediction Generalization Capabilities of Message-Passing GNNs  in Larger Test Graphs",
    "abstract": "This work provides the first theoretical study on the ability of graph Message Passing Neural Networks (gMPNNs) -- such as Graph Neural Networks (GNNs) -- to perform inductive out-of-distribution (OOD) link prediction tasks, where deployment (test) graph sizes are larger than training graphs. We first prove non-asymptotic bounds showing that link predictors based on permutation-equivariant (structural) node embeddings obtained by gMPNNs can converge to a random guess as test graphs get larger. We then propose a theoretically-sound gMPNN that outputs structural pairwise (2-node) embeddings and prove non-asymptotic bounds showing that, as test graphs grow, these embeddings converge to embeddings of a continuous function that retains its ability to predict links OOD. Empirical results on random graphs show agreement with our theoretical results. ",
    "url": "https://arxiv.org/abs/2205.15117",
    "authors": [
      "Yangze Zhou",
      "Gitta Kutyniok",
      "Bruno Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.15128",
    "title": "Domain Constraints in Feature Space: Strengthening Robustness of Android  Malware Detection against Realizable Adversarial Examples",
    "abstract": "Strengthening the robustness of machine learning-based malware detectors against realistic evasion attacks remains one of the major obstacles for Android malware detection. To that end, existing work has focused on interpreting domain constraints of Android malware in the problem space, where problem-space realizable adversarial examples are generated. In this paper, we provide another promising way to achieve the same goal but based on interpreting the domain constraints in the feature space, where feature-space realizable adversarial examples are generated. Specifically, we present a novel approach to extracting feature-space domain constraints by learning meaningful feature dependencies from data, and applying them based on a novel robust feature space. Experimental results successfully demonstrate the effectiveness of our novel robust feature space in providing adversarial robustness for DREBIN, a state-of-the-art Android malware detector. For example, it can decrease the evasion rate of a realistic gradient-based attack by $96.4\\%$ in a limited-knowledge (transfer) setting and by $13.8\\%$ in a more challenging, perfect-knowledge setting. In addition, we show that directly using our learned domain constraints in the adversarial retraining framework leads to about $84\\%$ improvement in a limited-knowledge setting, with up to $377\\times$ faster implementation than using problem-space adversarial examples. ",
    "url": "https://arxiv.org/abs/2205.15128",
    "authors": [
      "Hamid Bostani",
      "Zhuoran Liu",
      "Zhengyu Zhao",
      "Veelasha Moonsamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.15130",
    "title": "Why Adversarial Training of ReLU Networks Is Difficult?",
    "abstract": "This paper mathematically derives an analytic solution of the adversarial perturbation on a ReLU network, and theoretically explains the difficulty of adversarial training. Specifically, we formulate the dynamics of the adversarial perturbation generated by the multi-step attack, which shows that the adversarial perturbation tends to strengthen eigenvectors corresponding to a few top-ranked eigenvalues of the Hessian matrix of the loss w.r.t. the input. We also prove that adversarial training tends to strengthen the influence of unconfident input samples with large gradient norms in an exponential manner. Besides, we find that adversarial training strengthens the influence of the Hessian matrix of the loss w.r.t. network parameters, which makes the adversarial training more likely to oscillate along directions of a few samples, and boosts the difficulty of adversarial training. Crucially, our proofs provide a unified explanation for previous findings in understanding adversarial training. ",
    "url": "https://arxiv.org/abs/2205.15130",
    "authors": [
      "Xu Cheng",
      "Hao Zhang",
      "Yue Xin",
      "Wen Shen",
      "Jie Ren",
      "Quanshi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.15135",
    "title": "Group Probability-Weighted Tree Sums for Interpretable Modeling of  Heterogeneous Data",
    "abstract": "Machine learning in high-stakes domains, such as healthcare, faces two critical challenges: (1) generalizing to diverse data distributions given limited training data while (2) maintaining interpretability. To address these challenges, we propose an instance-weighted tree-sum method that effectively pools data across diverse groups to output a concise, rule-based model. Given distinct groups of instances in a dataset (e.g., medical patients grouped by age or treatment site), our method first estimates group membership probabilities for each instance. Then, it uses these estimates as instance weights in FIGS (Tan et al. 2022), to grow a set of decision trees whose values sum to the final prediction. We call this new method Group Probability-Weighted Tree Sums (G-FIGS). G-FIGS achieves state-of-the-art prediction performance on important clinical datasets; e.g., holding the level of sensitivity fixed at 92%, G-FIGS increases specificity for identifying cervical spine injury by up to 10% over CART and up to 3% over FIGS alone, with larger gains at higher sensitivity levels. By keeping the total number of rules below 16 in FIGS, the final models remain interpretable, and we find that their rules match medical domain expertise. All code, data, and models are released on Github. ",
    "url": "https://arxiv.org/abs/2205.15135",
    "authors": [
      "Keyan Nasseri",
      "Chandan Singh",
      "James Duncan",
      "Aaron Kornblith",
      "Bin Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.15139",
    "title": "Detecting fake news by enhanced text representation with  multi-EDU-structure awareness",
    "abstract": "Since fake news poses a serious threat to society and individuals, numerous studies have been brought by considering text, propagation and user profiles. Due to the data collection problem, these methods based on propagation and user profiles are less applicable in the early stages. A good alternative method is to detect news based on text as soon as they are released, and a lot of text-based methods were proposed, which usually utilized words, sentences or paragraphs as basic units. But, word is a too fine-grained unit to express coherent information well, sentence or paragraph is too coarse to show specific information. Which granularity is better and how to utilize it to enhance text representation for fake news detection are two key problems. In this paper, we introduce Elementary Discourse Unit (EDU) whose granularity is between word and sentence, and propose a multi-EDU-structure awareness model to improve text representation for fake news detection, namely EDU4FD. For the multi-EDU-structure awareness, we build the sequence-based EDU representations and the graph-based EDU representations. The former is gotten by modeling the coherence between consecutive EDUs with TextCNN that reflect the semantic coherence. For the latter, we first extract rhetorical relations to build the EDU dependency graph, which can show the global narrative logic and help deliver the main idea truthfully. Then a Relation Graph Attention Network (RGAT) is set to get the graph-based EDU representation. Finally, the two EDU representations are incorporated as the enhanced text representation for fake news detection, using a gated recursive unit combined with a global attention mechanism. Experiments on four cross-source fake news datasets show that our model outperforms the state-of-the-art text-based methods. ",
    "url": "https://arxiv.org/abs/2205.15139",
    "authors": [
      "Yuhang Wang",
      "Li Wang",
      "Yanjie Yang",
      "Yilin Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.15145",
    "title": "Machine Learning Methods for Health-Index Prediction in Coating Chambers",
    "abstract": "Coating chambers create thin layers that improve the mechanical and optical surface properties in jewelry production using physical vapor deposition. In such a process, evaporated material condensates on the walls of such chambers and, over time, causes mechanical defects and unstable processes. As a result, manufacturers perform extensive maintenance procedures to reduce production loss. Current rule-based maintenance strategies neglect the impact of specific recipes and the actual condition of the vacuum chamber. Our overall goal is to predict the future condition of the coating chamber to allow cost and quality optimized maintenance of the equipment. This paper describes the derivation of a novel health indicator that serves as a step toward condition-based maintenance for coating chambers. We indirectly use gas emissions of the chamber's contamination to evaluate the machine's condition. Our approach relies on process data and does not require additional hardware installation. Further, we evaluated multiple machine learning algorithms for a condition-based forecast of the health indicator that also reflects production planning. Our results show that models based on decision trees are the most effective and outperform all three benchmarks, improving at least $0.22$ in the mean average error. Our work paves the way for cost and quality optimized maintenance of coating applications. ",
    "url": "https://arxiv.org/abs/2205.15145",
    "authors": [
      "Clemens Heistracher",
      "Anahid Jalali",
      "J\u00fcrgen Schneeweiss",
      "Klaudia Kovacs",
      "Catherine Laflamme",
      "Bernhard Haslhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.15156",
    "title": "Towards Efficient 3D Object Detection with Knowledge Distillation",
    "abstract": "Despite substantial progress in 3D object detection, advanced 3D detectors often suffer from heavy computation overheads. To this end, we explore the potential of knowledge distillation (KD) for developing efficient 3D object detectors, focusing on popular pillar- and voxel-based detectors.Without well-developed teacher-student pairs, we first study how to obtain student models with good trade offs between accuracy and efficiency from the perspectives of model compression and input resolution reduction. Then, we build a benchmark to assess existing KD methods developed in the 2D domain for 3D object detection upon six well-constructed teacher-student pairs. Further, we propose an improved KD pipeline incorporating an enhanced logit KD method that performs KD on only a few pivotal positions determined by teacher classification response, and a teacher-guided student model initialization to facilitate transferring teacher model's feature extraction ability to students through weight inheritance. Finally, we conduct extensive experiments on the Waymo dataset. Our best performing model achieves $65.75\\%$ LEVEL 2 mAPH, surpassing its teacher model and requiring only $44\\%$ of teacher flops. Our most efficient model runs 51 FPS on an NVIDIA A100, which is $2.2\\times$ faster than PointPillar with even higher accuracy. Code will be available. ",
    "url": "https://arxiv.org/abs/2205.15156",
    "authors": [
      "Jihan Yang",
      "Shaoshuai Shi",
      "Runyu Ding",
      "Zhe Wang",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.15160",
    "title": "On algorithmic applications of sim-width and mim-width of $(H_1,  H_2)$-free graphs",
    "abstract": "Mim-width and sim-width are among the most powerful graph width parameters, with sim-width more powerful than mim-width, which is in turn more powerful than clique-width. While several $\\mathsf{NP}$-hard graph problems become tractable for graph classes whose mim-width is bounded and quickly computable, no algorithmic applications of boundedness of sim-width are known. In [Kang et al., A width parameter useful for chordal and co-comparability graphs, Theoretical Computer Science, 704:1-17, 2017], it is asked whether \\textsc{Independent Set} and \\textsc{$3$-Colouring} are $\\mathsf{NP}$-complete on graphs of sim-width at most $1$. We observe that, for each $k \\in \\mathbb{N}$, \\textsc{List $k$-Colouring} is polynomial-time solvable for graph classes whose sim-width is bounded and quickly computable. Moreover, we show that if the same holds for \\textsc{Independent Set}, then \\textsc{Independent $\\mathcal{H}$-Packing} is polynomial-time solvable for graph classes whose sim-width is bounded and quickly computable. This problem is a common generalisation of \\textsc{Independent Set}, \\textsc{Induced Matching}, \\textsc{Dissociation Set} and \\textsc{$k$-Separator}. We also make progress toward classifying the mim-width of $(H_1,H_2)$-free graphs in the case $H_1$ is complete or edgeless. Our results solve some open problems in [Brettell et al., Bounding the mim-width of hereditary graph classes, Journal of Graph Theory, 99(1):117-151, 2022]. ",
    "url": "https://arxiv.org/abs/2205.15160",
    "authors": [
      "Andrea Munaro",
      "Shizhou Yang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2205.15173",
    "title": "Self-Supervised Pre-training of Vision Transformers for Dense Prediction  Tasks",
    "abstract": "We present a new self-supervised pre-training of Vision Transformers for dense prediction tasks. It is based on a contrastive loss across views that compares pixel-level representations to global image representations. This strategy produces better local features suitable for dense prediction tasks as opposed to contrastive pre-training based on global image representation only. Furthermore, our approach does not suffer from a reduced batch size since the number of negative examples needed in the contrastive loss is in the order of the number of local features. We demonstrate the effectiveness of our pre-training strategy on two dense prediction tasks: semantic segmentation and monocular depth estimation. ",
    "url": "https://arxiv.org/abs/2205.15173",
    "authors": [
      "Jaonary Rabarisoa",
      "Velentin Belissen",
      "Florian Chabot",
      "Quoc-Cuong Pham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.15187",
    "title": "Do Deep Neural Networks Always Perform Better When Eating More Data?",
    "abstract": "Data has now become a shortcoming of deep learning. Researchers in their own fields share the thinking that \"deep neural networks might not always perform better when they eat more data,\" which still lacks experimental validation and a convincing guiding theory. Here to fill this lack, we design experiments from Identically Independent Distribution(IID) and Out of Distribution(OOD), which give powerful answers. For the purpose of guidance, based on the discussion of results, two theories are proposed: under IID condition, the amount of information determines the effectivity of each sample, the contribution of samples and difference between classes determine the amount of sample information and the amount of class information; under OOD condition, the cross-domain degree of samples determine the contributions, and the bias-fitting caused by irrelevant elements is a significant factor of cross-domain. The above theories provide guidance from the perspective of data, which can promote a wide range of practical applications of artificial intelligence. ",
    "url": "https://arxiv.org/abs/2205.15187",
    "authors": [
      "Jiachen Yang",
      "Zhuo Zhang",
      "Yicheng Gong",
      "Shukun Ma",
      "Xiaolan Guo",
      "Yue Yang",
      "Shuai Xiao",
      "Jiabao Wen",
      "Yang Li",
      "Xinbo Gao",
      "Wen Lu",
      "Qinggang Meng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.15198",
    "title": "STN: Scalable Tensorizing Networks via Structure-Aware Training and  Adaptive Compression",
    "abstract": "Deep neural networks (DNNs) have delivered a remarkable performance in many tasks of computer vision. However, over-parameterized representations of popular architectures dramatically increase their computational complexity and storage costs, and hinder their availability in edge devices with constrained resources. Regardless of many tensor decomposition (TD) methods that have been well-studied for compressing DNNs to learn compact representations, they suffer from non-negligible performance degradation in practice. In this paper, we propose Scalable Tensorizing Networks (STN), which dynamically and adaptively adjust the model size and decomposition structure without retraining. First, we account for compression during training by adding a low-rank regularizer to guarantee networks' desired low-rank characteristics in full tensor format. Then, considering network layers exhibit various low-rank structures, STN is obtained by a data-driven adaptive TD approach, for which the topological structure of decomposition per layer is learned from the pre-trained model, and the ranks are selected appropriately under specified storage constraints. As a result, STN is compatible with arbitrary network architectures and achieves higher compression performance and flexibility over other tensorizing versions. Comprehensive experiments on several popular architectures and benchmarks substantiate the superiority of our model towards improving parameter efficiency. ",
    "url": "https://arxiv.org/abs/2205.15198",
    "authors": [
      "Chang Nie",
      "Huan Wang",
      "Lu Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.15218",
    "title": "A Graph and Attentive Multi-Path Convolutional Network for Traffic  Prediction",
    "abstract": "Traffic prediction is an important and yet highly challenging problem due to the complexity and constantly changing nature of traffic systems. To address the challenges, we propose a graph and attentive multi-path convolutional network (GAMCN) model to predict traffic conditions such as traffic speed across a given road network into the future. Our model focuses on the spatial and temporal factors that impact traffic conditions. To model the spatial factors, we propose a variant of the graph convolutional network (GCN) named LPGCN to embed road network graph vertices into a latent space, where vertices with correlated traffic conditions are close to each other. To model the temporal factors, we use a multi-path convolutional neural network (CNN) to learn the joint impact of different combinations of past traffic conditions on the future traffic conditions. Such a joint impact is further modulated by an attention} generated from an embedding of the prediction time, which encodes the periodic patterns of traffic conditions. We evaluate our model on real-world road networks and traffic data. The experimental results show that our model outperforms state-of-art traffic prediction models by up to 18.9% in terms of prediction errors and 23.4% in terms of prediction efficiency. ",
    "url": "https://arxiv.org/abs/2205.15218",
    "authors": [
      "Jianzhong Qi",
      "Zhuowei Zhao",
      "Egemen Tanin",
      "Tingru Cui",
      "Neema Nassir",
      "Majid Sarvi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.15234",
    "title": "Few-Shot Adaptation of Pre-Trained Networks for Domain Shift",
    "abstract": "Deep networks are prone to performance degradation when there is a domain shift between the source (training) data and target (test) data. Recent test-time adaptation methods update batch normalization layers of pre-trained source models deployed in new target environments with streaming data to mitigate such performance degradation. Although such methods can adapt on-the-fly without first collecting a large target domain dataset, their performance is dependent on streaming conditions such as mini-batch size and class-distribution, which can be unpredictable in practice. In this work, we propose a framework for few-shot domain adaptation to address the practical challenges of data-efficient adaptation. Specifically, we propose a constrained optimization of feature normalization statistics in pre-trained source models supervised by a small support set from the target domain. Our method is easy to implement and improves source model performance with as few as one sample per class for classification tasks. Extensive experiments on 5 cross-domain classification and 4 semantic segmentation datasets show that our method achieves more accurate and reliable performance than test-time adaptation, while not being constrained by streaming conditions. ",
    "url": "https://arxiv.org/abs/2205.15234",
    "authors": [
      "Wenyu Zhang",
      "Li Shen",
      "Wanyue Zhang",
      "Chuan-Sheng Foo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.15269",
    "title": "Kernel Neural Optimal Transport",
    "abstract": "We study the Neural Optimal Transport (NOT) algorithm which uses the general optimal transport formulation and learns stochastic transport plans. We show that NOT with the weak quadratic cost might learn fake plans which are not optimal. To resolve this issue, we introduce kernel weak quadratic costs. We show that they provide improved theoretical guarantees and practical performance. We test NOT with kernel costs on the unpaired image-to-image translation task. ",
    "url": "https://arxiv.org/abs/2205.15269",
    "authors": [
      "Alexander Korotin",
      "Daniil Selikhanovych",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.15271",
    "title": "MetaSSD: Meta-Learned Self-Supervised Detection",
    "abstract": "Deep learning-based symbol detector gains increasing attention due to the simple algorithm design than the traditional model-based algorithms such as Viterbi and BCJR. The supervised learning framework is often employed to predict the input symbols, where training symbols are used to train the model. There are two major limitations in the supervised approaches: a) a model needs to be retrained from scratch when new train symbols come to adapt to a new channel status, and b) the length of the training symbols needs to be longer than a certain threshold to make the model generalize well on unseen symbols. To overcome these challenges, we propose a meta-learning-based self-supervised symbol detector named MetaSSD. Our contribution is two-fold: a) meta-learning helps the model adapt to a new channel environment based on experience with various meta-training environments, and b) self-supervised learning helps the model to use relatively less supervision than the previously suggested learning-based detectors. In experiments, MetaSSD outperforms OFDM-MMSE with noisy channel information and shows comparable results with BCJR. Further ablation studies show the necessity of each component in our framework. ",
    "url": "https://arxiv.org/abs/2205.15271",
    "authors": [
      "Moon Jeong Park",
      "Jungseul Ok",
      "Yo-Seb Jeon",
      "Dongwoo Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.15279",
    "title": "The openESEA Modelling Language for Ethical, Social and Environmental  Accounting: Technical Report",
    "abstract": "Over the years ethical, social and environmental accounting (ESEA) has become a common practice among responsible organisations. ESEA entails assessing and reporting organisations\" performance on environmental, social and governance topics. In this report, we present a textual grammar for specifying ESEA methods. With the grammar ESEA models can be created. Such models can be interpreted by our open-source, model-driven tool, called openESEA. The report presents the metamodel of the grammar, the grammar itself, and explanations of each grammar primitive. ",
    "url": "https://arxiv.org/abs/2205.15279",
    "authors": [
      "Vijanti Ramautar",
      "Sergio Espa\u00f1a"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ]
  },
  {
    "id": "arXiv:2205.15285",
    "title": "Fast Dynamic Radiance Fields with Time-Aware Neural Voxels",
    "abstract": "Neural radiance fields (NeRF) have shown great success in modeling 3D scenes and synthesizing novel-view images. However, most previous NeRF methods take much time to optimize one single scene. Explicit data structures, e.g. voxel features, show great potential to accelerate the training process. However, voxel features face two big challenges to be applied to dynamic scenes, i.e. modeling temporal information and capturing different scales of point motions. We propose a radiance field framework by representing scenes with time-aware voxel features, named as TiNeuVox. A tiny coordinate deformation network is introduced to model coarse motion trajectories and temporal information is further enhanced in the radiance network. A multi-distance interpolation method is proposed and applied on voxel features to model both small and large motions. Our framework significantly accelerates the optimization of dynamic radiance fields while maintaining high rendering quality. Empirical evaluation is performed on both synthetic and real scenes. Our TiNeuVox completes training with only 8 minutes and 8-MB storage cost while showing similar or even better rendering performance than previous dynamic NeRF methods. ",
    "url": "https://arxiv.org/abs/2205.15285",
    "authors": [
      "Jiemin Fang",
      "Taoran Yi",
      "Xinggang Wang",
      "Lingxi Xie",
      "Xiaopeng Zhang",
      "Wenyu Liu",
      "Matthias Nie\u00dfner",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2205.15286",
    "title": "Accelerating spiking neural network training",
    "abstract": "Spiking neural networks (SNN) are a type of artificial network inspired by the use of action potentials in the brain. There is a growing interest in emulating these networks on neuromorphic computers due to their improved energy consumption and speed, which are the main scaling issues of their counterpart the artificial neural network (ANN). Significant progress has been made in directly training SNNs to perform on par with ANNs in terms of accuracy. These methods are however slow due to their sequential nature, leading to long training times. We propose a new technique for directly training single-spike-per-neuron SNNs which eliminates all sequential computation and relies exclusively on vectorised operations. We demonstrate over a $\\times 10$ speedup in training with robust classification performance on real datasets of low to medium spatio-temporal complexity (Fashion-MNIST and Neuromophic-MNIST). Our proposed solution manages to solve certain tasks with over a $95.68 \\%$ reduction in spike counts relative to a conventionally trained SNN, which could significantly reduce energy requirements when deployed on neuromorphic computers. ",
    "url": "https://arxiv.org/abs/2205.15286",
    "authors": [
      "Luke Taylor",
      "Andrew King",
      "Nicol Harper"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.15288",
    "title": "Self-Supervised Visual Representation Learning with Semantic Grouping",
    "abstract": "In this paper, we tackle the problem of learning visual representations from unlabeled scene-centric data. Existing works have demonstrated the potential of utilizing the underlying complex structure within scene-centric data; still, they commonly rely on hand-crafted objectness priors or specialized pretext tasks to build a learning framework, which may harm generalizability. Instead, we propose contrastive learning from data-driven semantic slots, namely SlotCon, for joint semantic grouping and representation learning. The semantic grouping is performed by assigning pixels to a set of learnable prototypes, which can adapt to each sample by attentive pooling over the feature and form new slots. Based on the learned data-dependent slots, a contrastive objective is employed for representation learning, which enhances the discriminability of features, and conversely facilitates grouping semantically coherent pixels together. Compared with previous efforts, by simultaneously optimizing the two coupled objectives of semantic grouping and contrastive learning, our approach bypasses the disadvantages of hand-crafted priors and is able to learn object/group-level representations from scene-centric images. Experiments show our approach effectively decomposes complex scenes into semantic groups for feature learning and significantly benefits downstream tasks, including object detection, instance segmentation, and semantic segmentation. The code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2205.15288",
    "authors": [
      "Xin Wen",
      "Bingchen Zhao",
      "Anlin Zheng",
      "Xiangyu Zhang",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.15300",
    "title": "A Combination of Deep Neural Networks and K-Nearest Neighbors for Credit  Card Fraud Detection",
    "abstract": "Detection of a Fraud transaction on credit cards became one of the major problems for financial institutions, organizations and companies. As the global financial system is highly connected to non-cash transactions and online operations fraud makers invent more effective ways to access customers' finances. The main problem in credit card fraud detection is that the number of fraud transactions is significantly lower than genuine ones. The aim of the paper is to implement new techniques, which contains of under-sampling algorithms, K-nearest Neighbor Algorithm (KNN) and Deep Neural Network (KNN) on new obtained dataset. The performance evaluation showed that DNN model gives precise high accuracy (98.12%), which shows the good ability of presented method to detect fraudulent transactions. ",
    "url": "https://arxiv.org/abs/2205.15300",
    "authors": [
      "Dinara Rzayeva",
      "Saber Malekzadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.15301",
    "title": "Can Transformer be Too Compositional? Analysing Idiom Processing in  Neural Machine Translation",
    "abstract": "Unlike literal expressions, idioms' meanings do not directly follow from their parts, posing a challenge for neural machine translation (NMT). NMT models are often unable to translate idioms accurately and over-generate compositional, literal translations. In this work, we investigate whether the non-compositionality of idioms is reflected in the mechanics of the dominant NMT model, Transformer, by analysing the hidden states and attention patterns for models with English as source language and one of seven European languages as target language. When Transformer emits a non-literal translation - i.e. identifies the expression as idiomatic - the encoder processes idioms more strongly as single lexical units compared to literal expressions. This manifests in idioms' parts being grouped through attention and in reduced interaction between idioms and their context. In the decoder's cross-attention, figurative inputs result in reduced attention on source-side tokens. These results suggest that Transformer's tendency to process idioms as compositional expressions contributes to literal translations of idioms. ",
    "url": "https://arxiv.org/abs/2205.15301",
    "authors": [
      "Verna Dankers",
      "Christopher G. Lucas",
      "Ivan Titov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.14189",
    "title": "Optimizing Objective Functions from Trained ReLU Neural Networks via  Sampling",
    "abstract": "This paper introduces scalable, sampling-based algorithms that optimize trained neural networks with ReLU activations. We first propose an iterative algorithm that takes advantage of the piecewise linear structure of ReLU neural networks and reduces the initial mixed-integer optimization problem (MIP) into multiple easy-to-solve linear optimization problems (LPs) through sampling. Subsequently, we extend this approach by searching around the neighborhood of the LP solution computed at each iteration. This scheme allows us to devise a second, enhanced algorithm that reduces the initial MIP problem into smaller, easier-to-solve MIPs. We analytically show the convergence of the methods and we provide a sample complexity guarantee. We also validate the performance of our algorithms by comparing them against state-of-the-art MIP-based methods. Finally, we show computationally how the sampling algorithms can be used effectively to warm-start MIP-based methods. ",
    "url": "https://arxiv.org/abs/2205.14189",
    "authors": [
      "Georgia Perakis",
      "Asterios Tsiourvas"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.14202",
    "title": "Robust Phi-Divergence MDPs",
    "abstract": "In recent years, robust Markov decision processes (MDPs) have emerged as a prominent modeling framework for dynamic decision problems affected by uncertainty. In contrast to classical MDPs, which only account for stochasticity by modeling the dynamics through a stochastic process with a known transition kernel, robust MDPs additionally account for ambiguity by optimizing in view of the most adverse transition kernel from a prescribed ambiguity set. In this paper, we develop a novel solution framework for robust MDPs with s-rectangular ambiguity sets that decomposes the problem into a sequence of robust Bellman updates and simplex projections. Exploiting the rich structure present in the simplex projections corresponding to phi-divergence ambiguity sets, we show that the associated s-rectangular robust MDPs can be solved substantially faster than with state-of-the-art commercial solvers as well as a recent first-order solution scheme, thus rendering them attractive alternatives to classical MDPs in practical applications. ",
    "url": "https://arxiv.org/abs/2205.14202",
    "authors": [
      "Chin Pang Ho",
      "Marek Petrik",
      "Wolfram Wiesemann"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14249",
    "title": "Experience report of physics-informed neural networks in fluid  simulations: pitfalls and frustration",
    "abstract": "The deep learning boom motivates researchers and practitioners of computational fluid dynamics eager to integrate the two areas.The PINN (physics-informed neural network) method is one such attempt. While most reports in the literature show positive outcomes of applying the PINN method, our experiments with it stifled such optimism. This work presents our not-so-successful story of using PINN to solve two fundamental flow problems: 2D Taylor-Green vortex at $Re = 100$ and 2D cylinder flow at $Re = 200$. The PINN method solved the 2D Taylor-Green vortex problem with acceptable results, and we used this flow as an accuracy and performance benchmark. About 32 hours of training were required for the PINN method's accuracy to match the accuracy of a $16 \\times 16$ finite-difference simulation, which took less than 20 seconds. The 2D cylinder flow, on the other hand, did not even result in a physical solution. The PINN method behaved like a steady-flow solver and did not capture the vortex shedding phenomenon. By sharing our experience, we would like to emphasize that the PINN method is still a work-in-progress. More work is needed to make PINN feasible for real-world problems. ",
    "url": "https://arxiv.org/abs/2205.14249",
    "authors": [
      "Pi-Yueh Chuang",
      "Lorena A. Barba"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14461",
    "title": "Collaborative likelihood-ratio estimation over graphs",
    "abstract": "Assuming we have i.i.d observations from two unknown probability density functions (pdfs), $p$ and $p'$, the likelihood-ratio estimation (LRE) is an elegant approach to compare the two pdfs just by relying on the available data, and without knowing the pdfs explicitly. In this paper we introduce a graph-based extension of this problem: Suppose each node $v$ of a fixed graph has access to observations coming from two unknown node-specific pdfs, $p_v$ and $p'_v$; the goal is then to compare the respective $p_v$ and $p'_v$ of each node by also integrating information provided by the graph structure. This setting is interesting when the graph conveys some sort of `similarity' between the node-wise estimation tasks, which suggests that the nodes can collaborate to solve more efficiently their individual tasks, while on the other hand trying to limit the data sharing among them. Our main contribution is a distributed non-parametric framework for graph-based LRE, called GRULSIF, that incorporates in a novel way elements from f-divengence functionals, Kernel methods, and Multitask Learning. Among the several applications of LRE, we choose the two-sample hypothesis testing to develop a proof of concept for our graph-based learning framework. Our experiments compare favorably the performance of our approach against state-of-the-art non-parametric statistical tests that apply at each node independently, and thus disregard the graph structure. ",
    "url": "https://arxiv.org/abs/2205.14461",
    "authors": [
      "Alejandro de la Concha",
      "Argyris Kalogeratos",
      "Nicolas Vayatis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14539",
    "title": "Improving VAE-based Representation Learning",
    "abstract": "Latent variable models like the Variational Auto-Encoder (VAE) are commonly used to learn representations of images. However, for downstream tasks like semantic classification, the representations learned by VAE are less competitive than other non-latent variable models. This has led to some speculations that latent variable models may be fundamentally unsuitable for representation learning. In this work, we study what properties are required for good representations and how different VAE structure choices could affect the learned properties. We show that by using a decoder that prefers to learn local features, the remaining global features can be well captured by the latent, which significantly improves performance of a downstream classification task. We further apply the proposed model to semi-supervised learning tasks and demonstrate improvements in data efficiency. ",
    "url": "https://arxiv.org/abs/2205.14539",
    "authors": [
      "Mingtian Zhang",
      "Tim Z. Xiao",
      "Brooks Paige",
      "David Barber"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14552",
    "title": "Graph Agnostic Estimators with Staggered Rollout Designs under Network  Interference",
    "abstract": "Randomized experiments are widely used to estimate causal effects across a variety of domains. However, classical causal inference approaches rely on critical independence assumptions that are violated by network interference, when the treatment of one individual influences the outcomes of others. All existing approaches require at least approximate knowledge of the network, which may be unavailable and costly to collect. We consider the task of estimating the total treatment effect (TTE), or the average difference between the outcomes when the whole population is treated versus when the whole population is untreated. By leveraging a staggered rollout design, in which treatment is incrementally given to random subsets of individuals, we derive unbiased estimators for TTE that do not rely on any prior structural knowledge of the network, as long as the network interference effects are constrained to low-degree interactions among neighbors of an individual. We derive bounds on the variance of the estimators, and we show in experiments that our estimator performs well against baselines on simulated data. Central to our theoretical contribution is a connection between staggered rollout observations and polynomial extrapolation. ",
    "url": "https://arxiv.org/abs/2205.14552",
    "authors": [
      "Mayleen Cortez",
      "Matthew Eichhorn",
      "Christina Lee Yu"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.14595",
    "title": "Safeguarding NOMA Networks via Reconfigurable Dual-Functional Surface  under Imperfect CSI",
    "abstract": "This paper investigates the use of the reconfigurable dual-functional surface to guarantee the full-space secure transmission in non-orthogonal multiple access (NOMA) networks. In the presence of eavesdroppers, the downlink communication from the base station to the legitimate users is safeguarded by the simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS), where three practical operating protocols, namely energy splitting (ES), mode selection (MS), and time splitting (TS), are studied. The joint optimization of power allocation, active and passive beamforming is investigated to maximize the secrecy energy efficiency (SEE), taking into account the imperfect channel state information (CSI) of all channels. For ES, by approximating the semi-infinite constraints with the S-procedure and general sign-definiteness, the problem is solved by an alternating optimization framework. Besides, the proposed algorithm is extended to the MS protocol by solving a mixed-integer non-convex problem. While for TS, a two-layer iterative method is proposed. Simulation results show that: 1) The proposed STAR-RIS assisted NOMA networks are able to provide up to 33.6\\% higher SEE than conventional RIS counterparts; 2) TS and ES protocols are generally preferable for low and high power domain, respectively; 3) The accuracy of CSI estimation and the bit resolution power consumption are crucial to reap the SEE benefits offered by STAR-RIS. ",
    "url": "https://arxiv.org/abs/2205.14595",
    "authors": [
      "Wen Wang",
      "Wanli Ni",
      "Hui Tian",
      "Zhaohui Yang",
      "Chongwen Huang",
      "Kai-Kit Wong"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2205.14627",
    "title": "Continuous Generative Neural Networks",
    "abstract": "In this work, we present and study Continuous Generative Neural Networks (CGNNs), namely, generative models in the continuous setting. The architecture is inspired by DCGAN, with one fully connected layer, several convolutional layers and nonlinear activation functions. In the continuous $L^2$ setting, the dimensions of the spaces of each layer are replaced by the scales of a multiresolution analysis of a compactly supported wavelet. We present conditions on the convolutional filters and on the nonlinearity that guarantee that a CGNN is injective. This theory finds applications to inverse problems, and allows for deriving Lipschitz stability estimates for (possibly nonlinear) infinite-dimensional inverse problems with unknowns belonging to the manifold generated by a CGNN. Several numerical simulations, including image deblurring, illustrate and validate this approach. ",
    "url": "https://arxiv.org/abs/2205.14627",
    "authors": [
      "Giovanni S. Alberti",
      "Matteo Santacesaria",
      "Silvia Sciutto"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14662",
    "title": "No-Regret Learning in Network Stochastic Zero-Sum Games",
    "abstract": "No-regret learning has been widely used to compute a Nash equilibrium in two-person zero-sum games. However, there is still a lack of regret analysis for network stochastic zero-sum games, where players competing in two subnetworks only have access to some local information, and the cost functions include uncertainty. Such a game model can be found in security games, when a group of inspectors work together to detect a group of evaders. In this paper, we propose a distributed stochastic mirror descent (D-SMD) method, and establish the regret bounds $O(\\sqrt{T})$ and $O(\\log T)$ in the expected sense for convex-concave and strongly convex-strongly concave costs, respectively. Our bounds match those of the best known first-order online optimization algorithms. We then prove the convergence of the time-averaged iterates of D-SMD to the set of Nash equilibria. Finally, we show that the actual iterates of D-SMD almost surely converge to the Nash equilibrium in the strictly convex-strictly concave setting. ",
    "url": "https://arxiv.org/abs/2205.14662",
    "authors": [
      "Shijie Huang",
      "Jinlong Lei",
      "Yiguang Hong"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2205.14714",
    "title": "Heterogeneous Treatment Effects Estimation: When Machine Learning meets  multiple treatment regime",
    "abstract": "In many scientific and engineering domains, inferring the effect of treatment and exploring its heterogeneity is crucial for optimization and decision making. In addition to Machine Learning based models (e.g. Random Forests or Neural Networks), many meta-algorithms have been developed to estimate the Conditional Average Treatment Effect (CATE) function in the binary setting, with the main advantage of not restraining the estimation to a specific supervised learning method. However, this task becomes more challenging when the treatment is not binary. In this paper, we investigate the Rubin Causal Model under the multi-treatment regime and we focus on estimating heterogeneous treatment effects. We generalize \\textit{Meta-learning} algorithms to estimate the CATE for each possible treatment value. Using synthetic and semi-synthetic simulation datasets, we assess the quality of each meta-learner in observational data, and we highlight in particular the performances of the X-learner. ",
    "url": "https://arxiv.org/abs/2205.14714",
    "authors": [
      "Naoufal Acharki",
      "Josselin Garnier",
      "Antoine Bertoncello",
      "Ramiro Lugo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2205.14751",
    "title": "A Generative Adversarial Network-based Selective Ensemble  Characteristic-to-Expression Synthesis (SE-CTES) Approach and Its  Applications in Healthcare",
    "abstract": "Investigating the causal relationships between characteristics and expressions plays a critical role in healthcare analytics. Effective synthesis for expressions using given characteristics can make great contributions to health risk management and medical decision-making. For example, predicting the resulting physiological symptoms on patients from given treatment characteristics is helpful for the disease prevention and personalized treatment strategy design. Therefore, the objective of this study is to effectively synthesize the expressions based on given characteristics. However, the mapping from characteristics to expressions is usually from a relatively low dimension space to a high dimension space, but most of the existing methods such as regression models could not effectively handle such mapping. Besides, the relationship between characteristics and expressions may contain not only deterministic patterns, but also stochastic patterns. To address these challenges, this paper proposed a novel selective ensemble characteristic-to-expression synthesis (SE-CTES) approach inspired by generative adversarial network (GAN). The novelty of the proposed method can be summarized into three aspects: (1) GAN-based architecture for deep neural networks are incorporated to learn the relatively low dimensional mapping to high dimensional mapping containing both deterministic and stochastic patterns; (2) the weights of the two mismatching errors in the GAN-based architecture are proposed to be different to reduce the learning bias in the training process; and (3) a selective ensemble learning framework is proposed to reduce the prediction bias and improve the synthesis stability. To validate the effectiveness of the proposed approach, extensive numerical simulation studies and a real-world healthcare case study were applied and the results demonstrated that the proposed method is very promising. ",
    "url": "https://arxiv.org/abs/2205.14751",
    "authors": [
      "Yuxuan Li",
      "Ying Lin",
      "Chenang Liu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14784",
    "title": "Transient Behavior of Gossip Opinion Dynamics with Community Structure",
    "abstract": "We study transient behavior of gossip opinion dynamics, in which agents randomly interact pairwise over a graph with community structure. We first study behavior of the model over a weighted graph with two communities. Edges within a community have identical weights different from edge weights between communities. A sharp phase transition is discovered: When edge weights within communities are larger than those between communities and those between regular and stubborn agents, most agents in the same community hold opinions close to the initial average opinion of that community with large probability, at an early stage of the process. However, if the difference between intra- and inter-community weights is small enough, most of the agents instead hold opinions close to everyone's initial average opinion at the early stage. In contrast, when the influence of stubborn agents is large enough, agent opinions settle quickly into their steady states. We then conduct numerical experiments to validate the theoretical results, and demonstrate extensions to multiple communities and stochastic block models, by providing two numerical examples. Different from the traditional asymptotic analysis in most opinion dynamics literature, the paper characterizes the influences of stubborn agents and community structure on the initial phase of the opinion evolution. ",
    "url": "https://arxiv.org/abs/2205.14784",
    "authors": [
      "Yu Xing",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.14811",
    "title": "Last-iterate convergence analysis of stochastic momentum methods for  neural networks",
    "abstract": "The stochastic momentum method is a commonly used acceleration technique for solving large-scale stochastic optimization problems in artificial neural networks. Current convergence results of stochastic momentum methods under non-convex stochastic settings mostly discuss convergence in terms of the random output and minimum output. To this end, we address the convergence of the last iterate output (called last-iterate convergence) of the stochastic momentum methods for non-convex stochastic optimization problems, in a way conformal with traditional optimization theory. We prove the last-iterate convergence of the stochastic momentum methods under a unified framework, covering both stochastic heavy ball momentum and stochastic Nesterov accelerated gradient momentum. The momentum factors can be fixed to be constant, rather than time-varying coefficients in existing analyses. Finally, the last-iterate convergence of the stochastic momentum methods is verified on the benchmark MNIST and CIFAR-10 datasets. ",
    "url": "https://arxiv.org/abs/2205.14811",
    "authors": [
      "Dongpo Xu",
      "Jinlan Liu",
      "Yinghua Lu",
      "Jun Kong",
      "Danilo Mandic"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2205.14818",
    "title": "Excess Risk of Two-Layer ReLU Neural Networks in Teacher-Student  Settings and its Superiority to Kernel Methods",
    "abstract": "While deep learning has outperformed other methods for various tasks, theoretical frameworks that explain its reason have not been fully established. To address this issue, we investigate the excess risk of two-layer ReLU neural networks in a teacher-student regression model, in which a student network learns an unknown teacher network through its outputs. Especially, we consider the student network that has the same width as the teacher network and is trained in two phases: first by noisy gradient descent and then by the vanilla gradient descent. Our result shows that the student network provably reaches a near-global optimal solution and outperforms any kernel methods estimator (more generally, linear estimators), including neural tangent kernel approach, random feature model, and other kernel methods, in a sense of the minimax optimal rate. The key concept inducing this superiority is the non-convexity of the neural network models. Even though the loss landscape is highly non-convex, the student network adaptively learns the teacher neurons. ",
    "url": "https://arxiv.org/abs/2205.14818",
    "authors": [
      "Shunta Akiyama",
      "Taiji Suzuki"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.15050",
    "title": "Multi-fidelity robust controller design with gradient sampling",
    "abstract": "Robust controllers that stabilize dynamical systems even under disturbances and noise are often formulated as solutions of nonsmooth, nonconvex optimization problems. While methods such as gradient sampling can handle the nonconvexity and nonsmoothness, the costs of evaluating the objective function may be substantial, making robust control challenging for dynamical systems with high-dimensional state spaces. In this work, we introduce multi-fidelity variants of gradient sampling that leverage low-cost, low-fidelity models with low-dimensional state spaces for speeding up the optimization process while nonetheless providing convergence guarantees for a high-fidelity model of the system of interest, which is primarily accessed only in the last phase of the optimization process. Our first multi-fidelity method initiates gradient sampling on higher fidelity models with starting points obtained from cheaper, lower fidelity models. Our second multi-fidelity method relies on ensembles of gradients that are computed from low- and high-fidelity models. Numerical experiments with controlling the cooling of a steel rail profile and laminar flow in a cylinder wake demonstrate that our new multi-fidelity gradient sampling methods achieve up to two orders of magnitude speedup compared to the single-fidelity gradient sampling method that relies on the high-fidelity model alone. ",
    "url": "https://arxiv.org/abs/2205.15050",
    "authors": [
      "Steffen W. R. Werner",
      "Michael L. Overton",
      "Benjamin Peherstorfer"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2205.15170",
    "title": "GAN-based Medical Image Small Region Forgery Detection via a Two-Stage  Cascade Framework",
    "abstract": "Using generative adversarial network (GAN)\\cite{RN90} for data enhancement of medical images is significantly helpful for many computer-aided diagnosis (CAD) tasks. A new attack called CT-GAN has emerged. It can inject or remove lung cancer lesions to CT scans. Because the tampering region may even account for less than 1\\% of the original image, even state-of-the-art methods are challenging to detect the traces of such tampering. This paper proposes a cascade framework to detect GAN-based medical image small region forgery like CT-GAN. In the local detection stage, we train the detector network with small sub-images so that interference information in authentic regions will not affect the detector. We use depthwise separable convolution and residual to prevent the detector from over-fitting and enhance the ability to find forged regions through the attention mechanism. The detection results of all sub-images in the same image will be combined into a heatmap. In the global classification stage, using gray level co-occurrence matrix (GLCM) can better extract features of the heatmap. Because the shape and size of the tampered area are uncertain, we train PCA and SVM methods for classification. Our method can classify whether a CT image has been tampered and locate the tampered position. Sufficient experiments show that our method can achieve excellent performance. ",
    "url": "https://arxiv.org/abs/2205.15170",
    "authors": [
      "Jianyi Zhang",
      "Xuanxi Huang",
      "Yaqi Liu",
      "Yuyang Han",
      "Zixiao Xiang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.15189",
    "title": "Independence number of intersection graphs of axis-parallel segments",
    "abstract": "We prove that for any triangle-free intersection graph of $n$ axis-parallel segments in the plane, the independence number $\\alpha$ of this graph is at least $\\alpha \\ge n/4 + \\Omega(\\sqrt{n})$. We complement this with a construction of a graph in this class satisfying $\\alpha \\le n/4 + c \\sqrt{n}$ for an absolute constant $c$, which demonstrates the optimality of our result. ",
    "url": "https://arxiv.org/abs/2205.15189",
    "authors": [
      "Marco Caoduro",
      "Jana Cslovjecsek",
      "Micha\u0142 Pilipczuk",
      "Karol W\u0119grzycki"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2205.15190",
    "title": "Vehicle Route Planning using Dynamically Weighted Dijkstra's Algorithm  with Traffic Prediction",
    "abstract": "Traditional vehicle routing algorithms do not consider the changing nature of traffic. While implementations of Dijkstra's algorithm with varying weights exist, the weights are often changed after the outcome of algorithm is executed, which may not always result in the optimal route being chosen. Hence, this paper proposes a novel vehicle routing algorithm that improves upon Dijkstra's algorithm using a traffic prediction model based on the traffic flow in a road network. Here, Dijkstra's algorithm is adapted to be dynamic and time dependent using traffic flow theory principles during the planning stage itself. The model provides predicted traffic parameters and travel time across each edge of the road network at every time instant, leading to better routing results. The dynamic algorithm proposed here predicts changes in traffic conditions at each time step of planning to give the optimal forward-looking path. The proposed algorithm is verified by comparing it with conventional Dijkstra's algorithm on a graph with randomly simulated traffic, and is shown to predict the optimal route better with continuously changing traffic. ",
    "url": "https://arxiv.org/abs/2205.15190",
    "authors": [
      "Piyush Udhan",
      "Akhilesh Ganeshkar",
      "Poobigan Murugesan",
      "Abhishek Raj Permani",
      "Sameep Sanjeeva",
      "Parth Deshpande"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.15239",
    "title": "Conformal Credal Self-Supervised Learning",
    "abstract": "In semi-supervised learning, the paradigm of self-training refers to the idea of learning from pseudo-labels suggested by the learner itself. Across various domains, corresponding methods have proven effective and achieve state-of-the-art performance. However, pseudo-labels typically stem from ad-hoc heuristics, relying on the quality of the predictions though without guaranteeing their validity. One such method, so-called credal self-supervised learning, maintains pseudo-supervision in the form of sets of (instead of single) probability distributions over labels, thereby allowing for a flexible yet uncertainty-aware labeling. Again, however, there is no justification beyond empirical effectiveness. To address this deficiency, we make use of conformal prediction, an approach that comes with guarantees on the validity of set-valued predictions. As a result, the construction of credal sets of labels is supported by a rigorous theoretical foundation, leading to better calibrated and less error-prone supervision for unlabeled data. Along with this, we present effective algorithms for learning from credal self-supervision. An empirical study demonstrates excellent calibration properties of the pseudo-supervision, as well as the competitiveness of our method on several benchmark datasets. ",
    "url": "https://arxiv.org/abs/2205.15239",
    "authors": [
      "Julian Lienen",
      "Caglar Demir",
      "Eyke H\u00fcllermeier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1708.02975",
    "title": "Anomaly Detection on Graph Time Series",
    "abstract": " Comments: Very preminary work with some fatal mistakes. Some other work covering this will appear soon ",
    "url": "https://arxiv.org/abs/1708.02975",
    "authors": [
      "Daniel Hsu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1908.08600",
    "title": "Online Causal Inference for Advertising in Real-Time Bidding Auctions",
    "abstract": " Title: Online Causal Inference for Advertising in Real-Time Bidding Auctions ",
    "url": "https://arxiv.org/abs/1908.08600",
    "authors": [
      "Caio Waisman",
      "Harikesh S. Nair",
      "Carlos Carrion"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1912.12636",
    "title": "Training of Quantized Deep Neural Networks using a Magnetic Tunnel  Junction-Based Synapse",
    "abstract": " Comments: Published in Semiconductor Science and Technology, Vol 36 ",
    "url": "https://arxiv.org/abs/1912.12636",
    "authors": [
      "Tzofnat Greenberg Toledo",
      "Ben Perach",
      "Itay Hubara",
      "Daniel Soudry",
      "Shahar Kvatinsky"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2003.01227",
    "title": "Fast Predictive Uncertainty for Classification with Bayesian Deep  Networks",
    "abstract": " Comments: Updated version. Accepted for publication at UAI2022 ",
    "url": "https://arxiv.org/abs/2003.01227",
    "authors": [
      "Marius Hobbhahn",
      "Agustinus Kristiadi",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2006.04583",
    "title": "Vertex removal in biclique graphs",
    "abstract": " Title: Vertex removal in biclique graphs ",
    "url": "https://arxiv.org/abs/2006.04583",
    "authors": [
      "Leandro Montero"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2006.07046",
    "title": "Disentangled Representation Learning and Generation with Manifold  Optimization",
    "abstract": " Title: Disentangled Representation Learning and Generation with Manifold  Optimization ",
    "url": "https://arxiv.org/abs/2006.07046",
    "authors": [
      "Arun Pandey",
      "Michael Fanuel",
      "Joachim Schreurs",
      "Johan A. K. Suykens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2007.03941",
    "title": "Liaison, safeguard, and well-being: analyzing the role of social robots  during the COVID-19 pandemic",
    "abstract": " Comments: 23 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2007.03941",
    "authors": [
      "Laura Aymerich-Franch",
      "Iliana Ferrer"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2009.13619",
    "title": "Ferrite: A Judgmental Embedding of Session Types in Rust",
    "abstract": " Title: Ferrite: A Judgmental Embedding of Session Types in Rust ",
    "url": "https://arxiv.org/abs/2009.13619",
    "authors": [
      "Ruofei Chen",
      "Stephanie Balzer"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2010.09088",
    "title": "Energy-based error bound of physics-informed neural network solutions in  elasticity",
    "abstract": " Title: Energy-based error bound of physics-informed neural network solutions in  elasticity ",
    "url": "https://arxiv.org/abs/2010.09088",
    "authors": [
      "Mengwu Guo",
      "Ehsan Haghighat"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2011.01816",
    "title": "A Deep Learning based Detection Method for Combined  Integrity-Availability Cyber Attacks in Power System",
    "abstract": " Title: A Deep Learning based Detection Method for Combined  Integrity-Availability Cyber Attacks in Power System ",
    "url": "https://arxiv.org/abs/2011.01816",
    "authors": [
      "Wangkun Xu",
      "Fei Teng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2012.00675",
    "title": "Topological Learning for Brain Networks",
    "abstract": " Comments: Accepted for publication in the Annals of Applied Statistics; 32 pages, 14 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2012.00675",
    "authors": [
      "Tananun Songdechakraiwut",
      "Moo K. Chung"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2012.13154",
    "title": "Adversarial Momentum-Contrastive Pre-Training",
    "abstract": " Comments: 8 pages; ",
    "url": "https://arxiv.org/abs/2012.13154",
    "authors": [
      "Cong Xu",
      "Dan Li",
      "Min Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2101.03280",
    "title": "Modeling and Detecting Communities in Node Attributed Networks",
    "abstract": " Title: Modeling and Detecting Communities in Node Attributed Networks ",
    "url": "https://arxiv.org/abs/2101.03280",
    "authors": [
      "Ren Ren",
      "Jinliang Shao",
      "Adrian N. Bishop",
      "Wei Xing Zheng"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2101.07077",
    "title": "Yet Another Representation of Binary Decision Trees: A Mathematical  Demonstration",
    "abstract": " Title: Yet Another Representation of Binary Decision Trees: A Mathematical  Demonstration ",
    "url": "https://arxiv.org/abs/2101.07077",
    "authors": [
      "Jinxiong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.01452",
    "title": "Social Profit Optimization with Demand Response Management in  Electricity Market: A Multi-timescale Leader-following Approach",
    "abstract": " Comments: 33 pages, 15 figures ",
    "url": "https://arxiv.org/abs/2103.01452",
    "authors": [
      "Jianzheng Wang",
      "Yipeng Pang",
      "Guoqiang Hu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2105.09673",
    "title": "An Exact Poly-Time Membership-Queries Algorithm for Extraction a  three-Layer ReLU Network",
    "abstract": " Title: An Exact Poly-Time Membership-Queries Algorithm for Extraction a  three-Layer ReLU Network ",
    "url": "https://arxiv.org/abs/2105.09673",
    "authors": [
      "Amit Daniely",
      "Elad Granot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.06196",
    "title": "CausalAdv: Adversarial Robustness through the Lens of Causality",
    "abstract": " Comments: ICLR2022, 20 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2106.06196",
    "authors": [
      "Yonggang Zhang",
      "Mingming Gong",
      "Tongliang Liu",
      "Gang Niu",
      "Xinmei Tian",
      "Bo Han",
      "Bernhard Sch\u00f6lkopf",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.10595",
    "title": "Heterogeneous Multi-task Learning with Expert Diversity",
    "abstract": " Comments: 10 pages, 7 figures, BIOKDD, IEEE/ACM ",
    "url": "https://arxiv.org/abs/2106.10595",
    "authors": [
      "Raquel Aoki",
      "Frederick Tung",
      "Gabriel L. Oliveira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.11420",
    "title": "Policy Smoothing for Provably Robust Reinforcement Learning",
    "abstract": " Comments: Published as a conference paper at ICLR 2022 ",
    "url": "https://arxiv.org/abs/2106.11420",
    "authors": [
      "Aounon Kumar",
      "Alexander Levine",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.13367",
    "title": "SeaNet -- Towards A Knowledge Graph Based Autonomic Management of  Software Defined Networks",
    "abstract": " Title: SeaNet -- Towards A Knowledge Graph Based Autonomic Management of  Software Defined Networks ",
    "url": "https://arxiv.org/abs/2106.13367",
    "authors": [
      "Qianru Zhou",
      "Alasdair J.G. Gray",
      "Stephen McLaughlin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2107.08924",
    "title": "Epistemic Neural Networks",
    "abstract": " Title: Epistemic Neural Networks ",
    "url": "https://arxiv.org/abs/2107.08924",
    "authors": [
      "Ian Osband",
      "Zheng Wen",
      "Seyed Mohammad Asghari",
      "Vikranth Dwaracherla",
      "Morteza Ibrahimi",
      "Xiuyuan Lu",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2108.12821",
    "title": "Analyzing and Mitigating Interference in Neural Architecture Search",
    "abstract": " Comments: ICML 2022, Spotlight ",
    "url": "https://arxiv.org/abs/2108.12821",
    "authors": [
      "Jin Xu",
      "Xu Tan",
      "Kaitao Song",
      "Renqian Luo",
      "Yichong Leng",
      "Tao Qin",
      "Tie-Yan Liu",
      "Jian Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.06148",
    "title": "DAFNe: A One-Stage Anchor-Free Approach for Oriented Object Detection",
    "abstract": " Comments: Main paper: 8 pages, References: 2 pages, Appendix: 7 pages; Main paper: 6 figures, Appendix: 6 figures ",
    "url": "https://arxiv.org/abs/2109.06148",
    "authors": [
      "Steven Lang",
      "Fabrizio Ventola",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.03141",
    "title": "Efficient Sharpness-aware Minimization for Improved Training of Neural  Networks",
    "abstract": " Title: Efficient Sharpness-aware Minimization for Improved Training of Neural  Networks ",
    "url": "https://arxiv.org/abs/2110.03141",
    "authors": [
      "Jiawei Du",
      "Hanshu Yan",
      "Jiashi Feng",
      "Joey Tianyi Zhou",
      "Liangli Zhen",
      "Rick Siow Mong Goh",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.07728",
    "title": "Pre-training Molecular Graph Representation with 3D Geometry",
    "abstract": " Title: Pre-training Molecular Graph Representation with 3D Geometry ",
    "url": "https://arxiv.org/abs/2110.07728",
    "authors": [
      "Shengchao Liu",
      "Hanchen Wang",
      "Weiyang Liu",
      "Joan Lasenby",
      "Hongyu Guo",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2111.03253",
    "title": "Dynamic Data Augmentation with Gating Networks for Time Series  Recognition",
    "abstract": " Comments: Accepted to ICPR2022 ",
    "url": "https://arxiv.org/abs/2111.03253",
    "authors": [
      "Daisuke Oba",
      "Shinnosuke Matsuo",
      "Brian Kenji Iwana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.04027",
    "title": "Riesz transform associated with the fractional Fourier transform and  applications in image edge detection",
    "abstract": " Comments: 29 pages ",
    "url": "https://arxiv.org/abs/2111.04027",
    "authors": [
      "Zunwei Fu",
      "Loukas Grafakos",
      "Yan Lin",
      "Yue Wu",
      "Shuhui Yang"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2111.07093",
    "title": "AttacKG: Constructing Technique Knowledge Graph from Cyber Threat  Intelligence Reports",
    "abstract": " Title: AttacKG: Constructing Technique Knowledge Graph from Cyber Threat  Intelligence Reports ",
    "url": "https://arxiv.org/abs/2111.07093",
    "authors": [
      "Zhenyuan Li",
      "Jun Zeng",
      "Yan Chen",
      "Zhenkai Liang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2111.13879",
    "title": "ML-based Handover Prediction and AP Selection in Cognitive Wi-Fi  Networks",
    "abstract": " Title: ML-based Handover Prediction and AP Selection in Cognitive Wi-Fi  Networks ",
    "url": "https://arxiv.org/abs/2111.13879",
    "authors": [
      "Muhammad Asif Khan",
      "Ridha Hamila",
      "Adel Gastli",
      "Serkan Kiranyaz",
      "Nasser Ahmed Al-Emadi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.15246",
    "title": "Hallucinated Neural Radiance Fields in the Wild",
    "abstract": " Comments: Accepted by CVPR 2022. Project website: this https URL ",
    "url": "https://arxiv.org/abs/2111.15246",
    "authors": [
      "Xingyu Chen",
      "Qi Zhang",
      "Xiaoyu Li",
      "Yue Chen",
      "Ying Feng",
      "Xuan Wang",
      "Jue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.00510",
    "title": "Trimap-guided Feature Mining and Fusion Network for Natural Image  Matting",
    "abstract": " Comments: submitted to Computer Vision and Image Understanding ",
    "url": "https://arxiv.org/abs/2112.00510",
    "authors": [
      "Weihao Jiang",
      "Dongdong Yu",
      "Zhaozhi Xie",
      "Yaoyi Li",
      "Zehuan Yuan",
      "Hongtao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.06397",
    "title": "N-Cloth: Predicting 3D Cloth Deformation with Mesh-Based Networks",
    "abstract": " Comments: 12 pages ",
    "url": "https://arxiv.org/abs/2112.06397",
    "authors": [
      "Yudi Li",
      "Min Tang",
      "Yun Yang",
      "Zi Huang",
      "Ruofeng Tong",
      "Shuangcai Yang",
      "Yao Li",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.07823",
    "title": "Bayesian Graph Contrastive Learning",
    "abstract": " Title: Bayesian Graph Contrastive Learning ",
    "url": "https://arxiv.org/abs/2112.07823",
    "authors": [
      "Arman Hasanzadeh",
      "Mohammadreza Armandpour",
      "Ehsan Hajiramezanali",
      "Mingyuan Zhou",
      "Nick Duffield",
      "Krishna Narayanan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.07918",
    "title": "M-FasterSeg: An Efficient Semantic Segmentation Network Based on Neural  Architecture Search",
    "abstract": " Title: M-FasterSeg: An Efficient Semantic Segmentation Network Based on Neural  Architecture Search ",
    "url": "https://arxiv.org/abs/2112.07918",
    "authors": [
      "Junjun Wu",
      "Huiyu Kuang",
      "Qinghua Lu",
      "Zeqin Lin",
      "Qingwu Shi",
      "Xilin Liu",
      "Xiaoman Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.08696",
    "title": "Few-Shot Semantic Parsing with Language Models Trained On Code",
    "abstract": " Comments: NAACL 2022 ",
    "url": "https://arxiv.org/abs/2112.08696",
    "authors": [
      "Richard Shin",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.08866",
    "title": "Detecting Model Misspecification in Amortized Bayesian Inference with  Neural Networks",
    "abstract": " Title: Detecting Model Misspecification in Amortized Bayesian Inference with  Neural Networks ",
    "url": "https://arxiv.org/abs/2112.08866",
    "authors": [
      "Marvin Schmitt",
      "Paul-Christian B\u00fcrkner",
      "Ullrich K\u00f6the",
      "Stefan T. Radev"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.11136",
    "title": "Adversarial Gradient Driven Exploration for Deep Click-Through Rate  Prediction",
    "abstract": " Comments: This paper is accepted by the KDD2022 ",
    "url": "https://arxiv.org/abs/2112.11136",
    "authors": [
      "Kailun Wu",
      "Zhangming Chan",
      "Weijie Bian",
      "Lejian Ren",
      "Shiming Xiang",
      "Shuguang Han",
      "Hongbo Deng",
      "Bo Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.01134",
    "title": "Network Collaborator: Knowledge Transfer Between Network Reconstruction  and Community Detection from Dynamics",
    "abstract": " Comments: Submit to IEEE Computational Intelligence Magazine ",
    "url": "https://arxiv.org/abs/2201.01134",
    "authors": [
      "Kai Wu",
      "Chao Wang",
      "Junyuan Chen",
      "Jing Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2201.06274",
    "title": "Detecting danger in gridworlds using Gromov's Link Condition",
    "abstract": " Comments: 17 pages, 12 figures, 4 appendices; some parts rewritten and rearranged to improve exposition, no changes to mathematical content ",
    "url": "https://arxiv.org/abs/2201.06274",
    "authors": [
      "Thomas F Burns",
      "Robert Tang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Combinatorics (math.CO)",
      "Geometric Topology (math.GT)",
      "Metric Geometry (math.MG)"
    ]
  },
  {
    "id": "arXiv:2201.08619",
    "title": "Dangerous Cloaking: Natural Trigger based Backdoor Attacks on Object  Detectors in the Physical World",
    "abstract": " Title: Dangerous Cloaking: Natural Trigger based Backdoor Attacks on Object  Detectors in the Physical World ",
    "url": "https://arxiv.org/abs/2201.08619",
    "authors": [
      "Hua Ma",
      "Yinshan Li",
      "Yansong Gao",
      "Alsharif Abuadbba",
      "Zhi Zhang",
      "Anmin Fu",
      "Hyoungshick Kim",
      "Said F. Al-Sarawi",
      "Nepal Surya",
      "Derek Abbott"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.10185",
    "title": "Zero-Shot Sketch Based Image Retrieval using Graph Transformer",
    "abstract": " Comments: Accepted at ICPR 2022 ",
    "url": "https://arxiv.org/abs/2201.10185",
    "authors": [
      "Sumrit Gupta",
      "Ushasi Chaudhuri",
      "Biplab Banerjee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11147",
    "title": "OntoProtein: Protein Pretraining With Gene Ontology Embedding",
    "abstract": " Comments: Accepted by ICLR 2022 ",
    "url": "https://arxiv.org/abs/2201.11147",
    "authors": [
      "Ningyu Zhang",
      "Zhen Bi",
      "Xiaozhuan Liang",
      "Siyuan Cheng",
      "Haosen Hong",
      "Shumin Deng",
      "Jiazhang Lian",
      "Qiang Zhang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11613",
    "title": "Domain-Invariant Representation Learning from EEG with Private Encoders",
    "abstract": " Comments: 5 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2201.11613",
    "authors": [
      "David Bethge",
      "Philipp Hallgarten",
      "Tobias Grosse-Puppendahl",
      "Mohamed Kari",
      "Ralf Mikut",
      "Albrecht Schmidt",
      "Ozan \u00d6zdenizci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2201.12433",
    "title": "FedGCN: Convergence and Communication Tradeoffs in Federated Training of  Graph Convolutional Networks",
    "abstract": " Title: FedGCN: Convergence and Communication Tradeoffs in Federated Training of  Graph Convolutional Networks ",
    "url": "https://arxiv.org/abs/2201.12433",
    "authors": [
      "Yuhang Yao",
      "Carlee Joe-Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2201.12558",
    "title": "The KFIoU Loss for Rotated Object Detection",
    "abstract": " Comments: 19 pages, 5 figures, 11 tables, tensorflow code: this https URL, pytorch code: this https URL ",
    "url": "https://arxiv.org/abs/2201.12558",
    "authors": [
      "Xue Yang",
      "Yue Zhou",
      "Gefan Zhang",
      "Jirui Yang",
      "Wentao Wang",
      "Junchi Yan",
      "Xiaopeng Zhang",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12886",
    "title": "N-HiTS: Neural Hierarchical Interpolation for Time Series Forecasting",
    "abstract": " Title: N-HiTS: Neural Hierarchical Interpolation for Time Series Forecasting ",
    "url": "https://arxiv.org/abs/2201.12886",
    "authors": [
      "Cristian Challu",
      "Kin G. Olivares",
      "Boris N. Oreshkin",
      "Federico Garza",
      "Max Mergenthaler-Canseco",
      "Artur Dubrawski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.03026",
    "title": "Context Autoencoder for Self-Supervised Representation Learning",
    "abstract": " Title: Context Autoencoder for Self-Supervised Representation Learning ",
    "url": "https://arxiv.org/abs/2202.03026",
    "authors": [
      "Xiaokang Chen",
      "Mingyu Ding",
      "Xiaodi Wang",
      "Ying Xin",
      "Shentong Mo",
      "Yunhao Wang",
      "Shumin Han",
      "Ping Luo",
      "Gang Zeng",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.04770",
    "title": "Unsupervised Time-Series Representation Learning with Iterative Bilinear  Temporal-Spectral Fusion",
    "abstract": " Comments: Accepted by ICML 2022 ",
    "url": "https://arxiv.org/abs/2202.04770",
    "authors": [
      "Ling Yang",
      "Shenda Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.04936",
    "title": "Robust Graph Representation Learning for Local Corruption Recovery",
    "abstract": " Title: Robust Graph Representation Learning for Local Corruption Recovery ",
    "url": "https://arxiv.org/abs/2202.04936",
    "authors": [
      "Bingxin Zhou",
      "Yuanhong Jiang",
      "Yu Guang Wang",
      "Jingwei Liang",
      "Junbin Gao",
      "Shirui Pan",
      "Xiaoqun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05226",
    "title": "Deadwooding: Robust Global Pruning for Deep Neural Networks",
    "abstract": " Comments: 21 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2202.05226",
    "authors": [
      "Sawinder Kaur",
      "Ferdinando Fioretto",
      "Asif Salekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06417",
    "title": "A Contrastive Framework for Neural Text Generation",
    "abstract": " Comments: 22 pages, 8 figures, and 10 tables (v2 adds some experimental results) ",
    "url": "https://arxiv.org/abs/2202.06417",
    "authors": [
      "Yixuan Su",
      "Tian Lan",
      "Yan Wang",
      "Dani Yogatama",
      "Lingpeng Kong",
      "Nigel Collier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.07133",
    "title": "Sim-to-Real Domain Adaptation for Lane Detection and Classification in  Autonomous Driving",
    "abstract": " Comments: Accepted by IV 2022 ",
    "url": "https://arxiv.org/abs/2202.07133",
    "authors": [
      "Chuqing Hu",
      "Sinclair Hudson",
      "Martin Ethier",
      "Mohammad Al-Sharman",
      "Derek Rayside",
      "William Melek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07643",
    "title": "Lie Point Symmetry Data Augmentation for Neural PDE Solvers",
    "abstract": " Comments: Published at ICML 2022, Github: this https URL ",
    "url": "https://arxiv.org/abs/2202.07643",
    "authors": [
      "Johannes Brandstetter",
      "Max Welling",
      "Daniel E. Worrall"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.08480",
    "title": "Structural and Semantic Contrastive Learning for Unsupervised Node  Representation Learning",
    "abstract": " Title: Structural and Semantic Contrastive Learning for Unsupervised Node  Representation Learning ",
    "url": "https://arxiv.org/abs/2202.08480",
    "authors": [
      "Kaize Ding",
      "Yancheng Wang",
      "Yingzhen Yang",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.10185",
    "title": "OSegNet: Operational Segmentation Network for COVID-19 Detection using  Chest X-ray Images",
    "abstract": " Title: OSegNet: Operational Segmentation Network for COVID-19 Detection using  Chest X-ray Images ",
    "url": "https://arxiv.org/abs/2202.10185",
    "authors": [
      "Aysen Degerli",
      "Serkan Kiranyaz",
      "Muhammad E. H. Chowdhury",
      "Moncef Gabbouj"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.11091",
    "title": "Efficient and Differentiable Conformal Prediction with General Function  Classes",
    "abstract": " Comments: Appearing at ICLR 2022 ",
    "url": "https://arxiv.org/abs/2202.11091",
    "authors": [
      "Yu Bai",
      "Song Mei",
      "Huan Wang",
      "Yingbo Zhou",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.12570",
    "title": "Towards Learning Causal Representations from Multi-Instance Bags",
    "abstract": " Title: Towards Learning Causal Representations from Multi-Instance Bags ",
    "url": "https://arxiv.org/abs/2202.12570",
    "authors": [
      "Weijia Zhang",
      "Xuanhui Zhang",
      "Hanwen Deng",
      "Min-Ling Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.12887",
    "title": "Biological error correction codes generate fault-tolerant neural  networks",
    "abstract": " Title: Biological error correction codes generate fault-tolerant neural  networks ",
    "url": "https://arxiv.org/abs/2202.12887",
    "authors": [
      "Alexander Zlokapa",
      "Andrew K. Tan",
      "John M. Martyn",
      "Ila R. Fiete",
      "Max Tegmark",
      "Isaac L. Chuang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.01874",
    "title": "Thermodynamics-informed graph neural networks",
    "abstract": " Comments: 14 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2203.01874",
    "authors": [
      "Quercus Hern\u00e1ndez",
      "Alberto Bad\u00edas",
      "Francisco Chinesta",
      "El\u00edas Cueto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2203.04192",
    "title": "Reward-Biased Maximum Likelihood Estimation for Neural Contextual  Bandits",
    "abstract": " Title: Reward-Biased Maximum Likelihood Estimation for Neural Contextual  Bandits ",
    "url": "https://arxiv.org/abs/2203.04192",
    "authors": [
      "Yu-Heng Hung",
      "Ping-Chun Hsieh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.06925",
    "title": "WCL-BBCD: A Contrastive Learning and Knowledge Graph Approach to Named  Entity Recognition",
    "abstract": " Title: WCL-BBCD: A Contrastive Learning and Knowledge Graph Approach to Named  Entity Recognition ",
    "url": "https://arxiv.org/abs/2203.06925",
    "authors": [
      "Renjie Zhou",
      "Qiang Hu",
      "Jian Wan",
      "Jilin Zhang",
      "Qiang Liu",
      "Tianxiang Hu",
      "Jianjun Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.09081",
    "title": "Do We Really Need a Learnable Classifier at the End of Deep Neural  Network?",
    "abstract": " Title: Do We Really Need a Learnable Classifier at the End of Deep Neural  Network? ",
    "url": "https://arxiv.org/abs/2203.09081",
    "authors": [
      "Yibo Yang",
      "Shixiang Chen",
      "Xiangtai Li",
      "Liang Xie",
      "Zhouchen Lin",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.12136",
    "title": "Wasserstein Distributionally Robust Optimization with Wasserstein  Barycenters",
    "abstract": " Title: Wasserstein Distributionally Robust Optimization with Wasserstein  Barycenters ",
    "url": "https://arxiv.org/abs/2203.12136",
    "authors": [
      "Tim Tsz-Kit Lau",
      "Han Liu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.12997",
    "title": "Hierarchical Nearest Neighbor Graph Embedding for Efficient  Dimensionality Reduction",
    "abstract": " Comments: CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.12997",
    "authors": [
      "M. Saquib Sarfraz",
      "Marios Koulakis",
      "Constantin Seibold",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2203.13310",
    "title": "MonoDETR: Depth-guided Transformer for Monocular 3D Object Detection",
    "abstract": " Title: MonoDETR: Depth-guided Transformer for Monocular 3D Object Detection ",
    "url": "https://arxiv.org/abs/2203.13310",
    "authors": [
      "Renrui Zhang",
      "Han Qiu",
      "Tai Wang",
      "Ziyu Guo",
      "Xuanzhuo Xu",
      "Yu Qiao",
      "Peng Gao",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.13655",
    "title": "Gransformer: Transformer-based Graph Generation",
    "abstract": " Title: Gransformer: Transformer-based Graph Generation ",
    "url": "https://arxiv.org/abs/2203.13655",
    "authors": [
      "Ahmad Khajenezhad",
      "Seyed Ali Osia",
      "Mahmood Karimian",
      "Hamid Beigy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15177",
    "title": "Min-Max Similarity: A Contrastive Learning Based Semi-Supervised  Learning Network for Surgical Tools Segmentation",
    "abstract": " Title: Min-Max Similarity: A Contrastive Learning Based Semi-Supervised  Learning Network for Surgical Tools Segmentation ",
    "url": "https://arxiv.org/abs/2203.15177",
    "authors": [
      "Ange Lou",
      "Kareem Tawfik",
      "Xing Yao",
      "Ziteng Liu",
      "Jack Noble"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.16437",
    "title": "Weakly supervised causal representation learning",
    "abstract": " Comments: Published at the ICLR 2022 workshop on Objects, Structure and Causality ",
    "url": "https://arxiv.org/abs/2203.16437",
    "authors": [
      "Johann Brehmer",
      "Pim de Haan",
      "Phillip Lippe",
      "Taco Cohen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.03768",
    "title": "Global ECG Classification by Self-Operational Neural Networks with  Feature Injection",
    "abstract": " Title: Global ECG Classification by Self-Operational Neural Networks with  Feature Injection ",
    "url": "https://arxiv.org/abs/2204.03768",
    "authors": [
      "Muhammad Uzair Zahid",
      "Serkan Kiranyaz",
      "Moncef Gabbouj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04245",
    "title": "Online Emotions During the Storming of the U.S. Capitol: Evidence from  the Social Media Network Parler",
    "abstract": " Title: Online Emotions During the Storming of the U.S. Capitol: Evidence from  the Social Media Network Parler ",
    "url": "https://arxiv.org/abs/2204.04245",
    "authors": [
      "Johannes Jakubik",
      "Michael V\u00f6ssing",
      "Dominik B\u00e4r",
      "Nicolas Pr\u00f6llochs",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.06676",
    "title": "DRAGON (Differentiable Graph Execution) : A suite of Hardware Simulation  and Optimization tools for Modern AI/Non-AI Workloads",
    "abstract": " Title: DRAGON (Differentiable Graph Execution) : A suite of Hardware Simulation  and Optimization tools for Modern AI/Non-AI Workloads ",
    "url": "https://arxiv.org/abs/2204.06676",
    "authors": [
      "Khushal Sethi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2204.10050",
    "title": "SemEval-2022 Task 2: Multilingual Idiomaticity Detection and Sentence  Embedding",
    "abstract": " Comments: Data available at this https URL and competition website at this https URL ",
    "url": "https://arxiv.org/abs/2204.10050",
    "authors": [
      "Harish Tayyar Madabushi",
      "Edward Gow-Smith",
      "Marcos Garcia",
      "Carolina Scarton",
      "Marco Idiart",
      "Aline Villavicencio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.01355",
    "title": "Predicting Loose-Fitting Garment Deformations Using Bone-Driven Motion  Networks",
    "abstract": " Comments: SIGGRAPH 22 Conference Paper ",
    "url": "https://arxiv.org/abs/2205.01355",
    "authors": [
      "Xiaoyu Pan",
      "Jiaming Mai",
      "Xinwei Jiang",
      "Dongxue Tang",
      "Jingxiang Li",
      "Tianjia Shao",
      "Kun Zhou",
      "Xiaogang Jin",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.02357",
    "title": "Hybrid Transformer with Multi-level Fusion for Multimodal Knowledge  Graph Completion",
    "abstract": " Comments: Accepted by SIGIR 2022. Fix typos ",
    "url": "https://arxiv.org/abs/2205.02357",
    "authors": [
      "Xiang Chen",
      "Ningyu Zhang",
      "Lei Li",
      "Shumin Deng",
      "Chuanqi Tan",
      "Changliang Xu",
      "Fei Huang",
      "Luo Si",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.02708",
    "title": "Meta-learning Adaptive Deep Kernel Gaussian Processes for Molecular  Property Prediction",
    "abstract": " Comments: 19 pages, 6 figures, 5 tables, 1 algorithm ",
    "url": "https://arxiv.org/abs/2205.02708",
    "authors": [
      "Wenlin Chen",
      "Austin Tripp",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.03168",
    "title": "Defending against Reconstruction Attacks through Differentially Private  Federated Learning for Classification of Heterogeneous Chest X-Ray Data",
    "abstract": " Title: Defending against Reconstruction Attacks through Differentially Private  Federated Learning for Classification of Heterogeneous Chest X-Ray Data ",
    "url": "https://arxiv.org/abs/2205.03168",
    "authors": [
      "Joceline Ziegler",
      "Bjarne Pfitzner",
      "Heinrich Schulz",
      "Axel Saalbach",
      "Bert Arnrich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.04747",
    "title": "Controlling Extra-Textual Attributes about Dialogue Participants -- A  Case Study of English-to-Polish Neural Machine Translation",
    "abstract": " Comments: 9 pages, 9 figures, EAMT2022 camera-ready ",
    "url": "https://arxiv.org/abs/2205.04747",
    "authors": [
      "Sebastian T. Vincent",
      "Lo\u00efc Barrault",
      "Carolina Scarton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.07384",
    "title": "Incorporating Prior Knowledge into Neural Networks through an Implicit  Composite Kernel",
    "abstract": " Comments: 17 pages, 14 figures, 1 table, submitted to 36th Conference on Neural Information Processing Systems (NeurIPS 2022) ",
    "url": "https://arxiv.org/abs/2205.07384",
    "authors": [
      "Ziyang Jiang",
      "Tongshu Zheng",
      "David Carlson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.08479",
    "title": "Opportunistic Routing in Quantum Networks",
    "abstract": " Comments: This paper is accepted in INFOCOM (IEEE Conference on Computer Communications) 2022 ",
    "url": "https://arxiv.org/abs/2205.08479",
    "authors": [
      "Ali Farahbakhsh",
      "Chen Feng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2205.08671",
    "title": "K-textures, a self-supervised hard clustering deep learning algorithm  for satellite image segmentation",
    "abstract": " Comments: 19 pages, 10 figures, submitted to Frontiers in Environmental Science, section Environmental Informatics and Remote Sensing, Research Topic: Advances in Machine Learning and Deep Learning for Monitoring Terrestrial Ecosystems ",
    "url": "https://arxiv.org/abs/2205.08671",
    "authors": [
      "Fabien H. Wagner",
      "Ricardo Dalagnol",
      "Alber H. S\u00e1nchez",
      "Mayumi C.M. Hirye",
      "Samuel Favrichon",
      "Jake H. Lee",
      "Steffen Mauceri",
      "Yan Yang",
      "Sassan Saatchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.08689",
    "title": "Spatial-Temporal Interactive Dynamic Graph Convolution Network for  Traffic Forecasting",
    "abstract": " Title: Spatial-Temporal Interactive Dynamic Graph Convolution Network for  Traffic Forecasting ",
    "url": "https://arxiv.org/abs/2205.08689",
    "authors": [
      "Aoyu Liu",
      "Yaying Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.08978",
    "title": "Fast Neural Network based Solving of Partial Differential Equations",
    "abstract": " Title: Fast Neural Network based Solving of Partial Differential Equations ",
    "url": "https://arxiv.org/abs/2205.08978",
    "authors": [
      "Jaroslaw Rzepecki",
      "Daniel Bates",
      "Chris Doran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2205.09418",
    "title": "Leveraging Dynamic Objects for Relative Localization Correction in a  Connected Autonomous Vehicle Network",
    "abstract": " Comments: ISPRS congress 2022 ",
    "url": "https://arxiv.org/abs/2205.09418",
    "authors": [
      "Yunshuang Yuan",
      "Monika Sester"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.09702",
    "title": "Parallel and Distributed Graph Neural Networks: An In-Depth Concurrency  Analysis",
    "abstract": " Title: Parallel and Distributed Graph Neural Networks: An In-Depth Concurrency  Analysis ",
    "url": "https://arxiv.org/abs/2205.09702",
    "authors": [
      "Maciej Besta",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.09884",
    "title": "Time Series Anomaly Detection via Reinforcement Learning-Based Model  Selection",
    "abstract": " Comments: 6 pages, 3 figures, submitted to IEEE Canadian Conference on Electrical and Computer Engineering (CCECE) 2022 ",
    "url": "https://arxiv.org/abs/2205.09884",
    "authors": [
      "Jiuqi Elise Zhang",
      "Di Wu",
      "Benoit Boulet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10663",
    "title": "Transformer based Generative Adversarial Network for Liver Segmentation",
    "abstract": " Title: Transformer based Generative Adversarial Network for Liver Segmentation ",
    "url": "https://arxiv.org/abs/2205.10663",
    "authors": [
      "Ugur Demir",
      "Zheyuan Zhang",
      "Bin Wang",
      "Matthew Antalek",
      "Elif Keles",
      "Debesh Jha",
      "Amir Borhani",
      "Daniela Ladner",
      "Ulas Bagci"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11461",
    "title": "Undecidability of Network Coding, Conditional Information Inequalities,  and Conditional Independence Implication",
    "abstract": " Comments: 20 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2205.11461",
    "authors": [
      "Cheuk Ting Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2205.11664",
    "title": "Towards Model Generalization for Monocular 3D Object Detection",
    "abstract": " Comments: Some mistakes are raised up and we need to re-write the paper and re-order the paper structure ",
    "url": "https://arxiv.org/abs/2205.11664",
    "authors": [
      "Zhenyu Li",
      "Zehui Chen",
      "Ang Li",
      "Liangji Fang",
      "Qinhong Jiang",
      "Xianming Liu",
      "Junjun Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11736",
    "title": "Towards a Defense against Backdoor Attacks in Continual Federated  Learning",
    "abstract": " Title: Towards a Defense against Backdoor Attacks in Continual Federated  Learning ",
    "url": "https://arxiv.org/abs/2205.11736",
    "authors": [
      "Shuaiqi Wang",
      "Jonathan Hayase",
      "Giulia Fanti",
      "Sewoong Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.12465",
    "title": "FBNETGEN: Task-aware GNN-based fMRI Analysis via Functional Brain  Network Generation",
    "abstract": " Comments: This paper has been accepted for presentation in MIDL 2022 ",
    "url": "https://arxiv.org/abs/2205.12465",
    "authors": [
      "Xuan Kan",
      "Hejie Cui",
      "Joshua Lukemire",
      "Ying Guo",
      "Carl Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2205.13060",
    "title": "Designing an Efficient End-to-end Machine Learning Pipeline for  Real-time Empty-shelf Detection",
    "abstract": " Comments: 7 figures, 3 tables, 10 pages ",
    "url": "https://arxiv.org/abs/2205.13060",
    "authors": [
      "Dipendra Jha",
      "Ata Mahjoubfar",
      "Anupama Joshi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13137",
    "title": "MixMIM: Mixed and Masked Image Modeling for Efficient Visual  Representation Learning",
    "abstract": " Comments: preprint. Code: this https URL ",
    "url": "https://arxiv.org/abs/2205.13137",
    "authors": [
      "Jihao Liu",
      "Xin Huang",
      "Yu Liu",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13921",
    "title": "Federated Semi-Supervised Learning with Prototypical Networks",
    "abstract": " Title: Federated Semi-Supervised Learning with Prototypical Networks ",
    "url": "https://arxiv.org/abs/2205.13921",
    "authors": [
      "Woojung Kim",
      "Keondo Park",
      "Kihyuk Sohn",
      "Raphael Shu",
      "Hyung-Sin Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]