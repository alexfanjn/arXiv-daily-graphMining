[
  {
    "id": "arXiv:2106.15878",
    "title": "Towards establishing formal verification and inductive code synthesis in  the PLC domain",
    "abstract": "Nowadays, formal methods are used in various areas for the verification of programs or for code generation from models in order to increase the quality of software and to reduce costs. However, there are still fields in which formal methods have not been widely adopted, despite the large set of possible benefits offered. This is the case for the area of programmable logic controllers (PLC). This article aims to evaluate the potential of formal methods in the context of PLC development. For this purpose, the general concepts of formal methods are first introduced and then transferred to the PLC area, resulting in an engineering-oriented description of the technology that is based on common concepts from PLC development. Based on this description, PLC professionals with varying degrees of experience were interviewed for their perspective on the topic and to identify possible use cases within the PLC domain. The survey results indicate the technology's high potential in the PLC area, either as a tool to directly support the developer or as a key element within a model-based systems engineering toolchain. The evaluation of the survey results is performed with the aid of a demo application that communicates with the Totally Integrated Automation Portal from Siemens and generates programs via Fastsynth, a model-based open source code generator. Benchmarks based on an industry-related PLC project show satisfactory synthesis times and a successful integration into the workflow of a PLC developer. ",
    "url": "https://arxiv.org/abs/2106.15878",
    "authors": [
      "Matthias Wei\u00df",
      "Philipp Marks",
      "Benjamin Maschler",
      "Dustin White",
      "Pascal Kesseli",
      "Michael Weyrich"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Programming Languages (cs.PL)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2106.15965",
    "title": "Embedded out-of-distribution detection on an autonomous robot platform",
    "abstract": "Machine learning (ML) is actively finding its way into modern cyber-physical systems (CPS), many of which are safety-critical real-time systems. It is well known that ML outputs are not reliable when testing data are novel with regards to model training and validation data, i.e., out-of-distribution (OOD) test data. We implement an unsupervised deep neural network-based OOD detector on a real-time embedded autonomous Duckiebot and evaluate detection performance. Our OOD detector produces a success rate of 87.5% for emergency stopping a Duckiebot on a braking test bed we designed. We also provide case analysis on computing resource challenges specific to the Robot Operating System (ROS) middleware on the Duckiebot. ",
    "url": "https://arxiv.org/abs/2106.15965",
    "authors": [
      "Michael Yuhas",
      "Yeli Feng",
      "Daniel Jun Xian Ng",
      "Zahra Rahiminasab",
      "Arvind Easwaran"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2106.16004",
    "title": "What can linear interpolation of neural network loss landscapes tell us?",
    "abstract": "Studying neural network loss landscapes provides insights into the nature of the underlying optimization problems. Unfortunately, loss landscapes are notoriously difficult to visualize in a human-comprehensible fashion. One common way to address this problem is to plot linear slices of the landscape, for example from the initial state of the network to the final state after optimization. On the basis of this analysis, prior work has drawn broader conclusions about the difficulty of the optimization problem. In this paper, we put inferences of this kind to the test, systematically evaluating how linear interpolation and final performance vary when altering the data, choice of initialization, and other optimizer and architecture design choices. Further, we use linear interpolation to study the role played by individual layers and substructures of the network. We find that certain layers are more sensitive to the choice of initialization and optimizer hyperparameter settings, and we exploit these observations to design custom optimization schemes. However, our results cast doubt on the broader intuition that the presence or absence of barriers when interpolating necessarily relates to the success of optimization. ",
    "url": "https://arxiv.org/abs/2106.16004",
    "authors": [
      "Tiffany Vlaar",
      "Jonathan Frankle"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.16009",
    "title": "MissFormer: (In-)attention-based handling of missing observations for  trajectory filtering and prediction",
    "abstract": "In applications such as object tracking, time-series data inevitably carry missing observations. Following the success of deep learning-based models for various sequence learning tasks, these models increasingly replace classic approaches in object tracking applications for inferring the object motions state. While traditional tracking approaches can deal with missing observations, most of their deep counterparts are, by default, not suited for this. Towards this end, this paper introduces a transformer-based approach for handling missing observations in variable input length trajectory data. The model is formed indirectly by successively increasing the complexity of the demanded inference tasks. Starting from reproducing noise-free trajectories, the model then learns to infer trajectories from noisy inputs. By providing missing tokens, binary-encoded missing events, the model learns to in-attend to missing data and infers a complete trajectory conditioned on the remaining inputs. In the case of a sequence of successive missing events, the model then acts as a pure prediction model. The model's abilities are demonstrated on synthetic data and real-world data reflecting prototypical object tracking scenarios. ",
    "url": "https://arxiv.org/abs/2106.16009",
    "authors": [
      "Stefan Becker",
      "Ronny Hug",
      "Wolfgang H\u00fcbner",
      "Michael Arens",
      "Brendan T. Morris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.15909",
    "title": "Effect of acoustic scene complexity and visual scene representation on  auditory perception in virtual audio-visual environments",
    "abstract": "In daily life, social interaction and acoustic communication often take place in complex acoustic environments (CAE) with a variety of interfering sounds and reverberation. For hearing research and evaluation of hearing systems simulated CAEs using virtual reality techniques have gained interest in the context of ecologically validity. In the current study, the effect of scene complexity and visual representation of the scene on psychoacoustic measures like sound source location, distance perception, loudness, speech intelligibility, and listening effort in a virtual audio-visual environment was investigated. A 3-dimensional, 86-channel loudspeaker array was used to render the sound field in combination with or without a head-mounted display (HMD) to create an immersive stereoscopic visual representation of the scene. The scene consisted of a ring of eight (virtual) loudspeakers which played a target speech stimulus and non-sense speech interferers in several spatial conditions. Either an anechoic (snowy outdoor scenery) or echoic environment (loft apartment) with a reverberation time (T60) of about 1.5 s was simulated. In addition to varying the number of interferers, scene complexity was varied by assessing the psychoacoustic measures in isolated consecutive measurements or simultaneously. Results showed no significant effect of wearing the HMD on the data. Loudness and distance perception showed significantly different results when they were measured simultaneously instead of consecutively in isolation. The advantage of the suggested setup is that it can be directly transferred to a corresponding real room, enabling a 1:1 comparison and verification of the perception experiments in the real and virtual environment. ",
    "url": "https://arxiv.org/abs/2106.15909",
    "authors": [
      "Stefan Fichna",
      "Thomas Biberger",
      "Bernhard U. Seeber",
      "Stephan D. Ewert"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2106.16044",
    "title": "Energy and Randic index of directed graphs",
    "abstract": "The concept of Randic index has been extended recently for a digraph. We prove that $2R(G)\\leq \\mathcal{E}(G)\\leq 2\\sqrt{\\Delta(G)} R(G)$, where $G$ is a digraph, and $R(G)$ denotes the Randic index, $\\mathcal{E}(G)$ denotes the Nikiforov energy and $\\Delta(G) $ denotes the maximum degree of $G$. In both inequalities we describe the graphs for which the equality holds. ",
    "url": "https://arxiv.org/abs/2106.16044",
    "authors": [
      "Gerardo Arizmendi",
      "Octavio Arizmendi"
    ],
    "subjectives": [
      "Spectral Theory (math.SP)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2106.16239",
    "title": "Fixed points of monotonic and (weakly) scalable neural networks",
    "abstract": "We derive conditions for the existence of fixed points of neural networks, an important research objective to understand their behavior in modern applications involving autoencoders and loop unrolling techniques, among others. In particular, we focus on networks with nonnegative inputs and nonnegative network parameters, as often considered in the literature. We show that such networks can be recognized as monotonic and (weakly) scalable functions within the framework of nonlinear Perron-Frobenius theory. This fact enables us to derive conditions for the existence of a nonempty fixed point set of the neural networks, and these conditions are weaker than those obtained recently using arguments in convex analysis, which are typically based on the assumption of nonexpansivity of the activation functions. Furthermore, we prove that the shape of the fixed point set of monotonic and weakly scalable neural networks is often an interval, which degenerates to a point for the case of scalable networks. The chief results of this paper are verified in numerical simulations, where we consider an autoencoder-type network that first compresses angular power spectra in massive MIMO systems, and, second, reconstruct the input spectra from the compressed signal. ",
    "url": "https://arxiv.org/abs/2106.16239",
    "authors": [
      "Tomasz Piotrowski",
      "Renato L. G. Cavalcante"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2102.10159",
    "title": "A convergent finite difference method for computing minimal Lagrangian  graphs",
    "abstract": " Title: A convergent finite difference method for computing minimal Lagrangian  graphs ",
    "url": "https://arxiv.org/abs/2102.10159",
    "authors": [
      "Brittany Froese Hamfeldt",
      "Jacob Lesniewski"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2104.05575",
    "title": "GAttANet: Global attention agreement for convolutional neural networks",
    "abstract": " Comments: Paper accepted to ICANN 2021 - The 30th International Conference on Artificial Neural Networks ",
    "url": "https://arxiv.org/abs/2104.05575",
    "authors": [
      "Rufin VanRullen",
      "Andrea Alamia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2104.09866",
    "title": "Distill on the Go: Online knowledge distillation in self-supervised  learning",
    "abstract": " Comments: Spotlight @ Learning from Limited or Imperfect Data (L2ID) Workshop - CVPR 2021 ",
    "url": "https://arxiv.org/abs/2104.09866",
    "authors": [
      "Prashant Bhat",
      "Elahe Arani",
      "Bahram Zonooz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.13813",
    "title": "Grey-box models for wave loading prediction",
    "abstract": " Title: Grey-box models for wave loading prediction ",
    "url": "https://arxiv.org/abs/2105.13813",
    "authors": [
      "Daniel J Pitchforth",
      "Timothy J Rogers",
      "Ulf T Tygesen",
      "Elizabeth J Cross"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2106.03412",
    "title": "Resolution learning in deep convolutional networks using scale-space  theory",
    "abstract": " Title: Resolution learning in deep convolutional networks using scale-space  theory ",
    "url": "https://arxiv.org/abs/2106.03412",
    "authors": [
      "Silvia L.Pintea",
      "Nergis Tomen",
      "Stanley F. Goes",
      "Marco Loog",
      "Jan C. van Gemert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]