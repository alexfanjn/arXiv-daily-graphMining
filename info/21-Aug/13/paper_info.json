[
  {
    "id": "arXiv:2108.05643",
    "title": "On minimal representations of shallow ReLU networks",
    "abstract": "The realization function of a shallow ReLU network is a continuous and piecewise affine function $f:\\mathbb R^d\\to \\mathbb R$, where the domain $\\mathbb R^{d}$ is partitioned by a set of $n$ hyperplanes into cells on which $f$ is affine. We show that the minimal representation for $f$ uses either $n$, $n+1$ or $n+2$ neurons and we characterize each of the three cases. In the particular case, where the input layer is one-dimensional, minimal representations always use at most $n+1$ neurons but in all higher dimensional settings there are functions for which $n+2$ neurons are needed. Then we show that the set of minimal networks representing $f$ forms a $C^\\infty$-submanifold $M$ and we derive the dimension and the number of connected components of $M$. Additionally, we give a criterion for the hyperplanes that guarantees that all continuous, piecewise affine functions are realization functions of appropriate ReLU networks. ",
    "url": "https://arxiv.org/abs/2108.05643",
    "authors": [
      "S. Dereich",
      "S. Kassing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2108.05885",
    "title": "The paradox of the compositionality of natural language: a neural  machine translation case study",
    "abstract": "Moving towards human-like linguistic performance is often argued to require compositional generalisation. Whether neural networks exhibit this ability is typically studied using artificial languages, for which the compositionality of input fragments can be guaranteed and their meanings algebraically composed. However, compositionality in natural language is vastly more complex than this rigid, arithmetics-like version of compositionality, and as such artificial compositionality tests do not allow us to draw conclusions about how neural models deal with compositionality in more realistic scenarios. In this work, we re-instantiate three compositionality tests from the literature and reformulate them for neural machine translation (NMT). The results highlight two main issues: the inconsistent behaviour of NMT models and their inability to (correctly) modulate between local and global processing. Aside from an empirical study, our work is a call to action: we should rethink the evaluation of compositionality in neural networks of natural language, where composing meaning is not as straightforward as doing the math. ",
    "url": "https://arxiv.org/abs/2108.05885",
    "authors": [
      "Verna Dankers",
      "Elia Bruni",
      "Dieuwke Hupkes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2008.07468",
    "title": "A unified algorithm for colouring graphs of bounded clique-width",
    "abstract": " Title: A unified algorithm for colouring graphs of bounded clique-width ",
    "url": "https://arxiv.org/abs/2008.07468",
    "authors": [
      "Bruno Courcelle",
      "Ir\u00e8ne Durand",
      "Michael Raskin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2009.07101",
    "title": "Approximate spectral clustering using both reference vectors and  topology of the network generated by growing neural gas",
    "abstract": " Title: Approximate spectral clustering using both reference vectors and  topology of the network generated by growing neural gas ",
    "url": "https://arxiv.org/abs/2009.07101",
    "authors": [
      "Kazuhisa Fujita"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2010.09256",
    "title": "Diffusion in large networks",
    "abstract": " Title: Diffusion in large networks ",
    "url": "https://arxiv.org/abs/2010.09256",
    "authors": [
      "Michel Grabisch",
      "Agnieszka Rusinowska",
      "Xavier Venel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2103.12323",
    "title": "Anomaly detection using principles of human perception",
    "abstract": " Title: Anomaly detection using principles of human perception ",
    "url": "https://arxiv.org/abs/2103.12323",
    "authors": [
      "Mohammad Nassir"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  }
]