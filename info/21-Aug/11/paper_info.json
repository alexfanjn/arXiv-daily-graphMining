[
  {
    "id": "arXiv:2108.04345",
    "title": "Explainable AI and susceptibility to adversarial attacks: a case study  in classification of breast ultrasound images",
    "abstract": "Ultrasound is a non-invasive imaging modality that can be conveniently used to classify suspicious breast nodules and potentially detect the onset of breast cancer. Recently, Convolutional Neural Networks (CNN) techniques have shown promising results in classifying ultrasound images of the breast into benign or malignant. However, CNN inference acts as a black-box model, and as such, its decision-making is not interpretable. Therefore, increasing effort has been dedicated to explaining this process, most notably through GRAD-CAM and other techniques that provide visual explanations into inner workings of CNNs. In addition to interpretation, these methods provide clinically important information, such as identifying the location for biopsy or treatment. In this work, we analyze how adversarial assaults that are practically undetectable may be devised to alter these importance maps dramatically. Furthermore, we will show that this change in the importance maps can come with or without altering the classification result, rendering them even harder to detect. As such, care must be taken when using these importance maps to shed light on the inner workings of deep learning. Finally, we utilize Multi-Task Learning (MTL) and propose a new network based on ResNet-50 to improve the classification accuracies. Our sensitivity and specificity is comparable to the state of the art results. ",
    "url": "https://arxiv.org/abs/2108.04345",
    "authors": [
      "Hamza Rasaee",
      "Hassan Rivaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.04494",
    "title": "Finding NeMo: Fishing in banking networks using network motifs",
    "abstract": "Banking fraud causes billion-dollar losses for banks worldwide. In fraud detection, graphs help understand complex transaction patterns and discovering new fraud schemes. This work explores graph patterns in a real-world transaction dataset by extracting and analyzing its network motifs. Since banking graphs are heterogeneous, we focus on heterogeneous network motifs. Additionally, we propose a novel network randomization process that generates valid banking graphs. From our exploratory analysis, we conclude that network motifs extract insightful and interpretable patterns. ",
    "url": "https://arxiv.org/abs/2108.04494",
    "authors": [
      "Xavier Fontes",
      "David Apar\u00edcio",
      "Maria In\u00eas Silva",
      "Beatriz Malveiro",
      "Jo\u00e3o Tiago Ascens\u00e3o",
      "Pedro Bizarro"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2108.04585",
    "title": "Recurrent neural network-based Internal Model Control of unknown  nonlinear stable systems",
    "abstract": "Owing to their superior modeling capabilities, gated Recurrent Neural Networks (RNNs), such as Gated Recurrent Units (GRUs) and Long Short-Term Memory networks (LSTMs), have become popular tools for learning dynamical systems. This paper aims to discuss how these networks can be adopted for the synthesis of Internal Model Control (IMC) architectures. To this end, a first gated RNN is used to learn a model of the unknown input-output stable plant. Then, another gated RNN approximating the model inverse is trained. The proposed scheme is able to cope with the saturation of the control variables, and it can be deployed on low-power embedded controllers since it does not require any online computation. The approach is then tested on the Quadruple Tank benchmark system, resulting in satisfactory closed-loop performances. ",
    "url": "https://arxiv.org/abs/2108.04585",
    "authors": [
      "Fabio Bonassi",
      "Riccardo Scattolini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2108.04588",
    "title": "Distinguishing classes of intersection graphs of homothets or  similarities of two convex disks",
    "abstract": "For smooth convex disks $A$, i.e., convex compact subsets of the plane with non-empty interior, we classify the classes $G^{\\text{hom}}(A)$ and $G^{\\text{sim}}(A)$ of intersection graphs that can be obtained from homothets and similarities of $A$, respectively. Namely, we prove that $G^{\\text{hom}}(A)=G^{\\text{hom}}(B)$ if and only if $A$ and $B$ are affine equivalent, and $G^{\\text{sim}}(A)=G^{\\text{sim}}(B)$ if and only if $A$ and $B$ are similar. ",
    "url": "https://arxiv.org/abs/2108.04588",
    "authors": [
      "Mikkel Abrahamsen",
      "Bartosz Walczak"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)",
      "Metric Geometry (math.MG)"
    ]
  },
  {
    "id": "arXiv:2108.04614",
    "title": "White blood cell subtype detection and classification",
    "abstract": "Machine learning has endless applications in the health care industry. White blood cell classification is one of the interesting and promising area of research. The classification of the white blood cells plays an important part in the medical diagnosis. In practise white blood cell classification is performed by the haematologist by taking a small smear of blood and careful examination under the microscope. The current procedures to identify the white blood cell subtype is more time taking and error-prone. The computer aided detection and diagnosis of the white blood cells tend to avoid the human error and reduce the time taken to classify the white blood cells. In the recent years several deep learning approaches have been developed in the context of classification of the white blood cells that are able to identify but are unable to localize the positions of white blood cells in the blood cell image. Following this, the present research proposes to utilize YOLOv3 object detection technique to localize and classify the white blood cells with bounding boxes. With exhaustive experimental analysis, the proposed work is found to detect the white blood cell with 99.2% accuracy and classify with 90% accuracy. ",
    "url": "https://arxiv.org/abs/2108.04614",
    "authors": [
      "Nalla Praveen",
      "Narinder Singh Punn",
      "Sanjay Kumar Sonbhadra",
      "Sonali Agarwal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.04616",
    "title": "Hope Speech detection in under-resourced Kannada language",
    "abstract": "Numerous methods have been developed to monitor the spread of negativity in modern years by eliminating vulgar, offensive, and fierce comments from social media platforms. However, there are relatively lesser amounts of study that converges on embracing positivity, reinforcing supportive and reassuring content in online forums. Consequently, we propose creating an English-Kannada Hope speech dataset, KanHope and comparing several experiments to benchmark the dataset. The dataset consists of 6,176 user-generated comments in code mixed Kannada scraped from YouTube and manually annotated as bearing hope speech or Not-hope speech. In addition, we introduce DC-BERT4HOPE, a dual-channel model that uses the English translation of KanHope for additional training to promote hope speech detection. The approach achieves a weighted F1-score of 0.756, bettering other models. Henceforth, KanHope aims to instigate research in Kannada while broadly promoting researchers to take a pragmatic approach towards online content that encourages, positive, and supportive. ",
    "url": "https://arxiv.org/abs/2108.04616",
    "authors": [
      "Adeep Hande",
      "Ruba Priyadharshini",
      "Anbukkarasi Sampath",
      "Kingston Pal Thamburaj",
      "Prabakaran Chandran",
      "Bharathi Raja Chakravarthi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2108.04658",
    "title": "U-Net-and-a-half: Convolutional network for biomedical image  segmentation using multiple expert-driven annotations",
    "abstract": "Development of deep learning systems for biomedical segmentation often requires access to expert-driven, manually annotated datasets. If more than a single expert is involved in the annotation of the same images, then the inter-expert agreement is not necessarily perfect, and no single expert annotation can precisely capture the so-called ground truth of the regions of interest on all images. Also, it is not trivial to generate a reference estimate using annotations from multiple experts. Here we present a deep neural network, defined as U-Net-and-a-half, which can simultaneously learn from annotations performed by multiple experts on the same set of images. U-Net-and-a-half contains a convolutional encoder to generate features from the input images, multiple decoders that allow simultaneous learning from image masks obtained from annotations that were independently generated by multiple experts, and a shared low-dimensional feature space. To demonstrate the applicability of our framework, we used two distinct datasets from digital pathology and radiology, respectively. Specifically, we trained two separate models using pathologist-driven annotations of glomeruli on whole slide images of human kidney biopsies (10 patients), and radiologist-driven annotations of lumen cross-sections of human arteriovenous fistulae obtained from intravascular ultrasound images (10 patients), respectively. The models based on U-Net-and-a-half exceeded the performance of the traditional U-Net models trained on single expert annotations alone, thus expanding the scope of multitask learning in the context of biomedical image segmentation. ",
    "url": "https://arxiv.org/abs/2108.04658",
    "authors": [
      "Yichi Zhang",
      "Jesper Kers",
      "Clarissa A. Cassol",
      "Joris J. Roelofs",
      "Najia Idrees",
      "Alik Farber",
      "Samir Haroon",
      "Kevin P. Daly",
      "Suvranu Ganguli",
      "Vipul C. Chitalia",
      "Vijaya B. Kolachalama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.04742",
    "title": "The information of attribute uncertainties: what convolutional neural  networks can learn about errors in input data",
    "abstract": "Errors in measurements are key to weighting the value of data, but are often neglected in Machine Learning (ML). We show how Convolutional Neural Networks (CNNs) are able to learn about the context and patterns of signal and noise, leading to improvements in the performance of classification methods. We construct a model whereby two classes of objects follow an underlying Gaussian distribution, and where the features (the input data) have varying, but known, levels of noise. This model mimics the nature of scientific data sets, where the noises arise as realizations of some random processes whose underlying distributions are known. The classification of these objects can then be performed using standard statistical techniques (e.g., least-squares minimization or Markov-Chain Monte Carlo), as well as ML techniques. This allows us to take advantage of a maximum likelihood approach to object classification, and to measure the amount by which the ML methods are incorporating the information in the input data uncertainties. We show that, when each data point is subject to different levels of noise (i.e., noises with different distribution functions), that information can be learned by the CNNs, raising the ML performance to at least the same level of the least-squares method -- and sometimes even surpassing it. Furthermore, we show that, with varying noise levels, the confidence of the ML classifiers serves as a proxy for the underlying cumulative distribution function, but only if the information about specific input data uncertainties is provided to the CNNs. ",
    "url": "https://arxiv.org/abs/2108.04742",
    "authors": [
      "Nat\u00e1lia V. N. Rodrigues",
      "L. Raul Abramo",
      "Nina S. Hirata"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2108.04620",
    "title": "A proof of convergence for the gradient descent optimization method with  random initializations in the training of neural networks with ReLU  activation for piecewise linear target functions",
    "abstract": "Gradient descent (GD) type optimization methods are the standard instrument to train artificial neural networks (ANNs) with rectified linear unit (ReLU) activation. Despite the great success of GD type optimization methods in numerical simulations for the training of ANNs with ReLU activation, it remains - even in the simplest situation of the plain vanilla GD optimization method with random initializations and ANNs with one hidden layer - an open problem to prove (or disprove) the conjecture that the risk of the GD optimization method converges in the training of such ANNs to zero as the width of the ANNs, the number of independent random initializations, and the number of GD steps increase to infinity. In this article we prove this conjecture in the situation where the probability distribution of the input data is equivalent to the continuous uniform distribution on a compact interval, where the probability distributions for the random initializations of the ANN parameters are standard normal distributions, and where the target function under consideration is continuous and piecewise affine linear. Roughly speaking, the key ingredients in our mathematical convergence analysis are (i) to prove that suitable sets of global minima of the risk functions are \\emph{twice continuously differentiable submanifolds of the ANN parameter spaces}, (ii) to prove that the Hessians of the risk functions on these sets of global minima satisfy an appropriate \\emph{maximal rank condition}, and, thereafter, (iii) to apply the machinery in [Fehrman, B., Gess, B., Jentzen, A., Convergence rates for the stochastic gradient descent method for non-convex objective functions. J. Mach. Learn. Res. 21(136): 1--48, 2020] to establish convergence of the GD optimization method with random initializations. ",
    "url": "https://arxiv.org/abs/2108.04620",
    "authors": [
      "Arnulf Jentzen",
      "Adrian Riekert"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2007.11946",
    "title": "A Solution to Product detection in Densely Packed Scenes",
    "abstract": " Comments: 6 pages ",
    "url": "https://arxiv.org/abs/2007.11946",
    "authors": [
      "Tianze Rong",
      "Yanjia Zhu",
      "Hongxiang Cai",
      "Yichao Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2011.02829",
    "title": "Deep tree-ensembles for multi-output prediction",
    "abstract": " Title: Deep tree-ensembles for multi-output prediction ",
    "url": "https://arxiv.org/abs/2011.02829",
    "authors": [
      "Felipe Kenji Nakano",
      "Konstantinos Pliakos",
      "Celine Vens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2011.10443",
    "title": "Variational Laplace for Bayesian neural networks",
    "abstract": " Title: Variational Laplace for Bayesian neural networks ",
    "url": "https://arxiv.org/abs/2011.10443",
    "authors": [
      "Ali Unlu",
      "Laurence Aitchison"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.08565",
    "title": "Learning point embedding for 3D data processing",
    "abstract": " Title: Learning point embedding for 3D data processing ",
    "url": "https://arxiv.org/abs/2107.08565",
    "authors": [
      "Zhenpeng Chen",
      "Yuan li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.14582",
    "title": "NeuralDP Differentially private neural networks by design",
    "abstract": " Comments: Paper withdrawn. The paper contains a factual error ",
    "url": "https://arxiv.org/abs/2107.14582",
    "authors": [
      "Moritz Knolle",
      "Dmitrii Usynin",
      "Alexander Ziller",
      "Marcus R. Makowski",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  }
]