[
  {
    "id": "arXiv:2505.00707",
    "title": "A high-order combined interpolation/finite element technique for evolutionary coupled groundwater-surface water problem",
    "abstract": "           A high-order combined interpolation/finite element technique is developed for solving the coupled groundwater-surface water system that governs flows in karst aquifers. In the proposed high-order scheme we approximate the time derivative with piecewise polynomial interpolation of second-order and use the finite element discretization of piecewise polynomials of degree $d$ and $d+1$, where $d \\geq 2$ is an integer, to approximate the space derivatives. The stability together with the error estimates of the constructed technique are established in $L^{\\infty}(0,T;\\text{\\,}L^{2})$-norm. The analysis suggests that the developed computational technique is unconditionally stable, temporal second-order accurate and convergence in space of order $d+1$. Furthermore, the new approach is faster and more efficient than a broad range of numerical methods discussed in the literature for the given initial-boundary value problem. Some examples are carried out to confirm the theoretical results.         ",
    "url": "https://arxiv.org/abs/2505.00707",
    "authors": [
      "Eric Ngondiep",
      "Areej A. Binsultant",
      "Ibtisam M. Aldawish"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2505.00741",
    "title": "Detection and Classification of Diseases in Multi-Crop Leaves using LSTM and CNN Models",
    "abstract": "           Plant diseases pose a serious challenge to agriculture by reducing crop yield and affecting food quality. Early detection and classification of these diseases are essential for minimising losses and improving crop management practices. This study applies Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) models to classify plant leaf diseases using a dataset containing 70,295 training images and 17,572 validation images across 38 disease classes. The CNN model was trained using the Adam optimiser with a learning rate of 0.0001 and categorical cross-entropy as the loss function. After 10 training epochs, the model achieved a training accuracy of 99.1% and a validation accuracy of 96.4%. The LSTM model reached a validation accuracy of 93.43%. Performance was evaluated using precision, recall, F1-score, and confusion matrix, confirming the reliability of the CNN-based approach. The results suggest that deep learning models, particularly CNN, enable an effective solution for accurate and scalable plant disease classification, supporting practical applications in agricultural monitoring.         ",
    "url": "https://arxiv.org/abs/2505.00741",
    "authors": [
      "Srinivas Kanakala",
      "Sneha Ningappa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2505.00743",
    "title": "DOPE: Dual Object Perception-Enhancement Network for Vision-and-Language Navigation",
    "abstract": "           Vision-and-Language Navigation (VLN) is a challenging task where an agent must understand language instructions and navigate unfamiliar environments using visual cues. The agent must accurately locate the target based on visual information from the environment and complete tasks through interaction with the surroundings. Despite significant advancements in this field, two major limitations persist: (1) Many existing methods input complete language instructions directly into multi-layer Transformer networks without fully exploiting the detailed information within the instructions, thereby limiting the agent's language understanding capabilities during task execution; (2) Current approaches often overlook the modeling of object relationships across different modalities, failing to effectively utilize latent clues between objects, which affects the accuracy and robustness of navigation decisions. We propose a Dual Object Perception-Enhancement Network (DOPE) to address these issues to improve navigation performance. First, we design a Text Semantic Extraction (TSE) to extract relatively essential phrases from the text and input them into the Text Object Perception-Augmentation (TOPA) to fully leverage details such as objects and actions within the instructions. Second, we introduce an Image Object Perception-Augmentation (IOPA), which performs additional modeling of object information across different modalities, enabling the model to more effectively utilize latent clues between objects in images and text, enhancing decision-making accuracy. Extensive experiments on the R2R and REVERIE datasets validate the efficacy of the proposed approach.         ",
    "url": "https://arxiv.org/abs/2505.00743",
    "authors": [
      "Yinfeng Yu",
      "Dongsheng Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2505.00752",
    "title": "DARTer: Dynamic Adaptive Representation Tracker for Nighttime UAV Tracking",
    "abstract": "           Nighttime UAV tracking presents significant challenges due to extreme illumination variations and viewpoint changes, which severely degrade tracking performance. Existing approaches either rely on light enhancers with high computational costs or introduce redundant domain adaptation mechanisms, failing to fully utilize the dynamic features in varying perspectives. To address these issues, we propose \\textbf{DARTer} (\\textbf{D}ynamic \\textbf{A}daptive \\textbf{R}epresentation \\textbf{T}racker), an end-to-end tracking framework designed for nighttime UAV scenarios. DARTer leverages a Dynamic Feature Blender (DFB) to effectively fuse multi-perspective nighttime features from static and dynamic templates, enhancing representation robustness. Meanwhile, a Dynamic Feature Activator (DFA) adaptively activates Vision Transformer layers based on extracted features, significantly improving efficiency by reducing redundant computations. Our model eliminates the need for complex multi-task loss functions, enabling a streamlined training process. Extensive experiments on multiple nighttime UAV tracking benchmarks demonstrate the superiority of DARTer over state-of-the-art trackers. These results confirm that DARTer effectively balances tracking accuracy and efficiency, making it a promising solution for real-world nighttime UAV tracking applications.         ",
    "url": "https://arxiv.org/abs/2505.00752",
    "authors": [
      "Xuzhao Li",
      "Xuchen Li",
      "Shiyu Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2505.00757",
    "title": "Efficient On-Chip Implementation of 4D Radar-Based 3D Object Detection on Hailo-8L",
    "abstract": "           4D radar has attracted attention in autonomous driving due to its ability to enable robust 3D object detection even under adverse weather conditions. To practically deploy such technologies, it is essential to achieve real-time processing within low-power embedded environments. Addressing this, we present the first on-chip implementation of a 4D radar-based 3D object detection model on the Hailo-8L AI accelerator. Although conventional 3D convolutional neural network (CNN) architectures require 5D inputs, the Hailo-8L only supports 4D tensors, posing a significant challenge. To overcome this limitation, we introduce a tensor transformation method that reshapes 5D inputs into 4D formats during the compilation process, enabling direct deployment without altering the model structure. The proposed system achieves 46.47% AP_3D and 52.75% AP_BEV, maintaining comparable accuracy to GPU-based models while achieving an inference speed of 13.76 Hz. These results demonstrate the applicability of 4D radar-based perception technologies to autonomous driving systems.         ",
    "url": "https://arxiv.org/abs/2505.00757",
    "authors": [
      "Woong-Chan Byun",
      "Dong-Hee Paek",
      "Seung-Hyun Song",
      "Seung-Hyun Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2505.00772",
    "title": "Person detection and re-identification in open-world settings of retail stores and public spaces",
    "abstract": "           Practical applications of computer vision in smart cities usually assume system integration and operation in challenging open-world environments. In the case of person re-identification task the main goal is to retrieve information whether the specific person has appeared in another place at a different time instance of the same video, or over multiple camera feeds. This typically assumes collecting raw data from video surveillance cameras in different places and under varying illumination conditions. In the considered open-world setting it also requires detection and localization of the person inside the analyzed video frame before the main re-identification step. With multi-person and multi-camera setups the system complexity becomes higher, requiring sophisticated tracking solutions and re-identification models. In this work we will discuss existing challenges in system design architectures, consider possible solutions based on different computer vision techniques, and describe applications of such systems in retail stores and public spaces for improved marketing analytics. In order to analyse sensitivity of person re-identification task under different open-world environments, a performance of one close to real-time solution will be demonstrated over several video captures and live camera feeds. Finally, based on conducted experiments we will indicate further research directions and possible system improvements.         ",
    "url": "https://arxiv.org/abs/2505.00772",
    "authors": [
      "Branko Brklja\u010d",
      "Milan Brklja\u010d"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2505.00792",
    "title": "Improving Routing in Sparse Mixture of Experts with Graph of Tokens",
    "abstract": "           Sparse Mixture of Experts (SMoE) has emerged as a key to achieving unprecedented scalability in deep learning. By activating only a small subset of parameters per sample, SMoE achieves an exponential increase in parameter counts while maintaining a constant computational overhead. However, SMoE models are susceptible to routing fluctuations--changes in the routing of a given input to its target expert--at the late stage of model training, leading to model non-robustness. In this work, we unveil the limitation of SMoE through the perspective of the probabilistic graphical model (PGM). Through this PGM framework, we highlight the independence in the expert-selection of tokens, which exposes the model to routing fluctuation and non-robustness. Alleviating this independence, we propose the novel Similarity-Aware (S)MoE, which considers interactions between tokens during expert selection. We then derive a new PGM underlying an (S)MoE-Attention block, going beyond just a single (S)MoE layer. Leveraging the token similarities captured by the attention matrix, we propose the innovative Attention-Aware (S)MoE, which employs the attention matrix to guide the routing of tokens to appropriate experts in (S)MoE. We theoretically prove that Similarity/Attention-Aware routing help reduce the entropy of expert selection, resulting in more stable token routing mechanisms. We empirically validate our models on various tasks and domains, showing significant improvements in reducing routing fluctuations, enhancing accuracy, and increasing model robustness over the baseline MoE-Transformer with token routing via softmax gating.         ",
    "url": "https://arxiv.org/abs/2505.00792",
    "authors": [
      "Tam Nguyen",
      "Ngoc N. Tran",
      "Khai Nguyen",
      "Richard G. Baraniuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2505.00804",
    "title": "Improved Approximation of Sensor Network Performance for Seabed Acoustic Sensors",
    "abstract": "           Sensor locations to detect Poisson-distributed targets, such as seabed sensors that detect shipping traffic, can be selected to maximize the so-called void probability, which is the probability of detecting all targets. Because evaluation of void probability is computationally expensive, we propose a new approximation of void probability that can greatly reduce the computational cost of selecting locations for a network of sensors. We build upon prior work that approximates void probability using Jensen's inequality. Our new approach better accommodates uncertainty in the (Poisson) target model and yields a sharper error bound. The proposed method is evaluated using historical ship traffic data from the Hampton Roads Channel, Virginia, demonstrating a reduction in the approximation error compared to the previous approach. The results validate the effectiveness of the improved approximation for maritime surveillance applications.         ",
    "url": "https://arxiv.org/abs/2505.00804",
    "authors": [
      "Mingyu Kim",
      "Daniel J. Stilwell",
      "Harun Yetkin",
      "Jorge Jimenez"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2505.00810",
    "title": "Scalable Unit Harmonization in Medical Informatics Using Bi-directional Transformers and Bayesian-Optimized BM25 and Sentence Embedding Retrieval",
    "abstract": "           Objective: To develop and evaluate a scalable methodology for harmonizing inconsistent units in large-scale clinical datasets, addressing a key barrier to data interoperability. Materials and Methods: We designed a novel unit harmonization system combining BM25, sentence embeddings, Bayesian optimization, and a bidirectional transformer based binary classifier for retrieving and matching laboratory test entries. The system was evaluated using the Optum Clinformatics Datamart dataset (7.5 billion entries). We implemented a multi-stage pipeline: filtering, identification, harmonization proposal generation, automated re-ranking, and manual validation. Performance was assessed using Mean Reciprocal Rank (MRR) and other standard information retrieval metrics. Results: Our hybrid retrieval approach combining BM25 and sentence embeddings (MRR: 0.8833) significantly outperformed both lexical-only (MRR: 0.7985) and embedding-only (MRR: 0.5277) approaches. The transformer-based reranker further improved performance (absolute MRR improvement: 0.10), bringing the final system MRR to 0.9833. The system achieved 83.39\\% precision at rank 1 and 94.66\\% recall at rank 5. Discussion: The hybrid architecture effectively leverages the complementary strengths of lexical and semantic approaches. The reranker addresses cases where initial retrieval components make errors due to complex semantic relationships in medical terminology. Conclusion: Our framework provides an efficient, scalable solution for unit harmonization in clinical datasets, reducing manual effort while improving accuracy. Once harmonized, data can be reused seamlessly in different analyses, ensuring consistency across healthcare systems and enabling more reliable multi-institutional studies and meta-analyses.         ",
    "url": "https://arxiv.org/abs/2505.00810",
    "authors": [
      "Jordi de la Torre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2505.00823",
    "title": "Data-Driven Optical To Thermal Inference in Pool Boiling Using Generative Adversarial Networks",
    "abstract": "           Phase change plays a critical role in thermal management systems, yet quantitative characterization of multiphase heat transfer remains limited by the challenges of measuring temperature fields in chaotic, rapidly evolving flow regimes. While computational methods offer spatiotemporal resolution in idealized cases, replicating complex experimental conditions remains prohibitively difficult. Here, we present a data-driven framework that leverages a conditional generative adversarial network (CGAN) to infer temperature fields from geometric phase contours in a canonical pool boiling configuration where advanced data collection techniques are restricted. Using high-speed imaging data and simulation-informed training, our model demonstrates the ability to reconstruct temperature fields with errors below 6%. We further show that standard data augmentation strategies are effective in enhancing both accuracy and physical plausibility of the predicted maps across both simulation and experimental datasets when precise physical constraints are not applicable. Our results highlight the potential of deep generative models to bridge the gap between observable multiphase phenomena and underlying thermal transport, offering a powerful approach to augment and interpret experimental measurements in complex two-phase systems.         ",
    "url": "https://arxiv.org/abs/2505.00823",
    "authors": [
      "Qianxi Fu",
      "Youngjoon Suh",
      "Xiaojing Zhang",
      "Yoonjin Won"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)"
    ]
  },
  {
    "id": "arXiv:2505.00827",
    "title": "MIMIC-\\RNum{4}-Ext-22MCTS: A 22 Millions-Event Temporal Clinical Time-Series Dataset with Relative Timestamp for Risk Prediction",
    "abstract": "           Clinical risk prediction based on machine learning algorithms plays a vital role in modern healthcare. A crucial component in developing a reliable prediction model is collecting high-quality time series clinical events. In this work, we release such a dataset that consists of 22,588,586 Clinical Time Series events, which we term MIMIC-\\RNum{4}-Ext-22MCTS. Our source data are discharge summaries selected from the well-known yet unstructured MIMIC-IV-Note \\cite{Johnson2023-pg}. We then extract clinical events as short text span from the discharge summaries, along with the timestamps of these events as temporal information. The general-purpose MIMIC-IV-Note pose specific challenges for our work: it turns out that the discharge summaries are too lengthy for typical natural language models to process, and the clinical events of interest often are not accompanied with explicit timestamps. Therefore, we propose a new framework that works as follows: 1) we break each discharge summary into manageably small text chunks; 2) we apply contextual BM25 and contextual semantic search to retrieve chunks that have a high potential of containing clinical events; and 3) we carefully design prompts to teach the recently released Llama-3.1-8B \\cite{touvron2023llama} model to identify or infer temporal information of the chunks. We show that the obtained dataset is so informative and transparent that standard models fine-tuned on our dataset are achieving significant improvements in healthcare applications. In particular, the BERT model fine-tuned based on our dataset achieves 10\\% improvement in accuracy on medical question answering task, and 3\\% improvement in clinical trial matching task compared with the classic BERT. The GPT-2 model, fine-tuned on our dataset, produces more clinically reliable results for clinical questions.         ",
    "url": "https://arxiv.org/abs/2505.00827",
    "authors": [
      "Jing Wang",
      "Xing Niu",
      "Juyong Kim",
      "Jie Shen",
      "Tong Zhang",
      "Jeremy C. Weiss"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2505.00881",
    "title": "Protocol-agnostic and Data-free Backdoor Attacks on Pre-trained Models in RF Fingerprinting",
    "abstract": "           While supervised deep neural networks (DNNs) have proven effective for device authentication via radio frequency (RF) fingerprinting, they are hindered by domain shift issues and the scarcity of labeled data. The success of large language models has led to increased interest in unsupervised pre-trained models (PTMs), which offer better generalization and do not require labeled datasets, potentially addressing the issues mentioned above. However, the inherent vulnerabilities of PTMs in RF fingerprinting remain insufficiently explored. In this paper, we thoroughly investigate data-free backdoor attacks on such PTMs in RF fingerprinting, focusing on a practical scenario where attackers lack access to downstream data, label information, and training processes. To realize the backdoor attack, we carefully design a set of triggers and predefined output representations (PORs) for the PTMs. By mapping triggers and PORs through backdoor training, we can implant backdoor behaviors into the PTMs, thereby introducing vulnerabilities across different downstream RF fingerprinting tasks without requiring prior knowledge. Extensive experiments demonstrate the wide applicability of our proposed attack to various input domains, protocols, and PTMs. Furthermore, we explore potential detection and defense methods, demonstrating the difficulty of fully safeguarding against our proposed backdoor attack.         ",
    "url": "https://arxiv.org/abs/2505.00881",
    "authors": [
      "Tianya Zhao",
      "Ningning Wang",
      "Junqing Zhang",
      "Xuyu Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2505.00901",
    "title": "Heterogeneous Memory Benchmarking Toolkit",
    "abstract": "           This paper presents an open-source kernel-level heterogeneous memory characterization framework (MemScope) for embedded systems that enables users to understand and precisely characterize the temporal behavior of all available memory modules under configurable contention stress scenarios. Since kernel-level provides a high degree of control over allocation, cache maintenance, $CPUs$, interrupts, and I/O device activity, seeking the most accurate way to benchmark heterogeneous memory subsystems, would be achieved by implementing it in the kernel. This gives us the privilege to directly map pieces of contiguous physical memory and instantiate allocators, allowing us to finely control cores to create and eliminate interference. Additionally, we can minimize noise and interruptions, guaranteeing more consistent and precise results compared to equivalent user-space solutions. Running our Framework on a Xilinx Zynq UltraScale+ ZCU102 CPU_FPGA platform, demonstrates its capability to precisely benchmark bandwidth and latency across various memory types, including PL-side DRAM and BRAM, in a multi-core system.         ",
    "url": "https://arxiv.org/abs/2505.00901",
    "authors": [
      "Golsana Ghaemi",
      "Kazem Taram",
      "Renato Mancuso"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2505.00904",
    "title": "Neural Networks Enabled Discovery On the Higher-Order Nonlinear Partial Differential Equation of Traffic Dynamics",
    "abstract": "           Modeling the traffic dynamics is essential for understanding and predicting the traffic spatiotemporal evolution. However, deriving the partial differential equation (PDE) models that capture these dynamics is challenging due to their potential high order property and nonlinearity. In this paper, we introduce a novel deep learning framework, \"TRAFFIC-PDE-LEARN\", designed to discover hidden PDE models of traffic network dynamics directly from measurement data. By harnessing the power of the neural network to approximate a spatiotemporal fundamental diagram that facilitates smooth estimation of partial derivatives with low-resolution loop detector data. Furthermore, the use of automatic differentiation enables efficient computation of the necessary partial derivatives through the chain and product rules, while sparse regression techniques facilitate the precise identification of physically interpretable PDE components. Tested on data from a real-world traffic network, our model demonstrates that the underlying PDEs governing traffic dynamics are both high-order and nonlinear. By leveraging the learned dynamics for prediction purposes, the results underscore the effectiveness of our approach and its potential to advance intelligent transportation systems.         ",
    "url": "https://arxiv.org/abs/2505.00904",
    "authors": [
      "Zihang Wei",
      "Yunlong Zhang",
      "Chenxi Liu",
      "Yang Zhou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2505.00907",
    "title": "Co-Designing a Knowledge Graph Navigation Interface: A Participatory Approach",
    "abstract": "           Navigating and visualizing multilayered knowledge graphs remains a challenging, unresolved problem in information systems design. Building on our earlier study, which engaged end users in both the design and population of a domain-specific knowledge graph, we now focus on translating their insights into actionable interface guidelines. In this paper, we synthesize recommendations drawn from a participatory workshop with doctoral students. We then demonstrate how these recommendations inform the design of a prototype interface. Finally, we found that a participatory iterative design approach can help designers in decision making, leading to interfaces that are both innovative and user-centric. By combining user-driven requirements with proven visualization techniques, this paper presents a coherent framework for guiding future development of knowledge-graph navigation tools.         ",
    "url": "https://arxiv.org/abs/2505.00907",
    "authors": [
      "Stanislava Gardasevic",
      "Manika Lamba",
      "Jasmine S. Malone"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2505.00908",
    "title": "Learning Neural Control Barrier Functions from Offline Data with Conservatism",
    "abstract": "           Safety filters, particularly those based on control barrier functions, have gained increased interest as effective tools for safe control of dynamical systems. Existing correct-by-construction synthesis algorithms, however, suffer from the curse of dimensionality. Deep learning approaches have been proposed in recent years to address this challenge. In this paper, we contribute to this line of work by proposing an algorithm for training control barrier functions from offline datasets. Our algorithm trains the filter to not only prevent the system from reaching unsafe states but also out-of-distribution ones, at which the filter would be unreliable. It is inspired by Conservative Q-learning, an offline reinforcement learning algorithm. We call its outputs Conservative Control Barrier Functions (CCBFs). Our empirical results demonstrate that CCBFs outperform existing methods in maintaining safety and out-of-distribution avoidance while minimally affecting task performance.         ",
    "url": "https://arxiv.org/abs/2505.00908",
    "authors": [
      "Ihab Tabbara",
      "Hussein Sibai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2505.00912",
    "title": "Towards a format for describing networks / 1. Networks and knowledge graphs",
    "abstract": "           The relationship between the concepts of network and knowledge graph is explored. A knowledge graph can be considered a special type of network. When using a knowledge graph, various networks can be obtained from it, and network analysis procedures can be applied to them. RDF is a formalization of the knowledge graph concept for the Semantic Web, but some of its solutions are also extensible to a format for describing general networks.         ",
    "url": "https://arxiv.org/abs/2505.00912",
    "authors": [
      "Vladimir Batagelj",
      "Toma\u017e Pisanski",
      "Iztok Savnik",
      "Ana Slavec",
      "Nino Ba\u0161i\u0107"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2505.00918",
    "title": "Dynamic and Distributed Routing in IoT Networks based on Multi-Objective Q-Learning",
    "abstract": "           The last few decades have witnessed a rapid increase in IoT devices owing to their wide range of applications, such as smart healthcare monitoring systems, smart cities, and environmental monitoring. A critical task in IoT networks is sensing and transmitting information over the network. The IoT nodes gather data by sensing the environment and then transmit this data to a destination node via multi-hop communication, following some routing protocols. These protocols are usually designed to optimize possibly contradictory objectives, such as maximizing packet delivery ratio and energy efficiency. While most literature has focused on optimizing a static objective that remains unchanged, many real-world IoT applications require adapting to rapidly shifting priorities. For example, in monitoring systems, some transmissions are time-critical and require a high priority on low latency, while other transmissions are less urgent and instead prioritize energy efficiency. To meet such dynamic demands, we propose novel dynamic and distributed routing based on multiobjective Q-learning that can adapt to changes in preferences in real-time. Our algorithm builds on ideas from both multi-objective optimization and Q-learning. We also propose a novel greedy interpolation policy scheme to take near-optimal decisions for unexpected preference changes. The proposed scheme can approximate and utilize the Pareto-efficient solutions for dynamic preferences, thus utilizing past knowledge to adapt to unpredictable preferences quickly during runtime. Simulation results show that the proposed scheme outperforms state-of-the-art algorithms for various exploration strategies, preference variation patterns, and important metrics like overall reward, energy efficiency, and packet delivery ratio.         ",
    "url": "https://arxiv.org/abs/2505.00918",
    "authors": [
      "Shubham Vaishnav",
      "Praveen Kumar Donta",
      "Sindri Magn\u00fasson"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2505.00921",
    "title": "Towards a format for describing networks / 2. Format elements",
    "abstract": "           The key elements that a common format for describing networks should include are discussed.         ",
    "url": "https://arxiv.org/abs/2505.00921",
    "authors": [
      "Vladimir Batagelj",
      "Toma\u017e Pisanski",
      "Iztok Savnik",
      "Ana Slavec",
      "Nino Ba\u0161i\u0107"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2505.00922",
    "title": "Cluster deletion and clique partitioning in graphs with bounded clique number",
    "abstract": "           The Cluster Deletion problem takes a graph $G$ as input and asks for a minimum size set of edges $X$ such that $G-X$ is the disjoint union of complete graphs. An equivalent formulation is the Clique Partition problem, which asks to find a partition of $V(G)$ into cliques such that the total number of edges is maximized. We begin by giving a much simpler proof of a theorem of Gao, Hare, and Nastos that Cluster Deletion is efficiently solvable on the class of cographs. We then investigate Cluster Deletion and Clique Partition on permutation graphs, which are a superclass of cographs. Our findings suggest that Cluster Deletion may be NP-hard on permutation graphs. Finally, we prove that for graphs with clique number at most $c$, there is a $\\frac{2\\binom{c}{2}}{\\binom{c}{2}+1}$-approximation algorithm for Clique Partition. This is the first polynomial time algorithm which achieves an approximation ratio better than 2 for graphs with bounded clique number. More generally, our algorithm runs in polynomial time on any graph class for which Maximum Clique can be computed in polynomial time. We also provide a class of examples which shows that our approximation ratio is best possible.         ",
    "url": "https://arxiv.org/abs/2505.00922",
    "authors": [
      "Nicola Galesi",
      "Tony Huynh",
      "Fariba Ranjbar"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2505.00924",
    "title": "MARS: Defending Unmanned Aerial Vehicles From Attacks on Inertial Sensors with Model-based Anomaly Detection and Recovery",
    "abstract": "           Unmanned Aerial Vehicles (UAVs) rely on measurements from Inertial Measurement Units (IMUs) to maintain stable flight. However, IMUs are susceptible to physical attacks, including acoustic resonant and electromagnetic interference attacks, resulting in immediate UAV crashes. Consequently, we introduce a Model-based Anomaly detection and Recovery System (MARS) that enables UAVs to quickly detect adversarial attacks on inertial sensors and achieve dynamic flight recovery. MARS features an attack-resilient state estimator based on the Extended Kalman Filter, which incorporates position, velocity, heading, and rotor speed measurements to reconstruct accurate attitude and angular velocity information for UAV control. Moreover, a statistical anomaly detection system monitors IMU sensor data, raising a system-level alert if an attack is detected. Upon receiving the alert, a multi-stage dynamic flight recovery strategy suspends the ongoing mission, stabilizes the drone in a hovering condition, and then resumes tasks under the resilient control. Experimental results in PX4 software-in-the-loop environments as well as real-world MARS-PX4 autopilot-equipped drones demonstrate the superiority of our approach over existing IMU-defense frameworks, showcasing the ability of the UAVs to survive attacks and complete the missions.         ",
    "url": "https://arxiv.org/abs/2505.00924",
    "authors": [
      "Haocheng Meng",
      "Shaocheng Luo",
      "Zhenyuan Liang",
      "Qing Huang",
      "Amir Khazraei",
      "Miroslav Pajic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2505.00928",
    "title": "Virtual Force-Based Routing of Modular Agents on a Graph",
    "abstract": "           Modular vehicles have become an area of academic interest in the field of multi-agent systems. Modularity allows vehicles to connect and disconnect with each other mid-transit which provides a balance between efficiency and flexibility when solving complex and large scale tasks in urban or aerial transportation. This paper details a generalized scheme to route multiple modular agents on a graph to a predetermined set of target nodes. The objective is to visit all target nodes while incurring minimum resource expenditure. Agents that are joined together will incur the equivalent cost of a single agent, which is motivated by the logistical benefits of traffic reduction and increased fuel efficiency. To solve this problem, we introduce a heuristic algorithm that seeks to balance the optimality of the path that an agent takes and the cost benefit of joining agents. Our approach models the agents and targets as point charges, where the agents take the path of highest attractive force from its target node and neighboring agents. We validate our approach by simulating multiple modular agents along real-world transportation routes in the road network of Champaign-Urbana, Illinois, USA. For two vehicles, it performed equally compared to an existing modular-agent routing algorithm. Three agents were then routed using our method and the performance was benchmarked against non-modular agents using a simple shortest path policy where it performs better than the non-modular implementation 81 percent of the time. Moreover, we show that the proposed algorithm operates faster than existing routing methods for modular agents.         ",
    "url": "https://arxiv.org/abs/2505.00928",
    "authors": [
      "Adam Casselman",
      "Manav Vora",
      "Melkior Ornik"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2505.00930",
    "title": "Robust Root Cause Diagnosis using In-Distribution Interventions",
    "abstract": "           Diagnosing the root cause of an anomaly in a complex interconnected system is a pressing problem in today's cloud services and industrial operations. We propose In-Distribution Interventions (IDI), a novel algorithm that predicts root cause as nodes that meet two criteria: 1) **Anomaly:** root cause nodes should take on anomalous values; 2) **Fix:** had the root cause nodes assumed usual values, the target node would not have been anomalous. Prior methods of assessing the fix condition rely on counterfactuals inferred from a Structural Causal Model (SCM) trained on historical data. But since anomalies are rare and fall outside the training distribution, the fitted SCMs yield unreliable counterfactual estimates. IDI overcomes this by relying on interventional estimates obtained by solely probing the fitted SCM at in-distribution inputs. We present a theoretical analysis comparing and bounding the errors in assessing the fix condition using interventional and counterfactual estimates. We then conduct experiments by systematically varying the SCM's complexity to demonstrate the cases where IDI's interventional approach outperforms the counterfactual approach and vice versa. Experiments on both synthetic and PetShop RCD benchmark datasets demonstrate that \\our\\ consistently identifies true root causes more accurately and robustly than nine existing state-of-the-art RCD baselines. Code is released at this https URL.         ",
    "url": "https://arxiv.org/abs/2505.00930",
    "authors": [
      "Lokesh Nagalapatti",
      "Ashutosh Srivastava",
      "Sunita Sarawagi",
      "Amit Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2505.00932",
    "title": "A Self-Supervised Transformer for Unusable Shared Bike Detection",
    "abstract": "           The rapid expansion of bike-sharing systems (BSS) has greatly improved urban \"last-mile\" connectivity, yet large-scale deployments face escalating operational challenges, particularly in detecting faulty bikes. Existing detection approaches either rely on static model-based thresholds that overlook dynamic spatiotemporal (ST) usage patterns or employ supervised learning methods that struggle with label scarcity and class imbalance. To address these limitations, this paper proposes a novel Self-Supervised Transformer (SSTransformer) framework for automatically detecting unusable shared bikes, leveraging ST features extracted from GPS trajectories and trip records. The model incorporates a self-supervised pre-training strategy to enhance its feature extraction capabilities, followed by fine-tuning for efficient status recognition. In the pre-training phase, the Transformer encoder learns generalized representations of bike movement via a self-supervised objective; in the fine-tuning phase, the encoder is adapted to a downstream binary classification task. Comprehensive experiments on a real-world dataset of 10,730 bikes (1,870 unusable, 8,860 normal) from Chengdu, China, demonstrate that SSTransformer significantly outperforms traditional machine learning, ensemble learning, and deep learning baselines, achieving the best accuracy (97.81%), precision (0.8889), and F1-score (0.9358). This work highlights the effectiveness of self-supervised Transformer on ST data for capturing complex anomalies in BSS, paving the way toward more reliable and scalable maintenance solutions for shared mobility.         ",
    "url": "https://arxiv.org/abs/2505.00932",
    "authors": [
      "Yin Huang",
      "Yongqi Dong",
      "Youhua Tang",
      "Alvaro Garc\u00eda Hernandez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2505.00933",
    "title": "TunnElQNN: A Hybrid Quantum-classical Neural Network for Efficient Learning",
    "abstract": "           Hybrid quantum-classical neural networks (HQCNNs) represent a promising frontier in machine learning, leveraging the complementary strengths of both models. In this work, we propose the development of TunnElQNN, a non-sequential architecture composed of alternating classical and quantum layers. Within the classical component, we employ the Tunnelling Diode Activation Function (TDAF), inspired by the I-V characteristics of quantum tunnelling. We evaluate the performance of this hybrid model on a synthetic dataset of interleaving half-circle for multi-class classification tasks with varying degrees of class overlap. The model is compared against a baseline hybrid architecture that uses the conventional ReLU activation function (ReLUQNN). Our results show that the TunnElQNN model consistently outperforms the ReLUQNN counterpart. Furthermore, we analyse the decision boundaries generated by TunnElQNN under different levels of class overlap and compare them to those produced by a neural network implementing TDAF within a fully classical architecture. These findings highlight the potential of integrating physics-inspired activation functions with quantum components to enhance the expressiveness and robustness of hybrid quantum-classical machine learning architectures.         ",
    "url": "https://arxiv.org/abs/2505.00933",
    "authors": [
      "A. H. Abbas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2505.00938",
    "title": "CDFormer: Cross-Domain Few-Shot Object Detection Transformer Against Feature Confusion",
    "abstract": "           Cross-domain few-shot object detection (CD-FSOD) aims to detect novel objects across different domains with limited class instances. Feature confusion, including object-background confusion and object-object confusion, presents significant challenges in both cross-domain and few-shot settings. In this work, we introduce CDFormer, a cross-domain few-shot object detection transformer against feature confusion, to address these challenges. The method specifically tackles feature confusion through two key modules: object-background distinguishing (OBD) and object-object distinguishing (OOD). The OBD module leverages a learnable background token to differentiate between objects and background, while the OOD module enhances the distinction between objects of different classes. Experimental results demonstrate that CDFormer outperforms previous state-of-the-art approaches, achieving 12.9% mAP, 11.0% mAP, and 10.4% mAP improvements under the 1/5/10 shot settings, respectively, when fine-tuned.         ",
    "url": "https://arxiv.org/abs/2505.00938",
    "authors": [
      "Boyuan Meng",
      "Xiaohan Zhang",
      "Peilin Li",
      "Zhe Wu",
      "Yiming Li",
      "Wenkai Zhao",
      "Beinan Yu",
      "Hui-Liang Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2505.00941",
    "title": "FreCT: Frequency-augmented Convolutional Transformer for Robust Time Series Anomaly Detection",
    "abstract": "           Time series anomaly detection is critical for system monitoring and risk identification, across various domains, such as finance and healthcare. However, for most reconstruction-based approaches, detecting anomalies remains a challenge due to the complexity of sequential patterns in time series data. On the one hand, reconstruction-based techniques are susceptible to computational deviation stemming from anomalies, which can lead to impure representations of normal sequence patterns. On the other hand, they often focus on the time-domain dependencies of time series, while ignoring the alignment of frequency information beyond the time domain. To address these challenges, we propose a novel Frequency-augmented Convolutional Transformer (FreCT). FreCT utilizes patch operations to generate contrastive views and employs an improved Transformer architecture integrated with a convolution module to capture long-term dependencies while preserving local topology information. The introduced frequency analysis based on Fourier transformation could enhance the model's ability to capture crucial characteristics beyond the time domain. To protect the training quality from anomalies and improve the robustness, FreCT deploys stop-gradient Kullback-Leibler (KL) divergence and absolute error to optimize consistency information in both time and frequency domains. Extensive experiments on four public datasets demonstrate that FreCT outperforms existing methods in identifying anomalies.         ",
    "url": "https://arxiv.org/abs/2505.00941",
    "authors": [
      "Wenxin Zhang",
      "Ding Xu",
      "Guangzhen Yao",
      "Xiaojian Lin",
      "Renxiang Guan",
      "Chengze Du",
      "Renda Han",
      "Xi Xuan",
      "Cuicui Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2505.00946",
    "title": "Addressing Noise and Stochasticity in Fraud Detection for Service Networks",
    "abstract": "           Fraud detection is crucial in social service networks to maintain user trust and improve service network security. Existing spectral graph-based methods address this challenge by leveraging different graph filters to capture signals with different frequencies in service networks. However, most graph filter-based methods struggle with deriving clean and discriminative graph signals. On the one hand, they overlook the noise in the information propagation process, resulting in degradation of filtering ability. On the other hand, they fail to discriminate the frequency-specific characteristics of graph signals, leading to distortion of signals fusion. To address these issues, we develop a novel spectral graph network based on information bottleneck theory (SGNN-IB) for fraud detection in service networks. SGNN-IB splits the original graph into homophilic and heterophilic subgraphs to better capture the signals at different frequencies. For the first limitation, SGNN-IB applies information bottleneck theory to extract key characteristics of encoded representations. For the second limitation, SGNN-IB introduces prototype learning to implement signal fusion, preserving the frequency-specific characteristics of signals. Extensive experiments on three real-world datasets demonstrate that SGNN-IB outperforms state-of-the-art fraud detection methods.         ",
    "url": "https://arxiv.org/abs/2505.00946",
    "authors": [
      "Wenxin Zhang",
      "Ding Xu",
      "Xi Xuan",
      "Lei Jiang",
      "Guangzhen Yao",
      "Renda Han",
      "Xiangxiang Lang",
      "Cuicui Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2505.00951",
    "title": "Preserving Privacy and Utility in LLM-Based Product Recommendations",
    "abstract": "           Large Language Model (LLM)-based recommendation systems leverage powerful language models to generate personalized suggestions by processing user interactions and preferences. Unlike traditional recommendation systems that rely on structured data and collaborative filtering, LLM-based models process textual and contextual information, often using cloud-based infrastructure. This raises privacy concerns, as user data is transmitted to remote servers, increasing the risk of exposure and reducing control over personal information. To address this, we propose a hybrid privacy-preserving recommendation framework which separates sensitive from nonsensitive data and only shares the latter with the cloud to harness LLM-powered recommendations. To restore lost recommendations related to obfuscated sensitive data, we design a de-obfuscation module that reconstructs sensitive recommendations locally. Experiments on real-world e-commerce datasets show that our framework achieves almost the same recommendation utility with a system which shares all data with an LLM, while preserving privacy to a large extend. Compared to obfuscation-only techniques, our approach improves HR@10 scores and category distribution alignment, offering a better balance between privacy and recommendation quality. Furthermore, our method runs efficiently on consumer-grade hardware, making privacy-aware LLM-based recommendation systems practical for real-world use.         ",
    "url": "https://arxiv.org/abs/2505.00951",
    "authors": [
      "Tina Khezresmaeilzadeh",
      "Jiang Zhang",
      "Dimitrios Andreadis",
      "Konstantinos Psounis"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2505.00953",
    "title": "Enhancing User Sequence Modeling through Barlow Twins-based Self-Supervised Learning",
    "abstract": "           User sequence modeling is crucial for modern large-scale recommendation systems, as it enables the extraction of informative representations of users and items from their historical interactions. These user representations are widely used for a variety of downstream tasks to enhance users' online experience. A key challenge for learning these representations is the lack of labeled training data. While self-supervised learning (SSL) methods have emerged as a promising solution for learning representations from unlabeled data, many existing approaches rely on extensive negative sampling, which can be computationally expensive and may not always be feasible in real-world scenario. In this work, we propose an adaptation of Barlow Twins, a state-of-the-art SSL methods, to user sequence modeling by incorporating suitable augmentation methods. Our approach aims to mitigate the need for large negative sample batches, enabling effective representation learning with smaller batch sizes and limited labeled data. We evaluate our method on the MovieLens-1M, MovieLens-20M, and Yelp datasets, demonstrating that our method consistently outperforms the widely-used dual encoder model across three downstream tasks, achieving an 8%-20% improvement in accuracy. Our findings underscore the effectiveness of our approach in extracting valuable sequence-level information for user modeling, particularly in scenarios where labeled data is scarce and negative examples are limited.         ",
    "url": "https://arxiv.org/abs/2505.00953",
    "authors": [
      "Yuhan Liu",
      "Lin Ning",
      "Neo Wu",
      "Karan Singhal",
      "Philip Andrew Mansfield",
      "Devora Berlowitz",
      "Sushant Prakash",
      "Bradley Green"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2505.00956",
    "title": "Audio Personas: Augmenting Social Perception via Body-Anchored Audio Cues",
    "abstract": "           We introduce Audio Personas, enabling users to \"decorate\" themselves with body-anchored sounds in audio augmented reality. Like outfits, makeup, and fragrances, audio personas offer an alternative yet dynamic channel to augment face-to-face interactions. For instance, one can set their audio persona as rain sounds to reflect a bad mood, bee sounds to establish personal boundaries, or a playful \"woosh\" sound to mimic passing by someone like a breeze. To instantiate the concept, we implemented a headphone-based prototype with multi-user tracking and audio streaming. Our formative study with designers revealed that audio personas were preferred in public and semi-public-private spaces for managing social impressions (e.g., personality) and signaling current states (e.g., emotions). Our preregistered in-lab study with 64 participants showed that audio personas influenced how participants formed impressions. Individuals with positive audio personas were rated as more socially attractive, more likable, and less threatening than those with negative audio personas.         ",
    "url": "https://arxiv.org/abs/2505.00956",
    "authors": [
      "Yujie Tao",
      "Libby Ye",
      "Jeremy N. Bailenson",
      "Sean Follmer"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2505.00958",
    "title": "Extended Persistent Homology Distinguishes Simple and Complex Contagions with High Accuracy",
    "abstract": "           The social contagion literature makes a distinction between simple (independent cascade or bond percolation processes that pass infections through edges) and complex contagions (bootstrap percolation or threshold processes that require local reinforcement to spread). However, distinguishing simple and complex contagions using observational data poses a significant challenge in practice. Estimating population-level activation functions from observed contagion dynamics is hindered by confounding factors that influence adoptions (other than neighborhood interactions), as well as heterogeneity in individual behaviors and modeling variations that make it difficult to design appropriate null models for inferring contagion types. Here, we show that a new tool from topological data analysis (TDA), called extended persistent homology (EPH), when applied to contagion processes over networks, can effectively detect simple and complex contagion processes, as well as predict their parameters. We train classification and regression models using EPH-based topological summaries computed on simulated simple and complex contagion dynamics on three real-world network datasets and obtain high predictive performance over a wide range of contagion parameters and under a variety of informational constraints, including uncertainty in model parameters, noise, and partial observability of contagion dynamics. EPH captures the role of cycles of varying lengths in the observed contagion dynamics and offers a useful metric to classify contagion models and predict their parameters. Analyzing geometrical features of network contagion using TDA tools such as EPH can find applications in other network problems such as seeding, vaccination, and quarantine optimization, as well as network inference and reconstruction problems.         ",
    "url": "https://arxiv.org/abs/2505.00958",
    "authors": [
      "Vahid Shamsaddini",
      "M. Amin Rahimian"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Algebraic Topology (math.AT)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2505.00963",
    "title": "Adaptive Branch-and-Bound Tree Exploration for Neural Network Verification",
    "abstract": "           Formal verification is a rigorous approach that can provably ensure the quality of neural networks, and to date, Branch and Bound (BaB) is the state-of-the-art that performs verification by splitting the problem as needed and applying off-the-shelf verifiers to sub-problems for improved performance. However, existing BaB may not be efficient, due to its naive way of exploring the space of sub-problems that ignores the \\emph{importance} of different sub-problems. To bridge this gap, we first introduce a notion of ``importance'' that reflects how likely a counterexample can be found with a sub-problem, and then we devise a novel verification approach, called ABONN, that explores the sub-problem space of BaB adaptively, in a Monte-Carlo tree search (MCTS) style. The exploration is guided by the ``importance'' of different sub-problems, so it favors the sub-problems that are more likely to find counterexamples. As soon as it finds a counterexample, it can immediately terminate; even though it cannot find, after visiting all the sub-problems, it can still manage to verify the problem. We evaluate ABONN with 552 verification problems from commonly-used datasets and neural network models, and compare it with the state-of-the-art verifiers as baseline approaches. Experimental evaluation shows that ABONN demonstrates speedups of up to $15.2\\times$ on MNIST and $24.7\\times$ on CIFAR-10. We further study the influences of hyperparameters to the performance of ABONN, and the effectiveness of our adaptive tree exploration.         ",
    "url": "https://arxiv.org/abs/2505.00963",
    "authors": [
      "Kota Fukuda",
      "Guanqin Zhang",
      "Zhenya Zhang",
      "Yulei Sui",
      "Jianjun Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2505.00976",
    "title": "Attack and defense techniques in large language models: A survey and new perspectives",
    "abstract": "           Large Language Models (LLMs) have become central to numerous natural language processing tasks, but their vulnerabilities present significant security and ethical challenges. This systematic survey explores the evolving landscape of attack and defense techniques in LLMs. We classify attacks into adversarial prompt attack, optimized attacks, model theft, as well as attacks on application of LLMs, detailing their mechanisms and implications. Consequently, we analyze defense strategies, including prevention-based and detection-based defense methods. Although advances have been made, challenges remain to adapt to the dynamic threat landscape, balance usability with robustness, and address resource constraints in defense implementation. We highlight open problems, including the need for adaptive scalable defenses, explainable security techniques, and standardized evaluation frameworks. This survey provides actionable insights and directions for developing secure and resilient LLMs, emphasizing the importance of interdisciplinary collaboration and ethical considerations to mitigate risks in real-world applications.         ",
    "url": "https://arxiv.org/abs/2505.00976",
    "authors": [
      "Zhiyu Liao",
      "Kang Chen",
      "Yuanguo Lin",
      "Kangkang Li",
      "Yunxuan Liu",
      "Hefeng Chen",
      "Xingwang Huang",
      "Yuanhui Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2505.00977",
    "title": "A Character-based Diffusion Embedding Algorithm for Enhancing the Generation Quality of Generative Linguistic Steganographic Texts",
    "abstract": "           Generating high-quality steganographic text is a fundamental challenge in the field of generative linguistic steganography. This challenge arises primarily from two aspects: firstly, the capabilities of existing models in text generation are limited; secondly, embedding algorithms fail to effectively mitigate the negative impacts of sensitive information's properties, such as semantic content or randomness. Specifically, to ensure that the recipient can accurately extract hidden information, embedding algorithms often have to consider selecting candidate words with relatively low probabilities. This phenomenon leads to a decrease in the number of high-probability candidate words and an increase in low-probability candidate words, thereby compromising the semantic coherence and logical fluency of the steganographic text and diminishing the overall quality of the generated steganographic material. To address this issue, this paper proposes a novel embedding algorithm, character-based diffusion embedding algorithm (CDEA). Unlike existing embedding algorithms that strive to eliminate the impact of sensitive information's properties on the generation process, CDEA leverages sensitive information's properties. It enhances the selection frequency of high-probability candidate words in the candidate pool based on general statistical properties at the character level and grouping methods based on power-law distributions, while reducing the selection frequency of low-probability candidate words in the candidate pool. Furthermore, to ensure the effective transformation of sensitive information in long sequences, we also introduce the XLNet model. Experimental results demonstrate that the combination of CDEA and XLNet significantly improves the quality of generated steganographic text, particularly in terms of perceptual-imperceptibility.         ",
    "url": "https://arxiv.org/abs/2505.00977",
    "authors": [
      "Yingquan Chen",
      "Qianmu Li",
      "Xiaocong Wu",
      "Huifeng Li",
      "Qing Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2505.00981",
    "title": "Multi-agents based User Values Mining for Recommendation",
    "abstract": "           Recommender systems have rapidly evolved and become integral to many online services. However, existing systems sometimes produce unstable and unsatisfactory recommendations that fail to align with users' fundamental and long-term preferences. This is because they primarily focus on extracting shallow and short-term interests from user behavior data, which is inherently dynamic and challenging to model. Unlike these transient interests, user values are more stable and play a crucial role in shaping user behaviors, such as purchasing items and consuming content. Incorporating user values into recommender systems can help stabilize recommendation performance and ensure results better reflect users' latent preferences. However, acquiring user values is typically difficult and costly. To address this challenge, we leverage the strong language understanding, zero-shot inference, and generalization capabilities of Large Language Models (LLMs) to extract user values from users' historical interactions. Unfortunately, direct extraction using LLMs presents several challenges such as length constraints and hallucination. To overcome these issues, we propose ZOOM, a zero-shot multi-LLM collaborative framework for effective and accurate user value extraction. In ZOOM, we apply text summarization techniques to condense item content while preserving essential meaning. To mitigate hallucinations, ZOOM introduces two specialized agent roles: evaluators and supervisors, to collaboratively generate accurate user values. Extensive experiments on two widely used recommendation datasets with two state-of-the-art recommendation models demonstrate the effectiveness and generalization of our framework in automatic user value mining and recommendation performance improvement.         ",
    "url": "https://arxiv.org/abs/2505.00981",
    "authors": [
      "Lijian Chen",
      "Wei Yuan",
      "Tong Chen",
      "Xiangyu Zhao",
      "Nguyen Quoc Viet Hung",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2505.00982",
    "title": "Accelerating Deep Neural Network Training via Distributed Hybrid Order Optimization",
    "abstract": "           Scaling deep neural network (DNN) training to more devices can reduce time-to-solution. However, it is impractical for users with limited computing resources. FOSI, as a hybrid order optimizer, converges faster than conventional optimizers by taking advantage of both gradient information and curvature information when updating the DNN model. Therefore, it provides a new chance for accelerating DNN training in the resource-constrained setting. In this paper, we explore its distributed design, namely DHO$_2$, including distributed calculation of curvature information and model update with partial curvature information to accelerate DNN training with a low memory burden. To further reduce the training time, we design a novel strategy to parallelize the calculation of curvature information and the model update on different devices. Experimentally, our distributed design can achieve an approximate linear reduction of memory burden on each device with the increase of the device number. Meanwhile, it achieves $1.4\\times\\sim2.1\\times$ speedup in the total training time compared with other distributed designs based on conventional first- and second-order optimizers.         ",
    "url": "https://arxiv.org/abs/2505.00982",
    "authors": [
      "Shunxian Gu",
      "Chaoqun You",
      "Bangbang Ren",
      "Lailong Luo",
      "Junxu Xia",
      "Deke Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2505.00983",
    "title": "Toward Data-centric Directed Graph Learning: An Entropy-driven Approach",
    "abstract": "           The directed graph (digraph), as a generalization of undirected graphs, exhibits superior representation capability in modeling complex topology systems and has garnered considerable attention in recent years. Despite the notable efforts made by existing DiGraph Neural Networks (DiGNNs) to leverage directed edges, they still fail to comprehensively delve into the abundant data knowledge concealed in the digraphs. This data-level limitation results in model-level sub-optimal predictive performance and underscores the necessity of further exploring the potential correlations between the directed edges (topology) and node profiles (feature and labels) from a data-centric perspective, thereby empowering model-centric neural networks with stronger encoding capabilities. In this paper, we propose \\textbf{E}ntropy-driven \\textbf{D}igraph knowl\\textbf{E}dge distillatio\\textbf{N} (EDEN), which can serve as a data-centric digraph learning paradigm or a model-agnostic hot-and-plug data-centric Knowledge Distillation (KD) module. The core idea is to achieve data-centric ML, guided by our proposed hierarchical encoding theory for structured data. Specifically, EDEN first utilizes directed structural measurements from a topology perspective to construct a coarse-grained Hierarchical Knowledge Tree (HKT). Subsequently, EDEN quantifies the mutual information of node profiles to refine knowledge flow in the HKT, enabling data-centric KD supervision within model training. As a general framework, EDEN can also naturally extend to undirected scenarios and demonstrate satisfactory performance. In our experiments, EDEN has been widely evaluated on 14 (di)graph datasets (homophily and heterophily) and across 4 downstream tasks. The results demonstrate that EDEN attains SOTA performance and exhibits strong improvement for prevalent (Di)GNNs.         ",
    "url": "https://arxiv.org/abs/2505.00983",
    "authors": [
      "Xunkai Li",
      "Zhengyu Wu",
      "Kaichi Yu",
      "Hongchao Qin",
      "Guang Zeng",
      "Rong-Hua Li",
      "Guoren Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2505.00990",
    "title": "Identifying Root Cause of bugs by Capturing Changed Code Lines with Relational Graph Neural Networks",
    "abstract": "           The Just-In-Time defect prediction model helps development teams improve software quality and efficiency by assessing whether code changes submitted by developers are likely to introduce defects in real-time, allowing timely identification of potential issues during the commit stage. However, two main challenges exist in current work due to the reality that all deleted and added lines in bug-fixing commits may be related to the root cause of the introduced bug: 1) lack of effective integration of heterogeneous graph information, and 2) lack of semantic relationships between changed code lines. To address these challenges, we propose a method called RC-Detection, which utilizes relational graph convolutional network to capture the semantic relationships between changed code lines. RC-Detection is used to detect root-cause deletion lines in changed code lines, thereby identifying the root cause of introduced bugs in bug-fixing commits. To evaluate the effectiveness of RC-Detection, we used three datasets that contain high-quality bug-fixing and bug-introducing commits. Extensive experiments were conducted to evaluate the performance of our model by collecting data from 87 open-source projects, including 675 bug-fix commits. The experimental results show that, compared to the most advanced root cause detection methods, RC-Detection improved Recall@1, Recall@2, Recall@3, and MFR by at 4.107%, 5.113%, 4.289%, and 24.536%, respectively.         ",
    "url": "https://arxiv.org/abs/2505.00990",
    "authors": [
      "Jiaqi Zhang",
      "Shikai Guo",
      "Hui Li",
      "Chenchen Li",
      "Yu Chai",
      "Rong Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2505.01003",
    "title": "3D Human Pose Estimation via Spatial Graph Order Attention and Temporal Body Aware Transformer",
    "abstract": "           Nowadays, Transformers and Graph Convolutional Networks (GCNs) are the prevailing techniques for 3D human pose estimation. However, Transformer-based methods either ignore the spatial neighborhood relationships between the joints when used for skeleton representations or disregard the local temporal patterns of the local joint movements in skeleton sequence modeling, while GCN-based methods often neglect the need for pose-specific representations. To address these problems, we propose a new method that exploits the graph modeling capability of GCN to represent each skeleton with multiple graphs of different orders, incorporated with a newly introduced Graph Order Attention module that dynamically emphasizes the most representative orders for each joint. The resulting spatial features of the sequence are further processed using a proposed temporal Body Aware Transformer that models the global body feature dependencies in the sequence with awareness of the local inter-skeleton feature dependencies of joints. Given that our 3D pose output aligns with the central 2D pose in the sequence, we improve the self-attention mechanism to be aware of the central pose while diminishing its focus gradually towards the first and the last poses. Extensive experiments on Human3.6m, MPIINF-3DHP, and HumanEva-I datasets demonstrate the effectiveness of the proposed method. Code and models are made available on Github.         ",
    "url": "https://arxiv.org/abs/2505.01003",
    "authors": [
      "Kamel Aouaidjia",
      "Aofan Li",
      "Wenhao Zhang",
      "Chongsheng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2505.01006",
    "title": "Token-free Models for Sarcasm Detection",
    "abstract": "           Tokenization is a foundational step in most natural language processing (NLP) pipelines, yet it introduces challenges such as vocabulary mismatch and out-of-vocabulary issues. Recent work has shown that models operating directly on raw text at the byte or character level can mitigate these limitations. In this paper, we evaluate two token-free models, ByT5 and CANINE, on the task of sarcasm detection in both social media (Twitter) and non-social media (news headlines) domains. We fine-tune and benchmark these models against token-based baselines and state-of-the-art approaches. Our results show that ByT5-small and CANINE outperform token-based counterparts and achieve new state-of-the-art performance, improving accuracy by 0.77% and 0.49% on the News Headlines and Twitter Sarcasm datasets, respectively. These findings underscore the potential of token-free models for robust NLP in noisy and informal domains such as social media.         ",
    "url": "https://arxiv.org/abs/2505.01006",
    "authors": [
      "Sumit Mamtani",
      "Maitreya Sonawane",
      "Kanika Agarwal",
      "Nishanth Sanjeev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2505.01007",
    "title": "Towards the Resistance of Neural Network Watermarking to Fine-tuning",
    "abstract": "           This paper proves a new watermarking method to embed the ownership information into a deep neural network (DNN), which is robust to fine-tuning. Specifically, we prove that when the input feature of a convolutional layer only contains low-frequency components, specific frequency components of the convolutional filter will not be changed by gradient descent during the fine-tuning process, where we propose a revised Fourier transform to extract frequency components from the convolutional filter. Additionally, we also prove that these frequency components are equivariant to weight scaling and weight permutations. In this way, we design a watermark module to encode the watermark information to specific frequency components in a convolutional filter. Preliminary experiments demonstrate the effectiveness of our method.         ",
    "url": "https://arxiv.org/abs/2505.01007",
    "authors": [
      "Ling Tang",
      "Yuefeng Chen",
      "Hui Xue",
      "Quanshi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2505.01008",
    "title": "Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content",
    "abstract": "           The recent proliferation of photorealistic images created by generative models has sparked both excitement and concern, as these images are increasingly indistinguishable from real ones to the human eye. While offering new creative and commercial possibilities, the potential for misuse, such as in misinformation and fraud, highlights the need for effective detection methods. Current detection approaches often rely on access to model weights or require extensive collections of real image datasets, limiting their scalability and practical application in real world scenarios. In this work, we introduce a novel black box detection framework that requires only API access, sidestepping the need for model weights or large auxiliary datasets. Our approach leverages a corrupt and recover strategy: by masking part of an image and assessing the model ability to reconstruct it, we measure the likelihood that the image was generated by the model itself. For black-box models that do not support masked image inputs, we incorporate a cost efficient surrogate model trained to align with the target model distribution, enhancing detection capability. Our framework demonstrates strong performance, outperforming baseline methods by 4.31% in mean average precision across eight diffusion model variant datasets.         ",
    "url": "https://arxiv.org/abs/2505.01008",
    "authors": [
      "Haoyue Bai",
      "Yiyou Sun",
      "Wei Cheng",
      "Haifeng Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2505.01022",
    "title": "Detecting the Root Cause Code Lines in Bug-Fixing Commits by Heterogeneous Graph Learning",
    "abstract": "           With the continuous growth in the scale and complexity of software systems, defect remediation has become increasingly difficult and costly. Automated defect prediction tools can proactively identify software changes prone to defects within software projects, thereby enhancing software development efficiency. However, existing work in heterogeneous and complex software projects continues to face challenges, such as struggling with heterogeneous commit structures and ignoring cross-line dependencies in code changes, which ultimately reduce the accuracy of defect identification. To address these challenges, we propose an approach called RC_Detector. RC_Detector comprises three main components: the bug-fixing graph construction component, the code semantic aggregation component, and the cross-line semantic retention component. The bug-fixing graph construction component identifies the code syntax structures and program dependencies within bug-fixing commits and transforms them into heterogeneous graph formats by converting the source code into vector representations. The code semantic aggregation component adapts to heterogeneous data by using heterogeneous attention to learn the hidden semantic representation of target code lines. The cross-line semantic retention component regulates propagated semantic information by using attenuation and reinforcement gates derived from old and new code semantic representations, effectively preserving cross-line semantic relationships. Extensive experiments were conducted to evaluate the performance of our model by collecting data from 87 open-source projects, including 675 bug-fixing commits. The experimental results demonstrate that our model outperforms state-of-the-art approaches, achieving significant improvements of 83.15%,96.83%,78.71%,74.15%,54.14%,91.66%,91.66%, and 34.82% in MFR, respectively, compared with the state-of-the-art approaches.         ",
    "url": "https://arxiv.org/abs/2505.01022",
    "authors": [
      "Liguo Ji",
      "Shikai Guo",
      "Lehuan Zhang",
      "Hui Li",
      "Yu Chai",
      "Rong Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2505.01036",
    "title": "Stagnation in Evolutionary Algorithms: Convergence $\\neq$ Optimality",
    "abstract": "           In the evolutionary computation community, it is widely believed that stagnation impedes convergence in evolutionary algorithms, and that convergence inherently indicates optimality. However, this perspective is misleading. In this study, it is the first to highlight that the stagnation of an individual can actually facilitate the convergence of the entire population, and convergence does not necessarily imply optimality, not even local optimality. Convergence alone is insufficient to ensure the effectiveness of evolutionary algorithms. Several counterexamples are provided to illustrate this argument.         ",
    "url": "https://arxiv.org/abs/2505.01036",
    "authors": [
      "Xiaojun Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2505.01040",
    "title": "Edge Detection based on Channel Attention and Inter-region Independence Test",
    "abstract": "           Existing edge detection methods often suffer from noise amplification and excessive retention of non-salient details, limiting their applicability in high-precision industrial scenarios. To address these challenges, we propose CAM-EDIT, a novel framework that integrates Channel Attention Mechanism (CAM) and Edge Detection via Independence Testing (EDIT). The CAM module adaptively enhances discriminative edge features through multi-channel fusion, while the EDIT module employs region-wise statistical independence analysis (using Fisher's exact test and chi-square test) to suppress uncorrelated this http URL experiments on BSDS500 and NYUDv2 datasets demonstrate state-of-the-art performance. Among the nine comparison algorithms, the F-measure scores of CAM-EDIT are 0.635 and 0.460, representing improvements of 19.2\\% to 26.5\\% over traditional methods (Canny, CannySR), and better than the latest learning based methods (TIP2020, MSCNGP). Noise robustness evaluations further reveal a 2.2\\% PSNR improvement under Gaussian noise compared to baseline methods. Qualitative results exhibit cleaner edge maps with reduced artifacts, demonstrating its potential for high-precision industrial applications.         ",
    "url": "https://arxiv.org/abs/2505.01040",
    "authors": [
      "Ru-yu Yan",
      "Da-Qing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2505.01050",
    "title": "Transferable Adversarial Attacks on Black-Box Vision-Language Models",
    "abstract": "           Vision Large Language Models (VLLMs) are increasingly deployed to offer advanced capabilities on inputs comprising both text and images. While prior research has shown that adversarial attacks can transfer from open-source to proprietary black-box models in text-only and vision-only contexts, the extent and effectiveness of such vulnerabilities remain underexplored for VLLMs. We present a comprehensive analysis demonstrating that targeted adversarial examples are highly transferable to widely-used proprietary VLLMs such as GPT-4o, Claude, and Gemini. We show that attackers can craft perturbations to induce specific attacker-chosen interpretations of visual information, such as misinterpreting hazardous content as safe, overlooking sensitive or restricted material, or generating detailed incorrect responses aligned with the attacker's intent. Furthermore, we discover that universal perturbations -- modifications applicable to a wide set of images -- can consistently induce these misinterpretations across multiple proprietary VLLMs. Our experimental results on object recognition, visual question answering, and image captioning show that this vulnerability is common across current state-of-the-art models, and underscore an urgent need for robust mitigations to ensure the safe and secure deployment of VLLMs.         ",
    "url": "https://arxiv.org/abs/2505.01050",
    "authors": [
      "Kai Hu",
      "Weichen Yu",
      "Li Zhang",
      "Alexander Robey",
      "Andy Zou",
      "Chengming Xu",
      "Haoqi Hu",
      "Matt Fredrikson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2505.01060",
    "title": "Monotone Peridynamic Neural Operator for Nonlinear Material Modeling with Conditionally Unique Solutions",
    "abstract": "           Data-driven methods have emerged as powerful tools for modeling the responses of complex nonlinear materials directly from experimental measurements. Among these methods, the data-driven constitutive models present advantages in physical interpretability and generalizability across different boundary conditions/domain settings. However, the well-posedness of these learned models is generally not guaranteed a priori, which makes the models prone to non-physical solutions in downstream simulation tasks. In this study, we introduce monotone peridynamic neural operator (MPNO), a novel data-driven nonlocal constitutive model learning approach based on neural operators. Our approach learns a nonlocal kernel together with a nonlinear constitutive relation, while ensuring solution uniqueness through a monotone gradient network. This architectural constraint on gradient induces convexity of the learnt energy density function, thereby guaranteeing solution uniqueness of MPNO in small deformation regimes. To validate our approach, we evaluate MPNO's performance on both synthetic and real-world datasets. On synthetic datasets with manufactured kernel and constitutive relation, we show that the learnt model converges to the ground-truth as the measurement grid size decreases both theoretically and numerically. Additionally, our MPNO exhibits superior generalization capabilities than the conventional neural networks: it yields smaller displacement solution errors in down-stream tasks with new and unseen loadings. Finally, we showcase the practical utility of our approach through applications in learning a homogenized model from molecular dynamics data, highlighting its expressivity and robustness in real-world scenarios.         ",
    "url": "https://arxiv.org/abs/2505.01060",
    "authors": [
      "Jihong Wang",
      "Xiaochuan Tian",
      "Zhongqiang Zhang",
      "Stewart Silling",
      "Siavash Jafarzadeh",
      "Yue Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2505.01067",
    "title": "A Rusty Link in the AI Supply Chain: Detecting Evil Configurations in Model Repositories",
    "abstract": "           Recent advancements in large language models (LLMs) have spurred the development of diverse AI applications from code generation and video editing to text generation; however, AI supply chains such as Hugging Face, which host pretrained models and their associated configuration files contributed by the public, face significant security challenges; in particular, configuration files originally intended to set up models by specifying parameters and initial settings can be exploited to execute unauthorized code, yet research has largely overlooked their security compared to that of the models themselves; in this work, we present the first comprehensive study of malicious configurations on Hugging Face, identifying three attack scenarios (file, website, and repository operations) that expose inherent risks; to address these threats, we introduce CONFIGSCAN, an LLM-based tool that analyzes configuration files in the context of their associated runtime code and critical libraries, effectively detecting suspicious elements with low false positive rates and high accuracy; our extensive evaluation uncovers thousands of suspicious repositories and configuration files, underscoring the urgent need for enhanced security validation in AI model hosting platforms.         ",
    "url": "https://arxiv.org/abs/2505.01067",
    "authors": [
      "Ziqi Ding",
      "Qian Fu",
      "Junchen Ding",
      "Gelei Deng",
      "Yi Liu",
      "Yuekang Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2505.01068",
    "title": "Multimodal Transformers are Hierarchical Modal-wise Heterogeneous Graphs",
    "abstract": "           Multimodal Sentiment Analysis (MSA) is a rapidly developing field that integrates multimodal information to recognize sentiments, and existing models have made significant progress in this area. The central challenge in MSA is multimodal fusion, which is predominantly addressed by Multimodal Transformers (MulTs). Although act as the paradigm, MulTs suffer from efficiency concerns. In this work, from the perspective of efficiency optimization, we propose and prove that MulTs are hierarchical modal-wise heterogeneous graphs (HMHGs), and we introduce the graph-structured representation pattern of MulTs. Based on this pattern, we propose an Interlaced Mask (IM) mechanism to design the Graph-Structured and Interlaced-Masked Multimodal Transformer (GsiT). It is formally equivalent to MulTs which achieves an efficient weight-sharing mechanism without information disorder through IM, enabling All-Modal-In-One fusion with only 1/3 of the parameters of pure MulTs. A Triton kernel called Decomposition is implemented to ensure avoiding additional computational overhead. Moreover, it achieves significantly higher performance than traditional MulTs. To further validate the effectiveness of GsiT itself and the HMHG concept, we integrate them into multiple state-of-the-art models and demonstrate notable performance improvements and parameter reduction on widely used MSA datasets.         ",
    "url": "https://arxiv.org/abs/2505.01068",
    "authors": [
      "Yijie Jin",
      "Junjie Peng",
      "Xuanchao Lin",
      "Haochen Yuan",
      "Lan Wang",
      "Cangzhi Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2505.01073",
    "title": "Retrieval Augmented Learning: A Retrial-based Large Language Model Self-Supervised Learning and Autonomous Knowledge Generation",
    "abstract": "           The lack of domain-specific data in the pre-training of Large Language Models (LLMs) severely limits LLM-based decision systems in specialized applications, while post-training a model in the scenarios requires significant computational resources. In this paper, we present Retrial-Augmented Learning (RAL), a reward-free self-supervised learning framework for LLMs that operates without model training. By developing Retrieval-Augmented Generation (RAG) into a module for organizing intermediate data, we realized a three-stage autonomous knowledge generation of proposing a hypothesis, validating the hypothesis, and generating the knowledge. The method is evaluated in the LLM-PySC2 environment, a representative decision-making platform that combines sufficient complexity with domain-specific knowledge requirements. Experiments demonstrate that the proposed method effectively reduces hallucination by generating and utilizing validated knowledge, and increases decision-making performance at an extremely low cost. Meanwhile, the approach exhibits potential in out-of-distribution(OOD) tasks, robustness, and transferability, making it a cost-friendly but effective solution for decision-making problems and autonomous knowledge generation.         ",
    "url": "https://arxiv.org/abs/2505.01073",
    "authors": [
      "Zongyuan Li",
      "Pengfei Li",
      "Runnan Qi",
      "Yanan Ni",
      "Lumin Jiang",
      "Hui Wu",
      "Xuebo Zhang",
      "Kuihua Huang",
      "Xian Guo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2505.01123",
    "title": "Poster: Machine Learning for Vulnerability Detection as Target Oracle in Automated Fuzz Driver Generation",
    "abstract": "           In vulnerability detection, machine learning has been used as an effective static analysis technique, although it suffers from a significant rate of false positives. Contextually, in vulnerability discovery, fuzzing has been used as an effective dynamic analysis technique, although it requires manually writing fuzz drivers. Fuzz drivers usually target a limited subset of functions in a library that must be chosen according to certain criteria, e.g., the depth of a function, the number of paths. These criteria are verified by components called target oracles. In this work, we propose an automated fuzz driver generation workflow composed of: (1) identifying a likely vulnerable function by leveraging a machine learning for vulnerability detection model as a target oracle, (2) automatically generating fuzz drivers, (3) fuzzing the target function to find bugs which could confirm the vulnerability inferred by the target oracle. We show our method on an existing vulnerability in libgd, with a plan for large-scale evaluation.         ",
    "url": "https://arxiv.org/abs/2505.01123",
    "authors": [
      "Gianpietro Castiglione",
      "Marcello Maugeri",
      "Giampaolo Bella"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2505.01130",
    "title": "Risk Analysis and Design Against Adversarial Actions",
    "abstract": "           Learning models capable of providing reliable predictions in the face of adversarial actions has become a central focus of the machine learning community in recent years. This challenge arises from observing that data encountered at deployment time often deviate from the conditions under which the model was trained. In this paper, we address deployment-time adversarial actions and propose a versatile, well-principled framework to evaluate the model's robustness against attacks of diverse types and intensities. While we initially focus on Support Vector Regression (SVR), the proposed approach extends naturally to the broad domain of learning via relaxed optimization techniques. Our results enable an assessment of the model vulnerability without requiring additional test data and operate in a distribution-free setup. These results not only provide a tool to enhance trust in the model's applicability but also aid in selecting among competing alternatives. Later in the paper, we show that our findings also offer useful insights for establishing new results within the out-of-distribution framework.         ",
    "url": "https://arxiv.org/abs/2505.01130",
    "authors": [
      "Marco C. Campi",
      "Algo Car\u00e8",
      "Luis G. Crespo",
      "Simone Garatti",
      "Federico A. Ramponi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2505.01139",
    "title": "Active Sybil Attack and Efficient Defense Strategy in IPFS DHT",
    "abstract": "           The InterPlanetary File System (IPFS) is a decentralized peer-to-peer (P2P) storage that relies on Kademlia, a Distributed Hash Table (DHT) structure commonly used in P2P systems for its proved scalability. However, DHTs are known to be vulnerable to Sybil attacks, in which a single entity controls multiple malicious nodes. Recent studies have shown that IPFS is affected by a passive content eclipse attack, leveraging Sybils, in which adversarial nodes hide received indexed information from other peers, making the content appear unavailable. Fortunately, the latest mitigation strategy coupling an attack detection based on statistical tests and a wider publication strategy upon detection was able to circumvent it. In this work, we present a new active attack, with malicious nodes responding with semantically correct but intentionally false data, exploiting both an optimized placement of Sybils to stay below the detection threshold and an early trigger of the content discovery termination in Kubo, the main IPFS implementation. Our attack achieves to completely eclipse content on the latest Kubo release. When evaluated against the most recent known mitigation, it successfully denies access to the target content in approximately 80\\% of lookup attempts. To address this vulnerability, we propose a new mitigation called SR-DHT-Store, which enables efficient, Sybil-resistant content publication without relying on attack detection but instead on a systematic and precise use of region-based queries, defined by a dynamically computed XOR distance to the target ID. SR-DHT-Store can be combined with other defense mechanisms resulting in a defense strategy that completely mitigates both passive and active Sybil attacks at a lower overhead, while allowing an incremental deployment.         ",
    "url": "https://arxiv.org/abs/2505.01139",
    "authors": [
      "V. H. M. Netto",
      "T. Cholez",
      "C. L. Ignat"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2505.01159",
    "title": "A Parameter-Driven Physics-Informed Neural Network Framework for Solving Two-Parameter Singular Perturbation Problems Involving Boundary Layers",
    "abstract": "           In this article, our goal is to solve two-parameter singular perturbation problems (SPPs) in one- and two-dimensions using an adapted Physics-Informed Neural Networks (PINNs) approach. Such problems are of major importance in engineering and sciences as it appears in control theory, fluid and gas dynamics, financial modelling and so on. Solutions of such problems exhibit boundary and/or interior layers, which make them difficult to handle. It has been validated in the literature that standard PINNs have low accuracy and can't handle such problems efficiently. Recently Cao et. al \\cite{cao2023physics} proposed a new parameter asymptotic PINNs (PA-PINNs) to solve one-parameter singularly perturbed convection-dominated problems. It was observed that PA-PINNs works better than standard PINNs and gPINNs in terms of accuracy, convergence and stability. In this article, for the first time robustness of PA-PINNs will be validated for solving two-parameter SPPs.         ",
    "url": "https://arxiv.org/abs/2505.01159",
    "authors": [
      "Pradanya Boro",
      "Aayushman Raina",
      "Srinivasan Natesan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2505.01168",
    "title": "Harmonizing Intra-coherence and Inter-divergence in Ensemble Attacks for Adversarial Transferability",
    "abstract": "           The development of model ensemble attacks has significantly improved the transferability of adversarial examples, but this progress also poses severe threats to the security of deep neural networks. Existing methods, however, face two critical challenges: insufficient capture of shared gradient directions across models and a lack of adaptive weight allocation mechanisms. To address these issues, we propose a novel method Harmonized Ensemble for Adversarial Transferability (HEAT), which introduces domain generalization into adversarial example generation for the first time. HEAT consists of two key modules: Consensus Gradient Direction Synthesizer, which uses Singular Value Decomposition to synthesize shared gradient directions; and Dual-Harmony Weight Orchestrator which dynamically balances intra-domain coherence, stabilizing gradients within individual models, and inter-domain diversity, enhancing transferability across models. Experimental results demonstrate that HEAT significantly outperforms existing methods across various datasets and settings, offering a new perspective and direction for adversarial attack research.         ",
    "url": "https://arxiv.org/abs/2505.01168",
    "authors": [
      "Zhaoyang Ma",
      "Zhihao Wu",
      "Wang Lu",
      "Xin Gao",
      "Jinghang Yue",
      "Taolin Zhang",
      "Lipo Wang",
      "Youfang Lin",
      "Jing Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2505.01181",
    "title": "Explainable AI Based Diagnosis of Poisoning Attacks in Evolutionary Swarms",
    "abstract": "           Swarming systems, such as for example multi-drone networks, excel at cooperative tasks like monitoring, surveillance, or disaster assistance in critical environments, where autonomous agents make decentralized decisions in order to fulfill team-level objectives in a robust and efficient manner. Unfortunately, team-level coordinated strategies in the wild are vulnerable to data poisoning attacks, resulting in either inaccurate coordination or adversarial behavior among the agents. To address this challenge, we contribute a framework that investigates the effects of such data poisoning attacks, using explainable AI methods. We model the interaction among agents using evolutionary intelligence, where an optimal coalition strategically emerges to perform coordinated tasks. Then, through a rigorous evaluation, the swarm model is systematically poisoned using data manipulation attacks. We showcase the applicability of explainable AI methods to quantify the effects of poisoning on the team strategy and extract footprint characterizations that enable diagnosing. Our findings indicate that when the model is poisoned above 10%, non-optimal strategies resulting in inefficient cooperation can be identified.         ",
    "url": "https://arxiv.org/abs/2505.01181",
    "authors": [
      "Mehrdad Asadi",
      "Roxana R\u0103dulescu",
      "Ann Now\u00e9"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2505.01186",
    "title": "Secure Cluster-Based Hierarchical Federated Learning in Vehicular Networks",
    "abstract": "           Hierarchical Federated Learning (HFL) has recently emerged as a promising solution for intelligent decision-making in vehicular networks, helping to address challenges such as limited communication resources, high vehicle mobility, and data heterogeneity. However, HFL remains vulnerable to adversarial and unreliable vehicles, whose misleading updates can significantly compromise the integrity and convergence of the global model. To address these challenges, we propose a novel defense framework that integrates dynamic vehicle selection with robust anomaly detection within a cluster-based HFL architecture, specifically designed to counter Gaussian noise and gradient ascent attacks. The framework performs a comprehensive reliability assessment for each vehicle by evaluating historical accuracy, contribution frequency, and anomaly records. Anomaly detection combines Z-score and cosine similarity analyses on model updates to identify both statistical outliers and directional deviations in model updates. To further refine detection, an adaptive thresholding mechanism is incorporated into the cosine similarity metric, dynamically adjusting the threshold based on the historical accuracy of each vehicle to enforce stricter standards for consistently high-performing vehicles. In addition, a weighted gradient averaging mechanism is implemented, which assigns higher weights to gradient updates from more trustworthy vehicles. To defend against coordinated attacks, a cross-cluster consistency check is applied to identify collaborative attacks in which multiple compromised clusters coordinate misleading updates. Together, these mechanisms form a multi-level defense strategy to filter out malicious contributions effectively. Simulation results show that the proposed algorithm significantly reduces convergence time compared to benchmark methods across both 1-hop and 3-hop topologies.         ",
    "url": "https://arxiv.org/abs/2505.01186",
    "authors": [
      "M. Saeid HaghighiFard",
      "Sinem Coleri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2505.01193",
    "title": "Going deep and going wide: Counting logic and homomorphism indistinguishability over graphs of bounded treedepth and treewidth",
    "abstract": "           We study the expressive power of first-order logic with counting quantifiers, especially the k-variable and quantifier-rank-q fragment C^k_q, using homomorphism indistinguishability. Recently, Dawar, Jakl, and Reggio~(2021) proved that two graphs satisfy the same C^k_q-sentences if and only if they are homomorphism indistinguishable over the class T^k_q of graphs admitting a k-pebble forest cover of depth q. After reproving this result using elementary means, we provide a graph-theoretic analysis of the graph class T^k_q. This allows us to separate T^k_q from the intersection TW_{k-1} \\cap TD_q, provided that q is sufficiently larger than k. Here TW_{k-1} is the class of all graphs of treewidth at most k-1 and TD_q is the class of all graphs of treedepth at most q. We are able to lift this separation to a (semantic) separation of the respective homomorphism indistinguishability relations \\equiv_{T^k_q} and \\equiv_{TW_{k-1} \\cap TD_q}. We do this by showing that the classes TD_q and T^k_q are homomorphism distinguishing closed, as conjectured by Roberson~(2022). In order to prove Roberson's conjecture for T^k_q we characterise T^k_q in terms of a monotone Cops-and-Robber game. The crux is to prove that if Cop has a winning strategy then Cop also has a winning strategy that is monotone. To that end, we show how to transform Cops' winning strategy into a pree-tree-decomposition, which is inspired by decompositions of matroids, and then applying an intricate breadth-first `cleaning up' procedure along the pree-tree-decomposition (which may temporarily lose the property of representing a strategy), in order to achieve monotonicity while controlling the number of rounds simultaneously across all branches of the decomposition via a vertex exchange argument.         ",
    "url": "https://arxiv.org/abs/2505.01193",
    "authors": [
      "Isolde Adler",
      "Eva Fluck",
      "Tim Seppelt",
      "Gian Luca Spitzer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2505.01207",
    "title": "T-Graph: Enhancing Sparse-view Camera Pose Estimation by Pairwise Translation Graph",
    "abstract": "           Sparse-view camera pose estimation, which aims to estimate the 6-Degree-of-Freedom (6-DoF) poses from a limited number of images captured from different viewpoints, is a fundamental yet challenging problem in remote sensing applications. Existing methods often overlook the translation information between each pair of viewpoints, leading to suboptimal performance in sparse-view scenarios. To address this limitation, we introduce T-Graph, a lightweight, plug-and-play module to enhance camera pose estimation in sparse-view settings. T-graph takes paired image features as input and maps them through a Multilayer Perceptron (MLP). It then constructs a fully connected translation graph, where nodes represent cameras and edges encode their translation relationships. It can be seamlessly integrated into existing models as an additional branch in parallel with the original prediction, maintaining efficiency and ease of use. Furthermore, we introduce two pairwise translation representations, relative-t and pair-t, formulated under different local coordinate systems. While relative-t captures intuitive spatial relationships, pair-t offers a rotation-disentangled alternative. The two representations contribute to enhanced adaptability across diverse application scenarios, further improving our module's robustness. Extensive experiments on two state-of-the-art methods (RelPose++ and Forge) using public datasets (C03D and IMC PhotoTourism) validate both the effectiveness and generalizability of T-Graph. The results demonstrate consistent improvements across various metrics, notably camera center accuracy, which improves by 1% to 6% from 2 to 8 viewpoints.         ",
    "url": "https://arxiv.org/abs/2505.01207",
    "authors": [
      "Qingyu Xian",
      "Weiqin Jiao",
      "Hao Cheng",
      "Berend Jan van der Zwaag",
      "Yanqiu Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2505.01218",
    "title": "Quantitative Attractor Analysis of High-Capacity Kernel Logistic Regression Hopfield Networks",
    "abstract": "           Traditional Hopfield networks, using Hebbian learning, face severe storage capacity limits ($\\approx 0.14$ P/N) and spurious attractors. Kernel Logistic Regression (KLR) offers a non-linear approach, mapping patterns to high-dimensional feature spaces for improved separability. Our previous work showed KLR dramatically improves capacity and noise robustness over conventional methods. This paper quantitatively analyzes the attractor structures in KLR-trained networks via extensive simulations. We evaluated recall from diverse initial states across wide storage loads (up to 4.0 P/N) and noise levels. We quantified convergence rates and speed. Our analysis confirms KLR's superior performance: high capacity (up to 4.0 P/N) and robustness. The attractor landscape is remarkably \"clean,\" with near-zero spurious fixed points. Recall failures under high load/noise are primarily due to convergence to other learned patterns, not spurious ones. Dynamics are exceptionally fast (typically 1-2 steps for high-similarity states). This characterization reveals how KLR reshapes dynamics for high-capacity associative memory, highlighting its effectiveness and contributing to AM understanding.         ",
    "url": "https://arxiv.org/abs/2505.01218",
    "authors": [
      "Akira Tamamori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2505.01219",
    "title": "Tell me who its founders are and I'll tell you what your online community looks like: Online community founders' personality and community attributes",
    "abstract": "           Online communities are an increasingly important stakeholder for firms, and despite the growing body of research on them, much remains to be learned about them and about the factors that determine their attributes and sustainability. Whereas most of the literature focuses on predictors such as community activity, network structure, and platform interface, there is little research about behavioral and psychological aspects of community members and leaders. In the present study we focus on the personality traits of community founders as predictors of community attributes and sustainability. We develop a tool to estimate community members' Big Five personality traits from their social media text and use it to estimate the traits of 35,164 founders in 8,625 Reddit communities. We find support for most of our predictions about the relationships between founder traits and community sustainability and attributes, including the level of engagement within the community, aspects of its social network structure, and whether the founders themselves remain active in it.         ",
    "url": "https://arxiv.org/abs/2505.01219",
    "authors": [
      "Yaniv Dover",
      "Shaul Oreg"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2505.01232",
    "title": "Bilateral Cognitive Security Games in Networked Control Systems under Stealthy Injection Attacks",
    "abstract": "           This paper studies a strategic security problem in networked control systems under stealthy false data injection attacks. The security problem is modeled as a bilateral cognitive security game between a defender and an adversary, each possessing cognitive reasoning abilities. The adversary with an adversarial cognitive ability strategically attacks some interconnections of the system with the aim of disrupting the network performance while remaining stealthy to the defender. Meanwhile, the defender with a defense cognitive ability strategically monitors some nodes to impose the stealthiness constraint with the purpose of minimizing the worst-case disruption caused by the adversary. Within the proposed bilateral cognitive security framework, the preferred cognitive levels of the two strategic agents are formulated in terms of two newly proposed concepts, cognitive mismatch and cognitive resonance. Moreover, we propose a method to compute the policies for the defender and the adversary with arbitrary cognitive abilities. A sufficient condition is established under which an increase in cognitive levels does not alter the policies for the defender and the adversary, ensuring convergence. The obtained results are validated through numerical simulations.         ",
    "url": "https://arxiv.org/abs/2505.01232",
    "authors": [
      "Anh Tung Nguyen",
      "Quanyan Zhu",
      "Andr\u00e9 Teixeira"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2505.01233",
    "title": "Security Metrics for Uncertain Interconnected Systems under Stealthy Data Injection Attacks",
    "abstract": "           This paper quantifies the security of uncertain interconnected systems under stealthy data injection attacks. In particular, we consider a large-scale system composed of a certain subsystem interconnected with an uncertain subsystem, where only the input-output channels are accessible. An adversary is assumed to inject false data to maximize the performance loss of the certain subsystem while remaining undetected. By abstracting the uncertain subsystem as a class of admissible systems satisfying an $\\mathcal{L}_2$ gain constraint, the worst-case performance loss is obtained as the solution to a convex semi-definite program depending only on the certain subsystem dynamics and such an $\\mathcal{L}_2$ gain constraint. This solution is proved to serve as an upper bound for the actual worst-case performance loss when the model of the entire system is fully certain. The results are demonstrated through numerical simulations of the power transmission grid spanning Sweden and Northern Denmark.         ",
    "url": "https://arxiv.org/abs/2505.01233",
    "authors": [
      "Anh Tung Nguyen",
      "Sribalaji C. Anand",
      "Andr\u00e9 M. H. Teixeira"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2505.01234",
    "title": "Robust Deep Learning-Based Physical Layer Communications: Strategies and Approaches",
    "abstract": "           Deep learning (DL) has emerged as a transformative technology with immense potential to reshape the sixth-generation (6G) wireless communication network. By utilizing advanced algorithms for feature extraction and pattern recognition, DL provides unprecedented capabilities in optimizing the network efficiency and performance, particularly in physical layer communications. Although DL technologies present the great potential, they also face significant challenges related to the robustness, which are expected to intensify in the complex and demanding 6G environment. Specifically, current DL models typically exhibit substantial performance degradation in dynamic environments with time-varying channels, interference of noise and different scenarios, which affect their effectiveness in diverse real-world applications. This paper provides a comprehensive overview of strategies and approaches for robust DL-based methods in physical layer communications. First we introduce the key challenges that current DL models face. Then we delve into a detailed examination of DL approaches specifically tailored to enhance robustness in 6G, which are classified into data-driven and model-driven strategies. Finally, we verify the effectiveness of these methods by case studies and outline future research directions.         ",
    "url": "https://arxiv.org/abs/2505.01234",
    "authors": [
      "Fenghao Zhu",
      "Xinquan Wang",
      "Chen Zhu",
      "Tierui Gong",
      "Zhaohui Yang",
      "Chongwen Huang",
      "Xiaoming Chen",
      "Zhaoyang Zhang",
      "M\u00e9rouane Debbah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2505.01255",
    "title": "PREMISE: Matching-based Prediction for Accurate Review Recommendation",
    "abstract": "           We present PREMISE (PREdict with Matching ScorEs), a new architecture for the matching-based learning in the multimodal fields for the multimodal review helpfulness (MRHP) task. Distinct to previous fusion-based methods which obtains multimodal representations via cross-modal attention for downstream tasks, PREMISE computes the multi-scale and multi-field representations, filters duplicated semantics, and then obtained a set of matching scores as feature vectors for the downstream recommendation task. This new architecture significantly boosts the performance for such multimodal tasks whose context matching content are highly correlated to the targets of that task, compared to the state-of-the-art fusion-based methods. Experimental results on two publicly available datasets show that PREMISE achieves promising performance with less computational cost.         ",
    "url": "https://arxiv.org/abs/2505.01255",
    "authors": [
      "Wei Han",
      "Hui Chen",
      "Soujanya Poria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2505.01266",
    "title": "Tight Runtime Guarantees From Understanding the Population Dynamics of the GSEMO Multi-Objective Evolutionary Algorithm",
    "abstract": "           The global simple evolutionary multi-objective optimizer (GSEMO) is a simple, yet often effective multi-objective evolutionary algorithm (MOEA). By only maintaining non-dominated solutions, it has a variable population size that automatically adjusts to the needs of the optimization process. The downside of the dynamic population size is that the population dynamics of this algorithm are harder to understand, resulting, e.g., in the fact that only sporadic tight runtime analyses exist. In this work, we significantly enhance our understanding of the dynamics of the GSEMO, in particular, for the classic CountingOnesCountingZeros (COCZ) benchmark. From this, we prove a lower bound of order $\\Omega(n^2 \\log n)$, for the first time matching the seminal upper bounds known for over twenty years. We also show that the GSEMO finds any constant fraction of the Pareto front in time $O(n^2)$, improving over the previous estimate of $O(n^2 \\log n)$ for the time to find the first Pareto optimum. Our methods extend to other classic benchmarks and yield, e.g., the first $\\Omega(n^{k+1})$ lower bound for the OJZJ benchmark in the case that the gap parameter is $k \\in \\{2,3\\}$. We are therefore optimistic that our new methods will be useful in future mathematical analyses of MOEAs.         ",
    "url": "https://arxiv.org/abs/2505.01266",
    "authors": [
      "Benjamin Doerr",
      "Martin Krejca",
      "Andre Opris"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2505.01267",
    "title": "Diffusion-based Adversarial Purification from the Perspective of the Frequency Domain",
    "abstract": "           The diffusion-based adversarial purification methods attempt to drown adversarial perturbations into a part of isotropic noise through the forward process, and then recover the clean images through the reverse process. Due to the lack of distribution information about adversarial perturbations in the pixel domain, it is often unavoidable to damage normal semantics. We turn to the frequency domain perspective, decomposing the image into amplitude spectrum and phase spectrum. We find that for both spectra, the damage caused by adversarial perturbations tends to increase monotonically with frequency. This means that we can extract the content and structural information of the original clean sample from the frequency components that are less damaged. Meanwhile, theoretical analysis indicates that existing purification methods indiscriminately damage all frequency components, leading to excessive damage to the image. Therefore, we propose a purification method that can eliminate adversarial perturbations while maximizing the preservation of the content and structure of the original image. Specifically, at each time step during the reverse process, for the amplitude spectrum, we replace the low-frequency components of the estimated image's amplitude spectrum with the corresponding parts of the adversarial image. For the phase spectrum, we project the phase of the estimated image into a designated range of the adversarial image's phase spectrum, focusing on the low frequencies. Empirical evidence from extensive experiments demonstrates that our method significantly outperforms most current defense methods.         ",
    "url": "https://arxiv.org/abs/2505.01267",
    "authors": [
      "Gaozheng Pei",
      "Ke Ma",
      "Yingfei Sun",
      "Qianqian Xu",
      "Qingming Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2505.01269",
    "title": "Verifying Parameterized Networks Specified by Vertex-Replacement Graph Grammars",
    "abstract": "           We consider the parametric reachability problem (PRP) for families of networks described by vertex-replacement (VR) graph grammars, where network nodes run replicas of finite-state processes that communicate via binary handshaking. We show that the PRP problem for VR grammars can be effectively reduced to the PRP problem for hyperedge-replacement (HR) grammars at the cost of introducing extra edges for routing messages. This transformation is motivated by the existence of several parametric verification techniques for families of networks specified by HR grammars, or similar inductive formalisms. Our reduction enables applying the verification techniques for HR systems to systems with dense architectures, such as user-specified cliques and multi-partite graphs.         ",
    "url": "https://arxiv.org/abs/2505.01269",
    "authors": [
      "Radu Iosif",
      "Arnaud Sangnier",
      "Neven Villani"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2505.01282",
    "title": "Micro-Patterns in Solidity Code",
    "abstract": "           Solidity is the predominant programming language for blockchain-based smart contracts, and its characteristics pose significant challenges for code analysis and maintenance. Traditional software analysis approaches, while effective for conventional programming languages, often fail to address Solidity-specific features such as gas optimization and security constraints. This paper introduces micro-patterns - recurring, small-scale design structures that capture key behavioral and structural peculiarities specific to a language - for Solidity language and demonstrates their value in understanding smart contract development practices. We identified 18 distinct micro-patterns organized in five categories (Security, Functional, Optimization, Interaction, and Feedback), detailing their characteristics to enable automated detection. To validate this proposal, we analyzed a dataset of 23258 smart contracts from five popular blockchains (Ethereum, Polygon, Arbitrum, Fantom and Optimism). Our analysis reveals widespread adoption of micro-patterns, with 99% of contracts implementing at least one pattern and an average of 2.76 patterns per contract. The Storage Saver pattern showed the highest adoption (84.62% mean coverage), while security patterns demonstrated platform-specific adoption rates. Statistical analysis revealed significant platform-specific differences in pattern adoption, particularly in Borrower, Implementer, and Storage Optimization patterns.         ",
    "url": "https://arxiv.org/abs/2505.01282",
    "authors": [
      "Luca Ruschioni",
      "Robert Shuttleworth",
      "Rumyana Neykova",
      "Barbara Re",
      "Giuseppe Destefanis"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2505.01292",
    "title": "Fine-grained Manipulation Attacks to Local Differential Privacy Protocols for Data Streams",
    "abstract": "           Local Differential Privacy (LDP) enables massive data collection and analysis while protecting end users' privacy against untrusted aggregators. It has been applied to various data types (e.g., categorical, numerical, and graph data) and application settings (e.g., static and streaming). Recent findings indicate that LDP protocols can be easily disrupted by poisoning or manipulation attacks, which leverage injected/corrupted fake users to send crafted data conforming to the LDP reports. However, current attacks primarily target static protocols, neglecting the security of LDP protocols in the streaming settings. Our research fills the gap by developing novel fine-grained manipulation attacks to LDP protocols for data streams. By reviewing the attack surfaces in existing algorithms, We introduce a unified attack framework with composable modules, which can manipulate the LDP estimated stream toward a target stream. Our attack framework can adapt to state-of-the-art streaming LDP algorithms with different analytic tasks (e.g., frequency and mean) and LDP models (event-level, user-level, w-event level). We validate our attacks theoretically and through extensive experiments on real-world datasets, and finally explore a possible defense mechanism for mitigating these attacks.         ",
    "url": "https://arxiv.org/abs/2505.01292",
    "authors": [
      "Xinyu Li",
      "Xuebin Ren",
      "Shusen Yang",
      "Liang Shi",
      "Chia-Mu Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2505.01305",
    "title": "Early Detection of Patient Deterioration from Real-Time Wearable Monitoring System",
    "abstract": "           Early detection of patient deterioration is crucial for reducing mortality rates. Heart rate data has shown promise in assessing patient health, and wearable devices offer a cost-effective solution for real-time monitoring. However, extracting meaningful insights from diverse heart rate data and handling missing values in wearable device data remain key challenges. To address these challenges, we propose TARL, an innovative approach that models the structural relationships of representative subsequences, known as shapelets, in heart rate time series. TARL creates a shapelet-transition knowledge graph to model shapelet dynamics in heart rate time series, indicating illness progression and potential future changes. We further introduce a transition-aware knowledge embedding to reinforce relationships among shapelets and quantify the impact of missing values, enabling the formulation of comprehensive heart rate representations. These representations capture explanatory structures and predict future heart rate trends, aiding early illness detection. We collaborate with physicians and nurses to gather ICU patient heart rate data from wearables and diagnostic metrics assessing illness severity for evaluating deterioration. Experiments on real-world ICU data demonstrate that TARL achieves both high reliability and early detection. A case study further showcases TARL's explainable detection process, highlighting its potential as an AI-driven tool to assist clinicians in recognizing early signs of patient deterioration.         ",
    "url": "https://arxiv.org/abs/2505.01305",
    "authors": [
      "Lo Pang-Yun Ting",
      "Hong-Pei Chen",
      "An-Shan Liu",
      "Chun-Yin Yeh",
      "Po-Lin Chen",
      "Kun-Ta Chuang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2505.01309",
    "title": "Enhancing SPARQL Query Rewriting for Complex Ontology Alignments",
    "abstract": "           SPARQL query rewriting is a fundamental mechanism for uniformly querying heterogeneous ontologies in the Linked Data Web. However, the complexity of ontology alignments, particularly rich correspondences (c : c), makes this process challenging. Existing approaches primarily focus on simple (s : s) and partially complex ( s : c) alignments, thereby overlooking the challenges posed by more expressive alignments. Moreover, the intricate syntax of SPARQL presents a barrier for non-expert users seeking to fully exploit the knowledge encapsulated in ontologies. This article proposes an innovative approach for the automatic rewriting of SPARQL queries from a source ontology to a target ontology, based on a user's need expressed in natural language. It leverages the principles of equivalence transitivity as well as the advanced capabilities of large language models such as GPT-4. By integrating these elements, this approach stands out for its ability to efficiently handle complex alignments, particularly (c : c) correspondences , by fully exploiting their expressiveness. Additionally, it facilitates access to aligned ontologies for users unfamiliar with SPARQL, providing a flexible solution for querying heterogeneous data.         ",
    "url": "https://arxiv.org/abs/2505.01309",
    "authors": [
      "Anicet Lepetit Ondo",
      "Laurence Capus",
      "Mamadou Bousso"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2505.01313",
    "title": "A Neural Architecture Search Method using Auxiliary Evaluation Metric based on ResNet Architecture",
    "abstract": "           This paper proposes a neural architecture search space using ResNet as a framework, with search objectives including parameters for convolution, pooling, fully connected layers, and connectivity of the residual network. In addition to recognition accuracy, this paper uses the loss value on the validation set as a secondary objective for optimization. The experimental results demonstrate that the search space of this paper together with the optimisation approach can find competitive network architectures on the MNIST, Fashion-MNIST and CIFAR100 datasets.         ",
    "url": "https://arxiv.org/abs/2505.01313",
    "authors": [
      "Shang Wang",
      "Huanrong Tang",
      "Jianquan Ouyang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2505.01314",
    "title": "A Transformer-based Neural Architecture Search Method",
    "abstract": "           This paper presents a neural architecture search method based on Transformer architecture, searching cross multihead attention computation ways for different number of encoder and decoder combinations. In order to search for neural network structures with better translation results, we considered perplexity as an auxiliary evaluation metric for the algorithm in addition to BLEU scores and iteratively improved each individual neural network within the population by a multi-objective genetic algorithm. Experimental results show that the neural network structures searched by the algorithm outperform all the baseline models, and that the introduction of the auxiliary evaluation metric can find better models than considering only the BLEU score as an evaluation metric.         ",
    "url": "https://arxiv.org/abs/2505.01314",
    "authors": [
      "Shang Wang",
      "Huanrong Tang",
      "Jianquan Ouyang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2505.01328",
    "title": "Constrained Network Adversarial Attacks: Validity, Robustness, and Transferability",
    "abstract": "           While machine learning has significantly advanced Network Intrusion Detection Systems (NIDS), particularly within IoT environments where devices generate large volumes of data and are increasingly susceptible to cyber threats, these models remain vulnerable to adversarial attacks. Our research reveals a critical flaw in existing adversarial attack methodologies: the frequent violation of domain-specific constraints, such as numerical and categorical limits, inherent to IoT and network traffic. This leads to up to 80.3% of adversarial examples being invalid, significantly overstating real-world vulnerabilities. These invalid examples, though effective in fooling models, do not represent feasible attacks within practical IoT deployments. Consequently, relying on these results can mislead resource allocation for defense, inflating the perceived susceptibility of IoT-enabled NIDS models to adversarial manipulation. Furthermore, we demonstrate that simpler surrogate models like Multi-Layer Perceptron (MLP) generate more valid adversarial examples compared to complex architectures such as CNNs and LSTMs. Using the MLP as a surrogate, we analyze the transferability of adversarial severity to other ML/DL models commonly used in IoT contexts. This work underscores the importance of considering both domain constraints and model architecture when evaluating and designing robust ML/DL models for security-critical IoT and network applications.         ",
    "url": "https://arxiv.org/abs/2505.01328",
    "authors": [
      "Anass Grini",
      "Oumaima Taheri",
      "Btissam El Khamlichi",
      "Amal El Fallah-Seghrouchni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2505.01348",
    "title": "Learning Stabilizing Policies via an Unstable Subspace Representation",
    "abstract": "           We study the problem of learning to stabilize (LTS) a linear time-invariant (LTI) system. Policy gradient (PG) methods for control assume access to an initial stabilizing policy. However, designing such a policy for an unknown system is one of the most fundamental problems in control, and it may be as hard as learning the optimal policy itself. Existing work on the LTS problem requires large data as it scales quadratically with the ambient dimension. We propose a two-phase approach that first learns the left unstable subspace of the system and then solves a series of discounted linear quadratic regulator (LQR) problems on the learned unstable subspace, targeting to stabilize only the system's unstable dynamics and reduce the effective dimension of the control space. We provide non-asymptotic guarantees for both phases and demonstrate that operating on the unstable subspace reduces sample complexity. In particular, when the number of unstable modes is much smaller than the state dimension, our analysis reveals that LTS on the unstable subspace substantially speeds up the stabilization process. Numerical experiments are provided to support this sample complexity reduction achieved by our approach.         ",
    "url": "https://arxiv.org/abs/2505.01348",
    "authors": [
      "Leonardo F. Toso",
      "Lintao Ye",
      "James Anderson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2505.00412",
    "title": "Maximum list $r$-colorable induced subgraphs in $kP_3$-free graphs",
    "abstract": "           We show that, for every fixed positive integers $r$ and $k$, \\textsc{Max-Weight List $r$-Colorable Induced Subgraph} admits a polynomial-time algorithm on $kP_3$-free graphs. This problem is a common generalization of \\textsc{Max-Weight Independent Set}, \\textsc{Odd Cycle Transversal} and \\textsc{List $r$-Coloring}, among others. Our result has several consequences. First, it implies that, for every fixed $r \\geq 5$, assuming $\\mathsf{P}\\neq \\mathsf{NP}$, \\textsc{Max-Weight List $r$-Colorable Induced Subgraph} is polynomial-time solvable on $H$-free graphs if and only if $H$ is an induced subgraph of either $kP_3$ or $P_5+kP_1$, for some $k \\geq 1$. Second, it makes considerable progress toward a complexity dichotomy for \\textsc{Odd Cycle Transversal} on $H$-free graphs, allowing to answer a question of Agrawal, Lima, Lokshtanov, Rz{\u0105}{\u017c}ewski, Saurabh, and Sharma [TALG 2024]. Third, it gives a short and self-contained proof of the known result of Chudnovsky, Hajebi, and Spirkl [Combinatorica 2024] that \\textsc{List $r$-Coloring} on $kP_3$-free graphs is polynomial-time solvable for every fixed $r$ and $k$. We also consider two natural distance-$d$ generalizations of \\textsc{Max-Weight Independent Set} and \\textsc{List $r$-Coloring} and provide polynomial-time algorithms on $kP_3$-free graphs for every fixed integers $r$, $k$, and $d \\geq 6$.         ",
    "url": "https://arxiv.org/abs/2505.00412",
    "authors": [
      "Esther Galby",
      "Paloma T. Lima",
      "Andrea Munaro",
      "Amir Nikabadi"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2505.00736",
    "title": "Modeling and Analyzing Urban Networks and Amenities with OSMnx",
    "abstract": "           OSMnx is a Python package for downloading, modeling, analyzing, and visualizing urban networks and any other geospatial features from OpenStreetMap data. A large and growing body of literature uses it to conduct scientific studies across the disciplines of geography, urban planning, transport engineering, computer science, and others. The OSMnx project has recently developed and implemented many new features, modeling capabilities, and analytical methods. The package now encompasses substantially more functionality than was previously documented in the literature. This article introduces OSMnx's modern capabilities, usage, and design -- in addition to the scientific theory and logic underlying them. It shares lessons learned in geospatial software development and reflects on open science's implications for urban modeling and analysis.         ",
    "url": "https://arxiv.org/abs/2505.00736",
    "authors": [
      "Geoff Boeing"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Mathematical Software (cs.MS)",
      "Systems and Control (eess.SY)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Applied Physics (physics.app-ph)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2505.00737",
    "title": "A Survey on 3D Reconstruction Techniques in Plant Phenotyping: From Classical Methods to Neural Radiance Fields (NeRF), 3D Gaussian Splatting (3DGS), and Beyond",
    "abstract": "           Plant phenotyping plays a pivotal role in understanding plant traits and their interactions with the environment, making it crucial for advancing precision agriculture and crop improvement. 3D reconstruction technologies have emerged as powerful tools for capturing detailed plant morphology and structure, offering significant potential for accurate and automated phenotyping. This paper provides a comprehensive review of the 3D reconstruction techniques for plant phenotyping, covering classical reconstruction methods, emerging Neural Radiance Fields (NeRF), and the novel 3D Gaussian Splatting (3DGS) approach. Classical methods, which often rely on high-resolution sensors, are widely adopted due to their simplicity and flexibility in representing plant structures. However, they face challenges such as data density, noise, and scalability. NeRF, a recent advancement, enables high-quality, photorealistic 3D reconstructions from sparse viewpoints, but its computational cost and applicability in outdoor environments remain areas of active research. The emerging 3DGS technique introduces a new paradigm in reconstructing plant structures by representing geometry through Gaussian primitives, offering potential benefits in both efficiency and scalability. We review the methodologies, applications, and performance of these approaches in plant phenotyping and discuss their respective strengths, limitations, and future prospects (this https URL). Through this review, we aim to provide insights into how these diverse 3D reconstruction techniques can be effectively leveraged for automated and high-throughput plant phenotyping, contributing to the next generation of agricultural technology.         ",
    "url": "https://arxiv.org/abs/2505.00737",
    "authors": [
      "Jiajia Li",
      "Xinda Qi",
      "Seyed Hamidreza Nabaei",
      "Meiqi Liu",
      "Dong Chen",
      "Xin Zhang",
      "Xunyuan Yin",
      "Zhaojian Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2505.01012",
    "title": "Quantum Support Vector Regression for Robust Anomaly Detection",
    "abstract": "           Anomaly Detection (AD) is critical in data analysis, particularly within the domain of IT security. In recent years, Machine Learning (ML) algorithms have emerged as a powerful tool for AD in large-scale data. In this study, we explore the potential of quantum ML approaches, specifically quantum kernel methods, for the application to robust AD. We build upon previous work on Quantum Support Vector Regression (QSVR) for semisupervised AD by conducting a comprehensive benchmark on IBM quantum hardware using eleven datasets. Our results demonstrate that QSVR achieves strong classification performance and even outperforms the noiseless simulation on two of these datasets. Moreover, we investigate the influence of - in the NISQ-era inevitable - quantum noise on the performance of the QSVR. Our findings reveal that the model exhibits robustness to depolarizing, phase damping, phase flip, and bit flip noise, while amplitude damping and miscalibration noise prove to be more disruptive. Finally, we explore the domain of Quantum Adversarial Machine Learning and demonstrate that QSVR is highly vulnerable to adversarial attacks and that noise does not improve the adversarial robustness of the model.         ",
    "url": "https://arxiv.org/abs/2505.01012",
    "authors": [
      "Kilian Tscharke",
      "Maximilian Wendlinger",
      "Sebastian Issel",
      "Pascal Debus"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2505.01037",
    "title": "Characterization and Learning of Causal Graphs from Hard Interventions",
    "abstract": "           A fundamental challenge in the empirical sciences involves uncovering causal structure through observation and experimentation. Causal discovery entails linking the conditional independence (CI) invariances in observational data to their corresponding graphical constraints via d-separation. In this paper, we consider a general setting where we have access to data from multiple experimental distributions resulting from hard interventions, as well as potentially from an observational distribution. By comparing different interventional distributions, we propose a set of graphical constraints that are fundamentally linked to Pearl's do-calculus within the framework of hard interventions. These graphical constraints associate each graphical structure with a set of interventional distributions that are consistent with the rules of do-calculus. We characterize the interventional equivalence class of causal graphs with latent variables and introduce a graphical representation that can be used to determine whether two causal graphs are interventionally equivalent, i.e., whether they are associated with the same family of hard interventional distributions, where the elements of the family are indistinguishable using the invariances from do-calculus. We also propose a learning algorithm to integrate multiple datasets from hard interventions, introducing new orientation rules. The learning objective is a tuple of augmented graphs which entails a set of causal graphs. We also prove the soundness of the proposed algorithm.         ",
    "url": "https://arxiv.org/abs/2505.01037",
    "authors": [
      "Zihan Zhou",
      "Muhammad Qasim Elahi",
      "Murat Kocaoglu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2505.01140",
    "title": "Robustness and uncertainty of direct numerical simulation under the influence of rounding and noise",
    "abstract": "           Numerical precision in large-scale scientific computations has become an emerging topic due to recent developments in computer hardware. Lower floating point precision offers the potential for significant performance improvements, but the uncertainty added from reducing the numerical precision is a major obstacle for it to reach prevalence in high-fidelity simulations of turbulence. In the present work, the impact of reducing the numerical precision under different rounding schemes is investigated and compared to the presence of white noise in the simulation data to obtain statistical averages of different quantities in the flow. To investigate how this impacts the simulation, an experimental methodology to assess the impact of these sources of uncertainty is proposed, in which each realization $u^i$ at time $t_i$ is perturbed, either by constraining the flow to a coarser discretization of the phase space (corresponding to low precision formats rounded with deterministic and stochastic rounding) or by perturbing the flow with white noise with a uniform distribution. The purpose of this approach is to assess the limiting factors for precision, and how robust a direct numerical simulation (DNS) is to noise and numerical precision. Our results indicate that for low-Re turbulent channel flow, stochastic rounding and noise impacts the results significantly less than deterministic rounding, indicating potential benefits of stochastic rounding over conventional round-to-nearest. We find that to capture the probability density function of the velocity change in time, the floating point precision is especially important in regions with small relative velocity changes and low turbulence intensity, but less important in regions with large velocity gradients and variations such as in the near-wall region.         ",
    "url": "https://arxiv.org/abs/2505.01140",
    "authors": [
      "Martin Karp",
      "Niclas Jansson",
      "Saleh Rezaeiravesh",
      "Stefano Markidis",
      "Philipp Schlatter"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Mathematical Software (cs.MS)"
    ]
  },
  {
    "id": "arXiv:2505.01167",
    "title": "Uncovering complementary information sharing in spider monkey collective foraging using higher-order spatial networks",
    "abstract": "           Collectives are often able to process information in a distributed fashion, surpassing each individual member's processing capacity. In fission-fusion dynamics, where group members come together and split from others often, sharing complementary information about uniquely known foraging areas could allow a group to track a heterogenous foraging environment better than any group member on its own. We analyse the partial overlaps between individual core ranges, which we assume represent the knowledge of an individual during a given season. We identify sets of individuals whose overlap shows a balance between redundantly and uniquely known portions and we use simplicial complexes to represent these higher-order interactions. The structure of the simplicial complexes shows holes in various dimensions, revealing complementarity in the foraging information that is being shared. We propose that the complex spatial networks arising from fission-fusion dynamics allow for adaptive, collective processing of foraging information in dynamic environments.         ",
    "url": "https://arxiv.org/abs/2505.01167",
    "authors": [
      "Gabriel Ramos-Fernandez",
      "Ross S. Walker",
      "Matthew J. Silk",
      "Denis Boyer",
      "Sandra E. Smith-Aguilar"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.14316",
    "title": "Identifying discreditable firms in a large-scale ownership network",
    "abstract": "           Violations of laws and regulations about food safety, production safety, quality standard and environmental protection, or negative consequences from loan, guarantee and pledge contracts, may result in operating and credit risks of firms. The above illegal or trust-breaking activities are collectively called discreditable activities, and firms with discreditable activities are named as discreditable firms. Identification of discreditable firms is of great significance for investment attraction, bank lending, equity investment, supplier selection, job seeking, and so on. In this paper, we collect registration records of about 113 million Chinese firms and construct an ownership network with about 6 million nodes, where each node is a firm who has invested at least one firm or has been invested by at least one firm. Analysis of publicly available records of discreditable activities show strong network effect, namely the probability of a firm to be discreditable is remarkably higher than the average probability given the fact that one of its investors or investees is discreditable. In comparison, for the risk of being a discreditable firm, an investee has higher impact than an investor in average. The impact of a firm on surrounding firms decays along with the increasing topological distance, analogous to the well-known \"three degrees of separation\" phenomenon. The uncovered correlation of discreditable activities can be considered as a representative example of network effect, in addition to the propagation of diseases, opinions and human behaviors. Lastly, we show that the utilization of the network effect largely improves the accuracy of the algorithm to identify discreditable firms.         ",
    "url": "https://arxiv.org/abs/2211.14316",
    "authors": [
      "Tao Zhou",
      "Yan-Li Lee",
      "Qian Li",
      "Duanbing Chen",
      "Wenbo Xie",
      "Tong Wu",
      "Tu Zeng"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2309.02637",
    "title": "Killing Two Birds with One Stone: Malicious Package Detection in NPM and PyPI using a Single Model of Malicious Behavior Sequence",
    "abstract": "           Open-source software (OSS) supply chain enlarges the attack surface, which makes package registries attractive targets for attacks. Recently, package registries NPM and PyPI have been flooded with malicious packages. The effectiveness of existing malicious NPM and PyPI package detection approaches is hindered by two challenges. The first challenge is how to leverage the knowledge of malicious packages from different ecosystems in a unified way such that multi-lingual malicious package detection can be feasible. The second challenge is how to model malicious behavior in a sequential way such that maliciousness can be precisely captured. To address the two challenges, we propose and implement Cerebro to detect malicious packages in NPM and PyPI. We curate a feature set based on a high-level abstraction of malicious behavior to enable multi-lingual knowledge fusing. We organize extracted features into a behavior sequence to model sequential malicious behavior. We fine-tune the BERT model to understand the semantics of malicious behavior. Extensive evaluation has demonstrated the effectiveness of Cerebro over the state-of-the-art as well as the practically acceptable efficiency. Cerebro has successfully detected 306 and 196 new malicious packages in PyPI and NPM, and received 385 thank letters from the official PyPI and NPM teams.         ",
    "url": "https://arxiv.org/abs/2309.02637",
    "authors": [
      "Junan Zhang",
      "Kaifeng Huang",
      "Yiheng Huang",
      "Bihuan Chen",
      "Ruisi Wang",
      "Chong Wang",
      "Xin Peng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2401.02398",
    "title": "Generating synthetic data for neural operators",
    "abstract": "           Recent advances in the literature show promising potential of deep learning methods, particularly neural operators, in obtaining numerical solutions to partial differential equations (PDEs) beyond the reach of current numerical solvers. However, existing data-driven approaches often rely on training data produced by numerical PDE solvers (e.g., finite difference or finite element methods). We introduce a \"backward\" data generation method that avoids solving the PDE numerically: by randomly sampling candidate solutions $u_j$ from the appropriate solution space (e.g., $H_0^1(\\Omega)$), we compute the corresponding right-hand side $f_j$ directly from the equation by differentiation. This produces training pairs ${(f_j, u_j)}$ by computing derivatives rather than solving a PDE numerically for each data point, enabling fast, large-scale data generation consisting of exact solutions. Experiments indicate that models trained on this synthetic data generalize well when tested on data produced by standard solvers. While the idea is simple, we hope this method will expand the potential of neural PDE solvers that do not rely on classical numerical solvers to generate their data.         ",
    "url": "https://arxiv.org/abs/2401.02398",
    "authors": [
      "Erisa Hasani",
      "Rachel A. Ward"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2405.00998",
    "title": "Part-aware Shape Generation with Latent 3D Diffusion of Neural Voxel Fields",
    "abstract": "           This paper presents a novel latent 3D diffusion model for the generation of neural voxel fields, aiming to achieve accurate part-aware structures. Compared to existing methods, there are two key designs to ensure high-quality and accurate part-aware generation. On one hand, we introduce a latent 3D diffusion process for neural voxel fields, enabling generation at significantly higher resolutions that can accurately capture rich textural and geometric details. On the other hand, a part-aware shape decoder is introduced to integrate the part codes into the neural voxel fields, guiding the accurate part decomposition and producing high-quality rendering results. Through extensive experimentation and comparisons with state-of-the-art methods, we evaluate our approach across four different classes of data. The results demonstrate the superior generative capabilities of our proposed method in part-aware shape generation, outperforming existing state-of-the-art methods.         ",
    "url": "https://arxiv.org/abs/2405.00998",
    "authors": [
      "Yuhang Huang",
      "SHilong Zou",
      "Xinwang Liu",
      "Kai Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2405.14606",
    "title": "Logical Characterizations of Recurrent Graph Neural Networks with Reals and Floats",
    "abstract": "           In pioneering work from 2019, Barcel\u00f3 and coauthors identified logics that precisely match the expressive power of constant iteration-depth graph neural networks (GNNs) relative to properties definable in first-order logic. In this article, we give exact logical characterizations of recurrent GNNs in two scenarios: (1) in the setting with floating-point numbers and (2) with reals. For floats, the formalism matching recurrent GNNs is a rule-based modal logic with counting, while for reals we use a suitable infinitary modal logic, also with counting. These results give exact matches between logics and GNNs in the recurrent setting without relativising to a background logic in either case, but using some natural assumptions about floating-point arithmetic. Applying our characterizations, we also prove that, relative to graph properties definable in monadic second-order logic (MSO), our infinitary and rule-based logics are equally expressive. This implies that recurrent GNNs with reals and floats have the same expressive power over MSO-definable properties and shows that, for such properties, also recurrent GNNs with reals are characterized by a (finitary!) rule-based modal logic. In the general case, in contrast, the expressive power with floats is weaker than with reals. In addition to logic-oriented results, we also characterize recurrent GNNs, with both reals and floats, via distributed automata, drawing links to distributed computing models.         ",
    "url": "https://arxiv.org/abs/2405.14606",
    "authors": [
      "Veeti Ahvonen",
      "Damian Heiman",
      "Antti Kuusisto",
      "Carsten Lutz"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.01494",
    "title": "Robust Classification by Coupling Data Mollification with Label Smoothing",
    "abstract": "           Introducing training-time augmentations is a key technique to enhance generalization and prepare deep neural networks against test-time corruptions. Inspired by the success of generative diffusion models, we propose a novel approach of coupling data mollification, in the form of image noising and blurring, with label smoothing to align predicted label confidences with image degradation. The method is simple to implement, introduces negligible overheads, and can be combined with existing augmentations. We demonstrate improved robustness and uncertainty quantification on the corrupted image benchmarks of CIFAR, TinyImageNet and ImageNet datasets.         ",
    "url": "https://arxiv.org/abs/2406.01494",
    "authors": [
      "Markus Heinonen",
      "Ba-Hien Tran",
      "Michael Kampffmeyer",
      "Maurizio Filippone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2406.01927",
    "title": "Position-based Rogue Access Point Detection",
    "abstract": "           Rogue Wi-Fi access point (AP) attacks can lead to data breaches and unauthorized access. Existing rogue AP detection methods and tools often rely on channel state information (CSI) or received signal strength indicator (RSSI), but they require specific hardware or achieve low detection accuracy. On the other hand, AP positions are typically fixed, and Wi-Fi can support indoor positioning of user devices. Based on this position information, the mobile platform can check if one (or more) AP in range is rogue. The inclusion of a rogue AP would in principle result in a wrong estimated position. Thus, the idea to use different subsets of APs: the positions computed based on subsets that include a rogue AP will be significantly different from those that do not. Our scheme contains two components: subset generation and position validation. First, we generate subsets of RSSIs from APs, which are then utilized for positioning, similar to receiver autonomous integrity monitoring (RAIM). Second, the position estimates, along with uncertainties, are combined into a Gaussian mixture, to check for inconsistencies by evaluating the overlap of the Gaussian components. Our comparative analysis, conducted on a real-world dataset with three types of attacks and synthetic RSSIs integrated, demonstrates a substantial improvement in rogue AP detection accuracy.         ",
    "url": "https://arxiv.org/abs/2406.01927",
    "authors": [
      "Wenjie Liu",
      "Panos Papadimitratos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2408.08518",
    "title": "Visual-Friendly Concept Protection via Selective Adversarial Perturbations",
    "abstract": "           Personalized concept generation by tuning diffusion models with a few images raises potential legal and ethical concerns regarding privacy and intellectual property rights. Researchers attempt to prevent malicious personalization using adversarial perturbations. However, previous efforts have mainly focused on the effectiveness of protection while neglecting the visibility of perturbations. They utilize global adversarial perturbations, which introduce noticeable alterations to original images and significantly degrade visual quality. In this work, we propose the Visual-Friendly Concept Protection (VCPro) framework, which prioritizes the protection of key concepts chosen by the image owner through adversarial perturbations with lower perceptibility. To ensure these perturbations are as inconspicuous as possible, we introduce a relaxed optimization objective to identify the least perceptible yet effective adversarial perturbations, solved using the Lagrangian multiplier method. Qualitative and quantitative experiments validate that VCPro achieves a better trade-off between the visibility of perturbations and protection effectiveness, effectively prioritizing the protection of target concepts in images with less perceptible perturbations.         ",
    "url": "https://arxiv.org/abs/2408.08518",
    "authors": [
      "Xiaoyue Mi",
      "Fan Tang",
      "Juan Cao",
      "Peng Li",
      "Yang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.12010",
    "title": "Differential Confounding Privacy and Inverse Composition",
    "abstract": "           Differential privacy (DP) has become the gold standard for privacy-preserving data analysis, but its applicability can be limited in scenarios involving complex dependencies between sensitive information and datasets. To address this, we introduce \\textit{differential confounding privacy} (DCP), a specialized form of the Pufferfish privacy (PP) framework that generalizes DP by accounting for broader relationships between sensitive information and datasets. DCP adopts the $(\\epsilon, \\delta)$-indistinguishability framework to quantify privacy loss. We show that while DCP mechanisms retain privacy guarantees under composition, they lack the graceful compositional properties of DP. To overcome this, we propose an \\textit{Inverse Composition (IC)} framework, where a leader-follower model optimally designs a privacy strategy to achieve target guarantees without relying on worst-case privacy proofs, such as sensitivity calculation. Experimental results validate IC's effectiveness in managing privacy budgets and ensuring rigorous privacy guarantees under composition.         ",
    "url": "https://arxiv.org/abs/2408.12010",
    "authors": [
      "Tao Zhang",
      "Bradley A. Malin",
      "Netanel Raviv",
      "Yevgeniy Vorobeychik"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2409.18118",
    "title": "Slowly Scaling Per-Record Differential Privacy",
    "abstract": "           We develop formal privacy mechanisms for releasing statistics from data with many outlying values, such as income data. These mechanisms ensure that a per-record differential privacy guarantee degrades slowly in the protected records' influence on the statistics being released. Formal privacy mechanisms generally add randomness, or \"noise,\" to published statistics. If a noisy statistic's distribution changes little with the addition or deletion of a single record in the underlying dataset, an attacker looking at this statistic will find it plausible that any particular record was present or absent, preserving the records' privacy. More influential records -- those whose addition or deletion would change the statistics' distribution more -- typically suffer greater privacy loss. The per-record differential privacy framework quantifies these record-specific privacy guarantees, but existing mechanisms let these guarantees degrade rapidly (linearly or quadratically) with influence. While this may be acceptable in cases with some moderately influential records, it results in unacceptably high privacy losses when records' influence varies widely, as is common in economic data. We develop mechanisms with privacy guarantees that instead degrade as slowly as logarithmically with influence. These mechanisms allow for the accurate, unbiased release of statistics, while providing meaningful protection for highly influential records. As an example, we consider the private release of sums of unbounded establishment data such as payroll, where our mechanisms extend meaningful privacy protection even to very large establishments. We evaluate these mechanisms empirically and demonstrate their utility.         ",
    "url": "https://arxiv.org/abs/2409.18118",
    "authors": [
      "Brian Finley",
      "Anthony M Caruso",
      "Justin C Doty",
      "Ashwin Machanavajjhala",
      "Mikaela R Meyer",
      "David Pujol",
      "William Sexton",
      "Zachary Terner"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2410.06126",
    "title": "$X^2$-DFD: A framework for eXplainable and eXtendable Deepfake Detection",
    "abstract": "           Detecting deepfakes has become an important task. Most existing detection methods provide only real/fake predictions without offering human-comprehensible explanations. Recent studies leveraging MLLMs for deepfake detection have shown improvements in explainability. However, the performance of pre-trained MLLMs (e.g., LLaVA) remains limited due to a lack of understanding of their capabilities for this task and strategies to enhance them. In this work, we empirically assess the strengths and weaknesses of MLLMs specifically in deepfake detection via forgery features analysis. Building on these assessments, we propose a novel framework called ${X}^2$-DFD, consisting of three core modules. The first module, Model Feature Assessment (MFA), measures the detection capabilities of forgery features intrinsic to MLLMs, and gives a descending ranking of these features. The second module, Strong Feature Strengthening (SFS), enhances the detection and explanation capabilities by fine-tuning the MLLM on a dataset constructed based on the top-ranked features. The third module, Weak Feature Supplementing (WFS), improves the fine-tuned MLLM's capabilities on lower-ranked features by integrating external dedicated deepfake detectors. To verify the effectiveness of this framework, we further present a practical implementation, where an automated forgery features generation, evaluation, and ranking procedure is designed for MFA module; an automated generation procedure of the fine-tuning dataset containing real and fake images with explanations based on top-ranked features is developed for SFS model; an external conventional deepfake detector focusing on blending artifact, which corresponds to a low detection capability in the pre-trained MLLM, is integrated for WFS module. Experiments show that our approach enhances both detection and explanation performance.         ",
    "url": "https://arxiv.org/abs/2410.06126",
    "authors": [
      "Yize Chen",
      "Zhiyuan Yan",
      "Siwei Lyu",
      "Baoyuan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2410.16481",
    "title": "Caging in Time: A Framework for Robust Object Manipulation under Uncertainties and Limited Robot Perception",
    "abstract": "           Real-world object manipulation has been commonly challenged by physical uncertainties and perception limitations. Being an effective strategy, while caging configuration-based manipulation frameworks have successfully provided robust solutions, they are not broadly applicable due to their strict requirements on the availability of multiple robots, widely distributed contacts, or specific geometries of robots or objects. Building upon previous sensorless manipulation ideas and uncertainty handling approaches, this work proposes a novel framework termed Caging in Time to allow caging configurations to be formed even with one robot engaged in a task. This concept leverages the insight that while caging requires constraining the object's motion, only part of the cage actively contacts the object at any moment. As such, by strategically switching the end-effector configuration and collapsing it in time, we form a cage with its necessary portion active whenever needed. We instantiate our approach on challenging quasi-static and dynamic manipulation tasks, showing that Caging in Time can be achieved in general cage formulations including geometry-based and energy-based cages. With extensive experiments, we show robust and accurate manipulation, in an open-loop manner, without requiring detailed knowledge of the object geometry or physical properties, or real-time accurate feedback on the manipulation states. In addition to being an effective and robust open-loop manipulation solution, Caging in Time can be a supplementary strategy to other manipulation systems affected by uncertain or limited robot perception.         ",
    "url": "https://arxiv.org/abs/2410.16481",
    "authors": [
      "Gaotian Wang",
      "Kejia Ren",
      "Andrew S. Morgan",
      "Kaiyu Hang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2411.06360",
    "title": "An Efficient Matrix Multiplication Algorithm for Accelerating Inference in Binary and Ternary Neural Networks",
    "abstract": "           Despite their tremendous success and versatility, Deep Neural Networks (DNNs) such as Large Language Models (LLMs) suffer from inference inefficiency and rely on advanced computational infrastructure. To address these challenges and make these models more accessible and cost-effective, in this paper, we propose algorithms to improve the inference time and memory efficiency of DNNs with binary and ternary weight matrices. Particularly focusing on matrix multiplication as the bottleneck operation of inference, we observe that, once trained, the weight matrices of a model no longer change. This allows us to preprocess these matrices and create indices that help reduce the storage requirements by a logarithmic factor while enabling our efficient inference algorithms. Specifically, for a $n\\times n$ weight matrix, our efficient algorithm guarantees a time complexity of $O(\\frac{n^2}{\\log n})$, a logarithmic factor improvement over the standard vector-matrix multiplication. Besides theoretical analysis, we conduct extensive experiments to evaluate the practical efficiency of our algorithms. Our results confirm the superiority of our approach both with respect to time and memory, as we observed a reduction in the multiplication time up to 29x and memory usage up to 6x. When applied to LLMs, our experiments show up to a 5.24x speedup in the inference time.         ",
    "url": "https://arxiv.org/abs/2411.06360",
    "authors": [
      "Mohsen Dehghankar",
      "Mahdi Erfanian",
      "Abolfazl Asudeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2411.12150",
    "title": "HEIGHT: Heterogeneous Interaction Graph Transformer for Robot Navigation in Crowded and Constrained Environments",
    "abstract": "           We study the problem of robot navigation in dense and interactive crowds with environmental constraints such as corridors and furniture. Previous methods fail to consider all types of interactions among agents and obstacles, leading to unsafe and inefficient robot paths. In this article, we leverage a graph-based representation of crowded and constrained scenarios and propose a structured framework to learn robot navigation policies with deep reinforcement learning. We first split the representations of different components in the environment and propose a heterogeneous spatio-temporal (st) graph to model distinct interactions among humans, robots, and obstacles. Based on the heterogeneous st-graph, we propose HEIGHT, a novel navigation policy network architecture with different components to capture heterogeneous interactions among entities through space and time. HEIGHT utilizes attention mechanisms to prioritize important interactions and a recurrent network to track changes in the dynamic scene over time, encouraging the robot to avoid collisions adaptively. Through extensive simulation and real-world experiments, we demonstrate that HEIGHT outperforms state-of-the-art baselines in terms of success and efficiency in challenging navigation scenarios. Furthermore, we demonstrate that our pipeline achieves better zero-shot generalization capability than previous works when the densities of humans and obstacles change. More videos are available at this https URL.         ",
    "url": "https://arxiv.org/abs/2411.12150",
    "authors": [
      "Shuijing Liu",
      "Haochen Xia",
      "Fatemeh Cheraghi Pouria",
      "Kaiwen Hong",
      "Neeloy Chakraborty",
      "Zichao Hu",
      "Joydeep Biswas",
      "Katherine Driggs-Campbell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2411.17662",
    "title": "RoboPEPP: Vision-Based Robot Pose and Joint Angle Estimation through Embedding Predictive Pre-Training",
    "abstract": "           Vision-based pose estimation of articulated robots with unknown joint angles has applications in collaborative robotics and human-robot interaction tasks. Current frameworks use neural network encoders to extract image features and downstream layers to predict joint angles and robot pose. While images of robots inherently contain rich information about the robot's physical structures, existing methods often fail to leverage it fully; therefore, limiting performance under occlusions and truncations. To address this, we introduce RoboPEPP, a method that fuses information about the robot's physical model into the encoder using a masking-based self-supervised embedding-predictive architecture. Specifically, we mask the robot's joints and pre-train an encoder-predictor model to infer the joints' embeddings from surrounding unmasked regions, enhancing the encoder's understanding of the robot's physical model. The pre-trained encoder-predictor pair, along with joint angle and keypoint prediction networks, is then fine-tuned for pose and joint angle estimation. Random masking of input during fine-tuning and keypoint filtering during evaluation further improves robustness. Our method, evaluated on several datasets, achieves the best results in robot pose and joint angle estimation while being the least sensitive to occlusions and requiring the lowest execution time.         ",
    "url": "https://arxiv.org/abs/2411.17662",
    "authors": [
      "Raktim Gautam Goswami",
      "Prashanth Krishnamurthy",
      "Yann LeCun",
      "Farshad Khorrami"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2412.07446",
    "title": "A Causal World Model Underlying Next Token Prediction: Exploring GPT in a Controlled Environment",
    "abstract": "           Do generative pre-trained transformer (GPT) models, trained only to predict the next token, implicitly learn a world model from which a sequence is generated one token at a time? We address this question by deriving a causal interpretation of the attention mechanism in GPT, and suggesting a causal world model that arises from this interpretation. Furthermore, we propose that GPT models, at inference time, can be utilized for zero-shot causal structure learning for input sequences and present a confidence score. Empirical evaluation is conducted in a controlled environment using the setup and rules of the Othello and Chess strategy games. A GPT, pre-trained on real-world games played with the intention of winning, is tested on out-of-distribution synthetic data consisting of sequences of random legal moves. We find that the GPT model is likely to generate legal next moves for out-of-distribution sequences for which a causal structure is encoded in the attention mechanism with high confidence. In cases for which the GPT model generates illegal moves it also fails to capture any causal structure.         ",
    "url": "https://arxiv.org/abs/2412.07446",
    "authors": [
      "Raanan Y. Rohekar",
      "Yaniv Gurwicz",
      "Sungduk Yu",
      "Estelle Aflalo",
      "Vasudev Lal"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2501.06382",
    "title": "Dynamics of Spontaneous Topic Changes in Next Token Prediction with Self-Attention",
    "abstract": "           Human cognition is punctuated by abrupt, spontaneous shifts between topics-driven by emotional, contextual, or associative cues-a phenomenon known as spontaneous thought in neuroscience. In contrast, self-attention based models depend on structured patterns over their inputs to predict each next token, lacking spontaneity. Motivated by this distinction, we characterize spontaneous topic changes in self-attention architectures, revealing both their similarities and their divergences from spontaneous human thought. First, we establish theoretical results under a simplified, single-layer self-attention model with suitable conditions by defining the topic as a set of Token Priority Graphs (TPGs). Specifically, we demonstrate that (1) the model maintains the priority order of tokens related to the input topic, (2) a spontaneous topic change can occur only if lower-priority tokens outnumber all higher-priority tokens of the input topic, and (3) unlike human cognition, the longer context length or the more ambiguous input topic reduces the likelihood of spontaneous change. Second, we empirically validate that these dynamics persist in modern, state-of-the-art LLMs, underscoring a fundamental disparity between human cognition and AI behaviour in the context of spontaneous topic changes. To the best of our knowledge, no prior work has explored these questions with a focus as closely aligned to human thought.         ",
    "url": "https://arxiv.org/abs/2501.06382",
    "authors": [
      "Mumin Jia",
      "Jairo Diaz-Rodriguez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2501.08324",
    "title": "ADAM: An AI Reasoning and Bioinformatics Model for Alzheimer's Disease Detection and Microbiome-Clinical Data Integration",
    "abstract": "           Alzheimer's Disease Analysis Model (ADAM) is a multi-agent reasoning large language model (LLM) framework designed to integrate and analyze multimodal data, including microbiome profiles, clinical datasets, and external knowledge bases, to enhance the understanding and classification of Alzheimer's disease (AD). By leveraging the agentic system with LLM, ADAM produces insights from diverse data sources and contextualizes the findings with literature-driven evidence. A comparative evaluation with XGBoost revealed a significantly improved mean F1 score and significantly reduced variance for ADAM, highlighting its robustness and consistency, particularly when utilizing human biological data. Although currently tailored for binary classification tasks with two data modalities, future iterations will aim to incorporate additional data types, such as neuroimaging and peripheral biomarkers, and expand them to predict disease progression, thereby broadening ADAM's scalability and applicability in AD research and diagnostic applications.         ",
    "url": "https://arxiv.org/abs/2501.08324",
    "authors": [
      "Ziyuan Huang",
      "Vishaldeep Kaur Sekhon",
      "Roozbeh Sadeghian",
      "Maria L. Vaida",
      "Cynthia Jo",
      "Doyle Ward",
      "Vanni Bucci",
      "John P. Haran"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2501.13298",
    "title": "Collaborative Coded Caching for Partially Connected Networks",
    "abstract": "           Coded caching leverages the differences in user cache memories to achieve gains that scale with the total cache size, alleviating network congestion due to high-quality content requests. Additionally, distributing transmitters over a wide area can mitigate the adverse effects of path loss. In this work, we consider a partially connected network where the channel between distributed transmitters (helpers) and users is modeled as a distributed multiple-input-multiple-output (MIMO) Gaussian broadcast channel. We propose a novel delivery scheme consisting of two phases: partitioning and transmission. In the partitioning phase, users with identical cache profiles are partitioned into the minimum number of sets, such that users within each set can successfully decode their desired message from a joint transmission enabled by MIMO precoding. To optimally partition the users, we employ the branch and bound method. In the transmission phase, each partition is treated as a single entity, and codewords are multicast to partitions with distinct cache profiles. The proposed delivery scheme is applicable to any partially connected network, and while the partitioning is optimal, the overall delivery scheme, including transmission, is heuristic. Interestingly, simulation results show that its performance closely approximates that of the fully connected optimal solution.         ",
    "url": "https://arxiv.org/abs/2501.13298",
    "authors": [
      "Kagan Akcay",
      "Eleftherios Lampiris",
      "MohammadJavad Salehi",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2501.18851",
    "title": "Project-and-Fuse: Improving RGB-D Semantic Segmentation via Graph Convolution Networks",
    "abstract": "           Most existing RGB-D semantic segmentation methods focus on the feature level fusion, including complex cross-modality and cross-scale fusion modules. However, these methods may cause misalignment problem in the feature fusion process and counter-intuitive patches in the segmentation results. Inspired by the popular pixel-node-pixel pipeline, we propose to 1) fuse features from two modalities in a late fusion style, during which the geometric feature injection is guided by texture feature prior; 2) employ Graph Neural Networks (GNNs) on the fused feature to alleviate the emergence of irregular patches by inferring patch relationship. At the 3D feature extraction stage, we argue that traditional CNNs are not efficient enough for depth maps. So, we encode depth map into normal map, after which CNNs can easily extract object surface this http URL projection matrix generation stage, we find the existence of Biased-Assignment and Ambiguous-Locality issues in the original pipeline. Therefore, we propose to 1) adopt the Kullback-Leibler Loss to ensure no missing important pixel features, which can be viewed as hard pixel mining process; 2) connect regions that are close to each other in the Euclidean space as well as in the semantic space with larger edge weights so that location informations can been considered. Extensive experiments on two public datasets, NYU-DepthV2 and SUN RGB-D, have shown that our approach can consistently boost the performance of RGB-D semantic segmentation task.         ",
    "url": "https://arxiv.org/abs/2501.18851",
    "authors": [
      "Xiaoyan Jiang",
      "Bohan Wang",
      "Xinlong Wan",
      "Shanshan Chen",
      "Hamido Fujita",
      "Hanan Abd.Al Juaid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2502.03963",
    "title": "AL-PINN: Active Learning-Driven Physics-Informed Neural Networks for Efficient Sample Selection in Solving Partial Differential Equations",
    "abstract": "           Physics-Informed Neural Networks (PINNs) have emerged as a promising approach for solving Partial Differential Equations (PDEs) by incorporating physical constraints into deep learning models. However, standard PINNs often require a large number of training samples to achieve high accuracy, leading to increased computational costs. To address this issue, we propose Active Learning-Driven PINNs (AL-PINN), which integrates Uncertainty Quantification (UQ) and Active Learning (AL) strategies to optimize sample selection dynamically. AL-PINN utilizes Monte Carlo Dropout to estimate epistemic uncertainty in the model predictions, enabling the adaptive selection of high-uncertainty regions for additional training. This approach significantly enhances learning efficiency by focusing computational resources on the most informative data points. We evaluate AL-PINN on benchmark PDE problems with known analytical solutions and real-world WeatherBench climate data. Our results demonstrate that AL-PINN achieves comparable or superior accuracy compared to traditional PINNs while reducing the number of required training samples. The proposed framework is particularly beneficial for scientific and engineering applications where data collection is expensive or limited, such as climate modeling, medical simulations, and material science. Our findings highlight the potential of active learning in accelerating PINN-based PDE solvers while maintaining high accuracy and computational efficiency.         ",
    "url": "https://arxiv.org/abs/2502.03963",
    "authors": [
      "Keon Vin Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.05088",
    "title": "Nonlinear manifold approximation using compositional polynomial networks",
    "abstract": "           We consider the problem of approximating a subset $M$ of a Hilbert space $X$ by a low-dimensional manifold $M_n$, using samples from $M$. We propose a nonlinear approximation method where $M_n $ is defined as the range of a smooth nonlinear decoder $D$ defined on $\\mathbb{R}^n$ with values in a possibly high-dimensional linear space $X_N$, and a linear encoder $E$ which associates to an element from $ M$ its coefficients $E(u)$ on a basis of a $n$-dimensional subspace $X_n \\subset X_N$, where $X_n$ and $X_N$ are optimal or near to optimal linear spaces, depending on the selected error measure. The linearity of the encoder allows to easily obtain the parameters $E(u)$ associated with a given element $u$ in $M$. The proposed decoder is a polynomial map from $\\mathbb{R}^n$ to $X_N$ which is obtained by a tree-structured composition of polynomial maps, estimated sequentially from samples in $M$. Rigorous error and stability analyses are provided, as well as an adaptive strategy for constructing a decoder that guarantees an approximation of the set $M$ with controlled mean-squared or wort-case errors, and a controlled stability (Lipschitz continuity) of the encoder and decoder pair. We demonstrate the performance of our method through numerical experiments.         ",
    "url": "https://arxiv.org/abs/2502.05088",
    "authors": [
      "Antoine Bensalah",
      "Anthony Nouy",
      "Joel Soffo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2502.05174",
    "title": "MELON: Provable Indirect Prompt Injection Defense via Masked Re-execution and Tool Comparison",
    "abstract": "           Recent research has explored that LLM agents are vulnerable to indirect prompt injection (IPI) attacks, where malicious tasks embedded in tool-retrieved information can redirect the agent to take unauthorized actions. Existing defenses against IPI have significant limitations: either require essential model training resources, lack effectiveness against sophisticated attacks, or harm the normal utilities. We present MELON (Masked re-Execution and TooL comparisON), a novel IPI defense. Our approach builds on the observation that under a successful attack, the agent's next action becomes less dependent on user tasks and more on malicious tasks. Following this, we design MELON to detect attacks by re-executing the agent's trajectory with a masked user prompt modified through a masking function. We identify an attack if the actions generated in the original and masked executions are similar. We also include three key designs to reduce the potential false positives and false negatives. Extensive evaluation on the IPI benchmark AgentDojo demonstrates that MELON outperforms SOTA defenses in both attack prevention and utility preservation. Moreover, we show that combining MELON with a SOTA prompt augmentation defense (denoted as MELON-Aug) further improves its performance. We also conduct a detailed ablation study to validate our key designs.         ",
    "url": "https://arxiv.org/abs/2502.05174",
    "authors": [
      "Kaijie Zhu",
      "Xianjun Yang",
      "Jindong Wang",
      "Wenbo Guo",
      "William Yang Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.07425",
    "title": "Towards a Foundation Model for Physics-Informed Neural Networks: Multi-PDE Learning with Active Sampling",
    "abstract": "           Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework for solving partial differential equations (PDEs) by embedding physical laws into neural network training. However, traditional PINN models are typically designed for single PDEs, limiting their generalizability across different physical systems. In this work, we explore the potential of a foundation PINN model capable of solving multiple PDEs within a unified architecture. We investigate the efficacy of a single PINN framework trained on four distinct PDEs-the Simple Harmonic Oscillator (SHO), the 1D Heat Equation, the 1D Wave Equation, and the 2D Laplace Equation, demonstrating its ability to learn diverse physical dynamics. To enhance sample efficiency, we incorporate Active Learning (AL) using Monte Carlo (MC) Dropout-based uncertainty estimation, selecting the most informative training samples iteratively. We evaluate different active learning strategies, comparing models trained on 10%, 20%, 30%, 40%, and 50% of the full dataset, and analyze their impact on solution accuracy. Our results indicate that targeted uncertainty sampling significantly improves performance with fewer training samples, leading to efficient learning across multiple PDEs. This work highlights the feasibility of a generalizable PINN-based foundation model, capable of adapting to different physics-based problems without redesigning network architectures. Our findings suggest that multi-PDE PINNs with active learning can serve as an effective approach for reducing computational costs while maintaining high accuracy in physics-based deep learning applications.         ",
    "url": "https://arxiv.org/abs/2502.07425",
    "authors": [
      "Keon Vin Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.15507",
    "title": "Activation Steering in Neural Theorem Provers",
    "abstract": "           Large Language Models (LLMs) have shown promise in proving formal theorems using proof assistants like Lean. However, current state of the art language models struggles to predict next step in proofs leading practitioners to use different sampling techniques to improve LLMs capabilities. We observe that the LLM is capable of predicting the correct tactic; however, it faces challenges in ranking it appropriately within the set of candidate tactics, affecting the overall selection process. To overcome this hurdle, we use activation steering to guide LLMs responses to improve the generations at the time of inference. Our results suggest that activation steering offers a promising lightweight alternative to specialized fine-tuning for enhancing theorem proving capabilities in LLMs, particularly valuable in resource-constrained environments.         ",
    "url": "https://arxiv.org/abs/2502.15507",
    "authors": [
      "Shashank Kirtania"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2502.18826",
    "title": "Adversarial Combinatorial Semi-bandits with Graph Feedback",
    "abstract": "           In combinatorial semi-bandits, a learner repeatedly selects from a combinatorial decision set of arms, receives the realized sum of rewards, and observes the rewards of the individual selected arms as feedback. In this paper, we extend this framework to include \\emph{graph feedback}, where the learner observes the rewards of all neighboring arms of the selected arms in a feedback graph $G$. We establish that the optimal regret over a time horizon $T$ scales as $\\widetilde{\\Theta}(S\\sqrt{T}+\\sqrt{\\alpha ST})$, where $S$ is the size of the combinatorial decisions and $\\alpha$ is the independence number of $G$. This result interpolates between the known regrets $\\widetilde\\Theta(S\\sqrt{T})$ under full information (i.e., $G$ is complete) and $\\widetilde\\Theta(\\sqrt{KST})$ under the semi-bandit feedback (i.e., $G$ has only self-loops), where $K$ is the total number of arms. A key technical ingredient is to realize a convexified action using a random decision vector with negative correlations. We also show that online stochastic mirror descent (OSMD) that only realizes convexified actions in expectation is suboptimal.         ",
    "url": "https://arxiv.org/abs/2502.18826",
    "authors": [
      "Yuxiao Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2503.01284",
    "title": "Soybean Disease Detection via Interpretable Hybrid CNN-GNN: Integrating MobileNetV2 and GraphSAGE with Cross-Modal Attention",
    "abstract": "           Soybean leaf disease detection is critical for agricultural productivity but faces challenges due to visually similar symptoms and limited interpretability in conventional methods. While Convolutional Neural Networks (CNNs) excel in spatial feature extraction, they often neglect inter-image relational dependencies, leading to misclassifications. This paper proposes an interpretable hybrid Sequential CNN-Graph Neural Network (GNN) framework that synergizes MobileNetV2 for localized feature extraction and GraphSAGE for relational modeling. The framework constructs a graph where nodes represent leaf images, with edges defined by cosine similarity-based adjacency matrices and adaptive neighborhood sampling. This design captures fine-grained lesion features and global symptom patterns, addressing inter-class similarity challenges. Cross-modal interpretability is achieved via Grad-CAM and Eigen-CAM visualizations, generating heatmaps to highlight disease-influential regions. Evaluated on a dataset of ten soybean leaf diseases, the model achieves $97.16\\%$ accuracy, surpassing standalone CNNs ($\\le95.04\\%$) and traditional machine learning models ($\\le77.05\\%$). Ablation studies validate the sequential architecture's superiority over parallel or single-model configurations. With only 2.3 million parameters, the lightweight MobileNetV2-GraphSAGE combination ensures computational efficiency, enabling real-time deployment in resource-constrained environments. The proposed approach bridges the gap between accurate classification and practical applicability, offering a robust, interpretable tool for agricultural diagnostics while advancing CNN-GNN integration in plant pathology research.         ",
    "url": "https://arxiv.org/abs/2503.01284",
    "authors": [
      "Md Abrar Jahin",
      "Soudeep Shahriar",
      "M. F. Mridha",
      "Md. Jakir Hossen",
      "Nilanjan Dey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.09022",
    "title": "Prompt Inversion Attack against Collaborative Inference of Large Language Models",
    "abstract": "           Large language models (LLMs) have been widely applied for their remarkable capability of content generation. However, the practical use of open-source LLMs is hindered by high resource requirements, making deployment expensive and limiting widespread development. The collaborative inference is a promising solution for this problem, in which users collaborate by each hosting a subset of layers and transmitting intermediate activation. Many companies are building collaborative inference platforms to reduce LLM serving costs, leveraging users' underutilized GPUs. Despite widespread interest in collaborative inference within academia and industry, the privacy risks associated with LLM collaborative inference have not been well studied. This is largely because of the challenge posed by inverting LLM activation due to its strong non-linearity. In this paper, to validate the severity of privacy threats in LLM collaborative inference, we introduce the concept of prompt inversion attack (PIA), where a malicious participant intends to recover the input prompt through the activation transmitted by its previous participant. Extensive experiments show that our PIA method substantially outperforms existing baselines. For example, our method achieves an 88.4\\% token accuracy on the Skytrax dataset with the Llama-65B model when inverting the maximum number of transformer layers, while the best baseline method only achieves 22.8\\% accuracy. The results verify the effectiveness of our PIA attack and highlights its practical threat to LLM collaborative inference systems.         ",
    "url": "https://arxiv.org/abs/2503.09022",
    "authors": [
      "Wenjie Qu",
      "Yuguang Zhou",
      "Yongji Wu",
      "Tingsong Xiao",
      "Binhang Yuan",
      "Yiming Li",
      "Jiaheng Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2503.12623",
    "title": "MAVEN: Multi-modal Attention for Valence-Arousal Emotion Network",
    "abstract": "           Dynamic emotion recognition in the wild remains challenging due to the transient nature of emotional expressions and temporal misalignment of multi-modal cues. Traditional approaches predict valence and arousal and often overlook the inherent correlation between these two dimensions. The proposed Multi-modal Attention for Valence-Arousal Emotion Network (MAVEN) integrates visual, audio, and textual modalities through a bi-directional cross-modal attention mechanism. MAVEN uses modality-specific encoders to extract features from synchronized video frames, audio segments, and transcripts, predicting emotions in polar coordinates following Russell's circumplex model. The evaluation of the Aff-Wild2 dataset using MAVEN achieved a concordance correlation coefficient (CCC) of 0.3061, surpassing the ResNet-50 baseline model with a CCC of 0.22. The multistage architecture captures the subtle and transient nature of emotional expressions in conversational videos and improves emotion recognition in real-world situations. The code is available at: this https URL ",
    "url": "https://arxiv.org/abs/2503.12623",
    "authors": [
      "Vrushank Ahire",
      "Kunal Shah",
      "Mudasir Nazir Khan",
      "Nikhil Pakhale",
      "Lownish Rai Sookha",
      "M. A. Ganaie",
      "Abhinav Dhall"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2503.12994",
    "title": "Conversation-Based Multimodal Abuse Detection Through Text and Graph Embeddings",
    "abstract": "           Abusive behavior is common on online social networks, and forces the hosts of such platforms to find new solutions to address this problem. Various methods have been proposed to automate this task in the past decade. Most of them rely on the exchanged content, but ignore the structure and dynamics of the conversation, which could provide some relevant information. In this article, we propose to use representation learning methods to automatically produce embeddings of this textual content and of the conversational graphs depicting message exchanges. While the latter could be enhanced by including additional information on top of the raw conversational structure, no method currently exists to learn wholegraph representations using simultaneously edge directions, weights, signs, and vertex attributes. We propose two such methods to fill this gap in the literature. We experiment with 5 textual and 13 graph embedding methods, and apply them to a dataset of online messages annotated for abuse detection. Our best results achieve an F -measure of 81.02 using text alone and 80.61 using graphs alone. We also combine both modalities of information (text and graphs) through three fusion strategies, and show that this strongly improves abuse detection performance, increasing the F -measure to 87.06. Finally, we identify which specific engineered features are captured by the embedding methods under consideration. These features have clear interpretations and help explain what information the representation learning methods deem discriminative.         ",
    "url": "https://arxiv.org/abs/2503.12994",
    "authors": [
      "No\u00e9 Cecillon",
      "Vincent Labatut",
      "Richard Dufour"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2503.14877",
    "title": "Synthesizing Grid Data with Cyber Resilience and Privacy Guarantees",
    "abstract": "           Differential privacy (DP) provides a principled approach to synthesizing data (e.g., loads) from real-world power systems while limiting the exposure of sensitive information. However, adversaries may exploit synthetic data to calibrate cyberattacks on the source grids. To control these risks, we propose new DP algorithms for synthesizing data that provide the source grids with both cyber resilience and privacy guarantees. The algorithms incorporate both normal operation and attack optimization models to balance the fidelity of synthesized data and cyber resilience. The resulting post-processing optimization is reformulated as a robust optimization problem, which is compatible with the exponential mechanism of DP to moderate its computational burden.         ",
    "url": "https://arxiv.org/abs/2503.14877",
    "authors": [
      "Shengyang Wu",
      "Vladimir Dvorkin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2503.20331",
    "title": "WiCross: Indoor Human Zone-Crossing Detection Using Commodity WiFi Devices",
    "abstract": "           Detecting whether a target crosses the given zone (e.g., a door) can enable various practical applications in smart homes, including intelligent security and people counting. The traditional infrared-based approach only covers a line and can be easily cracked. In contrast, reusing the ubiquitous WiFi devices deployed in homes has the potential to cover a larger area of interest as WiFi signals are scattered throughout the entire space. By detecting the walking direction (i.e., approaching and moving away) with WiFi signal strength change, existing work can identify the behavior of crossing between WiFi transceiver pair. However, this method mistakenly classifies the turn-back behavior as crossing behavior, resulting in a high false alarm rate. In this paper, we propose WiCross, which can accurately distinguish the turn-back behavior with the phase statistics pattern of WiFi signals and thus robustly identify whether the target crosses the area between the WiFi transceiver pair. We implement WiCross with commercial WiFi devices and extensive experiments demonstrate that WiCross can achieve an accuracy higher than 95\\% with a false alarm rate of less than 5%.         ",
    "url": "https://arxiv.org/abs/2503.20331",
    "authors": [
      "Weiyan Shi",
      "Xuanzhi Wang",
      "Kai Niu",
      "Leye Wang",
      "Daqing Zhang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2504.09149",
    "title": "MASH: Masked Anchored SpHerical Distances for 3D Shape Representation and Generation",
    "abstract": "           We introduce Masked Anchored SpHerical Distances (MASH), a novel multi-view and parametrized representation of 3D shapes. Inspired by multi-view geometry and motivated by the importance of perceptual shape understanding for learning 3D shapes, MASH represents a 3D shape as a collection of observable local surface patches, each defined by a spherical distance function emanating from an anchor point. We further leverage the compactness of spherical harmonics to encode the MASH functions, combined with a generalized view cone with a parameterized base that masks the spatial extent of the spherical function to attain locality. We develop a differentiable optimization algorithm capable of converting any point cloud into a MASH representation accurately approximating ground-truth surfaces with arbitrary geometry and topology. Extensive experiments demonstrate that MASH is versatile for multiple applications including surface reconstruction, shape generation, completion, and blending, achieving superior performance thanks to its unique representation encompassing both implicit and explicit features.         ",
    "url": "https://arxiv.org/abs/2504.09149",
    "authors": [
      "Changhao Li",
      "Yu Xin",
      "Xiaowei Zhou",
      "Ariel Shamir",
      "Hao Zhang",
      "Ligang Liu",
      "Ruizhen Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2504.12561",
    "title": "Kernel Ridge Regression for Efficient Learning of High-Capacity Hopfield Networks",
    "abstract": "           Hopfield networks using Hebbian learning suffer from limited storage capacity. While supervised methods like Linear Logistic Regression (LLR) offer some improvement, kernel methods like Kernel Logistic Regression (KLR) significantly enhance capacity and noise robustness. However, KLR requires computationally expensive iterative learning. We propose Kernel Ridge Regression (KRR) as an efficient kernel-based alternative for learning high-capacity Hopfield networks. KRR utilizes the kernel trick and predicts bipolar states via regression, crucially offering a non-iterative, closed-form solution for learning dual variables. We evaluate KRR and compare its performance against Hebbian, LLR, and KLR. Our results demonstrate that KRR achieves state-of-the-art storage capacity (reaching $\\beta$=1.5) and noise robustness, comparable to KLR. Crucially, KRR drastically reduces training time, being orders of magnitude faster than LLR and significantly faster than KLR, especially at higher storage loads. This establishes KRR as a potent and highly efficient method for building high-performance associative memories, providing comparable performance to KLR with substantial training speed advantages. This work provides the first empirical comparison between KRR and KLR in the context of Hopfield network learning.         ",
    "url": "https://arxiv.org/abs/2504.12561",
    "authors": [
      "Akira Tamamori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2504.14204",
    "title": "DConAD: A Differencing-based Contrastive Representation Learning Framework for Time Series Anomaly Detection",
    "abstract": "           Time series anomaly detection holds notable importance for risk identification and fault detection across diverse application domains. Unsupervised learning methods have become popular because they have no requirement for labels. However, due to the challenges posed by the multiplicity of abnormal patterns, the sparsity of anomalies, and the growth of data scale and complexity, these methods often fail to capture robust and representative dependencies within the time series for identifying anomalies. To enhance the ability of models to capture normal patterns of time series and avoid the retrogression of modeling ability triggered by the dependencies on high-quality prior knowledge, we propose a differencing-based contrastive representation learning framework for time series anomaly detection (DConAD). Specifically, DConAD generates differential data to provide additional information about time series and utilizes transformer-based architecture to capture spatiotemporal dependencies, which enhances the robustness of unbiased representation learning ability. Furthermore, DConAD implements a novel KL divergence-based contrastive learning paradigm that only uses positive samples to avoid deviation from reconstruction and deploys the stop-gradient strategy to compel convergence. Extensive experiments on five public datasets show the superiority and effectiveness of DConAD compared with nine baselines. The code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2504.14204",
    "authors": [
      "Wenxin Zhang",
      "Xiaojian Lin",
      "Wenjun Yu",
      "Guangzhen Yao",
      "jingxiang Zhong",
      "Yu Li",
      "Renda Han",
      "Songcheng Xu",
      "Hao Shi",
      "Cuicui Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2504.17701",
    "title": "Network Sampling: An Overview and Comparative Analysis",
    "abstract": "           Network sampling is a crucial technique for analyzing large or partially observable networks. However, the effectiveness of different sampling methods can vary significantly depending on the context. In this study, we empirically compare representative methods from three main categories: node-based, edge-based, and exploration-based sampling. We used two real-world datasets for our analysis: a scientific collaboration network and a temporal message-sending network. Our results indicate that no single sampling method consistently outperforms the others in both datasets. Although advanced methods tend to provide better accuracy on static networks, they often perform poorly on temporal networks, where simpler techniques can be more effective. These findings suggest that the best sampling strategy depends not only on the structural characteristics of the network but also on the specific metrics that need to be preserved or analyzed. Our work offers practical insights for researchers in choosing sampling approaches that are tailored to different types of networks and analytical objectives.         ",
    "url": "https://arxiv.org/abs/2504.17701",
    "authors": [
      "Quoc Chuong Nguyen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2504.18814",
    "title": "Zero-Day Botnet Attack Detection in IoV: A Modular Approach Using Isolation Forests and Particle Swarm Optimization",
    "abstract": "           The Internet of Vehicles (IoV) is transforming transportation by enhancing connectivity and enabling autonomous driving. However, this increased interconnectivity introduces new security vulnerabilities. Bot malware and cyberattacks pose significant risks to Connected and Autonomous Vehicles (CAVs), as demonstrated by real-world incidents involving remote vehicle system compromise. To address these challenges, we propose an edge-based Intrusion Detection System (IDS) that monitors network traffic to and from CAVs. Our detection model is based on a meta-ensemble classifier capable of recognizing known (Nday) attacks and detecting previously unseen (zero-day) attacks. The approach involves training multiple Isolation Forest (IF) models on Multi-access Edge Computing (MEC) servers, with each IF specialized in identifying a specific type of botnet attack. These IFs, either trained locally or shared by other MEC nodes, are then aggregated using a Particle Swarm Optimization (PSO) based stacking strategy to construct a robust meta-classifier. The proposed IDS has been evaluated on a vehicular botnet dataset, achieving an average detection rate of 92.80% for N-day attacks and 77.32% for zero-day attacks. These results highlight the effectiveness of our solution in detecting both known and emerging threats, providing a scalable and adaptive defense mechanism for CAVs within the IoV ecosystem.         ",
    "url": "https://arxiv.org/abs/2504.18814",
    "authors": [
      "Abdelaziz Amara Korba",
      "Nour Elislem Karabadji",
      "Yacine Ghamri-Doudane"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2504.18837",
    "title": "Sentiment and Social Signals in the Climate Crisis: A Survey on Analyzing Social Media Responses to Extreme Weather Events",
    "abstract": "           Extreme weather events driven by climate change, such as wildfires, floods, and heatwaves, prompt significant public reactions on social media platforms. Analyzing the sentiment expressed in these online discussions can offer valuable insights into public perception, inform policy decisions, and enhance emergency responses. Although sentiment analysis has been widely studied in various fields, its specific application to climate-induced events, particularly in real-time, high-impact situations like the 2025 Los Angeles forest fires, remains underexplored. In this survey, we thoroughly examine the methods, datasets, challenges, and ethical considerations related to sentiment analysis of social media content concerning weather and climate change events. We present a detailed taxonomy of approaches, ranging from lexicon-based and machine learning models to the latest strategies driven by large language models (LLMs). Additionally, we discuss data collection and annotation techniques, including weak supervision and real-time event tracking. Finally, we highlight several open problems, such as misinformation detection, multimodal sentiment extraction, and model alignment with human values. Our goal is to guide researchers and practitioners in effectively understanding sentiment during the climate crisis era.         ",
    "url": "https://arxiv.org/abs/2504.18837",
    "authors": [
      "Pouya Shaeri",
      "Yasaman Mohammadpour",
      "Alimohammad Beigi",
      "Ariane Middel",
      "Huan Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2504.19108",
    "title": "A Multi-Language Perspective on the Robustness of LLM Code Generation",
    "abstract": "           Large language models have gained significant traction and popularity in recent times, extending their usage to code-generation tasks. While this field has garnered considerable attention, the exploration of testing and evaluating the robustness of code generation models remains an ongoing endeavor. Previous studies have primarily focused on code generation models specifically for the Python language, overlooking other widely used programming languages. In this research, we conduct a comprehensive comparative analysis to assess the robustness performance of several prominent code generation models. Furthermore, we investigate how their performance varies across different programming languages. To accomplish this, we introduce perturbations in four key areas of the prompt: DocString, function name, syntax, and format. We have compiled and released a dedicated dataset for this purpose. This work presents our experimental findings, shedding light on the performance of code generation models in various scenarios.         ",
    "url": "https://arxiv.org/abs/2504.19108",
    "authors": [
      "Fazle Rabbi",
      "Zishuo Ding",
      "Jinqiu Yang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2504.19684",
    "title": "ClearVision: Leveraging CycleGAN and SigLIP-2 for Robust All-Weather Classification in Traffic Camera Imagery",
    "abstract": "           Adverse weather conditions challenge safe transportation, necessitating robust real-time weather detection from traffic camera imagery. We propose a novel framework combining CycleGAN-based domain adaptation with efficient contrastive learning to enhance weather classification, particularly in low-light nighttime conditions. Our approach leverages the lightweight SigLIP-2 model, which employs pairwise sigmoid loss to reduce computational demands, integrated with CycleGAN to transform nighttime images into day-like representations while preserving weather cues. Evaluated on an Iowa Department of Transportation dataset, the baseline EVA-02 model with CLIP achieves a per-class overall accuracy of 96.55\\% across three weather conditions (No Precipitation, Rain, Snow) and a day/night overall accuracy of 96.55\\%, but shows a significant day-night gap (97.21\\% day vs.\\ 63.40\\% night). With CycleGAN, EVA-02 improves to 97.01\\% per-class accuracy and 96.85\\% day/night accuracy, boosting nighttime performance to 82.45\\%. Our Vision-SigLIP-2 + Text-SigLIP-2 + CycleGAN + Contrastive configuration excels in nighttime scenarios, achieving the highest nighttime accuracy of 85.90\\%, with 94.00\\% per-class accuracy and 93.35\\% day/night accuracy. This model reduces training time by 89\\% (from 6 hours to 40 minutes) and inference time by 80\\% (from 15 seconds to 3 seconds) compared to EVA-02. By narrowing the day-night performance gap from 33.81 to 8.90 percentage points, our framework provides a scalable, efficient solution for all-weather classification using existing camera infrastructure.         ",
    "url": "https://arxiv.org/abs/2504.19684",
    "authors": [
      "Anush Lakshman Sivaraman",
      "Kojo Adu-Gyamfi",
      "Ibne Farabi Shihab",
      "Anuj Sharma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.21035",
    "title": "A False Sense of Privacy: Evaluating Textual Data Sanitization Beyond Surface-level Privacy Leakage",
    "abstract": "           Sanitizing sensitive text data typically involves removing personally identifiable information (PII) or generating synthetic data under the assumption that these methods adequately protect privacy; however, their effectiveness is often only assessed by measuring the leakage of explicit identifiers but ignoring nuanced textual markers that can lead to re-identification. We challenge the above illusion of privacy by proposing a new framework that evaluates re-identification attacks to quantify individual privacy risks upon data release. Our approach shows that seemingly innocuous auxiliary information -- such as routine social activities -- can be used to infer sensitive attributes like age or substance use history from sanitized data. For instance, we demonstrate that Azure's commercial PII removal tool fails to protect 74\\% of information in the MedQA dataset. Although differential privacy mitigates these risks to some extent, it significantly reduces the utility of the sanitized text for downstream tasks. Our findings indicate that current sanitization techniques offer a \\textit{false sense of privacy}, highlighting the need for more robust methods that protect against semantic-level information leakage.         ",
    "url": "https://arxiv.org/abs/2504.21035",
    "authors": [
      "Rui Xin",
      "Niloofar Mireshghallah",
      "Shuyue Stella Li",
      "Michael Duan",
      "Hyunwoo Kim",
      "Yejin Choi",
      "Yulia Tsvetkov",
      "Sewoong Oh",
      "Pang Wei Koh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.21357",
    "title": "Mining and Intervention of Social Networks Information Cocoon Based on Multi-Layer Network Community Detection",
    "abstract": "           With the rapid development of information technology and the widespread utilization of recommendation algorithms, users are able to access information more conveniently, while the content they receive tends to be homogeneous. Homogeneous viewpoints and preferences tend to cluster users into sub-networks, leading to group polarization and increasing the likelihood of forming information cocoons. This paper aims to handle information cocoon phenomena in debates on social media. In order to investigate potential user connections, we construct a double-layer network that incorporates two dimensions: relational ties and feature-based similarity between users. Based on the structure of the multi-layer network, we promote two graph auto-encoder (GAE) based community detection algorithms, which can be applied to the partition and determination of information cocoons. This paper tests these two algorithms on Cora, Citeseer, and synthetic datasets, comparing them with existing multi-layer network unsupervised community detection algorithms. Numerical experiments illustrate that the algorithms proposed in this paper significantly improve prediction accuracy indicator NMI (normalized mutual information) and network topology indicator Q. Additionally, an influence-based intervention measure on which algorithms can operate is proposed. Through the Markov states transition model, we simulate the intervention effects, which illustrate that our community detection algorithms play a vital role in partitioning and determining information cocoons. Simultaneously, our intervention strategy alleviates the polarization of viewpoints and the formation of information cocoons with minimal intervention effort.         ",
    "url": "https://arxiv.org/abs/2504.21357",
    "authors": [
      "Suwen Yang",
      "Lei Shi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2505.00138",
    "title": "Q Cells in Wireless Networks",
    "abstract": "           For a given set of transmitters such as cellular base stations or WiFi access points, is it possible to analytically characterize the set of locations that are \"covered\" in the sense that users at these locations experience a certain minimum quality of service? In this paper, we affirmatively answer this question, by providing explicit simple outer bounds and estimates for the coverage manifold. The key geometric elements of our analytical method are the Q cells, defined as the intersections of a small number of disks. The Q cell of a transmitter is an outer bound to the service region of the transmitter, and, in turn, the union of Q cells is an outer bound to the coverage manifold. In infinite networks, connections to the meta distribution of the signal-to-interference ratio allow for a scaling of the Q cells to obtain accurate estimates of the coverage manifold.         ",
    "url": "https://arxiv.org/abs/2505.00138",
    "authors": [
      "Martin Haenggi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2505.00296",
    "title": "The Complexity of Minimum-Envy House Allocation Over Graphs",
    "abstract": "           In this paper, we study a generalization of the House Allocation problem. In our problem, agents are represented by vertices of a graph $\\GG_{\\mathcal{A}} = (\u00c5, E_\u00c5)$, and each agent $a \\in \u00c5$ is associated with a set of preferred houses $\\PP_a \\subseteq \\HH$, where $\u00c5$ is the set of agents and $\\HH$ is the set of houses. A house allocation is an injective function $\\phi: \u00c5\\rightarrow \\HH$, and an agent $a$ envies a neighbour $a' \\in N_{\\GG_\u00c5}(a)$ under $\\phi$ if $\\phi(a) \\notin \\PP_a$ and $\\phi(a') \\in \\PP_a$. We study two natural objectives: the first problem called \\ohaa, aims to compute an allocation that minimizes the number of envious agents; the second problem called \\ohaah aims to maximize, among all minimum-envy allocations, the number of agents who are assigned a house they prefer. These two objectives capture complementary notions of fairness and individual satisfaction. We design polynomial time algorithms for both problems for the variant when each agent prefers exactly one house. On the other hand, when the list of preferred houses for each agent has size at most $2$ then we show that both problems are \\NP-hard even when the agent graph $\\GG_\u00c5$ is a complete bipartite graph. We also show that both problems are \\NP-hard even when the number $|\\mathcal H|$ of houses is equal to the number $|\\mathcal A|$ of agents. This is in contrast to the classical {\\sc House Allocation} problem, where the problem is polynomial time solvable when $|\\mathcal H| = |\\mathcal A|$. The two problems are also \\NP-hard when the agent graph has a small vertex cover. On the positive side, we design exact algorithms that exploit certain structural properties of $\\GG_\u00c5$ such as sparsity, existence of balanced separators or existence of small-sized vertex covers, and perform better than the naive brute-force algorithm.         ",
    "url": "https://arxiv.org/abs/2505.00296",
    "authors": [
      "Palash Dey",
      "Anubhav Dhar",
      "Ashlesha Hota",
      "Sudeshna Kolay"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2306.03271",
    "title": "Volumetric medical image segmentation through dual self-distillation in U-shaped networks",
    "abstract": "           U-shaped networks and its variants have demonstrated exceptional results for medical image segmentation. In this paper, we propose a novel dual self-distillation (DSD) framework in U-shaped networks for volumetric medical image segmentation. DSD distills knowledge from the ground-truth segmentation labels to the decoder layers. Additionally, DSD also distills knowledge from the deepest decoder and encoder layer to the shallower decoder and encoder layers respectively of a single U-shaped network. DSD is a general training strategy that could be attached to the backbone architecture of any U-shaped network to further improve its segmentation performance. We attached DSD on several state-of-the-art U-shaped backbones, and extensive experiments on various public 3D medical image segmentation datasets (cardiac substructure, brain tumor and Hippocampus) demonstrated significant improvement over the same backbones without DSD. On average, after attaching DSD to the U-shaped backbones, we observed an increase of 2.82\\%, 4.53\\% and 1.3\\% in Dice similarity score, a decrease of 7.15 mm, 6.48 mm and 0.76 mm in the Hausdorff distance, for cardiac substructure, brain tumor and Hippocampus segmentation, respectively. These improvements were achieved with negligible increase in the number of trainable parameters and training time. Our proposed DSD framework also led to significant qualitative improvements for cardiac substructure, brain tumor and Hippocampus segmentation over the U-shaped backbones. The source code is publicly available at this https URL.         ",
    "url": "https://arxiv.org/abs/2306.03271",
    "authors": [
      "Soumyanil Banerjee",
      "Nicholas Summerfield",
      "Ming Dong",
      "Carri Glide-Hurst"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2407.14398",
    "title": "Exponential Quantum Advantage for Pathfinding in Regular Sunflower Graphs",
    "abstract": "           Finding problems that allow for superpolynomial quantum speedup is one of the most important tasks in quantum computation. A key challenge is identifying problem structures that can only be exploited by quantum mechanics. In this paper, we find a class of graphs that allows for exponential quantum-classical separation for the pathfinding problem with the adjacency list oracle, and this class of graphs is named regular sunflower graphs. We prove that, with high probability, a regular sunflower graph of degree at least $7$ is a mild expander graph, that is, the spectral gap of the graph Laplacian is at least inverse polylogarithmic in the graph size. We provide an efficient quantum algorithm to find an $s$-$t$ path in the regular sunflower graph while any classical algorithm takes exponential time. This quantum advantage is achieved by efficiently preparing a $0$-eigenstate of the adjacency matrix of the regular sunflower graph as a quantum superposition state over the vertices, and this quantum state contains enough information to help us efficiently find an $s$-$t$ path in the regular sunflower graph. Because the security of an isogeny-based cryptosystem depends on the hardness of finding an $s$-$t$ path in an expander graph \\cite{Charles2009}, a quantum speedup of the pathfinding problem on an expander graph is of significance. Our result represents a step towards this goal as the first provable exponential speedup for pathfinding in a mild expander graph.         ",
    "url": "https://arxiv.org/abs/2407.14398",
    "authors": [
      "Jianqiang Li",
      "Yu Tong"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2409.07769",
    "title": "Mesh-based Super-Resolution of Fluid Flows with Multiscale Graph Neural Networks",
    "abstract": "           A graph neural network (GNN) approach is introduced in this work which enables mesh-based three-dimensional super-resolution of fluid flows. In this framework, the GNN is designed to operate not on the full mesh-based field at once, but on localized meshes of elements (or cells) directly. To facilitate mesh-based GNN representations in a manner similar to spectral (or finite) element discretizations, a baseline GNN layer (termed a message passing layer, which updates local node properties) is modified to account for synchronization of coincident graph nodes, rendering compatibility with commonly used element-based mesh connectivities. The architecture is multiscale in nature, and is comprised of a combination of coarse-scale and fine-scale message passing layer sequences (termed processors) separated by a graph unpooling layer. The coarse-scale processor embeds a query element (alongside a set number of neighboring coarse elements) into a single latent graph representation using coarse-scale synchronized message passing over the element neighborhood, and the fine-scale processor leverages additional message passing operations on this latent graph to correct for interpolation errors. Demonstration studies are performed using hexahedral mesh-based data from Taylor-Green Vortex and backward-facing step flow simulations at Reynolds numbers of 1600 and 3200. Through analysis of both global and local errors, the results ultimately show how the GNN is able to produce accurate super-resolved fields compared to targets in both coarse-scale and multiscale model configurations. Reconstruction errors for fixed architectures were found to increase in proportion to the Reynolds number. Geometry extrapolation studies on a separate cavity flow configuration show promising cross-mesh capabilities of the super-resolution strategy.         ",
    "url": "https://arxiv.org/abs/2409.07769",
    "authors": [
      "Shivam Barwey",
      "Pinaki Pal",
      "Saumil Patel",
      "Riccardo Balin",
      "Bethany Lusch",
      "Venkatram Vishwanath",
      "Romit Maulik",
      "Ramesh Balakrishnan"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2505.00625",
    "title": "SA-GAT-SR: Self-Adaptable Graph Attention Networks with Symbolic Regression for high-fidelity material property prediction",
    "abstract": "           Recent advances in machine learning have demonstrated an enormous utility of deep learning approaches, particularly Graph Neural Networks (GNNs) for materials science. These methods have emerged as powerful tools for high-throughput prediction of material properties, offering a compelling enhancement and alternative to traditional first-principles calculations. While the community has predominantly focused on developing increasingly complex and universal models to enhance predictive accuracy, such approaches often lack physical interpretability and insights into materials behavior. Here, we introduce a novel computational paradigm, Self-Adaptable Graph Attention Networks integrated with Symbolic Regression (SA-GAT-SR), that synergistically combines the predictive capability of GNNs with the interpretative power of symbolic regression. Our framework employs a self-adaptable encoding algorithm that automatically identifies and adjust attention weights so as to screen critical features from an expansive 180-dimensional feature space while maintaining O(n) computational scaling. The integrated SR module subsequently distills these features into compact analytical expressions that explicitly reveal quantum-mechanically meaningful relationships, achieving 23 times acceleration compared to conventional SR implementations that heavily rely on first principle calculations-derived features as input. This work suggests a new framework in computational materials science, bridging the gap between predictive accuracy and physical interpretability, offering valuable physical insights into material behavior.         ",
    "url": "https://arxiv.org/abs/2505.00625",
    "authors": [
      "Liu Junchi",
      "Tang Ying",
      "Tretiak Sergei",
      "Duan Wenhui",
      "Zhou Liujiang"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  }
]