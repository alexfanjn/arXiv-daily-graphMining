[
  {
    "id": "arXiv:2509.04458",
    "title": "Predicting Failures of LLMs to Link Biomedical Ontology Terms to Identifiers Evidence Across Models and Ontologies",
    "abstract": "           Large language models often perform well on biomedical NLP tasks but may fail to link ontology terms to their correct identifiers. We investigate why these failures occur by analyzing predictions across two major ontologies, Human Phenotype Ontology and Gene Ontology, and two high-performing models, GPT-4o and LLaMa 3.1 405B. We evaluate nine candidate features related to term familiarity, identifier usage, morphology, and ontology structure. Univariate and multivariate analyses show that exposure to ontology identifiers is the strongest predictor of linking success.         ",
    "url": "https://arxiv.org/abs/2509.04458",
    "authors": [
      "Daniel B. Hier",
      "Steven Keith Platt",
      "Tayo Obafemi-Ajayi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2509.04460",
    "title": "CoCoNUTS: Concentrating on Content while Neglecting Uninformative Textual Styles for AI-Generated Peer Review Detection",
    "abstract": "           The growing integration of large language models (LLMs) into the peer review process presents potential risks to the fairness and reliability of scholarly evaluation. While LLMs offer valuable assistance for reviewers with language refinement, there is growing concern over their use to generate substantive review content. Existing general AI-generated text detectors are vulnerable to paraphrasing attacks and struggle to distinguish between surface language refinement and substantial content generation, suggesting that they primarily rely on stylistic cues. When applied to peer review, this limitation can result in unfairly suspecting reviews with permissible AI-assisted language enhancement, while failing to catch deceptively humanized AI-generated reviews. To address this, we propose a paradigm shift from style-based to content-based detection. Specifically, we introduce CoCoNUTS, a content-oriented benchmark built upon a fine-grained dataset of AI-generated peer reviews, covering six distinct modes of human-AI collaboration. Furthermore, we develop CoCoDet, an AI review detector via a multi-task learning framework, designed to achieve more accurate and robust detection of AI involvement in review content. Our work offers a practical foundation for evaluating the use of LLMs in peer review, and contributes to the development of more precise, equitable, and reliable detection methods for real-world scholarly applications. Our code and data will be publicly available at this https URL.         ",
    "url": "https://arxiv.org/abs/2509.04460",
    "authors": [
      "Yihan Chen",
      "Jiawei Chen",
      "Guozhao Mo",
      "Xuanang Chen",
      "Ben He",
      "Xianpei Han",
      "Le Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.04461",
    "title": "From Post To Personality: Harnessing LLMs for MBTI Prediction in Social Media",
    "abstract": "           Personality prediction from social media posts is a critical task that implies diverse applications in psychology and sociology. The Myers Briggs Type Indicator (MBTI), a popular personality inventory, has been traditionally predicted by machine learning (ML) and deep learning (DL) techniques. Recently, the success of Large Language Models (LLMs) has revealed their huge potential in understanding and inferring personality traits from social media content. However, directly exploiting LLMs for MBTI prediction faces two key challenges: the hallucination problem inherent in LLMs and the naturally imbalanced distribution of MBTI types in the population. In this paper, we propose PostToPersonality (PtoP), a novel LLM based framework for MBTI prediction from social media posts of individuals. Specifically, PtoP leverages Retrieval Augmented Generation with in context learning to mitigate hallucination in LLMs. Furthermore, we fine tune a pretrained LLM to improve model specification in MBTI understanding with synthetic minority oversampling, which balances the class imbalance by generating synthetic samples. Experiments conducted on a real world social media dataset demonstrate that PtoP achieves state of the art performance compared with 10 ML and DL baselines.         ",
    "url": "https://arxiv.org/abs/2509.04461",
    "authors": [
      "Tian Ma",
      "Kaiyu Feng",
      "Yu Rong",
      "Kangfei Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2509.04485",
    "title": "ASCENDgpt: A Phenotype-Aware Transformer Model for Cardiovascular Risk Prediction from Electronic Health Records",
    "abstract": "           We present ASCENDgpt, a transformer-based model specifically designed for cardiovascular risk prediction from longitudinal electronic health records (EHRs). Our approach introduces a novel phenotype-aware tokenization scheme that maps 47,155 raw ICD codes to 176 clinically meaningful phenotype tokens, achieving 99.6\\% consolidation of diagnosis codes while preserving semantic information. This phenotype mapping contributes to a total vocabulary of 10,442 tokens - a 77.9\\% reduction when compared with using raw ICD codes directly. We pretrain ASCENDgpt on sequences derived from 19402 unique individuals using a masked language modeling objective, then fine-tune for time-to-event prediction of five cardiovascular outcomes: myocardial infarction (MI), stroke, major adverse cardiovascular events (MACE), cardiovascular death, and all-cause mortality. Our model achieves excellent discrimination on the held-out test set with an average C-index of 0.816, demonstrating strong performance across all outcomes (MI: 0.792, stroke: 0.824, MACE: 0.800, cardiovascular death: 0.842, all-cause mortality: 0.824). The phenotype-based approach enables clinically interpretable predictions while maintaining computational efficiency. Our work demonstrates the effectiveness of domain-specific tokenization and pretraining for EHR-based risk prediction tasks.         ",
    "url": "https://arxiv.org/abs/2509.04485",
    "authors": [
      "Chris Sainsbury",
      "Andreas Karwath"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.04489",
    "title": "CleanNews: a Network-aware Fake News Mitigation Architecture for Social Media",
    "abstract": "           With the widespread use of the internet and handheld devices, social media now holds a power similar to that of old newspapers. People use social media platforms for quick and accessible information. However, this convenience comes with a variety of risks. Anyone can freely post content, true or false, with the probability of remaining online forever. This makes it crucial to identify and tackle misinformation and disinformation on online platforms. In this article, we propose CleanNews, a comprehensive architecture to identify fake news in real-time accurately. CleanNews uses advanced deep learning architectures, combining convolutional and bidirectional recurrent neural networks, i.e., LSTM and GRU, layers to detect fake news. A key contribution of our work is a novel embedding technique that fuses textual information with user network structure, allowing the model to jointly learn linguistic and relational cues associated with misinformation. Furthermore, we use two network immunization algorithms, i.e., SparseShield and NetShield, to mitigate the spread of false information within networks. We conduct extensive ablation studies to evaluate the contribution of each model component and systematically tune hyperparameters to maximize performance. The experimental evaluation on two real-world datasets shows the efficacy of CleanNews in combating the spread of fake news.         ",
    "url": "https://arxiv.org/abs/2509.04489",
    "authors": [
      "Maria-Diana Cotelin",
      "Ciprian-Octavian Truic\u0103",
      "Elena-Simona Apostol"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2509.04492",
    "title": "Learned Hallucination Detection in Black-Box LLMs using Token-level Entropy Production Rate",
    "abstract": "           Hallucinations in Large Language Model (LLM) outputs for Question Answering (QA) tasks critically undermine their real-world reliability. This paper introduces an applied methodology for robust, one-shot hallucination detection, specifically designed for scenarios with limited data access, such as interacting with black-box LLM APIs that typically expose only a few top candidate log-probabilities per token. Our approach derives uncertainty indicators directly from these readily available log-probabilities generated during non-greedy decoding. We first derive an Entropy Production Rate (EPR) metric that offers baseline performance, later augmented with supervised learning. Our learned model uses features representing the entropic contributions of the accessible top-ranked tokens within a single generated sequence, requiring no multiple query re-runs. Evaluated across diverse QA datasets and multiple LLMs, this estimator significantly improves hallucination detection over using EPR alone. Crucially, high performance is demonstrated using only the typically small set of available log-probabilities (e.g., top <10 per token), confirming its practical efficiency and suitability for these API-constrained deployments. This work provides a readily deployable technique to enhance the trustworthiness of LLM responses from a single generation pass in QA and Retrieval-Augmented Generation (RAG) systems, with its utility further demonstrated in a finance framework analyzing responses to queries on annual reports from an industrial dataset.         ",
    "url": "https://arxiv.org/abs/2509.04492",
    "authors": [
      "Charles Moslonka",
      "Hicham Randrianarivo",
      "Arthur Garnier",
      "Emmanuel Malherbe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.04506",
    "title": "Memristor-Based Neural Network Accelerators for Space Applications: Enhancing Performance with Temporal Averaging and SIRENs",
    "abstract": "           Memristors are an emerging technology that enables artificial intelligence (AI) accelerators with high energy efficiency and radiation robustness -- properties that are vital for the deployment of AI on-board spacecraft. However, space applications require reliable and precise computations, while memristive devices suffer from non-idealities, such as device variability, conductance drifts, and device faults. Thus, porting neural networks (NNs) to memristive devices often faces the challenge of severe performance degradation. In this work, we show in simulations that memristor-based NNs achieve competitive performance levels on on-board tasks, such as navigation \\& control and geodesy of asteroids. Through bit-slicing, temporal averaging of NN layers, and periodic activation functions, we improve initial results from around $0.07$ to $0.01$ and $0.3$ to $0.007$ for both tasks using RRAM devices, coming close to state-of-the-art levels ($0.003-0.005$ and $0.003$, respectively). Our results demonstrate the potential of memristors for on-board space applications, and we are convinced that future technology and NN improvements will further close the performance gap to fully unlock the benefits of memristors.         ",
    "url": "https://arxiv.org/abs/2509.04506",
    "authors": [
      "Zacharia A. Rudge",
      "Dominik Dold",
      "Moritz Fieback",
      "Dario Izzo",
      "Said Hamdioui"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2509.04519",
    "title": "Hierarchical Section Matching Prediction (HSMP) BERT for Fine-Grained Extraction of Structured Data from Hebrew Free-Text Radiology Reports in Crohn's Disease",
    "abstract": "           Extracting structured clinical information from radiology reports is challenging, especially in low-resource languages. This is pronounced in Crohn's disease, with sparsely represented multi-organ findings. We developed Hierarchical Structured Matching Prediction BERT (HSMP-BERT), a prompt-based model for extraction from Hebrew radiology text. In an administrative database study, we analyzed 9,683 reports from Crohn's patients imaged 2010-2023 across Israeli providers. A subset of 512 reports was radiologist-annotated for findings across six gastrointestinal organs and 15 pathologies, yielding 90 structured labels per subject. Multilabel-stratified split (66% train+validation; 33% test), preserving label prevalence. Performance was evaluated with accuracy, F1, Cohen's $\\kappa$, AUC, PPV, NPV, and recall. On 24 organ-finding combinations with $>$15 positives, HSMP-BERT achieved mean F1 0.83$\\pm$0.08 and $\\kappa$ 0.65$\\pm$0.17, outperforming the SMP zero-shot baseline (F1 0.49$\\pm$0.07, $\\kappa$ 0.06$\\pm$0.07) and standard fine-tuning (F1 0.30$\\pm$0.27, $\\kappa$ 0.27$\\pm$0.34; paired t-test $p < 10^{-7}$). Hierarchical inference cuts runtime 5.1$\\times$ vs. traditional inference. Applied to all reports, it revealed associations among ileal wall thickening, stenosis, and pre-stenotic dilatation, plus age- and sex-specific trends in inflammatory findings. HSMP-BERT offers a scalable solution for structured extraction in radiology, enabling population-level analysis of Crohn's disease and demonstrating AI's potential in low-resource settings.         ",
    "url": "https://arxiv.org/abs/2509.04519",
    "authors": [
      "Zvi Badash",
      "Hadas Ben-Atya",
      "Naama Gavrielov",
      "Liam Hazan",
      "Gili Focht",
      "Ruth Cytter-Kuint",
      "Talar Hagopian",
      "Dan Turner",
      "Moti Freiman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2509.04537",
    "title": "Emergent Social Dynamics of LLM Agents in the El Farol Bar Problem",
    "abstract": "           We investigate the emergent social dynamics of Large Language Model (LLM) agents in a spatially extended El Farol Bar problem, observing how they autonomously navigate this classic social dilemma. As a result, the LLM agents generated a spontaneous motivation to go to the bar and changed their decision making by becoming a collective. We also observed that the LLM agents did not solve the problem completely, but rather behaved more like humans. These findings reveal a complex interplay between external incentives (prompt-specified constraints such as the 60\\% threshold) and internal incentives (culturally-encoded social preferences derived from pre-training), demonstrating that LLM agents naturally balance formal game-theoretic rationality with social motivations that characterize human behavior. These findings suggest that a new model of group decision making, which could not be handled in the previous game-theoretic problem setting, can be realized by LLM agents.         ",
    "url": "https://arxiv.org/abs/2509.04537",
    "authors": [
      "Ryosuke Takata",
      "Atsushi Masumori",
      "Takashi Ikegammi"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2509.04549",
    "title": "Manipulating Transformer-Based Models: Controllability, Steerability, and Robust Interventions",
    "abstract": "           Transformer-based language models excel in NLP tasks, but fine-grained control remains challenging. This paper explores methods for manipulating transformer models through principled interventions at three levels: prompts, activations, and weights. We formalize controllable text generation as an optimization problem addressable via prompt engineering, parameter-efficient fine-tuning, model editing, and reinforcement learning. We introduce a unified framework encompassing prompt-level steering, activation interventions, and weight-space edits. We analyze robustness and safety implications, including adversarial attacks and alignment mitigations. Theoretically, we show minimal weight updates can achieve targeted behavior changes with limited side-effects. Empirically, we demonstrate >90% success in sentiment control and factual edits while preserving base performance, though generalization-specificity trade-offs exist. We discuss ethical dual-use risks and the need for rigorous evaluation. This work lays groundwork for designing controllable and robust language models.         ",
    "url": "https://arxiv.org/abs/2509.04549",
    "authors": [
      "Faruk Alpay",
      "Taylan Alpay"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.04588",
    "title": "Toward Faithfulness-guided Ensemble Interpretation of Neural Network",
    "abstract": "           Interpretable and faithful explanations for specific neural inferences are crucial for understanding and evaluating model behavior. Our work introduces \\textbf{F}aithfulness-guided \\textbf{E}nsemble \\textbf{I}nterpretation (\\textbf{FEI}), an innovative framework that enhances the breadth and effectiveness of faithfulness, advancing interpretability by providing superior visualization. Through an analysis of existing evaluation benchmarks, \\textbf{FEI} employs a smooth approximation to elevate quantitative faithfulness scores. Diverse variations of \\textbf{FEI} target enhanced faithfulness in hidden layer encodings, expanding interpretability. Additionally, we propose a novel qualitative metric that assesses hidden layer faithfulness. In extensive experiments, \\textbf{FEI} surpasses existing methods, demonstrating substantial advances in qualitative visualization and quantitative faithfulness scores. Our research establishes a comprehensive framework for elevating faithfulness in neural network explanations, emphasizing both breadth and precision         ",
    "url": "https://arxiv.org/abs/2509.04588",
    "authors": [
      "Siyu Zhang",
      "Kenneth Mcmillan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.04593",
    "title": "Wasserstein Distributionally Robust Adaptive Covariance Steering",
    "abstract": "           We present a methodology for predictable and safe covariance steering control of uncertain nonlinear stochastic processes. The systems under consideration are subject to general uncertainties, which include unbounded random disturbances (aleatoric uncertainties) and incomplete model knowledge (state-dependent epistemic uncertainties). These general uncertainties lead to temporally evolving state distributions that are entirely unknown, can have arbitrary shapes, and may diverge unquantifiably from expected behaviors, leading to unpredictable and unsafe behaviors. Our method relies on an $\\mathcal{L}_1$-adaptive control architecture that ensures robust control of uncertain stochastic processes while providing Wasserstein metric certificates in the space of probability measures. We show how these distributional certificates can be incorporated into the high-level covariance control steering to guarantee safe control. Unlike existing distributionally robust planning and control methodologies, our approach avoids difficult-to-verify requirements like the availability of finite samples from the true underlying distribution or an a priori knowledge of time-varying ambiguity sets to which the state distributions are assumed to belong.         ",
    "url": "https://arxiv.org/abs/2509.04593",
    "authors": [
      "Aditya Gahlawat",
      "Vivek Khatana",
      "Duo Wang",
      "Sambhu H. Karumanchi",
      "Naira Hovakimyan",
      "Petros Voulgaris"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2509.04597",
    "title": "DisPatch: Disarming Adversarial Patches in Object Detection with Diffusion Models",
    "abstract": "           Object detection is fundamental to various real-world applications, such as security monitoring and surveillance video analysis. Despite their advancements, state-of-theart object detectors are still vulnerable to adversarial patch attacks, which can be easily applied to real-world objects to either conceal actual items or create non-existent ones, leading to severe consequences. Given the current diversity of adversarial patch attacks and potential unknown threats, an ideal defense method should be effective, generalizable, and robust against adaptive attacks. In this work, we introduce DISPATCH, the first diffusion-based defense framework for object detection. Unlike previous works that aim to \"detect and remove\" adversarial patches, DISPATCH adopts a \"regenerate and rectify\" strategy, leveraging generative models to disarm attack effects while preserving the integrity of the input image. Specifically, we utilize the in-distribution generative power of diffusion models to regenerate the entire image, aligning it with benign data. A rectification process is then employed to identify and replace adversarial regions with their regenerated benign counterparts. DISPATCH is attack-agnostic and requires no prior knowledge of the existing patches. Extensive experiments across multiple detectors and attacks demonstrate that DISPATCH consistently outperforms state-of-the-art defenses on both hiding attacks and creating attacks, achieving the best overall mAP.5 score of 89.3% on hiding attacks, and lowering the attack success rate to 24.8% on untargeted creating attacks. Moreover, it maintains strong robustness against adaptive attacks, making it a practical and reliable defense for object detection systems.         ",
    "url": "https://arxiv.org/abs/2509.04597",
    "authors": [
      "Jin Ma",
      "Mohammed Aldeen",
      "Christopher Salas",
      "Feng Luo",
      "Mashrur Chowdhury",
      "Mert Pes\u00e9",
      "Long Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.04601",
    "title": "Quantum-Enhanced Multi-Task Learning with Learnable Weighting for Pharmacokinetic and Toxicity Prediction",
    "abstract": "           Prediction for ADMET (Absorption, Distribution, Metabolism, Excretion, and Toxicity) plays a crucial role in drug discovery and development, accelerating the screening and optimization of new drugs. Existing methods primarily rely on single-task learning (STL), which often fails to fully exploit the complementarities between tasks. Besides, it requires more computational resources while training and inference of each task independently. To address these issues, we propose a new unified Quantum-enhanced and task-Weighted Multi-Task Learning (QW-MTL) framework, specifically designed for ADMET classification tasks. Built upon the Chemprop-RDKit backbone, QW-MTL adopts quantum chemical descriptors to enrich molecular representations with additional information about the electronic structure and interactions. Meanwhile, it introduces a novel exponential task weighting scheme that combines dataset-scale priors with learnable parameters to achieve dynamic loss balancing across tasks. To the best of our knowledge, this is the first work to systematically conduct joint multi-task training across all 13 Therapeutics Data Commons (TDC) classification benchmarks, using leaderboard-style data splits to ensure a standardized and realistic evaluation setting. Extensive experimental results show that QW-MTL significantly outperforms single-task baselines on 12 out of 13 tasks, achieving high predictive performance with minimal model complexity and fast inference, demonstrating the effectiveness and efficiency of multi-task molecular learning enhanced by quantum-informed features and adaptive task weighting.         ",
    "url": "https://arxiv.org/abs/2509.04601",
    "authors": [
      "Han Zhang",
      "Fengji Ma",
      "Jiamin Su",
      "Xinyue Yang",
      "Lei Wang",
      "Wen-Cai Ye",
      "Li Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.04615",
    "title": "Breaking to Build: A Threat Model of Prompt-Based Attacks for Securing LLMs",
    "abstract": "           The proliferation of Large Language Models (LLMs) has introduced critical security challenges, where adversarial actors can manipulate input prompts to cause significant harm and circumvent safety alignments. These prompt-based attacks exploit vulnerabilities in a model's design, training, and contextual understanding, leading to intellectual property theft, misinformation generation, and erosion of user trust. A systematic understanding of these attack vectors is the foundational step toward developing robust countermeasures. This paper presents a comprehensive literature survey of prompt-based attack methodologies, categorizing them to provide a clear threat model. By detailing the mechanisms and impacts of these exploits, this survey aims to inform the research community's efforts in building the next generation of secure LLMs that are inherently resistant to unauthorized distillation, fine-tuning, and editing.         ",
    "url": "https://arxiv.org/abs/2509.04615",
    "authors": [
      "Brennen Hill",
      "Surendra Parla",
      "Venkata Abhijeeth Balabhadruni",
      "Atharv Prajod Padmalayam",
      "Sujay Chandra Shekara Sharma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.04619",
    "title": "$\\mathcal{L}_1$-DRAC: Distributionally Robust Adaptive Control",
    "abstract": "           Data-driven machine learning methodologies have attracted considerable attention for the control and estimation of dynamical systems. However, such implementations suffer from a lack of predictability and robustness. Thus, adoption of data-driven tools has been minimal for safety-aware applications despite their impressive empirical results. While classical tools like robust adaptive control can ensure predictable performance, their consolidation with data-driven methods remains a challenge and, when attempted, leads to conservative results. The difficulty of consolidation stems from the inherently different `spaces' that robust control and data-driven methods occupy. Data-driven methods suffer from the distribution-shift problem, which current robust adaptive controllers can only tackle if using over-simplified learning models and unverifiable assumptions. In this paper, we present $\\mathcal{L}_1$ distributionally robust adaptive control ($\\mathcal{L}_1$-DRAC): a control methodology for uncertain stochastic processes that guarantees robustness certificates in terms of uniform (finite-time) and maximal distributional deviation. We leverage the $\\mathcal{L}_1$ adaptive control methodology to ensure the existence of Wasserstein ambiguity set around a nominal distribution, which is guaranteed to contain the true distribution. The uniform ambiguity set produces an ambiguity tube of distributions centered on the nominal temporally-varying nominal distribution. The designed controller generates the ambiguity tube in response to both epistemic (model uncertainties) and aleatoric (inherent randomness and disturbances) uncertainties.         ",
    "url": "https://arxiv.org/abs/2509.04619",
    "authors": [
      "Aditya Gahlawat",
      "Sambhu H. Karumanchi",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2509.04623",
    "title": "Split Conformal Prediction in the Function Space with Neural Operators",
    "abstract": "           Uncertainty quantification for neural operators remains an open problem in the infinite-dimensional setting due to the lack of finite-sample coverage guarantees over functional outputs. While conformal prediction offers finite-sample guarantees in finite-dimensional spaces, it does not directly extend to function-valued outputs. Existing approaches (Gaussian processes, Bayesian neural networks, and quantile-based operators) require strong distributional assumptions or yield conservative coverage. This work extends split conformal prediction to function spaces following a two step method. We first establish finite-sample coverage guarantees in a finite-dimensional space using a discretization map in the output function space. Then these guarantees are lifted to the function-space by considering the asymptotic convergence as the discretization is refined. To characterize the effect of resolution, we decompose the conformal radius into discretization, calibration, and misspecification components. This decomposition motivates a regression-based correction to transfer calibration across resolutions. Additionally, we propose two diagnostic metrics (conformal ensemble score and internal agreement) to quantify forecast degradation in autoregressive settings. Empirical results show that our method maintains calibrated coverage with less variation under resolution shifts and achieves better coverage in super-resolution tasks.         ",
    "url": "https://arxiv.org/abs/2509.04623",
    "authors": [
      "David Millard",
      "Lars Lindemann",
      "Ali Baheri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.04625",
    "title": "NEXUS: Efficient and Scalable Multi-Cell mmWave Baseband Processing with Heterogeneous Compute",
    "abstract": "           The rapid adoption of 5G New Radio (NR), particularly in the millimeter-wave (mmWave) spectrum, imposes stringent demands on the flexibility, scalability, and efficiency of baseband processing. While virtualized Radio Access Networks (vRANs) enable dynamic spectrum sharing across cells, compute resource allocation for baseband processing, especially in multi-cell deployments with heterogeneous workloads, remains underexplored. In this paper, we present NEXUS, the first system to realize real-time, virtualized multi-cell mmWave baseband processing on a single server with heterogeneous compute resources. NEXUS integrates software-based digital signal processing pipelines with hardware-accelerated LDPC decoding, and introduces a novel framework for sharing Intel's ACC100 eASIC across multiple CPU cores via virtual functions (VFs). For single-cell operation, NEXUS employs a random forest (RAF)-based model that predicts the most energy-efficient resource allocation for the given cell configuration with microsecond-level inference latency and high accuracy. For multi-cell scenarios, NEXUS introduces a power-aware scheduler that incorporates a lightweight contention model to adjust resource allocation strategies under concurrent execution. Through extensive evaluation across various Frequency Range 2 (FR2) cell configurations, we show that NEXUS supports up to 16 concurrent cells under full load, achieving 5.37Gbps aggregate throughput, while reducing the multi-cell scheduling search space by orders of magnitude. These results demonstrate that virtualized, resource-aware baseband processing is both practical and efficient for next-generation vRAN systems.         ",
    "url": "https://arxiv.org/abs/2509.04625",
    "authors": [
      "Zhenzhou Qi",
      "Chung-Hsuan Tung",
      "Zhihui Gao",
      "Tingjun Chen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2509.04631",
    "title": "Fundamental bounds on efficiency-confidence trade-off for transductive conformal prediction",
    "abstract": "           Transductive conformal prediction addresses the simultaneous prediction for multiple data points. Given a desired confidence level, the objective is to construct a prediction set that includes the true outcomes with the prescribed confidence. We demonstrate a fundamental trade-off between confidence and efficiency in transductive methods, where efficiency is measured by the size of the prediction sets. Specifically, we derive a strict finite-sample bound showing that any non-trivial confidence level leads to exponential growth in prediction set size for data with inherent uncertainty. The exponent scales linearly with the number of samples and is proportional to the conditional entropy of the data. Additionally, the bound includes a second-order term, dispersion, defined as the variance of the log conditional probability distribution. We show that this bound is achievable in an idealized setting. Finally, we examine a special case of transductive prediction where all test data points share the same label. We show that this scenario reduces to the hypothesis testing problem with empirically observed statistics and provide an asymptotically optimal confidence predictor, along with an analysis of the error exponent.         ",
    "url": "https://arxiv.org/abs/2509.04631",
    "authors": [
      "Arash Behboodi",
      "Alvaro H.C. Correia",
      "Fabio Valerio Massoli",
      "Christos Louizos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2509.04642",
    "title": "Maestro: Joint Graph & Config Optimization for Reliable AI Agents",
    "abstract": "           Building reliable LLM agents requires decisions at two levels: the graph (which modules exist and how information flows) and the configuration of each node (models, prompts, tools, control knobs). Most existing optimizers tune configurations while holding the graph fixed, leaving structural failure modes unaddressed. We introduce Maestro, a framework-agnostic holistic optimizer for LLM agents that jointly searches over graphs and configurations to maximize agent quality, subject to explicit rollout/token budgets. Beyond numeric metrics, Maestro leverages reflective textual feedback from traces to prioritize edits, improving sample efficiency and targeting specific failure modes. On the IFBench and HotpotQA benchmarks, Maestro consistently surpasses leading prompt optimizers--MIPROv2, GEPA, and GEPA+Merge--by an average of 12%, 4.9%, and 4.86%, respectively; even when restricted to prompt-only optimization, it still leads by 9.65%, 2.37%, and 2.41%. Maestro achieves these results with far fewer rollouts than GEPA. We further show large gains on two applications (interviewer & RAG agents), highlighting that joint graph & configuration search addresses structural failure modes that prompt tuning alone cannot fix.         ",
    "url": "https://arxiv.org/abs/2509.04642",
    "authors": [
      "Wenxiao Wang",
      "Priyatham Kattakinda",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2509.04655",
    "title": "Polysemantic Dropout: Conformal OOD Detection for Specialized LLMs",
    "abstract": "           We propose a novel inference-time out-of-domain (OOD) detection algorithm for specialized large language models (LLMs). Despite achieving state-of-the-art performance on in-domain tasks through fine-tuning, specialized LLMs remain vulnerable to incorrect or unreliable outputs when presented with OOD inputs, posing risks in critical applications. Our method leverages the Inductive Conformal Anomaly Detection (ICAD) framework, using a new non-conformity measure based on the model's dropout tolerance. Motivated by recent findings on polysemanticity and redundancy in LLMs, we hypothesize that in-domain inputs exhibit higher dropout tolerance than OOD inputs. We aggregate dropout tolerance across multiple layers via a valid ensemble approach, improving detection while maintaining theoretical false alarm bounds from ICAD. Experiments with medical-specialized LLMs show that our approach detects OOD inputs better than baseline methods, with AUROC improvements of $2\\%$ to $37\\%$ when treating OOD datapoints as positives and in-domain test datapoints as negatives.         ",
    "url": "https://arxiv.org/abs/2509.04655",
    "authors": [
      "Ayush Gupta",
      "Ramneet Kaur",
      "Anirban Roy",
      "Adam D. Cobb",
      "Rama Chellappa",
      "Susmit Jha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.04661",
    "title": "Flexible inference of learning rules from de novo learning data using neural networks",
    "abstract": "           Understanding how animals learn is a central challenge in neuroscience, with growing relevance to the development of animal- or human-aligned artificial intelligence. However, most existing approaches assume specific parametric forms for the learning rule (e.g., Q-learning, policy gradient) or are limited to simplified settings like bandit tasks, which do not involve learning a new input-output mapping from scratch. In contrast, animals must often learn new behaviors de novo, which poses a rich challenge for learning-rule inference. We target this problem by inferring learning rules directly from animal decision-making data during de novo task learning, a setting that requires models flexible enough to capture suboptimality, history dependence, and rich external stimulus integration without strong structural priors. We first propose a nonparametric framework that parameterizes the per-trial update of policy weights with a deep neural network (DNN), and validate it by recovering ground-truth rules in simulation. We then extend to a recurrent variant (RNN) that captures non-Markovian dynamics by allowing updates to depend on trial history. Applied to a large behavioral dataset of mice learning a sensory decision-making task over multiple weeks, our models improved predictions on held-out data. The inferred rules revealed asymmetric updates after correct versus error trials and history dependence, consistent with non-Markovian learning. Overall, these results introduce a flexible framework for inferring biological learning rules from behavioral data in de novo learning tasks, providing insights to inform experimental training protocols and the development of behavioral digital twins.         ",
    "url": "https://arxiv.org/abs/2509.04661",
    "authors": [
      "Yuhan Helena Liu",
      "Victor Geadah",
      "Jonathan Pillow"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2509.04669",
    "title": "VCMamba: Bridging Convolutions with Multi-Directional Mamba for Efficient Visual Representation",
    "abstract": "           Recent advances in Vision Transformers (ViTs) and State Space Models (SSMs) have challenged the dominance of Convolutional Neural Networks (CNNs) in computer vision. ViTs excel at capturing global context, and SSMs like Mamba offer linear complexity for long sequences, yet they do not capture fine-grained local features as effectively as CNNs. Conversely, CNNs possess strong inductive biases for local features but lack the global reasoning capabilities of transformers and Mamba. To bridge this gap, we introduce \\textit{VCMamba}, a novel vision backbone that integrates the strengths of CNNs and multi-directional Mamba SSMs. VCMamba employs a convolutional stem and a hierarchical structure with convolutional blocks in its early stages to extract rich local features. These convolutional blocks are then processed by later stages incorporating multi-directional Mamba blocks designed to efficiently model long-range dependencies and global context. This hybrid design allows for superior feature representation while maintaining linear complexity with respect to image resolution. We demonstrate VCMamba's effectiveness through extensive experiments on ImageNet-1K classification and ADE20K semantic segmentation. Our VCMamba-B achieves 82.6% top-1 accuracy on ImageNet-1K, surpassing PlainMamba-L3 by 0.3% with 37% fewer parameters, and outperforming Vision GNN-B by 0.3% with 64% fewer parameters. Furthermore, VCMamba-B obtains 47.1 mIoU on ADE20K, exceeding EfficientFormer-L7 by 2.0 mIoU while utilizing 62% fewer parameters. Code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2509.04669",
    "authors": [
      "Mustafa Munir",
      "Alex Zhang",
      "Radu Marculescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.04683",
    "title": "Echoes Before Collapse: Deep Learning Detection of Flickering in Complex Systems",
    "abstract": "           Deep learning offers powerful tools for anticipating tipping points in complex systems, yet its potential for detecting flickering (noise-driven switching between coexisting stable states) remains unexplored. Flickering is a hallmark of reduced resilience in climate systems, ecosystems, financial markets, and other systems. It can precede critical regime shifts that are highly impactful but difficult to predict. Here we show that convolutional long short-term memory (CNN LSTM) models, trained on synthetic time series generated from simple polynomial functions with additive noise, can accurately identify flickering patterns. Despite being trained on simplified dynamics, our models generalize to diverse stochastic systems and reliably detect flickering in empirical datasets, including dormouse body temperature records and palaeoclimate proxies from the African Humid Period. These findings demonstrate that deep learning can extract early warning signals from noisy, nonlinear time series, providing a flexible framework for identifying instability across a wide range of dynamical systems.         ",
    "url": "https://arxiv.org/abs/2509.04683",
    "authors": [
      "Yazdan Babazadeh Maghsoodlo",
      "Madhur Anand",
      "Chris T. Bauch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.04694",
    "title": "Unified Representation Learning for Multi-Intent Diversity and Behavioral Uncertainty in Recommender Systems",
    "abstract": "           This paper addresses the challenge of jointly modeling user intent diversity and behavioral uncertainty in recommender systems. A unified representation learning framework is proposed. The framework builds a multi-intent representation module and an uncertainty modeling mechanism. It extracts multi-granularity interest structures from user behavior sequences. Behavioral ambiguity and preference fluctuation are captured using Bayesian distribution modeling. In the multi-intent modeling part, the model introduces multiple latent intent vectors. These vectors are weighted and fused using an attention mechanism to generate semantically rich representations of long-term user preferences. In the uncertainty modeling part, the model learns the mean and covariance of behavior representations through Gaussian distributions. This reflects the user's confidence in different behavioral contexts. Next, a learnable fusion strategy is used to combine long-term intent and short-term behavior signals. This produces the final user representation, improving both recommendation accuracy and robustness. The method is evaluated on standard public datasets. Experimental results show that it outperforms existing representative models across multiple metrics. It also demonstrates greater stability and adaptability under cold-start and behavioral disturbance scenarios. The approach alleviates modeling bottlenecks faced by traditional methods when dealing with complex user behavior. These findings confirm the effectiveness and practical value of the unified modeling strategy in real-world recommendation tasks.         ",
    "url": "https://arxiv.org/abs/2509.04694",
    "authors": [
      "Wei Xu",
      "Jiasen Zheng",
      "Junjiang Lin",
      "Mingxuan Han",
      "Junliang Du"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.04710",
    "title": "Network-Aware Differential Privacy",
    "abstract": "           Differential privacy (DP) is a privacy-enhancement technology (PET) that receives prominent attention from the academia, industry, and government. One main development over the past decade has been the decentralization of DP, including local DP and shuffle DP. Despite that decentralized DP heavily relies on network communications for data collection,we found that: 1) no systematic study has surveyed the research opportunities at the intersection of networking and DP; 2) nor have there been significant efforts to develop DP mechanisms that are explicitly tailored for network environments. In this paper, we seek to address this gap by initiating a new direction of network-aware DP. We identified two focus areas where the network research can offer substantive contributions to the design and deployment of DP, related to network security and topology. Through this work, we hope to encourage more research that adapt/optimize DP's deployment in various network environments.         ",
    "url": "https://arxiv.org/abs/2509.04710",
    "authors": [
      "Zhou Li",
      "Yu Zheng",
      "Tianhao Wang",
      "Sang-Woo Jun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2509.04711",
    "title": "Domain Adaptation for Different Sensor Configurations in 3D Object Detection",
    "abstract": "           Recent advances in autonomous driving have underscored the importance of accurate 3D object detection, with LiDAR playing a central role due to its robustness under diverse visibility conditions. However, different vehicle platforms often deploy distinct sensor configurations, causing performance degradation when models trained on one configuration are applied to another because of shifts in the point cloud distribution. Prior work on multi-dataset training and domain adaptation for 3D object detection has largely addressed environmental domain gaps and density variation within a single LiDAR; in contrast, the domain gap for different sensor configurations remains largely unexplored. In this work, we address domain adaptation across different sensor configurations in 3D object detection. We propose two techniques: Downstream Fine-tuning (dataset-specific fine-tuning after multi-dataset training) and Partial Layer Fine-tuning (updating only a subset of layers to improve cross-configuration generalization). Using paired datasets collected in the same geographic region with multiple sensor configurations, we show that joint training with Downstream Fine-tuning and Partial Layer Fine-tuning consistently outperforms naive joint training for each configuration. Our findings provide a practical and scalable solution for adapting 3D object detection models to the diverse vehicle platforms.         ",
    "url": "https://arxiv.org/abs/2509.04711",
    "authors": [
      "Satoshi Tanaka",
      "Kok Seang Tan",
      "Isamu Yamashita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2509.04719",
    "title": "STADI: Fine-Grained Step-Patch Diffusion Parallelism for Heterogeneous GPUs",
    "abstract": "           The escalating adoption of diffusion models for applications such as image generation demands efficient parallel inference techniques to manage their substantial computational cost. However, existing diffusion parallelism inference schemes often underutilize resources in heterogeneous multi-GPU environments, where varying hardware capabilities or background tasks cause workload imbalance. This paper introduces Spatio-Temporal Adaptive Diffusion Inference (STADI), a novel framework to accelerate diffusion model inference in such settings. At its core is a hybrid scheduler that orchestrates fine-grained parallelism across both temporal and spatial dimensions. Temporally, STADI introduces a novel computation-aware step allocator applied after warmup phases, using a least-common-multiple-minimizing quantization technique to reduce denoising steps on slower GPUs and execution synchronization. To further minimize GPU idle periods, STADI executes an elastic patch parallelism mechanism that allocates variably sized image patches to GPUs according to their computational capability, ensuring balanced workload distribution through a complementary spatial mechanism. Extensive experiments on both load-imbalanced and heterogeneous multi-GPU clusters validate STADI's efficacy, demonstrating improved load balancing and mitigation of performance bottlenecks. Compared to patch parallelism, a state-of-the-art diffusion inference framework, our method significantly reduces end-to-end inference latency by up to 45% and significantly improves resource utilization on heterogeneous GPUs.         ",
    "url": "https://arxiv.org/abs/2509.04719",
    "authors": [
      "Han Liang",
      "Jiahui Zhou",
      "Zicheng Zhou",
      "Xiaoxi Zhang",
      "Xu Chen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.04722",
    "title": "Hierarchical Reduced-Order Model Predictive Control for Robust Locomotion on Humanoid Robots",
    "abstract": "           As humanoid robots enter real-world environments, ensuring robust locomotion across diverse environments is crucial. This paper presents a computationally efficient hierarchical control framework for humanoid robot locomotion based on reduced-order models -- enabling versatile step planning and incorporating arm and torso dynamics to better stabilize the walking. At the high level, we use the step-to-step dynamics of the ALIP model to simultaneously optimize over step periods, step lengths, and ankle torques via nonlinear MPC. The ALIP trajectories are used as references to a linear MPC framework that extends the standard SRB-MPC to also include simplified arm and torso dynamics. We validate the performance of our approach through simulation and hardware experiments on the Unitree G1 humanoid robot. In the proposed framework the high-level step planner runs at 40 Hz and the mid-level MPC at 500 Hz using the onboard mini-PC. Adaptive step timing increased the push recovery success rate by 36%, and the upper body control improved the yaw disturbance rejection. We also demonstrate robust locomotion across diverse indoor and outdoor terrains, including grass, stone pavement, and uneven gym mats.         ",
    "url": "https://arxiv.org/abs/2509.04722",
    "authors": [
      "Adrian B. Ghansah",
      "Sergio A. Esteban",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2509.04729",
    "title": "CD-Mamba: Cloud detection with long-range spatial dependency modeling",
    "abstract": "           Remote sensing images are frequently obscured by cloud cover, posing significant challenges to data integrity and reliability. Effective cloud detection requires addressing both short-range spatial redundancies and long-range atmospheric similarities among cloud patches. Convolutional neural networks are effective at capturing local spatial dependencies, while Mamba has strong capabilities in modeling long-range dependencies. To fully leverage both local spatial relations and long-range dependencies, we propose CD-Mamba, a hybrid model that integrates convolution and Mamba's state-space modeling into a unified cloud detection network. CD-Mamba is designed to comprehensively capture pixelwise textural details and long term patchwise dependencies for cloud detection. This design enables CD-Mamba to manage both pixel-wise interactions and extensive patch-wise dependencies simultaneously, improving detection accuracy across diverse spatial scales. Extensive experiments validate the effectiveness of CD-Mamba and demonstrate its superior performance over existing methods.         ",
    "url": "https://arxiv.org/abs/2509.04729",
    "authors": [
      "Tianxiang Xue",
      "Jiayi Zhao",
      "Jingsheng Li",
      "Changlu Chen",
      "Kun Zhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.04733",
    "title": "CoVeR: Conformal Calibration for Versatile and Reliable Autoregressive Next-Token Prediction",
    "abstract": "           Autoregressive pre-trained models combined with decoding methods have achieved impressive performance on complex reasoning tasks. While mainstream decoding strategies such as beam search can generate plausible candidate sets, they often lack provable coverage guarantees, and struggle to effectively balance search efficiency with the need for versatile trajectories, particularly those involving long-tail sequences that are essential in certain real-world applications. To address these limitations, we propose \\textsc{CoVeR}, a novel model-free decoding strategy wihtin the conformal prediction framework that simultaneously maintains a compact search space and ensures high coverage probability over desirable trajectories. Theoretically, we establish a PAC-style generalization bound, guaranteeing that \\textsc{CoVeR} asymptotically achieves a coverage rate of at least $1 - \\alpha$ for any target level $\\alpha \\in (0,1)$.         ",
    "url": "https://arxiv.org/abs/2509.04733",
    "authors": [
      "Yuzhu Chen",
      "Yingjie Wang",
      "Shunyu Liu",
      "Yongcheng Jing",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.04734",
    "title": "Beyond I-Con: Exploring New Dimension of Distance Measures in Representation Learning",
    "abstract": "           The Information Contrastive (I-Con) framework revealed that over 23 representation learning methods implicitly minimize KL divergence between data and learned distributions that encode similarities between data points. However, a KL-based loss may be misaligned with the true objective, and properties of KL divergence such as asymmetry and unboundedness may create optimization challenges. We present Beyond I-Con, a framework that enables systematic discovery of novel loss functions by exploring alternative statistical divergences and similarity kernels. Key findings: (1) on unsupervised clustering of DINO-ViT embeddings, we achieve state-of-the-art results by modifying the PMI algorithm to use total variation (TV) distance; (2) on supervised contrastive learning, we outperform the standard approach by using TV and a distance-based similarity kernel instead of KL and an angular kernel; (3) on dimensionality reduction, we achieve superior qualitative results and better performance on downstream tasks than SNE by replacing KL with a bounded f-divergence. Our results highlight the importance of considering divergence and similarity kernel choices in representation learning optimization.         ",
    "url": "https://arxiv.org/abs/2509.04734",
    "authors": [
      "Jasmine Shone",
      "Shaden Alshammari",
      "Mark Hamilton",
      "Zhening Li",
      "William Freeman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.04737",
    "title": "Imitation Learning Based on Disentangled Representation Learning of Behavioral Characteristics",
    "abstract": "           In the field of robot learning, coordinating robot actions through language instructions is becoming increasingly feasible. However, adapting actions to human instructions remains challenging, as such instructions are often qualitative and require exploring behaviors that satisfy varying conditions. This paper proposes a motion generation model that adapts robot actions in response to modifier directives human instructions imposing behavioral conditions during task execution. The proposed method learns a mapping from modifier directives to actions by segmenting demonstrations into short sequences, assigning weakly supervised labels corresponding to specific modifier types. We evaluated our method in wiping and pick and place tasks. Results show that it can adjust motions online in response to modifier directives, unlike conventional batch-based methods that cannot adapt during execution.         ",
    "url": "https://arxiv.org/abs/2509.04737",
    "authors": [
      "Ryoga Oishi",
      "Sho Sakaino",
      "Toshiaki Tsuji"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2509.04745",
    "title": "Phonological Representation Learning for Isolated Signs Improves Out-of-Vocabulary Generalization",
    "abstract": "           Sign language datasets are often not representative in terms of vocabulary, underscoring the need for models that generalize to unseen signs. Vector quantization is a promising approach for learning discrete, token-like representations, but it has not been evaluated whether the learned units capture spurious correlations that hinder out-of-vocabulary performance. This work investigates two phonological inductive biases: Parameter Disentanglement, an architectural bias, and Phonological Semi-Supervision, a regularization technique, to improve isolated sign recognition of known signs and reconstruction quality of unseen signs with a vector-quantized autoencoder. The primary finding is that the learned representations from the proposed model are more effective for one-shot reconstruction of unseen signs and more discriminative for sign identification compared to a controlled baseline. This work provides a quantitative analysis of how explicit, linguistically-motivated biases can improve the generalization of learned representations of sign language.         ",
    "url": "https://arxiv.org/abs/2509.04745",
    "authors": [
      "Lee Kezar",
      "Zed Sehyr",
      "Jesse Thomason"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.04747",
    "title": "Solving Inverse Acoustic Obstacle Scattering Problem with Phaseless Far-Field Measurement Using Deep Neural Network Surrogates",
    "abstract": "           In this work, we investigate the use of deep neural networks (DNNs) as surrogates for solving the inverse acoustic scattering problem of recovering a sound-soft obstacle from phaseless far-field measurements. We approximate the forward maps from the obstacle to the far-field data using DNNs, and for star-shaped domains in two and three dimensions, we establish the expression rates for fully connected feedforward neural networks with the ReLU activation for approximating the forward maps. The analysis is based on the weak formulation of the direct problem, and can handle variable coefficients. Numerically we validate the accuracy of the DNN surrogates of the forward maps, and demonstrate the use of DNN surrogates in the Bayesian treatment of the inverse obstacle scattering problem. Numerical experiments indicate that the surrogates are effective in both two- and three-dimensional cases, and can significantly speed up the exploration of the posterior distribution of the shape parameters using Markov chain Monte Carlo.         ",
    "url": "https://arxiv.org/abs/2509.04747",
    "authors": [
      "Yuxin Fan",
      "Jiho Hong",
      "Bangti Jin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2509.04757",
    "title": "MCANet: A Multi-Scale Class-Specific Attention Network for Multi-Label Post-Hurricane Damage Assessment using UAV Imagery",
    "abstract": "           Rapid and accurate post-hurricane damage assessment is vital for disaster response and recovery. Yet existing CNN-based methods struggle to capture multi-scale spatial features and to distinguish visually similar or co-occurring damage types. To address these issues, we propose MCANet, a multi-label classification framework that learns multi-scale representations and adaptively attends to spatially relevant regions for each damage category. MCANet employs a Res2Net-based hierarchical backbone to enrich spatial context across scales and a multi-head class-specific residual attention module to enhance discrimination. Each attention branch focuses on different spatial granularities, balancing local detail with global context. We evaluate MCANet on the RescueNet dataset of 4,494 UAV images collected after Hurricane Michael. MCANet achieves a mean average precision (mAP) of 91.75%, outperforming ResNet, Res2Net, VGG, MobileNet, EfficientNet, and ViT. With eight attention heads, performance further improves to 92.35%, boosting average precision for challenging classes such as Road Blocked by over 6%. Class activation mapping confirms MCANet's ability to localize damage-relevant regions, supporting interpretability. Outputs from MCANet can inform post-disaster risk mapping, emergency routing, and digital twin-based disaster response. Future work could integrate disaster-specific knowledge graphs and multimodal large language models to improve adaptability to unseen disasters and enrich semantic understanding for real-world decision-making.         ",
    "url": "https://arxiv.org/abs/2509.04757",
    "authors": [
      "Zhangding Liu",
      "Neda Mohammadi",
      "John E. Taylor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.04758",
    "title": "Dynamic Group Detection using VLM-augmented Temporal Groupness Graph",
    "abstract": "           This paper proposes dynamic human group detection in videos. For detecting complex groups, not only the local appearance features of in-group members but also the global context of the scene are important. Such local and global appearance features in each frame are extracted using a Vision-Language Model (VLM) augmented for group detection in our method. For further improvement, the group structure should be consistent over time. While previous methods are stabilized on the assumption that groups are not changed in a video, our method detects dynamically changing groups by global optimization using a graph with all frames' groupness probabilities estimated by our groupness-augmented CLIP features. Our experimental results demonstrate that our method outperforms state-of-the-art group detection methods on public datasets. Code: this https URL ",
    "url": "https://arxiv.org/abs/2509.04758",
    "authors": [
      "Kaname Yokoyama",
      "Chihiro Nakatani",
      "Norimichi Ukita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.04759",
    "title": "Toward Robust URL Extraction for Open Science: A Study of arXiv File Formats and Temporal Trends",
    "abstract": "           In this work, we study how URL extraction results depend on input format. We compiled a pilot dataset by extracting URLs from 10 arXiv papers and used the same heuristic method to extract URLs from four formats derived from the PDF files or the source LaTeX files. We found that accurate and complete URL extraction from any single format or a combination of multiple formats is challenging, with the best F1-score of 0.71. Using the pilot dataset, we evaluate extraction performance across formats and show that structured formats like HTML and XML produce more accurate results than PDFs or Text. Combining multiple formats improves coverage, especially when targeting research-critical resources. We further apply URL extraction on two tasks, namely classifying URLs into open-access datasets and software and the others, and analyzing the trend of URLs usage in arXiv papers from 1992 to 2024. These results suggest that using a combination of multiple formats achieves better performance on URL extraction than a single format, and the number of URLs in arXiv papers has been steadily increasing since 1992 to 2014 and has been drastically increasing from 2014 to 2024. The dataset and the Jupyter notebooks used for the preliminary analysis are publicly available at this https URL ",
    "url": "https://arxiv.org/abs/2509.04759",
    "authors": [
      "Rochana R. Obadage",
      "Lamia Salsabil",
      "Sawood Alam",
      "Bipasha Banarjee",
      "William A. Ingram",
      "Edward A. Fox",
      "Jian Wu"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2509.04772",
    "title": "FloodVision: Urban Flood Depth Estimation Using Foundation Vision-Language Models and Domain Knowledge Graph",
    "abstract": "           Timely and accurate floodwater depth estimation is critical for road accessibility and emergency response. While recent computer vision methods have enabled flood detection, they suffer from both accuracy limitations and poor generalization due to dependence on fixed object detectors and task-specific training. To enable accurate depth estimation that can generalize across diverse flood scenarios, this paper presents FloodVision, a zero-shot framework that combines the semantic reasoning abilities of the foundation vision-language model GPT-4o with a structured domain knowledge graph. The knowledge graph encodes canonical real-world dimensions for common urban objects including vehicles, people, and infrastructure elements to ground the model's reasoning in physical reality. FloodVision dynamically identifies visible reference objects in RGB images, retrieves verified heights from the knowledge graph to mitigate hallucination, estimates submergence ratios, and applies statistical outlier filtering to compute final depth values. Evaluated on 110 crowdsourced images from MyCoast New York, FloodVision achieves a mean absolute error of 8.17 cm, reducing the GPT-4o baseline 10.28 cm by 20.5% and surpassing prior CNN-based methods. The system generalizes well across varying scenes and operates in near real-time, making it suitable for future integration into digital twin platforms and citizen-reporting apps for smart city flood resilience.         ",
    "url": "https://arxiv.org/abs/2509.04772",
    "authors": [
      "Zhangding Liu",
      "Neda Mohammadi",
      "John E. Taylor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.04785",
    "title": "Graph Unlearning: Efficient Node Removal in Graph Neural Networks",
    "abstract": "           With increasing concerns about privacy attacks and potential sensitive information leakage, researchers have actively explored methods to efficiently remove sensitive training data and reduce privacy risks in graph neural network (GNN) models. Node unlearning has emerged as a promising technique for protecting the privacy of sensitive nodes by efficiently removing specific training node information from GNN models. However, existing node unlearning methods either impose restrictions on the GNN structure or do not effectively utilize the graph topology for node unlearning. Some methods even compromise the graph's topology, making it challenging to achieve a satisfactory performance-complexity trade-off. To address these issues and achieve efficient unlearning for training node removal in GNNs, we propose three novel node unlearning methods: Class-based Label Replacement, Topology-guided Neighbor Mean Posterior Probability, and Class-consistent Neighbor Node Filtering. Among these methods, Topology-guided Neighbor Mean Posterior Probability and Class-consistent Neighbor Node Filtering effectively leverage the topological features of the graph, resulting in more effective node unlearning. To validate the superiority of our proposed methods in node unlearning, we conducted experiments on three benchmark datasets. The evaluation criteria included model utility, unlearning utility, and unlearning efficiency. The experimental results demonstrate the utility and efficiency of the proposed methods and illustrate their superiority compared to state-of-the-art node unlearning methods. Overall, the proposed methods efficiently remove sensitive training nodes and protect the privacy information of sensitive nodes in GNNs. The findings contribute to enhancing the privacy and security of GNN models and provide valuable insights into the field of node unlearning.         ",
    "url": "https://arxiv.org/abs/2509.04785",
    "authors": [
      "Faqian Guan",
      "Tianqing Zhu",
      "Zhoutian Wang",
      "Wei Ren",
      "Wanlei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.04802",
    "title": "Mind the Gap: Evaluating Model- and Agentic-Level Vulnerabilities in LLMs with Action Graphs",
    "abstract": "           As large language models transition to agentic systems, current safety evaluation frameworks face critical gaps in assessing deployment-specific risks. We introduce AgentSeer, an observability-based evaluation framework that decomposes agentic executions into granular action and component graphs, enabling systematic agentic-situational assessment. Through cross-model validation on GPT-OSS-20B and Gemini-2.0-flash using HarmBench single turn and iterative refinement attacks, we demonstrate fundamental differences between model-level and agentic-level vulnerability profiles. Model-level evaluation reveals baseline differences: GPT-OSS-20B (39.47% ASR) versus Gemini-2.0-flash (50.00% ASR), with both models showing susceptibility to social engineering while maintaining logic-based attack resistance. However, agentic-level assessment exposes agent-specific risks invisible to traditional evaluation. We discover \"agentic-only\" vulnerabilities that emerge exclusively in agentic contexts, with tool-calling showing 24-60% higher ASR across both models. Cross-model analysis reveals universal agentic patterns, agent transfer operations as highest-risk tools, semantic rather than syntactic vulnerability mechanisms, and context-dependent attack effectiveness, alongside model-specific security profiles in absolute ASR levels and optimal injection strategies. Direct attack transfer from model-level to agentic contexts shows degraded performance (GPT-OSS-20B: 57% human injection ASR; Gemini-2.0-flash: 28%), while context-aware iterative attacks successfully compromise objectives that failed at model-level, confirming systematic evaluation gaps. These findings establish the urgent need for agentic-situation evaluation paradigms, with AgentSeer providing the standardized methodology and empirical validation.         ",
    "url": "https://arxiv.org/abs/2509.04802",
    "authors": [
      "Ilham Wicaksono",
      "Zekun Wu",
      "Theo King",
      "Adriano Koshiyama",
      "Philip Treleaven"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2509.04810",
    "title": "Code Review Without Borders: Evaluating Synthetic vs. Real Data for Review Recommendation",
    "abstract": "           Automating the decision of whether a code change requires manual review is vital for maintaining software quality in modern development workflows. However, the emergence of new programming languages and frameworks creates a critical bottleneck: while large volumes of unlabelled code are readily available, there is an insufficient amount of labelled data to train supervised models for review classification. We address this challenge by leveraging Large Language Models (LLMs) to translate code changes from well-resourced languages into equivalent changes in underrepresented or emerging languages, generating synthetic training data where labelled examples are scarce. We assume that although LLMs have learned the syntax and semantics of new languages from available unlabelled code, they have yet to fully grasp which code changes are considered significant or review-worthy within these emerging ecosystems. To overcome this, we use LLMs to generate synthetic change examples and train supervised classifiers on them. We systematically compare the performance of these classifiers against models trained on real labelled data. Our experiments across multiple GitHub repositories and language pairs demonstrate that LLM-generated synthetic data can effectively bootstrap review recommendation systems, narrowing the performance gap even in low-resource settings. This approach provides a scalable pathway to extend automated code review capabilities to rapidly evolving technology stacks, even in the absence of annotated data.         ",
    "url": "https://arxiv.org/abs/2509.04810",
    "authors": [
      "Yogev Cohen",
      "Dudi Ohayon",
      "Romy Somkin",
      "Yehudit Aperstein",
      "Alexander Apartsin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.04823",
    "title": "Evaluating Cognitive-Behavioral Fixation via Multimodal User Viewing Patterns on Social Media",
    "abstract": "           Digital social media platforms frequently contribute to cognitive-behavioral fixation, a phenomenon in which users exhibit sustained and repetitive engagement with narrow content domains. While cognitive-behavioral fixation has been extensively studied in psychology, methods for computationally detecting and evaluating such fixation remain underexplored. To address this gap, we propose a novel framework for assessing cognitive-behavioral fixation by analyzing users' multimodal social media engagement patterns. Specifically, we introduce a multimodal topic extraction module and a cognitive-behavioral fixation quantification module that collaboratively enable adaptive, hierarchical, and interpretable assessment of user behavior. Experiments on existing benchmarks and a newly curated multimodal dataset demonstrate the effectiveness of our approach, laying the groundwork for scalable computational analysis of cognitive fixation. All code in this project is publicly available for research purposes at this https URL.         ",
    "url": "https://arxiv.org/abs/2509.04823",
    "authors": [
      "Yujie Wang",
      "Yunwei Zhao",
      "Jing Yang",
      "Han Han",
      "Shiguang Shan",
      "Jie Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2509.04877",
    "title": "Integrating Large Language Models in Software Engineering Education: A Pilot Study through GitHub Repositories Mining",
    "abstract": "           Context: Large Language Models (LLMs) such as ChatGPT are increasingly adopted in software engineering (SE) education, offering both opportunities and challenges. Their adoption requires systematic investigation to ensure responsible integration into curricula. Objective: This doctoral research aims to develop a validated framework for integrating LLMs into SE education through a multi-phase process, including taxonomies development, empirical investigation, and case studies. This paper presents the first empirical step. Method: We conducted a pilot repository mining study of 400 GitHub projects, analyzing README files and issues discussions to identify the presence of motivator and demotivator previously synthesized in our literature review [ 8] study. Results: Motivators such as engagement and motivation (227 hits), software engineering process understanding (133 hits), and programming assistance and debugging support (97 hits) were strongly represented. Demotivators, including plagiarism and IP concerns (385 hits), security, privacy and data integrity (87 hits), and over-reliance on AI in learning (39 hits), also appeared prominently. In contrast, demotivators such as challenges in evaluating learning outcomes and difficulty in curriculum redesign recorded no hits across the repositories. Conclusion: The study provides early empirical validation of motivators/demotivators taxonomies with respect to their themes, highlights research practice gaps, and lays the foundation for developing a comprehensive framework to guide the responsible adoption of LLMs in SE education.         ",
    "url": "https://arxiv.org/abs/2509.04877",
    "authors": [
      "Maryam Khan",
      "Muhammad Azeem Akbar",
      "Jussi Kasurinen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2509.04887",
    "title": "RINSER: Accurate API Prediction Using Masked Language Models",
    "abstract": "           Malware authors commonly use obfuscation to hide API identities in binary files, making analysis difficult and time-consuming for a human expert to understand the behavior and intent of the program. Automatic API prediction tools are necessary to efficiently analyze unknown binaries, facilitating rapid malware triage while reducing the workload on human analysts. In this paper, we present RINSER (AccuRate API predictioN using maSked languagE model leaRning), an automated framework for predicting Windows API (WinAPI) function names. RINSER introduces the novel concept of API codeprints, a set of API-relevant assembly instructions, and supports x86 PE binaries. RINSER relies on BERT's masked language model (LM) to predict API names at scale, achieving 85.77% accuracy for normal binaries and 82.88% accuracy for stripped binaries. We evaluate RINSER on a large dataset of 4.7M API codeprints from 11,098 malware binaries, covering 4,123 unique Windows APIs, making it the largest publicly available dataset of this type. RINSER successfully discovered 65 obfuscated Windows APIs related to C2 communication, spying, and evasion in our dataset, which the commercial disassembler IDA failed to identify. Furthermore, we compared RINSER against three state-of-the-art approaches, showing over 20% higher prediction accuracy. We also demonstrated RINSER's resilience to adversarial attacks, including instruction randomization and code displacement, with a performance drop of no more than 3%.         ",
    "url": "https://arxiv.org/abs/2509.04887",
    "authors": [
      "Muhammad Ejaz Ahmed",
      "Christopher Cody",
      "Muhammad Ikram",
      "Sean Lamont",
      "Alsharif Abuadbba",
      "Seyit Camtepe",
      "Surya Nepal",
      "Muhammad Ali Kaafar"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2509.04908",
    "title": "SparkUI-Parser: Enhancing GUI Perception with Robust Grounding and Parsing",
    "abstract": "           The existing Multimodal Large Language Models (MLLMs) for GUI perception have made great progress. However, the following challenges still exist in prior methods: 1) They model discrete coordinates based on text autoregressive mechanism, which results in lower grounding accuracy and slower inference speed. 2) They can only locate predefined sets of elements and are not capable of parsing the entire interface, which hampers the broad application and support for downstream tasks. To address the above issues, we propose SparkUI-Parser, a novel end-to-end framework where higher localization precision and fine-grained parsing capability of the entire interface are simultaneously achieved. Specifically, instead of using probability-based discrete modeling, we perform continuous modeling of coordinates based on a pre-trained Multimodal Large Language Model (MLLM) with an additional token router and coordinate decoder. This effectively mitigates the limitations inherent in the discrete output characteristics and the token-by-token generation process of MLLMs, consequently boosting both the accuracy and the inference speed. To further enhance robustness, a rejection mechanism based on a modified Hungarian matching algorithm is introduced, which empowers the model to identify and reject non-existent elements, thereby reducing false positives. Moreover, we present ScreenParse, a rigorously constructed benchmark to systematically assess structural perception capabilities of GUI models across diverse scenarios. Extensive experiments demonstrate that our approach consistently outperforms SOTA methods on ScreenSpot, ScreenSpot-v2, CAGUI-Grounding and ScreenParse benchmarks. The resources are available at this https URL.         ",
    "url": "https://arxiv.org/abs/2509.04908",
    "authors": [
      "Hongyi Jing",
      "Jiafu Chen",
      "Chen Rao",
      "Ziqiang Dang",
      "Jiajie Teng",
      "Tianyi Chu",
      "Juncheng Mo",
      "Shuo Fang",
      "Huaizhong Lin",
      "Rui Lv",
      "Chenguang Ma",
      "Lei Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2509.04925",
    "title": "A transformer-BiGRU-based framework with data augmentation and confident learning for network intrusion detection",
    "abstract": "           In today's fast-paced digital communication, the surge in network traffic data and frequency demands robust and precise network intrusion solutions. Conventional machine learning methods struggle to grapple with complex patterns within the vast network intrusion datasets, which suffer from data scarcity and class imbalance. As a result, we have integrated machine learning and deep learning techniques within the network intrusion detection system to bridge this gap. This study has developed TrailGate, a novel framework that combines machine learning and deep learning techniques. By integrating Transformer and Bidirectional Gated Recurrent Unit (BiGRU) architectures with advanced feature selection strategies and supplemented by data augmentation techniques, TrailGate can identifies common attack types and excels at detecting and mitigating emerging threats. This algorithmic fusion excels at detecting common and well-understood attack types and has the unique ability to swiftly identify and neutralize emerging threats that stem from existing paradigms.         ",
    "url": "https://arxiv.org/abs/2509.04925",
    "authors": [
      "Jiale Zhang",
      "Pengfei He",
      "Fei Li",
      "Kewei Li",
      "Yan Wang",
      "Lan Huang",
      "Ruochi Zhang",
      "Fengfeng Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2509.04958",
    "title": "Learning Multidimensional Urban Poverty Representation with Satellite Imagery",
    "abstract": "           Recent advances in deep learning have enabled the inference of urban socioeconomic characteristics from satellite imagery. However, models relying solely on urbanization traits often show weak correlations with poverty indicators, as unplanned urban growth can obscure economic disparities and spatial inequalities. To address this limitation, we introduce a novel representation learning framework that captures multidimensional deprivation-related traits from very high-resolution satellite imagery for precise urban poverty mapping. Our approach integrates three complementary traits: (1) accessibility traits, learned via contrastive learning to encode proximity to essential infrastructure; (2) morphological traits, derived from building footprints to reflect housing conditions in informal settlements; and (3) economic traits, inferred from nightlight intensity as a proxy for economic activity. To mitigate spurious correlations - such as those from non-residential nightlight sources that misrepresent poverty conditions - we incorporate a backdoor adjustment mechanism that leverages morphological traits during training of the economic module. By fusing these complementary features into a unified representation, our framework captures the complex nature of poverty, which often diverges from economic development trends. Evaluations across three capital cities - Cape Town, Dhaka, and Phnom Penh - show that our model significantly outperforms existing baselines, offering a robust tool for poverty mapping and policy support in data-scarce regions.         ",
    "url": "https://arxiv.org/abs/2509.04958",
    "authors": [
      "Sungwon Park",
      "Sumin Lee",
      "Jihee Kim",
      "Jae-Gil Lee",
      "Meeyoung Cha",
      "Jeasurk Yang",
      "Donghyun Ahn"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2509.04966",
    "title": "Neuro-Spectral Architectures for Causal Physics-Informed Networks",
    "abstract": "           Physics-Informed Neural Networks (PINNs) have emerged as a powerful neural framework for solving partial differential equations (PDEs). However, standard MLP-based PINNs often fail to converge when dealing with complex initial-value problems, leading to solutions that violate causality and suffer from a spectral bias towards low-frequency components. To address these issues, we introduce NeuSA (Neuro-Spectral Architectures), a novel class of PINNs inspired by classical spectral methods, designed to solve linear and nonlinear PDEs with variable coefficients. NeuSA learns a projection of the underlying PDE onto a spectral basis, leading to a finite-dimensional representation of the dynamics which is then integrated with an adapted Neural ODE (NODE). This allows us to overcome spectral bias, by leveraging the high-frequency components enabled by the spectral representation; to enforce causality, by inheriting the causal structure of NODEs, and to start training near the target solution, by means of an initialization scheme based on classical methods. We validate NeuSA on canonical benchmarks for linear and nonlinear wave equations, demonstrating strong performance as compared to other architectures, with faster convergence, improved temporal consistency and superior predictive accuracy. Code and pretrained models will be released.         ",
    "url": "https://arxiv.org/abs/2509.04966",
    "authors": [
      "Arthur Bizzi",
      "Leonardo M. Moreira",
      "M\u00e1rcio Marques",
      "Leonardo Mendon\u00e7a",
      "Christian J\u00fanior de Oliveira",
      "Vitor Balestro",
      "Lucas dos Santos Fernandez",
      "Daniel Yukimura",
      "Pavel Petrov",
      "Jo\u00e3o M. Pereira",
      "Tiago Novello",
      "Lucas Nissenbaum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.04973",
    "title": "Topology-Aware Graph Reinforcement Learning for Dynamic Routing in Cloud Networks",
    "abstract": "           This paper proposes a topology-aware graph reinforcement learning approach to address the routing policy optimization problem in cloud server environments. The method builds a unified framework for state representation and structural evolution by integrating a Structure-Aware State Encoding (SASE) module and a Policy-Adaptive Graph Update (PAGU) mechanism. It aims to tackle the challenges of decision instability and insufficient structural awareness under dynamic topologies. The SASE module models node states through multi-layer graph convolution and structural positional embeddings, capturing high-order dependencies in the communication topology and enhancing the expressiveness of state representations. The PAGU module adjusts the graph structure based on policy behavior shifts and reward feedback, enabling adaptive structural updates in dynamic environments. Experiments are conducted on the real-world GEANT topology dataset, where the model is systematically evaluated against several representative baselines in terms of throughput, latency control, and link balance. Additional experiments, including hyperparameter sensitivity, graph sparsity perturbation, and node feature dimensionality variation, further explore the impact of structure modeling and graph updates on model stability and decision quality. Results show that the proposed method outperforms existing graph reinforcement learning models across multiple performance metrics, achieving efficient and robust routing in dynamic and complex cloud networks.         ",
    "url": "https://arxiv.org/abs/2509.04973",
    "authors": [
      "Yuxi Wang",
      "Heyao Liu",
      "Guanzi Yao",
      "Nyutian Long",
      "Yue Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.04980",
    "title": "MAIA: An Inpainting-Based Approach for Music Adversarial Attacks",
    "abstract": "           Music adversarial attacks have garnered significant interest in the field of Music Information Retrieval (MIR). In this paper, we present Music Adversarial Inpainting Attack (MAIA), a novel adversarial attack framework that supports both white-box and black-box attack scenarios. MAIA begins with an importance analysis to identify critical audio segments, which are then targeted for modification. Utilizing generative inpainting models, these segments are reconstructed with guidance from the output of the attacked model, ensuring subtle and effective adversarial perturbations. We evaluate MAIA on multiple MIR tasks, demonstrating high attack success rates in both white-box and black-box settings while maintaining minimal perceptual distortion. Additionally, subjective listening tests confirm the high audio fidelity of the adversarial samples. Our findings highlight vulnerabilities in current MIR systems and emphasize the need for more robust and secure models.         ",
    "url": "https://arxiv.org/abs/2509.04980",
    "authors": [
      "Yuxuan Liu",
      "Peihong Zhang",
      "Rui Sang",
      "Zhixin Li",
      "Shengchen Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2509.04985",
    "title": "Training a Perceptual Model for Evaluating Auditory Similarity in Music Adversarial Attack",
    "abstract": "           Music Information Retrieval (MIR) systems are highly vulnerable to adversarial attacks that are often imperceptible to humans, primarily due to a misalignment between model feature spaces and human auditory perception. Existing defenses and perceptual metrics frequently fail to adequately capture these auditory nuances, a limitation supported by our initial listening tests showing low correlation between common metrics and human judgments. To bridge this gap, we introduce Perceptually-Aligned MERT Transformer (PAMT), a novel framework for learning robust, perceptually-aligned music representations. Our core innovation lies in the psychoacoustically-conditioned sequential contrastive transformer, a lightweight projection head built atop a frozen MERT encoder. PAMT achieves a Spearman correlation coefficient of 0.65 with subjective scores, outperforming existing perceptual metrics. Our approach also achieves an average of 9.15\\% improvement in robust accuracy on challenging MIR tasks, including Cover Song Identification and Music Genre Classification, under diverse perceptual adversarial attacks. This work pioneers architecturally-integrated psychoacoustic conditioning, yielding representations significantly more aligned with human perception and robust against music adversarial attacks.         ",
    "url": "https://arxiv.org/abs/2509.04985",
    "authors": [
      "Yuxuan Liu",
      "Rui Sang",
      "Peihong Zhang",
      "Zhixin Li",
      "Shengchen Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2509.04998",
    "title": "Directed Evolution of Proteins via Bayesian Optimization in Embedding Space",
    "abstract": "           Directed evolution is an iterative laboratory process of designing proteins with improved function by iteratively synthesizing new protein variants and evaluating their desired property with expensive and time-consuming biochemical screening. Machine learning methods can help select informative or promising variants for screening to increase their quality and reduce the amount of necessary screening. In this paper, we present a novel method for machine-learning-assisted directed evolution of proteins which combines Bayesian optimization with informative representation of protein variants extracted from a pre-trained protein language model. We demonstrate that the new representation based on the sequence embeddings significantly improves the performance of Bayesian optimization yielding better results with the same number of conducted screening in total. At the same time, our method outperforms the state-of-the-art machine-learning-assisted directed evolution methods with regression objective.         ",
    "url": "https://arxiv.org/abs/2509.04998",
    "authors": [
      "Matou\u0161 Sold\u00e1t",
      "Ji\u0159\u00ed Kl\u00e9ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2509.04999",
    "title": "Adversarial Augmentation and Active Sampling for Robust Cyber Anomaly Detection",
    "abstract": "           Advanced Persistent Threats (APTs) present a considerable challenge to cybersecurity due to their stealthy, long-duration nature. Traditional supervised learning methods typically require large amounts of labeled data, which is often scarce in real-world scenarios. This paper introduces a novel approach that combines AutoEncoders for anomaly detection with active learning to iteratively enhance APT detection. By selectively querying an oracle for labels on uncertain or ambiguous samples, our method reduces labeling costs while improving detection accuracy, enabling the model to effectively learn with minimal data and reduce reliance on extensive manual labeling. We present a comprehensive formulation of the Attention Adversarial Dual AutoEncoder-based anomaly detection framework and demonstrate how the active learning loop progressively enhances the model's performance. The framework is evaluated on real-world, imbalanced provenance trace data from the DARPA Transparent Computing program, where APT-like attacks account for just 0.004\\% of the data. The datasets, which cover multiple operating systems including Android, Linux, BSD, and Windows, are tested in two attack scenarios. The results show substantial improvements in detection rates during active learning, outperforming existing methods.         ",
    "url": "https://arxiv.org/abs/2509.04999",
    "authors": [
      "Sidahmed Benabderrahmane",
      "Talal Rahwan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.05000",
    "title": "Dual-Domain Perspective on Degradation-Aware Fusion: A VLM-Guided Robust Infrared and Visible Image Fusion Framework",
    "abstract": "           Most existing infrared-visible image fusion (IVIF) methods assume high-quality inputs, and therefore struggle to handle dual-source degraded scenarios, typically requiring manual selection and sequential application of multiple pre-enhancement steps. This decoupled pre-enhancement-to-fusion pipeline inevitably leads to error accumulation and performance degradation. To overcome these limitations, we propose Guided Dual-Domain Fusion (GD^2Fusion), a novel framework that synergistically integrates vision-language models (VLMs) for degradation perception with dual-domain (frequency/spatial) joint optimization. Concretely, the designed Guided Frequency Modality-Specific Extraction (GFMSE) module performs frequency-domain degradation perception and suppression and discriminatively extracts fusion-relevant sub-band features. Meanwhile, the Guided Spatial Modality-Aggregated Fusion (GSMAF) module carries out cross-modal degradation filtering and adaptive multi-source feature aggregation in the spatial domain to enhance modality complementarity and structural consistency. Extensive qualitative and quantitative experiments demonstrate that GD^2Fusion achieves superior fusion performance compared with existing algorithms and strategies in dual-source degraded scenarios. The code will be publicly released after acceptance of this paper.         ",
    "url": "https://arxiv.org/abs/2509.05000",
    "authors": [
      "Tianpei Zhang",
      "Jufeng Zhao",
      "Yiming Zhu",
      "Guangmang Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.05002",
    "title": "Graph Reconstruction with a Connected Components Oracle",
    "abstract": "           In the Graph Reconstruction (GR) problem, the goal is to recover a hidden graph by utilizing some oracle that provides limited access to the structure of the graph. The interest is in characterizing how strong different oracles are when the complexity of an algorithm is measured in the number of performed queries. We study a novel oracle that returns the set of connected components (CC) on the subgraph induced by the queried subset of vertices. Our main contributions are as follows: 1. For a hidden graph with $n$ vertices, $m$ edges, maximum degree $\\Delta$, and treewidth $k$, GR can be solved in $O(\\min\\{m, \\Delta^2, k^2\\} \\cdot \\log n)$ CC queries by an adaptive randomized algorithm. 2. For a hidden graph with $n$ vertices, $m$ edges, maximum degree $\\Delta$, and treewidth $k$, no algorithm can solve GR in $o(\\min\\{m, \\Delta^2, k^2\\})$ CC queries.         ",
    "url": "https://arxiv.org/abs/2509.05002",
    "authors": [
      "Juha Harviainen",
      "Pekka Parviainen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2509.05003",
    "title": "Estimating Cellular Network Delays in Finnish Railways: A Machine Learning Enhanced Approach",
    "abstract": "           There is growing interest in using public cellular networks for specialized communication applications, replacing standalone sector-specific networks. One such application is transitioning from the aging GSM-R railway network to public 4G and 5G networks. Finland is modernizing its railway communication system through the Digirail project, leveraging public cellular networks. To evaluate network performance, a nationwide measurement campaign was conducted in two modes: Best Quality and Packet Replication. However, Best Quality mode introduces artificial delays, making it unsuitable for real-world assessments. In this paper, railway network delays are modeled using machine learning based on measurements from the Packet Replication mode. The best-performing model is then employed to generate a dataset estimating network delays across Finland's railway network. This dataset provides a more accurate representation of network performance. Machine learning based network performance prediction is shown to be feasible, and the results indicate that Finland's public cellular network can meet the stringent performance requirements of railway network control.         ",
    "url": "https://arxiv.org/abs/2509.05003",
    "authors": [
      "Saeideh Mansouri",
      "Mohamed Shamekh",
      "Simon Indola",
      "Petri Mahonen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2509.05018",
    "title": "Depth-Aware Initialization for Stable and Efficient Neural Network Training",
    "abstract": "           In past few years, various initialization schemes have been proposed. These schemes are glorot initialization, He initialization, initialization using orthogonal matrix, random walk method for initialization. Some of these methods stress on keeping unit variance of activation and gradient propagation through the network layer. Few of these methods are independent of the depth information while some methods has considered the total network depth for better initialization. In this paper, comprehensive study has been done where depth information of each layer as well as total network is incorporated for better initialization scheme. It has also been studied that for deeper networks theoretical assumption of unit variance throughout the network does not perform well. It requires the need to increase the variance of the network from first layer activation to last layer activation. We proposed a novel way to increase the variance of the network in flexible manner, which incorporates the information of each layer depth. Experiments shows that proposed method performs better than the existing initialization scheme.         ",
    "url": "https://arxiv.org/abs/2509.05018",
    "authors": [
      "Vijay Pandey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.05019",
    "title": "Leveraging Transfer Learning and Mobile-enabled Convolutional Neural Networks for Improved Arabic Handwritten Character Recognition",
    "abstract": "           The study explores the integration of transfer learning (TL) with mobile-enabled convolutional neural networks (MbNets) to enhance Arabic Handwritten Character Recognition (AHCR). Addressing challenges like extensive computational requirements and dataset scarcity, this research evaluates three TL strategies--full fine-tuning, partial fine-tuning, and training from scratch--using four lightweight MbNets: MobileNet, SqueezeNet, MnasNet, and ShuffleNet. Experiments were conducted on three benchmark datasets: AHCD, HIJJA, and IFHCDB. MobileNet emerged as the top-performing model, consistently achieving superior accuracy, robustness, and efficiency, with ShuffleNet excelling in generalization, particularly under full fine-tuning. The IFHCDB dataset yielded the highest results, with 99% accuracy using MnasNet under full fine-tuning, highlighting its suitability for robust character recognition. The AHCD dataset achieved competitive accuracy (97%) with ShuffleNet, while HIJJA posed significant challenges due to its variability, achieving a peak accuracy of 92% with ShuffleNet. Notably, full fine-tuning demonstrated the best overall performance, balancing accuracy and convergence speed, while partial fine-tuning underperformed across metrics. These findings underscore the potential of combining TL and MbNets for resource-efficient AHCR, paving the way for further optimizations and broader applications. Future work will explore architectural modifications, in-depth dataset feature analysis, data augmentation, and advanced sensitivity analysis to enhance model robustness and generalizability.         ",
    "url": "https://arxiv.org/abs/2509.05019",
    "authors": [
      "Mohsine El Khayati",
      "Ayyad Maafiri",
      "Yassine Himeur",
      "Hamzah Ali Alkhazaleh",
      "Shadi Atalla",
      "Wathiq Mansoor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.05034",
    "title": "Towards Efficient Pixel Labeling for Industrial Anomaly Detection and Localization",
    "abstract": "           Industrial product inspection is often performed using Anomaly Detection (AD) frameworks trained solely on non-defective samples. Although defective samples can be collected during production, leveraging them usually requires pixel-level annotations, limiting scalability. To address this, we propose ADClick, an Interactive Image Segmentation (IIS) algorithm for industrial anomaly detection. ADClick generates pixel-wise anomaly annotations from only a few user clicks and a brief textual description, enabling precise and efficient labeling that significantly improves AD model performance (e.g., AP = 96.1\\% on MVTec AD). We further introduce ADClick-Seg, a cross-modal framework that aligns visual features and textual prompts via a prototype-based approach for anomaly detection and localization. By combining pixel-level priors with language-guided cues, ADClick-Seg achieves state-of-the-art results on the challenging ``Multi-class'' AD task (AP = 80.0\\%, PRO = 97.5\\%, Pixel-AUROC = 99.1\\% on MVTec AD).         ",
    "url": "https://arxiv.org/abs/2509.05034",
    "authors": [
      "Jingqi Wu",
      "Hanxi Li",
      "Lin Yuanbo Wu",
      "Hao Chen",
      "Deyin Liu",
      "Peng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.05066",
    "title": "ToM-SSI: Evaluating Theory of Mind in Situated Social Interactions",
    "abstract": "           Most existing Theory of Mind (ToM) benchmarks for foundation models rely on variations of the Sally-Anne test, offering only a very limited perspective on ToM and neglecting the complexity of human social interactions. To address this gap, we propose ToM-SSI: a new benchmark specifically designed to test ToM capabilities in environments rich with social interactions and spatial dynamics. While current ToM benchmarks are limited to text-only or dyadic interactions, ToM-SSI is multimodal and includes group interactions of up to four agents that communicate and move in situated environments. This unique design allows us to study, for the first time, mixed cooperative-obstructive settings and reasoning about multiple agents' mental state in parallel, thus capturing a wider range of social cognition than existing benchmarks. Our evaluations reveal that the current models' performance is still severely limited, especially in these new tasks, highlighting critical gaps for future research.         ",
    "url": "https://arxiv.org/abs/2509.05066",
    "authors": [
      "Matteo Bortoletto",
      "Constantin Ruhdorfer",
      "Andreas Bulling"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.05071",
    "title": "Systematic Review and Meta-analysis of AI-driven MRI Motion Artifact Detection and Correction",
    "abstract": "           Background: To systematically review and perform a meta-analysis of artificial intelligence (AI)-driven methods for detecting and correcting magnetic resonance imaging (MRI) motion artifacts, assessing current developments, effectiveness, challenges, and future research directions. Methods: A comprehensive systematic review and meta-analysis were conducted, focusing on deep learning (DL) approaches, particularly generative models, for the detection and correction of MRI motion artifacts. Quantitative data were extracted regarding utilized datasets, DL architectures, and performance metrics. Results: DL, particularly generative models, show promise for reducing motion artifacts and improving image quality; however, limited generalizability, reliance on paired training data, and risk of visual distortions remain key challenges that motivate standardized datasets and reporting. Conclusions: AI-driven methods, particularly DL generative models, show significant potential for improving MRI image quality by effectively addressing motion artifacts. However, critical challenges must be addressed, including the need for comprehensive public datasets, standardized reporting protocols for artifact levels, and more advanced, adaptable DL techniques to reduce reliance on extensive paired datasets. Addressing these aspects could substantially enhance MRI diagnostic accuracy, reduce healthcare costs, and improve patient care outcomes.         ",
    "url": "https://arxiv.org/abs/2509.05071",
    "authors": [
      "Mojtaba Safari",
      "Zach Eidex",
      "Richard L.J. Qiu",
      "Matthew Goette",
      "Tonghe Wang",
      "Xiaofeng Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2509.05072",
    "title": "Finding your MUSE: Mining Unexpected Solutions Engine",
    "abstract": "           Innovators often exhibit cognitive fixation on existing solutions or nascent ideas, hindering the exploration of novel alternatives. This paper introduces a methodology for constructing Functional Concept Graphs (FCGs), interconnected representations of functional elements that support abstraction, problem reframing, and analogical inspiration. Our approach yields large-scale, high-quality FCGs with explicit abstraction relations, overcoming limitations of prior work. We further present MUSE, an algorithm leveraging FCGs to generate creative inspirations for a given problem. We demonstrate our method by computing an FCG on 500K patents, which we release for further research.         ",
    "url": "https://arxiv.org/abs/2509.05072",
    "authors": [
      "Nir Sweed",
      "Hanit Hakim",
      "Ben Wolfson",
      "Hila Lifshitz",
      "Dafna Shahaf"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2509.05078",
    "title": "Scale-interaction transformer: a hybrid cnn-transformer model for facial beauty prediction",
    "abstract": "           Automated Facial Beauty Prediction (FBP) is a challenging computer vision task due to the complex interplay of local and global facial features that influence human perception. While Convolutional Neural Networks (CNNs) excel at feature extraction, they often process information at a fixed scale, potentially overlooking the critical inter-dependencies between features at different levels of granularity. To address this limitation, we introduce the Scale-Interaction Transformer (SIT), a novel hybrid deep learning architecture that synergizes the feature extraction power of CNNs with the relational modeling capabilities of Transformers. The SIT first employs a multi-scale module with parallel convolutions to capture facial characteristics at varying receptive fields. These multi-scale representations are then framed as a sequence and processed by a Transformer encoder, which explicitly models their interactions and contextual relationships via a self-attention mechanism. We conduct extensive experiments on the widely-used SCUT-FBP5500 benchmark dataset, where the proposed SIT model establishes a new state-of-the-art. It achieves a Pearson Correlation of 0.9187, outperforming previous methods. Our findings demonstrate that explicitly modeling the interplay between multi-scale visual cues is crucial for high-performance FBP. The success of the SIT architecture highlights the potential of hybrid CNN-Transformer models for complex image regression tasks that demand a holistic, context-aware understanding.         ",
    "url": "https://arxiv.org/abs/2509.05078",
    "authors": [
      "Djamel Eddine Boukhari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.05084",
    "title": "Recurrent State Encoders for Efficient Neural Combinatorial Optimization",
    "abstract": "           The primary paradigm in Neural Combinatorial Optimization (NCO) are construction methods, where a neural network is trained to sequentially add one solution component at a time until a complete solution is constructed. We observe that the typical changes to the state between two steps are small, since usually only the node that gets added to the solution is removed from the state. An efficient model should be able to reuse computation done in prior steps. To that end, we propose to train a recurrent encoder that computes the state embeddings not only based on the state but also the embeddings of the step before. We show that the recurrent encoder can achieve equivalent or better performance than a non-recurrent encoder even if it consists of $3\\times$ fewer layers, thus significantly improving on latency. We demonstrate our findings on three different problems: the Traveling Salesman Problem (TSP), the Capacitated Vehicle Routing Problem (CVRP), and the Orienteering Problem (OP) and integrate the models into a large neighborhood search algorithm, to showcase the practical relevance of our findings.         ",
    "url": "https://arxiv.org/abs/2509.05084",
    "authors": [
      "Tim Dernedde",
      "Daniela Thyssens",
      "Lars Schmidt-Thieme"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.05086",
    "title": "Robust Experts: the Effect of Adversarial Training on CNNs with Sparse Mixture-of-Experts Layers",
    "abstract": "           Robustifying convolutional neural networks (CNNs) against adversarial attacks remains challenging and often requires resource-intensive countermeasures. We explore the use of sparse mixture-of-experts (MoE) layers to improve robustness by replacing selected residual blocks or convolutional layers, thereby increasing model capacity without additional inference cost. On ResNet architectures trained on CIFAR-100, we find that inserting a single MoE layer in the deeper stages leads to consistent improvements in robustness under PGD and AutoPGD attacks when combined with adversarial training. Furthermore, we discover that when switch loss is used for balancing, it causes routing to collapse onto a small set of overused experts, thereby concentrating adversarial training on these paths and inadvertently making them more robust. As a result, some individual experts outperform the gated MoE model in robustness, suggesting that robust subpaths emerge through specialization. Our code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2509.05086",
    "authors": [
      "Svetlana Pavlitska",
      "Haixi Fan",
      "Konstantin Ditschuneit",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.05115",
    "title": "Hybrid Matrix Factorization Based Graph Contrastive Learning for Recommendation System",
    "abstract": "           In recent years, methods that combine contrastive learning with graph neural networks have emerged to address the challenges of recommendation systems, demonstrating powerful performance and playing a significant role in this domain. Contrastive learning primarily tackles the issue of data sparsity by employing data augmentation strategies, effectively alleviating this problem and showing promising results. Although existing research has achieved favorable outcomes, most current graph contrastive learning methods are based on two types of data augmentation strategies: the first involves perturbing the graph structure, such as by randomly adding or removing edges; and the second applies clustering techniques. We believe that the interactive information obtained through these two strategies does not fully capture the user-item interactions. In this paper, we propose a novel method called HMFGCL (Hybrid Matrix Factorization Based Graph Contrastive Learning), which integrates two distinct matrix factorization techniques-low-rank matrix factorization (MF) and singular value decomposition (SVD)-to complementarily acquire global collaborative information, thereby constructing enhanced views. Experimental results on multiple public datasets demonstrate that our model outperforms existing baselines, particularly on small-scale datasets.         ",
    "url": "https://arxiv.org/abs/2509.05115",
    "authors": [
      "Hao Chen",
      "Wenming Ma",
      "Zihao Chu",
      "Mingqi Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2509.05117",
    "title": "HyPINO: Multi-Physics Neural Operators via HyperPINNs and the Method of Manufactured Solutions",
    "abstract": "           We present HyPINO, a multi-physics neural operator designed for zero-shot generalization across a broad class of parametric PDEs without requiring task-specific fine-tuning. Our approach combines a Swin Transformer-based hypernetwork with mixed supervision: (i) labeled data from analytical solutions generated via the Method of Manufactured Solutions (MMS), and (ii) unlabeled samples optimized using physics-informed objectives. The model maps PDE parametrizations to target Physics-Informed Neural Networks (PINNs) and can handle linear elliptic, hyperbolic, and parabolic equations in two dimensions with varying source terms, geometries, and mixed Dirichlet/Neumann boundary conditions, including interior boundaries. HyPINO achieves strong zero-shot accuracy on seven benchmark problems from PINN literature, outperforming U-Nets, Poseidon, and Physics-Informed Neural Operators (PINO). Further, we introduce an iterative refinement procedure that compares the physics of the generated PINN to the requested PDE and uses the discrepancy to generate a \"delta\" PINN. Summing their contributions and repeating this process forms an ensemble whose combined solution progressively reduces the error on six benchmarks and achieves over 100x gain in average $L_2$ loss in the best case, while retaining forward-only inference. Additionally, we evaluate the fine-tuning behavior of PINNs initialized by HyPINO and show that they converge faster and to lower final error than both randomly initialized and Reptile-meta-learned PINNs on five benchmarks, performing on par on the remaining two. Our results highlight the potential of this scalable approach as a foundation for extending neural operators toward solving increasingly complex, nonlinear, and high-dimensional PDE problems with significantly improved accuracy and reduced computational cost.         ",
    "url": "https://arxiv.org/abs/2509.05117",
    "authors": [
      "Rafael Bischof",
      "Michal Piovar\u010di",
      "Michael A. Kraus",
      "Siddhartha Mishra",
      "Bernd Bickel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.05122",
    "title": "Improved Bounds for Twin-Width Parameter Variants with Algorithmic Applications to Counting Graph Colorings",
    "abstract": "           The $H$-Coloring problem is a well-known generalization of the classical NP-complete problem $k$-Coloring where the task is to determine whether an input graph admits a homomorphism to the template graph $H$. This problem has been the subject of intense theoretical research and in this article we study the complexity of $H$-Coloring with respect to the parameters clique-width and the more recent component twin-width, which describe desirable computational properties of graphs. We give two surprising linear bounds between these parameters, thus improving the previously known exponential and double exponential bounds. Our constructive proof naturally extends to related parameters and as a showcase we prove that total twin-width and linear clique-width can be related via a tight quadratic bound. These bounds naturally lead to algorithmic applications. The linear bounds between component twin-width and clique-width entail natural approximations of component twin-width, by making use of the results known for clique-width. As for computational aspects of graph coloring, we target the richer problem of counting the number of homomorphisms to $H$ (#$H$-Coloring). The first algorithm that we propose uses a contraction sequence of the input graph $G$ parameterized by the component twin-width of $G$. This leads to a positive FPT result for the counting version. The second uses a contraction sequence of the template graph $H$ and here we instead measure the complexity with respect to the number of vertices in the input graph. Using our linear bounds we show that our algorithms are always at least as fast as the previously best #$H$-Coloring algorithms (based on clique-width) and for several interesting classes of graphs (e.g., cographs, cycles of length $\\ge 7$, or distance-hereditary graphs) are in fact strictly faster.         ",
    "url": "https://arxiv.org/abs/2509.05122",
    "authors": [
      "Ambroise Baril",
      "Miguel Couceiro",
      "Victor Lagerkvist"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2509.05157",
    "title": "Efficient Contractions of Dynamic Graphs -- with Applications",
    "abstract": "           A non-trivial minimum cut (NMC) sparsifier is a multigraph $\\hat{G}$ that preserves all non-trivial minimum cuts of a given undirected graph $G$. We introduce a flexible data structure for fully dynamic graphs that can efficiently provide an NMC sparsifier upon request at any point during the sequence of updates. We employ simple dynamic forest data structures to achieve a fast from-scratch construction of the sparsifier at query time. Based on the strength of the adversary and desired type of time bounds, the data structure comes with different guarantees. Specifically, let $G$ be a fully dynamic simple graph with $n$ vertices and minimum degree $\\delta$. Then our data structure supports an insertion/deletion of an edge to/from $G$ in $n^{o(1)}$ worst-case time. Furthermore, upon request, it can return w.h.p. an NMC sparsifier of $G$ that has $O(n/\\delta)$ vertices and $O(n)$ edges, in $\\hat{O}(n)$ time. The probabilistic guarantees hold against an adaptive adversary. Alternatively, the update and query times can be improved to $\\tilde{O}(1)$ and $\\tilde{O}(n)$ respectively, if amortized-time guarantees are sufficient, or if the adversary is oblivious. We discuss two applications of our data structure. First, it can be used to efficiently report a cactus representation of all minimum cuts of a fully dynamic simple graph. Using the NMC sparsifier we can w.h.p. build this cactus in worst-case time $\\hat{O}(n)$ against an adaptive adversary. Second, our data structure allows us to efficiently compute the maximal $k$-edge-connected subgraphs of undirected simple graphs, by repeatedly applying a minimum cut algorithm on the NMC sparsifier. Specifically, we can compute w.h.p. the maximal $k$-edge-connected subgraphs of a simple graph with $n$ vertices and $m$ edges in $\\tilde{O}(m+n^2/k)$ time which is an improvement for $k = \\Omega(n^{1/8})$ and works for fully dynamic graphs.         ",
    "url": "https://arxiv.org/abs/2509.05157",
    "authors": [
      "Monika Henzinger",
      "Evangelos Kosinas",
      "Robin M\u00fcnk",
      "Harald R\u00e4cke"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2509.05162",
    "title": "Verifiability and Privacy in Federated Learning through Context-Hiding Multi-Key Homomorphic Authenticators",
    "abstract": "           Federated Learning has rapidly expanded from its original inception to now have a large body of research, several frameworks, and sold in a variety of commercial offerings. Thus, its security and robustness is of significant importance. There are many algorithms that provide robustness in the case of malicious clients. However, the aggregator itself may behave maliciously, for example, by biasing the model or tampering with the weights to weaken the models privacy. In this work, we introduce a verifiable federated learning protocol that enables clients to verify the correctness of the aggregators computation without compromising the confidentiality of their updates. Our protocol uses a standard secure aggregation technique to protect individual model updates with a linearly homomorphic authenticator scheme that enables efficient, privacy-preserving verification of the aggregated result. Our construction ensures that clients can detect manipulation by the aggregator while maintaining low computational overhead. We demonstrate that our approach scales to large models, enabling verification over large neural networks with millions of parameters.         ",
    "url": "https://arxiv.org/abs/2509.05162",
    "authors": [
      "Simone Bottoni",
      "Giulio Zizzo",
      "Stefano Braghin",
      "Alberto Trombetta"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2509.05167",
    "title": "Model predictive quantum control: A modular approach for efficient and robust quantum optimal control",
    "abstract": "           Model predictive control (MPC) is one of the most successful modern control methods. It relies on repeatedly solving a finite-horizon optimal control problem and applying the beginning piece of the optimal input. In this paper, we develop a modular framework for improving efficiency and robustness of quantum optimal control (QOC) via MPC. We first provide a tutorial introduction to basic concepts of MPC from a QOC perspective. We then present multiple MPC schemes, ranging from simple approaches to more sophisticated schemes which admit stability guarantees. This yields a modular framework which can be used 1) to improve efficiency of open-loop QOC and 2) to improve robustness of closed-loop quantum control by incorporating feedback. We demonstrate these benefits with numerical results, where we benchmark the proposed methods against competing approaches.         ",
    "url": "https://arxiv.org/abs/2509.05167",
    "authors": [
      "Eya Guizani",
      "Julian Berberich"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2509.05188",
    "title": "SL-SLR: Self-Supervised Representation Learning for Sign Language Recognition",
    "abstract": "           Sign language recognition (SLR) is a machine learning task aiming to identify signs in videos. Due to the scarcity of annotated data, unsupervised methods like contrastive learning have become promising in this field. They learn meaningful representations by pulling positive pairs (two augmented versions of the same instance) closer and pushing negative pairs (different from the positive pairs) apart. In SLR, in a sign video, only certain parts provide information that is truly useful for its recognition. Applying contrastive methods to SLR raises two issues: (i) contrastive learning methods treat all parts of a video in the same way, without taking into account the relevance of certain parts over others; (ii) shared movements between different signs make negative pairs highly similar, complicating sign discrimination. These issues lead to learning non-discriminative features for sign recognition and poor results in downstream tasks. In response, this paper proposes a self-supervised learning framework designed to learn meaningful representations for SLR. This framework consists of two key components designed to work together: (i) a new self-supervised approach with free-negative pairs; (ii) a new data augmentation technique. This approach shows a considerable gain in accuracy compared to several contrastive and self-supervised methods, across linear evaluation, semi-supervised learning, and transferability between sign languages.         ",
    "url": "https://arxiv.org/abs/2509.05188",
    "authors": [
      "Ariel Basso Madjoukeng",
      "J\u00e9r\u00f4me Fink",
      "Pierre Poitier",
      "Edith Belise Kenmogne",
      "Benoit Frenay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.05190",
    "title": "Accuracy-Constrained CNN Pruning for Efficient and Reliable EEG-Based Seizure Detection",
    "abstract": "           Deep learning models, especially convolutional neural networks (CNNs), have shown considerable promise for biomedical signals such as EEG-based seizure detection. However, these models come with challenges, primarily due to their size and compute requirements in environments where real-time detection or limited resources are available. In this study, we present a lightweight one-dimensional CNN model with structured pruning to improve efficiency and reliability. The model was trained with mild early stopping to address possible overfitting, achieving an accuracy of 92.78% and a macro-F1 score of 0.8686. Structured pruning of the baseline CNN involved removing 50% of the convolutional kernels based on their importance to model predictions. Surprisingly, after pruning the weights and memory by 50%, the new network was still able to maintain predictive capabilities, while modestly increasing precision to 92.87% and improving the macro-F1 score to 0.8707. Overall, we present a convincing case that structured pruning removes redundancy, improves generalization, and, in combination with mild early stopping, achieves a promising way forward to improve seizure detection efficiency and reliability, which is clear motivation for resource-limited settings.         ",
    "url": "https://arxiv.org/abs/2509.05190",
    "authors": [
      "Mounvik K",
      "N Harshit"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.05199",
    "title": "Triadic Fusion of Cognitive, Functional, and Causal Dimensions for Explainable LLMs: The TAXAL Framework",
    "abstract": "           Large Language Models (LLMs) are increasingly being deployed in high-risk domains where opacity, bias, and instability undermine trust and accountability. Traditional explainability methods, focused on surface outputs, do not capture the reasoning pathways, planning logic, and systemic impacts of agentic LLMs. We introduce TAXAL (Triadic Alignment for eXplainability in Agentic LLMs), a triadic fusion framework that unites three complementary dimensions: cognitive (user understanding), functional (practical utility), and causal (faithful reasoning). TAXAL provides a unified, role-sensitive foundation for designing, evaluating, and deploying explanations in diverse sociotechnical settings. Our analysis synthesizes existing methods, ranging from post-hoc attribution and dialogic interfaces to explanation-aware prompting, and situates them within the TAXAL triadic fusion model. We further demonstrate its applicability through case studies in law, education, healthcare, and public services, showing how explanation strategies adapt to institutional constraints and stakeholder roles. By combining conceptual clarity with design patterns and deployment pathways, TAXAL advances explainability as a technical and sociotechnical practice, supporting trustworthy and context-sensitive LLM applications in the era of agentic AI.         ",
    "url": "https://arxiv.org/abs/2509.05199",
    "authors": [
      "David Herrera-Poyatos",
      "Carlos Pel\u00e1ez-Gonz\u00e1lez",
      "Cristina Zuheros",
      "Virilo Tejedor",
      "Rosana Montes",
      "Francisco Herrera"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2509.05201",
    "title": "Robust Model Predictive Control Design for Autonomous Vehicles with Perception-based Observers",
    "abstract": "           This paper presents a robust model predictive control (MPC) framework that explicitly addresses the non-Gaussian noise inherent in deep learning-based perception modules used for state estimation. Recognizing that accurate uncertainty quantification of the perception module is essential for safe feedback control, our approach departs from the conventional assumption of zero-mean noise quantification of the perception error. Instead, it employs set-based state estimation with constrained zonotopes to capture biased, heavy-tailed uncertainties while maintaining bounded estimation errors. To improve computational efficiency, the robust MPC is reformulated as a linear program (LP), using a Minkowski-Lyapunov-based cost function with an added slack variable to prevent degenerate solutions. Closed-loop stability is ensured through Minkowski-Lyapunov inequalities and contractive zonotopic invariant sets. The largest stabilizing terminal set and its corresponding feedback gain are then derived via an ellipsoidal approximation of the zonotopes. The proposed framework is validated through both simulations and hardware experiments on an omnidirectional mobile robot along with a camera and a convolutional neural network-based perception module implemented within a ROS2 framework. The results demonstrate that the perception-aware MPC provides stable and accurate control performance under heavy-tailed noise conditions, significantly outperforming traditional Gaussian-noise-based designs in terms of both state estimation error bounding and overall control performance.         ",
    "url": "https://arxiv.org/abs/2509.05201",
    "authors": [
      "Nariman Niknejad",
      "Gokul S. Sankar",
      "Bahare Kiumarsi",
      "Hamidreza Modares"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2509.05207",
    "title": "RapidGNN: Energy and Communication-Efficient Distributed Training on Large-Scale Graph Neural Networks",
    "abstract": "           Graph Neural Networks (GNNs) have become popular across a diverse set of tasks in exploring structural relationships between entities. However, due to the highly connected structure of the datasets, distributed training of GNNs on large-scale graphs poses significant challenges. Traditional sampling-based approaches mitigate the computational loads, yet the communication overhead remains a challenge. This paper presents RapidGNN, a distributed GNN training framework with deterministic sampling-based scheduling to enable efficient cache construction and prefetching of remote features. Evaluation on benchmark graph datasets demonstrates RapidGNN's effectiveness across different scales and topologies. RapidGNN improves end-to-end training throughput by 2.46x to 3.00x on average over baseline methods across the benchmark datasets, while cutting remote feature fetches by over 9.70x to 15.39x. RapidGNN further demonstrates near-linear scalability with an increasing number of computing units efficiently. Furthermore, it achieves increased energy efficiency over the baseline methods for both CPU and GPU by 44% and 32%, respectively.         ",
    "url": "https://arxiv.org/abs/2509.05207",
    "authors": [
      "Arefin Niam",
      "Tevfik Kosar",
      "M S Q Zulkar Nine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.05213",
    "title": "An Efficient Subspace Algorithm for Federated Learning on Heterogeneous Data",
    "abstract": "           This work addresses the key challenges of applying federated learning to large-scale deep neural networks, particularly the issue of client drift due to data heterogeneity across clients and the high costs of communication, computation, and memory. We propose FedSub, an efficient subspace algorithm for federated learning on heterogeneous data. Specifically, FedSub utilizes subspace projection to guarantee local updates of each client within low-dimensional subspaces, thereby reducing communication, computation, and memory costs. Additionally, it incorporates low-dimensional dual variables to mitigate client drift. We provide convergence analysis that reveals the impact of key factors such as step size and subspace projection matrices on convergence. Experimental results demonstrate its efficiency.         ",
    "url": "https://arxiv.org/abs/2509.05213",
    "authors": [
      "Jiaojiao Zhang",
      "Yuqi Xu",
      "Kun Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2509.05230",
    "title": "CURE: Controlled Unlearning for Robust Embeddings -- Mitigating Conceptual Shortcuts in Pre-Trained Language Models",
    "abstract": "           Pre-trained language models have achieved remarkable success across diverse applications but remain susceptible to spurious, concept-driven correlations that impair robustness and fairness. In this work, we introduce CURE, a novel and lightweight framework that systematically disentangles and suppresses conceptual shortcuts while preserving essential content information. Our method first extracts concept-irrelevant representations via a dedicated content extractor reinforced by a reversal network, ensuring minimal loss of task-relevant information. A subsequent controllable debiasing module employs contrastive learning to finely adjust the influence of residual conceptual cues, enabling the model to either diminish harmful biases or harness beneficial correlations as appropriate for the target task. Evaluated on the IMDB and Yelp datasets using three pre-trained architectures, CURE achieves an absolute improvement of +10 points in F1 score on IMDB and +2 points on Yelp, while introducing minimal computational overhead. Our approach establishes a flexible, unsupervised blueprint for combating conceptual biases, paving the way for more reliable and fair language understanding systems.         ",
    "url": "https://arxiv.org/abs/2509.05230",
    "authors": [
      "Aysenur Kocak",
      "Shuo Yang",
      "Bardh Prenkaj",
      "Gjergji Kasneci"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.05238",
    "title": "Uncertain but Useful: Leveraging CNN Variability into Data Augmentation",
    "abstract": "           Deep learning (DL) is rapidly advancing neuroimaging by achieving state-of-the-art performance with reduced computation times. Yet the numerical stability of DL models -- particularly during training -- remains underexplored. While inference with DL is relatively stable, training introduces additional variability primarily through iterative stochastic optimization. We investigate this training-time variability using FastSurfer, a CNN-based whole-brain segmentation pipeline. Controlled perturbations are introduced via floating point perturbations and random seeds. We find that: (i) FastSurfer exhibits higher variability compared to that of a traditional neuroimaging pipeline, suggesting that DL inherits and is particularly susceptible to sources of instability present in its predecessors; (ii) ensembles generated with perturbations achieve performance similar to an unperturbed baseline; and (iii) variability effectively produces ensembles of numerical model families that can be repurposed for downstream applications. As a proof of concept, we demonstrate that numerical ensembles can be used as a data augmentation strategy for brain age regression. These findings position training-time variability not only as a reproducibility concern but also as a resource that can be harnessed to improve robustness and enable new applications in neuroimaging.         ",
    "url": "https://arxiv.org/abs/2509.05238",
    "authors": [
      "In\u00e9s Gonzalez-Pepe",
      "Vinuyan Sivakolunthu",
      "Yohan Chatelain",
      "Tristan Glatard"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.05259",
    "title": "A Kolmogorov-Arnold Network for Interpretable Cyberattack Detection in AGC Systems",
    "abstract": "           Automatic Generation Control (AGC) is essential for power grid stability but remains vulnerable to stealthy cyberattacks, such as False Data Injection Attacks (FDIAs), which can disturb the system's stability while evading traditional detection methods. Unlike previous works that relied on blackbox approaches, this work proposes Kolmogorov-Arnold Networks (KAN) as an interpretable and accurate method for FDIA detection in AGC systems, considering the system nonlinearities. KAN models include a method for extracting symbolic equations, and are thus able to provide more interpretability than the majority of machine learning models. The proposed KAN is trained offline to learn the complex nonlinear relationships between the AGC measurements under different operating scenarios. After training, symbolic formulas that describe the trained model's behavior can be extracted and leveraged, greatly enhancing interpretability. Our findings confirm that the proposed KAN model achieves FDIA detection rates of up to 95.97% and 95.9% for the initial model and the symbolic formula, respectively, with a low false alarm rate, offering a reliable approach to enhancing AGC cybersecurity.         ",
    "url": "https://arxiv.org/abs/2509.05259",
    "authors": [
      "Jehad Jilan",
      "Niranjana Naveen Nambiar",
      "Ahmad Mohammad Saber",
      "Alok Paranjape",
      "Amr Youssef",
      "Deepa Kundur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2509.05263",
    "title": "LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation",
    "abstract": "           Recent research has been increasingly focusing on developing 3D world models that simulate complex real-world scenarios. World models have found broad applications across various domains, including embodied AI, autonomous driving, entertainment, etc. A more realistic simulation with accurate physics will effectively narrow the sim-to-real gap and allow us to gather rich information about the real world conveniently. While traditional manual modeling has enabled the creation of virtual 3D scenes, modern approaches have leveraged advanced machine learning algorithms for 3D world generation, with most recent advances focusing on generative methods that can create virtual worlds based on user instructions. This work explores such a research direction by proposing LatticeWorld, a simple yet effective 3D world generation framework that streamlines the industrial production pipeline of 3D environments. LatticeWorld leverages lightweight LLMs (LLaMA-2-7B) alongside the industry-grade rendering engine (e.g., Unreal Engine 5) to generate a dynamic environment. Our proposed framework accepts textual descriptions and visual instructions as multimodal inputs and creates large-scale 3D interactive worlds with dynamic agents, featuring competitive multi-agent interaction, high-fidelity physics simulation, and real-time rendering. We conduct comprehensive experiments to evaluate LatticeWorld, showing that it achieves superior accuracy in scene layout generation and visual fidelity. Moreover, LatticeWorld achieves over a $90\\times$ increase in industrial production efficiency while maintaining high creative quality compared with traditional manual production methods. Our demo video is available at this https URL ",
    "url": "https://arxiv.org/abs/2509.05263",
    "authors": [
      "Yinglin Duan",
      "Zhengxia Zou",
      "Tongwei Gu",
      "Wei Jia",
      "Zhan Zhao",
      "Luyi Xu",
      "Xinzhu Liu",
      "Hao Jiang",
      "Kang Chen",
      "Shuang Qiu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.05265",
    "title": "On Evaluating the Poisoning Robustness of Federated Learning under Local Differential Privacy",
    "abstract": "           Federated learning (FL) combined with local differential privacy (LDP) enables privacy-preserving model training across decentralized data sources. However, the decentralized data-management paradigm leaves LDPFL vulnerable to participants with malicious intent. The robustness of LDPFL protocols, particularly against model poisoning attacks (MPA), where adversaries inject malicious updates to disrupt global model convergence, remains insufficiently studied. In this paper, we propose a novel and extensible model poisoning attack framework tailored for LDPFL settings. Our approach is driven by the objective of maximizing the global training loss while adhering to local privacy constraints. To counter robust aggregation mechanisms such as Multi-Krum and trimmed mean, we develop adaptive attacks that embed carefully crafted constraints into a reverse training process, enabling evasion of these defenses. We evaluate our framework across three representative LDPFL protocols, three benchmark datasets, and two types of deep neural networks. Additionally, we investigate the influence of data heterogeneity and privacy budgets on attack effectiveness. Experimental results demonstrate that our adaptive attacks can significantly degrade the performance of the global model, revealing critical vulnerabilities and highlighting the need for more robust LDPFL defense strategies against MPA. Our code is available at this https URL ",
    "url": "https://arxiv.org/abs/2509.05265",
    "authors": [
      "Zijian Wang",
      "Wei Tong",
      "Tingxuan Han",
      "Haoyu Chen",
      "Tianling Zhang",
      "Yunlong Mao",
      "Sheng Zhong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.05281",
    "title": "Dual-Branch Convolutional Framework for Spatial and Frequency-Based Image Forgery Detection",
    "abstract": "           With a very rapid increase in deepfakes and digital image forgeries, ensuring the authenticity of images is becoming increasingly challenging. This report introduces a forgery detection framework that combines spatial and frequency-based features for detecting forgeries. We propose a dual branch convolution neural network that operates on features extracted from spatial and frequency domains. Features from both branches are fused and compared within a Siamese network, yielding 64 dimensional embeddings for classification. When benchmarked on CASIA 2.0 dataset, our method achieves an accuracy of 77.9%, outperforming traditional statistical methods. Despite its relatively weaker performance compared to larger, more complex forgery detection pipelines, our approach balances computational complexity and detection reliability, making it ready for practical deployment. It provides a strong methodology for forensic scrutiny of digital images. In a broader sense, it advances the state of the art in visual forensics, addressing an urgent requirement in media verification, law enforcement and digital content reliability.         ",
    "url": "https://arxiv.org/abs/2509.05281",
    "authors": [
      "Naman Tyagi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.05288",
    "title": "Learning to accelerate distributed ADMM using graph neural networks",
    "abstract": "           Distributed optimization is fundamental in large-scale machine learning and control applications. Among existing methods, the Alternating Direction Method of Multipliers (ADMM) has gained popularity due to its strong convergence guarantees and suitability for decentralized computation. However, ADMM often suffers from slow convergence and sensitivity to hyperparameter choices. In this work, we show that distributed ADMM iterations can be naturally represented within the message-passing framework of graph neural networks (GNNs). Building on this connection, we propose to learn adaptive step sizes and communication weights by a graph neural network that predicts the hyperparameters based on the iterates. By unrolling ADMM for a fixed number of iterations, we train the network parameters end-to-end to minimize the final iterates error for a given problem class, while preserving the algorithm's convergence properties. Numerical experiments demonstrate that our learned variant consistently improves convergence speed and solution quality compared to standard ADMM. The code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2509.05288",
    "authors": [
      "Henri Doerks",
      "Paul H\u00e4usner",
      "Daniel Hern\u00e1ndez Escobar",
      "Jens Sj\u00f6lund"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2509.04463",
    "title": "Multiscale Graph Neural Network for Turbulent Flow-Thermal Prediction Around a Complex-Shaped Pin-Fin",
    "abstract": "           This study presents the development of a domain-responsive edge-aware multiscale Graph Neural Network for predicting steady, turbulent flow and thermal behavior in a two-dimensional channel containing arbitrarily shaped complex pin-fin geometries. The training dataset was constructed through an automated framework that integrated geometry generation, meshing, and flow-field solutions in ANSYS Fluent. The pin-fin geometry was parameterized using piecewise cubic splines, producing 1,000 diverse configurations through Latin Hypercube Sampling. Each simulation was converted into a graph structure, where nodes carried a feature vector containing spatial coordinates, a normalized streamwise position, one-hot boundary indicators, and a signed distance to the nearest boundary such as wall. This graph structure served as input to the newly developed Graph Neural Network, which was trained to predict temperature, velocity magnitude, and pressure at each node using data from ANSYS. The network predicted fields with outstanding accuracy, capturing boundary layers, recirculation, and the stagnation region upstream of the pin-fins while reducing wall time by 2-3 orders of magnitude. In conclusion, the novel graph neural network offered a fast and reliable surrogate for simulations in complex flow configurations.         ",
    "url": "https://arxiv.org/abs/2509.04463",
    "authors": [
      "Riddhiman Raut",
      "Evan M. Mihalko",
      "Amrita Basak"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2509.04477",
    "title": "Universal Representation of Generalized Convex Functions and their Gradients",
    "abstract": "           Solutions to a wide range of optimization problems, from optimal transport theory to mathematical economics, often take the form of generalized convex functions (GCFs). This characterization can be used to convert nested bilevel optimization problems into single-level optimization problems. Despite this, the characterization has not been fully exploited in numerical optimization. When the solution to an optimization problem is known to belong to a particular class of objects, this information can be leveraged by parameterizing that class of objects and optimizing over this parameterization. The hallmark of a good parameterization is the Universal Approximation Property (UAP): that is, the parameterization approximates any object in the class arbitrarily well. For example, neural networks satisfy the UAP with respect to the class of continuous functions. Building on the literature concerned with the parameterization of convex functions, we extend these ideas to GCFs. We present a convex and potentially one-to-one parameterization of GCFs and their gradients that satisfies the UAP. We also compare this class to shallow neural networks and highlight their shared characteristics. The ideas pursued here have been implemented in the Python package \\href{this https URL}{\\texttt{gconvex}}, available online. Using it, we tackle the problem of finding the revenue-maximizing auction for multiple goods and demonstrate how our parameterization can effectively solve this problem.         ",
    "url": "https://arxiv.org/abs/2509.04477",
    "authors": [
      "Moeen Nehzati"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.04592",
    "title": "Incentivising Personalised Colorectal Cancer Screening: an Adversarial Risk Analysis Approach",
    "abstract": "           This paper presents a framework for incentivising colorectal cancer (CRC) screening programs from the perspective of policymakers and under the assumption that the citizens participating in the program have misaligned objectives. To do so, it leverages tools from adversarial risk analysis to propose an optimal incentive scheme under uncertainty. The work relies on previous work on modeling CRC risk and optimal screening strategies and provides use cases regarding individual and group-based optimal incentives based on a simple financial scheme.         ",
    "url": "https://arxiv.org/abs/2509.04592",
    "authors": [
      "Daniel Corrales",
      "David Rios Insua"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2509.04677",
    "title": "Inferring the Graph Structure of Images for Graph Neural Networks",
    "abstract": "           Image datasets such as MNIST are a key benchmark for testing Graph Neural Network (GNN) architectures. The images are traditionally represented as a grid graph with each node representing a pixel and edges connecting neighboring pixels (vertically and horizontally). The graph signal is the values (intensities) of each pixel in the image. The graphs are commonly used as input to graph neural networks (e.g., Graph Convolutional Neural Networks (Graph CNNs) [1, 2], Graph Attention Networks (GAT) [3], GatedGCN [4]) to classify the images. In this work, we improve the accuracy of downstream graph neural network tasks by finding alternative graphs to the grid graph and superpixel methods to represent the dataset images, following the approach in [5, 6]. We find row correlation, column correlation, and product graphs for each image in MNIST and Fashion-MNIST using correlations between the pixel values building on the method in [5, 6]. Experiments show that using these different graph representations and features as input into downstream GNN models improves the accuracy over using the traditional grid graph and superpixel methods in the literature.         ",
    "url": "https://arxiv.org/abs/2509.04677",
    "authors": [
      "Mayur S Gowda",
      "John Shi",
      "Augusto Santos",
      "Jos\u00e9 M. F. Moura"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2509.04805",
    "title": "AI-Driven Fronthaul Link Compression in Wireless Communication Systems: Review and Method Design",
    "abstract": "           Modern fronthaul links in wireless systems must transport high-dimensional signals under stringent bandwidth and latency constraints, which makes compression indispensable. Traditional strategies such as compressed sensing, scalar quantization, and fixed-codec pipelines often rely on restrictive priors, degrade sharply at high compression ratios, and are hard to tune across channels and deployments. Recent progress in Artificial Intelligence (AI) has brought end-to-end learned transforms, vector and hierarchical quantization, and learned entropy models that better exploit the structure of Channel State Information(CSI), precoding matrices, I/Q samples, and LLRs. This paper first surveys AI-driven compression techniques and then provides a focused analysis of two representative high-compression routes: CSI feedback with end-to-end learning and Resource Block (RB) granularity precoding optimization combined with compression. Building on these insights, we propose a fronthaul compression strategy tailored to cell-free architectures. The design targets high compression with controlled performance loss, supports RB-level rate adaptation, and enables low-latency inference suitable for centralized cooperative transmission in next-generation networks.         ",
    "url": "https://arxiv.org/abs/2509.04805",
    "authors": [
      "Keqin Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.04849",
    "title": "Histogram Driven Amplitude Embedding for Qubit Efficient Quantum Image Compression",
    "abstract": "           This work introduces a compact and hardware efficient method for compressing color images using near term quantum devices. The approach segments the image into fixed size blocks called bixels, and computes the total intensity within each block. A global histogram with B bins is then constructed from these block intensities, and the normalized square roots of the bin counts are encoded as amplitudes into an n qubit quantum state. Amplitude embedding is performed using PennyLane and executed on real IBM Quantum hardware. The resulting state is measured to reconstruct the histogram, enabling approximate recovery of block intensities and full image reassembly. The method maintains a constant qubit requirement based solely on the number of histogram bins, independent of the resolution of the image. By adjusting B, users can control the trade off between fidelity and resource usage. Empirical results demonstrate high quality reconstructions using as few as 5 to 7 qubits, significantly outperforming conventional pixel level encodings in terms of qubit efficiency and validating the practical application of the method for current NISQ era quantum systems.         ",
    "url": "https://arxiv.org/abs/2509.04849",
    "authors": [
      "Sahil Tomar",
      "Sandeep Kumar"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Emerging Technologies (cs.ET)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2509.04870",
    "title": "Multi-modal Uncertainty Robust Tree Cover Segmentation For High-Resolution Remote Sensing Images",
    "abstract": "           Recent advances in semantic segmentation of multi-modal remote sensing images have significantly improved the accuracy of tree cover mapping, supporting applications in urban planning, forest monitoring, and ecological assessment. Integrating data from multiple modalities-such as optical imagery, light detection and ranging (LiDAR), and synthetic aperture radar (SAR)-has shown superior performance over single-modality methods. However, these data are often acquired days or even months apart, during which various changes may occur, such as vegetation disturbances (e.g., logging, and wildfires) and variations in imaging quality. Such temporal misalignments introduce cross-modal uncertainty, especially in high-resolution imagery, which can severely degrade segmentation accuracy. To address this challenge, we propose MURTreeFormer, a novel multi-modal segmentation framework that mitigates and leverages aleatoric uncertainty for robust tree cover mapping. MURTreeFormer treats one modality as primary and others as auxiliary, explicitly modeling patch-level uncertainty in the auxiliary modalities via a probabilistic latent representation. Uncertain patches are identified and reconstructed from the primary modality's distribution through a VAE-based resampling mechanism, producing enhanced auxiliary features for fusion. In the decoder, a gradient magnitude attention (GMA) module and a lightweight refinement head (RH) are further integrated to guide attention toward tree-like structures and to preserve fine-grained spatial details. Extensive experiments on multi-modal datasets from Shanghai and Zurich demonstrate that MURTreeFormer significantly improves segmentation performance and effectively reduces the impact of temporally induced aleatoric uncertainty.         ",
    "url": "https://arxiv.org/abs/2509.04870",
    "authors": [
      "Yuanyuan Gui",
      "Wei Li",
      "Yinjian Wang",
      "Xiang-Gen Xia",
      "Mauro Marty",
      "Christian Ginzler",
      "Zuyuan Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.04874",
    "title": "Robust Voting Rules on the Interval Domain",
    "abstract": "           In this paper, we study voting rules on the interval domain, where the alternatives are arranged according to an externally given strict total order and voters report intervals of this order to indicate the alternatives they support. For this setting, we introduce and characterize the class of position-threshold rules, which compute a collective position of the voters with respect to every alternative and choose the left-most alternative whose collective position exceeds its threshold value. Our characterization of these rules mainly relies on reinforcement, a well-known population consistency condition, and robustness, a new axiom that restricts how the outcome is allowed to change when a voter removes the left-most or right-most alternative from his interval. Moreover, we characterize a generalization of the median rule to the interval domain, which selects the median of the endpoints of the voters' intervals.         ",
    "url": "https://arxiv.org/abs/2509.04874",
    "authors": [
      "Patrick Lederer"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2509.04914",
    "title": "RobQFL: Robust Quantum Federated Learning in Adversarial Environment",
    "abstract": "           Quantum Federated Learning (QFL) merges privacy-preserving federation with quantum computing gains, yet its resilience to adversarial noise is unknown. We first show that QFL is as fragile as centralized quantum learning. We propose Robust Quantum Federated Learning (RobQFL), embedding adversarial training directly into the federated loop. RobQFL exposes tunable axes: client coverage $\\gamma$ (0-100\\%), perturbation scheduling (fixed-$\\varepsilon$ vs $\\varepsilon$-mixes), and optimization (fine-tune vs scratch), and distils the resulting $\\gamma \\times \\varepsilon$ surface into two metrics: Accuracy-Robustness Area and Robustness Volume. On 15-client simulations with MNIST and Fashion-MNIST, IID and Non-IID conditions, training only 20-50\\% clients adversarially boosts $\\varepsilon \\leq 0.1$ accuracy $\\sim$15 pp at $< 2$ pp clean-accuracy cost; fine-tuning adds 3-5 pp. With $\\geq$75\\% coverage, a moderate $\\varepsilon$-mix is optimal, while high-$\\varepsilon$ schedules help only at 100\\% coverage. Label-sorted non-IID splits halve robustness, underscoring data heterogeneity as a dominant risk.         ",
    "url": "https://arxiv.org/abs/2509.04914",
    "authors": [
      "Walid El Maouaki",
      "Nouhaila Innan",
      "Alberto Marchisio",
      "Taoufik Said",
      "Muhammad Shafique",
      "Mohamed Bennai"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.04919",
    "title": "Optimal Variance and Covariance Estimation under Differential Privacy in the Add-Remove Model and Beyond",
    "abstract": "           In this paper, we study the problem of estimating the variance and covariance of datasets under differential privacy in the add-remove model. While estimation in the swap model has been extensively studied in the literature, the add-remove model remains less explored and more challenging, as the dataset size must also be kept private. To address this issue, we develop efficient mechanisms for variance and covariance estimation based on the \\emph{B\u00e9zier mechanism}, a novel moment-release framework that leverages Bernstein bases. We prove that our proposed mechanisms are minimax optimal in the high-privacy regime by establishing new minimax lower bounds. Moreover, beyond worst-case scenarios, we analyze instance-wise utility and show that the B\u00e9zier-based estimator consistently achieves better utility compared to alternative mechanisms. Finally, we demonstrate the effectiveness of the B\u00e9zier mechanism beyond variance and covariance estimation, showcasing its applicability to other statistical tasks.         ",
    "url": "https://arxiv.org/abs/2509.04919",
    "authors": [
      "Shokichi Takakura",
      "Seng Pei Liew",
      "Satoshi Hasegawa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.05041",
    "title": "Dynamical Learning in Deep Asymmetric Recurrent Neural Networks",
    "abstract": "           We show that asymmetric deep recurrent neural networks, enhanced with additional sparse excitatory couplings, give rise to an exponentially large, dense accessible manifold of internal representations which can be found by different algorithms, including simple iterative dynamics. Building on the geometrical properties of the stable configurations, we propose a distributed learning scheme in which input-output associations emerge naturally from the recurrent dynamics, without any need of gradient evaluation. A critical feature enabling the learning process is the stability of the configurations reached at convergence, even after removal of the supervisory output signal. Extensive simulations demonstrate that this approach performs competitively on standard AI benchmarks. The model can be generalized in multiple directions, both computational and biological, potentially contributing to narrowing the gap between AI and computational neuroscience.         ",
    "url": "https://arxiv.org/abs/2509.05041",
    "authors": [
      "Davide Badalotti",
      "Carlo Baldassi",
      "Marc M\u00e9zard",
      "Mattia Scardecchia",
      "Riccardo Zecchina"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2509.05069",
    "title": "Subgroup perfect codes of $S_n$ in Cayley sum graphs",
    "abstract": "           A perfect code in a graph $\\Gamma = (V, E)$ is a subset $C$ of $V$ such that no two vertices in $C$ are adjacent, and every vertex in $V \\setminus C$ is adjacent to exactly one vertex in $C$. Let $ G $ be a finite group, and let $ S $ be a square-free normal subset of $ G $. The Cayley sum graph of $ G $ with respect to $ S $ is a simple graph with vertex set $ G $ and two vertices $ x $ and $ y $ are adjacent if $ xy\\in S .$ A subset $ C $ of $ G $ is called perfect code of $ G $ if there exists a Cayley sum graph of $ G $ that admits $ C $ as a perfect code. In particular, if a subgroup of $ G $ is a perfect code of $ G $, then the subgroup is called a subgroup perfect code of $ G $. In this work, we prove that there does not exist any proper perfect subgroup code of symmetric group $ S_n $. Using this result, we provide a complete characterization of the perfect subgroup code of the alternating group $A_n$.         ",
    "url": "https://arxiv.org/abs/2509.05069",
    "authors": [
      "Ankan Shaw",
      "Biswajit Mondal",
      "Satya Bagchi"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)",
      "Group Theory (math.GR)"
    ]
  },
  {
    "id": "arXiv:2509.05205",
    "title": "MEAN-RIR: Multi-Modal Environment-Aware Network for Robust Room Impulse Response Estimation",
    "abstract": "           This paper presents a Multi-Modal Environment-Aware Network (MEAN-RIR), which uses an encoder-decoder framework to predict room impulse response (RIR) based on multi-level environmental information from audio, visual, and textual sources. Specifically, reverberant speech capturing room acoustic properties serves as the primary input, which is combined with panoramic images and text descriptions as supplementary inputs. Each input is processed by its respective encoder, and the outputs are fed into cross-attention modules to enable effective interaction between different modalities. The MEAN-RIR decoder generates two distinct components: the first component captures the direct sound and early reflections, while the second produces masks that modulate learnable filtered noise to synthesize the late reverberation. These two components are mixed to reconstruct the final RIR. The results show that MEAN-RIR significantly improves RIR estimation, with notable gains in acoustic parameters.         ",
    "url": "https://arxiv.org/abs/2509.05205",
    "authors": [
      "Jiajian Chen",
      "Jiakang Chen",
      "Hang Chen",
      "Qing Wang",
      "Yu Gao",
      "Jun Du"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.15960",
    "title": "FC-PINO: High Precision Physics-Informed Neural Operators via Fourier Continuation",
    "abstract": "           The physics-informed neural operator (PINO) is a machine learning paradigm that has demonstrated promising results for learning solutions to partial differential equations (PDEs). It leverages the Fourier Neural Operator to learn solution operators in function spaces and leverages physics losses during training to penalize deviations from known physics laws. Spectral differentiation provides an efficient way to compute derivatives for the physics losses, but it inherently assumes periodicity. When applied to non-periodic functions, this assumption of periodicity can lead to significant errors, including Gibbs phenomena near domain boundaries which degrade the accuracy of both function representations and derivative computations, especially for higher order derivatives. To overcome this limitation, we introduce the FC-PINO (Fourier-Continuation-based PINO) architecture which extends the accuracy and efficiency of PINO and spectral differentiation to non-periodic and non-smooth PDEs. In FC-PINO, we propose integrating Fourier continuation into the PINO framework, and test two different continuation approaches: FC-Legendre and FC-Gram. By transforming non-periodic signals into periodic functions on extended domains in a well-conditioned manner, Fourier continuation enables fast and accurate derivative computations. This approach avoids the discretization sensitivity of finite differences and the memory overhead of automatic differentiation. We demonstrate that standard PINO struggles to solve non-periodic and non-smooth PDEs with high precision, across challenging benchmarks. In contrast, the proposed FC-PINO provides accurate, robust, and scalable solutions, substantially outperforming PINO alternatives, and demonstrating that Fourier continuation is critical for extending PINO to a wider range of PDE problems when high-precision solutions are needed.         ",
    "url": "https://arxiv.org/abs/2211.15960",
    "authors": [
      "Adarsh Ganeshram",
      "Haydn Maust",
      "Valentin Duruisseaux",
      "Zongyi Li",
      "Yixuan Wang",
      "Daniel Leibovici",
      "Oscar Bruno",
      "Thomas Hou",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.02304",
    "title": "Imitating and Finetuning Model Predictive Control for Robust and Symmetric Quadrupedal Locomotion",
    "abstract": "           Control of legged robots is a challenging problem that has been investigated by different approaches, such as model-based control and learning algorithms. This work proposes a novel Imitating and Finetuning Model Predictive Control (IFM) framework to take the strengths of both approaches. Our framework first develops a conventional model predictive controller (MPC) using Differential Dynamic Programming and Raibert heuristic, which serves as an expert policy. Then we train a clone of the MPC using imitation learning to make the controller learnable. Finally, we leverage deep reinforcement learning with limited exploration for further finetuning the policy on more challenging terrains. By conducting comprehensive simulation and hardware experiments, we demonstrate that the proposed IFM framework can significantly improve the performance of the given MPC controller on rough, slippery, and conveyor terrains that require careful coordination of footsteps. We also showcase that IFM can efficiently produce more symmetric, periodic, and energy-efficient gaits compared to Vanilla RL with a minimal burden of reward shaping.         ",
    "url": "https://arxiv.org/abs/2311.02304",
    "authors": [
      "Donghoon Youm",
      "Hyunyoung Jung",
      "Hyeongjun Kim",
      "Jemin Hwangbo",
      "Hae-Won Park",
      "Sehoon Ha"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2312.03325",
    "title": "FAGC:Feature Augmentation on Geodesic Curve in the Pre-Shape Space",
    "abstract": "           Due to the constraints on model performance imposed by the size of the training data, data augmentation has become an essential technique in deep learning. However, most existing data augmentation methods are affected by information loss and perform poorly in small-sample scenarios, which limits their application. To overcome the limitation, we propose a Feature Augmentation method on Geodesic Curve in the pre-shape space, called the FAGC. First, a pre-trained neural network model is employed to extract features from the input images. Then, the image features as a vector is projected into the pre-shape space by removing its position and scale information. In the pre-shape space, an optimal Geodesic curve is constructed to fit the feature vectors. Finally, new feature vectors are generated for model learning by interpolating along the constructed Geodesic curve. We conducted extensive experiments to demonstrate the effectiveness and versatility of the FAGC. The results demonstrate that applying the FAGC to deep learning or machine learning methods can significantly improve their performance in small-sample tasks.         ",
    "url": "https://arxiv.org/abs/2312.03325",
    "authors": [
      "Yuexing Han",
      "Gan Hu",
      "Guanxin Wan",
      "Bing Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.14295",
    "title": "Demystifying Chains, Trees, and Graphs of Thoughts",
    "abstract": "           The field of natural language processing (NLP) has witnessed significant progress in recent years, with a notable focus on improving large language models' (LLM) performance through innovative prompting techniques. Among these, prompt engineering coupled with structures has emerged as a promising paradigm, with designs such as Chain-of-Thought, Tree of Thoughts, or Graph of Thoughts, in which the overall LLM reasoning is guided by a structure such as a graph. As illustrated with numerous examples, this paradigm significantly enhances the LLM's capability to solve numerous tasks, ranging from logical or mathematical reasoning to planning or creative writing. To facilitate the understanding of this growing field and pave the way for future developments, we devise a general blueprint for effective and efficient LLM reasoning schemes. For this, we conduct an in-depth analysis of the prompt execution pipeline, clarifying and clearly defining different concepts. We then build the first taxonomy of structure-enhanced LLM reasoning schemes. We focus on identifying fundamental classes of harnessed structures, and we analyze the representations of these structures, algorithms executed with these structures, and many others. We refer to these structures as reasoning topologies, because their representation becomes to a degree spatial, as they are contained within the LLM context. Our study compares existing prompting schemes using the proposed taxonomy, discussing how certain design choices lead to different patterns in performance and cost. We also outline theoretical underpinnings, relationships between prompting and other parts of the LLM ecosystem such as knowledge bases, and the associated research challenges. Our work will help to advance future prompt engineering techniques.         ",
    "url": "https://arxiv.org/abs/2401.14295",
    "authors": [
      "Maciej Besta",
      "Florim Memedi",
      "Zhenyu Zhang",
      "Robert Gerstenberger",
      "Guangyuan Piao",
      "Nils Blach",
      "Piotr Nyczyk",
      "Marcin Copik",
      "Grzegorz Kwa\u015bniewski",
      "J\u00fcrgen M\u00fcller",
      "Lukas Gianinazzi",
      "Ales Kubicek",
      "Hubert Niewiadomski",
      "Aidan O'Mahony",
      "Onur Mutlu",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.08674",
    "title": "The dynamic interplay between in-context and in-weight learning in humans and neural networks",
    "abstract": "           Human learning embodies a striking duality: sometimes, we appear capable of following logical, compositional rules and benefit from structured curricula (e.g., in formal education), while other times, we rely on an incremental approach or trial-and-error, learning better from curricula that are randomly interleaved. Influential psychological theories explain this seemingly disparate behavioral evidence by positing two qualitatively different learning systems -- one for rapid, rule-based inferences and another for slow, incremental adaptation. It remains unclear how to reconcile such theories with neural networks, which learn via incremental weight updates and are thus a natural model for the latter type of learning, but are not obviously compatible with the former. However, recent evidence suggests that metalearning neural networks and large language models are capable of \"in-context learning\" (ICL) -- the ability to flexibly grasp the structure of a new task from a few examples. Here, we show that the dynamic interplay between ICL and default in-weight learning (IWL) naturally captures a broad range of learning phenomena observed in humans, reproducing curriculum effects on category-learning and compositional tasks, and recapitulating a tradeoff between flexibility and retention. Our work shows how emergent ICL can equip neural networks with fundamentally different learning properties that can coexist with their native IWL, thus offering a novel perspective on dual-process theories and human cognitive flexibility.         ",
    "url": "https://arxiv.org/abs/2402.08674",
    "authors": [
      "Jacob Russin",
      "Ellie Pavlick",
      "Michael J. Frank"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2403.05265",
    "title": "MMoE: Robust Spoiler Detection with Multi-modal Information and Domain-aware Mixture-of-Experts",
    "abstract": "           Online movie review websites are valuable for information and discussion about movies. However, the massive spoiler reviews detract from the movie-watching experience, making spoiler detection an important task. Previous methods simply focus on reviews' text content, ignoring the heterogeneity of information in the platform. For instance, the metadata and the corresponding user's information of a review could be helpful. Besides, the spoiler language of movie reviews tends to be genre-specific, thus posing a domain generalization challenge for existing methods. To this end, we propose MMoE, a multi-modal network that utilizes information from multiple modalities to facilitate robust spoiler detection and adopts Mixture-of-Experts to enhance domain generalization. MMoE first extracts graph, text, and meta feature from the user-movie network, the review's textual content, and the review's metadata respectively. To handle genre-specific spoilers, we then adopt Mixture-of-Experts architecture to process information in three modalities to promote robustness. Finally, we use an expert fusion layer to integrate the features from different perspectives and make predictions based on the fused embedding. Experiments demonstrate that MMoE achieves state-of-the-art performance on two widely-used spoiler detection datasets, surpassing previous SOTA methods by 2.56% and 8.41% in terms of accuracy and F1-score. Further experiments also demonstrate MMoE's superiority in robustness and generalization. Our code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2403.05265",
    "authors": [
      "Zinan Zeng",
      "Sen Ye",
      "Zijian Cai",
      "Heng Wang",
      "Yuhan Liu",
      "Haokai Zhang",
      "Minnan Luo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2405.15164",
    "title": "From Frege to chatGPT: Compositionality in language, cognition, and deep neural networks",
    "abstract": "           Compositionality has long been considered a key explanatory property underlying human intelligence: arbitrary concepts can be composed into novel complex combinations, permitting the acquisition of an open ended, potentially infinite expressive capacity from finite learning experiences. Influential arguments have held that neural networks fail to explain this aspect of behavior, leading many to dismiss them as viable models of human cognition. Over the last decade, however, modern deep neural networks (DNNs), which share the same fundamental design principles as their predecessors, have come to dominate artificial intelligence, exhibiting the most advanced cognitive behaviors ever demonstrated in machines. In particular, large language models (LLMs), DNNs trained to predict the next word on a large corpus of text, have proven capable of sophisticated behaviors such as writing syntactically complex sentences without grammatical errors, producing cogent chains of reasoning, and even writing original computer programs -- all behaviors thought to require compositional processing. In this chapter, we survey recent empirical work from machine learning for a broad audience in philosophy, cognitive science, and neuroscience, situating recent breakthroughs within the broader context of philosophical arguments about compositionality. In particular, our review emphasizes two approaches to endowing neural networks with compositional generalization capabilities: (1) architectural inductive biases, and (2) metalearning, or learning to learn. We also present findings suggesting that LLM pretraining can be understood as a kind of metalearning, and can thereby equip DNNs with compositional generalization abilities in a similar way. We conclude by discussing the implications that these findings may have for the study of compositionality in human cognition and by suggesting avenues for future research.         ",
    "url": "https://arxiv.org/abs/2405.15164",
    "authors": [
      "Jacob Russin",
      "Sam Whitman McGrath",
      "Danielle J. Williams"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.06486",
    "title": "Continuum Attention for Neural Operators",
    "abstract": "           Transformers, and the attention mechanism in particular, have become ubiquitous in machine learning. Their success in modeling nonlocal, long-range correlations has led to their widespread adoption in natural language processing, computer vision, and time series problems. Neural operators, which map spaces of functions into spaces of functions, are necessarily both nonlinear and nonlocal if they are universal; it is thus natural to ask whether the attention mechanism can be used in the design of neural operators. Motivated by this, we study transformers in the function space setting. We formulate attention as a map between infinite dimensional function spaces and prove that the attention mechanism as implemented in practice is a Monte Carlo or finite difference approximation of this operator. The function space formulation allows for the design of transformer neural operators, a class of architectures designed to learn mappings between function spaces. In this paper, we state and prove the first universal approximation result for transformer neural operators, using only a slight modification of the architecture implemented in practice. The prohibitive cost of applying the attention operator to functions defined on multi-dimensional domains leads to the need for more efficient attention-based architectures. For this reason we also introduce a function space generalization of the patching strategy from computer vision, and introduce a class of associated neural operators. Numerical results, on an array of operator learning problems, demonstrate the promise of our approaches to function space formulations of attention and their use in neural operators.         ",
    "url": "https://arxiv.org/abs/2406.06486",
    "authors": [
      "Edoardo Calvello",
      "Nikola B. Kovachki",
      "Matthew E. Levine",
      "Andrew M. Stuart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2408.05748",
    "title": "Low-Dimensional Federated Knowledge Graph Embedding via Knowledge Distillation",
    "abstract": "           Federated Knowledge Graph Embedding (FKGE) aims to facilitate collaborative learning of entity and relation embeddings from distributed Knowledge Graphs (KGs) across multiple clients, while preserving data privacy. Training FKGE models with higher dimensions is typically favored due to their potential for achieving superior performance. However, high-dimensional embeddings present significant challenges in terms of storage resource and inference speed. Unlike traditional KG embedding methods, FKGE involves multiple client-server communication rounds, where communication efficiency is critical. Existing embedding compression methods for traditional KGs may not be directly applicable to FKGE as they often require multiple model trainings which potentially incur substantial communication costs. In this paper, we propose a light-weight component based on Knowledge Distillation (KD) which is titled FedKD and tailored specifically for FKGE methods. During client-side local training, FedKD facilitates the low-dimensional student model to mimic the score distribution of triples from the high-dimensional teacher model using KL divergence loss. Unlike traditional KD way, FedKD adaptively learns a temperature to scale the score of positive triples and separately adjusts the scores of corresponding negative triples using a predefined temperature, thereby mitigating teacher over-confidence issue. Furthermore, we dynamically adjust the weight of KD loss to optimize the training process. Extensive experiments on three datasets support the effectiveness of FedKD.         ",
    "url": "https://arxiv.org/abs/2408.05748",
    "authors": [
      "Xiaoxiong Zhang",
      "Zhiwei Zeng",
      "Xin Zhou",
      "Zhiqi Shen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.11813",
    "title": "SEA: Supervised Embedding Alignment for Token-Level Visual-Textual Integration in MLLMs",
    "abstract": "           Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities by integrating visual and textual inputs, yet modality alignment remains one of the most challenging aspects. Current MLLMs typically rely on simple adapter architectures and pretraining approaches to bridge vision encoders with large language models (LLM), guided by image-level supervision. We identify this paradigm often leads to suboptimal alignment between modalities, significantly constraining the LLM's ability to properly interpret and reason with visual features particularly for smaller language models. This limitation degrades overall performance-particularly for smaller language models where capacity constraints are more pronounced and adaptation capabilities are limited. To address this fundamental limitation, we propose Supervised Embedding Alignment (SEA), a token-level supervision alignment method that enables more precise visual-text alignment during pretraining. SEA introduces minimal computational overhead while preserving language capabilities and substantially improving cross-modal understanding. Our comprehensive analyses reveal critical insights into the adapter's role in multimodal integration, and extensive experiments demonstrate that SEA consistently improves performance across various model sizes, with smaller models benefiting the most (average performance gain of 7.61% for Gemma-2B). This work establishes a foundation for developing more effective alignment strategies for future multimodal systems.         ",
    "url": "https://arxiv.org/abs/2408.11813",
    "authors": [
      "Yuanyang Yin",
      "Yaqi Zhao",
      "Yajie Zhang",
      "Yuanxing Zhang",
      "Ke Lin",
      "Jiahao Wang",
      "Xin Tao",
      "Pengfei Wan",
      "Wentao Zhang",
      "Feng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2409.11686",
    "title": "Automated detection of underdiagnosed medical conditions via opportunistic imaging",
    "abstract": "           Abdominal computed tomography (CT) scans are frequently performed in clinical settings. Opportunistic CT involves repurposing routine CT images to extract diagnostic information and is an emerging tool for detecting underdiagnosed conditions such as sarcopenia, hepatic steatosis, and ascites. This study utilizes deep learning methods to promote accurate diagnosis and clinical documentation. We analyze 2,674 inpatient CT scans to identify discrepancies between imaging phenotypes (characteristics derived from opportunistic CT scans) and their corresponding documentation in radiology reports and ICD coding. Through our analysis, we find that only 0.5%, 3.2%, and 30.7% of scans diagnosed with sarcopenia, hepatic steatosis, and ascites (respectively) through either opportunistic imaging or radiology reports were ICD-coded. Our findings demonstrate opportunistic CT's potential to enhance diagnostic precision and accuracy of risk adjustment models, offering advancements in precision medicine.         ",
    "url": "https://arxiv.org/abs/2409.11686",
    "authors": [
      "Asad Aali",
      "Andrew Johnston",
      "Louis Blankemeier",
      "Dave Van Veen",
      "Laura T Derry",
      "David Svec",
      "Jason Hom",
      "Robert D. Boutin",
      "Akshay S. Chaudhari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2409.12929",
    "title": "LogicPro: Improving Complex Logical Reasoning via Program-Guided Learning",
    "abstract": "           In this paper, we propose a new data synthesis method called \\textbf{LogicPro}, which leverages LeetCode-style algorithm \\underline{Pro}blems and their corresponding \\underline{Pro}gram solutions to synthesize Complex \\underline{Logic}al Reasoning data in text format. First, we synthesize complex reasoning problems through source algorithm problems and test cases. Then, standard answers and intermediate variable outputs are obtained for each problem based on standard python solutions and test cases. Finally, with the guidance of code intermediate variables, we synthesize the text reasoning process for each reasoning problems. Through this method, we can synthesize data that is difficult, scalable, effective, and comes with golden standard answers and high-quality reasoning processes. As a result, with our 540K synthesized dataset constructed solely from 2,360 algorithm problems, our approach \\footnote{Code and data are publicly available at this https URL} achieves significant improvements in multiple models for the datasets \\textit{BBH$^{27}$}, \\textit{LogicBench}, \\textit{DROP}, \\textit{AR-LSAT}, and \\textit{GSM8K}, etc. outperforming a wide range of existing reasoning datasets.         ",
    "url": "https://arxiv.org/abs/2409.12929",
    "authors": [
      "Jin Jiang",
      "Yuchen Yan",
      "Yang Liu",
      "Jianing Wang",
      "Shuai Peng",
      "Xunliang Cai",
      "Yixin Cao",
      "Mengdi Zhang",
      "Liangcai Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2410.17351",
    "title": "Hierarchical Multi-agent Reinforcement Learning for Cyber Network Defense",
    "abstract": "           Recent advances in multi-agent reinforcement learning (MARL) have created opportunities to solve complex real-world tasks. Cybersecurity is a notable application area, where defending networks against sophisticated adversaries remains a challenging task typically performed by teams of security operators. In this work, we explore novel MARL strategies for building autonomous cyber network defenses that address challenges such as large policy spaces, partial observability, and stealthy, deceptive adversarial strategies. To facilitate efficient and generalized learning, we propose a hierarchical Proximal Policy Optimization (PPO) architecture that decomposes the cyber defense task into specific sub-tasks like network investigation and host recovery. Our approach involves training sub-policies for each sub-task using PPO enhanced with cybersecurity domain expertise. These sub-policies are then leveraged by a master defense policy that coordinates their selection to solve complex network defense tasks. Furthermore, the sub-policies can be fine-tuned and transferred with minimal cost to defend against shifts in adversarial behavior or changes in network settings. We conduct extensive experiments using CybORG Cage 4, the state-of-the-art MARL environment for cyber defense. Comparisons with multiple baselines across different adversaries show that our hierarchical learning approach achieves top performance in terms of convergence speed, episodic return, and several interpretable metrics relevant to cybersecurity, including the fraction of clean machines on the network, precision, and false positives.         ",
    "url": "https://arxiv.org/abs/2410.17351",
    "authors": [
      "Aditya Vikram Singh",
      "Ethan Rathbun",
      "Emma Graham",
      "Lisa Oakley",
      "Simona Boboila",
      "Alina Oprea",
      "Peter Chin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2410.18122",
    "title": "Yesterday's News: Benchmarking Multi-Dimensional Out-of-Distribution Generalization of Misinformation Detection Models",
    "abstract": "           This article introduces misinfo-general, a benchmark dataset for evaluating misinformation models' ability to perform out-of-distribution generalization. Misinformation changes rapidly, much more quickly than moderators can annotate at scale, resulting in a shift between the training and inference data distributions. As a result, misinformation detectors need to be able to perform out-of-distribution generalization, an attribute they currently lack. Our benchmark uses distant labelling to enable simulating covariate shifts in misinformation content. We identify time, event, topic, publisher, political bias, misinformation type as important axes for generalization, and we evaluate a common class of baseline models on each. Using article metadata, we show how this model fails desiderata, which is not necessarily obvious from classification metrics. Finally, we analyze properties of the data to ensure limited presence of modelling shortcuts. We make the dataset and accompanying code publicly available: this https URL ",
    "url": "https://arxiv.org/abs/2410.18122",
    "authors": [
      "Ivo Verhoeven",
      "Pushkar Mishra",
      "Ekaterina Shutova"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2410.23903",
    "title": "Neural Network Verification with PyRAT",
    "abstract": "           As AI systems are becoming more and more popular and used in various critical domains (health, transport, energy, ...), the need to provide guarantees and trust of their safety is undeniable. To this end, we present PyRAT, a tool based on abstract interpretation to verify the safety and the robustness of neural networks. In this paper, we describe the different abstractions used by PyRAT to find the reachable states of a neural network starting from its input as well as the main features of the tool to provide fast and accurate analysis of neural networks. PyRAT has already been used in several collaborations to ensure safety guarantees, with its second place at the VNN-Comp 2024 showcasing its performance.         ",
    "url": "https://arxiv.org/abs/2410.23903",
    "authors": [
      "Augustin Lemesle",
      "Julien Lehmann",
      "Tristan Le Gall"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2411.06317",
    "title": "Harpocrates: A Statically Typed Privacy Conscious Pro-gramming Framework",
    "abstract": "           In this paper, we introduce Harpocrates, a compiler plugin and a framework pair for Scala that binds the privacy policies to the data during data creation in form of oblivious membranes. Harpocrates eliminates raw data for a policy protected type from the application, ensuring it can only exist in protected form and centralizes the policy checking to the policy declaration site, making the privacy logic easy to maintain and verify. Instead of approaching privacy from an information flow verification perspective, Harpocrates allow the data to flow freely throughout the application, inside the policy membranes but enforces the policies when the data is tried to be accessed, mutated, declassified or passed through the application boundary. The centralization of the policies allow the maintainers to change the enforced logic simply by updating a single function while keeping the rest of the application oblivious to the change. Especially in a setting where the data definition is shared by multiple applications, the publisher can update the policies without requiring the dependent applications to make any changes beyond updating the dependency version.         ",
    "url": "https://arxiv.org/abs/2411.06317",
    "authors": [
      "Sinan Pehlivanoglu",
      "Malte Schwarzkopf"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2412.13341",
    "title": "Concept-ROT: Poisoning Concepts in Large Language Models with Model Editing",
    "abstract": "           Model editing methods modify specific behaviors of Large Language Models by altering a small, targeted set of network weights and require very little data and compute. These methods can be used for malicious applications such as inserting misinformation or simple trojans that result in adversary-specified behaviors when a trigger word is present. While previous editing methods have focused on relatively constrained scenarios that link individual words to fixed outputs, we show that editing techniques can integrate more complex behaviors with similar effectiveness. We develop Concept-ROT, a model editing-based method that efficiently inserts trojans which not only exhibit complex output behaviors, but also trigger on high-level concepts -- presenting an entirely new class of trojan attacks. Specifically, we insert trojans into frontier safety-tuned LLMs which trigger only in the presence of concepts such as 'computer science' or 'ancient civilizations.' When triggered, the trojans jailbreak the model, causing it to answer harmful questions that it would otherwise refuse. Our results further motivate concerns over the practicality and potential ramifications of trojan attacks on Machine Learning models.         ",
    "url": "https://arxiv.org/abs/2412.13341",
    "authors": [
      "Keltin Grimes",
      "Marco Christiani",
      "David Shriver",
      "Marissa Connor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2412.14113",
    "title": "Adversarial Hubness in Multi-Modal Retrieval",
    "abstract": "           Hubness is a phenomenon in high-dimensional vector spaces where a point from the natural distribution is unusually close to many other points. This is a well-known problem in information retrieval that causes some items to accidentally (and incorrectly) appear relevant to many queries. In this paper, we investigate how attackers can exploit hubness to turn any image or audio input in a multi-modal retrieval system into an adversarial hub. Adversarial hubs can be used to inject universal adversarial content (e.g., spam) that will be retrieved in response to thousands of different queries, and also for targeted attacks on queries related to specific, attacker-chosen concepts. We present a method for creating adversarial hubs and evaluate the resulting hubs on benchmark multi-modal retrieval datasets and an image-to-image retrieval system implemented by Pinecone, a popular vector database. For example, in text-caption-to-image retrieval, a single adversarial hub, generated using 100 random queries, is retrieved as the top-1 most relevant image for more than 21,000 out of 25,000 test queries (by contrast, the most common natural hub is the top-1 response to only 102 queries), demonstrating the strong generalization capabilities of adversarial hubs. We also investigate whether techniques for mitigating natural hubness can also mitigate adversarial hubs, and show that they are not effective against hubs that target queries related to specific concepts.         ",
    "url": "https://arxiv.org/abs/2412.14113",
    "authors": [
      "Tingwei Zhang",
      "Fnu Suya",
      "Rishi Jha",
      "Collin Zhang",
      "Vitaly Shmatikov"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2501.04631",
    "title": "Disentangled Clothed Avatar Generation with Layered Representation",
    "abstract": "           Clothed avatar generation has wide applications in virtual and augmented reality, filmmaking, and more. Previous methods have achieved success in generating diverse digital avatars, however, generating avatars with disentangled components (\\eg, body, hair, and clothes) has long been a challenge. In this paper, we propose LayerAvatar, the first feed-forward diffusion-based method for generating component-disentangled clothed avatars. To achieve this, we first propose a layered UV feature plane representation, where components are distributed in different layers of the Gaussian-based UV feature plane with corresponding semantic labels. This representation supports high-resolution and real-time rendering, as well as expressive animation including controllable gestures and facial expressions. Based on the well-designed representation, we train a single-stage diffusion model and introduce constrain terms to address the severe occlusion problem of the innermost human body layer. Extensive experiments demonstrate the impressive performances of our method in generating disentangled clothed avatars, and we further explore its applications in component transfer. The project page is available at: this https URL ",
    "url": "https://arxiv.org/abs/2501.04631",
    "authors": [
      "Weitian Zhang",
      "Yichao Yan",
      "Sijing Wu",
      "Manwen Liao",
      "Xiaokang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2501.18724",
    "title": "Large Language Models with Temporal Reasoning for Longitudinal Clinical Summarization and Prediction",
    "abstract": "           Recent advances in large language models (LLMs) have shown potential in clinical text summarization, but their ability to handle long patient trajectories with multi-modal data spread across time remains underexplored. This study systematically evaluates several state-of-the-art open-source LLMs, their Retrieval Augmented Generation (RAG) variants and chain-of-thought (CoT) prompting on long-context clinical summarization and prediction. We examine their ability to synthesize structured and unstructured Electronic Health Records (EHR) data while reasoning over temporal coherence, by re-engineering existing tasks, including discharge summarization and diagnosis prediction from two publicly available EHR datasets. Our results indicate that long context windows improve input integration but do not consistently enhance clinical reasoning, and LLMs are still struggling with temporal progression and rare disease prediction. While RAG shows improvements in hallucination in some cases, it does not fully address these limitations. Our work fills the gap in long clinical text summarization, establishing a foundation for evaluating LLMs with multi-modal data and temporal reasoning.         ",
    "url": "https://arxiv.org/abs/2501.18724",
    "authors": [
      "Maya Kruse",
      "Shiyue Hu",
      "Nicholas Derby",
      "Yifu Wu",
      "Samantha Stonbraker",
      "Bingsheng Yao",
      "Dakuo Wang",
      "Elizabeth Goldberg",
      "Yanjun Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2502.00612",
    "title": "Using Causality for Enhanced Prediction of Web Traffic Time Series",
    "abstract": "           Predicting web service traffic has significant social value, as it can be applied to various practical scenarios, including but not limited to dynamic resource scaling, load balancing, system anomaly detection, service-level agreement compliance, and fraud detection. Web service traffic is characterized by frequent and drastic fluctuations over time and are influenced by heterogeneous web user behaviors, making accurate prediction a challenging task. Previous research has extensively explored statistical approaches, and neural networks to mine features from preceding service traffic time series for prediction. However, these methods have largely overlooked the causal relationships between services. Drawing inspiration from causality in ecological systems, we empirically recognize the causal relationships between web services. To leverage these relationships for improved web service traffic prediction, we propose an effective neural network module, CCMPlus, designed to extract causal relationship features across services. This module can be seamlessly integrated with existing time series models to consistently enhance the performance of web service traffic predictions. We theoretically justify that the causal correlation matrix generated by the CCMPlus module captures causal relationships among services. Empirical results on real-world datasets from Microsoft Azure, Alibaba Group, and Ant Group confirm that our method surpasses state-of-the-art approaches in Mean Squared Error (MSE) and Mean Absolute Error (MAE) for predicting service traffic time series. These findings highlight the efficacy of leveraging causal relationships for improved predictions.         ",
    "url": "https://arxiv.org/abs/2502.00612",
    "authors": [
      "Chang Tian",
      "Mingzhe Xing",
      "Zenglin Shi",
      "Matthew B. Blaschko",
      "Yinliang Yue",
      "Marie-Francine Moens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2502.12796",
    "title": "Learning Counterfactually Fair Models via Improved Generation with Neural Causal Models",
    "abstract": "           One of the main concerns while deploying machine learning models in real-world applications is fairness. Counterfactual fairness has emerged as an intuitive and natural definition of fairness. However, existing methodologies for enforcing counterfactual fairness seem to have two limitations: (i) generating counterfactual samples faithful to the underlying causal graph, and (ii) as we argue in this paper, existing regularizers are mere proxies and do not directly enforce the exact definition of counterfactual fairness. In this work, our aim is to mitigate both issues. Firstly, we propose employing Neural Causal Models (NCMs) for generating the counterfactual samples. For implementing the abduction step in NCMs, the posteriors of the exogenous variables need to be estimated given a counterfactual query, as they are not readily available. As a consequence, $\\mathcal{L}_3$ consistency with respect to the underlying causal graph cannot be guaranteed in practice due to the estimation errors involved. To mitigate this issue, we propose a novel kernel least squares loss term that enforces the $\\mathcal{L}_3$ constraints explicitly. Thus, we obtain an improved counterfactual generation suitable for the counterfactual fairness task. Secondly, we propose a new MMD-based regularizer term that explicitly enforces the counterfactual fairness conditions into the base model while training. We show an improved trade-off between counterfactual fairness and generalization over existing baselines on synthetic and benchmark datasets.         ",
    "url": "https://arxiv.org/abs/2502.12796",
    "authors": [
      "Krishn Vishwas Kher",
      "Saksham Mittal",
      "Aditya Varun V",
      "Shantanu Das",
      "SakethaNath Jagarlapudi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.02780",
    "title": "Quantitative Resilience Modeling for Autonomous Cyber Defense",
    "abstract": "           Cyber resilience is the ability of a system to recover from an attack with minimal impact on system operations. However, characterizing a network's resilience under a cyber attack is challenging, as there are no formal definitions of resilience applicable to diverse network topologies and attack patterns. In this work, we propose a quantifiable formulation of resilience that considers multiple defender operational goals, the criticality of various network resources for daily operations, and provides interpretability to security operators about their system's resilience under attack. We evaluate our approach within the CybORG environment, a reinforcement learning (RL) framework for autonomous cyber defense, analyzing trade-offs between resilience, costs, and prioritization of operational goals. Furthermore, we introduce methods to aggregate resilience metrics across time-variable attack patterns and multiple network topologies, comprehensively characterizing system resilience. Using insights gained from our resilience metrics, we design RL autonomous defensive agents and compare them against several heuristic baselines, showing that proactive network hardening techniques and prompt recovery of compromised machines are critical for effective cyber defenses.         ",
    "url": "https://arxiv.org/abs/2503.02780",
    "authors": [
      "Xavier Cadet",
      "Simona Boboila",
      "Edward Koh",
      "Peter Chin",
      "Alina Oprea"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2503.14333",
    "title": "Revealing higher-order neural representations of uncertainty with the Noise Estimation through Reinforcement-based Diffusion (NERD) model",
    "abstract": "           Studies often aim to reveal ``first-order\" representations (FORs), which encode aspects of an observer's environment, such as contents or structure. A less-common target is ``higher-order\" representations (HORs), which are ``about\" FORs -- e.g., their strength or uncertainty -- and which may contribute to learning. HORs about uncertainty are unlikely to be direct ``read-outs\" of FOR characteristics, instead reflecting noisy estimation processes incorporating prior expectations about uncertainty, but how the brain represents such expected uncertainty distributions remains largely unexplored. Here, we study ``noise expectation\" HORs using neural data from a task which may require the brain to learn about its own noise: decoded neurofeedback, wherein human subjects learn to volitionally produce target neural patterns. We develop and apply a Noise Estimation through Reinforcement-based Diffusion (NERD) model to characterize how brains may undertake this process, and show that NERD offers high explanatory power for human behavior.         ",
    "url": "https://arxiv.org/abs/2503.14333",
    "authors": [
      "Hojjat Azimi Asrari",
      "Megan A. K. Peters"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2503.17111",
    "title": "A Digital Machine Learning Algorithm Simulating Spiking Neural Network CoLaNET",
    "abstract": "           During last several years, our research team worked on development of a spiking neural network (SNN) architecture, which could be used in the wide range of supervised learning classification tasks. It should work under the condition, that all participating signals (the classified object description, correct class label and SNN decision) should have spiking nature. As a result, the CoLaNET (columnar layered network) SNN architecture was invented. The distinctive feature of this architecture is a combination of prototypical network structures corresponding to different classes and significantly distinctive instances of one class (=columns) and functionally differing populations of neurons inside columns (=layers). The other distinctive feature is a novel combination of anti-Hebbian and dopamine-modulated plasticity. While CoLaNET is relatively simple, it includes several hyperparameters. Their choice for particular classification tasks is not trivial. Besides that, specific features of the data classified (e.g. classification of separate pictures like in MNIST dataset vs. classifying objects in a continuous video stream) require certain modifications of CoLaNET structure. To solve these problems, the deep mathematical exploration of CoLaNET should be carried out. However, SNNs, being stochastic discrete systems, are usually very hard for exact mathematical analysis. To make it easier, I developed a continuous numeric (non-spiking) machine learning algorithm which approximates CoLaNET behavior with satisfactory accuracy. It is described in the paper. At present, it is being studied by exact analytic methods. We hope that the results of this study could be applied to direct calculation of CoLaNET hyperparameters and optimization of its structure.         ",
    "url": "https://arxiv.org/abs/2503.17111",
    "authors": [
      "Mikhail Kiselev"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2504.02618",
    "title": "Variational Online Mirror Descent for Robust Learning in Schr\u00f6dinger Bridge",
    "abstract": "           The Schr\u00f6dinger bridge (SB) has evolved into a universal class of probabilistic generative models. In practice, however, estimated learning signals are innately uncertain, and the reliability promised by existing methods is often based on speculative optimal case scenarios. Recent studies regarding the Sinkhorn algorithm through mirror descent (MD) have gained attention, revealing geometric insights into solution acquisition of the SB problems. In this paper, we propose a variational online MD (OMD) framework for the SB problems, which provides further stability to SB solvers. We formally prove convergence and a regret bound for the novel OMD formulation of SB acquisition. As a result, we propose a simulation-free SB algorithm called Variational Mirrored Schr\u00f6dinger Bridge (VMSB) by utilizing the Wasserstein-Fisher-Rao geometry of the Gaussian mixture parameterization for Schr\u00f6dinger potentials. Based on the Wasserstein gradient flow theory, the algorithm offers tractable learning dynamics that precisely approximate each OMD step. In experiments, we validate the performance of the proposed VMSB algorithm across an extensive suite of benchmarks. VMSB consistently outperforms contemporary SB solvers on a wide range of SB problems, demonstrating the robustness as well as generality predicted by our OMD theory.         ",
    "url": "https://arxiv.org/abs/2504.02618",
    "authors": [
      "Dong-Sig Han",
      "Jaein Kim",
      "Hee Bin Yoo",
      "Byoung-Tak Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2504.03352",
    "title": "StereoDetect: Detecting Stereotypes and Anti-stereotypes the Correct Way Using Social Psychological Underpinnings",
    "abstract": "           Stereotypes are known to have very harmful effects, making their detection critically important. However, current research predominantly focuses on detecting and evaluating stereotypical biases, thereby leaving the study of stereotypes in its early stages. Our study revealed that many works have failed to clearly distinguish between stereotypes and stereotypical biases, which has significantly slowed progress in advancing research in this area. Stereotype and Anti-stereotype detection is a problem that requires social knowledge; hence, it is one of the most difficult areas in Responsible AI. This work investigates this task, where we propose a five-tuple definition and provide precise terminologies disentangling stereotypes, anti-stereotypes, stereotypical bias, and general bias. We provide a conceptual framework grounded in social psychology for reliable detection. We identify key shortcomings in existing benchmarks for this task of stereotype and anti-stereotype detection. To address these gaps, we developed StereoDetect, a well curated, definition-aligned benchmark dataset designed for this task. We show that sub-10B language models and GPT-4o frequently misclassify anti-stereotypes and fail to recognize neutral overgeneralizations. We demonstrate StereoDetect's effectiveness through multiple qualitative and quantitative comparisons with existing benchmarks and models fine-tuned on them. The dataset and code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2504.03352",
    "authors": [
      "Kaustubh Shivshankar Shejole",
      "Pushpak Bhattacharyya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2504.12882",
    "title": "ViClaim: A Multilingual Multilabel Dataset for Automatic Claim Detection in Videos",
    "abstract": "           The growing influence of video content as a medium for communication and misinformation underscores the urgent need for effective tools to analyze claims in multilingual and multi-topic settings. Existing efforts in misinformation detection largely focus on written text, leaving a significant gap in addressing the complexity of spoken text in video transcripts. We introduce ViClaim, a dataset of 1,798 annotated video transcripts across three languages (English, German, Spanish) and six topics. Each sentence in the transcripts is labeled with three claim-related categories: fact-check-worthy, fact-non-check-worthy, or opinion. We developed a custom annotation tool to facilitate the highly complex annotation process. Experiments with state-of-the-art multilingual language models demonstrate strong performance in cross-validation (macro F1 up to 0.896) but reveal challenges in generalization to unseen topics, particularly for distinct domains. Our findings highlight the complexity of claim detection in video transcripts. ViClaim offers a robust foundation for advancing misinformation detection in video-based communication, addressing a critical gap in multimodal analysis.         ",
    "url": "https://arxiv.org/abs/2504.12882",
    "authors": [
      "Patrick Giedemann",
      "Pius von D\u00e4niken",
      "Jan Deriu",
      "Alvaro Rodrigo",
      "Anselmo Pe\u00f1as",
      "Mark Cieliebak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2505.10264",
    "title": "Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning",
    "abstract": "           Federated Learning (FL) enables collaborative training of machine learning models across distributed clients without sharing raw data, ostensibly preserving data privacy. Nevertheless, recent studies have revealed critical vulnerabilities in FL, showing that a malicious central server can manipulate model updates to reconstruct clients' private training data. Existing data reconstruction attacks have important limitations: they often rely on assumptions about the clients' data distribution or their efficiency significantly degrades when batch sizes exceed just a few tens of samples. In this work, we introduce a novel data reconstruction attack that overcomes these limitations. Our method leverages a new geometric perspective on fully connected layers to craft malicious model parameters, enabling the perfect recovery of arbitrarily large data batches in classification tasks without any prior knowledge of clients' data. Through extensive experiments on both image and tabular datasets, we demonstrate that our attack outperforms existing methods and achieves perfect reconstruction of data batches two orders of magnitude larger than the state of the art.         ",
    "url": "https://arxiv.org/abs/2505.10264",
    "authors": [
      "Francesco Diana",
      "Andr\u00e9 Nusser",
      "Chuan Xu",
      "Giovanni Neglia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2505.13655",
    "title": "Optimal Client Sampling in Federated Learning with Client-Level Heterogeneous Differential Privacy",
    "abstract": "           Federated Learning with client-level differential privacy (DP) provides a promising framework for collaboratively training models while rigorously protecting clients' privacy. However, classic approaches like DP-FedAvg struggle when clients have heterogeneous privacy requirements, as they must uniformly enforce the strictest privacy level across clients, leading to excessive DP noise and significant model utility degradation. Existing methods to improve the model utility in such heterogeneous privacy settings often assume a trusted server and are largely heuristic, resulting in suboptimal performance and lacking strong theoretical underpinnings. In this work, we address these challenges under a practical attack model where both clients and the server are honest-but-curious. We propose GDPFed, which partitions clients into groups based on their privacy budgets and achieves client-level DP within each group to reduce the privacy budget waste and hence improve the model utility. Based on the privacy and convergence analysis of GDPFed, we find that the magnitude of DP noise depends on both model dimensionality and the per-group client sampling ratios. To further improve the performance of GDPFed, we introduce GDPFed$^+$, which integrates model sparsification to eliminate unnecessary noise and optimizes per-group client sampling ratios to minimize convergence error. Extensive empirical evaluations on multiple benchmark datasets demonstrate the effectiveness of GDPFed$^+$, showing substantial performance gains compared with state-of-the-art methods.         ",
    "url": "https://arxiv.org/abs/2505.13655",
    "authors": [
      "Jiahao Xu",
      "Rui Hu",
      "Olivera Kotevska"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2505.16422",
    "title": "Unlocking Smarter Device Control: Foresighted Planning with a World Model-Driven Code Execution Approach",
    "abstract": "           The automatic control of mobile devices is essential for efficiently performing complex tasks that involve multiple sequential steps. However, these tasks pose significant challenges due to the limited environmental information available at each step, primarily through visual observations. As a result, current approaches, which typically rely on reactive policies, focus solely on immediate observations and often lead to suboptimal decision-making. To address this problem, we propose \\textbf{Foresighted Planning with World Model-Driven Code Execution (FPWC)},a framework that prioritizes natural language understanding and structured reasoning to enhance the agent's global understanding of the environment by developing a task-oriented, refinable \\emph{world model} at the outset of the task. Foresighted actions are subsequently generated through iterative planning within this world model, executed in the form of executable code. Extensive experiments conducted in simulated environments and on real mobile devices demonstrate that our method outperforms previous approaches, particularly achieving a 44.4\\% relative improvement in task success rate compared to the state-of-the-art in the simulated environment. Code and demo are provided in the supplementary material.         ",
    "url": "https://arxiv.org/abs/2505.16422",
    "authors": [
      "Xiaoran Yin",
      "Xu Luo",
      "Hao Wu",
      "Lianli Gao",
      "Jingkuan Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2505.17114",
    "title": "RAVEN: Query-Guided Representation Alignment for Question Answering over Audio, Video, Embedded Sensors, and Natural Language",
    "abstract": "           Multimodal question answering (QA) often requires identifying which video, audio, or sensor tokens are relevant to the question. Yet modality disagreements are common: off-camera speech, background noise, or motion outside the field of view often mislead fusion models that weight all streams equally. We present RAVEN, a unified QA architecture whose core is QuART, a query-conditioned cross-modal gating module that assigns scalar relevance scores to each token across modalities, enabling the model to amplify informative signals and suppress distractors before fusion. RAVEN is trained through a three-stage pipeline comprising unimodal pretraining, query-aligned fusion, and disagreement-oriented fine-tuning -- each stage targeting a distinct challenge in multi-modal reasoning: representation quality, cross-modal relevance, and robustness to modality mismatch. To support training and evaluation, we release AVS-QA, a dataset of 300K synchronized Audio--Video-Sensor streams paired with automatically generated question-answer pairs. Experimental results on seven multi-modal QA benchmarks -- including egocentric and exocentric tasks -- show that RAVEN achieves up to 14.5\\% and 8.0\\% gains in accuracy compared to state-of-the-art multi-modal large language models, respectively. Incorporating sensor data provides an additional 16.4\\% boost, and the model remains robust under modality corruption, outperforming SOTA baselines by 50.23\\%. Our code and dataset are available at this https URL.         ",
    "url": "https://arxiv.org/abs/2505.17114",
    "authors": [
      "Subrata Biswas",
      "Mohammad Nur Hossain Khan",
      "Bashima Islam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2506.09824",
    "title": "A Weighted Loss Approach to Robust Federated Learning under Data Heterogeneity",
    "abstract": "           Federated learning (FL) is a machine learning paradigm that enables multiple data holders to collaboratively train a machine learning model without sharing their training data with external parties. In this paradigm, workers locally update a model and share with a central server their updated gradients (or model parameters). While FL seems appealing from a privacy perspective, it opens a number of threats from a security perspective as (Byzantine) participants can contribute poisonous gradients (or model parameters) harming model convergence. Byzantine-resilient FL addresses this issue by ensuring that the training proceeds as if Byzantine participants were absent. Towards this purpose, common strategies ignore outlier gradients during model aggregation, assuming that Byzantine gradients deviate more from honest gradients than honest gradients do from each other. However, in heterogeneous settings, honest gradients may differ significantly, making it difficult to distinguish honest outliers from Byzantine ones. In this paper, we introduce the Worker Label Alignement Loss (WoLA), a weighted loss that aligns honest worker gradients despite data heterogeneity, which facilitates the identification of Byzantines' gradients. This approach significantly outperforms state-of-the-art methods in heterogeneous settings. In this paper, we provide both theoretical insights and empirical evidence of its effectiveness.         ",
    "url": "https://arxiv.org/abs/2506.09824",
    "authors": [
      "Johan Erbani",
      "Sonia Ben Mokhtar",
      "Pierre-Edouard Portier",
      "Elod Egyed-Zsigmond",
      "Diana Nurbakova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2506.17733",
    "title": "YOLOv13: Real-Time Object Detection with Hypergraph-Enhanced Adaptive Visual Perception",
    "abstract": "           The YOLO series models reign supreme in real-time object detection due to their superior accuracy and computational efficiency. However, both the convolutional architectures of YOLO11 and earlier versions and the area-based self-attention mechanism introduced in YOLOv12 are limited to local information aggregation and pairwise correlation modeling, lacking the capability to capture global multi-to-multi high-order correlations, which limits detection performance in complex scenarios. In this paper, we propose YOLOv13, an accurate and lightweight object detector. To address the above-mentioned challenges, we propose a Hypergraph-based Adaptive Correlation Enhancement (HyperACE) mechanism that adaptively exploits latent high-order correlations and overcomes the limitation of previous methods that are restricted to pairwise correlation modeling based on hypergraph computation, achieving efficient global cross-location and cross-scale feature fusion and enhancement. Subsequently, we propose a Full-Pipeline Aggregation-and-Distribution (FullPAD) paradigm based on HyperACE, which effectively achieves fine-grained information flow and representation synergy within the entire network by distributing correlation-enhanced features to the full pipeline. Finally, we propose to leverage depthwise separable convolutions to replace vanilla large-kernel convolutions, and design a series of blocks that significantly reduce parameters and computational complexity without sacrificing performance. We conduct extensive experiments on the widely used MS COCO benchmark, and the experimental results demonstrate that our method achieves state-of-the-art performance with fewer parameters and FLOPs. Specifically, our YOLOv13-N improves mAP by 3.0\\% over YOLO11-N and by 1.5\\% over YOLOv12-N. The code and models of our YOLOv13 model are available at: this https URL.         ",
    "url": "https://arxiv.org/abs/2506.17733",
    "authors": [
      "Mengqi Lei",
      "Siqi Li",
      "Yihong Wu",
      "Han Hu",
      "You Zhou",
      "Xinhu Zheng",
      "Guiguang Ding",
      "Shaoyi Du",
      "Zongze Wu",
      "Yue Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2507.05644",
    "title": "The Features at Convergence Theorem: a first-principles alternative to the Neural Feature Ansatz for how networks learn representations",
    "abstract": "           It is a central challenge in deep learning to understand how neural networks learn representations. A leading approach is the Neural Feature Ansatz (NFA) (Radhakrishnan et al. 2024), a conjectured mechanism for how feature learning occurs. Although the NFA is empirically validated, it is an educated guess and lacks a theoretical basis, and thus it is unclear when it might fail, and how to improve it. In this paper, we take a first-principles approach to understanding why this observation holds, and when it does not. We use first-order optimality conditions to derive the Features at Convergence Theorem (FACT), an alternative to the NFA that (a) obtains greater agreement with learned features at convergence, (b) explains why the NFA holds in most settings, and (c) captures essential feature learning phenomena in neural networks such as grokking behavior in modular arithmetic and phase transitions in learning sparse parities, similarly to the NFA. Thus, our results unify theoretical first-order optimality analyses of neural networks with the empirically-driven NFA literature, and provide a principled alternative that provably and empirically holds at convergence.         ",
    "url": "https://arxiv.org/abs/2507.05644",
    "authors": [
      "Enric Boix-Adsera",
      "Neil Mallinar",
      "James B. Simon",
      "Mikhail Belkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2507.06269",
    "title": "BayesSDF: Surface-Based Laplacian Uncertainty Estimation for 3D Geometry with Neural Signed Distance Fields",
    "abstract": "           Accurate surface estimation is critical for downstream tasks in scientific simulation, and quantifying uncertainty in implicit neural 3D representations still remains a substantial challenge due to computational inefficiencies, scalability issues, and geometric inconsistencies. However, current neural implicit surface models do not offer a principled way to quantify uncertainty, limiting their reliability in real-world applications. Inspired by recent probabilistic rendering approaches, we introduce BayesSDF, a novel probabilistic framework for uncertainty estimation in neural implicit 3D representations. Unlike radiance-based models such as Neural Radiance Fields (NeRF) or 3D Gaussian Splatting, Signed Distance Functions (SDFs) provide continuous, differentiable surface representations, making them especially well-suited for uncertainty-aware modeling. BayesSDF applies a Laplace approximation over SDF weights and derives Hessian-based metrics to estimate local geometric instability. We empirically demonstrate that these uncertainty estimates correlate strongly with surface reconstruction error across both synthetic and real-world benchmarks. By enabling surface-aware uncertainty quantification, BayesSDF lays the groundwork for more robust, interpretable, and actionable 3D perception systems.         ",
    "url": "https://arxiv.org/abs/2507.06269",
    "authors": [
      "Rushil Desai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2507.13120",
    "title": "RS-TinyNet: Stage-wise Feature Fusion Network for Detecting Tiny Objects in Remote Sensing Images",
    "abstract": "           Detecting tiny objects in remote sensing (RS) imagery has been a long-standing challenge due to their extremely limited spatial information, weak feature representations, and dense distributions across complex backgrounds. Despite numerous efforts devoted, mainstream detectors still underperform in such scenarios. To bridge this gap, we introduce RS-TinyNet, a multi-stage feature fusion and enhancement model explicitly tailored for RS tiny object detection in various RS scenarios. RS-TinyNet comes with two novel designs: tiny object saliency modeling and feature integrity reconstruction. Guided by these principles, we design three step-wise feature enhancement modules. Among them, the multi-dimensional collaborative attention (MDCA) module employs multi-dimensional attention to enhance the saliency of tiny objects. Additionally, the auxiliary reversible branch (ARB) and a progressive fusion detection head (PFDH) module are introduced to preserve information flow and fuse multi-level features to bridge semantic gaps and retain structural detail. Comprehensive experiments on public RS dataset AI-TOD show that our RS-TinyNet surpasses existing state-of-the-art (SOTA) detectors by 4.0% AP and 6.5% AP75. Evaluations on DIOR benchmark dataset further validate its superior detection performance in diverse RS scenarios. These results demonstrate that the proposed multi-stage feature fusion strategy offers an effective and practical solution for tiny object detection in complex RS environments.         ",
    "url": "https://arxiv.org/abs/2507.13120",
    "authors": [
      "Xiaozheng Jiang",
      "Wei Zhang",
      "Xuerui Mao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.15862",
    "title": "Quantifying Holistic Review: A Multi-Modal Approach to College Admissions Prediction",
    "abstract": "           This paper introduces the Comprehensive Applicant Profile Score (CAPS), a novel multi-modal framework designed to quantitatively model and interpret holistic college admissions evaluations. CAPS decomposes applicant profiles into three interpretable components: academic performance (Standardized Academic Score, SAS), essay quality (Essay Quality Index, EQI), and extracurricular engagement (Extracurricular Impact Score, EIS). Leveraging transformer-based semantic embeddings, LLM scoring, and XGBoost regression, CAPS provides transparent and explainable evaluations aligned with human judgment. Experiments on a synthetic but realistic dataset demonstrate strong performance, achieving an EQI prediction R^2 of 0.80, classification accuracy over 75%, a macro F1 score of 0.69, and a weighted F1 score of 0.74. CAPS addresses key limitations in traditional holistic review -- particularly the opacity, inconsistency, and anxiety faced by applicants -- thus paving the way for more equitable and data-informed admissions practices.         ",
    "url": "https://arxiv.org/abs/2507.15862",
    "authors": [
      "Jun-Wei Zeng",
      "Jerry Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2507.23567",
    "title": "3D-MOOD: Lifting 2D to 3D for Monocular Open-Set Object Detection",
    "abstract": "           Monocular 3D object detection is valuable for various applications such as robotics and AR/VR. Existing methods are confined to closed-set settings, where the training and testing sets consist of the same scenes and/or object categories. However, real-world applications often introduce new environments and novel object categories, posing a challenge to these methods. In this paper, we address monocular 3D object detection in an open-set setting and introduce the first end-to-end 3D Monocular Open-set Object Detector (3D-MOOD). We propose to lift the open-set 2D detection into 3D space through our designed 3D bounding box head, enabling end-to-end joint training for both 2D and 3D tasks to yield better overall performance. We condition the object queries with geometry prior and overcome the generalization for 3D estimation across diverse scenes. To further improve performance, we design the canonical image space for more efficient cross-dataset training. We evaluate 3D-MOOD on both closed-set settings (Omni3D) and open-set settings (Omni3D to Argoverse 2, ScanNet), and achieve new state-of-the-art results. Code and models are available at this http URL.         ",
    "url": "https://arxiv.org/abs/2507.23567",
    "authors": [
      "Yung-Hsu Yang",
      "Luigi Piccinelli",
      "Mattia Segu",
      "Siyuan Li",
      "Rui Huang",
      "Yuqian Fu",
      "Marc Pollefeys",
      "Hermann Blum",
      "Zuria Bauer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2508.00735",
    "title": "Overlapping IPv4, IPv6, and TCP data: exploring errors, test case context and multiple overlaps inside network stacks and NIDSes with PYROLYSE",
    "abstract": "           IP fragmentation and TCP segmentation allow for splitting large data packets into smaller ones, e.g., for transmission across network links of limited capacity. These mechanisms permit complete or partial overlaps with different data on the overlapping portions. IPv4, IPv6, and TCP reassembly policies, i.e., the data chunk preferences that depend on the overlap types, differ across protocol implementations. This leads to vulnerabilities, as NIDSes may interpret the packet differently from the monitored host OSes. Some NIDSes, such as Suricata or Snort, can be configured so that their policies are consistent with the monitored OSes. The first contribution of the paper is PYROLYSE, an audit tool that exhaustively tests and describes the reassembly policies of various IP and TCP implementation types. This tool ensures that implementations reassemble overlapping chunk sequences without errors. The second contribution is the analysis of PYROLYSE artifacts. We first show that the reassembly policies are much more diverse than previously thought. Indeed, by testing all the overlap possibilities for n <= 3 test case chunks and different testing scenarios, we observe from 14 to 20 different behaviors out of 23 tested implementations depending on the protocol. Second, we report eight errors impacting one OS, two NIDSes, and two embedded stacks, which can lead to security issues such as NIDS pattern-matching bypass or DoS attacks. A CVE was assigned to a NIDS error. Finally, we show that implemented IP and TCP policies obtained through chunk pair testing are usually inconsistent with the observed triplet reassemblies. Therefore, contrarily to what they currently do, NIDSes or other network traffic analysis tools should not apply n = 2 pair policies when the number of overlapping chunks exceeds two.         ",
    "url": "https://arxiv.org/abs/2508.00735",
    "authors": [
      "Lucas Aubard",
      "Johan Mazel",
      "Gilles Guette",
      "Pierre Chifflier"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2508.04833",
    "title": "OPTIMUMP2P: Fast and Reliable Gossiping in P2P Networks",
    "abstract": "           Gossip algorithms are pivotal in the dissemination of information within decentralized systems. Consequently, numerous gossip libraries have been developed and widely utilized especially in blockchain protocols for the propagation of blocks and transactions. A well-established library is libp2p, which provides two gossip algorithms: floodsub and gossipsub. These algorithms enable the delivery of published messages to a set of peers. In this work we aim to enhance the performance and reliability of libp2p by introducing OPTIMUMP2P, a novel gossip algorithm that leverages the capabilities of Random Linear Network Coding (RLNC) to expedite the dissemination of information in a peer-to-peer (P2P) network while ensuring reliable delivery, even in the presence of malicious actors capable of corrupting the transmitted data. Preliminary research from the Ethereum Foundation has demonstrated the use of RLNC in the significant improvement in the block propagation time [14]. Here we present extensive evaluation results both in simulation and real-world environments that demonstrate the performance gains of OPTIMUMP2P over the Gossipsub protocol.         ",
    "url": "https://arxiv.org/abs/2508.04833",
    "authors": [
      "Nicolas Nicolaou",
      "Onyeka Obi",
      "Aayush Rajasekaran",
      "Alejandro Bergasov",
      "Aleksandr Bezobchuk",
      "Kishori M. Konwar",
      "Michael Meier",
      "Santiago Paiva",
      "Har Preet Singh",
      "Swarnabha Sinha. Sriram Vishwanath",
      "Muriel Medard"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2508.10542",
    "title": "GCRPNet: Graph-Enhanced Contextual and Regional Perception Network For Salient Object Detection in Optical Remote Sensing Images",
    "abstract": "           Salient object detection (SOD) in optical remote sensing images (ORSIs) faces numerous challenges, including significant variations in target scales and low contrast between targets and the background. Existing methods based on vision transformers (ViTs) and convolutional neural networks (CNNs) architectures aim to leverage both global and local features, but the difficulty in effectively integrating these heterogeneous features limits their overall performance. To overcome these limitations, we propose a graph-enhanced contextual and regional perception network (GCRPNet), which builds upon the Mamba architecture to simultaneously capture long-range dependencies and enhance regional feature representation. Specifically, we employ the visual state space (VSS) encoder to extract multi-scale features. To further achieve deep guidance and enhancement of these features, we first design a difference-similarity guided hierarchical graph attention module (DS-HGAM). This module strengthens cross-layer interaction capabilities between features of different scales while enhancing the model's structural perception,allowing it to distinguish between foreground and background more effectively. Then, we design the LEVSS block as the decoder of GCRPNet. This module integrates our proposed adaptive scanning strategy and multi-granularity collaborative attention enhancement module (MCAEM). It performs adaptive patch scanning on feature maps processed via multi-scale convolutions, thereby capturing rich local region information and enhancing Mamba's local modeling capability. Extensive experimental results demonstrate that the proposed model achieves state-of-the-art performance, validating its effectiveness and superiority.         ",
    "url": "https://arxiv.org/abs/2508.10542",
    "authors": [
      "Mengyu Ren",
      "Yutong Li",
      "Hua Li",
      "Runmin Cong",
      "Sam Kwong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2508.11987",
    "title": "FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction",
    "abstract": "           Future prediction is a complex task for LLM agents, requiring a high level of analytical thinking, information gathering, contextual understanding, and decision-making under uncertainty. Agents must not only gather and interpret vast amounts of dynamic information but also integrate diverse data sources, weigh uncertainties, and adapt predictions based on emerging trends, just as human experts do in fields like politics, economics, and finance. Despite its importance, no large-scale benchmark exists for evaluating agents on future prediction, largely due to challenges in handling real-time updates and retrieving timely, accurate answers. To address this, we introduce $\\textbf{FutureX}$, a dynamic and live evaluation benchmark specifically designed for LLM agents performing future prediction tasks. FutureX is the largest and most diverse live benchmark for future prediction, supporting real-time daily updates and eliminating data contamination through an automated pipeline for question gathering and answer collection. We evaluate 25 LLM/agent models, including those with reasoning, search capabilities, and integration of external tools such as the open-source Deep Research Agent and closed-source Deep Research models. This comprehensive evaluation assesses agents' adaptive reasoning and performance in dynamic environments. Additionally, we provide in-depth analyses of agents' failure modes and performance pitfalls in future-oriented tasks, including the vulnerability to fake web pages and the temporal validity. Our goal is to establish a dynamic, contamination-free evaluation standard that drives the development of LLM agents capable of performing at the level of professional human analysts in complex reasoning and predictive thinking.         ",
    "url": "https://arxiv.org/abs/2508.11987",
    "authors": [
      "Zhiyuan Zeng",
      "Jiashuo Liu",
      "Siyuan Chen",
      "Tianci He",
      "Yali Liao",
      "Yixiao Tian",
      "Jinpeng Wang",
      "Zaiyuan Wang",
      "Yang Yang",
      "Lingyue Yin",
      "Mingren Yin",
      "Zhenwei Zhu",
      "Tianle Cai",
      "Zehui Chen",
      "Jiecao Chen",
      "Yantao Du",
      "Xiang Gao",
      "Jiacheng Guo",
      "Liang Hu",
      "Jianpeng Jiao",
      "Xiangsheng Li",
      "Jingkai Liu",
      "Shuang Ni",
      "Zhoufutu Wen",
      "Ge Zhang",
      "Kaiyuan Zhang",
      "Xin Zhou",
      "Jose Blanchet",
      "Xipeng Qiu",
      "Mengdi Wang",
      "Wenhao Huang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2508.13676",
    "title": "MHSNet:An MoE-based Hierarchical Semantic Representation Network for Accurate Duplicate Resume Detection with Large Language Model",
    "abstract": "           To maintain the company's talent pool, recruiters need to continuously search for resumes from third-party websites (e.g., LinkedIn, Indeed). However, fetched resumes are often incomplete and inaccurate. To improve the quality of third-party resumes and enrich the company's talent pool, it is essential to conduct duplication detection between the fetched resumes and those already in the company's talent pool. Such duplication detection is challenging due to the semantic complexity, structural heterogeneity, and information incompleteness of resume texts. To this end, we propose MHSNet, an multi-level identity verification framework that fine-tunes BGE-M3 using contrastive learning. With the fine-tuned , Mixture-of-Experts (MoE) generates multi-level sparse and dense representations for resumes, enabling the computation of corresponding multi-level semantic similarities. Moreover, the state-aware Mixture-of-Experts (MoE) is employed in MHSNet to handle diverse incomplete resumes. Experimental results verify the effectiveness of MHSNet         ",
    "url": "https://arxiv.org/abs/2508.13676",
    "authors": [
      "Yu Li",
      "Zulong Chen",
      "Wenjian Xu",
      "Hong Wen",
      "Yipeng Yu",
      "Man Lung Yiu",
      "Yuyu Yin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2508.16172",
    "title": "Graph RAG as Human Choice Model: Building a Data-Driven Mobility Agent with Preference Chain",
    "abstract": "           Understanding human behavior in urban environments is a crucial field within city sciences. However, collecting accurate behavioral data, particularly in newly developed areas, poses significant challenges. Recent advances in generative agents, powered by Large Language Models (LLMs), have shown promise in simulating human behaviors without relying on extensive datasets. Nevertheless, these methods often struggle with generating consistent, context-sensitive, and realistic behavioral outputs. To address these limitations, this paper introduces the Preference Chain, a novel method that integrates Graph Retrieval-Augmented Generation (RAG) with LLMs to enhance context-aware simulation of human behavior in transportation systems. Experiments conducted on the Replica dataset demonstrate that the Preference Chain outperforms standard LLM in aligning with real-world transportation mode choices. The development of the Mobility Agent highlights potential applications of proposed method in urban mobility modeling for emerging cities, personalized travel behavior analysis, and dynamic traffic forecasting. Despite limitations such as slow inference and the risk of hallucination, the method offers a promising framework for simulating complex human behavior in data-scarce environments, where traditional data-driven models struggle due to limited data availability.         ",
    "url": "https://arxiv.org/abs/2508.16172",
    "authors": [
      "Kai Hu",
      "Parfait Atchade-Adelomou",
      "Carlo Adornetto",
      "Adrian Mora-Carrero",
      "Luis Alonso-Pastor",
      "Ariel Noyman",
      "Yubo Liu",
      "Kent Larson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2508.16531",
    "title": "Quality control in sublinear time: a case study via random graphs",
    "abstract": "           Many algorithms are designed to work well on average over inputs. When running such an algorithm on an arbitrary input, we must ask: Can we trust the algorithm on this input? We identify a new class of algorithmic problems addressing this, which we call \"Quality Control Problems.\" These problems are specified by a (positive, real-valued) \"quality function\" $\\rho$ and a distribution $D$ such that, with high probability, a sample drawn from $D$ is \"high quality,\" meaning its $\\rho$-value is near $1$. The goal is to accept inputs $x \\sim D$ and reject potentially adversarially generated inputs $x$ with $\\rho(x)$ far from $1$. The objective of quality control is thus weaker than either component problem: testing for \"$\\rho(x) \\approx 1$\" or testing if $x \\sim D$, and offers the possibility of more efficient algorithms. In this work, we consider the sublinear version of the quality control problem, where $D \\in \\Delta(\\{0,1\\}^N)$ and the goal is to solve the $(D ,\\rho)$-quality problem with $o(N)$ queries and time. As a case study, we consider random graphs, i.e., $D = G_{n,p}$ (and $N = \\binom{n}2$), and the $k$-clique count function $\\rho_k := C_k(G)/\\mathbb{E}_{G' \\sim G_{n,p}}[C_k(G')]$, where $C_k(G)$ is the number of $k$-cliques in $G$. Testing if $G \\sim G_{n,p}$ with one sample, let alone with sublinear query access to the sample, is of course impossible. Testing if $\\rho_k(G)\\approx 1$ requires $p^{-\\Omega(k^2)}$ samples. In contrast, we show that the quality control problem for $G_{n,p}$ (with $n \\geq p^{-ck}$ for some constant $c$) with respect to $\\rho_k$ can be tested with $p^{-O(k)}$ queries and time, showing quality control is provably superpolynomially more efficient in this setting. More generally, for a motif $H$ of maximum degree $\\Delta(H)$, the respective quality control problem can be solved with $p^{-O(\\Delta(H))}$ queries and running time.         ",
    "url": "https://arxiv.org/abs/2508.16531",
    "authors": [
      "Cassandra Marcussen",
      "Ronitt Rubinfeld",
      "Madhu Sudan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2508.17450",
    "title": "Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PD",
    "abstract": "           Large Language Models (LLMs) can struggle to balance gullibility to misinformation and resistance to valid corrections in persuasive dialogues, a critical challenge for reliable deployment. We introduce DuET-PD (Dual Evaluation for Trust in Persuasive Dialogues), a framework evaluating multi-turn stance-change dynamics across dual dimensions: persuasion type (corrective/misleading) and domain (knowledge via MMLU-Pro, and safety via SALAD-Bench). We find that even a state-of-the-art model like GPT-4o achieves only 27.32% accuracy in MMLU-Pro under sustained misleading persuasions. Moreover, results reveal a concerning trend of increasing sycophancy in newer open-source models. To address this, we introduce Holistic DPO, a training approach balancing positive and negative persuasion examples. Unlike prompting or resist-only training, Holistic DPO enhances both robustness to misinformation and receptiveness to corrections, improving Llama-3.1-8B-Instruct's accuracy under misleading persuasion in safety contexts from 4.21% to 76.54%. These contributions offer a pathway to developing more reliable and adaptable LLMs for multi-turn dialogue. Code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2508.17450",
    "authors": [
      "Bryan Chen Zhengyu Tan",
      "Daniel Wai Kit Chin",
      "Zhengyuan Liu",
      "Nancy F. Chen",
      "Roy Ka-Wei Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2508.18802",
    "title": "HyperTASR: Hypernetwork-Driven Task-Aware Scene Representations for Robust Manipulation",
    "abstract": "           Effective policy learning for robotic manipulation requires scene representations that selectively capture task-relevant environmental features. Current approaches typically employ task-agnostic representation extraction, failing to emulate the dynamic perceptual adaptation observed in human cognition. We present HyperTASR, a hypernetwork-driven framework that modulates scene representations based on both task objectives and the execution phase. Our architecture dynamically generates representation transformation parameters conditioned on task specifications and progression state, enabling representations to evolve contextually throughout task execution. This approach maintains architectural compatibility with existing policy learning frameworks while fundamentally reconfiguring how visual features are processed. Unlike methods that simply concatenate or fuse task embeddings with task-agnostic representations, HyperTASR establishes computational separation between task-contextual and state-dependent processing paths, enhancing learning efficiency and representational quality. Comprehensive evaluations in both simulation and real-world environments demonstrate substantial performance improvements across different representation paradigms. Through ablation studies and attention visualization, we confirm that our approach selectively prioritizes task-relevant scene information, closely mirroring human adaptive perception during manipulation tasks. The project website is at [HyperTASR](this https URL \"this http URL).         ",
    "url": "https://arxiv.org/abs/2508.18802",
    "authors": [
      "Li Sun",
      "Jiefeng Wu",
      "Feng Chen",
      "Ruizhe Liu",
      "Yanchao Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2508.20201",
    "title": "Social Bias in Multilingual Language Models: A Survey",
    "abstract": "           Pretrained multilingual models exhibit the same social bias as models processing English texts. This systematic review analyzes emerging research that extends bias evaluation and mitigation approaches into multilingual and non-English contexts. We examine these studies with respect to linguistic diversity, cultural awareness, and their choice of evaluation metrics and mitigation techniques. Our survey illuminates gaps in the field's dominant methodological design choices (e.g., preference for certain languages, scarcity of multilingual mitigation experiments) while cataloging common issues encountered and solutions implemented in adapting bias benchmarks across languages and cultures. Drawing from the implications of our findings, we chart directions for future research that can reinforce the multilingual bias literature's inclusivity, cross-cultural appropriateness, and alignment with state-of-the-art NLP advancements.         ",
    "url": "https://arxiv.org/abs/2508.20201",
    "authors": [
      "Lance Calvin Lim Gamboa",
      "Yue Feng",
      "Mark Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2509.00030",
    "title": "MultiStream-LLM: Bridging Modalities for Robust Sign Language Translation",
    "abstract": "           Despite progress in gloss-free Sign Language Translation (SLT), monolithic end-to-end models consistently fail on two critical components of natural signing: the precise recognition of high-speed fingerspelling and the integration of asynchronous non-manual cues from the face. Recent progress in Automated Sign Language Translation with Large Language Models has side stepped this challenge, forcing a single network to learn these simultaneously resulting in poor performance when tasked with translating crucial information such as names,places, and technical terms. We introduce MultiStream-LLM, a modular framework designed to overcome these limitations. Our approach employs separate, specialized predictors for continuous signing, fingerspelling, and lipreading. Each expert network first decodes its specific modality into a sequence of tokens. These parallel streams are then fused by a lightweight transformer that resolves temporal misalignments before passing the combined representation to a Large Language Model (LLM) for final sentence generation. Our method establishes a new state-of-the-art on the How2Sign benchmark with a BLEU-4 score of 23.5 and achieves 73.2% letter accuracy on the challenging ChicagoFSWildPlus fingerspelling dataset. These results validate our core hypothesis: by isolating and solving distinct recogni tion tasks before fusion, our multi-expert approach provides a more powerful and effective pathway to robust, high-fidelity sign language translation.         ",
    "url": "https://arxiv.org/abs/2509.00030",
    "authors": [
      "Marshall Thomas",
      "Edward Fish",
      "Richard Bowden"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.00461",
    "title": "TECP: Token-Entropy Conformal Prediction for LLMs",
    "abstract": "           Uncertainty quantification (UQ) for open-ended language generation remains a critical yet underexplored challenge, especially under black-box constraints where internal model signals are inaccessible. In this paper, we introduce Token-Entropy Conformal Prediction (TECP), a novel framework that leverages token-level entropy as a logit-free, reference-free uncertainty measure and integrates it into a split conformal prediction (CP) pipeline to construct prediction sets with formal coverage guarantees. Unlike existing approaches that rely on semantic consistency heuristics or white-box features, TECP directly estimates epistemic uncertainty from the token entropy structure of sampled generations and calibrates uncertainty thresholds via CP quantiles to ensure provable error control. Empirical evaluations across six large language models and two benchmarks (CoQA and TriviaQA) demonstrate that TECP consistently achieves reliable coverage and compact prediction sets, outperforming prior self-consistency-based UQ methods. Our method provides a principled and efficient solution for trustworthy generation in black-box LLM settings.         ",
    "url": "https://arxiv.org/abs/2509.00461",
    "authors": [
      "Beining Xu",
      "Yongming Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.00801",
    "title": "Adaptation of Parameters in Heterogeneous Multi-agent Systems",
    "abstract": "           This paper proposes an adaptation mechanism for heterogeneous multi-agent systems to align the agents' internal parameters, based on enforced consensus through strong couplings. Unlike homogeneous systems, where exact consensus is attainable, the heterogeneity in node dynamics precludes perfect synchronization. Nonetheless, previous work has demonstrated that strong coupling can induce approximate consensus, whereby the agents exhibit emergent collective behavior governed by the so-called blended dynamics. Building on this observation, we introduce an adaptation law that gradually aligns the internal parameters of agents without requiring direct parameter communication. The proposed method reuses the same coupling signal employed for state synchronization, which may result in a biologically or sociologically plausible adaptation process. Under a persistent excitation condition, we prove that the linearly parametrized vector fields of the agents converge to each other, thereby making the dynamics asymptotically homogeneous, and leading to exact consensus of the state variables.         ",
    "url": "https://arxiv.org/abs/2509.00801",
    "authors": [
      "Hyungbo Shim",
      "Jin Gyu Lee",
      "B. D. O. Anderson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2509.00832",
    "title": "Crystal Structure Prediction with a Geometric Permutation-Invariant Loss Function",
    "abstract": "           Crystalline structure prediction remains an open challenge in materials design. Despite recent advances in computational materials science, accurately predicting the three-dimensional crystal structures of organic materials--an essential first step for designing materials with targeted properties--remains elusive. In this work, we address the problem of molecular assembly, where a set $\\mathcal{S}$ of identical rigid molecules is packed to form a crystalline structure. Existing state-of-the-art models typically rely on computationally expensive, iterative flow-matching approaches. We propose a novel loss function that correctly captures key geometric molecular properties while maintaining permutation invariance over $\\mathcal{S}$. We achieve this via a differentiable linear assignment scheme based on the Sinkhorn algorithm. Remarkably, we show that even a simple regression using our method {\\em SinkFast} significantly outperforms more complex flow-matching approaches on the COD-Cluster17 benchmark, a curated subset of the Crystallography Open Database (COD).         ",
    "url": "https://arxiv.org/abs/2509.00832",
    "authors": [
      "Emmanuel Jehanno",
      "Romain Menegaux",
      "Julien Mairal",
      "Sergei Grudinin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ]
  },
  {
    "id": "arXiv:2509.00868",
    "title": "A Modular and Scalable Simulator for Connected-UAVs Communication in 5G Networks",
    "abstract": "           Cellular-connected UAV systems have enabled a wide range of low-altitude aerial services. However, these systems still face many challenges, such as frequent handovers and the inefficiency of traditional transport protocols. To better study these issues, we develop a modular and scalable simulation platform specifically designed for UAVs communication leveraging the research ecology in wireless communication of MATLAB. The platform supports flexible 5G NR node deployment, customizable UAVs mobility models, and multi-network-interface extensions. It also supports multiple transport protocols including TCP, UDP, QUIC, etc., allowing to investigate how different transport protocols affect UAVs communication performance. In addition, the platform includes a handover management module, enabling the evaluation of both traditional and learning-based handover strategies. Our platform can serve as a testbed for the development and evaluation of advanced transmission strategies in cellular-connected UAV systems.         ",
    "url": "https://arxiv.org/abs/2509.00868",
    "authors": [
      "Yong Su",
      "Yiyi Chen",
      "Shenghong Yi",
      "Hui Feng",
      "Yuedong Xu",
      "Wang Xiang",
      "Bo Hu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2509.02072",
    "title": "Abex-rat: Synergizing Abstractive Augmentation and Adversarial Training for Classification of Occupational Accident Reports",
    "abstract": "           The automatic classification of occupational accident reports is a critical research area for enhancing workplace safety and enabling large-scale risk analysis. However, the severe class imbalance inherent in these real-world datasets often compromises the performance of analytical models, particularly for rare but severe incident types, hindering the development of reliable automated systems. To address this challenge, we propose ABEX-RAT, a novel and efficient framework that synergizes generative data augmentation with robust adversarial training. Our approach first employs a twostep abstractive-expansive (ABEX) pipeline, which leverages a large language model to distill core incident semantics and then uses a generative model to create diverse, highquality synthetic samples for underrepresented classes. Subsequently, a lightweight classifier is trained on the augmented data using a computationally efficient random adversarial training (RAT) protocol, which stochastically applies perturbations to enhance model generalization and robustness without significant overhead. Experimental results on the public OSHA dataset demonstrate that our method achieves new state-of-the-art performance, reaching a macro-F1 score of 90.32% and significantly outperforming previous SOTA and fine-tuned large model baselines. Our work validates that this synergistic strategy is a highly effective and efficient alternative to brute-force fine-tuning for specialized, imbalanced classification tasks. The code is publicly available at:this https URL.         ",
    "url": "https://arxiv.org/abs/2509.02072",
    "authors": [
      "Jian Chen",
      "Jiabao Dou",
      "Jinbao Tian",
      "Yunqi Xu",
      "Zhou Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2509.03231",
    "title": "Exploring persuasive interactions with generative social robots: An experimental framework",
    "abstract": "           Integrating generative AI such as Large Language Models into social robots has improved their ability to engage in natural, human-like communication. This study presents a method to examine their persuasive capabilities. We designed an experimental framework focused on decision making and tested it in a pilot that varied robot appearance and self-knowledge. Using qualitative analysis, we evaluated interaction quality, persuasion effectiveness, and the robot's communicative strategies. Participants generally experienced the interaction positively, describing the robot as competent, friendly, and supportive, while noting practical limits such as delayed responses and occasional speech-recognition errors. Persuasiveness was highly context dependent and shaped by robot behavior: Participants responded well to polite, reasoned suggestions and expressive gestures, but emphasized the need for more personalized, context-aware arguments and clearer social roles. These findings suggest that generative social robots can influence user decisions, but their effectiveness depends on communicative nuance and contextual relevance. We propose refinements to the framework to further study persuasive dynamics between robots and human users.         ",
    "url": "https://arxiv.org/abs/2509.03231",
    "authors": [
      "Stephan Vonschallen",
      "Larissa Julia Corina Finsler",
      "Theresa Schmiedel",
      "Friederike Eyssel"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2509.03786",
    "title": "SLENet: A Guidance-Enhanced Network for Underwater Camouflaged Object Detection",
    "abstract": "           Underwater Camouflaged Object Detection (UCOD) aims to identify objects that blend seamlessly into underwater environments. This task is critically important to marine ecology. However, it remains largely underexplored and accurate identification is severely hindered by optical distortions, water turbidity, and the complex traits of marine organisms. To address these challenges, we introduce the UCOD task and present DeepCamo, a benchmark dataset designed for this domain. We also propose Semantic Localization and Enhancement Network (SLENet), a novel framework for UCOD. We first benchmark state-of-the-art COD models on DeepCamo to reveal key issues, upon which SLENet is built. In particular, we incorporate Gamma-Asymmetric Enhancement (GAE) module and a Localization Guidance Branch (LGB) to enhance multi-scale feature representation while generating a location map enriched with global semantic information. This map guides the Multi-Scale Supervised Decoder (MSSD) to produce more accurate predictions. Experiments on our DeepCamo dataset and three benchmark COD datasets confirm SLENet's superior performance over SOTA methods, and underscore its high generality for the broader COD task.         ",
    "url": "https://arxiv.org/abs/2509.03786",
    "authors": [
      "Xinxin Huang",
      "Han Sun",
      "Ningzhong Liu",
      "Huiyu Zhou",
      "Yinan Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.16019",
    "title": "Survival Analysis with Adversarial Regularization",
    "abstract": "           Survival Analysis (SA) models the time until an event occurs, with applications in fields like medicine, defense, finance, and aerospace. Recent research indicates that Neural Networks (NNs) can effectively capture complex data patterns in SA, whereas simple generalized linear models often fall short in this regard. However, dataset uncertainties (e.g., noisy measurements, human error) can degrade NN model performance. To address this, we leverage advances in NN verification to develop training objectives for robust, fully-parametric SA models. Specifically, we propose an adversarially robust loss function based on a Min-Max optimization problem. We employ CROWN-Interval Bound Propagation (CROWN-IBP) to tackle the computational challenges inherent in solving this Min-Max problem. Evaluated over 10 SurvSet datasets, our method, Survival Analysis with Adversarial Regularization (SAWAR), consistently outperforms baseline adversarial training methods and state-of-the-art (SOTA) deep SA models across various covariate perturbations with respect to Negative Log Likelihood (NegLL), Integrated Brier Score (IBS), and Concordance Index (CI) metrics. Thus, we demonstrate that adversarial robustness enhances SA predictive performance and calibration, mitigating data uncertainty and improving generalization across diverse datasets by up to 150% compared to baselines.         ",
    "url": "https://arxiv.org/abs/2312.16019",
    "authors": [
      "Michael Potter",
      "Stefano Maxenti",
      "Michael Everett"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2412.02670",
    "title": "The Broader Landscape of Robustness in Algorithmic Statistics",
    "abstract": "           The last decade has seen a number of advances in computationally efficient algorithms for statistical methods subject to robustness constraints. An estimator may be robust in a number of different ways: to contamination of the dataset, to heavy-tailed data, or in the sense that it preserves privacy of the dataset. We survey recent results in these areas with a focus on the problem of mean estimation, drawing technical and conceptual connections between the various forms of robustness, showing that the same underlying algorithmic ideas lead to computationally efficient estimators in all these settings.         ",
    "url": "https://arxiv.org/abs/2412.02670",
    "authors": [
      "Gautam Kamath"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2501.18912",
    "title": "Analyzing Classroom Interaction Data Using Prompt Engineering and Network Analysis",
    "abstract": "           Classroom interactions play a vital role in developing critical thinking, collaborative problem-solving abilities, and enhanced learning outcomes. While analyzing these interactions is crucial for improving educational practices, the examination of classroom dialogues presents significant challenges due to the complexity and high-dimensionality of conversational data. This study presents an integrated framework that combines prompt engineering with network analysis to investigate classroom interactions comprehensively. Our approach automates utterance classification through prompt engineering, enabling efficient and scalable dialogue analysis without requiring pre-labeled datasets. The classified interactions are subsequently transformed into network representations, facilitating the analysis of classroom dynamics as structured social networks. To uncover complex interaction patterns and how underlying interaction structures relate to student learning, we utilize network mediation analysis. In this approach, latent interaction structures, derived from the additive and multiplicative effects network (AMEN) model that places students within a latent social space, act as mediators. In particular, we investigate how the gender gap in mathematics performance may be mediated by students' classroom interaction structures.         ",
    "url": "https://arxiv.org/abs/2501.18912",
    "authors": [
      "Gwanghee Kim",
      "Ick Hoon Jin",
      "Minjeong Jeon"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2504.03727",
    "title": "Graph Transformer-Based Flood Susceptibility Mapping: Application to the French Riviera and Railway Infrastructure Under Climate Change",
    "abstract": "           Increasing flood frequency and severity due to climate change threatens infrastructure and demands improved susceptibility mapping techniques. While traditional machine learning (ML) approaches are widely used, they struggle to capture spatial dependencies and poor boundary delineation between susceptibility classes. This study introduces the first application of a graph transformer (GT) architecture for flood susceptibility mapping to the flood-prone French Riviera (e.g., 2020 Storm Alex) using topography, hydrology, geography, and environmental data. GT incorporates watershed topology using Laplacian positional encoders (PEs) and attention mechanisms. The developed GT model has an AUC-ROC (0.9739), slightly lower than XGBoost (0.9853). However, the GT model demonstrated better clustering and delineation with a higher Moran's I value (0.6119) compared to the random forest (0.5775) and XGBoost (0.5311) with p-value lower than 0.0001. Feature importance revealed a striking consistency across models, with elevation, slope, distance to channel, and convergence index being the critical factors. Dimensionality reduction on Laplacian PEs revealed partial clusters, indicating they could capture spatial information; however, their importance was lower than flood factors. Since climate and land use changes aggravate flood risk, susceptibility maps are developed for the 2050 year under different Representative Concentration Pathways (RCPs) and railway track vulnerability is assessed. All RCP scenarios revealed increased area across susceptibility classes, except for the very low category. RCP 8.5 projections indicate that 17.46% of the watershed area and 54% of railway length fall within very-high susceptible zones, compared to 6.19% and 35.61%, respectively, under current conditions. The developed maps can be integrated into a multi-hazard framework.         ",
    "url": "https://arxiv.org/abs/2504.03727",
    "authors": [
      "Sreenath Vemula",
      "Filippo Gatti",
      "Pierre Jehel"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.08216",
    "title": "Landmark-Based Node Representations for Shortest Path Distance Approximations in Random Graphs",
    "abstract": "           Learning node representations is a fundamental problem in graph machine learning. While existing embedding methods effectively preserve local similarity measures, they often fail to capture global functions like graph distances. Inspired by Bourgain's seminal work on Hilbert space embeddings of metric spaces (1985), we study the performance of local distance-preserving node embeddings. Known as landmark-based algorithms, these embeddings approximate pairwise distances by computing shortest paths from a small subset of reference nodes called landmarks. Our main theoretical contribution shows that random graphs, such as Erdos-Renyi random graphs, require lower dimensions in landmark-based embeddings compared to worst-case graphs. Empirically, we demonstrate that the GNN-based approximations for the distances to landmarks generalize well to larger real-world networks, offering a scalable and transferable alternative for graph representation learning.         ",
    "url": "https://arxiv.org/abs/2504.08216",
    "authors": [
      "My Le",
      "Luana Ruiz",
      "Souvik Dhara"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.17439",
    "title": "Doubly robust outlier resistant inference on causal treatment effect",
    "abstract": "           Outliers can severely distort causal effect estimation in observational studies, especially in small samples. We develop a doubly robust estimator of the ATE under a contaminated-data model that explicitly accommodates outliers. Robustness to outliers is delivered via a bounded-influence estimating equation for the outcome model and covariate balancing propensity scores (CBPS) for treatment assignment. To mitigate overfitting in high dimensions, we incorporate variable selection and unify all components within a penalized empirical likelihood framework. For further inference, we derive an optimal finite-sample confidence interval (CI) whose endpoints are invariant to outliers under the contaminated model. Across extensive simulations and two gene-expression applications (Golub; Khan pediatric tumor), the proposed ATE estimator and finite-sample CI outperform state-of-the-art competitors in bias, mean squared error, empirical coverage, and interval length over a wide range of contamination levels and sample sizes.         ",
    "url": "https://arxiv.org/abs/2507.17439",
    "authors": [
      "Byeonghee Lee",
      "Juhyun Park",
      "Saebom Jeon",
      "Joonsung Kang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2508.16897",
    "title": "Generating Synthetic Contrast-Enhanced Chest CT Images from Non-Contrast Scans Using Slice-Consistent Brownian Bridge Diffusion Network",
    "abstract": "           Contrast-enhanced computed tomography (CT) imaging is essential for diagnosing and monitoring thoracic diseases, including aortic pathologies. However, contrast agents pose risks such as nephrotoxicity and allergic-like reactions. The ability to generate high-fidelity synthetic contrast-enhanced CT angiography (CTA) images without contrast administration would be transformative, enhancing patient safety and accessibility while reducing healthcare costs. In this study, we propose the first bridge diffusion-based solution for synthesizing contrast-enhanced CTA images from non-contrast CT scans. Our approach builds on the Slice-Consistent Brownian Bridge Diffusion Model (SC-BBDM), leveraging its ability to model complex mappings while maintaining consistency across slices. Unlike conventional slice-wise synthesis methods, our framework preserves full 3D anatomical integrity while operating in a high-resolution 2D fashion, allowing seamless volumetric interpretation under a low memory budget. To ensure robust spatial alignment, we implement a comprehensive preprocessing pipeline that includes resampling, registration using the Symmetric Normalization method, and a sophisticated dilated segmentation mask to extract the aorta and surrounding structures. We create two datasets from the Coltea-Lung dataset: one containing only the aorta and another including both the aorta and heart, enabling a detailed analysis of anatomical context. We compare our approach against baseline methods on both datasets, demonstrating its effectiveness in preserving vascular structures while enhancing contrast fidelity.         ",
    "url": "https://arxiv.org/abs/2508.16897",
    "authors": [
      "Pouya Shiri",
      "Xin Yi",
      "Neel P. Mistry",
      "Samaneh Javadinia",
      "Mohammad Chegini",
      "Seok-Bum Ko",
      "Amirali Baniasadi",
      "Scott J. Adams"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2509.00931",
    "title": "Semi-Supervised Bayesian GANs with Log-Signatures for Uncertainty-Aware Credit Card Fraud Detection",
    "abstract": "           We present a novel deep generative semi-supervised framework for credit card fraud detection, formulated as time series classification task. As financial transaction data streams grow in scale and complexity, traditional methods often require large labeled datasets, struggle with time series of irregular sampling frequencies and varying sequence lengths. To address these challenges, we extend conditional Generative Adversarial Networks (GANs) for targeted data augmentation, integrate Bayesian inference to obtain predictive distributions and quantify uncertainty, and leverage log-signatures for robust feature encoding of transaction histories. We introduce a novel Wasserstein distance-based loss to align generated and real unlabeled samples while simultaneously maximizing classification accuracy on labeled data. Our approach is evaluated on the BankSim dataset, a widely used simulator for credit card transaction data, under varying proportions of labeled samples, demonstrating consistent improvements over benchmarks in both global statistical and domain-specific metrics. These findings highlight the effectiveness of GAN-driven semi-supervised learning with log-signatures for irregularly sampled time series and emphasize the importance of uncertainty-aware predictions.         ",
    "url": "https://arxiv.org/abs/2509.00931",
    "authors": [
      "David Hirnschall"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.02586",
    "title": "MitoDetect++: A Domain-Robust Pipeline for Mitosis Detection and Atypical Subtyping",
    "abstract": "           Automated detection and classification of mitotic figures especially distinguishing atypical from normal remain critical challenges in computational pathology. We present MitoDetect++, a unified deep learning pipeline designed for the MIDOG 2025 challenge, addressing both mitosis detection and atypical mitosis classification. For detection (Track 1), we employ a U-Net-based encoder-decoder architecture with EfficientNetV2-L as the backbone, enhanced with attention modules, and trained via combined segmentation losses. For classification (Track 2), we leverage the Virchow2 vision transformer, fine-tuned efficiently using Low-Rank Adaptation (LoRA) to minimize resource consumption. To improve generalization and mitigate domain shifts, we integrate strong augmentations, focal loss, and group-aware stratified 5-fold cross-validation. At inference, we deploy test-time augmentation (TTA) to boost robustness. Our method achieves a balanced accuracy of 0.892 across validation domains, highlighting its clinical applicability and scalability across tasks.         ",
    "url": "https://arxiv.org/abs/2509.02586",
    "authors": [
      "Esha Sadia Nasir",
      "Jiaqi Lv",
      "Mostafa Jahanifar",
      "Shan E Ahmed Raza"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.03547",
    "title": "Combining feature-based approaches with graph neural networks and symbolic regression for synergistic performance and interpretability",
    "abstract": "           This study introduces MatterVial, an innovative hybrid framework for feature-based machine learning in materials science. MatterVial expands the feature space by integrating latent representations from a diverse suite of pretrained graph neural network (GNN) models including: structure-based (MEGNet), composition-based (ROOST), and equivariant (ORB) graph networks, with computationally efficient, GNN-approximated descriptors and novel features from symbolic regression. Our approach combines the chemical transparency of traditional feature-based models with the predictive power of deep learning architectures. When augmenting the feature-based model MODNet on Matbench tasks, this method yields significant error reductions and elevates its performance to be competitive with, and in several cases superior to, state-of-the-art end-to-end GNNs, with accuracy increases exceeding 40% for multiple tasks. An integrated interpretability module, employing surrogate models and symbolic regression, decodes the latent GNN-derived descriptors into explicit, physically meaningful formulas. This unified framework advances materials informatics by providing a high-performance, transparent tool that aligns with the principles of explainable AI, paving the way for more targeted and autonomous materials discovery.         ",
    "url": "https://arxiv.org/abs/2509.03547",
    "authors": [
      "Rog\u00e9rio Almeida Gouv\u00eaa",
      "Pierre-Paul De Breuck",
      "Tatiane Pretto",
      "Gian-Marco Rignanese",
      "Marcos Jos\u00e9 Leite Santos"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  }
]