[
  {
    "id": "arXiv:2509.02575",
    "title": "The Lifecycle Principle: Stabilizing Dynamic Neural Networks with State Memory",
    "abstract": "           I investigate a stronger form of regularization by deactivating neurons for extended periods, a departure from the temporary changes of methods like Dropout. However, this long-term dynamism introduces a critical challenge: severe training instability when neurons are revived with random weights. To solve this, I propose the Lifecycle (LC) principle, a regularization mechanism centered on a key innovation: state memory. Instead of re-initializing a revived neuron, my method restores its parameters to their last known effective state. This process preserves learned knowledge and avoids destructive optimization shocks. My theoretical analysis reveals that the LC principle smooths the loss landscape, guiding optimization towards flatter minima associated with better generalization. Experiments on image classification benchmarks demonstrate that my method improves generalization and robustness. Crucially, ablation studies confirm that state memory is essential for achieving these gains.         ",
    "url": "https://arxiv.org/abs/2509.02575",
    "authors": [
      "Zichuan Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.02581",
    "title": "Charting the Future of Scholarly Knowledge with AI: A Community Perspective",
    "abstract": "           Despite the growing availability of tools designed to support scholarly knowledge extraction and organization, many researchers still rely on manual methods, sometimes due to unfamiliarity with existing technologies or limited access to domain-adapted solutions. Meanwhile, the rapid increase in scholarly publications across disciplines has made it increasingly difficult to stay current, further underscoring the need for scalable, AI-enabled approaches to structuring and synthesizing scholarly knowledge. Various research communities have begun addressing this challenge independently, developing tools and frameworks aimed at building reliable, dynamic, and queryable scholarly knowledge bases. However, limited interaction across these communities has hindered the exchange of methods, models, and best practices, slowing progress toward more integrated solutions. This manuscript identifies ways to foster cross-disciplinary dialogue, identify shared challenges, categorize new collaboration and shape future research directions in scholarly knowledge and organization.         ",
    "url": "https://arxiv.org/abs/2509.02581",
    "authors": [
      "Azanzi Jiomekong",
      "Hande K\u00fc\u00e7\u00fck McGinty",
      "Keith G. Mills",
      "Allard Oelen",
      "Enayat Rajabi",
      "Harry McElroy",
      "Antrea Christou",
      "Anmol Saini",
      "Janice Anta Zebaze",
      "Hannah Kim",
      "Anna M. Jacyszyn",
      "S\u00f6ren Auer"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.02592",
    "title": "Beyond Synthetic Augmentation: Group-Aware Threshold Calibration for Robust Balanced Accuracy in Imbalanced Learning",
    "abstract": "           Class imbalance remains a fundamental challenge in machine learning, with traditional solutions often creating as many problems as they solve. We demonstrate that group-aware threshold calibration--setting different decision thresholds for different demographic groups--provides superior robustness compared to synthetic data generation methods. Through extensive experiments, we show that group-specific thresholds achieve 1.5-4% higher balanced accuracy than SMOTE and CT-GAN augmented models while improving worst-group balanced accuracy. Unlike single-threshold approaches that apply one cutoff across all groups, our group-aware method optimizes the Pareto frontier between balanced accuracy and worst-group balanced accuracy, enabling fine-grained control over group-level performance. Critically, we find that applying group thresholds to synthetically augmented data yields minimal additional benefit, suggesting these approaches are fundamentally redundant. Our results span seven model families including linear, tree-based, instance-based, and boosting methods, confirming that group-aware threshold calibration offers a simpler, more interpretable, and more effective solution to class imbalance.         ",
    "url": "https://arxiv.org/abs/2509.02592",
    "authors": [
      "Hunter Gittlin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.02605",
    "title": "Synthetic Founders: AI-Generated Social Simulations for Startup Validation Research in Computational Social Science",
    "abstract": "           We present a comparative docking experiment that aligns human-subject interview data with large language model (LLM)-driven synthetic personas to evaluate fidelity, divergence, and blind spots in AI-enabled simulation. Fifteen early-stage startup founders were interviewed about their hopes and concerns regarding AI-powered validation, and the same protocol was replicated with AI-generated founder and investor personas. A structured thematic synthesis revealed four categories of outcomes: (1) Convergent themes - commitment-based demand signals, black-box trust barriers, and efficiency gains were consistently emphasized across both datasets; (2) Partial overlaps - founders worried about outliers being averaged away and the stress of real customer validation, while synthetic personas highlighted irrational blind spots and framed AI as a psychological buffer; (3) Human-only themes - relational and advocacy value from early customer engagement and skepticism toward moonshot markets; and (4) Synthetic-only themes - amplified false positives and trauma blind spots, where AI may overstate adoption potential by missing negative historical experiences. We interpret this comparative framework as evidence that LLM-driven personas constitute a form of hybrid social simulation: more linguistically expressive and adaptable than traditional rule-based agents, yet bounded by the absence of lived history and relational consequence. Rather than replacing empirical studies, we argue they function as a complementary simulation category - capable of extending hypothesis space, accelerating exploratory validation, and clarifying the boundaries of cognitive realism in computational social science.         ",
    "url": "https://arxiv.org/abs/2509.02605",
    "authors": [
      "Jorn K. Teutloff"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2509.02609",
    "title": "Contrastive clustering based on regular equivalence for influential node identification in complex networks",
    "abstract": "           Identifying influential nodes in complex networks is a fundamental task in network analysis with wide-ranging applications across domains. While deep learning has advanced node influence detection, existing supervised approaches remain constrained by their reliance on labeled data, limiting their applicability in real-world scenarios where labels are scarce or unavailable. While contrastive learning demonstrates significant potential for performance enhancement, existing approaches predominantly rely on multiple-embedding generation to construct positive/negative sample pairs. To overcome these limitations, we propose ReCC (\\textit{r}egular \\textit{e}quivalence-based \\textit{c}ontrastive \\textit{c}lustering), a novel deep unsupervised framework for influential node identification. We first reformalize influential node identification as a label-free deep clustering problem, then develop a contrastive learning mechanism that leverages regular equivalence-based similarity, which captures structural similarities between nodes beyond local neighborhoods, to generate positive and negative samples. This mechanism is integrated into a graph convolutional network to learn node embeddings that are used to differentiate influential from non-influential nodes. ReCC is pre-trained using network reconstruction loss and fine-tuned with a combined contrastive and clustering loss, with both phases being independent of labeled data. Additionally, ReCC enhances node representations by combining structural metrics with regular equivalence-based similarities. Extensive experiments demonstrate that ReCC outperforms state-of-the-art approaches across several benchmarks.         ",
    "url": "https://arxiv.org/abs/2509.02609",
    "authors": [
      "Yanmei Hu",
      "Yihang Wu",
      "Bing Sun",
      "Xue Yue",
      "Biao Cai",
      "Xiangtao Li",
      "Yang Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.02624",
    "title": "Who Owns The Robot?: Four Ethical and Socio-technical Questions about Wellbeing Robots in the Real World through Community Engagement",
    "abstract": "           Recent studies indicate that robotic coaches can play a crucial role in promoting wellbeing. However, the real-world deployment of wellbeing robots raises numerous ethical and socio-technical questions and concerns. To explore these questions, we undertake a community-centered investigation to examine three different communities' perspectives on using robotic wellbeing coaches in real-world environments. We frame our work as an anticipatory ethical investigation, which we undertake to better inform the development of robotic technologies with communities' opinions, with the ultimate goal of aligning robot development with public interest. We conducted workshops with three communities who are under-represented in robotics development: 1) members of the public at a science festival, 2) women computer scientists at a conference, and 3) humanities researchers interested in history and philosophy of science. In the workshops, we collected qualitative data using the Social Robot Co-Design Canvas on Ethics. We analysed the collected qualitative data with Thematic Analysis, informed by notes taken during workshops. Through our analysis, we identify four themes regarding key ethical and socio-technical questions about the real-world use of wellbeing robots. We group participants' insights and discussions around these broad thematic questions, discuss them in light of state-of-the-art literature, and highlight areas for future investigation. Finally, we provide the four questions as a broad framework that roboticists can and should use during robotic development and deployment, in order to reflect on the ethics and socio-technical dimensions of their robotic applications, and to engage in dialogue with communities of robot users. The four questions are: 1) Is the robot safe and how can we know that?, 2) Who is the robot built for and with?, 3) Who owns the robot and the data?, and 4) Why a robot?.         ",
    "url": "https://arxiv.org/abs/2509.02624",
    "authors": [
      "Minja Axelsson",
      "Jiaee Cheong",
      "Rune Nyrup",
      "Hatice Gunes"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2509.02709",
    "title": "Preference Robustness for DPO with Applications to Public Health",
    "abstract": "           We study an LLM fine-tuning task for designing reward functions for sequential resource allocation problems in public health, guided by human preferences expressed in natural language. This setting presents a challenging testbed for alignment due to complex and ambiguous objectives and limited data availability. We propose DPO-PRO, a robust fine-tuning algorithm based on Direct Preference Optimization (DPO), which accounts for uncertainty in the preference distribution using a lightweight Distributionally Robust Optimization (DRO) formulation. Unlike prior DRO-based DPO methods, DPO-PRO is significantly less conservative. We evaluate DPO-PRO on a real-world maternal mobile health program operated by the non-profit organization ARMMAN, as well as on standard alignment benchmarks. Experimental results demonstrate that our method consistently improves robustness to noisy preference signals compared to existing DPO variants. Moreover, DPO-PRO achieves comparable performance to prior self-reflection-based baseline for reward function design, while requiring significantly lower inference-time cost.         ",
    "url": "https://arxiv.org/abs/2509.02709",
    "authors": [
      "Cheol Woo Kim",
      "Shresth Verma",
      "Mauricio Tec",
      "Milind Tambe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.02762",
    "title": "Synthetic generation of online social networks through homophily",
    "abstract": "           Online social networks (OSNs) have become increasingly relevant for studying social behavior and information diffusion. Nevertheless, they are limited by restricted access to real OSN data due to privacy, legal, and platform-related constraints. In response, synthetic social networks serve as a viable approach to support controlled experimentation, but current generators reproduce only topology and overlook attribute-driven homophily and semantic realism. This work proposes a homophily-based algorithm that produces synthetic microblogging social networks such as X. The model creates a social graph for a given number of users, integrating semantic affinity among user attributes, stochastic variation in link formation, triadic closure to foster clustering, and long-range connections to ensure global reachability. A systematic grid search is used to calibrate five hyperparameters (affinity strength, noise, closure probability, distant link probability, and candidate pool size) for reaching five structural values observed in real social networks (density, clustering coefficient, LCC proportion, normalized shortest path, and modularity). The framework is validated by generating synthetic OSNs at four scales (10^3-10^6 nodes), and benchmarking them against a real-world Bluesky network comprising 4 million users. Comparative results show that the framework reliably reproduces the structural properties of the real network. Overall, the framework outperforms leading importance-sampling techniques applied to the same baseline. The generated graphs capture topological realism and yield attribute-driven communities that align with sociological expectations, providing a realistic, scalable testbed that liberates social researchers from relying on live digital platforms.         ",
    "url": "https://arxiv.org/abs/2509.02762",
    "authors": [
      "Alejandro Buitrago L\u00f3pez",
      "Javier Pastor-Galindo",
      "Jos\u00e9 A. Ruip\u00e9rez-Valiente"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2509.02771",
    "title": "Analysis of Speaker Verification Performance Trade-offs with Neural Audio Codec Transmission",
    "abstract": "           Neural audio codecs (NACs) have made significant advancements in recent years and are rapidly being adopted in many audio processing pipelines. However, they can introduce audio distortions which degrade speaker verification (SV) performance. This study investigates the impact of both traditional and neural audio codecs at varying bitrates on three state of-the-art SV models evaluated on the VoxCeleb1 dataset. Our findings reveal a consistent degradation in SV performance across all models and codecs as bitrates decrease. Notably, NACs do not fundamentally break SV performance when compared to traditional codecs. They outperform Opus by 6-8% at low-bitrates (< 12 kbps) and remain marginally behind at higher bitrates ($\\approx$ 24 kbps), with an EER increase of only 0.4-0.7%. The disparity at higher bitrates is likely due to the primary optimization of NACs for perceptual quality, which can inadvertently discard critical speaker-discriminative features, unlike Opus which was designed to preserve vocal characteristics. Our investigation suggests that NACs are a feasible alternative to traditional codecs, especially under bandwidth limitations. To bridge the gap at higher bitrates, future work should focus on developing speaker-aware NACs or retraining and adapting SV models.         ",
    "url": "https://arxiv.org/abs/2509.02771",
    "authors": [
      "Nirmalya Mallick Thakur",
      "Jia Qi Yip",
      "Eng Siong Chng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2509.02774",
    "title": "Computational Social Science and Critical Studies of Education and Technology: An Improbable Combination?",
    "abstract": "           As belief around the potential of computational social science grows, fuelled by recent advances in machine learning, data scientists are ostensibly becoming the new experts in education. Scholars engaged in critical studies of education and technology have sought to interrogate the growing datafication of education yet tend not to use computational methods as part of this response. In this paper, we discuss the feasibility and desirability of the use of computational approaches as part of a critical research agenda. Presenting and reflecting upon two examples of projects that use computational methods in education to explore questions of equity and justice, we suggest that such approaches might help expand the capacity of critical researchers to highlight existing inequalities, make visible possible approaches for beginning to address such inequalities, and engage marginalised communities in designing and ultimately deploying these possibilities. Drawing upon work within the fields of Critical Data Studies and Science and Technology Studies, we further reflect on the two cases to discuss the possibilities and challenges of reimagining computational methods for critical research in education and technology, focusing on six areas of consideration: criticality, philosophy, inclusivity, context, classification, and responsibility.         ",
    "url": "https://arxiv.org/abs/2509.02774",
    "authors": [
      "Rebecca Eynon",
      "Nabeel Gillani"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2509.02803",
    "title": "Learning Laplacian Eigenvectors: a Pre-training Method for Graph Neural Networks",
    "abstract": "           We propose a novel framework for pre-training Graph Neural Networks (GNNs) by inductively learning Laplacian eigenvectors. Traditional Message Passing Neural Networks (MPNNs) often struggle to capture global and regional graph structure due to over-smoothing risk as network depth increases. Because the low-frequency eigenvectors of the graph Laplacian matrix encode global information, pre-training GNNs to predict these eigenvectors encourages the network to naturally learn large-scale structural patterns over each graph. Empirically, we show that models pre-trained via our framework outperform baseline models on a variety of graph structure-based tasks. While most existing pre-training methods focus on domain-specific tasks like node or edge feature reconstruction, our self-supervised pre-training framework is structure-based and highly flexible. Eigenvector-learning can be applied to all graph-based datasets, and can be used with synthetic features when task-specific data is sparse.         ",
    "url": "https://arxiv.org/abs/2509.02803",
    "authors": [
      "Howard Dai",
      "Nyambura Njenga",
      "Benjamin Whitsett",
      "Catherine Ma",
      "Darwin Deng",
      "Sara de \u00c1ngel",
      "Alexandre Van Tassel",
      "Siddharth Viswanath",
      "Ryan Pellico",
      "Ian Adelstein",
      "Smita Krishnaswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.02806",
    "title": "BISCAY: Practical Radio KPI Driven Congestion Control for Mobile Networks",
    "abstract": "           Mobile application performance relies heavily on the congestion control design of the underlying transport, which is typically bottlenecked by cellular link and has to cope with rapid cellular link bandwidth fluctuations. We observe that radio KPI measurements from the mobile device chipset can be exploited for precise and timely measurement of available bandwidth on the cellular link. Building on this insight, we propose Biscay, a practical and radio KPI-driven congestion control system design for mobile networks. Biscay leverages OpenDiag, the in-kernel real-time radio KPI extraction tool we introduce in this paper, along with our KPI-based accurate bandwidth determination layer towards dynamically adjusting the congestion window to optimally use the available bandwidth while keeping delay to the minimum. Our solution is practical and deployable, as shown through our implementation of Biscay and OpenDiag on unrooted Android 5G phones. We extensively evaluate Biscay against different state-of-the-art congestion control designs including BBR and CUBIC with emulations driven by real measurement traces as well as real-world experiments spanning diverse 4G and 5G scenarios, and show that it provides significant average and tail delay improvements (typically over 90% reduction) while yielding better or similar throughput. These gains are enabled by 100% improvement in the granularity of on-device radio KPI measurements with OpenDiag compared to existing alternatives like MobileInsight.         ",
    "url": "https://arxiv.org/abs/2509.02806",
    "authors": [
      "Jon Larrea",
      "Tanya Shreedhar",
      "Mahesh K. Marina"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2509.02811",
    "title": "Performance Evaluation of LoRa for IoT Applications in Non-Terrestrial Networks via ns-3",
    "abstract": "           The integration of Internet of Things (IoT) and Non-Terrestrial Networks (NTNs) has emerged as a key paradigm to provide connectivity for sensors and actuators via satellite gateways in remote areas where terrestrial infrastructure is limited or unavailable. Among other Low-Power Wide-Area Network (LPWAN) technologies for IoT, Long Range (LoRa) holds great potential given its long range, energy efficiency, and flexibility. In this paper, we explore the feasibility and performance of LoRa to support large-scale IoT connectivity through Low Earth Orbit (LEO) satellite gateways. To do so, we developed a new ns3-LoRa-NTN simulation module, which integrates and extends the ns3-LoRa and ns3-NTN modules, to enable full-stack end-to-end simulation of satellite communication in LoRa networks. Our results, given in terms of average data rate and Packet Reception Ratio (PRR), confirm that LoRa can effectively support direct communication from the ground to LEO satellites, but network optimization is required to mitigate collision probability when end nodes use the same Spreading Factors (SFs) over long distances.         ",
    "url": "https://arxiv.org/abs/2509.02811",
    "authors": [
      "Alessandro Traspadini",
      "Michele Zorzi",
      "Marco Giordani"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2509.02824",
    "title": "GPS Spoofing Attacks on Automated Frequency Coordination System in Wi-Fi 6E and Beyond",
    "abstract": "           The 6 GHz spectrum, recently opened for unlicensed use under Wi-Fi 6E and Wi-Fi 7, overlaps with frequencies used by mission-critical incumbent systems such as public safety communications and utility infrastructure. To prevent interference, the FCC mandates the use of Automated Frequency Coordination (AFC) systems, which assign safe frequency and power levels based on Wi-Fi Access Point (AP)-reported locations. In this work, we demonstrate that GPS-based location reporting, which Wi-Fi APs use, can be spoofed using inexpensive, off-the-shelf radio equipment. This enables attackers to manipulate AP behavior, gain unauthorized spectrum access, cause harmful interference, or disable APs entirely by spoofing them into foreign locations. We validate these attacks in a controlled lab setting against a commercial AP and evaluate a commercial AFC system under spoofed scenarios. Our findings highlight critical gaps in the security assumptions of AFC and motivate the need for stronger location integrity protections.         ",
    "url": "https://arxiv.org/abs/2509.02824",
    "authors": [
      "Yilu Dong",
      "Tianchang Yang",
      "Arupjyoti Bhuyan",
      "Syed Rafiul Hussain"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2509.02826",
    "title": "Ensemble Learning for Healthcare: A Comparative Analysis of Hybrid Voting and Ensemble Stacking in Obesity Risk Prediction",
    "abstract": "           Obesity is a critical global health issue driven by dietary, physiological, and environmental factors, and is strongly associated with chronic diseases such as diabetes, cardiovascular disorders, and cancer. Machine learning has emerged as a promising approach for early obesity risk prediction, yet a comparative evaluation of ensemble techniques -- particularly hybrid majority voting and ensemble stacking -- remains limited. This study aims to compare hybrid majority voting and ensemble stacking methods for obesity risk prediction, identifying which approach delivers higher accuracy and efficiency. The analysis seeks to highlight the complementary strengths of these ensemble techniques in guiding better predictive model selection for healthcare applications. Two datasets were utilized to evaluate three ensemble models: Majority Hard Voting, Weighted Hard Voting, and Stacking (with a Multi-Layer Perceptron as meta-classifier). A pool of nine Machine Learning (ML) algorithms, evaluated across a total of 50 hyperparameter configurations, was analyzed to identify the top three models to serve as base learners for the ensemble methods. Preprocessing steps involved dataset balancing, and outlier detection, and model performance was evaluated using Accuracy and F1-Score. On Dataset-1, weighted hard voting and stacking achieved nearly identical performance (Accuracy: 0.920304, F1: 0.920070), outperforming majority hard voting. On Dataset-2, stacking demonstrated superior results (Accuracy: 0.989837, F1: 0.989825) compared to majority hard voting (Accuracy: 0.981707, F1: 0.981675) and weighted hard voting, which showed the lowest performance. The findings confirm that ensemble stacking provides stronger predictive capability, particularly for complex data distributions, while hybrid majority voting remains a robust alternative.         ",
    "url": "https://arxiv.org/abs/2509.02826",
    "authors": [
      "Towhidul Islam",
      "Md Sumon Ali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2509.02844",
    "title": "Conformal Prediction for Time-series Forecasting with Change Points",
    "abstract": "           Conformal prediction has been explored as a general and efficient way to provide uncertainty quantification for time series. However, current methods struggle to handle time series data with change points - sudden shifts in the underlying data-generating process. In this paper, we propose a novel Conformal Prediction for Time-series with Change points (CPTC) algorithm, addressing this gap by integrating a model to predict the underlying state with online conformal prediction to model uncertainties in non-stationary time series. We prove CPTC's validity and improved adaptivity in the time series setting under minimum assumptions, and demonstrate CPTC's practical effectiveness on 6 synthetic and real-world datasets, showing improved validity and adaptivity compared to state-of-the-art baselines.         ",
    "url": "https://arxiv.org/abs/2509.02844",
    "authors": [
      "Sophia Sun",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.02856",
    "title": "Managing Correlations in Data and Privacy Demand",
    "abstract": "           Previous works in the differential privacy literature that allow users to choose their privacy levels typically operate under the heterogeneous differential privacy (HDP) framework with the simplifying assumption that user data and privacy levels are not correlated. Firstly, we demonstrate that the standard HDP framework falls short when user data and privacy demands are allowed to be correlated. Secondly, to address this shortcoming, we propose an alternate framework, Add-remove Heterogeneous Differential Privacy (AHDP), that jointly accounts for user data and privacy preference. We show that AHDP is robust to possible correlations between data and privacy. Thirdly, we formalize the guarantees of the proposed AHDP framework through an operational hypothesis testing perspective. The hypothesis testing setup may be of independent interest in analyzing other privacy frameworks as well. Fourthly, we show that there exists non-trivial AHDP mechanisms that notably do not require prior knowledge of the data-privacy correlations. We propose some such mechanisms and apply them to core statistical tasks such as mean estimation, frequency estimation, and linear regression. The proposed mechanisms are simple to implement with minimal assumptions and modeling requirements, making them attractive for real-world use. Finally, we empirically evaluate proposed AHDP mechanisms, highlighting their trade-offs using LLM-generated synthetic datasets, which we release for future research.         ",
    "url": "https://arxiv.org/abs/2509.02856",
    "authors": [
      "Syomantak Chaudhuri",
      "Thomas A. Courtade"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.02859",
    "title": "Speech DF Arena: A Leaderboard for Speech DeepFake Detection Models",
    "abstract": "           Parallel to the development of advanced deepfake audio generation, audio deepfake detection has also seen significant progress. However, a standardized and comprehensive benchmark is still missing. To address this, we introduce Speech DeepFake (DF) Arena, the first comprehensive benchmark for audio deepfake detection. Speech DF Arena provides a toolkit to uniformly evaluate detection systems, currently across 14 diverse datasets and attack scenarios, standardized evaluation metrics and protocols for reproducibility and transparency. It also includes a leaderboard to compare and rank the systems to help researchers and developers enhance their reliability and robustness. We include 14 evaluation sets, 12 state-of-the-art open-source and 3 proprietary detection systems. Our study presents many systems exhibiting high EER in out-of-domain scenarios, highlighting the need for extensive cross-domain evaluation. The leaderboard is hosted on Huggingface1 and a toolkit for reproducing results across the listed datasets is available on GitHub.         ",
    "url": "https://arxiv.org/abs/2509.02859",
    "authors": [
      "Sandipana Dowerah",
      "Atharva Kulkarni",
      "Ajinkya Kulkarni",
      "Hoan My Tran",
      "Joonas Kalda",
      "Artem Fedorchenko",
      "Benoit Fauve",
      "Damien Lolive",
      "Tanel Alum\u00e4e",
      "Matthew Magimai Doss"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2509.02864",
    "title": "A-SEA3L-QA: A Fully Automated Self-Evolving, Adversarial Workflow for Arabic Long-Context Question-Answer Generation",
    "abstract": "           We present an end-to-end, self-evolving adversarial workflow for long-context Question-Answer (QA) Generation in Arabic. By orchestrating multiple specialized LVLMs: a question generator, an evaluator, and a swarm of answer generators, our system iteratively refines its own performance without any human intervention. Starting from raw, multi-page Arabic documents across diverse domains, the question generator produces fine-grained, context-aware queries to be tackled by the answer generator swarm, and the evaluator assesses and feeds back quality metrics. This closed-loop cycle enables continuous learning: low-confidence outputs trigger automated re-generation and model updates, progressively enhancing question difficulty and relevance. Moreover, we set the quality metrics as a tunable hyperparameter, enabling question generation at controllable and customizable difficulty levels. We release AraLongBench, a large-scale Arabic benchmark of single- and multi-page challenges spanning hundreds of pages, and demonstrate that our self-evolving workflow substantially outperform static pipelines, markedly boosting the long-context comprehension capabilities of leading Arabic Large Vision Language Models (LVLMs). Lastly, we also meticulously architect a fully automated agentic workflow for long-context Arabic document collection.         ",
    "url": "https://arxiv.org/abs/2509.02864",
    "authors": [
      "Kesen Wang",
      "Daulet Toibazar",
      "Pedro J. Moreno"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.02869",
    "title": "A Distributed Gradient-Based Deployment Strategy for a Network of Sensors with a Probabilistic Sensing Model",
    "abstract": "           This paper presents a distributed gradient-based deployment strategy to maximize coverage in hybrid wireless sensor networks (WSNs) with probabilistic sensing. Leveraging Voronoi partitioning, the overall coverage is reformulated as a sum of local contributions, enabling mobile sensors to optimize their positions using only local information. The strategy adopts the Elfes model to capture detection uncertainty and introduces a dynamic step size based on the gradient of the local coverage, ensuring movements adaptive to regional importance. Obstacle awareness is integrated via visibility constraints, projecting sensor positions to unobstructed paths. A threshold-based decision rule ensures movement occurs only for sufficiently large coverage gains, with convergence achieved when all sensors and their neighbors stop at a local maximum configuration. Simulations demonstrate improved coverage over static deployments, highlighting scalability and practicality for real-world applications.         ",
    "url": "https://arxiv.org/abs/2509.02869",
    "authors": [
      "Hesam Mosalli",
      "Amir G. Aghdam"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2509.02892",
    "title": "Improving Generative Methods for Causal Evaluation via Simulation-Based Inference",
    "abstract": "           Generating synthetic datasets that accurately reflect real-world observational data is critical for evaluating causal estimators, but remains a challenging task. Existing generative methods offer a solution by producing synthetic datasets anchored in the observed data (source data) while allowing variation in key parameters such as the treatment effect and amount of confounding bias. However, existing methods typically require users to provide point estimates of such parameters (rather than distributions) and fixed estimates (rather than estimates that can be improved with reference to the source data). This denies users the ability to express uncertainty over parameter values and removes the potential for posterior inference, potentially leading to unreliable estimator comparisons. We introduce simulation-based inference for causal evaluation (SBICE), a framework that models generative parameters as uncertain and infers their posterior distribution given a source dataset. Leveraging techniques in simulation-based inference, SBICE identifies parameter configurations that produce synthetic datasets closely aligned with the source data distribution. Empirical results demonstrate that SBICE improves the reliability of estimator evaluations by generating more realistic datasets, which supports a robust and data-consistent approach to causal benchmarking under uncertainty.         ",
    "url": "https://arxiv.org/abs/2509.02892",
    "authors": [
      "Pracheta Amaranath",
      "Vinitra Muralikrishnan",
      "Amit Sharma",
      "David D. Jensen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2509.02908",
    "title": "Advancing Minority Stress Detection with Transformers: Insights from the Social Media Datasets",
    "abstract": "           Individuals from sexual and gender minority groups experience disproportionately high rates of poor health outcomes and mental disorders compared to their heterosexual and cisgender counterparts, largely as a consequence of minority stress as described by Meyer's (2003) model. This study presents the first comprehensive evaluation of transformer-based architectures for detecting minority stress in online discourse. We benchmark multiple transformer models including ELECTRA, BERT, RoBERTa, and BART against traditional machine learning baselines and graph-augmented variants. We further assess zero-shot and few-shot learning paradigms to assess their applicability on underrepresented datasets. Experiments are conducted on the two largest publicly available Reddit corpora for minority stress detection, comprising 12,645 and 5,789 posts, and are repeated over five random seeds to ensure robustness. Our results demonstrate that integrating graph structure consistently improves detection performance across transformer-only models and that supervised fine-tuning with relational context outperforms zero and few-shot approaches. Theoretical analysis reveals that modeling social connectivity and conversational context via graph augmentation sharpens the models' ability to identify key linguistic markers such as identity concealment, internalized stigma, and calls for support, suggesting that graph-enhanced transformers offer the most reliable foundation for digital health interventions and public health policy.         ",
    "url": "https://arxiv.org/abs/2509.02908",
    "authors": [
      "Santosh Chapagain",
      "Cory J Cascalheira",
      "Shah Muhammad Hamdi",
      "Soukaina Filali Boubrahimi",
      "Jillian R. Scheer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2509.02915",
    "title": "English Pronunciation Evaluation without Complex Joint Training: LoRA Fine-tuned Speech Multimodal LLM",
    "abstract": "           This study demonstrates that a Multimodal Large Language Model (MLLM) adapted via Low-Rank Adaptation (LoRA) can perform both Automatic Pronunciation Assessment (APA) and Mispronunciation Detection and Diagnosis (MDD) simultaneously. Leveraging Microsoft's Phi-4-multimodal-instruct, our fine-tuning method eliminates the need for complex architectural changes or separate training procedures conventionally required for these distinct tasks. Fine-tuned on the Speechocean762 dataset, the pronunciation evaluation scores predicted by the model exhibited a strong Pearson Correlation Coefficient (PCC > 0.7) with human-assigned scores, while achieving low Word Error Rate (WER) and Phoneme Error Rate (PER) (both < 0.15). Notably, fine-tuning only the LoRA layers was sufficient to achieve performance levels comparable to those achieved by fine-tuning all audio layers. This research highlights that an integrated pronunciation assessment system can be established by adapting large multimodal models without full fine-tuning, utilizing a significantly simpler training methodology compared to previous joint models designed for simultaneous APA and MDD. This efficient LoRA-based approach paves the way for more accessible, integrated, and effective Computer-Assisted Pronunciation Training (CAPT) technologies for English L2 learners.         ",
    "url": "https://arxiv.org/abs/2509.02915",
    "authors": [
      "Taekyung Ahn",
      "Hosung Nam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2509.02920",
    "title": "Event Detection and Classification for Long Range Sensing of Elephants Using Seismic Signal",
    "abstract": "           Detecting elephants through seismic signals is an emerging research topic aimed at developing solutions for Human-Elephant Conflict (HEC). Despite the promising results, such solutions heavily rely on manual classification of elephant footfalls, which limits their applicability for real-time classification in natural settings. To address this limitation and build on our previous work, this study introduces a classification framework targeting resource-constrained implementations, prioritizing both accuracy and computational efficiency. As part of this framework, a novel event detection technique named Contextually Customized Windowing (CCW), tailored specifically for detecting elephant footfalls, was introduced, and evaluations were conducted by comparing it with the Short-Term Average/Long-Term Average (STA/LTA) method. The yielded results show that the maximum validated detection range was 155.6 m in controlled conditions and 140 m in natural environments. Elephant footfall classification using Support Vector Machine (SVM) with a Radial Basis Function (RBF) kernel demonstrated superior performance across multiple settings, achieving an accuracy of 99% in controlled environments, 73% in natural elephant habitats, and 70% in HEC-prone human habitats, the most challenging scenario. Furthermore, feature impact analysis using explainable AI identified the number of Zero Crossings and Dynamic Time Warping (DTW) Alignment Cost as the most influential factors in all experiments, while Predominant Frequency exhibited significant influence in controlled settings.         ",
    "url": "https://arxiv.org/abs/2509.02920",
    "authors": [
      "Jaliya L. Wijayaraja",
      "Janaka L. Wijekoon",
      "Malitha Wijesundara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Emerging Technologies (cs.ET)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2509.02928",
    "title": "A Data-Driven RetinaNet Model for Small Object Detection in Aerial Images",
    "abstract": "           In the realm of aerial imaging, the ability to detect small objects is pivotal for a myriad of applications, encompassing environmental surveillance, urban design, and crisis management. Leveraging RetinaNet, this work unveils DDR-Net: a data-driven, deep-learning model devised to enhance the detection of diminutive objects. DDR-Net introduces novel, data-driven techniques to autonomously ascertain optimal feature maps and anchor estimations, cultivating a tailored and proficient training process while maintaining precision. Additionally, this paper presents an innovative sampling technique to bolster model efficacy under limited data training constraints. The model's enhanced detection capabilities support critical applications including wildlife and habitat monitoring, traffic flow optimization, and public safety improvements through accurate identification of small objects like vehicles and pedestrians. DDR-Net significantly reduces the cost and time required for data collection and training, offering efficient performance even with limited data. Empirical assessments over assorted aerial avian imagery datasets demonstrate that DDR-Net markedly surpasses RetinaNet and alternative contemporary models. These innovations advance current aerial image analysis technologies and promise wide-ranging impacts across multiple sectors including agriculture, security, and archaeology.         ",
    "url": "https://arxiv.org/abs/2509.02928",
    "authors": [
      "Zhicheng Tang",
      "Jinwen Tang",
      "Yi Shang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.02930",
    "title": "VendiRL: A Framework for Self-Supervised Reinforcement Learning of Diversely Diverse Skills",
    "abstract": "           In self-supervised reinforcement learning (RL), one of the key challenges is learning a diverse set of skills to prepare agents for unknown future tasks. Despite impressive advances, scalability and evaluation remain prevalent issues. Regarding scalability, the search for meaningful skills can be obscured by high-dimensional feature spaces, where relevant features may vary across downstream task domains. For evaluating skill diversity, defining what constitutes \"diversity\" typically requires a hard commitment to a specific notion of what it means for skills to be diverse, potentially leading to inconsistencies in how skill diversity is understood, making results across different approaches hard to compare, and leaving many forms of diversity unexplored. To address these issues, we adopt a measure of sample diversity that translates ideas from ecology to machine learning -- the Vendi Score -- allowing the user to specify and evaluate any desired form of diversity. We demonstrate how this metric facilitates skill evaluation and introduce VendiRL, a unified framework for learning diversely diverse sets of skills. Given distinct similarity functions, VendiRL motivates distinct forms of diversity, which could support skill-diversity pretraining in new and richly interactive environments where optimising for various forms of diversity may be desirable.         ",
    "url": "https://arxiv.org/abs/2509.02930",
    "authors": [
      "Erik M. Lintunen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2509.02933",
    "title": "Demonstrating Visual Information Manipulation Attacks in Augmented Reality: A Hands-On Miniature City-Based Setup",
    "abstract": "           Augmented reality (AR) enhances user interaction with the real world but also presents vulnerabilities, particularly through Visual Information Manipulation (VIM) attacks. These attacks alter important real-world visual cues, leading to user confusion and misdirected actions. In this demo, we present a hands-on experience using a miniature city setup, where users interact with manipulated AR content via the Meta Quest 3. The demo highlights the impact of VIM attacks on user decision-making and underscores the need for effective security measures in AR systems. Future work includes a user study and cross-platform testing.         ",
    "url": "https://arxiv.org/abs/2509.02933",
    "authors": [
      "Yanming Xiu",
      "Maria Gorlatova"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2509.02942",
    "title": "RankGraph: Unified Heterogeneous Graph Learning for Cross-Domain Recommendation",
    "abstract": "           Cross-domain recommendation systems face the challenge of integrating fine-grained user and item relationships across various product domains. To address this, we introduce RankGraph, a scalable graph learning framework designed to serve as a core component in recommendation foundation models (FMs). By constructing and leveraging graphs composed of heterogeneous nodes and edges across multiple products, RankGraph enables the integration of complex relationships between users, posts, ads, and other entities. Our framework employs a GPU-accelerated Graph Neural Network and contrastive learning, allowing for dynamic extraction of subgraphs such as item-item and user-user graphs to support similarity-based retrieval and real-time clustering. Furthermore, RankGraph integrates graph-based pretrained representations as contextual tokens into FM sequence models, enriching them with structured relational knowledge. RankGraph has demonstrated improvements in click (+0.92%) and conversion rates (+2.82%) in online A/B tests, showcasing its effectiveness in cross-domain recommendation scenarios.         ",
    "url": "https://arxiv.org/abs/2509.02942",
    "authors": [
      "Renzhi Wu",
      "Junjie Yang",
      "Li Chen",
      "Hong Li",
      "Li Yu",
      "Hong Yan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.02951",
    "title": "Complex Scaling for the Junction of Semi-infinite Gratings",
    "abstract": "           We present and analyze an integral equation method for the scattering of a non-periodic source from a geometry consisting of two semi-infinite, periodic structures glued together in two dimensions. The two structures may involve a periodic wall, several layers of transmission surfaces with a shared period, or periodic sets of obstacles. This integral equation is posed on the infinite interface between the two periodic structures using kernels built out of the Green's function for each structure. To combat the slow decay of the Green's function, we also show that our integral equation can be analytically continued into the complex plane, where it can be truncated with exponential accuracy. A careful analysis of the domain Green's functions far from the periodic structure is then used to prove that the analytically continued equation is Fredholm index zero. Finally, we show that the solution we generate satisfies a radiation condition and demonstrate an efficient and high order solver for this problem.         ",
    "url": "https://arxiv.org/abs/2509.02951",
    "authors": [
      "Fruzsina J. Agocs",
      "Tristan Goodwill",
      "Jeremy Hoskins"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2509.02952",
    "title": "STAR: A Fast and Robust Rigid Registration Framework for Serial Histopathological Images",
    "abstract": "           Registration of serial whole-slide histopathological images (WSIs) is critical for enabling direct comparison across diverse stains and for preparing paired datasets in artificial intelligence (AI) workflows such as virtual staining and biomarker prediction. While existing methods often rely on complex deformable or deep learning approaches that are computationally intensive and difficult to reproduce, lightweight rigid frameworks-sufficient for many consecutive-section scenarios-remain underdeveloped. We introduce STAR (Serial Tissue Alignment for Rigid registration), a fast and robust open-source framework for multi-WSI alignment. STAR integrates stain-conditioned preprocessing with a hierarchical coarse-to-fine correlation strategy, adaptive kernel scaling, and built-in quality control, achieving reliable rigid registration across heterogeneous tissue types and staining protocols, including hematoxylin-eosin (H&E), special histochemical stains (e.g., PAS, PASM, Masson's), and immunohistochemical (IHC) markers (e.g., CD31, KI67). Evaluated on the ANHIR 2019 and ACROBAT 2022 datasets spanning multiple organs and scanning conditions, STAR consistently produced stable alignments within minutes per slide, demonstrating robustness to cross-stain variability and partial tissue overlap. Beyond benchmarks, we present case studies on H&E-IHC alignment, construction of multi-IHC panels, and typical failure modes, underscoring both utility and limitations. Released as an open and lightweight tool, STAR provides a reproducible baseline that lowers the barrier for clinical adoption and enables large-scale paired data preparation for next-generation computational pathology.         ",
    "url": "https://arxiv.org/abs/2509.02952",
    "authors": [
      "Zeyu Liu",
      "Shengwei Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.02962",
    "title": "Resilient Multimodal Industrial Surface Defect Detection with Uncertain Sensors Availability",
    "abstract": "           Multimodal industrial surface defect detection (MISDD) aims to identify and locate defect in industrial products by fusing RGB and 3D modalities. This article focuses on modality-missing problems caused by uncertain sensors availability in MISDD. In this context, the fusion of multiple modalities encounters several troubles, including learning mode transformation and information vacancy. To this end, we first propose cross-modal prompt learning, which includes: i) the cross-modal consistency prompt serves the establishment of information consistency of dual visual modalities; ii) the modality-specific prompt is inserted to adapt different input patterns; iii) the missing-aware prompt is attached to compensate for the information vacancy caused by dynamic modalities-missing. In addition, we propose symmetric contrastive learning, which utilizes text modality as a bridge for fusion of dual vision modalities. Specifically, a paired antithetical text prompt is designed to generate binary text semantics, and triple-modal contrastive pre-training is offered to accomplish multimodal learning. Experiment results show that our proposed method achieves 73.83% I-AUROC and 93.05% P-AUROC with a total missing rate 0.7 for RGB and 3D modalities (exceeding state-of-the-art methods 3.84% and 5.58% respectively), and outperforms existing approaches to varying degrees under different missing types and rates. The source code will be available at this https URL.         ",
    "url": "https://arxiv.org/abs/2509.02962",
    "authors": [
      "Shuai Jiang",
      "Yunfeng Ma",
      "Jingyu Zhou",
      "Yuan Bian",
      "Yaonan Wang",
      "Min Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.02966",
    "title": "KEPT: Knowledge-Enhanced Prediction of Trajectories from Consecutive Driving Frames with Vision-Language Models",
    "abstract": "           Accurate short-horizon trajectory prediction is pivotal for safe and reliable autonomous driving, yet existing vision-language models (VLMs) often fail to effectively ground their reasoning in scene dynamics and domain knowledge. To address this challenge, this paper introduces KEPT, a knowledge-enhanced VLM framework that predicts ego trajectories directly from consecutive front-view driving frames. KEPT couples a temporal frequency-spatial fusion (TFSF) video encoder, trained via self-supervised learning with hard-negative mining, with a scalable k-means + HNSW retrieval stack that supplies scene-aligned exemplars. Retrieved priors are embedded into chain-of-thought (CoT) prompts with explicit planning constraints, while a triple-stage fine-tuning schedule incrementally aligns the language head to metric spatial cues, physically feasible motion, and temporally conditioned front-view planning. Evaluated on nuScenes dataset, KEPT achieves state-of-the-art performance across open-loop protocols: under NoAvg, it achieves 0.70m average L2 with a 0.21\\% collision rate; under TemAvg with lightweight ego status, it attains 0.31m average L2 and a 0.07\\% collision rate. Ablation studies show that all three fine-tuning stages contribute complementary benefits, and that using Top-2 retrieved exemplars yields the best accuracy-safety trade-off. The k-means-clustered HNSW index delivers sub-millisecond retrieval latency, supporting practical deployment. These results indicate that retrieval-augmented, CoT-guided VLMs offer a promising, data-efficient pathway toward interpretable and trustworthy autonomous driving.         ",
    "url": "https://arxiv.org/abs/2509.02966",
    "authors": [
      "Yujin Wang",
      "Tianyi Wang",
      "Quanfeng Liu",
      "Wenxian Fan",
      "Junfeng Jiao",
      "Christian Claudel",
      "Yunbing Yan",
      "Bingzhao Gao",
      "Jianqiang Wang",
      "Hong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.02967",
    "title": "AR-KAN: Autoregressive-Weight-Enhanced Kolmogorov-Arnold Network for Time Series Forecasting",
    "abstract": "           Conventional neural networks frequently face challenges in spectral analysis of signals. To address this challenge, Fourier neural networks (FNNs) and similar approaches integrate components of Fourier series into the structure of neural networks. Nonetheless, a significant hurdle is often overlooked: the superposition of periodic signals does not necessarily result in a periodic signal. For example, when forecasting almost periodic functions composed of signals with incommensurate frequencies, traditional models such as Autoregressive Integrated Moving Average (ARIMA) frequently outperform most neural networks including large language models (LLMs). To tackle this goal, we propose Autoregressive-Weight-Enhanced AR-KAN, a hybrid model that combines the benefits of both methods. Using the Universal Myopic Mapping Theorem, we apply a Kolmogorov-Arnold Network (KAN) for the static nonlinear part and include memory through a pre-trained AR component, which can be explained to retain the most useful information while eliminating redundancy. Experimental data indicates that AR-KAN delivers superior results on $72\\%$ of real-world datasets.         ",
    "url": "https://arxiv.org/abs/2509.02967",
    "authors": [
      "Chen Zeng",
      "Tiehang Xu",
      "Qiao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2509.02969",
    "title": "VQualA 2025 Challenge on Engagement Prediction for Short Videos: Methods and Results",
    "abstract": "           This paper presents an overview of the VQualA 2025 Challenge on Engagement Prediction for Short Videos, held in conjunction with ICCV 2025. The challenge focuses on understanding and modeling the popularity of user-generated content (UGC) short videos on social media platforms. To support this goal, the challenge uses a new short-form UGC dataset featuring engagement metrics derived from real-world user interactions. This objective of the Challenge is to promote robust modeling strategies that capture the complex factors influencing user engagement. Participants explored a variety of multi-modal features, including visual content, audio, and metadata provided by creators. The challenge attracted 97 participants and received 15 valid test submissions, contributing significantly to progress in short-form UGC video engagement prediction.         ",
    "url": "https://arxiv.org/abs/2509.02969",
    "authors": [
      "Dasong Li",
      "Sizhuo Ma",
      "Hang Hua",
      "Wenjie Li",
      "Jian Wang",
      "Chris Wei Zhou",
      "Fengbin Guan",
      "Xin Li",
      "Zihao Yu",
      "Yiting Lu",
      "Ru-Ling Liao",
      "Yan Ye",
      "Zhibo Chen",
      "Wei Sun",
      "Linhan Cao",
      "Yuqin Cao",
      "Weixia Zhang",
      "Wen Wen",
      "Kaiwei Zhang",
      "Zijian Chen",
      "Fangfang Lu",
      "Xiongkuo Min",
      "Guangtao Zhai",
      "Erjia Xiao",
      "Lingfeng Zhang",
      "Zhenjie Su",
      "Hao Cheng",
      "Yu Liu",
      "Renjing Xu",
      "Long Chen",
      "Xiaoshuai Hao",
      "Zhenpeng Zeng",
      "Jianqin Wu",
      "Xuxu Wang",
      "Qian Yu",
      "Bo Hu",
      "Weiwei Wang",
      "Pinxin Liu",
      "Yunlong Tang",
      "Luchuan Song",
      "Jinxi He",
      "Jiaru Wu",
      "Hanjia Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2509.02993",
    "title": "SPENet: Self-guided Prototype Enhancement Network for Few-shot Medical Image Segmentation",
    "abstract": "           Few-Shot Medical Image Segmentation (FSMIS) aims to segment novel classes of medical objects using only a few labeled images. Prototype-based methods have made significant progress in addressing FSMIS. However, they typically generate a single global prototype for the support image to match with the query image, overlooking intra-class variations. To address this issue, we propose a Self-guided Prototype Enhancement Network (SPENet). Specifically, we introduce a Multi-level Prototype Generation (MPG) module, which enables multi-granularity measurement between the support and query images by simultaneously generating a global prototype and an adaptive number of local prototypes. Additionally, we observe that not all local prototypes in the support image are beneficial for matching, especially when there are substantial discrepancies between the support and query images. To alleviate this issue, we propose a Query-guided Local Prototype Enhancement (QLPE) module, which adaptively refines support prototypes by incorporating guidance from the query image, thus mitigating the negative effects of such discrepancies. Extensive experiments on three public medical datasets demonstrate that SPENet outperforms existing state-of-the-art methods, achieving superior performance.         ",
    "url": "https://arxiv.org/abs/2509.02993",
    "authors": [
      "Chao Fan",
      "Xibin Jia",
      "Anqi Xiao",
      "Hongyuan Yu",
      "Zhenghan Yang",
      "Dawei Yang",
      "Hui Xu",
      "Yan Huang",
      "Liang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.03006",
    "title": "Enhancing Robustness in Post-Processing Watermarking: An Ensemble Attack Network Using CNNs and Transformers",
    "abstract": "           Recent studies on deep watermarking have predominantly focused on in-processing watermarking, which integrates the watermarking process into image generation. However, post-processing watermarking, which embeds watermarks after image generation, offers more flexibility. It can be applied to outputs from any generative model (e.g. GANs, diffusion models) without needing access to the model's internal structure. It also allows users to embed unique watermarks into individual images. Therefore, this study focuses on post-processing watermarking and enhances its robustness by incorporating an ensemble attack network during training. We construct various versions of attack networks using CNN and Transformer in both spatial and frequency domains to investigate how each combination influences the robustness of the watermarking model. Our results demonstrate that combining a CNN-based attack network in the spatial domain with a Transformer-based attack network in the frequency domain yields the highest robustness in watermarking models. Extensive evaluation on the WAVES benchmark, using average bit accuracy as the metric, demonstrates that our ensemble attack network significantly enhances the robustness of baseline watermarking methods under various stress tests. In particular, for the Regeneration Attack defined in WAVES, our method improves StegaStamp by 18.743%. The code is released at:this https URL.         ",
    "url": "https://arxiv.org/abs/2509.03006",
    "authors": [
      "Tzuhsuan Huang",
      "Cheng Yu Yeo",
      "Tsai-Ling Huang",
      "Hong-Han Shuai",
      "Wen-Huang Cheng",
      "Jun-Cheng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.03032",
    "title": "Background Matters Too: A Language-Enhanced Adversarial Framework for Person Re-Identification",
    "abstract": "           Person re-identification faces two core challenges: precisely locating the foreground target while suppressing background noise and extracting fine-grained features from the target region. Numerous visual-only approaches address these issues by partitioning an image and applying attention modules, yet they rely on costly manual annotations and struggle with complex occlusions. Recent multimodal methods, motivated by CLIP, introduce semantic cues to guide visual understanding. However, they focus solely on foreground information, but overlook the potential value of background cues. Inspired by human perception, we argue that background semantics are as important as the foreground semantics in ReID, as humans tend to eliminate background distractions while focusing on target appearance. Therefore, this paper proposes an end-to-end framework that jointly models foreground and background information within a dual-branch cross-modal feature extraction pipeline. To help the network distinguish between the two domains, we propose an intra-semantic alignment and inter-semantic adversarial learning strategy. Specifically, we align visual and textual features that share the same semantics across domains, while simultaneously penalizing similarity between foreground and background features to enhance the network's discriminative power. This strategy drives the model to actively suppress noisy background regions and enhance attention toward identity-relevant foreground cues. Comprehensive experiments on two holistic and two occluded ReID benchmarks demonstrate the effectiveness and generality of the proposed method, with results that match or surpass those of current state-of-the-art approaches.         ",
    "url": "https://arxiv.org/abs/2509.03032",
    "authors": [
      "Kaicong Huang",
      "Talha Azfar",
      "Jack M. Reilly",
      "Thomas Guggisberg",
      "Ruimin Ke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.03052",
    "title": "Fast approximation algorithms for the 1-median problem on real-world large graphs",
    "abstract": "           The 1-median problem (1MP) on undirected weighted graphs seeks to find a facility location minimizing the total weighted distance to all customer nodes. Although the 1MP can be solved exactly by computing the single-source shortest paths from each customer node, such approaches become computationally expensive on large-scale graphs with millions of nodes. In many real-world applications, such as recommendation systems based on large-scale knowledge graphs, the number of nodes (i.e., potential facility locations) is enormous, whereas the number of customer nodes is relatively small and spatially concentrated. In such cases, exhaustive graph exploration is not only inefficient but also unnecessary. Leveraging this observation, we propose three approximation algorithms that reduce computation by terminating Dijkstra's algorithm early. We provide theoretical analysis showing that one of the proposed algorithms guarantees an approximation ratio of 2, whereas the other two improve this ratio to 1.618. We demonstrate that the lower bound of the approximation ratio is 1.2 by presenting a specific instance. Moreover, we show that all proposed algorithms return optimal solutions when the number of customer nodes is less than or equal to three. Extensive experiments demonstrate that our algorithms significantly outperform baseline exact methods in runtime while maintaining near-optimal accuracy across all tested graph types. Notably, on grid graphs with 10 million nodes, our algorithms obtains all optimal solutions within 1 millisecond, whereas the baseline exact method requires over 70 seconds on average.         ",
    "url": "https://arxiv.org/abs/2509.03052",
    "authors": [
      "Keisuke Ueta",
      "Wei Wu",
      "Mutsunori Yagiura"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2509.03056",
    "title": "Discrete Functional Geometry of ReLU Networks via ReLU Transition Graphs",
    "abstract": "           We extend the ReLU Transition Graph (RTG) framework into a comprehensive graph-theoretic model for understanding deep ReLU networks. In this model, each node represents a linear activation region, and edges connect regions that differ by a single ReLU activation flip, forming a discrete geometric structure over the network's functional behavior. We prove that RTGs at random initialization exhibit strong expansion, binomial degree distributions, and spectral properties that tightly govern generalization. These structural insights enable new bounds on capacity via region entropy and on generalization via spectral gap and edge-wise KL divergence. Empirically, we construct RTGs for small networks, measure their smoothness and connectivity properties, and validate theoretical predictions. Our results show that region entropy saturates under overparameterization, spectral gap correlates with generalization, and KL divergence across adjacent regions reflects functional smoothness. This work provides a unified framework for analyzing ReLU networks through the lens of discrete functional geometry, offering new tools to understand, diagnose, and improve generalization.         ",
    "url": "https://arxiv.org/abs/2509.03056",
    "authors": [
      "Sahil Rajesh Dhayalkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.03058",
    "title": "EverTracer: Hunting Stolen Large Language Models via Stealthy and Robust Probabilistic Fingerprint",
    "abstract": "           The proliferation of large language models (LLMs) has intensified concerns over model theft and license violations, necessitating robust and stealthy ownership verification. Existing fingerprinting methods either require impractical white-box access or introduce detectable statistical anomalies. We propose EverTracer, a novel gray-box fingerprinting framework that ensures stealthy and robust model provenance tracing. EverTracer is the first to repurpose Membership Inference Attacks (MIAs) for defensive use, embedding ownership signals via memorization instead of artificial trigger-output overfitting. It consists of Fingerprint Injection, which fine-tunes the model on any natural language data without detectable artifacts, and Verification, which leverages calibrated probability variation signal to distinguish fingerprinted models. This approach remains robust against adaptive adversaries, including input level modification, and model-level modifications. Extensive experiments across architectures demonstrate EverTracer's state-of-the-art effectiveness, stealthness, and resilience, establishing it as a practical solution for securing LLM intellectual property. Our code and data are publicly available at this https URL.         ",
    "url": "https://arxiv.org/abs/2509.03058",
    "authors": [
      "Zhenhua Xu",
      "Meng Han",
      "Wenpeng Xing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2509.03060",
    "title": "A Long Short-Term Memory (LSTM) Model for Business Sentiment Analysis Based on Recurrent Neural Network",
    "abstract": "           Business sentiment analysis (BSA) is one of the significant and popular topics of natural language processing. It is one kind of sentiment analysis techniques for business purposes. Different categories of sentiment analysis techniques like lexicon-based techniques and different types of machine learning algorithms are applied for sentiment analysis on different languages like English, Hindi, Spanish, etc. In this paper, long short-term memory (LSTM) is applied for business sentiment analysis, where a recurrent neural network is used. An LSTM model is used in a modified approach to prevent the vanishing gradient problem rather than applying the conventional recurrent neural network (RNN). To apply the modified RNN model, product review dataset is used. In this experiment, 70\\% of the data is trained for the LSTM and the rest 30\\% of the data is used for testing. The result of this modified RNN model is compared with other conventional RNN models, and a comparison is made among the results. It is noted that the proposed model performs better than the other conventional RNN models. Here, the proposed model, i.e., the modified RNN model approach has achieved around 91.33\\% of accuracy. By applying this model, any business company or e-commerce business site can identify the feedback from their customers about different types of products that customers like or dislike. Based on the customer reviews, a business company or e-commerce platform can evaluate its marketing strategy.         ",
    "url": "https://arxiv.org/abs/2509.03060",
    "authors": [
      "Md. Jahidul Islam Razin",
      "Md. Abdul Karim",
      "M. F. Mridha",
      "S M Rafiuddin",
      "Tahira Alam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2509.03062",
    "title": "High Cursive Complex Character Recognition using GAN External Classifier",
    "abstract": "           Handwritten characters can be trickier to classify due to their complex and cursive nature compared to simple and non-cursive characters. We present an external classifier along with a Generative Adversarial Network that can classify highly cursive and complex characters. The generator network produces fake handwritten character images, which are then used to augment the training data after adding adversarially perturbed noise and achieving a confidence score above a threshold with the discriminator network. The results show that the accuracy of convolutional neural networks decreases as character complexity increases, but our proposed model, ADA-GAN, remains more robust and effective for both cursive and complex characters.         ",
    "url": "https://arxiv.org/abs/2509.03062",
    "authors": [
      "S M Rafiuddin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.03103",
    "title": "FastCaps: A Design Methodology for Accelerating Capsule Network on Field Programmable Gate Arrays",
    "abstract": "           Capsule Network (CapsNet) has shown significant improvement in understanding the variation in images along with better generalization ability compared to traditional Convolutional Neural Network (CNN). CapsNet preserves spatial relationship among extracted features and apply dynamic routing to efficiently learn the internal connections between capsules. However, due to the capsule structure and the complexity of the routing mechanism, it is non-trivial to accelerate CapsNet performance in its original form on Field Programmable Gate Array (FPGA). Most of the existing works on CapsNet have achieved limited acceleration as they implement only the dynamic routing algorithm on FPGA, while considering all the processing steps synergistically is important for real-world applications of Capsule Networks. Towards this, we propose a novel two-step approach that deploys a full-fledged CapsNet on FPGA. First, we prune the network using a novel Look-Ahead Kernel Pruning (LAKP) methodology that uses the sum of look-ahead scores of the model parameters. Next, we simplify the nonlinear operations, reorder loops, and parallelize operations of the routing algorithm to reduce CapsNet hardware complexity. To the best of our knowledge, this is the first work accelerating a full-fledged CapsNet on FPGA. Experimental results on the MNIST and F-MNIST datasets (typical in Capsule Network community) show that the proposed LAKP approach achieves an effective compression rate of 99.26% and 98.84%, and achieves a throughput of 82 FPS and 48 FPS on Xilinx PYNQ-Z1 FPGA, respectively. Furthermore, reducing the hardware complexity of the routing algorithm increases the throughput to 1351 FPS and 934 FPS respectively. As corroborated by our results, this work enables highly performance-efficient deployment of CapsNets on low-cost FPGA that are popular in modern edge devices.         ",
    "url": "https://arxiv.org/abs/2509.03103",
    "authors": [
      "Abdul Rahoof",
      "Vivek Chaturvedi",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2509.03108",
    "title": "Backdoor Poisoning Attack Against Face Spoofing Attack Detection Methods",
    "abstract": "           Face recognition systems are robust against environmental changes and noise, and thus may be vulnerable to illegal authentication attempts using user face photos, such as spoofing attacks. To prevent such spoofing attacks, it is crucial to discriminate whether the input image is a live user image or a spoofed image prior to the face recognition process. Most existing spoofing attack detection methods utilize deep learning, which necessitates a substantial amount of training data. Consequently, if malicious data is injected into a portion of the training dataset, a specific spoofing attack may be erroneously classified as live, leading to false this http URL this paper, we propose a novel backdoor poisoning attack method to demonstrate the latent threat of backdoor poisoning within face anti-spoofing detection. The proposed method enables certain spoofing attacks to bypass detection by embedding features extracted from the spoofing attack's face image into a live face image without inducing any perceptible visual this http URL experiments conducted on public datasets, we demonstrate that the proposed method constitutes a realistic threat to existing spoofing attack detection systems.         ",
    "url": "https://arxiv.org/abs/2509.03108",
    "authors": [
      "Shota Iwamatsu",
      "Koichi Ito",
      "Takafumi Aoki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.03116",
    "title": "Measuring Scalar Constructs in Social Science with LLMs",
    "abstract": "           Many constructs that characterize language, like its complexity or emotionality, have a naturally continuous semantic structure; a public speech is not just \"simple\" or \"complex,\" but exists on a continuum between extremes. Although large language models (LLMs) are an attractive tool for measuring scalar constructs, their idiosyncratic treatment of numerical outputs raises questions of how to best apply them. We address these questions with a comprehensive evaluation of LLM-based approaches to scalar construct measurement in social science. Using multiple datasets sourced from the political science literature, we evaluate four approaches: unweighted direct pointwise scoring, aggregation of pairwise comparisons, token-probability-weighted pointwise scoring, and finetuning. Our study yields actionable findings for applied researchers. First, LLMs prompted to generate pointwise scores directly from texts produce discontinuous distributions with bunching at arbitrary numbers. The quality of the measurements improves with pairwise comparisons made by LLMs, but it improves even more by taking pointwise scores and weighting them by token probability. Finally, finetuning smaller models with as few as 1,000 training pairs can match or exceed the performance of prompted LLMs.         ",
    "url": "https://arxiv.org/abs/2509.03116",
    "authors": [
      "Hauke Licht",
      "Rupak Sarkar",
      "Patrick Y. Wu",
      "Pranav Goel",
      "Niklas Stoehr",
      "Elliott Ash",
      "Alexander Miserlis Hoyle"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2509.03130",
    "title": "A Plug-and-play Model-agnostic Embedding Enhancement Approach for Explainable Recommendation",
    "abstract": "           Existing multimedia recommender systems provide users with suggestions of media by evaluating the similarities, such as games and movies. To enhance the semantics and explainability of embeddings, it is a consensus to apply additional information (e.g., interactions, contexts, popularity). However, without systematic consideration of representativeness and value, the utility and explainability of embedding drops drastically. Hence, we introduce RVRec, a plug-and-play model-agnostic embedding enhancement approach that can improve both personality and explainability of existing systems. Specifically, we propose a probability-based embedding optimization method that uses a contrastive loss based on negative 2-Wasserstein distance to learn to enhance the representativeness of the embeddings. In addtion, we introduce a reweighing method based on multivariate Shapley values strategy to evaluate and explore the value of interactions and embeddings. Extensive experiments on multiple backbone recommenders and real-world datasets show that RVRec can improve the personalization and explainability of existing recommenders, outperforming state-of-the-art baselines.         ",
    "url": "https://arxiv.org/abs/2509.03130",
    "authors": [
      "Yunqi Mi",
      "Boyang Yan",
      "Guoshuai Zhao",
      "Jialie Shen",
      "Xueming Qian"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2509.03137",
    "title": "A Neural Network Approach to Multi-radionuclide TDCR Beta Spectroscopy",
    "abstract": "           Liquid scintillation triple-to-doubly coincident ratio (TDCR) spectroscopy is widely adopted as a standard method for radionuclide quantification because of its inherent advantages such as high precision, self-calibrating capability, and independence from radioactive reference sources. However, multiradionuclide analysis via TDCR faces the challenges of limited automation and reliance on mixture-specific standards, which may not be easily available. Here, we present an Artificial Intelligence (AI) framework that combines numerical spectral simulation and deep learning for standard-free automated analysis. $\\beta$ spectra for model training were generated using Geant4 simulations coupled with statistically modeled detector response sampling. A tailored neural network architecture, trained on this dataset covering various nuclei mix ratio and quenching scenarios, enables autonomous resolution of individual radionuclide activities and detecting efficiency through end-to-end learning paradigms. The model delivers consistent high accuracy across tasks: activity proportions (mean absolute error = 0.009), detection efficiencies (mean absolute error = 0.002), and spectral reconstruction (Structural Similarity Index = 0.9998), validating its physical plausibility for quenched $\\beta$ spectroscopy. This AI-driven methodology exhibits significant potential for automated safety-compliant multiradionuclide analysis with robust generalization, real-time processing capabilities, and engineering feasibility, particularly in scenarios where reference materials are unavailable or rapid field analysis is required.         ",
    "url": "https://arxiv.org/abs/2509.03137",
    "authors": [
      "Li Yi",
      "Qian Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Nuclear Experiment (nucl-ex)",
      "Computational Physics (physics.comp-ph)",
      "Instrumentation and Detectors (physics.ins-det)"
    ]
  },
  {
    "id": "arXiv:2509.03179",
    "title": "AutoDetect: Designing an Autoencoder-based Detection Method for Poisoning Attacks on Object Detection Applications in the Military Domain",
    "abstract": "           Poisoning attacks pose an increasing threat to the security and robustness of Artificial Intelligence systems in the military domain. The widespread use of open-source datasets and pretrained models exacerbates this risk. Despite the severity of this threat, there is limited research on the application and detection of poisoning attacks on object detection systems. This is especially problematic in the military domain, where attacks can have grave consequences. In this work, we both investigate the effect of poisoning attacks on military object detectors in practice, and the best approach to detect these attacks. To support this research, we create a small, custom dataset featuring military vehicles: MilCivVeh. We explore the vulnerability of military object detectors for poisoning attacks by implementing a modified version of the BadDet attack: a patch-based poisoning attack. We then assess its impact, finding that while a positive attack success rate is achievable, it requires a substantial portion of the data to be poisoned -- raising questions about its practical applicability. To address the detection challenge, we test both specialized poisoning detection methods and anomaly detection methods from the visual industrial inspection domain. Since our research shows that both classes of methods are lacking, we introduce our own patch detection method: AutoDetect, a simple, fast, and lightweight autoencoder-based method. Our method shows promising results in separating clean from poisoned samples using the reconstruction error of image slices, outperforming existing methods, while being less time- and memory-intensive. We urge that the availability of large, representative datasets in the military domain is a prerequisite to further evaluate risks of poisoning attacks and opportunities patch detection.         ",
    "url": "https://arxiv.org/abs/2509.03179",
    "authors": [
      "Alma M. Liezenga",
      "Stefan Wijnja",
      "Puck de Haan",
      "Niels W. T. Brink",
      "Jip J. van Stijn",
      "Yori Kamphuis",
      "Klamer Schutte"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.03201",
    "title": "CapsBeam: Accelerating Capsule Network based Beamformer for Ultrasound Non-Steered Plane Wave Imaging on Field Programmable Gate Array",
    "abstract": "           In recent years, there has been a growing trend in accelerating computationally complex non-real-time beamforming algorithms in ultrasound imaging using deep learning models. However, due to the large size and complexity these state-of-the-art deep learning techniques poses significant challenges when deploying on resource-constrained edge devices. In this work, we propose a novel capsule network based beamformer called CapsBeam, designed to operate on raw radio-frequency data and provide an envelope of beamformed data through non-steered plane wave insonification. Experiments on in-vivo data, CapsBeam reduced artifacts compared to the standard Delay-and-Sum (DAS) beamforming. For in-vitro data, CapsBeam demonstrated a 32.31% increase in contrast, along with gains of 16.54% and 6.7% in axial and lateral resolution compared to the DAS. Similarly, in-silico data showed a 26% enhancement in contrast, along with improvements of 13.6% and 21.5% in axial and lateral resolution, respectively, compared to the DAS. To reduce the parameter redundancy and enhance the computational efficiency, we pruned the model using our multi-layer LookAhead Kernel Pruning (LAKP-ML) methodology, achieving a compression ratio of 85% without affecting the image quality. Additionally, the hardware complexity of the proposed model is reduced by applying quantization, simplification of non-linear operations, and parallelizing operations. Finally, we proposed a specialized accelerator architecture for the pruned and optimized CapsBeam model, implemented on a Xilinx ZU7EV FPGA. The proposed accelerator achieved a throughput of 30 GOPS for the convolution operation and 17.4 GOPS for the dynamic routing operation.         ",
    "url": "https://arxiv.org/abs/2509.03201",
    "authors": [
      "Abdul Rahoof",
      "Vivek Chaturvedi",
      "Mahesh Raveendranatha Panicker",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2509.03215",
    "title": "Triangle Detection in Worst-Case Sparse Graphs via Local Sketching",
    "abstract": "           We present a non-algebraic, locality-preserving framework for triangle detection in worst-case sparse graphs. Our algorithm processes the graph in $O(\\log n)$ independent layers and partitions incident edges into prefix-based classes where each class maintains a 1-sparse triple over a prime field. Potential witnesses are surfaced by pair-key (PK) alignment, and every candidate is verified by a three-stage, zero-false-positive pipeline: a class-level 1-sparse consistency check, two slot-level decodings, and a final adjacency confirmation. \\textbf{To obtain single-run high-probability coverage, we further instantiate $R=c_G\\log n$ independent PK groups per class (each probing a constant number of complementary buckets), which amplifies the per-layer hit rate from $\\Theta(1/\\log n)$ to $1-n^{-\\Omega(1)}$ without changing the accounting.} A one-shot pairing discipline and class-term triggering yield a per-(layer,level) accounting bound of $O(m)$, while keep-coin concentration ensures that each vertex retains only $O(d^+(x))$ keys with high probability. Consequently, the total running time is $O(m\\log^2 n)$ and the peak space is $O(m\\log n)$, both with high probability. The algorithm emits a succinct Seeds+Logs artifact that enables a third party to replay all necessary checks and certify a NO-instance in $\\tilde O(m\\log n)$ time. We also prove a $\\Theta(1/\\log n)$ hit-rate lower bound for any single PK family under a constant-probe local model (via Yao)--motivating the use of $\\Theta(\\log n)$ independent groups--and discuss why global algebraic convolutions would break near-linear accounting or run into fine-grained barriers. We outline measured paths toward Las Vegas $O(m\\log n)$ and deterministic near-linear variants.         ",
    "url": "https://arxiv.org/abs/2509.03215",
    "authors": [
      "Hongyi Duan",
      "Jian'an Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2509.03221",
    "title": "LGBP-OrgaNet: Learnable Gaussian Band Pass Fusion of CNN and Transformer Features for Robust Organoid Segmentation and Tracking",
    "abstract": "           Organoids replicate organ structure and function, playing a crucial role in fields such as tumor treatment and drug screening. Their shape and size can indicate their developmental status, but traditional fluorescence labeling methods risk compromising their structure. Therefore, this paper proposes an automated, non-destructive approach to organoid segmentation and tracking. We introduced the LGBP-OrgaNet, a deep learning-based system proficient in accurately segmenting, tracking, and quantifying organoids. The model leverages complementary information extracted from CNN and Transformer modules and introduces the innovative feature fusion module, Learnable Gaussian Band Pass Fusion, to merge data from two branches. Additionally, in the decoder, the model proposes a Bidirectional Cross Fusion Block to fuse multi-scale features, and finally completes the decoding through progressive concatenation and upsampling. SROrga demonstrates satisfactory segmentation accuracy and robustness on organoids segmentation datasets, providing a potent tool for organoid research.         ",
    "url": "https://arxiv.org/abs/2509.03221",
    "authors": [
      "Jing Zhang",
      "Siying Tao",
      "Jiao Li",
      "Tianhe Wang",
      "Junchen Wu",
      "Ruqian Hao",
      "Xiaohui Du",
      "Ruirong Tan",
      "Rui Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.03226",
    "title": "BAMG: A Block-Aware Monotonic Graph Index for Disk-Based Approximate Nearest Neighbor Search",
    "abstract": "           Approximate Nearest Neighbor Search (ANNS) over high-dimensional vectors is a foundational problem in databases, where disk I/O often emerges as the dominant performance bottleneck at scale. Existing graph indexing solutions for disk-based ANNS typically either optimize the storage layout for a given graph or construct the graph independently of the storage layout, thus overlooking their interaction. In this paper, we propose the Block-aware Monotonic Relative Neighborhood Graph (BMRNG), a novel graph structure that jointly considers both geometric distance and storage layout for edge selection, theoretically guaranteeing the existence of I/O monotonic search paths. To address the scalability challenge of BMRNG construction, we further develop a practical and efficient variant, the Block-Aware Monotonic Graph (BAMG), which can be constructed in linear time from a monotonic graph considering the storage layout. BAMG integrates block-aware edge pruning with a decoupled storage design that separates raw vectors from the graph index, thereby maximizing block utilization and minimizing redundant disk reads. Additionally, we design a multi-layer navigation graph for adaptive and efficient query entry, along with a block-first search algorithm that prioritizes intra-block traversal to fully exploit each disk I/O operation. Extensive experiments on real-world datasets demonstrate that BAMG achieves up to 2.1x higher throughput and reduces I/O reads by up to 52% compared to state-of-the-art methods, while maintaining comparable recall.         ",
    "url": "https://arxiv.org/abs/2509.03226",
    "authors": [
      "Huiling Li",
      "Jianliang Xu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2509.03231",
    "title": "Exploring persuasive Interactions with generative social robots: An experimental framework",
    "abstract": "           Integrating generative AI such as large language models into social robots has improved their ability to engage in natural, human-like communication. This study presents a method to examine their persuasive capabilities. We designed an experimental framework focused on decision making and tested it in a pilot that varied robot appearance and self-knowledge. Using qualitative analysis, we evaluated interaction quality, persuasion effectiveness, and the robot's communicative strategies. Participants generally experienced the interaction positively, describing the robot as competent, friendly, and supportive, while noting practical limits such as delayed responses and occasional speech-recognition errors. Persuasiveness was highly context dependent and shaped by robot behavior: participants responded well to polite, reasoned suggestions and expressive gestures, but emphasized the need for more personalized, context-aware arguments and clearer social roles. These findings suggest that generative social robots can influence user decisions, but their effectiveness depends on communicative nuance and contextual relevance. We propose refinements to the framework to further study persuasive dynamics between robots and human users.         ",
    "url": "https://arxiv.org/abs/2509.03231",
    "authors": [
      "Stephan Vonschallen",
      "Larissa Julia Corina Finsler",
      "Theresa Schmiedel",
      "Friederike Eyssel"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2509.03234",
    "title": "TeRA: Vector-based Random Tensor Network for High-Rank Adaptation of Large Language Models",
    "abstract": "           Parameter-Efficient Fine-Tuning (PEFT) methods, such as Low-Rank Adaptation (LoRA), have significantly reduced the number of trainable parameters needed in fine-tuning large language models (LLMs). Subsequent developments of LoRA-style adapters have diverged into two main directions: (1) enhancing model expressivity with high-rank adapters, and (2) pushing for further parameter reduction, as exemplified by vector-based methods. However, these approaches present a trade-off, as achieving the expressivity of high-rank weight updates typically comes at the cost of sacrificing the extreme parameter efficiency offered by vector-based techniques. To address this issue, we propose a vector-based random \\underline{\\textbf{Te}}nsor network for high-\\underline{\\textbf{R}}ank \\underline{\\textbf{A}}daptation (TeRA), a novel PEFT method that achieves high-rank weight updates while retaining the parameter efficiency of vector-based PEFT adapters. This is achieved by parameterizing the tensorized weight update matrix as a Tucker-like tensor network (TN), in which large randomly initialized factors are frozen and shared across layers, while only small layer-specific scaling vectors, formed by entries in diagonal factor matrices, are trained. This design effectively decouples the rank of the weight update matrix from the number of trainable parameters. Comprehensive experiments demonstrate that TeRA matches or even outperforms high-rank adapters, while requiring a trainable parameter count similar to vector-based methods. Theoretical analysis and ablation studies further validate the effectiveness of our approach.         ",
    "url": "https://arxiv.org/abs/2509.03234",
    "authors": [
      "Yuxuan Gu",
      "Wuyang Zhou",
      "Giorgos Iacovides",
      "Danilo Mandic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.03240",
    "title": "Evaluation of Stress Detection as Time Series Events -- A Novel Window-Based F1-Metric",
    "abstract": "           Accurate evaluation of event detection in time series is essential for applications such as stress monitoring with wearable devices, where ground truth is typically annotated as single-point events, even though the underlying phenomena are gradual and temporally diffused. Standard metrics like F1 and point-adjusted F1 (F1$_{pa}$) often misrepresent model performance in such real-world, imbalanced datasets. We introduce a window-based F1 metric (F1$_w$) that incorporates temporal tolerance, enabling a more robust assessment of event detection when exact alignment is unrealistic. Empirical analysis in three physiological datasets, two in-the-wild (ADARP, Wrist Angel) and one experimental (ROAD), indicates that F1$_w$ reveals meaningful model performance patterns invisible to conventional metrics, while its window size can be adapted to domain knowledge to avoid overestimation. We show that the choice of evaluation metric strongly influences the interpretation of model performance: using predictions from TimesFM, only our temporally tolerant metrics reveal statistically significant improvements over random and null baselines in the two in-the-wild use cases. This work addresses key gaps in time series evaluation and provides practical guidance for healthcare applications where requirements for temporal precision vary by context.         ",
    "url": "https://arxiv.org/abs/2509.03240",
    "authors": [
      "Harald Vilhelm Skat-R\u00f8rdam",
      "Sneha Das",
      "Kathrine Sofie Rasmussen",
      "Nicole Nadine L\u00f8nfeldt",
      "Line Clemmensen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2509.03241",
    "title": "Unsupervised Learning based Element Resource Allocation for Reconfigurable Intelligent Surfaces in mmWave Network",
    "abstract": "           The increasing demand for high data rates and seamless connectivity in wireless systems has sparked significant interest in reconfigurable intelligent surfaces (RIS) and artificial intelligence-based wireless applications. RIS typically comprises passive reflective antenna elements that control the wireless propagation environment by adequately tuning the phase of the reflective elements. The allocation of RIS elements to multipleuser equipment (UEs) is crucial for efficiently utilizing RIS. In this work, we formulate a joint optimization problem that optimizes the RIS phase configuration and resource allocation under an $\\alpha$-fair scheduling framework and propose an efficient way of allocating RIS elements. Conventional iterative optimization methods, however, suffer from exponentially increasing computational complexity as the number of RIS elements increases and also complicate the generation of training labels for supervised learning. To overcome these challenges, we propose a five-layer fully connected neural network (FNN) combined with a preprocessing technique to significantly reduce input dimensionality, lower computational complexity, and enhance scalability. The simulation results show that our proposed NN-based solution reduces computational overhead while significantly improving system throughput by 6.8% compared to existing RIS element allocation schemes. Furthermore, the proposed system achieves better performance while reducing computational complexity, making it significantly more scalable than the iterative optimization algorithms.         ",
    "url": "https://arxiv.org/abs/2509.03241",
    "authors": [
      "Pujitha Mamillapalli",
      "Yoghitha Ramamoorthi",
      "Abhinav Kumar",
      "Tomoki Murakami",
      "Tomoaki Ogawa",
      "Yasushi Takatori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.03262",
    "title": "PI3DETR: Parametric Instance Detection of 3D Point Cloud Edges with a Geometry-Aware 3DETR",
    "abstract": "           We present PI3DETR, an end-to-end framework that directly predicts 3D parametric curve instances from raw point clouds, avoiding the intermediate representations and multi-stage processing common in prior work. Extending 3DETR, our model introduces a geometry-aware matching strategy and specialized loss functions that enable unified detection of differently parameterized curve types, including cubic B\u00e9zier curves, line segments, circles, and arcs, in a single forward pass. Optional post-processing steps further refine predictions without adding complexity. This streamlined design improves robustness to noise and varying sampling densities, addressing critical challenges in real world LiDAR and 3D sensing scenarios. PI3DETR sets a new state-of-the-art on the ABC dataset and generalizes effectively to real sensor data, offering a simple yet powerful solution for 3D edge and curve estimation.         ",
    "url": "https://arxiv.org/abs/2509.03262",
    "authors": [
      "Fabio F. Oberweger",
      "Michael Schwingshackl",
      "Vanessa Staderini"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.03277",
    "title": "PointAD+: Learning Hierarchical Representations for Zero-shot 3D Anomaly Detection",
    "abstract": "           In this paper, we aim to transfer CLIP's robust 2D generalization capabilities to identify 3D anomalies across unseen objects of highly diverse class semantics. To this end, we propose a unified framework to comprehensively detect and segment 3D anomalies by leveraging both point- and pixel-level information. We first design PointAD, which leverages point-pixel correspondence to represent 3D anomalies through their associated rendering pixel representations. This approach is referred to as implicit 3D representation, as it focuses solely on rendering pixel anomalies but neglects the inherent spatial relationships within point clouds. Then, we propose PointAD+ to further broaden the interpretation of 3D anomalies by introducing explicit 3D representation, emphasizing spatial abnormality to uncover abnormal spatial relationships. Hence, we propose G-aggregation to involve geometry information to enable the aggregated point representations spatially aware. To simultaneously capture rendering and spatial abnormality, PointAD+ proposes hierarchical representation learning, incorporating implicit and explicit anomaly semantics into hierarchical text prompts: rendering prompts for the rendering layer and geometry prompts for the geometry layer. A cross-hierarchy contrastive alignment is further introduced to promote the interaction between the rendering and geometry layers, facilitating mutual anomaly learning. Finally, PointAD+ integrates anomaly semantics from both layers to capture the generalized anomaly semantics. During the test, PointAD+ can integrate RGB information in a plug-and-play manner and further improve its detection performance. Extensive experiments demonstrate the superiority of PointAD+ in ZS 3D anomaly detection across unseen objects with highly diverse class semantics, achieving a holistic understanding of abnormality.         ",
    "url": "https://arxiv.org/abs/2509.03277",
    "authors": [
      "Qihang Zhou",
      "Shibo He",
      "Jiangtao Yan",
      "Wenchao Meng",
      "Jiming Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.03281",
    "title": "A Brain-Inspired Gating Mechanism Unlocks Robust Computation in Spiking Neural Networks",
    "abstract": "           While spiking neural networks (SNNs) provide a biologically inspired and energy-efficient computational framework, their robustness and the dynamic advantages inherent to biological neurons remain significantly underutilized owing to oversimplified neuron models. In particular, conventional leaky integrate-and-fire (LIF) neurons often omit the dynamic conductance mechanisms inherent in biological neurons, thereby limiting their capacity to cope with noise and temporal variability. In this work, we revisit dynamic conductance from a functional perspective and uncover its intrinsic role as a biologically plausible gating mechanism that modulates information flow. Building on this insight, we introduce the Dynamic Gated Neuron~(DGN), a novel spiking unit in which membrane conductance evolves in response to neuronal activity, enabling selective input filtering and adaptive noise suppression. We provide a theoretical analysis showing that DGN possess enhanced stochastic stability compared to standard LIF models, with dynamic conductance intriguingly acting as a disturbance rejection mechanism. DGN-based SNNs demonstrate superior performance across extensive evaluations on anti-noise tasks and temporal-related benchmarks such as TIDIGITS and SHD, consistently exhibiting excellent robustness. Our results highlight, for the first time, a biologically plausible dynamic gating as a key mechanism for robust spike-based computation, providing not only theoretical guarantees but also strong empirical validations. This work thus paves the way for more resilient, efficient, and biologically inspired spiking neural networks.         ",
    "url": "https://arxiv.org/abs/2509.03281",
    "authors": [
      "Qianyi Bai",
      "Haiteng Wang",
      "Qiang Yu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2509.03290",
    "title": "Machine Learning-Driven Anomaly Detection for 5G O-RAN Performance Metrics",
    "abstract": "           The ever-increasing reliance of critical services on network infrastructure coupled with the increased operational complexity of beyond-5G/6G networks necessitate the need for proactive and automated network fault management. The provision for open interfaces among different radio access network\\,(RAN) elements and the integration of AI/ML into network architecture enabled by the Open RAN\\,(O-RAN) specifications bring new possibilities for active network health monitoring and anomaly detection. In this paper we leverage these advantages and develop an anomaly detection framework that proactively detect the possible throughput drops for a UE and minimize the post-handover failures. We propose two actionable anomaly detection algorithms tailored for real-world deployment. The first algorithm identifies user equipment (UE) at risk of severe throughput degradation by analyzing key performance indicators (KPIs) such as resource block utilization and signal quality metrics, enabling proactive handover initiation. The second algorithm evaluates neighbor cell radio coverage quality, filtering out cells with anomalous signal strength or interference levels. This reduces candidate targets for handover by 41.27\\% on average. Together, these methods mitigate post-handover failures and throughput drops while operating much faster than the near-real-time latency constraints. This paves the way for self-healing 6G networks.         ",
    "url": "https://arxiv.org/abs/2509.03290",
    "authors": [
      "Babak Azkaei",
      "Kishor Chandra Joshi",
      "George Exarchakos"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2509.03319",
    "title": "Temporal social network modeling of mobile connectivity data with graph neural networks",
    "abstract": "           Graph neural networks (GNNs) have emerged as a state-of-the-art data-driven tool for modeling connectivity data of graph-structured complex networks and integrating information of their nodes and edges in space and time. However, as of yet, the analysis of social networks using the time series of people's mobile connectivity data has not been extensively investigated. In the present study, we investigate four snapshot - based temporal GNNs in predicting the phone call and SMS activity between users of a mobile communication network. In addition, we develop a simple non - GNN baseline model using recently proposed EdgeBank method. Our analysis shows that the ROLAND temporal GNN outperforms the baseline model in most cases, whereas the other three GNNs perform on average worse than the baseline. The results show that GNN based approaches hold promise in the analysis of temporal social networks through mobile connectivity data. However, due to the relatively small performance margin between ROLAND and the baseline model, further research is required on specialized GNN architectures for temporal social network analysis.         ",
    "url": "https://arxiv.org/abs/2509.03319",
    "authors": [
      "Joel Jaskari",
      "Chandreyee Roy",
      "Fumiko Ogushi",
      "Mikko Saukkoriipi",
      "Jaakko Sahlsten",
      "Kimmo Kaski"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.03323",
    "title": "Heatmap Guided Query Transformers for Robust Astrocyte Detection across Immunostains and Resolutions",
    "abstract": "           Astrocytes are critical glial cells whose altered morphology and density are hallmarks of many neurological disorders. However, their intricate branching and stain dependent variability make automated detection of histological images a highly challenging task. To address these challenges, we propose a hybrid CNN Transformer detector that combines local feature extraction with global contextual reasoning. A heatmap guided query mechanism generates spatially grounded anchors for small and faint astrocytes, while a lightweight Transformer module improves discrimination in dense clusters. Evaluated on ALDH1L1 and GFAP stained astrocyte datasets, the model consistently outperformed Faster R-CNN, YOLOv11 and DETR, achieving higher sensitivity with fewer false positives, as confirmed by FROC analysis. These results highlight the potential of hybrid CNN Transformer architectures for robust astrocyte detection and provide a foundation for advanced computational pathology tools.         ",
    "url": "https://arxiv.org/abs/2509.03323",
    "authors": [
      "Xizhe Zhang",
      "Jiayang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.03331",
    "title": "VulnRepairEval: An Exploit-Based Evaluation Framework for Assessing Large Language Model Vulnerability Repair Capabilities",
    "abstract": "           The adoption of Large Language Models (LLMs) for automated software vulnerability patching has shown promising outcomes on carefully curated evaluation sets. Nevertheless, existing datasets predominantly rely on superficial validation methods rather than exploit-based verification, leading to overestimated performance in security-sensitive applications. This paper introduces VulnRepairEval, an evaluation framework anchored in functional Proof-of-Concept (PoC) exploits. Our framework delivers a comprehensive, containerized evaluation pipeline that enables reproducible differential assessment, where repair success requires the original exploit to fail execution against the modified code. The benchmark construction involved extensive data curation: we processed over 400 CVEs and approximately 2,500 potential sources to extract a collection of authentic vulnerability instances (23 Python CVEs) amenable to automated testing with working PoCs. Through VulnRepairEval, we conduct a comprehensive evaluation of 12 popular LLMs and observe a significant performance deficit: even the top-performing model successfully addresses merely 5/23 instances (about 21.7%), exposing critical weaknesses in security-focused applications. Our failure analysis reveals that most unsuccessful attempts stem from imprecise vulnerability identification and patches containing syntactic or semantic errors. Enhanced prompting strategies and multi-agent approaches yield minimal improvements, with overall effectiveness remaining largely unaffected. This work contributes a stringent, practical evaluation framework for LLM-driven vulnerability remediation and underscores the necessity for assessment protocols that authentically reflect real-world exploitation scenarios.         ",
    "url": "https://arxiv.org/abs/2509.03331",
    "authors": [
      "Weizhe Wang",
      "Wei Ma",
      "Qiang Hu",
      "Yao Zhang",
      "Jianfei Sun",
      "Bin Wu",
      "Yang Liu",
      "Guangquan Xu",
      "Lingxiao Jiang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2509.03341",
    "title": "On the MIA Vulnerability Gap Between Private GANs and Diffusion Models",
    "abstract": "           Generative Adversarial Networks (GANs) and diffusion models have emerged as leading approaches for high-quality image synthesis. While both can be trained under differential privacy (DP) to protect sensitive data, their sensitivity to membership inference attacks (MIAs), a key threat to data confidentiality, remains poorly understood. In this work, we present the first unified theoretical and empirical analysis of the privacy risks faced by differentially private generative models. We begin by showing, through a stability-based analysis, that GANs exhibit fundamentally lower sensitivity to data perturbations than diffusion models, suggesting a structural advantage in resisting MIAs. We then validate this insight with a comprehensive empirical study using a standardized MIA pipeline to evaluate privacy leakage across datasets and privacy budgets. Our results consistently reveal a marked privacy robustness gap in favor of GANs, even in strong DP regimes, highlighting that model type alone can critically shape privacy leakage.         ",
    "url": "https://arxiv.org/abs/2509.03341",
    "authors": [
      "Ilana Sebag",
      "Jean-Yves Franceschi",
      "Alain Rakotomamonjy",
      "Alexandre Allauzen",
      "Jamal Atif"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.03350",
    "title": "Exposing Privacy Risks in Anonymizing Clinical Data: Combinatorial Refinement Attacks on k-Anonymity Without Auxiliary Information",
    "abstract": "           Despite longstanding criticism from the privacy community, k-anonymity remains a widely used standard for data anonymization, mainly due to its simplicity, regulatory alignment, and preservation of data utility. However, non-experts often defend k-anonymity on the grounds that, in the absence of auxiliary information, no known attacks can compromise its protections. In this work, we refute this claim by introducing Combinatorial Refinement Attacks (CRA), a new class of privacy attacks targeting k-anonymized datasets produced using local recoding. This is the first method that does not rely on external auxiliary information or assumptions about the underlying data distribution. CRA leverages the utility-optimizing behavior of local recoding anonymization of ARX, which is a widely used open-source software for anonymizing data in clinical settings, to formulate a linear program that significantly reduces the space of plausible sensitive values. To validate our findings, we partnered with a network of free community health clinics, an environment where (1) auxiliary information is indeed hard to find due to the population they serve and (2) open-source k-anonymity solutions are attractive due to regulatory obligations and limited resources. Our results on real-world clinical microdata reveal that even in the absence of external information, established anonymization frameworks do not deliver the promised level of privacy, raising critical privacy concerns.         ",
    "url": "https://arxiv.org/abs/2509.03350",
    "authors": [
      "Somiya Chhillar",
      "Mary K. Righi",
      "Rebecca E. Sutter",
      "Evgenios M. Kornaropoulos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2509.03367",
    "title": "Tuning Block Size for Workload Optimization in Consortium Blockchain Networks",
    "abstract": "           Determining the optimal block size is crucial for achieving high throughput in blockchain systems. Many studies have focused on tuning various components, such as databases, network bandwidth, and consensus mechanisms. However, the impact of block size on system performance remains a topic of debate, often resulting in divergent views and even leading to new forks in blockchain networks. This research proposes a mathematical model to maximize performance by determining the ideal block size for Hyperledger Fabric, a prominent consortium blockchain. By leveraging machine learning and solving the model with a genetic algorithm, the proposed approach assesses how factors such as block size, transaction size, and network capacity influence the block processing time. The integration of an optimization solver enables precise adjustments to block size configuration before deployment, ensuring improved performance from the outset. This systematic approach aims to balance block processing efficiency, network latency, and system throughput, offering a robust solution to improve blockchain performance across diverse business contexts.         ",
    "url": "https://arxiv.org/abs/2509.03367",
    "authors": [
      "Narges Dadkhah",
      "Somayeh Mohammadi",
      "Gerhard Wunder"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2509.03370",
    "title": "Neural Field Turing Machine: A Differentiable Spatial Computer",
    "abstract": "           We introduce the Neural Field Turing Machine (NFTM), a differentiable architecture that unifies symbolic computation, physical simulation, and perceptual inference within continuous spatial fields. NFTM combines a neural controller, continuous memory field, and movable read/write heads that perform local updates. At each timestep, the controller reads local patches, computes updates via learned rules, and writes them back while updating head positions. This design achieves linear O(N) scaling through fixed-radius neighborhoods while maintaining Turing completeness under bounded error. We demonstrate three example instantiations of NFTM: cellular automata simulation (Rule 110), physics-informed PDE solvers (2D heat equation), and iterative image refinement (CIFAR-10 inpainting). These instantiations learn local update rules that compose into global dynamics, exhibit stable long-horizon rollouts, and generalize beyond training horizons. NFTM provides a unified computational substrate bridging discrete algorithms and continuous field dynamics within a single differentiable framework.         ",
    "url": "https://arxiv.org/abs/2509.03370",
    "authors": [
      "Akash Malhotra",
      "Nac\u00e9ra Seghouani"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.03376",
    "title": "Transformer-Guided Content-Adaptive Graph Learning for Hyperspectral Unmixing",
    "abstract": "           Hyperspectral unmixing (HU) targets to decompose each mixed pixel in remote sensing images into a set of endmembers and their corresponding abundances. Despite significant progress in this field using deep learning, most methods fail to simultaneously characterize global dependencies and local consistency, making it difficult to preserve both long-range interactions and boundary details. This letter proposes a novel transformer-guided content-adaptive graph unmixing framework (T-CAGU), which overcomes these challenges by employing a transformer to capture global dependencies and introducing a content-adaptive graph neural network to enhance local relationships. Unlike previous work, T-CAGU integrates multiple propagation orders to dynamically learn the graph structure, ensuring robustness against noise. Furthermore, T-CAGU leverages a graph residual mechanism to preserve global information and stabilize training. Experimental results demonstrate its superiority over the state-of-the-art methods. Our code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2509.03376",
    "authors": [
      "Hui Chen",
      "Liangyu Liu",
      "Xianchao Xiu",
      "Wanquan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.03386",
    "title": "Hierarchical Low-Altitude Wireless Network Empowered Air Traffic Management",
    "abstract": "           As the increasing development of low-altitude aircrafts, the rational design of low-altitude networks directly impacts the aerial safety and resource utilization. To address the challenges of environmental complexity and aircraft diversity in the traffic management, we propose a hierarchical low-altitude wireless network (HLWN) framework. Empowered by the threedimensional spatial discretization and integrated wireless monitoring mechanisms in HLWN, we design low-altitude air corridors to guarantee safe operation and optimization. Besides, we develop the multi-dimensional flight risk assessment through conflict detection and probabilistic collision analysis, facilitating dynamic collision avoidance for heterogeneous aircrafts. Finally, the open issues and future directions are investigated to provide insights into HLAN development.         ",
    "url": "https://arxiv.org/abs/2509.03386",
    "authors": [
      "Ziye Jia",
      "Jia He",
      "Yuanhao Cui",
      "Qiuming Zhu",
      "Ligang Yuan",
      "Fuhui Zhou",
      "Qihui Wu",
      "Dusit Niyato",
      "Zhu Han"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2509.03394",
    "title": "CloudFormer: An Attention-based Performance Prediction for Public Clouds with Unknown Workload",
    "abstract": "           Cloud platforms are increasingly relied upon to host diverse, resource-intensive workloads due to their scalability, flexibility, and cost-efficiency. In multi-tenant cloud environments, virtual machines are consolidated on shared physical servers to improve resource utilization. While virtualization guarantees resource partitioning for CPU, memory, and storage, it cannot ensure performance isolation. Competition for shared resources such as last-level cache, memory bandwidth, and network interfaces often leads to severe performance degradation. Existing management techniques, including VM scheduling and resource provisioning, require accurate performance prediction to mitigate interference. However, this remains challenging in public clouds due to the black-box nature of VMs and the highly dynamic nature of workloads. To address these limitations, we propose CloudFormer, a dual-branch Transformer-based model designed to predict VM performance degradation in black-box environments. CloudFormer jointly models temporal dynamics and system-level interactions, leveraging 206 system metrics at one-second resolution across both static and dynamic scenarios. This design enables the model to capture transient interference effects and adapt to varying workload conditions without scenario-specific tuning. Complementing the methodology, we provide a fine-grained dataset that significantly expands the temporal resolution and metric diversity compared to existing benchmarks. Experimental results demonstrate that CloudFormer consistently outperforms state-of-the-art baselines across multiple evaluation metrics, achieving robust generalization across diverse and previously unseen workloads. Notably, CloudFormer attains a mean absolute error (MAE) of just 7.8%, representing a substantial improvement in predictive accuracy and outperforming existing methods at least by 28%.         ",
    "url": "https://arxiv.org/abs/2509.03394",
    "authors": [
      "Amirhossein Shahbazinia",
      "Darong Huang",
      "Luis Costero",
      "David Atienza"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2509.03409",
    "title": "Multi-level SSL Feature Gating for Audio Deepfake Detection",
    "abstract": "           Recent advancements in generative AI, particularly in speech synthesis, have enabled the generation of highly natural-sounding synthetic speech that closely mimics human voices. While these innovations hold promise for applications like assistive technologies, they also pose significant risks, including misuse for fraudulent activities, identity theft, and security threats. Current research on spoofing detection countermeasures remains limited by generalization to unseen deepfake attacks and languages. To address this, we propose a gating mechanism extracting relevant feature from the speech foundation XLS-R model as a front-end feature extractor. For downstream back-end classifier, we employ Multi-kernel gated Convolution (MultiConv) to capture both local and global speech artifacts. Additionally, we introduce Centered Kernel Alignment (CKA) as a similarity metric to enforce diversity in learned features across different MultiConv layers. By integrating CKA with our gating mechanism, we hypothesize that each component helps improving the learning of distinct synthetic speech patterns. Experimental results demonstrate that our approach achieves state-of-the-art performance on in-domain benchmarks while generalizing robustly to out-of-domain datasets, including multilingual speech samples. This underscores its potential as a versatile solution for detecting evolving speech deepfake threats.         ",
    "url": "https://arxiv.org/abs/2509.03409",
    "authors": [
      "Hoan My Tran",
      "Damien Lolive",
      "Aghilas Sini",
      "Arnaud Delhay",
      "Pierre-Fran\u00e7ois Marteau",
      "David Guennec"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2509.03419",
    "title": "Curse of Knowledge: When Complex Evaluation Context Benefits yet Biases LLM Judges",
    "abstract": "           As large language models (LLMs) grow more capable, they face increasingly diverse and complex tasks, making reliable evaluation challenging. The paradigm of LLMs as judges has emerged as a scalable solution, yet prior work primarily focuses on simple settings. Their reliability in complex tasks--where multi-faceted rubrics, unstructured reference answers, and nuanced criteria are critical--remains understudied. In this paper, we constructed ComplexEval, a challenge benchmark designed to systematically expose and quantify Auxiliary Information Induced Biases. We systematically investigated and validated 6 previously unexplored biases across 12 basic and 3 advanced scenarios. Key findings reveal: (1) all evaluated models exhibit significant susceptibility to these biases, with bias magnitude scaling with task complexity; (2) notably, Large Reasoning Models (LRMs) show paradoxical vulnerability. Our in-depth analysis offers crucial insights for improving the accuracy and verifiability of evaluation signals, paving the way for more general and robust evaluation models.         ",
    "url": "https://arxiv.org/abs/2509.03419",
    "authors": [
      "Weiyuan Li",
      "Xintao Wang",
      "Siyu Yuan",
      "Rui Xu",
      "Jiangjie Chen",
      "Qingqing Dong",
      "Yanghua Xiao",
      "Deqing Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2509.03433",
    "title": "Decoding Visual Neural Representations by Multimodal with Dynamic Balancing",
    "abstract": "           In this work, we propose an innovative framework that integrates EEG, image, and text data, aiming to decode visual neural representations from low signal-to-noise ratio EEG signals. Specifically, we introduce text modality to enhance the semantic correspondence between EEG signals and visual content. With the explicit semantic labels provided by text, image and EEG features of the same category can be more closely aligned with the corresponding text representations in a shared multimodal space. To fully utilize pre-trained visual and textual representations, we propose an adapter module that alleviates the instability of high-dimensional representation while facilitating the alignment and fusion of cross-modal features. Additionally, to alleviate the imbalance in multimodal feature contributions introduced by the textual representations, we propose a Modal Consistency Dynamic Balance (MCDB) strategy that dynamically adjusts the contribution weights of each modality. We further propose a stochastic perturbation regularization (SPR) term to enhance the generalization ability of semantic perturbation-based models by introducing dynamic Gaussian noise in the modality optimization process. The evaluation results on the ThingsEEG dataset show that our method surpasses previous state-of-the-art methods in both Top-1 and Top-5 accuracy metrics, improving by 2.0\\% and 4.7\\% respectively.         ",
    "url": "https://arxiv.org/abs/2509.03433",
    "authors": [
      "Kaili sun",
      "Xingyu Miao",
      "Bing Zhai",
      "Haoran Duan",
      "Yang Long"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.03446",
    "title": "Graph neural networks for learning liquid simulations in dynamic scenes containing kinematic objects",
    "abstract": "           Simulating particle dynamics with high fidelity is crucial for solving real-world interaction and control tasks involving liquids in design, graphics, and robotics. Recently, data-driven approaches, particularly those based on graph neural networks (GNNs), have shown progress in tackling such problems. However, these approaches are often limited to learning fluid behavior in static free-fall environments or simple manipulation settings involving primitive objects, often overlooking complex interactions with dynamically moving kinematic rigid bodies. Here, we propose a GNN-based framework designed from the ground up to learn the dynamics of liquids under rigid body interactions and active manipulations, where particles are represented as graph nodes and particle-object collisions are handled using surface representations with the bounding volume hierarchy (BVH) algorithm. This approach enables the network to model complex interactions between liquid particles and intricate surface geometries. Our model accurately captures fluid behavior in dynamic settings and can also function as a simulator in static free-fall environments. Despite being trained on a single-object manipulation task of pouring, our model generalizes effectively to environments with unseen objects and novel manipulation tasks such as stirring and scooping. Finally, we show that the learned dynamics can be leveraged to solve control and manipulation tasks using gradient-based optimization methods.         ",
    "url": "https://arxiv.org/abs/2509.03446",
    "authors": [
      "Niteesh Midlagajni",
      "Constantin A. Rothkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.03465",
    "title": "Joint Training of Image Generator and Detector for Road Defect Detection",
    "abstract": "           Road defect detection is important for road authorities to reduce the vehicle damage caused by road defects. Considering the practical scenarios where the defect detectors are typically deployed on edge devices with limited memory and computational resource, we aim at performing road defect detection without using ensemble-based methods or test-time augmentation (TTA). To this end, we propose to Jointly Train the image Generator and Detector for road defect detection (dubbed as JTGD). We design the dual discriminators for the generative model to enforce both the synthesized defect patches and overall images to look plausible. The synthesized image quality is improved by our proposed CLIP-based Fr\u00e9chet Inception Distance loss. The generative model in JTGD is trained jointly with the detector to encourage the generative model to synthesize harder examples for the detector. Since harder synthesized images of better quality caused by the aforesaid design are used in the data augmentation, JTGD outperforms the state-of-the-art method in the RDD2022 road defect detection benchmark across various countries under the condition of no ensemble and TTA. JTGD only uses less than 20% of the number of parameters compared with the competing baseline, which makes it more suitable for deployment on edge devices in practice.         ",
    "url": "https://arxiv.org/abs/2509.03465",
    "authors": [
      "Kuan-Chuan Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.03474",
    "title": "Geometric Foundations of Tuning without Forgetting in Neural ODEs",
    "abstract": "           In our earlier work, we introduced the principle of Tuning without Forgetting (TwF) for sequential training of neural ODEs, where training samples are added iteratively and parameters are updated within the subspace of control functions that preserves the end-point mapping at previously learned samples on the manifold of output labels in the first-order approximation sense. In this letter, we prove that this parameter subspace forms a Banach submanifold of finite codimension under nonsingular controls, and we characterize its tangent space. This reveals that TwF corresponds to a continuation/deformation of the control function along the tangent space of this Banach submanifold, providing a theoretical foundation for its mapping-preserving (not forgetting) during the sequential training exactly, beyond first-order approximation.         ",
    "url": "https://arxiv.org/abs/2509.03474",
    "authors": [
      "Erkan Bayram",
      "Mohamed-Ali Belabbas",
      "Tamer Ba\u015far"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2509.03477",
    "title": "Robult: Leveraging Redundancy and Modality Specific Features for Robust Multimodal Learning",
    "abstract": "           Addressing missing modalities and limited labeled data is crucial for advancing robust multimodal learning. We propose Robult, a scalable framework designed to mitigate these challenges by preserving modality-specific information and leveraging redundancy through a novel information-theoretic approach. Robult optimizes two core objectives: (1) a soft Positive-Unlabeled (PU) contrastive loss that maximizes task-relevant feature alignment while effectively utilizing limited labeled data in semi-supervised settings, and (2) a latent reconstruction loss that ensures unique modality-specific information is retained. These strategies, embedded within a modular design, enhance performance across various downstream tasks and ensure resilience to incomplete modalities during inference. Experimental results across diverse datasets validate that Robult achieves superior performance over existing approaches in both semi-supervised learning and missing modality contexts. Furthermore, its lightweight design promotes scalability and seamless integration with existing architectures, making it suitable for real-world multimodal applications.         ",
    "url": "https://arxiv.org/abs/2509.03477",
    "authors": [
      "Duy A. Nguyen",
      "Abhi Kamboj",
      "Minh N. Do"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.02582",
    "title": "Application of Quantum Convolutional Neural Networks for MRI-Based Brain Tumor Detection and Classification",
    "abstract": "           This study explores the application of Quantum Convolutional Neural Networks (QCNNs) for brain tumor classification using MRI images, leveraging quantum computing for enhanced computational efficiency. A dataset of 3,264 MRI images, including glioma, meningioma, pituitary tumors, and non-tumor cases, was utilized. The data was split into 80% training and 20% testing, with an oversampling technique applied to address class imbalance. The QCNN model consists of quantum convolution layers, flatten layers, and dense layers, with a filter size of 2, depth of 4, and 4 qubits, trained over 10 epochs. Two models were developed: a binary classification model distinguishing tumor presence and a multiclass classification model categorizing tumor types. The binary model achieved 88% accuracy, improving to 89% after data balancing, while the multiclass model achieved 52% accuracy, increasing to 62% after oversampling. Despite strong binary classification performance, the multiclass model faced challenges due to dataset complexity and quantum circuit limitations. These findings suggest that QCNNs hold promise for medical imaging applications, particularly in binary classification. However, further refinements, including optimized quantum circuit architectures and hybrid classical-quantum approaches, are necessary to enhance multiclass classification accuracy and improve QCNN applicability in clinical settings.         ",
    "url": "https://arxiv.org/abs/2509.02582",
    "authors": [
      "Sugih Pratama Nugraha",
      "Ariiq Islam Alfajri",
      "Tony Sumaryada",
      "Duong Thanh Tai",
      "Nissren Tamam",
      "Abdelmoneim Sulieman",
      "Sitti Yani"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.02585",
    "title": "Pan-Cancer mitotic figures detection and domain generalization: MIDOG 2025 Challenge",
    "abstract": "           This report details our submission to the Mitotic Domain Generalization (MIDOG) 2025 challenge, which addresses the critical task of mitotic figure detection in histopathology for cancer prognostication. Following the \"Bitter Lesson\"\\cite{sutton2019bitterlesson} principle that emphasizes data scale over algorithmic novelty, we have publicly released two new datasets to bolster training data for both conventional \\cite{Shen2024framework} and atypical mitoses \\cite{shen_2025_16780587}. Besides, we implement up-to-date training methodologies for both track and reach a Track-1 F1-Score of 0.8407 on our test set, as well as a Track-2 balanced accuracy of 0.9107 for atypical mitotic cell classification.         ",
    "url": "https://arxiv.org/abs/2509.02585",
    "authors": [
      "Zhuoyan Shen",
      "Esther B\u00e4r",
      "Maria Hawkins",
      "Konstantin Br\u00e4utigam",
      "Charles-Antoine Collins-Fekete"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.02586",
    "title": "MitoDetect++: A Domain-Robust Pipeline for Mitosis Detection and Atypical Subtyping",
    "abstract": "           Automated detection and classification of mitotic figures especially distinguishing atypical from normal remain critical challenges in computational pathology. We present MitoDetect++, a unified deep learning pipeline designed for the MIDOG 2025 challenge, addressing both mitosis detection and atypical mitosis classification. For detection (Track 1), we employ a U-Net-based encoder-decoder architecture with EfficientNetV2-L as the backbone, enhanced with attention modules, and trained via combined segmentation losses. For classification (Track 2), we leverage the Virchow2 vision transformer, fine-tuned efficiently using Low-Rank Adaptation (LoRA) to minimize resource consumption. To improve generalization and mitigate domain shifts, we integrate strong augmentations, focal loss, and group-aware stratified 5-fold cross-validation. At inference, we deploy test-time augmentation (TTA) to boost robustness. Our method achieves a balanced accuracy of 0.892 across validation domains, highlighting its clinical applicability and scalability across tasks.         ",
    "url": "https://arxiv.org/abs/2509.02586",
    "authors": [
      "Esha Sadia Nasir",
      "Jiaqi Lv",
      "Mostafa Jahanifer",
      "Shan E Ahmed Raza"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.02588",
    "title": "Sequential Hard Mining: a data-centric approach for Mitosis Detection",
    "abstract": "           With a continuously growing availability of annotated datasets of mitotic figures in histology images, finding the best way to optimally use with this unprecedented amount of data to optimally train deep learning models has become a new challenge. Here, we build upon previously proposed approaches with a focus on efficient sampling of training data inspired by boosting techniques and present our candidate solutions for the two tracks of the MIDOG 2025 challenge.         ",
    "url": "https://arxiv.org/abs/2509.02588",
    "authors": [
      "Maxime W. Lafarge",
      "Viktor H. Koelzer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.02593",
    "title": "Robust Pan-Cancer Mitotic Figure Detection with YOLOv12",
    "abstract": "           Mitotic figures represent a key histoprognostic feature in tumor pathology, providing crucial insights into tumor aggressiveness and proliferation. However, their identification remains challenging, subject to significant inter-observer variability, even among experienced pathologists. To address this issue, the MItosis DOmain Generalization (MIDOG) 2025 challenge marks the third edition of an international competition aiming to develop robust mitosis detection algorithms. In this paper, we present a mitotic figures detection approach based on the YOLOv12 object detection architecture, achieving a $F_1$-score of 0.801 on the preliminary test set of the MIDOG 2025 challenge, without relying on external data.         ",
    "url": "https://arxiv.org/abs/2509.02593",
    "authors": [
      "Rapha\u00ebl Bourgade",
      "Guillaume Balezo",
      "Thomas Walter"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.02597",
    "title": "Solutions for Mitotic Figure Detection and Atypical Classification in MIDOG 2025",
    "abstract": "           Deep learning has driven significant advances in mitotic figure analysis within computational pathology. In this paper, we present our approach to the Mitosis Domain Generalization (MIDOG) 2025 Challenge, which consists of two distinct tasks, i.e., mitotic figure detection and atypical mitosis classification. For the mitotic figure detection task, we propose a two-stage detection-classification framework that first localizes candidate mitotic figures and subsequently refines the predictions using a dedicated classification module. For the atypical mitosis classification task, we employ an ensemble strategy that integrates predictions from multiple state-of-the-art deep learning architectures to improve robustness and accuracy. Extensive experiments demonstrate the effectiveness of our proposed methods across both tasks.         ",
    "url": "https://arxiv.org/abs/2509.02597",
    "authors": [
      "Shuting Xu",
      "Runtong Liu",
      "Zhixuan Chen",
      "Junlin Hou",
      "Hao Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.02598",
    "title": "MIDOG 2025: Mitotic Figure Detection with Attention-Guided False Positive Correction",
    "abstract": "           We present a novel approach which extends the existing Fully Convolutional One-Stage Object Detector (FCOS) for mitotic figure detection. Our composite model adds a Feedback Attention Ladder CNN (FAL-CNN) model for classification of normal versus abnormal mitotic figures, feeding into a fusion network that is trained to generate adjustments to bounding boxes predicted by FCOS. Our network aims to reduce the false positive rate of the FCOS object detector, to improve the accuracy of object detection and enhance the generalisability of the network. Our model achieved an F1 score of 0.655 for mitosis detection on the preliminary evaluation dataset.         ",
    "url": "https://arxiv.org/abs/2509.02598",
    "authors": [
      "Andrew Broad",
      "Jason Keighley",
      "Lucy Godson",
      "Alex Wright"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.02599",
    "title": "RF-DETR for Robust Mitotic Figure Detection: A MIDOG 2025 Track 1 Approach",
    "abstract": "           Mitotic figure detection in histopathology images remains challenging due to significant domain shifts across different scanners, staining protocols, and tissue types. This paper presents our approach for the MIDOG 2025 challenge Track 1, focusing on robust mitotic figure detection across diverse histological contexts. While we initially planned a two-stage approach combining high-recall detection with subsequent classification refinement, time constraints led us to focus on optimizing a single-stage detection pipeline. We employed RF-DETR (Roboflow Detection Transformer) with hard negative mining, trained on MIDOG++ dataset. On the preliminary test set, our method achieved an F1 score of 0.789 with a recall of 0.839 and precision of 0.746, demonstrating effective generalization across unseen domains. The proposed solution offers insights into the importance of training data balance and hard negative mining for addressing domain shift challenges in mitotic figure detection.         ",
    "url": "https://arxiv.org/abs/2509.02599",
    "authors": [
      "Piotr Giedziun",
      "Jan So\u0142tysik",
      "Mateusz G\u00f3rczany",
      "Norbert Ropiak",
      "Marcin Przymus",
      "Piotr Krajewski",
      "Jaros\u0142aw Kwiecie\u0144",
      "Artur Bartczak",
      "Izabela Wasiak",
      "Mateusz Maniewski"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.02612",
    "title": "Is Synthetic Image Augmentation Useful for Imbalanced Classification Problems? Case-Study on the MIDOG2025 Atypical Cell Detection Competition",
    "abstract": "           The MIDOG 2025 challenge extends prior work on mitotic figure detection by introducing a new Track 2 on atypical mitosis classification. This task aims to distinguish normal from atypical mitotic figures in histopathology images, a clinically relevant but highly imbalanced and cross-domain problem. We investigated two complementary backbones: (i) ConvNeXt-Small, pretrained on ImageNet, and (ii) a histopathology-specific ViT from Lunit trained via self-supervision. To address the strong prevalence imbalance (9408 normal vs. 1741 atypical), we synthesized additional atypical examples to approximate class balance and compared models trained with real-only vs. real+synthetic data. Using five-fold cross-validation, both backbones reached strong performance (mean AUROC approximately 95 percent), with ConvNeXt achieving slightly higher peaks while Lunit exhibited greater fold-to-fold stability. Synthetic balancing, however, did not lead to consistent improvements. On the organizers' preliminary hidden test set, explicitly designed as an out-of-distribution debug subset, ConvNeXt attained the highest AUROC (95.4 percent), whereas Lunit remained competitive on balanced accuracy. These findings suggest that both ImageNet and domain-pretrained backbones are viable for atypical mitosis classification, with domain-pretraining conferring robustness and ImageNet pretraining reaching higher peaks, while naive synthetic balancing has limited benefit. Full hidden test set results will be reported upon challenge completion.         ",
    "url": "https://arxiv.org/abs/2509.02612",
    "authors": [
      "Leire Benito-Del-Valle",
      "Pedro A. Moreno-S\u00e1nchez",
      "Itziar Egusquiza",
      "Itsaso Vitoria",
      "Artzai Pic\u00f3n",
      "Cristina L\u00f3pez-Saratxaga",
      "Adrian Galdran"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.02627",
    "title": "A Two-Stage Strategy for Mitosis Detection Using Improved YOLO11x Proposals and ConvNeXt Classification",
    "abstract": "           MIDOG 2025 Track 1 requires mitosis detection in whole-slide images (WSIs) containing non-tumor, inflamed, and necrotic regions. Due to the complicated and heterogeneous context, as well as possible artifacts, there are often false positives and false negatives, thus degrading the detection F1-score. To address this problem, we propose a two-stage framework. Firstly, an improved YOLO11x, integrated with EMA attention and LSConv, is employed to generate mitosis candidates. We use a low confidence threshold to generate as many proposals as possible, ensuring the detection recall. Then, a ConvNeXt-Tiny classifier is employed to filter out the false positives, ensuring the detection precision. Consequently, the proposed two-stage framework can generate a high detection F1-score. Evaluated on a fused dataset comprising MIDOG++, MITOS_WSI_CCMCT, and MITOS_WSI_CMC, our framework achieves an F1-score of 0.882, which is 0.035 higher than the single-stage YOLO11x baseline. This performance gain is produced by a significant precision improvement, from 0.762 to 0.839, and a comparable recall. The code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2509.02627",
    "authors": [
      "Jie Xiao",
      "Mengye Lyu",
      "Shaojun Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.02629",
    "title": "\\textit{In Silico} Benchmarking of Detectable Byzantine Agreement in Noisy Quantum Networks",
    "abstract": "           Quantum communication resources offer significant advantages for fault-tolerant distributed protocols, particularly in Byzantine Agreement (BA), where reliability against adversarial interference is essential. Quantum Detectable Byzantine Agreement (QDBA) enables consensus protocols that surpass classical limitations by leveraging entangled quantum states. In this work, we focus on the practical realization of QDBA using Einstein-Podolsky-Rosen (EPR) pairs, the simplest maximally entangled quantum resources, making the protocol experimentally accessible across current quantum hardware platforms. We present a comprehensive computational study of the EPRQDBA protocol under realistic quantum network conditions, utilizing the Aliro Quantum Network Simulator to evaluate the performance and robustness of the protocol. Our simulations systematically explore the protocol's parameter space --including variations in network size, traitorous node count, the amount of entanglement consumed in the protocol, and physically motivated noise models tailored specifically for superconducting and photonic qubit technologies. Through extensive numerical experiments, we provide insights into how these physically realistic parameters impact protocol performance, establishing critical thresholds and optimal operational regimes for experimental implementations. This work bridges theoretical advances in quantum consensus protocols with practical network implementations, offering a concrete reference for experimentalists. Our findings serve as a guideline for evaluating and optimizing QDBA implementations in realistic, noisy environments.         ",
    "url": "https://arxiv.org/abs/2509.02629",
    "authors": [
      "Mayank Bhatia",
      "Shaan Doshi",
      "Daniel Winton",
      "Brian Doolittle",
      "Bruno Abreu",
      "Santiago N\u00fa\u00f1ez-Corrales"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2509.02630",
    "title": "Challenges and Lessons from MIDOG 2025: A Two-Stage Approach to Domain-Robust Mitotic Figure Detection",
    "abstract": "           Mitotic figure detection remains a challenging task in computational pathology due to domain variability and morphological complexity. This paper describes our participation in the MIDOG 2025 challenge, focusing on robust mitotic figure detection across diverse tissue domains. We developed a two-stage pipeline combining Faster R-CNN for candidate detection with an ensemble of three classifiers (DenseNet-121, EfficientNet-v2, InceptionResNet-v2) for false positive reduction. Our best submission achieved F1-score 0.2237 (Recall: 0.9528, Precision: 0.1267) using a Faster R-CNN trained solely on MIDOG++ dataset. While our high recall demonstrates effective mitotic figure detection, the critically low precision (12.67%) reveals fundamental challenges in distinguishing true mitoses from morphologically similar imposters across diverse domains. Analysis of six submission variants showed that subsequent optimization attempts were counterproductive, highlighting the omplexity of domain generalization in histopathology. This work provides valuable insights into the practical challenges of developing robust mitotic figure detection algorithms and emphasizes the importance of effective false positive suppression strategies.         ",
    "url": "https://arxiv.org/abs/2509.02630",
    "authors": [
      "Euiseop Song",
      "Jaeyoung Park",
      "Jaewoo Park"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.02637",
    "title": "A Single Detect Focused YOLO Framework for Robust Mitotic Figure Detection",
    "abstract": "           Mitotic figure detection is a crucial task in computational pathology, as mitotic activity serves as a strong prognostic marker for tumor aggressiveness. However, domain variability that arises from differences in scanners, tissue types, and staining protocols poses a major challenge to the robustness of automated detection methods. In this study, we introduce SDF-YOLO (Single Detect Focused YOLO), a lightweight yet domain-robust detection framework designed specifically for small, rare targets such as mitotic figures. The model builds on YOLOv11 with task-specific modifications, including a single detection head aligned with mitotic figure scale, coordinate attention to enhance positional sensitivity, and improved cross-channel feature mixing. Experiments were conducted on three datasets that span human and canine tumors: MIDOG ++, canine cutaneous mast cell tumor (CCMCT), and canine mammary carcinoma (CMC). When submitted to the preliminary test set for the MIDOG2025 challenge, SDF-YOLO achieved an average precision (AP) of 0.799, with a precision of 0.758, a recall of 0.775, an F1 score of 0.766, and an FROC-AUC of 5.793, demonstrating both competitive accuracy and computational efficiency. These results indicate that SDF-YOLO provides a reliable and efficient framework for robust mitotic figure detection across diverse domains.         ",
    "url": "https://arxiv.org/abs/2509.02637",
    "authors": [
      "Yasemin Topuz",
      "M. Taha G\u00f6kcan",
      "Serdar Y\u0131ld\u0131z",
      "Song\u00fcl Varl\u0131"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.02639",
    "title": "Enhanced Single-Cell RNA-seq Embedding through Gene Expression and Data-Driven Gene-Gene Interaction Integration",
    "abstract": "           Single-cell RNA sequencing (scRNA-seq) provides unprecedented insights into cellular heterogeneity, enabling detailed analysis of complex biological systems at single-cell resolution. However, the high dimensionality and technical noise inherent in scRNA-seq data pose significant analytical challenges. While current embedding methods focus primarily on gene expression levels, they often overlook crucial gene-gene interactions that govern cellular identity and function. To address this limitation, we present a novel embedding approach that integrates both gene expression profiles and data-driven gene-gene interactions. Our method first constructs a Cell-Leaf Graph (CLG) using random forest models to capture regulatory relationships between genes, while simultaneously building a K-Nearest Neighbor Graph (KNNG) to represent expression similarities between cells. These graphs are then combined into an Enriched Cell-Leaf Graph (ECLG), which serves as input for a graph neural network to compute cell embeddings. By incorporating both expression levels and gene-gene interactions, our approach provides a more comprehensive representation of cellular states. Extensive evaluation across multiple datasets demonstrates that our method enhances the detection of rare cell populations and improves downstream analyses such as visualization, clustering, and trajectory inference. This integrated approach represents a significant advance in single-cell data analysis, offering a more complete framework for understanding cellular diversity and dynamics.         ",
    "url": "https://arxiv.org/abs/2509.02639",
    "authors": [
      "Hojjat Torabi Goudarzi",
      "Maziyar Baran Pouyan"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.02653",
    "title": "Quantifying the Social Costs of Power Outages and Restoration Disparities Across Four U.S. Hurricanes",
    "abstract": "           The multifaceted nature of disaster impact shows that densely populated areas contribute more to aggregate burden, while sparsely populated but heavily affected regions suffer disproportionately at the individual level. This study introduces a framework for quantifying the societal impacts of power outages by translating customer weighted outage exposure into deprivation measures, integrating welfare metrics with three recovery indicators, average outage days per customer, restoration duration, and relative restoration rate, computed from sequential EAGLE I observations and linked to Zip Code Tabulation Area demographics. Applied to four United States hurricanes, Beryl 2024 Texas, Helene 2024 Florida, Milton 2024 Florida, and Ida 2021 Louisiana, this standardized pipeline provides the first cross event, fine scale evaluation of outage impacts and their drivers. Results demonstrate regressive patterns with greater burdens in lower income areas, mechanistic analysis shows deprivation increases with longer restoration durations and decreases with faster restoration rates, explainable modeling identifies restoration duration as the dominant driver, and clustering reveals distinct recovery typologies not captured by conventional reliability metrics. This framework delivers a transferable method for assessing outage impacts and equity, comparative cross event evidence linking restoration dynamics to social outcomes, and actionable spatial analyses that support equity informed restoration planning and resilience investment.         ",
    "url": "https://arxiv.org/abs/2509.02653",
    "authors": [
      "Xiangpeng Li",
      "Junwei Ma",
      "Bo Li",
      "Ali Mostafavi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)",
      "General Economics (econ.GN)"
    ]
  },
  {
    "id": "arXiv:2509.02710",
    "title": "Toward a robust lesion detection model in breast DCE-MRI: adapting foundation models to high-risk women",
    "abstract": "           Accurate breast MRI lesion detection is critical for early cancer diagnosis, especially in high-risk populations. We present a classification pipeline that adapts a pretrained foundation model, the Medical Slice Transformer (MST), for breast lesion classification using dynamic contrast-enhanced MRI (DCE-MRI). Leveraging DINOv2-based self-supervised pretraining, MST generates robust per-slice feature embeddings, which are then used to train a Kolmogorov--Arnold Network (KAN) classifier. The KAN provides a flexible and interpretable alternative to conventional convolutional networks by enabling localized nonlinear transformations via adaptive B-spline activations. This enhances the model's ability to differentiate benign from malignant lesions in imbalanced and heterogeneous clinical datasets. Experimental results demonstrate that the MST+KAN pipeline outperforms the baseline MST classifier, achieving AUC = 0.80 \\pm 0.02 while preserving interpretability through attention-based heatmaps. Our findings highlight the effectiveness of combining foundation model embeddings with advanced classification strategies for building robust and generalizable breast MRI analysis tools.         ",
    "url": "https://arxiv.org/abs/2509.02710",
    "authors": [
      "Gabriel A.B. do Nascimento",
      "Vincent Dong",
      "Guilherme J. Cavalcante",
      "Alex Nguyen",
      "Tha\u00eds G. do R\u00eago",
      "Yuri Malheiros",
      "Telmo M. Silva Filho",
      "Carla R. Zeballos Torrez",
      "James C. Gee",
      "Anne Marie McCarthy",
      "Andrew D. A. Maidment",
      "Bruno Barufaldi"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2509.02909",
    "title": "Treasure Hunt in Anonymous Graphs with Quantum Pebbles by Oblivious Agents",
    "abstract": "           We investigate the problem of finding a static treasure in anonymous graphs using oblivious agents and introduce a novel approach that leverages quantum information. In anonymous graphs, vertices are unlabelled, indistinguishable, and edges are locally labelled with port numbers. Agents typically rely on stationary classical pebbles placed by an oracle to guide their search. However, this classical approach is constrained by limited information transmission and high traversal complexity. Classical pebbles are not sufficient for search if the agents are oblivious. We propose the first use of quantum pebbles for search in anonymous graphs. Quantum pebbles periodically emit qubits in a fixed quantum state. Each pebble encodes the port number to the next node using a unique quantum state. The agent determines the correct path by performing measurements in multiple bases, exploiting the probabilistic nature of quantum measurement to distinguish states. We show that this strategy enables an oblivious agent to locate the treasure in $D$ steps using $D$ quantum pebbles, where $D$ is the length of the shortest path between the starting point and the treasure. Moreover, only $O((\\log D + \\log \\Delta)/(\\log 1/\\delta))$ measurements per node are required to ensure high success probability in a graph with maximum degree $\\Delta$ where $\\delta = \\cos^2(\\frac{\\pi}{2\\Delta})$. We propose the use of quantum information as a guidance mechanism in anonymous graph search. We demonstrate that quantum pebbles can not only emulate the functionality of classical pebbles but can do so with improved efficiency, offering a promising direction for future quantum-enhanced distributed algorithms.         ",
    "url": "https://arxiv.org/abs/2509.02909",
    "authors": [
      "Gaurav Gaur",
      "Barun Gorain",
      "Rishi Ranjan Singh",
      "Daya Gaur"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2509.02957",
    "title": "Ensemble YOLO Framework for Multi-Domain Mitotic Figure Detection in Histopathology Images",
    "abstract": "           Accurate detection of mitotic figures in whole slide histopathological images remains a challenging task due to their scarcity, morphological heterogeneity, and the variability introduced by tissue preparation and staining protocols. The MIDOG competition series provides standardized benchmarks for evaluating detection approaches across diverse domains, thus motivating the development of generalizable deep learning models. In this work, we investigate the performance of two modern one-stage detectors, YOLOv5 and YOLOv8, trained on MIDOG++, CMC, and CCMCT datasets. To enhance robustness, training incorporated stain-invariant color perturbations and texture preserving augmentations. In internal validation, YOLOv5 achieved superior precision, while YOLOv8 provided improved recall, reflecting architectural trade-offs between anchor-based and anchor-free detection. To capitalize on these complementary strengths, we employed an ensemble of the two models, which improved sensitivity without a major reduction in precision. These findings highlight the effectiveness of ensemble strategies built upon contemporary object detectors to advance automated mitosis detection in digital pathology.         ",
    "url": "https://arxiv.org/abs/2509.02957",
    "authors": [
      "Navya Sri Kelam",
      "Akash Parekh",
      "Saikiran Bonthu",
      "Nitin Singhal"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.03017",
    "title": "Non-Intrusive Intelligibility Prediction for Hearing Aids: Recent Advances, Trends, and Challenges",
    "abstract": "           This paper provides an overview of recent progress in non-intrusive speech intelligibility prediction for hearing aids (HA). We summarize developments in robust acoustic feature extraction, hearing loss modeling, and the use of emerging architectures for long-sequence processing. Listener-specific adaptation strategies and domain generalization approaches that aim to improve robustness in unseen acoustic environments are also discussed. Remaining challenges, such as the need for large-scale, diverse datasets and reliable cross-profile generalization, are acknowledged. Our goal is to offer a perspective on current trends, ongoing challenges, and possible future directions toward practical and reliable HA-oriented intelligibility prediction systems.         ",
    "url": "https://arxiv.org/abs/2509.03017",
    "authors": [
      "Ryandhimas E. Zezario"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2509.03064",
    "title": "Representation number of word-representable co-bipartite graph",
    "abstract": "           A graph $G = (V, E)$ is said to be word-representable if there exists a word $w$ over the alphabet $V$ such that, for any two distinct letters $x, y \\in V$, the letters $x$ and $y$ alternate in $w$ if and only if $xy \\in E$. A graph is co-bipartite if its complement is bipartite. Therefore, the vertex set of a co-bipartite graph can be partitioned into two disjoint subsets $X$ and $Y$ such that the subgraphs induced by $X$ and $Y$ are cliques. The concept of word-representability for graph classes has gained significant attention in recent years. The book Words and Graphs by Sergey Kitaev and Vadim Lozin presents examples of co-bipartite graphs that are not word-representable. It is known that a graph is word-representable if and only if it admits a semi-transitive orientation. Although the necessary and sufficient conditions for the existence of a semi-transitive orientation in co-bipartite graphs have been established, the characterization based on vertex ordering remains open. In this paper, we present necessary and sufficient conditions for a co-bipartite graph to be word-representable in terms of its vertex ordering. Furthermore, based on this vertex ordering, we provide an algorithm to construct a $3$-uniform word-representation for any word-representable co-bipartite graph. Using this result, we prove that except for the permutation graphs, the representation number of all other word-representable co-bipartite graphs is $3$.         ",
    "url": "https://arxiv.org/abs/2509.03064",
    "authors": [
      "Biswajit Das",
      "Ramesh Hariharasubramanian"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2509.03121",
    "title": "Expansion of gap-planar graphs",
    "abstract": "           A graph is $k$-gap-planar if it has a drawing in the plane such that every crossing can be charged to one of the two edges involved so that at most $k$ crossings are charged to each edge. We show this class of graphs has linear expansion. In particular, every $r$-shallow minor of a $k$-gap-planar graph has density $O(rk)$. Several extensions of this result are proved: for topological minors, for $k$-cover-planar graphs, for $k$-gap-cover-planar graphs, and for drawings on any surface. Application to graph colouring are presented.         ",
    "url": "https://arxiv.org/abs/2509.03121",
    "authors": [
      "David R. Wood"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2509.03165",
    "title": "PatchNet: A hierarchical approach for neural field-level inference from Quijote Simulations",
    "abstract": "           \\textit{What is the cosmological information content of a cubic Gigaparsec of dark matter? } Extracting cosmological information from the non-linear matter distribution has high potential to tighten parameter constraints in the era of next-generation surveys such as Euclid, DESI, and the Vera Rubin Observatory. Traditional approaches relying on summary statistics like the power spectrum and bispectrum, though analytically tractable, fail to capture the full non-Gaussian and non-linear structure of the density field. Simulation-Based Inference (SBI) provides a powerful alternative by learning directly from forward-modeled simulations. In this work, we apply SBI to the \\textit{Quijote} dark matter simulations and introduce a hierarchical method that integrates small-scale information from field sub-volumes or \\textit{patches} with large-scale statistics such as power spectrum and bispectrum. This hybrid strategy is efficient both computationally and in terms of the amount of training data required. It overcomes the memory limitations associated with full-field training. We show that our approach enhances Fisher information relative to analytical summaries and matches that of a very different approach (wavelet-based statistics), providing evidence that we are estimating the full information content of the dark matter density field at the resolution of $\\sim 7.8~\\mathrm{Mpc}/h$.         ",
    "url": "https://arxiv.org/abs/2509.03165",
    "authors": [
      "Anirban Bairagi",
      "Benjamin Wandelt"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2509.03188",
    "title": "Prompt-Guided Patch UNet-VAE with Adversarial Supervision for Adrenal Gland Segmentation in Computed Tomography Medical Images",
    "abstract": "           Segmentation of small and irregularly shaped abdominal organs, such as the adrenal glands in CT imaging, remains a persistent challenge due to severe class imbalance, poor spatial context, and limited annotated data. In this work, we propose a unified framework that combines variational reconstruction, supervised segmentation, and adversarial patch-based feedback to address these limitations in a principled and scalable manner. Our architecture is built upon a VAE-UNet backbone that jointly reconstructs input patches and generates voxel-level segmentation masks, allowing the model to learn disentangled representations of anatomical structure and appearance. We introduce a patch-based training pipeline that selectively injects synthetic patches generated from the learned latent space, and systematically study the effects of varying synthetic-to-real patch ratios during training. To further enhance output fidelity, the framework incorporates perceptual reconstruction loss using VGG features, as well as a PatchGAN-style discriminator for adversarial supervision over spatial realism. Comprehensive experiments on the BTCV dataset demonstrate that our approach improves segmentation accuracy, particularly in boundary-sensitive regions, while maintaining strong reconstruction quality. Our findings highlight the effectiveness of hybrid generative-discriminative training regimes for small-organ segmentation and provide new insights into balancing realism, diversity, and anatomical consistency in data-scarce scenarios.         ",
    "url": "https://arxiv.org/abs/2509.03188",
    "authors": [
      "Hania Ghouse",
      "Muzammil Behzad"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.03230",
    "title": "Network connectivity analysis via shortest paths",
    "abstract": "           Complex systems of interacting components often can be modeled by a simple graph $\\mathcal{G}$ that consists of a set of $n$ nodes and a set of $m$ edges. Such a graph can be represented by an adjacency matrix $A\\in\\R^{n\\times n}$, whose $(ij)$th entry is one if there is an edge pointing from node $i$ to node $j$, and is zero otherwise. The matrix $A$ and its positive integer powers reveal important properties of the graph and allow the construction of the path length matrix $L$ for the graph. The $(ij)$th entry of $L$ is the length of the shortest path from node $i$ to node $j$; if there is no path between these nodes, then the value of the entry is set to $\\infty$. We are interested in how well information flows via shortest paths of the graph. This can be studied with the aid of the path length matrix. The path length matrix allows the definition of several measures of communication in the network defined by the graph such as the global $K$-efficiency, which considers shortest paths that are made up of at most $K$ edges for some $K<n$, as well as the number of such shortest paths. Novel notions of connectivity introduced in this paper help us understand the importance of specific edges for the flow of information through the graph. This is of interest when seeking to simplify a network by removing selected edges or trying to assess the sensitivity of the flow of information to changes due to exterior causes such as a traffic stoppage on a road network.         ",
    "url": "https://arxiv.org/abs/2509.03230",
    "authors": [
      "Silvia Noschese",
      "Lothar Reichel"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2509.03292",
    "title": "Improving Perceptual Audio Aesthetic Assessment via Triplet Loss and Self-Supervised Embeddings",
    "abstract": "           We present a system for automatic multi-axis perceptual quality prediction of generative audio, developed for Track 2 of the AudioMOS Challenge 2025. The task is to predict four Audio Aesthetic Scores--Production Quality, Production Complexity, Content Enjoyment, and Content Usefulness--for audio generated by text-to-speech (TTS), text-to-audio (TTA), and text-to-music (TTM) systems. A main challenge is the domain shift between natural training data and synthetic evaluation data. To address this, we combine BEATs, a pretrained transformer-based audio representation model, with a multi-branch long short-term memory (LSTM) predictor and use a triplet loss with buffer-based sampling to structure the embedding space by perceptual similarity. Our results show that this improves embedding discriminability and generalization, enabling domain-robust audio quality assessment without synthetic training data.         ",
    "url": "https://arxiv.org/abs/2509.03292",
    "authors": [
      "Dyah A. M. G. Wisnu",
      "Ryandhimas E. Zezario",
      "Stefano Rini",
      "Hsin-Min Wang",
      "Yu Tsao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2509.03339",
    "title": "Line Graphs of Non-Word-Representable Graphs are Not Always Non-Word-Representable",
    "abstract": "           A graph is said to be word-representable if there exists a word over its vertex set such that any two vertices are adjacent if and only if they alternate in the word. If no such word exists, the graph is non-word-representable. In the literature, there are examples of non-word-representable graphs whose line graphs are non-word-representable. However, it is an open problem to determine whether the line graph of a non-word-representable graph is always non-word-representable or not? In this work, we address the open problem by considering a class of non-word-representable graphs, viz., Mycielski graphs of odd cycles of length at least five, and show that their line graphs are word-representable.         ",
    "url": "https://arxiv.org/abs/2509.03339",
    "authors": [
      "Khyodeno Mozhui",
      "Tithi Dwary",
      "K. V. Krishna"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2212.14511",
    "title": "Cost-Driven Representation Learning for Linear Quadratic Gaussian Control: Part I",
    "abstract": "           We study the task of learning state representations from potentially high-dimensional observations, with the goal of controlling an unknown partially observable system. We pursue a cost-driven approach, where a dynamic model in some latent state space is learned by predicting the costs without predicting the observations or actions. In particular, we focus on an intuitive cost-driven state representation learning method for solving Linear Quadratic Gaussian (LQG) control, one of the most fundamental partially observable control problems. As our main results, we establish finite-sample guarantees of finding a near-optimal state representation function and a near-optimal controller using the directly learned latent model, for finite-horizon time-varying LQG control problems. To the best of our knowledge, despite various empirical successes, finite-sample guarantees of such a cost-driven approach remain elusive. Our result underscores the value of predicting multi-step costs, an idea that is key to our theory, and notably also an idea that is known to be empirically valuable for learning state representations. A second part of this work, that is to appear as Part II, addresses the infinite-horizon linear time-invariant setting; it also extends the results to an approach that implicitly learns the latent dynamics, inspired by the recent empirical breakthrough of MuZero in model-based reinforcement learning.         ",
    "url": "https://arxiv.org/abs/2212.14511",
    "authors": [
      "Yi Tian",
      "Kaiqing Zhang",
      "Russ Tedrake",
      "Suvrit Sra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.09752",
    "title": "Explainable Machine Learning-Based Security and Privacy Protection Framework for Internet of Medical Things Systems",
    "abstract": "           The Internet of Medical Things transcends traditional medical boundaries, enabling a transition from reactive treatment to proactive prevention. This innovative method revolutionizes healthcare by facilitating early disease detection and tailored care, particularly in chronic disease management, where IoMT automates treatments based on real-time health data collection. Nonetheless, its benefits are countered by significant security challenges that endanger the lives of its users due to the sensitivity and value of the processed data, thereby attracting malicious interests. Moreover, the utilization of wireless communication for data transmission exposes medical data to interception and tampering by cybercriminals. Additionally, anomalies may arise due to human error, network interference, or hardware malfunctions. In this context, anomaly detection based on Machine Learning (ML) is an interesting solution, but it comes up against obstacles in terms of explicability and privacy protection. To address these challenges, a new framework for Intrusion Detection Systems is introduced, leveraging Artificial Neural Networks for intrusion detection while utilizing Federated Learning for privacy preservation. Additionally, eXplainable Artificial Intelligence methods are incorporated to enhance model explanation and interpretation. The efficacy of the proposed framework is evaluated and compared with centralized approaches using multiple datasets containing network and medical data, simulating various attack types impacting the confidentiality, integrity, and availability of medical and physiological data. The results offer compelling evidence that the FL method performs comparably to the centralized method, demonstrating high performance. Additionally, it affords the dual advantage of safeguarding privacy and providing model explanation while adhering to ethical principles.         ",
    "url": "https://arxiv.org/abs/2403.09752",
    "authors": [
      "Ayoub Si-ahmed",
      "Mohammed Ali Al-Garadi",
      "Narhimene Boustia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.09701",
    "title": "Towards Explainable Vulnerability Detection with Large Language Models",
    "abstract": "           Software vulnerabilities pose significant risks to the security and integrity of software systems. Although prior studies have explored vulnerability detection using deep learning and pre-trained models, these approaches often fail to provide the detailed explanations necessary for developers to understand and remediate vulnerabilities effectively. The advent of large language models (LLMs) has introduced transformative potential due to their advanced generative capabilities and ability to comprehend complex contexts, offering new possibilities for addressing these challenges. In this paper, we propose LLMVulExp, an automated framework designed to specialize LLMs for the dual tasks of vulnerability detection and explanation. To address the challenges of acquiring high-quality annotated data and injecting domain-specific knowledge, LLMVulExp leverages prompt-based techniques for annotating vulnerability explanations and finetunes LLMs using instruction tuning with Low-Rank Adaptation (LoRA), enabling LLMVulExp to detect vulnerability types in code while generating detailed explanations, including the cause, location, and repair suggestions. Additionally, we employ a Chain-of-Thought (CoT) based key code extraction strategy to focus LLMs on analyzing vulnerability-prone code, further enhancing detection accuracy and explanatory depth. Our experimental results demonstrate that LLMVulExp achieves over a 90% F1 score on the SeVC dataset, effectively combining high detection accuracy with actionable and coherent explanations. This study highlights the feasibility of utilizing LLMs for real-world vulnerability detection and explanation tasks, providing critical insights into their adaptation and application in software security.         ",
    "url": "https://arxiv.org/abs/2406.09701",
    "authors": [
      "Qiheng Mao",
      "Zhenhao Li",
      "Xing Hu",
      "Kui Liu",
      "Xin Xia",
      "Jianling Sun"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2408.16206",
    "title": "RMMI: Reactive Mobile Manipulation using an Implicit Neural Map",
    "abstract": "           Mobile manipulator robots operating in complex domestic and industrial environments must effectively coordinate their base and arm motions while avoiding obstacles. While current reactive control methods gracefully achieve this coordination, they rely on simplified and idealised geometric representations of the environment to avoid collisions. This limits their performance in cluttered environments. To address this problem, we introduce RMMI, a reactive control framework that leverages the ability of neural Signed Distance Fields (SDFs) to provide a continuous and differentiable representation of the environment's geometry. RMMI formulates a quadratic program that optimises jointly for robot base and arm motion, maximises the manipulability, and avoids collisions through a set of inequality constraints. These constraints are constructed by querying the SDF for the distance and direction to the closest obstacle for a large number of sampling points on the robot. We evaluate RMMI both in simulation and in a set of real-world experiments. For reaching in cluttered environments, we observe a 25% increase in success rate. For additional details, code, and experiment videos, please visit this https URL.         ",
    "url": "https://arxiv.org/abs/2408.16206",
    "authors": [
      "Nicolas Marticorena",
      "Tobias Fischer",
      "Jesse Haviland",
      "Niko Suenderhauf"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2409.00061",
    "title": "Enhancing Natural Language Inference Performance with Knowledge Graph for COVID-19 Automated Fact-Checking in Indonesian Language",
    "abstract": "           Automated fact-checking is a key strategy to overcome the spread of COVID-19 misinformation on the internet. These systems typically leverage deep learning approaches through Natural Language Inference (NLI) to verify the truthfulness of information based on supporting evidence. However, one challenge that arises in deep learning is performance stagnation due to a lack of knowledge during training. This study proposes using a Knowledge Graph (KG) as external knowledge to enhance NLI performance for automated COVID-19 fact-checking in the Indonesian language. The proposed model architecture comprises three modules: a fact module, an NLI module, and a classifier module. The fact module processes information from the KG, while the NLI module handles semantic relationships between the given premise and hypothesis. The representation vectors from both modules are concatenated and fed into the classifier module to produce the final result. The model was trained using the generated Indonesian COVID-19 fact-checking dataset and the COVID-19 KG Bahasa Indonesia. Our study demonstrates that incorporating KGs can significantly improve NLI performance in fact-checking, achieving the best accuracy of 0.8616. This suggests that KGs are a valuable component for enhancing NLI performance in automated fact-checking.         ",
    "url": "https://arxiv.org/abs/2409.00061",
    "authors": [
      "Arief Purnama Muharram",
      "Ayu Purwarianti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2409.19954",
    "title": "Domain Consistency Representation Learning for Lifelong Person Re-Identification",
    "abstract": "           Lifelong person re-identification (LReID) exhibits a contradictory relationship between intra-domain discrimination and inter-domain gaps when learning from continuous data. Intra-domain discrimination focuses on individual nuances (i.e., clothing type, accessories, etc.), while inter-domain gaps emphasize domain consistency. Achieving a trade-off between maximizing intra-domain discrimination and minimizing inter-domain gaps is a crucial challenge for improving LReID performance. Most existing methods strive to reduce inter-domain gaps through knowledge distillation to maintain domain consistency. However, they often ignore intra-domain discrimination. To address this challenge, we propose a novel domain consistency representation learning (DCR) model that explores global and attribute-wise representations as a bridge to balance intra-domain discrimination and inter-domain gaps. At the intra-domain level, we explore the complementary relationship between global and attribute-wise representations to improve discrimination among similar identities. Excessive learning intra-domain discrimination can lead to catastrophic forgetting. We further develop an attribute-oriented anti-forgetting (AF) strategy that explores attribute-wise representations to enhance inter-domain consistency, and propose a knowledge consolidation (KC) strategy to facilitate knowledge transfer. Extensive experiments show that our DCR achieves superior performance compared to state-of-the-art LReID methods. Our code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2409.19954",
    "authors": [
      "Shiben Liu",
      "Huijie Fan",
      "Qiang Wang",
      "Weihong Ren",
      "Yandong Tang",
      "Yang Cong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2410.06340",
    "title": "FedGraph: A Research Library and Benchmark for Federated Graph Learning",
    "abstract": "           Federated graph learning is an emerging field with significant practical challenges. While algorithms have been proposed to improve the accuracy of training graph neural networks, such as node classification on federated graphs, the system performance is often overlooked, despite it is crucial for real-world deployment. To bridge this gap, we introduce FedGraph, a research library designed for practical distributed training and comprehensive benchmarking of FGL algorithms. FedGraph supports a range of state-of-the-art graph learning methods and includes a monitoring class that evaluates system performance, with a particular focus on communication and computation costs during training. Unlike existing federated learning platforms, FedGraph natively integrates homomorphic encryption to enhance privacy preservation and supports scalable deployment across multiple physical machines with system-level performance evaluation to guide the system design of future algorithms. To enhance efficiency and privacy, we propose a low-rank communication scheme for algorithms like FedGCN that require pre-training communication, accelerating both the pre-training and training phases. Extensive experiments benchmark FGL algorithms on three major graph learning tasks and demonstrate FedGraph as the first efficient FGL framework to support encrypted low-rank communication and scale to graphs with 100 million nodes.         ",
    "url": "https://arxiv.org/abs/2410.06340",
    "authors": [
      "Yuhang Yao",
      "Yuan Li",
      "Xinyi Fan",
      "Junhao Li",
      "Kay Liu",
      "Weizhao Jin",
      "Yu Yang",
      "Srivatsan Ravi",
      "Philip S. Yu",
      "Carlee Joe-Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.18002",
    "title": "Digital Network Twins for Next-generation Wireless: Creation, Optimization, and Challenges",
    "abstract": "           Digital network twins (DNTs), by representing a physical network using a virtual model, offer significant benefits such as streamlined network development, enhanced productivity, and cost reduction for next-generation (nextG) communication infrastructure. Existing works mainly describe the deployment of DNT technologies in various service this http URL full life cycle of DNTs for telecommunication has not yet been comprehensively studied, particularly in the aspects of fine-grained creation, real-time adaptation, resource-efficient deployment, and security protection. This article presents an in-depth overview of DNTs, exploring their concrete integration into networks and communication, covering the fundamental designs, the emergent applications, and critical challenges in multiple dimensions. We also include two detailed case studies to illustrate how DNTs can be applied in real-world scenarios such as wireless traffic forecasting and edge caching. Additionally, a forward-looking vision of the research opportunities in tackling the challenges of DNTs is provided, aiming to fully maximize the benefits of DNTs in nextG networks.         ",
    "url": "https://arxiv.org/abs/2410.18002",
    "authors": [
      "Zifan Zhang",
      "Zhiyuan Peng",
      "Hanzhi Yu",
      "Mingzhe Chen",
      "Yuchen Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2410.20712",
    "title": "Interaction-Aware Vulnerability Detection in Smart Contract Bytecodes",
    "abstract": "           The detection of vulnerabilities in smart contracts remains a significant challenge. While numerous tools are available for analyzing smart contracts in source code, only about 1.79% of smart contracts on Ethereum are open-source. For existing tools that target bytecodes, most of them only consider the semantic logic context and disregard function interface information in the bytecodes. In this paper, we propose COBRA, a novel framework that integrates semantic context and function interfaces to detect vulnerabilities in bytecodes of the smart contract. To our best knowledge, COBRA is the first framework that combines these two features. Moreover, to infer the function signatures that are not present in signature databases, we propose SRIF, automatically learn the rules of function signatures from the smart contract bytecodes. The bytecodes associated with the function signatures are collected by constructing a control flow graph (CFG) for the SRIF training. We optimize the semantic context using the operation code in the static single assignment (SSA) format. Finally, we integrate the context and function interface representations in the latent space as the contract feature embedding. The contract features in the hidden space are decoded for vulnerability classifications with a decoder and attention module. Experimental results demonstrate that SRIF can achieve 94.76% F1-score for function signature inference. Furthermore, when the ground truth ABI exists, COBRA achieves 93.45% F1-score for vulnerability classification. In the absence of ABI, the inferred function feature fills the encoder, and the system accomplishes an 89.46% recall rate.         ",
    "url": "https://arxiv.org/abs/2410.20712",
    "authors": [
      "Wenkai Li",
      "Xiaoqi Li",
      "Yingjie Mao",
      "Yuqing Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2410.20940",
    "title": "Attacking Misinformation Detection Using Adversarial Examples Generated by Language Models",
    "abstract": "           Large language models have many beneficial applications, but can they also be used to attack content-filtering algorithms in social media platforms? We investigate the challenge of generating adversarial examples to test the robustness of text classification algorithms detecting low-credibility content, including propaganda, false claims, rumours and hyperpartisan news. We focus on simulation of content moderation by setting realistic limits on the number of queries an attacker is allowed to attempt. Within our solution (TREPAT), initial rephrasings are generated by large language models with prompts inspired by meaning-preserving NLP tasks, such as text simplification and style transfer. Subsequently, these modifications are decomposed into small changes, applied through beam search procedure, until the victim classifier changes its decision. We perform (1) quantitative evaluation using various prompts, models and query limits, (2) targeted manual assessment of the generated text and (3) qualitative linguistic analysis. The results confirm the superiority of our approach in the constrained scenario, especially in case of long input text (news articles), where exhaustive search is not feasible.         ",
    "url": "https://arxiv.org/abs/2410.20940",
    "authors": [
      "Piotr Przyby\u0142a",
      "Euan McGill",
      "Horacio Saggion"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2410.22846",
    "title": "Integrating Knowledge Graphs and Visualization Dashboards for Advance Data Discovery in VESA",
    "abstract": "           The increasing complexity and scale of scientific datasets demand advanced tools for efficient discovery and exploration. Traditional search systems often fall short in addressing the multidimensional nature of data and their intricate relationships, limiting their utility for researchers. This paper introduces the Knowledge Graph Based Visualization Search Application (VESA), which reshapes the process of data discovery by leveraging knowledge graph technology to establish meaningful connections and employing a visualization dashboard to enable multidimensional exploration. A software prototype is developed, showcasing our use case of connecting two Earth System Science repositories via a knowledge graph backend and visualization dashboard at the frontend. The framework's effectiveness was assessed against guidelines derived from a comprehensive literature review and further validated through an online user study. The evaluation revealed positive reception, highlighting VESA's low learning curve, ease of use, and potential to enhance data discovery workflows.         ",
    "url": "https://arxiv.org/abs/2410.22846",
    "authors": [
      "Pawandeep Kaur Betz",
      "Tobias Hecking",
      "Andreas Gerndt"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2411.11514",
    "title": "Learning a Neural Association Network for Self-supervised Multi-Object Tracking",
    "abstract": "           This paper introduces a novel framework to learn data association for multi-object tracking in a self-supervised manner. Fully-supervised learning methods are known to achieve excellent tracking performances, but acquiring identity-level annotations is tedious and time-consuming. Motivated by the fact that in real-world scenarios object motion can be usually represented by a Markov process, we present a novel expectation maximization (EM) algorithm that trains a neural network to associate detections for tracking, without requiring prior knowledge of their temporal correspondences. At the core of our method lies a neural Kalman filter, with an observation model conditioned on associations of detections parameterized by a neural network. Given a batch of frames as input, data associations between detections from adjacent frames are predicted by a neural network followed by a Sinkhorn normalization that determines the assignment probabilities of detections to states. Kalman smoothing is then used to obtain the marginal probability of observations given the inferred states, producing a training objective to maximize this marginal probability using gradient descent. The proposed framework is fully differentiable, allowing the underlying neural model to be trained end-to-end. We evaluate our approach on the challenging MOT17, MOT20, and BDD100K datasets and achieve state-of-the-art results in comparison to self-supervised trackers using public detections.         ",
    "url": "https://arxiv.org/abs/2411.11514",
    "authors": [
      "Shuai Li",
      "Michael Burke",
      "Subramanian Ramamoorthy",
      "Juergen Gall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2501.08848",
    "title": "RouteNet-Gauss: Hardware-Enhanced Network Modeling with Machine Learning",
    "abstract": "           Network simulation is pivotal in network modeling, assisting with tasks ranging from capacity planning to performance estimation. Traditional approaches such as Discrete Event Simulation (DES) face limitations in terms of computational cost and accuracy. This paper introduces RouteNet-Gauss, a novel integration of a testbed network with a Machine Learning (ML) model to address these challenges. By using the testbed as a hardware accelerator, RouteNet-Gauss generates training datasets rapidly and simulates network scenarios with high fidelity to real-world conditions. Experimental results show that RouteNet-Gauss significantly reduces prediction errors by up to 95% and achieves a 488x speedup in inference time compared to state-of-the-art DES-based methods. RouteNet-Gauss's modular architecture is dynamically constructed based on the specific characteristics of the network scenario, such as topology and routing. This enables it to understand and generalize to different network configurations beyond those seen during training, including networks up to 10x larger. Additionally, it supports Temporal Aggregated Performance Estimation (TAPE), providing configurable temporal granularity and maintaining high accuracy in flow performance metrics. This approach shows promise in improving both simulation efficiency and accuracy, offering a valuable tool for network operators.         ",
    "url": "https://arxiv.org/abs/2501.08848",
    "authors": [
      "Carlos G\u00fcemes-Palau",
      "Miquel Ferriol-Galm\u00e9s",
      "Jordi Paillisse-Vilanova",
      "Albert L\u00f3pez-Bresc\u00f3",
      "Pere Barlet-Ros",
      "Albert Cabellos-Aparicio"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2501.09997",
    "title": "Attention-guided Self-reflection for Zero-shot Hallucination Detection in Large Language Models",
    "abstract": "           Hallucination has emerged as a significant barrier to the effective application of Large Language Models (LLMs). In this work, we introduce a novel Attention-Guided SElf-Reflection (AGSER) approach for zero-shot hallucination detection in LLMs. The AGSER method utilizes attention contributions to categorize the input query into attentive and non-attentive queries. Each query is then processed separately through the LLMs, allowing us to compute consistency scores between the generated responses and the original answer. The difference between the two consistency scores serves as a hallucination estimator. In addition to its efficacy in detecting hallucinations, AGSER notably reduces computational overhead, requiring only three passes through the LLM and utilizing two sets of tokens. We have conducted extensive experiments with four widely-used LLMs across three different hallucination benchmarks, demonstrating that our approach significantly outperforms existing methods in zero-shot hallucination detection.         ",
    "url": "https://arxiv.org/abs/2501.09997",
    "authors": [
      "Qiang Liu",
      "Xinlong Chen",
      "Yue Ding",
      "Bowen Song",
      "Weiqiang Wang",
      "Shu Wu",
      "Liang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2501.12553",
    "title": "ViDDAR: Vision Language Model-Based Task-Detrimental Content Detection for Augmented Reality",
    "abstract": "           In Augmented Reality (AR), virtual content enhances user experience by providing additional information. However, improperly positioned or designed virtual content can be detrimental to task performance, as it can impair users' ability to accurately interpret real-world information. In this paper we examine two types of task-detrimental virtual content: obstruction attacks, in which virtual content prevents users from seeing real-world objects, and information manipulation attacks, in which virtual content interferes with users' ability to accurately interpret real-world information. We provide a mathematical framework to characterize these attacks and create a custom open-source dataset for attack evaluation. To address these attacks, we introduce ViDDAR (Vision language model-based Task-Detrimental content Detector for Augmented Reality), a comprehensive full-reference system that leverages Vision Language Models (VLMs) and advanced deep learning techniques to monitor and evaluate virtual content in AR environments, employing a user-edge-cloud architecture to balance performance with low latency. To the best of our knowledge, ViDDAR is the first system to employ VLMs for detecting task-detrimental content in AR settings. Our evaluation results demonstrate that ViDDAR effectively understands complex scenes and detects task-detrimental content, achieving up to 92.15% obstruction detection accuracy with a detection latency of 533 ms, and an 82.46% information manipulation content detection accuracy with a latency of 9.62 s.         ",
    "url": "https://arxiv.org/abs/2501.12553",
    "authors": [
      "Yanming Xiu",
      "Tim Scargill",
      "Maria Gorlatova"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2502.01684",
    "title": "Predict, Cluster, Refine: A Joint Embedding Predictive Self-Supervised Framework for Graph Representation Learning",
    "abstract": "           Graph representation learning has emerged as a cornerstone for tasks like node classification and link prediction, yet prevailing self-supervised learning (SSL) methods face challenges such as computational inefficiency, reliance on contrastive objectives, and representation collapse. Existing approaches often depend on feature reconstruction, negative sampling, or complex decoders, which introduce training overhead and hinder generalization. Further, current techniques which address such limitations fail to account for the contribution of node embeddings to a certain prediction in the absence of labeled nodes. To address these limitations, we propose a novel joint embedding predictive framework for graph SSL that eliminates contrastive objectives and negative sampling while preserving semantic and structural information. Additionally, we introduce a semantic-aware objective term that incorporates pseudo-labels derived from Gaussian Mixture Models (GMMs), enhancing node discriminability by evaluating latent feature contributions. Extensive experiments demonstrate that our framework outperforms state-of-the-art graph SSL methods across benchmarks, achieving superior performance without contrastive loss or complex decoders. Key innovations include (1) a non-contrastive, view-invariant joint embedding predictive architecture, (2) Leveraging single context and multiple targets relationship between subgraphs, and (3) GMM-based pseudo-label scoring to capture semantic contributions. This work advances graph SSL by offering a computationally efficient, collapse-resistant paradigm that bridges spatial and semantic graph features for downstream tasks. The code for our paper can be found at this https URL ",
    "url": "https://arxiv.org/abs/2502.01684",
    "authors": [
      "Srinitish Srinivasan",
      "Omkumar CU"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2502.20336",
    "title": "A posteriori certification for neural network approximations to PDEs",
    "abstract": "           We propose rigorous lower and upper bounds for neural network (NN) approximations to PDEs by efficiently computing the Riesz representations of suitable extension and restrictions of the NN residual towards geometrically simpler domains, which are either embedded or enveloping the original domain. Error bounds are proven and detailed for elliptic as well as parabolic problems. Numerical experiments show the good quantitative behaviour of the derived upper and lower error bounds.         ",
    "url": "https://arxiv.org/abs/2502.20336",
    "authors": [
      "Lewin Ernst",
      "Nikolaos Rekatsinas",
      "Karsten Urban"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2503.07702",
    "title": "A Reliable Self-Organized Distributed Complex Network for Communication of Smart Agents",
    "abstract": "           Collaboration is a fundamental and essential characteristic of many complex systems, ranging from ant colonies to human societies. Each component within a complex system interacts with others, even at a distance, to accomplish a given task. A network of collaboration can be defined to study the collective behavior of such systems within the framework of complex networks. The nodes in these networks may represent simple organisms or more sophisticated intelligent agents, such as humans. In this study, we utilize intelligent agents (nodes) trained through reinforcement learning techniques to establish connections with their neighbors, ultimately leading to the emergence of a large-scale communication cluster. Notably, there is no centralized administrator; instead, agents must adjust their connections based on information obtained from local observations. The connection strategy is formulated using a physical Hamiltonian, thereby categorizing this intelligent system under the paradigm of \"Physics-Guided Machine Learning\". The resulting self-organized distributed complex network has numerous industrial applications, including constructing Internet of Things (IoT) networks. The design of such networks often encounters challenges, the most critical of which is ensuring effective connectivity for reliable communication while optimizing energy consumption. IoT networks are inherently dynamic in many real-world applications, such as Vehicle Ad-hoc Networks (VANETs), where nodes are mobile, and the connection topology evolves rapidly over time. These systems require a robust and rapidly self-organizing communication network. Our findings demonstrate that the proposed intelligent agents facilitate the formation of self-organized complex networks capable of maintaining network-wide connectivity across various dynamic scenarios while simultaneously optimizing average electrical power consumption.         ",
    "url": "https://arxiv.org/abs/2503.07702",
    "authors": [
      "Mehdi Bakhshipoor",
      "Yousef Azizi",
      "Seyed Ehsan Nedaaee Oskoee"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2503.11427",
    "title": "FlowKac: An Efficient Neural Fokker-Planck solver using Temporal Normalizing Flows and the Feynman-Kac Formula",
    "abstract": "           Solving the Fokker-Planck equation for high-dimensional complex dynamical systems remains a pivotal yet challenging task due to the intractability of analytical solutions and the limitations of traditional numerical methods. In this work, we present FlowKac, a novel approach that reformulates the Fokker-Planck equation using the Feynman-Kac formula, allowing to query the solution at a given point via the expected values of stochastic paths. A key innovation of FlowKac lies in its adaptive stochastic sampling scheme which significantly reduces the computational complexity while maintaining high accuracy. This sampling technique, coupled with a time-indexed normalizing flow, designed for capturing time-evolving probability densities, enables robust sampling of collocation points, resulting in a flexible and mesh-free solver. This formulation mitigates the curse of dimensionality and enhances computational efficiency and accuracy, which is particularly crucial for applications that inherently require dimensions beyond the conventional three. We validate the robustness and scalability of our method through various experiments on a range of stochastic differential equations, demonstrating significant improvements over existing techniques.         ",
    "url": "https://arxiv.org/abs/2503.11427",
    "authors": [
      "Naoufal El Bekri",
      "Lucas Drumetz",
      "Franck Vermet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2504.09766",
    "title": "On the representation of stack operators by mathematical morphology",
    "abstract": "           This paper introduces the class of grey-scale image stack operators as those that (a) map binary-images into binary-images and (b) commute on average with cross-sectioning. Equivalently, stack operators are 1-Lipchitz extensions of set operators which can be represented by applying a characteristic set operator to the cross-sections of the image and adding. In particular, they are a generalisation of stack filters, for which the characteristic set operators are increasing. Our main result is that stack operators inherit lattice properties of the characteristic set operators. We focus on the case of translation-invariant and locally defined stack operators and show the main result by deducing the characteristic function, kernel, and basis representation of stack operators. The results of this paper have implications on the design of image operators, since imply that to solve some grey-scale image processing problems it is enough to design an operator for performing the desired transformation on binary images, and then considering its extension given by a stack operator. We leave many topics for future research regarding the machine learning of stack operators and the characterisation of the image processing problems that can be solved by them.         ",
    "url": "https://arxiv.org/abs/2504.09766",
    "authors": [
      "Diego Marcondes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2504.14212",
    "title": "Bias Analysis and Mitigation through Protected Attribute Detection and Regard Classification",
    "abstract": "           Large language models (LLMs) acquire general linguistic knowledge from massive-scale pretraining. However, pretraining data mainly comprised of web-crawled texts contain undesirable social biases which can be perpetuated or even amplified by LLMs. In this study, we propose an efficient yet effective annotation pipeline to investigate social biases in the pretraining corpora. Our pipeline consists of protected attribute detection to identify diverse demographics, followed by regard classification to analyze the language polarity towards each attribute. Through our experiments, we demonstrate the effect of our bias analysis and mitigation measures, focusing on Common Crawl as the most representative pretraining corpus.         ",
    "url": "https://arxiv.org/abs/2504.14212",
    "authors": [
      "Takuma Udagawa",
      "Yang Zhao",
      "Hiroshi Kanayama",
      "Bishwaranjan Bhattacharjee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2505.02476",
    "title": "Point Cloud Recombination: Systematic Real Data Augmentation Using Robotic Targets for LiDAR Perception Validation",
    "abstract": "           The validation of LiDAR-based perception of intelligent mobile systems operating in open-world applications remains a challenge due to the variability of real environmental conditions. Virtual simulations allow the generation of arbitrary scenes under controlled conditions but lack physical sensor characteristics, such as intensity responses or material-dependent effects. In contrast, real-world data offers true sensor realism but provides less control over influencing factors, hindering sufficient validation. Existing approaches address this problem with augmentation of real-world point cloud data by transferring objects between scenes. However, these methods do not consider validation and remain limited in controllability because they rely on empirical data. We solve these limitations by proposing Point Cloud Recombination, which systematically augments captured point cloud scenes by integrating point clouds acquired from physical target objects measured in controlled laboratory environments. Thus enabling the creation of vast amounts and varieties of repeatable, physically accurate test scenes with respect to phenomena-aware occlusions with registered 3D meshes. Using the Ouster OS1-128 Rev7 sensor, we demonstrate the augmentation of real-world urban and rural scenes with humanoid targets featuring varied clothing and poses, for repeatable positioning. We show that the recombined scenes closely match real sensor outputs, enabling targeted testing, scalable failure analysis, and improved system safety. By providing controlled yet sensor-realistic data, our method enables trustworthy conclusions about the limitations of specific sensors in compound with their algorithms, e.g., object detection.         ",
    "url": "https://arxiv.org/abs/2505.02476",
    "authors": [
      "Hubert Padusinski",
      "Christian Steinhauser",
      "Christian Scherl",
      "Julian Gaal",
      "Jacob Langner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2505.03911",
    "title": "Explaining Anomalies with Tensor Networks",
    "abstract": "           Tensor networks, a class of variational quantum many-body wave functions have attracted considerable research interest across many disciplines, including classical machine learning. Recently, Aizpurua et al. demonstrated explainable anomaly detection with matrix product states on a discrete-valued cyber-security task, using quantum-inspired methods to gain insight into the learned model and detected anomalies. Here, we extend this framework to real-valued data domains. We furthermore introduce tree tensor networks for the task of explainable anomaly detection. We demonstrate these methods with three benchmark problems, show adequate predictive performance compared to several baseline models and both tensor network architectures' ability to explain anomalous samples. We thereby extend the application of tensor networks to a broader class of potential problems and open a pathway for future extensions to more complex tensor network architectures.         ",
    "url": "https://arxiv.org/abs/2505.03911",
    "authors": [
      "Hans Hohenfeld",
      "Marius Beuerle",
      "Elie Mounzer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2505.13754",
    "title": "Unsupervised Learning of Local Updates for Maximum Independent Set in Dynamic Graphs",
    "abstract": "           We present the first unsupervised learning model for finding Maximum Independent Sets (MaxIS) in dynamic graphs where edges change over time. Our method combines structural learning from graph neural networks (GNNs) with a learned distributed update mechanism that, given an edge addition or deletion event, modifies nodes' internal memories and infers their MaxIS membership in a single, parallel step. We parameterize our model by the update mechanism's radius and investigate the resulting performance-runtime tradeoffs for various dynamic graph topologies. We evaluate our model against a mixed integer programming solver and the state-of-the-art learning-based methods for MaxIS on static graphs (ICML 2020; NeurIPS 2020, 2023). Across synthetic and empirical dynamic graphs of 50-1,000 nodes, our model achieves competitive approximation ratios with excellent scalability; on large graphs, it significantly outperforms the state-of-the-art learning methods in solution quality, runtime, and memory usage. When generalizing to graphs of 10,000 nodes (100x larger than the ones used for training), our model produces MaxIS solutions 1.05-1.18x larger than any other learning method, even while maintaining competitive runtimes.         ",
    "url": "https://arxiv.org/abs/2505.13754",
    "authors": [
      "Devendra Parkar",
      "Anya Chaturvedi",
      "Joshua J. Daymude"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2505.17067",
    "title": "Unveil Multi-Picture Descriptions for Multilingual Mild Cognitive Impairment Detection via Contrastive Learning",
    "abstract": "           Detecting Mild Cognitive Impairment from picture descriptions is critical yet challenging, especially in multilingual and multiple picture settings. Prior work has primarily focused on English speakers describing a single picture (e.g., the 'Cookie Theft'). The TAUKDIAL-2024 challenge expands this scope by introducing multilingual speakers and multiple pictures, which presents new challenges in analyzing picture-dependent content. To address these challenges, we propose a framework with three components: (1) enhancing discriminative representation learning via supervised contrastive learning, (2) involving image modality rather than relying solely on speech and text modalities, and (3) applying a Product of Experts (PoE) strategy to mitigate spurious correlations and overfitting. Our framework improves MCI detection performance, achieving a +7.1% increase in Unweighted Average Recall (UAR) (from 68.1% to 75.2%) and a +2.9% increase in F1 score (from 80.6% to 83.5%) compared to the text unimodal baseline. Notably, the contrastive learning component yields greater gains for the text modality compared to speech. These results highlight our framework's effectiveness in multilingual and multi-picture MCI detection.         ",
    "url": "https://arxiv.org/abs/2505.17067",
    "authors": [
      "Kristin Qi",
      "Jiali Cheng",
      "Youxiang Zhu",
      "Hadi Amiri",
      "Xiaohui Liang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2505.21360",
    "title": "CRISP-NAM: Competing Risks Interpretable Survival Prediction with Neural Additive Models",
    "abstract": "           Competing risks are crucial considerations in survival modelling, particularly in healthcare domains where patients may experience multiple distinct event types. We propose CRISP-NAM (Competing Risks Interpretable Survival Prediction with Neural Additive Models), an interpretable neural additive model for competing risks survival analysis which extends the neural additive architecture to model cause-specific hazards while preserving feature-level interpretability. Each feature contributes independently to risk estimation through dedicated neural networks, allowing for visualization of complex non-linear relationships between covariates and each competing risk. We demonstrate competitive performance on multiple datasets compared to existing approaches.         ",
    "url": "https://arxiv.org/abs/2505.21360",
    "authors": [
      "Dhanesh Ramachandram",
      "Ananya Raval"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2506.01211",
    "title": "Iola Walker: A Mobile Footfall Detection System for Music Composition",
    "abstract": "           This outing is part of a larger music technology research project. The objective is to find a method for materially enhancing music using hardware and software. There is a strong likelihood that there exists a new medium for experiencing music via a wearable device that ordinary listeners prefer over the current state of the art. If such a medium is discovered, it is a step towards altruistic, prosocial reform in the music industry. A new playback system infrastructure has a chance to soothe some of the societal problems tied to the larger entertainment industry ecosystem. Iola walker is a music playback system that allows musicians to compose music that changes in accordance with the listener's gait. Artifacts are available here: this https URL ",
    "url": "https://arxiv.org/abs/2506.01211",
    "authors": [
      "William B. James"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2506.01729",
    "title": "Update-Aware Robust Optimal Model Predictive Control for Nonlinear Systems",
    "abstract": "           Robust optimal or min-max model predictive control (MPC) approaches aim to guarantee constraint satisfaction over a known, bounded uncertainty set while minimizing a worst-case performance bound. Traditionally, these methods compute a trajectory that meets the desired properties over a fixed prediction horizon, apply a portion of the resulting input, and then re-solve the MPC problem using newly obtained measurements at the next time step. However, this approach fails to account for the fact that the control trajectory will be updated in the future, potentially leading to conservative designs. In this paper, we present a novel update-aware robust optimal MPC algorithm for decreasing horizon problems on nonlinear systems that explicitly accounts for future control trajectory updates. This additional insight allows our method to provably expand the feasible solution set and guarantee improved worst-case performance bounds compared to existing techniques. Our approach formulates the trajectory generation problem as a sequence of nested existence-constrained semi-infinite programs (SIPs), which can be efficiently solved using local reduction techniques. To demonstrate its effectiveness, we evaluate our approach on a planar quadrotor problem, where it clearly outperforms an equivalent method that does not account for future updates at the cost of increased computation time.         ",
    "url": "https://arxiv.org/abs/2506.01729",
    "authors": [
      "J. Wehbeh",
      "E. C. Kerrigan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2506.09785",
    "title": "A theoretical framework for self-supervised contrastive learning for continuous dependent data",
    "abstract": "           Self-supervised learning (SSL) has emerged as a powerful approach to learning representations, particularly in the field of computer vision. However, its application to dependent data, such as temporal and spatio-temporal domains, remains underexplored. Besides, traditional contrastive SSL methods often assume \\emph{semantic independence between samples}, which does not hold for dependent data exhibiting complex correlations. We propose a novel theoretical framework for contrastive SSL tailored to \\emph{continuous dependent data}, which allows the nearest samples to be semantically close to each other. In particular, we propose two possible \\textit{ground truth similarity measures} between objects -- \\emph{hard} and \\emph{soft} closeness. Under it, we derive an analytical form for the \\textit{estimated similarity matrix} that accommodates both types of closeness between samples, thereby introducing dependency-aware loss functions. We validate our approach, \\emph{Dependent TS2Vec}, on temporal and spatio-temporal downstream problems. Given the dependency patterns presented in the data, our approach surpasses modern ones for dependent data, highlighting the effectiveness of our theoretically grounded loss functions for SSL in capturing spatio-temporal dependencies. Specifically, we outperform TS2Vec on the standard UEA and UCR benchmarks, with accuracy improvements of $4.17$\\% and $2.08$\\%, respectively. Furthermore, on the drought classification task, which involves complex spatio-temporal patterns, our method achieves a $7$\\% higher ROC-AUC score.         ",
    "url": "https://arxiv.org/abs/2506.09785",
    "authors": [
      "Alexander Marusov",
      "Aleksandr Yugay",
      "Alexey Zaytsev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2506.12100",
    "title": "LLM Embedding-based Attribution (LEA): Quantifying Source Contributions to Generative Model's Response for Vulnerability Analysis",
    "abstract": "           Large Language Models (LLMs) are increasingly used for cybersecurity threat analysis, but their deployment in security-sensitive environments raises trust and safety concerns. With over 21,000 vulnerabilities disclosed in 2025, manual analysis is infeasible, making scalable and verifiable AI support critical. When querying LLMs, dealing with emerging vulnerabilities is challenging as they have a training cut-off date. While Retrieval-Augmented Generation (RAG) can inject up-to-date context to alleviate the cut-off date limitation, it remains unclear how much LLMs rely on retrieved evidence versus the model's internal knowledge, and whether the retrieved information is meaningful or even correct. This uncertainty could mislead security analysts, mis-prioritize patches, and increase security risks. Therefore, this work proposes LLM Embedding-based Attribution (LEA) to analyze the generated responses for vulnerability exploitation analysis. More specifically, LEA quantifies the relative contribution of internal knowledge vs. retrieved content in the generated responses. We evaluate LEA on 500 critical vulnerabilities disclosed between 2016 and 2025, across three RAG settings -- valid, generic, and incorrect -- using three state-of-the-art LLMs. Our results demonstrate LEA's ability to detect clear distinctions between non-retrieval, generic-retrieval, and valid-retrieval scenarios with over 95% accuracy on larger models. Finally, we demonstrate the limitations posed by incorrect retrieval of vulnerability information and raise a cautionary note to the cybersecurity community regarding the blind reliance on LLMs and RAG for vulnerability analysis. LEA offers security analysts with a metric to audit RAG-enhanced workflows, improving the transparent and trustworthy deployment of AI in cybersecurity threat analysis.         ",
    "url": "https://arxiv.org/abs/2506.12100",
    "authors": [
      "Reza Fayyazi",
      "Michael Zuzak",
      "Shanchieh Jay Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2506.12389",
    "title": "Revisiting Clustering of Neural Bandits: Selective Reinitialization for Mitigating Loss of Plasticity",
    "abstract": "           Clustering of Bandits (CB) methods enhance sequential decision-making by grouping bandits into clusters based on similarity and incorporating cluster-level contextual information, demonstrating effectiveness and adaptability in applications like personalized streaming recommendations. However, when extending CB algorithms to their neural version (commonly referred to as Clustering of Neural Bandits, or CNB), they suffer from loss of plasticity, where neural network parameters become rigid and less adaptable over time, limiting their ability to adapt to non-stationary environments (e.g., dynamic user preferences in recommendation). To address this challenge, we propose Selective Reinitialization (SeRe), a novel bandit learning framework that dynamically preserves the adaptability of CNB algorithms in evolving environments. SeRe leverages a contribution utility metric to identify and selectively reset underutilized units, mitigating loss of plasticity while maintaining stable knowledge retention. Furthermore, when combining SeRe with CNB algorithms, the adaptive change detection mechanism adjusts the reinitialization frequency according to the degree of non-stationarity, ensuring effective adaptation without unnecessary resets. Theoretically, we prove that SeRe enables sublinear cumulative regret in piecewise-stationary environments, outperforming traditional CNB approaches in long-term performances. Extensive experiments on six real-world recommendation datasets demonstrate that SeRe-enhanced CNB algorithms can effectively mitigate the loss of plasticity with lower regrets, improving adaptability and robustness in dynamic settings.         ",
    "url": "https://arxiv.org/abs/2506.12389",
    "authors": [
      "Zhiyuan Su",
      "Sunhao Dai",
      "Xiao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2506.13554",
    "title": "Non-Asymptotic Stability and Consistency Guarantees for Physics-Informed Neural Networks via Coercive Operator Analysis",
    "abstract": "           We present a unified theoretical framework for analyzing the stability and consistency of Physics-Informed Neural Networks (PINNs), grounded in operator coercivity, variational formulations, and non-asymptotic perturbation theory. PINNs approximate solutions to partial differential equations (PDEs) by minimizing residual losses over sampled collocation and boundary points. We formalize both operator-level and variational notions of consistency, proving that residual minimization in Sobolev norms leads to convergence in energy and uniform norms under mild regularity. Deterministic stability bounds quantify how bounded perturbations to the network outputs propagate through the full composite loss, while probabilistic concentration results via McDiarmid's inequality yield sample complexity guarantees for residual-based generalization. A unified generalization bound links residual consistency, projection error, and perturbation sensitivity. Empirical results on elliptic, parabolic, and nonlinear PDEs confirm the predictive accuracy of our theoretical bounds across regimes. The framework identifies key structural principles, such as operator coercivity, activation smoothness, and sampling admissibility, that underlie robust and generalizable PINN training, offering principled guidance for the design and analysis of PDE-informed learning systems.         ",
    "url": "https://arxiv.org/abs/2506.13554",
    "authors": [
      "Ronald Katende"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2506.15079",
    "title": "Neural Canonical Polyadic Factorization for Traffic Analysis",
    "abstract": "           Modern intelligent transportation systems rely on accurate spatiotemporal traffic analysis to optimize urban mobility and infrastructure resilience. However, pervasive missing data caused by sensor failures and heterogeneous sensing gaps fundamentally hinders reliable traffic modeling. This paper proposes a Neural Canonical Polyadic Factorization (NCPF) model that synergizes low-rank tensor algebra with deep representation learning for robust traffic data imputation. The model innovatively embeds CP decomposition into neural architecture through learnable embedding projections, where sparse traffic tensors are encoded into dense latent factors across road segments, time intervals, and mobility metrics. A hierarchical feature fusion mechanism employs Hadamard products to explicitly model multilinear interactions, while stacked multilayer perceptron layers nonlinearly refine these representations to capture complex spatiotemporal couplings. Extensive evaluations on six urban traffic datasets demonstrate NCPF's superiority over six state-of-the-art baselines. By unifying CP decomposition's interpretable factor analysis with neural network's nonlinear expressive power, NCPF provides a principled yet flexible approaches for high-dimensional traffic data imputation, offering critical support for next-generation transportation digital twins and adaptive traffic control systems.         ",
    "url": "https://arxiv.org/abs/2506.15079",
    "authors": [
      "Wenyu Luo",
      "Yikai Hou",
      "Peng Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2506.17948",
    "title": "Your Build Scripts Stink: The State of Code Smells in Build Scripts",
    "abstract": "           Build scripts are files that automate the process of compiling source code, managing dependencies, running tests, and packaging software into deployable artifacts. These scripts are ubiquitous in modern software development pipelines for streamlining testing and delivery. While developing build scripts, practitioners may inadvertently introduce code smells. Code smells are recurring patterns of poor coding practices that may lead to build failures or increase risk and technical debt. The goal of this study is to aid practitioners in avoiding code smells in build scripts through an empirical study of build scripts and issues on GitHub. We employed a mixed-methods approach, combining qualitative and quantitative analysis. We conducted a qualitative analysis of 2000 build-script-related GitHub issues. Next, we developed a static analysis tool, Sniffer, to identify code smells in 5882 build scripts of Maven, Gradle, CMake, and Make files, collected from 4877 open-source GitHub repositories. We identified 13 code smell categories, with a total of 10,895 smell occurrences, where 3184 were in Maven, 1214 in Gradle, 337 in CMake, and 6160 in Makefiles. Our analysis revealed that Insecure URLs were the most prevalent code smell in Maven build scripts, while Hardcoded Paths/URLs were commonly observed in both Gradle and CMake scripts. Wildcard Usage emerged as the most frequent smell in Makefiles. The co-occurrence analysis revealed strong associations between specific smell pairs of Hardcoded Paths/URLs with Duplicates, and Inconsistent Dependency Management with Empty or Incomplete Tags, indicating potential underlying issues in the build script structure and maintenance practices. Based on our findings, we also recommended strategies to mitigate the existence of code smells in build scripts to improve the efficiency, reliability, and maintainability of software projects.         ",
    "url": "https://arxiv.org/abs/2506.17948",
    "authors": [
      "Mahzabin Tamanna",
      "Yash Chandrani",
      "Matthew Burrows",
      "Brandon Wroblewski",
      "Laurie Williams",
      "Dominik Wermke"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2506.18368",
    "title": "Sequential keypoint density estimator: an overlooked baseline of skeleton-based video anomaly detection",
    "abstract": "           Detecting anomalous human behaviour is an important visual task in safety-critical applications such as healthcare monitoring, workplace safety, or public surveillance. In these contexts, abnormalities are often reflected with unusual human poses. Thus, we propose SeeKer, a method for detecting anomalies in sequences of human skeletons. Our method formulates the skeleton sequence density through autoregressive factorization at the keypoint level. The corresponding conditional distributions represent probable keypoint locations given prior skeletal motion. We formulate the joint distribution of the considered skeleton as causal prediction of conditional Gaussians across its constituent keypoints. A skeleton is flagged as anomalous if its keypoint locations surprise our model (i.e. receive a low density). In practice, our anomaly score is a weighted sum of per-keypoint log-conditionals, where the weights account for the confidence of the underlying keypoint detector. Despite its conceptual simplicity, SeeKer surpasses all previous methods on the UBnormal and MSAD-HR datasets while delivering competitive performance on the ShanghaiTech dataset.         ",
    "url": "https://arxiv.org/abs/2506.18368",
    "authors": [
      "Anja Deli\u0107",
      "Matej Grci\u0107",
      "Sini\u0161a \u0160egvi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2507.06463",
    "title": "Evaluating Efficiency and Novelty of LLM-Generated Code for Graph Analysis",
    "abstract": "           Large Language Models (LLMs) are increasingly used to automate software development, yet most prior evaluations focus on functional correctness or high-level languages such as Python. As one of the first systematic explorations of LLM-assisted software performance engineering, we present a comprehensive study of LLMs' ability to generate efficient C implementations of graph-analysis routines -- code that must satisfy stringent runtime and memory constraints. This emerging field of LLM-assisted algorithm engineering holds significant promise, as these models may possess the capability to design novel approaches that improve existing algorithms and their implementations. Eight state-of-the-art models (OpenAI ChatGPT o3 and o4-mini-high, Anthropic Claude 4 Sonnet and Sonnet Extended, Google Gemini 2.5 Flash and Pro, xAI Grok 3-Think, and DeepSeek DeepThink R1) are benchmarked using two distinct approaches. The first approach evaluates the ability of LLMs to generate algorithms that outperform existing benchmarks. The second approach assesses their capability to generate graph algorithms for integration into performance-critical systems. The results show that Claude Sonnet 4 Extended achieves superior performance in ready-to-use code generation and efficiency, outperforming human-written baselines in triangle counting. Although our findings demonstrate that contemporary LLMs excel in optimizing and integrating established algorithms, the potential for these models to eventually invent transformative algorithmic techniques represents a compelling frontier for future research. We provide prompts, generated code, and measurement scripts to promote reproducible research in this rapidly evolving domain. All of the source code is available on GitHub at this https URL.         ",
    "url": "https://arxiv.org/abs/2507.06463",
    "authors": [
      "Atieh Barati Nia",
      "Mohammad Dindoost",
      "David A. Bader"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2507.10578",
    "title": "When and Where do Data Poisons Attack Textual Inversion?",
    "abstract": "           Poisoning attacks pose significant challenges to the robustness of diffusion models (DMs). In this paper, we systematically analyze when and where poisoning attacks textual inversion (TI), a widely used personalization technique for DMs. We first introduce Semantic Sensitivity Maps, a novel method for visualizing the influence of poisoning on text embeddings. Second, we identify and experimentally verify that DMs exhibit non-uniform learning behavior across timesteps, focusing on lower-noise samples. Poisoning attacks inherit this bias and inject adversarial signals predominantly at lower timesteps. Lastly, we observe that adversarial signals distract learning away from relevant concept regions within training data, corrupting the TI process. Based on these insights, we propose Safe-Zone Training (SZT), a novel defense mechanism comprised of 3 key components: (1) JPEG compression to weaken high-frequency poison signals, (2) restriction to high timesteps during TI training to avoid adversarial signals at lower timesteps, and (3) loss masking to constrain learning to relevant regions. Extensive experiments across multiple poisoning methods demonstrate that SZT greatly enhances the robustness of TI against all poisoning attacks, improving generative quality beyond prior published defenses. Code: this http URL Data: this http URL ",
    "url": "https://arxiv.org/abs/2507.10578",
    "authors": [
      "Jeremy Styborski",
      "Mingzhi Lyu",
      "Jiayou Lu",
      "Nupur Kapur",
      "Adams Kong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2507.17695",
    "title": "Symbiotic Agents: A Novel Paradigm for Trustworthy AGI-driven Networks",
    "abstract": "           Large Language Model (LLM)-based autonomous agents are expected to play a vital role in the evolution of 6G networks, by empowering real-time decision-making related to management and service provisioning to end-users. This shift facilitates the transition from a specialized intelligence approach, where artificial intelligence (AI) algorithms handle isolated tasks, to artificial general intelligence (AGI)-driven networks, where agents possess broader reasoning capabilities and can manage diverse network functions. In this paper, we introduce a novel agentic paradigm that combines LLMs with real-time optimization algorithms towards Trustworthy AI, defined as symbiotic agents. Optimizers at the LLM's input-level provide bounded uncertainty steering for numerically precise tasks, whereas output-level optimizers supervised by the LLM enable adaptive real-time control. We design and implement two novel agent types including: (i) Radio Access Network optimizers, and (ii) multi-agent negotiators for Service-Level Agreements (SLAs). We further propose an end-to-end architecture for AGI networks and evaluate it on a 5G testbed capturing channel fluctuations from moving vehicles. Results show that symbiotic agents reduce decision errors fivefold compared to standalone LLM-based agents, while smaller language models (SLM) achieve similar accuracy with a 99.9% reduction in GPU resource overhead and in near-real-time loops of 82 ms. A multi-agent demonstration for collaborative RAN on the real-world testbed highlights significant flexibility in service-level agreement and resource allocation, reducing RAN over-utilization by approximately 44%. Drawing on our findings and open-source implementations, we introduce the symbiotic paradigm as the foundation for next-generation, AGI-driven networks-systems designed to remain adaptable, efficient, and trustworthy even as LLMs advance.         ",
    "url": "https://arxiv.org/abs/2507.17695",
    "authors": [
      "Ilias Chatzistefanidis",
      "Navid Nikaein"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2507.19733",
    "title": "Integrating Activity Predictions in Knowledge Graphs",
    "abstract": "           We argue that ontology-structured knowledge graphs can play a crucial role in generating predictions about future events. By leveraging the semantic framework provided by Basic Formal Ontology (BFO) and Common Core Ontologies (CCO), we demonstrate how data such as the movements of a fishing vessel can be organized in and retrieved from a knowledge graph. These query results are then used to create Markov chain models, allowing us to predict future states based on the vessel's history. To fully support this process, we introduce the term `spatiotemporal instant' to complete the necessary structural semantics. Additionally, we critique the prevailing ontological model of probability, according to which probabilities are about the future. We propose an alternative view, where at least some probabilities are treated as being about actual process profiles, which better captures the dynamics of real-world phenomena. Finally, we demonstrate how our Markov chain-based probability calculations can be seamlessly integrated back into the knowledge graph, enabling further analysis and decision-making.         ",
    "url": "https://arxiv.org/abs/2507.19733",
    "authors": [
      "Forrest Hare Alec Sculley",
      "Cameron Stockton"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2508.08040",
    "title": "BadPromptFL: A Novel Backdoor Threat to Prompt-based Federated Learning in Multimodal Models",
    "abstract": "           Prompt-based tuning has emerged as a lightweight alternative to full fine-tuning in large vision-language models, enabling efficient adaptation via learned contextual prompts. This paradigm has recently been extended to federated learning settings (e.g., PromptFL), where clients collaboratively train prompts under data privacy constraints. However, the security implications of prompt-based aggregation in federated multimodal learning remain largely unexplored, leaving a critical attack surface unaddressed. In this paper, we introduce \\textbf{BadPromptFL}, the first backdoor attack targeting prompt-based federated learning in multimodal contrastive models. In BadPromptFL, compromised clients jointly optimize local backdoor triggers and prompt embeddings, injecting poisoned prompts into the global aggregation process. These prompts are then propagated to benign clients, enabling universal backdoor activation at inference without modifying model parameters. Leveraging the contextual learning behavior of CLIP-style architectures, BadPromptFL achieves high attack success rates (e.g., \\(>90\\%\\)) with minimal visibility and limited client participation. Extensive experiments across multiple datasets and aggregation protocols validate the effectiveness, stealth, and generalizability of our attack, raising critical concerns about the robustness of prompt-based federated learning in real-world deployments.         ",
    "url": "https://arxiv.org/abs/2508.08040",
    "authors": [
      "Maozhen Zhang",
      "Mengnan Zhao",
      "Bo Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2508.11133",
    "title": "MoNaCo: More Natural and Complex Questions for Reasoning Across Dozens of Documents",
    "abstract": "           Automated agents, powered by Large language models (LLMs), are emerging as the go-to tool for querying information. However, evaluation benchmarks for LLM agents rarely feature natural questions that are both information-seeking and genuinely time-consuming for humans. To address this gap we introduce MoNaCo, a benchmark of 1,315 natural and time-consuming questions that require dozens, and at times hundreds, of intermediate steps to solve -- far more than any existing QA benchmark. To build MoNaCo, we developed a decomposed annotation pipeline to elicit and manually answer real-world time-consuming questions at scale. Frontier LLMs evaluated on MoNaCo achieve at most 61.2% F1, hampered by low recall and hallucinations. Our results underscore the limitations of LLM-powered agents in handling the complexity and sheer breadth of real-world information-seeking tasks -- with MoNaCo providing an effective resource for tracking such progress. The MoNaCo benchmark, codebase, prompts and models predictions are all publicly available at: this https URL ",
    "url": "https://arxiv.org/abs/2508.11133",
    "authors": [
      "Tomer Wolfson",
      "Harsh Trivedi",
      "Mor Geva",
      "Yoav Goldberg",
      "Dan Roth",
      "Tushar Khot",
      "Ashish Sabharwal",
      "Reut Tsarfaty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2508.12232",
    "title": "LinkAnchor: An Autonomous LLM-Based Agent for Issue-to-Commit Link Recovery",
    "abstract": "           Issue-to-commit link recovery plays an important role in software traceability and improves project management. However, it remains a challenging task. A study on GitHub shows that only 42.2% of the issues are correctly linked to their commits. This highlights the potential for further development and research in this area. Existing studies have employed various AI/ML-based approaches, and with the recent development of large language models, researchers have leveraged LLMs to tackle this problem. These approaches suffer from two main issues. First, LLMs are constrained by limited context windows and cannot ingest all of the available data sources, such as long commit histories, extensive issue comments, and large code repositories. Second, most methods operate on individual issue-commit pairs; that is, given a single issue-commit pair, they determine whether the commit resolves the issue. This quickly becomes impractical in real-world repositories containing tens of thousands of commits. To address these limitations, we present LinkAnchor, the first autonomous LLM-based agent designed for issue-to-commit link recovery. The lazy-access architecture of LinkAnchor enables the underlying LLM to access the rich context of software, spanning commits, issue comments, and code files, without exceeding the token limit by dynamically retrieving only the most relevant contextual data. Additionally, LinkAnchor is able to automatically pinpoint the target commit rather than exhaustively scoring every possible candidate. Our evaluations show that LinkAnchor outperforms state-of-the-art issue-to-commit link recovery approaches by 60-262% in Hit@1 score across all our case study projects. We also publicly release LinkAnchor as a ready-to-use tool, along with our replication package. LinkAnchor is designed and tested for GitHub and Jira, and is easily extendable to other platforms.         ",
    "url": "https://arxiv.org/abs/2508.12232",
    "authors": [
      "Arshia Akhavan",
      "Alireza Hosseinpour",
      "Abbas Heydarnoori",
      "Mehdi Keshani"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2508.19352",
    "title": "Memorization in Graph Neural Networks",
    "abstract": "           Deep neural networks (DNNs) have been shown to memorize their training data, yet similar analyses for graph neural networks (GNNs) remain largely under-explored. We introduce NCMemo (Node Classification Memorization), the first framework to quantify label memorization in semi-supervised node classification. We first establish an inverse relationship between memorization and graph homophily, i.e., the property that connected nodes share similar labels/features. We find that lower homophily significantly increases memorization, indicating that GNNs rely on memorization to learn less homophilic graphs. Secondly, we analyze GNN training dynamics. We find that the increased memorization in low homophily graphs is tightly coupled to the GNNs' implicit bias on using graph structure during learning. In low homophily regimes, this structure is less informative, hence inducing memorization of the node labels to minimize training loss. Finally, we show that nodes with higher label inconsistency in their feature-space neighborhood are significantly more prone to memorization. Building on our insights into the link between graph homophily and memorization, we investigate graph rewiring as a means to mitigate memorization. Our results demonstrate that this approach effectively reduces memorization without compromising model performance. Moreover, we show that it lowers the privacy risk for previously memorized data points in practice. Thus, our work not only advances understanding of GNN learning but also supports more privacy-preserving GNN deployment.         ",
    "url": "https://arxiv.org/abs/2508.19352",
    "authors": [
      "Adarsh Jamadandi",
      "Jing Xu",
      "Adam Dziedzic",
      "Franziska Boenisch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2508.19493",
    "title": "Mind the Third Eye! Benchmarking Privacy Awareness in MLLM-powered Smartphone Agents",
    "abstract": "           Smartphones bring significant convenience to users but also enable devices to extensively record various types of personal information. Existing smartphone agents powered by Multimodal Large Language Models (MLLMs) have achieved remarkable performance in automating different tasks. However, as the cost, these agents are granted substantial access to sensitive users' personal information during this operation. To gain a thorough understanding of the privacy awareness of these agents, we present the first large-scale benchmark encompassing 7,138 scenarios to the best of our knowledge. In addition, for privacy context in scenarios, we annotate its type (e.g., Account Credentials), sensitivity level, and location. We then carefully benchmark seven available mainstream smartphone agents. Our results demonstrate that almost all benchmarked agents show unsatisfying privacy awareness (RA), with performance remaining below 60% even with explicit hints. Overall, closed-source agents show better privacy ability than open-source ones, and Gemini 2.0-flash achieves the best, achieving an RA of 67%. We also find that the agents' privacy detection capability is highly related to scenario sensitivity level, i.e., the scenario with a higher sensitivity level is typically more identifiable. We hope the findings enlighten the research community to rethink the unbalanced utility-privacy tradeoff about smartphone agents. Our code and benchmark are available at this https URL.         ",
    "url": "https://arxiv.org/abs/2508.19493",
    "authors": [
      "Zhixin Lin",
      "Jungang Li",
      "Shidong Pan",
      "Yibo Shi",
      "Yue Yao",
      "Dongliang Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2508.19855",
    "title": "Youtu-GraphRAG: Vertically Unified Agents for Graph Retrieval-Augmented Complex Reasoning",
    "abstract": "           Graph retrieval-augmented generation (GraphRAG) has effectively enhanced large language models in complex reasoning by organizing fragmented knowledge into explicitly structured graphs. Prior efforts have been made to improve either graph construction or graph retrieval in isolation, yielding suboptimal performance, especially when domain shifts occur. In this paper, we propose a vertically unified agentic paradigm, Youtu-GraphRAG, to jointly connect the entire framework as an intricate integration. Specifically, (i) a seed graph schema is introduced to bound the automatic extraction agent with targeted entity types, relations and attribute types, also continuously expanded for scalability over unseen domains; (ii) To obtain higher-level knowledge upon the schema, we develop novel dually-perceived community detection, fusing structural topology with subgraph semantics for comprehensive knowledge organization. This naturally yields a hierarchical knowledge tree that supports both top-down filtering and bottom-up reasoning with community summaries; (iii) An agentic retriever is designed to interpret the same graph schema to transform complex queries into tractable and parallel sub-queries. It iteratively performs reflection for more advanced reasoning; (iv) To alleviate the knowledge leaking problem in pre-trained LLM, we propose a tailored anonymous dataset and a novel 'Anonymity Reversion' task that deeply measures the real performance of the GraphRAG frameworks. Extensive experiments across six challenging benchmarks demonstrate the robustness of Youtu-GraphRAG, remarkably moving the Pareto frontier with up to 90.71% saving of token costs and 16.62% higher accuracy over state-of-the-art baselines. The results indicate our adaptability, allowing seamless domain transfer with minimal intervention on schema.         ",
    "url": "https://arxiv.org/abs/2508.19855",
    "authors": [
      "Junnan Dong",
      "Siyu An",
      "Yifei Yu",
      "Qian-Wen Zhang",
      "Linhao Luo",
      "Xiao Huang",
      "Yunsheng Wu",
      "Di Yin",
      "Xing Sun"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2508.20757",
    "title": "GUARD: Glocal Uncertainty-Aware Robust Decoding for Effective and Efficient Open-Ended Text Generation",
    "abstract": "           Open-ended text generation faces a critical challenge: balancing coherence with diversity in LLM outputs. While contrastive search-based decoding strategies have emerged to address this trade-off, their practical utility is often limited by hyperparameter dependence and high computational costs. We introduce GUARD, a self-adaptive decoding method that effectively balances these competing objectives through a novel \"Glocal\" uncertainty-driven framework. GUARD combines global entropy estimates with local entropy deviations to integrate both long-term and short-term uncertainty signals. We demonstrate that our proposed global entropy formulation effectively mitigates abrupt variations in uncertainty, such as sudden overconfidence or high entropy spikes, and provides theoretical guarantees of unbiasedness and consistency. To reduce computational overhead, we incorporate a simple yet effective token-count-based penalty into GUARD. Experimental results demonstrate that GUARD achieves a good balance between text diversity and coherence, while exhibiting substantial improvements in generation speed. In a more nuanced comparison study across different dimensions of text quality, both human and LLM evaluators validated its remarkable performance. Our code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2508.20757",
    "authors": [
      "Yuanhao Ding",
      "Esteban Garces Arias",
      "Meimingwei Li",
      "Julian Rodemann",
      "Matthias A\u00dfenmacher",
      "Danlu Chen",
      "Gaojuan Fan",
      "Christian Heumann",
      "Chongsheng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2508.21236",
    "title": "Population-Scale Network Embeddings Expose Educational Divides in Network Structure Related to Right-Wing Populist Voting",
    "abstract": "           Administrative registry data can be used to construct population-scale networks whose ties reflect shared social contexts between persons. With machine learning, such networks can be encoded into numerical representations -- embeddings -- that automatically capture individuals' position within the network. We created embeddings for all persons in the Dutch population from a population-scale network that represents five shared contexts: neighborhood, work, family, household, and school. To assess the informativeness of these embeddings, we used them to predict right-wing populist voting. Embeddings alone predicted right-wing populist voting above chance-level but performed worse than individual characteristics. Combining the best subset of embeddings with individual characteristics only slightly improved predictions. After transforming the embeddings to make their dimensions more sparse and orthogonal, we found that one embedding dimension was strongly associated with the outcome. Mapping this dimension back to the population network revealed differences in network structure related to right-wing populist voting between different school ties and achieved education levels. Our study contributes methodologically by demonstrating how population-scale network embeddings can be made interpretable, and substantively by linking structural network differences in education to right-wing populist voting.         ",
    "url": "https://arxiv.org/abs/2508.21236",
    "authors": [
      "Malte L\u00fcken",
      "Javier Garcia-Bernardo",
      "Sreeparna Deb",
      "Flavio Hafner",
      "Megha Khosla"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2509.00367",
    "title": "A Multimodal and Multi-centric Head and Neck Cancer Dataset for Tumor Segmentation and Outcome Prediction",
    "abstract": "           We describe a publicly available multimodal dataset of annotated Positron Emission Tomography/Computed Tomography (PET/CT) studies for head and neck cancer research. The dataset includes 1123 FDG-PET/CT studies from patients with histologically confirmed head and neck cancer, acquired from 10 international medical centers. All examinations consisted of co-registered PET/CT scans with varying acquisition protocols, reflecting real-world clinical diversity across institutions. Primary gross tumor volumes (GTVp) and involved lymph nodes (GTVn) were manually segmented by experienced radiation oncologists and radiologists following standardized guidelines and quality control measures. We provide anonymized NifTi files of all studies, along with expert-annotated segmentation masks, radiotherapy dose distribution for a subset of patients, and comprehensive clinical metadata. This metadata includes TNM staging, HPV status, demographics (age and gender), long-term follow-up outcomes, survival times, censoring indicators, and treatment information. We demonstrate how this dataset can be used for three key clinical tasks: automated tumor segmentation, recurrence-free survival prediction, and HPV status classification, providing benchmark results using state-of-the-art deep learning models, including UNet, SegResNet, and multimodal prognostic frameworks.         ",
    "url": "https://arxiv.org/abs/2509.00367",
    "authors": [
      "Numan Saeed",
      "Salma Hassan",
      "Shahad Hardan",
      "Ahmed Aly",
      "Darya Taratynova",
      "Umair Nawaz",
      "Ufaq Khan",
      "Muhammad Ridzuan",
      "Vincent Andrearczyk",
      "Adrien Depeursinge",
      "Mathieu Hatt",
      "Thomas Eugene",
      "Rapha\u00ebl Metz",
      "M\u00e9lanie Dore",
      "Gregory Delpon",
      "Vijay Ram Kumar Papineni",
      "Kareem Wahid",
      "Cem Dede",
      "Alaa Mohamed Shawky Ali",
      "Carlos Sjogreen",
      "Mohamed Naser",
      "Clifton D. Fuller",
      "Valentin Oreiller",
      "Mario Jreige",
      "John O. Prior",
      "Catherine Cheze Le Rest",
      "Olena Tankyevych",
      "Pierre Decazes",
      "Su Ruan",
      "Stephanie Tanadini-Lang",
      "Martin Valli\u00e8res",
      "Hesham Elhalawani",
      "Ronan Abgral",
      "Romain Floch",
      "Kevin Kerleguer",
      "Ulrike Schick",
      "Maelle Mauguen",
      "Arman Rahmim",
      "Mohammad Yaqub"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.00578",
    "title": "C-DiffDet+: Fusing Global Scene Context with Generative Denoising for High-Fidelity Object Detection",
    "abstract": "           Fine-grained object detection in challenging visual domains, such as vehicle damage assessment, presents a formidable challenge even for human experts to resolve reliably. While DiffusionDet has advanced the state-of-the-art through conditional denoising diffusion, its performance remains limited by local feature conditioning in context-dependent scenarios. We address this fundamental limitation by introducing Context-Aware Fusion (CAF), which leverages cross-attention mechanisms to integrate global scene context with local proposal features directly. The global context is generated using a separate dedicated encoder that captures comprehensive environmental information, enabling each object proposal to attend to scene-level understanding. Our framework significantly enhances the generative detection paradigm by enabling each object proposal to attend to comprehensive environmental information. Experimental results demonstrate an improvement over state-of-the-art models on the CarDD benchmark, establishing new performance benchmarks for context-aware object detection in fine-grained domains         ",
    "url": "https://arxiv.org/abs/2509.00578",
    "authors": [
      "Abdellah Zakaria Sellam",
      "Ilyes Benaissa",
      "Salah Eddine Bekhouche",
      "Abdenour Hadid",
      "Vito Ren\u00f3",
      "Cosimo Distante"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2509.00868",
    "title": "A Modular and Scalable Simulator for Connected-UAVs Communication in 5G Networks",
    "abstract": "           Cellular-connected UAV systems have enabled a wide range of low-altitude aerial services. However, these systems still face many challenges, such as frequent handovers and the inefficiency of traditional transport protocols. To better study these issues, we develop a modular and scalable simulation platform specifically designed for UAVs communication leveraging the research ecology in wireless communication of MATLAB. The platform supports flexible 5G NR node deployment, customizable UAVs mobility models, and multi-network-interface extensions. It also supports multiple transport protocols including TCP, UDP, QUIC, etc., allowing to investigate how different transport protocols affect UAVs communication performance. In addition, the platform includes a handover management module, enabling the evaluation of both traditional and learning-based handover strategies. Our platform can serve as a testbed for the development and evaluation of advanced transmission strategies in cellular-connected UAV systems.         ",
    "url": "https://arxiv.org/abs/2509.00868",
    "authors": [
      "Yong Su",
      "Yiyi Chen",
      "Shenghong Yi",
      "Hui Feng",
      "Yuedong Xu",
      "Wang Xiang",
      "Bo Hu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2509.00905",
    "title": "Spotlighter: Revisiting Prompt Tuning from a Representative Mining View",
    "abstract": "           CLIP's success has demonstrated that prompt tuning can achieve robust cross-modal semantic alignment for tasks ranging from open-domain recognition to fine-grained classification. However, redundant or weakly relevant feature components introduce noise and incur unnecessary computational costs. In this work, we propose Spotlighter, a lightweight token-selection framework that simultaneously enhances accuracy and efficiency in prompt tuning. Spotlighter evaluates each visual token's activation from both sample-wise and semantic-wise perspectives and retains only the top-scoring tokens for downstream prediction. A class-specific semantic memory bank of learned prototypes refines this selection, ensuring semantic representativeness and compensating for discarded features. To further prioritize informative signals, we introduce a two-level ranking mechanism that dynamically weights token--prototype interactions. Across 11 few-shot benchmarks, Spotlighter outperforms CLIP by up to 11.19\\% in harmonic mean accuracy and achieves up to 0.8K additional FPS, with only 21 extra parameters. These results establish Spotlighter as an effective and scalable baseline for prompt tuning. Code for our method will be available at this https URL.         ",
    "url": "https://arxiv.org/abs/2509.00905",
    "authors": [
      "Yutong Gao",
      "Maoyuan Shao",
      "Xinyang Huang",
      "Chuang Zhu",
      "Lijuan Sun",
      "Yu Weng",
      "Xuan Liu",
      "Guoshun Nan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2509.01293",
    "title": "Equivariant U-Shaped Neural Operators for the Cahn-Hilliard Phase-Field Model",
    "abstract": "           Phase separation in binary mixtures, governed by the Cahn-Hilliard equation, plays a central role in interfacial dynamics across materials science and soft matter. While numerical solvers are accurate, they are often computationally expensive and lack flexibility across varying initial conditions and geometries. Neural operators provide a data-driven alternative by learning solution operators between function spaces, but current architectures often fail to capture multiscale behavior and neglect underlying physical symmetries. Here we show that an equivariant U-shaped neural operator (E-UNO) can learn the evolution of the phase-field variable from short histories of past dynamics, achieving accurate predictions across space and time. The model combines global spectral convolution with a multi-resolution U-shaped architecture and regulates translation equivariance to align with the underlying physics. E-UNO outperforms standard Fourier neural operator and U-shaped neural operator baselines, particularly on fine-scale and high-frequency structures. By encoding symmetry and scale hierarchy, the model generalizes better, requires less training data, and yields physically consistent dynamics. This establishes E-UNO as an efficient surrogate for complex phase-field systems.         ",
    "url": "https://arxiv.org/abs/2509.01293",
    "authors": [
      "Xiao Xue",
      "M.F.P. ten Eikelder",
      "Tianyue Yang",
      "Yiqing Li",
      "Kan He",
      "Shuo Wang",
      "Peter V. Coveney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2509.02028",
    "title": "See No Evil: Adversarial Attacks Against Linguistic-Visual Association in Referring Multi-Object Tracking Systems",
    "abstract": "           Language-vision understanding has driven the development of advanced perception systems, most notably the emerging paradigm of Referring Multi-Object Tracking (RMOT). By leveraging natural-language queries, RMOT systems can selectively track objects that satisfy a given semantic description, guided through Transformer-based spatial-temporal reasoning modules. End-to-End (E2E) RMOT models further unify feature extraction, temporal memory, and spatial reasoning within a Transformer backbone, enabling long-range spatial-temporal modeling over fused textual-visual representations. Despite these advances, the reliability and robustness of RMOT remain underexplored. In this paper, we examine the security implications of RMOT systems from a design-logic perspective, identifying adversarial vulnerabilities that compromise both the linguistic-visual referring and track-object matching components. Additionally, we uncover a novel vulnerability in advanced RMOT models employing FIFO-based memory, whereby targeted and consistent attacks on their spatial-temporal reasoning introduce errors that persist within the history buffer over multiple subsequent frames. We present VEIL, a novel adversarial framework designed to disrupt the unified referring-matching mechanisms of RMOT models. We show that carefully crafted digital and physical perturbations can corrupt the tracking logic reliability, inducing track ID switches and terminations. We conduct comprehensive evaluations using the Refer-KITTI dataset to validate the effectiveness of VEIL and demonstrate the urgent need for security-aware RMOT designs for critical large-scale applications.         ",
    "url": "https://arxiv.org/abs/2509.02028",
    "authors": [
      "Halima Bouzidi",
      "Haoyu Liu",
      "Mohammad Abdullah Al Faruque"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2509.02499",
    "title": "MoSEs: Uncertainty-Aware AI-Generated Text Detection via Mixture of Stylistics Experts with Conditional Thresholds",
    "abstract": "           The rapid advancement of large language models has intensified public concerns about the potential misuse. Therefore, it is important to build trustworthy AI-generated text detection systems. Existing methods neglect stylistic modeling and mostly rely on static thresholds, which greatly limits the detection performance. In this paper, we propose the Mixture of Stylistic Experts (MoSEs) framework that enables stylistics-aware uncertainty quantification through conditional threshold estimation. MoSEs contain three core components, namely, the Stylistics Reference Repository (SRR), the Stylistics-Aware Router (SAR), and the Conditional Threshold Estimator (CTE). For input text, SRR can activate the appropriate reference data in SRR and provide them to CTE. Subsequently, CTE jointly models the linguistic statistical properties and semantic features to dynamically determine the optimal threshold. With a discrimination score, MoSEs yields prediction labels with the corresponding confidence level. Our framework achieves an average improvement 11.34% in detection performance compared to baselines. More inspiringly, MoSEs shows a more evident improvement 39.15% in the low-resource case. Our code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2509.02499",
    "authors": [
      "Junxi Wu",
      "Jinpeng Wang",
      "Zheng Liu",
      "Bin Chen",
      "Dongjian Hu",
      "Hao Wu",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2409.00827",
    "title": "Log-concavity of the independence polynomials of $\\mathbf{W}_{p}$ graphs",
    "abstract": "           Let $G$ be a graph of order $n$. For a positive integer $p$, $G$ is said to be a $\\mathbf{W}_{p}$ graph if $n\\geq p$ and every $p$ pairwise disjoint independent sets of $G$ are contained within $p$ pairwise disjoint maximum independent sets. In this paper, we establish that every connected $\\mathbf{W}_{p}$ graph $G$ is $p$-quasi-regularizable if and only if $n\\geq(p+1)\\cdot\\alpha$, where $\\alpha$ is the independence number of $G$ and $p\\neq2$. This finding ensures that the independence polynomial of a connected $\\mathbf{W}_{p}$ graph $G$ is log-concave whenever $(p+1)\\cdot\\alpha\\leq n\\leq p\\cdot\\alpha+2\\sqrt{p\\cdot\\alpha+p}$ and $\\frac{\\alpha^{2}}{4\\left( \\alpha+1\\right) }\\leq p$, or $p\\cdot\\alpha+2\\sqrt{p\\cdot\\alpha+p}<n\\leq \\frac{\\left( \\alpha^{2}+1\\right) \\cdot p+\\left( \\alpha-1\\right) ^{2}}{\\alpha-1}$ and $\\frac{\\alpha\\left( \\alpha-1\\right) }{\\alpha+1}\\leq p$. Moreover, the clique corona graph $G\\circ K_{p}$ serves as an example of the $\\mathbf{W}_{p}$ graph class. We further demonstrate that the independence polynomial of $G\\circ K_{p}$ is always log-concave for sufficiently large $p$. Keywords: very well-covered graph; quasi-regularizable graph; corona graph; $\\mathbf{W}_{p}$ graph; independence polynomial; log-concavity.         ",
    "url": "https://arxiv.org/abs/2409.00827",
    "authors": [
      "Do Trong Hoang",
      "Vadim E. Levit",
      "Eugen Mandrescu",
      "My Hanh Pham"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2412.02670",
    "title": "The Broader Landscape of Robustness in Algorithmic Statistics",
    "abstract": "           The last decade has seen a number of advances in computationally efficient algorithms for statistical methods subject to robustness constraints. An estimator may be robust in a number of different ways: to contamination of the dataset, to heavy-tailed data, or in the sense that it preserves privacy of the dataset. We survey recent results in these areas with a focus on the problem of mean estimation, drawing technical and conceptual connections between the various forms of robustness, showing that the same underlying algorithmic ideas lead to computationally efficient estimators in all these settings.         ",
    "url": "https://arxiv.org/abs/2412.02670",
    "authors": [
      "Gautam Kamath"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2501.01483",
    "title": "Embedding Similarity Guided License Plate Super Resolution",
    "abstract": "           Super-resolution (SR) techniques play a pivotal role in enhancing the quality of low-resolution images, particularly for applications such as security and surveillance, where accurate license plate recognition is crucial. This study proposes a novel framework that combines pixel-based loss with embedding similarity learning to address the unique challenges of license plate super-resolution (LPSR). The introduced pixel and embedding consistency loss (PECL) integrates a Siamese network and applies contrastive loss to force embedding similarities to improve perceptual and structural fidelity. By effectively balancing pixel-wise accuracy with embedding-level consistency, the framework achieves superior alignment of fine-grained features between high-resolution (HR) and super-resolved (SR) license plates. Extensive experiments on the CCPD and PKU dataset validate the efficacy of the proposed framework, demonstrating consistent improvements over state-of-the-art methods in terms of PSNR, SSIM, LPIPS, and optical character recognition (OCR) accuracy. These results highlight the potential of embedding similarity learning to advance both perceptual quality and task-specific performance in extreme super-resolution scenarios.         ",
    "url": "https://arxiv.org/abs/2501.01483",
    "authors": [
      "Abderrezzaq Sendjasni",
      "Mohamed-Chaker Larabi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2501.03379",
    "title": "The hard-core model in graph theory",
    "abstract": "           An independent set may not contain both a vertex and one of its neighbours. This basic fact makes the uniform distribution over independent sets rather special. We consider the hard-core model, an essential generalization of the uniform distribution over independent sets. We show how its local analysis yields remarkable insights into the global structure of independent sets in the host graph, in connection with, for instance, Ramsey numbers, graph colourings, and sphere packings.         ",
    "url": "https://arxiv.org/abs/2501.03379",
    "authors": [
      "Ewan Davies",
      "Ross J. Kang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2502.21269",
    "title": "Dynamical Decoupling of Generalization and Overfitting in Large Two-Layer Networks",
    "abstract": "           Understanding the inductive bias and generalization properties of large overparametrized machine learning models requires to characterize the dynamics of the training algorithm. We study the learning dynamics of large two-layer neural networks via dynamical mean field theory, a well established technique of non-equilibrium statistical physics. We show that, for large network width, the training dynamics exhibits a separation of timescales which implies: $(i)$ The emergence of a slow time scale associated with the growth in Gaussian/Rademacher complexity of the network; $(ii)$ Inductive bias towards small complexity if the initialization has small enough complexity; $(iii)$ A dynamical decoupling between feature learning and overfitting regimes; $(iv)$ A non-monotone behavior of the test error, associated `feature unlearning' regime at large times.         ",
    "url": "https://arxiv.org/abs/2502.21269",
    "authors": [
      "Andrea Montanari",
      "Pierfrancesco Urbani"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.22896",
    "title": "Representation and Stability Analysis of 1D PDEs with Periodic Boundary Conditions",
    "abstract": "           PDEs with periodic boundary conditions are frequently used to model processes in large spatial environments, assuming solutions to extend periodically beyond some bounded interval. However, solutions to these PDEs often do not converge to a unique equilibrium, but instead converge to non-stationary trajectories existing in the nullspace of the spatial differential operator (e.g. $\\frac{\\partial^2}{\\partial x^2}$). To analyse this convergence behaviour, in this paper, it is shown how such trajectories can be modeled for a broad class of linear, 2nd order, 1D PDEs with periodic as well as more general boundary conditions, using the Partial Integral Equation (PIE) representation. In particular, it is first shown how any PDE state satisfying these boundary conditions can be uniquely expressed in terms of two components, existing in the image and the nullspace of the differential operator $\\frac{\\partial^2}{\\partial x^2}$, respectively. An equivalent representation of linear PDEs is then derived as a PIE, explicitly defining the dynamics of both state components. Finally, a notion of exponential stability is defined that requires only one of the state components to converge to zero, and it is shown how this stability notion can be tested by solving a linear operator inequality. The proposed methodology is applied to examples of heat and wave equations, demonstrating that exponential stability can be verified with tight bounds on the rate of decay.         ",
    "url": "https://arxiv.org/abs/2503.22896",
    "authors": [
      "Declan Jagt",
      "Sergei Chernyshenko",
      "Matthew Peet"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2505.16893",
    "title": "Statistical Test for Saliency Maps of Graph Neural Networks via Selective Inference",
    "abstract": "           Graph Neural Networks (GNNs) have gained prominence for their ability to process graph-structured data across various domains. However, interpreting GNN decisions remains a significant challenge, leading to the adoption of saliency maps for identifying salient subgraphs composed of influential nodes and edges. Despite their utility, the reliability of GNN saliency maps has been questioned, particularly in terms of their robustness to input noise. In this study, we propose a statistical testing framework to rigorously evaluate the significance of saliency maps. Our main contribution lies in addressing the inflation of the Type I error rate caused by double-dipping of data, leveraging the framework of Selective Inference. Our method provides statistically valid $p$-values while controlling the Type I error rate, ensuring that identified salient subgraphs contain meaningful information rather than random artifacts. The method is applicable to a variety of saliency methods with piecewise linearity (e.g., Class Activation Mapping). We validate our method on synthetic and real-world datasets, demonstrating its capability in assessing the reliability of GNN interpretations.         ",
    "url": "https://arxiv.org/abs/2505.16893",
    "authors": [
      "Shuichi Nishino",
      "Tomohiro Shiraishi",
      "Teruyuki Katsuoka",
      "Ichiro Takeuchi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.10383",
    "title": "Dynamical stability for dense patterns in discrete attractor neural networks",
    "abstract": "           Neural networks storing multiple discrete attractors are canonical models of biological memory. Previously, the dynamical stability of such networks could only be guaranteed under highly restrictive conditions. Here, we derive a theory of the local stability of discrete fixed points in a broad class of networks with graded neural activities and in the presence of noise. By directly analyzing the bulk and outliers of the Jacobian spectrum, we show that all fixed points are stable below a critical load that is distinct from the classical \\textit{critical capacity} and depends on the statistics of neural activities in the fixed points as well as the single-neuron activation function. Our analysis highlights the computational benefits of threshold-linear activation and sparse-like patterns.         ",
    "url": "https://arxiv.org/abs/2507.10383",
    "authors": [
      "Uri Cohen",
      "M\u00e1t\u00e9 Lengyel"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2508.19660",
    "title": "Arbitrary Precision Printed Ternary Neural Networks with Holistic Evolutionary Approximation",
    "abstract": "           Printed electronics offer a promising alternative for applications beyond silicon-based systems, requiring properties like flexibility, stretchability, conformality, and ultra-low fabrication costs. Despite the large feature sizes in printed electronics, printed neural networks have attracted attention for meeting target application requirements, though realizing complex circuits remains challenging. This work bridges the gap between classification accuracy and area efficiency in printed neural networks, covering the entire processing-near-sensor system design and co-optimization from the analog-to-digital interface-a major area and power bottleneck-to the digital classifier. We propose an automated framework for designing printed Ternary Neural Networks with arbitrary input precision, utilizing multi-objective optimization and holistic approximation. Our circuits outperform existing approximate printed neural networks by 17x in area and 59x in power on average, being the first to enable printed-battery-powered operation with under 5% accuracy loss while accounting for analog-to-digital interfacing costs.         ",
    "url": "https://arxiv.org/abs/2508.19660",
    "authors": [
      "Vojtech Mrazek",
      "Konstantinos Balaskas",
      "Paula Carolina Lozano Duarte",
      "Zdenek Vasicek",
      "Mehdi B. Tahoori",
      "Georgios Zervakis"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2509.01057",
    "title": "Q-Learning-Driven Adaptive Rewiring for Cooperative Control in Heterogeneous Networks",
    "abstract": "           Cooperation emergence in multi-agent systems represents a fundamental statistical physics problem where microscopic learning rules drive macroscopic collective behavior transitions. We propose a Q-learning-based variant of adaptive rewiring that builds on mechanisms studied in the literature. This method combines temporal difference learning with network restructuring so that agents can optimize strategies and social connections based on interaction histories. Through neighbor-specific Q-learning, agents develop sophisticated partnership management strategies that enable cooperator cluster formation, creating spatial separation between cooperative and defective regions. Using power-law networks that reflect real-world heterogeneous connectivity patterns, we evaluate emergent behaviors under varying rewiring constraint levels, revealing distinct cooperation patterns across parameter space rather than sharp thermodynamic transitions. Our systematic analysis identifies three behavioral regimes: a permissive regime (low constraints) enabling rapid cooperative cluster formation, an intermediate regime with sensitive dependence on dilemma strength, and a patient regime (high constraints) where strategic accumulation gradually optimizes network structure. Simulation results show that while moderate constraints create transition-like zones that suppress cooperation, fully adaptive rewiring enhances cooperation levels through systematic exploration of favorable network configurations. Quantitative analysis reveals that increased rewiring frequency drives large-scale cluster formation with power-law size distributions. Our results establish a new paradigm for understanding intelligence-driven cooperation pattern formation in complex adaptive systems, revealing how machine learning serves as an alternative driving force for spontaneous organization in multi-agent networks.         ",
    "url": "https://arxiv.org/abs/2509.01057",
    "authors": [
      "Yi-Ning Weng",
      "Hsuan-Wei Lee"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]