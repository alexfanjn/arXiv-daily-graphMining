[
  {
    "id": "arXiv:2404.02923",
    "title": "An Unsupervised Adversarial Autoencoder for Cyber Attack Detection in  Power Distribution Grids",
    "abstract": "Detection of cyber attacks in smart power distribution grids with unbalanced configurations poses challenges due to the inherent nonlinear nature of these uncertain and stochastic systems. It originates from the intermittent characteristics of the distributed energy resources (DERs) generation and load variations. Moreover, the unknown behavior of cyber attacks, especially false data injection attacks (FDIAs) in the distribution grids with complex temporal correlations and the limited amount of labeled data increases the vulnerability of the grids and imposes a high risk in the secure and reliable operation of the grids. To address these challenges, this paper proposes an unsupervised adversarial autoencoder (AAE) model to detect FDIAs in unbalanced power distribution grids integrated with DERs, i.e., PV systems and wind generation. The proposed method utilizes long short-term memory (LSTM) in the structure of the autoencoder to capture the temporal dependencies in the time-series measurements and leverages the power of generative adversarial networks (GANs) for better reconstruction of the input data. The advantage of the proposed data-driven model is that it can detect anomalous points for the system operation without reliance on abstract models or mathematical representations. To evaluate the efficacy of the approach, it is tested on IEEE 13-bus and 123-bus systems with historical meteorological data (wind speed, ambient temperature, and solar irradiance) as well as historical real-world load data under three types of data falsification functions. The comparison of the detection results of the proposed model with other unsupervised learning methods verifies its superior performance in detecting cyber attacks in unbalanced power distribution grids. ",
    "url": "https://arxiv.org/abs/2404.02923",
    "authors": [
      "Mehdi Jabbari Zideh",
      "Mohammad Reza Khalghani",
      "Sarika Khushalani Solanki"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2404.02928",
    "title": "Jailbreaking Prompt Attack: A Controllable Adversarial Attack against  Diffusion Models",
    "abstract": "The fast advance of the image generation community has attracted attention worldwide. The safety issue needs to be further scrutinized and studied. There have been a few works around this area mostly achieving a post-processing design, model-specific, or yielding suboptimal image quality generation. Despite that, in this article, we discover a black-box attack method that enjoys three merits. It enables (i)-attacks both directed and semantic-driven that theoretically and practically pose a hazard to this vast user community, (ii)-surprisingly surpasses the white-box attack in a black-box manner and (iii)-without requiring any post-processing effort. Core to our approach is inspired by the concept guidance intriguing property of Classifier-Free guidance (CFG) in T2I models, and we discover that conducting frustratingly simple guidance in the CLIP embedding space, coupled with the semantic loss and an additionally sensitive word list works very well. Moreover, our results expose and highlight the vulnerabilities in existing defense mechanisms. ",
    "url": "https://arxiv.org/abs/2404.02928",
    "authors": [
      "Jiachen Ma",
      "Anda Cao",
      "Zhiqing Xiao",
      "Jie Zhang",
      "Chao Ye",
      "Junbo Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.02931",
    "title": "READ: Improving Relation Extraction from an ADversarial Perspective",
    "abstract": "Recent works in relation extraction (RE) have achieved promising benchmark accuracy; however, our adversarial attack experiments show that these works excessively rely on entities, making their generalization capability questionable. To address this issue, we propose an adversarial training method specifically designed for RE. Our approach introduces both sequence- and token-level perturbations to the sample and uses a separate perturbation vocabulary to improve the search for entity and context perturbations. Furthermore, we introduce a probabilistic strategy for leaving clean tokens in the context during adversarial training. This strategy enables a larger attack budget for entities and coaxes the model to leverage relational patterns embedded in the context. Extensive experiments show that compared to various adversarial training methods, our method significantly improves both the accuracy and robustness of the model. Additionally, experiments on different data availability settings highlight the effectiveness of our method in low-resource scenarios. We also perform in-depth analyses of our proposed method and provide further hints. We will release our code at https://github.com/David-Li0406/READ. ",
    "url": "https://arxiv.org/abs/2404.02931",
    "authors": [
      "Dawei Li",
      "William Hogan",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.02935",
    "title": "KnowHalu: Hallucination Detection via Multi-Form Knowledge Based Factual  Checking",
    "abstract": "This paper introduces KnowHalu, a novel approach for detecting hallucinations in text generated by large language models (LLMs), utilizing step-wise reasoning, multi-formulation query, multi-form knowledge for factual checking, and fusion-based detection mechanism. As LLMs are increasingly applied across various domains, ensuring that their outputs are not hallucinated is critical. Recognizing the limitations of existing approaches that either rely on the self-consistency check of LLMs or perform post-hoc fact-checking without considering the complexity of queries or the form of knowledge, KnowHalu proposes a two-phase process for hallucination detection. In the first phase, it identifies non-fabrication hallucinations--responses that, while factually correct, are irrelevant or non-specific to the query. The second phase, multi-form based factual checking, contains five key steps: reasoning and query decomposition, knowledge retrieval, knowledge optimization, judgment generation, and judgment aggregation. Our extensive evaluations demonstrate that KnowHalu significantly outperforms SOTA baselines in detecting hallucinations across diverse tasks, e.g., improving by 15.65% in QA tasks and 5.50% in summarization tasks, highlighting its effectiveness and versatility in detecting hallucinations in LLM-generated content. ",
    "url": "https://arxiv.org/abs/2404.02935",
    "authors": [
      "Jiawei Zhang",
      "Chejian Xu",
      "Yu Gai",
      "Freddy Lecue",
      "Dawn Song",
      "Bo Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.02937",
    "title": "Explainable Traffic Flow Prediction with Large Language Models",
    "abstract": "Traffic flow prediction provides essential future views in the intelligent transportation system. Explainable predictions offer valuable insights into the factors influencing traffic patterns, which help urban planners, traffic engineers, and policymakers make informed decisions about infrastructure development, traffic management strategies, and public transportation planning. Despite their widespread popularity and commendable accuracy, prediction methods grounded in deep learning frequently disappoint in terms of transparency and interpretability. Recently, the availability of large-scale spatio-temporal data and the development of large language models (LLMs) have opened up new opportunities for urban traffic prediction. With the popularity of LLMs, people witnessed the potential reasoning and generating ability of foundation models in various tasks. Considering text as input and output, LLMs have advantages in generating more intuitive and interpretable predictions. Hence, this work introduces TP-LLM, an explainable foundation-model-based method for traffic prediction, aiming at more direct and reasonable forecasting. TP-LLM presents a framework to unify multi-modality factors as language-based inputs, TP-LLM avoids complex spatial-temporal data programming and outperforms state-of-art baselines merely under fine-tuning foundation models. Also, TP-LLM can generate input-dependency explanations for more confident prediction and can be easily generalized to different city dynamics for zero-shot prediction with a similar framework. These findings demonstrate the potential of LLMs for explainable traffic prediction. ",
    "url": "https://arxiv.org/abs/2404.02937",
    "authors": [
      "Xusen Guo",
      "Qiming Zhang",
      "Mingxing Peng",
      "Meixin Zhua",
      "Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.02943",
    "title": "Learning in Convolutional Neural Networks Accelerated by Transfer  Entropy",
    "abstract": "Recently, there is a growing interest in applying Transfer Entropy (TE) in quantifying the effective connectivity between artificial neurons. In a feedforward network, the TE can be used to quantify the relationships between neuron output pairs located in different layers. Our focus is on how to include the TE in the learning mechanisms of a Convolutional Neural Network (CNN) architecture. We introduce a novel training mechanism for CNN architectures which integrates the TE feedback connections. Adding the TE feedback parameter accelerates the training process, as fewer epochs are needed. On the flip side, it adds computational overhead to each epoch. According to our experiments on CNN classifiers, to achieve a reasonable computational overhead--accuracy trade-off, it is efficient to consider only the inter-neural information transfer of a random subset of the neuron pairs from the last two fully connected layers. The TE acts as a smoothing factor, generating stability and becoming active only periodically, not after processing each input sample. Therefore, we can consider the TE is in our model a slowly changing meta-parameter. ",
    "url": "https://arxiv.org/abs/2404.02943",
    "authors": [
      "Adrian Moldovan",
      "Angel Ca\u0163aron",
      "R\u0103zvan Andonie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2404.02986",
    "title": "Universal Functional Regression with Neural Operator Flows",
    "abstract": "Regression on function spaces is typically limited to models with Gaussian process priors. We introduce the notion of universal functional regression, in which we aim to learn a prior distribution over non-Gaussian function spaces that remains mathematically tractable for functional regression. To do this, we develop Neural Operator Flows (OpFlow), an infinite-dimensional extension of normalizing flows. OpFlow is an invertible operator that maps the (potentially unknown) data function space into a Gaussian process, allowing for exact likelihood estimation of functional point evaluations. OpFlow enables robust and accurate uncertainty quantification via drawing posterior samples of the Gaussian process and subsequently mapping them into the data function space. We empirically study the performance of OpFlow on regression and generation tasks with data generated from Gaussian processes with known posterior forms and non-Gaussian processes, as well as real-world earthquake seismograms with an unknown closed-form distribution. ",
    "url": "https://arxiv.org/abs/2404.02986",
    "authors": [
      "Yaozhong Shi",
      "Angela F. Gao",
      "Zachary E. Ross",
      "Kamyar Azizzadenesheli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2404.03011",
    "title": "Transfer learning applications for anomaly detection in wind turbines",
    "abstract": "Anomaly detection in wind turbines typically involves using normal behaviour models to detect faults early. However, training autoencoder models for each turbine is time-consuming and resource intensive. Thus, transfer learning becomes essential for wind turbines with limited data or applications with limited computational resources. This study examines how cross-turbine transfer learning can be applied to autoencoder-based anomaly detection. Here, autoencoders are combined with constant thresholds for the reconstruction error to determine if input data contains an anomaly. The models are initially trained on one year's worth of data from one or more source wind turbines. They are then fine-tuned using smaller amounts of data from another turbine. Three methods for fine-tuning are investigated: adjusting the entire autoencoder, only the decoder, or only the threshold of the model. The performance of the transfer learning models is compared to baseline models that were trained on one year's worth of data from the target wind turbine. The results of the tests conducted in this study indicate that models trained on data of multiple wind turbines do not improve the anomaly detection capability compared to models trained on data of one source wind turbine. In addition, modifying the model's threshold can lead to comparable or even superior performance compared to the baseline, whereas fine-tuning the decoder or autoencoder further enhances the models' performance. ",
    "url": "https://arxiv.org/abs/2404.03011",
    "authors": [
      "Cyriana M.A. Roelofs",
      "Christian G\u00fcck",
      "Stefan Faulstich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.03015",
    "title": "DPFT: Dual Perspective Fusion Transformer for Camera-Radar-based Object  Detection",
    "abstract": "The perception of autonomous vehicles has to be efficient, robust, and cost-effective. However, cameras are not robust against severe weather conditions, lidar sensors are expensive, and the performance of radar-based perception is still inferior to the others. Camera-radar fusion methods have been proposed to address this issue, but these are constrained by the typical sparsity of radar point clouds and often designed for radars without elevation information. We propose a novel camera-radar fusion approach called Dual Perspective Fusion Transformer (DPFT), designed to overcome these limitations. Our method leverages lower-level radar data (the radar cube) instead of the processed point clouds to preserve as much information as possible and employs projections in both the camera and ground planes to effectively use radars with elevation information and simplify the fusion with camera data. As a result, DPFT has demonstrated state-of-the-art performance on the K-Radar dataset while showing remarkable robustness against adverse weather conditions and maintaining a low inference time. The code is made available as open-source software under https://github.com/TUMFTM/DPFT. ",
    "url": "https://arxiv.org/abs/2404.03015",
    "authors": [
      "Felix Fent",
      "Andras Palffy",
      "Holger Caesar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.03017",
    "title": "Distributionally Robust Policy and Lyapunov-Certificate Learning",
    "abstract": "This article presents novel methods for synthesizing distributionally robust stabilizing neural controllers and certificates for control systems under model uncertainty. A key challenge in designing controllers with stability guarantees for uncertain systems is the accurate determination of and adaptation to shifts in model parametric uncertainty during online deployment. We tackle this with a novel distributionally robust formulation of the Lyapunov derivative chance constraint ensuring a monotonic decrease of the Lyapunov certificate. To avoid the computational complexity involved in dealing with the space of probability measures, we identify a sufficient condition in the form of deterministic convex constraints that ensures the Lyapunov derivative constraint is satisfied. We integrate this condition into a loss function for training a neural network-based controller and show that, for the resulting closed-loop system, the global asymptotic stability of its equilibrium can be certified with high confidence, even with Out-of-Distribution (OoD) model uncertainties. To demonstrate the efficacy and efficiency of the proposed methodology, we compare it with an uncertainty-agnostic baseline approach and several reinforcement learning approaches in two control problems in simulation. ",
    "url": "https://arxiv.org/abs/2404.03017",
    "authors": [
      "Kehan Long",
      "Jorge Cortes",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2404.03019",
    "title": "GeoT: Tensor Centric Library for Graph Neural Network via Efficient  Segment Reduction on GPU",
    "abstract": "In recent years, Graph Neural Networks (GNNs) have ignited a surge of innovation, significantly enhancing the processing of geometric data structures such as graphs, point clouds, and meshes. As the domain continues to evolve, a series of frameworks and libraries are being developed to push GNN efficiency to new heights. While graph-centric libraries have achieved success in the past, the advent of efficient tensor compilers has highlighted the urgent need for tensor-centric libraries. Yet, efficient tensor-centric frameworks for GNNs remain scarce due to unique challenges and limitations encountered when implementing segment reduction in GNN contexts. We introduce GeoT, a cutting-edge tensor-centric library designed specifically for GNNs via efficient segment reduction. GeoT debuts innovative parallel algorithms that not only introduce new design principles but also expand the available design space. Importantly, GeoT is engineered for straightforward fusion within a computation graph, ensuring compatibility with contemporary tensor-centric machine learning frameworks and compilers. Setting a new performance benchmark, GeoT marks a considerable advancement by showcasing an average operator speedup of 1.80x and an end-to-end speedup of 1.68x. ",
    "url": "https://arxiv.org/abs/2404.03019",
    "authors": [
      "Zhongming Yu",
      "Genghan Zhang",
      "Hanxian Huang",
      "Xin Chen",
      "Jishen Zhao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.03025",
    "title": "When Digital Twin Meets Generative AI: Intelligent Closed-Loop Network  Management",
    "abstract": "Generative artificial intelligence (GAI) and digital twin (DT) are advanced data processing and virtualization technologies to revolutionize communication networks. Thanks to the powerful data processing capabilities of GAI, integrating it into DT is a potential approach to construct an intelligent holistic virtualized network for better network management performance. To this end, we propose a GAI-driven DT (GDT) network architecture to enable intelligent closed-loop network management. In the architecture, various GAI models can empower DT status emulation, feature abstraction, and network decision-making. The interaction between GAI-based and model-based data processing can facilitate intelligent external and internal closed-loop network management. To further enhance network management performance, three potential approaches are proposed, i.e., model light-weighting, adaptive model selection, and data-model-driven network management. We present a case study pertaining to data-model-driven network management for the GDT network, followed by some open research issues. ",
    "url": "https://arxiv.org/abs/2404.03025",
    "authors": [
      "Xinyu Huang",
      "Haojun Yang",
      "Conghao Zhou",
      "Xuemin Shen",
      "Weihua Zhuang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2404.03027",
    "title": "JailBreakV-28K: A Benchmark for Assessing the Robustness of MultiModal  Large Language Models against Jailbreak Attacks",
    "abstract": "With the rapid advancements in Multimodal Large Language Models (MLLMs), securing these models against malicious inputs while aligning them with human values has emerged as a critical challenge. In this paper, we investigate an important and unexplored question of whether techniques that successfully jailbreak Large Language Models (LLMs) can be equally effective in jailbreaking MLLMs. To explore this issue, we introduce JailBreakV-28K, a pioneering benchmark designed to assess the transferability of LLM jailbreak techniques to MLLMs, thereby evaluating the robustness of MLLMs against diverse jailbreak attacks. Utilizing a dataset of 2, 000 malicious queries that is also proposed in this paper, we generate 20, 000 text-based jailbreak prompts using advanced jailbreak attacks on LLMs, alongside 8, 000 image-based jailbreak inputs from recent MLLMs jailbreak attacks, our comprehensive dataset includes 28, 000 test cases across a spectrum of adversarial scenarios. Our evaluation of 10 open-source MLLMs reveals a notably high Attack Success Rate (ASR) for attacks transferred from LLMs, highlighting a critical vulnerability in MLLMs that stems from their text-processing capabilities. Our findings underscore the urgent need for future research to address alignment vulnerabilities in MLLMs from both textual and visual inputs. ",
    "url": "https://arxiv.org/abs/2404.03027",
    "authors": [
      "Weidi Luo",
      "Siyuan Ma",
      "Xiaogeng Liu",
      "Xiaoyu Guo",
      "Chaowei Xiao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.03033",
    "title": "Autonomous Vehicle Networks for More Reliable Truck Tracking in  Challenged High Mountain Roads, Tunnels and Bridges Environments",
    "abstract": "The popularity of online shopping has challenged the existing express tracking. How to provide customers with reliable and stable express tracking has become one of the important issues that express companies need to solve now. The current stage of courier tracking is not ideal in challenging environments such as mountain roads, tunnels and city centres. Therefore, the project aims to overcome the challenging environment and achieve stable express tracking, and proposes the Ya'an scenario and conducted multiple experiments. We show that opportunistic DTN-aware protocols are feasible solution for trucks to maintain stable communication in challenging environments, and nodes maintain extremely high message delivery rates and average delays that can maintain communication. ",
    "url": "https://arxiv.org/abs/2404.03033",
    "authors": [
      "Junhao Chen",
      "Milena Radenkovic"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2404.03048",
    "title": "Decentralised Moderation for Interoperable Social Networks: A  Conversation-based Approach for Pleroma and the Fediverse",
    "abstract": "The recent development of decentralised and interoperable social networks (such as the \"fediverse\") creates new challenges for content moderators. This is because millions of posts generated on one server can easily \"spread\" to another, even if the recipient server has very different moderation policies. An obvious solution would be to leverage moderation tools to automatically tag (and filter) posts that contravene moderation policies, e.g. related to toxic speech. Recent work has exploited the conversational context of a post to improve this automatic tagging, e.g. using the replies to a post to help classify if it contains toxic speech. This has shown particular potential in environments with large training sets that contain complete conversations. This, however, creates challenges in a decentralised context, as a single conversation may be fragmented across multiple servers. Thus, each server only has a partial view of an entire conversation because conversations are often federated across servers in a non-synchronized fashion. To address this, we propose a decentralised conversation-aware content moderation approach suitable for the fediverse. Our approach employs a graph deep learning model (GraphNLI) trained locally on each server. The model exploits local data to train a model that combines post and conversational information captured through random walks to detect toxicity. We evaluate our approach with data from Pleroma, a major decentralised and interoperable micro-blogging network containing 2 million conversations. Our model effectively detects toxicity on larger instances, exclusively trained using their local post information (0.8837 macro-F1). Our approach has considerable scope to improve moderation in decentralised and interoperable social networks such as Pleroma or Mastodon. ",
    "url": "https://arxiv.org/abs/2404.03048",
    "authors": [
      "Vibhor Agarwal",
      "Aravindh Raman",
      "Nishanth Sastry",
      "Ahmed M. Abdelmoniem",
      "Gareth Tyson",
      "Ignacio Castro"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.03066",
    "title": "Traffic Divergence Theory: An Analysis Formalism for Dynamic Networks",
    "abstract": "Traffic dynamics is universally crucial in analyzing and designing almost any network. This article introduces a novel theoretical approach to analyzing network traffic dynamics. This theory's machinery is based on the notion of traffic divergence, which captures the flow (im)balance of network nodes and links. It features various analytical probes to investigate both spatial and temporal traffic dynamics. In particular, the maximal traffic distribution in a network can be characterized by spatial traffic divergence rate, which reveals the relative difference among node traffic divergence. To illustrate the usefulness, we apply the theory to two network-driven problems: throughput estimation of data center networks and power-optimized communication planning for robot networks, and show the merits of the proposed theory through simulations. ",
    "url": "https://arxiv.org/abs/2404.03066",
    "authors": [
      "Matin Macktoobian",
      "Zhan Shu",
      "Qing Zhao"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2404.03067",
    "title": "Self-supervised 6-DoF Robot Grasping by Demonstration via Augmented  Reality Teleoperation System",
    "abstract": "Most existing 6-DoF robot grasping solutions depend on strong supervision on grasp pose to ensure satisfactory performance, which could be laborious and impractical when the robot works in some restricted area. To this end, we propose a self-supervised 6-DoF grasp pose detection framework via an Augmented Reality (AR) teleoperation system that can efficiently learn human demonstrations and provide 6-DoF grasp poses without grasp pose annotations. Specifically, the system collects the human demonstration from the AR environment and contrastively learns the grasping strategy from the demonstration. For the real-world experiment, the proposed system leads to satisfactory grasping abilities and learning to grasp unknown objects within three demonstrations. ",
    "url": "https://arxiv.org/abs/2404.03067",
    "authors": [
      "Xiwen Dengxiong",
      "Xueting Wang",
      "Shi Bai",
      "Yunbo Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.03080",
    "title": "Construction of Functional Materials Knowledge Graph in  Multidisciplinary Materials Science via Large Language Model",
    "abstract": "The convergence of materials science and artificial intelligence has unlocked new opportunities for gathering, analyzing, and generating novel materials sourced from extensive scientific literature. Despite the potential benefits, persistent challenges such as manual annotation, precise extraction, and traceability issues remain. Large language models have emerged as promising solutions to address these obstacles. This paper introduces Functional Materials Knowledge Graph (FMKG), a multidisciplinary materials science knowledge graph. Through the utilization of advanced natural language processing techniques, extracting millions of entities to form triples from a corpus comprising all high-quality research papers published in the last decade. It organizes unstructured information into nine distinct labels, covering Name, Formula, Acronym, Structure/Phase, Properties, Descriptor, Synthesis, Characterization Method, Application, and Domain, seamlessly integrating papers' Digital Object Identifiers. As the latest structured database for functional materials, FMKG acts as a powerful catalyst for expediting the development of functional materials and a fundation for building a more comprehensive material knowledge graph using full paper text. Furthermore, our research lays the groundwork for practical text-mining-based knowledge management systems, not only in intricate materials systems but also applicable to other specialized domains. ",
    "url": "https://arxiv.org/abs/2404.03080",
    "authors": [
      "Yanpeng Ye",
      "Jie Ren",
      "Shaozhou Wang",
      "Yuwei Wan",
      "Imran Razzak",
      "Tong Xie",
      "Wenjie Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.03081",
    "title": "First-order PDES for Graph Neural Networks: Advection And Burgers  Equation Models",
    "abstract": "Graph Neural Networks (GNNs) have established themselves as the preferred methodology in a multitude of domains, ranging from computer vision to computational biology, especially in contexts where data inherently conform to graph structures. While many existing methods have endeavored to model GNNs using various techniques, a prevalent challenge they grapple with is the issue of over-smoothing. This paper presents new Graph Neural Network models that incorporate two first-order Partial Differential Equations (PDEs). These models do not increase complexity but effectively mitigate the over-smoothing problem. Our experimental findings highlight the capacity of our new PDE model to achieve comparable results with higher-order PDE models and fix the over-smoothing problem up to 64 layers. These results underscore the adaptability and versatility of GNNs, indicating that unconventional approaches can yield outcomes on par with established techniques. ",
    "url": "https://arxiv.org/abs/2404.03081",
    "authors": [
      "Yifan Qu",
      "Oliver Krzysik",
      "Hans De Sterck",
      "Omer Ege Kara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2404.03088",
    "title": "Robust Federated Learning for Wireless Networks: A Demonstration with  Channel Estimation",
    "abstract": "Federated learning (FL) offers a privacy-preserving collaborative approach for training models in wireless networks, with channel estimation emerging as a promising application. Despite extensive studies on FL-empowered channel estimation, the security concerns associated with FL require meticulous attention. In a scenario where small base stations (SBSs) serve as local models trained on cached data, and a macro base station (MBS) functions as the global model setting, an attacker can exploit the vulnerability of FL, launching attacks with various adversarial attacks or deployment tactics. In this paper, we analyze such vulnerabilities, corresponding solutions were brought forth, and validated through simulation. ",
    "url": "https://arxiv.org/abs/2404.03088",
    "authors": [
      "Zexin Fang",
      "Bin Han",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2404.03097",
    "title": "SalFoM: Dynamic Saliency Prediction with Video Foundation Models",
    "abstract": "Recent advancements in video saliency prediction (VSP) have shown promising performance compared to the human visual system, whose emulation is the primary goal of VSP. However, current state-of-the-art models employ spatio-temporal transformers trained on limited amounts of data, hindering generalizability adaptation to downstream tasks. The benefits of vision foundation models present a potential solution to improve the VSP process. However, adapting image foundation models to the video domain presents significant challenges in modeling scene dynamics and capturing temporal information. To address these challenges, and as the first initiative to design a VSP model based on video foundation models, we introduce SalFoM, a novel encoder-decoder video transformer architecture. Our model employs UnMasked Teacher (UMT) as feature extractor and presents a heterogeneous decoder which features a locality-aware spatio-temporal transformer and integrates local and global spatio-temporal information from various perspectives to produce the final saliency map. Our qualitative and quantitative experiments on the challenging VSP benchmark datasets of DHF1K, Hollywood-2 and UCF-Sports demonstrate the superiority of our proposed model in comparison with the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2404.03097",
    "authors": [
      "Morteza Moradi",
      "Mohammad Moradi",
      "Francesco Rundo",
      "Concetto Spampinato",
      "Ali Borji",
      "Simone Palazzo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.03099",
    "title": "Composite Bayesian Optimization In Function Spaces Using NEON -- Neural  Epistemic Operator Networks",
    "abstract": "Operator learning is a rising field of scientific computing where inputs or outputs of a machine learning model are functions defined in infinite-dimensional spaces. In this paper, we introduce NEON (Neural Epistemic Operator Networks), an architecture for generating predictions with uncertainty using a single operator network backbone, which presents orders of magnitude less trainable parameters than deep ensembles of comparable performance. We showcase the utility of this method for sequential decision-making by examining the problem of composite Bayesian Optimization (BO), where we aim to optimize a function $f=g\\circ h$, where $h:X\\to C(\\mathcal{Y},\\mathbb{R}^{d_s})$ is an unknown map which outputs elements of a function space, and $g: C(\\mathcal{Y},\\mathbb{R}^{d_s})\\to \\mathbb{R}$ is a known and cheap-to-compute functional. By comparing our approach to other state-of-the-art methods on toy and real world scenarios, we demonstrate that NEON achieves state-of-the-art performance while requiring orders of magnitude less trainable parameters. ",
    "url": "https://arxiv.org/abs/2404.03099",
    "authors": [
      "Leonardo Ferreira Guilhoto",
      "Paris Perdikaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2404.03107",
    "title": "Reducing the Impact of I/O Contention in Numerical Weather Prediction  Workflows at Scale Using DAOS",
    "abstract": "Operational Numerical Weather Prediction (NWP) workflows are highly data-intensive. Data volumes have increased by many orders of magnitude over the last 40 years, and are expected to continue to do so, especially given the upcoming adoption of Machine Learning in forecast processes. Parallel POSIX-compliant file systems have been the dominant paradigm in data storage and exchange in HPC workflows for many years. This paper presents ECMWF's move beyond the POSIX paradigm, implementing a backend for their storage library to support DAOS -- a novel high-performance object store designed for massively distributed Non-Volatile Memory. This system is demonstrated to be able to outperform the highly mature and optimised POSIX backend when used under high load and contention, as per typical forecast workflow I/O patterns. This work constitutes a significant step forward, beyond the performance constraints imposed by POSIX semantics. ",
    "url": "https://arxiv.org/abs/2404.03107",
    "authors": [
      "Nicolau Manubens",
      "Simon D. Smart",
      "Emanuele Danovaro",
      "Tiago Quintino",
      "Adrian Jackson"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2404.03110",
    "title": "Ego-Motion Aware Target Prediction Module for Robust Multi-Object  Tracking",
    "abstract": "Multi-object tracking (MOT) is a prominent task in computer vision with application in autonomous driving, responsible for the simultaneous tracking of multiple object trajectories. Detection-based multi-object tracking (DBT) algorithms detect objects using an independent object detector and predict the imminent location of each target. Conventional prediction methods in DBT utilize Kalman Filter(KF) to extrapolate the target location in the upcoming frames by supposing a constant velocity motion model. These methods are especially hindered in autonomous driving applications due to dramatic camera motion or unavailable detections. Such limitations lead to tracking failures manifested by numerous identity switches and disrupted trajectories. In this paper, we introduce a novel KF-based prediction module called the Ego-motion Aware Target Prediction (EMAP) module by focusing on the integration of camera motion and depth information with object motion models. Our proposed method decouples the impact of camera rotational and translational velocity from the object trajectories by reformulating the Kalman Filter. This reformulation enables us to reject the disturbances caused by camera motion and maximizes the reliability of the object motion model. We integrate our module with four state-of-the-art base MOT algorithms, namely OC-SORT, Deep OC-SORT, ByteTrack, and BoT-SORT. In particular, our evaluation on the KITTI MOT dataset demonstrates that EMAP remarkably drops the number of identity switches (IDSW) of OC-SORT and Deep OC-SORT by 73% and 21%, respectively. At the same time, it elevates other performance metrics such as HOTA by more than 5%. Our source code is available at https://github.com/noyzzz/EMAP. ",
    "url": "https://arxiv.org/abs/2404.03110",
    "authors": [
      "Navid Mahdian",
      "Mohammad Jani",
      "Amir M. Soufi Enayati",
      "Homayoun Najjaran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.03114",
    "title": "Testing the Effect of Code Documentation on Large Language Model Code  Understanding",
    "abstract": "Large Language Models (LLMs) have demonstrated impressive abilities in recent years with regards to code generation and understanding. However, little work has investigated how documentation and other code properties affect an LLM's ability to understand and generate code or documentation. We present an empirical analysis of how underlying properties of code or documentation can affect an LLM's capabilities. We show that providing an LLM with \"incorrect\" documentation can greatly hinder code understanding, while incomplete or missing documentation does not seem to significantly affect an LLM's ability to understand code. ",
    "url": "https://arxiv.org/abs/2404.03114",
    "authors": [
      "William Macke",
      "Michael Doyle"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.03115",
    "title": "Deep Learning-Based Weather-Related Power Outage Prediction with  Socio-Economic and Power Infrastructure Data",
    "abstract": "This paper presents a deep learning-based approach for hourly power outage probability prediction within census tracts encompassing a utility company's service territory. Two distinct deep learning models, conditional Multi-Layer Perceptron (MLP) and unconditional MLP, were developed to forecast power outage probabilities, leveraging a rich array of input features gathered from publicly available sources including weather data, weather station locations, power infrastructure maps, socio-economic and demographic statistics, and power outage records. Given a one-hour-ahead weather forecast, the models predict the power outage probability for each census tract, taking into account both the weather prediction and the location's characteristics. The deep learning models employed different loss functions to optimize prediction performance. Our experimental results underscore the significance of socio-economic factors in enhancing the accuracy of power outage predictions at the census tract level. ",
    "url": "https://arxiv.org/abs/2404.03115",
    "authors": [
      "Xuesong Wang",
      "Nina Fatehi",
      "Caisheng Wang",
      "Masoud H. Nazari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2404.03134",
    "title": "Robust Pronoun Use Fidelity with English LLMs: Are they Reasoning,  Repeating, or Just Biased?",
    "abstract": "Robust, faithful and harm-free pronoun use for individuals is an important goal for language models as their use increases, but prior work tends to study only one or two of these components at a time. To measure progress towards the combined goal, we introduce the task of pronoun use fidelity: given a context introducing a co-referring entity and pronoun, the task is to reuse the correct pronoun later, independent of potential distractors. We present a carefully-designed dataset of over 5 million instances to evaluate pronoun use fidelity in English, and we use it to evaluate 37 popular large language models across architectures (encoder-only, decoder-only and encoder-decoder) and scales (11M-70B parameters). We find that while models can mostly faithfully reuse previously-specified pronouns in the presence of no distractors, they are significantly worse at processing she/her/her, singular they and neopronouns. Additionally, models are not robustly faithful to pronouns, as they are easily distracted. With even one additional sentence containing a distractor pronoun, accuracy drops on average by 34%. With 5 distractor sentences, accuracy drops by 52% for decoder-only models and 13% for encoder-only models. We show that widely-used large language models are still brittle, with large gaps in reasoning and in processing different pronouns in a setting that is very simple for humans, and we encourage researchers in bias and reasoning to bridge them. ",
    "url": "https://arxiv.org/abs/2404.03134",
    "authors": [
      "Vagrant Gautam",
      "Eileen Bingert",
      "Dawei Zhu",
      "Anne Lauscher",
      "Dietrich Klakow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2404.03139",
    "title": "Theoretical and Empirical Insights into the Origins of Degree Bias in  Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) often perform better for high-degree nodes than low-degree nodes on node classification tasks. This degree bias can reinforce social marginalization by, e.g., sidelining authors of lowly-cited papers when predicting paper topics in citation networks. While researchers have proposed numerous hypotheses for why GNN degree bias occurs, we find via a survey of 38 degree bias papers that these hypotheses are often not rigorously validated, and can even be contradictory. Thus, we provide an analysis of the origins of degree bias in message-passing GNNs with different graph filters. We prove that high-degree test nodes tend to have a lower probability of misclassification regardless of how GNNs are trained. Moreover, we show that degree bias arises from a variety of factors that are associated with a node's degree (e.g., homophily of neighbors, diversity of neighbors). Furthermore, we show that during training, some GNNs may adjust their loss on low-degree nodes more slowly than on high-degree nodes; however, with sufficiently many epochs of training, message-passing GNNs can achieve their maximum possible training accuracy, which is not significantly limited by their expressive power. Throughout our analysis, we connect our findings to previously-proposed hypotheses for the origins of degree bias, supporting and unifying some while drawing doubt to others. We validate our theoretical findings on 8 common real-world networks, and based on our theoretical and empirical insights, describe a roadmap to alleviate degree bias. ",
    "url": "https://arxiv.org/abs/2404.03139",
    "authors": [
      "Arjun Subramonian",
      "Jian Kang",
      "Yizhou Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2404.03155",
    "title": "TEGRA -- Scaling Up Terascale Graph Processing with Disaggregated  Computing",
    "abstract": "Graphs are essential for representing relationships in various domains, driving modern AI applications such as graph analytics and neural networks across science, engineering, cybersecurity, transportation, and economics. However, the size of modern graphs are rapidly expanding, posing challenges for traditional CPUs and GPUs in meeting real-time processing demands. As a result, hardware accelerators for graph processing have been proposed. However, the largest graphs that can be handled by these systems is still modest often targeting Twitter graph(1.4B edges approximately). This paper aims to address this limitation by developing a graph accelerator capable of terascale graph processing. Scale out architectures, architectures where nodes are replicated to expand to larger datasets, are natural for handling larger graphs. We argue that this approach is not appropriate for very large-scale graphs because it leads to under utilization of both memory resources and compute resources. Additionally, vertex and edge processing have different access patterns. Communication overheads also pose further challenges in designing scalable architectures. To overcome these issues, this paper proposes TEGRA, a scale-up architecture for terascale graph processing. TEGRA leverages a composable computing system with disaggregated resources and a communication architecture inspired by Active Messages. By employing direct communication between cores and optimizing memory interconnect utilization, TEGRA effectively reduces communication overhead and improves resource utilization, therefore enabling efficient processing of terascale graphs. ",
    "url": "https://arxiv.org/abs/2404.03155",
    "authors": [
      "William Shaddix",
      "Mahyar Samani",
      "Marjan Fariborz",
      "S.J. Ben Yoo",
      "Jason Lowe-Power",
      "Venkatesh Akella"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2404.03162",
    "title": "LTRDetector: Exploring Long-Term Relationship for Advanced Persistent  Threats Detection",
    "abstract": "Advanced Persistent Threat (APT) is challenging to detect due to prolonged duration, infrequent occurrence, and adept concealment techniques. Existing approaches primarily concentrate on the observable traits of attack behaviors, neglecting the intricate relationships formed throughout the persistent attack lifecycle. Thus, we present an innovative APT detection framework named LTRDetector, implementing an end-to-end holistic operation. LTRDetector employs an innovative graph embedding technique to retain comprehensive contextual information, then derives long-term features from these embedded provenance graphs. During the process, we compress the data of the system provenance graph for effective feature learning. Furthermore, in order to detect attacks conducted by using zero-day exploits, we captured the system's regular behavior and detects abnormal activities without relying on predefined attack signatures. We also conducted extensive evaluations using five prominent datasets, the efficacy evaluation of which underscores the superiority of LTRDetector compared to existing state-of-the-art techniques. ",
    "url": "https://arxiv.org/abs/2404.03162",
    "authors": [
      "Xiaoxiao Liu",
      "Fan Xu",
      "Nan Wang",
      "Qinxin Zhao",
      "Dalin Zhang",
      "Xibin Zhao",
      "Jiqiang Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2404.03164",
    "title": "Does Knowledge Graph Really Matter for Recommender Systems?",
    "abstract": "Recommender systems (RSs) are designed to provide personalized recommendations to users. Recently, knowledge graphs (KGs) have been widely introduced in RSs to improve recommendation accuracy. In this study, however, we demonstrate that RSs do not necessarily perform worse even if the KG is downgraded to the user-item interaction graph only (or removed). We propose an evaluation framework KG4RecEval to systematically evaluate how much a KG contributes to the recommendation accuracy of a KG-based RS, using our defined metric KGER (KG utilization efficiency in recommendation). We consider the scenarios where knowledge in a KG gets completely removed, randomly distorted and decreased, and also where recommendations are for cold-start users. Our extensive experiments on four commonly used datasets and a number of state-of-the-art KG-based RSs reveal that: to remove, randomly distort or decrease knowledge does not necessarily decrease recommendation accuracy, even for cold-start users. These findings inspire us to rethink how to better utilize knowledge from existing KGs, whereby we discuss and provide insights into what characteristics of datasets and KG-based RSs may help improve KG utilization efficiency. ",
    "url": "https://arxiv.org/abs/2404.03164",
    "authors": [
      "Haonan Zhang",
      "Dongxia Wang",
      "Zhu Sun",
      "Yanhui Li",
      "Youcheng Sun",
      "Huizhi Liang",
      "Wenhai Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.03165",
    "title": "Towards Collaborative Family-Centered Design for Online Safety, Privacy  and Security",
    "abstract": "Traditional online safety technologies often overly restrict teens and invade their privacy, while parents often lack knowledge regarding their digital privacy. As such, prior researchers have called for more collaborative approaches on adolescent online safety and networked privacy. In this paper, we propose family-centered approaches to foster parent-teen collaboration in ensuring their mobile privacy and online safety while respecting individual privacy, to enhance open discussion and teens' self-regulation. However, challenges such as power imbalances and conflicts with family values arise when implementing such approaches, making parent-teen collaboration difficult. Therefore, attending the family-centered design workshop will provide an invaluable opportunity for us to discuss these challenges and identify best research practices for the future of collaborative online safety and privacy within families. ",
    "url": "https://arxiv.org/abs/2404.03165",
    "authors": [
      "Mamtaj Akter",
      "Zainab Agha",
      "Ashwaq Alsoubai",
      "Naima Ali",
      "Pamela Wisniewski"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2404.03172",
    "title": "SEPE-SQED: Symbolic Quick Error Detection by Semantically Equivalent  Program Execution",
    "abstract": "Symbolic quick error detection (SQED) has greatly improved efficiency in formal chip verification. However, it has a limitation in detecting single-instruction bugs due to its reliance on the self-consistency property. To address this, we propose a new variant called symbolic quick error detection by semantically equivalent program execution (SEPE-SQED), which utilizes program synthesis techniques to find sequences with equivalent meanings to original instructions. SEPE-SQED effectively detects single-instruction bugs by differentiating their impact on the original instruction and its semantically equivalent program (instruction sequence). To manage the search space associated with program synthesis, we introduce the CEGIS based on the highest priority first algorithm. The experimental results show that our proposed CEGIS approach improves the speed of generating the desired set of equivalent programs by 50% in time compared to previous methods. Compared to SQED, SEPE-SQED offers a wider variety of instruction combinations and can provide a shorter trace for triggering bugs in certain scenarios. ",
    "url": "https://arxiv.org/abs/2404.03172",
    "authors": [
      "Yufeng Li",
      "Qiusong Yang",
      "Yiwei Ci",
      "Enyuan Tian"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Hardware Architecture (cs.AR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2404.03176",
    "title": "Information-Theoretic Generalization Bounds for Deep Neural Networks",
    "abstract": "Deep neural networks (DNNs) exhibit an exceptional capacity for generalization in practical applications. This work aims to capture the effect and benefits of depth for supervised learning via information-theoretic generalization bounds. We first derive two hierarchical bounds on the generalization error in terms of the Kullback-Leibler (KL) divergence or the 1-Wasserstein distance between the train and test distributions of the network internal representations. The KL divergence bound shrinks as the layer index increases, while the Wasserstein bound implies the existence of a layer that serves as a generalization funnel, which attains a minimal 1-Wasserstein distance. Analytic expressions for both bounds are derived under the setting of binary Gaussian classification with linear DNNs. To quantify the contraction of the relevant information measures when moving deeper into the network, we analyze the strong data processing inequality (SDPI) coefficient between consecutive layers of three regularized DNN models: Dropout, DropConnect, and Gaussian noise injection. This enables refining our generalization bounds to capture the contraction as a function of the network architecture parameters. Specializing our results to DNNs with a finite parameter space and the Gibbs algorithm reveals that deeper yet narrower network architectures generalize better in those examples, although how broadly this statement applies remains a question. ",
    "url": "https://arxiv.org/abs/2404.03176",
    "authors": [
      "Haiyun He",
      "Christina Lee Yu",
      "Ziv Goldfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2404.03181",
    "title": "MonoCD: Monocular 3D Object Detection with Complementary Depths",
    "abstract": "Monocular 3D object detection has attracted widespread attention due to its potential to accurately obtain object 3D localization from a single image at a low cost. Depth estimation is an essential but challenging subtask of monocular 3D object detection due to the ill-posedness of 2D to 3D mapping. Many methods explore multiple local depth clues such as object heights and keypoints and then formulate the object depth estimation as an ensemble of multiple depth predictions to mitigate the insufficiency of single-depth information. However, the errors of existing multiple depths tend to have the same sign, which hinders them from neutralizing each other and limits the overall accuracy of combined depth. To alleviate this problem, we propose to increase the complementarity of depths with two novel designs. First, we add a new depth prediction branch named complementary depth that utilizes global and efficient depth clues from the entire image rather than the local clues to reduce the correlation of depth predictions. Second, we propose to fully exploit the geometric relations between multiple depth clues to achieve complementarity in form. Benefiting from these designs, our method achieves higher complementarity. Experiments on the KITTI benchmark demonstrate that our method achieves state-of-the-art performance without introducing extra data. In addition, complementary depth can also be a lightweight and plug-and-play module to boost multiple existing monocular 3d object detectors. Code is available at https://github.com/elvintanhust/MonoCD. ",
    "url": "https://arxiv.org/abs/2404.03181",
    "authors": [
      "Longfei Yan",
      "Pei Yan",
      "Shengzhou Xiong",
      "Xuanyu Xiang",
      "Yihua Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.03190",
    "title": "Adaptive Discrete Disparity Volume for Self-supervised Monocular Depth  Estimation",
    "abstract": "In self-supervised monocular depth estimation tasks, discrete disparity prediction has been proven to attain higher quality depth maps than common continuous methods. However, current discretization strategies often divide depth ranges of scenes into bins in a handcrafted and rigid manner, limiting model performance. In this paper, we propose a learnable module, Adaptive Discrete Disparity Volume (ADDV), which is capable of dynamically sensing depth distributions in different RGB images and generating adaptive bins for them. Without any extra supervision, this module can be integrated into existing CNN architectures, allowing networks to produce representative values for bins and a probability volume over them. Furthermore, we introduce novel training strategies - uniformizing and sharpening - through a loss term and temperature parameter, respectively, to provide regularizations under self-supervised conditions, preventing model degradation or collapse. Empirical results demonstrate that ADDV effectively processes global information, generating appropriate bins for various scenes and producing higher quality depth maps compared to handcrafted methods. ",
    "url": "https://arxiv.org/abs/2404.03190",
    "authors": [
      "Jianwei Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.03197",
    "title": "A Rolling Horizon Restoration Framework for Post-disaster Restoration of  Electrical Distribution Networks",
    "abstract": "Severe weather events such as floods, hurricanes, earthquakes, and large wind or ice storms can cause extensive damage to electrical distribution networks, requiring a multi-day restoration effort. Complicating the recovery process is the lack of complete and accurate information regarding the extent and locations of damages, at least during the initial part of the recovery process. These factors make workforce planning challenging. In this paper, we adopt a rolling horizon restoration framework whereby repairs are planned for adjustable finite length restoration windows. Considering both repair times as well as travel times, we show that the optimal scheduling problem with multiple crews, each with their own time budget, can be recast in terms of a cost constrained reward maximizing mTSP (traveling salesman problem) on doubly weighted graphs, where the objective is to maximize the aggregate reward earned during the upcoming restoration window, provided no crew violates its time budget and certain electrical continuity constraints are met. We propose a mixed integer linear programming (MILP) model for solving the above problem which is validated on standard IEEE PES test feeder networks. ",
    "url": "https://arxiv.org/abs/2404.03197",
    "authors": [
      "Ran Wei",
      "Arindam K. Das",
      "Payman Arabshahi",
      "Daniel S. Kirschen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2404.03225",
    "title": "FACTUAL: A Novel Framework for Contrastive Learning Based Robust SAR  Image Classification",
    "abstract": "Deep Learning (DL) Models for Synthetic Aperture Radar (SAR) Automatic Target Recognition (ATR), while delivering improved performance, have been shown to be quite vulnerable to adversarial attacks. Existing works improve robustness by training models on adversarial samples. However, by focusing mostly on attacks that manipulate images randomly, they neglect the real-world feasibility of such attacks. In this paper, we propose FACTUAL, a novel Contrastive Learning framework for Adversarial Training and robust SAR classification. FACTUAL consists of two components: (1) Differing from existing works, a novel perturbation scheme that incorporates realistic physical adversarial attacks (such as OTSA) to build a supervised adversarial pre-training network. This network utilizes class labels for clustering clean and perturbed images together into a more informative feature space. (2) A linear classifier cascaded after the encoder to use the computed representations to predict the target labels. By pre-training and fine-tuning our model on both clean and adversarial samples, we show that our model achieves high prediction accuracy on both cases. Our model achieves 99.7% accuracy on clean samples, and 89.6% on perturbed samples, both outperforming previous state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2404.03225",
    "authors": [
      "Xu Wang",
      "Tian Ye",
      "Rajgopal Kannan",
      "Viktor Prasanna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.03226",
    "title": "INSPIRIT: Optimizing Heterogeneous Task Scheduling through Adaptive  Priority in Task-based Runtime Systems",
    "abstract": "As modern HPC computing platforms become increasingly heterogeneous, it is challenging for programmers to fully leverage the computation power of massive parallelism offered by such heterogeneity. Consequently, task-based runtime systems have been proposed as an intermediate layer to hide the complex heterogeneity from the application programmers. The core functionality of these systems is to realize efficient task-to-resource mapping in the form of Directed Acyclic Graph (DAG) scheduling. However, existing scheduling schemes face several drawbacks to determine task priorities due to the heavy reliance on domain knowledge or failure to efficiently exploit the interaction of application and hardware characteristics. In this paper, we propose INSPIRIT, an efficient and lightweight scheduling framework with adaptive priority designed for task-based runtime systems. INSPIRIT introduces two novel task attributes \\textit{inspiring ability} and \\textit{inspiring efficiency} for dictating scheduling, eliminating the need for application domain knowledge. In addition, INSPIRIT jointly considers runtime information such as ready tasks in worker queues to guide task scheduling. This approach exposes more performance opportunities in heterogeneous hardware at runtime while effectively reducing the overhead for adjusting task priorities. Our evaluation results demonstrate that INSPIRIT achieves superior performance compared to cutting edge scheduling schemes on both synthesized and real-world task DAGs. ",
    "url": "https://arxiv.org/abs/2404.03226",
    "authors": [
      "Yiqing Wang",
      "Xiaoyan Liu",
      "Hailong Yang",
      "Xinyu Yang",
      "Pengbo Wang",
      "Yi Liu",
      "Zhongzhi Luan",
      "Depei Qian"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2404.03233",
    "title": "Learn What You Want to Unlearn: Unlearning Inversion Attacks against  Machine Unlearning",
    "abstract": "Machine unlearning has become a promising solution for fulfilling the \"right to be forgotten\", under which individuals can request the deletion of their data from machine learning models. However, existing studies of machine unlearning mainly focus on the efficacy and efficiency of unlearning methods, while neglecting the investigation of the privacy vulnerability during the unlearning process. With two versions of a model available to an adversary, that is, the original model and the unlearned model, machine unlearning opens up a new attack surface. In this paper, we conduct the first investigation to understand the extent to which machine unlearning can leak the confidential content of the unlearned data. Specifically, under the Machine Learning as a Service setting, we propose unlearning inversion attacks that can reveal the feature and label information of an unlearned sample by only accessing the original and unlearned model. The effectiveness of the proposed unlearning inversion attacks is evaluated through extensive experiments on benchmark datasets across various model architectures and on both exact and approximate representative unlearning approaches. The experimental results indicate that the proposed attack can reveal the sensitive information of the unlearned data. As such, we identify three possible defenses that help to mitigate the proposed attacks, while at the cost of reducing the utility of the unlearned model. The study in this paper uncovers an underexplored gap between machine unlearning and the privacy of unlearned data, highlighting the need for the careful design of mechanisms for implementing unlearning without leaking the information of the unlearned data. ",
    "url": "https://arxiv.org/abs/2404.03233",
    "authors": [
      "Hongsheng Hu",
      "Shuo Wang",
      "Tian Dong",
      "Minhui Xue"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2404.03240",
    "title": "Knowledge-Based Convolutional Neural Network for the Simulation and  Prediction of Two-Phase Darcy Flows",
    "abstract": "Physics-informed neural networks (PINNs) have gained significant prominence as a powerful tool in the field of scientific computing and simulations. Their ability to seamlessly integrate physical principles into deep learning architectures has revolutionized the approaches to solving complex problems in physics and engineering. However, a persistent challenge faced by mainstream PINNs lies in their handling of discontinuous input data, leading to inaccuracies in predictions. This study addresses these challenges by incorporating the discretized forms of the governing equations into the PINN framework. We propose to combine the power of neural networks with the dynamics imposed by the discretized differential equations. By discretizing the governing equations, the PINN learns to account for the discontinuities and accurately capture the underlying relationships between inputs and outputs, improving the accuracy compared to traditional interpolation techniques. Moreover, by leveraging the power of neural networks, the computational cost associated with numerical simulations is substantially reduced. We evaluate our model on a large-scale dataset for the prediction of pressure and saturation fields demonstrating high accuracies compared to non-physically aware models. ",
    "url": "https://arxiv.org/abs/2404.03240",
    "authors": [
      "Zakaria Elabid",
      "Daniel Busby",
      "Abdenour Hadid"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2404.03248",
    "title": "Learning Transferable Negative Prompts for Out-of-Distribution Detection",
    "abstract": "Existing prompt learning methods have shown certain capabilities in Out-of-Distribution (OOD) detection, but the lack of OOD images in the target dataset in their training can lead to mismatches between OOD images and In-Distribution (ID) categories, resulting in a high false positive rate. To address this issue, we introduce a novel OOD detection method, named 'NegPrompt', to learn a set of negative prompts, each representing a negative connotation of a given class label, for delineating the boundaries between ID and OOD images. It learns such negative prompts with ID data only, without any reliance on external outlier data. Further, current methods assume the availability of samples of all ID classes, rendering them ineffective in open-vocabulary learning scenarios where the inference stage can contain novel ID classes not present during training. In contrast, our learned negative prompts are transferable to novel class labels. Experiments on various ImageNet benchmarks show that NegPrompt surpasses state-of-the-art prompt-learning-based OOD detection methods and maintains a consistent lead in hard OOD detection in closed- and open-vocabulary classification scenarios. Code is available at https://github.com/mala-lab/negprompt. ",
    "url": "https://arxiv.org/abs/2404.03248",
    "authors": [
      "Tianqi Li",
      "Guansong Pang",
      "Xiao Bai",
      "Wenjun Miao",
      "Jin Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.03254",
    "title": "Mining Area Skyline Objects from Map-based Big Data using Apache Spark  Framework",
    "abstract": "The computation of the skyline provides a mechanism for utilizing multiple location-based criteria to identify optimal data points. However, the efficiency of these computations diminishes and becomes more challenging as the input data expands. This study presents a novel algorithm aimed at mitigating this challenge by harnessing the capabilities of Apache Spark, a distributed processing platform, for conducting area skyline computations. The proposed algorithm enhances processing speed and scalability. In particular, our algorithm encompasses three key phases: the computation of distances between data points, the generation of distance tuples, and the execution of the skyline operators. Notably, the second phase employs a local partial skyline extraction technique to minimize the volume of data transmitted from each executor (a parallel processing procedure) to the driver (a central processing procedure). Afterwards, the driver processes the received data to determine the final skyline and creates filters to exclude irrelevant points. Extensive experimentation on eight datasets reveals that our algorithm significantly reduces both data size and computation time required for area skyline computation. ",
    "url": "https://arxiv.org/abs/2404.03254",
    "authors": [
      "Chen Li",
      "Ye Zhu",
      "Yang Cao",
      "Jinli Zhang",
      "Annisa Annisa",
      "Debo Cheng",
      "Yasuhiko Morimoto"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2404.03267",
    "title": "To Search or to Recommend: Predicting Open-App Motivation with Neural  Hawkes Process",
    "abstract": "Incorporating Search and Recommendation (S&R) services within a singular application is prevalent in online platforms, leading to a new task termed open-app motivation prediction, which aims to predict whether users initiate the application with the specific intent of information searching, or to explore recommended content for entertainment. Studies have shown that predicting users' motivation to open an app can help to improve user engagement and enhance performance in various downstream tasks. However, accurately predicting open-app motivation is not trivial, as it is influenced by user-specific factors, search queries, clicked items, as well as their temporal occurrences. Furthermore, these activities occur sequentially and exhibit intricate temporal dependencies. Inspired by the success of the Neural Hawkes Process (NHP) in modeling temporal dependencies in sequences, this paper proposes a novel neural Hawkes process model to capture the temporal dependencies between historical user browsing and querying actions. The model, referred to as Neural Hawkes Process-based Open-App Motivation prediction model (NHP-OAM), employs a hierarchical transformer and a novel intensity function to encode multiple factors, and open-app motivation prediction layer to integrate time and user-specific information for predicting users' open-app motivations. To demonstrate the superiority of our NHP-OAM model and construct a benchmark for the Open-App Motivation Prediction task, we not only extend the public S&R dataset ZhihuRec but also construct a new real-world Open-App Motivation Dataset (OAMD). Experiments on these two datasets validate NHP-OAM's superiority over baseline models. Further downstream application experiments demonstrate NHP-OAM's effectiveness in predicting users' Open-App Motivation, highlighting the immense application value of NHP-OAM. ",
    "url": "https://arxiv.org/abs/2404.03267",
    "authors": [
      "Zhongxiang Sun",
      "Zihua Si",
      "Xiao Zhang",
      "Xiaoxue Zang",
      "Yang Song",
      "Hongteng Xu",
      "Jun Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2404.03279",
    "title": "MMSE Channel Estimation in Large-Scale MIMO: Improved Robustness with  Reduced Complexity",
    "abstract": "Large-scale MIMO systems with a massive number N of individually controlled antennas pose significant challenges for minimum mean square error (MMSE) channel estimation, based on uplink pilots. The major ones arise from the computational complexity, which scales with $N^3$, and from the need for accurate knowledge of the channel statistics. This paper aims to address both challenges by introducing reduced-complexity channel estimation methods that achieve the performance of MMSE in terms of estimation accuracy and uplink spectral efficiency while demonstrating improved robustness in practical scenarios where channel statistics must be estimated. This is achieved by exploiting the inherent structure of the spatial correlation matrix induced by the array geometry. Specifically, we use a Kronecker decomposition for uniform planar arrays and a well-suited circulant approximation for uniform linear arrays. By doing so, a significantly lower computational complexity is achieved, scaling as $N\\sqrt{N}$ and $N\\log N$ for squared planar arrays and linear arrays, respectively. ",
    "url": "https://arxiv.org/abs/2404.03279",
    "authors": [
      "Giacomo Bacci",
      "Antonio Alberto D'Amico",
      "Luca Sanguinetti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2404.03284",
    "title": "Maximizing network capacity, control and management in designing a  Telemedicine network: a review and recent challenges",
    "abstract": "Telemedicine networks have seen significant changes in their capacity, monitoring, management, and control framework during the previous decades. The evolution of network capacity, control, and management for Unmanned Aerial Vehicle (UAV) & Software-Defined Networks (SDN) as support to telemedicine, artificial intelligence in telemedicine networks, and capabilities in designing a telemedicine network with respect to its performance and customization is presented in this study, with a historical history and a future view. The first section of the article goes over the history of traffic and capacity expansion, as well as future projections. By introducing a medical and image data communication protocol for telemedicine, the second section examines the technological constraints of expanding capacity in the era of UAV & software defined networking. The third section discusses ways to maximize network capacity by considering quality of service (QoS) capacity issues. Finally, the article explores how to construct a telemedicine network that can provide performance, customization, and capabilities to keep up with increased traffic in the coming decades. Research gaps and future directions were presented in the last section ",
    "url": "https://arxiv.org/abs/2404.03284",
    "authors": [
      "B. O. Sadiq",
      "O. S. Zakariyya",
      "M. D. Buhari",
      "A. N. Shuaibu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2404.03326",
    "title": "A Directional Diffusion Graph Transformer for Recommendation",
    "abstract": "In real-world recommender systems, implicitly collected user feedback, while abundant, often includes noisy false-positive and false-negative interactions. The possible misinterpretations of the user-item interactions pose a significant challenge for traditional graph neural recommenders. These approaches aggregate the users' or items' neighbours based on implicit user-item interactions in order to accurately capture the users' profiles. To account for and model possible noise in the users' interactions in graph neural recommenders, we propose a novel Diffusion Graph Transformer (DiffGT) model for top-k recommendation. Our DiffGT model employs a diffusion process, which includes a forward phase for gradually introducing noise to implicit interactions, followed by a reverse process to iteratively refine the representations of the users' hidden preferences (i.e., a denoising process). In our proposed approach, given the inherent anisotropic structure observed in the user-item interaction graph, we specifically use anisotropic and directional Gaussian noises in the forward diffusion process. Our approach differs from the sole use of isotropic Gaussian noises in existing diffusion models. In the reverse diffusion process, to reverse the effect of noise added earlier and recover the true users' preferences, we integrate a graph transformer architecture with a linear attention module to denoise the noisy user/item embeddings in an effective and efficient manner. In addition, such a reverse diffusion process is further guided by personalised information (e.g., interacted items) to enable the accurate estimation of the users' preferences on items. Our extensive experiments conclusively demonstrate the superiority of our proposed graph diffusion model over ten existing state-of-the-art approaches across three benchmark datasets. ",
    "url": "https://arxiv.org/abs/2404.03326",
    "authors": [
      "Zixuan Yi",
      "Xi Wang",
      "Iadh Ounis"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2404.03340",
    "title": "Meta Invariance Defense Towards Generalizable Robustness to Unknown  Adversarial Attacks",
    "abstract": "Despite providing high-performance solutions for computer vision tasks, the deep neural network (DNN) model has been proved to be extremely vulnerable to adversarial attacks. Current defense mainly focuses on the known attacks, but the adversarial robustness to the unknown attacks is seriously overlooked. Besides, commonly used adaptive learning and fine-tuning technique is unsuitable for adversarial defense since it is essentially a zero-shot problem when deployed. Thus, to tackle this challenge, we propose an attack-agnostic defense method named Meta Invariance Defense (MID). Specifically, various combinations of adversarial attacks are randomly sampled from a manually constructed Attacker Pool to constitute different defense tasks against unknown attacks, in which a student encoder is supervised by multi-consistency distillation to learn the attack-invariant features via a meta principle. The proposed MID has two merits: 1) Full distillation from pixel-, feature- and prediction-level between benign and adversarial samples facilitates the discovery of attack-invariance. 2) The model simultaneously achieves robustness to the imperceptible adversarial perturbations in high-level image classification and attack-suppression in low-level robust image regeneration. Theoretical and empirical studies on numerous benchmarks such as ImageNet verify the generalizable robustness and superiority of MID under various attacks. ",
    "url": "https://arxiv.org/abs/2404.03340",
    "authors": [
      "Lei Zhang",
      "Yuhang Zhou",
      "Yi Yang",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.03348",
    "title": "Knowledge Distillation-Based Model Extraction Attack using Private  Counterfactual Explanations",
    "abstract": "In recent years, there has been a notable increase in the deployment of machine learning (ML) models as services (MLaaS) across diverse production software applications. In parallel, explainable AI (XAI) continues to evolve, addressing the necessity for transparency and trustworthiness in ML models. XAI techniques aim to enhance the transparency of ML models by providing insights, in terms of the model's explanations, into their decision-making process. Simultaneously, some MLaaS platforms now offer explanations alongside the ML prediction outputs. This setup has elevated concerns regarding vulnerabilities in MLaaS, particularly in relation to privacy leakage attacks such as model extraction attacks (MEA). This is due to the fact that explanations can unveil insights about the inner workings of the model which could be exploited by malicious users. In this work, we focus on investigating how model explanations, particularly Generative adversarial networks (GANs)-based counterfactual explanations (CFs), can be exploited for performing MEA within the MLaaS platform. We also delve into assessing the effectiveness of incorporating differential privacy (DP) as a mitigation strategy. To this end, we first propose a novel MEA methodology based on Knowledge Distillation (KD) to enhance the efficiency of extracting a substitute model of a target model exploiting CFs. Then, we advise an approach for training CF generators incorporating DP to generate private CFs. We conduct thorough experimental evaluations on real-world datasets and demonstrate that our proposed KD-based MEA can yield a high-fidelity substitute model with reduced queries with respect to baseline approaches. Furthermore, our findings reveal that the inclusion of a privacy layer impacts the performance of the explainer, the quality of CFs, and results in a reduction in the MEA performance. ",
    "url": "https://arxiv.org/abs/2404.03348",
    "authors": [
      "Fatima Ezzeddine",
      "Omran Ayoub",
      "Silvia Giordano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2404.03354",
    "title": "A Comprehensive Survey on Self-Supervised Learning for Recommendation",
    "abstract": "Recommender systems play a crucial role in tackling the challenge of information overload by delivering personalized recommendations based on individual user preferences. Deep learning techniques, such as RNNs, GNNs, and Transformer architectures, have significantly propelled the advancement of recommender systems by enhancing their comprehension of user behaviors and preferences. However, supervised learning methods encounter challenges in real-life scenarios due to data sparsity, resulting in limitations in their ability to learn representations effectively. To address this, self-supervised learning (SSL) techniques have emerged as a solution, leveraging inherent data structures to generate supervision signals without relying solely on labeled data. By leveraging unlabeled data and extracting meaningful representations, recommender systems utilizing SSL can make accurate predictions and recommendations even when confronted with data sparsity. In this paper, we provide a comprehensive review of self-supervised learning frameworks designed for recommender systems, encompassing a thorough analysis of over 170 papers. We conduct an exploration of nine distinct scenarios, enabling a comprehensive understanding of SSL-enhanced recommenders in different contexts. For each domain, we elaborate on different self-supervised learning paradigms, namely contrastive learning, generative learning, and adversarial learning, so as to present technical details of how SSL enhances recommender systems in various contexts. We consistently maintain the related open-source materials at https://github.com/HKUDS/Awesome-SSLRec-Papers. ",
    "url": "https://arxiv.org/abs/2404.03354",
    "authors": [
      "Xubin Ren",
      "Wei Wei",
      "Lianghao Xia",
      "Chao Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.03359",
    "title": "REACT: Revealing Evolutionary Action Consequence Trajectories for  Interpretable Reinforcement Learning",
    "abstract": "To enhance the interpretability of Reinforcement Learning (RL), we propose Revealing Evolutionary Action Consequence Trajectories (REACT). In contrast to the prevalent practice of validating RL models based on their optimal behavior learned during training, we posit that considering a range of edge-case trajectories provides a more comprehensive understanding of their inherent behavior. To induce such scenarios, we introduce a disturbance to the initial state, optimizing it through an evolutionary algorithm to generate a diverse population of demonstrations. To evaluate the fitness of trajectories, REACT incorporates a joint fitness function that encourages both local and global diversity in the encountered states and chosen actions. Through assessments with policies trained for varying durations in discrete and continuous environments, we demonstrate the descriptive power of REACT. Our results highlight its effectiveness in revealing nuanced aspects of RL models' behavior beyond optimal performance, thereby contributing to improved interpretability. ",
    "url": "https://arxiv.org/abs/2404.03359",
    "authors": [
      "Philipp Altmann",
      "C\u00e9line Davignon",
      "Maximilian Zorn",
      "Fabian Ritz",
      "Claudia Linnhoff-Popien",
      "Thomas Gabor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2404.03368",
    "title": "Graph Neural Networks for Electric and Hydraulic Data Fusion to Enhance  Short-term Forecasting of Pumped-storage Hydroelectricity",
    "abstract": "Pumped-storage hydropower plants (PSH) actively participate in grid power-frequency control and therefore often operate under dynamic conditions, which results in rapidly varying system states. Predicting these dynamically changing states is essential for comprehending the underlying sensor and machine conditions. This understanding aids in detecting anomalies and faults, ensuring the reliable operation of the connected power grid, and in identifying faulty and miscalibrated sensors. PSH are complex, highly interconnected systems encompassing electrical and hydraulic subsystems, each characterized by their respective underlying networks that can individually be represented as graphs. To take advantage of this relational inductive bias, graph neural networks (GNNs) have been separately applied to state forecasting tasks in the individual subsystems, but without considering their interdependencies. In PSH, however, these subsystems depend on the same control input, making their operations highly interdependent and interconnected. Consequently, hydraulic and electrical sensor data should be fused across PSH subsystems to improve state forecasting accuracy. This approach has not been explored in GNN literature yet because many available PSH graphs are limited to their respective subsystem boundaries, which makes the method unsuitable to be applied directly. In this work, we introduce the application of spectral-temporal graph neural networks, which leverage self-attention mechanisms to concurrently capture and learn meaningful subsystem interdependencies and the dynamic patterns observed in electric and hydraulic sensors. Our method effectively fuses data from the PSH's subsystems by operating on a unified, system-wide graph, learned directly from the data, This approach leads to demonstrably improved state forecasting performance and enhanced generalizability. ",
    "url": "https://arxiv.org/abs/2404.03368",
    "authors": [
      "Raffael Theiler",
      "Olga Fink"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2404.03380",
    "title": "On the Theoretical Expressive Power and the Design Space of Higher-Order  Graph Transformers",
    "abstract": "Graph transformers have recently received significant attention in graph learning, partly due to their ability to capture more global interaction via self-attention. Nevertheless, while higher-order graph neural networks have been reasonably well studied, the exploration of extending graph transformers to higher-order variants is just starting. Both theoretical understanding and empirical results are limited. In this paper, we provide a systematic study of the theoretical expressive power of order-$k$ graph transformers and sparse variants. We first show that, an order-$k$ graph transformer without additional structural information is less expressive than the $k$-Weisfeiler Lehman ($k$-WL) test despite its high computational cost. We then explore strategies to both sparsify and enhance the higher-order graph transformers, aiming to improve both their efficiency and expressiveness. Indeed, sparsification based on neighborhood information can enhance the expressive power, as it provides additional information about input graph structures. In particular, we show that a natural neighborhood-based sparse order-$k$ transformer model is not only computationally efficient, but also expressive -- as expressive as $k$-WL test. We further study several other sparse graph attention models that are computationally efficient and provide their expressiveness analysis. Finally, we provide experimental results to show the effectiveness of the different sparsification strategies. ",
    "url": "https://arxiv.org/abs/2404.03380",
    "authors": [
      "Cai Zhou",
      "Rose Yu",
      "Yusu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)",
      "General Topology (math.GN)"
    ]
  },
  {
    "id": "arXiv:2404.03437",
    "title": "Knowledge Graph Representation for Political Information Sources",
    "abstract": "With the rise of computational social science, many scholars utilize data analysis and natural language processing tools to analyze social media, news articles, and other accessible data sources for examining political and social discourse. Particularly, the study of the emergence of echo-chambers due to the dissemination of specific information has become a topic of interest in mixed methods research areas. In this paper, we analyze data collected from two news portals, Breitbart News (BN) and New York Times (NYT) to prove the hypothesis that the formation of echo-chambers can be partially explained on the level of an individual information consumption rather than a collective topology of individuals' social networks. Our research findings are presented through knowledge graphs, utilizing a dataset spanning 11.5 years gathered from BN and NYT media portals. We demonstrate that the application of knowledge representation techniques to the aforementioned news streams highlights, contrary to common assumptions, shows relative \"internal\" neutrality of both sources and polarizing attitude towards a small fraction of entities. Additionally, we argue that such characteristics in information sources lead to fundamental disparities in audience worldviews, potentially acting as a catalyst for the formation of echo-chambers. ",
    "url": "https://arxiv.org/abs/2404.03437",
    "authors": [
      "Tinatin Osmonova",
      "Alexey Tikhonov",
      "Ivan P. Yamshchikov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2404.03442",
    "title": "Privacy Engineering From Principles to Practice: A Roadmap",
    "abstract": "Privacy engineering is gaining momentum in industry and academia alike. So far, manifold low-level primitives and higher-level methods and strategies have successfully been established. Still, fostering adoption in real-world information systems calls for additional aspects to be consciously considered in research and practice. ",
    "url": "https://arxiv.org/abs/2404.03442",
    "authors": [
      "Frank Pallas",
      "Katharina Koerner",
      "Isabel Barber\u00e1",
      "Jaap-Henk Hoepman",
      "Meiko Jensen",
      "Nandita Rao Narla",
      "Nikita Samarin",
      "Max-R. Ulbricht",
      "Isabel Wagner",
      "Kim Wuyts",
      "Christian Zimmermann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2404.03444",
    "title": "Simultaneous State Estimation and Contact Detection for Legged Robots by  Multiple-Model Kalman Filtering",
    "abstract": "This paper proposes an algorithm for combined contact detection and state estimation for legged robots. The proposed algorithm models the robot's movement as a switched system, in which different modes relate to different feet being in contact with the ground. The key element in the proposed algorithm is an interacting multiple-model Kalman filter, which identifies the currently-active mode defining contacts, while estimating the state. The rationale for the proposed estimation framework is that contacts (and contact forces) impact the robot's state and vice versa. This paper presents validation studies with a quadruped using (i) the high-fidelity simulator Gazebo for a comparison with ground truth values and a baseline estimator, and (ii) hardware experiments with the Unitree A1 robot. The simulation study shows that the proposed algorithm outperforms the baseline estimator, which does not simultaneous detect contacts. The hardware experiments showcase the applicability of the proposed algorithm and highlights the ability to detect contacts. ",
    "url": "https://arxiv.org/abs/2404.03444",
    "authors": [
      "Marcel Menner",
      "Karl Berntorp"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2404.03471",
    "title": "Reevaluating Bias Detection in Language Models: The Role of Implicit  Norm",
    "abstract": "Large language models (LLMs), trained on vast datasets, can carry biases that manifest in various forms, from overt discrimination to implicit stereotypes. One facet of bias is performance disparities in LLMs, often harming underprivileged groups, such as racial minorities. A common approach to quantifying bias is to use template-based bias probes, which explicitly state group membership (e.g. White) and evaluate if the outcome of a task, sentiment analysis for instance, is invariant to the change of group membership (e.g. change White race to Black). This approach is widely used in bias quantification. However, in this work, we find evidence of an unexpectedly overlooked consequence of using template-based probes for LLM bias quantification. We find that in doing so, text examples associated with White ethnicities appear to be classified as exhibiting negative sentiment at elevated rates. We hypothesize that the scenario arises artificially through a mismatch between the pre-training text of LLMs and the templates used to measure bias through reporting bias, unstated norms that imply group membership without explicit statement. Our finding highlights the potential misleading impact of varying group membership through explicit mention in bias quantification ",
    "url": "https://arxiv.org/abs/2404.03471",
    "authors": [
      "Farnaz Kohankhaki",
      "Jacob-Junqi Tian",
      "David Emerson",
      "Laleh Seyyed-Kalantari",
      "Faiza Khan Khattak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.03472",
    "title": "Lower bounds for graph reconstruction with maximal independent set  queries",
    "abstract": "We investigate the number of maximal independent set queries required to reconstruct the edges of a hidden graph. We show that randomised adaptive algorithms need at least $\\Omega(\\Delta^2 \\log(n / \\Delta) / \\log \\Delta)$ queries to reconstruct $n$-vertex graphs of maximum degree $\\Delta$ with success probability at least $1/2$, and we further improve this lower bound to $\\Omega(\\Delta^2 \\log(n / \\Delta))$ for randomised non-adaptive algorithms. We also prove that deterministic non-adaptive algorithms require at least $\\Omega(\\Delta^3 \\log n / \\log \\Delta)$ queries. This improves bounds of Konrad, O'Sullivan, and Traistaru, and answers one of their questions. The proof of the lower bound for deterministic non-adaptive algorithms relies on a connection to cover-free families, for which we also improve known bounds. ",
    "url": "https://arxiv.org/abs/2404.03472",
    "authors": [
      "Lukas Michel",
      "Alex Scott"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2404.03473",
    "title": "Generalization Bounds for Message Passing Networks on Mixture of  Graphons",
    "abstract": "We study the generalization capabilities of Message Passing Neural Networks (MPNNs), a prevalent class of Graph Neural Networks (GNN). We derive generalization bounds specifically for MPNNs with normalized sum aggregation and mean aggregation. Our analysis is based on a data generation model incorporating a finite set of template graphons. Each graph within this framework is generated by sampling from one of the graphons with a certain degree of perturbation. In particular, we extend previous MPNN generalization results to a more realistic setting, which includes the following modifications: 1) we analyze simple random graphs with Bernoulli-distributed edges instead of weighted graphs; 2) we sample both graphs and graph signals from perturbed graphons instead of clean graphons; and 3) we analyze sparse graphs instead of dense graphs. In this more realistic and challenging scenario, we provide a generalization bound that decreases as the average number of nodes in the graphs increases. Our results imply that MPNNs with higher complexity than the size of the training set can still generalize effectively, as long as the graphs are sufficiently large. ",
    "url": "https://arxiv.org/abs/2404.03473",
    "authors": [
      "Sohir Maskey",
      "Gitta Kutyniok",
      "Ron Levie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.03493",
    "title": "A Methodology to Study the Impact of Spiking Neural Network Parameters  considering Event-Based Automotive Data",
    "abstract": "Autonomous Driving (AD) systems are considered as the future of human mobility and transportation. Solving computer vision tasks such as image classification and object detection/segmentation, with high accuracy and low power/energy consumption, is highly needed to realize AD systems in real life. These requirements can potentially be satisfied by Spiking Neural Networks (SNNs). However, the state-of-the-art works in SNN-based AD systems still focus on proposing network models that can achieve high accuracy, and they have not systematically studied the roles of SNN parameters when used for learning event-based automotive data. Therefore, we still lack understanding of how to effectively develop SNN models for AD systems. Toward this, we propose a novel methodology to systematically study and analyze the impact of SNN parameters considering event-based automotive data, then leverage this analysis for enhancing SNN developments. To do this, we first explore different settings of SNN parameters that directly affect the learning mechanism (i.e., batch size, learning rate, neuron threshold potential, and weight decay), then analyze the accuracy results. Afterward, we propose techniques that jointly improve SNN accuracy and reduce training time. Experimental results show that our methodology can improve the SNN models for AD systems than the state-of-the-art, as it achieves higher accuracy (i.e., 86%) for the NCARS dataset, and it can also achieve iso-accuracy (i.e., ~85% with standard deviation less than 0.5%) while speeding up the training time by 1.9x. In this manner, our research work provides a set of guidelines for SNN parameter enhancements, thereby enabling the practical developments of SNN-based AD systems. ",
    "url": "https://arxiv.org/abs/2404.03493",
    "authors": [
      "Iqra Bano",
      "Rachmad Vidya Wicaksana Putra",
      "Alberto Marchisio",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.03495",
    "title": "About Test-time training for outlier detection",
    "abstract": "In this paper, we introduce DOUST, our method applying test-time training for outlier detection, significantly improving the detection performance. After thoroughly evaluating our algorithm on common benchmark datasets, we discuss a common problem and show that it disappears with a large enough test set. Thus, we conclude that under reasonable conditions, our algorithm can reach almost supervised performance even when no labeled outliers are given. ",
    "url": "https://arxiv.org/abs/2404.03495",
    "authors": [
      "Simon Kl\u00fcttermann",
      "Emmanuel M\u00fcller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.03507",
    "title": "DQ-DETR: DETR with Dynamic Query for Tiny Object Detection",
    "abstract": "Despite previous DETR-like methods having performed successfully in generic object detection, tiny object detection is still a challenging task for them since the positional information of object queries is not customized for detecting tiny objects, whose scale is extraordinarily smaller than general objects. Also, DETR-like methods using a fixed number of queries make them unsuitable for aerial datasets, which only contain tiny objects, and the numbers of instances are imbalanced between different images. Thus, we present a simple yet effective model, named DQ-DETR, which consists of three different components: categorical counting module, counting-guided feature enhancement, and dynamic query selection to solve the above-mentioned problems. DQ-DETR uses the prediction and density maps from the categorical counting module to dynamically adjust the number of object queries and improve the positional information of queries. Our model DQ-DETR outperforms previous CNN-based and DETR-like methods, achieving state-of-the-art mAP 30.2% on the AI-TOD-V2 dataset, which mostly consists of tiny objects. ",
    "url": "https://arxiv.org/abs/2404.03507",
    "authors": [
      "Yi-Xin Huang",
      "Hou-I Liu",
      "Hong-Han Shuai",
      "Wen-Huang Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.03511",
    "title": "Improved Total Domination and Total Roman Domination in Unit Disk Graphs",
    "abstract": "Let $G=(V, E)$ be a simple undirected graph with no isolated vertex. A set $D_t\\subseteq V$ is a total dominating set of $G$ if $(i)$ $D_t$ is a dominating set, and $(ii)$ the set $D_t$ induces a subgraph with no isolated vertex. The total dominating set of minimum cardinality is called the minimum total dominating set, and the size of the minimum total dominating set is called the total domination number ($\\gamma_t(G)$). Given a graph $G$, the total dominating set (TDS) problem is to find a total dominating set of minimum cardinality. A Roman dominating function (RDF) on a graph $G$ is a function $f:V\\rightarrow \\{0,1,2\\}$ such that each vertex $v\\in V$ with $f(v)=0$ is adjacent to at least one vertex $u\\in V$ with $f(u)=2$. A RDF $f$ of a graph $G$ is said to be a total Roman dominating function (TRDF) if the induced subgraph of $V_1\\cup V_2$ does not contain any isolated vertex, where $V_i=\\{u\\in V|f(u)=i\\}$. Given a graph $G$, the total Roman dominating set (TRDS) problem is to minimize the weight, $W(f)=\\sum_{u\\in V} f(u)$, called the total Roman domination number ($\\gamma_{tR}(G)$). In this paper, we are the first to show that the TRDS problem is NP-complete in unit disk graphs (UDGs). Furthermore, we propose a $7.17\\operatorname{-}$ factor approximation algorithm for the TDS problem and a $6.03\\operatorname{-}$ factor approximation algorithm for the TRDS problem in geometric unit disk graphs. The running time for both algorithms is notably bounded by $O(n\\log{k})$, where $n$ represents the number of vertices in the given UDG and $k$ represents the size of the independent set in (i.e., $D$ and $V_2$ in TDS and TRDS problems, respectively) the given UDG. ",
    "url": "https://arxiv.org/abs/2404.03511",
    "authors": [
      "Sasmita Rout",
      "Gautam Kumar Das"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2404.03523",
    "title": "Integrating Generative AI into Financial Market Prediction for Improved  Decision Making",
    "abstract": "This study provides an in-depth analysis of the model architecture and key technologies of generative artificial intelligence, combined with specific application cases, and uses conditional generative adversarial networks ( cGAN ) and time series analysis methods to simulate and predict dynamic changes in financial markets. The research results show that the cGAN model can effectively capture the complexity of financial market data, and the deviation between the prediction results and the actual market performance is minimal, showing a high degree of accuracy. ",
    "url": "https://arxiv.org/abs/2404.03523",
    "authors": [
      "Chang Che",
      "Zengyi Huang",
      "Chen Li",
      "Haotian Zheng",
      "Xinyu Tian"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2404.03527",
    "title": "HAPNet: Toward Superior RGB-Thermal Scene Parsing via Hybrid,  Asymmetric, and Progressive Heterogeneous Feature Fusion",
    "abstract": "Data-fusion networks have shown significant promise for RGB-thermal scene parsing. However, the majority of existing studies have relied on symmetric duplex encoders for heterogeneous feature extraction and fusion, paying inadequate attention to the inherent differences between RGB and thermal modalities. Recent progress in vision foundation models (VFMs) trained through self-supervision on vast amounts of unlabeled data has proven their ability to extract informative, general-purpose features. However, this potential has yet to be fully leveraged in the domain. In this study, we take one step toward this new research area by exploring a feasible strategy to fully exploit VFM features for RGB-thermal scene parsing. Specifically, we delve deeper into the unique characteristics of RGB and thermal modalities, thereby designing a hybrid, asymmetric encoder that incorporates both a VFM and a convolutional neural network. This design allows for more effective extraction of complementary heterogeneous features, which are subsequently fused in a dual-path, progressive manner. Moreover, we introduce an auxiliary task to further enrich the local semantics of the fused features, thereby improving the overall performance of RGB-thermal scene parsing. Our proposed HAPNet, equipped with all these components, demonstrates superior performance compared to all other state-of-the-art RGB-thermal scene parsing networks, achieving top ranks across three widely used public RGB-thermal scene parsing datasets. We believe this new paradigm has opened up new opportunities for future developments in data-fusion scene parsing approaches. ",
    "url": "https://arxiv.org/abs/2404.03527",
    "authors": [
      "Jiahang Li",
      "Peng Yun",
      "Qijun Chen",
      "Rui Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.03528",
    "title": "BanglaAutoKG: Automatic Bangla Knowledge Graph Construction with  Semantic Neural Graph Filtering",
    "abstract": "Knowledge Graphs (KGs) have proven essential in information processing and reasoning applications because they link related entities and give context-rich information, supporting efficient information retrieval and knowledge discovery; presenting information flow in a very effective manner. Despite being widely used globally, Bangla is relatively underrepresented in KGs due to a lack of comprehensive datasets, encoders, NER (named entity recognition) models, POS (part-of-speech) taggers, and lemmatizers, hindering efficient information processing and reasoning applications in the language. Addressing the KG scarcity in Bengali, we propose BanglaAutoKG, a pioneering framework that is able to automatically construct Bengali KGs from any Bangla text. We utilize multilingual LLMs to understand various languages and correlate entities and relations universally. By employing a translation dictionary to identify English equivalents and extracting word features from pre-trained BERT models, we construct the foundational KG. To reduce noise and align word embeddings with our goal, we employ graph-based polynomial filters. Lastly, we implement a GNN-based semantic filter, which elevates contextual understanding and trims unnecessary edges, culminating in the formation of the definitive KG. Empirical findings and case studies demonstrate the universal effectiveness of our model, capable of autonomously constructing semantically enriched KGs from any text. ",
    "url": "https://arxiv.org/abs/2404.03528",
    "authors": [
      "Azmine Toushik Wasi",
      "Taki Hasan Rafi",
      "Raima Islam",
      "Dong-Kyu Chae"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2404.03543",
    "title": "CodeEditorBench: Evaluating Code Editing Capability of Large Language  Models",
    "abstract": "Large Language Models (LLMs) for code are rapidly evolving, with code editing emerging as a critical capability. We introduce CodeEditorBench, an evaluation framework designed to rigorously assess the performance of LLMs in code editing tasks, including debugging, translating, polishing, and requirement switching. Unlike existing benchmarks focusing solely on code generation, CodeEditorBench emphasizes real-world scenarios and practical aspects of software development. We curate diverse coding challenges and scenarios from five sources, covering various programming languages, complexity levels, and editing tasks. Evaluation of 19 LLMs reveals that closed-source models (particularly Gemini-Ultra and GPT-4), outperform open-source models in CodeEditorBench, highlighting differences in model performance based on problem types and prompt sensitivities. CodeEditorBench aims to catalyze advancements in LLMs by providing a robust platform for assessing code editing capabilities. We will release all prompts and datasets to enable the community to expand the dataset and benchmark emerging LLMs. By introducing CodeEditorBench, we contribute to the advancement of LLMs in code editing and provide a valuable resource for researchers and practitioners. ",
    "url": "https://arxiv.org/abs/2404.03543",
    "authors": [
      "Jiawei Guo",
      "Ziming Li",
      "Xueling Liu",
      "Kaijing Ma",
      "Tianyu Zheng",
      "Zhouliang Yu",
      "Ding Pan",
      "Yizhi LI",
      "Ruibo Liu",
      "Yue Wang",
      "Shuyue Guo",
      "Xingwei Qu",
      "Xiang Yue",
      "Ge Zhang",
      "Wenhu Chen",
      "Jie Fu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.03574",
    "title": "TinyVQA: Compact Multimodal Deep Neural Network for Visual Question  Answering on Resource-Constrained Devices",
    "abstract": "Traditional machine learning models often require powerful hardware, making them unsuitable for deployment on resource-limited devices. Tiny Machine Learning (tinyML) has emerged as a promising approach for running machine learning models on these devices, but integrating multiple data modalities into tinyML models still remains a challenge due to increased complexity, latency, and power consumption. This paper proposes TinyVQA, a novel multimodal deep neural network for visual question answering tasks that can be deployed on resource-constrained tinyML hardware. TinyVQA leverages a supervised attention-based model to learn how to answer questions about images using both vision and language modalities. Distilled knowledge from the supervised attention-based VQA model trains the memory aware compact TinyVQA model and low bit-width quantization technique is employed to further compress the model for deployment on tinyML devices. The TinyVQA model was evaluated on the FloodNet dataset, which is used for post-disaster damage assessment. The compact model achieved an accuracy of 79.5%, demonstrating the effectiveness of TinyVQA for real-world applications. Additionally, the model was deployed on a Crazyflie 2.0 drone, equipped with an AI deck and GAP8 microprocessor. The TinyVQA model achieved low latencies of 56 ms and consumes 693 mW power while deployed on the tiny drone, showcasing its suitability for resource-constrained embedded systems. ",
    "url": "https://arxiv.org/abs/2404.03574",
    "authors": [
      "Hasib-Al Rashid",
      "Argho Sarkar",
      "Aryya Gangopadhyay",
      "Maryam Rahnemoonfar",
      "Tinoosh Mohsenin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.03578",
    "title": "Distributionally Robust Reinforcement Learning with Interactive Data  Collection: Fundamental Hardness and Near-Optimal Algorithm",
    "abstract": "The sim-to-real gap, which represents the disparity between training and testing environments, poses a significant challenge in reinforcement learning (RL). A promising approach to addressing this challenge is distributionally robust RL, often framed as a robust Markov decision process (RMDP). In this framework, the objective is to find a robust policy that achieves good performance under the worst-case scenario among all environments within a pre-specified uncertainty set centered around the training environment. Unlike previous work, which relies on a generative model or a pre-collected offline dataset enjoying good coverage of the deployment environment, we tackle robust RL via interactive data collection, where the learner interacts with the training environment only and refines the policy through trial and error. In this robust RL paradigm, two main challenges emerge: managing distributional robustness while striking a balance between exploration and exploitation during data collection. Initially, we establish that sample-efficient learning without additional assumptions is unattainable owing to the curse of support shift; i.e., the potential disjointedness of the distributional supports between the training and testing environments. To circumvent such a hardness result, we introduce the vanishing minimal value assumption to RMDPs with a total-variation (TV) distance robust set, postulating that the minimal value of the optimal robust value function is zero. We prove that such an assumption effectively eliminates the support shift issue for RMDPs with a TV distance robust set, and present an algorithm with a provable sample complexity guarantee. Our work makes the initial step to uncovering the inherent difficulty of robust RL via interactive data collection and sufficient conditions for designing a sample-efficient algorithm accompanied by sharp sample complexity analysis. ",
    "url": "https://arxiv.org/abs/2404.03578",
    "authors": [
      "Miao Lu",
      "Han Zhong",
      "Tong Zhang",
      "Jose Blanchet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2404.03584",
    "title": "Towards more realistic human motion prediction with attention to motion  coordination",
    "abstract": "Joint relation modeling is a curial component in human motion prediction. Most existing methods rely on skeletal-based graphs to build the joint relations, where local interactive relations between joint pairs are well learned. However, the motion coordination, a global joint relation reflecting the simultaneous cooperation of all joints, is usually weakened because it is learned from part to whole progressively and asynchronously. Thus, the final predicted motions usually appear unrealistic. To tackle this issue, we learn a medium, called coordination attractor (CA), from the spatiotemporal features of motion to characterize the global motion features, which is subsequently used to build new relative joint relations. Through the CA, all joints are related simultaneously, and thus the motion coordination of all joints can be better learned. Based on this, we further propose a novel joint relation modeling module, Comprehensive Joint Relation Extractor (CJRE), to combine this motion coordination with the local interactions between joint pairs in a unified manner. Additionally, we also present a Multi-timescale Dynamics Extractor (MTDE) to extract enriched dynamics from the raw position information for effective prediction. Extensive experiments show that the proposed framework outperforms state-of-the-art methods in both short- and long-term predictions on H3.6M, CMU-Mocap, and 3DPW. ",
    "url": "https://arxiv.org/abs/2404.03584",
    "authors": [
      "Pengxiang Ding",
      "Jianqin Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.03592",
    "title": "ReFT: Representation Finetuning for Language Models",
    "abstract": "Parameter-efficient fine-tuning (PEFT) methods seek to adapt large models via updates to a small number of weights. However, much prior interpretability work has shown that representations encode rich semantic information, suggesting that editing representations might be a more powerful alternative. Here, we pursue this hypothesis by developing a family of $\\textbf{Representation Finetuning (ReFT)}$ methods. ReFT methods operate on a frozen base model and learn task-specific interventions on hidden representations. We define a strong instance of the ReFT family, Low-rank Linear Subspace ReFT (LoReFT). LoReFT is a drop-in replacement for existing PEFTs and learns interventions that are 10x-50x more parameter-efficient than prior state-of-the-art PEFTs. We showcase LoReFT on eight commonsense reasoning tasks, four arithmetic reasoning tasks, Alpaca-Eval v1.0, and GLUE. In all these evaluations, LoReFT delivers the best balance of efficiency and performance, and almost always outperforms state-of-the-art PEFTs. We release a generic ReFT training library publicly at https://github.com/stanfordnlp/pyreft. ",
    "url": "https://arxiv.org/abs/2404.03592",
    "authors": [
      "Zhengxuan Wu",
      "Aryaman Arora",
      "Zheng Wang",
      "Atticus Geiger",
      "Dan Jurafsky",
      "Christopher D. Manning",
      "Christopher Potts"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.03598",
    "title": "Intent Detection and Entity Extraction from BioMedical Literature",
    "abstract": "Biomedical queries have become increasingly prevalent in web searches, reflecting the growing interest in accessing biomedical literature. Despite recent research on large-language models (LLMs) motivated by endeavours to attain generalized intelligence, their efficacy in replacing task and domain-specific natural language understanding approaches remains questionable. In this paper, we address this question by conducting a comprehensive empirical evaluation of intent detection and named entity recognition (NER) tasks from biomedical text. We show that Supervised Fine Tuned approaches are still relevant and more effective than general-purpose LLMs. Biomedical transformer models such as PubMedBERT can surpass ChatGPT on NER task with only 5 supervised examples. ",
    "url": "https://arxiv.org/abs/2404.03598",
    "authors": [
      "Ankan Mullick",
      "Mukur Gupta",
      "Pawan Goyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.03617",
    "title": "On the Efficiency of Convolutional Neural Networks",
    "abstract": "Since the breakthrough performance of AlexNet in 2012, convolutional neural networks (convnets) have grown into extremely powerful vision models. Deep learning researchers have used convnets to produce accurate results that were unachievable a decade ago. Yet computer scientists make computational efficiency their primary objective. Accuracy with exorbitant cost is not acceptable; an algorithm must also minimize its computational requirements. Confronted with the daunting computation that convnets use, deep learning researchers also became interested in efficiency. Researchers applied tremendous effort to find the convnet architectures that have the greatest efficiency. However, skepticism grew among researchers and engineers alike about the relevance of arithmetic complexity. Contrary to the prevailing view that latency and arithmetic complexity are irreconcilable, a simple formula relates both through computational efficiency. This insight enabled us to co-optimize the separate factors that determine latency. We observed that the degenerate conv2d layers that produce the best accuracy-complexity trade-off also have low operational intensity. Therefore, kernels that implement these layers use significant memory resources. We solved this optimization problem with block-fusion kernels that implement all layers of a residual block, thereby creating temporal locality, avoiding communication, and reducing workspace size. Our ConvFirst model with block-fusion kernels ran approximately four times as fast as the ConvNeXt baseline with PyTorch Inductor, at equal accuracy on the ImageNet-1K classification task. Our unified approach to convnet efficiency envisions a new era of models and kernels that achieve greater accuracy at lower cost. ",
    "url": "https://arxiv.org/abs/2404.03617",
    "authors": [
      "Andrew Lavin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.03623",
    "title": "Unveiling LLMs: The Evolution of Latent Representations in a Temporal  Knowledge Graph",
    "abstract": "Large Language Models (LLMs) demonstrate an impressive capacity to recall a vast range of common factual knowledge information. However, unravelling the underlying reasoning of LLMs and explaining their internal mechanisms of exploiting this factual knowledge remain active areas of investigation. Our work analyzes the factual knowledge encoded in the latent representation of LLMs when prompted to assess the truthfulness of factual claims. We propose an end-to-end framework that jointly decodes the factual knowledge embedded in the latent space of LLMs from a vector space to a set of ground predicates and represents its evolution across the layers using a temporal knowledge graph. Our framework relies on the technique of activation patching which intervenes in the inference computation of a model by dynamically altering its latent representations. Consequently, we neither rely on external models nor training processes. We showcase our framework with local and global interpretability analyses using two claim verification datasets: FEVER and CLIMATE-FEVER. The local interpretability analysis exposes different latent errors from representation to multi-hop reasoning errors. On the other hand, the global analysis uncovered patterns in the underlying evolution of the model's factual knowledge (e.g., store-and-seek factual information). By enabling graph-based analyses of the latent representations, this work represents a step towards the mechanistic interpretability of LLMs. ",
    "url": "https://arxiv.org/abs/2404.03623",
    "authors": [
      "Marco Bronzini",
      "Carlo Nicolini",
      "Bruno Lepri",
      "Jacopo Staiano",
      "Andrea Passerini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2404.03631",
    "title": "Robust Concept Erasure Using Task Vectors",
    "abstract": "With the rapid growth of text-to-image models, a variety of techniques have been suggested to prevent undesirable image generations. Yet, these methods often only protect against specific user prompts and have been shown to allow unsafe generations with other inputs. Here we focus on unconditionally erasing a concept from a text-to-image model rather than conditioning the erasure on the user's prompt. We first show that compared to input-dependent erasure methods, concept erasure that uses Task Vectors (TV) is more robust to unexpected user inputs, not seen during training. However, TV-based erasure can also affect the core performance of the edited model, particularly when the required edit strength is unknown. To this end, we propose a method called Diverse Inversion, which we use to estimate the required strength of the TV edit. Diverse Inversion finds within the model input space a large set of word embeddings, each of which induces the generation of the target concept. We find that encouraging diversity in the set makes our estimation more robust to unexpected prompts. Finally, we show that Diverse Inversion enables us to apply a TV edit only to a subset of the model weights, enhancing the erasure capabilities while better maintaining the core functionality of the model. ",
    "url": "https://arxiv.org/abs/2404.03631",
    "authors": [
      "Minh Pham",
      "Kelly O. Marshall",
      "Chinmay Hegde",
      "Niv Cohen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.03650",
    "title": "OpenNeRF: Open Set 3D Neural Scene Segmentation with Pixel-Wise Features  and Rendered Novel Views",
    "abstract": "Large visual-language models (VLMs), like CLIP, enable open-set image segmentation to segment arbitrary concepts from an image in a zero-shot manner. This goes beyond the traditional closed-set assumption, i.e., where models can only segment classes from a pre-defined training set. More recently, first works on open-set segmentation in 3D scenes have appeared in the literature. These methods are heavily influenced by closed-set 3D convolutional approaches that process point clouds or polygon meshes. However, these 3D scene representations do not align well with the image-based nature of the visual-language models. Indeed, point cloud and 3D meshes typically have a lower resolution than images and the reconstructed 3D scene geometry might not project well to the underlying 2D image sequences used to compute pixel-aligned CLIP features. To address these challenges, we propose OpenNeRF which naturally operates on posed images and directly encodes the VLM features within the NeRF. This is similar in spirit to LERF, however our work shows that using pixel-wise VLM features (instead of global CLIP features) results in an overall less complex architecture without the need for additional DINO regularization. Our OpenNeRF further leverages NeRF's ability to render novel views and extract open-set VLM features from areas that are not well observed in the initial posed images. For 3D point cloud segmentation on the Replica dataset, OpenNeRF outperforms recent open-vocabulary methods such as LERF and OpenScene by at least +4.9 mIoU. ",
    "url": "https://arxiv.org/abs/2404.03650",
    "authors": [
      "Francis Engelmann",
      "Fabian Manhardt",
      "Michael Niemeyer",
      "Keisuke Tateno",
      "Marc Pollefeys",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.02999",
    "title": "MeshBrush: Painting the Anatomical Mesh with Neural Stylization for  Endoscopy",
    "abstract": "Style transfer is a promising approach to close the sim-to-real gap in medical endoscopy. Rendering realistic endoscopic videos by traversing pre-operative scans (such as MRI or CT) can generate realistic simulations as well as ground truth camera poses and depth maps. Although image-to-image (I2I) translation models such as CycleGAN perform well, they are unsuitable for video-to-video synthesis due to the lack of temporal consistency, resulting in artifacts between frames. We propose MeshBrush, a neural mesh stylization method to synthesize temporally consistent videos with differentiable rendering. MeshBrush uses the underlying geometry of patient imaging data while leveraging existing I2I methods. With learned per-vertex textures, the stylized mesh guarantees consistency while producing high-fidelity outputs. We demonstrate that mesh stylization is a promising approach for creating realistic simulations for downstream tasks such as training and preoperative planning. Although our method is tested and designed for ureteroscopy, its components are transferable to general endoscopic and laparoscopic procedures. ",
    "url": "https://arxiv.org/abs/2404.02999",
    "authors": [
      "John J. Han",
      "Ayberk Acar",
      "Nicholas Kavoussi",
      "Jie Ying Wu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.03137",
    "title": "Robust Partitioning and Operation for Maximal Uncertain-Load Delivery in  Distribution Grids",
    "abstract": "To mitigate the vulnerability of distribution grids to severe weather events, some electric utilities use preemptive de-energization as the primary line of defense, causing significant power outages. In such instances, networked microgrids could improve resiliency and maximize load delivery, though the modeling of three-phase unbalanced network physics and computational complexity pose challenges. These challenges are further exacerbated by an increased penetration of uncertain loads. In this paper, we present a two-stage mixed-integer robust optimization problem that configures and operates networked microgrids, and is guaranteed to be robust and feasible to all realizations of loads within a specified uncertainty set, while maximizing load delivery. To solve this problem, we propose a cutting-plane algorithm, with convergence guarantees, which approximates a convex recourse function with sub-gradient cuts. Finally, we provide a detailed case study on the IEEE 37-bus test system to demonstrate the economic benefits of networking microgrids to maximize uncertain-load delivery. ",
    "url": "https://arxiv.org/abs/2404.03137",
    "authors": [
      "Hannah Moring",
      "Harsha Nagarajan",
      "Kshitij Girigoudar",
      "David M. Fobes",
      "Johanna L. Mathieu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2404.03204",
    "title": "RALL-E: Robust Codec Language Modeling with Chain-of-Thought Prompting  for Text-to-Speech Synthesis",
    "abstract": "We present RALL-E, a robust language modeling method for text-to-speech (TTS) synthesis. While previous work based on large language models (LLMs) shows impressive performance on zero-shot TTS, such methods often suffer from poor robustness, such as unstable prosody (weird pitch and rhythm/duration) and a high word error rate (WER), due to the autoregressive prediction style of language models. The core idea behind RALL-E is chain-of-thought (CoT) prompting, which decomposes the task into simpler steps to enhance the robustness of LLM-based TTS. To accomplish this idea, RALL-E first predicts prosody features (pitch and duration) of the input text and uses them as intermediate conditions to predict speech tokens in a CoT style. Second, RALL-E utilizes the predicted duration prompt to guide the computing of self-attention weights in Transformer to enforce the model to focus on the corresponding phonemes and prosody features when predicting speech tokens. Results of comprehensive objective and subjective evaluations demonstrate that, compared to a powerful baseline method VALL-E, RALL-E significantly improves the WER of zero-shot TTS from $6.3\\%$ (without reranking) and $2.1\\%$ (with reranking) to $2.8\\%$ and $1.0\\%$, respectively. Furthermore, we demonstrate that RALL-E correctly synthesizes sentences that are hard for VALL-E and reduces the error rate from $68\\%$ to $4\\%$. ",
    "url": "https://arxiv.org/abs/2404.03204",
    "authors": [
      "Detai Xin",
      "Xu Tan",
      "Kai Shen",
      "Zeqian Ju",
      "Dongchao Yang",
      "Yuancheng Wang",
      "Shinnosuke Takamichi",
      "Hiroshi Saruwatari",
      "Shujie Liu",
      "Jinyu Li",
      "Sheng Zhao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2404.03227",
    "title": "Decentralized Learning Strategies for Estimation Error Minimization with  Graph Neural Networks",
    "abstract": "We address the challenge of sampling and remote estimation for autoregressive Markovian processes in a multi-hop wireless network with statistically-identical agents. Agents cache the most recent samples from others and communicate over wireless collision channels governed by an underlying graph topology. Our goal is to minimize time-average estimation error and/or age of information with decentralized scalable sampling and transmission policies, considering both oblivious (where decision-making is independent of the physical processes) and non-oblivious policies (where decision-making depends on physical processes). We prove that in oblivious policies, minimizing estimation error is equivalent to minimizing the age of information. The complexity of the problem, especially the multi-dimensional action spaces and arbitrary network topologies, makes theoretical methods for finding optimal transmission policies intractable. We optimize the policies using a graphical multi-agent reinforcement learning framework, where each agent employs a permutation-equivariant graph neural network architecture. Theoretically, we prove that our proposed framework exhibits desirable transferability properties, allowing transmission policies trained on small- or moderate-size networks to be executed effectively on large-scale topologies. Numerical experiments demonstrate that (i) Our proposed framework outperforms state-of-the-art baselines; (ii) The trained policies are transferable to larger networks, and their performance gains increase with the number of agents; (iii) The training procedure withstands non-stationarity even if we utilize independent learning techniques; and, (iv) Recurrence is pivotal in both independent learning and centralized training and decentralized execution, and improves the resilience to non-stationarity in independent learning. ",
    "url": "https://arxiv.org/abs/2404.03227",
    "authors": [
      "Xingran Chen",
      "Navid NaderiAlizadeh",
      "Alejandro Ribeiro",
      "Shirin Saeedi Bidokhti"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.03250",
    "title": "Multi-task learning via robust regularized clustering with non-convex  group penalties",
    "abstract": "Multi-task learning (MTL) aims to improve estimation and prediction performance by sharing common information among related tasks. One natural assumption in MTL is that tasks are classified into clusters based on their characteristics. However, existing MTL methods based on this assumption often ignore outlier tasks that have large task-specific components or no relation to other tasks. To address this issue, we propose a novel MTL method called Multi-Task Learning via Robust Regularized Clustering (MTLRRC). MTLRRC incorporates robust regularization terms inspired by robust convex clustering, which is further extended to handle non-convex and group-sparse penalties. The extension allows MTLRRC to simultaneously perform robust task clustering and outlier task detection. The connection between the extended robust clustering and the multivariate M-estimator is also established. This provides an interpretation of the robustness of MTLRRC against outlier tasks. An efficient algorithm based on a modified alternating direction method of multipliers is developed for the estimation of the parameters. The effectiveness of MTLRRC is demonstrated through simulation studies and application to real data. ",
    "url": "https://arxiv.org/abs/2404.03250",
    "authors": [
      "Akira Okazaki",
      "Shuichi Kawano"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2404.03332",
    "title": "A classification of well-behaved graph clustering schemes",
    "abstract": "Community detection in graphs is a problem that is likely to be relevant whenever network data appears, and consequently the problem has received much attention with many different methods and algorithms applied. However, many of these methods are hard to study theoretically, and they optimise for somewhat different goals. A general and rigorous account of the problem and possible methods remains elusive. We study the class of all clustering methods that are monotone under addition of vertices and edges, phrasing this as a functoriality notion. We show that if additionally we require the methods to have no resolution limit in a strong sense, this is equivalent to a notion of representability, which requires them to be explainable and determined by a representing set of graphs. We show that representable clustering methods are always computable in polynomial time, and in any nowhere dense class they are computable in roughly quadratic time. Finally, we extend our definitions to the case of hierarchical clustering, and give a notion of representability for hierarchical clustering schemes. ",
    "url": "https://arxiv.org/abs/2404.03332",
    "authors": [
      "Vilhelm Agdur"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Social and Information Networks (cs.SI)",
      "Category Theory (math.CT)"
    ]
  },
  {
    "id": "arXiv:2404.03425",
    "title": "ChangeMamba: Remote Sensing Change Detection with Spatio-Temporal State  Space Model",
    "abstract": "Convolutional neural networks (CNN) and Transformers have made impressive progress in the field of remote sensing change detection (CD). However, both architectures have their inherent shortcomings. Recently, the Mamba architecture, based on spatial state models, has shown remarkable performance in a series of natural language processing tasks, which can effectively compensate for the shortcomings of the above two architectures. In this paper, we explore for the first time the potential of the Mamba architecture for remote sensing change detection tasks. We tailor the corresponding frameworks, called MambaBCD, MambaSCD, and MambaBDA, for binary change detection (BCD), semantic change detection (SCD), and building damage assessment (BDA), respectively. All three frameworks adopt the cutting-edge visual Mamba architecture as the encoder, which allows full learning of global spatial contextual information from the input images. For the change decoder, which is available in all three architectures, we propose three spatio-temporal relationship modeling mechanisms, which can be naturally combined with the Mamba architecture and fully utilize its attribute to achieve spatio-temporal interaction of multi-temporal features and obtain accurate change information. On five benchmark datasets, our proposed frameworks outperform current CNN- and Transformer-based approaches without using any complex strategies or tricks, fully demonstrating the potential of the Mamba architecture. Specifically, we obtained 83.11%, 88.39% and 94.19% F1 scores on the three BCD datasets SYSU, LEVIR-CD+, and WHU-CD; on the SCD dataset SECOND, we obtained 24.04% SeK; and on the xBD dataset, we obtained 81.41% overall F1 score. The source code will be available in https://github.com/ChenHongruixuan/MambaCD ",
    "url": "https://arxiv.org/abs/2404.03425",
    "authors": [
      "Hongruixuan Chen",
      "Jian Song",
      "Chengxi Han",
      "Junshi Xia",
      "Naoto Yokoya"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.03506",
    "title": "CountARFactuals -- Generating plausible model-agnostic counterfactual  explanations with adversarial random forests",
    "abstract": "Counterfactual explanations elucidate algorithmic decisions by pointing to scenarios that would have led to an alternative, desired outcome. Giving insight into the model's behavior, they hint users towards possible actions and give grounds for contesting decisions. As a crucial factor in achieving these goals, counterfactuals must be plausible, i.e., describing realistic alternative scenarios within the data manifold. This paper leverages a recently developed generative modeling technique -- adversarial random forests (ARFs) -- to efficiently generate plausible counterfactuals in a model-agnostic way. ARFs can serve as a plausibility measure or directly generate counterfactual explanations. Our ARF-based approach surpasses the limitations of existing methods that aim to generate plausible counterfactual explanations: It is easy to train and computationally highly efficient, handles continuous and categorical data naturally, and allows integrating additional desiderata such as sparsity in a straightforward manner. ",
    "url": "https://arxiv.org/abs/2404.03506",
    "authors": [
      "Susanne Dandl",
      "Kristin Blesch",
      "Timo Freiesleben",
      "Gunnar K\u00f6nig",
      "Jan Kapar",
      "Bernd Bischl",
      "Marvin Wright"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.03549",
    "title": "Alzheimer's disease detection in PSG signals",
    "abstract": "Alzheimer's disease (AD) and sleep disorders exhibit a close association, where disruptions in sleep patterns often precede the onset of Mild Cognitive Impairment (MCI) and early-stage AD. This study delves into the potential of utilizing sleep-related electroencephalography (EEG) signals acquired through polysomnography (PSG) for the early detection of AD. Our primary focus is on exploring semi-supervised Deep Learning techniques for the classification of EEG signals due to the clinical scenario characterized by the limited data availability. The methodology entails testing and comparing the performance of semi-supervised SMATE and TapNet models, benchmarked against the supervised XCM model, and unsupervised Hidden Markov Models (HMMs). The study highlights the significance of spatial and temporal analysis capabilities, conducting independent analyses of each sleep stage. Results demonstrate the effectiveness of SMATE in leveraging limited labeled data, achieving stable metrics across all sleep stages, and reaching 90% accuracy in its supervised form. Comparative analyses reveal SMATE's superior performance over TapNet and HMM, while XCM excels in supervised scenarios with an accuracy range of 92 - 94%. These findings underscore the potential of semi-supervised models in early AD detection, particularly in overcoming the challenges associated with the scarcity of labeled data. Ablation tests affirm the critical role of spatio-temporal feature extraction in semi-supervised predictive performance, and t-SNE visualizations validate the model's proficiency in distinguishing AD patterns. Overall, this research contributes to the advancement of AD detection through innovative Deep Learning approaches, highlighting the crucial role of semi-supervised learning in addressing data limitations. ",
    "url": "https://arxiv.org/abs/2404.03549",
    "authors": [
      "Lorena Gallego-Vi\u00f1ar\u00e1s",
      "Juan Miguel Mira-Tom\u00e1s",
      "Anna Michela-Gaeta",
      "Gerard Pinol-Ripoll",
      "Ferr\u00e1n Barb\u00e9",
      "Pablo M. Olmos",
      "Arrate Mu\u00f1oz-Barrutia"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:1911.10829",
    "title": "Neural Random Forest Imitation",
    "abstract": " Comments: Published as part of \"Two Worlds in One Network: Fusing Deep Learning and Random Forests for Classification and Object Detection\" in Volunteered Geographic Information, Springer Nature Switzerland ",
    "url": "https://arxiv.org/abs/1911.10829",
    "authors": [
      "Christoph Reinders",
      "Bodo Rosenhahn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2007.06257",
    "title": "Rewiring the Transformer with Depth-Wise LSTMs",
    "abstract": " Title: Rewiring the Transformer with Depth-Wise LSTMs ",
    "url": "https://arxiv.org/abs/2007.06257",
    "authors": [
      "Hongfei Xu",
      "Yang Song",
      "Qiuhui Liu",
      "Josef van Genabith",
      "Deyi Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2010.08114",
    "title": "Distributed Representations of Entities in Open-World Knowledge Graphs",
    "abstract": " Comments: Knowledge-Based Systems 2024 ",
    "url": "https://arxiv.org/abs/2010.08114",
    "authors": [
      "Lingbing Guo",
      "Zhuo Chen",
      "Jiaoyan Chen",
      "Yichi Zhang",
      "Zequn Sun",
      "Zhongpo Bo",
      "Yin Fang",
      "Xiaoze Liu",
      "Huajun Chen",
      "Wen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2010.13187",
    "title": "Improving the Reconstruction of Disentangled Representation Learners via  Multi-Stage Modeling",
    "abstract": " Title: Improving the Reconstruction of Disentangled Representation Learners via  Multi-Stage Modeling ",
    "url": "https://arxiv.org/abs/2010.13187",
    "authors": [
      "Akash Srivastava",
      "Yamini Bansal",
      "Yukun Ding",
      "Cole Lincoln Hurwitz",
      "Kai Xu",
      "Bernhard Egger",
      "Prasanna Sattigeri",
      "Joshua B. Tenenbaum",
      "Phuong Le",
      "Arun Prakash R",
      "Nengfeng Zhou",
      "Joel Vaughan",
      "Yaquan Wang",
      "Anwesha Bhattacharyya",
      "Kristjan Greenewald",
      "David D. Cox",
      "Dan Gutfreund"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13856",
    "title": "Robust deep learning for eye fundus images: Bridging real and synthetic  data for enhancing generalization",
    "abstract": " Comments: Accepted by the Biomedical Signal Processing and Control ",
    "url": "https://arxiv.org/abs/2203.13856",
    "authors": [
      "Guilherme C. Oliveira",
      "Gustavo H. Rosa",
      "Daniel C. G. Pedronette",
      "Jo\u00e3o P. Papa",
      "Himeesh Kumar",
      "Leandro A. Passos",
      "Dinesh Kumar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.08310",
    "title": "Decomposition and factorisation of transients in Functional Graphs",
    "abstract": " Title: Decomposition and factorisation of transients in Functional Graphs ",
    "url": "https://arxiv.org/abs/2208.08310",
    "authors": [
      "Fran\u00e7ois Dor\u00e9",
      "Enrico Formenti",
      "Antonio E. Porreca",
      "Sara Riva"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2211.06073",
    "title": "SceneFake: An Initial Dataset and Benchmarks for Scene Fake Audio  Detection",
    "abstract": " Comments: Accepted by Pattern Recognition, 1 April 2024 ",
    "url": "https://arxiv.org/abs/2211.06073",
    "authors": [
      "Jiangyan Yi",
      "Chenglong Wang",
      "Jianhua Tao",
      "Chu Yuan Zhang",
      "Cunhang Fan",
      "Zhengkun Tian",
      "Haoxin Ma",
      "Ruibo Fu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2212.13179",
    "title": "Mining Architectural Information: A Systematic Mapping Study",
    "abstract": " Comments: Preprint accepted for publication in Empirical Software Engineering, 2024 ",
    "url": "https://arxiv.org/abs/2212.13179",
    "authors": [
      "Musengamana Jean de Dieu",
      "Peng Liang",
      "Mojtaba Shahin",
      "Chen Yang",
      "Zengyang Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.11963",
    "title": "NEMTO: Neural Environment Matting for Novel View and Relighting  Synthesis of Transparent Objects",
    "abstract": " Comments: ICCV 2023 ",
    "url": "https://arxiv.org/abs/2303.11963",
    "authors": [
      "Dongqing Wang",
      "Tong Zhang",
      "Sabine S\u00fcsstrunk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2304.12445",
    "title": "Real-Time Ground Fault Detection for Inverter-Based Microgrid Systems",
    "abstract": " Comments: 18 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2304.12445",
    "authors": [
      "Jingwei Dong",
      "Yucheng Liao",
      "Haiwei Xie",
      "Jochen Cremer",
      "Peyman Mohajerin Esfahani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.00006",
    "title": "Truncated Affinity Maximization: One-class Homophily Modeling for Graph  Anomaly Detection",
    "abstract": " Comments: Accepted at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.00006",
    "authors": [
      "Hezhe Qiao",
      "Guansong Pang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.05494",
    "title": "Adversarial Evasion Attacks Practicality in Networks: Testing the Impact  of Dynamic Learning",
    "abstract": " Title: Adversarial Evasion Attacks Practicality in Networks: Testing the Impact  of Dynamic Learning ",
    "url": "https://arxiv.org/abs/2306.05494",
    "authors": [
      "Mohamed el Shehaby",
      "Ashraf Matrawy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2307.02633",
    "title": "Hybrid Ground-State Quantum Algorithms based on Neural Schr\u00f6dinger  Forging",
    "abstract": " Comments: 12 pages, 9 figures, 5 pages supplemental material ",
    "url": "https://arxiv.org/abs/2307.02633",
    "authors": [
      "Paulin de Schoulepnikoff",
      "Oriel Kiss",
      "Sofia Vallecorsa",
      "Giuseppe Carleo",
      "Michele Grossi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.06647",
    "title": "DeepIPCv2: LiDAR-powered Robust Environmental Perception and  Navigational Control for Autonomous Vehicle",
    "abstract": " Title: DeepIPCv2: LiDAR-powered Robust Environmental Perception and  Navigational Control for Autonomous Vehicle ",
    "url": "https://arxiv.org/abs/2307.06647",
    "authors": [
      "Oskar Natan",
      "Jun Miura"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12301",
    "title": "Image Outlier Detection Without Training using RANSAC",
    "abstract": " Title: Image Outlier Detection Without Training using RANSAC ",
    "url": "https://arxiv.org/abs/2307.12301",
    "authors": [
      "Chen-Han Tsai",
      "Yu-Shao Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14406",
    "title": "Demystifying Code Snippets in Code Reviews: A Study of the OpenStack and  Qt Communities and A Practitioner Survey",
    "abstract": " Comments: Preprint accepted for publication in Empirical Software Engineering, 2024 ",
    "url": "https://arxiv.org/abs/2307.14406",
    "authors": [
      "Beiqi Zhang",
      "Liming Fu",
      "Peng Liang",
      "Jiaxin Yu",
      "Chong Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.02793",
    "title": "Crowdsourcing Fraud Detection over Heterogeneous Temporal MMMA Graph",
    "abstract": " Comments: Full technical report for our DASFAA 2024 paper: Crowdsourcing Fraud Detection over Heterogeneous Temporal MMMA Graph ",
    "url": "https://arxiv.org/abs/2308.02793",
    "authors": [
      "Zequan Xu",
      "Qihang Sun",
      "Shaofeng Hu",
      "Jieming Shi",
      "Hui Li"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.07402",
    "title": "Semi-supervised Domain Adaptation on Graphs with Contrastive Learning  and Minimax Entropy",
    "abstract": " Title: Semi-supervised Domain Adaptation on Graphs with Contrastive Learning  and Minimax Entropy ",
    "url": "https://arxiv.org/abs/2309.07402",
    "authors": [
      "Jiaren Xiao",
      "Quanyu Dai",
      "Xiao Shen",
      "Xiaochen Xie",
      "Jing Dai",
      "James Lam",
      "Ka-Wai Kwok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.08546",
    "title": "Towards Robust Continual Learning with Bayesian Adaptive Moment  Regularization",
    "abstract": " Title: Towards Robust Continual Learning with Bayesian Adaptive Moment  Regularization ",
    "url": "https://arxiv.org/abs/2309.08546",
    "authors": [
      "Jack Foster",
      "Alexandra Brintrup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.12521",
    "title": "Profile-Error-Tolerant Target-Speaker Voice Activity Detection",
    "abstract": " Comments: Submission for ICASSP 2024 ",
    "url": "https://arxiv.org/abs/2309.12521",
    "authors": [
      "Dongmei Wang",
      "Xiong Xiao",
      "Naoyuki Kanda",
      "Midia Yousefi",
      "Takuya Yoshioka",
      "Jian Wu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.12545",
    "title": "Provably Robust and Plausible Counterfactual Explanations for Neural  Networks via Robust Optimisation",
    "abstract": " Comments: Accepted at ACML 2023, camera-ready version ",
    "url": "https://arxiv.org/abs/2309.12545",
    "authors": [
      "Junqi Jiang",
      "Jianglin Lan",
      "Francesco Leofante",
      "Antonio Rago",
      "Francesca Toni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00615",
    "title": "Scene-aware Human Motion Forecasting via Mutual Distance Prediction",
    "abstract": " Title: Scene-aware Human Motion Forecasting via Mutual Distance Prediction ",
    "url": "https://arxiv.org/abs/2310.00615",
    "authors": [
      "Chaoyue Xing",
      "Wei Mao",
      "Miaomiao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00763",
    "title": "Data-Efficient Strategies for Probabilistic Voltage Envelopes under  Network Contingencies",
    "abstract": " Comments: 10 Pages ",
    "url": "https://arxiv.org/abs/2310.00763",
    "authors": [
      "Parikshit Pareek",
      "Deepjyoti Deka",
      "Sidhant Misra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.00965",
    "title": "Effective Learning with Node Perturbation in Deep Neural Networks",
    "abstract": " Comments: 14 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2310.00965",
    "authors": [
      "Sander Dalm",
      "Marcel van Gerven",
      "Nasir Ahmad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.02003",
    "title": "L2MAC: Large Language Model Automatic Computer for Extensive Code  Generation",
    "abstract": " Comments: Published in The Twelfth International Conference on Learning Representations (ICLR), 2024. Copyright 2023 by the author(s) ",
    "url": "https://arxiv.org/abs/2310.02003",
    "authors": [
      "Samuel Holt",
      "Max Ruiz Luyten",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2310.02059",
    "title": "Security Weaknesses of Copilot Generated Code in GitHub",
    "abstract": " Title: Security Weaknesses of Copilot Generated Code in GitHub ",
    "url": "https://arxiv.org/abs/2310.02059",
    "authors": [
      "Yujia Fu",
      "Peng Liang",
      "Amjed Tahir",
      "Zengyang Li",
      "Mojtaba Shahin",
      "Jiaxin Yu",
      "Jinfu Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.19454",
    "title": "MMM and MMMSynth: Clustering of heterogeneous tabular data, and  synthetic data generation",
    "abstract": " Comments: 17 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2310.19454",
    "authors": [
      "Chandrani Kumari",
      "Rahul Siddharthan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.05780",
    "title": "Real-time Control of Electric Autonomous Mobility-on-Demand Systems via  Graph Reinforcement Learning",
    "abstract": " Comments: 9 pages, revised SF travel data, includes additional experimental results, content and clarification revisions per reviewer feedback, and typo fixes ",
    "url": "https://arxiv.org/abs/2311.05780",
    "authors": [
      "Aaryan Singhal",
      "Daniele Gammelli",
      "Justin Luke",
      "Karthik Gopalakrishnan",
      "Dominik Helmreich",
      "Marco Pavone"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.10599",
    "title": "Chatbots as social companions: How people perceive consciousness, human  likeness, and social health benefits in machines",
    "abstract": " Comments: 18 pages, 3 figures, presented at ASSC '26 at NYU ",
    "url": "https://arxiv.org/abs/2311.10599",
    "authors": [
      "Rose E. Guingrich",
      "Michael S. A. Graziano"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16944",
    "title": "Teaching DevOps Security Education with Hands-on Labware: Automated  Detection of Security Weakness in Python",
    "abstract": " Title: Teaching DevOps Security Education with Hands-on Labware: Automated  Detection of Security Weakness in Python ",
    "url": "https://arxiv.org/abs/2311.16944",
    "authors": [
      "Mst Shapna Akter",
      "Juanjose Rodriguez-Cardenas",
      "Md Mostafizur Rahman",
      "Hossain Shahriar",
      "Akond Rahman",
      "Fan Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.00778",
    "title": "MorpheuS: Neural Dynamic 360\u00b0 Surface Reconstruction from Monocular  RGB-D Video",
    "abstract": " Comments: CVPR2024. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2312.00778",
    "authors": [
      "Hengyi Wang",
      "Jingwen Wang",
      "Lourdes Agapito"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.04609",
    "title": "Short-term prediction of construction waste transport activities using  AI-Truck",
    "abstract": " Comments: 11 pages, 15 figures ",
    "url": "https://arxiv.org/abs/2312.04609",
    "authors": [
      "Meng Xu",
      "Ke Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.11843",
    "title": "Enhancing Social Decision-Making of Autonomous Vehicles: A  Mixed-Strategy Game Approach With Interaction Orientation Identification",
    "abstract": " Title: Enhancing Social Decision-Making of Autonomous Vehicles: A  Mixed-Strategy Game Approach With Interaction Orientation Identification ",
    "url": "https://arxiv.org/abs/2312.11843",
    "authors": [
      "Jiaqi Liu",
      "Xiao Qi",
      "Peng Hang",
      "Jian Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2401.13785",
    "title": "Unified Spatio-Temporal Tri-Perspective View Representation for 3D  Semantic Occupancy Prediction",
    "abstract": " Title: Unified Spatio-Temporal Tri-Perspective View Representation for 3D  Semantic Occupancy Prediction ",
    "url": "https://arxiv.org/abs/2401.13785",
    "authors": [
      "Sathira Silva",
      "Savindu Bhashitha Wannigama",
      "Gihan Jayatilaka",
      "Muhammad Haris Khan",
      "Roshan Ragel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.14694",
    "title": "TA-RNN: an Attention-based Time-aware Recurrent Neural Network  Architecture for Electronic Health Records",
    "abstract": " Title: TA-RNN: an Attention-based Time-aware Recurrent Neural Network  Architecture for Electronic Health Records ",
    "url": "https://arxiv.org/abs/2401.14694",
    "authors": [
      "Mohammad Al Olaimat",
      "Serdar Bozdag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.05042",
    "title": "Sticky Fingers: Resilience of Satellite Fingerprinting against Jamming  Attacks",
    "abstract": " Comments: 9 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2402.05042",
    "authors": [
      "Joshua Smailes",
      "Edd Salkield",
      "Sebastian K\u00f6hler",
      "Simon Birnbach",
      "Martin Strohmeier",
      "Ivan Martinovic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.11322",
    "title": "SpikeNAS: A Fast Memory-Aware Neural Architecture Search Framework for  Spiking Neural Network-based Autonomous Agents",
    "abstract": " Comments: 8 pages, 13 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2402.11322",
    "authors": [
      "Rachmad Vidya Wicaksana Putra",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.11887",
    "title": "Generative Semi-supervised Graph Anomaly Detection",
    "abstract": " Comments: 13 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2402.11887",
    "authors": [
      "Hezhe Qiao",
      "Qingsong Wen",
      "Xiaoli Li",
      "Ee-Peng Lim",
      "Guansong Pang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.13332",
    "title": "Causal hybrid modeling with double machine learning",
    "abstract": " Title: Causal hybrid modeling with double machine learning ",
    "url": "https://arxiv.org/abs/2402.13332",
    "authors": [
      "Kai-Hendrik Cohrs",
      "Gherardo Varando",
      "Nuno Carvalhais",
      "Markus Reichstein",
      "Gustau Camps-Valls"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2402.13729",
    "title": "Hybrid Video Diffusion Models with 2D Triplane and 3D Wavelet  Representation",
    "abstract": " Comments: Project page is available at this https URL ",
    "url": "https://arxiv.org/abs/2402.13729",
    "authors": [
      "Kihong Kim",
      "Haneol Lee",
      "Jihye Park",
      "Seyeon Kim",
      "Kwanghee Lee",
      "Seungryong Kim",
      "Jaejun Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.14151",
    "title": "BIRCO: A Benchmark of Information Retrieval Tasks with Complex  Objectives",
    "abstract": " Title: BIRCO: A Benchmark of Information Retrieval Tasks with Complex  Objectives ",
    "url": "https://arxiv.org/abs/2402.14151",
    "authors": [
      "Xiaoyue Wang",
      "Jianyou Wang",
      "Weili Cao",
      "Kaicheng Wang",
      "Ramamohan Paturi",
      "Leon Bergen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.01216",
    "title": "API Is Enough: Conformal Prediction for Large Language Models Without  Logit-Access",
    "abstract": " Title: API Is Enough: Conformal Prediction for Large Language Models Without  Logit-Access ",
    "url": "https://arxiv.org/abs/2403.01216",
    "authors": [
      "Jiayuan Su",
      "Jing Luo",
      "Hongwei Wang",
      "Lu Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.03149",
    "title": "Robust Federated Learning Mitigates Client-side Training Data  Distribution Inference Attacks",
    "abstract": " Comments: To appear in The Web Conference 2024 (WWW '24) ",
    "url": "https://arxiv.org/abs/2403.03149",
    "authors": [
      "Yichang Xu",
      "Ming Yin",
      "Minghong Fang",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.07817",
    "title": "UniHand: Privacy-preserving Universal Handover for Small-Cell Networks  in 5G-enabled Mobile Communication with KCI Resilience",
    "abstract": " Title: UniHand: Privacy-preserving Universal Handover for Small-Cell Networks  in 5G-enabled Mobile Communication with KCI Resilience ",
    "url": "https://arxiv.org/abs/2403.07817",
    "authors": [
      "Rabiah Alnashwan",
      "Prosanta Gope",
      "Benjamin Dowling"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.14915",
    "title": "Network Learning with Directional Sign Patterns",
    "abstract": " Title: Network Learning with Directional Sign Patterns ",
    "url": "https://arxiv.org/abs/2403.14915",
    "authors": [
      "Anqi Dong",
      "Can Chen",
      "Tryphon T. Georgiou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.16301",
    "title": "Q-adaptive: A Multi-Agent Reinforcement Learning Based Routing on  Dragonfly Network",
    "abstract": " Title: Q-adaptive: A Multi-Agent Reinforcement Learning Based Routing on  Dragonfly Network ",
    "url": "https://arxiv.org/abs/2403.16301",
    "authors": [
      "Yao Kang",
      "Xin Wang",
      "Zhiling Lan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2403.16760",
    "title": "As Good As A Coin Toss: Human detection of AI-generated images, videos,  audio, and audiovisual stimuli",
    "abstract": " Comments: For study pre-registration, see this https URL ",
    "url": "https://arxiv.org/abs/2403.16760",
    "authors": [
      "Di Cooke",
      "Abigail Edwards",
      "Sophia Barkoff",
      "Kathryn Kelly"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2403.16826",
    "title": "A Progressive Codebook Optimization Scheme for Sparse Code Multiple  Access in Downlink Channels",
    "abstract": " Title: A Progressive Codebook Optimization Scheme for Sparse Code Multiple  Access in Downlink Channels ",
    "url": "https://arxiv.org/abs/2403.16826",
    "authors": [
      "Tuofeng Lei",
      "Qu Luo",
      "Shuyan Ni",
      "Shimiao Chen",
      "Xin Song",
      "Pei Xiao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2403.17036",
    "title": "Union: An Automatic Workload Manager for Accelerating Network Simulation",
    "abstract": " Title: Union: An Automatic Workload Manager for Accelerating Network Simulation ",
    "url": "https://arxiv.org/abs/2403.17036",
    "authors": [
      "Xin Wang",
      "Misbah Mubarak",
      "Yao Kang",
      "Robert B. Ross",
      "Zhiling Lan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2403.17729",
    "title": "EulerFormer: Sequential User Behavior Modeling with Complex Vector  Attention",
    "abstract": " Comments: Accepted for publication in SIGIR'24 ",
    "url": "https://arxiv.org/abs/2403.17729",
    "authors": [
      "Zhen Tian",
      "Wayne Xin Zhao",
      "Changwang Zhang",
      "Xin Zhao",
      "Zhongrui Ma",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.19612",
    "title": "ILPO-NET: Network for the invariant recognition of arbitrary volumetric  patterns in 3D",
    "abstract": " Title: ILPO-NET: Network for the invariant recognition of arbitrary volumetric  patterns in 3D ",
    "url": "https://arxiv.org/abs/2403.19612",
    "authors": [
      "Dmitrii Zhemchuzhnikov",
      "Sergei Grudinin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00391",
    "title": "Robust time-discretisation and linearisation schemes for singular and  degenerate evolution systems modelling biofilm growth",
    "abstract": " Comments: 40 pages,7 figures, journal submission ",
    "url": "https://arxiv.org/abs/2404.00391",
    "authors": [
      "R.K.H. Smeets",
      "K. Mitra",
      "I.S. Pop",
      "S. Sonner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2404.00775",
    "title": "Measuring audio prompt adherence with distribution-based embedding  distances",
    "abstract": " Title: Measuring audio prompt adherence with distribution-based embedding  distances ",
    "url": "https://arxiv.org/abs/2404.00775",
    "authors": [
      "Maarten Grachten"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2404.00826",
    "title": "Extracting Social Determinants of Health from Pediatric Patient Notes  Using Large Language Models: Novel Corpus and Methods",
    "abstract": " Comments: 12 pages, 2 figures and 3 tables. Accepted by LREC-COLING 2024 ",
    "url": "https://arxiv.org/abs/2404.00826",
    "authors": [
      "Yujuan Fu",
      "Giridhar Kaushik Ramachandran",
      "Nicholas J Dobbins",
      "Namu Park",
      "Michael Leu",
      "Abby R. Rosenberg",
      "Kevin Lybarger",
      "Fei Xia",
      "Ozlem Uzuner",
      "Meliha Yetisgen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.01064",
    "title": "Roadside Monocular 3D Detection via 2D Detection Prompting",
    "abstract": " Title: Roadside Monocular 3D Detection via 2D Detection Prompting ",
    "url": "https://arxiv.org/abs/2404.01064",
    "authors": [
      "Yechi Ma",
      "Shuoquan Wei",
      "Churun Zhang",
      "Wei Hua",
      "Yanan Li",
      "Shu Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.01685",
    "title": "A Methodology for Improving Accuracy of Embedded Spiking Neural Networks  through Kernel Size Scaling",
    "abstract": " Comments: 3 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2404.01685",
    "authors": [
      "Rachmad Vidya Wicaksana Putra",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.01965",
    "title": "Towards Leveraging AutoML for Sustainable Deep Learning: A  Multi-Objective HPO Approach on Deep Shift Neural Networks",
    "abstract": " Title: Towards Leveraging AutoML for Sustainable Deep Learning: A  Multi-Objective HPO Approach on Deep Shift Neural Networks ",
    "url": "https://arxiv.org/abs/2404.01965",
    "authors": [
      "Leona Hennig",
      "Tanja Tornede",
      "Marius Lindauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.01988",
    "title": "Cooperative Students: Navigating Unsupervised Domain Adaptation in  Nighttime Object Detection",
    "abstract": " Comments: Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2404.01988",
    "authors": [
      "Jicheng Yuan",
      "Anh Le-Tuan",
      "Manfred Hauswirth",
      "Danh Le-Phuoc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.02072",
    "title": "EGTR: Extracting Graph from Transformer for Scene Graph Generation",
    "abstract": " Comments: CVPR 2024 ",
    "url": "https://arxiv.org/abs/2404.02072",
    "authors": [
      "Jinbae Im",
      "JeongYeon Nam",
      "Nokyung Park",
      "Hyungmin Lee",
      "Seunghyun Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.02405",
    "title": "TE-TAD: Towards Full End-to-End Temporal Action Detection via  Time-Aligned Coordinate Expression",
    "abstract": " Title: TE-TAD: Towards Full End-to-End Temporal Action Detection via  Time-Aligned Coordinate Expression ",
    "url": "https://arxiv.org/abs/2404.02405",
    "authors": [
      "Ho-Joong Kim",
      "Jung-Ho Hong",
      "Heejo Kong",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.02614",
    "title": "Vestibular schwannoma growth prediction from longitudinal MRI by time  conditioned neural fields",
    "abstract": " Title: Vestibular schwannoma growth prediction from longitudinal MRI by time  conditioned neural fields ",
    "url": "https://arxiv.org/abs/2404.02614",
    "authors": [
      "Yunjie Chen",
      "Jelmer M. Wolterink",
      "Olaf M. Neve",
      "Stephan R. Romeijn",
      "Berit M. Verbist",
      "Erik F. Hensen",
      "Qian Tao",
      "Marius Staring"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.02656",
    "title": "Non-negative Subspace Feature Representation for Few-shot Learning in  Medical Imaging",
    "abstract": " Title: Non-negative Subspace Feature Representation for Few-shot Learning in  Medical Imaging ",
    "url": "https://arxiv.org/abs/2404.02656",
    "authors": [
      "Keqiang Fan",
      "Xiaohao Cai",
      "Mahesan Niranjan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]